[{"id": "1707.00030", "submitter": "Wieslaw Kopec", "authors": "Wies{\\l}aw Kope\\'c (1), Kinga Skorupska (1), Anna Jaskulska (1),\n  Katarzyna Abramczuk (2), Radoslaw Nielek (1) and Adam Wierzbicki (1) ((1)\n  Polish-Japanese Academy of Information Technology, Warsaw, Poland, (2) Warsaw\n  University, Warsaw, Poland)", "title": "LivingLab PJAIT: Towards Better Urban Participation of Seniors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a brief summary of development LivingLab PJAIT as an\nattempt to establish a comprehensive and sustainable ICT-based solution for\nempowerment of elderly communities towards better urban participation of\nseniors. We report on our various endeavors for better involvement and\nparticipation of older adults in urban life by lowering ICT barriers,\nencouraging social inclusion, intergenerational interaction, physical activity\nand engaging older adults in the process of development of ICT solutions. We\nreport on a model and assumptions of the LivingLab PJAIT as well as a number of\nactivities created and implemented for LivingLab participants: from ICT\ncourses, both traditional and e-learning, through on-line crowdsourcing tasks,\nto blended activities of different forms and complexity. We also provide\nconclusions on the lessons learned in the process and some future plans,\nincluding solutions for better senior urban participation and citizen science.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 19:42:58 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Kope\u0107", "Wies\u0142aw", ""], ["Skorupska", "Kinga", ""], ["Jaskulska", "Anna", ""], ["Abramczuk", "Katarzyna", ""], ["Nielek", "Radoslaw", ""], ["Wierzbicki", "Adam", ""]]}, {"id": "1707.00046", "submitter": "Alexandra Chouldechova", "authors": "Alexandra Chouldechova and Max G'Sell", "title": "Fairer and more accurate, but for whom?", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex statistical machine learning models are increasingly being used or\nconsidered for use in high-stakes decision-making pipelines in domains such as\nfinancial services, health care, criminal justice and human services. These\nmodels are often investigated as possible improvements over more classical\ntools such as regression models or human judgement. While the modeling approach\nmay be new, the practice of using some form of risk assessment to inform\ndecisions is not. When determining whether a new model should be adopted, it is\ntherefore essential to be able to compare the proposed model to the existing\napproach across a range of task-relevant accuracy and fairness metrics. Looking\nat overall performance metrics, however, may be misleading. Even when two\nmodels have comparable overall performance, they may nevertheless disagree in\ntheir classifications on a considerable fraction of cases. In this paper we\nintroduce a model comparison framework for automatically identifying subgroups\nin which the differences between models are most pronounced. Our primary focus\nis on identifying subgroups where the models differ in terms of\nfairness-related quantities such as racial or gender disparities. We present\nexperimental results from a recidivism prediction task and a hypothetical\nlending example.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 21:07:09 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Chouldechova", "Alexandra", ""], ["G'Sell", "Max", ""]]}, {"id": "1707.00061", "submitter": "Su Lin Blodgett", "authors": "Su Lin Blodgett, Brendan O'Connor", "title": "Racial Disparity in Natural Language Processing: A Case Study of Social\n  Media African-American English", "comments": "Presented as a talk at the 2017 Workshop on Fairness, Accountability,\n  and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We highlight an important frontier in algorithmic fairness: disparity in the\nquality of natural language processing algorithms when applied to language from\nauthors of different social groups. For example, current systems sometimes\nanalyze the language of females and minorities more poorly than they do of\nwhites and males. We conduct an empirical analysis of racial disparity in\nlanguage identification for tweets written in African-American English, and\ndiscuss implications of disparity in NLP.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 22:57:50 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Blodgett", "Su Lin", ""], ["O'Connor", "Brendan", ""]]}, {"id": "1707.00075", "submitter": "Alex Beutel", "authors": "Alex Beutel, Jilin Chen, Zhe Zhao, Ed H. Chi", "title": "Data Decisions and Theoretical Implications when Adversarially Learning\n  Fair Representations", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we learn a classifier that is \"fair\" for a protected or sensitive\ngroup, when we do not know if the input to the classifier belongs to the\nprotected group? How can we train such a classifier when data on the protected\ngroup is difficult to attain? In many settings, finding out the sensitive input\nattribute can be prohibitively expensive even during model training, and\nsometimes impossible during model serving. For example, in recommender systems,\nif we want to predict if a user will click on a given recommendation, we often\ndo not know many attributes of the user, e.g., race or age, and many attributes\nof the content are hard to determine, e.g., the language or topic. Thus, it is\nnot feasible to use a different classifier calibrated based on knowledge of the\nsensitive attribute.\n  Here, we use an adversarial training procedure to remove information about\nthe sensitive attribute from the latent representation learned by a neural\nnetwork. In particular, we study how the choice of data for the adversarial\ntraining effects the resulting fairness properties. We find two interesting\nresults: a small amount of data is needed to train these adversarial models,\nand the data distribution empirically drives the adversary's notion of\nfairness.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 01:09:33 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 01:31:36 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Beutel", "Alex", ""], ["Chen", "Jilin", ""], ["Zhao", "Zhe", ""], ["Chi", "Ed H.", ""]]}, {"id": "1707.00093", "submitter": "Robin Burke", "authors": "Robin Burke", "title": "Multisided Fairness for Recommendation", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on machine learning has begun to consider issues of fairness. In\nthis paper, we extend the concept of fairness to recommendation. In particular,\nwe show that in some recommendation contexts, fairness may be a multisided\nconcept, in which fair outcomes for multiple individuals need to be considered.\nBased on these considerations, we present a taxonomy of classes of\nfairness-aware recommender systems and suggest possible fairness-aware\nrecommendation architectures.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 04:14:02 GMT"}, {"version": "v2", "created": "Sat, 8 Jul 2017 12:13:59 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Burke", "Robin", ""]]}, {"id": "1707.00338", "submitter": "Luciana Foss", "authors": "Leila Ribeiro, Luciana Foss, Simone Andr\\'e da Costa Cavalheiro", "title": "Entendendo o Pensamento Computacional", "comments": "18 pages, in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this article is to clarify the meaning of Computational Thinking.\nWe differentiate logical from computational reasoning and discuss the\nimportance of Computational Thinking in solving problems. The three pillars of\nComputational Thinking - Abstraction, Automation and Analysis - are outlined,\nhighlighting the role of each one in developing the skills needed for the\nproblem-solving process.\n  -----\n  O objetivo deste artigo \\'e esclarecer o significado de Pensamento\nComputacional. Diferencia-se o racioc\\'inio l\\'ogico do computacional e\ndiscute-se a import\\^ancia do Pensamento Computacional na resolu\\c{c}\\~ao de\nproblemas. Os tr\\^es pilares do Pensamento Computacional - Abstra\\c{c}\\~ao,\nAutoma\\c{c}\\~ao e An\\'alise - s\\~ao delineados, destacando-se o papel de cada\num deles no desenvolvimento das habilidades necess\\'arias para o processo de\nsolu\\c{c}\\~ao de problemas.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jul 2017 19:38:55 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Ribeiro", "Leila", ""], ["Foss", "Luciana", ""], ["Cavalheiro", "Simone Andr\u00e9 da Costa", ""]]}, {"id": "1707.00391", "submitter": "Suresh Venkatasubramanian", "authors": "Amanda Bower and Sarah N. Kitchen and Laura Niss and Martin J. Strauss\n  and Alexander Vargas and Suresh Venkatasubramanian", "title": "Fair Pipelines", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work facilitates ensuring fairness of machine learning in the real world\nby decoupling fairness considerations in compound decisions. In particular,\nthis work studies how fairness propagates through a compound decision-making\nprocesses, which we call a pipeline. Prior work in algorithmic fairness only\nfocuses on fairness with respect to one decision. However, many decision-making\nprocesses require more than one decision. For instance, hiring is at least a\ntwo stage model: deciding who to interview from the applicant pool and then\ndeciding who to hire from the interview pool. Perhaps surprisingly, we show\nthat the composition of fair components may not guarantee a fair pipeline under\na $(1+\\varepsilon)$-equal opportunity definition of fair. However, we identify\ncircumstances that do provide that guarantee. We also propose numerous\ndirections for future work on more general compound machine learning decisions.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 03:53:29 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Bower", "Amanda", ""], ["Kitchen", "Sarah N.", ""], ["Niss", "Laura", ""], ["Strauss", "Martin J.", ""], ["Vargas", "Alexander", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "1707.00432", "submitter": "Daniel Graziotin", "authors": "Daniel Graziotin, Fabian Fagerholm, Xiaofeng Wang, Pekka Abrahamsson", "title": "What happens when software developers are (un)happy", "comments": "18 pages, 2 figures", "journal-ref": "Journal of Systems and Software (2018), 140, 32-47", "doi": "10.1016/j.jss.2018.02.041", "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing literature on affect among software developers mostly reports on\nthe linkage between happiness, software quality, and developer productivity.\nUnderstanding happiness and unhappiness in all its components -- positive and\nnegative emotions and moods -- is an attractive and important endeavor.\nScholars in industrial and organizational psychology have suggested that\nunderstanding happiness and unhappiness could lead to cost-effective ways of\nenhancing working conditions, job performance, and to limiting the occurrence\nof psychological disorders. Our comprehension of the consequences of\n(un)happiness among developers is still too shallow, being mainly expressed in\nterms of development productivity and software quality. In this paper, we study\nwhat happens when developers are happy and unhappy while developing software.\nQualitative data analysis of responses given by 317 questionnaire participants\nidentified 42 consequences of unhappiness and 32 of happiness. We found\nconsequences of happiness and unhappiness that are beneficial and detrimental\nfor developers' mental well-being, the software development process, and the\nproduced artifacts. Our classification scheme, available as open data enables\nnew happiness research opportunities of cause-effect type, and it can act as a\nguideline for practitioners for identifying damaging effects of unhappiness and\nfor fostering happiness on the job.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 07:48:08 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 11:00:02 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 15:13:45 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Graziotin", "Daniel", ""], ["Fagerholm", "Fabian", ""], ["Wang", "Xiaofeng", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1707.00574", "submitter": "Azadeh Nematzadeh", "authors": "Azadeh Nematzadeh, Giovanni Luca Ciampaglia, Filippo Menczer,\n  Alessandro Flammini", "title": "How algorithmic popularity bias hinders or promotes quality", "comments": null, "journal-ref": "Scientific Reports Volume 8, Article number: 15951 (2018)", "doi": "10.1038/s41598-018-34203-2", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms that favor popular items are used to help us select among many\nchoices, from engaging articles on a social media news feed to songs and books\nthat others have purchased, and from top-raked search engine results to\nhighly-cited scientific papers. The goal of these algorithms is to identify\nhigh-quality items such as reliable news, beautiful movies, prestigious\ninformation sources, and important discoveries --- in short, high-quality\ncontent should rank at the top. Prior work has shown that choosing what is\npopular may amplify random fluctuations and ultimately lead to sub-optimal\nrankings. Nonetheless, it is often assumed that recommending what is popular\nwill help high-quality content \"bubble up\" in practice. Here we identify the\nconditions in which popularity may be a viable proxy for quality content by\nstudying a simple model of cultural market endowed with an intrinsic notion of\nquality. A parameter representing the cognitive cost of exploration controls\nthe critical trade-off between quality and popularity. We find a regime of\nintermediate exploration cost where an optimal balance exists, such that\nchoosing what is popular actually promotes high-quality items to the top.\nOutside of these limits, however, popularity bias is more likely to hinder\nquality. These findings clarify the effects of algorithmic popularity bias on\nquality outcomes, and may inform the design of more principled mechanisms for\ntechno-social cultural markets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 14:42:03 GMT"}, {"version": "v2", "created": "Fri, 14 Jul 2017 21:06:23 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Nematzadeh", "Azadeh", ""], ["Ciampaglia", "Giovanni Luca", ""], ["Menczer", "Filippo", ""], ["Flammini", "Alessandro", ""]]}, {"id": "1707.00599", "submitter": "Vasant Honavar", "authors": "Vasant G. Honavar, Katherine Yelick, Klara Nahrstedt, Holly Rushmeier,\n  Jennifer Rexford, Mark D. Hill, Elizabeth Bradley, and Elizabeth Mynatt", "title": "Advanced Cyberinfrastructure for Science, Engineering, and Public Policy", "comments": "A Computing Community Consortium (CCC) white paper, 9 pages. arXiv\n  admin note: text overlap with arXiv:1604.02006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in many domains increasingly benefits from our ability to view the\nsystems through a computational lens, i.e., using computational abstractions of\nthe domains; and our ability to acquire, share, integrate, and analyze\ndisparate types of data. These advances would not be possible without the\nadvanced data and computational cyberinfrastructure and tools for data capture,\nintegration, analysis, modeling, and simulation. However, despite, and perhaps\nbecause of, advances in \"big data\" technologies for data acquisition,\nmanagement and analytics, the other largely manual, and labor-intensive aspects\nof the decision making process, e.g., formulating questions, designing studies,\norganizing, curating, connecting, correlating and integrating crossdomain data,\ndrawing inferences and interpreting results, have become the rate-limiting\nsteps to progress. Advancing the capability and capacity for evidence-based\nimprovements in science, engineering, and public policy requires support for\n(1) computational abstractions of the relevant domains coupled with\ncomputational methods and tools for their analysis, synthesis, simulation,\nvisualization, sharing, and integration; (2) cognitive tools that leverage and\nextend the reach of human intellect, and partner with humans on all aspects of\nthe activity; (3) nimble and trustworthy data cyber-infrastructures that\nconnect, manage a variety of instruments, multiple interrelated data types and\nassociated metadata, data representations, processes, protocols and workflows;\nand enforce applicable security and data access and use policies; and (4)\norganizational and social structures and processes for collaborative and\ncoordinated activity across disciplinary and institutional boundaries.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 16:21:05 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Honavar", "Vasant G.", ""], ["Yelick", "Katherine", ""], ["Nahrstedt", "Klara", ""], ["Rushmeier", "Holly", ""], ["Rexford", "Jennifer", ""], ["Hill", "Mark D.", ""], ["Bradley", "Elizabeth", ""], ["Mynatt", "Elizabeth", ""]]}, {"id": "1707.00754", "submitter": "Radoslaw Nielek", "authors": "Grzegorz Kowalik, Radoslaw Nielek", "title": "Senior Programmers: Characteristics of Elderly Users from Stack Overflow", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-47874-6_7", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we presents results of research about elderly users of Stack\nOverflow (Question and Answer portal for programmers). They have different\nroles, different main activities and different habits. They are an important\npart of the community, as they tend to have higher reputation and they like to\nshare their knowledge. This is a great example of possible way of keeping\nelderly people active and helpful for society.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 20:51:36 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Kowalik", "Grzegorz", ""], ["Nielek", "Radoslaw", ""]]}, {"id": "1707.00780", "submitter": "Chao Lan", "authors": "Chao Lan and Jun Huan", "title": "Discriminatory Transfer", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe standard transfer learning can improve prediction accuracies of\ntarget tasks at the cost of lowering their prediction fairness -- a phenomenon\nwe named discriminatory transfer. We examine prediction fairness of a standard\nhypothesis transfer algorithm and a standard multi-task learning algorithm, and\nshow they both suffer discriminatory transfer on the real-world Communities and\nCrime data set. The presented case study introduces an interaction between\nfairness and transfer learning, as an extension of existing fairness studies\nthat focus on single task learning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 23:20:39 GMT"}, {"version": "v2", "created": "Sat, 8 Jul 2017 15:02:09 GMT"}, {"version": "v3", "created": "Thu, 13 Jul 2017 15:29:17 GMT"}, {"version": "v4", "created": "Mon, 7 Aug 2017 21:00:19 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Lan", "Chao", ""], ["Huan", "Jun", ""]]}, {"id": "1707.00781", "submitter": "David Sanchez", "authors": "Bruno Gon\\c{c}alves, Luc\\'ia Loureiro-Porto, Jos\\'e J. Ramasco, David\n  S\\'anchez", "title": "Mapping the Americanization of English in Space and Time", "comments": "16 pages, 6 figures, 2 tables. Published version", "journal-ref": "PLoS ONE 13: e0197741 (2018)", "doi": "10.1371/journal.pone.0197741", "report-no": null, "categories": "cs.CL cond-mat.stat-mech cs.CY physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As global political preeminence gradually shifted from the United Kingdom to\nthe United States, so did the capacity to culturally influence the rest of the\nworld. In this work, we analyze how the world-wide varieties of written English\nare evolving. We study both the spatial and temporal variations of vocabulary\nand spelling of English using a large corpus of geolocated tweets and the\nGoogle Books datasets corresponding to books published in the US and the UK.\nThe advantage of our approach is that we can address both standard written\nlanguage (Google Books) and the more colloquial forms of microblogging messages\n(Twitter). We find that American English is the dominant form of English\noutside the UK and that its influence is felt even within the UK borders.\nFinally, we analyze how this trend has evolved over time and the impact that\nsome cultural events have had in shaping it.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 23:32:55 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 12:27:21 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Gon\u00e7alves", "Bruno", ""], ["Loureiro-Porto", "Luc\u00eda", ""], ["Ramasco", "Jos\u00e9 J.", ""], ["S\u00e1nchez", "David", ""]]}, {"id": "1707.00863", "submitter": "Ciprian Corneanu", "authors": "Sergio Alloza, Flavio Escribano, Sergi Delgado, Ciprian Corneanu,\n  Sergio Escalera", "title": "XBadges. Identifying and training soft skills with commercial video\n  games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XBadges is a research project based on the hypothesis that commercial video\ngames (nonserious games) can train soft skills. We measure persistence, spatial\nreasoning and risk taking before and after subjects participate in controlled\ngame playing sessions. In addition, we have developed an automatic facial\nexpression recognition system capable of inferring their emotions while\nplaying, allowing us to study the role of emotions in soft skills acquisition.\nWe have used Flappy Bird, Pacman and Tetris for assessing changes in\npersistence, risk taking and spatial reasoning respectively. Results show how\nplaying Tetris significantly improves spatial reasoning and how playing Pacman\nsignificantly improves prudence in certain areas of behavior. As for emotions,\nthey reveal that being concentrated helps to improve performance and skills\nacquisition. Frustration is also shown as a key element. With the results\nobtained we are able to glimpse multiple applications in areas which need soft\nskills development.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 09:05:37 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Alloza", "Sergio", ""], ["Escribano", "Flavio", ""], ["Delgado", "Sergi", ""], ["Corneanu", "Ciprian", ""], ["Escalera", "Sergio", ""]]}, {"id": "1707.00906", "submitter": "Eszter Hazai", "authors": "Zsolt Bikadi, Sapumal Ahangama, Eszter Hazai", "title": "Prediction of Domain Values: High throughput screening of domain names\n  using Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As connected devices multiply and the internet matures into a ubiquitous\nplatform for exchange and communication, the question of what makes a domain\nname valuable is ever more significant. Due to the scarcity of meaningful\nvocabulary and the persistence of domain-related data, the buying and selling\nof previously owned domain names, also known as the domain aftermarket, has\nevolved into a billion dollar industry. Each day over a 100,000 domain names\nexpire and become available for re-registration. Manual appraisal is impossible\nat such a volume; thus a method for the automated identification of valuable\ndomain names is called for. The aim of our study was to develop a method for\nhigh throughput screening of domain names for rapid identification of the\nvaluable ones. Five different aspects that make a domain name valuable were\nidentified: name quality, domain authority, domain traffic, active domain age\nand domain health. An SVM method was developed for high throughput screening of\ndomain names. Our method was able to identify valuable domain names with 97%\naccuracy for the test set and 93% for the external set and can be used for\nroutinely screening the domain aftermarket.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 10:59:11 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Bikadi", "Zsolt", ""], ["Ahangama", "Sapumal", ""], ["Hazai", "Eszter", ""]]}, {"id": "1707.00971", "submitter": "Camila Ara\\'ujo", "authors": "Camila Souza Araujo, Gabriel Magno, Wagner Meira Jr, Virgilio Almeida,\n  Pedro Hartung and Danilo Doneda", "title": "Characterizing videos, audience and advertising in Youtube channels for\n  kids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online video services, messaging systems, games and social media services are\ntremendously popular among young people and children in many countries. Most of\nthe digital services offered on the internet are advertising funded, which\nmakes advertising ubiquitous in children's everyday life. To understand the\nimpact of advertising-based digital services on children, we study the\ncollective behavior of users of YouTube for kids channels and present the\ndemographics of a large number of users. We collected data from 12,848 videos\nfrom 17 channels in US and UK and 24 channels in Brazil. The channels in\nEnglish have been viewed more than 37 billion times. We also collected more\nthan 14 million comments made by users. Based on a combination of text-analysis\nand face recognition tools, we show the presence of racial and gender biases in\nour large sample of users. We also identify children actively using YouTube,\nalthough the minimum age for using the service is 13 years in most countries.\nWe provide comparisons of user behavior among the three countries, which\nrepresent large user populations in the global North and the global South.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 13:31:03 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Araujo", "Camila Souza", ""], ["Magno", "Gabriel", ""], ["Meira", "Wagner", "Jr"], ["Almeida", "Virgilio", ""], ["Hartung", "Pedro", ""], ["Doneda", "Danilo", ""]]}, {"id": "1707.01031", "submitter": "Mohammad S. Jalali", "authors": "M. S. Jalali", "title": "Decision-Making and Biases in Cybersecurity Capability Development:\n  Evidence from a Simulation Game Experiment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC math.DS stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed a simulation game to study the effectiveness of decision-makers\nin overcoming two complexities in building cybersecurity capabilities:\npotential delays in capability development; and uncertainties in predicting\ncyber incidents. Analyzing 1,479 simulation runs, we compared the performances\nof a group of experienced professionals with those of an inexperienced control\ngroup. Experienced subjects did not understand the mechanisms of delays any\nbetter than inexperienced subjects; however, experienced subjects were better\nable to learn the need for proactive decision-making through an iterative\nprocess. Both groups exhibited similar errors when dealing with the uncertainty\nof cyber incidents. Our findings highlight the importance of training for\ndecision-makers with a focus on systems thinking skills, and lay the groundwork\nfor future research on uncovering mental biases about the complexities of\ncybersecurity.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 15:17:38 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 19:23:07 GMT"}, {"version": "v3", "created": "Mon, 8 Jan 2018 22:14:17 GMT"}, {"version": "v4", "created": "Tue, 3 Jul 2018 00:06:29 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Jalali", "M. S.", ""]]}, {"id": "1707.01032", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute, Carolina Lang, Nicolas B. Ponieman, Sebastian\n  Anapolsky", "title": "The City Pulse of Buenos Aires", "comments": "Published in NetMob 2015 (Fourth Conference on the Scientific\n  Analysis of Mobile Phone Datasets), MIT Media Lab, Cambridge, USA, 8-10 April\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cell phone technology generates massive amounts of data. Although this data\nhas been gathered for billing and logging purposes, today it has a much higher\nvalue, because its volume makes it very useful for big data analyses. In this\nproject, we analyze the viability of using cell phone records to lower the cost\nof urban and transportation planning, in particular, to find out how people\ntravel in a specific city (in this case, Buenos Aires, in Argentina). We use\nanonymized cell phone data to estimate the distribution of the population in\nthe city using different periods of time. We compare those results with\ntraditional methods (urban polling) using data from Buenos Aires\norigin-destination surveys. Traditional polling methods have a much smaller\nsample, in the order of tens of thousands (or even less for smaller cities), to\nmaintain reasonable costs. Furthermore, these studies are performed at most\nonce per decade, in the best cases, in Argentina and many other countries. Our\nobjective is to prove that new methods based on cell phone data are reliable,\nand can be used indirectly to keep a real-time track of the flow of people\namong different parts of a city. We also go further to explore new\npossibilities opened by these methods.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 15:18:06 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 18:31:46 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Sarraute", "Carlos", ""], ["Lang", "Carolina", ""], ["Ponieman", "Nicolas B.", ""], ["Anapolsky", "Sebastian", ""]]}, {"id": "1707.01149", "submitter": "Carlos Sarraute", "authors": "Juan de Monasterio, Alejo Salles, Carolina Lang, Diego Weinberg,\n  Martin Minnoni, Matias Travizano, Carlos Sarraute", "title": "Analyzing the Spread of Chagas Disease with Mobile Phone Data", "comments": "6 pages, 6 figures", "journal-ref": "IEEE/ACM ASONAM pp. 607-612, San Francisco CA, USA, August 18-21\n  (2016)", "doi": "10.1109/ASONAM.2016.7752298", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We use mobile phone records for the analysis of mobility patterns and the\ndetection of possible risk zones of Chagas disease in two Latin American\ncountries. We show that geolocalized call records are rich in social and\nindividual information, which can be used to infer whether an individual has\nlived in an endemic area. We present two case studies, in Argentina and in\nMexico, using data provided by mobile phone companies from each country. The\nrisk maps that we generate can be used by health campaign managers to target\nspecific areas and allocate resources more effectively.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 20:50:42 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["de Monasterio", "Juan", ""], ["Salles", "Alejo", ""], ["Lang", "Carolina", ""], ["Weinberg", "Diego", ""], ["Minnoni", "Martin", ""], ["Travizano", "Matias", ""], ["Sarraute", "Carlos", ""]]}, {"id": "1707.01377", "submitter": "Edouard Ribes", "authors": "Edouard Ribes (1), Karim Touahri (2), Beno\\^it Perthame (3) ((1) IRSEM\n  (2) UPD5 (3) LJLL)", "title": "Employee turnover prediction and retention policies design: a case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper illustrates the similarities between the problems of customer\nchurn and employee turnover. An example of employee turnover prediction model\nleveraging classical machine learning techniques is developed. Model outputs\nare then discussed to design \\& test employee retention policies. This type of\nretention discussion is, to our knowledge, innovative and constitutes the main\nvalue of this paper.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 13:06:54 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Ribes", "Edouard", ""], ["Touahri", "Karim", ""], ["Perthame", "Beno\u00eet", ""]]}, {"id": "1707.01477", "submitter": "Michael Veale", "authors": "Reuben Binns, Michael Veale, Max Van Kleek, Nigel Shadbolt", "title": "Like trainer, like bot? Inheritance of bias in algorithmic content\n  moderation", "comments": "12 pages, 3 figures, 9th International Conference on Social\n  Informatics (SocInfo 2017), Oxford, UK, 13--15 September 2017 (forthcoming in\n  Springer Lecture Notes in Computer Science)", "journal-ref": null, "doi": "10.1007/978-3-319-67256-4_32", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internet has become a central medium through which `networked publics'\nexpress their opinions and engage in debate. Offensive comments and personal\nattacks can inhibit participation in these spaces. Automated content moderation\naims to overcome this problem using machine learning classifiers trained on\nlarge corpora of texts manually annotated for offence. While such systems could\nhelp encourage more civil debate, they must navigate inherently normatively\ncontestable boundaries, and are subject to the idiosyncratic norms of the human\nraters who provide the training data. An important objective for platforms\nimplementing such measures might be to ensure that they are not unduly biased\ntowards or against particular norms of offence. This paper provides some\nexploratory methods by which the normative biases of algorithmic content\nmoderation systems can be measured, by way of a case study using an existing\ndataset of comments labelled for offence. We train classifiers on comments\nlabelled by different demographic subsets (men and women) to understand how\ndifferences in conceptions of offence between these groups might affect the\nperformance of the resulting models on various test sets. We conclude by\ndiscussing some of the ethical choices facing the implementers of algorithmic\nmoderation systems, given various desired levels of diversity of viewpoints\namongst discussion participants.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 17:19:45 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Binns", "Reuben", ""], ["Veale", "Michael", ""], ["Van Kleek", "Max", ""], ["Shadbolt", "Nigel", ""]]}, {"id": "1707.01790", "submitter": "Michael Feldman", "authors": "Michael Feldman, Frida Juldaschewa and Abraham Bernstein", "title": "Data Analytics on Online Labor Markets: Opportunities and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data-driven economy has led to a significant shortage of data scientists.\nTo address this shortage, this study explores the prospects of outsourcing data\nanalysis tasks to freelancers available on online labor markets (OLMs) by\nidentifying the essential factors for this endeavor. Specifically, we explore\nthe skills required from freelancers, collect information about the skills\npresent on major OLMs, and identify the main hurdles for out-/crowd-sourcing\ndata analysis. Adopting a sequential mixed-method approach, we interviewed 20\ndata scientists and subsequently surveyed 80 respondents from OLMs. Besides\nconfirming the need for expected skills such as technical/mathematical\ncapabilities, it also identifies less known ones such as domain understanding,\nan eye for aesthetic data visualization, good communication skills, and a\nnatural understanding of the possibilities/limitations of data analysis in\ngeneral. Finally, it elucidates obstacles for crowdsourcing like the\ncommunication overhead, knowledge gaps, quality assurance, and data\nconfidentiality, which need to be mitigated.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 13:47:14 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Feldman", "Michael", ""], ["Juldaschewa", "Frida", ""], ["Bernstein", "Abraham", ""]]}, {"id": "1707.01848", "submitter": "Wieslaw Kopec", "authors": "Wies{\\l}aw Kope\\'c, Katarzyna Abramczuk, Bart{\\l}omiej Balcerzak,\n  Marta Ju\\'zwin Katarzyna Gniadzik, Grzegorz Kowalik, Rados{\\l}aw Nielek", "title": "A Location-Based Game for Two Generations: Teaching Mobile Technology to\n  the Elderly with the Support of Young Volunteers", "comments": "The final publication is available at Springer via\n  http://dx.doi.org/10.1007/978-3-319-49655-9_12", "journal-ref": null, "doi": "10.1007/978-3-319-49655-9_12", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a cooperative location-based game for the elderly with\nthe use of tablets equipped with mobile application. The game was designed to\ntackle at once several crucial topics related to the issue of aging, namely the\nsocial inclusion, education in the field of modern technology, motivation for\nlearning as well as physical activity. Mixed-aged teams consisting of two\nplayers: a junior and a senior took part in the game. The preliminary results\nsuggest that the game can successfully address a number of issues including\nimproving the elderly technical skills, increasing the elderly physical\nactivity as well as positive intergenerational interaction. The paper describes\nthe game setup in details and presents some initial data gathered during the\ngameplay.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 16:07:00 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Kope\u0107", "Wies\u0142aw", ""], ["Abramczuk", "Katarzyna", ""], ["Balcerzak", "Bart\u0142omiej", ""], ["Gniadzik", "Marta Ju\u017awin Katarzyna", ""], ["Kowalik", "Grzegorz", ""], ["Nielek", "Rados\u0142aw", ""]]}, {"id": "1707.02260", "submitter": "L. Elisa Celis", "authors": "L. Elisa Celis and Nisheeth K. Vishnoi", "title": "Fair Personalization", "comments": "To appear at FAT/ML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is pervasive in the online space as, when combined with\nlearning, it leads to higher efficiency and revenue by allowing the most\nrelevant content to be served to each user. However, recent studies suggest\nthat such personalization can propagate societal or systemic biases, which has\nled to calls for regulatory mechanisms and algorithms to combat inequality.\nHere we propose a rigorous algorithmic framework that allows for the\npossibility to control biased or discriminatory personalization with respect to\nsensitive attributes of users without losing all of the benefits of\npersonalization.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 16:40:06 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Celis", "L. Elisa", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1707.02327", "submitter": "Marco Tulio Valente", "authors": "Jailton Coelho, Marco Tulio Valente", "title": "Why Modern Open Source Projects Fail", "comments": "Paper accepted at 25th International Symposium on the Foundations of\n  Software Engineering (FSE), pages 1-11, 2017", "journal-ref": null, "doi": "10.1145/3106237.3106246", "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open source is experiencing a renaissance period, due to the appearance of\nmodern platforms and workflows for developing and maintaining public code. As a\nresult, developers are creating open source software at speeds never seen\nbefore. Consequently, these projects are also facing unprecedented mortality\nrates. To better understand the reasons for the failure of modern open source\nprojects, this paper describes the results of a survey with the maintainers of\n104 popular GitHub systems that have been deprecated. We provide a set of nine\nreasons for the failure of these open source projects. We also show that some\nmaintenance practices -- specifically the adoption of contributing guidelines\nand continuous integration -- have an important association with a project\nfailure or success. Finally, we discuss and reveal the principal strategies\ndevelopers have tried to overcome the failure of the studied projects.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 18:33:29 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Coelho", "Jailton", ""], ["Valente", "Marco Tulio", ""]]}, {"id": "1707.02341", "submitter": "Adebayo Omotosho Dr", "authors": "Adebayo Omotosho, Ukeme Asanga, Aderogba Fakorede", "title": "Electronic Prescription System for Pediatricians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the development of an electronic prescription system for\npediatricians that considered the factors that influence a childs prescription.\nThe system implements a knowledge base which contains drug information and\nformulary. It allows the pediatrician to have access to the electronic health\nrecord of patients before prescription writing. The resulting prescription is\nmarked with verifiable randomly generated prescription ID before it is sent to\nthe dispensing pharmacy and this accounts for the security feature of the\nprescription system. Microsoft Office Visio 2007, PHP and My SQL database\nserver were used to present and develop the system. Implementation results\nshowed the system is capable of reducing common prescription error as the most\ninformed prescription is being generated for the child electronically.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 19:44:36 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Omotosho", "Adebayo", ""], ["Asanga", "Ukeme", ""], ["Fakorede", "Aderogba", ""]]}, {"id": "1707.02353", "submitter": "Alex Zhavoronkov", "authors": "Konstantin Chekanov, Polina Mamoshina, Roman V. Yampolskiy, Radu\n  Timofte, Morten Scheibye-Knudsen, Alex Zhavoronkov", "title": "Evaluating race and sex diversity in the world's largest companies using\n  deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity is one of the fundamental properties for the survival of species,\npopulations, and organizations. Recent advances in deep learning allow for the\nrapid and automatic assessment of organizational diversity and possible\ndiscrimination by race, sex, age and other parameters. Automating the process\nof assessing the organizational diversity using the deep neural networks and\neliminating the human factor may provide a set of real-time unbiased reports to\nall stakeholders. In this pilot study we applied the deep-learned predictors of\nrace and sex to the executive management and board member profiles of the 500\nlargest companies from the 2016 Forbes Global 2000 list and compared the\npredicted ratios to the ratios within each company's country of origin and\nranked them by the sex-, age- and race- diversity index (DI). While the study\nhas many limitations and no claims are being made concerning the individual\ncompanies, it demonstrates a method for the rapid and impartial assessment of\norganizational diversity using deep neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 12:32:19 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Chekanov", "Konstantin", ""], ["Mamoshina", "Polina", ""], ["Yampolskiy", "Roman V.", ""], ["Timofte", "Radu", ""], ["Scheibye-Knudsen", "Morten", ""], ["Zhavoronkov", "Alex", ""]]}, {"id": "1707.02435", "submitter": "Rex Bringula", "authors": "Rex P. Bringula, Julius Jan M. Sarmiento, Roselle S. Basa", "title": "Computer Self-efficacy and Its Relationship with Web Portal Usage:\n  Evidence from the University of the East", "comments": "6 pages, International Journal of Computing Sciences Research, 2017", "journal-ref": null, "doi": "10.25147/ijcsr.2017.001.1.02", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The University of the East Web Portal is an academic, web based system that\nprovides educational electronic materials and e-learning services. To fully\noptimize its usage, it is imperative to determine the factors that relate to\nits usage. Thus, this study, to determine the computer self-efficacy of the\nfaculty members of the University of the East and its relationship with their\nweb portal usage, was conceived. Using a validated questionnaire, the profile\nof the respondents, their computer self-efficacy, and web portal usage were\ngathered. Data showed that the respondents were relatively young (M = 40 years\nold), majority had masters degree (f = 85, 72%), most had been using the web\nportal for four semesters (f = 60, 51%), and the large part were intermediate\nweb portal users (f = 69, 59%). They were highly skilled in using the computer\n(M = 4.29) and skilled in using the Internet (M = 4.28). E-learning services (M\n= 3.29) and online library resources (M = 3.12) were only used occasionally.\nPearson correlation revealed that age was positively correlated with online\nlibrary resources (r = 0.267, p < 0.05) and a negative relationship existed\nbetween perceived skill level in using the portal and online library resources\nusage (r = -0.206, p < 0.05). A 2x2 chi square revealed that the highest\neducational attainment had a significant relationship with online library\nresources (chi square = 5.489, df = 1, p < 0.05). Basic computer (r = 0.196, p\n< 0.05) and Internet skills (r = 0.303, p < 0.05) were significantly and\npositively related with e-learning services usage but not with online library\nresources usage. Other individual factors such as attitudes towards the web\nportal and anxiety towards using the web portal can be investigated.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 13:06:40 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Bringula", "Rex P.", ""], ["Sarmiento", "Julius Jan M.", ""], ["Basa", "Roselle S.", ""]]}, {"id": "1707.02662", "submitter": "Greg Wilson", "authors": "Gabriel A. Devenyi, R\\'emi Emonet, Rayna M. Harris, Kate L. Hertweck,\n  Damien Irving, Ian Milligan, and Greg Wilson", "title": "Ten simple rules for collaborative lesson development", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1005963", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The collaborative development methods pioneered by the open source software\ncommunity offer a way to create lessons that are open, accessible, and\nsustainable. This paper presents ten simple rules for doing this drawn from our\nexperience with several successful projects.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 00:27:22 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Devenyi", "Gabriel A.", ""], ["Emonet", "R\u00e9mi", ""], ["Harris", "Rayna M.", ""], ["Hertweck", "Kate L.", ""], ["Irving", "Damien", ""], ["Milligan", "Ian", ""], ["Wilson", "Greg", ""]]}, {"id": "1707.02924", "submitter": "Ahmad Siddiqui Dr", "authors": "Ahmad Tasnim Siddiqui, Mehedi Masud", "title": "A System Framework for Smart Class System to Boost Education and\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large number of reasonably priced computers, Internet broadband\nconnectivity and rich education content has created a global phenomenon by\nwhich information and communication technology (ICT) has used to remodel\neducation. E-learning can be explained as the use of available information,\ncomputational and communication technologies to assist learning practice. In\nthe modern world, education has become more universal, and people are looking\nfor learning with simplicity and interest. Students are looking for more\ninteractive and attractive learning style rather than old traditional style.\nUsing technological learning, we can enhance the education system. We can\ndeliver quality education to students as well as we can ease and uniform the\nprocess of education by using the modern technologies and methods. In this\npaper, we propose a smart class model to manage the entire educational\nactivities and hence to enhance the quality of education.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 18:22:11 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Siddiqui", "Ahmad Tasnim", ""], ["Masud", "Mehedi", ""]]}, {"id": "1707.03678", "submitter": "Vahid Moosavi", "authors": "Diana Alvarez-Marin, Vahid Moosavi", "title": "Inverting normative city theories and computational urban models:\n  Towards a coexistence with urban data streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two unavoidable processes punctuate our century: The unprecedented\nurbanisation of our planet (United Nations, 2014) and the spread of ubiquitous\ncomputing (Weiser, 1991) and urban data streams. This process of urbanisation\ncorresponds with the process of digitalisation of urban life: while\nurbanisation acts on a physical infrastructural level, the digital develops as\na kind of metastructure above the infrastructure. This metastructural level\noffers a flexible framework through which information is continuously and\noperatively being symbolized. Today, Information technology and the\navailability of abundant urban data streams could be considered as forerunners\nof our time, having unprecedented impacts comparable to the ones brought by the\nsteam engine at the dawn of industrialisation and the electrification of\ncities. It is therefore no longer conceivable to think of the physical\nstructure of the city without including its digital counterpart. Against this\nbackground, we will explore the role of computational power and information\ntechnologies as dominant factors in the formation of computational urban models\nand normative city theories. We will show how these models and theories,\nemerging mainly during the 19th and 20th centuries, present leaping\ncorrespondences with more ancient conceptions of the city, when observed from a\nmeta-level or episteme (Foucault, 2002) approach. First, and for the sake of\nclarity, we will deal with some methodological elucidations around the concepts\nof theory, model and episteme, and how we will refer conceptually to these\nterms throughout this paper. Secondly, we will review these evolving\ntechnological and computational levels of abstraction and their influence on\nthe different conceptions of the city. Thirdly, we will develop the hypothesis\nof a conceptual gap, between our current technological capacity -- grounded on\nthe abundance and availability of urban data streams -- and the state of the\nart in urban modelling and city theory. Lastly, building upon Foucault's\nconcept of episteme (Foucault, 1970) and genealogy (Foucault, 1977b), we will\nexplore this gap by speculating around the possibility of an inversion in\ncomputational urban modelling and city theory. And above all, we will question\nthe terms in which we can think of the city, in an age where the world can be\nvirtually conceived as fully urban, and the continuity and abundance of urban\ndata streams giving account of it can be taken for granted. How are we\narticulating the phenomena we call city on top of this generic common ground?\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 12:43:37 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Alvarez-Marin", "Diana", ""], ["Moosavi", "Vahid", ""]]}, {"id": "1707.03717", "submitter": "Amanda Ramcharan", "authors": "Amanda Ramcharan, Kelsee Baranowski, Peter McCloskey, Babuali Ahmed,\n  James Legg, and David Hughes", "title": "Using Transfer Learning for Image-Based Cassava Disease Detection", "comments": "10 pages, 4 figures", "journal-ref": "Frontiers in Plant Science 2017 vol. 8 p. 1852", "doi": "10.3389/fpls.2017.01852", "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cassava is the third largest source of carbohydrates for human food in the\nworld but is vulnerable to virus diseases, which threaten to destabilize food\nsecurity in sub-Saharan Africa. Novel methods of cassava disease detection are\nneeded to support improved control which will prevent this crisis. Image\nrecognition offers both a cost effective and scalable technology for disease\ndetection. New transfer learning methods offer an avenue for this technology to\nbe easily deployed on mobile devices. Using a dataset of cassava disease images\ntaken in the field in Tanzania, we applied transfer learning to train a deep\nconvolutional neural network to identify three diseases and two types of pest\ndamage (or lack thereof). The best trained model accuracies were 98% for brown\nleaf spot (BLS), 96% for red mite damage (RMD), 95% for green mite damage\n(GMD), 98% for cassava brown streak disease (CBSD), and 96% for cassava mosaic\ndisease (CMD). The best model achieved an overall accuracy of 93% for data not\nused in the training process. Our results show that the transfer learning\napproach for image recognition of field images offers a fast, affordable, and\neasily deployable strategy for digital plant disease detection.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 15:01:59 GMT"}, {"version": "v2", "created": "Tue, 1 Aug 2017 19:29:43 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Ramcharan", "Amanda", ""], ["Baranowski", "Kelsee", ""], ["McCloskey", "Peter", ""], ["Ahmed", "Babuali", ""], ["Legg", "James", ""], ["Hughes", "David", ""]]}, {"id": "1707.03778", "submitter": "Amira Ghenai", "authors": "Amira Ghenai, Yelena Mejova", "title": "Catching Zika Fever: Application of Crowdsourcing and Machine Learning\n  for Tracking Health Misinformation on Twitter", "comments": "11 pages, 7 figures, short version to be published in the Fifth IEEE\n  International Conference on Healthcare Informatics (ICHI 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In February 2016, World Health Organization declared the Zika outbreak a\nPublic Health Emergency of International Concern. With developing evidence it\ncan cause birth defects, and the Summer Olympics coming up in the worst\naffected country, Brazil, the virus caught fire on social media. In this work,\nuse Zika as a case study in building a tool for tracking the misinformation\naround health concerns on Twitter. We collect more than 13 million tweets --\nspanning the initial reports in February 2016 and the Summer Olympics --\nregarding the Zika outbreak and track rumors outlined by the World Health\nOrganization and Snopes fact checking website. The tool pipeline, which\nincorporates health professionals, crowdsourcing, and machine learning, allows\nus to capture health-related rumors around the world, as well as clarification\ncampaigns by reputable health organizations. In the case of Zika, we discover\nan extremely bursty behavior of rumor-related topics, and show that, once the\nquestionable topic is detected, it is possible to identify rumor-bearing tweets\nusing automated techniques. Thus, we illustrate insights the proposed tools\nprovide into potentially harmful information on social media, allowing public\nhealth researchers and practitioners to respond with a targeted and timely\naction.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 15:55:20 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Ghenai", "Amira", ""], ["Mejova", "Yelena", ""]]}, {"id": "1707.03959", "submitter": "Ian Wood", "authors": "Ian B. Wood, Pedro Leal Varela, Johan Bollen, Luis M. Rocha, and Joana\n  Gon\\c{c}alves-S\\'a", "title": "Human Sexual Cycles are Driven by Culture and Match Collective Moods", "comments": "Main Paper: 21 pages, 4 figures Supplementary Material: 66 pages, 15\n  figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a long-standing question whether human sexual and reproductive cycles\nare affected predominantly by biology or culture. The literature is mixed with\nrespect to whether biological or cultural factors best explain the reproduction\ncycle phenomenon, with biological explanations dominating the argument. The\nbiological hypothesis proposes that human reproductive cycles are an adaptation\nto the seasonal cycles caused by hemisphere positioning, while the cultural\nhypothesis proposes that conception dates vary mostly due to cultural factors,\nsuch as vacation schedule or religious holidays. However, for many countries,\ncommon records used to investigate these hypotheses are incomplete or\nunavailable, biasing existing analysis towards primarily Christian countries in\nthe Northern Hemisphere. Here we show that interest in sex peaks sharply online\nduring major cultural and religious celebrations, regardless of hemisphere\nlocation. This online interest, when shifted by nine months, corresponds to\ndocumented human birth cycles, even after adjusting for numerous factors such\nas language, season, and amount of free time due to holidays. We further show\nthat mood, measured independently on Twitter, contains distinct collective\nemotions associated with those cultural celebrations, and these collective\nmoods correlate with sex search volume outside of these holidays as well. Our\nresults provide converging evidence that the cyclic sexual and reproductive\nbehavior of human populations is mostly driven by culture and that this\ninterest in sex is associated with specific emotions, characteristic of, but\nnot limited to, major cultural and religious celebrations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 02:21:46 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 19:49:30 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Wood", "Ian B.", ""], ["Varela", "Pedro Leal", ""], ["Bollen", "Johan", ""], ["Rocha", "Luis M.", ""], ["Gon\u00e7alves-S\u00e1", "Joana", ""]]}, {"id": "1707.03969", "submitter": "Yingjie Hu", "authors": "Yingjie Hu, Wenwen Li", "title": "Spatial Data Infrastructures", "comments": "The Geographic Information Science & Technology Body of Knowledge,\n  John P. Wilson (ed.). (2017)", "journal-ref": null, "doi": "10.22224/gistbok/2017.2.1", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial data infrastructure (SDI) is the infrastructure that facilitates the\ndiscovery, access, management, distribution, reuse, and preservation of digital\ngeospatial resources. These resources may include maps, data, geospatial\nservices, and tools. As cyberinfrastructures, SDIs are similar to other\ninfrastructures, such as water supplies and transportation networks, since they\nplay fundamental roles in many aspects of the society. These roles have become\neven more significant in today's big data age, when a large volume of\ngeospatial data and Web services are available. From a technological\nperspective, SDIs mainly consist of data, hardware, and software. However, a\ntruly functional SDI also needs the efforts of people, supports from\norganizations, government policies, data and software standards, and many\nothers. In this chapter, we will present the concepts and values of SDIs, as\nwell as a brief history of SDI development in the U.S. We will also discuss the\ncomponents of a typical SDI, and will specifically focus on three key\ncomponents: geoportals, metadata, and search functions. Examples of the\nexisting SDI implementations will also be discussed.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 03:51:54 GMT"}, {"version": "v2", "created": "Thu, 10 Aug 2017 05:48:53 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Hu", "Yingjie", ""], ["Li", "Wenwen", ""]]}, {"id": "1707.03988", "submitter": "Fulvio Mastrogiovanni", "authors": "Luca Buoncompagni, Barbara Bruno, Antonella Giuni, Fulvio\n  Mastrogiovanni, Renato Zaccaria", "title": "Arianna: towards a new paradigm for assistive technology at home", "comments": "Paper accepted at the Eight Italian Forum on Ambient Assisted Living\n  (ForItAAL 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing elderly and people with special needs to retain their independence\nas long as possible is one of the biggest challenges of the society of\ntomorrow. Teseo, a startup company spinoff from the University of Genoa, aims\nat accelerating the transition towards a sustainable healthcare system. Teseo's\nfirst concept and product, Arianna, allows for the automated recognition of\nactivities of daily living at home and acts as a wellbeing and healthcare\npersonalized assistant. This abstract outlines the main concepts underlying its\nfeatures and capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 06:28:37 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Buoncompagni", "Luca", ""], ["Bruno", "Barbara", ""], ["Giuni", "Antonella", ""], ["Mastrogiovanni", "Fulvio", ""], ["Zaccaria", "Renato", ""]]}, {"id": "1707.03997", "submitter": "John J. Camilleri", "authors": "John J. Camilleri and Mohammad Reza Haghshenas and Gerardo Schneider", "title": "A Web-Based Tool for Analysing Normative Documents in English", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to use formal methods to analyse normative documents written in\nEnglish, such as privacy policies and service-level agreements. This requires\nthe combination of a number of different elements, including information\nextraction from natural language, formal languages for model representation,\nand an interface for property specification and verification. We have worked on\na collection of components for this task: a natural language extraction tool, a\nsuitable formalism for representing such documents, an interface for building\nmodels in this formalism, and methods for answering queries asked of a given\nmodel. In this work, each of these concerns is brought together in a web-based\ntool, providing a single interface for analysing normative texts in English.\nThrough the use of a running example, we describe each component and\ndemonstrate the workflow established by our tool.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 07:22:18 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Camilleri", "John J.", ""], ["Haghshenas", "Mohammad Reza", ""], ["Schneider", "Gerardo", ""]]}, {"id": "1707.04044", "submitter": "Olivier Giraud", "authors": "C. Coquid\\'e, B. Georgeot, O. Giraud", "title": "Distinguishing humans from computers in the game of go: a complex\n  network approach", "comments": "7 pages, 6 figures", "journal-ref": "EPL 119, 48001 (2017)", "doi": "10.1209/0295-5075/119/48001", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare complex networks built from the game of go and obtained from\ndatabases of human-played games with those obtained from computer-played games.\nOur investigations show that statistical features of the human-based networks\nand the computer-based networks differ, and that these differences can be\nstatistically significant on a relatively small number of games using specific\nestimators. We show that the deterministic or stochastic nature of the computer\nalgorithm playing the game can also be distinguished from these quantities.\nThis can be seen as tool to implement a Turing-like test for go simulators.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 09:44:18 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 18:36:38 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Coquid\u00e9", "C.", ""], ["Georgeot", "B.", ""], ["Giraud", "O.", ""]]}, {"id": "1707.04327", "submitter": "Adnan Darwiche", "authors": "Adnan Darwiche", "title": "Human-Level Intelligence or Animal-Like Abilities?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vision systems of the eagle and the snake outperform everything that we\ncan make in the laboratory, but snakes and eagles cannot build an eyeglass or a\ntelescope or a microscope. (Judea Pearl)\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 21:17:14 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Darwiche", "Adnan", ""]]}, {"id": "1707.04364", "submitter": "Mohammad Kachuee Mr.", "authors": "Sandeep Singh Sandha, Mohammad Kachuee, Sajad Darabi", "title": "Complex Event Processing of Health Data in Real-time to Predict Heart\n  Failure Risk and Stress", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a scalable system which can do real-time analytics\nfor different health applications. The occurrence of different health\nconditions can be regarded as the complex events and thus this concept can be\nextended to other use cases easily. Large number of users should be able to\nsend the data in real-time, and should be able to receive the feedback and\nresult. Keeping the requirements in mind we used Kafka and Spark to develop our\nsystem. In this setting, multiple users are running Kafka producer clients,\nwhich are sending data in real-time. Spark streaming is used to process data\nfrom Kafka of different window sizes to analyze the health conditions. We have\ndeveloped and tested the heart attack risk and stress prediction as our sample\ncomplex events detection use cases. We have simulated and tested our system\nwith multiple health datasets.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 01:22:50 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Sandha", "Sandeep Singh", ""], ["Kachuee", "Mohammad", ""], ["Darabi", "Sajad", ""]]}, {"id": "1707.04657", "submitter": "Aswin Ramachandran", "authors": "Aswin Ramachandran, Louis Johnson", "title": "Variable Instruction Fetch Rate to Reduce Control Dependent Penalties", "comments": "8 pages, 6 Figures, Disclosure: The work is a part of my PhD\n  dissertation at OSU and not in anyway related to Intel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to overcome the branch execution penalties of hard-to-predict\ninstruction branches, two new instruction fetch micro-architectural methods are\nproposed in this paper. In addition, to compare performance of the two proposed\nmethods, different instruction fetch policy schemes of existing multi-branch\npath architectures are evaluated. An improvement in Instructions Per Cycle\n(IPC) of 29.4% on average over single-thread execution with gshare branch\npredictor on SPEC 2000/2006 benchmark is shown. In this paper, wide pipeline\nmachines are simulated for evaluation purposes. The methods discussed in this\npaper can be extended to High Performance Scientific Computing needs, if the\ndemands of IPC improvement are far more critical than $cost.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 22:50:47 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Ramachandran", "Aswin", ""], ["Johnson", "Louis", ""]]}, {"id": "1707.04935", "submitter": "Yuri G. Gordienko", "authors": "Serhii Hamotskyi, Anis Rojbi, Sergii Stirenko, and Yuri Gordienko", "title": "Automatized Generation of Alphabets of Symbols", "comments": "4 pages, 3 figures; Federated Conference on Computer Science and\n  Information Systems, Prague (FedCSIS-2017) (Prague, Czech Republic)", "journal-ref": "Proceedings of the 2017 Federated Conference on Computer Science\n  and Information Systems (FedCSIS-2017), p.639-642, Prague, Czech Republic,\n  September 3-6, 2017", "doi": "10.15439/2017F413", "report-no": null, "categories": "cs.HC cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the generation of symbols (and alphabets) based on\nspecific user requirements (medium, priorities, type of information that needs\nto be conveyed). A framework for the generation of alphabets is proposed, and\nits use for the generation of a shorthand writing system is explored. We\ndiscuss the possible use of machine learning and genetic algorithms to gather\ninputs for generation of such alphabets and for optimization of already\ngenerated ones. The alphabets generated using such methods may be used in very\ndifferent fields, from the creation of synthetic languages and constructed\nscripts to the creation of sensible commands for multimodal interaction through\nHuman-Computer Interfaces, such as mouse gestures, touchpads, body gestures,\neye-tracking cameras, and brain-computing Interfaces, especially in\napplications for elderly care and people with disabilities.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 19:40:26 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Hamotskyi", "Serhii", ""], ["Rojbi", "Anis", ""], ["Stirenko", "Sergii", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1707.04941", "submitter": "Haewoon Kwak", "authors": "Haewoon Kwak and Jisun An", "title": "Multiplex Media Attention and Disregard Network among 129 Countries", "comments": "To appear in the 2017 IEEE/ACM International Conference on Advances\n  in Social Networks Analysis and Mining (ASONAM 2017), Sydney, Australia, 31\n  July - 03 August, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We built a multiplex media attention and disregard network (MADN) among 129\ncountries over 212 days. By characterizing the MADN from multiple levels, we\nfound that it is formed primarily by skewed, hierarchical, and asymmetric\nrelationships. Also, we found strong evidence that our news world is becoming a\n\"global village.\" However, at the same time, unique attention blocks of the\nMiddle East and North Africa (MENA) region, as well as Russia and its\nneighbors, still exist.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 20:20:03 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 11:24:55 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Kwak", "Haewoon", ""], ["An", "Jisun", ""]]}, {"id": "1707.05364", "submitter": "Shahzad Ahmed Mr.", "authors": "Shahzad Ahmed, M. Usman Ali, Javed Ferzund, Muhammad Atif Sarwar,\n  Abbas Rehman and Atif Mehmood", "title": "Modern Data Formats for Big Bioinformatics Data Analytics", "comments": "12 Pages, 20 figures and 2 Tables", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications, Issue 8, No. 4, page 366-377 (1 May 2017)", "doi": "10.14569/IJACSA.2017.080450", "report-no": null, "categories": "cs.DB cs.CY cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Next Generation Sequencing (NGS) technology has resulted in massive amounts\nof proteomics and genomics data. This data is of no use if it is not properly\nanalyzed. ETL (Extraction, Transformation, Loading) is an important step in\ndesigning data analytics applications. ETL requires proper understanding of\nfeatures of data. Data format plays a key role in understanding of data,\nrepresentation of data, space required to store data, data I/O during\nprocessing of data, intermediate results of processing, in-memory analysis of\ndata and overall time required to process data. Different data mining and\nmachine learning algorithms require input data in specific types and formats.\nThis paper explores the data formats used by different tools and algorithms and\nalso presents modern data formats that are used on Big Data Platform. It will\nhelp researchers and developers in choosing appropriate data format to be used\nfor a particular tool or algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 11:35:53 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Ahmed", "Shahzad", ""], ["Ali", "M. Usman", ""], ["Ferzund", "Javed", ""], ["Sarwar", "Muhammad Atif", ""], ["Rehman", "Abbas", ""], ["Mehmood", "Atif", ""]]}, {"id": "1707.05667", "submitter": "Dorota Orzeszek", "authors": "Dorota Orzeszek, Wieslaw Kopec, Marcin Wichrowski, Radoslaw Nielek,\n  Bartlomiej Balcerzak, Grzegorz Kowalik, Malwina Puchalska-Kaminska", "title": "Beyond Participatory Design: Towards a Model for Teaching Seniors\n  Application Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population aging and the ubiquity of technology in everyday life have made\ndesigning solutions for older adults a necessity. User-centered and\nparticipatory design approaches include elderly users in the software\ndevelopment process to some extent but do not encourage them to take a leading\nrole in designing applications to address their unmet needs. Teaching seniors\nabout software design could help them actively participate in creating much\nneeded solutions for their age group but this cannot be done without first\nunderstanding their conceptual models of technology. Past experiences play a\nsignificant role in determining the way learners model abstract concepts and so\nolder adults' conceptual models of user interfaces (and human-computer\ninteraction in general) differ from those used in teaching application design\nto younger students. In this paper we analyze a workshop on user interface\ndesign and prototyping for seniors to better understand older adults' learning\nprocess and the issues they encounter while learning abstract ideas related to\nhuman-computer interaction. We conclude the study by proposing guidelines for\nteaching older adults abstract technology related concepts.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 15:05:01 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Orzeszek", "Dorota", ""], ["Kopec", "Wieslaw", ""], ["Wichrowski", "Marcin", ""], ["Nielek", "Radoslaw", ""], ["Balcerzak", "Bartlomiej", ""], ["Kowalik", "Grzegorz", ""], ["Puchalska-Kaminska", "Malwina", ""]]}, {"id": "1707.06208", "submitter": "Nicole Radziwill", "authors": "Nicole M. Radziwill, Morgan C. Benton", "title": "Design for X (DfX) in the Internet of Things (IoT)", "comments": "Journal of Quality Management Systems, Applied Engineering, &\n  Technology Management. Vol 1, June 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing quality in is a cornerstone of modern quality management\nphilosophies. Design for X (DfX) techniques provide guidelines, heuristics, and\nmetrics to ensure that a particular quality attribute exists in a design.\nAlthough hundreds of papers have been published on DfX approaches, few\nresearchers have explored systematically applying multiple DfX in a particular\nproblem context. As the Internet of Things (IoT) evolves, boundaries between\npeople, computers, and objects will become less distinct, underscoring the need\nfor more holistic design. Using mixed methods, this paper examines the utility\nof DfX in the emerging IoT ecosystem. We identify DfX that are applicable to\nIoT-related design, and find gaps that demand further research and development.\nThe results from this study can be used to help designers and quality managers\nselect or develop appropriate DfX to use in designing components for the\nInternet of Things (IoT), supporting actionable strategies for quality and\ncustomer satisfaction.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 02:13:22 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Radziwill", "Nicole M.", ""], ["Benton", "Morgan C.", ""]]}, {"id": "1707.06210", "submitter": "Mehrdad J. Bani", "authors": "Mehrdad J. Bani and Mina Haji", "title": "College Student Retention: When Do We Losing Them?", "comments": "Submitted to Proceedings of the World Congress on Engineering and\n  Computer Science 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the long term goals of any college or university is increasing the\nstudent retention. The negative impact of student dropout are clear to\nstudents, parents, universities and society. The positive effect of decreasing\nstudent attrition is also self-evident including higher chance of having a\nbetter career and higher standard of life for college graduate. In view of\nthese reasons, directors in higher education feel increasingly pressurized to\noutline and implement strategies to increase student retention. In this paper,\nwe provide a detailed analysis of the student attrition problem and use\nstatistical methods to predict when students are going to dropout from school\nusing real case data. Our work has a number of advantages with the potential of\nbeing employed by higher education administrator of universities. We take\nadvantage of multiple kinds of information about different aspects of student's\ncharacteristic and efficiently utilize them to make a personalized decision\nabout the risk of dropout for a particular student.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 02:30:05 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Bani", "Mehrdad J.", ""], ["Haji", "Mina", ""]]}, {"id": "1707.06211", "submitter": "Louis Francois Pau", "authors": "L-F Pau", "title": "Wireless enabled clothing: New modular technologies and overall supply\n  chain impact", "comments": null, "journal-ref": null, "doi": null, "report-no": "CR-26 Upg\\\"otva AB", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is devoted to the realization of wireless enabled clothing,\nemploying recent new technologies in electronics, textile, and renewable power.\nThis new wireless enabled clothing architecture is modular and\ndistributed,allowing for customization in functionality and clothing designs.\nAre studied the implications for supply chains,distribution channels, and cost\nbenefits. Modular wireless enabled clothing offers significant personalization\nopportunities at costs comparable with mobile terminals.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 09:32:22 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Pau", "L-F", ""]]}, {"id": "1707.06359", "submitter": "Joshua Abah Abah", "authors": "Joshua Abah Abah", "title": "Recency Bias in the Era of Big Data: The Need to Strengthen the Status\n  of History of Mathematics in Nigerian Schools", "comments": "8 pages", "journal-ref": "Advances in Multidisciplinary and Scientific Research Journal,\n  2(4), December 2016, 241-248", "doi": null, "report-no": null, "categories": "math.HO cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of information available to the mathematics teacher is so enormous\nthat the selection of desirable content is gradually becoming a huge task in\nitself. With respect to the inclusion of elements of history of mathematics in\nmathematics instruction, the era of Big Data introduces a high likelihood of\nRecency Bias, a hitherto unconnected challenge for stakeholders in mathematics\neducation. This tendency to choose recent information at the expense of\nrelevant older, composite, historical facts stands to defeat the aims and\nobjectives of the epistemological and cultural approach to mathematics\ninstructional delivery. This study is a didactic discourse with focus on this\nthreat to the history and pedagogy of mathematics, particularly as it affects\nmathematics education in Nigeria. The implications for mathematics curriculum\ndevelopers, teacher-training programmes, teacher lesson preparation, and\npublication of mathematics instructional materials were also deeply considered.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 03:28:28 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Abah", "Joshua Abah", ""]]}, {"id": "1707.06433", "submitter": "Umutcan \\c{S}im\\c{s}ek", "authors": "Eleni Fotopoulou, Anastasios Zafeiropoulos, Fernando Terroso, Aurora\n  Gonzalez, Antonio Skarmeta, Umutcan \\c{S}im\\c{s}ek and Anna Fensel", "title": "Data Aggregation, Fusion and Recommendations for Strengthening Citizens\n  Energy-aware Behavioural Profiles", "comments": "To appear in the proceedings of Global IoT Summit 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, ENTROPY platform, an IT ecosystem for supporting energy\nefficiency in buildings through behavioural change of the occupants is\nprovided. The ENTROPY platform targets at providing a set of mechanisms for\naccelerating the adoption of energy efficient practices through the increase of\nthe energy awareness and energy saving potential of the occupants. The platform\ntakes advantage of novel sensor networking technologies for supporting\nefficient sensor data aggregation mechanisms, semantic web technologies for\nunified data representation, machine learning mechanisms for getting insights\nfrom the available data and recommendation mechanisms for providing\npersonalised content to end users. These technologies are combined and provided\nthrough an integrated platform, targeting at leading to occupants' behavioural\nchange with regards to their energy consumption profiles.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 09:57:49 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Fotopoulou", "Eleni", ""], ["Zafeiropoulos", "Anastasios", ""], ["Terroso", "Fernando", ""], ["Gonzalez", "Aurora", ""], ["Skarmeta", "Antonio", ""], ["\u015eim\u015fek", "Umutcan", ""], ["Fensel", "Anna", ""]]}, {"id": "1707.06505", "submitter": "Daniel Tr\\\"ader", "authors": "Daniel Tr\\\"ader, Alexander Zeier, Andreas Heinemann", "title": "Design and Implementation Aspects of Mobile Derived Identities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ongoing digitalisation of our everyday tasks, more and more\neGovernment services make it possible for citizens to take care of their\nadministrative obligations online. This type of services requires a certain\nassurance level for user authentication. To meet these requirements, a digital\nidentity issued to the citizen is essential. Nowadays, due to the widespread\nuse of smartphones, mobile user authentication is often favoured. This\nnaturally supports two-factor authentication schemes (2FA). We use the term\nmobile derived identity to stress two aspects: a) the identity is enabled for\nmobile usage and b) the identity is somehow derived from a physical or digital\nproof of identity. This work reviews 21 systems that support mobile derived\nidentities. One subset of the considered systems is already in place (public or\nprivate sector in Europe), another subset is subject to research. Our goal is\nto identify prevalent design and implementation aspects for these systems in\norder to gain a better understanding on best practises and common views on\nmobile derived identities. We found, that research prefers storing identity\ndata on the mobile device itself whereas real world systems usually rely on\ncloud storage. 2FA is common in both worlds, however biometrics as second\nfactor is the exception.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 13:51:41 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Tr\u00e4der", "Daniel", ""], ["Zeier", "Alexander", ""], ["Heinemann", "Andreas", ""]]}, {"id": "1707.06552", "submitter": "Cesare Furlanello", "authors": "C. Furlanello, M. De Domenico, G. Jurman and N. Bussola", "title": "Towards a scientific blockchain framework for reproducible data analysis", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Publishing reproducible analyses is a long-standing and widespread challenge\nfor the scientific community, funding bodies and publishers. Although a\ndefinitive solution is still elusive, the problem is recognized to affect all\ndisciplines and lead to a critical system inefficiency. Here, we propose a\nblockchain-based approach to enhance scientific reproducibility, with a focus\non life science studies and precision medicine. While the interest of encoding\npermanently into an immutable ledger all the study key information-including\nendpoints, data and metadata, protocols, analytical methods and all\nfindings-has been already highlighted, here we apply the blockchain approach to\nsolve the issue of rewarding time and expertise of scientists that commit to\nverify reproducibility. Our mechanism builds a trustless ecosystem of\nresearchers, funding bodies and publishers cooperating to guarantee digital and\npermanent access to information and reproducible results. As a natural\nbyproduct, a procedure to quantify scientists' and institutions' reputation for\nranking purposes is obtained.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 14:53:42 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Furlanello", "C.", ""], ["De Domenico", "M.", ""], ["Jurman", "G.", ""], ["Bussola", "N.", ""]]}, {"id": "1707.06603", "submitter": "Araz Taeihagh", "authors": "Araz Taeihagh", "title": "Crowdsourcing, Sharing Economies and Development", "comments": null, "journal-ref": "Journal of Developing Societies, Vol 33, Issue 2, Pages 191 to 222\n  (2017)", "doi": "10.1177/0169796X17710072", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the similarities and differences between crowdsourcing and sharing\neconomy? What factors influence their use in developing countries? In light of\nrecent developments in the use of IT-mediated technologies, such as\ncrowdsourcing and the sharing economy, this manuscript examines their\nsimilarities and differences, and the challenges regarding their effective use\nin developing countries. We first examine each individually and highlight\ndifferent forms of each IT-mediated technology. Given that crowdsourcing and\nsharing economy share aspects such as the use of IT, a reliance on crowds,\nmonetary exchange, and the use of reputation systems, we systematically compare\nthe similarities and differences of different types of crowdsourcing with the\nsharing economy, thus addressing a gap in the current literature. Using this\nknowledge, we examine the different challenges faced by developing countries\nwhen using crowdsourcing and the sharing economy, and highlight the differences\nin the applicability of these IT-mediated technologies when faced with specific\ndevelopment issues.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 16:47:00 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Taeihagh", "Araz", ""]]}, {"id": "1707.06613", "submitter": "Nicole Immorlica", "authors": "Cynthia Dwork, Nicole Immorlica, Adam Tauman Kalai, Max Leiserson", "title": "Decoupled classifiers for fair and efficient machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it is ethical and legal to use a sensitive attribute (such as gender or\nrace) in machine learning systems, the question remains how to do so. We show\nthat the naive application of machine learning algorithms using sensitive\nfeatures leads to an inherent tradeoff in accuracy between groups. We provide a\nsimple and efficient decoupling technique, that can be added on top of any\nblack-box machine learning algorithm, to learn different classifiers for\ndifferent groups. Transfer learning is used to mitigate the problem of having\ntoo little data on any one group.\n  The method can apply to a range of fairness criteria. In particular, we\nrequire the application designer to specify as joint loss function that makes\nexplicit the trade-off between fairness and accuracy. Our reduction is shown to\nefficiently find the minimum loss as long as the objective has a certain\nnatural monotonicity property which may be of independent interest in the study\nof fairness in algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 17:08:48 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Dwork", "Cynthia", ""], ["Immorlica", "Nicole", ""], ["Kalai", "Adam Tauman", ""], ["Leiserson", "Max", ""]]}, {"id": "1707.06643", "submitter": "Boyang Li", "authors": "Ng Annalyn, Maarten W. Bos, Leonid Sigal, and Boyang Li", "title": "Predicting Personality from Book Preferences with User-Generated Content\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychological studies have shown that personality traits are associated with\nbook preferences. However, past findings are based on questionnaires focusing\non conventional book genres and are unrepresentative of niche content. For a\nmore comprehensive measure of book content, this study harnesses a massive\narchive of content labels, also known as 'tags', created by users of an online\nbook catalogue, Goodreads.com. Combined with data on preferences and\npersonality scores collected from Facebook users, the tag labels achieve high\naccuracy in personality prediction by psychological standards. We also group\ntags into broader genres, to check their validity against past findings. Our\nresults are robust across both tag and genre levels of analyses, and consistent\nwith existing literature. Moreover, user-generated tag labels reveal unexpected\ninsights, such as cultural differences, book reading behaviors, and other\nnon-content factors affecting preferences. To our knowledge, this is currently\nthe largest study that explores the relationship between personality and book\ncontent preferences.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 19:41:01 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Annalyn", "Ng", ""], ["Bos", "Maarten W.", ""], ["Sigal", "Leonid", ""], ["Li", "Boyang", ""]]}, {"id": "1707.06939", "submitter": "James Bagrow", "authors": "Xipei Liu and James P. Bagrow", "title": "Autocompletion interfaces make crowd workers slower, but their use\n  promotes response diversity", "comments": "12 pages, 6 figures", "journal-ref": "Human Computation 6:1:42-55 (2019)", "doi": "10.15346/hc.v6i1.3", "report-no": null, "categories": "cs.HC cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creative tasks such as ideation or question proposal are powerful\napplications of crowdsourcing, yet the quantity of workers available for\naddressing practical problems is often insufficient. To enable scalable\ncrowdsourcing thus requires gaining all possible efficiency and information\nfrom available workers. One option for text-focused tasks is to allow assistive\ntechnology, such as an autocompletion user interface (AUI), to help workers\ninput text responses. But support for the efficacy of AUIs is mixed. Here we\ndesigned and conducted a randomized experiment where workers were asked to\nprovide short text responses to given questions. Our experimental goal was to\ndetermine if an AUI helps workers respond more quickly and with improved\nconsistency by mitigating typos and misspellings. Surprisingly, we found that\nneither occurred: workers assigned to the AUI treatment were slower than those\nassigned to the non-AUI control and their responses were more diverse, not\nless, than those of the control. Both the lexical and semantic diversities of\nresponses were higher, with the latter measured using word2vec. A crowdsourcer\ninterested in worker speed may want to avoid using an AUI, but using an AUI to\nboost response diversity may be valuable to crowdsourcers interested in\nreceiving as much novel information from workers as possible.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 15:41:38 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Liu", "Xipei", ""], ["Bagrow", "James P.", ""]]}, {"id": "1707.07066", "submitter": "Hayafumi Watanabe", "authors": "Hayafumi Watanabe", "title": "Ultraslow diffusion in language: Dynamics of appearance of already\n  popular adjectives on Japanese blogs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What dynamics govern a time series representing the appearance of words in\nsocial media data? In this paper, we investigate an elementary dynamics, from\nwhich word-dependent special effects are segregated, such as breaking news,\nincreasing (or decreasing) concerns, or seasonality. To elucidate this problem,\nwe investigated approximately three billion Japanese blog articles over a\nperiod of six years, and analysed some corresponding solvable mathematical\nmodels. From the analysis, we found that a word appearance can be explained by\nthe random diffusion model based on the power-law forgetting process, which is\na type of long memory point process related to ARFIMA(0,0.5,0). In particular,\nwe confirmed that ultraslow diffusion (where the mean squared displacement\ngrows logarithmically), which the model predicts in an approximate manner,\nreproduces the actual data. In addition, we also show that the model can\nreproduce other statistical properties of a time series: (i) the fluctuation\nscaling, (ii) spectrum density, and (iii) shapes of the probability density\nfunctions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 23:13:50 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 05:05:33 GMT"}, {"version": "v3", "created": "Fri, 28 Jul 2017 05:39:01 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Watanabe", "Hayafumi", ""]]}, {"id": "1707.07210", "submitter": "Julian Georg Zilly", "authors": "Julian Zilly, Amit Boyarski, Micael Carvalho, Amir Atapour Abarghouei,\n  Konstantinos Amplianitis, Aleksandr Krasnov, Massimiliano Mancini, Hern\\'an\n  Gonzalez, Riccardo Spezialetti, Carlos Sampedro P\\'erez, Hao Li", "title": "Inspiring Computer Vision System Solutions", "comments": "5 pages. 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \"digital Michelangelo project\" was a seminal computer vision project in\nthe early 2000's that pushed the capabilities of acquisition systems and\ninvolved multiple people from diverse fields, many of whom are now leaders in\nindustry and academia. Reviewing this project with modern eyes provides us with\nthe opportunity to reflect on several issues, relevant now as then to the field\nof computer vision and research in general, that go beyond the technical\naspects of the work.\n  This article was written in the context of a reading group competition at the\nweek-long International Computer Vision Summer School 2017 (ICVSS) on Sicily,\nItaly. To deepen the participants understanding of computer vision and to\nfoster a sense of community, various reading groups were tasked to highlight\nimportant lessons which may be learned from provided literature, going beyond\nthe contents of the paper. This report is the winning entry of this guided\ndiscourse (Fig. 1). The authors closely examined the origins, fruits and most\nimportantly lessons about research in general which may be distilled from the\n\"digital Michelangelo project\". Discussions leading to this report were held\nwithin the group as well as with Hao Li, the group mentor.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jul 2017 20:20:57 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Zilly", "Julian", ""], ["Boyarski", "Amit", ""], ["Carvalho", "Micael", ""], ["Abarghouei", "Amir Atapour", ""], ["Amplianitis", "Konstantinos", ""], ["Krasnov", "Aleksandr", ""], ["Mancini", "Massimiliano", ""], ["Gonzalez", "Hern\u00e1n", ""], ["Spezialetti", "Riccardo", ""], ["P\u00e9rez", "Carlos Sampedro", ""], ["Li", "Hao", ""]]}, {"id": "1707.07232", "submitter": "Iyad Rahwan", "authors": "Iyad Rahwan", "title": "Society-in-the-Loop: Programming the Algorithmic Social Contract", "comments": "(in press), Ethics of Information Technology, 2017", "journal-ref": "Ethics and Information Technology, 2017", "doi": "10.1007/s10676-017-9430-8", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent rapid advances in Artificial Intelligence (AI) and Machine Learning\nhave raised many questions about the regulatory and governance mechanisms for\nautonomous machines. Many commentators, scholars, and policy-makers now call\nfor ensuring that algorithms governing our lives are transparent, fair, and\naccountable. Here, I propose a conceptual framework for the regulation of AI\nand algorithmic systems. I argue that we need tools to program, debug and\nmaintain an algorithmic social contract, a pact between various human\nstakeholders, mediated by machines. To achieve this, we can adapt the concept\nof human-in-the-loop (HITL) from the fields of modeling and simulation, and\ninteractive machine learning. In particular, I propose an agenda I call\nsociety-in-the-loop (SITL), which combines the HITL control paradigm with\nmechanisms for negotiating the values of various stakeholders affected by AI\nsystems, and monitoring compliance with the agreement. In short, `SITL = HITL +\nSocial Contract.'\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 00:03:52 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 03:39:40 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Rahwan", "Iyad", ""]]}, {"id": "1707.07592", "submitter": "Filippo Menczer", "authors": "Chengcheng Shao, Giovanni Luca Ciampaglia, Onur Varol, Kaicheng Yang,\n  Alessandro Flammini, Filippo Menczer", "title": "The spread of low-credibility content by social bots", "comments": "41 pages, 20 figures, 3 tables", "journal-ref": "Nature Communications, 9: 4787, 2018", "doi": "10.1038/s41467-018-06930-7", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive spread of digital misinformation has been identified as a major\nglobal risk and has been alleged to influence elections and threaten\ndemocracies. Communication, cognitive, social, and computer scientists are\nengaged in efforts to study the complex causes for the viral diffusion of\nmisinformation online and to develop solutions, while search and social media\nplatforms are beginning to deploy countermeasures. With few exceptions, these\nefforts have been mainly informed by anecdotal evidence rather than systematic\ndata. Here we analyze 14 million messages spreading 400 thousand articles on\nTwitter during and following the 2016 U.S. presidential campaign and election.\nWe find evidence that social bots played a disproportionate role in amplifying\nlow-credibility content. Accounts that actively spread articles from\nlow-credibility sources are significantly more likely to be bots. Automated\naccounts are particularly active in amplifying content in the very early\nspreading moments, before an article goes viral. Bots also target users with\nmany followers through replies and mentions. Humans are vulnerable to this\nmanipulation, retweeting bots who post links to low-credibility content.\nSuccessful low-credibility sources are heavily supported by social bots. These\nresults suggest that curbing social bots may be an effective strategy for\nmitigating the spread of online misinformation.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 14:53:36 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 02:42:10 GMT"}, {"version": "v3", "created": "Sat, 30 Dec 2017 22:30:03 GMT"}, {"version": "v4", "created": "Thu, 24 May 2018 23:18:12 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Shao", "Chengcheng", ""], ["Ciampaglia", "Giovanni Luca", ""], ["Varol", "Onur", ""], ["Yang", "Kaicheng", ""], ["Flammini", "Alessandro", ""], ["Menczer", "Filippo", ""]]}, {"id": "1707.07913", "submitter": "Piotr Szyma\\'nski", "authors": "Piotr Szyma\\'nski, Micha{\\l} \\.Zo{\\l}nieruk, Piotr Oleszczyk, Igor\n  Gisterek, Tomasz Kajdanowicz", "title": "Spatio-temporal profiling of public transport delays based on large\n  scale vehicle positioning data from GPS in Wroc{\\l}aw", "comments": "accepted to KnowME2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years many studies of urban mobility based on large data sets have\nbeen published: most of them based on crowdsourced GPS data or smart-card data.\nWe present, what is to our knowledge the first, exploration of public transport\ndelay data harvested from a large-scale, official public transport positioning\nsystem, provided by the Wroc{\\l}aw Municipality. We evaluate the\ncharacteristics of delays between stops in relation to direction, time and\ndelay variance of 1648 stop pairs from 15 mln delay reports. We construct a\nnormalized feature matrix of likelihood of a given delay change happening at a\ngiven hour on the edge between two stops. We then calculate distances between\nsuch matrices using earth mover's distance and cluster them using hierarchical\nagglomerative clustering with Ward's linkage method. We obtain four profiles of\ndelay changes in Wroc{\\l}aw: edges without impact on delay, edges likely to\ncause delay, edges likely to decrease delay and edges likely to strongly\ndecrease delay (ex. when a public transport vehicle is speeding). We analyze\nthe spatial and mode of transport properties of each cluster and provide\ninsights into reasons of delay change patterns in each of the detected\nprofiles.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 10:55:33 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Szyma\u0144ski", "Piotr", ""], ["\u017bo\u0142nieruk", "Micha\u0142", ""], ["Oleszczyk", "Piotr", ""], ["Gisterek", "Igor", ""], ["Kajdanowicz", "Tomasz", ""]]}, {"id": "1707.07994", "submitter": "Piotr Br\\'odka", "authors": "Jean-Francois Ethier, Vasa Curcin, Mark M. McGilchrist, Sarah N. Lim\n  Choi Keung, Lei Zhao, Anna Andreasson, Piotr Br\\'odka, Radoslaw Michalski,\n  Theodoros N. Arvanitis, Nikolaos Mastellos, Anita Burgun, Brendan C. Delaney", "title": "eSource for clinical trials: Implementation and evaluation of a\n  standards-based approach in a real world trial", "comments": null, "journal-ref": "International Journal of Medical Informatics Volume 106, October\n  2017, Pages 17-24", "doi": "10.1016/j.ijmedinf.2017.06.006", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The Learning Health System (LHS) requires integration of research\ninto routine practice. eSource or embedding clinical trial functionalities into\nroutine electronic health record (EHR) systems has long been put forward as a\nsolution to the rising costs of research. We aimed to create and validate an\neSource solution that would be readily extensible as part of a LHS.\n  Materials and Methods: The EU FP7 TRANSFoRm project's approach is based on\ndual modelling, using the Clinical Research Information Model (CRIM) and the\nClinical Data Integration Model of meaning (CDIM) to bridge the gap between\nclinical and research data structures, using the CDISC Operational Data Model\n(ODM) standard. Validation against GCP requirements was conducted in a clinical\nsite, and a cluster randomised evaluation by site nested into a live clinical\ntrial.\n  Results: Using the form definition element of ODM, we linked precisely\nmodelled data queries to data elements, constrained against CDIM concepts, to\nenable automated patient identification for specific protocols and\nprepopulation of electronic case report forms (e-CRF). Both control and eSource\nsites recruited better than expected with no significant difference.\nCompleteness of clinical forms was significantly improved by eSource, but\nPatient Related Outcome Measures (PROMs) were less well completed on\nsmartphones than paper in this population.\n  Discussion: The TRANSFoRm approach provides an ontologically-based approach\nto eSource in a low-resource, heterogeneous, highly distributed environment,\nthat allows precise prospective mapping of data elements in the EHR.\n  Conclusion: Further studies using this approach to CDISC should optimise the\ndelivery of PROMS, whilst building a sustainable infrastructure for eSource\nwith research networks, trials units and EHR vendors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 13:46:39 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Ethier", "Jean-Francois", ""], ["Curcin", "Vasa", ""], ["McGilchrist", "Mark M.", ""], ["Keung", "Sarah N. Lim Choi", ""], ["Zhao", "Lei", ""], ["Andreasson", "Anna", ""], ["Br\u00f3dka", "Piotr", ""], ["Michalski", "Radoslaw", ""], ["Arvanitis", "Theodoros N.", ""], ["Mastellos", "Nikolaos", ""], ["Burgun", "Anita", ""], ["Delaney", "Brendan C.", ""]]}, {"id": "1707.08120", "submitter": "Piotr Mardziel", "authors": "Anupam Datta, Matt Fredrikson, Gihyuk Ko, Piotr Mardziel, Shayak Sen", "title": "Proxy Non-Discrimination in Data-Driven Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.07807", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learnt systems inherit biases against protected classes, historically\ndisparaged groups, from training data. Usually, these biases are not explicit,\nthey rely on subtle correlations discovered by training algorithms, and are\ntherefore difficult to detect. We formalize proxy discrimination in data-driven\nsystems, a class of properties indicative of bias, as the presence of protected\nclass correlates that have causal influence on the system's output. We evaluate\nan implementation on a corpus of social datasets, demonstrating how to validate\nsystems against these properties and to repair violations where they occur.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 21:16:24 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Datta", "Anupam", ""], ["Fredrikson", "Matt", ""], ["Ko", "Gihyuk", ""], ["Mardziel", "Piotr", ""], ["Sen", "Shayak", ""]]}, {"id": "1707.08164", "submitter": "Tom Brown", "authors": "Stefan Pfenninger, Lion Hirth, Ingmar Schlecht, Eva Schmid, Frauke\n  Wiese, Tom Brown, Chris Davis, Birgit Fais, Matthew Gidden, Heidi Heinrichs,\n  Clara Heuberger, Simon Hilpert, Uwe Krien, Carsten Matke, Arjuna Nebel,\n  Robbie Morrison, Berit M\\\"uller, Guido Ple{\\ss}mann, Matthias Reeg, J\\\"orn C.\n  Richstein, Abhishek Shivakumar, Iain Staffell, Tim Tr\\\"ondle, Clemens\n  Wingenbach", "title": "Opening the black box of energy modelling: Strategies and lessons\n  learned", "comments": "9 pages, 1 figure", "journal-ref": "Energy Strategy Reviews, Volume 19, January 2018, Pages 63-71", "doi": "10.1016/j.esr.2017.12.002", "report-no": null, "categories": "cs.CY cs.GL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The global energy system is undergoing a major transition, and in energy\nplanning and decision-making across governments, industry and academia, models\nplay a crucial role. Because of their policy relevance and contested nature,\nthe transparency and open availability of energy models and data are of\nparticular importance. Here we provide a practical how-to guide based on the\ncollective experience of members of the Open Energy Modelling Initiative\n(Openmod). We discuss key steps to consider when opening code and data,\nincluding determining intellectual property ownership, choosing a licence and\nappropriate modelling languages, distributing code and data, and providing\nsupport and building communities. After illustrating these decisions with\nexamples and lessons learned from the community, we conclude that even though\nindividual researchers' choices are important, institutional changes are still\nalso necessary for more openness and transparency in energy research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 08:39:29 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 14:59:32 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Pfenninger", "Stefan", ""], ["Hirth", "Lion", ""], ["Schlecht", "Ingmar", ""], ["Schmid", "Eva", ""], ["Wiese", "Frauke", ""], ["Brown", "Tom", ""], ["Davis", "Chris", ""], ["Fais", "Birgit", ""], ["Gidden", "Matthew", ""], ["Heinrichs", "Heidi", ""], ["Heuberger", "Clara", ""], ["Hilpert", "Simon", ""], ["Krien", "Uwe", ""], ["Matke", "Carsten", ""], ["Nebel", "Arjuna", ""], ["Morrison", "Robbie", ""], ["M\u00fcller", "Berit", ""], ["Ple\u00dfmann", "Guido", ""], ["Reeg", "Matthias", ""], ["Richstein", "J\u00f6rn C.", ""], ["Shivakumar", "Abhishek", ""], ["Staffell", "Iain", ""], ["Tr\u00f6ndle", "Tim", ""], ["Wingenbach", "Clemens", ""]]}, {"id": "1707.08169", "submitter": "Alex Budilovsky G", "authors": "Oleksiy Budilovsky, Golnaz Alipour, Andre Knoesen, Lisa Brown, Soheil\n  Ghiasi", "title": "A Data-Driven Approach to Pre-Operative Evaluation of Lung Cancer\n  Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lung cancer is the number one cause of cancer deaths. Many early stage lung\ncancer patients have resectable tumors; however, their cardiopulmonary function\nneeds to be properly evaluated before they are deemed operative candidates.\nConsequently, a subset of such patients is asked to undergo standard pulmonary\nfunction tests, such as cardiopulmonary exercise tests (CPET) or stair climbs,\nto have their pulmonary function evaluated. The standard tests are expensive,\nlabor intensive, and sometimes ineffective due to co-morbidities, such as\nlimited mobility. Recovering patients would benefit greatly from a device that\ncan be worn at home, is simple to use, and is relatively inexpensive. Using\nadvances in information technology, the goal is to design a continuous,\ninexpensive, mobile and patient-centric mechanism for evaluation of a patient's\npulmonary function. A light mobile mask is designed, fitted with CO2, O2, flow\nvolume, and accelerometer sensors and tested on 18 subjects performing 15\nminute exercises. The data collected from the device is stored in a cloud\nservice and machine learning algorithms are used to train and predict a user's\nactivity .Several classification techniques are compared - K Nearest Neighbor,\nRandom Forest, Support Vector Machine, Artificial Neural Network, and Naive\nBayes. One useful area of interest involves comparing a patient's predicted\nactivity levels, especially using only breath data, to that of a normal\nperson's, using the classification models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 22:18:08 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Budilovsky", "Oleksiy", ""], ["Alipour", "Golnaz", ""], ["Knoesen", "Andre", ""], ["Brown", "Lisa", ""], ["Ghiasi", "Soheil", ""]]}, {"id": "1707.08182", "submitter": "Mohamed Amine Marhraoui M.", "authors": "Mohamed Amine Marhraoui and Abdellah El Manouar", "title": "Towards a new Framework linking knowledge management systems and\n  organizational agility : an empirical study", "comments": "16 pages, 7 figures", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 9, No 1, February 2017", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of data has exploded over the last ten years. Data is captured and\nshared from personal devices, transactional operations, sensors, social media\nand other sources. Firms should, thus, be able to explore the new opportunities\nand rapidly seize them by developing the corresponding capabilities. In our\nwork, we focus on two emerging dynamic capabilities: Absorptive capacity and\norganizational agility. We propose a new theoretical Framework based on the\nprevious literature linking the use of knowledge management systems and\norganizational agility by highlighting the mediating role of absorptive\ncapacity. In addition, we carried out an empirical study based on a survey to\nsupport and validate the proposed Framework. The main findings of this study\nare presented.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 17:21:33 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Marhraoui", "Mohamed Amine", ""], ["Manouar", "Abdellah El", ""]]}, {"id": "1707.08454", "submitter": "Thomas Lef\\`evre", "authors": "Vincent Laugier (1,2), Eric Stindel (3), Alcibiade Lichterowicz (1),\n  S\\'everine Ansart (3) and Thomas Lef\\`evre (4,5) ((1) Tekliko SARL - 362,\n  chemin de la Bosque Antonelle, France, (2) Tekliko Pte Ltd - 100, Singapore,\n  (3) Laboratory of Medical Information Processing (LaTIM - INSERM UMR 1101),\n  France, (4) Department of forensic medicine, H\\^opital Jean Verdier APHP,\n  France, (5) IRIS - Institut de Recherches Interdisciplinaires sur les enjeux\n  Sociaux, INSERM, CNRS, EHESS, Universit\\'e Paris 13, France)", "title": "Making the best of data derived from a daily practice in clinical legal\n  medicine for research and practice - the example of Spe3dLab", "comments": "15 pages, 3 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forensic science suffers from a lack of studies with high-quality design,\nsuch as randomized controlled trials (RCT). Evidence in forensic science may be\nof insufficient quality, which is a major concern. Results from RCT are\ncriticized for providing artificial results that are not useful in real life\nand unfit for individualized prescription. Various sources of collected data\n(e.g. data collected in routine practice) could be exploited for distinct\ngoals. Obstacles remain before such data can be practically accessed and used,\nincluding technical issues. We present an easy-to-use software dedicated to\ninnovative data analyses for practitioners and researchers. We provide 2\nexamples in forensics. Spe3dLab has been developed by 3 French teams: a\nbioinformatics laboratory (LaTIM), a private partner (Tekliko) and a department\nof forensic medicine (Jean Verdier Hospital). It was designed to be open\nsource, relying on documented and maintained libraries, query-oriented and\ncapable of handling the entire data process from capture to export of best\npredictive models for their integration in information systems. Spe3dLab was\nused for 2 specific forensics applications: i) the search for multiple causal\nfactors and ii) the best predictive model of the functional impairment (total\nincapacity to work, TIW) of assault survivors. 2,892 patients were included\nover a 6-month period. Time to evaluation was the only direct cause identified\nfor TIW, and victim category was an indirect cause. The specificity and\nsensitivity of the predictive model were 99.9% and 90%, respectively. Spe3dLab\nis a quick and efficient tool for accessing observational, routinely collected\ndata and performing innovative analyses. Analyses can be exported for\nvalidation and routine use by practitioners, e.g., for computer-aided\nevaluation of complex problems. It can provide a fully integrated solution for\nindividualized medicine.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 15:27:46 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Laugier", "Vincent", ""], ["Stindel", "Eric", ""], ["Lichterowicz", "Alcibiade", ""], ["Ansart", "S\u00e9verine", ""], ["Lef\u00e8vre", "Thomas", ""]]}, {"id": "1707.08607", "submitter": "Kevin Xu", "authors": "Rehan Ahmad and Kevin S. Xu", "title": "Effects of Contact Network Models on Stochastic Epidemic Simulations", "comments": "To appear at International Conference on Social Informatics (SocInfo)\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of modeling the spread of epidemics through a population has\nled to the development of mathematical models for infectious disease\npropagation. A number of empirical studies have collected and analyzed data on\ncontacts between individuals using a variety of sensors. Typically one uses\nsuch data to fit a probabilistic model of network contacts over which a disease\nmay propagate. In this paper, we investigate the effects of different contact\nnetwork models with varying levels of complexity on the outcomes of simulated\nepidemics using a stochastic Susceptible-Infectious-Recovered (SIR) model. We\nevaluate these network models on six datasets of contacts between people in a\nvariety of settings. Our results demonstrate that the choice of network model\ncan have a significant effect on how closely the outcomes of an epidemic\nsimulation on a simulated network match the outcomes on the actual network\nconstructed from the sensor data. In particular, preserving degrees of nodes\nappears to be much more important than preserving cluster structure for\naccurate epidemic simulations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 18:59:37 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Ahmad", "Rehan", ""], ["Xu", "Kevin S.", ""]]}, {"id": "1707.08715", "submitter": "Madhusudan Singh Ph.D.", "authors": "Madhusudan Singh and Shiho Kim", "title": "Safety Requirement Specifications for Connected Vehicles", "comments": "5 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the coming years, transportation system will be revamped in a manner that\nthere will be more intelligent and autonomous vehicle phenomenon around us such\nas smart cars, auto driving system, etc. Some of automotive industries are\nalready producing smart cars. However, the main concern of this paper is on the\ninfrastructure for connected vehicles, which can support such intelligent\ntransportation. Current transportation system lacks proper infrastructure to\nsupport connected vehicles. Hence, in this article, we have surveyed and\nanalyzed the current transportation system in developed and developing\ncountries. In contrast, we are going to introduce secure intelligent\ntransportation (roadside) infrastructure that is user centric (Driver,\nAutonomous driver etc.) for connected vehicles. In this paper we present the\nbasic requirements of safety engineering infrastructure of roadside\ninfrastructure in ITS for connected vehicles. Connected vehicles has network\ninfrastructure to communicate with vehicle-to-vehicle (V-to-V),\nvehicle-to-infrastructure (V-to-I), lane correction system, and traffic\ninformation system etc. The connected vehicle is a good model for learning\ndemands of infrastructure for ITS process because the system having a lot of\nuse-cases and we must understand relationship between public institutions,\npeople, companies in order to proceed ITS System.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 05:56:50 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 07:15:38 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Singh", "Madhusudan", ""], ["Kim", "Shiho", ""]]}, {"id": "1707.08741", "submitter": "EPTCS", "authors": "Zo\\'e Christoff (University of Bayreuth), Davide Grossi (University of\n  Liverpool)", "title": "Binary Voting with Delegable Proxy: An Analysis of Liquid Democracy", "comments": "In Proceedings TARK 2017, arXiv:1707.08250", "journal-ref": "EPTCS 251, 2017, pp. 134-150", "doi": "10.4204/EPTCS.251.10", "report-no": null, "categories": "cs.MA cs.AI cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper provides an analysis of the voting method known as delegable proxy\nvoting, or liquid democracy. The analysis first positions liquid democracy\nwithin the theory of binary aggregation. It then focuses on two issues of the\nsystem: the occurrence of delegation cycles; and the effect of delegations on\nindividual rationality when voting on logically interdependent propositions. It\nfinally points to proposals on how the system may be modified in order to\naddress the above issues.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 07:47:30 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Christoff", "Zo\u00e9", "", "University of Bayreuth"], ["Grossi", "Davide", "", "University of\n  Liverpool"]]}, {"id": "1707.08826", "submitter": "Daniel Gamermann Dr.", "authors": "Daniel Gamermann and Felipe Leite Antunes", "title": "Evidence of Fraud in Brazil's Electoral Campaigns Via the Benford's Law", "comments": "21 pages, 3 figures, 9 tables", "journal-ref": null, "doi": "10.1016/j.physa.2017.12.120", "report-no": null, "categories": "stat.AP cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of democracy is that the people govern through elected\nrepresentatives. Therefore, a democracy is healthy as long as the elected\npoliticians do represent the people. We have analyzed data from the Brazilian\nelectoral court (Tribunal Superior Eleitoral, TSE) concerning money donations\nfor the electoral campaigns and the election results. Our work points to two\ndisturbing conclusions: money is a determining factor on whether a candidate is\nelected or not (as opposed to representativeness); secondly, the use of\nBenford's Law to analyze the declared donations received by the parties and\nelectoral campaigns shows evidence of fraud in the declarations. A better term\nto define Brazil's government system is what we define as chrimatocracy (govern\nby money).\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 12:47:14 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Gamermann", "Daniel", ""], ["Antunes", "Felipe Leite", ""]]}, {"id": "1707.09489", "submitter": "Poonam Yadav Dr", "authors": "Poonam Yadav and Jeremy Cohen and John Darlington", "title": "CitizenGrid: An Online Middleware for Crowdsourcing Scientific Research", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, contributions of the general public in scientific\nprojects has increased due to the advancement of communication and computing\ntechnologies. Internet played an important role in connecting scientists and\nvolunteers who are interested in participating in their scientific projects.\nHowever, despite potential benefits, only a limited number of crowdsourcing\nbased large-scale science (citizen science) projects have been deployed due to\nthe complexity involved in setting them up and running them. In this paper, we\npresent CitizenGrid - an online middleware platform which addresses security\nand deployment complexity issues by making use of cloud computing and\nvirtualisation technologies. CitizenGrid incentivises scientists to make their\nsmall-to-medium scale applications available as citizen science projects by: 1)\nproviding a directory of projects through a web-based portal that makes\napplications easy to discover; 2) providing flexibility to participate in,\nmonitor, and control multiple citizen science projects from a common interface;\n3) supporting diverse categories of citizen science projects. The paper\ndescribes the design, development and evaluation of CitizenGrid and its use\ncases.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 09:48:14 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Yadav", "Poonam", ""], ["Cohen", "Jeremy", ""], ["Darlington", "John", ""]]}, {"id": "1707.09566", "submitter": "Poonam Yadav Dr", "authors": "Poonam Yadav and Ioannis Charalampidis and Jeremy Cohen and John\n  Darlington and Francois Grey", "title": "A collaborative citizen science platform for real-time volunteer\n  computing and games", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volunteer computing (VC) or distributed computing projects are common in the\ncitizen cyberscience (CCS) community and present extensive opportunities for\nscientists to make use of computing power donated by volunteers to undertake\nlarge-scale scientific computing tasks. Volunteer computing is generally a\nnon-interactive process for those contributing computing resources to a project\nwhereas volunteer thinking (VT) or distributed thinking, which allows\nvolunteers to participate interactively in citizen cyberscience projects to\nsolve human computation tasks. In this paper we describe the integration of\nthree tools, the Virtual Atom Smasher (VAS) game developed by CERN, LiveQ, a\njob distribution middleware, and CitizenGrid, an online platform for hosting\nand providing computation to CCS projects. This integration demonstrates the\ncombining of volunteer computing and volunteer thinking to help address the\nscientific and educational goals of games like VAS. The paper introduces the\nthree tools and provides details of the integration process along with further\npotential usage scenarios for the resulting platform.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 22:46:20 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 13:31:44 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Yadav", "Poonam", ""], ["Charalampidis", "Ioannis", ""], ["Cohen", "Jeremy", ""], ["Darlington", "John", ""], ["Grey", "Francois", ""]]}, {"id": "1707.09570", "submitter": "Hiroki Sayama", "authors": "Hiroki Sayama", "title": "Mapping the Curricular Structure and Contents of Network Science Courses", "comments": "17 pages, 11 figures, 2 tables; to appear in Cramer, C. et al.\n  (eds.), Network Science in Education -- Tools and Techniques for Transforming\n  Teaching and Learning (Springer, 2017, in press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DM cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As network science has matured as an established field of research, there are\nalready a number of courses on this topic developed and offered at various\nhigher education institutions, often at postgraduate levels. In those courses,\ninstructors adopted different approaches with different focus areas and\ncurricular designs. We collected information about 30 existing network science\ncourses from various online sources, and analyzed the contents of their syllabi\nor course schedules. The topics and their curricular sequences were extracted\nfrom the course syllabi/schedules and represented as a directed weighted graph,\nwhich we call the topic network. Community detection in the topic network\nrevealed seven topic clusters, which matched reasonably with the concept list\npreviously generated by students and educators through the Network Literacy\ninitiative. The minimum spanning tree of the topic network revealed typical\nflows of curricular contents, starting with examples of networks, moving onto\nrandom networks and small-world networks, then branching off to various\nsubtopics from there. These results illustrate the current state of consensus\nformation (including variations and disagreements) among the network science\ncommunity on what should be taught about networks and how, which may also be\ninformative for K--12 education and informal education.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jul 2017 23:48:49 GMT"}, {"version": "v2", "created": "Sun, 15 Oct 2017 16:34:15 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Sayama", "Hiroki", ""]]}, {"id": "1707.09972", "submitter": "Haixia Peng", "authors": "Haixia Peng, Le Liang, Xuemin Shen, Geoffrey Ye Li", "title": "Vehicular Communications: A Network Layer Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicular communications, referring to information exchange among vehicles,\npedestrians, and infrastructures, have become very popular and been widely\nstudied recently due to its great potential to support intelligent\ntransportation and various safety applications. Via vehicular communications,\nmanually driving vehicles and autonomous vehicles can collect useful\ninformation to improve traffic safety and support infotainment services. In\nthis paper, we provide a comprehensive overview of recent research on enabling\nefficient vehicular communications from the network layer perspective. First,\nwe introduce general applications and unique characteristics of vehicular\nnetworks and the corresponding classifications. Based on different driving\npatterns of vehicles, we divide vehicular networks into two categories, i.e.,\nmanually driving vehicular networks and automated driving vehicular networks,\nand then discuss the available communication techniques, network structures,\nrouting protocols, and handoff strategies applied in these vehicular networks.\nFinally, we identify the challenges confronted by the current vehicular\ncommunications and present the corresponding research opportunities.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 17:34:16 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Peng", "Haixia", ""], ["Liang", "Le", ""], ["Shen", "Xuemin", ""], ["Li", "Geoffrey Ye", ""]]}]