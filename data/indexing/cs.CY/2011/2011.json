[{"id": "2011.00191", "submitter": "Hancheng Cao", "authors": "Hancheng Cao, Zhilong Chen, Mengjie Cheng, Shuling Zhao, Tao Wang,\n  Yong Li", "title": "You Recommend, I Buy: How and Why People Engage in Instant Messaging\n  Based Social Commerce", "comments": "Hancheng Cao and Zhilong Chen contributed equally to this work;\n  Accepted to CSCW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an emerging business phenomenon especially in China, instant messaging\n(IM) based social commerce is growing increasingly popular, attracting hundreds\nof millions of users and is becoming one important way where people make\neveryday purchases. Such platforms embed shopping experiences within IM apps,\ne.g., WeChat, WhatsApp, where real-world friends post and recommend products\nfrom the platforms in IM group chats and quite often form lasting\nrecommending/buying relationships. How and why do users engage in IM based\nsocial commerce? Do such platforms create novel experiences that are distinct\nfrom prior commerce? And do these platforms bring changes to user social lives\nand relationships? To shed light on these questions, we launched a qualitative\nstudy where we carried out semi-structured interviews on 12 instant messaging\nbased social commerce users in China. We showed that IM based social commerce:\n1) enables more reachable, cost-reducing, and immersive user shopping\nexperience, 2) shapes user decision-making process in shopping through\npre-existing social relationship, mutual trust, shared identity, and community\nnorm, and 3) creates novel social interactions, which can contribute to new tie\nformation while maintaining existing social relationships. We demonstrate that\nall these unique aspects link closely to the characteristics of IM platforms,\nas well as the coupling of user social and economic lives under such business\nmodel. Our study provides important research and design implications for social\ncommerce, and decentralized, trusted socio-technical systems in general.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 05:21:59 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 05:42:09 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Cao", "Hancheng", ""], ["Chen", "Zhilong", ""], ["Cheng", "Mengjie", ""], ["Zhao", "Shuling", ""], ["Wang", "Tao", ""], ["Li", "Yong", ""]]}, {"id": "2011.00251", "submitter": "Rikke Bjerg Jensen", "authors": "Rikke Bjerg Jensen", "title": "Fragmented digital connectivity and security at sea", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores how uneven and often unreliable digital connections shape\nthe patterns and routines of everyday life, work and rest for seafarers, during\nlong periods at sea. Such fragmented connections, which surface when the ship\nmoves in and out of connectivity or when onboard data allowances run out,\ncreate a series of uncertainties that might unsettle individual and collective\nnotions of security. Ethnographic in nature, the study engaged 43 seafarers on\nboard two container ships in European waters, during two two-week voyages\nbetween February and April 2018. This provided an empirically grounded\nexploration of how digitally facilitated connections, relations and networks,\nenabled through increasingly connected ships, shape and reshape seafarer lives.\nFindings from this study demonstrate the creative ways in which seafarers\nnavigate and negotiate digitally facilitated connections to maintain relational\nties with family and friends. The paper concludes by setting out future\nresearch directions and practical implications that speak to connectivity and\nsecurity at sea.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 11:51:45 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Jensen", "Rikke Bjerg", ""]]}, {"id": "2011.00303", "submitter": "Benjamin Kinsella", "authors": "Michael Dowd, Anna Dixon, Benjamin Kinsella", "title": "Optimizing Waste Management Collection Routes in Urban Haiti: A\n  Collaboration between DataKind and SOIL", "comments": "6 pages, 5 figures 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sustainable Organic Integrated Livelihoods (SOIL) is a research and\ndevelopment organization that aims to increase access to cost-effective\nhousehold sanitation services in urban communities in Haiti. Each week, SOIL\nprovides over 1,000 households with ecological sanitation toilets, then\ntransports the waste to be transformed into rich compost. However, SOIL faces\nseveral challenges regarding the route optimization of their mixed fleet\nvehicle routing. This paper builds upon the authors' submission to Bloomberg's\n2019 Data for Good Exchange (D4GX), presenting preliminary findings from a\njoint collaboration between DataKind, a data science nonprofit, and SOIL. This\nresearch showcases how optimization algorithms and open source tools (i.e.,\nOpenStreetMap and Google OR-Tools) can help improve and reduce the costs of\nmixed-fleet routing problems, particularly in the context of developing\ncountries. As a result of this work, SOIL is able to make improvement to their\ncollection routes, which account for different road conditions and vehicle\ntypes. These improvements reduce operational costs and fuel use, which are\nessential to the service's expansion in the coming years.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 16:18:06 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Dowd", "Michael", ""], ["Dixon", "Anna", ""], ["Kinsella", "Benjamin", ""]]}, {"id": "2011.00336", "submitter": "Neil Yeung Y", "authors": "Neil Yeung, Jonathan Lai, Jiebo Luo", "title": "Face Off: Polarized Public Opinions on Personal Face Mask Usage during\n  the COVID-19 Pandemic", "comments": "9 pages, 14 figures, to be published in Special Session on\n  Intelligent Data Mining, IEEE Big Data 2020; typos corrected, added\n  Acknowledgement section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of a growing body of scientific evidence on the effectiveness of\nindividual face mask usage for reducing transmission rates, individual face\nmask usage has become a highly polarized topic within the United States. A\nseries of policy shifts by various governmental bodies have been speculated to\nhave contributed to the polarization of face masks. A typical method to\ninvestigate the effects of these policy shifts is to use surveys. However,\nsurvey-based approaches have multiple limitations: biased responses, limited\nsample size, badly crafted questions may skew responses and inhibit insight,\nand responses may prove quickly irrelevant as opinions change in response to a\ndynamic topic. We propose a novel approach to 1) accurately gauge public\nsentiment towards face masks in the United States during COVID-19 using a\nmulti-modal demographic inference framework with topic modeling and 2)\ndetermine whether face mask policy shifts contributed to polarization towards\nface masks using offline change point analysis on Twitter data. First, we infer\nseveral key demographics of individual Twitter users such as their age, gender,\nand whether they are a college student using a multi-modal demographic\nprediction framework and analyze the average sentiment for each respective\ndemographic. Next, we conduct topic analysis using latent Dirichlet allocation\n(LDA). Finally, we conduct offline change point discovery on our sentiment time\nseries data using the Pruned Exact Linear Time (PELT) search algorithm.\nExperimental results on a large corpus of Twitter data reveal multiple insights\nregarding demographic sentiment towards face masks that agree with existing\nsurveys. Furthermore, we find two key policy-shift events contributed to\nstatistically significant changes in sentiment for both Republicans and\nDemocrats.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:52:41 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2020 01:43:09 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Yeung", "Neil", ""], ["Lai", "Jonathan", ""], ["Luo", "Jiebo", ""]]}, {"id": "2011.00379", "submitter": "Jialu Wang", "authors": "Jialu Wang, Yang Liu, Caleb Levy", "title": "Fair Classification with Group-Dependent Label Noise", "comments": "11 pages, 9 tables", "journal-ref": null, "doi": "10.1145/3442188.3445915", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work examines how to train fair classifiers in settings where training\nlabels are corrupted with random noise, and where the error rates of corruption\ndepend both on the label class and on the membership function for a protected\nsubgroup. Heterogeneous label noise models systematic biases towards particular\ngroups when generating annotations. We begin by presenting analytical results\nwhich show that naively imposing parity constraints on demographic disparity\nmeasures, without accounting for heterogeneous and group-dependent error rates,\ncan decrease both the accuracy and the fairness of the resulting classifier.\nOur experiments demonstrate these issues arise in practice as well. We address\nthese problems by performing empirical risk minimization with carefully defined\nsurrogate loss functions and surrogate constraints that help avoid the pitfalls\nintroduced by heterogeneous label noise. We provide both theoretical and\nempirical justifications for the efficacy of our methods. We view our results\nas an important example of how imposing fairness on biased data sets without\nproper care can do at least as much harm as it does good.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 22:35:01 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 00:01:56 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Wang", "Jialu", ""], ["Liu", "Yang", ""], ["Levy", "Caleb", ""]]}, {"id": "2011.00414", "submitter": "Varun Behera", "authors": "Varun Nagesh Jolly Behera, Ashish Ranjan, Motahar Reza", "title": "Graph based Clustering Algorithm for Social Community Transmission\n  Prediction of COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.DM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A system to model the spread of COVID-19 cases after lockdown has been\nproposed, to define new preventive measures based on hotspots, using the graph\nclustering algorithm. This method allows for more lenient measures in areas\nless prone to the virus spread. There exist methods to model the spread of the\nvirus, by predicting the number of confirmed cases. But the proposed system\nfocuses more on the preventive side of the solution from a geographical point\nof view, by predicting the areas or regions that may become hotspots for the\nvirus in the near future. The fact that the virus can only be transmitted by\nbeing in close proximity to an already infected person, suggests that, the\nregions that can easily be reached from an existing hotspot, have a higher\nchance of becoming a new hotspot. Moreover, in smaller regions, even after\nstrict provisions, positive cases have been found. To consider this fact, the\ngeographic distance between the nearest hotspots can be used as a measure of\nlikelihood of the region also becoming a hotspot. In this paper, a weighted\ngraph of regions with the regions themselves as weighted nodes with weight of\nthe nodes as the number of active cases and the distance as edge weights. The\ngraph can be completely connected or connected based on a distance threshold.\nThe nodes are the administrative, and the distance measure tells the possible\ntransmission between separate communities. Using this data, the potential\nregions that can become hotspots can be predicted, and preventive measures can\nbe devised.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 03:59:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Behera", "Varun Nagesh Jolly", ""], ["Ranjan", "Ashish", ""], ["Reza", "Motahar", ""]]}, {"id": "2011.00464", "submitter": "Jose Berengueres Ph.D", "authors": "Jose Berengueres", "title": "What is the T-Algorithm? A case study to evaluate a new University", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate Scott Galloway's T-algorithm as a thinking framework via a\nsimulated case. We explain how we applied it to analyze the investment\nstrategies when starting a new university. We note that the algorithm can be\nused to describe but also prescribe the strategy design space. We also point\nweak and strong points of the said algorithm and compare it to existing tools\nsuch as the Business canvas model and SWOT.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 10:26:35 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 23:21:38 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Berengueres", "Jose", ""]]}, {"id": "2011.00603", "submitter": "Guilherme Alves", "authors": "Guilherme Alves, Vaishnavi Bhargava, Miguel Couceiro, Amedeo Napoli", "title": "Making ML models fairer through explanations: the case of LimeOut", "comments": "11 pages, 5 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Algorithmic decisions are now being used on a daily basis, and based on\nMachine Learning (ML) processes that may be complex and biased. This raises\nseveral concerns given the critical impact that biased decisions may have on\nindividuals or on society as a whole. Not only unfair outcomes affect human\nrights, they also undermine public trust in ML and AI. In this paper we address\nfairness issues of ML models based on decision outcomes, and we show how the\nsimple idea of \"feature dropout\" followed by an \"ensemble approach\" can improve\nmodel fairness. To illustrate, we will revisit the case of \"LimeOut\" that was\nproposed to tackle \"process fairness\", which measures a model's reliance on\nsensitive or discriminatory features. Given a classifier, a dataset and a set\nof sensitive features, LimeOut first assesses whether the classifier is fair by\nchecking its reliance on sensitive features using \"Lime explanations\". If\ndeemed unfair, LimeOut then applies feature dropout to obtain a pool of\nclassifiers. These are then combined into an ensemble classifier that was\nempirically shown to be less dependent on sensitive features without\ncompromising the classifier's accuracy. We present different experiments on\nmultiple datasets and several state of the art classifiers, which show that\nLimeOut's classifiers improve (or at least maintain) not only process fairness\nbut also other fairness metrics such as individual and group fairness, equal\nopportunity, and demographic parity.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2020 19:07:11 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Alves", "Guilherme", ""], ["Bhargava", "Vaishnavi", ""], ["Couceiro", "Miguel", ""], ["Napoli", "Amedeo", ""]]}, {"id": "2011.00665", "submitter": "Tadashi Okoshi", "authors": "Tadashi Okoshi, Wataru Sasaki, Hiroshi Kawane, Kota Tsubouchi", "title": "NationalMood: Large-scale Estimation of People's Mood from Web Search\n  Query and Mobile Sensor Data", "comments": "submitted to The Web Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to estimate current affective statuses of web users has\nconsiderable potential towards the realization of user-centric opportune\nservices. However, determining the type of data to be used for such estimation\nas well as collecting the ground truth of such affective statuses are difficult\nin the real world situation. We propose a novel way of such estimation based on\na combinational use of user's web search queries and mobile sensor data. Our\nlarge-scale data analysis with about 11,000,000 users and 100 recent\nadvertisement log revealed (1) the existence of certain class of advertisement\nto which mood-status-based delivery would be significantly effective, (2) that\nour \"National Mood Score\" shows the ups and downs of people's moods in COVID-19\npandemic that inversely correlated to the number of patients, as well as the\nweekly mood rhythm of people.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 01:15:04 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 02:37:02 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Okoshi", "Tadashi", ""], ["Sasaki", "Wataru", ""], ["Kawane", "Hiroshi", ""], ["Tsubouchi", "Kota", ""]]}, {"id": "2011.00751", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "A Critical Correspondence on Humpty Dumpty's Funding for European\n  Journalism", "comments": "Revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short critical correspondence discusses the Digital News Innovation\n(DNI) fund orchestrated by Humpty Dumpty -- a.k.a. Google -- for helping\nEuropean journalism to innovate and renew itself. Based on topic modeling and\ncritical discourse analysis, the results indicate that the innovative projects\nmostly mimic the old business model of Humpty Dumpty. With these results and\nthe accompanying critical discussion, this correspondence contributes to the\nongoing battle between platforms and media.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 05:16:23 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 12:20:41 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 04:42:22 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "2011.00843", "submitter": "Loe Feijs", "authors": "Loe Feijs", "title": "Analyzing the Structure of Mondrian's 1920-1940 Compositions", "comments": "10 pages, 3 figures, 2 plots. Work presented at the 2020\n  Minisymposium Mathematics and Arts at the annual meeting of the German\n  Mathematical Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mondrian was one of the most significant painters of the 20th century. He was\na prominent member of DeStijl, the movement which revolutionized art by setting\nit free of the obligation to make images of existing objects, persons, or\nsituations. DeStijl was one of the interrelated movements in early 20th century\nEurope including Cubism, Constructivism, the Futurists, and Dada. Their\ndisruptive ideas changed the meaning of Western art. It was Mondrian, more than\nanyone else, who worked restlessly to find expression for the purest possible\nkind of beauty and truth, based on a theory called Neoplasticism. He was\nalready famous during his lifetime and still now, his name is almost synonym\nfor modern art. We analyze the structure of the system of black lines in his\npaintings and put the hypothesis to the test that the paintings could be\nobtained by recursive (binary) splitting. We used a novel tailor-made\ninteractive analysis tool and apply it to as many Mondrian paintings as\npossible (in total 147). The results will be explained in a visual manner, but\nwe also present statistical findings from the analysis of the 147 paintings.\nOur main conclusion is that the hypothesis of splitting decomposition is in\ngeneral not true. It is possible to make Mondrian-like compositions by\nsplitting, yet one misses out on a great deal of Neoplastic beauty if one would\nwork by splitting only. It is possible to consider all crossings as pairs of\nTees, but that is clumsy, and it leaves out essential information. Moreover\nthere are other important design decisions of Mondrian, such as the\nkeeping-distance to the canvas-edge which are not well-described by splitting.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 09:38:08 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Feijs", "Loe", ""]]}, {"id": "2011.00946", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen and Kalle Hjerppe", "title": "The GDPR Enforcement Fines at Glance", "comments": "Revised. Substantial overlap expected with arXiv:2003.05151; accepted\n  by venue (i.e., extended conference paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The General Data Protection Regulation (GDPR) came into force in 2018. After\nthis enforcement, many fines have already been imposed by national data\nprotection authorities in Europe. This paper examines the individual GDPR\narticles referenced in the enforcement decisions, as well as predicts the\namount of enforcement fines with available meta-data and text mining features\nextracted from the enforcement decision documents. According to the results,\nthree articles related to the general principles, lawfulness, and information\nsecurity have been the most frequently referenced ones. Although the amount of\nfines imposed vary across the articles referenced, these three particular\narticles do not stand out. Furthermore, a better statistical evidence is\navailable with other meta-data features, including information about the\nparticular European countries in which the enforcements were made. Accurate\npredictions are attainable even with simple machine learning techniques for\nregression analysis. Basic text mining features outperform the meta-data\nfeatures in this regard. In addition to these results, the paper reflects the\nGDPR's enforcement against public administration obstacles in the European\nUnion (EU), as well as discusses the use of automatic decision-making systems\nin judiciary.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 13:01:45 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 10:42:07 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Ruohonen", "Jukka", ""], ["Hjerppe", "Kalle", ""]]}, {"id": "2011.00997", "submitter": "Isaac Johnson", "authors": "Isaac Johnson", "title": "Analyzing Wikidata Transclusion on English Wikipedia", "comments": "Accepted to 1st Wikidata Workshop at ISWC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikidata is steadily becoming more central to Wikipedia, not just in\nmaintaining interlanguage links, but in automated population of content within\nthe articles themselves. It is not well understood, however, how widespread\nthis transclusion of Wikidata content is within Wikipedia. This work presents a\ntaxonomy of Wikidata transclusion from the perspective of its potential impact\non readers and an associated in-depth analysis of Wikidata transclusion within\nEnglish Wikipedia. It finds that Wikidata transclusion that impacts the content\nof Wikipedia articles happens at a much lower rate (5%) than previous\nstatistics had suggested (61%). Recommendations are made for how to adjust\ncurrent tracking mechanisms of Wikidata transclusion to better support metrics\nand patrollers in their evaluation of Wikidata transclusion.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:16:42 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Johnson", "Isaac", ""]]}, {"id": "2011.01007", "submitter": "Steven Weber", "authors": "Steven Weber", "title": "The 2020s Political Economy of Machine Translation", "comments": "42 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the hypothesis that the diversity of human languages,\nright now a barrier to interoperability in communication and trade, will become\nsignificantly less of a barrier as machine translation technologies are\ndeployed over the next several years.But this new boundary-breaking technology\ndoes not reduce all boundaries equally, and it creates new challenges for the\ndistribution of ideas and thus for innovation and economic growth.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:28:16 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Weber", "Steven", ""]]}, {"id": "2011.01200", "submitter": "Valentyn Yanchuk M", "authors": "Valentyn M. Yanchuk, Andrii G. Tkachuk, Dmitry S. Antoniuk, Tetiana A.\n  Vakaliuk, and Anna A. Humeniuk", "title": "Mathematical simulation of package delivery optimization using a\n  combination of carriers", "comments": null, "journal-ref": "International Conference on Machine Learning Techniques and NLP\n  (MLNLP 2020), October 24-25, 2020, Sydney, Australia. Computer Science &\n  Information Technology (CS & IT), Vol. 10, N.12, pp. 45-55", "doi": "10.5121/csit.2020.101205", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of goods and services in the contemporary world requires permanent\nimprovement of services e-commerce platform performance. Modern society is so\ndeeply integrated with mail deliveries, purchasing of goods and services\nonline, that makes competition between service and good providers a key\nselection factor. As long as logistic, timely, and cost-effective delivery\nplays important part authors decided to analyze possible ways of improvements\nin the current field, especially for regions distantly located from popular\ndistribution centers. Considering both: fast and lazy delivery the factor of\ncosts is playing an important role for each end-user. Given work proposes a\nsimulation that analyses the current cost of delivery for e-commerce orders in\nthe context of delivery by the Supplier Fleet, World-Wide delivery service\nfleet, and possible vendor drop-ship and checks of the alternative ways can be\nused to minimize the costs. The main object of investigation is focused around\nmid and small businesses living far from big distribution centers (except edge\ncases like lighthouses, edge rocks with very limited accessibility) but\nactively using e-commerce solutions for daily activities fulfillment. Authors\nanalyzed and proposed a solution for the problem of cost optimization for\npackages delivery for long-distance deliveries using a combination of paths\ndelivered by supplier fleets, worldwide and local carriers. Data models and\nAdd-ons of contemporary Enterprise Resource Planning systems were used, and\nadditional development is proposed in the perspective of the flow selection\nchange. The experiment is based on data sources of the United States companies\nusing a wide range of carriers for delivery services and uses the data sources\nof the real companies; however, it applies repetitive simulations to analyze\nvariances in obtained solutions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 18:44:04 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yanchuk", "Valentyn M.", ""], ["Tkachuk", "Andrii G.", ""], ["Antoniuk", "Dmitry S.", ""], ["Vakaliuk", "Tetiana A.", ""], ["Humeniuk", "Anna A.", ""]]}, {"id": "2011.01251", "submitter": "Shelby Smith", "authors": "Shelby Smith and Chaitanya Baru", "title": "NSF Convergence Approach to Transition Basic Research into Practice", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The National Science Foundation Convergence Accelerator addresses\nnational-scale societal challenges through use-inspired convergence research.\nLeveraging a convergence approach the Convergence Accelerator builds upon basic\nresearch and discovery to make timely investments to strengthen the Nations\ninnovation ecosystem associated with several key R&D priority areas and\npractices to include the coronavirus disease 2019, harnessing the data\nrevolution, the future of work, and quantum technology. Artificial Intelligence\nis a key underlying theme across all of these areas.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 19:00:22 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Smith", "Shelby", ""], ["Baru", "Chaitanya", ""]]}, {"id": "2011.01331", "submitter": "William Fleshman", "authors": "Brian B., William Fleshman, Kevin H., Ryan Kaliszewski, Shawn R", "title": "Deception and the Strategy of Influence", "comments": "The Next Wave article pre-release, full issue soon available on\n  www.nsa.gov/thenextwave", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations have long used deception as a means to exert influence in\npursuit of their agendas. In particular, information operations such as\npropaganda distribution, support of antigovernment protest, and revelation of\npolitically and socially damaging secrets were abundant during World War II and\nthe Cold War. A key component of each of these efforts is deceiving the targets\nby obscuring intent and identity. Information from a trusted source is more\ninfluential than information from an adversary and therefore more likely to\nsway opinions. The ubiquitous adoption of social media, characterized by\nuser-generated and peer disseminated content, has notably increased the\nfrequency, scale, and efficacy of influence operations worldwide. In this\narticle, we explore how methods of deception including audience building, media\nhijacking, and community subversion inform the techniques and tradecraft of\ntoday's influence operators. We then discuss how a properly equipped and\ninformed public can diagnose and counter malign influence operations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 21:39:00 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["B.", "Brian", ""], ["Fleshman", "William", ""], ["H.", "Kevin", ""], ["Kaliszewski", "Ryan", ""], ["R", "Shawn", ""]]}, {"id": "2011.01468", "submitter": "Gadekallu Thippa Reddy", "authors": "Manoj MK, Gautam Srivastava, Siva Rama Krishnan Somayaji, Thippa Reddy\n  Gadekallu, Praveen Kumar Reddy Maddikunta, Sweta Bhattacharya", "title": "An Incentive Based Approach for COVID-19 using Blockchain Technology", "comments": "Accepted for presentation at IEEE GLOBECOM 2020", "journal-ref": null, "doi": "10.1109/GCWkshps50303.2020.9367469", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current situation of COVID-19 demands novel solutions to boost healthcare\nservices and economic growth. A full-fledged solution that can help the\ngovernment and people retain their normal lifestyle and improve the economy is\ncrucial. By bringing into the picture a unique incentive-based approach, the\nstrain of government and the people can be greatly reduced. By providing\nincentives for actions such as voluntary testing, isolation, etc., the\ngovernment can better plan strategies for fighting the situation while people\nin need can benefit from the incentive offered. This idea of combining strength\nto battle against the virus can bring out newer possibilities that can give an\nupper hand in this war. As the unpredictable future develops, sharing and\nmaintaining COVID related data of every user could be the needed trigger to\nkick start the economy and blockchain paves the way for this solution with\ndecentralization and immutability of data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 04:25:36 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["MK", "Manoj", ""], ["Srivastava", "Gautam", ""], ["Somayaji", "Siva Rama Krishnan", ""], ["Gadekallu", "Thippa Reddy", ""], ["Maddikunta", "Praveen Kumar Reddy", ""], ["Bhattacharya", "Sweta", ""]]}, {"id": "2011.01712", "submitter": "Bryan Ford", "authors": "Haoqian Zhang, Cristina Basescu, and Bryan Ford", "title": "Economic Principles of PoPCoin, a Democratic Time-based Cryptocurrency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While democracy is founded on the principle of equal opportunity to manage\nour lives and pursue our fortunes, the forms of money we have inherited from\nmillenia of evolution has brought us to an unsustainable dead-end of exploding\ninequality. PoPCoin proposes to leverage the unique historical opportunities\nthat digital cryptocurrencies present for a \"clean-slate\" redesign of money, in\nparticular around long-term equitability and sustainability, rather than solely\nstability, as our primary goals. We develop and analyze a monetary policy for\nPoPCoin that embodies these equitability goals in two basic rules that maybe\nsummarized as supporting equal opportunity in \"space\" and \"time\": the first by\nregularly distributing new money equally to all participants much like a basic\nincome, the second by holding the aggregate value of these distributions to a\nconstant and non-diminishing portion of total money supply through demurrage.\nThrough preliminary economic analysis, we find that these rules in combination\nyield a unique form of money with numerous intriguing and promising properties,\nsuch as a quantifiable and provable upper bound on monetary inequality, a\nnatural \"early adopter's reward\" that could incentivize rapid growth while\ntapering off as participation saturates, resistance to the risk of deflationary\nspirals, and migration incentives opposite those created by conventional basic\nincomes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 13:57:22 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Zhang", "Haoqian", ""], ["Basescu", "Cristina", ""], ["Ford", "Bryan", ""]]}, {"id": "2011.01725", "submitter": "Vincent Valton PhD", "authors": "Vincent Valton, Toby Wise, Oliver J. Robinson", "title": "Recommendations for Bayesian hierarchical model specifications for\n  case-control studies in mental health", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical model fitting has become commonplace for case-control studies of\ncognition and behaviour in mental health. However, these techniques require us\nto formalise assumptions about the data-generating process at the group level,\nwhich may not be known. Specifically, researchers typically must choose whether\nto assume all subjects are drawn from a common population, or to model them as\nderiving from separate populations. These assumptions have profound\nimplications for computational psychiatry, as they affect the resulting\ninference (latent parameter recovery) and may conflate or mask true group-level\ndifferences. To test these assumptions we ran systematic simulations on\nsynthetic multi-group behavioural data from a commonly used multi-armed bandit\ntask (reinforcement learning task). We then examined recovery of group\ndifferences in latent parameter space under the two commonly used generative\nmodelling assumptions: (1) modelling groups under a common shared group-level\nprior (assuming all participants are generated from a common distribution, and\nare likely to share common characteristics); (2) modelling separate groups\nbased on symptomatology or diagnostic labels, resulting in separate group-level\npriors. We evaluated the robustness of these approaches to variations in data\nquality and prior specifications on a variety of metrics. We found that fitting\ngroups separately (assumptions 2), provided the most accurate and robust\ninference across all conditions. Our results suggest that when dealing with\ndata from multiple clinical groups, researchers should analyse patient and\ncontrol groups separately as it provides the most accurate and robust recovery\nof the parameters of interest.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:19:59 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Valton", "Vincent", ""], ["Wise", "Toby", ""], ["Robinson", "Oliver J.", ""]]}, {"id": "2011.02045", "submitter": "Kiran Raja Dr", "authors": "Sushma Venkatesh, Raghavendra Ramachandra, Kiran Raja, Christoph Busch", "title": "Face Morphing Attack Generation & Detection: A Comprehensive Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The vulnerability of Face Recognition System (FRS) to various kind of attacks\n(both direct and in-direct attacks) and face morphing attacks has received a\ngreat interest from the biometric community. The goal of a morphing attack is\nto subvert the FRS at Automatic Border Control (ABC) gates by presenting the\nElectronic Machine Readable Travel Document (eMRTD) or e-passport that is\nobtained based on the morphed face image. Since the application process for the\ne-passport in the majority countries requires a passport photo to be presented\nby the applicant, a malicious actor and the accomplice can generate the morphed\nface image and to obtain the e-passport. An e-passport with a morphed face\nimages can be used by both the malicious actor and the accomplice to cross the\nborder as the morphed face image can be verified against both of them. This can\nresult in a significant threat as a malicious actor can cross the border\nwithout revealing the track of his/her criminal background while the details of\naccomplice are recorded in the log of the access control system. This survey\naims to present a systematic overview of the progress made in the area of face\nmorphing in terms of both morph generation and morph detection. In this paper,\nwe describe and illustrate various aspects of face morphing attacks, including\ndifferent techniques for generating morphed face images but also the\nstate-of-the-art regarding Morph Attack Detection (MAD) algorithms based on a\nstringent taxonomy and finally the availability of public databases, which\nallow to benchmark new MAD algorithms in a reproducible manner. The outcomes of\ncompetitions/benchmarking, vulnerability assessments and performance evaluation\nmetrics are also provided in a comprehensive manner. Furthermore, we discuss\nthe open challenges and potential future works that need to be addressed in\nthis evolving field of biometrics.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 22:36:27 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Venkatesh", "Sushma", ""], ["Ramachandra", "Raghavendra", ""], ["Raja", "Kiran", ""], ["Busch", "Christoph", ""]]}, {"id": "2011.02079", "submitter": "Corinna Hertweck", "authors": "Corinna Hertweck and Christoph Heitz and Michele Loi", "title": "On the Moral Justification of Statistical Parity", "comments": "11 pages, accepted to ACM FAccT 2021", "journal-ref": null, "doi": "10.1145/3442188.3445936", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial but often neglected aspect of algorithmic fairness is the question\nof how we justify enforcing a certain fairness metric from a moral perspective.\nWhen fairness metrics are proposed, they are typically argued for by\nhighlighting their mathematical properties. Rarely are the moral assumptions\nbeneath the metric explained. Our aim in this paper is to consider the moral\naspects associated with the statistical fairness criterion of independence\n(statistical parity). To this end, we consider previous work, which discusses\nthe two worldviews \"What You See Is What You Get\" (WYSIWYG) and \"We're All\nEqual\" (WAE) and by doing so provides some guidance for clarifying the possible\nassumptions in the design of algorithms. We present an extension of this work,\nwhich centers on morality. The most natural moral extension is that\nindependence needs to be fulfilled if and only if differences in predictive\nfeatures (e.g. high school grades and standardized test scores are predictive\nof performance at university) between socio-demographic groups are caused by\nunjust social disparities or measurement errors. Through two counterexamples,\nwe demonstrate that this extension is not universally true. This means that the\nquestion of whether independence should be used or not cannot be satisfactorily\nanswered by only considering the justness of differences in the predictive\nfeatures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 00:26:15 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 12:39:36 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Hertweck", "Corinna", ""], ["Heitz", "Christoph", ""], ["Loi", "Michele", ""]]}, {"id": "2011.02100", "submitter": "Lin Meng", "authors": "Zhiwei Liu, Lin Meng, Fei Jiang, Jiawei Zhang, Philip S. Yu", "title": "Deoscillated Graph Collaborative Filtering", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative Filtering (CF) signals are crucial for a Recommender\nSystem~(RS) model to learn user and item embeddings. High-order information can\nalleviate the cold-start issue of CF-based methods, which is modelled through\npropagating the information over the user-item bipartite graph. Recent Graph\nNeural Networks~(GNNs) propose to stack multiple aggregation layers to\npropagate high-order signals. However, the oscillation problem, varying\nlocality of bipartite graph, and the fix propagation pattern spoil the ability\nof multi-layer structure to propagate information. The oscillation problem\nresults from the bipartite structure, as the information from users only\npropagates to items. Besides oscillation problem, varying locality suggests the\ndensity of nodes should be considered in the propagation process. Moreover, the\nlayer-fixed propagation pattern introduces redundant information between\nlayers. In order to tackle these problems, we propose a new RS model, named as\n\\textbf{D}eoscillated \\textbf{G}raph \\textbf{C}ollaborative\n\\textbf{F}iltering~(DGCF). We introduce cross-hop propagation layers in it to\nbreak the bipartite propagating structure, thus resolving the oscillation\nproblem. Additionally, we design innovative locality-adaptive layers which\nadaptively propagate information. Stacking multiple cross-hop propagation\nlayers and locality layers constitutes the DGCF model, which models high-order\nCF signals adaptively to the locality of nodes and layers. Extensive\nexperiments on real-world datasets show the effectiveness of DGCF. Detailed\nanalyses indicate that DGCF solves oscillation problem, adaptively learns local\nfactor, and has layer-wise propagation pattern. Our code is available online at\nhttps://github.com/JimLiu96/DeosciRec.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 02:26:53 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 19:30:24 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Liu", "Zhiwei", ""], ["Meng", "Lin", ""], ["Jiang", "Fei", ""], ["Zhang", "Jiawei", ""], ["Yu", "Philip S.", ""]]}, {"id": "2011.02142", "submitter": "Benjamin Rubinstein", "authors": "Chris Culnane, Benjamin I. P. Rubinstein, David Watts", "title": "Not fit for Purpose: A critical analysis of the 'Five Safes'", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adopted by government agencies in Australia, New Zealand and the UK as policy\ninstrument or as embodied into legislation, the 'Five Safes' framework aims to\nmanage risks of releasing data derived from personal information. Despite its\npopularity, the Five Safes has undergone little legal or technical critical\nanalysis. We argue that the Fives Safes is fundamentally flawed: from being\ndisconnected from existing legal protections and appropriation of notions of\nsafety without providing any means to prefer strong technical measures, to\nviewing disclosure risk as static through time and not requiring repeat\nassessment. The Five Safes provides little confidence that resulting data\nsharing is performed using 'safety' best practice or for purposes in service of\npublic interest.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 05:41:45 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Culnane", "Chris", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Watts", "David", ""]]}, {"id": "2011.02151", "submitter": "Kwadwo Opong-Mensah", "authors": "Kwadwo Opong-Mensah", "title": "Simulation of Human and Artificial Emotion (SHArE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework for Simulation of Human and Artificial Emotion (SHArE)\ndescribes the architecture of emotion in terms of parameters transferable\nbetween psychology, neuroscience, and artificial intelligence. These parameters\ncan be defined as abstract concepts or granularized down to the voltage levels\nof individual neurons. This model enables emotional trajectory design for\nhumans which may lead to novel therapeutic solutions for various mental health\nconcerns. For artificial intelligence, this work provides a compact notation\nwhich can be applied to neural networks as a means to observe the emotions and\nmotivations of machines.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 06:45:30 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Opong-Mensah", "Kwadwo", ""]]}, {"id": "2011.02272", "submitter": "Mayank Vatsa", "authors": "Richa Singh, Mayank Vatsa, Nalini Ratha", "title": "Trustworthy AI", "comments": "ACM CODS-COMAD 2021 Tutorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern AI systems are reaping the advantage of novel learning methods. With\ntheir increasing usage, we are realizing the limitations and shortfalls of\nthese systems. Brittleness to minor adversarial changes in the input data,\nability to explain the decisions, address the bias in their training data, high\nopacity in terms of revealing the lineage of the system, how they were trained\nand tested, and under which parameters and conditions they can reliably\nguarantee a certain level of performance, are some of the most prominent\nlimitations. Ensuring the privacy and security of the data, assigning\nappropriate credits to data sources, and delivering decent outputs are also\nrequired features of an AI system. We propose the tutorial on Trustworthy AI to\naddress six critical issues in enhancing user and public trust in AI systems,\nnamely: (i) bias and fairness, (ii) explainability, (iii) robust mitigation of\nadversarial attacks, (iv) improved privacy and security in model building, (v)\nbeing decent, and (vi) model attribution, including the right level of credit\nassignment to the data sources, model architectures, and transparency in\nlineage.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 20:04:18 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Singh", "Richa", ""], ["Vatsa", "Mayank", ""], ["Ratha", "Nalini", ""]]}, {"id": "2011.02273", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela and Maria Perez-Ortiz and Emine Yilmaz and John\n  Shawe-Taylor", "title": "VLEngagement: A Dataset of Scientific Video Lectures for Evaluating\n  Population-based Engagement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the emergence of e-learning and personalised education, the production\nand distribution of digital educational resources have boomed. Video lectures\nhave now become one of the primary modalities to impart knowledge to masses in\nthe current digital age. The rapid creation of video lecture content challenges\nthe currently established human-centred moderation and quality assurance\npipeline, demanding for more efficient, scalable and automatic solutions for\nmanaging learning resources. Although a few datasets related to engagement with\neducational videos exist, there is still an important need for data and\nresearch aimed at understanding learner engagement with scientific video\nlectures. This paper introduces VLEngagement, a novel dataset that consists of\ncontent-based and video-specific features extracted from publicly available\nscientific video lectures and several metrics related to user engagement. We\nintroduce several novel tasks related to predicting and understanding\ncontext-agnostic engagement in video lectures, providing preliminary baselines.\nThis is the largest and most diverse publicly available dataset to our\nknowledge that deals with such tasks. The extraction of Wikipedia topic-based\nfeatures also allows associating more sophisticated Wikipedia based features to\nthe dataset to improve the performance in these tasks. The dataset, helper\ntools and example code snippets are available publicly at\nhttps://github.com/sahanbull/context-agnostic-engagement\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 14:20:19 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Bulathwela", "Sahan", ""], ["Perez-Ortiz", "Maria", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "2011.02277", "submitter": "Subasish Das", "authors": "Subasish Das", "title": "Ridesharing Services and Car-Seats: Technological Perceptions and Usage\n  Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Children are one of the most vulnerable groups in traffic crashes. Child\nsafety seats (CSSs) can decrease the severity of crash outcomes for children.\nThe usage of CSSs has significantly improved in the U.S. over the last 40\nyears, but it is anticipated that the usage of CSSs in popular ridesharing\nservices (RSSs), such as Uber and Lyft, is not widespread. This paper used a\npublicly available nationwide internet survey that was designed to gain an\nunderstanding of riders and drivers perception toward child passenger safety in\nregard to technological perception on RSSs. This study performed a rigorous\nexploratory data analysis to identify the key psychological insights of the\nsurvey participants. Additionally, a recently developed dimension-reduction\nmethod has been applied to understand the co-occurrence patterns of the\nresponses to gain intuitive insights. It is found that urban-dwelling parents\nwith higher education degrees eventually use RSSs often due to their\nfamiliarity of the technological advantages. On the other hand, non-urban and\nmoderately educated parents and guardians are dismissive in using RSSs while\nhaving kids with them to ride due to less trust on the technology.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 06:52:33 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Das", "Subasish", ""]]}, {"id": "2011.02279", "submitter": "Daniel Estrada", "authors": "Daniel Estrada", "title": "Ideal theory in AI ethics", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the ways AI ethics research operates on an ideology of\nideal theory, in the sense discussed by Mills (2005) and recently applied to AI\nethics by Fazelpour \\& Lipton (2020). I address the structural and\nmethodological conditions that attract AI ethics researchers to ideal\ntheorizing, and the consequences this approach has for the quality and future\nof our research community. Finally, I discuss the possibilities for a nonideal\nfuture in AI ethics.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 18:49:39 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 04:36:05 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Estrada", "Daniel", ""]]}, {"id": "2011.02282", "submitter": "McKane Andrus", "authors": "McKane Andrus, Elena Spitzer, Jeffrey Brown, Alice Xiang", "title": "\"What We Can't Measure, We Can't Understand\": Challenges to Demographic\n  Data Procurement in the Pursuit of Fairness", "comments": "13 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As calls for fair and unbiased algorithmic systems increase, so too does the\nnumber of individuals working on algorithmic fairness in industry. However,\nthese practitioners often do not have access to the demographic data they feel\nthey need to detect bias in practice. Even with the growing variety of toolkits\nand strategies for working towards algorithmic fairness, they almost invariably\nrequire access to demographic attributes or proxies. We investigated this\ndilemma through semi-structured interviews with 38 practitioners and\nprofessionals either working in or adjacent to algorithmic fairness.\nParticipants painted a complex picture of what demographic data availability\nand use look like on the ground, ranging from not having access to personal\ndata of any kind to being legally required to collect and use demographic data\nfor discrimination assessments. In many domains, demographic data collection\nraises a host of difficult questions, including how to balance privacy and\nfairness, how to define relevant social categories, how to ensure meaningful\nconsent, and whether it is appropriate for private companies to infer someone's\ndemographics. Our research suggests challenges that must be considered by\nbusinesses, regulators, researchers, and community groups in order to enable\npractitioners to address algorithmic bias in practice. Critically, we do not\npropose that the overall goal of future work should be to simply lower the\nbarriers to collecting demographic data. Rather, our study surfaces a swath of\nnormative questions about how, when, and whether this data should be procured,\nand, in cases where it is not, what should still be done to mitigate bias.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 21:06:41 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2021 01:18:19 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Andrus", "McKane", ""], ["Spitzer", "Elena", ""], ["Brown", "Jeffrey", ""], ["Xiang", "Alice", ""]]}, {"id": "2011.02284", "submitter": "Lena Maier-Hein", "authors": "Lena Maier-Hein, Matthias Eisenmann, Duygu Sarikaya, Keno M\\\"arz, Toby\n  Collins, Anand Malpani, Johannes Fallert, Hubertus Feussner, Stamatia\n  Giannarou, Pietro Mascagni, Hirenkumar Nakawala, Adrian Park, Carla Pugh,\n  Danail Stoyanov, Swaroop S. Vedula, Beat Peter M\\\"uller, Kevin Cleary, Gabor\n  Fichtinger, Germain Forestier, Bernard Gibaud, Teodor Grantcharov, Makoto\n  Hashizume, Hannes Kenngott, Ron Kikinis, Lars M\\\"undermann, Nassir Navab,\n  Sinan Onogur, Raphael Sznitman, Russell Taylor, Minu Dietlinde Tizabi, Martin\n  Wagner, Gregory D. Hager, Thomas Neumuth, Nicolas Padoy, Pierre Jannin,\n  Stefanie Speidel", "title": "Surgical Data Science -- from Concepts to Clinical Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent developments in data science in general and machine learning in\nparticular have transformed the way experts envision the future of surgery.\nSurgical data science is a new research field that aims to improve the quality\nof interventional healthcare through the capture, organization, analysis and\nmodeling of data. While an increasing number of data-driven approaches and\nclinical applications have been studied in the fields of radiological and\nclinical data science, translational success stories are still lacking in\nsurgery. In this publication, we shed light on the underlying reasons and\nprovide a roadmap for future advances in the field. Based on an international\nworkshop involving leading researchers in the field of surgical data science,\nwe review current practice, key achievements and initiatives as well as\navailable standards and tools for a number of topics relevant to the field,\nnamely (1) technical infrastructure for data acquisition, storage and access in\nthe presence of regulatory constraints, (2) data annotation and sharing and (3)\ndata analytics. Drawing from this extensive review, we present current\nchallenges for technology development and (4) describe a roadmap for faster\nclinical translation and exploitation of the full potential of surgical data\nscience.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 14:20:16 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Maier-Hein", "Lena", ""], ["Eisenmann", "Matthias", ""], ["Sarikaya", "Duygu", ""], ["M\u00e4rz", "Keno", ""], ["Collins", "Toby", ""], ["Malpani", "Anand", ""], ["Fallert", "Johannes", ""], ["Feussner", "Hubertus", ""], ["Giannarou", "Stamatia", ""], ["Mascagni", "Pietro", ""], ["Nakawala", "Hirenkumar", ""], ["Park", "Adrian", ""], ["Pugh", "Carla", ""], ["Stoyanov", "Danail", ""], ["Vedula", "Swaroop S.", ""], ["M\u00fcller", "Beat Peter", ""], ["Cleary", "Kevin", ""], ["Fichtinger", "Gabor", ""], ["Forestier", "Germain", ""], ["Gibaud", "Bernard", ""], ["Grantcharov", "Teodor", ""], ["Hashizume", "Makoto", ""], ["Kenngott", "Hannes", ""], ["Kikinis", "Ron", ""], ["M\u00fcndermann", "Lars", ""], ["Navab", "Nassir", ""], ["Onogur", "Sinan", ""], ["Sznitman", "Raphael", ""], ["Taylor", "Russell", ""], ["Tizabi", "Minu Dietlinde", ""], ["Wagner", "Martin", ""], ["Hager", "Gregory D.", ""], ["Neumuth", "Thomas", ""], ["Padoy", "Nicolas", ""], ["Jannin", "Pierre", ""], ["Speidel", "Stefanie", ""]]}, {"id": "2011.02285", "submitter": "Panagiotis Filntisis", "authors": "Panagiotis P. Filntisis, Athanasia Zlatintsi, Niki Efthymiou,\n  Emmanouil Kalisperakis, Thomas Karantinos, Marina Lazaridi, Nikolaos Smyrnis,\n  Petros Maragos", "title": "Identifying differences in physical activity and autonomic function\n  patterns between psychotic patients and controls over a long period of\n  continuous monitoring using wearable sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital phenotyping is a nascent multidisciplinary field that has the\npotential to revolutionize psychiatry and its clinical practice. In this paper,\nwe present a rigorous statistical analysis of short-time features extracted\nfrom wearable data, during long-term continuous monitoring of patients with\npsychotic disorders and healthy control counterparts. Our novel analysis\nidentifies features that fluctuate significantly between the two groups, and\noffers insights on several factors that differentiate them, which could be\nleveraged in the future for relapse prevention and individualized assistance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 03:44:29 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Filntisis", "Panagiotis P.", ""], ["Zlatintsi", "Athanasia", ""], ["Efthymiou", "Niki", ""], ["Kalisperakis", "Emmanouil", ""], ["Karantinos", "Thomas", ""], ["Lazaridi", "Marina", ""], ["Smyrnis", "Nikolaos", ""], ["Maragos", "Petros", ""]]}, {"id": "2011.02286", "submitter": "Enzo Rucci", "authors": "Enzo Rucci and Lisandro Delia and Joaqu\\'in Pujol and Paula Erbino and\n  Armando De Giusti and Juan Jos\\'e Gagliardino", "title": "Diabetes Link: Platform for Self-Control and Monitoring People with\n  Diabetes", "comments": "This article was accepted for publicatin on Third International\n  Conference on Applied Informatics - ICAI 2020 (icai.itiud.org)", "journal-ref": null, "doi": "10.1007/978-3-030-61702-8_25", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Diabetes Mellitus (DM) is a chronic disease characterized by an increase in\nblood glucose (sugar) above normal levels and it appears when human body is not\nable to produce enough insulin to cover the peripheral tissue demand. Nowadays,\nDM affects the 8.5% of the world's population and, even though no cure for it\nhas been found, an adequate monitoring and treatment allow patients to have an\nalmost normal life. This paper introduces Diabetes Link, a comprehensive\nplatform for control and monitoring people with DM. Diabetes Link allows\nrecording various parameters relevant for the treatment and calculating\ndifferent statistical charts using them. In addition, it allows connecting with\nother users (supervisors) so they can monitor the controls. Even more, the\nextensive comparative study carried out reflects that Diabetes Link presents\ndistinctive and superior features against other proposals. We conclude that\nDiabetes Link represents a broad and accessible tool that can help make\nday-to-day control easier and optimize the efficacy in DM control and\ntreatment.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 19:59:27 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Rucci", "Enzo", ""], ["Delia", "Lisandro", ""], ["Pujol", "Joaqu\u00edn", ""], ["Erbino", "Paula", ""], ["De Giusti", "Armando", ""], ["Gagliardino", "Juan Jos\u00e9", ""]]}, {"id": "2011.02287", "submitter": "Wei Xie", "authors": "Hua Zheng, Ilya O. Ryzhov, Wei Xie, and Judy Zhong", "title": "Personalized Multimorbidity Management for Patients with Type 2 Diabetes\n  Using Reinforcement Learning of Electronic Health Records", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Comorbid chronic conditions are common among people with type 2 diabetes. We\ndeveloped an Artificial Intelligence algorithm, based on Reinforcement Learning\n(RL), for personalized diabetes and multi-morbidity management with strong\npotential to improve health outcomes relative to current clinical practice. In\nthis paper, we modeled glycemia, blood pressure and cardiovascular disease\n(CVD) risk as health outcomes using a retrospective cohort of 16,665 patients\nwith type 2 diabetes from New York University Langone Health ambulatory care\nelectronic health records in 2009 to 2017. We trained a RL prescription\nalgorithm that recommends a treatment regimen optimizing patients' cumulative\nhealth outcomes using their individual characteristics and medical history at\neach encounter. The RL recommendations were evaluated on an independent subset\nof patients. The results demonstrate that the proposed personalized\nreinforcement learning prescriptive framework for type 2 diabetes yielded high\nconcordance with clinicians' prescriptions and substantial improvements in\nglycemia, blood pressure, cardiovascular disease risk outcomes.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 00:58:27 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zheng", "Hua", ""], ["Ryzhov", "Ilya O.", ""], ["Xie", "Wei", ""], ["Zhong", "Judy", ""]]}, {"id": "2011.02359", "submitter": "ASM Iftekhar Anam", "authors": "Md. Aktaruzzaman Pramanik, Md Mahbubur Rahman, ASM Iftekhar Anam, Amin\n  Ahsan Ali, M Ashraful Amin, and A K M Mahbubur Rahman", "title": "Modeling Traffic Congestion in Developing Countries using Google Maps\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic congestion research is on the rise, thanks to urbanization, economic\ngrowth, and industrialization. Developed countries invest a lot of research\nmoney in collecting traffic data using Radio Frequency Identification (RFID),\nloop detectors, speed sensors, high-end traffic light, and GPS. However, these\nprocesses are expensive, infeasible, and non-scalable for developing countries\nwith numerous non-motorized vehicles, proliferated ride-sharing services, and\nfrequent pedestrians. This paper proposes a novel approach to collect traffic\ndata from Google Map's traffic layer with minimal cost. We have implemented\nwidely used models such as Historical Averages (HA), Support Vector Regression\n(SVR), Support Vector Regression with Graph (SVR-Graph), Auto-Regressive\nIntegrated Moving Average (ARIMA) to show the efficacy of the collected traffic\ndata in forecasting future congestion. We show that even with these simple\nmodels, we could predict the traffic congestion ahead of time. We also\ndemonstrate that the traffic patterns are significantly different between\nweekdays and weekends.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 13:46:34 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Pramanik", "Md. Aktaruzzaman", ""], ["Rahman", "Md Mahbubur", ""], ["Anam", "ASM Iftekhar", ""], ["Ali", "Amin Ahsan", ""], ["Amin", "M Ashraful", ""], ["Rahman", "A K M Mahbubur", ""]]}, {"id": "2011.02407", "submitter": "Jiahao Chen", "authors": "Ashrya Agrawal and Florian Pfisterer and Bernd Bischl and Francois\n  Buet-Golfouse and Srijan Sood and Jiahao Chen and Sameena Shah and Sebastian\n  Vollmer", "title": "Debiasing classifiers: is reality at variance with expectation?", "comments": "13 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical study of debiasing methods for classifiers, showing\nthat debiasers often fail in practice to generalize out-of-sample, and can in\nfact make fairness worse rather than better. A rigorous evaluation of the\ndebiasing treatment effect requires extensive cross-validation beyond what is\nusually done. We demonstrate that this phenomenon can be explained as a\nconsequence of bias-variance trade-off, with an increase in variance\nnecessitated by imposing a fairness constraint. Follow-up experiments validate\nthe theoretical prediction that the estimation variance depends strongly on the\nbase rates of the protected class. Considering fairness--performance trade-offs\njustifies the counterintuitive notion that partial debiasing can actually yield\nbetter results in practice on out-of-sample data.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:00:54 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 00:06:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Agrawal", "Ashrya", ""], ["Pfisterer", "Florian", ""], ["Bischl", "Bernd", ""], ["Buet-Golfouse", "Francois", ""], ["Sood", "Srijan", ""], ["Chen", "Jiahao", ""], ["Shah", "Sameena", ""], ["Vollmer", "Sebastian", ""]]}, {"id": "2011.02412", "submitter": "Bryan Ford", "authors": "Bryan Ford", "title": "Identity and Personhood in Digital Democracy: Evaluating Inclusion,\n  Equality, Security, and Privacy in Pseudonym Parties and Other Proofs of\n  Personhood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital identity seems like a prerequisite for digital democracy: how can we\nensure \"one person, one vote\" online without identifying voters? But digital\nidentity solutions - ID checking, biometrics, self-sovereign identity, and\ntrust networks - all present flaws, leaving users vulnerable to exclusion,\nidentity loss or theft, and coercion. These flaws may be insurmountable because\ndigital identity is a cart pulling the horse. We cannot achieve digital\nidentity secure enough for the weight of digital democracy, until we build it\non a solid foundation of \"digital personhood.\" While identity is about\ndistinguishing one person from another through attributes or affiliations,\npersonhood is about giving all real people inalienable digital participation\nrights independent of identity, including protection against erosion of their\ndemocratic rights through identity loss, theft, coercion, or fakery.\n  We explore and analyze alternative approaches to \"proof of personhood\" that\nmay provide this missing foundation. Pseudonym parties marry the transparency\nof periodic physical-world events with the power of digital tokens between\nevents. These tokens represent limited-term but renewable claims usable for\npurposes such as online voting or liquid democracy, sampled juries or\ndeliberative polls, abuse-resistant social communication, or minting universal\nbasic income in a permissionless cryptocurrency. Enhancing pseudonym parties to\nprovide participants a moment of enforced physical security and privacy can\naddress coercion and vote-buying risks that plague today's E-voting systems. We\nalso examine other proposed approaches to proof of personhood, some of which\noffer conveniences such as all-online participation. These alternatives\ncurrently fall short of satisfying all the key digital personhood goals,\nunfortunately, but offer valuable insights into the challenges we face.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 17:08:54 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Ford", "Bryan", ""]]}, {"id": "2011.02612", "submitter": "Da Zhang", "authors": "Shize Qin, Lena Klaa{\\ss}en, Ulrich Gallersd\\\"orfer, Christian Stoll,\n  Da Zhang", "title": "Bitcoin's future carbon footprint", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The carbon footprint of Bitcoin has drawn wide attention, but Bitcoin's\nlong-term impact on the climate remains uncertain. Here we present a framework\nto overcome uncertainties in previous estimates and project Bitcoin's\nelectricity consumption and carbon footprint in the long term. If we assume\nBitcoin's market capitalization grows in line with the one of gold, we find\nthat the annual electricity consumption of Bitcoin may increase from 60 to 400\nTWh between 2020 and 2100. The future carbon footprint of Bitcoin strongly\ndepends on the decarbonization pathway of the electricity sector. If the\nelectricity sector achieves carbon neutrality by 2050, Bitcoin's carbon\nfootprint has peaked already. However, in the business-as-usual scenario,\nemissions sum up to 2 gigatons until 2100, an amount comparable to 7% of global\nemissions in 2019. The Bitcoin price spike at the end of 2020 shows, however,\nthat progressive development of market capitalization could yield an\nelectricity consumption of more than 100 TWh already in 2021, and lead to\ncumulative emissions of over 5 gigatons by 2100. Therefore, we also discuss\npolicy instruments to reduce Bitcoin's future carbon footprint.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 01:58:16 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 06:12:37 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Qin", "Shize", ""], ["Klaa\u00dfen", "Lena", ""], ["Gallersd\u00f6rfer", "Ulrich", ""], ["Stoll", "Christian", ""], ["Zhang", "Da", ""]]}, {"id": "2011.02773", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (Montreal AI Ethics Institute and Microsoft)", "title": "The Gray Rhino of Pandemic Preparedness: Proactive digital, data, and\n  organizational infrastructure to help humanity build resilience in the face\n  of pandemics", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID-19 has exposed glaring holes in our existing digital, data, and\norganizational practices. Researchers ensconced in epidemiological and human\nhealth work have repeatedly pointed out how urban encroachment, climate change,\nand other human-triggered activities and patterns are going to make zoonotic\npandemics more frequent and commonplace. The Gray Rhino mindset provides a\nuseful reframing (as opposed to viewing pandemics such as the current one as a\nBlack Swan event) that can help us recover faster from these (increasingly)\nfrequent occurrences and build resiliency in our digital, data, and\norganizational infrastructure. Mitigating the social and economic impacts of\npandemics can be eased through building infrastructure that elucidate leading\nindicators via passive intelligence gathering so that responses to containing\nthe spread of pandemics are not blanket measures; instead, they can be\nfine-grained allowing for more efficient utilization of scarce resources and\nminimizing disruption to our way of life.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 11:55:42 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gupta", "Abhishek", "", "Montreal AI Ethics Institute and Microsoft"]]}, {"id": "2011.02787", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Alexandrine Royer (1 and 3), Victoria Heath\n  (1 and 4), Connor Wright (1 and 5), Camylle Lanteigne (1, 6, and 7), Allison\n  Cohen (1, 8, and 9), Marianna Bergamaschi Ganapini (1 and 10), Muriam Fancy\n  (1, 11, and 12), Erick Galinkin (1 and 13), Ryan Khurana (1), Mo Akif (1),\n  Renjie Butalid (1), Falaah Arif Khan (1, 14, and 15), Masa Sweidan (1 and\n  16), Audrey Balogh (1 and 16) ((1) Montreal AI Ethics Institute, (2)\n  Microsoft, (3) University of Cambridge, (4) Creative Commons, (5) University\n  of Exeter, (6) Concordia University, (7) Algora Lab, (8) AI Global, (9) Mila,\n  (10) Union College, (11) University of Toronto, (12) University of Ottawa,\n  (13) Rapid7, (14) NYU Center for Responsible AI, (15) IIIT Hyderabad, (16)\n  McGill University)", "title": "The State of AI Ethics Report (October 2020)", "comments": "158 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in the field of AI Ethics since July\n2020. This report aims to help anyone, from machine learning experts to human\nrights activists and policymakers, quickly digest and understand the\never-changing developments in the field. Through research and article\nsummaries, as well as expert commentary, this report distills the research and\nreporting surrounding various domains related to the ethics of AI, including:\nAI and society, bias and algorithmic justice, disinformation, humans and AI,\nlabor impacts, privacy, risk, and future of AI ethics.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. These experts include: Danit Gal (Tech\nAdvisor, United Nations), Amba Kak (Director of Global Policy and Programs,\nNYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI,\nAccenture), Brent Barron (Director of Strategic Projects and Knowledge\nManagement, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of\nthe OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of\nManagement), and Katya Klinova (AI and Economy Program Lead, Partnership on\nAI).\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 12:36:16 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Royer", "Alexandrine", "", "1 and 3"], ["Heath", "Victoria", "", "1 and 4"], ["Wright", "Connor", "", "1 and 5"], ["Lanteigne", "Camylle", "", "1, 6, and 7"], ["Cohen", "Allison", "", "1, 8, and 9"], ["Ganapini", "Marianna Bergamaschi", "", "1 and 10"], ["Fancy", "Muriam", "", "1, 11, and 12"], ["Galinkin", "Erick", "", "1 and 13"], ["Khurana", "Ryan", "", "1, 14, and 15"], ["Akif", "Mo", "", "1, 14, and 15"], ["Butalid", "Renjie", "", "1, 14, and 15"], ["Khan", "Falaah Arif", "", "1, 14, and 15"], ["Sweidan", "Masa", "", "1 and\n  16"], ["Balogh", "Audrey", "", "1 and 16"]]}, {"id": "2011.02839", "submitter": "Udit Gupta", "authors": "Udit Gupta, Young Geun Kim, Sylvia Lee, Jordan Tse, Hsien-Hsin S. Lee,\n  Gu-Yeon Wei, David Brooks, Carole-Jean Wu", "title": "Chasing Carbon: The Elusive Environmental Footprint of Computing", "comments": "To appear in IEEE International Symposium on High-Performance\n  Computer Architecture (HPCA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given recent algorithm, software, and hardware innovation, computing has\nenabled a plethora of new applications. As computing becomes increasingly\nubiquitous, however, so does its environmental impact. This paper brings the\nissue to the attention of computer-systems researchers. Our analysis, built on\nindustry-reported characterization, quantifies the environmental effects of\ncomputing in terms of carbon emissions. Broadly, carbon emissions have two\nsources: operational energy consumption, and hardware manufacturing and\ninfrastructure. Although carbon emissions from the former are decreasing thanks\nto algorithmic, software, and hardware innovations that boost performance and\npower efficiency, the overall carbon footprint of computer systems continues to\ngrow. This work quantifies the carbon output of computer systems to show that\nmost emissions related to modern mobile and data-center equipment come from\nhardware manufacturing and infrastructure. We therefore outline future\ndirections for minimizing the environmental impact of computing systems.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 18:15:22 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Gupta", "Udit", ""], ["Kim", "Young Geun", ""], ["Lee", "Sylvia", ""], ["Tse", "Jordan", ""], ["Lee", "Hsien-Hsin S.", ""], ["Wei", "Gu-Yeon", ""], ["Brooks", "David", ""], ["Wu", "Carole-Jean", ""]]}, {"id": "2011.02883", "submitter": "Yan Huang Dr.", "authors": "Junjie Pang, Jianbo Li, Zhenzhen Xie, Yan Huang, Zhipeng Cai", "title": "Collaborative City Digital Twin For Covid-19 Pandemic: A Federated\n  Learning Solution", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a collaborative city digital twin based on FL, a\nnovel paradigm that allowing multiple city DT to share the local strategy and\nstatus in a timely manner. In particular, an FL central server manages the\nlocal updates of multiple collaborators (city DT), provides a global model\nwhich is trained in multiple iterations at different city DT systems, until the\nmodel gains the correlations between various response plan and infection trend.\nThat means, a collaborative city DT paradigm based on FL techniques can obtain\nknowledge and patterns from multiple DTs, and eventually establish a `global\nview' for city crisis management. Meanwhile, it also helps to improve each city\ndigital twin selves by consolidating other DT's respective data without\nviolating privacy rules. To validate the proposed solution, we take COVID-19\npandemic as a case study. The experimental results on the real dataset with\nvarious response plan validate our proposed solution and demonstrate the\nsuperior performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 15:20:31 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pang", "Junjie", ""], ["Li", "Jianbo", ""], ["Xie", "Zhenzhen", ""], ["Huang", "Yan", ""], ["Cai", "Zhipeng", ""]]}, {"id": "2011.02933", "submitter": "Abdallah Namoun", "authors": "Abdallah Namoun and Ahmad B. Alkhodre", "title": "Towards Usability Guidelines for the Design of Effective Arabic\n  Websites: Design Practices and Lessons Focusing on Font and Image usage", "comments": "10 pages, 17 figures, 2 tables, journal", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications(IJACSA), 10(4), (2019), 585-594", "doi": "10.14569/IJACSA.2019.0100472", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Arabic websites constitute 1% of the web content with more than 225\nmillion viewers and 41% Internet penetration. However, there is a lack of\ndesign guidelines related to the selection and use of appropriate font type and\nsize and images in Arabic websites. Both text and images are vital multimedia\ncomponents of websites and thereby were selected for investigation in this\nstudy. The herein paper performed an indepth inspection of font and image\ndesign practices within 73 most visited Arabic websites in Saudi Arabia\naccording to Alexa Internet ranking in the first quarter of 2019. Our\nexhaustive analysis showed discrepancies between the international design\nrecommendations and the actual design of Arabic websites. There was a\nconsiderable variation and inconsistency in using font types and sizes between\nand within the Arabic websites. Arabic Droid Kufi was used mostly for styling\npage titles and navigation menus, whilst Tahoma was used for styling\nparagraphs. The font size of the Arabic text ranged from 12 to 16 pixels, which\nmay lead to poor readability. Images were used heavily in the Arabic websites\ncausing prolonged site loading times. Moreover, the images strongly reflected\nthe dimensions of the Saudi culture, especially collectivism and masculinity.\nCurrent Arabic web design practices are compared against the findings from past\nstudies about international designs and lessons aiming at ameliorating the\nArabic web design are inferred.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 15:54:47 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Namoun", "Abdallah", ""], ["Alkhodre", "Ahmad B.", ""]]}, {"id": "2011.02962", "submitter": "Ramesha Karunasena", "authors": "Ramesha Karunasena, Mohammad Sarparajul Ambiya, Arunesh Sinha, Ruchit\n  Nagar, Saachi Dalal, Divy Thakkar, Dhyanesh Narayanan, Milind Tambe", "title": "Measuring Data Collection Diligence for Community Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analytics has tremendous potential to provide targeted benefit in\nlow-resource communities, however the availability of high-quality public\nhealth data is a significant challenge in developing countries primarily due to\nnon-diligent data collection by community health workers (CHWs). In this work,\nwe define and test a data collection diligence score. This challenging\nunlabeled data problem is handled by building upon domain expert's guidance to\ndesign a useful data representation of the raw data, using which we design a\nsimple and natural score. An important aspect of the score is relative scoring\nof the CHWs, which implicitly takes into account the context of the local area.\nThe data is also clustered and interpreting these clusters provides a natural\nexplanation of the past behavior of each data collector. We further predict the\ndiligence score for future time steps. Our framework has been validated on the\nground using observations by the field monitors of our partner NGO in India.\nBeyond the successful field test, our work is in the final stages of deployment\nin the state of Rajasthan, India.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 16:45:03 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 03:51:09 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 10:20:28 GMT"}, {"version": "v4", "created": "Fri, 13 Nov 2020 02:33:28 GMT"}, {"version": "v5", "created": "Wed, 7 Apr 2021 15:16:09 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Karunasena", "Ramesha", ""], ["Ambiya", "Mohammad Sarparajul", ""], ["Sinha", "Arunesh", ""], ["Nagar", "Ruchit", ""], ["Dalal", "Saachi", ""], ["Thakkar", "Divy", ""], ["Narayanan", "Dhyanesh", ""], ["Tambe", "Milind", ""]]}, {"id": "2011.03020", "submitter": "Jiaxin Pei", "authors": "Jiaxin Pei and David Jurgens", "title": "Quantifying Intimacy in Language", "comments": "EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intimacy is a fundamental aspect of how we relate to others in social\nsettings. Language encodes the social information of intimacy through both\ntopics and other more subtle cues (such as linguistic hedging and swearing).\nHere, we introduce a new computational framework for studying expressions of\nthe intimacy in language with an accompanying dataset and deep learning model\nfor accurately predicting the intimacy level of questions (Pearson's r=0.87).\nThrough analyzing a dataset of 80.5M questions across social media, books, and\nfilms, we show that individuals employ interpersonal pragmatic moves in their\nlanguage to align their intimacy with social settings. Then, in three studies,\nwe further demonstrate how individuals modulate their intimacy to match social\nnorms around gender, social distance, and audience, each validating key\nfindings from studies in social psychology. Our work demonstrates that intimacy\nis a pervasive and impactful social dimension of language.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:27:20 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Pei", "Jiaxin", ""], ["Jurgens", "David", ""]]}, {"id": "2011.03044", "submitter": "Gissel Velarde", "authors": "Gissel Velarde", "title": "Artificial Intelligence and its impact on the Fourth Industrial\n  Revolution: A Review", "comments": null, "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA) Vol.10, No.6, November 2019", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence may revolutionize everything during the so-called\nfourth industrial revolution, which carries several emerging technologies and\ncould progress without precedents in human history due to its speed and scope.\nGovernment, academia, industry, and civil society show interest in\nunderstanding the multidimensional impact of the emerging industrial\nrevolution; however, its development is hard to predict. Experts consider\nemerging technologies could bring tremendous benefits to humanity; at the same\ntime, they could pose an existential risk. This paper reviews the development\nand trends in AI, as well as the benefits, risks, and strategies in the field.\nDuring the course of the emerging industrial revolution, the common good may be\nachieved in a collaborative environment of shared interests and the hardest\nwork will be the implementation and monitoring of projects at a global scale.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 15:57:34 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Velarde", "Gissel", ""]]}, {"id": "2011.03116", "submitter": "Danish Contractor", "authors": "Danish Contractor and Daniel McDuff and Julia Haines and Jenny Lee and\n  Christopher Hines and Brent Hecht", "title": "Behavioral Use Licensing for Responsible AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific research and development relies on the sharing of ideas and\nartifacts. With the growing reliance on artificial intelligence (AI) for many\ndifferent applications, the sharing of code, data, and models is important to\nensure the ability to replicate methods and the democratization of scientific\nknowledge. Many high-profile journals and conferences expect code to be\nsubmitted and released with papers. Furthermore, developers often want to\nrelease code and models to encourage development of technology that leverages\ntheir frameworks and services. However, AI algorithms are becoming increasingly\npowerful and generalized. Ultimately, the context in which an algorithm is\napplied can be far removed from that which the developers had intended. A\nnumber of organizations have expressed concerns about inappropriate or\nirresponsible use of AI and have proposed AI ethical guidelines and responsible\nAI initiatives. While such guidelines are useful and help shape policy, they\nare not easily enforceable. Governments have taken note of the risks associated\nwith certain types of AI applications and have passed legislation. While these\nare enforceable, they require prolonged scientific and political deliberation.\n  In this paper we advocate the use of licensing to enable legally enforceable\nbehavioral use conditions on software and data. We argue that licenses serve as\na useful tool for enforcement in situations where it is difficult or\ntime-consuming to legislate AI usage. Furthermore, by using such licenses, AI\ndevelopers provide a signal to the AI community, as well as governmental\nbodies, that they are taking responsibility for their technologies and are\nencouraging responsible use by downstream users.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 09:23:28 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Contractor", "Danish", ""], ["McDuff", "Daniel", ""], ["Haines", "Julia", ""], ["Lee", "Jenny", ""], ["Hines", "Christopher", ""], ["Hecht", "Brent", ""]]}, {"id": "2011.03117", "submitter": "Francesca Noardo", "authors": "Francesca Noardo, Teng Wu, Ken Arroyo Ohori, Thomas Krijnen, Jantien\n  Stoter", "title": "The use of IFC models towards automation of urban planning checks for\n  building permit", "comments": "25 pages, 16 figures, new revised version of the manuscript,\n  re-submitted as a new submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To support building permit issuing with automatic digital tools, the reuse of\nmodels produced by designers would make the process quicker and more objective.\nHowever, current studies and pilots often leave a gap with respect to the\nmodels as actually provided by architects, having varying quality and content.\nIn this study, rather than taking a top down approach, we started from the\navailable data and made the necessary inferences, which gave the opportunity to\ntackle basic and common issues often preventing smooth automatic processing.\nSpecific characteristics of the IFC models were outlined and a tool was\ndeveloped to extract the necessary information from them to check\nrepresentative regulations. While the case study is specific in location,\nregulations and input models, the type of issues encountered are a generally\napplicable example for automated code compliance checking. This represents a\nsolid base for. future works towards the automation of building permits\nissuing.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:29:47 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 11:34:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Noardo", "Francesca", ""], ["Wu", "Teng", ""], ["Ohori", "Ken Arroyo", ""], ["Krijnen", "Thomas", ""], ["Stoter", "Jantien", ""]]}, {"id": "2011.03143", "submitter": "Cleber Rocco Dr.", "authors": "Vitor Bezzan and Cleber D. Rocco", "title": "Predicting special care during the COVID-19 pandemic: A machine learning\n  approach", "comments": "21 pages, 7 Figures, 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than ever COVID-19 is putting pressure on health systems all around the\nworld, especially in Brazil. In this study we propose an analytical approach\nbased on statistics and machine learning that uses lab exam data coming from\npatients to predict whether patients are going to require special care\n(hospitalisation in regular or special-care units). We also predict the number\nof days the patients will stay under such care. The two-step procedure\ndeveloped uses Bayesian Optimisation to select the best model among several\ncandidates leads us to final models that achieve 0.94 area under ROC curve\nperformance for the first target and 1.87 root mean squared error for the\nsecond target (which is a 77% improvement over the mean baseline), making our\nmodel ready to be deployed as a decision system that could be available for\neveryone interested. The analytical approach can be used in other diseases and\ncan help the planning hospital capacity.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 00:18:27 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Bezzan", "Vitor", ""], ["Rocco", "Cleber D.", ""]]}, {"id": "2011.03158", "submitter": "Chenwei Wang", "authors": "Yuan Wang, Chenwei Wang, Yinan Ling, Keita Yokoyama, Hsin-Tai Wu, Yi\n  Fang", "title": "Leveraging an Efficient and Semantic Location Embedding to Seek New\n  Ports of Bike Share Services", "comments": "10 pages, 5 figures, 8 tables, to appear in 2020 IEEE International\n  Conference on Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For short distance traveling in crowded urban areas, bike share services are\nbecoming popular owing to the flexibility and convenience. To expand the\nservice coverage, one of the key tasks is to seek new service ports, which\nrequires to well understand the underlying features of the existing service\nports. In this paper, we propose a new model, named for Efficient and Semantic\nLocation Embedding (ESLE), which carries both geospatial and semantic\ninformation of the geo-locations. To generate ESLE, we first train a\nmulti-label model with a deep Convolutional Neural Network (CNN) by feeding the\nstatic map-tile images and then extract location embedding vectors from the\nmodel. Compared to most recent relevant literature, ESLE is not only much\ncheaper in computation, but also easier to interpret via a systematic semantic\nanalysis. Finally, we apply ESLE to seek new service ports for NTT DOCOMO's\nbike share services operated in Japan. The initial results demonstrate the\neffectiveness of ESLE, and provide a few insights that might be difficult to\ndiscover by using the conventional approaches.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 02:08:32 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Wang", "Yuan", ""], ["Wang", "Chenwei", ""], ["Ling", "Yinan", ""], ["Yokoyama", "Keita", ""], ["Wu", "Hsin-Tai", ""], ["Fang", "Yi", ""]]}, {"id": "2011.03528", "submitter": "Felix Parker", "authors": "Felix Parker, Hamilton Sawczuk, Fardin Ganjkhanloo, Farzin Ahmadi,\n  Kimia Ghobadi", "title": "Optimal Resource and Demand Redistribution for Healthcare Systems Under\n  Stress from COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  When facing an extreme stressor, such as the COVID-19 pandemic, healthcare\nsystems typically respond reactively by creating surge capacity at facilities\nthat are at or approaching their baseline capacity. However, creating\nindividual capacity at each facility is not necessarily the optimal approach,\nand redistributing demand and critical resources between facilities can reduce\nthe total required capacity. Data shows that this additional load was unevenly\ndistributed between hospitals during the COVID-19 pandemic, requiring some to\ncreate surge capacity while nearby hospitals had unused capacity. Not only is\nthis inefficient, but it also could lead to a decreased quality of care at\nover-capacity hospitals. In this work, we study the problem of finding optimal\ndemand and resource transfers to minimize the required surge capacity and\nresource shortage during a period of heightened demand. We develop and analyze\na series of linear and mixed-integer programming models that solve variants of\nthe demand and resource redistribution problem. We additionally consider demand\nuncertainty and use robust optimization to ensure solution feasibility. We also\nincorporate a range of operational constraints and costs that decision-makers\nmay need to consider when implementing such a scheme. Our models are validated\nretrospectively using COVID-19 hospitalization data from New Jersey, Texas, and\nMiami, yielding at least an 85% reduction in required surge capacity relative\nto the observed outcome of each case. Results show that such solutions are\noperationally feasible and sufficiently robust against demand uncertainty. In\nsummary, this work provides decision-makers in healthcare systems with a\npractical and flexible tool to reduce the surge capacity necessary to properly\ncare for patients in cases when some facilities are over capacity.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 18:56:02 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Parker", "Felix", ""], ["Sawczuk", "Hamilton", ""], ["Ganjkhanloo", "Fardin", ""], ["Ahmadi", "Farzin", ""], ["Ghobadi", "Kimia", ""]]}, {"id": "2011.03654", "submitter": "Jessica Dai", "authors": "Jessica Dai, Sina Fazelpour, Zachary C. Lipton", "title": "Fair Machine Learning Under Partial Compliance", "comments": "Presented at AIES 2021. Previously at the NeurIPS 2020 Workshop on\n  Consequential Decision Making in Dynamic Environments and the NeurIPS 2020\n  Workshop on ML for Economic Policy", "journal-ref": null, "doi": "10.1145/3461702.3462521", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, fair machine learning research focuses on a single decisionmaker\nand assumes that the underlying population is stationary. However, many of the\ncritical domains motivating this work are characterized by competitive\nmarketplaces with many decisionmakers. Realistically, we might expect only a\nsubset of them to adopt any non-compulsory fairness-conscious policy, a\nsituation that political philosophers call partial compliance. This possibility\nraises important questions: how does the strategic behavior of decision\nsubjects in partial compliance settings affect the allocation outcomes? If k%\nof employers were to voluntarily adopt a fairness-promoting intervention,\nshould we expect k% progress (in aggregate) towards the benefits of universal\nadoption, or will the dynamics of partial compliance wash out the hoped-for\nbenefits? How might adopting a global (versus local) perspective impact the\nconclusions of an auditor? In this paper, we propose a simple model of an\nemployment market, leveraging simulation as a tool to explore the impact of\nboth interaction effects and incentive effects on outcomes and auditing\nmetrics. Our key findings are that at equilibrium: (1) partial compliance (k%\nof employers) can result in far less than proportional (k%) progress towards\nthe full compliance outcomes; (2) the gap is more severe when fair employers\nmatch global (vs local) statistics; (3) choices of local vs global statistics\ncan paint dramatically different pictures of the performance vis-a-vis fairness\ndesiderata of compliant versus non-compliant employers; and (4) partial\ncompliance to local parity measures can induce extreme segregation.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 01:46:53 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 06:55:54 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 17:17:16 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Dai", "Jessica", ""], ["Fazelpour", "Sina", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2011.03731", "submitter": "Hongyan Chang", "authors": "Hongyan Chang, Reza Shokri", "title": "On the Privacy Risks of Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness and privacy are essential pillars of trustworthy machine\nlearning. Fair machine learning aims at minimizing discrimination against\nprotected groups by, for example, imposing a constraint on models to equalize\ntheir behavior across different groups. This can subsequently change the\ninfluence of training data points on the fair model, in a disproportionate way.\nWe study how this can change the information leakage of the model about its\ntraining data. We analyze the privacy risks of group fairness (e.g., equalized\nodds) through the lens of membership inference attacks: inferring whether a\ndata point is used for training a model. We show that fairness comes at the\ncost of privacy, and this cost is not distributed equally: the information\nleakage of fair models increases significantly on the unprivileged subgroups,\nwhich are the ones for whom we need fair learning. We show that the more biased\nthe training data is, the higher the privacy cost of achieving fairness for the\nunprivileged subgroups will be. We provide comprehensive empirical analysis for\ngeneral machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 09:15:31 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2021 01:45:56 GMT"}, {"version": "v3", "created": "Sun, 28 Mar 2021 08:36:27 GMT"}, {"version": "v4", "created": "Wed, 7 Apr 2021 05:43:22 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Chang", "Hongyan", ""], ["Shokri", "Reza", ""]]}, {"id": "2011.03847", "submitter": "Long Nguyen", "authors": "Hoang Long Nguyen, Zhenhe Pan, Hashim Abu-gellban, Fang Jin, Yuanlin\n  Zhang", "title": "Google Trends Analysis of COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The World Health Organization (WHO) announced that COVID-19 was a pandemic\ndisease on the 11th of March as there were 118K cases in several countries and\nterritories. Numerous researchers worked on forecasting the number of confirmed\ncases since anticipating the growth of the cases helps governments adopting\nknotty decisions to ease the lockdowns orders for their countries. These orders\nhelp several people who have lost their jobs and support gravely impacted\nbusinesses. Our research aims to investigate the relation between Google search\ntrends and the spreading of the novel coronavirus (COVID-19) over countries\nworldwide, to predict the number of cases. We perform a correlation analysis on\nthe keywords of the related Google search trends according to the number of\nconfirmed cases reported by the WHO. After that, we applied several machine\nlearning techniques (Multiple Linear Regression, Non-negative Integer\nRegression, Deep Neural Network), to forecast the number of confirmed cases\nglobally based on historical data as well as the hybrid data (Google search\ntrends). Our results show that Google search trends are highly associated with\nthe number of reported confirmed cases, where the Deep Learning approach\noutperforms other forecasting techniques. We believe that it is not only a\npromising approach for forecasting the confirmed cases of COVID-19, but also\nfor similar forecasting problems that are associated with the related Google\ntrends.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 20:55:19 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Nguyen", "Hoang Long", ""], ["Pan", "Zhenhe", ""], ["Abu-gellban", "Hashim", ""], ["Jin", "Fang", ""], ["Zhang", "Yuanlin", ""]]}, {"id": "2011.03850", "submitter": "Anahid Basiri Prof", "authors": "Anahid Basiri", "title": "Open Area Path Finding to Improve Wheelchair Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Navigation is one of the most widely used applications of the Location Based\nServices (LBS) which have become part of our digitally informed daily lives.\nNavigation services, however, have generally been designed for drivers rather\nthan other users such as pedestrians or wheelchair users. For these users the\ndirected networks of streets and roads do not limit their movements, but their\nmovements may have other limitations, including lower speed of movement, and\nbeing more dependent on weather and the pavement surface conditions. This paper\nproposes and implements a novel path finding algorithm for open areas, i.e.\nareas with no network of pathways such as grasslands and parks where the\nconventional graph-based algorithms fail to calculate a practically traversable\npath. The new method provides multimodality, a higher level of performance,\nefficiency, and user satisfaction in comparison with currently available\nsolutions. The proposed algorithm creates a new graph in the open area, which\ncan consider the obstacles and barriers and calculate the path based on the\nfactors that are important for wheelchair users. Factors, including slope,\nwidth, and surface condition of the routes, are recognised by mining the actual\ntrajectories of wheelchairs users using trajectory mining and machine learning\ntechniques. Unlike raster-based techniques, a graph-based open area path\nfinding algorithm allows the routing to be fully compatible with current\ntransportation routing services, and enables a full multimodal routing service.\nThe implementations and tests show at least a 76.4% similarity between the\nproposed algorithm outputs and actual wheelchair users trajectories.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 21:20:32 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Basiri", "Anahid", ""]]}, {"id": "2011.03995", "submitter": "Yun William Yu", "authors": "Abbas Hammoud and Yun William Yu", "title": "Privacy-accuracy trade-offs in noisy digital exposure notifications", "comments": "11 pages, preprint submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the global spread of Covid-19 began to overwhelm the attempts of\ngovernments to conduct manual contact-tracing, there has been much interest in\nusing the power of mobile phones to automate the contact-tracing process\nthrough the development of exposure notification applications. The rough idea\nis simple: use Bluetooth or other data-exchange technologies to record contacts\nbetween users, enable users to report positive diagnoses, and alert users who\nhave been exposed to sick users. Of course, there are many privacy concerns\nassociated with this idea. Much of the work in this area has been concerned\nwith designing mechanisms for tracing contacts and alerting users that do not\nleak additional information about users beyond the existence of exposure\nevents. However, although designing practical protocols is of crucial\nimportance, it is essential to realize that notifying users about exposure\nevents may itself leak confidential information (e.g. that a particular contact\nhas been diagnosed). Luckily, while digital contact tracing is a relatively new\ntask, the generic problem of privacy and data disclosure has been studied for\ndecades. Indeed, the framework of differential privacy further permits provable\nquery privacy by adding random noise. In this article, we translate two results\nfrom statistical privacy and social recommendation algorithms to exposure\nnotification. We thus prove some naive bounds on the degree to which accuracy\nmust be sacrificed if exposure notification frameworks are to be made more\nprivate through the injection of noise.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 15:00:38 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Hammoud", "Abbas", ""], ["Yu", "Yun William", ""]]}, {"id": "2011.04049", "submitter": "Cecilia Panigutti", "authors": "Cecilia Panigutti, Alan Perotti, Andr\\`e Panisson, Paolo Bajardi and\n  Dino Pedreschi", "title": "FairLens: Auditing Black-box Clinical Decision Support Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive application of algorithmic decision-making is raising concerns\non the risk of unintended bias in AI systems deployed in critical settings such\nas healthcare. The detection and mitigation of biased models is a very delicate\ntask which should be tackled with care and involving domain experts in the\nloop. In this paper we introduce FairLens, a methodology for discovering and\nexplaining biases. We show how our tool can be used to audit a fictional\ncommercial black-box model acting as a clinical decision support system. In\nthis scenario, the healthcare facility experts can use FairLens on their own\nhistorical data to discover the model's biases before incorporating it into the\nclinical decision flow. FairLens first stratifies the available patient data\naccording to attributes such as age, ethnicity, gender and insurance; it then\nassesses the model performance on such subgroups of patients identifying those\nin need of expert evaluation. Finally, building on recent state-of-the-art XAI\n(eXplainable Artificial Intelligence) techniques, FairLens explains which\nelements in patients' clinical history drive the model error in the selected\nsubgroup. Therefore, FairLens allows experts to investigate whether to trust\nthe model and to spotlight group-specific biases that might constitute\npotential fairness issues.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 18:40:50 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Panigutti", "Cecilia", ""], ["Perotti", "Alan", ""], ["Panisson", "Andr\u00e8", ""], ["Bajardi", "Paolo", ""], ["Pedreschi", "Dino", ""]]}, {"id": "2011.04088", "submitter": "Yichuan Li", "authors": "Yichuan Li, Bohan Jiang, Kai Shu, Huan Liu", "title": "MM-COVID: A Multilingual and Multimodal Data Repository for Combating\n  COVID-19 Disinformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 epidemic is considered as the global health crisis of the whole\nsociety and the greatest challenge mankind faced since World War Two.\nUnfortunately, the fake news about COVID-19 is spreading as fast as the virus\nitself. The incorrect health measurements, anxiety, and hate speeches will have\nbad consequences on people's physical health, as well as their mental health in\nthe whole world. To help better combat the COVID-19 fake news, we propose a new\nfake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19\nFake News Data Repository). This dataset provides the multilingual fake news\nand the relevant social context. We collect 3981 pieces of fake news content\nand 7192 trustworthy information from English, Spanish, Portuguese, Hindi,\nFrench and Italian, 6 different languages. We present a detailed and\nexploratory analysis of MM-COVID from different perspectives and demonstrate\nthe utility of MM-COVID in several potential applications of COVID-19 fake news\nstudy on multilingual and social media.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 21:42:03 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 06:04:23 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Li", "Yichuan", ""], ["Jiang", "Bohan", ""], ["Shu", "Kai", ""], ["Liu", "Huan", ""]]}, {"id": "2011.04219", "submitter": "Anay Mehrotra", "authors": "Anay Mehrotra and L. Elisa Celis", "title": "Mitigating Bias in Set Selection with Noisy Protected Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subset selection algorithms are ubiquitous in AI-driven applications,\nincluding, online recruiting portals and image search engines, so it is\nimperative that these tools are not discriminatory on the basis of protected\nattributes such as gender or race. Currently, fair subset selection algorithms\nassume that the protected attributes are known as part of the dataset. However,\nprotected attributes may be noisy due to errors during data collection or if\nthey are imputed (as is often the case in real-world settings). While a wide\nbody of work addresses the effect of noise on the performance of machine\nlearning algorithms, its effect on fairness remains largely unexamined. We find\nthat in the presence of noisy protected attributes, in attempting to increase\nfairness without considering noise, one can, in fact, decrease the fairness of\nthe result!\n  Towards addressing this, we consider an existing noise model in which there\nis probabilistic information about the protected attributes (e.g., [58, 34, 20,\n46]), and ask is fair selection possible under noisy conditions? We formulate a\n``denoised'' selection problem which functions for a large class of fairness\nmetrics; given the desired fairness goal, the solution to the denoised problem\nviolates the goal by at most a small multiplicative amount with high\nprobability. Although this denoised problem turns out to be NP-hard, we give a\nlinear-programming based approximation algorithm for it. We evaluate this\napproach on both synthetic and real-world datasets. Our empirical results show\nthat this approach can produce subsets which significantly improve the fairness\nmetrics despite the presence of noisy protected attributes, and, compared to\nprior noise-oblivious approaches, has better Pareto-tradeoffs between utility\nand fairness.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 06:45:15 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 17:56:05 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mehrotra", "Anay", ""], ["Celis", "L. Elisa", ""]]}, {"id": "2011.04322", "submitter": "Wei Jeng", "authors": "Hsu-Chun Hsiao, Chun-Ying Huang, Bing-Kai Hong, Shin-Ming Cheng,\n  Hsin-Yuan Hu, Chia-Chien Wu, Jian-Sin Lee, Shih-Hong Wang, Wei Jeng", "title": "An Empirical Evaluation of Bluetooth-based Decentralized Contact Tracing\n  in Crowds", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital contact tracing is being used by many countries to help contain\nCOVID-19's spread in a post-lockdown world. Among the various available\ntechniques, decentralized contact tracing that uses Bluetooth received signal\nstrength indication (RSSI) to detect proximity is considered less of a privacy\nrisk than approaches that rely on collecting absolute locations via GPS,\ncellular-tower history, or QR-code scanning. As of October 2020, there have\nbeen millions of downloads of such Bluetooth-based contract-tracing apps, as\nmore and more countries officially adopt them. However, the effectiveness of\nthese apps in the real world remains unclear due to a lack of empirical\nresearch that includes realistic crowd sizes and densities. This study aims to\nfill that gap, by empirically investigating the effectiveness of\nBluetooth-based contact tracing in crowd environments with a total of 80\nparticipants, emulating classrooms, moving lines, and other types of real-world\ngatherings. The results confirm that Bluetooth RSSI is unreliable for detecting\nproximity, and that this inaccuracy worsens in environments that are especially\ncrowded. In other words, this technique may be least useful when it is most in\nneed, and that it is fragile when confronted by low-cost jamming. Moreover,\ntechnical problems such as high energy consumption and phone overheating caused\nby the contact-tracing app were found to negatively influence users'\nwillingness to adopt it. On the bright side, however, Bluetooth RSSI may still\nbe useful for detecting coarse-grained contact events, for example, proximity\nof up to 20m lasting for an hour. Based on our findings, we recommend that\nexisting contact-tracing apps can be re-purposed to focus on coarse-grained\nproximity detection, and that future ones calibrate distance estimates and\nadjust broadcast frequencies based on auxiliary information.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 10:44:03 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 02:32:07 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Hsiao", "Hsu-Chun", ""], ["Huang", "Chun-Ying", ""], ["Hong", "Bing-Kai", ""], ["Cheng", "Shin-Ming", ""], ["Hu", "Hsin-Yuan", ""], ["Wu", "Chia-Chien", ""], ["Lee", "Jian-Sin", ""], ["Wang", "Shih-Hong", ""], ["Jeng", "Wei", ""]]}, {"id": "2011.04480", "submitter": "Hern\\'an Czemerinski", "authors": "Hern\\'an Czemerinski, Mart\\'in Scasso, Fernando Schapachnik", "title": "What's the worth of having a single CS teacher program aimed at teachers\n  with heterogeneous profiles?", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is consensus regarding the relevance of including Computer Science (CS)\nin official school curricula. However, this discipline cannot be taught on a\nlarge scale until there are enough trained teachers who can effectively lead a\nclass. In this article, we discuss the results of a 400-hour teacher training\nprogram conducted in Argentina aimed at K-12 teachers with no CS background.\nThe only requirement to sign up was to be an in-service teacher, and therefore\nthere were a plethora of different teacher profiles that attended the courses.\nOur research aims at understanding whether a single teacher training program\ncan be effective in teaching CS contents and specific pedagogy to teachers with\nvery heterogeneous profiles. Also, we investigate what teachers expect to do\nwith the contents they learn. To assess these questions anonymous examinations\nand questionnaires were given and interviews were conducted with course\nattendees. Even though the majority reached the expected minimum bar regarding\nCS contents and pedagogy, significant differences appear in their\nself-perception as regards career opportunities in CS teaching. Our conclusion\nis that carrying out CS teacher training for a broad spectrum of profiles may\nbe effective for promoting CS contents. However, if the goal is to boost\nteachers' confidence in teaching a CS subject, then having a program which\nfocuses on a more restricted selection of profiles would be a better strategy.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 15:03:31 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Czemerinski", "Hern\u00e1n", ""], ["Scasso", "Mart\u00edn", ""], ["Schapachnik", "Fernando", ""]]}, {"id": "2011.04601", "submitter": "Dimitris Spathis", "authors": "Dimitris Spathis, Ignacio Perez-Pozuelo, Soren Brage, Nicholas J.\n  Wareham and Cecilia Mascolo", "title": "Learning Generalizable Physiological Representations from Large-scale\n  Wearable Data", "comments": "Accepted to the Machine Learning for Mobile Health workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, research on sensor-equipped mobile devices has primarily focused on\nthe purely supervised task of human activity recognition (walking, running,\netc), demonstrating limited success in inferring high-level health outcomes\nfrom low-level signals, such as acceleration. Here, we present a novel\nself-supervised representation learning method using activity and heart rate\n(HR) signals without semantic labels. With a deep neural network, we set HR\nresponses as the supervisory signal for the activity data, leveraging their\nunderlying physiological relationship.\n  We evaluate our model in the largest free-living combined-sensing dataset\n(comprising more than 280,000 hours of wrist accelerometer & wearable ECG data)\nand show that the resulting embeddings can generalize in various downstream\ntasks through transfer learning with linear classifiers, capturing\nphysiologically meaningful, personalized information. For instance, they can be\nused to predict (higher than 70 AUC) variables associated with individuals'\nhealth, fitness and demographic characteristics, outperforming unsupervised\nautoencoders and common bio-markers. Overall, we propose the first multimodal\nself-supervised method for behavioral and physiological data with implications\nfor large-scale health and lifestyle monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:56:03 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Spathis", "Dimitris", ""], ["Perez-Pozuelo", "Ignacio", ""], ["Brage", "Soren", ""], ["Wareham", "Nicholas J.", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2011.04763", "submitter": "Philip Waggoner", "authors": "Philip D. Waggoner", "title": "Pandemic Policymaking: Learning the Lower Dimensional Manifold of\n  Congressional Responsiveness", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recent study leveraging text of pandemic-related policymaking from\n1973--2020 explored whether pandemic policymaking has evolved, or whether we\nare witnessing a new, unique era of policymaking as it relates to large-scale\ncrises like COVID-19. This research picks up on this approach over the same\nperiod of study and based on the same data, but excluding text. Instead, using\nhigh dimensional manifold learning, this study explores the latent structure of\nthe pandemic policymaking space based only on bill-level characteristics.\nResults indicate the COVID-19 era of policymaking maps extremely closely onto\nprior periods of related policymaking. This suggests that there is less of an\n\"evolutionary trend\" in pandemic policymaking, where instead there is striking\nuniformity in Congressional policymaking related to these types of large-scale\ncrises, despite being in a unique era of hyperpolarization, division, and\nineffective governance.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 21:06:59 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 13:44:34 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Waggoner", "Philip D.", ""]]}, {"id": "2011.04917", "submitter": "Ramaravind Kommiya Mothilal", "authors": "Ramaravind Kommiya Mothilal and Divyat Mahajan and Chenhao Tan and\n  Amit Sharma", "title": "Towards Unifying Feature Attribution and Counterfactual Explanations:\n  Different Means to the Same End", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": "10.1145/3461702.3462597", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature attributions and counterfactual explanations are popular approaches\nto explain a ML model. The former assigns an importance score to each input\nfeature, while the latter provides input examples with minimal changes to alter\nthe model's predictions. To unify these approaches, we provide an\ninterpretation based on the actual causality framework and present two key\nresults in terms of their use. First, we present a method to generate feature\nattribution explanations from a set of counterfactual examples. These feature\nattributions convey how important a feature is to changing the classification\noutcome of a model, especially on whether a subset of features is necessary\nand/or sufficient for that change, which attribution-based methods are unable\nto provide. Second, we show how counterfactual examples can be used to evaluate\nthe goodness of an attribution-based explanation in terms of its necessity and\nsufficiency. As a result, we highlight the complementarity of these two\napproaches. Our evaluation on three benchmark datasets - Adult-Income,\nLendingClub, and German-Credit - confirms the complementarity. Feature\nattribution methods like LIME and SHAP and counterfactual explanation methods\nlike Wachter et al. and DiCE often do not agree on feature importance rankings.\nIn addition, by restricting the features that can be modified for generating\ncounterfactual examples, we find that the top-k features from LIME or SHAP are\noften neither necessary nor sufficient explanations of a model's prediction.\nFinally, we present a case study of different explanation methods on a\nreal-world hospital triage problem\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 05:41:43 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 12:18:19 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 17:49:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mothilal", "Ramaravind Kommiya", ""], ["Mahajan", "Divyat", ""], ["Tan", "Chenhao", ""], ["Sharma", "Amit", ""]]}, {"id": "2011.05064", "submitter": "Herman Ho-Man Yau", "authors": "Herman Yau, Chris Russell, Simon Hadfield,", "title": "What Did You Think Would Happen? Explaining Agent Behaviour Through\n  Intended Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel form of explanation for Reinforcement Learning, based\naround the notion of intended outcome. These explanations describe the outcome\nan agent is trying to achieve by its actions. We provide a simple proof that\ngeneral methods for post-hoc explanations of this nature are impossible in\ntraditional reinforcement learning. Rather, the information needed for the\nexplanations must be collected in conjunction with training the agent. We\nderive approaches designed to extract local explanations based on intention for\nseveral variants of Q-function approximation and prove consistency between the\nexplanations and the Q-values learned. We demonstrate our method on multiple\nreinforcement learning problems, and provide code to help researchers\nintrospecting their RL environments and algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 12:05:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Yau", "Herman", ""], ["Russell", "Chris", ""], ["Hadfield", "Simon", ""]]}, {"id": "2011.05092", "submitter": "Simon Oh", "authors": "Simon Oh, Antonis F. Lentzakis, Ravi Seshadri, Moshe Ben-Akiva", "title": "Network Impacts of Automated Mobility-on-Demand: A Macroscopic\n  Fundamental Diagram Perspective", "comments": "29 pages, 9 figures, 6 tables, submitted to the journal Simulation\n  Modelling Practice and Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technological advancements have brought increasing attention to Automated\nMobility on Demand (AMOD) as a promising solution that may improve future urban\nmobility. During the last decade, extensive research has been conducted on the\ndesign and evaluation of AMOD systems using simulation models. This paper adds\nto this growing body of literature by investigating the network impacts of AMOD\nthrough high-fidelity activity- and agent-based traffic simulation, including\ndetailed models of AMOD fleet operations. Through scenario simulations of the\nentire island of Singapore, we explore network traffic dynamics by employing\nthe concept of the Macroscopic Fundamental Diagram (MFD). Taking into account\nthe spatial variability of density, we are able to capture the hysteresis\nloops, which inevitably form in a network of this size. Model estimation\nresults at both the vehicle and passenger flow level are documented.\nEnvironmental impacts including energy and emissions are also discussed.\nFindings from the case study of Singapore suggest that the introduction of AMOD\nmay bring about significant impacts on network performance in terms of\nincreased VKT, additional travel delay and energy consumption, while reducing\nvehicle emissions, with respect to the baseline. Despite the increase in\nnetwork congestion, production of passenger flows remains relatively unchanged.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 13:39:35 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Oh", "Simon", ""], ["Lentzakis", "Antonis F.", ""], ["Seshadri", "Ravi", ""], ["Ben-Akiva", "Moshe", ""]]}, {"id": "2011.05168", "submitter": "Meredith Rawls", "authors": "Meredith L. Rawls, Heidi B. Thiemann, Victor Chemin, Lucianne\n  Walkowicz, Mike W. Peel, and Yan G. Grange", "title": "Satellite Constellation Internet Affordability and Need", "comments": "4 pages, 1 figure, published in RNAAS", "journal-ref": "Res. Notes AAS 4 189 (2020)", "doi": "10.3847/2515-5172/abc48e", "report-no": null, "categories": "physics.pop-ph astro-ph.IM cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large satellite constellations in low-Earth orbit seek to be the\ninfrastructure for global broadband Internet and other telecommunication needs.\nWe briefly review the impacts of satellite constellations on astronomy and show\nthat the Internet service offered by these satellites will primarily target\npopulations where it is unaffordable, not needed, or both. The harm done by\ntens to hundreds of thousands of low-Earth orbit satellites to astronomy,\nstargazers worldwide, and the environment is not acceptable.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 20:57:46 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 01:37:40 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Rawls", "Meredith L.", ""], ["Thiemann", "Heidi B.", ""], ["Chemin", "Victor", ""], ["Walkowicz", "Lucianne", ""], ["Peel", "Mike W.", ""], ["Grange", "Yan G.", ""]]}, {"id": "2011.05442", "submitter": "Kenji Saito", "authors": "Hiroshi Watanabe, Kenji Saito, Satoshi Miyazaki, Toshiharu Okada,\n  Hiroyuki Fukuyama, Tsuneo Kato, Katsuo Taniguchi", "title": "Proof of Authenticity of Logistics Information with Passive RFID Tags\n  and Blockchain", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In tracing the (robotically automated) logistics of large quantities of\ngoods, inexpensive passive RFID tags are preferred for cost reasons.\nAccordingly, security between such tags and readers have primarily been studied\namong many issues of RFID. However, the authenticity of data cannot be\nguaranteed if logistics services can give false information. Although the use\nof blockchain is often discussed, it is simply a recording system, so there is\na risk that false records may be written to it.\n  As a solution, we propose a design in which a digitally signing,\nlocation-constrained and tamper-evident reader atomically writes an evidence to\nblockchain along with its reading and writing a tag.\n  By semi-formal modeling, we confirmed that the confidentiality and integrity\nof the information can be maintained throughout the system, and digitally\nsigned data can be verified later despite possible compromise of private keys\nor signature algorithms, or expiration of public key certificates. We also\nintroduce a prototype design to show that our proposal is viable.\n  This makes it possible to trace authentic logistics information using\ninexpensive passive RFID tags. Furthermore, by abstracting the reader/writer as\na sensor/actuator, this model can be extended to IoT in general.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 22:45:49 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Watanabe", "Hiroshi", ""], ["Saito", "Kenji", ""], ["Miyazaki", "Satoshi", ""], ["Okada", "Toshiharu", ""], ["Fukuyama", "Hiroyuki", ""], ["Kato", "Tsuneo", ""], ["Taniguchi", "Katsuo", ""]]}, {"id": "2011.05537", "submitter": "Lucas Rosenblatt", "authors": "Lucas Rosenblatt, Xiaoyan Liu, Samira Pouyanfar, Eduardo de Leon, Anuj\n  Desai, Joshua Allen", "title": "Differentially Private Synthetic Data: Applied Evaluations and\n  Enhancements", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning practitioners frequently seek to leverage the most\ninformative available data, without violating the data owner's privacy, when\nbuilding predictive models. Differentially private data synthesis protects\npersonal details from exposure, and allows for the training of differentially\nprivate machine learning models on privately generated datasets. But how can we\neffectively assess the efficacy of differentially private synthetic data? In\nthis paper, we survey four differentially private generative adversarial\nnetworks for data synthesis. We evaluate each of them at scale on five standard\ntabular datasets, and in two applied industry scenarios. We benchmark with\nnovel metrics from recent literature and other standard machine learning tools.\nOur results suggest some synthesizers are more applicable for different privacy\nbudgets, and we further demonstrate complicating domain-based tradeoffs in\nselecting an approach. We offer experimental learning on applied machine\nlearning scenarios with private internal data to researchers and practioners\nalike. In addition, we propose QUAIL, an ensemble-based modeling approach to\ngenerating synthetic data. We examine QUAIL's tradeoffs, and note circumstances\nin which it outperforms baseline differentially private supervised learning\nmodels under the same budget constraint.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 04:03:08 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Rosenblatt", "Lucas", ""], ["Liu", "Xiaoyan", ""], ["Pouyanfar", "Samira", ""], ["de Leon", "Eduardo", ""], ["Desai", "Anuj", ""], ["Allen", "Joshua", ""]]}, {"id": "2011.05679", "submitter": "Francesc Serratosa", "authors": "Francesc Serratosa", "title": "Security in biometric systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of biometric systems is to provide an identification mechanism.\nThis identification mechanism can be used to fulfil several objectives. The\nmost common, related to providing security to a resource, is usually\nauthentication or detection of authorized personnel and detection of\nunauthorized personnel. From the technical point of view, these two objectives\ncan be included in a single point since most functionalities are achieved by\nmaking searches of people previously identified in the database of the system\nin question. In the first case access is given to people entered in the\ndatabase and in the second case access is given to people who are not entered\nin the database. Although these are the two most common attacks there are also\nothers that we will discuss in this chapter. The structure of the chapter is as\nfollows. The first part of the chapter gives an overview of the basic types of\nattacks and describes the usual protection measures (Sections 1, 2 and 3). The\nsecond part of the chapter describes several attacks that can be made on\nsystems based on fingerprinting, face recognition, and iris recognition\n(Sections 4 and 5). Once the attack methodologies have been described, some\nspecific protection measures are also discussed (Sections 4 and 5). Finally,\nside channel attacks and their usefulness in combination with other possible\nattacks are described (Section 6).\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:16:06 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Serratosa", "Francesc", ""]]}, {"id": "2011.05689", "submitter": "Renata Georgia Raidou", "authors": "Renata G. Raidou, M. Eduard Gr\\\"oller, Hsiang-Yun Wu", "title": "Slice and Dice: A Physicalization Workflow for Anatomical Edutainment", "comments": null, "journal-ref": null, "doi": "10.1111/cgf.14173", "report-no": null, "categories": "cs.GR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  During the last decades, anatomy has become an interesting topic in\neducation---even for laymen or schoolchildren. As medical imaging techniques\nbecome increasingly sophisticated, virtual anatomical education applications\nhave emerged. Still, anatomical models are often preferred, as they facilitate\n3D localization of anatomical structures. Recently, data physicalizations\n(i.e., physical visualizations) have proven to be effective and\nengaging---sometimes, even more than their virtual counterparts. So far,\nmedical data physicalizations involve mainly 3D printing, which is still\nexpensive and cumbersome. We investigate alternative forms of physicalizations,\nwhich use readily available technologies (home printers) and inexpensive\nmaterials (paper or semi-transparent films) to generate crafts for anatomical\nedutainment. To the best of our knowledge, this is the first computer-generated\ncrafting approach within an anatomical edutainment context. Our approach\nfollows a cost-effective, simple, and easy-to-employ workflow, resulting in\nassemblable data sculptures (i.e., semi-transparent sliceforms). It primarily\nsupports volumetric data (such as CT or MRI), but mesh data can also be\nimported. An octree slices the imported volume and an optimization step\nsimplifies the slice configuration, proposing the optimal order for easy\nassembly. A packing algorithm places the resulting slices with their labels,\nannotations, and assembly instructions on a paper or transparent film of\nuser-selected size, to be printed, assembled into a sliceform, and explored. We\nconducted two user studies to assess our approach, demonstrating that it is an\ninitial positive step towards the successful creation of interactive and\nengaging anatomical physicalizations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 10:51:55 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Raidou", "Renata G.", ""], ["Gr\u00f6ller", "M. Eduard", ""], ["Wu", "Hsiang-Yun", ""]]}, {"id": "2011.05759", "submitter": "James Hackman", "authors": "James David Hackman", "title": "Forget-me-block: Exploring digital preservation strategies using\n  Distributed Ledger Technology in the context of personal information\n  management", "comments": "Dissertation submitted to the University of Bristol in accordance\n  with the requirements of the degree of Master of Science by advanced study in\n  Computer Science in the Faculty of Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Received wisdom portrays digital records as guaranteeing perpetuity; as the\nNew York Times wrote a decade ago: \"the web means the end of forgetting\". The\nreality however is that digital records suffer similar risks of access loss as\nthe analogue versions they replace. Often this risk is outsourced to\nspecialised third parties. Common use cases include Personal Information\nManagement (PIM): e.g. calendars, diaries, tasks, etc. Frequently these are\noutsourced at two removes - firstly by the individual to their employer (e.g.\nusing a company system) and then by their employer to an external provider. So\nenters a new risk: organisational change; by the time the information is\nrequired the organisational chain that links user to data may be broken: the\nemployer transitions to a different provider, the employee leaves the company,\nthe IS provider pivots to new offerings. The advent of Distributed Ledger\nTechnology (DLT) could help mitigate these risks; and has led to a\nre-evaluation of the relationship between data creation and ownership. Although\nDLT is an imprecise term, it typically involves data storage across\norganisationally separate entities in a cryptographically secure form; and\ntherefore could present a partial solution to the risk. This project presents\nthe first research that applies DLT to the field of PIM, furthering design\nscience state of the art by a novel implementation of a calendar application on\nthe Ethereum blockchain. It also extends current research in utilising DLT in\ndigital preservation, namely by enacting a continuum approach within a DL that\nallows for transfer of ownership of digital objects as they transition from\nindividual to collective relevance. Finally it provides guidelines for future\nuse of DLT within digital preservation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2020 22:53:32 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Hackman", "James David", ""]]}, {"id": "2011.05762", "submitter": "Riddhiman Adib", "authors": "Jannat Tumpa, Riddhiman Adib, Dipranjan Das, Nathalie Abenoza, Andrew\n  Zolot, Velinka Medic, Judy Kim, Al Castro, Mirtha Sosa Pacheco, Jay Romant\n  and Sheikh Iqbal Ahamed", "title": "mTOCS: Mobile Teleophthalmology in Community Settings to improve\n  Eye-health in Diabetic Population", "comments": "Submitted to Elsevier Smart Health Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetic eye diseases, particularly Diabetic Retinopathy,is the leading cause\nof vision loss worldwide and can be prevented by early diagnosis through annual\neye-screenings. However, cost, healthcare disparities, cultural limitations,\netc. are the main barriers against regular screening. Eye-screenings conducted\nin community events with native-speaking staffs can facilitate regular check-up\nand development of awareness among underprivileged communities compared to\ntraditional clinical settings. However, there are not sufficient technology\nsupport for carrying out the screenings in community settings with\ncollaboration from community partners using native languages. In this paper, we\nhave proposed and discussed the development of our software framework, \"Mobile\nTeleophthalomogy in Community Settings (mTOCS)\", that connects the community\npartners with eye-specialists and the Health Department staffs of respective\ncities to expedite this screening process. Moreover, we have presented the\nanalysis from our study on the acceptance of community-based screening methods\namong the community participants as well as on the effectiveness of mTOCS among\nthe community partners. The results have evinced that mTOCS has been capable of\nproviding an improved rate of eye-screenings and better health outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2020 19:54:13 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Tumpa", "Jannat", ""], ["Adib", "Riddhiman", ""], ["Das", "Dipranjan", ""], ["Abenoza", "Nathalie", ""], ["Zolot", "Andrew", ""], ["Medic", "Velinka", ""], ["Kim", "Judy", ""], ["Castro", "Al", ""], ["Pacheco", "Mirtha Sosa", ""], ["Romant", "Jay", ""], ["Ahamed", "Sheikh Iqbal", ""]]}, {"id": "2011.05773", "submitter": "Nicholas Micallef", "authors": "Nicholas Micallef, Bing He, Srijan Kumar, Mustaque Ahamad and Nasir\n  Memon", "title": "The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic", "comments": "PrePrint - IEEE BigData 2020. The code and data can be found in\n  http://claws.cc.gatech.edu/covid_counter_misinformation.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 13:48:44 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2020 04:20:37 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Micallef", "Nicholas", ""], ["He", "Bing", ""], ["Kumar", "Srijan", ""], ["Ahamad", "Mustaque", ""], ["Memon", "Nasir", ""]]}, {"id": "2011.05802", "submitter": "Maiia Marienko", "authors": "Maiia Marienko, Yulia Nosenko, Mariya Shyshkina", "title": "Personalization of learning using adaptive technologies and augmented\n  reality", "comments": "16 pages, 1 figures, Proceedings of the 3rd International Workshop on\n  Augmented Reality in Education (2731). pp. 341-356. ISSN 1613-0073", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.ed-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The research is aimed at developing the recommendations for educators on\nusing adaptive technologies and augmented reality in personalized learning\nimplementation. The latest educational technologies related to learning\npersonalization and the adaptation of its content to the individual needs of\nstudents and group work are considered. The current state of research is\ndescribed, the trends of development are determined. Due to a detailed analysis\nof scientific works, a retrospective of the development of adaptive and, in\nparticular, cloud-oriented systems is shown. The preconditions of their\nappearance and development, the main scientific ideas that contributed to this\nare analyzed. The analysis showed that the scientists point to four possible\ntypes of semantic interaction of augmented reality and adaptive technologies.\nThe adaptive cloud-based educational systems design is considered as the\npromising trend of research. It was determined that adaptability can be\nmanifested in one or a combination of several aspects: content, evaluation and\nconsistency. The cloud technology is taken as a platform for integrating\nadaptive learning with augmented reality as the effective modern tools to\npersonalize learning. The prospects of the adaptive cloud-based systems design\nin the context of teachers training are evaluated. The essence and place of\nassistive technologies in adaptive learning systems design are defined. It is\nshown that augmented reality can be successfully applied in inclusive\neducation. The ways of combining adaptive systems and augmented reality tools\nto support the process of teachers training are considered. The recommendations\non the use of adaptive cloud-based systems in teacher education are given.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 21:34:05 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Marienko", "Maiia", ""], ["Nosenko", "Yulia", ""], ["Shyshkina", "Mariya", ""]]}, {"id": "2011.05805", "submitter": "Mashnoon Islam", "authors": "Mashnoon Islam, Redwanul Karim, Kalyan Roy, Saif Mahmood, Sadat\n  Hossain, M. Rashedur Rahman", "title": "Crime Prediction Using Multiple-ANFIS Architecture and Spatiotemporal\n  Data", "comments": "Accepted Version, 2018 IEEE International Conference on Intelligent\n  Systems (IS) September 25-27, Funchal - Madeira, Portugal", "journal-ref": null, "doi": "10.1109/IS.2018.8710564", "report-no": null, "categories": "cs.CY cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical values alone cannot bring the whole scenario of crime occurrences\nin the city of Dhaka. We need a better way to use these statistical values to\npredict crime occurrences and make the city a safer place to live. Proper\ndecision-making for the future is key in reducing the rate of criminal offenses\nin an area or a city. If the law enforcement bodies can allocate their\nresources efficiently for the future, the rate of crime in Dhaka can be brought\ndown to a minimum. In this work, we have made an initiative to provide an\neffective tool with which law enforcement officials and detectives can predict\ncrime occurrences ahead of time and take better decisions easily and quickly.\nWe have used several Fuzzy Inference Systems (FIS) and Adaptive Neuro-Fuzzy\nInference Systems (ANFIS) to predict the type of crime that is highly likely to\noccur at a certain place and time.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 19:57:30 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Islam", "Mashnoon", ""], ["Karim", "Redwanul", ""], ["Roy", "Kalyan", ""], ["Mahmood", "Saif", ""], ["Hossain", "Sadat", ""], ["Rahman", "M. Rashedur", ""]]}, {"id": "2011.05806", "submitter": "Maryam Edalati", "authors": "Maryam Edalati", "title": "The Potential of Machine Learning and NLP for Handling Students'\n  Feedback (A Short Survey)", "comments": "10 pages, 3 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides a review of the literature of students' feedback papers\npublished in recent years employing data mining techniques. In particular, the\nfocus is to highlight those papers which are using either machine learning or\ndeep learning approaches. Student feedback assessment is a hot topic which has\nattracted a lot of attention in recent times. The importance has increased\nmanyfold due to the recent pandemic outbreak which pushed many colleges and\nuniversities to shift teaching from on-campus physical classes to online via\neLearning platforms and tools including massive open online courses (MOOCs).\nAssessing student feedback is even more important now. This short survey paper,\ntherefore, highlights recent trends in the natural language processing domain\non the topic of automatic student feedback assessment. It presents techniques\ncommonly utilized in this domain and discusses some future research directions.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 17:28:40 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Edalati", "Maryam", ""]]}, {"id": "2011.05807", "submitter": "Jason Pittman", "authors": "Jason M. Pittman, Ashlyn Hanks", "title": "Detecting Synthetic Phenomenology in a Contained Artificial General\n  Intelligence", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-like intelligence in a machine is a contentious subject. Whether\nmankind should or should not pursue the creation of artificial general\nintelligence is hotly debated. As well, researchers have aligned in opposing\nfactions according to whether mankind can create it. For our purposes, we\nassume mankind can and will do so. Thus, it becomes necessary to contemplate\nhow to do so in a safe and trusted manner -- enter the idea of boxing or\ncontainment. As part of such thinking, we wonder how a phenomenology might be\ndetected given the operational constraints imposed by any potential containment\nsystem. Accordingly, this work provides an analysis of existing measures of\nphenomenology through qualia and extends those ideas into the context of a\ncontained artificial general intelligence.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 16:10:38 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Pittman", "Jason M.", ""], ["Hanks", "Ashlyn", ""]]}, {"id": "2011.05808", "submitter": "Silvia Liberata Ullo", "authors": "A. Sebastianelli, F. Mauro, G. Di Cosmo, F. Passarini, M. Carminati,\n  S. L. Ullo", "title": "AIRSENSE-TO-ACT: A Concept Paper for COVID-19 Countermeasures based on\n  Artificial Intelligence algorithms and multi-sources Data Processing", "comments": "19 pages, 14 figures, 50 references, sottomesso ad una Special Issue\n  di ISPRS International Journal of Geo-Information\n  (https://www.mdpi.com/journal/ijgi/special_issues/Impacts_COVID-19 ),\n  attualmente under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aim of this paper is the description of a new tool to support institutions in\nthe implementation of targeted countermeasures, based on quantitative and\nmulti-scale elements, for the fight and prevention of emergencies, such as the\ncurrent COVID-19 pandemic. The tool is a centralized system (web application),\nsingle multi-user platform, which relies on Artificial Intelligence (AI)\nalgorithms for the processing of heterogeneous data, and which can produce an\noutput level of risk. The model includes a specific neural network which will\nbe first trained to learn the correlation between selected inputs, related to\nthe case of interest: environmental variables (chemical-physical, such as\nmeteorological), human activity (such as traffic and crowding), level of\npollution (in particular the concentration of particulate matter), and\nepidemiological variables related to the evolution of the contagion. The tool\nrealized in the first phase of the project will serve later both as a decision\nsupport system (DSS) with predictive capacity, when fed by the actual measured\ndata, and as a simulation bench performing the tuning of certain input values,\nto identify which of them lead to a decrease in the degree of risk. In this\nway, the authors aim to design different scenarios to compare different\nrestrictive strategies and the actual expected benefits, to adopt measures\nsized to the actual need, and adapted to the specific areas of analysis, useful\nto safeguard human health, but also the economic and social impact of the\nchoices.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 17:50:14 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Sebastianelli", "A.", ""], ["Mauro", "F.", ""], ["Di Cosmo", "G.", ""], ["Passarini", "F.", ""], ["Carminati", "M.", ""], ["Ullo", "S. L.", ""]]}, {"id": "2011.06007", "submitter": "Yugyeong Kim", "authors": "Yugyeong Kim, Sudip Vhaduri, and Christian Poellabauer", "title": "Understanding College Students' Phone Call Behaviors Towards a\n  Sustainable Mobile Health and Wellbeing Solution", "comments": "Accepted for publication in the 3rd International Conference on\n  Systems Engineering (CIIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the transition from high school to on-campus college life, a student\nleaves home and starts facing enormous life changes, including meeting new\npeople, more responsibilities, being away from family, and academic challenges.\nThese recent changes lead to an elevation of stress and anxiety, affecting a\nstudent's health and wellbeing. With the help of smartphones and their rich\ncollection of sensors, we can continuously monitor various factors that affect\nstudents' behavioral patterns, such as communication behaviors associated with\ntheir health, wellbeing, and academic success. In this work, we try to assess\ncollege students' communication patterns (in terms of phone call duration and\nfrequency) that vary across various geographical contexts (e.g., dormitories,\nclasses, dining) during different times (e.g., epochs of a day, days of a week)\nusing visualization techniques. Findings from this work will help foster the\ndesign and delivery of smartphone-based health interventions; thereby, help the\nstudents adapt to the changes in life.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 19:00:13 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Kim", "Yugyeong", ""], ["Vhaduri", "Sudip", ""], ["Poellabauer", "Christian", ""]]}, {"id": "2011.06049", "submitter": "Jeanne N. Clelland", "authors": "Jeanne Clelland, Haley Colgate, Daryl DeFord, Beth Malmskog, Flavia\n  Sancier-Barbosa", "title": "Colorado in Context: Congressional Redistricting and Competing Fairness\n  Criteria in Colorado", "comments": "39 pages, 21 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we apply techniques of ensemble analysis to understand the\npolitical baseline for Congressional representation in Colorado. We generate a\nlarge random sample of reasonable redistricting plans and determine the\npartisan balance of each district using returns from state-wide elections in\n2018, and analyze the 2011/2012 enacted districts in this context. Colorado\nrecently adopted a new framework for redistricting, creating an independent\ncommission to draw district boundaries, prohibiting partisan bias and\nincumbency considerations, requiring that political boundaries (such as\ncounties) be preserved as much as possible, and also requiring that mapmakers\nmaximize the number of competitive districts. We investigate the relationships\nbetween partisan outcomes, number of counties which are split, and number of\ncompetitive districts in a plan. This paper also features two novel\nimprovements in methodology--a more rigorous statistical framework for\nunderstanding necessary sample size, and a weighted-graph method for generating\nrandom plans which split approximately as few counties as acceptable\nhuman-drawn maps.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 20:05:50 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 22:13:57 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Clelland", "Jeanne", ""], ["Colgate", "Haley", ""], ["DeFord", "Daryl", ""], ["Malmskog", "Beth", ""], ["Sancier-Barbosa", "Flavia", ""]]}, {"id": "2011.06058", "submitter": "Erik Drysdale", "authors": "Erik Drysdale, Devin Singh, Anna Goldenberg", "title": "Forecasting Emergency Department Capacity Constraints for COVID\n  Isolation Beds", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting patient volumes in a hospital setting is a well-studied\napplication of time series forecasting. Existing tools usually make forecasts\nat the daily or weekly level to assist in planning for staffing requirements.\nPrompted by new COVID-related capacity constraints placed on our pediatric\nhospital's emergency department, we developed an hourly forecasting tool to\nmake predictions over a 24 hour window. These forecasts would give our hospital\nsufficient time to be able to martial resources towards expanding capacity and\naugmenting staff (e.g. transforming wards or bringing in physicians on call).\nUsing Gaussian Process Regressions (GPRs), we obtain strong performance for\nboth point predictions (average R-squared: 82%) as well as classification\naccuracy when predicting the ordinal tiers of our hospital's capacity (average\nprecision/recall: 82%/74%). Compared to traditional regression approaches, GPRs\nnot only obtain consistently higher performance, but are also robust to the\ndataset shifts that have occurred throughout 2020. Hospital stakeholders are\nencouraged by the strength of our results, and we are currently working on\nmoving our tool to a real-time setting with the goal of augmenting the\ncapabilities of our healthcare workers.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 19:35:41 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Drysdale", "Erik", ""], ["Singh", "Devin", ""], ["Goldenberg", "Anna", ""]]}, {"id": "2011.06249", "submitter": "Wentao Xu", "authors": "Wentao Xu, Kazutoshi Sasahara", "title": "Characterizing the roles of bots during the COVID-19 infodemic on\n  Twitter", "comments": "17 pages, main text: 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An infodemic is an emerging phenomenon caused by an overabundance of\ninformation online. This proliferation of information makes it difficult for\nthe public to identify trustworthy news and credible information from\nuntrustworthy sites and non-credible sources. The perils of an infodemic\ndebuted with the outbreak of the COVID-19 and bots (i.e., automated accounts\ncontrolled by a set of algorithms) that are suspected of involving the\ninfodemic.Although previous research has revealed that bots played a central\nrole in spreading misinformation during major political events, it is unclear\nhow bots behaved during the infodemic. In this paper, we examined the roles of\nbots in the case of the COVID-19 infodemic and the diffusion of non-credible\ninformation such as \"5G\" and \"Bill Gates\" conspiracy theories and \"Trump\" and\n\"WHO\" related contents by analyzing retweet networks and retweeted items. We\nshow the bipartite topology of their retweet networks, which indicates that\nright-wing self-medium accounts and conspiracy theorists may lead to this\nopinion cleavage, while malicious bots might favor amplification of the\ndiffusion of non-credible information. Although the basic influence of\ninformation diffusion could be larger in human users than bots, the effects of\nbots are non-negligible under an infodemic situation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 08:04:32 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 02:46:07 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Xu", "Wentao", ""], ["Sasahara", "Kazutoshi", ""]]}, {"id": "2011.06275", "submitter": "Jakub Tetek", "authors": "Jakub T\\v{e}tek, Marek Sklenka, Tom\\'a\\v{s} Gaven\\v{c}iak", "title": "Performance of Bounded-Rational Agents With the Ability to Self-Modify", "comments": "Fixed minor problems; To appear in SafeAI @ AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-modification of agents embedded in complex environments is hard to\navoid, whether it happens via direct means (e.g. own code modification) or\nindirectly (e.g. influencing the operator, exploiting bugs or the environment).\nIt has been argued that intelligent agents have an incentive to avoid modifying\ntheir utility function so that their future instances work towards the same\ngoals.\n  Everitt et al. (2016) formally show that providing an option to self-modify\nis harmless for perfectly rational agents. We show that this result is no\nlonger true for agents with bounded rationality. In such agents,\nself-modification may cause exponential deterioration in performance and\ngradual misalignment of a previously aligned agent. We investigate how the size\nof this effect depends on the type and magnitude of imperfections in the\nagent's rationality (1-4 below). We also discuss model assumptions and the\nwider problem and framing space.\n  We examine four ways in which an agent can be bounded-rational: it either (1)\ndoesn't always choose the optimal action, (2) is not perfectly aligned with\nhuman values, (3) has an inaccurate model of the environment, or (4) uses the\nwrong temporal discounting factor. We show that while in the cases (2)-(4) the\nmisalignment caused by the agent's imperfection does not increase over time,\nwith (1) the misalignment may grow exponentially.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 09:25:08 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 09:55:26 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["T\u011btek", "Jakub", ""], ["Sklenka", "Marek", ""], ["Gaven\u010diak", "Tom\u00e1\u0161", ""]]}, {"id": "2011.06422", "submitter": "Philip Waggoner", "authors": "Philip D. Waggoner, Alec Macmillen", "title": "Pursuing Open-Source Development of Predictive Algorithms: The Case of\n  Criminal Sentencing Algorithms", "comments": "26 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, there is uncertainty surrounding the merits of open-source versus\nproprietary algorithm development. Though justification in favor of each\nexists, we argue that open-source algorithm development should be the standard\nin highly consequential contexts that affect people's lives for reasons of\ntransparency and collaboration, which contribute to greater predictive accuracy\nand enjoy the additional advantage of cost-effectiveness. To make this case, we\nfocus on criminal sentencing algorithms, as criminal sentencing is highly\nconsequential, and impacts society and individual people. Further, the\npopularity of this topic has surged in the wake of recent studies uncovering\nracial bias in proprietary sentencing algorithms among other issues of\nover-fitting and model complexity. We suggest these issues are exacerbated by\nthe proprietary and expensive nature of virtually all widely used criminal\nsentencing algorithms. Upon replicating a major algorithm using real criminal\nprofiles, we fit three penalized regressions and demonstrate an increase in\npredictive power of these open-source and relatively computationally\ninexpensive options. The result is a data-driven suggestion that if judges who\nare making sentencing decisions want to craft appropriate sentences based on a\nhigh degree of accuracy and at low costs, then they should be pursuing\nopen-source options.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 14:53:43 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Waggoner", "Philip D.", ""], ["Macmillen", "Alec", ""]]}, {"id": "2011.06504", "submitter": "Kexin Huang", "authors": "Kexin Huang, Sankeerth Garapati, Alexander S. Rich", "title": "An Interpretable End-to-end Fine-tuning Approach for Long Clinical Text", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured clinical text in EHRs contains crucial information for\napplications including decision support, trial matching, and retrospective\nresearch. Recent work has applied BERT-based models to clinical information\nextraction and text classification, given these models' state-of-the-art\nperformance in other NLP domains. However, BERT is difficult to apply to\nclinical notes because it doesn't scale well to long sequences of text. In this\nwork, we propose a novel fine-tuning approach called SnipBERT. Instead of using\nentire notes, SnipBERT identifies crucial snippets and then feeds them into a\ntruncated BERT-based model in a hierarchical manner. Empirically, SnipBERT not\nonly has significant predictive performance gain across three tasks but also\nprovides improved interpretability, as the model can identify key pieces of\ntext that led to its prediction.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 17:14:32 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Huang", "Kexin", ""], ["Garapati", "Sankeerth", ""], ["Rich", "Alexander S.", ""]]}, {"id": "2011.06829", "submitter": "Erick Elejalde", "authors": "Elejalde Erick and Galanopoulos Damianos and Niederee Claudia and\n  Mezaris Vasileios", "title": "Migration-Related Semantic Concepts for the Retrieval of Relevant Video\n  Content", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-71711-7_34", "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Migration, and especially irregular migration, is a critical issue for border\nagencies and society in general. Migration-related situations and decisions are\ninfluenced by various factors, including the perceptions about migration routes\nand target countries. An improved understanding of such factors can be achieved\nby systematic automated analyses of media and social media channels, and the\nvideos and images published in them. However, the multifaceted nature of\nmigration and the variety of ways migration-related aspects are expressed in\nimages and videos make the finding and automated analysis of migration-related\nmultimedia content a challenging task. We propose a novel approach that\neffectively bridges the gap between a substantiated domain understanding -\nencapsulated into a set of Migration-related semantic concepts - and the\nexpression of such concepts in a video, by introducing an advanced video\nanalysis and retrieval method for this purpose.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 09:37:10 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Erick", "Elejalde", ""], ["Damianos", "Galanopoulos", ""], ["Claudia", "Niederee", ""], ["Vasileios", "Mezaris", ""]]}, {"id": "2011.07161", "submitter": "Kelton Minor", "authors": "Kelton Minor, Andreas Bjerre-Nielsen, Sigga Svala Jonasdottir, Sune\n  Lehmann, Nick Obradovich", "title": "Ambient heat and human sleep", "comments": "29 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Ambient temperatures are rising globally, with the greatest increases\nrecorded at night. Concurrently, the prevalence of insufficient sleep is\nincreasing in many populations, with substantial costs to human health and\nwell-being. Even though nearly a third of the human lifespan is spent asleep,\nit remains unknown whether temperature and weather impact objective measures of\nsleep in real-world settings, globally. Here we link billions of sleep\nmeasurements from wearable devices comprising over 7 million nighttime sleep\nrecords across 68 countries to local daily meteorological data from 2015 to\n2017. Rising nighttime temperatures shorten within-person sleep duration\nprimarily through delayed onset, increasing the probability of insufficient\nsleep. The effect of temperature on sleep loss is substantially larger for\nresidents from lower income countries and older adults, and females are\naffected more than are males. Nighttime temperature increases inflict the\ngreatest sleep loss during summer and fall months, and we do not find evidence\nof short-term acclimatization. Coupling historical behavioral measurements with\noutput from climate models, we project that climate change will further erode\nhuman sleep, producing substantial geographic inequalities. Our findings have\nsignificant implications for adaptation planning and illuminate a pathway\nthrough which rising temperatures may globally impact public health.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 23:04:42 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Minor", "Kelton", ""], ["Bjerre-Nielsen", "Andreas", ""], ["Jonasdottir", "Sigga Svala", ""], ["Lehmann", "Sune", ""], ["Obradovich", "Nick", ""]]}, {"id": "2011.07194", "submitter": "Amanda Coston", "authors": "Amanda Coston, Neel Guha, Derek Ouyang, Lisa Lu, Alexandra\n  Chouldechova, and Daniel E. Ho", "title": "Leveraging Administrative Data for Bias Audits: Assessing Disparate\n  Coverage with Mobility Data for COVID-19 Policy", "comments": null, "journal-ref": "Proceedings of the 2021 ACM Conference on Fairness,\n  Accountability, and Transparency. pp. 173-184", "doi": "10.1145/3442188.3445881", "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anonymized smartphone-based mobility data has been widely adopted in devising\nand evaluating COVID-19 response strategies such as the targeting of public\nhealth resources. Yet little attention has been paid to measurement validity\nand demographic bias, due in part to the lack of documentation about which\nusers are represented as well as the challenge of obtaining ground truth data\non unique visits and demographics. We illustrate how linking large-scale\nadministrative data can enable auditing mobility data for bias in the absence\nof demographic information and ground truth labels. More precisely, we show\nthat linking voter roll data -- containing individual-level voter turnout for\nspecific voting locations along with race and age -- can facilitate the\nconstruction of rigorous bias and reliability tests. These tests illuminate a\nsampling bias that is particularly noteworthy in the pandemic context: older\nand non-white voters are less likely to be captured by mobility data. We show\nthat allocating public health resources based on such mobility data could\ndisproportionately harm high-risk elderly and minority groups.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 02:04:14 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 01:42:13 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Coston", "Amanda", ""], ["Guha", "Neel", ""], ["Ouyang", "Derek", ""], ["Lu", "Lisa", ""], ["Chouldechova", "Alexandra", ""], ["Ho", "Daniel E.", ""]]}, {"id": "2011.07212", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "Do Cyber Capabilities and Cyber Power Incentivize International\n  Cooperation?", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores a research question about whether defensive and offensive\ncyber security power and the capabilities to exercise the power influence the\nincentives of nation-states to participate in bilateral and multilateral\ncooperation (BMC) through formal and informal agreements, alliances, and norms.\nDrawing from international relations in general and structural realism in\nparticular, three hypotheses are presented for assessing the research question\nempirically: (i) increasing cyber capability lessens the incentives for BMC;\n(ii) actively demonstrating and exerting cyber power decreases the willingness\nfor BMC; and (iii) small states prefer BMC for cyber security and politics\nthereto. According to a cross-country dataset of 29 countries, all three\nhypotheses are rejected. Although presenting a \"negative result\" with respect\nto the research question, the accompanying discussion contributes to the\nstate-centric cyber security research in international relations and political\nscience.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 03:34:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "2011.07303", "submitter": "Sophia Duan", "authors": "Mark Frost, Sophia Xiaoxia Duan", "title": "Rethinking the Role of Technology in Virtual Teams in Light of COVID-19", "comments": "Australasian Conference on Information Systems (ACIS2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of virtual teams by organisations has grown tremendously as a\nstrategic response to COVID-19. However, the concept of virtual teams is not\nsomething new, with many businesses over the past three decades gradually\nincorporating virtual and/or dispersed teams into their processes. Research on\nvirtual teams has followed that of co-located face-to-face teams through lenses\nsuch as trust, communication, teamwork, leadership and collaboration. This\npaper introduces a new paradigm for examining the development of virtual teams,\narguably one that would facilitate the consideration of technology as part of a\nvirtual team rather than simply as an alternate to face-to-face teams. That is,\nviewing the development of virtual teams with embedded technology within an\norganisation through an innovation framework.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 13:50:05 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Frost", "Mark", ""], ["Duan", "Sophia Xiaoxia", ""]]}, {"id": "2011.07376", "submitter": "George Obaido", "authors": "George Obaido, Abejide Ade-Ibijola, Hima Vadapalli", "title": "Synthesis of SQL Queries from South African Local Language Narrations", "comments": "8 pages, 3 figures, Advances in Science, Technology and Engineering\n  Systems Journal", "journal-ref": "5(5), 1189-1195 (2020)", "doi": "10.25046/aj0505144", "report-no": null, "categories": "cs.CY cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  English remains the language of choice for database courses and widely used\nfor instruction in nearly all South African universities, and also in many\ncountries. Novice programmers of native origins are mostly taught Structured\nQuery Language (SQL) through English as the medium of instruction.\nConsequently, this creates a myriad of problems in understanding the syntax of\nSQL as most native learners are not too proficient in English. This could\naffect a learner's ability in comprehending SQL syntaxes. To resolve this\nproblem, this work proposes a tool called local language narrations\n(Local-Nar-SQL) to SQL that uses a type of Finite Machine, such as a Jumping\nFinite Automaton to translate local language narratives into SQL queries.\nFurther, the generated query extracts information from a sample database and\npresents output to the learner. This paper is an extension of work originally\npresented in a previous study in this field. A survey involving 145\nparticipants concluded that the majority found Local-Nar-SQL to be helpful in\nunderstanding SQL queries from local languages. If the proposed tool is used as\na learning aid, native learners will find it easier to work with SQL, which\nwill eliminate many of the barriers faced with English proficiencies in\nprogramming pedagogies.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 19:38:08 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Obaido", "George", ""], ["Ade-Ibijola", "Abejide", ""], ["Vadapalli", "Hima", ""]]}, {"id": "2011.07396", "submitter": "Ali Septiandri", "authors": "Ali Akbar Septiandri, Aditiawarman, Roy Tjiong, Erlina Burhan, Anuraj\n  Shankar", "title": "Cost-Sensitive Machine Learning Classification for Mass Tuberculosis\n  Verbal Screening", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score-based algorithms for tuberculosis (TB) verbal screening perform poorly,\ncausing misclassification that leads to missed cases and unnecessary costly\nlaboratory tests for false positives. We compared score-based classification\ndefined by clinicians to machine learning classification such as SVM-RBF,\nlogistic regression, and XGBoost. We restricted our analyses to data from\nadults, the population most affected by TB, and investigated the difference\nbetween untuned and unweighted classifiers to the cost-sensitive ones.\nPredictions were compared with the corresponding GeneXpert MTB/Rif results.\nAfter adjusting the weight of the positive class to 40 for XGBoost, we achieved\n96.64% sensitivity and 35.06% specificity. As such, the sensitivity of our\nidentifier increased by 1.26% while specificity increased by 13.19% in absolute\nvalue compared to the traditional score-based method defined by our clinicians.\nOur approach further demonstrated that only 2000 data points were sufficient to\nenable the model to converge. The results indicate that even with limited data\nwe can actually devise a better method to identify TB suspects from verbal\nscreening.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 21:41:29 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Septiandri", "Ali Akbar", ""], ["Aditiawarman", "", ""], ["Tjiong", "Roy", ""], ["Burhan", "Erlina", ""], ["Shankar", "Anuraj", ""]]}, {"id": "2011.07453", "submitter": "Kurtis Evan David", "authors": "Kurtis Evan David, Qiang Liu, Ruth Fong", "title": "Debiasing Convolutional Neural Networks via Meta Orthogonalization", "comments": "Accepted to NeuRIPS 2020 Workshop on Algorithmic Fairness through the\n  Lens of Causality and Interpretability (AFCI). Supplemental materials\n  provided at:\n  https://drive.google.com/drive/folders/1klIAqZDgg3sCVmzFjLw5Y_T-GTc2E3oh?usp=sharing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While deep learning models often achieve strong task performance, their\nsuccesses are hampered by their inability to disentangle spurious correlations\nfrom causative factors, such as when they use protected attributes (e.g., race,\ngender, etc.) to make decisions. In this work, we tackle the problem of\ndebiasing convolutional neural networks (CNNs) in such instances. Building off\nof existing work on debiasing word embeddings and model interpretability, our\nMeta Orthogonalization method encourages the CNN representations of different\nconcepts (e.g., gender and class labels) to be orthogonal to one another in\nactivation space while maintaining strong downstream task performance. Through\na variety of experiments, we systematically test our method and demonstrate\nthat it significantly mitigates model bias and is competitive against current\nadversarial debiasing methods.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 05:13:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["David", "Kurtis Evan", ""], ["Liu", "Qiang", ""], ["Fong", "Ruth", ""]]}, {"id": "2011.07555", "submitter": "Pashmina Cameron", "authors": "Goutham Ramakrishnan, Aditya Nori, Hannah Murfet, Pashmina Cameron", "title": "Towards Compliant Data Management Systems for Healthcare ML", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing popularity of machine learning approaches and the rising\nawareness of data protection and data privacy presents an opportunity to build\ntruly secure and trustworthy healthcare systems. Regulations such as GDPR and\nHIPAA present broad guidelines and frameworks, but the implementation can\npresent technical challenges. Compliant data management systems require\nenforcement of a number of technical and administrative safeguards. While\npolicies can be set for both safeguards there is limited availability to\nunderstand compliance in real time. Increasingly, machine learning\npractitioners are becoming aware of the importance of keeping track of\nsensitive data. With sensitivity over personally identifiable, health or\ncommercially sensitive information there would be value in understanding\nassessment of the flow of data in a more dynamic fashion. We review how data\nflows within machine learning projects in healthcare from source to storage to\nuse in training algorithms and beyond. Based on this, we design engineering\nspecifications and solutions for versioning of data. Our objective is to design\ntools to detect and track sensitive data across machines and users across the\nlife cycle of a project, prioritizing efficiency, consistency and ease of use.\nWe build a prototype of the solution that demonstrates the difficulties in this\ndomain. Together, these represent first efforts towards building a compliant\ndata management system for healthcare machine learning projects.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 15:27:51 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Ramakrishnan", "Goutham", ""], ["Nori", "Aditya", ""], ["Murfet", "Hannah", ""], ["Cameron", "Pashmina", ""]]}, {"id": "2011.07571", "submitter": "Robert Haines", "authors": "Caroline Jay, Robert Haines, Daniel S. Katz", "title": "Software must be recognised as an important output of scholarly research", "comments": "6 pages. Submitted to IJDC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software now lies at the heart of scholarly research. Here we argue that as\nwell as being important from a methodological perspective, software should, in\nmany instances, be recognised as an output of research, equivalent to an\nacademic paper. The article discusses the different roles that software may\nplay in research and highlights the relationship between software and research\nsustainability and reproducibility. It describes the challenges associated with\nthe processes of citing and reviewing software, which differ from those used\nfor papers. We conclude that whilst software outputs do not necessarily fit\ncomfortably within the current publication model, there is a great deal of\npositive work underway that is likely to make an impact in addressing this.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 16:34:31 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Jay", "Caroline", ""], ["Haines", "Robert", ""], ["Katz", "Daniel S.", ""]]}, {"id": "2011.07586", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Javier Antor\\'an, Yunfeng Zhang, Q. Vera Liao, Prasanna\n  Sattigeri, Riccardo Fogliato, Gabrielle Gauthier Melan\\c{c}on, Ranganath\n  Krishnan, Jason Stanley, Omesh Tickoo, Lama Nachman, Rumi Chunara, Madhulika\n  Srikumar, Adrian Weller, Alice Xiang", "title": "Uncertainty as a Form of Transparency: Measuring, Communicating, and\n  Using Uncertainty", "comments": "AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society\n  (AIES) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic transparency entails exposing system properties to various\nstakeholders for purposes that include understanding, improving, and contesting\npredictions. Until now, most research into algorithmic transparency has\npredominantly focused on explainability. Explainability attempts to provide\nreasons for a machine learning model's behavior to stakeholders. However,\nunderstanding a model's specific behavior alone might not be enough for\nstakeholders to gauge whether the model is wrong or lacks sufficient knowledge\nto solve the task at hand. In this paper, we argue for considering a\ncomplementary form of transparency by estimating and communicating the\nuncertainty associated with model predictions. First, we discuss methods for\nassessing uncertainty. Then, we characterize how uncertainty can be used to\nmitigate model unfairness, augment decision-making, and build trustworthy\nsystems. Finally, we outline methods for displaying uncertainty to stakeholders\nand recommend how to collect information required for incorporating uncertainty\ninto existing ML pipelines. This work constitutes an interdisciplinary review\ndrawn from literature spanning machine learning, visualization/HCI, design,\ndecision-making, and fairness. We aim to encourage researchers and\npractitioners to measure, communicate, and use uncertainty as a form of\ntransparency.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 17:26:14 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:11:01 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 10:33:03 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bhatt", "Umang", ""], ["Antor\u00e1n", "Javier", ""], ["Zhang", "Yunfeng", ""], ["Liao", "Q. Vera", ""], ["Sattigeri", "Prasanna", ""], ["Fogliato", "Riccardo", ""], ["Melan\u00e7on", "Gabrielle Gauthier", ""], ["Krishnan", "Ranganath", ""], ["Stanley", "Jason", ""], ["Tickoo", "Omesh", ""], ["Nachman", "Lama", ""], ["Chunara", "Rumi", ""], ["Srikumar", "Madhulika", ""], ["Weller", "Adrian", ""], ["Xiang", "Alice", ""]]}, {"id": "2011.07647", "submitter": "Tim Miller", "authors": "Simon Coghlan and Tim Miller and Jeannie Paterson", "title": "Good proctor or \"Big Brother\"? AI Ethics and Online Exam Supervision\n  Technologies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article philosophically analyzes online exam supervision technologies,\nwhich have been thrust into the public spotlight due to campus lockdowns during\nthe COVID-19 pandemic and the growing demand for online courses. Online exam\nproctoring technologies purport to provide effective oversight of students\nsitting online exams, using artificial intelligence (AI) systems and human\ninvigilators to supplement and review those systems. Such technologies have\nalarmed some students who see them as `Big Brother-like', yet some universities\ndefend their judicious use. Critical ethical appraisal of online proctoring\ntechnologies is overdue. This article philosophically analyzes these\ntechnologies, focusing on the ethical concepts of academic integrity, fairness,\nnon-maleficence, transparency, privacy, respect for autonomy, liberty, and\ntrust. Most of these concepts are prominent in the new field of AI ethics and\nall are relevant to the education context. The essay provides ethical\nconsiderations that educational institutions will need to carefully review\nbefore electing to deploy and govern specific online proctoring technologies.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2020 22:53:56 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Coghlan", "Simon", ""], ["Miller", "Tim", ""], ["Paterson", "Jeannie", ""]]}, {"id": "2011.07887", "submitter": "Wojciech Jamroga", "authors": "Wojciech Jamroga, David Mestel, Peter B. Roenne, Peter Y. A. Ryan,\n  Marjan Skrobot", "title": "A Survey of Requirements for COVID-19 Mitigation Strategies. Part I:\n  Newspaper Clips", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The COVID-19 pandemic has influenced virtually all aspects of our lives.\nAcross the world, countries have applied various mitigation strategies for the\nepidemic, based on social, political, and technological instruments. We\npostulate that one should {identify the relevant requirements} before\ncommitting to a particular mitigation strategy. One way to achieve it is\nthrough an overview of what is considered relevant by the general public, and\nreferred to in the media. To this end, we have collected a number of news clips\nthat mention the possible goals and requirements for a mitigation strategy. The\nsnippets are sorted thematically into several categories, such as\nhealth-related goals, social and political impact, civil rights, ethical\nrequirements, and so on.\n  In a forthcoming companion paper, we will present a digest of the\nrequirements, derived from the news clips, and a preliminary take on their\nformal specification.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 12:00:49 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 11:12:04 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2021 17:44:06 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Jamroga", "Wojciech", ""], ["Mestel", "David", ""], ["Roenne", "Peter B.", ""], ["Ryan", "Peter Y. A.", ""], ["Skrobot", "Marjan", ""]]}, {"id": "2011.08069", "submitter": "Aastha Mehta", "authors": "Gilles Barthe, Roberta De Viti, Peter Druschel, Deepak Garg, Manuel\n  Gomez-Rodriguez, Pierfrancesco Ingo, Matthew Lentz, Aastha Mehta, Bernhard\n  Sch\\\"olkopf", "title": "PanCast: Listening to Bluetooth Beacons for Epidemic Risk Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the ongoing COVID-19 pandemic, there have been burgeoning efforts to\ndevelop and deploy smartphone apps to expedite contact tracing and risk\nnotification. Most of these apps track pairwise encounters between individuals\nvia Bluetooth and then use these tracked encounters to identify and notify\nthose who might have been in proximity of a contagious individual.\nUnfortunately, these apps have not yet proven sufficiently effective, partly\nowing to low adoption rates, but also due to the difficult tradeoff between\nutility and privacy and the fact that, in COVID-19, most individuals do not\ninfect anyone but a few superspreaders infect many in superspreading events. In\nthis paper, we proposePanCast, a privacy-preserving and inclusive system for\nepidemic risk assessment and notification that scales gracefully with adoption\nrates, utilizes location and environmental information to increase utility\nwithout tracking its users, and can be used to identify superspreading events.\nTo this end, rather than capturing pairwise encounters between smartphones, our\nsystem utilizes Bluetooth encounters between beacons placed in strategic\nlocations where superspreading events are most likely to occur and inexpensive,\nzero-maintenance, small devices that users can attach to their keyring. PanCast\nallows healthy individuals to use the system in a purely passive \"radio\" mode,\nand can assist and benefit from other digital and manual contact tracing\nsystems. Finally, PanCast can be gracefully dismantled at the end of the\npandemic, minimizing abuse from any malevolent government or entity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 16:19:37 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Barthe", "Gilles", ""], ["De Viti", "Roberta", ""], ["Druschel", "Peter", ""], ["Garg", "Deepak", ""], ["Gomez-Rodriguez", "Manuel", ""], ["Ingo", "Pierfrancesco", ""], ["Lentz", "Matthew", ""], ["Mehta", "Aastha", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "2011.08254", "submitter": "Michael Lash", "authors": "Michael T. Lash and W. Nick Street", "title": "Personalized Cardiovascular Disease Risk Mitigation via Longitudinal\n  Inverse Classification", "comments": "Forthcoming in AIBH 2020 (a BIBM 2020 workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiovascular disease (CVD) is a serious illness affecting millions\nworld-wide and is the leading cause of death in the US. Recent years, however,\nhave seen tremendous growth in the area of personalized medicine, a field of\nmedicine that places the patient at the center of the medical decision-making\nand treatment process. Many CVD-focused personalized medicine innovations focus\non genetic biomarkers, which provide person-specific CVD insights at the\ngenetic level, but do not focus on the practical steps a patient could take to\nmitigate their risk of CVD development. In this work we propose longitudinal\ninverse classification, a recommendation framework that provides personalized\nlifestyle recommendations that minimize the predicted probability of CVD risk.\nOur framework takes into account historical CVD risk, as well as other patient\ncharacteristics, to provide recommendations. Our experiments show that earlier\nadoption of the recommendations elicited from our framework produce significant\nCVD risk reduction.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 20:23:01 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lash", "Michael T.", ""], ["Street", "W. Nick", ""]]}, {"id": "2011.08498", "submitter": "Ashwin Rao", "authors": "Ashwin Rao, Fred Morstatter, Minda Hu, Emily Chen, Keith Burghardt,\n  Emilio Ferrara and Kristina Lerman", "title": "Political Partisanship and Anti-Science Attitudes in Online Discussions\n  about Covid-19", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus pandemic continues to ravage communities across the US.\nOpinion surveys identified importance of political ideology in shaping\nperceptions of the pandemic and compliance with preventive measures. Here, we\nuse social media data to study complexity of polarization. We analyze a large\ndataset of tweets related to the pandemic collected between January and May of\n2020, and develop methods to classify the ideological alignment of users along\nthe moderacy (hardline vs moderate), political (liberal vs conservative) and\nscience (anti-science vs pro-science) dimensions. While polarization along the\nscience and political dimensions are correlated, politically moderate users are\nmore likely to be aligned with the pro-science views, and politically hardline\nusers with anti-science views. Contrary to expectations, we do not find that\npolarization grows over time; instead, we see increasing activity by moderate\npro-science users. We also show that anti-science conservatives tend to tweet\nfrom the Southern US, while anti-science moderates from the Western states. Our\nfindings shed light on the multi-dimensional nature of polarization, and the\nfeasibility of tracking polarized opinions about the pandemic across time and\nspace through social media data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 08:22:20 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Rao", "Ashwin", ""], ["Morstatter", "Fred", ""], ["Hu", "Minda", ""], ["Chen", "Emily", ""], ["Burghardt", "Keith", ""], ["Ferrara", "Emilio", ""], ["Lerman", "Kristina", ""]]}, {"id": "2011.08512", "submitter": "Sean McGregor", "authors": "Sean McGregor", "title": "Preventing Repeated Real World AI Failures by Cataloging Incidents: The\n  AI Incident Database", "comments": "6 pages, 7 figures, Pre-print accepted to Innovative Applications of\n  Artificial Intelligence (IAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Mature industrial sectors (e.g., aviation) collect their real world failures\nin incident databases to inform safety improvements. Intelligent systems\ncurrently cause real world harms without a collective memory of their failings.\nAs a result, companies repeatedly make the same mistakes in the design,\ndevelopment, and deployment of intelligent systems. A collection of intelligent\nsystem failures experienced in the real world (i.e., incidents) is needed to\nensure intelligent systems benefit people and society. The AI Incident Database\nis an incident collection initiated by an industrial/non-profit cooperative to\nenable AI incident avoidance and mitigation. The database supports a variety of\nresearch and development use cases with faceted and full text search on more\nthan 1,000 incident reports archived to date.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 08:55:14 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["McGregor", "Sean", ""]]}, {"id": "2011.08575", "submitter": "Harsh Maheshwari", "authors": "Shreyas S, Harsh Maheshwari, Avijit Saha, Samik Datta, Shashank Jain,\n  Disha Makhija, Anuj Nagpal, Sneha Shukla, Suyash S", "title": "Audience Creation for Consumables -- Simple and Scalable Precision\n  Merchandising for a Growing Marketplace", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Consumable categories, such as grocery and fast-moving consumer goods, are\nquintessential to the growth of e-commerce marketplaces in developing\ncountries. In this work, we present the design and implementation of a\nprecision merchandising system, which creates audience sets from over 10\nmillion consumers and is deployed at Flipkart Supermart, one of the largest\nonline grocery stores in India. We employ temporal point process to model the\nlatent periodicity and mutual-excitation in the purchase dynamics of\nconsumables. Further, we develop a likelihood-free estimation procedure that is\nrobust against data sparsity, censure and noise typical of a growing\nmarketplace. Lastly, we scale the inference by quantizing the triggering\nkernels and exploiting sparse matrix-vector multiplication primitive available\non a commercial distributed linear algebra backend. In operation spanning more\nthan a year, we have witnessed a consistent increase in click-through rate in\nthe range of 25-70% for banner-based merchandising in the storefront, and in\nthe range of 12-26% for push notification-based campaigns.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 11:46:38 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["S", "Shreyas", ""], ["Maheshwari", "Harsh", ""], ["Saha", "Avijit", ""], ["Datta", "Samik", ""], ["Jain", "Shashank", ""], ["Makhija", "Disha", ""], ["Nagpal", "Anuj", ""], ["Shukla", "Sneha", ""], ["S", "Suyash", ""]]}, {"id": "2011.08598", "submitter": "Andrei Costin", "authors": "Tuomo Lahtinen and Lauri Sintonen and Hannu Turtiainen and Andrei\n  Costin", "title": "Feasibility Study on CCTV-aware Routing and Navigation for Privacy,\n  Anonymity, and Safety. Jyvaskyla -- Case-study of the First City to Benefit\n  from CCTV-aware Technology. (Preprint)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In order to withstand the ever-increasing invasion of privacy by CCTV cameras\nand technologies, on par CCTV-aware solutions must exist that provide privacy,\nsafety, and cybersecurity features. We argue that a first important step\ntowards such CCTV-aware solutions must be a mapping system that provides both\nprivacy and safety routing and navigation options. To the best of our\nknowledge, there are no mapping nor navigation systems that support privacy and\nsafety routing options. In this paper, we explore the feasibility of a\nCCTV-aware routing and navigation solution. The aim of this feasibility\nexploration is to understand what are the main impacts of CCTV on privacy, and\nwhat are the challenges and benefits to building such technology. We evaluate\nour approach on seven (7) pedestrian walking routes within the downtown area of\nthe city of Jyvaskyla, Finland. We first map a total of 450 CCTV cameras, and\nthen experiment with routing and navigation under several different\nconfigurations to coarsely model the possible cameras' parameters and coverage\nfrom the real-world. We report two main results. First, our preliminary\nfindings support the overall feasibility of our approach. Second, the results\nalso reveal a data-driven worrying reality for persons wishing to preserve\ntheir privacy/anonymity as their main living choice. When modelling cameras at\ntheir low performance end, a privacy-preserving route has on average a 1.5x\ndistance increase when compared to generic routing. When modelling cameras at\ntheir medium-to-high performance end, a privacy-preserving route has on average\na 5.0x distance increase, while in some cases there are no privacy-preserving\nroutes possible at all. These results further support and encourage both global\nmapping of CCTV cameras and refinements to camera modelling and underlying\ntechnology.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 12:45:40 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Lahtinen", "Tuomo", ""], ["Sintonen", "Lauri", ""], ["Turtiainen", "Hannu", ""], ["Costin", "Andrei", ""]]}, {"id": "2011.08740", "submitter": "Deeksha Arya", "authors": "Deeksha Arya (1, 2), Hiroya Maeda (2), Sanjay Kumar Ghosh (1), Durga\n  Toshniwal (1), Hiroshi Omata (2), Takehiro Kashiyama (2) and Yoshihide\n  Sekimoto (2) ((1) Indian Institute of Technology Roorkee, India, (2) The\n  University of Tokyo, Japan)", "title": "Global Road Damage Detection: State-of-the-art Solutions", "comments": "11 Pages, 2 Figures, 3 Tables", "journal-ref": null, "doi": "10.1109/BigData50022.2020.9377790", "report-no": null, "categories": "cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper summarizes the Global Road Damage Detection Challenge (GRDDC), a\nBig Data Cup organized as a part of the IEEE International Conference on Big\nData'2020. The Big Data Cup challenges involve a released dataset and a\nwell-defined problem with clear evaluation metrics. The challenges run on a\ndata competition platform that maintains a leaderboard for the participants. In\nthe presented case, the data constitute 26336 road images collected from India,\nJapan, and the Czech Republic to propose methods for automatically detecting\nroad damages in these countries. In total, 121 teams from several countries\nregistered for this competition. The submitted solutions were evaluated using\ntwo datasets test1 and test2, comprising 2,631 and 2,664 images. This paper\nencapsulates the top 12 solutions proposed by these teams. The best performing\nmodel utilizes YOLO-based ensemble learning to yield an F1 score of 0.67 on\ntest1 and 0.66 on test2. The paper concludes with a review of the facets that\nworked well for the presented challenge and those that could be improved in\nfuture challenges.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 16:19:02 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Arya", "Deeksha", ""], ["Maeda", "Hiroya", ""], ["Ghosh", "Sanjay Kumar", ""], ["Toshniwal", "Durga", ""], ["Omata", "Hiroshi", ""], ["Kashiyama", "Takehiro", ""], ["Sekimoto", "Yoshihide", ""]]}, {"id": "2011.08787", "submitter": "Jennifer Cole", "authors": "Jennifer Cole", "title": "The COVID19 infodemic. The role and place of academics in science\n  communication", "comments": "17 Pages", "journal-ref": "Global Journal of Medicine and Public Health Vol 9 Issue 2 2020", "doi": null, "report-no": "https://gjmedph.com//Uploads/VP1_COVID%2019%20Infodemic.pdf", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the COVID19 pandemic has spread across the world, a concurrent pandemic of\ninformation has spread with it. Deemed an infodemic by the World Health\nOrganization, and described as an overabundance of information, some accurate,\nsome not, that occurs during an epidemic, this proliferation of data, research\nand opinions provides both opportunities and challenges for academics.\nAcademics and scientists have a key role to play in the solutions to the\ninfodemic challenge: as educators, influences and communicators, even where\ntheir expertise and experience does not align precisely with the SARS-Cov2\nvirus and its impacts.\n  Successful communication requires a better understanding of how the public\nseeks, understands and processes scientific information, however, in order to\nmaximise the ways in which experts engage with traditional and social media and\nto make sure that such engagement does not add to confusion and misinformation\nalongside efforts to counter or challenge it. This paper will outline the key\nadvantages to be had from greater engagement with COVID19 discussions, the\npopular channels through which such discussions take place and through which\ninformation is disseminated. It also warns against the common pitfalls those\nwho choose to engage might encounter, whilst stressing that the disadvantages\nof doing so are far outweighed by the advantages such engagement offers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 17:30:10 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Cole", "Jennifer", ""]]}, {"id": "2011.09145", "submitter": "Muhammad Usama", "authors": "R. Tallal Javed, Mirza Elaaf Shuja, Muhammad Usama, Junaid Qadir,\n  Waleed Iqbal, Gareth Tyson, Ignacio Castro, and Kiran Garimella", "title": "A First Look at COVID-19 Messages on WhatsApp in Pakistan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The worldwide spread of COVID-19 has prompted extensive online discussions,\ncreating an `infodemic' on social media platforms such as WhatsApp and Twitter.\nHowever, the information shared on these platforms is prone to be unreliable\nand/or misleading. In this paper, we present the first analysis of COVID-19\ndiscourse on public WhatsApp groups from Pakistan. Building on a large scale\nannotation of thousands of messages containing text and images, we identify the\nmain categories of discussion. We focus on COVID-19 messages and understand the\ndifferent types of images/text messages being propagated. By exploring user\nbehavior related to COVID messages, we inspect how misinformation is spread.\nFinally, by quantifying the flow of information across WhatsApp and Twitter, we\nshow how information spreads across platforms and how WhatsApp acts as a source\nfor much of the information shared on Twitter.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 07:56:24 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 05:45:58 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Javed", "R. Tallal", ""], ["Shuja", "Mirza Elaaf", ""], ["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Iqbal", "Waleed", ""], ["Tyson", "Gareth", ""], ["Castro", "Ignacio", ""], ["Garimella", "Kiran", ""]]}, {"id": "2011.09285", "submitter": "Reza Fotohi", "authors": "Maryam Faraji-Biregani and Reza Fotohi", "title": "Secure communication between UAVs using a method based on smart agents\n  in unmanned aerial vehicles", "comments": "25 pages, 10 figures, 14 tables, JCR (Q2). J Supercomput (2020)", "journal-ref": null, "doi": "10.1007/s11227-020-03462-0", "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unmanned aerial vehicles (UAVs) can be deployed to monitor very large areas\nwithout the need for network infrastructure. UAVs communicate with each other\nduring flight and exchange information with each other. However, such\ncommunication poses security challenges due to its dynamic topology. To solve\nthese challenges, the proposed method uses two phases to counter malicious UAV\nattacks. In the first phase, we applied a number of rules and principles to\ndetect malicious UAVs. In this phase, we try to identify and remove malicious\nUAVs according to the behavior of UAVs in the network in order to prevent\nsending fake information to the investigating UAVs. In the second phase, a\nmobile agent based on a three-step negotiation process is used to eliminate\nmalicious UAVs. In this way, we use mobile agents to inform our normal neighbor\nUAVs so that they do not listen to the data generated by the malicious UAVs.\nTherefore, the mobile agent of each UAV uses reliable neighbors through a\nthree-step negotiation process so that they do not listen to the traffic\ngenerated by the malicious UAVs. The NS-3 simulator was used to demonstrate the\nefficiency of the SAUAV method. The proposed method is more efficient than\nCST-UAS, CS-AVN, HVCR, and BSUM-based methods in detection rate, false positive\nrate, false negative rate, packet delivery rate, and residual energy.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 10:33:39 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Faraji-Biregani", "Maryam", ""], ["Fotohi", "Reza", ""]]}, {"id": "2011.09361", "submitter": "Zina Ibrahim", "authors": "Zina M Ibrahim, Daniel Bean, Thomas Searle, Honghan Wu, Anthony Shek,\n  Zeljko Kraljevic, James Galloway, Sam Norton, James T Teo, Richard JB Dobson", "title": "A Knowledge Distillation Ensemble Framework for Predicting Short and\n  Long-term Hospitalisation Outcomes from Electronic Health Records Data", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to perform accurate prognosis of patients is crucial for\nproactive clinical decision making, informed resource management and\npersonalised care. Existing outcome prediction models suffer from a low recall\nof infrequent positive outcomes. We present a highly-scalable and robust\nmachine learning framework to automatically predict adversity represented by\nmortality and ICU admission from time-series vital signs and laboratory results\nobtained within the first 24 hours of hospital admission. The stacked platform\ncomprises two components: a) an unsupervised LSTM Autoencoder that learns an\noptimal representation of the time-series, using it to differentiate the less\nfrequent patterns which conclude with an adverse event from the majority\npatterns that do not, and b) a gradient boosting model, which relies on the\nconstructed representation to refine prediction, incorporating static features\nof demographics, admission details and clinical summaries. The model is used to\nassess a patient's risk of adversity over time and provides visual\njustifications of its prediction based on the patient's static features and\ndynamic signals. Results of three case studies for predicting mortality and ICU\nadmission show that the model outperforms all existing outcome prediction\nmodels, achieving PR-AUC of 0.891 (95$%$ CI: 0.878 - 0.969) in predicting\nmortality in ICU and general ward settings and 0.908 (95$%$ CI: 0.870-0.935) in\npredicting ICU admission.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 15:56:28 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 12:10:29 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ibrahim", "Zina M", ""], ["Bean", "Daniel", ""], ["Searle", "Thomas", ""], ["Wu", "Honghan", ""], ["Shek", "Anthony", ""], ["Kraljevic", "Zeljko", ""], ["Galloway", "James", ""], ["Norton", "Sam", ""], ["Teo", "James T", ""], ["Dobson", "Richard JB", ""]]}, {"id": "2011.09504", "submitter": "Amariah Becker", "authors": "Amariah Becker and Justin Solomon", "title": "Redistricting Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why not have a computer just draw a map? This is something you hear a lot\nwhen people talk about gerrymandering, and it's easy to think at first that\nthis could solve redistricting altogether. But there are more than a couple\nproblems with this idea. In this chapter, two computer scientists survey what's\nbeen done in algorithmic redistricting, discuss what doesn't work and highlight\napproaches that show promise. This preprint was prepared as a chapter in the\nforthcoming edited volume Political Geometry, an interdisciplinary collection\nof essays on redistricting. (https://mggg.org/gerrybook)\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 19:19:20 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Becker", "Amariah", ""], ["Solomon", "Justin", ""]]}, {"id": "2011.09536", "submitter": "Asadullah Hill Galib", "authors": "Asadullah Hill Galib, Nadia Nahar, and B M Mainul Hossain", "title": "The Influences of Pre-birth Factors in Early Assessment of Child\n  Mortality using Machine Learning Techniques", "comments": "21 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of child mortality is crucial as it pertains to the policy and\nprograms of a country. The early assessment of patterns and trends in causes of\nchild mortality help decision-makers assess needs, prioritize interventions,\nand monitor progress. Post-birth factors of the child, such as real-time\nclinical data, health data of the child, etc. are frequently used in child\nmortality studies. However, in the early assessment of child mortality,\npre-birth factors would be more practical and beneficial than the post-birth\nfactors. This study aims at incorporating pre-birth factors, such as birth\nhistory, maternal history, reproduction history, socioeconomic condition, etc.\nfor classifying child mortality. To assess the relative importance of the\nfeatures, Information Gain (IG) attribute evaluator is employed. For\nclassifying child mortality, four machine learning algorithms are evaluated.\nResults show that the proposed approach achieved an AUC score of 0.947 in\nclassifying child mortality which outperformed the clinical standards. In terms\nof accuracy, precision, recall, and f-1 score, the results are also notable and\nuniform. In developing countries like Bangladesh, the early assessment of child\nmortality using pre-birth factors would be effective and feasible as it avoids\nthe uncertainty of the post-birth factors.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 20:37:55 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Galib", "Asadullah Hill", ""], ["Nahar", "Nadia", ""], ["Hossain", "B M Mainul", ""]]}, {"id": "2011.09794", "submitter": "Yi-Jheng Lin", "authors": "Yi-Jheng Lin, Che-Hao Yu, Tzu-Hsuan Liu, Cheng-Shang Chang, and\n  Wen-Tsuen Chen", "title": "Positively Correlated Samples Save Pooled Testing Costs", "comments": "14 pages, 8 figures, submitted for publication", "journal-ref": null, "doi": "10.1109/TNSE.2021.3081759", "report-no": null, "categories": "stat.ME cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The group testing approach that achieves significant cost reduction over the\nindividual testing approach has received a lot of interest lately for massive\ntesting of COVID-19. Many studies simply assume samples mixed in a group are\nindependent. However, this assumption may not be reasonable for a contagious\ndisease like COVID-19. Specifically, people within a family tend to infect each\nother and thus are likely to be positively correlated. By exploiting positive\ncorrelation, we make the following two main contributions. One is to provide a\nrigorous proof that further cost reduction can be achieved by using the Dorfman\ntwo-stage method when samples within a group are positively correlated. The\nother is to propose a hierarchical agglomerative algorithm for pooled testing\nwith a social graph, where an edge in the social graph connects frequent social\ncontacts between two persons. Such an algorithm leads to notable cost reduction\n(roughly 20%-35%) compared to random pooling when the Dorfman two-stage\nalgorithm is applied.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 12:39:54 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 07:58:32 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Lin", "Yi-Jheng", ""], ["Yu", "Che-Hao", ""], ["Liu", "Tzu-Hsuan", ""], ["Chang", "Cheng-Shang", ""], ["Chen", "Wen-Tsuen", ""]]}, {"id": "2011.09838", "submitter": "Matthew Norris", "authors": "Matthew Norris", "title": "Using Ordinal Data to Assess Distance Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is some disagreement on whether Likert scale data should be treated as\nordinal or continuous. This paper treats Likert data as ordinal, uses\nnon-parametric hypothesis testing, and clustering to validate those variables\nthat have significant results from hypothesis testing.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 02:08:28 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Norris", "Matthew", ""]]}, {"id": "2011.09840", "submitter": "Sachithra Lokuge", "authors": "Sachithra Lokuge and Maduka Subasinghage", "title": "Knowledge Management Competence and ISD Vendor Innovativeness in\n  Turbulent Markets", "comments": "Australasian Conference on Information Systems, 2020, Wellington", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous changes in the technology and the business landscape place high\nstrain on managing knowledge in organisations. Prior researchers highlight a\npositive connotation with knowledge management competence and organisational\ninnovativeness in a turbulent environment. However, the rapid changes in the\nmarket and technology landscape may exert an additional pressure on the\nemployees and such pressures may ultimately hinder organisational\ninnovativeness. Drawing on knowledge management and innovation literature, this\nresearch conceptualises a model that investigates this tenacious relationship\nbetween knowledge management competence and innovativeness specifically in\nturbulent dynamic markets, considering information systems development\n(ISD)-outsourcing as the context. Following a mixed method approach, this\nresearch expects to provide guidance for ISD-outsourcing vendors to manage\ninnovation expectations, knowledge management process and performance of the\nemployees in dynamic market conditions.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 01:07:30 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Lokuge", "Sachithra", ""], ["Subasinghage", "Maduka", ""]]}, {"id": "2011.09848", "submitter": "Pablo Moreno-Munoz", "authors": "Pablo Moreno-Mu\\~noz, Lorena Romero-Medrano, \\'Angela Moreno, Jes\\'us\n  Herrera-L\\'opez, Enrique Baca-Garc\\'ia and Antonio Art\\'es-Rodr\\'iguez", "title": "Passive detection of behavioral shifts for suicide attempt prevention", "comments": "Machine Learning for Mobile Health Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  More than one million people commit suicide every year worldwide. The costs\nof daily cares, social stigma and treatment issues are still hard barriers to\novercome in mental health. Most symptoms of mental disorders are related to the\nbehavioral state of a patient, such as the mobility or social activity.\nMobile-based technologies allow the passive collection of patients data, which\nsupplements conventional assessments that rely on biased questionnaires and\noccasional medical appointments. In this work, we present a non-invasive\nmachine learning (ML) model to detect behavioral shifts in psychiatric patients\nfrom unobtrusive data collected by a smartphone app. Our clinically validated\nresults shed light on the idea of an early detection mobile tool for the task\nof suicide attempt prevention.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 11:44:43 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Moreno-Mu\u00f1oz", "Pablo", ""], ["Romero-Medrano", "Lorena", ""], ["Moreno", "\u00c1ngela", ""], ["Herrera-L\u00f3pez", "Jes\u00fas", ""], ["Baca-Garc\u00eda", "Enrique", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "2011.09851", "submitter": "Daniel Oberski", "authors": "Laura Boeschoten and Jef Ausloos and Judith Moeller and Theo Araujo\n  and Daniel L. Oberski", "title": "Digital trace data collection through data donation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A potentially powerful method of social-scientific data collection and\ninvestigation has been created by an unexpected institution: the law. Article\n15 of the EU's 2018 General Data Protection Regulation (GDPR) mandates that\nindividuals have electronic access to a copy of their personal data, and all\nmajor digital platforms now comply with this law by providing users with \"data\ndownload packages\" (DDPs). Through voluntary donation of DDPs, all data\ncollected by public and private entities during the course of citizens' digital\nlife can be obtained and analyzed to answer social-scientific questions - with\nconsent. Thus, consented DDPs open the way for vast new research opportunities.\nHowever, while this entirely new method of data collection will undoubtedly\ngain popularity in the coming years, it also comes with its own questions of\nrepresentativeness and measurement quality, which are often evaluated\nsystematically by means of an error framework. Therefore, in this paper we\nprovide a blueprint for digital trace data collection using DDPs, and devise a\n\"total error framework\" for such projects. Our error framework for digital\ntrace data collection through data donation is intended to facilitate high\nquality social-scientific investigations using DDPs while critically reflecting\nits unique methodological challenges and sources of error. In addition, we\nprovide a quality control checklist to guide researchers in leveraging the vast\nopportunities afforded by this new mode of investigation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 11:19:25 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Boeschoten", "Laura", ""], ["Ausloos", "Jef", ""], ["Moeller", "Judith", ""], ["Araujo", "Theo", ""], ["Oberski", "Daniel L.", ""]]}, {"id": "2011.09861", "submitter": "Stefano Balietti", "authors": "Stefano Balietti", "title": "The human quest for discovering mathematical beauty in the arts", "comments": "5 pages, 1 figure", "journal-ref": "Proceedings of the National Academy of Sciences (PNAS), 117(44),\n  pp. 27073-27075 (2020)", "doi": "10.1073/pnas.2018652117", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the words of the twentieth-century British mathematician G. H. Hardy, \"the\nhuman function is to 'discover or observe' mathematics\" (1). For centuries,\nstarting from the ancient Greeks, mankind has hunted for beauty and order in\narts and in nature. This quest for mathematical beauty has led to the discovery\nof recurrent mathematical structures, such as the golden ratio, Fibonacci, and\nLucas numbers, whose ubiquitous presences have been tantalizing the minds of\nartists and scientists alike. The captivation for this quest comes with high\nstakes. In fact, art is the definitive expression of human creativity, and its\nmathematical understanding would deliver us the keys for decoding human culture\nand its evolution (2). However, it was not until fairly recently that the scope\nand the scale of the human quest for mathematical beauty was radically expanded\nby the simultaneous confluence of three separate innovations. The mass\ndigitization of large art archives, the surge in computational power, and the\ndevelopment of robust statistical methods to capture hidden patterns in vast\namounts of data have made it possible to reveal the---otherwise unnoticeable to\nthe human eye---mathematics concealed in large artistic corpora. Starting from\nits inception, marked by the foundational work by Birkhoff (3), progress in the\nbroad field of computational aesthetics has reached a scale that would have\nbeen unimaginable just a decade ago. The recent expansion is not limited to the\nvisual arts (2) but includes music (4), stories (5), language phonology (6),\nhumor in jokes (7), and even equations (8); for a comprehensive review, see\nref. 9.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 10:45:29 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Balietti", "Stefano", ""]]}, {"id": "2011.09865", "submitter": "Ramon Vilarino", "authors": "Ramon Vilarino, Renato Vicente", "title": "Dissecting Racial Bias in a Credit Scoring System Experimentally\n  Developed for the Brazilian Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We dissect an experimental credit scoring model developed with real data and\ndemonstrate -- without having access to protected attributes -- how the use of\nlocation information introduces racial bias. We analyze the tree gradient\nboosting model with the aid of a game-theoretic ML explainability technique,\ncounterfactual experiments and Brazilian census data. The present experiment\ntestifies to the importance of developing methods and language that goes beyond\nthe need of access to protected attributes when auditing ML models, the\nnecessity of considering regional specifics when reflecting on racial issues,\nand the importance of census data to the AI research community. To the best of\nour knowledge, this is the first documented case of how algorithmic racial bias\nmay easily emerge in a ML credit scoring model built with Brazilian data, a\ncountry with the largest Black population outside Africa.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 02:14:32 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:56:09 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Vilarino", "Ramon", ""], ["Vicente", "Renato", ""]]}, {"id": "2011.09867", "submitter": "Hanshuang Tong", "authors": "Hanshuang Tong, Yun Zhou and Zhen Wang", "title": "Exercise Hierarchical Feature Enhanced Knowledge Tracing", "comments": "5 pages, 4 figures, Accepted by AIED 2020. In the 21st International\n  Conference on Artificial Intelligence in Education (AIED 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-52240-7_59", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing is a fundamental task in the computer-aid educational\nsystem. In this paper, we propose a hierarchical exercise feature enhanced\nknowledge tracing framework, which could enhance the ability of knowledge\ntracing by incorporating knowledge distribution, semantic features, and\ndifficulty features from exercise text. Extensive experiments show the high\nperformance of our framework.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2020 12:16:07 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Tong", "Hanshuang", ""], ["Zhou", "Yun", ""], ["Wang", "Zhen", ""]]}, {"id": "2011.10144", "submitter": "Johanna Einsiedler", "authors": "Johanna Einsiedler, Yun Cheng, Franz Papst, Olga Saukh", "title": "Interpretable and Transferable Models to Understand the Impact of\n  Lockdown Measures on Local Air Quality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 related lockdown measures offer a unique opportunity to\nunderstand how changes in economic activity and traffic affect ambient air\nquality and how much pollution reduction potential can the society offer\nthrough digitalization and mobilitylimiting policies. In this work, we estimate\npollution reduction over the lockdown period by using the measurements from\nground air pollution monitoring stations, training a long-term prediction model\nand comparing its predictions to measured values over the lockdown month.We\nshow that our models achieve state-of-the-art performance on the data from air\npollution measurement stations in Switzerland and in China: evaluate up to\n-15.8% / +34.4% change in NO2 / PM10 in Zurich; -35.3 % / -3.5 % and -42.4 % /\n-34.7 % in NO2 / PM2.5 in Beijing and Wuhan respectively. Our reduction\nestimates are consistent with recent publications, yet in contrast to prior\nworks, our method takes local weather into account. What can we learn from\npollution emissions during lockdown? The lockdown period was too short to train\nmeaningful models from scratch. To tackle this problem, we use transfer\nlearning to newly fit only traffic-dependent variables. We show that the\nresulting models are accurate, suitable for an analysis of the post-lockdown\nperiod and capable of estimating the future air pollution reduction potential.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 23:09:30 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 08:59:34 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Einsiedler", "Johanna", ""], ["Cheng", "Yun", ""], ["Papst", "Franz", ""], ["Saukh", "Olga", ""]]}, {"id": "2011.10264", "submitter": "Veronica Sanz", "authors": "Miguel G. Folgado and Ver\\'onica Sanz", "title": "Exploring the political pulse of a country using data science tools", "comments": "7 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we illustrate the use of Data Science techniques to analyse\ncomplex human communication. In particular, we consider tweets from leaders of\npolitical parties as a dynamical proxy to political programmes and ideas. We\nalso study the temporal evolution of their contents as a reaction to specific\nevents. We analyse levels of positive and negative sentiment in the tweets\nusing new tools adapted to social media. We also train an Artificial\nIntelligence to recognise the political affiliation of a tweet. The AI is able\nto predict the origin of the tweet with a precision in the range of 71-75\\%,\nand the political leaning (left or right) with a precision of around 90\\%. This\nstudy is meant to be viewed as a proof-of-concept of interdisciplinary nature,\nat the interface between Data Science and political analysis.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:17:12 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Folgado", "Miguel G.", ""], ["Sanz", "Ver\u00f3nica", ""]]}, {"id": "2011.10265", "submitter": "Rex Bringula", "authors": "Rex Bringula, Kristian Paul M. Lugtu, Mark Anthony D. Uy, Ariel Aviles", "title": "How do you feel: Emotions exhibited while Playing Computer Games and\n  their Relationship with Gaming Behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This descriptive study utilized a validated questionnaire to determine the\nemotions exhibited by computer gamers in cyber caf\\'es. It was revealed that\nmost of the gamers were young, male, single, as well as high school and\nvocational students who belonged to middle-income families. Most of them had\ncomputer access at home but only a few had Internet access at home. Gamers\ntended to play games in cyber caf\\'es at least three times a week, usually in\nthe evening, for at least two hours per visit. They also reported that they\nplayed games frequently. Majority of the gamers were fond of playing DOTA,\nLeague of Legends, and CABAL and they had been playing games for at least two\nyears. It was disclosed that they exhibited both positive and negative emotions\nwhile playing games. It was shown that gamers were inclined to be more anxious\nto be defeated in a game as gaming became frequent and length of years in\nplaying games increased. They also had the tendency to become more stressed\nwhen length of years of playing games increased. On the other hand, other\ngaming behaviors were not significantly related to other emotions. Thus, the\nnull hypothesis stating that gaming behaviors of the respondents are not\nsignificantly related to the emotions exhibited while playing the computer\ngames is partially rejected. Therefore, not all emotions exhibited while\nplaying computer games could be attributed to their gaming behaviors. It is\nrecommended that other emotions such as anger, frustration, boredom, amusement,\netc. be included in future research.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 08:18:38 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Bringula", "Rex", ""], ["Lugtu", "Kristian Paul M.", ""], ["Uy", "Mark Anthony D.", ""], ["Aviles", "Ariel", ""]]}, {"id": "2011.10369", "submitter": "Fanchao Qi", "authors": "Fanchao Qi, Yangyi Chen, Mukai Li, Zhiyuan Liu, Maosong Sun", "title": "ONION: A Simple and Effective Defense Against Textual Backdoor Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backdoor attacks, which are a kind of emergent training-time threat to deep\nneural networks (DNNS). They can manipulate the output of DNNs and posses high\ninsidiousness. In the field of natural language processing, some attack methods\nhave been proposed and achieve very high attack success rates on multiple\npopular models. Nevertheless, the studies on defending textual backdoor defense\nare little conducted. In this paper, we propose a simple and effective textual\nbackdoor defense named ONION, which is based on outlier word detection and\nmight be the first method that can handle all the attack situations.\nExperiments demonstrate the effectiveness of our model when blocking two latest\nbackdoor attack methods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 12:17:21 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Qi", "Fanchao", ""], ["Chen", "Yangyi", ""], ["Li", "Mukai", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "2011.10470", "submitter": "Milad Asgari Mehrabadi", "authors": "Milad Asgari Mehrabadi, Seyed Amir Hossein Aqajari, Iman Azimi,\n  Charles A Downs, Nikil Dutt and Amir M Rahmani", "title": "Detection of COVID-19 Using Heart Rate and Blood Pressure: Lessons\n  Learned from Patients with ARDS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world has been affected by COVID-19 coronavirus. At the time of this\nstudy, the number of infected people in the United States is the highest\nglobally (7.9 million infections). Within the infected population, patients\ndiagnosed with acute respiratory distress syndrome (ARDS) are in more\nlife-threatening circumstances, resulting in severe respiratory system failure.\nVarious studies have investigated the infections to COVID-19 and ARDS by\nmonitoring laboratory metrics and symptoms. Unfortunately, these methods are\nmerely limited to clinical settings, and symptom-based methods are shown to be\nineffective. In contrast, vital signs (e.g., heart rate) have been utilized to\nearly-detect different respiratory diseases in ubiquitous health monitoring. We\nposit that such biomarkers are informative in identifying ARDS patients\ninfected with COVID-19. In this study, we investigate the behavior of COVID-19\non ARDS patients by utilizing simple vital signs. We analyze the long-term\ndaily logs of blood pressure and heart rate associated with 70 ARDS patients\nadmitted to five University of California academic health centers (containing\n42506 samples for each vital sign) to distinguish subjects with COVID-19\npositive and negative test results. In addition to the statistical analysis, we\ndevelop a deep neural network model to extract features from the longitudinal\ndata. Using only the first eight days of the data, our deep learning model is\nable to achieve 78.79% accuracy to classify the vital signs of ARDS patients\ninfected with COVID-19 versus other ARDS diagnosed patients.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 19:56:27 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Mehrabadi", "Milad Asgari", ""], ["Aqajari", "Seyed Amir Hossein", ""], ["Azimi", "Iman", ""], ["Downs", "Charles A", ""], ["Dutt", "Nikil", ""], ["Rahmani", "Amir M", ""]]}, {"id": "2011.10482", "submitter": "Giuseppe Fenza", "authors": "Alfonso Di Pace and Giuseppe Fenza and Mariacristina Gallo and\n  Vincenzo Loia and Aldo Meglio and Francesco Orciuoli", "title": "Implementing the Cognition Level for Industry 4.0 by integrating\n  Augmented Reality and Manufacturing Execution Systems", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-44041-1_83", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the current industrial practices, the exponential growth in terms of\navailability and affordability of sensors, data acquisition systems, and\ncomputer networks forces factories to move toward implementing high integrating\nCyber-Physical Systems (CPS) with production, logistics, and services. This\ntransforms today's factories into Industry 4.0 factories with significant\neconomic potential. Industry 4.0, also known as the fourth Industrial\nRevolution, levers on the integration of cyber technologies, the Internet of\nThings, and Services. This paper proposes an Augmented Reality (AR)-based\nsystem that creates a Cognition Level that integrates existent Manufacturing\nExecution Systems (MES) to CPS. The idea is to highlight the opportunities\noffered by AR technologies to CPS by describing an application scenario. The\nsystem, analyzed in a real factory, shows its capacity to integrate physical\nand digital worlds strongly. Furthermore, the conducted survey (based on the\nSituation Awareness Global Assessment Technique method) reveals significant\nadvantages in terms of production monitoring, progress, and workers' Situation\nAwareness in general.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 21:53:13 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Di Pace", "Alfonso", ""], ["Fenza", "Giuseppe", ""], ["Gallo", "Mariacristina", ""], ["Loia", "Vincenzo", ""], ["Meglio", "Aldo", ""], ["Orciuoli", "Francesco", ""]]}, {"id": "2011.10518", "submitter": "Amanuel Alambo", "authors": "Amanuel Alambo, Swati Padhee, Tanvi Banerjee, and Krishnaprasad\n  Thirunarayan", "title": "COVID-19 and Mental Health/Substance Use Disorders on Reddit: A\n  Longitudinal Study", "comments": "First workshop on computational & affective intelligence in\n  healthcare applications in conjunction with ICPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 pandemic has adversely and disproportionately impacted people\nsuffering from mental health issues and substance use problems. This has been\nexacerbated by social isolation during the pandemic and the social stigma\nassociated with mental health and substance use disorders, making people\nreluctant to share their struggles and seek help. Due to the anonymity and\nprivacy they provide, social media emerged as a convenient medium for people to\nshare their experiences about their day to day struggles. Reddit is a\nwell-recognized social media platform that provides focused and structured\nforums called subreddits, that users subscribe to and discuss their experiences\nwith others. Temporal assessment of the topical correlation between social\nmedia postings about mental health/substance use and postings about Coronavirus\nis crucial to better understand public sentiment on the pandemic and its\nevolving impact, especially related to vulnerable populations. In this study,\nwe conduct a longitudinal topical analysis of postings between subreddits\nr/depression, r/Anxiety, r/SuicideWatch, and r/Coronavirus, and postings\nbetween subreddits r/opiates, r/OpiatesRecovery, r/addiction, and r/Coronavirus\nfrom January 2020 - October 2020. Our results show a high topical correlation\nbetween postings in r/depression and r/Coronavirus in September 2020. Further,\nthe topical correlation between postings on substance use disorders and\nCoronavirus fluctuates, showing the highest correlation in August 2020. By\nmonitoring these trends from platforms such as Reddit, epidemiologists, and\nmental health professionals can gain insights into the challenges faced by\ncommunities for targeted interventions.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 17:23:49 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Alambo", "Amanuel", ""], ["Padhee", "Swati", ""], ["Banerjee", "Tanvi", ""], ["Thirunarayan", "Krishnaprasad", ""]]}, {"id": "2011.10653", "submitter": "Abe Leite", "authors": "Abe Leite and Sa\\'ul A. Blanco", "title": "Effects of Human vs. Automatic Feedback on Students' Understanding of AI\n  Concepts and Programming Style", "comments": "Published in SIGCSE '20: Proceedings of the 51st ACM Technical\n  Symposium on Computer Science Education", "journal-ref": "SIGCSE '20: Proceedings of the 51st ACM Technical Symposium on\n  Computer Science Education (Feb 2020) 44-50", "doi": "10.1145/3328778.3366921", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of automatic grading tools has become nearly ubiquitous in large\nundergraduate programming courses, and recent work has focused on improving the\nquality of automatically generated feedback. However, there is a relative lack\nof data directly comparing student outcomes when receiving computer-generated\nfeedback and human-written feedback. This paper addresses this gap by splitting\none 90-student class into two feedback groups and analyzing differences in the\ntwo cohorts' performance. The class is an intro to AI with programming HW\nassignments. One group of students received detailed computer-generated\nfeedback on their programming assignments describing which parts of the\nalgorithms' logic was missing; the other group additionally received\nhuman-written feedback describing how their programs' syntax relates to issues\nwith their logic, and qualitative (style) recommendations for improving their\ncode. Results on quizzes and exam questions suggest that human feedback helps\nstudents obtain a better conceptual understanding, but analyses found no\ndifference between the groups' ability to collaborate on the final project. The\ncourse grade distribution revealed that students who received human-written\nfeedback performed better overall; this effect was the most pronounced in the\nmiddle two quartiles of each group. These results suggest that feedback about\nthe syntax-logic relation may be a primary mechanism by which human feedback\nimproves student outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 21:40:32 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Leite", "Abe", ""], ["Blanco", "Sa\u00fal A.", ""]]}, {"id": "2011.10660", "submitter": "Uwe Aickelin", "authors": "Chris Roadknight, Prapa Rattadilok, Uwe Aickelin", "title": "Teaching Key Machine Learning Principles Using Anti-learning Datasets", "comments": "2018 IEEE International Conference on Teaching, Assessment, and\n  Learning for Engineering (TALE), Pages 960-964", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much of the teaching of machine learning focuses on iterative hill-climbing\napproaches and the use of local knowledge to gain information leading to local\nor global maxima. In this paper we advocate the teaching of alternative methods\nof generalising to the best possible solution, including a method called\nanti-learning. By using simple teaching methods, students can achieve a deeper\nunderstanding of the importance of validation on data excluded from the\ntraining process and that each problem requires its own methods to solve. We\nalso exemplify the requirement to train a model using sufficient data by\nshowing that different granularities of cross-validation can yield very\ndifferent results.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 05:43:40 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Roadknight", "Chris", ""], ["Rattadilok", "Prapa", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2011.10666", "submitter": "Lily Xu", "authors": "Rachel Guo, Lily Xu, Drew Cronin, Francis Okeke, Andrew Plumptre,\n  Milind Tambe", "title": "Enhancing Poaching Predictions for Under-Resourced Wildlife Conservation\n  Parks Using Remote Sensing Imagery", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World. 4 pages, 1 page references. 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Illegal wildlife poaching is driving the loss of biodiversity. To combat\npoaching, rangers patrol expansive protected areas for illegal poaching\nactivity. However, rangers often cannot comprehensively search such large\nparks. Thus, the Protection Assistant for Wildlife Security (PAWS) was\nintroduced as a machine learning approach to help identify the areas with\nhighest poaching risk. As PAWS is deployed to parks around the world, we\nrecognized that many parks have limited resources for data collection and\ntherefore have scarce feature sets. To ensure under-resourced parks have access\nto meaningful poaching predictions, we introduce the use of publicly available\nremote sensing data to extract features for parks. By employing this data from\nGoogle Earth Engine, we also incorporate previously unavailable dynamic data to\nenrich predictions with seasonal trends. We automate the entire\ndata-to-deployment pipeline and find that, with only using publicly available\ndata, we recuperate prediction performance comparable to predictions made using\nfeatures manually computed by park specialists. We conclude that the inclusion\nof satellite imagery creates a robust system through which parks of any\nresource level can benefit from poaching risks for years to come.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 22:06:57 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Guo", "Rachel", ""], ["Xu", "Lily", ""], ["Cronin", "Drew", ""], ["Okeke", "Francis", ""], ["Plumptre", "Andrew", ""], ["Tambe", "Milind", ""]]}, {"id": "2011.10754", "submitter": "Libu\\v{s}e Hannah Vep\\v{r}ek", "authors": "Libu\\v{s}e Hannah Vep\\v{r}ek, Patricia Seymour, Pietro Michelucci", "title": "Human computation requires and enables a new approach to ethical review", "comments": "8 pages, 4 figures. This is a pre-publication draft submitted to 34th\n  Conference on Neural Information Processing Systems (NeurIPS 2020),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With humans increasingly serving as computational elements in distributed\ninformation processing systems and in consideration of the profit-driven\nmotives and potential inequities that might accompany the emerging thinking\neconomy[1], we recognize the need for establishing a set of related ethics to\nensure the fair treatment and wellbeing of online cognitive laborers and the\nconscientious use of the capabilities to which they contribute. Toward this\nend, we first describe human-in-the-loop computing in context of the new\nconcerns it raises that are not addressed by traditional ethical research\nstandards. We then describe shortcomings in the traditional approach to ethical\nreview and introduce a dynamic approach for sustaining an ethical framework\nthat can continue to evolve within the rapidly shifting context of disruptive\nnew technologies.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 09:44:29 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Vep\u0159ek", "Libu\u0161e Hannah", ""], ["Seymour", "Patricia", ""], ["Michelucci", "Pietro", ""]]}, {"id": "2011.11024", "submitter": "Antonela Tommasel", "authors": "Antonela Tommasel, Daniela Godoy, Juan Manuel Rodriguez", "title": "Tracking the evolution of crisis processes and mental health on social\n  media during the COVID-19 pandemic", "comments": "25 pages, 6 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The COVID-19 pandemic has affected all aspects of society, not only bringing\nhealth hazards, but also posing challenges to public order, governments and\nmental health. Moreover, it is the first one in history in which people from\naround the world uses social media to massively express their thoughts and\nconcerns. This study aims at examining the stages of crisis response and\nrecovery as a sociological problem by operationalizing a well-known model of\ncrisis stages in terms of a psycho-linguistic analysis. Based on a large\ncollection of Twitter data spanning from March to August 2020 in Argentina, we\npresent a thematic analysis on the differences in language used in social media\nposts, and look at indicators that reveal the different stages of a crisis and\nthe country response thereof. The analysis was combined with a study of the\ntemporal prevalence of mental health conversations across the time span. Beyond\nthe Argentinian case-study, the proposed approach and analyses can be applied\nto any public large-scale data. This approach can provide insights for the\ndesign of public health politics oriented to monitor and eventually intervene\nduring the different stages of a crisis, and thus improve the adverse mental\nhealth effects on the population.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 14:30:09 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Tommasel", "Antonela", ""], ["Godoy", "Daniela", ""], ["Rodriguez", "Juan Manuel", ""]]}, {"id": "2011.11033", "submitter": "Rex Bringula", "authors": "Rex Bringula, Ma. Carmela Racelis, Rey C. Rodrigueza", "title": "Who's Who in the Information Technology Research in the Philippines A\n  Social Network Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study reported the conference papers presented conducted by the two\ncomputing societies in the Philippines. Toward this goal, all published\nconference proceedings from the National Conference of IT Education and\nPhilippine Computing Society Conference were gathered and analyzed using social\nnetwork analysis. The findings of the study disclosed that there are 733 papers\npresented in the conference for the span of 18 years. On the average, both\nconferences had 27 papers presented annually. Private higher education\ninstitutions dominated the list of research productive schools where De La\nSalle University tops the list. A researcher in the University of the\nPhilippines-Diliman is the most prolific researcher with 39 publications and\n\"algorithm\" was the most researched topic. Researchers tend to work in small\nteam consisting of 2 to 3 members. Implications and limitations of the study\nare also presented.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 15:02:12 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bringula", "Rex", ""], ["Racelis", "Ma. Carmela", ""], ["Rodrigueza", "Rey C.", ""]]}, {"id": "2011.11035", "submitter": "Rex Bringula", "authors": "Rex P. Bringula", "title": "Development of Rubrics for Capstone Project Courses: Perspectives from\n  Teachers and Students", "comments": null, "journal-ref": "WCCCE 2015", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study attempted to develop fair, relevant, and content-valid assessment\ntools for capstone project courses. Toward this goal, new rating instruments\nbased on the concept of rubrics were proposed. To ensure that the new\ninstruments were valid and fair, several meetings with faculty and students of\nthe computing science departments (i.e., Computer Science and Information\nTechnology) were successively conducted. Eight faculty members and 10 students\nparticipated in the study. The final versions of the instruments were completed\nafter a series of careful deliberations with faculty and students. Faculty and\nstudents perceived the new instruments fairer than the previous ones. Since the\nfinal instruments will be deployed this semester, their strengths and\nweaknesses are not yet known at this time. Directions for future research are\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 15:06:46 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Bringula", "Rex P.", ""]]}, {"id": "2011.11095", "submitter": "Gevorg Yeghikyan", "authors": "Gevorg Yeghikyan", "title": "How will AI and automation transform society and cities?", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Against the backdrop of rising anxiety and discussions on the impact of AI on\nsociety, I explore in this article the structural possibilities of AI and\nautomation triggering a new social conflict between the current capitalist\nelites and the emerging \"creative class\" (R&D scientists, engineers, business\ndevelopers, etc.), and how this conflict can produce social tensions and\ntransform urban space. By drawing insights from a structurally similar conflict\nin 17-18th century Europe between the aristocracy and the emerging bourgeoisie,\nthe impact of this conflict on the social, spatial, and power landscapes in\ncities of that time, as well as current trends in urban geography, this article\noutlines the prospects of urban transformations under changing production and\nconsumption economies.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 19:44:51 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yeghikyan", "Gevorg", ""]]}, {"id": "2011.11112", "submitter": "Shadrack Awah Buo", "authors": "Shadrack Awah Buo", "title": "An application of cyberpsychology in business email compromise", "comments": "11 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Business Email Compromise (BEC) and why it is becoming\na major issue to businesses worldwide. It also presents a case study of a BEC\nincident against Unatrac Holding Ltd and analyses the techniques used by the\ncybercriminals to defraud the company. A critical analysis of the psychological\nand sociotechnical impacts of BEC to both the company and employees are\nconducted, and potential risk mitigations strategies and recommendations are\nprovided to prevent future attacks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 21:31:51 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 09:53:57 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Buo", "Shadrack Awah", ""]]}, {"id": "2011.11384", "submitter": "Shenghuan Yang", "authors": "Guangxin He, Shenghuan Yang, Miaomiao Lei, Xing Wu, Yixin Sun, Yimeng\n  Dang", "title": "Influence of Murder Incident of Ride-hailing Drivers on Ride-hailing\n  User's Consuming Willingness in Nanchang", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the frequent murder incidents of ride-hailing drivers in China in\n2018, ride-hailing companies took a series of measures to prevent such\nincidents and ensure ride-hailing passengers' safety. This study investigated\nusers' willingness to use ride-hailing apps after murder incidents and users'\nattitudes toward Safety Rectification. We found that murder incidents of\nride-hailing drivers had a significant adverse impact on people's usage of\nride-hailing apps. Female users' consuming willingness was 0.633 times that of\nmale users, such as\" psychological harm\" was more evident among females, and\nSafety Rectification had a calming effect for some users. Finally, we found\nthat people were satisfied with ride-hailing apps' efficiency, but were not\nsatisfied with safety and reliability, considered them important; female users\nwere more concerned about the security than male users.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 05:49:24 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 08:01:49 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["He", "Guangxin", ""], ["Yang", "Shenghuan", ""], ["Lei", "Miaomiao", ""], ["Wu", "Xing", ""], ["Sun", "Yixin", ""], ["Dang", "Yimeng", ""]]}, {"id": "2011.11393", "submitter": "Hang Yuan", "authors": "Hang Yuan, Claudia Vanea, Federica Lucivero, Nina Hallowell", "title": "Training Ethically Responsible AI Researchers: a Case Study", "comments": "First two authors contributed equally. Part of the Navigating the\n  Broader Impacts of AI Research Workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ethical oversight of AI research is beset by a number of problems. There are\nnumerous ways to tackle these problems, however, they leave full responsibility\nfor ethical reflection in the hands of review boards and committees. In this\npaper, we propose an alternative solution: the training of ethically\nresponsible AI researchers. We showcase this solution through a case study of a\ncentre for doctoral training and outline how ethics training is structured in\nthe program. We go on to present two second-year students' reflections on their\ntraining which demonstrates some of their newly found capabilities as ethically\nresponsible researchers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 14:12:50 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Yuan", "Hang", ""], ["Vanea", "Claudia", ""], ["Lucivero", "Federica", ""], ["Hallowell", "Nina", ""]]}, {"id": "2011.11483", "submitter": "Vik Shirvaikar", "authors": "Vik Shirvaikar and Choudur Lakshminarayan", "title": "Social Determinants of Recidivism: A Machine Learning Solution", "comments": "12 main pages, 5 appendix pages, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In criminal justice analytics, the widely-studied problem of recidivism\nprediction (forecasting re-offenses after release or parole) is fraught with\nethical missteps. In particular, Machine Learning (ML) models rely on\nhistorical patterns of behavior to predict future outcomes, engendering a\nvicious feedback loop of recidivism and incarceration. This paper repurposes ML\nto instead identify social factors that can serve as levers to prevent\nrecidivism. Our contributions are along three dimensions. (1) Recidivism models\ntypically agglomerate individuals into one dataset, but we invoke unsupervised\nlearning to extract homogeneous subgroups with similar features. (2) We then\napply subgroup-level supervised learning to determine factors correlated to\nrecidivism. (3) We therefore shift the focus from predicting which individuals\nwill re-offend to identifying broader underlying factors that explain\nrecidivism, with the goal of informing preventative policy intervention. We\ndemonstrate that this approach can guide the ethical application of ML using\nreal-world data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 04:15:41 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 18:25:26 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 18:43:01 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Shirvaikar", "Vik", ""], ["Lakshminarayan", "Choudur", ""]]}, {"id": "2011.11525", "submitter": "Julius Garcia", "authors": "Rosalyn P. Reyes, Evelyn C. Samson, Julius G. Garcia", "title": "An Interactive Foreign Language Trainer Using Assessment and Feedback\n  Modalities", "comments": "IJITGEB, Vol. 2, No. 1, 2020, pp. 9-17, ISSN 2686-0694, e-ISSN\n  2721-0030", "journal-ref": "International Journal in Information Technology in Governance,\n  Education and Business, 2(1), 9-17, 2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  English has long been set as the universal language. Basically most, if not\nall countries in the world know how to speak English or at least try to use it\nin their everyday communications for the purpose of globalizing. This study is\ndesigned to help the students learn from one or all of the four most commonly\nused foreign languages in the field of Information Technology namely Korean,\nMandarin Chinese, Japanese, and Spanish. Composed of a set of words, phrases,\nand sentences, the program is intended to quickly teach the students in the\nform of basic, intermediate, and advanced levels. This study has used the Agile\nmodel in system development. Functionality, reliability, usability, efficiency,\nand portability were also considered in determining the level of the\nacceptability of the system in terms of ISO 25010:2011. This interactive\nforeign language trainer is built to associate fun with learning, to remedy the\nlack of perseverance by some in learning a new language, and to make learning\nthe users' favorite playtime activity. The study allows the user to interact\nwith the program which provides support for their learning. Moreover, this\nstudy reveals that integrating feedback modalities in the training and\nassessment modules of the software strengthens and enhances the memory in\nlearning the language.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 16:35:59 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Reyes", "Rosalyn P.", ""], ["Samson", "Evelyn C.", ""], ["Garcia", "Julius G.", ""]]}, {"id": "2011.11611", "submitter": "Maria Kalantzi", "authors": "Maria Kalantzi, Agoritsa Polyzou, and George Karypis", "title": "FERN: Fair Team Formation for Mutually Beneficial Collaborative Learning", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Team Formation is becoming increasingly important for a plethora of\napplications in open source community projects, remote working platforms, as\nwell as online educational systems. The latter case, in particular, poses\nsignificant challenges that are specific to the educational domain. Indeed,\nteaming students aims to accomplish far more than the successful completion of\na specific task. It needs to ensure that all members in the team benefit from\nthe collaborative work, while also ensuring that the participants are not\ndiscriminated with respect to their protected attributes, such as race and\ngender. Towards achieving these goals, this work introduces FERN, a fair team\nformation approach that promotes mutually beneficial peer learning, dictated by\nprotected group fairness as equality of opportunity in collaborative learning.\nWe formulate the problem as a multi-objective discrete optimization problem. We\nshow this problem to be NP-hard and propose a heuristic hill-climbing\nalgorithm. Extensive experiments on both synthetic and real-world datasets\nagainst well-known team formation techniques show the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 18:38:01 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Kalantzi", "Maria", ""], ["Polyzou", "Agoritsa", ""], ["Karypis", "George", ""]]}, {"id": "2011.11688", "submitter": "Kenneth Joseph", "authors": "Zijian An, Kenneth Joseph", "title": "An analysis of replies to Trump's tweets", "comments": "Accepted at ICWSM'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Donald Trump has tweeted thousands of times during his presidency. These\npublic statements are an increasingly important way through which Trump\ncommunicates his political and personal views. A better understanding of the\nway the American public consumes and responds to these tweets is therefore\ncritical. In the present work, we address both consumption of and response to\nTrump's tweets by studying replies to them on Twitter. With respect to\nresponse, we find that a small number of older, white, left-leaning, and female\nAmericans are responsible for the vast majority of replies to Trump's tweets.\nThese individuals also attend to a broader range of Trump's tweets than the\nrest of the individuals we study. With respect to consumption, we note that\nTrump's tweets are often viewed not in isolation, but rather in the context of\na set of algorithmically-curated replies. These replies may therefore color the\nway Americans consume Trump's tweets. To this end, we find some evidence that\nTwitter accounts see replies in line with their political leanings. However, we\nshow that this can be largely, although not entirely, attributed to the fact\nthat Twitter is more likely to show replies by accounts a user follows. As a\nbasis for comparison, all results for Trump are compared and contrasted with\nreplies to Joe Biden's tweets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:29:29 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["An", "Zijian", ""], ["Joseph", "Kenneth", ""]]}, {"id": "2011.11694", "submitter": "Lakmal Meegahapola", "authors": "Lakmal Meegahapola, Salvador Ruiz-Correa, Daniel Gatica-Perez", "title": "Alone or With Others? Understanding Eating Episodes of College Students\n  with Mobile Sensing", "comments": "19th International Conference on Mobile and Ubiquitous Multimedia\n  (MUM 2020)", "journal-ref": null, "doi": "10.1145/3428361.3428463", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding food consumption patterns and contexts using mobile sensing is\nfundamental to build mobile health applications that require minimal user\ninteraction to generate mobile food diaries. Many available mobile food\ndiaries, both commercial and in research, heavily rely on self-reports, and\nthis dependency limits the long term adoption of these apps by people. The\nsocial context of eating (alone, with friends, with family, with a partner,\netc.) is an important self-reported feature that influences aspects such as\nfood type, psychological state while eating, and the amount of food, according\nto prior research in nutrition and behavioral sciences. In this work, we use\ntwo datasets regarding the everyday eating behavior of college students in two\ncountries, namely Switzerland (N_ch=122) and Mexico (N_mx=84), to examine the\nrelation between the social context of eating and passive sensing data from\nwearables and smartphones. Moreover, we design a classification task, namely\ninferring eating-alone vs. eating-with-others episodes using passive sensing\ndata and time of eating, obtaining accuracies between 77% and 81%. We believe\nthat this is a first step towards understanding more complex social contexts\nrelated to food consumption using mobile sensing.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 19:45:55 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 08:54:40 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Meegahapola", "Lakmal", ""], ["Ruiz-Correa", "Salvador", ""], ["Gatica-Perez", "Daniel", ""]]}, {"id": "2011.11764", "submitter": "Gerardo Romo-C\\'ardenas", "authors": "G.S.Romo-C\\'ardenas, M.A. Cos\\'io-Le\\'on, G.J. Avil\\'es-Rodriguez, N.\n  Isiodoro-Carballo, E. Zu\\~niga-Violante, J.dD. S\\'anchez-L\\'opez, J.I.\n  Nieto-Hip\\'olito", "title": "Development and evaluation of the use of a virtual health filter survey\n  in a private primary education system in Baja California Mexico during the\n  SARS-CoV-2 contingency (COVID-19)", "comments": "Spanish, 9 pages, 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This work reports on the design, implementation and evaluation of a survey\nused as a remote sanitary filter, which was applied in the Adventist\nEducational System of Baja California. During the SARS-CoV-2 sanitary\ncontingency. This with the intention of acquiring information safely and in\nreal time. Allowing to safeguard the integrity of the educational community as\na whole. Accessible and easily distributed digital resources were used in order\nto meet the necessary requirements of distribution, acquisition and management\nof the information. These were adapted to the previously established\ncommunication dynamic of the educational system. The use of the survey as a\nsanitary filter allowed to acquire relevant health information from the student\ncommunity and facilitated decision-making regarding class attendance by their\ntutors.These in consideration to the conditions established by educational and\nhealth authorities. Despite the short time during the design and\nimplementation, the communication of the educational system allowed the\neffective distribution, application and monitoring of the digital survey.\nSimilar strategies can be used in the follow-up during the reactivation after\nlockdown and to analyze social components that may be involved in these\nscenarios\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 22:15:53 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Romo-C\u00e1rdenas", "G. S.", ""], ["Cos\u00edo-Le\u00f3n", "M. A.", ""], ["Avil\u00e9s-Rodriguez", "G. J.", ""], ["Isiodoro-Carballo", "N.", ""], ["Zu\u00f1iga-Violante", "E.", ""], ["S\u00e1nchez-L\u00f3pez", "J. dD.", ""], ["Nieto-Hip\u00f3lito", "J. I.", ""]]}, {"id": "2011.11801", "submitter": "Nik Dawson", "authors": "Nikolas Dawson, Marian-Andrei Rizoiu, Mary-Anne Williams", "title": "Job Transitions in a Time of Automation and Labor Market Crises", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Job security can never be taken for granted, especially in times of rapid,\nwidespread and unexpected social and economic change. These changes can force\nworkers to transition to new jobs. This may be because technologies emerge or\nproduction is moved abroad. Perhaps it is a global crisis, such as COVID-19,\nwhich shutters industries and displaces labor en masse. Regardless of the\nimpetus, people are faced with the challenge of moving between jobs to find new\nwork. Successful transitions typically occur when workers leverage their\nexisting skills in the new occupation. Here, we propose a novel method to\nmeasure the similarity between occupations using their underlying skills. We\nthen build a recommender system for identifying optimal transition pathways\nbetween occupations using job advertisements (ads) data and a longitudinal\nhousehold survey. Our results show that not only we can accurately predict\noccupational transitions (Accuracy = 76%), but we account for the asymmetric\ndifficulties of moving between jobs (it is easier to move in one direction than\nthe other). We also build an early warning indicator for new technology\nadoption (showcasing Artificial Intelligence), a major driver of rising job\ntransitions. By using real-time data, our systems can respond to labor demand\nshifts as they occur (such as those caused by COVID-19), and can be leveraged\nby policy-makers, educators, and jobseekers who are forced to confront the\noften distressing challenges of having to find new jobs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 23:58:26 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Dawson", "Nikolas", ""], ["Rizoiu", "Marian-Andrei", ""], ["Williams", "Mary-Anne", ""]]}, {"id": "2011.11940", "submitter": "Zhiqi Wang", "authors": "Zhiqi Wang, Yue Chen, Wolfgang Gl\\\"anzel", "title": "Preprints as accelerator of scholarly communication: An empirical\n  analysis in Mathematics", "comments": "This is the accepted manuscript of the paper being published in\n  Journal of Informetrics. The link to the final published journal version :\n  https://linkinghub.elsevier.com/retrieve/pii/S1751157720300729", "journal-ref": "Journal of Informetrics,2020,14(4)", "doi": "10.1016/j.joi.2020.101097", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this study we analyse the key driving factors of preprints in enhancing\nscholarly communication. To this end we use four groups of metrics, one\nreferring to scholarly communication and based on bibliometric indicators (Web\nof Science and Scopus citations), while the others reflect usage (usage counts\nin Web of Science), capture (Mendeley readers) and social media attention\n(Tweets). Hereby we measure two effects associated with preprint publishing:\npublication delay and impact. We define and use several indicators to assess\nthe impact of journal articles with previous preprint versions in arXiv. In\nparticular, the indicators measure several times characterizing the process of\narXiv preprints publishing and the reviewing process of the journal versions,\nand the ageing patterns of citations to preprints. In addition, we compare the\nobserved patterns between preprints and non-OA articles without any previous\npreprint versions in arXiv. We could observe that the \"early-view\" and\n\"open-access\" effects of preprints contribute to a measurable citation and\nreadership advantage of preprints. Articles with preprint versions are more\nlikely to be mentioned in social media and have shorter Altmetric attention\ndelay. Usage and capture prove to have only moderate but stronger correlation\nwith citations than Tweets. The different slopes of the regression lines\nbetween the different indicators reflect different order of magnitude of usage,\ncapture and citation data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 07:32:35 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2020 00:00:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Wang", "Zhiqi", ""], ["Chen", "Yue", ""], ["Gl\u00e4nzel", "Wolfgang", ""]]}, {"id": "2011.12014", "submitter": "Maximilian Splieth\\\"over", "authors": "Maximilian Splieth\\\"over, Henning Wachsmuth", "title": "Argument from Old Man's View: Assessing Social Bias in Argumentation", "comments": "Accepted at the 7th Workshop on Argument Mining 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social bias in language - towards genders, ethnicities, ages, and other\nsocial groups - poses a problem with ethical impact for many NLP applications.\nRecent research has shown that machine learning models trained on respective\ndata may not only adopt, but even amplify the bias. So far, however, little\nattention has been paid to bias in computational argumentation. In this paper,\nwe study the existence of social biases in large English debate portals. In\nparticular, we train word embedding models on portal-specific corpora and\nsystematically evaluate their bias using WEAT, an existing metric to measure\nbias in word embeddings. In a word co-occurrence analysis, we then investigate\ncauses of bias. The results suggest that all tested debate corpora contain\nunbalanced and biased data, mostly in favor of male people with\nEuropean-American names. Our empirical insights contribute towards an\nunderstanding of bias in argumentative data sources.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 10:39:44 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Splieth\u00f6ver", "Maximilian", ""], ["Wachsmuth", "Henning", ""]]}, {"id": "2011.12096", "submitter": "Diego Kozlowski", "authors": "Diego Kozlowski, Gabriela Lozano, Carla M. Felcher, Fernando Gonzalez\n  and Edgar Altszyler", "title": "Gender bias in magazines oriented to men and women: a computational\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cultural products are a source to acquire individual values and behaviours.\nTherefore, the differences in the content of the magazines aimed specifically\nat women or men are a means to create and reproduce gender stereotypes. In this\nstudy, we compare the content of a women-oriented magazine with that of a\nmen-oriented one, both produced by the same editorial group, over a decade\n(2008-2018). With Topic Modelling techniques we identify the main themes\ndiscussed in the magazines and quantify how much the presence of these topics\ndiffers between magazines over time. Then, we performed a word-frequency\nanalysis to validate this methodology and extend the analysis to other subjects\nthat did not emerge automatically. Our results show that the frequency of\nappearance of the topics Family, Business and Women as sex objects, present an\ninitial bias that tends to disappear over time. Conversely, in Fashion and\nScience topics, the initial differences between both magazines are maintained.\nBesides, we show that in 2012, the content associated with horoscope increased\nin the women-oriented magazine, generating a new gap that remained open over\ntime. Also, we show a strong increase in the use of words associated with\nfeminism since 2015 and specifically the word abortion in 2018. Overall, these\ncomputational tools allowed us to analyse more than 24,000 articles. Up to our\nknowledge, this is the first study to compare magazines in such a large\ndataset, a task that would have been prohibitive using manual content analysis\nmethodologies.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 14:02:49 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kozlowski", "Diego", ""], ["Lozano", "Gabriela", ""], ["Felcher", "Carla M.", ""], ["Gonzalez", "Fernando", ""], ["Altszyler", "Edgar", ""]]}, {"id": "2011.12121", "submitter": "Dimitris Spathis", "authors": "Dimitris Spathis, Ignacio Perez-Pozuelo, Soren Brage, Nicholas J.\n  Wareham and Cecilia Mascolo", "title": "Self-supervised transfer learning of physiological representations from\n  free-living wearable data", "comments": "9 pages, 3 figures (long version of extended abstract\n  arXiv:2011.04601)", "journal-ref": null, "doi": "10.1145/3450439.3451863", "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearable devices such as smartwatches are becoming increasingly popular tools\nfor objectively monitoring physical activity in free-living conditions. To\ndate, research has primarily focused on the purely supervised task of human\nactivity recognition, demonstrating limited success in inferring high-level\nhealth outcomes from low-level signals. Here, we present a novel\nself-supervised representation learning method using activity and heart rate\n(HR) signals without semantic labels. With a deep neural network, we set HR\nresponses as the supervisory signal for the activity data, leveraging their\nunderlying physiological relationship. In addition, we propose a custom\nquantile loss function that accounts for the long-tailed HR distribution\npresent in the general population.\n  We evaluate our model in the largest free-living combined-sensing dataset\n(comprising >280k hours of wrist accelerometer & wearable ECG data). Our\ncontributions are two-fold: i) the pre-training task creates a model that can\naccurately forecast HR based only on cheap activity sensors, and ii) we\nleverage the information captured through this task by proposing a simple\nmethod to aggregate the learnt latent representations (embeddings) from the\nwindow-level to user-level. Notably, we show that the embeddings can generalize\nin various downstream tasks through transfer learning with linear classifiers,\ncapturing physiologically meaningful, personalized information. For instance,\nthey can be used to predict variables associated with individuals' health,\nfitness and demographic characteristics, outperforming unsupervised\nautoencoders and common bio-markers. Overall, we propose the first multimodal\nself-supervised method for behavioral and physiological data with implications\nfor large-scale health and lifestyle monitoring.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 23:21:34 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Spathis", "Dimitris", ""], ["Perez-Pozuelo", "Ignacio", ""], ["Brage", "Soren", ""], ["Wareham", "Nicholas J.", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "2011.12329", "submitter": "Dana Naous", "authors": "Dana Naous, Manus Bonner, Mathias Humbert, Christine Legner", "title": "Towards Mass Adoption of Contact Tracing Apps -- Learning from Users'\n  Preferences to Improve App Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Contact tracing apps have become one of the main approaches to control and\nslow down the spread of COVID-19 and ease up lockdown measures. While these\napps can be very effective in stopping the transmission chain and saving lives,\ntheir adoption remains under the expected critical mass. The public debate\nabout contact tracing apps emphasizes general privacy reservations and is\nconducted at an expert level, but lacks the user perspective related to actual\ndesigns. To address this gap, we explore user preferences for contact tracing\napps using market research techniques, and specifically conjoint analysis. Our\nmain contributions are empirical insights into individual and group\npreferences, as well as insights for prescriptive design. While our results\nconfirm the privacy-preserving design of most European contact tracing apps,\nthey also provide a more nuanced understanding of acceptable features. Based on\nmarket simulation and variation analysis, we conclude that adding\ngoal-congruent features will play an important role in fostering mass adoption.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 19:08:09 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Naous", "Dana", ""], ["Bonner", "Manus", ""], ["Humbert", "Mathias", ""], ["Legner", "Christine", ""]]}, {"id": "2011.12510", "submitter": "Kentaro Iio", "authors": "Kentaro Iio, Xiaoyu Guo, Xiaoqiang \"Jack\" Kong, Kelly Rees and Xiubin\n  Bruce Wang", "title": "COVID-19 and Social Distancing: Disparities in Mobility Adaptation\n  between Income Groups", "comments": "13 pages, 7 figures", "journal-ref": "Transportation Research Interdisciplinary Perspectives (2021):\n  100333", "doi": "10.1016/j.trip.2021.100333", "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In response to the coronavirus disease 2019 (COVID-19) pandemic, governments\nhave encouraged and ordered citizens to practice social distancing,\nparticularly by working and studying at home. Intuitively, only a subset of\npeople have the ability to practice remote work. However, there has been little\nresearch on the disparity of mobility adaptation across different income groups\nin US cities during the pandemic. The authors worked to fill this gap by\nquantifying the impacts of the pandemic on human mobility by income in Greater\nHouston, Texas. In this paper, we determined human mobility using\npseudonymized, spatially disaggregated cell phone location data. A longitudinal\nstudy across estimated income groups was conducted by measuring the total\ntravel distance, radius of gyration, number of visited locations, and per-trip\ndistance in April 2020 compared to the data in a baseline. An apparent\ndisparity in mobility was found across estimated income groups. In particular,\nthere was a strong negative correlation ($\\rho$ = -0.90) between a traveler's\nestimated income and travel distance in April. Disparities in mobility\nadaptability were further shown since those in higher income brackets\nexperienced larger percentage drops in the radius of gyration and the number of\ndistinct visited locations than did those in lower income brackets. The\nfindings of this study suggest a need to understand the reasons behind the\nmobility inflexibility among low-income populations during the pandemic. The\nstudy illuminates an equity issue which may be of interest to policy makers and\nresearchers alike in the wake of an epidemic.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:26:08 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 03:03:19 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 21:57:11 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Iio", "Kentaro", ""], ["Guo", "Xiaoyu", ""], ["Kong", "Xiaoqiang \"Jack\"", ""], ["Rees", "Kelly", ""], ["Wang", "Xiubin Bruce", ""]]}, {"id": "2011.12620", "submitter": "Shah Miah Prof", "authors": "Soliman Aljarboa, Shah J. Miah", "title": "An Integration of UTAUT and Task-Technology Fit Frameworks for Assessing\n  the Acceptance of Clinical Decision Support Systems in the Context of a\n  Developing Country", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is to create a basis of theoretical contribution for a new PhD\nthesis in the area of Clinical Decision Support Systems (CDSS) acceptance. Over\nthe past three years, we conducted qualitative research into three distinctive\nphases to develop an extended Task-Technology Fit (TTF) Framework. These phases\nare for initiating requirement generation of the framework, discovering the\nfactors of the framework through perspectives, and evaluating the new proposed\nframework. The new condition is related to developing country in which various\nsectors such as healthcare is mostly under attention. We conduct a new\ninspective for assisting decisions to support technology and its usefulness in\nthis sector to integrate with other frameworks for assisting the value, use,\nand how can be better accepted in the context of healthcare professionals.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 10:20:46 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Aljarboa", "Soliman", ""], ["Miah", "Shah J.", ""]]}, {"id": "2011.12644", "submitter": "Luis F. Abanto-Leon", "authors": "Luis F. Abanto-Leon and Andreas Baeuml and Gek Hong (Allyson) Sim and\n  Matthias Hollick and Arash Asadi", "title": "Stay Connected, Leave no Trace: Enhancing Security and Privacy in WiFi\n  via Obfuscating Radiometric Fingerprints", "comments": "ACM Sigmetrics 2021 / In Proc. ACM Meas. Anal. Comput. Syst., Vol. 4,\n  3, Article 44 (December 2020)", "journal-ref": null, "doi": "10.1145/3428329", "report-no": null, "categories": "cs.CR cs.CY cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The intrinsic hardware imperfection of WiFi chipsets manifests itself in the\ntransmitted signal, leading to a unique radiometric fingerprint. This\nfingerprint can be used as an additional means of authentication to enhance\nsecurity. In fact, recent works propose practical fingerprinting solutions that\ncan be readily implemented in commercial-off-the-shelf devices. In this paper,\nwe prove analytically and experimentally that these solutions are highly\nvulnerable to impersonation attacks. We also demonstrate that such a unique\ndevice-based signature can be abused to violate privacy by tracking the user\ndevice, and, as of today, users do not have any means to prevent such privacy\nattacks other than turning off the device.\n  We propose RF-Veil, a radiometric fingerprinting solution that not only is\nrobust against impersonation attacks but also protects user privacy by\nobfuscating the radiometric fingerprint of the transmitter for non-legitimate\nreceivers. Specifically, we introduce a randomized pattern of phase errors to\nthe transmitted signal such that only the intended receiver can extract the\noriginal fingerprint of the transmitter. In a series of experiments and\nanalyses, we expose the vulnerability of adopting naive randomization to\nstatistical attacks and introduce countermeasures. Finally, we show the\nefficacy of RF-Veil experimentally in protecting user privacy and enhancing\nsecurity. More importantly, our proposed solution allows communicating with\nother devices, which do not employ RF-Veil.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 11:10:59 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 12:25:18 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Abanto-Leon", "Luis F.", "", "Allyson"], ["Baeuml", "Andreas", "", "Allyson"], ["Hong", "Gek", "", "Allyson"], ["Sim", "", ""], ["Hollick", "Matthias", ""], ["Asadi", "Arash", ""]]}, {"id": "2011.12750", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "AI virtues -- The missing link in putting AI ethics into practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several seminal ethics initiatives have stipulated sets of principles and\nstandards for good technology development in the AI sector. However, widespread\ncriticism has pointed out a lack of practical realization of these principles.\nFollowing that, AI ethics underwent a practical turn, but without deviating\nfrom the principled approach and the many shortcomings associated with it. This\npaper proposes a different approach. It defines four basic AI virtues, namely\njustice, honesty, responsibility and care, all of which represent specific\nmotivational settings that constitute the very precondition for ethical\ndecision making in the AI field. Moreover, it defines two second-order AI\nvirtues, prudence and fortitude, that bolster achieving the basic virtues by\nhelping with overcoming bounded ethicality or the many hidden psychological\nforces that impair ethical decision making and that are hitherto disregarded in\nAI ethics. Lastly, the paper describes measures for successfully cultivating\nthe mentioned virtues in organizations dealing with AI research and\ndevelopment.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 14:14:47 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 10:23:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "2011.12767", "submitter": "John Paul Miranda", "authors": "John Paul P. Miranda, Jaymark A. Yambao, Jhon Asley M. Marcelo,\n  Christopher Robert N. Gonzales, Vee-jay T. Mungcal", "title": "Towards the Development of 3D Engine Assembly Simulation Learning Module\n  for Senior High School", "comments": "13 pages, 10 figures", "journal-ref": "International Journal of Computing Sciences Research (ISSN print:\n  2546-0552; ISSN online: 2546-115X) Vol. 5, No. 1, 2021", "doi": "10.25147/ijcsr.2017.001.1.54", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The focus of the study is to develop a 3D engine assembly simulation learning\nmodule to address the lack of equipment in one senior high school in the\nPhilippines. The study used mixed-method to determine the considerations needed\nin developing an application for educational use particularly among\nlaboratory/practical subjects like engine assembly. The study used ISO 25010\nquality standards in evaluating the application(n=153 students and 3 ICT\nexperts).Results showed that the application is moderately acceptable(overall\nmean = 3.52) under ISO 25010 quality standards. The study created an engine\nsimulation learning assembly in which teachers can use to augment their lesson.\nThe study also highlights the applicability of using 3D-related technologies\nfor practical and laboratory subjects particularly highly technical-related\nsubjects. Future studies may develop a similar application in the same context\nusing mobile and other emerging technology(i.e., Virtual Reality, Augmented\nReality) as well as making the content more customizable. Effectivity of the\nsystem in an actual setting is also worth pursuing. The study highlighted the\npotential use of 3D technology in a classroom setting.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 10:45:29 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Miranda", "John Paul P.", ""], ["Yambao", "Jaymark A.", ""], ["Marcelo", "Jhon Asley M.", ""], ["Gonzales", "Christopher Robert N.", ""], ["Mungcal", "Vee-jay T.", ""]]}, {"id": "2011.12843", "submitter": "Homa Hosseinmardi", "authors": "Homa Hosseinmardi, Amir Ghasemian, Aaron Clauset, David M. Rothschild,\n  Markus Mobius, Duncan J. Watts", "title": "Evaluating the scale, growth, and origins of right-wing echo chambers on\n  YouTube", "comments": "29 pages, 21 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although it is understudied relative to other social media platforms, YouTube\nis arguably the largest and most engaging online media consumption platform in\nthe world. Recently, YouTube's outsize influence has sparked concerns that its\nrecommendation algorithm systematically directs users to radical right-wing\ncontent. Here we investigate these concerns with large scale longitudinal data\nof individuals' browsing behavior spanning January 2016 through December 2019.\nConsistent with previous work, we find that political news content accounts for\na relatively small fraction (11%) of consumption on YouTube, and is dominated\nby mainstream and largely centrist sources. However, we also find evidence for\na small but growing \"echo chamber\" of far-right content consumption. Users in\nthis community show higher engagement and greater \"stickiness\" than users who\nconsume any other category of content. Moreover, YouTube accounts for an\nincreasing fraction of these users' overall online news consumption. Finally,\nwhile the size, intensity, and growth of this echo chamber present real\nconcerns, we find no evidence that they are caused by YouTube recommendations.\nRather, consumption of radical content on YouTube appears to reflect broader\npatterns of news consumption across the web. Our results emphasize the\nimportance of measuring consumption directly rather than inferring it from\nrecommendations.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 16:00:20 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Hosseinmardi", "Homa", ""], ["Ghasemian", "Amir", ""], ["Clauset", "Aaron", ""], ["Rothschild", "David M.", ""], ["Mobius", "Markus", ""], ["Watts", "Duncan J.", ""]]}, {"id": "2011.12923", "submitter": "Agatha Hennigen De Mattos", "authors": "Agatha C. H. de Mattos, Gavin McArdle, Michela Bertolotto", "title": "Assessing the Quality of Gridded Population Data for Quantifying the\n  Population Living in Deprived Communities", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over a billion people live in slums in settlements that are often located in\necologically sensitive areas and hence highly vulnerable. This is a problem in\nmany parts of the world, but it is more prominent in low-income countries,\nwhere in 2014 on average 65% of the urban population lived in slums. As a\nresult, building resilient communities requires quantifying the population\nliving in these deprived areas and improving their living conditions. However,\nmost of the data about slums comes from census data, which is only available at\naggregate levels and often excludes these settlements. Consequently,\nresearchers have looked at alternative approaches. These approaches, however,\ncommonly rely on expensive high-resolution satellite imagery and field-surveys,\nwhich hinders their large-scale applicability. In this paper, we investigate a\ncost-effective methodology to estimate the slum population by assessing the\nquality of gridded population data. We evaluate the accuracy of the WorldPOP\nand LandScan population layers against ground-truth data composed of 1,703\ngeoreferenced polygons that were mapped as deprived areas and which had their\npopulation surveyed during the 2010 Brazilian census. While the LandScan data\ndid not produce satisfactory results for most polygons, the WorldPOP estimates\nwere less than 20% off for 67% of the polygons and the overall error for the\ntotality of the studied area was only -5.9%. This small error margin\ndemonstrates that population layers with a resolution of at least a 100m, such\nas WorldPOP's, can be useful tools to estimate the population living in slums.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 18:14:30 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["de Mattos", "Agatha C. H.", ""], ["McArdle", "Gavin", ""], ["Bertolotto", "Michela", ""]]}, {"id": "2011.13032", "submitter": "Grace Abuhamad", "authors": "Grace Abuhamad and Claudel Rheault", "title": "Like a Researcher Stating Broader Impact For the Very First Time", "comments": "Navigating the Broader Impacts of AI Research Workshop at the 34th\n  Conference on Neural Information Processing Systems (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In requiring that a statement of broader impact accompany all submissions for\nthis year's conference, the NeurIPS program chairs made ethics part of the\nstake in groundbreaking AI research. While there is precedent from other fields\nand increasing awareness within the NeurIPS community, this paper seeks to\nanswer the question of how individual researchers reacted to the new\nrequirement, including not just their views, but also their experience in\ndrafting and their reflections after paper acceptances. We present survey\nresults and considerations to inform the next iteration of the broader impact\nrequirement should it remain a requirement for future NeurIPS conferences.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 21:32:29 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Abuhamad", "Grace", ""], ["Rheault", "Claudel", ""]]}, {"id": "2011.13087", "submitter": "Alicia Y. Tsai", "authors": "Alicia Y. Tsai and Selim Gunay and Minjune Hwang and Pengyuan Zhai and\n  Chenglong Li and Laurent El Ghaoui and Khalid M. Mosalam", "title": "Text Analytics for Resilience-Enabled Extreme Events Reconnaissance", "comments": "Published at NeurIPS 2020 Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response (AI+HADR 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hazard reconnaissance for natural disasters (e.g., earthquakes) is\nimportant for understanding the performance of the built environment, speeding\nup the recovery, enhancing resilience and making informed decisions related to\ncurrent and future hazards. Natural language processing (NLP) is used in this\nstudy for the purposes of increasing the accuracy and efficiency of natural\nhazard reconnaissance through automation. The study particularly focuses on (1)\nautomated data (news and social media) collection hosted by the Pacific\nEarthquake Engineering Research (PEER) Center server, (2) automatic generation\nof reconnaissance reports, and (3) use of social media to extract post-hazard\ninformation such as the recovery time. Obtained results are encouraging for\nfurther development and wider usage of various NLP methods in natural hazard\nreconnaissance.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 01:43:29 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 18:07:20 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Tsai", "Alicia Y.", ""], ["Gunay", "Selim", ""], ["Hwang", "Minjune", ""], ["Zhai", "Pengyuan", ""], ["Li", "Chenglong", ""], ["Ghaoui", "Laurent El", ""], ["Mosalam", "Khalid M.", ""]]}, {"id": "2011.13153", "submitter": "Josephine Seah", "authors": "Josephine Seah", "title": "Nose to Glass: Looking In to Get Beyond", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Brought into the public discourse through investigative work by journalists\nand scholars, awareness of algorithmic harms is at an all-time high. An\nincreasing amount of research has been conducted under the banner of enhancing\nresponsible artificial intelligence (AI), with the goal of addressing,\nalleviating, and eventually mitigating the harms brought on by the roll out of\nalgorithmic systems. Nonetheless, implementation of such tools remains low.\nGiven this gap, this paper offers a modest proposal: that the field,\nparticularly researchers concerned with responsible research and innovation,\nmay stand to gain from supporting and prioritising more ethnographic work. This\nembedded work can flesh out implementation frictions and reveal organisational\nand institutional norms that existing work on responsible artificial\nintelligence AI has not yet been able to offer. In turn, this can contribute to\nmore insights about the anticipation of risks and mitigation of harm. This\npaper reviews similar empirical work typically found elsewhere, commonly in\nscience and technology studies and safety science research, and lays out\nchallenges of this form of inquiry.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 06:51:45 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 13:24:07 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Seah", "Josephine", ""]]}, {"id": "2011.13170", "submitter": "Priyanka Nanayakkara", "authors": "Priyanka Nanayakkara, Nicholas Diakopoulos, Jessica Hullman", "title": "Anticipatory Ethics and the Role of Uncertainty", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making conjectures about future consequences of a technology is an exercise\nin trying to reduce various forms of uncertainty. Both to produce and reason\nabout these conjectures requires understanding their potential limitations. In\nother words, we need systematic ways of considering uncertainty associated with\ngiven conjectures for downstream consequences. In this work, we frame the task\nof considering future consequences as an anticipatory ethics problem, where the\ngoal is to develop scenarios that reflect plausible outcomes and their ethical\nimplications following a technology's introduction into society. In order to\nshed light on how various forms of uncertainty might inform how we reason about\na resulting scenario, we provide a characterization of the types of uncertainty\nthat arise in a potential scenario-building process.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 08:12:00 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Nanayakkara", "Priyanka", ""], ["Diakopoulos", "Nicholas", ""], ["Hullman", "Jessica", ""]]}, {"id": "2011.13188", "submitter": "Christian Janiesch", "authors": "Marcus Fischer, Adrian Hofmann, Florian Imgrund, Christian Janiesch,\n  Axel Winkelmann", "title": "On the Composition of the Long Tail of Business Processes: Implications\n  from a Process Mining Study", "comments": "Accepted for publication at Information Systems", "journal-ref": null, "doi": "10.1016/j.is.2020.101689", "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Digital transformation forces companies to rethink their processes to meet\ncurrent customer needs. Business Process Management (BPM) can provide the means\nto structure and tackle this change. However, most approaches to BPM face\nrestrictions on the number of processes they can optimize at a time due to\ncomplexity and resource restrictions. Investigating this shortcoming, the\nconcept of the long tail of business processes suggests a hybrid approach that\nentails managing important processes centrally, while incrementally improving\nthe majority of processes at their place of execution. This study scrutinizes\nthis observation as well as corresponding implications. First, we define a\nsystem of indicators to automatically prioritize processes based on execution\ndata. Second, we use process mining to analyze processes from multiple\ncompanies to investigate the distribution of process value in terms of their\nprocess variants. Third, we examine the characteristics of the process variants\ncontained in the short head and the long tail to derive and justify\nrecommendations for their management. Our results suggest that the assumption\nof a long-tailed distribution holds across companies and indicators and also\napplies to the overall improvement potential of processes and their variants.\nAcross all cases, process variants in the long tail were characterized by fewer\ncustomer contacts, lower execution frequencies, and a larger number of involved\nstakeholders, making them suitable candidates for distributed improvement.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 09:04:15 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Fischer", "Marcus", ""], ["Hofmann", "Adrian", ""], ["Imgrund", "Florian", ""], ["Janiesch", "Christian", ""], ["Winkelmann", "Axel", ""]]}, {"id": "2011.13276", "submitter": "Cedric Du Mouza", "authors": "Jacky Akoka (CEDRIC - ISID, IMT-BS), Isabelle Comyn-Wattiau (CEDRIC -\n  ISID), St\\'ephane Lamass\\'e (LAMOP), C\\'edric Du Mouza (CEDRIC - ISID)", "title": "Contribution of Conceptual Modeling to Enhancing Historians' Intuition\n  -Application to Prosopography", "comments": null, "journal-ref": "International Conference on Conceptual Modeling (ER), Nov 2020,\n  Vienne, Austria", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historians, and in particular researchers in prosopography, focus a lot of\neffort on extracting and coding information from historical sources to build\ndatabases. To deal with this situation, they rely in some cases on their\nintuition. One important issue is to provide these researchers with the\ninformation extracted from the sources in a sufficiently structured form to\nallow the databases to be queried and to verify, and possibly, to validate\nhypotheses. The research in this paper attempts to take up the challenge of\nhelping historians capturing and assessing information throughout automatic\nprocesses. The issue emerges when too many sources of uncertain information are\navailable. Based on the high-level information fusion approach, we propose a\nprocess that automatically supports historians' intuition in the domain of\nprosopography. The contribution is threefold: a conceptual data model, a\nprocess model, and a set of rules combining the reliability of sources and the\ncredibility of information.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 13:21:36 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Akoka", "Jacky", "", "CEDRIC - ISID, IMT-BS"], ["Comyn-Wattiau", "Isabelle", "", "CEDRIC -\n  ISID"], ["Lamass\u00e9", "St\u00e9phane", "", "LAMOP"], ["Mouza", "C\u00e9dric Du", "", "CEDRIC - ISID"]]}, {"id": "2011.13350", "submitter": "Santiago Cortes", "authors": "Santiago Cortes and Yullys M. Quintero", "title": "Unsupervised learning for economic risk evaluation in the context of\n  Covid-19 pandemic", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Justifying draconian measures during the Covid-19 pandemic was difficult not\nonly because of the restriction of individual rights, but also because of its\neconomic impact. The objective of this work is to present a machine learning\napproach to identify regions that should implement similar health policies. For\nthat end, we successfully developed a system that gives a notion of economic\nimpact given the prediction of new incidental cases through unsupervised\nlearning and time series forecasting. This system was built taking into account\ncomputational restrictions and low maintenance requirements in order to improve\nthe system's resilience. Finally this system was deployed as part of a web\napplication for simulation and data analysis of COVID-19, in Colombia,\navailable at (https://covid19.dis.eafit.edu.co).\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 15:31:06 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Cortes", "Santiago", ""], ["Quintero", "Yullys M.", ""]]}, {"id": "2011.13416", "submitter": "Margarita Boyarskaya", "authors": "Margarita Boyarskaya, Alexandra Olteanu, Kate Crawford", "title": "Overcoming Failures of Imagination in AI Infused System Development and\n  Deployment", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  NeurIPS 2020 requested that research paper submissions include impact\nstatements on \"potential nefarious uses and the consequences of failure.\"\nHowever, as researchers, practitioners and system designers, a key challenge to\nanticipating risks is overcoming what Clarke (1962) called 'failures of\nimagination.' The growing research on bias, fairness, and transparency in\ncomputational systems aims to illuminate and mitigate harms, and could thus\nhelp inform reflections on possible negative impacts of particular pieces of\ntechnical work. The prevalent notion of computational harms -- narrowly\nconstrued as either allocational or representational harms -- does not fully\ncapture the open, context dependent, and unobservable nature of harms across\nthe wide range of AI infused systems.The current literature focuses on a small\nrange of examples of harms to motivate algorithmic fixes, overlooking the wider\nscope of probable harms and the way these harms might affect different\nstakeholders. The system affordances may also exacerbate harms in unpredictable\nways, as they determine stakeholders' control(including of non-users) over how\nthey use and interact with a system output. To effectively assist in\nanticipating harmful uses, we argue that frameworks of harms must be\ncontext-aware and consider a wider range of potential stakeholders, system\naffordances, as well as viable proxies for assessing harms in the widest sense.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 18:09:52 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 10:06:12 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2020 08:51:12 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Boyarskaya", "Margarita", ""], ["Olteanu", "Alexandra", ""], ["Crawford", "Kate", ""]]}, {"id": "2011.13447", "submitter": "Julius Garcia", "authors": "Mayumi Kubota, Julius G. Garcia", "title": "Creating and Maintaining Filipino and Japanese Students Social Capital\n  with Facebook", "comments": "IJEMT, Vol.11, No. 1, 2017, pp.97 107 ISSN 1882 2290", "journal-ref": "International Journal for Educational Media and Technology 2017,\n  Vol.11, No. 1, pp.97-107", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This study investigated perceptions and patterns of Facebook use among\nFilipino and Japanese undergraduate students and the relationship of these\nfactors to creating and maintaining students social capital, international\nposture, and willingness to communicate. The survey of undergraduate students\nwas conducted online and 483 valid responses were obtained. Data revealed the\ncharacteristic uses of FB by Filipino and Japanese undergraduate students. An\ninterrelation model among six factors, International Posture, WTC, Perception,\nBridging, Bonding, and Utilization for Filipino students showed the importance\nof utilization or FB usage for bridging social capital and bonding social\ncapital. For Japanese students, bonding social capital mediated between\nutilization or FB usage and bridging. Bridging social capital was established\nonly through bonding social capital. Thus, unless Japanese students are close\nenough to their FB friends, they do not construct new relationships on FB that\nwill influence Filipino students in the process of virtual internationalization\nin the future.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 19:09:15 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kubota", "Mayumi", ""], ["Garcia", "Julius G.", ""]]}, {"id": "2011.13563", "submitter": "Chiara Ledesma", "authors": "Chiara Ledesma, Oshean Lee Garonita, Lorenzo Jaime Flores, Isabelle\n  Tingzon, and Danielle Dalisay", "title": "Interpretable Poverty Mapping using Social Media Data, Satellite Images,\n  and Geospatial Information", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to accurate, granular, and up-to-date poverty data is essential for\nhumanitarian organizations to identify vulnerable areas for poverty alleviation\nefforts. Recent works have shown success in combining computer vision and\nsatellite imagery for poverty estimation; however, the cost of acquiring\nhigh-resolution images coupled with black box models can be a barrier to\nadoption for many development organizations. In this study, we present a\ninterpretable and cost-efficient approach to poverty estimation using machine\nlearning and readily accessible data sources including social media data,\nlow-resolution satellite images, and volunteered geographic information. Using\nour method, we achieve an $R^2$ of 0.66 for wealth estimation in the\nPhilippines, compared to 0.63 using satellite imagery. Finally, we use feature\nimportance analysis to identify the highest contributing features both globally\nand locally to help decision makers gain deeper insights into poverty.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 05:24:53 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Ledesma", "Chiara", ""], ["Garonita", "Oshean Lee", ""], ["Flores", "Lorenzo Jaime", ""], ["Tingzon", "Isabelle", ""], ["Dalisay", "Danielle", ""]]}, {"id": "2011.13583", "submitter": "Apoorv Khandelwal", "authors": "Margot Hanley, Apoorv Khandelwal, Hadar Averbuch-Elor, Noah Snavely\n  and Helen Nissenbaum", "title": "An Ethical Highlighter for People-Centric Dataset Creation", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Important ethical concerns arising from computer vision datasets of people\nhave been receiving significant attention, and a number of datasets have been\nwithdrawn as a result. To meet the academic need for people-centric datasets,\nwe propose an analytical framework to guide ethical evaluation of existing\ndatasets and to serve future dataset creators in avoiding missteps. Our work is\ninformed by a review and analysis of prior works and highlights where such\nethical challenges arise.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 07:18:44 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Hanley", "Margot", ""], ["Khandelwal", "Apoorv", ""], ["Averbuch-Elor", "Hadar", ""], ["Snavely", "Noah", ""], ["Nissenbaum", "Helen", ""]]}, {"id": "2011.13604", "submitter": "Carole Adam", "authors": "Elise Beck, Julie Dugdale, Carole Adam, Christelle Ga\\\"idatzis, Julius\n  Ba\\~ngate", "title": "A methodology for co-constructing an interdisciplinary model: from model\n  to survey, from survey to model", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How should computer science and social science collaborate to build a common\nmodel? How should they proceed to gather data that is really useful to the\nmodelling? How can they design a survey that is tailored to the target model?\nThis paper aims to answer those crucial questions in the framework of a\nmultidisciplinary research project. This research addresses the issue of\nco-constructing a model when several disciplines are involved, and is applied\nto modelling human behaviour immediately after an earthquake. The main\ncontribution of the work is to propose a tool dedicated to multidisciplinary\ndialogue. It also proposes a reflexive analysis of the enriching intellectual\nprocess carried out by the different disciplines involved. Finally, from\nworking with an anthropologist, a complementary view of the multidisciplinary\nprocess is given.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 08:41:47 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Beck", "Elise", ""], ["Dugdale", "Julie", ""], ["Adam", "Carole", ""], ["Ga\u00efdatzis", "Christelle", ""], ["Ba\u00f1gate", "Julius", ""]]}, {"id": "2011.13638", "submitter": "Nadeem Kafi", "authors": "Nadeem Kafi, Zubair Ahmed Shaikh, and Muhammad Shahid Shaikh", "title": "Human Computations in Citizen Crowds: A Knowledge Management Solution\n  Framework", "comments": null, "journal-ref": "Mehran University Research Journal of Engineering & Technology,\n  Vol. 37, No. 3, 513-528 July 2018, p-ISSN: 0254-7821, e-ISSN: 2413-7219", "doi": "10.22581/muet1982.1803.06", "report-no": null, "categories": "cs.HC cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KG (Knowledge Generation) and understanding have traditionally been a\nHuman-centric activity. KE (Knowledge Engineering) and KM (Knowledge\nManagement) have tried to augment human knowledge on two separate planes: the\nfirst deals with machine interpretation of knowledge while the later explore\ninteractions in human networks for KG and understanding. However, both remain\ncomputer-centric. Crowdsourced HC (Human Computations) have recently utilized\nhuman cognition and memory to generate diverse knowledge streams on specific\ntasks, which are mostly easy for humans to solve but remain challenging for\nmachine algorithms. Literature shows little work on KM frameworks for citizen\ncrowds, which gather input from the diverse category of Humans, organize that\nknowledge concerning tasks and knowledge categories and recreate new knowledge\nas a computer-centric activity. In this paper, we present an attempt to create\na framework by implementing a simple solution, called ExamCheck, to focus on\nthe generation of knowledge, feedback on that knowledge and recording the\nresults of that knowledge in academic settings. Our solution, based on HC,\nshows that a structured KM framework can address a complex problem in a context\nthat is important for participants themselves.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 10:18:01 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kafi", "Nadeem", ""], ["Shaikh", "Zubair Ahmed", ""], ["Shaikh", "Muhammad Shahid", ""]]}, {"id": "2011.13740", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul", "title": "Recent Advances in Selective Image Encryption and its Indispensability\n  due to COVID-19", "comments": "6 pages, Published in IEEE RAICS 2020, see https://raics.in", "journal-ref": "2020 IEEE Recent Advances in Intelligent Computational Systems\n  (RAICS), 2020, pp. 201-206", "doi": "10.1109/RAICS51191.2020.9332513", "report-no": null, "categories": "cs.CR cs.CY cs.GR cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic serves as a grim reminder of the unexpected nature of\nthese outbreaks and gives rise to a unique set of research challenges in a\nvariety of fields. As people all over the world adjust to this new 'normal',\nwith most workplaces, from companies to educational institutions shifting\nonline, enormous surges in the transmission of images and videos have been\nobserved, creating record-breaking stresses on the internet backbone. At the\nsame time, maintaining the privacy and security of the users' data is of\nimmense importance, this is where fast and efficient image encryption\nalgorithms play a vital role. This paper discusses the calamitous effects of\nthe pandemic on the world population and how their changes in multimedia\nconsumption have led to an urgent need for the development and deployment of\nsecure and fast image encryption, especially selective image encryption\ntechniques. It carefully surveys the most recent advances in this field,\ndiscusses their real-world effects and finally explores some future research\navenues, to provide swift relief and recover from the disastrous effects of the\npandemic.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 14:02:54 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 02:11:48 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 10:21:00 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Paul", "Aditya Jyoti", ""]]}, {"id": "2011.13785", "submitter": "Tasos Spiliotopoulos", "authors": "Tasos Spiliotopoulos, Ian Oakley", "title": "Urban Twitter Networks and Communities: A Case Study of Microblogging in\n  Athens", "comments": "Published in the proceedings of Hybrid City Conference 2013, Athens,\n  Greece", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper examines the community formed by the Twitter users that used a\ncity-level hashtag. In particular, we provide a network perspective of the city\nof Athens, Greece, as demonstrated by the analysis and visualization of the\nrelevant Twitter hashtag data, in order to present both an overview and deeper\ninsights at the microblogging practices of this geographic local network.\nFurther analysis suggests that the Twitter community defined by the members of\nthe network shows strong signs of a real-life community.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 15:38:42 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Spiliotopoulos", "Tasos", ""], ["Oakley", "Ian", ""]]}, {"id": "2011.13802", "submitter": "Tasos Spiliotopoulos", "authors": "Tasos Spiliotopoulos, Ian Oakley", "title": "Post or Tweet: Lessons from a Study of Facebook and Twitter Usage", "comments": "Published in the CHI 2016 Workshop on Following user pathways: Using\n  cross platform and mixed methods analysis in social media studies, San Jose,\n  CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This workshop paper reports on an ongoing mixed-methods study on the two\narguably most popular social network sites, Facebook and Twitter, for the same\nusers. The overarching goal of the study is to shed light into the nuances of\nsocial media selection and cross-platform use by combining survey data about\nparticipants' motivations with usage data collected via API extraction. We\ndescribe the set-up of the study and focus our discussion on the challenges and\ninsights relating to participant recruiting and data collection, handling and\ndimensionalizing usage data, and comparing usage data across sites.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 15:55:02 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Spiliotopoulos", "Tasos", ""], ["Oakley", "Ian", ""]]}, {"id": "2011.13988", "submitter": "Katelyn Morrison", "authors": "Katelyn Morrison", "title": "Reducing Discrimination in Learning Algorithms for Social Good in\n  Sociotechnical Systems", "comments": "3 page position paper accepted to the AI for Social Good workshop at\n  The International Joint Conference on Artificial Intelligence (IJCAI). To be\n  presented on January 8th, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sociotechnical systems within cities are now equipped with machine learning\nalgorithms in hopes to increase efficiency and functionality by modeling and\npredicting trends. Machine learning algorithms have been applied in these\ndomains to address challenges such as balancing the distribution of bikes\nthroughout a city and identifying demand hotspots for ride sharing drivers.\nHowever, these algorithms applied to challenges in sociotechnical systems have\nexacerbated social inequalities due to previous bias in data sets or the lack\nof data from marginalized communities. In this paper, I will address how smart\nmobility initiatives in cities use machine learning algorithms to address\nchallenges. I will also address how these algorithms unintentionally\ndiscriminate against features such as socioeconomic status to motivate the\nimportance of algorithmic fairness. Using the bike sharing program in\nPittsburgh, PA, I will present a position on how discrimination can be\neliminated from the pipeline using Bayesian Optimization.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 20:45:10 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 05:10:08 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Morrison", "Katelyn", ""]]}, {"id": "2011.14036", "submitter": "Taro Makino", "authors": "Taro Makino, Stanislaw Jastrzebski, Witold Oleszkiewicz, Celin Chacko,\n  Robin Ehrenpreis, Naziya Samreen, Chloe Chhor, Eric Kim, Jiyon Lee, Kristine\n  Pysarenko, Beatriu Reig, Hildegard Toth, Divya Awal, Linda Du, Alice Kim,\n  James Park, Daniel K. Sodickson, Laura Heacock, Linda Moy, Kyunghyun Cho,\n  Krzysztof J. Geras", "title": "Differences between human and machine perception in medical diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) show promise in image-based medical diagnosis,\nbut cannot be fully trusted since their performance can be severely degraded by\ndataset shifts to which human perception remains invariant. If we can better\nunderstand the differences between human and machine perception, we can\npotentially characterize and mitigate this effect. We therefore propose a\nframework for comparing human and machine perception in medical diagnosis. The\ntwo are compared with respect to their sensitivity to the removal of clinically\nmeaningful information, and to the regions of an image deemed most suspicious.\nDrawing inspiration from the natural image domain, we frame both comparisons in\nterms of perturbation robustness. The novelty of our framework is that separate\nanalyses are performed for subgroups with clinically meaningful differences. We\nargue that this is necessary in order to avert Simpson's paradox and draw\ncorrect conclusions. We demonstrate our framework with a case study in breast\ncancer screening, and reveal significant differences between radiologists and\nDNNs. We compare the two with respect to their robustness to Gaussian low-pass\nfiltering, performing a subgroup analysis on microcalcifications and soft\ntissue lesions. For microcalcifications, DNNs use a separate set of high\nfrequency components than radiologists, some of which lie outside the image\nregions considered most suspicious by radiologists. These features run the risk\nof being spurious, but if not, could represent potential new biomarkers. For\nsoft tissue lesions, the divergence between radiologists and DNNs is even\nstarker, with DNNs relying heavily on spurious high frequency components\nignored by radiologists. Importantly, this deviation in soft tissue lesions was\nonly observable through subgroup analysis, which highlights the importance of\nincorporating medical domain knowledge into our comparison framework.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 00:32:17 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Makino", "Taro", ""], ["Jastrzebski", "Stanislaw", ""], ["Oleszkiewicz", "Witold", ""], ["Chacko", "Celin", ""], ["Ehrenpreis", "Robin", ""], ["Samreen", "Naziya", ""], ["Chhor", "Chloe", ""], ["Kim", "Eric", ""], ["Lee", "Jiyon", ""], ["Pysarenko", "Kristine", ""], ["Reig", "Beatriu", ""], ["Toth", "Hildegard", ""], ["Awal", "Divya", ""], ["Du", "Linda", ""], ["Kim", "Alice", ""], ["Park", "James", ""], ["Sodickson", "Daniel K.", ""], ["Heacock", "Laura", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "2011.14059", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu and Matthew Castelllana", "title": "Discrete Math with Programming: A Principled Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete mathematics is the foundation of computer science. It focuses on\nconcepts and reasoning methods that are studied using math notations. It has\nlong been argued that discrete math is better taught with programming, which\ntakes concepts and computing methods and turns them into executable programs.\nWhat has been lacking is a principled approach that supports all central\nconcepts of discrete math -- especially predicate logic -- and that directly\nand precisely connects math notations with executable programs. This paper\nintroduces such an approach. It is based on the use of a powerful language that\nextends the Python programming language with proper logic quantification (\"for\nall\" and \"exists some\"), as well as declarative set comprehension (also known\nas set builder) and aggregation (e.g., sum and product). Math and logical\nstatements can be expressed precisely at a high level and be executed directly\non a computer, encouraging declarative programming together with algorithmic\nprogramming. We describe the approach, detailed examples, experience in using\nit, and the lessons learned.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 03:41:27 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Castelllana", "Matthew", ""]]}, {"id": "2011.14075", "submitter": "Benjamin Laufer", "authors": "Benjamin Laufer", "title": "Feedback Effects in Repeat-Use Criminal Risk Assessments", "comments": "10 pages. arXiv admin note: substantial text overlap with\n  arXiv:2005.13404", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS cs.LG cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the criminal legal context, risk assessment algorithms are touted as\ndata-driven, well-tested tools. Studies known as validation tests are typically\ncited by practitioners to show that a particular risk assessment algorithm has\npredictive accuracy, establishes legitimate differences between risk groups,\nand maintains some measure of group fairness in treatment. To establish these\nimportant goals, most tests use a one-shot, single-point measurement. Using a\nPolya Urn model, we explore the implication of feedback effects in sequential\nscoring-decision processes. We show through simulation that risk can propagate\nover sequential decisions in ways that are not captured by one-shot tests. For\nexample, even a very small or undetectable level of bias in risk allocation can\namplify over sequential risk-based decisions, leading to observable group\ndifferences after a number of decision iterations. Risk assessment tools\noperate in a highly complex and path-dependent process, fraught with historical\ninequity. We conclude from this study that these tools do not properly account\nfor compounding effects, and require new approaches to development and\nauditing.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 06:40:05 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Laufer", "Benjamin", ""]]}, {"id": "2011.14192", "submitter": "Amatya Sharma", "authors": "Palash Dey, Arnab Maiti and Amatya Sharma", "title": "On Parameterized Complexity of Liquid Democracy", "comments": "Submitted to 7th Annual International Conference on Algorithms and\n  Discrete Applied Mathematics [CALDAM 2021]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In liquid democracy, each voter either votes herself or delegates her vote to\nsome other voter. This gives rise to what is called a delegation graph. To\ndecide the voters who eventually votes along with the subset of voters whose\nvotes they give, we need to resolve the cycles in the delegation graph. This\ngives rise to the Resolve Delegation problem where we need to find an acyclic\nsub-graph of the delegation graph such that the number of voters whose votes\nthey give is bounded above by some integer {\\lambda}. Putting a cap on the\nnumber of voters whose votes a voter gives enable the system designer restrict\nthe power of any individual voter. The Resolve Delegation problem is already\nknown to be NP-hard. In this paper we study the parameterized complexity of\nthis problem. We show that Resolve Delegation is para-NP-hard with respect to\nparameters {\\lambda}, number of sink nodes and the maximum degree of the\ndelegation graph. We also show that Resolve Delegation is W[1]-hard even with\nrespect to the treewidth of the delegation graph. We complement our negative\nresults by exhibiting FPT algorithms with respect to some other parameters. We\nfinally show that a related problem, which we call Resolve Fractional\nDelegation, is polynomial time solvable.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 18:48:22 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Dey", "Palash", ""], ["Maiti", "Arnab", ""], ["Sharma", "Amatya", ""]]}, {"id": "2011.14315", "submitter": "Shah Miah Prof", "authors": "Soliman Aljarboa, Shah J Miah", "title": "Assessing the Acceptance of Clinical Decision Support Tools using an\n  Integrated Technology Acceptance Model", "comments": null, "journal-ref": "IEEE CSDE Conference 2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the medical development in recent decades, the multiplicity of different\ndiseases, and an increased number of patients, the use of an advanced\nhealthcare information technology (HIT) such as a clinical decision support\nsystem (CDSS) has been of necessary to help general practitioners (GPs). CDSS\nmay fail due to the failure to understand the factors influencing the GP's\nacceptance of CDSS. Identifying factors that promote acceptance of CDSS can be\na vital aspect for its successful implementation. This study seeks to identify\nfactors that influence the acceptance of CDSS in Saudi Arabia by GPs. This\nstudy relies mainly on the unified theory of acceptance and use of technology\n(UTAUT) which has been integrated with a task-technology fit (TTF) model and\nhas applied a qualitative method to collect the data through using\nsemi-structured interviews with 12 GPs. The study's results indicated that\nperformance expectancy, effort expectancy, facilitating conditions, technology\nfit for the task, technology characteristics and task characteristics have all\ninfluenced the acceptance of CDSS. The results also indicated the need to\nextend the UTAUT model to investigate and explore other factors in GPs'\nacceptance of CDSS.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 08:52:07 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Aljarboa", "Soliman", ""], ["Miah", "Shah J", ""]]}, {"id": "2011.14326", "submitter": "Roland Molontay", "authors": "Kate Barnes, Tiernon Riesenmy, Minh Duc Trinh, Eli Lleshi, N\\'ora\n  Balogh, Roland Molontay", "title": "Dank or Not? -- Analyzing and Predicting the Popularity of Memes on\n  Reddit", "comments": "23 pages, 12 figures", "journal-ref": null, "doi": "10.1007/s41109-021-00358-7", "report-no": null, "categories": "cs.SI cs.CL cs.CV cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet memes have become an increasingly pervasive form of contemporary\nsocial communication that attracted a lot of research interest recently. In\nthis paper, we analyze the data of 129,326 memes collected from Reddit in the\nmiddle of March, 2020, when the most serious coronavirus restrictions were\nbeing introduced around the world. This article not only provides a looking\nglass into the thoughts of Internet users during the COVID-19 pandemic but we\nalso perform a content-based predictive analysis of what makes a meme go viral.\nUsing machine learning methods, we also study what incremental predictive power\nimage related attributes have over textual attributes on meme popularity. We\nfind that the success of a meme can be predicted based on its content alone\nmoderately well, our best performing machine learning model predicts viral\nmemes with AUC=0.68. We also find that both image related and textual\nattributes have significant incremental predictive power over each other.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 09:57:17 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 08:31:42 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Barnes", "Kate", ""], ["Riesenmy", "Tiernon", ""], ["Trinh", "Minh Duc", ""], ["Lleshi", "Eli", ""], ["Balogh", "N\u00f3ra", ""], ["Molontay", "Roland", ""]]}, {"id": "2011.14386", "submitter": "Eisa Alanazi", "authors": "Btool Hamoui, Abdulaziz Alashaikh, Eisa Alanazi", "title": "Google Searches and COVID-19 Cases in Saudi Arabia: A Correlation Study", "comments": "7 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: The outbreak of the new coronavirus disease (COVID-19) has\naffected human life to a great extent on a worldwide scale. During the\ncoronavirus pandemic, public health professionals at the early outbreak faced\nan extraordinary challenge to track and quantify the spread of disease.\nObjective: To investigate whether a digital surveillance model using google\ntrends (GT) is feasible to monitor the outbreak of coronavirus in the Kingdom\nof Saudi Arabia. Methods: We retrieve GT data using ten common COVID-19\nsymptoms related keywords from March 2, 2020, to October 31, 2020. Spearman\ncorrelation were performed to determine the correlation between COVID-19 cases\nand the Google search terms. Results: GT data related to Cough and Sore Throat\nwere the most searched symptoms by the Internet users in Saudi Arabia. The\nhighest daily correlation found with the Loss of Smell followed by Loss of\nTaste and Diarrhea. Strong correlation as well was found between the weekly\nconfirmed cases and the same symptoms: Loss of Smell, Loss of Taste and\nDiarrhea. Conclusions: We conducted an investigation study utilizing Internet\nsearches related to COVID-19 symptoms for surveillance of the pandemic spread.\nThis study documents that google searches can be used as a supplementary\nsurveillance tool in COVID-19 monitoring in Saudi Arabia.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2020 15:11:37 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Hamoui", "Btool", ""], ["Alashaikh", "Abdulaziz", ""], ["Alanazi", "Eisa", ""]]}, {"id": "2011.14754", "submitter": "Mostafa Haghi Kashani", "authors": "Sepideh Bazzaz Abkenar, Mostafa Haghi Kashani, Mohammad Akbari,\n  Ebrahim Mahdipour", "title": "Twitter Spam Detection: A Systematic Review", "comments": "18 pages, 12 figures, 14 tables, 91 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the rise of Internet access and mobile devices around the\nglobe, more people are using social networks for collaboration and receiving\nreal-time information. Twitter, the microblogging that is becoming a critical\nsource of communication and news propagation, has grabbed the attention of\nspammers to distract users. So far, researchers have introduced various defense\ntechniques to detect spams and combat spammer activities on Twitter. To\novercome this problem, in recent years, many novel techniques have been offered\nby researchers, which have greatly enhanced the spam detection performance.\nTherefore, it raises a motivation to conduct a systematic review about\ndifferent approaches of spam detection on Twitter. This review focuses on\ncomparing the existing research techniques on Twitter spam detection\nsystematically. Literature review analysis reveals that most of the existing\nmethods rely on Machine Learning-based algorithms. Among these Machine Learning\nalgorithms, the major differences are related to various feature selection\nmethods. Hence, we propose a taxonomy based on different feature selection\nmethods and analyses, namely content analysis, user analysis, tweet analysis,\nnetwork analysis, and hybrid analysis. Then, we present numerical analyses and\ncomparative studies on current approaches, coming up with open challenges that\nhelp researchers develop solutions in this topic.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:10:24 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 11:31:06 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Abkenar", "Sepideh Bazzaz", ""], ["Kashani", "Mostafa Haghi", ""], ["Akbari", "Mohammad", ""], ["Mahdipour", "Ebrahim", ""]]}, {"id": "2011.14775", "submitter": "Santu Sardar", "authors": "Santu Sardar, Amit K. Mishra and Mohammed Z. A. Khan", "title": "Crowd Size using CommSense Instrument for COVID-19 Echo Period", "comments": "Accepted in IEEE Consumer Electronics Magazine (IEEE-CEM); to be\n  Published", "journal-ref": null, "doi": "10.1109/MCE.2020.3032791", "report-no": null, "categories": "cs.NI cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The period after the COVID-19 wave is called the Echo-period. Estimation of\ncrowd size in an outdoor environment is essential in the Echo-period. Making a\nsimple and flexible working system for the same is the need of the hour. This\narticle proposes and evaluates a non-intrusive, passive, and costeffective\nsolution for crowd size estimation in an outdoor environment. We call the\nproposed system as LTE communication infrastructure based environment sensing\nor LTE-CommSense. This system does not need any active signal transmission as\nit uses LTE transmitted signal. So, this is a power-efficient, simple low\nfootprint device. Importantly, the personal identity of the people in the crowd\ncan not be obtained using this method. First, the system uses practical data to\ndetermine whether the outdoor environment is empty or not. If not, it tries to\nestimate the number of people occupying the near range locality. Performance\nevaluation with practical data confirms the feasibility of this proposed\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2020 12:22:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sardar", "Santu", ""], ["Mishra", "Amit K.", ""], ["Khan", "Mohammed Z. A.", ""]]}, {"id": "2011.14858", "submitter": "Aditya Jyoti Paul", "authors": "Puranjay Mohan, Aditya Jyoti Paul, Abhay Chirania", "title": "A Tiny CNN Architecture for Medical Face Mask Detection for\n  Resource-Constrained Endpoints", "comments": "11 pages, Published in Springer LNEE at\n  http://link.springer.com/chapter/10.1007%2F978-981-16-0749-3_52", "journal-ref": "Innovations in Electrical and Electronic Engineering. Lecture\n  Notes in Electrical Engineering, vol 756, pp 657-670, Springer, Singapore,\n  2021", "doi": "10.1007/978-981-16-0749-3_52", "report-no": null, "categories": "cs.CV cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world is going through one of the most dangerous pandemics of all time\nwith the rapid spread of the novel coronavirus (COVID-19). According to the\nWorld Health Organisation, the most effective way to thwart the transmission of\ncoronavirus is to wear medical face masks. Monitoring the use of face masks in\npublic places has been a challenge because manual monitoring could be unsafe.\nThis paper proposes an architecture for detecting medical face masks for\ndeployment on resource-constrained endpoints having extremely low memory\nfootprints. A small development board with an ARM Cortex-M7 microcontroller\nclocked at 480 Mhz and having just 496 KB of framebuffer RAM, has been used for\nthe deployment of the model. Using the TensorFlow Lite framework, the model is\nquantized to further reduce its size. The proposed model is 138 KB post\nquantization and runs at the inference speed of 30 FPS.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 14:56:23 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 18:52:33 GMT"}, {"version": "v3", "created": "Thu, 3 Jun 2021 12:55:21 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Mohan", "Puranjay", ""], ["Paul", "Aditya Jyoti", ""], ["Chirania", "Abhay", ""]]}]