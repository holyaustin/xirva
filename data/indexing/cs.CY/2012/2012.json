[{"id": "2012.00012", "submitter": "Liye Fu", "authors": "Liye Fu, Susan R. Fussell and Cristian Danescu-Niculescu-Mizil", "title": "Facilitating the Communication of Politeness through Fine-Grained\n  Paraphrasing", "comments": "Proceedings of EMNLP 2020, 14 pages. Data and code at\n  https://convokit.cornell.edu/ and\n  https://github.com/CornellNLP/politeness-paraphrase", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aided by technology, people are increasingly able to communicate across\ngeographical, cultural, and language barriers. This ability also results in new\nchallenges, as interlocutors need to adapt their communication approaches to\nincreasingly diverse circumstances. In this work, we take the first steps\ntowards automatically assisting people in adjusting their language to a\nspecific communication circumstance.\n  As a case study, we focus on facilitating the accurate transmission of\npragmatic intentions and introduce a methodology for suggesting paraphrases\nthat achieve the intended level of politeness under a given communication\ncircumstance. We demonstrate the feasibility of this approach by evaluating our\nmethod in two realistic communication scenarios and show that it can reduce the\npotential for misalignment between the speaker's intentions and the listener's\nperceptions in both cases.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 19:00:00 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Fu", "Liye", ""], ["Fussell", "Susan R.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "2012.00105", "submitter": "Nang Laik Ma Dr", "authors": "Nang Laik Ma, Gim Hong Chua", "title": "Using Data Analytics to predict students score", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Education is very important to Singapore, and the government has continued to\ninvest heavily in our education system to become one of the world-class systems\ntoday. A strong foundation of Science, Technology, Engineering, and Mathematics\n(STEM) was what underpinned Singapore's development over the past 50 years.\nPISA is a triennial international survey that evaluates education systems\nworldwide by testing the skills and knowledge of 15-year-old students who are\nnearing the end of compulsory education. In this paper, the authors used the\nPISA data from 2012 and 2015 and developed machine learning techniques to\npredictive the students' scores and understand the inter-relationships among\nsocial, economic, and education factors. The insights gained would be useful to\nhave fresh perspectives on education, useful for policy formulation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 13:04:55 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ma", "Nang Laik", ""], ["Chua", "Gim Hong", ""]]}, {"id": "2012.00106", "submitter": "Joseph Near", "authors": "Ivoline C. Ngong, Krystal Maughan, Joseph P. Near", "title": "Towards Auditability for Fairness in Deep Learning", "comments": "Presented at the workshop on Algorithmic Fairness through the Lens of\n  Causality and Interpretability (AFCI'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group fairness metrics can detect when a deep learning model behaves\ndifferently for advantaged and disadvantaged groups, but even models that score\nwell on these metrics can make blatantly unfair predictions. We present smooth\nprediction sensitivity, an efficiently computed measure of individual fairness\nfor deep learning models that is inspired by ideas from interpretability in\ndeep learning. smooth prediction sensitivity allows individual predictions to\nbe audited for fairness. We present preliminary experimental results suggesting\nthat smooth prediction sensitivity can help distinguish between fair and unfair\npredictions, and that it may be helpful in detecting blatantly unfair\npredictions from \"group-fair\" models.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:28:12 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ngong", "Ivoline C.", ""], ["Maughan", "Krystal", ""], ["Near", "Joseph P.", ""]]}, {"id": "2012.00136", "submitter": "Harry Halpin", "authors": "Harry Halpin", "title": "A Critique of Immunity Passports and W3C Decentralized Identifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Due to the widespread COVID-19 pandemic, there has been a push for `immunity\npassports' and even technical proposals. Although the debate about the medical\nand ethical problems of immunity passports has been widespread, there has been\nless inspection of the technical foundations of immunity passport schemes.\nThese schemes are envisaged to be used for sharing COVID-19 test and\nvaccination results in general. The most prominent immunity passport schemes\nhave involved a stack of little-known standards, such as Decentralized\nIdentifiers (DIDs) and Verifiable Credentials (VCs) from the World Wide Web\nConsortium (W3C). Our analysis shows that this group of technical identity\nstandards are based on under-specified and often non-standardized documents\nthat have substantial security and privacy issues, due in part to the\nquestionable use of blockchain technology. One concrete proposal for immunity\npassports is even susceptible to dictionary attacks. The use of `cryptography\ntheater' in efforts like immunity passports, where cryptography is used to\nallay the privacy concerns of users, should be discouraged in standardization.\nDeployment of these W3C standards for `self-sovereign identity' in use-cases\nlike immunity passports could just as well lead to a dangerous form identity\ntotalitarianism.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 22:10:43 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Halpin", "Harry", ""]]}, {"id": "2012.00289", "submitter": "Travis Greene", "authors": "Travis Greene, Galit Shmueli, Jan Fell, Ching-Fu Lin, Mark L. Shope,\n  Han-Wei Liu", "title": "The Hidden Inconsistencies Introduced by Predictive Algorithms in\n  Judicial Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithms, from simple automation to machine learning, have been introduced\ninto judicial contexts to ostensibly increase the consistency and efficiency of\nlegal decision making. In this paper, we describe four types of inconsistencies\nintroduced by risk prediction algorithms. These inconsistencies threaten to\nviolate the principle of treating similar cases similarly and often arise from\nthe need to operationalize legal concepts and human behavior into specific\nmeasures that enable the building and evaluation of predictive algorithms.\nThese inconsistencies, however, are likely to be hidden from their end-users:\njudges, parole officers, lawyers, and other decision-makers. We describe the\ninconsistencies, their sources, and propose various possible indicators and\nsolutions. We also consider the issue of inconsistencies due to the use of\nalgorithms in light of current trends towards more autonomous algorithms and\nless human-understandable behavioral big data. We conclude by discussing judges\nand lawyers' duties of technological (\"algorithmic\") competence and call for\ngreater alignment between the evaluation of predictive algorithms and\ncorresponding judicial goals.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 06:12:30 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Greene", "Travis", ""], ["Shmueli", "Galit", ""], ["Fell", "Jan", ""], ["Lin", "Ching-Fu", ""], ["Shope", "Mark L.", ""], ["Liu", "Han-Wei", ""]]}, {"id": "2012.00333", "submitter": "Sachin Thukral", "authors": "Sachin Thukral, Suyash Sangwan, Arnab Chatterjee, Lipika Dey", "title": "Identifying pandemic-related stress factors from social-media posts --\n  effects on students and young-adults", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has thrown natural life out of gear across the globe.\nStrict measures are deployed to curb the spread of the virus that is causing\nit, and the most effective of them have been social isolation. This has led to\nwide-spread gloom and depression across society but more so among the young and\nthe elderly. There are currently more than 200 million college students in 186\ncountries worldwide, affected due to the pandemic. The mode of education has\nchanged suddenly, with the rapid adaptation of e-learning, whereby teaching is\nundertaken remotely and on digital platforms. This study presents insights\ngathered from social media posts that were posted by students and young adults\nduring the COVID times. Using statistical and NLP techniques, we analyzed the\nbehavioral issues reported by users themselves in their posts in\ndepression-related communities on Reddit. We present methodologies to\nsystematically analyze content using linguistic techniques to find out the\nstress-inducing factors. Online education, losing jobs, isolation from friends,\nand abusive families emerge as key stress factors.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 08:42:27 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Thukral", "Sachin", ""], ["Sangwan", "Suyash", ""], ["Chatterjee", "Arnab", ""], ["Dey", "Lipika", ""]]}, {"id": "2012.00402", "submitter": "Sivaramakrishnan K N", "authors": "Sivaramakrishnan KN, Lipika Deka, Manik Gupta", "title": "Use of Remote Sensing Data to Identify Air Pollution Signatures in India", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Air quality has major impact on a country's socio-economic position and\nidentifying major air pollution sources is at the heart of tackling the issue.\nSpatially and temporally distributed air quality data acquisition across a\ncountry as varied as India has been a challenge to such analysis. The launch of\nthe Sentinel-5P satellite has helped in the observation of a wider variety of\nair pollutants than measured before at a global scale on a daily basis. In this\nchapter, spatio-temporal multi pollutant data retrieved from Sentinel-5P\nsatellite is used to cluster states as well as districts in India and\nassociated average monthly pollution signature and trends depicted by each of\nthe clusters are derived and presented.The clustering signatures can be used to\nidentify states and districts based on the types of pollutants emitted by\nvarious pollution sources.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 11:06:23 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 08:51:10 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["KN", "Sivaramakrishnan", ""], ["Deka", "Lipika", ""], ["Gupta", "Manik", ""]]}, {"id": "2012.00419", "submitter": "Wiebke Toussaint", "authors": "Wiebke Toussaint and Aaron Yi Ding", "title": "Machine Learning Systems in the IoT: Trustworthiness Trade-offs for Edge\n  Intelligence", "comments": "In Proceedings of the Second International Conference on Cognitive\n  Machine Intelligence (CogMI 2020)", "journal-ref": null, "doi": "10.1109/CogMI50398.2020.00030", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning systems (MLSys) are emerging in the Internet of Things (IoT)\nto provision edge intelligence, which is paving our way towards the vision of\nubiquitous intelligence. However, despite the maturity of machine learning\nsystems and the IoT, we are facing severe challenges when integrating MLSys and\nIoT in practical context. For instance, many machine learning systems have been\ndeveloped for large-scale production (e.g., cloud environments), but IoT\nintroduces additional demands due to heterogeneous and resource-constrained\ndevices and decentralized operation environment. To shed light on this\nconvergence of MLSys and IoT, this paper analyzes the trade-offs by covering\nthe latest developments (up to 2020) on scaling and distributing ML across\ncloud, edge, and IoT devices. We position machine learning systems as a\ncomponent of the IoT, and edge intelligence as a socio-technical system. On the\nchallenges of designing trustworthy edge intelligence, we advocate a holistic\ndesign approach that takes multi-stakeholder concerns, design requirements and\ntrade-offs into consideration, and highlight the future research opportunities\nin edge intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 11:42:34 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Toussaint", "Wiebke", ""], ["Ding", "Aaron Yi", ""]]}, {"id": "2012.00515", "submitter": "Pablo Arag\\'on", "authors": "Pablo Aragon, Adriana Alvarado Garcia, Christopher A. Le Dantec,\n  Claudia Flores-Saviaga, Jorge Saldivar", "title": "Civic Technologies: Research, Practice and Open Challenges", "comments": "Proposal, outcome and position papers of the 23rd ACM Conference on\n  Computer-Supported Cooperative Work and Social Computing (CSCW 2020) workshop\n  \"Civic Technologies: Research, Practice, and Open Challenges\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Over the last years, civic technology projects have emerged around the world\nto advance open government and community action. Although Computer-Supported\nCooperative Work (CSCW) and Human-Computer Interaction (HCI) communities have\nshown a growing interest in researching issues around civic technologies, yet\nmost research still focuses on projects from the Global North. The goal of this\nworkshop is, therefore, to advance CSCW research by raising awareness for the\nongoing challenges and open questions around civic technology by bridging the\ngap between researchers and practitioners from different regions.\n  The workshop will be organized around three central topics: (1) discuss how\nthe local context and infrastructure affect the design, implementation,\nadoption, and maintenance of civic technology; (2) identify key elements of the\nconfiguration of trust among government, citizenry, and local organizations and\nhow these elements change depending on the sociopolitical context where\ncommunity engagement takes place; (3) discover what methods and strategies are\nbest suited for conducting research on civic technologies in different\ncontexts. These core topics will be covered across sessions that will initiate\nin-depth discussions and, thereby, stimulate collaboration between the CSCW\nresearch community and practitioners of civic technologies from both Global\nNorth and South.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 14:26:40 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Aragon", "Pablo", ""], ["Garcia", "Adriana Alvarado", ""], ["Dantec", "Christopher A. Le", ""], ["Flores-Saviaga", "Claudia", ""], ["Saldivar", "Jorge", ""]]}, {"id": "2012.00530", "submitter": "Maria Bada Dr", "authors": "Maria Bada and Richard Clayton", "title": "Online Suicide Games: A Form of Digital Self-harm or A Myth?", "comments": "7 pages", "journal-ref": "In Wiederhold, B, & Riva, G. & Debb, S. Annual Review of\n  Cybertherapy and Telemedicine (ARCTT) International Association of\n  CyberPsychology, Training, and Rehabilitation (iACToR), 2019", "doi": null, "report-no": "Conference Proceedings CYPSY24: 24th Annual CyberPsychology,\n  CyberTherapy & Social Networking Conference, 2019", "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online suicide games are claimed to involve a series of challenges, ending in\nsuicide. A whole succession of these such as the Blue Whale Challenge, Momo,\nthe Fire Fairy and Doki Doki have appeared in recent years. The challenge\nculture is a deeply rooted online phenomenon, whether the challenge is\ndangerous or not, while social media particularly motivates youngsters to take\npart because of their desire for attention. Although there is no evidence that\nthe suicide games are real, authorities around the world have reacted by\nreleasing warnings and creating information campaigns to warn youngsters and\nparents. We interviewed teachers, child protection experts and NGOs, conducted\na systematic review of historical news reports from 2015-2019 and searched\npolice and other authority websites to identify relevant warning releases. We\nthen synthesized the existing knowledge on the suicide games phenomenon. A key\nfinding of our work is that media, social media and warning releases by\nauthorities are mainly just serving to spread the challenge culture and\nexaggerate fears regarding online risk.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 14:45:47 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bada", "Maria", ""], ["Clayton", "Richard", ""]]}, {"id": "2012.00552", "submitter": "Cristina Abad", "authors": "Cristina L. Abad, Eduardo Ortiz-Holguin, Edwin F. Boza", "title": "Have We Reached Consensus? An Analysis of Distributed Systems Syllabi", "comments": "Accepted for publication at ACM SIGCSE Technical Symposium 2021:\n  https://sigcse2021.sigcse.org/ Publication DOI (already assigned by ACM):\n  10.1145/3408877.3432409 Dataset available at:\n  https://zenodo.org/record/4290623#.X8ZaOWjYre8", "journal-ref": null, "doi": "10.1145/3408877.3432409", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correctly applying distributed systems concepts is important for software\nthat seeks to be scalable, reliable and fast. For this reason, Distributed\nSystems is a course included in many Computer Science programs. To both\ndescribe current trends in teaching distributed systems and as a reference for\neducators that seek to improve the quality of their syllabi, we present a\nreview of 51 syllabi of distributed systems courses from top Computer Science\nprograms around the world. We manually curated the syllabi and extracted data\nthat allowed us to identify approaches used in teaching this subject, including\nchoice of topics, book, and paper reading list. We present our results and a\ndiscussion on whether what is being taught matches the guidelines of two\nimportant curriculum initiatives.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 15:00:32 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Abad", "Cristina L.", ""], ["Ortiz-Holguin", "Eduardo", ""], ["Boza", "Edwin F.", ""]]}, {"id": "2012.00874", "submitter": "Patrick Kelley", "authors": "Allison Woodruff and Yasmin Asare Anderson and Katherine Jameson\n  Armstrong and Marina Gkiza and Jay Jennings and Christopher Moessner and\n  Fernanda Viegas and Martin Wattenberg and and Lynette Webb and Fabian Wrede\n  and Patrick Gage Kelley", "title": "\"A cold, technical decision-maker\": Can AI provide explainability,\n  negotiability, and humanity?", "comments": "23 pages, 1 appendix, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithmic systems are increasingly deployed to make decisions in many areas\nof people's lives. The shift from human to algorithmic decision-making has been\naccompanied by concern about potentially opaque decisions that are not aligned\nwith social values, as well as proposed remedies such as explainability. We\npresent results of a qualitative study of algorithmic decision-making,\ncomprised of five workshops conducted with a total of 60 participants in\nFinland, Germany, the United Kingdom, and the United States. We invited\nparticipants to reason about decision-making qualities such as explainability\nand accuracy in a variety of domains. Participants viewed AI as a\ndecision-maker that follows rigid criteria and performs mechanical tasks well,\nbut is largely incapable of subjective or morally complex judgments. We discuss\nparticipants' consideration of humanity in decision-making, and introduce the\nconcept of 'negotiability,' the ability to go beyond formal criteria and work\nflexibly around the system.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 22:36:54 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Woodruff", "Allison", ""], ["Anderson", "Yasmin Asare", ""], ["Armstrong", "Katherine Jameson", ""], ["Gkiza", "Marina", ""], ["Jennings", "Jay", ""], ["Moessner", "Christopher", ""], ["Viegas", "Fernanda", ""], ["Wattenberg", "Martin", ""], ["Webb", "and Lynette", ""], ["Wrede", "Fabian", ""], ["Kelley", "Patrick Gage", ""]]}, {"id": "2012.01022", "submitter": "Ritwik Gupta", "authors": "Ritwik Gupta, Eric T. Heim", "title": "Proceedings of NeurIPS 2019 Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the \"proceedings\" of the 1st AI + HADR workshop which was held in\nVancouver, Canada on December 13, 2019 as part of the Neural Information\nProcessing Systems conference. These are non-archival and serve solely as a\ncollation of all the papers accepted to the workshop.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 08:19:55 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 17:43:43 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gupta", "Ritwik", ""], ["Heim", "Eric T.", ""]]}, {"id": "2012.01126", "submitter": "Swati Padhee", "authors": "Swati Padhee (1), Amanuel Alambo (1), Tanvi Banerjee (1), Arvind\n  Subramaniam (2), Daniel M. Abrams (3), Gary K.Nave Jr. (3), Nirmish Shah (2)\n  ((1) Wright State University, (2) Duke University, (3) Northwestern\n  University)", "title": "Pain Intensity Assessment in Sickle Cell Disease patients using Vital\n  Signs during Hospital Visits", "comments": "Accepted for presentation at the FIRST WORKSHOP ON COMPUTATIONAL &\n  AFFECTIVE INTELLIGENCE IN HEALTHCARE APPLICATIONS (VULNERABLE POPULATIONS) In\n  Conjunction with the International Conference on Pattern Recognition (ICPR)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pain in sickle cell disease (SCD) is often associated with increased\nmorbidity, mortality, and high healthcare costs. The standard method for\npredicting the absence, presence, and intensity of pain has long been\nself-report. However, medical providers struggle to manage patients based on\nsubjective pain reports correctly and pain medications often lead to further\ndifficulties in patient communication as they may cause sedation and\nsleepiness. Recent studies have shown that objective physiological measures can\npredict subjective self-reported pain scores for inpatient visits using machine\nlearning (ML) techniques. In this study, we evaluate the generalizability of ML\ntechniques to data collected from 50 patients over an extended period across\nthree types of hospital visits (i.e., inpatient, outpatient and outpatient\nevaluation). We compare five classification algorithms for various pain\nintensity levels at both intra-individual (within each patient) and\ninter-individual (between patients) level. While all the tested classifiers\nperform much better than chance, a Decision Tree (DT) model performs best at\npredicting pain on an 11-point severity scale (from 0-10) with an accuracy of\n0.728 at an inter-individual level and 0.653 at an intra-individual level. The\naccuracy of DT significantly improves to 0.941 on a 2-point rating scale (i.e.,\nno/mild pain: 0-5, severe pain: 6-10) at an intra-individual level. Our\nexperimental results demonstrate that ML techniques can provide an objective\nand quantitative evaluation of pain intensity levels for all three types of\nhospital visits.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 15:25:29 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Padhee", "Swati", ""], ["Alambo", "Amanuel", ""], ["Banerjee", "Tanvi", ""], ["Subramaniam", "Arvind", ""], ["Abrams", "Daniel M.", ""], ["Nave", "Gary K.", "Jr."], ["Shah", "Nirmish", ""]]}, {"id": "2012.01127", "submitter": "Tetiana Vakaliuk", "authors": "Tetiana A. Vakaliuk, Valerii V. Kontsedailo, Dmytro S. Antoniuk, Olha\n  V. Korotun, Iryna S. Mintii and Andrey V. Pikilnyak", "title": "Using game simulator Software Inc in the Software Engineering education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents the possibilities of using game simulator Sotware Inc in\nthe training of future software engineer in higher education. Attention is\ndrawn to some specific settings that need to be taken into account when\ntraining in the course of training future software engineers. More and more\neducational institutions are introducing new teaching methods, which result in\nthe use of engineering students, in particular, future software engineers, to\ndeal with real professional situations in the learning process. The use of\nmodern ICT, including game simulators, in the educational process, allows to\nimprove the quality of educational material and to enhance the educational\neffects from the use of innovative pedagogical programs and methods, as it\ngives teachers additional opportunities for constructing individual educational\ntrajectories of students. The use of ICT allows for a differentiated approach\nto students with different levels of readiness to study. A feature of any\nsoftware engineer is the need to understand the related subject area for which\nthe software is being developed. An important condition for the preparation of\na highly qualified specialist is the independent fulfillment by the student of\nscientific research, the generation, and implementation of his idea into a\nfinished commercial product. In the process of research, students gain\nknowledge, skills of the future IT specialist and competences of the legal\nprotection of the results of intellectual activity, technological audit,\nmarketing, product realization in the market of innovations. Note that when the\nreal-world practice is impossible for students, game simulators that simulate\nreal software development processes are an alternative.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 13:26:55 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Vakaliuk", "Tetiana A.", ""], ["Kontsedailo", "Valerii V.", ""], ["Antoniuk", "Dmytro S.", ""], ["Korotun", "Olha V.", ""], ["Mintii", "Iryna S.", ""], ["Pikilnyak", "Andrey V.", ""]]}, {"id": "2012.01128", "submitter": "Francois Roewer-Despres", "authors": "Francois Roewer-Despres, Janelle Berscheid", "title": "Continuous Subject-in-the-Loop Integration: Centering AI on Marginalized\n  Communities", "comments": "4 pages, Accepted at the Resistance AI Workshop @ NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its utopian promises as a disruptive equalizer, AI - like most tools\ndeployed under the guise of neutrality - has tended to simply reinforce\nexisting social structures. To counter this trend, radical AI calls for\ncentering on the marginalized. We argue that gaps in key infrastructure are\npreventing the widespread adoption of radical AI, and propose a guiding\nprinciple for both identifying these infrastructure gaps and evaluating whether\nproposals for new infrastructure effectively center marginalized voices.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 00:56:11 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Roewer-Despres", "Francois", ""], ["Berscheid", "Janelle", ""]]}, {"id": "2012.01138", "submitter": "Farah Shamout", "authors": "Ghadeer O. Ghosheh, Bana Alamad, Kai-Wen Yang, Faisil Syed, Nasir\n  Hayat, Imran Iqbal, Fatima Al Kindi, Sara Al Junaibi, Maha Al Safi, Raghib\n  Ali, Walid Zaher, Mariam Al Harbi, Farah E. Shamout", "title": "Clinical prediction system of complications among COVID-19 patients: a\n  development and validation retrospective multicentre study", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing prognostic tools mainly focus on predicting the risk of mortality\namong patients with coronavirus disease 2019. However, clinical evidence\nsuggests that COVID-19 can result in non-mortal complications that affect\npatient prognosis. To support patient risk stratification, we aimed to develop\na prognostic system that predicts complications common to COVID-19. In this\nretrospective study, we used data collected from 3,352 COVID-19 patient\nencounters admitted to 18 facilities between April 1 and April 30, 2020, in Abu\nDhabi (AD), UAE. The hospitals were split based on geographical proximity to\nassess for our proposed system's learning generalizability, AD Middle region\nand AD Western & Eastern regions, A and B, respectively. Using data collected\nduring the first 24 hours of admission, the machine learning-based prognostic\nsystem predicts the risk of developing any of seven complications during the\nhospital stay. The complications include secondary bacterial infection, AKI,\nARDS, and elevated biomarkers linked to increased patient severity, including\nd-dimer, interleukin-6, aminotransferases, and troponin. During training, the\nsystem applies an exclusion criteria, hyperparameter tuning, and model\nselection for each complication-specific model. The system achieves good\naccuracy across all complications and both regions. In test set A (587 patient\nencounters), the system achieves 0.91 AUROC for AKI and >0.80 AUROC for most of\nthe other complications. In test set B (225 patient encounters), the respective\nsystem achieves 0.90 AUROC for AKI, elevated troponin, and elevated\ninterleukin-6, and >0.80 AUROC for most of the other complications. The best\nperforming models, as selected by our system, were mainly gradient boosting\nmodels and logistic regression. Our results show that a data-driven approach\nusing machine learning can predict the risk of such complications with high\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 18:16:23 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Ghosheh", "Ghadeer O.", ""], ["Alamad", "Bana", ""], ["Yang", "Kai-Wen", ""], ["Syed", "Faisil", ""], ["Hayat", "Nasir", ""], ["Iqbal", "Imran", ""], ["Kindi", "Fatima Al", ""], ["Junaibi", "Sara Al", ""], ["Safi", "Maha Al", ""], ["Ali", "Raghib", ""], ["Zaher", "Walid", ""], ["Harbi", "Mariam Al", ""], ["Shamout", "Farah E.", ""]]}, {"id": "2012.01139", "submitter": "Uriel Melendres", "authors": "Charis Ann M. Sancho and Uriel M. Melendres", "title": "Development of Dynamic Local Area Network (LAN) Based Mock Board\n  Examination System", "comments": "18 pages", "journal-ref": "International Journal of Computing Sciences Research, 5(1),\n  502-518 (2021)", "doi": "10.25147/ijcsr.2017.001.1.55", "report-no": "IT4BHEEEM-2020-004", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose-Mock board exam is necessary to identify if the students are ready to\ntake the board exam. However, preparing for the examination is not easy. It\ntakes too much time to release the result, given that the College has limited\npersonnel. Thus, the proponents developed the Dynamic Local Area Network (LAN)\nBased Mock Board Examination System that makes the preparation and checking\neasy.\n  Method-The proponents followed the iterative waterfall model to develop the\nsystem efficiently. Some criteria of ISO 25010 were adopted in the evaluation\ninstrument. Simultaneously, evaluators are composed of program chairperson,\nCollege of Computer Studies (CCS) faculty, board program students, and alumni.\n  Results-The result of 4.91 in Functional Suitability, 4.87 in Performance\nEfficiency, 4.91 in Usability, 4.90 in Security, and 4.92 in Maintainability\nshows that the system is fully functional and is usable by any board program.\n  Conclusion The computer-based examination, implemented through LAN, can\nsimplify administering personnel of MinSCAT mock board examination. The\ndevelopment of the \"Dynamic LAN Based Mock Board Examination System\" is a great\nhelp to the MinSCAT and their board program graduates if it is implemented.\n  Recommendations-The system has hidden weaknesses that were only identified in\nactual operation. Thus, further testing is needed, like beta testing, to\nidentify and correct it for better performance. After beta-testing, the system\ncan be improved through iteration of the Waterfall Model phases.\n  Research Implications-The developed system can improve the mock board\nexamination process and ease preparing this significant examination. Moreover,\nit immediately provides a result that helps the examinees to identify their\nweaknesses and do a further review to master it.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 08:10:06 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Sancho", "Charis Ann M.", ""], ["Melendres", "Uriel M.", ""]]}, {"id": "2012.01144", "submitter": "Carlos Maltzahn", "authors": "Stephanie Lieggi and Ivo Jimenez and Jeff LeFevre and Carlos Maltzahn", "title": "The CROSS Incubator: A Case Study for funding and training RSEs", "comments": "Presented at RSE-HPC 2020: Research Software Engineers in HPC -\n  Creating Community, Building Careers, Addressing Challenges, co-located with\n  SC20, Virtual, November 12, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The incubator and research projects sponsored by the Center for Research in\nOpen Source Software (CROSS, cross.ucsc.edu) at UC Santa Cruz have been very\neffective at promoting the professional and technical development of research\nsoftware engineers. Carlos Maltzahn founded CROSS in 2015 with a generous gift\nof $2,000,000 from UC Santa Cruz alumnus Dr. Sage Weil and founding memberships\nof Toshiba America Electronic Components, SK Hynix Memory Solutions, and Micron\nTechnology. Over the past five years, CROSS funding has enabled PhD students to\nnot only create research software projects but also learn how to draw in new\ncontributors and leverage established open source software communities. This\nposition paper will present CROSS fellowships as case studies for how\nuniversity-led open source projects can create a real-world, reproducible model\nfor effectively training, funding and supporting research software engineers.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 20:16:43 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Lieggi", "Stephanie", ""], ["Jimenez", "Ivo", ""], ["LeFevre", "Jeff", ""], ["Maltzahn", "Carlos", ""]]}, {"id": "2012.01148", "submitter": "Yilei Zeng", "authors": "Yilei Zeng, Aayush Shah, Jameson Thai, Michael Zyda", "title": "Applied Machine Learning for Games: A Graduate School Course", "comments": "The Eleventh Symposium on Educational Advances in Artificial\n  Intelligence (EAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The game industry is moving into an era where old-style game engines are\nbeing replaced by re-engineered systems with embedded machine learning\ntechnologies for the operation, analysis and understanding of game play. In\nthis paper, we describe our machine learning course designed for graduate\nstudents interested in applying recent advances of deep learning and\nreinforcement learning towards gaming. This course serves as a bridge to foster\ninterdisciplinary collaboration among graduate schools and does not require\nprior experience designing or building games. Graduate students enrolled in\nthis course apply different fields of machine learning techniques such as\ncomputer vision, natural language processing, computer graphics, human computer\ninteraction, robotics and data analysis to solve open challenges in gaming.\nStudent projects cover use-cases such as training AI-bots in gaming benchmark\nenvironments and competitions, understanding human decision patterns in gaming,\nand creating intelligent non-playable characters or environments to foster\nengaging gameplay. Projects demos can help students open doors for an industry\ncareer, aim for publications, or lay the foundations of a future product. Our\nstudents gained hands-on experience in applying state of the art machine\nlearning techniques to solve real-life problems in gaming.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 05:46:14 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 18:06:59 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Zeng", "Yilei", ""], ["Shah", "Aayush", ""], ["Thai", "Jameson", ""], ["Zyda", "Michael", ""]]}, {"id": "2012.01162", "submitter": "Kenn Migan Vincent Gumonan", "authors": "Kenn Migan Vincent C. Gumonan, and Aleta C. Fabregas", "title": "ASIAVR: Asian Studies Virtual Reality Game a Learning Tool", "comments": "14 pages, 10 figures, presented in International Science, Technology\n  and Engineering Conference ISTEC 2019, and published in International Journal\n  of Computing Sciences Research", "journal-ref": null, "doi": "10.25147/ijcsr.2017.001.1.53", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study aims to develop an application that will serve as an alternative\nlearning tool for learning Asian Studies. The delivery of lessons into a\nvirtual reality game depends on the pace of students. The developed application\ncomprises several more features that enable users to get valuable information\nfrom an immersive environment. The researchers used Rapid Application\nDevelopment (RAD) in developing the application. It follows phases such as\nrequirement planning, user design, construction, and cutover. Two sets of\nquestionnaires were developed, one for the teachers and another for the\nstudents. Then, testing and evaluation were conducted through purposive\nsampling to select the respondents. The application was overall rated as 3.56\nwhich is verbally interpreted as very good. The result was based on the system\nevaluation using ISO 9126 in terms of functionality, usability, content,\nreliability, and performance. The developed application meets the objectives to\nprovide an alternative learning tool for learning Asian Studies. The\napplication is well commended and accepted by the end-users to provide an\ninteractive and immersive environment for students to learn at their own pace.\nFurther enhancement of the audio, gameplay, and graphics of the tool. Schools\nshould take into consideration the adoption of the Asian Studies Virtual\nReality is a good alternative tool for their teachers and students to teach and\nlearn Asian Studies. The use of more 3D objects relevant to the given\ninformation to enhance the game experience may be considered. A databank for\nthe quiz questions that will be loaded into the game should also be considered.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 04:24:03 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Gumonan", "Kenn Migan Vincent C.", ""], ["Fabregas", "Aleta C.", ""]]}, {"id": "2012.01165", "submitter": "Chinasa Okolo", "authors": "Chinasa T. Okolo", "title": "AI in the \"Real World\": Examining the Impact of AI Deployment in\n  Low-Resource Contexts", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As AI becomes integrated throughout the world, its potential for impact\nwithin low-resource regions around the Global South have grown. AI research\nlabs from tech giants like Microsoft, Google, and IBM have a significant\npresence in countries such as India, Ghana, and South Africa. The work done by\nthese labs is often motivated by the potential impact it could have on local\npopulations, but the deployment of these tools has not always gone smoothly.\nThis paper presents a case study examining the deployment of AI by large\nindustry labs situated in low-resource contexts, highlights factors impacting\nunanticipated deployments, and reflects on the state of AI deployment within\nthe Global South, providing suggestions that embrace inclusive design\nmethodologies within AI development that prioritize the needs of marginalized\ncommunities and elevate their status not just as beneficiaries of AI systems\nbut as primary stakeholders.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 01:49:24 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Okolo", "Chinasa T.", ""]]}, {"id": "2012.01167", "submitter": "Albert Paytaren", "authors": "Albert V. Paytaren", "title": "Seminar and Training Programs Recommender System for Faculty Members of\n  Higher Education Institution", "comments": null, "journal-ref": "International Journal of Computing Sciences Research (ISSN print:\n  2546-0552; ISSN online: 2546-115X) Vol. 4, No. 4, pp. 359-369, 2020", "doi": "10.25147/ijcsr.2017.001.1.43", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study aims to develop a personalized Recommender System that helps to\naddress the problems encountered by the faculty members of Higher Education\nInstitutions in the selection of Seminar and Training Programs (STP). The\nresearcher used the Descriptive Developmental Method of research to gather\ninformation relevant to the current problems and challenges encountered and\nused these to develop software that addresses the identified challenges. For\nthe development of the software, the researcher adopted a step-wise approach\ndefined in the Incremental Developmental Model. The level of acceptance of the\ndeveloped system was evaluated by 24 faculty respondents. The level of\nacceptance of the developed system was classified into functionality,\nreliability, and usability and the study garnered an evaluation score of 4.65,\n4.67, and 4.67 respectively. The overall interpretation of the results of the\nevaluation is Highly Acceptable. The study created a system that provides\nseminars and training program recommendations. The developed recommender system\nwas rated Highly Acceptable, respondents were very satisfied with the features\nof the system and agreed that it was functional, reliable, and usable.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 00:53:51 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Paytaren", "Albert V.", ""]]}, {"id": "2012.01168", "submitter": "Arvind  Kiwelekar", "authors": "Arvind W. Kiwelekar, Sanil S. Gandhi, Laxaman D. Netak, Shankar B.\n  Deosarkar", "title": "Use-cases of Blockchain Technology for Humanitarian Engineering", "comments": "23 pages", "journal-ref": "in book Information and Communication Technologies for\n  Humanitarian Services, pp143-163 (2020)", "doi": "10.1049/PBTE089E_ch", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Humanitarian Engineers need innovative methods to make technological\ninterventions for solving societal problems. The emerging blockchain technology\nhas the enormous potential to provide effective interventions in various\ndevelopmental sectors, including Agriculture, Education, Health, and\nTransportation. In these sectors, mediators have been considered as one of the\nimpediments for developmental work. Blockchain technology facilitates\npeer-to-peer business transactions, thus eliminating the role of mediators.\nHence, the blockchain technology is emerging as an alternative to conventional\nmediator-centred solutions adopting client-server based Internet technologies.\nA combination of blockchain technology with other technologies can be used to\naddress domain-specific challenges. For example, the combination of blockchain\ntechnology and Internet-of-Thing (IoT) has the potential to monitor the usage\nof scarce resources such as the level of ground-water and amount of energy\nconsumption. The aims of this chapter are twofold. Firstly, it describes the\nprimary building blocks of blockchain technology. Secondly, it illustrates\nvarious use-case scenarios of blockchain technology in the fields of\nAgriculture, Energy Health and others.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 13:19:06 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Kiwelekar", "Arvind W.", ""], ["Gandhi", "Sanil S.", ""], ["Netak", "Laxaman D.", ""], ["Deosarkar", "Shankar B.", ""]]}, {"id": "2012.01171", "submitter": "Bartolomeo Silvestri", "authors": "Bartolomeo Silvestri, Alessandro Rinaldi, Antonella Berardi, Michele\n  Roccotelli, Simone Acquaviva and Maria Pia Fanti", "title": "A Serious Game Approach for the Electro-Mobility Sector", "comments": "This paper has been presented at 2019 IEEE International Conference\n  on Systems, Man and Cybernetics (SMC)", "journal-ref": null, "doi": "10.1109/SMC.2019.8914388", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Serious Games (SGs) represent a new approach to improve learning processes\nmore effectively and economically than traditional methods. This paper aims to\npresent a SG approach for the electro-mobility context, in order to encourage\nthe use of electric light vehicles. The design of the SG is based on the\ntypical elements of the classic \"game\" with a real gameplay with different\npurposes. In this work, the proposed SG aims to raise awareness on\nenvironmental issues caused by mobility and actively involve users, on\nimproving livability in the city and on real savings using alternative means to\ntraditional vehicles. The objective of the designed tool is to propose elements\nof fun and entertainment for tourists or users of electric vehicles in the\ncities, while giving useful information about the benefits of using such\nvehicles, discovering touristic and interesting places in the city to discover.\nIn this way, the user is stimulated to explore the artistic and historical\naspects of the city through an effective learning process: he/she is encouraged\nto search the origins and the peculiarities of the monuments.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 13:41:35 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Silvestri", "Bartolomeo", ""], ["Rinaldi", "Alessandro", ""], ["Berardi", "Antonella", ""], ["Roccotelli", "Michele", ""], ["Acquaviva", "Simone", ""], ["Fanti", "Maria Pia", ""]]}, {"id": "2012.01172", "submitter": "Burak Yildiz", "authors": "Burak Yildiz, Hayley Hung, Jesse H. Krijthe, Cynthia C. S. Liem, Marco\n  Loog, Gosia Migut, Frans Oliehoek, Annibale Panichella, Przemyslaw Pawelczak,\n  Stjepan Picek, Mathijs de Weerdt, and Jan van Gemert", "title": "ReproducedPapers.org: Openly teaching and structuring machine learning\n  reproducibility", "comments": "Accepted to RRPR 2020: Third Workshop on Reproducible Research in\n  Pattern Recognition", "journal-ref": null, "doi": "10.1007/978-3-030-76423-4_1", "report-no": null, "categories": "cs.CY cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present ReproducedPapers.org: an open online repository for teaching and\nstructuring machine learning reproducibility. We evaluate doing a reproduction\nproject among students and the added value of an online reproduction repository\namong AI researchers. We use anonymous self-assessment surveys and obtained 144\nresponses. Results suggest that students who do a reproduction project place\nmore value on scientific reproductions and become more critical thinkers.\nStudents and AI researchers agree that our online reproduction repository is\nvaluable.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 11:19:45 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Yildiz", "Burak", ""], ["Hung", "Hayley", ""], ["Krijthe", "Jesse H.", ""], ["Liem", "Cynthia C. S.", ""], ["Loog", "Marco", ""], ["Migut", "Gosia", ""], ["Oliehoek", "Frans", ""], ["Panichella", "Annibale", ""], ["Pawelczak", "Przemyslaw", ""], ["Picek", "Stjepan", ""], ["de Weerdt", "Mathijs", ""], ["van Gemert", "Jan", ""]]}, {"id": "2012.01180", "submitter": "Julius Garcia", "authors": "Julius G. Garcia, Connie C. Aunario, Go Frendi Gunawan", "title": "Usability Dimensions and Behavioral Intention to Use Markdown to Moodle\n  in Test Construction", "comments": "IJEMT, Vol. 13, No. 1, 2019, pp.44 to 53, ISSN 1882 2290", "journal-ref": "International Journal for Educational Media and Technology 2019,\n  Vol.13, No. 1", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Creating test with numerous items in Moodle can be tedious and less intuitive\ncompared to conventional method. This study aims to determine the Markdown to\nMoodle performance in easing the test construction process and explain the\nunderlying factors of the behavioral intention to use the application. Markdown\nto Moodle is an application that allows users to type the bulk of test items\ndirectly to the browser and generates .doc, .md and .xml files stored in the\nlocal drive. The .xml can be imported to Moodle test bank. This lessens the\ntime of creating test items one at a time in the Moodle. A training and a\nsurvey were conducted among teachers with Moodle usage experience. Results from\nthis study allowed the researchers to determine the usability of the\napplication and the users behavioral intention. This highlights the workflow\ncontinuity in test construction as a key factor in the usage and performance of\nthe application.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 19:01:06 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Garcia", "Julius G.", ""], ["Aunario", "Connie C.", ""], ["Gunawan", "Go Frendi", ""]]}, {"id": "2012.01184", "submitter": "J\\'er\\^ome Darmont", "authors": "Pegdwend\\'e Sawadogo, J\\'er\\^ome Darmont, Fabien Duchateau", "title": "Feedback from the participants of the ADBIS, TPDL and EDA 2020 joint\n  conferences", "comments": "7 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents the way the joint ADBIS, TPDL and EDA 2020 conferences\nwere organized online and the results of the participant survey conducted\nthereafter. We present the lessons learned from the participants' feedback.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 17:02:26 GMT"}, {"version": "v2", "created": "Sat, 19 Dec 2020 22:03:07 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Sawadogo", "Pegdwend\u00e9", ""], ["Darmont", "J\u00e9r\u00f4me", ""], ["Duchateau", "Fabien", ""]]}, {"id": "2012.01186", "submitter": "Hao Sheng", "authors": "Eric Li, Jingyi Su, Hao Sheng, Lawrence Wai", "title": "AGenT Zero: Zero-shot Automatic Multiple-Choice Question Generation for\n  Skill Assessments", "comments": "AAAI 2021 Workshop on AI Education/TIPCE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-choice questions (MCQs) offer the most promising avenue for skill\nevaluation in the era of virtual education and job recruiting, where\ntraditional performance-based alternatives such as projects and essays have\nbecome less viable, and grading resources are constrained. The automated\ngeneration of MCQs would allow assessment creation at scale. Recent advances in\nnatural language processing have given rise to many complex question generation\nmethods. However, the few methods that produce deployable results in specific\ndomains require a large amount of domain-specific training data that can be\nvery costly to acquire. Our work provides an initial foray into MCQ generation\nunder high data-acquisition cost scenarios by strategically emphasizing\nparaphrasing the question context (compared to the task). In addition to\nmaintaining semantic similarity between the question-answer pairs, our\npipeline, which we call AGenT Zero, consists of only pre-trained models and\nrequires no fine-tuning, minimizing data acquisition costs for question\ngeneration. AGenT Zero successfully outperforms other pre-trained methods in\nfluency and semantic similarity. Additionally, with some small changes, our\nassessment pipeline can be generalized to a broader question and answer space,\nincluding short answer or fill in the blank questions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 04:06:57 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 23:46:56 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Li", "Eric", ""], ["Su", "Jingyi", ""], ["Sheng", "Hao", ""], ["Wai", "Lawrence", ""]]}, {"id": "2012.01187", "submitter": "Sepinoud Azimi", "authors": "Sepinoud Azimi, Carmen-Gabriela Popa, and Tatjana Cuci\\'c", "title": "Improving Students Performance in Small-Scale Online Courses -- A\n  Machine Learning-Based Intervention", "comments": null, "journal-ref": null, "doi": "10.3991/ijai.v2i2.19371", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The birth of massive open online courses (MOOCs) has had an undeniable effect\non how teaching is being delivered. It seems that traditional in class teaching\nis becoming less popular with the young generation, the generation that wants\nto choose when, where and at what pace they are learning. As such, many\nuniversities are moving towards taking their courses, at least partially,\nonline. However, online courses, although very appealing to the younger\ngeneration of learners, come at a cost. For example, the dropout rate of such\ncourses is higher than that of more traditional ones, and the reduced in person\ninteraction with the teachers results in less timely guidance and intervention\nfrom the educators. Machine learning (ML) based approaches have shown\nphenomenal successes in other domains. The existing stigma that applying ML\nbased techniques requires a large amount of data seems to be a bottleneck when\ndealing with small scale courses with limited amounts of produced data. In this\nstudy, we show not only that the data collected from an online learning\nmanagement system could be well utilized in order to predict students overall\nperformance but also that it could be used to propose timely intervention\nstrategies to boost the students performance level. The results of this study\nindicate that effective intervention strategies could be suggested as early as\nthe middle of the course to change the course of students progress for the\nbetter. We also present an assistive pedagogical tool based on the outcome of\nthis study, to assist in identifying challenging students and in suggesting\nearly intervention strategies.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 14:12:55 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Azimi", "Sepinoud", ""], ["Popa", "Carmen-Gabriela", ""], ["Cuci\u0107", "Tatjana", ""]]}, {"id": "2012.01188", "submitter": "Chinelo Oribhabor", "authors": "Chinelo Blessing Oribhabor", "title": "Investigating the Influence of Computer Anxiety on the Academic\n  Performance of Junior Secondary School Students in Computer Studies in\n  Nigeria", "comments": "12 pages", "journal-ref": "International Journal of Computing Sciences Research Vol. 4, No.\n  4, (2020) pp. 370-382", "doi": null, "report-no": "ISSN print: 2546-0552; ISSN online: 2546-115X", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study examined the influence of computer anxiety on the academic\nperformance of junior secondary school students in Computer Studies in Nigeria.\nThe research instrument that was used in the study was computer anxiety scale\nwhich was validated by the Guidance and Counseling lecturers and Educational\nMeasurement and Evaluation experts. The result of the study showed that most of\nthe students used in the study were mildly anxious when dealing with computer.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 12:32:23 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Oribhabor", "Chinelo Blessing", ""]]}, {"id": "2012.01191", "submitter": "Mandana Samiei", "authors": "Mandana Samiei, Caroline Weis, Larissa Schiavo, Tatjana Chavdarova,\n  Fariba Yousefi", "title": "Convening during COVID-19: Lessons learnt from organizing virtual\n  workshops in 2020", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This report is an account of the authors' experiences as organizers of WiML's\n\"Un-Workshop\" event at ICML 2020. Un-workshops focus on participant-driven\nstructured discussions on a pre-selected topic. For clarity, this event was\ndifferent from the \"WiML Workshop\", which is usually co-located with NeurIPS.\nIn this manuscript, organizers, share their experiences with the hope that it\nwill help future organizers to host a successful virtual event under similar\nconditions. Women in Machine Learning (WiML)'s mission is creating connections\nwithin a small community of women working in machine learning, in order to\nencourage mentorship, networking, and interchange of ideas and increase the\nimpact of women in the community.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2020 02:15:24 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Samiei", "Mandana", ""], ["Weis", "Caroline", ""], ["Schiavo", "Larissa", ""], ["Chavdarova", "Tatjana", ""], ["Yousefi", "Fariba", ""]]}, {"id": "2012.01192", "submitter": "Emad Alenany", "authors": "Emad Alenany, Abdessamad Ait El Cadi", "title": "Modeling patient flow in the emergency department using machine learning\n  and simulation", "comments": null, "journal-ref": "13th International Conference on Modelling, Optimization and\n  Simulation (MOSIM'20), Agadir, Morocco, 12-14 November 2020, Nov 2020,\n  Agadir, Morocco", "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the combination of machine learning (ML) and simulation is gaining\na lot of attention. This paper presents a novel application of ML within the\nsimulation to improve patient flow within an emergency department (ED). An ML\nmodel used within a real ED simulation model to quantify the effect of\ndetouring a patient out of the ED on the length of stay (LOS) and\ndoor-to-doctor time (DTDT) as a response to the prediction of patient admission\nto the hospital from the ED. The ML model trained using a set of six features\nincluding the patient age, arrival day, arrival hour of the day, and the triage\nlevel. The prediction model used a decision tree (DT) model, which is trained\nusing historical data achieves a 75% accuracy. The set of rules extracted from\nthe DT are coded within the simulation model. Given a certain probability of\nfree inpatient beds, the predicted admitted patient is then pulled out from the\nED to inpatient units to alleviate the crowding within the ED. The used policy\ncombined with adding specific ED resources achieve 9.39% and 8.18% reduction in\nLOS and DTDT, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 17:42:53 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Alenany", "Emad", ""], ["Cadi", "Abdessamad Ait El", ""]]}, {"id": "2012.01193", "submitter": "Mark Weber", "authors": "Mark Weber, Mikhail Yurochkin, Sherif Botros, Vanio Markov", "title": "Black Loans Matter: Distributionally Robust Fairness for Fighting\n  Subgroup Discrimination", "comments": "8 pages, NeurIPS Fair AI in Finance Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithmic fairness in lending today relies on group fairness metrics for\nmonitoring statistical parity across protected groups. This approach is\nvulnerable to subgroup discrimination by proxy, carrying significant risks of\nlegal and reputational damage for lenders and blatantly unfair outcomes for\nborrowers. Practical challenges arise from the many possible combinations and\nsubsets of protected groups. We motivate this problem against the backdrop of\nhistorical and residual racism in the United States polluting all available\ntraining data and raising public sensitivity to algorithimic bias. We review\nthe current regulatory compliance protocols for fairness in lending and discuss\ntheir limitations relative to the contributions state-of-the-art fairness\nmethods may afford. We propose a solution for addressing subgroup\ndiscrimination, while adhering to existing group fairness requirements, from\nrecent developments in individual fairness methods and corresponding fair\nmetric learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 21:04:07 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Weber", "Mark", ""], ["Yurochkin", "Mikhail", ""], ["Botros", "Sherif", ""], ["Markov", "Vanio", ""]]}, {"id": "2012.01268", "submitter": "Mojtaba Shahin", "authors": "Rifat Ara Shams, Mojtaba Shahin, Gillian Oliver, Waqar Hussain, Harsha\n  Perera, Arif Nurwidyantoro, Jon Whittle", "title": "Measuring Bangladeshi Female Farmers' Values for Agriculture Mobile\n  Applications Development", "comments": "10 Pages, Accepted to appear in 54th Hawaii International Conference\n  on System Sciences, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of mobile applications (apps) in daily life raises the\nimperative that the apps should reflect users' values. However, users' values\nare not usually taken into account in app development. Thus there is\nsignificant potential for user dissatisfaction and negative socio-economic\nconsequences. To be cognizant of values in apps, the first step is to find out\nwhat those values are, and that was the objective of this study conducted in\nBangladesh. Our focus was on rural women, specifically female farmers. The\nbasis for our study was Schwartz's universal human values theory, and we used\nan associated survey instrument, the Portrait Values Questionnaire (PVQ). Our\nsurvey of 193 Bangladeshi female farmers showed that Conformity and Security\nwere regarded as the most important values, while Power, Hedonism, and\nStimulation were the least important. This finding would be helpful for\ndevelopers to take into account when developing agriculture apps for this\nmarket. In addition, the methodology we used provides a model to follow to\nelicit the values of apps' users in other communities.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 11:15:28 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Shams", "Rifat Ara", ""], ["Shahin", "Mojtaba", ""], ["Oliver", "Gillian", ""], ["Hussain", "Waqar", ""], ["Perera", "Harsha", ""], ["Nurwidyantoro", "Arif", ""], ["Whittle", "Jon", ""]]}, {"id": "2012.01286", "submitter": "Shenghuan Yang", "authors": "Shenghuan Yang, Md Tariqul Islam", "title": "IBM Employee Attrition Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we analyzed the dataset IBM Employee Attrition to find the\nmain reasons why employees choose to resign. Firstly, we utilized the\ncorrelation matrix to see some features that were not significantly correlated\nwith other attributes and removed them from our dataset. Secondly, we selected\nimportant features by exploiting Random Forest, finding monthlyincome, age, and\nthe number of companies worked significantly impacted employee attrition. Next,\nwe also classified people into two clusters by using K-means Clustering.\nFinally, We performed binary logistic regression quantitative analysis: the\nattrition of people who traveled frequently was 2.4 times higher than that of\npeople who rarely traveled. And we also found that employees who work in Human\nResource have a higher tendency to leave.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 15:51:44 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 06:35:59 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 07:29:59 GMT"}, {"version": "v4", "created": "Fri, 11 Dec 2020 02:24:21 GMT"}, {"version": "v5", "created": "Thu, 31 Dec 2020 06:18:27 GMT"}, {"version": "v6", "created": "Fri, 1 Jan 2021 01:40:46 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Yang", "Shenghuan", ""], ["Islam", "Md Tariqul", ""]]}, {"id": "2012.01325", "submitter": "Navod Thilakarathne", "authors": "Navod Neranjan Thilakarathne, Mohan Krishna Kagita and W.D Madhuka\n  Priyashan", "title": "Green Internet of Things: The Next Generation Energy Efficient Internet\n  of Things", "comments": null, "journal-ref": null, "doi": "10.1007/978-981-16-2008-9_38", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is seen as a novel technical paradigm aimed at\nenabling connectivity between billions of interconnected devices all around the\nworld. This IoT is being served in various domains, such as smart healthcare,\ntraffic surveillance, smart homes, smart cities, and various industries. IoT's\nmain functionality includes sensing the surrounding environment, collecting\ndata from the surrounding, and transmitting those data to the remote data\ncenters or the cloud. This sharing of vast volumes of data between billions of\nIoT devices generates a large energy demand and increases energy wastage in the\nform of heat. The Green IoT envisages reducing the energy consumption of IoT\ndevices and keeping the environment safe and clean. Inspired by achieving a\nsustainable next-generation IoT ecosystem and guiding us toward making a\nhealthy green planet, we first offer an overview of Green IoT (GIoT), and then\nthe challenges and the future directions regarding the GIoT are presented in\nour study.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:52:18 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 11:50:31 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Thilakarathne", "Navod Neranjan", ""], ["Kagita", "Mohan Krishna", ""], ["Priyashan", "W. D Madhuka", ""]]}, {"id": "2012.01382", "submitter": "Geoffrey Goodell", "authors": "Oscar King and Geoffrey Goodell", "title": "Analysis of a Decentralised Digital Token Architecture for Public\n  Transport", "comments": "23 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digitisation is often viewed as beneficial to a user. Where originally people\nwould physically have to identify to a service, pay for a ticket in cash, or go\ninto a library to access a book, people can now achieve all of this through a\nclick of a button. While these actions may seem functionally identical to their\nanalogue counterparts, they come with one important difference. Namely, in the\ndigital case, a user's actions are automatically recorded. The recording of\nuser's interactions presents a problem because this information can be used\noutside the control of the person whom it concerns. This issue is only\nexacerbated by the centralisation of these aforementioned services'\nauthentication mechanisms permitting the collection of even more data.\n  This work aims to motivate the need and establish the feasibility for the\napplication of a privacy-enhancing digital token management service to public\ntransit. A proof-of-concept implementation of the Decentralised Digital\nIdentity Architecture proposed by Goodell and Aste is developed. This\nimplementation was optimised for the public transport use case. Finally, its\nperformance is tested in a local environment to better understand the technical\nchallenges and assess such a system's technical feasibility in a production\nsetting. It was observed that for loads between 1 and 5 requests per second the\nproof-of-concept performs within acceptable limits with a maximum median\nresponse time of 334 milliseconds. Above 5 requests per second response times\ndrastically increase due to hardware bottlenecks.\n  It was concluded that the demonstrated throughput and latency shows that the\nsystem can feasibly compete with solutions currently in use. Yet, further work\nis needed to demonstrate these performance characteristics in an environment\nsimilar to that experienced in production.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:24:43 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["King", "Oscar", ""], ["Goodell", "Geoffrey", ""]]}, {"id": "2012.01384", "submitter": "Wenwen Zhang", "authors": "Kaidi Wang, Wenwen Zhang", "title": "The Role of Urban Form in the Performance of Shared Automated Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The technology of Shared Automated Vehicles (SAVs) has advanced significantly\nin recent years. However, existing SAV studies primarily focus on the system\ndesign while limited studies have examined the impacts of exogenous variables,\nespecially urban form, on SAV performance. Therefore, it remains unclear what\nkey urban form measurements may influence SAV system's sustainability. This\nstudy fills the research gap by conducting simulation experiments using data\ncollected from 286 cities. This study identifies critical urban form\nmeasurements correlated with the simulated SAV performance using fixed effects\nregression models. The results suggest that SAVs are more efficient and\ngenerate less VMT in denser cities with more connected networks and diversified\nland use development patterns. The model results can help provide insights on\nland use and transportation policies to curb the adverse effects of SAVs in the\nfuture and generalize existing SAV simulation results to the rest of U.S.\ncities.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:28:44 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Wang", "Kaidi", ""], ["Zhang", "Wenwen", ""]]}, {"id": "2012.01546", "submitter": "Hannah Miller", "authors": "Ivona Bez\\'akov\\'a, Kimberly Fluet, Edith Hemaspaandra, Hannah Miller,\n  David E. Narv\\'aez", "title": "Effective Feedback for Introductory CS Theory: A JFLAP Extension and\n  Student Persistence", "comments": "Extended technical report for poster presentation in SIGCSE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing theory analyzes abstract computational models to rigorously study\nthe computational difficulty of various problems. Introductory computing theory\ncan be challenging for undergraduate students, and the main goal of our\nresearch is to help students learn these computational models. The most common\npedagogical tool for interacting with these models is the Java Formal Languages\nand Automata Package (JFLAP). We developed a JFLAP server extension, which\naccepts homework submissions from students, evaluates the submission as correct\nor incorrect, and provides a witness string when the submission is incorrect.\nOur extension currently provides witness feedback for deterministic finite\nautomata, nondeterministic finite automata, regular expressions, context-free\ngrammars, and pushdown automata.\n  In Fall 2019, we ran a preliminary investigation on two sections (Control and\nStudy) of the required undergraduate course Introduction to Computer Science\nTheory. The Study section used our extension for five targeted homework\nquestions, and the Control section solved and submitted these problems using\ntraditional means. Our results show that on these five questions, the Study\nsection performed better on average than the Control section. Moreover, the\nStudy section persisted in submitting attempts until correct, and from this\nfinding, our preliminary conclusion is that minimal (not detailed or\ngrade-based) witness feedback helps students to truly learn the concepts. We\ndescribe the results that support this conclusion as well as a related\nhypothesis conjecturing that with witness feedback and unlimited number of\nsubmissions, partial credit is both unnecessary and ineffective.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 21:39:01 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Bez\u00e1kov\u00e1", "Ivona", ""], ["Fluet", "Kimberly", ""], ["Hemaspaandra", "Edith", ""], ["Miller", "Hannah", ""], ["Narv\u00e1ez", "David E.", ""]]}, {"id": "2012.01553", "submitter": "Lucy Simko", "authors": "Lucy Simko, Jack Lucas Chang, Maggie Jiang, Ryan Calo, Franziska\n  Roesner, Tadayoshi Kohno", "title": "COVID-19 Contact Tracing and Privacy: A Longitudinal Study of Public\n  Opinion", "comments": "37 pages, 11 figures. Supercedes arXiv:2005.06056", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing use of technology-enabled contact tracing, the process of\nidentifying potentially infected COVID-19 patients by notifying all recent\ncontacts of an infected person. Governments, technology companies, and research\ngroups alike have been working towards releasing smartphone apps, using IoT\ndevices, and distributing wearable technology to automatically track \"close\ncontacts\" and identify prior contacts in the event an individual tests\npositive. However, there has been significant public discussion about the\ntensions between effective technology-based contact tracing and the privacy of\nindividuals. To inform this discussion, we present the results of seven months\nof online surveys focused on contact tracing and privacy, each with 100\nparticipants. Our first surveys were on April 1 and 3, before the first peak of\nthe virus in the US, and we continued to conduct the surveys weekly for 10\nweeks (through June), and then fortnightly through November, adding topical\nquestions to reflect current discussions about contact tracing and COVID-19.\nOur results present the diversity of public opinion and can inform policy\nmakers, technologists, researchers, and public health experts on whether and\nhow to leverage technology to reduce the spread of COVID-19, while considering\npotential privacy concerns. We are continuing to conduct longitudinal\nmeasurements and will update this report over time; citations to this version\nof the report should reference Report Version 2.0, December 4, 2020.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 21:50:42 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 19:07:10 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Simko", "Lucy", ""], ["Chang", "Jack Lucas", ""], ["Jiang", "Maggie", ""], ["Calo", "Ryan", ""], ["Roesner", "Franziska", ""], ["Kohno", "Tadayoshi", ""]]}, {"id": "2012.01614", "submitter": "Chakkrit Tantithamthavorn", "authors": "Chakkrit Tantithamthavorn, Jirayus Jiarpakdee, John Grundy", "title": "Explainable AI for Software Engineering", "comments": "Under Review at IEEE Computer Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence/Machine Learning techniques have been widely used in\nsoftware engineering to improve developer productivity, the quality of software\nsystems, and decision-making. However, such AI/ML models for software\nengineering are still impractical, not explainable, and not actionable. These\nconcerns often hinder the adoption of AI/ML models in software engineering\npractices. In this article, we first highlight the need for explainable AI in\nsoftware engineering. Then, we summarize three successful case studies on how\nexplainable AI techniques can be used to address the aforementioned challenges\nby making software defect prediction models more practical, explainable, and\nactionable.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 00:42:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Tantithamthavorn", "Chakkrit", ""], ["Jiarpakdee", "Jirayus", ""], ["Grundy", "John", ""]]}, {"id": "2012.01772", "submitter": "Rohan Sukumaran", "authors": "Darshan Gandhi, Rohan Sukumaran, Priyanshi Katiyar, Alex Radunsky,\n  Sunaina Anand, Shailesh Advani, Jil Kothari, Kasia Jakimowicz, Sheshank\n  Shankar, Sethuraman T. V., Krutika Misra, Aishwarya Saxena, Sanskruti\n  Landage, Richa Sonker, Parth Patwa, Aryan Mahindra, Mikhail Dmitrienko,\n  Kanishka Vaish, Ashley Mehra, Srinidhi Murali, Rohan Iyer, Joseph Bae, Vivek\n  Sharma, Abhishek Singh, Rachel Barbar and Ramesh Raskar", "title": "Digital Landscape of COVID-19 Testing: Challenges and Opportunities", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 Pandemic has left a devastating trail all over the world, in\nterms of loss of lives, economic decline, travel restrictions, trade deficit,\nand collapsing economy including real-estate, job loss, loss of health\nbenefits, the decline in quality of access to care and services and overall\nquality of life. Immunization from the anticipated vaccines will not be the\nstand-alone guideline that will help surpass the pandemic and return to\nnormalcy. Four pillars of effective public health intervention include\ndiagnostic testing for both asymptomatic and symptomatic individuals, contact\ntracing, quarantine of individuals with symptoms or who are exposed to\nCOVID-19, and maintaining strict hygiene standards at the individual and\ncommunity level. Digital technology, currently being used for COVID-19 testing\ninclude certain mobile apps, web dashboards, and online self-assessment tools.\nHerein, we look into various digital solutions adapted by communities across\nuniversities, businesses, and other organizations. We summarize the challenges\nexperienced using these tools in terms of quality of information, privacy, and\nuser-centric issues. Despite numerous digital solutions available and being\ndeveloped, many vary in terms of information being shared in terms of both\nquality and quantity, which can be overwhelming to the users. Understanding the\ntesting landscape through a digital lens will give a clear insight into the\nmultiple challenges that we face including data privacy, cost, and\nmiscommunication. It is the destiny of digitalization to navigate testing for\nCOVID-19. Block-chain based systems can be used for privacy preservation and\nensuring ownership of the data to remain with the user. Another solution\ninvolves having digital health passports with relevant and correct information.\nIn this early draft, we summarize the challenges and propose possible solutions\nto address the same.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 09:01:51 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Gandhi", "Darshan", ""], ["Sukumaran", "Rohan", ""], ["Katiyar", "Priyanshi", ""], ["Radunsky", "Alex", ""], ["Anand", "Sunaina", ""], ["Advani", "Shailesh", ""], ["Kothari", "Jil", ""], ["Jakimowicz", "Kasia", ""], ["Shankar", "Sheshank", ""], ["V.", "Sethuraman T.", ""], ["Misra", "Krutika", ""], ["Saxena", "Aishwarya", ""], ["Landage", "Sanskruti", ""], ["Sonker", "Richa", ""], ["Patwa", "Parth", ""], ["Mahindra", "Aryan", ""], ["Dmitrienko", "Mikhail", ""], ["Vaish", "Kanishka", ""], ["Mehra", "Ashley", ""], ["Murali", "Srinidhi", ""], ["Iyer", "Rohan", ""], ["Bae", "Joseph", ""], ["Sharma", "Vivek", ""], ["Singh", "Abhishek", ""], ["Barbar", "Rachel", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2012.01813", "submitter": "Johanna Johansen Ms", "authors": "Johanna Johansen, Tore Pedersen, Simone Fischer-H\\\"ubner, Christian\n  Johansen, Gerardo Schneider, Arnold Roosendaal, Harald Zwingelberg, Anders\n  Jakob Sivesind, Josef Noll", "title": "A Multidisciplinary Definition of Privacy Labels: The Story of Princess\n  Privacy and the Seven Helpers", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Privacy is currently in distress and in need of rescue, much like princesses\nin the all-familiar fairytales. We employ storytelling and metaphors from\nfairytales to make reader-friendly and streamline our arguments about how a\ncomplex concept of Privacy Labeling (the 'knight in shining armor') can be a\nsolution to the current state of Privacy (the 'princess in distress'). We give\na precise definition of Privacy Labeling (PL), painting a panoptic portrait\nfrom seven different perspectives (the 'seven helpers'): Business, Legal,\nRegulatory, Usability and Human Factors, Educative, Technological, and\nMultidisciplinary. We describe a common vision, proposing several important\n'traits of character' of PL as well as identifying 'undeveloped\npotentialities', i.e., open problems on which the community can focus. More\nspecifically, this position paper identifies the stakeholders of the PL and\ntheir needs with regard to privacy, describing how PL should be and look like\nin order to address these needs. Throughout the paper, we highlight goals,\ncharacteristics, open problems, and starting points for creating, what we\nconsider to be, the ideal PL. In the end we present three approaches to\nestablish and manage PL, through: self-evaluations, certifications, or\ncommunity endeavors. Based on these, we sketch a roadmap for future\ndevelopments.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 10:42:30 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:57:17 GMT"}, {"version": "v3", "created": "Sun, 9 May 2021 16:54:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Johansen", "Johanna", ""], ["Pedersen", "Tore", ""], ["Fischer-H\u00fcbner", "Simone", ""], ["Johansen", "Christian", ""], ["Schneider", "Gerardo", ""], ["Roosendaal", "Arnold", ""], ["Zwingelberg", "Harald", ""], ["Sivesind", "Anders Jakob", ""], ["Noll", "Josef", ""]]}, {"id": "2012.01876", "submitter": "Robert Paluch", "authors": "Robert Paluch, {\\L}ukasz G. Gajewski, Janusz A. Ho{\\l}yst, Boleslaw K.\n  Szymanski", "title": "Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review", "comments": "28 pages, 18 figures, 11 tables", "journal-ref": "Future Generation Computer Systems, Volume 112, November 2020,\n  Pages 1070-1092", "doi": "10.1016/j.future.2020.06.023", "report-no": null, "categories": "cs.SI cs.CY physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 12:45:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Paluch", "Robert", ""], ["Gajewski", "\u0141ukasz G.", ""], ["Ho\u0142yst", "Janusz A.", ""], ["Szymanski", "Boleslaw K.", ""]]}, {"id": "2012.01907", "submitter": "Djoanna Marie Salac", "authors": "Djoanna Marie V. Salac", "title": "PRESENT: An Android-Based Class Attendance Monitoring System Using Face\n  Recognition Technology", "comments": "14 pages, 6 figures", "journal-ref": "International Journal of Computing Sciences Research Vol. 2,No. 3,\n  pp. 102-115, 2019", "doi": "10.25147/ijcsr.2017.001.1.28", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The study aimed to develop an Android-Based Class Attendance Monitoring\nApplication using Face Recognition to make attendance checking and monitoring\neasier and faster. The researcher used incremental model as the software\ndevelopment process and the application was evaluated by seventeen (17) faculty\nmembers .A validated evaluation questionnaire was used to rate the level of\nacceptability of the application based on ISO 9126 software quality and the\nlevel of satisfaction for its major features. For the statistical treatment of\nthe data collected, Likert Scale, weighted mean and t-test were utilized by the\nresearcher. The results revealed that instructors find the existing way of\nchecking attendance as time consuming and a tedious task. Furthermore, the\nrespondents assessed the developed application as moderately acceptable in\nterms of functionality, reliability and usability while portability was rated\nas highly acceptable. With regards to the features, the respondents were very\nsatisfied. The researcher concluded that the developed application was useful\nand it can support the needs of the instructors to make attendance checking and\nmonitoring easier, faster, and reliable. Due to its acceptable evaluation\nresult, instructors should consider the use of this tool as an alternative to\nthe existing process of checking and monitoring class attendance. With the\nintegration of different technologies such as Android, face recognition and\nSMS, the traditional way of checking class attendance can be made easier,\nfaster, reliable and secured, thus improving classroom management.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 02:25:00 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Salac", "Djoanna Marie V.", ""]]}, {"id": "2012.01930", "submitter": "Tavpritesh Sethi", "authors": "Raghav Awasthi, Prachi Patel, Vineet Joshi, Shama Karkal, Tavpritesh\n  Sethi", "title": "Learning Explainable Interventions to Mitigate HIV Transmission in Sex\n  Workers Across Five States in India", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Female sex workers(FSWs) are one of the most vulnerable and stigmatized\ngroups in society. As a result, they often suffer from a lack of quality access\nto care. Grassroot organizations engaged in improving health services are often\nfaced with the challenge of improving the effectiveness of interventions due to\ncomplex influences. This work combines structure learning, discriminative\nmodeling, and grass-root level expertise of designing interventions across five\ndifferent Indian states to discover the influence of non-obvious factors for\nimproving safe-sex practices in FSWs. A bootstrapped, ensemble-averaged\nBayesian Network structure was learned to quantify the factors that could\nmaximize condom usage as revealed from the model. A discriminative model was\nthen constructed using XgBoost and random forest in order to predict condom use\nbehavior The best model achieved 83% sensitivity, 99% specificity, and 99% area\nunder the precision-recall curve for the prediction. Both generative and\ndiscriminative modeling approaches revealed that financial literacy training\nwas the primary influence and predictor of condom use in FSWs. These insights\nhave led to a currently ongoing field trial for assessing the real-world\nutility of this approach. Our work highlights the potential of explainable\nmodels for transparent discovery and prioritization of anti-HIV interventions\nin female sex workers in a resource-limited setting.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 08:35:16 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Awasthi", "Raghav", ""], ["Patel", "Prachi", ""], ["Joshi", "Vineet", ""], ["Karkal", "Shama", ""], ["Sethi", "Tavpritesh", ""]]}, {"id": "2012.01955", "submitter": "Gustavo Marfia", "authors": "Lorenzo Stacchio, Alessia Angeli, Giuseppe Lisanti, Daniela Calanca,\n  Gustavo Marfia", "title": "IMAGO: A family photo album dataset for a socio-historical analysis of\n  the twentieth century", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although one of the most popular practices in photography since the end of\nthe 19th century, an increase in scholarly interest in family photo albums\ndates back to the early 1980s. Such collections of photos may reveal\nsociological and historical insights regarding specific cultures and times.\nThey are, however, in most cases scattered among private homes and only\navailable on paper or photographic film, thus making their analysis by\nacademics such as historians, social-cultural anthropologists and cultural\ntheorists very cumbersome. In this paper, we analyze the IMAGO dataset\nincluding photos belonging to family albums assembled at the University of\nBologna's Rimini campus since 2004. Following a deep learning-based approach,\nthe IMAGO dataset has offered the opportunity of experimenting with photos\ntaken between year 1845 and year 2009, with the goals of assessing the dates\nand the socio-historical contexts of the images, without use of any other\nsources of information. Exceeding our initial expectations, such analysis has\nrevealed its merit not only in terms of the performance of the approach adopted\nin this work, but also in terms of the foreseeable implications and use for the\nbenefit of socio-historical research. To the best of our knowledge, this is the\nfirst work that moves along this path in literature.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 14:28:58 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Stacchio", "Lorenzo", ""], ["Angeli", "Alessia", ""], ["Lisanti", "Giuseppe", ""], ["Calanca", "Daniela", ""], ["Marfia", "Gustavo", ""]]}, {"id": "2012.02023", "submitter": "Robert Paluch", "authors": "Robert Paluch, {\\L}ukasz G. Gajewski, K. Suchecki, Janusz A. Ho{\\l}yst", "title": "Source location on multilayer networks", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Nowadays it is not uncommon to have to deal with dissemination on\nmulti-layered networks and often finding the source of said propagation can be\na crucial task. In this paper we tackle this exact problem with a maximum\nlikelihood approach that we extend to be operational on multi-layered graphs.\nWe test our method for source location estimation on synthetic networks and\noutline its potential strengths and limitations. We also observe some\nnon-trivial and perhaps surprising phenomena where the more of the system one\nobserves the worse the results become whereas increased problem complexity in\nthe form of more layers can actually improve our performance.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 16:08:38 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Paluch", "Robert", ""], ["Gajewski", "\u0141ukasz G.", ""], ["Suchecki", "K.", ""], ["Ho\u0142yst", "Janusz A.", ""]]}, {"id": "2012.02039", "submitter": "Robert Paluch", "authors": "Robert Paluch, Krzysztof Suchecki, Janusz A. Ho{\\l}yst", "title": "Locating the source of interacting signal in complex networks", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We investigate the problem of locating the source of a self-interacting\nsignal spreading in a complex networks. We use a well-known rumour model as an\nexample of the process with self-interaction. According to this model based on\nthe SIR epidemic dynamics, the infected nodes may interact and discourage each\nother from gossiping with probability $\\alpha$. We compare three algorithms of\nsource localization: Limited Pinto-Thiran-Vettarli (LPTV), Gradient Maximum\nLikelihood (GMLA) and one based on Pearson correlation between time and\ndistance. The results of numerical simulations show that additional\ninteractions between infected nodes decrease the quality of LPTV and Pearson.\nGMLA is the most resistant to harmful effects of the self-interactions, which\nis especially visible for medium and high level of stochasticity of the\nprocess, when spreading rate is below 0.5. The reason for this may be the fact\nthat GMLA uses only the nearest observers, which are much less likely affected\nby the interactions between infected nodes, because these contacts become\nimportant as the epidemics develops and the number of infected agents\nincreases.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 16:23:46 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Paluch", "Robert", ""], ["Suchecki", "Krzysztof", ""], ["Ho\u0142yst", "Janusz A.", ""]]}, {"id": "2012.02048", "submitter": "Ram Shankar Siva Kumar", "authors": "Kendra Albert, Maggie Delano, Jonathon Penney, Afsaneh Rigot and Ram\n  Shankar Siva Kumar", "title": "Ethical Testing in the Real World: Evaluating Physical Testing of\n  Adversarial Machine Learning", "comments": "Accepted to NeurIPS 2020 Workshop on Dataset Curation and Security;\n  Also accepted at Navigating the Broader Impacts of AI Research Workshop. All\n  authors contributed equally. The list of authors is arranged alphabetically", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper critically assesses the adequacy and representativeness of\nphysical domain testing for various adversarial machine learning (ML) attacks\nagainst computer vision systems involving human subjects. Many papers that\ndeploy such attacks characterize themselves as \"real world.\" Despite this\nframing, however, we found the physical or real-world testing conducted was\nminimal, provided few details about testing subjects and was often conducted as\nan afterthought or demonstration. Adversarial ML research without\nrepresentative trials or testing is an ethical, scientific, and health/safety\nissue that can cause real harms. We introduce the problem and our methodology,\nand then critique the physical domain testing methodologies employed by papers\nin the field. We then explore various barriers to more inclusive physical\ntesting in adversarial ML and offer recommendations to improve such testing\nnotwithstanding these challenges.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 16:28:45 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Albert", "Kendra", ""], ["Delano", "Maggie", ""], ["Penney", "Jonathon", ""], ["Rigot", "Afsaneh", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "2012.02108", "submitter": "Ritwik Gupta", "authors": "Ritwik Gupta, Eric T. Heim, Edoardo Nemni", "title": "Proceedings of NeurIPS 2020 Workshop on Artificial Intelligence for\n  Humanitarian Assistance and Disaster Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the \"proceedings\" of the 2nd AI + HADR workshop which was held\nvirtually on December 12, 2020 as part of the Neural Information Processing\nSystems conference. These are non-archival and merely serve as a way to collate\nall the papers accepted to the workshop.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 17:44:26 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 04:23:15 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Gupta", "Ritwik", ""], ["Heim", "Eric T.", ""], ["Nemni", "Edoardo", ""]]}, {"id": "2012.02121", "submitter": "Berni Fabito", "authors": "Bernie S. Fabito, Arlene O. Trillanes, Jeshnile R. Sarmiento", "title": "Barriers and Challenges of Computing Students in an Online Learning\n  Environment: Insights from One Private University in the Philippines", "comments": "18 pages, 1 table, 7 figures", "journal-ref": "International Journal of Computing Sciences Research, [S.l.], v.\n  5, n. 1, p. 441-458, sep. 2020. ISSN 2546-115X", "doi": "10.25147/ijcsr.2017.001.1.51", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While the literature presents various advantages of using blended learning,\npolicymakers must identify the barriers and challenges faced by students that\nmay cripple their online learning experience. Understanding these barriers can\nhelp academic institutions craft policies to advance and improve the students'\nonline learning experience. This study was conducted to determine the\nchallenges of computing students in one private University in the Philippines\nduring the period where the entire Luzon region was placed under the Enhanced\nCommunity Quarantine (ECQ) as a response to the COVID-19 pandemic. A survey\nthrough MS Forms Pro was performed to identify the experiences of students in\nonline learning. The survey ran from March 16 to March 18, 2020, which yielded\na total of 300 responses. Descriptive statistics revealed that the top three\nbarriers and challenges encountered by students were 1. the difficulty of\nclarifying topics or discussions with the professors, 2.the lack of study or\nworking area for doing online activities, and 3. the lack of a good Internet\nconnection for participating in online activities. It can be concluded that\nboth students and faculty members were not fully prepared to undergo full\nonline learning. More so, some faculty members may have failed to adapt to the\nneeds of the students in an online learning environment. While the primary data\nof the study mainly came from the students, it would also be an excellent\naddition to understand the perspective of the faculty members in terms of their\nexperiences with their students. Their insights could help validate the\nresponses in the survey and provide other barriers that may not have been\nincluded in the study.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 02:19:08 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Fabito", "Bernie S.", ""], ["Trillanes", "Arlene O.", ""], ["Sarmiento", "Jeshnile R.", ""]]}, {"id": "2012.02164", "submitter": "Luiz Giovanini", "authors": "Mirela Silva, Fabr\\'icio Ceschin, Prakash Shrestha, Christopher Brant,\n  Juliana Fernandes, Catia S. Silva, Andr\\'e Gr\\'egio, Daniela Oliveira, and\n  Luiz Giovanini", "title": "Predicting Misinformation and Engagement in COVID-19 Twitter Discourse\n  in the First Months of the Outbreak", "comments": "26 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disinformation entails the purposeful dissemination of falsehoods towards a\ngreater dubious agenda and the chaotic fracturing of a society. The general\npublic has grown aware of the misuse of social media towards these nefarious\nends, where even global public health crises have not been immune to\nmisinformation (deceptive content spread without intended malice). In this\npaper, we examine nearly 505K COVID-19-related tweets from the initial months\nof the pandemic to understand misinformation as a function of bot-behavior and\nengagement. Using a correlation-based feature selection method, we selected the\n11 most relevant feature subsets among over 170 features to distinguish\nmisinformation from facts, and to predict highly engaging misinformation tweets\nabout COVID-19. We achieved an average F-score of at least 72\\% with ten\npopular multi-class classifiers, reinforcing the relevance of the selected\nfeatures. We found that (i) real users tweet both facts and misinformation,\nwhile bots tweet proportionally more misinformation; (ii) misinformation tweets\nwere less engaging than facts; (iii) the textual content of a tweet was the\nmost important to distinguish fact from misinformation while (iv) user account\nmetadata and human-like activity were most important to predict high engagement\nin factual and misinformation tweets; and (v) sentiment features were not\nrelevant.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 18:47:34 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 15:13:31 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Silva", "Mirela", ""], ["Ceschin", "Fabr\u00edcio", ""], ["Shrestha", "Prakash", ""], ["Brant", "Christopher", ""], ["Fernandes", "Juliana", ""], ["Silva", "Catia S.", ""], ["Gr\u00e9gio", "Andr\u00e9", ""], ["Oliveira", "Daniela", ""], ["Giovanini", "Luiz", ""]]}, {"id": "2012.02237", "submitter": "Mark Philip Sy", "authors": "Mark Philip M. Sy, Christian James M. Historillo, Allen Cris T. Conde,\n  and Ma. Yvonne Czarina R. Costelo", "title": "Query Game 2.0: Improvement of a Web-Based Query Game for Cavite State\n  University Main Campus", "comments": null, "journal-ref": "International Journal of Computing Sciences Research, 4(2),\n  304-318", "doi": "10.25147/ijcsr.2017.001.1.41", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Purpose: The study aimed to improve the previous study covering a web-based\nquery game for Cavite State University. The study created a new mechanic and\ngameplay for the students to learn Structured Query Language (SQL). The\nenhancements also focused on the interactions of one or more students playing\nthe game.\n  Method: The researchers used iterative development process methodology in the\ndevelopment of the study. The system was assessed and evaluated using different\ntesting methods: unit, integration, and system testing. After passing the\ntests, 90 students of Information Technology and Computer Science program along\nwith 10 IT experts evaluated the system.\n  Results: The respondents were classified into technical and non-technical\nrespondents and the study garnered an evaluation score of 4.69 and 4.70\nrespectively. The overall interpretation of the results of the evaluation is\nExcellent.\n  Conclusion: The study created a system where the user can read and watch\nlectures and experience the tutorial. Instructors and students may communicate\nin the system, hence, promoting better relations and healthy competition\nbetween students.\n  Recommendations: Based on the conclusions of the study, the system can be\nused as a supplementary tool in teaching courses with Database Management. To\nenhance the analysis of query construction of the students, it is recommended\nto add a module that can analyze the pattern of creating queries and answering\nquestions for every user.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 06:43:05 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Sy", "Mark Philip M.", ""], ["Historillo", "Christian James M.", ""], ["Conde", "Allen Cris T.", ""], ["Costelo", "Ma. Yvonne Czarina R.", ""]]}, {"id": "2012.02242", "submitter": "Fateme Sarkohaki", "authors": "Mina Zaminkar, Fateme Sarkohaki, Reza Fotohi", "title": "A method based on encryption and node rating for securing the RPL\n  protocol communications in the IoT ecosystem", "comments": "24 pages, 11 figures, 6 tables", "journal-ref": "Int J Commun Syst. 2020;e4693", "doi": "10.1002/dac.4693", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet of Things (IoT) provides the possibility for milliards of devices\nthroughout the world to communicate with each other, and data is collected\nautonomously. The big data generated by the devices should be managed securely.\nDue to security challenges, like malicious nodes, many approaches cannot\nrespond to these concerns. In this paper, a robust hybrid method, including\nencryption, is used as an efficient approach for resolving the RPL protocol\nconcerns so that the devices are connected securely. Therefore, the proposed\nDSH-RPL method for securing the RPL protocol comprises the four following\nphases: The first phase creates a reliable RPL. The second phase detects the\nsinkhole attack. The third phase quarantines the detected malicious node, and\nthe fourth phase transmits data through encryption. The simulation results show\nthat the DSH-RPL reduces the false-positive rate more than 18.2% and 23.1%, and\nreduces the false-negative rate more than 16.1% and 22.78%, it also increases\nthe packet delivery rate more than 19.68% and 25.32% and increases the\ndetection rate more than 26% and 31% compared to SecTrust-RPL and IBOOS-RPL.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 09:27:38 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Zaminkar", "Mina", ""], ["Sarkohaki", "Fateme", ""], ["Fotohi", "Reza", ""]]}, {"id": "2012.02308", "submitter": "Jessica Schrouff", "authors": "Diana Mincu, Eric Loreaux, Shaobo Hou, Sebastien Baur, Ivan Protsyuk,\n  Martin G Seneviratne, Anne Mottram, Nenad Tomasev, Alan Karthikesanlingam and\n  Jessica Schrouff", "title": "Concept-based model explanations for Electronic Health Records", "comments": null, "journal-ref": "CHIL '21: Proceedings of the Conference on Health, Inference, and\n  Learning, 2021", "doi": "10.1145/3450439.3451858", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) are often used for sequential modeling of\nadverse outcomes in electronic health records (EHRs) due to their ability to\nencode past clinical states. These deep, recurrent architectures have displayed\nincreased performance compared to other modeling approaches in a number of\ntasks, fueling the interest in deploying deep models in clinical settings. One\nof the key elements in ensuring safe model deployment and building user trust\nis model explainability. Testing with Concept Activation Vectors (TCAV) has\nrecently been introduced as a way of providing human-understandable\nexplanations by comparing high-level concepts to the network's gradients. While\nthe technique has shown promising results in real-world imaging applications,\nit has not been applied to structured temporal inputs. To enable an application\nof TCAV to sequential predictions in the EHR, we propose an extension of the\nmethod to time series data. We evaluate the proposed approach on an open EHR\nbenchmark from the intensive care unit, as well as synthetic data where we are\nable to better isolate individual effects.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 22:18:24 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 10:30:50 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Mincu", "Diana", ""], ["Loreaux", "Eric", ""], ["Hou", "Shaobo", ""], ["Baur", "Sebastien", ""], ["Protsyuk", "Ivan", ""], ["Seneviratne", "Martin G", ""], ["Mottram", "Anne", ""], ["Tomasev", "Nenad", ""], ["Karthikesanlingam", "Alan", ""], ["Schrouff", "Jessica", ""]]}, {"id": "2012.02359", "submitter": "Paul Pu Liang", "authors": "Terrance Liu, Paul Pu Liang, Michal Muszynski, Ryo Ishii, David Brent,\n  Randy Auerbach, Nicholas Allen, Louis-Philippe Morency", "title": "Multimodal Privacy-preserving Mood Prediction from Mobile Data: A\n  Preliminary Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health conditions remain under-diagnosed even in countries with common\naccess to advanced medical care. The ability to accurately and efficiently\npredict mood from easily collectible data has several important implications\ntowards the early detection and intervention of mental health disorders. One\npromising data source to help monitor human behavior is from daily smartphone\nusage. However, care must be taken to summarize behaviors without identifying\nthe user through personal (e.g., personally identifiable information) or\nprotected attributes (e.g., race, gender). In this paper, we study behavioral\nmarkers or daily mood using a recent dataset of mobile behaviors from high-risk\nadolescent populations. Using computational models, we find that multimodal\nmodeling of both text and app usage features is highly predictive of daily mood\nover each modality alone. Furthermore, we evaluate approaches that reliably\nobfuscate user identity while remaining predictive of daily mood. By combining\nmultimodal representations with privacy-preserving learning, we are able to\npush forward the performance-privacy frontier as compared to unimodal\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 01:44:22 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Liu", "Terrance", ""], ["Liang", "Paul Pu", ""], ["Muszynski", "Michal", ""], ["Ishii", "Ryo", ""], ["Brent", "David", ""], ["Auerbach", "Randy", ""], ["Allen", "Nicholas", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "2012.02370", "submitter": "Rohit Ram", "authors": "Rohit Ram, Quyu Kong, Marian-Andrei Rizoiu", "title": "Birdspotter: A Tool for Analyzing and Labeling Twitter Users", "comments": null, "journal-ref": null, "doi": "10.1145/3437963.3441695", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of online social media on societal events and institutions is\nprofound; and with the rapid increases in user uptake, we are just starting to\nunderstand its ramifications. Social scientists and practitioners who model\nonline discourse as a proxy for real-world behavior, often curate large social\nmedia datasets. A lack of available tooling aimed at non-data science experts\nfrequently leaves this data (and the insights it holds) underutilized. Here, we\npropose birdspotter -- a tool to analyze and label Twitter users --, and\nbirdspotter.ml -- an exploratory visualizer for the computed metrics.\nbirdspotter provides an end-to-end analysis pipeline, from the processing of\npre-collected Twitter data, to general-purpose labeling of users, and\nestimating their social influence, within a few lines of code. The package\nfeatures tutorials and detailed documentation. We also illustrate how to train\nbirdspotter into a fully-fledged bot detector that achieves better than\nstate-of-the-art performances without making any Twitter API online calls, and\nwe showcase its usage in an exploratory analysis of a topical COVID-19 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 02:25:07 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 00:24:17 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Ram", "Rohit", ""], ["Kong", "Quyu", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "2012.02393", "submitter": "Bo Cowgill", "authors": "Bo Cowgill, Fabrizio Dell'Acqua and Sandra Matz", "title": "The Managerial Effects of Algorithmic Fairness Activism", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How do ethical arguments affect AI adoption in business? We randomly expose\nbusiness decision-makers to arguments used in AI fairness activism. Arguments\nemphasizing the inescapability of algorithmic bias lead managers to abandon AI\nfor manual review by humans and report greater expectations about lawsuits and\nnegative PR. These effects persist even when AI lowers gender and racial\ndisparities and when engineering investments to address AI fairness are\nfeasible. Emphasis on status quo comparisons yields opposite effects. We also\nmeasure the effects of \"scientific veneer\" in AI ethics arguments. Scientific\nveneer changes managerial behavior but does not asymmetrically benefit\nfavorable (versus critical) AI activism.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 04:11:31 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Cowgill", "Bo", ""], ["Dell'Acqua", "Fabrizio", ""], ["Matz", "Sandra", ""]]}, {"id": "2012.02394", "submitter": "Bo Cowgill", "authors": "Bo Cowgill, Fabrizio Dell'Acqua, Samuel Deng, Daniel Hsu, Nakul Verma\n  and Augustin Chaintreau", "title": "Biased Programmers? Or Biased Data? A Field Experiment in\n  Operationalizing AI Ethics", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Why do biased predictions arise? What interventions can prevent them? We\nevaluate 8.2 million algorithmic predictions of math performance from\n$\\approx$400 AI engineers, each of whom developed an algorithm under a randomly\nassigned experimental condition. Our treatment arms modified programmers'\nincentives, training data, awareness, and/or technical knowledge of AI ethics.\nWe then assess out-of-sample predictions from their algorithms using randomized\naudit manipulations of algorithm inputs and ground-truth math performance for\n20K subjects. We find that biased predictions are mostly caused by biased\ntraining data. However, one-third of the benefit of better training data comes\nthrough a novel economic mechanism: Engineers exert greater effort and are more\nresponsive to incentives when given better training data. We also assess how\nperformance varies with programmers' demographic characteristics, and their\nperformance on a psychological test of implicit bias (IAT) concerning gender\nand careers. We find no evidence that female, minority and low-IAT engineers\nexhibit lower bias or discrimination in their code. However, we do find that\nprediction errors are correlated within demographic groups, which creates\nperformance improvements through cross-demographic averaging. Finally, we\nquantify the benefits and tradeoffs of practical managerial or policy\ninterventions such as technical advice, simple reminders, and improved\nincentives for decreasing algorithmic bias.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 04:12:33 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Cowgill", "Bo", ""], ["Dell'Acqua", "Fabrizio", ""], ["Deng", "Samuel", ""], ["Hsu", "Daniel", ""], ["Verma", "Nakul", ""], ["Chaintreau", "Augustin", ""]]}, {"id": "2012.02571", "submitter": "Babis Magoutas", "authors": "Babis Magoutas, Gregoris Mentzas", "title": "Adaptivity and Personalization Application Scenarios in eParticipation", "comments": "eParticipation, 1st International Conference, ePart 2009, Linz,\n  Austria, September 1-3, 2009 Trauner Druck: Linz, Schriftenreihe Informatik #\n  31, pp. 205-215, 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adaptivity and personalization technologies appear not to be very much used\nin eparticipation projects to date. These technologies are commonly used to\novercome the overflow of information and service providers adopt them in order\nto acquire a better knowledge of their end-users and optimize their service\nofferings. In this paper we investigate the potential of adaptivity and\npersonalization principles and technologies when applied to the eParticipation\nfield and more specifically, to eParticipation websites. Potential application\nscenarios of these technologies in the context of policy engagement and active\nparticipation of citizens in democratic decision-making are defined and their\nimpact in eParticipation is examined.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 16:46:07 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Magoutas", "Babis", ""], ["Mentzas", "Gregoris", ""]]}, {"id": "2012.02592", "submitter": "Nadisha-Marie Aliman", "authors": "Nadisha-Marie Aliman, Leon Kester, and Roman Yampolskiy", "title": "Transdisciplinary AI Observatory -- Retrospective Analyses and\n  Future-Oriented Contradistinctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, AI safety gained international recognition in the light of\nheterogeneous safety-critical and ethical issues that risk overshadowing the\nbroad beneficial impacts of AI. In this context, the implementation of AI\nobservatory endeavors represents one key research direction. This paper\nmotivates the need for an inherently transdisciplinary AI observatory approach\nintegrating diverse retrospective and counterfactual views. We delineate aims\nand limitations while providing hands-on-advice utilizing concrete practical\nexamples. Distinguishing between unintentionally and intentionally triggered AI\nrisks with diverse socio-psycho-technological impacts, we exemplify a\nretrospective descriptive analysis followed by a retrospective counterfactual\nrisk analysis. Building on these AI observatory tools, we present near-term\ntransdisciplinary guidelines for AI safety. As further contribution, we discuss\ndifferentiated and tailored long-term directions through the lens of two\ndisparate modern AI safety paradigms. For simplicity, we refer to these two\ndifferent paradigms with the terms artificial stupidity (AS) and eternal\ncreativity (EC) respectively. While both AS and EC acknowledge the need for a\nhybrid cognitive-affective approach to AI safety and overlap with regard to\nmany short-term considerations, they differ fundamentally in the nature of\nmultiple envisaged long-term solution patterns. By compiling relevant\nunderlying contradistinctions, we aim to provide future-oriented incentives for\nconstructive dialectics in practical and theoretical AI safety research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2020 16:01:49 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 02:23:13 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Aliman", "Nadisha-Marie", ""], ["Kester", "Leon", ""], ["Yampolskiy", "Roman", ""]]}, {"id": "2012.02595", "submitter": "Thomas Vetterli", "authors": "Divyansh Agarwal, Yuta Baba, Pratik Sachdeva, Tanya Tandon, Thomas\n  Vetterli, Aziz Alghunaim", "title": "Accurate and Scalable Matching of Translators to Displaced Persons for\n  Overcoming Language Barriers", "comments": "Presented at NeurIPS 2020 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Residents of developing countries are disproportionately susceptible to\ndisplacement as a result of humanitarian crises. During such crises, language\nbarriers impede aid workers in providing services to those displaced. To build\nresilience, such services must be flexible and robust to a host of possible\nlanguages. \\textit{Tarjimly} aims to overcome the barriers by providing a\nplatform capable of matching bilingual volunteers to displaced persons or aid\nworkers in need of translating. However, Tarjimly's large pool of translators\ncomes with the challenge of selecting the right translator per request. In this\npaper, we describe a machine learning system that matches translator requests\nto volunteers at scale. We demonstrate that a simple logistic regression,\noperating on easily computable features, can accurately predict and rank\ntranslator response. In deployment, this lightweight system matches 82\\% of\nrequests with a median response time of 59 seconds, allowing aid workers to\naccelerate their services supporting displaced persons.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 22:50:00 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Agarwal", "Divyansh", ""], ["Baba", "Yuta", ""], ["Sachdeva", "Pratik", ""], ["Tandon", "Tanya", ""], ["Vetterli", "Thomas", ""], ["Alghunaim", "Aziz", ""]]}, {"id": "2012.02600", "submitter": "Bilal Farooq", "authors": "Irum Sanaullah and Nael Alsaleh and Shadi Djavadian and Bilal Farooq", "title": "Spatio-Temporal Analysis of On Demand Transit: A Case Study of\n  Belleville, Canada", "comments": null, "journal-ref": "Transportation Research Part A: Planning and Policy, 2021", "doi": "10.1016/j.?tra.?2021.?01.?020", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid increase in the cyber-physical nature of transportation,\navailability of GPS data, mobile applications, and effective communication\ntechnologies have led to the emergence of On-Demand Transit (ODT) systems. In\nSeptember 2018, the City of Belleville in Canada started an on-demand public\ntransit pilot project, where the late-night fixed-route (RT 11) was substituted\nwith the ODT providing a real-time ride-hailing service. We present an in-depth\nanalysis of the spatio-temporal demand and supply, level of service, and origin\nand destination patterns of Belleville ODT users, based on the data collected\nfrom September 2018 till May 2019. The independent and combined effects of the\ndemographic characteristics (population density, working-age, and median\nincome) on the ODT trip production and attraction levels were studied using GIS\nand the K-means machine learning clustering algorithm. The results indicate\nthat ODT trips demand is highest for 11:00 pm-11:45 pm during the weekdays and\n8:00 pm-8:30 pm during the weekends. We expect this to be the result of users\nreturning home from work or shopping. Results showed that 39% of the trips were\nfound to have a waiting time of smaller than 15 minutes, while 28% of trips had\na waiting time of 15-30 minutes. The dissemination areas with higher population\ndensity, lower median income, or higher working-age percentages tend to have\nhigher ODT trip attraction levels, except for the dissemination areas that have\nhighly attractive places like commercial areas.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 13:56:18 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sanaullah", "Irum", ""], ["Alsaleh", "Nael", ""], ["Djavadian", "Shadi", ""], ["Farooq", "Bilal", ""]]}, {"id": "2012.02724", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "The Treachery of Images in the Digital Sovereignty Debate", "comments": "Minds and Machines, published online in July 2021, pp. 1-18", "journal-ref": null, "doi": "10.1007/s11023-021-09566-7", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short theoretical and argumentative essay contributes to the ongoing\ndeliberation about the so-called digital sovereignty, as pursued particularly\nin the European Union (EU). Drawing from classical political science\nliterature, the essay approaches the debate through paradoxes that arise from\napplying classical notions of sovereignty to the digital domain. With these\nparadoxes and a focus on the Peace of Westphalia in 1648, the essay develops a\nviewpoint distinct from the conventional territorial notion of sovereignty.\nAccordingly, the lesson from Westphalia has more to do with the capacity of a\nstate to govern. It is also this capacity that is argued to enable the\nsovereignty of individuals within the digital realm. With this viewpoint, the\nessay further advances another, broader, and more pressing debate on politics\nand democracy in the digital era.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 17:14:33 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 10:49:18 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 06:01:17 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 09:51:15 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "2012.02748", "submitter": "Jonathan Dinu", "authors": "Jonathan Dinu (1), Jeffrey Bigham (2), J. Zico Kolter (2) ((1)\n  Unaffiliated, (2) Carnegie Mellon University)", "title": "Challenging common interpretability assumptions in feature attribution\n  explanations", "comments": "Presented at the NeurIPS 2020 ML-Retrospectives, Surveys &\n  Meta-Analyses Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  As machine learning and algorithmic decision making systems are increasingly\nbeing leveraged in high-stakes human-in-the-loop settings, there is a pressing\nneed to understand the rationale of their predictions. Researchers have\nresponded to this need with explainable AI (XAI), but often proclaim\ninterpretability axiomatically without evaluation. When these systems are\nevaluated, they are often tested through offline simulations with proxy metrics\nof interpretability (such as model complexity). We empirically evaluate the\nveracity of three common interpretability assumptions through a large scale\nhuman-subjects experiment with a simple \"placebo explanation\" control. We find\nthat feature attribution explanations provide marginal utility in our task for\na human decision maker and in certain cases result in worse decisions due to\ncognitive and contextual confounders. This result challenges the assumed\nuniversal benefit of applying these methods and we hope this work will\nunderscore the importance of human evaluation in XAI research. Supplemental\nmaterials -- including anonymized data from the experiment, code to replicate\nthe study, an interactive demo of the experiment, and the models used in the\nanalysis -- can be found at: https://doi.pizza/challenging-xai.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 17:57:26 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Dinu", "Jonathan", ""], ["Bigham", "Jeffrey", ""], ["Kolter", "J. Zico", ""]]}, {"id": "2012.02845", "submitter": "Zhichao Jiang", "authors": "Kosuke Imai, Zhichao Jiang, James Greiner, Ryan Halen, Sooahn Shin", "title": "Experimental Evaluation of Algorithm-Assisted Human Decision-Making:\n  Application to Pretrial Public Safety Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite an increasing reliance on fully-automated algorithmic decision making\nin our day-to-day lives, human beings still make highly consequential\ndecisions. As frequently seen in business, healthcare, and public policy,\nrecommendations produced by algorithms are provided to human decision-makers in\norder to guide their decisions. While there exists a fast-growing literature\nevaluating the bias and fairness of such algorithmic recommendations, an\noverlooked question is whether they help humans make better decisions. We\ndevelop a statistical methodology for experimentally evaluating the causal\nimpacts of algorithmic recommendations on human decisions. We also show how to\nexamine whether algorithmic recommendations improve the fairness of human\ndecisions and derive the optimal decisions under various settings. We apply the\nproposed methodology to the first-ever randomized controlled trial that\nevaluates the pretrial Public Safety Assessment (PSA) in the criminal justice\nsystem. A goal of the PSA is to help judges decide which arrested individuals\nshould be released. We find that the PSA provision has little overall impact on\nthe judge's decisions and subsequent arrestee behavior. However, our analysis\nprovides some potentially suggestive evidence that the PSA may help avoid\nunnecessarily harsh decisions for female arrestees regardless of their risk\nlevels while it encourages the judge to make stricter decisions for male\narrestees who are deemed to be risky. In terms of fairness, the PSA appears to\nincrease the gender bias against males while having little effect on the\nexisting racial biases of the judge's decisions against non-white males.\nFinally, we find that the PSA's recommendations might be too severe unless the\ncost of a new crime is sufficiently higher than the cost of a decision that may\nresult in an unnecessary incarceration.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 20:48:44 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Imai", "Kosuke", ""], ["Jiang", "Zhichao", ""], ["Greiner", "James", ""], ["Halen", "Ryan", ""], ["Shin", "Sooahn", ""]]}, {"id": "2012.02885", "submitter": "Abhishek Singh", "authors": "Abhishek Singh, Ramesh Raskar", "title": "Verifiable Proof of Health using Public Key Cryptography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current pandemic, testing continues to be the most important tool for\nmonitoring and curbing the disease spread and early identification of the\ndisease to perform health-related interventions like quarantine, contact\ntracing and etc. Therefore, the ability to verify the testing status is\npertinent as public places prepare to safely open. Recent advances in\ncryptographic tools have made it possible to build a secure and resilient\ndigital-id system. In this work, we propose to build an end to end COVID-19\nresults verification protocol that takes privacy, computation, and other\npractical concerns into account for designing an inter-operable layer of\ntesting results verification system that could potentially enable less\nstringent and more selective lockdowns. We also discuss various concerns\nencompassing the security, privacy, ethics and equity aspect of the proposed\nsystem.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 22:54:33 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Singh", "Abhishek", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2012.02939", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam, Dan Goldwasser", "title": "Does Yoga Make You Happy? Analyzing Twitter User Happiness using Textual\n  and Temporal Information", "comments": "accepted at IEEE BigData 2020", "journal-ref": null, "doi": "10.1109/BigData50022.2020.9378461", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although yoga is a multi-component practice to hone the body and mind and be\nknown to reduce anxiety and depression, there is still a gap in understanding\npeople's emotional state related to yoga in social media. In this study, we\ninvestigate the causal relationship between practicing yoga and being happy by\nincorporating textual and temporal information of users using Granger\ncausality. To find out causal features from the text, we measure two variables\n(i) Yoga activity level based on content analysis and (ii) Happiness level\nbased on emotional state. To understand users' yoga activity, we propose a\njoint embedding model based on the fusion of neural networks with attention\nmechanism by leveraging users' social and textual information. For measuring\nthe emotional state of yoga users (target domain), we suggest a transfer\nlearning approach to transfer knowledge from an attention-based neural network\nmodel trained on a source domain. Our experiment on Twitter dataset\ndemonstrates that there are 1447 users where \"yoga Granger-causes happiness\".\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 03:30:49 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Islam", "Tunazzina", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2012.02950", "submitter": "Guansong Pang", "authors": "Guansong Pang, Ngoc Thien Anh Pham, Emma Baker, Rebecca Bentley, Anton\n  van den Hengel", "title": "Deep Multi-task Learning for Depression Detection and Prediction in\n  Longitudinal Data", "comments": "9 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Depression is among the most prevalent mental disorders, affecting millions\nof people of all ages globally. Machine learning techniques have shown\neffective in enabling automated detection and prediction of depression for\nearly intervention and treatment. However, they are challenged by the relative\nscarcity of instances of depression in the data. In this work we introduce a\nnovel deep multi-task recurrent neural network to tackle this challenge, in\nwhich depression classification is jointly optimized with two auxiliary tasks,\nnamely one-class metric learning and anomaly ranking. The auxiliary tasks\nintroduce an inductive bias that improves the classification model's\ngeneralizability on small depression samples. Further, unlike existing studies\nthat focus on learning depression signs from static data without considering\ntemporal dynamics, we focus on longitudinal data because i) temporal changes in\npersonal development and family environment can provide critical cues for\npsychiatric disorders and ii) it may enable us to predict depression before the\nillness actually occurs. Extensive experimental results on child depression\ndata show that our model is able to i) achieve nearly perfect performance in\ndepression detection and ii) accurately predict depression 2-4 years before the\nclinical diagnosis, substantially outperforming seven competing methods.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 05:14:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Pang", "Guansong", ""], ["Pham", "Ngoc Thien Anh", ""], ["Baker", "Emma", ""], ["Bentley", "Rebecca", ""], ["Hengel", "Anton van den", ""]]}, {"id": "2012.02972", "submitter": "Kit Rodolfa", "authors": "Kit T. Rodolfa, Hemank Lamba, Rayid Ghani", "title": "Empirical observation of negligible fairness-accuracy trade-offs in\n  machine learning for public policy", "comments": "39 pages, 4 figures, 2 tables, 7 supplementary figures, 4\n  supplementary tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing applications of machine learning in policy and social impact settings\nhave raised concern for fairness implications, especially for racial\nminorities. These concerns have generated considerable interest among machine\nlearning and artificial intelligence researchers, who have developed new\nmethods and established theoretical bounds for improving fairness, focusing on\nthe source data, regularization and model training, or post-hoc adjustments to\nmodel scores. However, little work has studied the practical trade-offs between\nfairness and accuracy in real-world settings to understand how these bounds and\nmethods translate into policy choices and impact on society. Our empirical\nstudy fills this gap by investigating the impact on accuracy of mitigating\ndisparities across several policy settings, focusing on the common context of\nusing machine learning to inform benefit allocation in resource-constrained\nprograms across education, mental health, criminal justice, and housing safety.\nWe show that fairness-accuracy trade-offs in many applications are negligible\nin practice. In every setting, we find that explicitly focusing on achieving\nequity and using our proposed post-hoc disparity mitigation methods, fairness\nwas substantially improved without sacrificing accuracy. This observation was\nrobust across policy contexts studied, scale of resources available for\nintervention, time, and relative size of the protected groups. These empirical\nresults challenge a commonly held assumption that reducing disparities either\nrequires accepting an appreciable drop in accuracy or the development of novel,\ncomplex methods, making reducing disparities in these applications more\npractical.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 08:10:47 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 04:28:33 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Rodolfa", "Kit T.", ""], ["Lamba", "Hemank", ""], ["Ghani", "Rayid", ""]]}, {"id": "2012.03049", "submitter": "Kwan Hui Lim Dr", "authors": "Marcus Yong and Kwan Hui Lim", "title": "Urban Heat Islands: Beating the Heat with Multi-Modal Spatial Analysis", "comments": "Accepted at the 2020 IEEE International Conference on Big Data\n  (BigData'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's highly urbanized environment, the Urban Heat Island (UHI)\nphenomenon is increasingly prevalent where surface temperatures in urbanized\nareas are found to be much higher than surrounding rural areas. Excessive\nlevels of heat stress leads to problems at various levels, ranging from the\nindividual to the world. At the individual level, UHI could lead to the human\nbody being unable to cope and break-down in terms of core functions. At the\nworld level, UHI potentially contributes to global warming and adversely\naffects the environment. Using a multi-modal dataset comprising remote sensory\nimagery, geo-spatial data and population data, we proposed a framework for\ninvestigating how UHI is affected by a city's urban form characteristics\nthrough the use of statistical modelling. Using Singapore as a case study, we\ndemonstrate the usefulness of this framework and discuss our main findings in\nunderstanding the effects of UHI and urban form characteristics.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 15:18:22 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Yong", "Marcus", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "2012.03055", "submitter": "Nafees Mansoor PhD", "authors": "Nafees Mansoor", "title": "Conceptualizing and Realizing A Smart City Model for Bangladesh", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of the novel Corona Virus in 2019, named COVID-19, causes the\nongoing global pandemic. This pandemic has a devastating socio-economic impact\nacross the globe. On the other hand, due to the pre-pandemic aggressive\nurbanization with the steep population growth, modern cities also facing\nsubstantial challenges. Hence, usage of technology is anticipated to be the\nprecondition for adaptive, resilient, and sustainable development, where, a\nsmart city is defined as the accumulated advanced ideas of information and\ntechnology aiming to ensure a decent quality of life for the inhabitants.\nConsidering the current growth rate of 1.9 percent, the projected population of\nBangladesh will exceed 180 million in 2026. It is also speculated that Dhaka\nbeing the capital will be populated with 14 million inhabitants. Moreover,\nDhaka has already been labeled as the most densely populated city in the world.\nThus, concerned authorities are facing enormous challenges to provide and\nensure fundamental services to the in-habitants. Therefore, this has become the\nneed of the hour to conceptualize an information and communication\ntechnology-driven smart city for Bangladesh. A smart city may contain numerous\ncomponents; however, the proposed framework identifies seven components and\nservices for smart cities in Bangladesh. These are healthcare, education,\ntransportation, public safety, real estate, utilities, and city administration.\nDiscussions on these components are carried out in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 15:34:04 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Mansoor", "Nafees", ""]]}, {"id": "2012.03283", "submitter": "Jianwei Huang", "authors": "Jianwei Huang, Vinod Yegneswaran, Phillip Porras, and Guofei Gu", "title": "On the Privacy and Integrity Risks of Contact-Tracing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone-based contact-tracing applications are at the epicenter of the\nglobal fight against the Covid-19 pandemic. While governments and healthcare\nagencies are eager to mandate the deployment of such applications en-masse,\nthey face increasing scrutiny from the popular press, security companies, and\nhuman rights watch agencies that fear the exploitation of these technologies as\nsurveillance tools. Finding the optimal balance between community safety and\nprivacy has been a challenge, and strategies to address these concerns have\nvaried among countries. This paper describes two important attacks that affect\na broad swath of contact-tracing applications. The first, referred to as\ncontact-isolation attack, is a user-privacy attack that can be used to identify\npotentially infected patients in your neighborhood. The second is a\ncontact-pollution attack that affects the integrity of contact tracing\napplications by causing them to produce a high volume of false-positive alerts.\nWe developed prototype implementations and evaluated both attacks in the\ncontext of the DP-3T application framework, but these vulnerabilities affect a\nmuch broader class of applications. We found that both attacks are feasible and\nrealizable with a minimal attacker work factor. We further conducted an impact\nassessment of these attacks by using a simulation study and measurements from\nthe SafeGraph database. Our results indicate that attacks launched from a\nmodest number (on the order of 10,000) of monitoring points can effectively\ndecloak between 5-40\\% of infected users in a major metropolis, such as\nHouston.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 15:05:02 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 19:04:31 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Huang", "Jianwei", ""], ["Yegneswaran", "Vinod", ""], ["Porras", "Phillip", ""], ["Gu", "Guofei", ""]]}, {"id": "2012.03319", "submitter": "Alexis Tsoukias", "authors": "Alexis Tsouki\\`as", "title": "Social Responsibility of Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": "Cahier LAMSADE 397", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Should we be concerned by the massive use of devices and algorithms which\nautomatically handle an increasing number of everyday activities within our\nsocieties? The paper makes a short overview of the scientific investigation\naround this topic, showing that the development, existence and use of such\nautonomous artifacts is much older than the recent interest in machine learning\nmonopolised artificial intelligence. We then categorise the impact of using\nsuch artifacts to the whole process of data collection, structuring,\nmanipulation as well as in recommendation and decision making. The suggested\nframework allows to identify a number of challenges for the whole community of\ndecision analysts, both researchers and practitioners.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 16:46:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Tsouki\u00e0s", "Alexis", ""]]}, {"id": "2012.03487", "submitter": "Bonaventure F. P. Dossou", "authors": "Bonaventure F. P. Dossou, Alena Iureva, Sayali R. Rajhans, Vamsi S.\n  Pidikiti", "title": "An Approach to Intelligent Pneumonia Detection and Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each year, over 2.5 million people, most of them in developed countries, die\nfrom pneumonia [1]. Since many studies have proved pneumonia is successfully\ntreatable when timely and correctly diagnosed, many of diagnosis aids have been\ndeveloped, with AI-based methods achieving high accuracies [2]. However,\ncurrently, the usage of AI in pneumonia detection is limited, in particular,\ndue to challenges in generalizing a locally achieved result. In this report, we\npropose a roadmap for creating and integrating a system that attempts to solve\nthis challenge. We also address various technical, legal, ethical, and\nlogistical issues, with a blueprint of possible solutions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:27:45 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Dossou", "Bonaventure F. P.", ""], ["Iureva", "Alena", ""], ["Rajhans", "Sayali R.", ""], ["Pidikiti", "Vamsi S.", ""]]}, {"id": "2012.03659", "submitter": "Nithya Sambasivan", "authors": "Nithya Sambasivan, Erin Arnesen, Ben Hutchinson, Vinodkumar\n  Prabhakaran", "title": "Non-portability of Algorithmic Fairness in India", "comments": "Part of the Navigating the Broader Impacts of AI Research Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Conventional algorithmic fairness is Western in its sub-groups, values, and\noptimizations. In this paper, we ask how portable the assumptions of this\nlargely Western take on algorithmic fairness are to a different geo-cultural\ncontext such as India. Based on 36 expert interviews with Indian scholars, and\nan analysis of emerging algorithmic deployments in India, we identify three\nclusters of challenges that engulf the large distance between machine learning\nmodels and oppressed communities in India. We argue that a mere translation of\ntechnical fairness work to Indian subgroups may serve only as a window\ndressing, and instead, call for a collective re-imagining of Fair-ML, by\nre-contextualising data and models, empowering oppressed communities, and more\nimportantly, enabling ecosystems.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 23:14:13 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 20:10:12 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Sambasivan", "Nithya", ""], ["Arnesen", "Erin", ""], ["Hutchinson", "Ben", ""], ["Prabhakaran", "Vinodkumar", ""]]}, {"id": "2012.03728", "submitter": "Niklas K\\\"uhl Dr", "authors": "Lucas Baier, Niklas K\\\"uhl, Jakob Sch\\\"offer, Gerhard Satzger", "title": "Utilizing Concept Drift for Measuring the Effectiveness of Policy\n  Interventions: The Case of the COVID-19 Pandemic", "comments": null, "journal-ref": "European Journal of Information Systems (2020)", "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As a reaction to the high infectiousness and lethality of the COVID-19 virus,\ncountries around the world have adopted drastic policy measures to contain the\npandemic. However, it remains unclear which effect these measures, so-called\nnon-pharmaceutical interventions (NPIs), have on the spread of the virus. In\nthis article, we use machine learning and apply drift detection methods in a\nnovel way to measure the effectiveness of policy interventions: We analyze the\neffect of NPIs on the development of daily case numbers of COVID-19 across 9\nEuropean countries and 28 US states. Our analysis shows that it takes more than\ntwo weeks on average until NPIs show a significant effect on the number of new\ncases. We then analyze how characteristics of each country or state, e.g.,\ndecisiveness regarding NPIs, climate or population density, influence the time\nlag until NPIs show their effectiveness. In our analysis, especially the timing\nof school closures reveals a significant effect on the development of the\npandemic. This information is crucial for policy makers confronted with\ndifficult decisions to trade off strict containment of the virus with NPI\nrelief.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 09:28:39 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Baier", "Lucas", ""], ["K\u00fchl", "Niklas", ""], ["Sch\u00f6ffer", "Jakob", ""], ["Satzger", "Gerhard", ""]]}, {"id": "2012.03739", "submitter": "Yawen Zhang", "authors": "Yawen Zhang, Seth Spielman, Qi Liu, Si Shen, Jason Shuo Zhang, Qin Lv", "title": "Exploring the Usage of Online Food Delivery Data for Intra-Urban Job and\n  Housing Mobility Detection and Characterization", "comments": "Accepted by SocialCom-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human mobility plays a critical role in urban planning and policy-making.\nHowever, at certain spatial and temporal resolutions, it is very challenging to\ntrack, for example, job and housing mobility. In this study, we explore the\nusage of a new modality of dataset, online food delivery data, to detect job\nand housing mobility. By leveraging millions of meal orders from a popular\nonline food ordering and delivery service in Beijing, China, we are able to\ndetect job and housing moves at much higher spatial and temporal resolutions\nthan using traditional data sources. Popular moving seasons and\norigins/destinations can be well identified. More importantly, we match the\ndetected moves to both macro- and micro-level factors so as to characterize job\nand housing dynamics. Our findings suggest that commuting distance is a major\nfactor for job and housing mobility. We also observe that: (1) For home movers,\nthere is a trade-off between lower housing cost and shorter commuting distance\ngiven the urban spatial structure; (2) For job hoppers, those who frequently\nwork overtime are more likely to reduce their working hours by switching jobs.\nWhile this new modality of dataset has its limitations, we believe that\nensemble approaches would be promising, where a mash-up of multiple datasets\nwith different characteristic limitations can provide a more comprehensive\npicture of job and housing dynamics. Our work demonstrates the effectiveness of\nutilizing food delivery data to detect and analyze job and housing mobility,\nand contributes to realizing the full potential of ensemble-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 02:48:53 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Zhang", "Yawen", ""], ["Spielman", "Seth", ""], ["Liu", "Qi", ""], ["Shen", "Si", ""], ["Zhang", "Jason Shuo", ""], ["Lv", "Qin", ""]]}, {"id": "2012.03743", "submitter": "Marcos Baez", "authors": "Alessandro Pina, Marcos Baez, Florian Daniel", "title": "Bringing Cognitive Augmentation to Web Browsing Accessibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the opportunities brought by cognitive augmentation\nto provide a more natural and accessible web browsing experience. We explore\nthese opportunities through \\textit{conversational web browsing}, an emerging\ninteraction paradigm for the Web that enables blind and visually impaired users\n(BVIP), as well as regular users, to access the contents and features of\nwebsites through conversational agents. Informed by the literature, our\nprevious work and prototyping exercises, we derive a conceptual framework for\nsupporting BVIP conversational web browsing needs, to then focus on the\nchallenges of automatically providing this support, describing our early work\nand prototype that leverage heuristics that consider structural and content\nfeatures only.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 14:40:52 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Pina", "Alessandro", ""], ["Baez", "Marcos", ""], ["Daniel", "Florian", ""]]}, {"id": "2012.03746", "submitter": "Mojtaba Shahin", "authors": "Mojtaba Shahin, Olivia Ilic, Chris Gonsalvez, Jon Whittle", "title": "The Impact of a STEM-based Entrepreneurship Program on the\n  Entrepreneurial Intention of Secondary School Female Students", "comments": "20 Pages, Accepted to appear in International Entrepreneurship and\n  Management Journal (IEMJ), Springer, 2020", "journal-ref": "International Entrepreneurship and Management Journal (2021)", "doi": "10.1007/s11365-020-00713-7", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite dedicated effort and research in the last two decades, the\nentrepreneurship field is still limited by little evidence-based knowledge of\nthe impacts of entrepreneurship programs on the entrepreneurial intention of\nstudents in pre-university levels of study. Further, gender equity continues to\nbe an issue in the entrepreneurial sector, particularly in STEM-focused\nentrepreneurship. In this context, this study was designed to explore the\neffects of a one-day female-focused STEM-based entrepreneurship program (for\nbrevity, we call it the OzGirlsEntrepreneurship program) on the entrepreneurial\nintention of secondary school female students. The study collected data from\ntwo surveys completed by 193 secondary school female students, aged 14-16\nyears, who participated in the OzGirlsEntrepreneurship program. This program\nencouraged girls to develop and implement creative computational solutions to\nsocially relevant problems, with an Internet of Things (IoT) component using\nthe micro:bit device. The findings reveal that a key factor in the development\nof entrepreneurial attitudes in young female students is associated with\nsoft-skills development, particularly in the areas of creative thinking,\nrisk-taking, problem-solving, and leadership development. The importance of\nmeaningful human connections, including positive role modelling and peer to\npeer learning were also important factors in fostering entrepreneurial intent.\nWith these factors in mind, our findings highlight that the\nOzGirlsEntrepreneurship program substantially increased the entrepreneurial\nintention of secondary school female students. In addition, this study offers\nactionable implications and recommendations to develop and deliver\nentrepreneurship education programs for secondary school level students.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:18:37 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2021 02:06:13 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Shahin", "Mojtaba", ""], ["Ilic", "Olivia", ""], ["Gonsalvez", "Chris", ""], ["Whittle", "Jon", ""]]}, {"id": "2012.03782", "submitter": "Fumiyuki Kato", "authors": "Fumiyuki Kato, Yang Cao, and Yoshikawa Masatoshi", "title": "PCT-TEE: Trajectory-based Private Contact Tracing System with Trusted\n  Execution Environment", "comments": "arXiv admin note: substantial text overlap with arXiv:2010.13381.\n  text overlap with arXiv:2010.13381", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Bluetooth-based Private Contact Tracing (PCT) systems can privately\ndetect whether people have come into direct contact with COVID-19 patients.\nHowever, we find that the existing systems lack functionality and flexibility,\nwhich may hurt the success of the contact tracing. Specifically, they cannot\ndetect indirect contact (e.g., people may be exposed to coronavirus because of\nused the same elevator even without direct contact); they also cannot flexibly\nchange the rules of \"risky contact\", such as how many hours of exposure or how\nclose to a COVID-19 patient that is considered as risk exposure, which may be\nchanged with the environmental situation. In this paper, we propose an\nefficient and secure contact tracing system that enables both direct contact\nand indirect contact. To address the above problems, we need to utilize users'\ntrajectory data for private contact tracing, which we call trajectory-based\nPCT. We formalize this problem as Spatiotemporal Private Set Intersection. By\nanalyzing different approaches such as homomorphic encryption that could be\nextended to solve this problem, we identify that Trusted Execution Environment\n(TEE) is a proposing method to achieve our requirements. The major challenge is\nhow to design algorithms for spatiotemporal private set intersection under\nlimited secure memory of TEE. To this end, we design a TEE-based system with\nflexible trajectory data encoding algorithms. Our experiments on real-world\ndata show that the proposed system can process thousands of queries on tens of\nmillion records of trajectory data in a few seconds.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:22:19 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:03:46 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 11:32:55 GMT"}, {"version": "v4", "created": "Sun, 27 Jun 2021 14:25:28 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kato", "Fumiyuki", ""], ["Cao", "Yang", ""], ["Masatoshi", "Yoshikawa", ""]]}, {"id": "2012.03900", "submitter": "Govardana Sachithanandam Ramachandran", "authors": "Govardana Sachithanandam Ramachandran, Ivan Brugere, Lav R. Varshney,\n  and Caiming Xiong", "title": "GAEA: Graph Augmentation for Equitable Access via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disparate access to resources by different subpopulations is a prevalent\nissue in societal and sociotechnical networks. For example, urban\ninfrastructure networks may enable certain racial groups to more easily access\nresources such as high-quality schools, grocery stores, and polling places.\nSimilarly, social networks within universities and organizations may enable\ncertain groups to more easily access people with valuable information or\ninfluence. Here we introduce a new class of problems, Graph Augmentation for\nEquitable Access (GAEA), to enhance equity in networked systems by editing\ngraph edges under budget constraints. We prove such problems are NP-hard, and\ncannot be approximated within a factor of $(1-\\tfrac{1}{3e})$. We develop a\nprincipled, sample- and time- efficient Markov Reward Process (MRP)-based\nmechanism design framework for GAEA. Our algorithm outperforms baselines on a\ndiverse set of synthetic graphs. We further demonstrate the method on\nreal-world networks, by merging public census, school, and transportation\ndatasets for the city of Chicago and applying our algorithm to find\nhuman-interpretable edits to the bus network that enhance equitable access to\nhigh-quality schools across racial groups. Further experiments on Facebook\nnetworks of universities yield sets of new social connections that would\nincrease equitable access to certain attributed nodes across gender groups.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 18:29:32 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 11:27:25 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Ramachandran", "Govardana Sachithanandam", ""], ["Brugere", "Ivan", ""], ["Varshney", "Lav R.", ""], ["Xiong", "Caiming", ""]]}, {"id": "2012.04104", "submitter": "Fereshte Khani", "authors": "Fereshte Khani, Percy Liang", "title": "Removing Spurious Features can Hurt Accuracy and Affect Groups\n  Disproportionately", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of spurious features interferes with the goal of obtaining\nrobust models that perform well across many groups within the population. A\nnatural remedy is to remove spurious features from the model. However, in this\nwork we show that removal of spurious features can decrease accuracy due to the\ninductive biases of overparameterized models. We completely characterize how\nthe removal of spurious features affects accuracy across different groups (more\ngenerally, test distributions) in noiseless overparameterized linear\nregression. In addition, we show that removal of spurious feature can decrease\nthe accuracy even in balanced datasets -- each target co-occurs equally with\neach spurious feature; and it can inadvertently make the model more susceptible\nto other spurious features. Finally, we show that robust self-training can\nremove spurious features without affecting the overall accuracy. Experiments on\nthe Toxic-Comment-Detectoin and CelebA datasets show that our results hold in\nnon-linear models.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 23:08:59 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Khani", "Fereshte", ""], ["Liang", "Percy", ""]]}, {"id": "2012.04405", "submitter": "Ryan K. L. Ko", "authors": "Ryan K L Ko", "title": "Cyber Autonomy: Automating the Hacker- Self-healing, self-adaptive,\n  automatic cyber defense systems and their impact to the industry, society and\n  national security", "comments": "15 pages, 5 figures, preprint of chapter in edited book \"Emerging\n  Technologies and International Security: Machines, the State, and War\" edited\n  By Reuben Steff, Joe Burton, Simona R. Soare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper sets the context for the urgency for cyber autonomy, and the\ncurrent gaps of the cyber security industry. A novel framework proposing four\nphases of maturity for full cyber autonomy will be discussed. The paper also\nreviews new and emerging cyber security automation techniques and tools, and\ndiscusses their impact on society, the perceived cyber security skills\ngap/shortage and national security. We will also be discussing the delicate\nbalance between national security, human rights and ethics, and the potential\ndemise of the manual penetration testing industry in the face of automation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 12:50:09 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Ko", "Ryan K L", ""]]}, {"id": "2012.04570", "submitter": "Adel Daoud", "authors": "Adel Daoud and Devdatt Dubhashi", "title": "Statistical modeling: the three cultures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two decades ago, Leo Breiman identified two cultures for statistical\nmodeling. The data modeling culture (DMC) refers to practices aiming to conduct\nstatistical inference on one or several quantities of interest. The algorithmic\nmodeling culture (AMC) refers to practices defining a machine-learning (ML)\nprocedure that generates accurate predictions about an event of interest.\nBreiman argued that statisticians should give more attention to AMC than to\nDMC, because of the strengths of ML in adapting to data. While twenty years\nlater, DMC has lost some of its dominant role in statistics because of the\ndata-science revolution, we observe that this culture is still the leading\npractice in the natural and social sciences. DMC is the modus operandi because\nof the influence of the established scientific method, called the\nhypothetico-deductive scientific method. Despite the incompatibilities of AMC\nwith this scientific method, among some research groups, AMC and DMC cultures\nmix intensely. We argue that this mixing has formed a fertile spawning pool for\na mutated culture that we called the hybrid modeling culture (HMC) where\nprediction and inference have fused into new procedures where they reinforce\none another. This article identifies key characteristics of HMC, thereby\nfacilitating the scientific endeavor and fueling the evolution of statistical\ncultures towards better practices. By better, we mean increasingly reliable,\nvalid, and efficient statistical practices in analyzing causal relationships.\nIn combining inference and prediction, the result of HMC is that the\ndistinction between prediction and inference, taken to its limit, melts away.\nWe qualify our melting-away argument by describing three HMC practices, where\neach practice captures an aspect of the scientific cycle, namely, ML for causal\ninference, ML for data acquisition, and ML for theory prediction.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 17:15:02 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Daoud", "Adel", ""], ["Dubhashi", "Devdatt", ""]]}, {"id": "2012.04580", "submitter": "James Jordon", "authors": "James Jordon, Alan Wilson and Mihaela van der Schaar", "title": "Synthetic Data: Opening the data floodgates to enable faster, more\n  directed development of machine learning methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many ground-breaking advancements in machine learning can be attributed to\nthe availability of a large volume of rich data. Unfortunately, many\nlarge-scale datasets are highly sensitive, such as healthcare data, and are not\nwidely available to the machine learning community. Generating synthetic data\nwith privacy guarantees provides one such solution, allowing meaningful\nresearch to be carried out \"at scale\" - by allowing the entirety of the machine\nlearning community to potentially accelerate progress within a given field. In\nthis article, we provide a high-level view of synthetic data: what it means,\nhow we might evaluate it and how we might use it.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 17:26:10 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Jordon", "James", ""], ["Wilson", "Alan", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2012.04770", "submitter": "Michael Specter", "authors": "John Meklenburg, Michael Specter, Michael Wentz, Hari Balakrishnan,\n  Anantha Chandrakasan, John Cohn, Gary Hatke, Louise Ivers, Ronald Rivest,\n  Gerald Jay Sussman, Daniel Weitzner", "title": "SonicPACT: An Ultrasonic Ranging Method for the Private Automated\n  Contact Tracing (PACT) Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Throughout the course of the COVID-19 pandemic, several countries have\ndeveloped and released contact tracing and exposure notification smartphone\napplications (apps) to help slow the spread of the disease. To support such\napps, Apple and Google have released Exposure Notification Application\nProgramming Interfaces (APIs) to infer device (user) proximity using Bluetooth\nLow Energy (BLE) beacons. The Private Automated Contact Tracing (PACT) team has\nshown that accurately estimating the distance between devices using only BLE\nradio signals is challenging. This paper describes the design and\nimplementation of the SonicPACT protocol to use near-ultrasonic signals on\ncommodity iOS and Android smartphones to estimate distances using\ntime-of-flight measurements. The protocol allows Android and iOS devices to\ninteroperate, augmenting and improving the current exposure notification APIs.\nOur initial experimental results are promising, suggesting that SonicPACT\nshould be considered for implementation by Apple and Google.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 22:33:39 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Meklenburg", "John", ""], ["Specter", "Michael", ""], ["Wentz", "Michael", ""], ["Balakrishnan", "Hari", ""], ["Chandrakasan", "Anantha", ""], ["Cohn", "John", ""], ["Hatke", "Gary", ""], ["Ivers", "Louise", ""], ["Rivest", "Ronald", ""], ["Sussman", "Gerald Jay", ""], ["Weitzner", "Daniel", ""]]}, {"id": "2012.04800", "submitter": "Bahar Taskesen", "authors": "Bahar Taskesen, Jose Blanchet, Daniel Kuhn, Viet Anh Nguyen", "title": "A Statistical Test for Probabilistic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithms are now routinely used to make consequential decisions that affect\nhuman lives. Examples include college admissions, medical interventions or law\nenforcement. While algorithms empower us to harness all information hidden in\nvast amounts of data, they may inadvertently amplify existing biases in the\navailable datasets. This concern has sparked increasing interest in fair\nmachine learning, which aims to quantify and mitigate algorithmic\ndiscrimination. Indeed, machine learning models should undergo intensive tests\nto detect algorithmic biases before being deployed at scale. In this paper, we\nuse ideas from the theory of optimal transport to propose a statistical\nhypothesis test for detecting unfair classifiers. Leveraging the geometry of\nthe feature space, the test statistic quantifies the distance of the empirical\ndistribution supported on the test samples to the manifold of distributions\nthat render a pre-trained classifier fair. We develop a rigorous hypothesis\ntesting mechanism for assessing the probabilistic fairness of any pre-trained\nlogistic classifier, and we show both theoretically as well as empirically that\nthe proposed test is asymptotically correct. In addition, the proposed\nframework offers interpretability by identifying the most favorable\nperturbation of the data so that the given classifier becomes fair.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 00:20:02 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Taskesen", "Bahar", ""], ["Blanchet", "Jose", ""], ["Kuhn", "Daniel", ""], ["Nguyen", "Viet Anh", ""]]}, {"id": "2012.04970", "submitter": "Shah Miah Prof", "authors": "F H Masmali, S J Miah, NY Mathkoor", "title": "Internet of Things-based innovations in Saudi healthcare sector: A\n  methodological approach for investigating adoption issues", "comments": "5 pages", "journal-ref": "IEEE CDS Conference 2020, Gold Coast, QLD, Australia", "doi": null, "report-no": "IEEE Manuscript 213", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Using today's Internet network capacities, this technology has extended\nvarious benefits in healthcare sectors. For instance, existing studies already\nindicated that information technology applications with IoT-based innovations\nmay revolutionize the healthcare industry and subsequently help to improve the\nreal-time reporting of patients' health data. It should be noted that the\nadoption of IoT and its relevant interventions in the health sector has not\nbeen as fast as the uptake been observed in other industries. To tackle this\nissue, we develop a qualitative phenomenological approach for investigating\nfactors that affect IoT adoption and its integration into healthcare service\ndelivery in Saudi Arabia.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 10:49:50 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Masmali", "F H", ""], ["Miah", "S J", ""], ["Mathkoor", "NY", ""]]}, {"id": "2012.05017", "submitter": "Maurizio Canavari", "authors": "Marco Medici and S{\\o}ren Marcus Pedersen and Maurizio Canavari and\n  Thomas Anken and Panagiotis Stamatelopoulos and Zisis Tsiropoulos and Alex\n  Zotos and Ghasem Tohidloo", "title": "A web-tool for calculating the economic performance of precision\n  agriculture technology", "comments": null, "journal-ref": null, "doi": "10.1016/j.compag.2020.105930", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  To develop precision agriculture (PA) to its full potential and make\nagriculture progress toward sustainability and resilience, appropriate criteria\nfor the economic assessment are recognised as being one of the most significant\nissues requiring urgent and ongoing attention. In this work, we develop a\nweb-tool supporting the assessment of the net economic benefits of integrating\nprecision farming technologies in different contexts. The methodological\napproach of the tool is accessible to any agricultural stakeholder through a\nguided process that allows to evaluate and compare precision agriculture\ntechnologies with conventional systems, leading the final user to assess the\nfinancial viability and environmental impact resulting from the potential\nimplementation of various precision agriculture technologies in his farm. The\nweb-tool is designed to provide guidelines for farmers over their decisions to\ninvest in selected PA technologies, by increasing the knowledge level about\nnovel technologies characteristics and the related benefits. Possible input\nreduction also offers the possibility to investigate the mitigation of\nenvironmental impacts.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 12:51:15 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Medici", "Marco", ""], ["Pedersen", "S\u00f8ren Marcus", ""], ["Canavari", "Maurizio", ""], ["Anken", "Thomas", ""], ["Stamatelopoulos", "Panagiotis", ""], ["Tsiropoulos", "Zisis", ""], ["Zotos", "Alex", ""], ["Tohidloo", "Ghasem", ""]]}, {"id": "2012.05097", "submitter": "Jaap-Henk Hoepman", "authors": "Jaap-Henk Hoepman", "title": "A Critique of the Google Apple Exposure Notification (GAEN) Framework", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a response to the COVID-19 pandemic digital contact tracing has been\nproposed as a tool to support the health authorities in their quest to\ndetermine who has been in close and sustained contact with a person infected by\nthe coronavirus. In April 2020 Google and Apple released the Google Apple\nExposure Notification (GAEN) framework, as a decentralised and more privacy\nfriendly platform for contact tracing. The GAEN framework implements exposure\nnotification mostly at the operating system layer, instead of fully at the\napp(lication) layer. In this paper we study the consequences of this approach.\nWe argue that this creates a dormant functionality for mass surveillance at the\noperating system layer. We show how it does not technically prevent the health\nauthorities from implementing a purely centralised form of contact tracing\n(even though that is the stated aim). We highlight that GAEN allows Google and\nApple to dictate how contact tracing is (or rather isn't) implemented in\npractice by health authorities, and how it introduces the risk of function\ncreep.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 15:05:59 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 09:21:30 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Hoepman", "Jaap-Henk", ""]]}, {"id": "2012.05101", "submitter": "Erwan Le Merrer", "authors": "Erwan Le Merrer and Benoit Morgan and Gilles Tr\\'edan", "title": "Setting the Record Straighter on Shadow Banning", "comments": "Appearing in INFOCOM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shadow banning consists for an online social network in limiting the\nvisibility of some of its users, without them being aware of it. Twitter\ndeclares that it does not use such a practice, sometimes arguing about the\noccurrence of \"bugs\" to justify restrictions on some users. This paper is the\nfirst to address the plausibility or not of shadow banning on a major online\nplatform, by adopting both a statistical and a graph topological approach. We\nfirst conduct an extensive data collection and analysis campaign, gathering\noccurrences of visibility limitations on user profiles (we crawl more than 2.5\nmillion of them). In such a black-box observation setup, we highlight the\nsalient user profile features that may explain a banning practice (using\nmachine learning predictors). We then pose two hypotheses for the phenomenon:\ni) limitations are bugs, as claimed by Twitter, and ii) shadow banning\npropagates as an epidemic on user-interactions ego-graphs. We show that\nhypothesis i) is statistically unlikely with regards to the data we collected.\nWe then show some interesting correlation with hypothesis ii), suggesting that\nthe interaction topology is a good indicator of the presence of groups of\nshadow banned users on the service.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 15:17:33 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 12:08:39 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Merrer", "Erwan Le", ""], ["Morgan", "Benoit", ""], ["Tr\u00e9dan", "Gilles", ""]]}, {"id": "2012.05225", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Barry-John Theobald, Anurag Ranjan, Ahmed Hussein\n  Abdelaziz, Nicholas Apostoloff", "title": "MorphGAN: One-Shot Face Synthesis GAN for Detecting Recognition Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To detect bias in face recognition networks, it can be useful to probe a\nnetwork under test using samples in which only specific attributes vary in some\ncontrolled way. However, capturing a sufficiently large dataset with specific\ncontrol over the attributes of interest is difficult. In this work, we describe\na simulator that applies specific head pose and facial expression adjustments\nto images of previously unseen people. The simulator first fits a 3D morphable\nmodel to a provided image, applies the desired head pose and facial expression\ncontrols, then renders the model into an image. Next, a conditional Generative\nAdversarial Network (GAN) conditioned on the original image and the rendered\nmorphable model is used to produce the image of the original person with the\nnew facial expression and head pose. We call this conditional GAN -- MorphGAN.\nImages generated using MorphGAN conserve the identity of the person in the\noriginal image, and the provided control over head pose and facial expression\nallows test sets to be created to identify robustness issues of a facial\nrecognition deep network with respect to pose and expression. Images generated\nby MorphGAN can also serve as data augmentation when training data are scarce.\nWe show that by augmenting small datasets of faces with new poses and\nexpressions improves the recognition performance by up to 9% depending on the\naugmentation and data scarcity.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 18:43:03 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 18:48:22 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Theobald", "Barry-John", ""], ["Ranjan", "Anurag", ""], ["Abdelaziz", "Ahmed Hussein", ""], ["Apostoloff", "Nicholas", ""]]}, {"id": "2012.05370", "submitter": "Ben Green", "authors": "Ben Green, Yiling Chen", "title": "Algorithmic risk assessments can alter human decision-making processes\n  in high-stakes government contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Governments are increasingly turning to algorithmic risk assessments when\nmaking important decisions, believing that these algorithms will improve public\nservants' ability to make policy-relevant predictions and thereby lead to more\ninformed decisions. Yet because many policy decisions require balancing\nrisk-minimization with competing social goals, evaluating the impacts of risk\nassessments requires considering how public servants are influenced by risk\nassessments when making policy decisions rather than just how accurately these\nalgorithms make predictions. Through an online experiment with 2,140 lay\nparticipants simulating two high-stakes government contexts, we provide the\nfirst large-scale evidence that risk assessments can systematically alter\ndecision-making processes by increasing the salience of risk as a factor in\ndecisions and that these shifts could exacerbate racial disparities. These\nresults demonstrate that improving human prediction accuracy with algorithms\ndoes not necessarily improve human decisions and highlight the need to\nexperimentally test how government algorithms are used by human\ndecision-makers.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 23:44:45 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Green", "Ben", ""], ["Chen", "Yiling", ""]]}, {"id": "2012.05410", "submitter": "Elisa Bertino", "authors": "Elisa Bertino and Sujata Banerjee", "title": "Artificial Intelligence at the Edge", "comments": "A Computing Community Consortium (CCC) white paper, 4 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_3", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things (IoT) and edge computing applications aim to support a\nvariety of societal needs, including the global pandemic situation that the\nentire world is currently experiencing and responses to natural disasters.\n  The need for real-time interactive applications such as immersive video\nconferencing, augmented/virtual reality, and autonomous vehicles, in education,\nhealthcare, disaster recovery and other domains, has never been higher. At the\nsame time, there have been recent technological breakthroughs in highly\nrelevant fields such as artificial intelligence (AI)/machine learning (ML),\nadvanced communication systems (5G and beyond), privacy-preserving\ncomputations, and hardware accelerators. 5G mobile communication networks\nincrease communication capacity, reduce transmission latency and error, and\nsave energy -- capabilities that are essential for new applications. The\nenvisioned future 6G technology will integrate many more technologies,\nincluding for example visible light communication, to support groundbreaking\napplications, such as holographic communications and high precision\nmanufacturing. Many of these applications require computations and analytics\nclose to application end-points: that is, at the edge of the network, rather\nthan in a centralized cloud. AI techniques applied at the edge have tremendous\npotential both to power new applications and to need more efficient operation\nof edge infrastructure. However, it is critical to understand where to deploy\nAI systems within complex ecosystems consisting of advanced applications and\nthe specific real-time requirements towards AI systems.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 02:08:47 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Bertino", "Elisa", ""], ["Banerjee", "Sujata", ""]]}, {"id": "2012.05444", "submitter": "Shubhanshu Mishra", "authors": "Shubhanshu Mishra, Daniel Collier", "title": "A Framework for Generating Annotated Social Media Corpora with\n  Demographics, Stance, Civility, and Topicality", "comments": "Code at: https://github.com/socialmediaie/StudentDebtFbComments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we introduce a framework for annotating a social media text\ncorpora for various categories. Since, social media data is generated via\nindividuals, it is important to annotate the text for the individuals\ndemographic attributes to enable a socio-technical analysis of the corpora.\nFurthermore, when analyzing a large data-set we can often annotate a small\nsample of data and then train a prediction model using this sample to annotate\nthe full data for the relevant categories. We use a case study of a Facebook\ncomment corpora on student loan discussion which was annotated for gender,\nmilitary affiliation, age-group, political leaning, race, stance, topicalilty,\nneoliberlistic views and civility of the comment. We release three datasets of\nFacebook comments for further research at:\nhttps://github.com/socialmediaie/StudentDebtFbComments\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 04:06:25 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Mishra", "Shubhanshu", ""], ["Collier", "Daniel", ""]]}, {"id": "2012.05484", "submitter": "Yixuan Wang", "authors": "Ranjan Pal, Yixuan Wang, Swades De, Bodhibrata Nag, Pan Hui", "title": "Preference-Based Privacy Trading", "comments": "an extended and modified version of this report appears in IEEE\n  Access, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The question we raise through this paper is: Is it economically feasible to\ntrade consumer personal information with their formal consent (permission) and\nin return provide them incentives (monetary or otherwise)?. In view of (a) the\nbehavioral assumption that humans are `compromising' beings and have privacy\npreferences, (b) privacy as a good not having strict boundaries, and (c) the\npractical inevitability of inappropriate data leakage by data holders\ndownstream in the data-release supply-chain, we propose a design of regulated\nefficient/bounded inefficient economic mechanisms for oligopoly data trading\nmarkets using a novel preference function bidding approach on a simplified\nsellers-broker market. Our methodology preserves the heterogeneous privacy\npreservation constraints (at a grouped consumer, i.e., app, level) upto certain\ncompromise levels, and at the same time satisfies information demand (via the\nbroker) of agencies (e.g., advertising organizations) that collect client data\nfor the purpose of targeted behavioral advertising.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 07:03:10 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Pal", "Ranjan", ""], ["Wang", "Yixuan", ""], ["De", "Swades", ""], ["Nag", "Bodhibrata", ""], ["Hui", "Pan", ""]]}, {"id": "2012.05567", "submitter": "Brian Lim", "authors": "Wencan Zhang, Mariella Dimiccoli, Brian Y. Lim", "title": "Debiased-CAM for bias-agnostic faithful visual explanations of deep\n  convolutional networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class activation maps (CAMs) explain convolutional neural network predictions\nby identifying salient pixels, but they become misaligned and misleading when\nexplaining predictions on images under bias, such as images blurred\naccidentally or deliberately for privacy protection, or images with improper\nwhite balance. Despite model fine-tuning to improve prediction performance on\nthese biased images, we demonstrate that CAM explanations become more deviated\nand unfaithful with increased image bias. We present Debiased-CAM to recover\nexplanation faithfulness across various bias types and levels by training a\nmulti-input, multi-task model with auxiliary tasks for CAM and bias level\npredictions. With CAM as a prediction task, explanations are made tunable by\nretraining the main model layers and made faithful by self-supervised learning\nfrom CAMs of unbiased images. The model provides representative, bias-agnostic\nCAM explanations about the predictions on biased images as if generated from\ntheir unbiased form. In four simulation studies with different biases and\nprediction tasks, Debiased-CAM improved both CAM faithfulness and task\nperformance. We further conducted two controlled user studies to validate its\ntruthfulness and helpfulness, respectively. Quantitative and qualitative\nanalyses of participant responses confirmed Debiased-CAM as more truthful and\nhelpful. Debiased-CAM thus provides a basis to generate more faithful and\nrelevant explanations for a wide range of real-world applications with various\nsources of bias.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 10:28:47 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Zhang", "Wencan", ""], ["Dimiccoli", "Mariella", ""], ["Lim", "Brian Y.", ""]]}, {"id": "2012.05859", "submitter": "Piotr Sapiezynski", "authors": "NaLette Brodnax and Piotr Sapiezynski", "title": "Evolution of Digital Advertising Strategies during the 2020 US\n  Presidential Primary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Political advertising on digital platforms has grown dramatically in recent\nyears as campaigns embrace new ways of targeting supporters and potential\nvoters. Previous scholarship shows that digital advertising has both positive\neffects on democratic politics through increased voter knowledge and\nparticipation, and negative effects through user manipulation, opinion\necho-chambers, and diminished privacy. However, research on election campaign\nstrategies has focused primarily on traditional media, such as television.\nHere, we examine how political campaign dynamics have evolved in response to\nthe growth of digital media by analyzing the advertising strategies of US\npresidential election campaigns during the 2020 primary cycle. To identify\ngeographic and temporal trends, we employ regression analyses of campaign\nspending across nearly 600,000 advertisements published on Facebook. We show\nthat campaigns heavily target voters in candidates' home states during the\n\"invisible primary\" stage before shifting to states with early primaries.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 18:17:20 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Brodnax", "NaLette", ""], ["Sapiezynski", "Piotr", ""]]}, {"id": "2012.06034", "submitter": "Elisa Bertino", "authors": "Elisa Bertino, Finale Doshi-Velez, Maria Gini, Daniel Lopresti, and\n  David Parkes", "title": "Artificial Intelligence & Cooperation", "comments": "A Computing Community Consortium (CCC) white paper, 4 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_4", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rise of Artificial Intelligence (AI) will bring with it an\never-increasing willingness to cede decision-making to machines. But rather\nthan just giving machines the power to make decisions that affect us, we need\nways to work cooperatively with AI systems. There is a vital need for research\nin \"AI and Cooperation\" that seeks to understand the ways in which systems of\nAIs and systems of AIs with people can engender cooperative behavior. Trust in\nAI is also key: trust that is intrinsic and trust that can only be earned over\ntime. Here we use the term \"AI\" in its broadest sense, as employed by the\nrecent 20-Year Community Roadmap for AI Research (Gil and Selman, 2019),\nincluding but certainly not limited to, recent advances in deep learning.\n  With success, cooperation between humans and AIs can build society just as\nhuman-human cooperation has. Whether coming from an intrinsic willingness to be\nhelpful, or driven through self-interest, human societies have grown strong and\nthe human species has found success through cooperation. We cooperate \"in the\nsmall\" -- as family units, with neighbors, with co-workers, with strangers --\nand \"in the large\" as a global community that seeks cooperative outcomes around\nquestions of commerce, climate change, and disarmament. Cooperation has evolved\nin nature also, in cells and among animals. While many cases involving\ncooperation between humans and AIs will be asymmetric, with the human\nultimately in control, AI systems are growing so complex that, even today, it\nis impossible for the human to fully comprehend their reasoning,\nrecommendations, and actions when functioning simply as passive observers.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 23:54:31 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Bertino", "Elisa", ""], ["Doshi-Velez", "Finale", ""], ["Gini", "Maria", ""], ["Lopresti", "Daniel", ""], ["Parkes", "David", ""]]}, {"id": "2012.06049", "submitter": "Ian Foster", "authors": "Ian Foster, David Parkes, and Stephan Zheng", "title": "The Rise of AI-Driven Simulators: Building a New Crystal Ball", "comments": "A Computing Community Consortium (CCC) white paper, 4 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_6", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of computational simulation is by now so pervasive in society that it\nis no exaggeration to say that continued U.S. and international prosperity,\nsecurity, and health depend in part on continued improvements in simulation\ncapabilities. What if we could predict weather two weeks out, guide the design\nof new drugs for new viral diseases, or manage new manufacturing processes that\ncut production costs and times by an order of magnitude? What if we could\npredict collective human behavior, for example, response to an evacuation\nrequest during a natural disaster, or labor response to fiscal stimulus? (See\nalso the companion CCC Quad Paper on Pandemic Informatics, which discusses\nfeatures that would be essential to solving large-scale problems like\npreparation for, and response to, the inevitable next pandemic.)\n  The past decade has brought remarkable advances in complementary areas: in\nsensors, which can now capture enormous amounts of data about the world, and in\nAI methods capable of learning to extract predictive patterns from those data.\nThese advances may lead to a new era in computational simulation, in which\nsensors of many kinds are used to produce vast quantities of data, AI methods\nidentify patterns in those data, and new AI-driven simulators combine\nmachine-learned and mathematical rules to make accurate and actionable\npredictions. At the same time, there are new challenges -- computers in some\nimportant regards are no longer getting faster, and in some areas we are\nreaching the limits of mathematical understanding, or at least of our ability\nto translate mathematical understanding into efficient simulation. In this\npaper, we lay out some themes that we envision forming part of a cohesive,\nmulti-disciplinary, and application-inspired research agenda on AI-driven\nsimulators.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 00:13:40 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Foster", "Ian", ""], ["Parkes", "David", ""], ["Zheng", "Stephan", ""]]}, {"id": "2012.06057", "submitter": "Suresh Venkatasubramanian", "authors": "Suresh Venkatasubramanian, Nadya Bliss, Helen Nissenbaum, and Melanie\n  Moses", "title": "Interdisciplinary Approaches to Understanding Artificial Intelligence's\n  Impact on Society", "comments": "A Computing Community Consortium (CCC) white paper, 5 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_5", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Innovations in AI have focused primarily on the questions of \"what\" and\n\"how\"-algorithms for finding patterns in web searches, for instance-without\nadequate attention to the possible harms (such as privacy, bias, or\nmanipulation) and without adequate consideration of the societal context in\nwhich these systems operate. In part, this is driven by incentives and forces\nin the tech industry, where a more product-driven focus tends to drown out\nbroader reflective concerns about potential harms and misframings. But this\nfocus on what and how is largely a reflection of the engineering and\nmathematics-focused training in computer science, which emphasizes the building\nof tools and development of computational concepts.\n  As a result of this tight technical focus, and the rapid, worldwide explosion\nin its use, AI has come with a storm of unanticipated socio-technical problems,\nranging from algorithms that act in racially or gender-biased ways, get caught\nin feedback loops that perpetuate inequalities, or enable unprecedented\nbehavioral monitoring surveillance that challenges the fundamental values of\nfree, democratic societies.\n  Given that AI is no longer solely the domain of technologists but rather of\nsociety as a whole, we need tighter coupling of computer science and those\ndisciplines that study society and societal values.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 00:43:47 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Venkatasubramanian", "Suresh", ""], ["Bliss", "Nadya", ""], ["Nissenbaum", "Helen", ""], ["Moses", "Melanie", ""]]}, {"id": "2012.06058", "submitter": "Odest Chadwicke Jenkins", "authors": "Odest Chadwicke Jenkins, Daniel Lopresti, and Melanie Mitchell", "title": "Next Wave Artificial Intelligence: Robust, Explainable, Adaptable,\n  Ethical, and Accountable", "comments": "A Computing Community Consortium (CCC) white paper, 5 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_7", "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The history of AI has included several \"waves\" of ideas. The first wave, from\nthe mid-1950s to the 1980s, focused on logic and symbolic hand-encoded\nrepresentations of knowledge, the foundations of so-called \"expert systems\".\nThe second wave, starting in the 1990s, focused on statistics and machine\nlearning, in which, instead of hand-programming rules for behavior, programmers\nconstructed \"statistical learning algorithms\" that could be trained on large\ndatasets. In the most recent wave research in AI has largely focused on deep\n(i.e., many-layered) neural networks, which are loosely inspired by the brain\nand trained by \"deep learning\" methods. However, while deep neural networks\nhave led to many successes and new capabilities in computer vision, speech\nrecognition, language processing, game-playing, and robotics, their potential\nfor broad application remains limited by several factors.\n  A concerning limitation is that even the most successful of today's AI\nsystems suffer from brittleness-they can fail in unexpected ways when faced\nwith situations that differ sufficiently from ones they have been trained on.\nThis lack of robustness also appears in the vulnerability of AI systems to\nadversarial attacks, in which an adversary can subtly manipulate data in a way\nto guarantee a specific wrong answer or action from an AI system. AI systems\nalso can absorb biases-based on gender, race, or other factors-from their\ntraining data and further magnify these biases in their subsequent\ndecision-making. Taken together, these various limitations have prevented AI\nsystems such as automatic medical diagnosis or autonomous vehicles from being\nsufficiently trustworthy for wide deployment. The massive proliferation of AI\nacross society will require radically new ideas to yield technology that will\nnot sacrifice our productivity, our quality of life, or our values.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 00:50:09 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Jenkins", "Odest Chadwicke", ""], ["Lopresti", "Daniel", ""], ["Mitchell", "Melanie", ""]]}, {"id": "2012.06214", "submitter": "Shah Miah Prof", "authors": "Z. H. A Almtiri, S. J. Miah", "title": "Impact of Business technologies on the success of Ecommerce Strategies:\n  SMEs Perspective", "comments": null, "journal-ref": "IEEE CSD Confernece, December, 2020, Gold Coast, QLD, Australia", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The primary task of the study is to inspect the affiliation between the\nimplementation of technology and e-commerce success. It is imperative to study\nsuch an important relationship that directly impacts the rapid growth of\nInternet technology, new dimensions of e-services, and innovative measures that\nare necessary factors for electronic commerce operations. Despite most Saudi\nArabia retailers being aware of technological advancements, existing research\nreveals several challenges that hinder the adoption of e-commerce strategies,\nincluding the cost of installation and training. The advantages of e-commerce\nare frequently shown in recent studies. Internet technologies development has\nnarrowed the difference between traditional trade and online business grounds,\nwith additional traditional markets moving to online platforms. The Saudi\nArabia community has been recognized as a potential hub for advancing\ntechnology-based programs, particularly e-commerce.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 09:47:45 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Almtiri", "Z. H. A", ""], ["Miah", "S. J.", ""]]}, {"id": "2012.06466", "submitter": "Amee Trivedi", "authors": "Amee Trivedi, Deepak Vasisht", "title": "Digital Contact Tracing: Technologies, Shortcomings, and the Path\n  Forward", "comments": "7 pages", "journal-ref": "ACM SIGCOMM CCR (2020)", "doi": "10.1145/3431832.3431841", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the start of the COVID-19 pandemic, technology enthusiasts have pushed\nfor digital contact tracing as a critical tool for breaking the COVID-19\ntransmission chains. Motivated by this push, many countries and companies have\ncreated apps that enable digital contact tracing with the goal to identify the\nchain of transmission from an infected individual to others and enable early\nquarantine. Digital contact tracing applications like AarogyaSetu in India,\nTraceTogether in Singapore, SwissCovid in Switzerland, and others have been\ndownloaded hundreds of millions of times. Yet, this technology hasn't seen the\nimpact that we envisioned at the start of the pandemic. Some countries have\nrolled back their apps, while others have seen low adoption.\n  Therefore, it is prudent to ask what the technology landscape of\ncontact-tracing looks like and what are the missing pieces. We attempt to\nundertake this task in this paper. We present a high-level review of\ntechnologies underlying digital contact tracing, a set of metrics that are\nimportant while evaluating different contact tracing technologies, and evaluate\nwhere the different technologies stand today on this set of metrics. Our hope\nis two-fold: (a) Future designers of contact tracing applications can use this\nreview paper to understand the technology landscape, and (b) Researchers can\nidentify and solve the missing pieces of this puzzle so that we are ready to\nface the rest of the COVID-19 pandemic and any future pandemics. A majority of\nthis discussion is focused on the ability to identify contact between\nindividuals. The questions of ethics, privacy, and security of such contact\ntracing are briefly mentioned but not discussed in detail.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 16:36:34 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Trivedi", "Amee", ""], ["Vasisht", "Deepak", ""]]}, {"id": "2012.06502", "submitter": "Mohammad Mannan", "authors": "S. Ali, M. Elgharabawy, Q. Duchaussoy, M. Mannan, A. Youssef", "title": "Betrayed by the Guardian: Security and Privacy Risks of Parental Control\n  Solutions", "comments": null, "journal-ref": "Published at ACSAC 2020", "doi": "10.1145/3427228.3427287", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For parents of young children and adolescents, the digital age has introduced\nmany new challenges, including excessive screen time, inappropriate online\ncontent, cyber predators, and cyberbullying. To address these challenges, many\nparents rely on numerous parental control solutions on different platforms,\nincluding parental control network devices (e.g., WiFi routers) and software\napplications on mobile devices and laptops. While these parental control\nsolutions may help digital parenting, they may also introduce serious security\nand privacy risks to children and parents, due to their elevated privileges and\nhaving access to a significant amount of privacy-sensitive data. In this paper,\nwe present an experimental framework for systematically evaluating security and\nprivacy issues in parental control software and hardware solutions. Using the\ndeveloped framework, we provide the first comprehensive study of parental\ncontrol tools on multiple platforms including network devices, Windows\napplications, Chrome extensions and Android apps. Our analysis uncovers\npervasive security and privacy issues that can lead to leakage of private\ninformation, and/or allow an adversary to fully control the parental control\nsolution, and thereby may directly aid cyberbullying and cyber predators.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 17:06:00 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Ali", "S.", ""], ["Elgharabawy", "M.", ""], ["Duchaussoy", "Q.", ""], ["Mannan", "M.", ""], ["Youssef", "A.", ""]]}, {"id": "2012.07088", "submitter": "Ninghan Chen", "authors": "Ninghan Chen, Zhiqiang Zhong, Jun Pang", "title": "From #Jobsearch to #Mask: Improving COVID-19 Cascade Prediction with\n  Spillover Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the pandemic of social media panic spreads faster than the COVID-19\noutbreak, an urgent challenge arises: a prediction model needs to be developed\nto predict the future diffusion size of a piece of COVID-19 information at an\nearly stage of its emergence. In this paper, we focus on the cascade prediction\nof COVID-19 information with spillover effects. We build the first\nCOVID-19-related Twitter dataset of the Greater Region from the cascade\nperspective and explore the structure of the cascades. Moreover, the existence\nof spillover effects is verified in our data and spillover effects for\ninformation on COVID-19 symptoms, anti-contagion and treatment measures are\nfound to be from multiple topics of other information. Building on the above\nfindings, we design our SE-CGNN model (CoupledGNN with spillover effects) based\non CoupledGNN for cascade prediction. Experiments conducted on our dataset\ndemonstrate that our model outperforms the state-of-the-art methods for\nCOVID-19 information cascade prediction.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 16:12:28 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 16:06:51 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Chen", "Ninghan", ""], ["Zhong", "Zhiqiang", ""], ["Pang", "Jun", ""]]}, {"id": "2012.07449", "submitter": "Christopher Briggs", "authors": "Christopher Briggs, Zhong Fan, Peter Andras", "title": "Privacy Preserving Demand Forecasting to Encourage Consumer Acceptance\n  of Smart Energy Meters", "comments": "Accpeted at the Tackling Climate Change with Machine Learning\n  workshop at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this proposal paper we highlight the need for privacy preserving energy\ndemand forecasting to allay a major concern consumers have about smart meter\ninstallations. High resolution smart meter data can expose many private aspects\nof a consumer's household such as occupancy, habits and individual appliance\nusage. Yet smart metering infrastructure has the potential to vastly reduce\ncarbon emissions from the energy sector through improved operating\nefficiencies. We propose the application of a distributed machine learning\nsetting known as federated learning for energy demand forecasting at various\nscales to make load prediction possible whilst retaining the privacy of\nconsumers' raw energy consumption data.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:04:34 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Briggs", "Christopher", ""], ["Fan", "Zhong", ""], ["Andras", "Peter", ""]]}, {"id": "2012.07475", "submitter": "Mohammad Aliannejadi", "authors": "Matias Apa and Maria Cecilia Faini and Mohammad Aliannejadi and Maria\n  Soledad Pera", "title": "A Canine Census to Influence Public Policy", "comments": "Appeared in epiDAMIK Workshop in SIGKDD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential threat that domestic animals pose to the health of human\npopulations tends to be overlooked. We posit that positive steps forward can be\nmade in this area, via suitable state-wide public policy. In this paper, we\ndescribe the data collection process that took place in Casilda (a city in\nArgentina), in the context of a canine census. We outline preliminary findings\nemerging from the data, based on a number of perspectives, along with\nimplications of these findings in terms of informing public policy.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:48:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Apa", "Matias", ""], ["Faini", "Maria Cecilia", ""], ["Aliannejadi", "Mohammad", ""], ["Pera", "Maria Soledad", ""]]}, {"id": "2012.07716", "submitter": "Jack Bandy", "authors": "Jack Bandy, Nicholas Diakopoulos", "title": "#TulsaFlop: A Case Study of Algorithmically-Influenced Collective Action\n  on TikTok", "comments": "Presented at the FAccTRec Workshop on Responsible Recommendation (at\n  RecSys 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a re-election rally for the U.S. president drew smaller crowds than\nexpected in Tulsa, Oklahoma, many people attributed the low turnout to\ncollective action organized by TikTok users. Motivated by TikTok's surge in\npopularity and its growing sociopolitical implications, this work explores the\nrole of TikTok's recommender algorithm in amplifying call-to-action videos that\npromoted collective action against the Tulsa rally. We analyze call-to-action\nvideos from more than 600 TikTok users and compare the visibility (i.e. play\ncount) of these videos with other videos published by the same users. Evidence\nsuggests that Tulsa-related videos generally received more plays, and in some\ncases the amplification was dramatic. For example, one user's call-to-action\nvideo was played over 2 million times, but no other video by the user exceeded\n100,000 plays, and the user had fewer than 20,000 followers. Statistical\nmodeling suggests that the increased play count is explained by increased\nengagement rather than any systematic amplification of call-to-action videos.\nWe conclude by discussing the implications of recommender algorithms amplifying\nsociopolitical messages, and motivate several promising areas for future work.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 17:09:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Bandy", "Jack", ""], ["Diakopoulos", "Nicholas", ""]]}, {"id": "2012.07741", "submitter": "Elaine Nsoesie", "authors": "Adyasha Maharana, Morine Amutorine, Moinina David Sengeh, Elaine O.\n  Nsoesie", "title": "Use of Technology and Innovations in the COVID-19 Pandemic Response in\n  Africa", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of technology has been ubiquitous in efforts to combat the ongoing\npublic health crisis due to emergence and spread of the SARS-CoV-2 virus.\nAfrican countries have made tremendous use of technology to disseminate\ninformation, counter the spread of COVID-19, and develop cutting-edge\ntechniques to help with diagnosis, treatment and management of patients. The\nnature and outcomes of these efforts sometimes differ in Africa compared to\nother areas of the world due to its unique challenges and opportunities.\nSeveral countries have developed innovative technology-driven solutions to\ncater to a diverse population with varying access to technology. Much of the\nefforts are also earmarked by a flexible approach to problem solving, local\ntech entrepreneurship, and swift adoption of cutting-edge technology.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 18:59:13 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Maharana", "Adyasha", ""], ["Amutorine", "Morine", ""], ["Sengeh", "Moinina David", ""], ["Nsoesie", "Elaine O.", ""]]}, {"id": "2012.07742", "submitter": "Ashley O'Donoghue", "authors": "Steven Horng, Ashley O'Donoghue, Tenzin Dechen, Matthew Rabesa, Ayad\n  Shammout, Lawrence Markson, Venkat Jegadeesan, Manu Tandon, Jennifer P.\n  Stevens", "title": "Secondary Use of Employee COVID-19 Symptom Reporting as Syndromic\n  Surveillance as an Early Warning Signal of Future Hospitalizations", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Importance: Alternative methods for hospital utilization forecasting,\nessential information in hospital crisis planning, are necessary in a novel\npandemic when traditional data sources such as disease testing are limited.\nObjective: Determine whether mandatory daily employee symptom attestation data\ncan be used as syndromic surveillance to forecast COVID-19 hospitalizations in\nthe communities where employees live. Design: Retrospective cohort study.\nSetting: Large academic hospital network of 10 hospitals accounting for a total\nof 2,384 beds and 136,000 discharges in New England. Participants: 6,841\nemployees working on-site of Hospital 1 from April 2, 2020 to November 4, 2020,\nwho live in the 10 hospitals' service areas. Interventions: Mandatory, daily\nemployee self-reported symptoms were collected using an automated text\nmessaging system. Main Outcomes: Mean absolute error (MAE) and weighted mean\nabsolute percentage error (WMAPE) of 7 day forecasts of daily COVID-19 hospital\ncensus at each hospital. Results: 6,841 employees, with a mean age of 40.8 (SD\n= 13.6), 8.8 years of service (SD = 10.4), and 74.8% were female (n = 5,120),\nliving in the 10 hospitals' service areas. Our model has an MAE of 6.9 COVID-19\npatients and a WMAPE of 1.5% for hospitalizations for the entire hospital\nnetwork. The individual hospitals had an MAE that ranged from 0.9 to 4.5\npatients (WMAPE ranged from 2.1% to 16.1%). At Hospital 1, a doubling of the\nnumber of employees reporting symptoms (which corresponds to 4 additional\nemployees reporting symptoms at the mean for Hospital 1) is associated with a\n5% increase in COVID-19 hospitalizations at Hospital 1 in 7 days (95% CI:\n(0.02, 0.07)). Conclusions: We found that a real-time employee health\nattestation tool used at a single hospital could be used to predict subsequent\nhospitalizations in 7 days at hospitals throughout a larger hospital network in\nNew England.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 20:58:04 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Horng", "Steven", ""], ["O'Donoghue", "Ashley", ""], ["Dechen", "Tenzin", ""], ["Rabesa", "Matthew", ""], ["Shammout", "Ayad", ""], ["Markson", "Lawrence", ""], ["Jegadeesan", "Venkat", ""], ["Tandon", "Manu", ""], ["Stevens", "Jennifer P.", ""]]}, {"id": "2012.07743", "submitter": "Michael Fromm", "authors": "Michael Fromm, Evgeniy Faerman, Max Berrendorf, Siddharth Bhargava,\n  Ruoxia Qi, Yao Zhang, Lukas Dennert, Sophia Selle, Yang Mao, Thomas Seidl", "title": "Argument Mining Driven Analysis of Peer-Reviews", "comments": null, "journal-ref": null, "doi": "10.5281/zenodo.4314390", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Peer reviewing is a central process in modern research and essential for\nensuring high quality and reliability of published work. At the same time, it\nis a time-consuming process and increasing interest in emerging fields often\nresults in a high review workload, especially for senior researchers in this\narea. How to cope with this problem is an open question and it is vividly\ndiscussed across all major conferences. In this work, we propose an Argument\nMining based approach for the assistance of editors, meta-reviewers, and\nreviewers. We demonstrate that the decision process in the field of scientific\npublications is driven by arguments and automatic argument identification is\nhelpful in various use-cases. One of our findings is that arguments used in the\npeer-review process differ from arguments in other domains making the transfer\nof pre-trained models difficult. Therefore, we provide the community with a new\npeer-review dataset from different computer science conferences with annotated\narguments. In our extensive empirical evaluation, we show that Argument Mining\ncan be used to efficiently extract the most relevant parts from reviews, which\nare paramount for the publication decision. The process remains interpretable\nsince the extracted arguments can be highlighted in a review without detaching\nthem from their context.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 16:06:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Fromm", "Michael", ""], ["Faerman", "Evgeniy", ""], ["Berrendorf", "Max", ""], ["Bhargava", "Siddharth", ""], ["Qi", "Ruoxia", ""], ["Zhang", "Yao", ""], ["Dennert", "Lukas", ""], ["Selle", "Sophia", ""], ["Mao", "Yang", ""], ["Seidl", "Thomas", ""]]}, {"id": "2012.07744", "submitter": "Tetiana Vakaliuk", "authors": "Tetiana Vakaliuk, Dmitry Antoniuk, Andrii Morozov, Mariia Medvedieva,\n  and Mykhailo Medvediev", "title": "Green IT as a tool for design cloud-oriented sustainable learning\n  environment of a higher education institution", "comments": null, "journal-ref": "E3S Web of Conferences. Volume 166, 10013 (2020). The\n  International Conference on Sustainable Futures: Environmental,\n  Technological, Social and Economic Matters (ICSF 2020)", "doi": "10.1051/e3sconf/202016610013", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes the use of green IT as a tool for designing a\ncloud-oriented sustainable learning environment for a higher education\ninstitution. The article substantiates the expediency of designing such an\nenvironment as a prerequisite for the sustainable development of Ukraine. It is\nestablished that one of the goals of Ukraine's sustainable development for 2030\nis to provide fair quality education and to promote lifelong learning\nopportunities for all. Green IT is a set of approaches related to sustainable\ncomputing and information technology. The work of foreign scientists was\nanalyzed, which considered the issues of designing the learning environment\nusing green computing. As a result, Cloud LMS has been established that cloud\nLMS is a type of green IT and can serve as a tool for designing a\ncloud-oriented sustainable learning environment of a higher education\ninstitution. A model of a cloud-oriented sustainable learning environment of a\nhigher education institution using cloud LMS is proposed. The application of a\ncloud-oriented sustainable learning environment will provide such capabilities:\nkeep electronic journals; use on-line services; conduct correspondence,\nassessment of knowledge on-line; and more. And all of the above is the key to a\nsustainable development of the learning environment.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 14:25:01 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Vakaliuk", "Tetiana", ""], ["Antoniuk", "Dmitry", ""], ["Morozov", "Andrii", ""], ["Medvedieva", "Mariia", ""], ["Medvediev", "Mykhailo", ""]]}, {"id": "2012.07745", "submitter": "Konrad Kollnig", "authors": "Yury Kolotaev and Konrad Kollnig", "title": "Perceptions of YouTube's political influence", "comments": "Research report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  YouTube plays an ever more important role as a political medium. Yet, the\nimplications are to-date not well understood and difficult to analyse, since\naccess to YouTube's statistics is limited. To address this gap, we surveyed 124\npeople about their views and experiences around YouTube's political influence.\nOur results revealed diverse, sometimes conflicting views on YouTube's growing\npolitical role, and highlight the need for more research, discussion and\npossibly regulation.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 19:04:08 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Kolotaev", "Yury", ""], ["Kollnig", "Konrad", ""]]}, {"id": "2012.07746", "submitter": "Kayse Maass", "authors": "Malak El Khalkhali, Alex Bender, Geri L. Dimas, Kayse Lee Maass,\n  Renata Konrad, Jeffrey S. Blom, Joe Zhu, Andrew C. Trapp", "title": "Estimating Effectiveness of Identifying Human Trafficking via Data\n  Envelopment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transit monitoring is a preventative approach used to identify possible cases\nof human trafficking while an individual is in transit or before one crosses a\nborder. Transit monitoring is often conducted by non-governmental organizations\n(NGOs) who train staff to identify and intercept suspicious activity. Love\nJustice International (LJI) is one such NGO that has been conducting transit\nmonitoring for 14 years along the Nepal-India border at approximately 25-30\nmonitoring stations. In partnership with LJI, we developed a system that uses\ndata envelopment analysis (DEA) to help LJI decision-makers evaluate the\nperformance of these stations and make specific operational improvement\nrecommendations. We identified efficient stations, compared rankings of station\nperformance, and recommended strategies to improve efficiency. To the best of\nour knowledge, this is the first application of DEA in the anti-human\ntrafficking domain.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 17:06:50 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 14:08:55 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 13:59:00 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Khalkhali", "Malak El", ""], ["Bender", "Alex", ""], ["Dimas", "Geri L.", ""], ["Maass", "Kayse Lee", ""], ["Konrad", "Renata", ""], ["Blom", "Jeffrey S.", ""], ["Zhu", "Joe", ""], ["Trapp", "Andrew C.", ""]]}, {"id": "2012.07748", "submitter": "Zhihong Pang", "authors": "Zhihong Pang, Fan Feng, Zheng O'Neill", "title": "Investigation of the Impacts of COVID-19 on the Electricity Consumption\n  of a University Dormitory Using Weather Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigated the impacts of the COVID-19 pandemic on the\nelectricity consumption of a university dormitory building in the southern U.S.\nThe historical electricity consumption data of this university dormitory\nbuilding and weather data of an on-campus weather station, which were collected\nfrom January 1st, 2017 to July 31st, 2020, were used for analysis. Four inverse\ndata-driven prediction models, i.e., Artificial Neural Network, Long Short-Term\nMemory Recurrent Neural Network, eXtreme Gradient Boosting, and Light Gradient\nBoosting Machine, were exploited to account for the influence of the weather\nconditions. The results suggested that the total electricity consumption of the\nobjective building decreased by nearly 41% (about 276,000 kWh (942 MMBtu))\ncompared with the prediction value during the campus shutdown due to the\nCOVID-19. Besides, the daily load ratio (DLR) varied significantly as well. In\ngeneral, the DLR decreased gradually from 80% to nearly 40% in the second half\nof March 2020, maintained on a relatively stable level between 30% to 60% in\nApril, May, and June 2020, and then slowly recovered to 80% of the normal\ncapacity in July 2020.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 20:54:03 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Pang", "Zhihong", ""], ["Feng", "Fan", ""], ["O'Neill", "Zheng", ""]]}, {"id": "2012.07749", "submitter": "Elisa Ferracane", "authors": "Elisa Ferracane, Sandeep Konam", "title": "Towards Fairness in Classifying Medical Conversations into SOAP Sections", "comments": "To be presented at AAAI TAIH Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning algorithms are more widely deployed in healthcare, the\nquestion of algorithmic fairness becomes more critical to examine. Our work\nseeks to identify and understand disparities in a deployed model that\nclassifies doctor-patient conversations into sections of a medical SOAP note.\nWe employ several metrics to measure disparities in the classifier performance,\nand find small differences in a portion of the disadvantaged groups. A deeper\nanalysis of the language in these conversations and further stratifying the\ngroups suggests these differences are related to and often attributable to the\ntype of medical appointment (e.g., psychiatric vs. internist). Our findings\nstress the importance of understanding the disparities that may exist in the\ndata itself and how that affects a model's ability to equally distribute\nbenefits.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 14:55:22 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Ferracane", "Elisa", ""], ["Konam", "Sandeep", ""]]}, {"id": "2012.07750", "submitter": "Leon Abdillah", "authors": "Leon A. Abdillah", "title": "FinTech E-Commerce Payment Application User Experience Analysis during\n  COVID-19 Pandemic", "comments": "14 pages", "journal-ref": "Scientific Journal of Informatics (SJI), 7(2), 265-278 (2020)", "doi": "10.15294/sji.v7i2.26056", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of information technology in the era of big data and cloud\ncomputing has led to the trend of electronic payments through financial\ntechnology, or FinTech. One of the most popular FinTech applications in\nIndonesia is Go-Pay in the Gojek start-up application. This research will\nanalyze how the FinTech Go-Pay user experience both for transactions on Gojek\nand at merchants that collaborate with Gojek. User Experience (UX) is analyzed\nusing the User Experience Questionnaire which consists of 6 (six) variables\n(Attractiveness, Perspicuity, Efficiency, Dependability, Stimulation, and\nNovelty). Total data collected amounted to 258. After analyzing the calculation\nresults, the mean scores are obtained in the following order: Efficiency,\nPerspicuity, Stimulation, Attractiveness, Dependability, and Novelty. Then when\ncompared with benchmark data the following sequence is obtained: Efficiency,\nPerspicuity, Stimulation, Attractiveness, Dependability, and Novelty. Overall\nthe Go-Pay service is efficient and perspicuity, but the Go-Pay service needs\nto improve its novelty. This article provides additional knowledge or novelty\ncontributions, especially for user experience analysis using FinTech\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 03:03:16 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Abdillah", "Leon A.", ""]]}, {"id": "2012.07751", "submitter": "James Walsh", "authors": "James Walsh, Oluwafunmilola Kesa, Andrew Wang, Mihai Ilas, Patrick\n  O'Hara, Oscar Giles, Neil Dhir, Theodoros Damoulas", "title": "Near Real-Time Social Distancing in London", "comments": "Added appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 pandemic, policy makers at the Greater London Authority,\nthe regional governance body of London, UK, are reliant upon prompt and\naccurate data sources. Large well-defined heterogeneous compositions of\nactivity throughout the city are sometimes difficult to acquire, yet are a\nnecessity in order to learn 'busyness' and consequently make safe policy\ndecisions. One component of our project within this space is to utilise\nexisting infrastructure to estimate social distancing adherence by the general\npublic. Our method enables near immediate sampling and contextualisation of\nactivity and physical distancing on the streets of London via live traffic\ncamera feeds. We introduce a framework for inspecting and improving upon\nexisting methods, whilst also describing its active deployment on over 900\nreal-time feeds.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 22:49:38 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 22:12:55 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Walsh", "James", ""], ["Kesa", "Oluwafunmilola", ""], ["Wang", "Andrew", ""], ["Ilas", "Mihai", ""], ["O'Hara", "Patrick", ""], ["Giles", "Oscar", ""], ["Dhir", "Neil", ""], ["Damoulas", "Theodoros", ""]]}, {"id": "2012.08347", "submitter": "Andrew Trask", "authors": "Andrew Trask and Emma Bluemke and Ben Garfinkel and Claudia Ghezzou\n  Cuervas-Mons and Allan Dafoe", "title": "Beyond Privacy Trade-offs with Structured Transparency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many socially valuable activities depend on sensitive information, such as\nmedical research, public health policies, political coordination, and\npersonalized digital services. This is often posed as an inherent privacy\ntrade-off: we can benefit from data analysis or retain data privacy, but not\nboth. Across several disciplines, a vast amount of effort has been directed\ntoward overcoming this trade-off to enable productive uses of information\nwithout also enabling undesired misuse, a goal we term `structured\ntransparency'. In this paper, we provide an overview of the frontier of\nresearch seeking to develop structured transparency. We offer a general\ntheoretical framework and vocabulary, including characterizing the fundamental\ncomponents -- input privacy, output privacy, input verification, output\nverification, and flow governance -- and fundamental problems of copying,\nbundling, and recursive oversight. We argue that these barriers are less\nfundamental than they often appear. Recent progress in developing\n`privacy-enhancing technologies' (PETs), such as secure computation and\nfederated learning, may substantially reduce lingering use-misuse trade-offs in\na number of domains. We conclude with several illustrations of structured\ntransparency -- in open research, energy management, and credit scoring systems\n-- and a discussion of the risks of misuse of these tools.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 15:03:25 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Trask", "Andrew", ""], ["Bluemke", "Emma", ""], ["Garfinkel", "Ben", ""], ["Cuervas-Mons", "Claudia Ghezzou", ""], ["Dafoe", "Allan", ""]]}, {"id": "2012.08571", "submitter": "Sujata Banerjee", "authors": "Sujata Banerjee, Yiling Chen, Kobbi Nissim, David Parkes, Katie Siek,\n  and Lauren Wilcox", "title": "Modernizing Data Control: Making Personal Digital Data Mutually\n  Beneficial for Citizens and Industry", "comments": "A Computing Community Consortium (CCC) white paper, 6 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_9", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are entering a new \"data everywhere-anytime\" era that pivots us from being\ntracked online to continuous tracking as we move through our everyday lives. We\nhave smart devices in our homes, on our bodies, and around our communities that\ncollect data that is used to guide decisions that have a major impact on our\nlives - from loans to job interviews and judicial rulings to health care\ninterventions. We create a lot of data, but who owns that data? How is it\nshared? How will it be used? While the average person does not have a good\nunderstanding of how the data is being used, they know that it carries risks\nfor them and society.\n  Although some people may believe they own their data, in reality, the problem\nof understanding the myriad ways in which data is collected, shared, and used,\nand the consequences of these uses is so complex that only a few people want to\nmanage their data themselves. Furthermore, much of the value in the data cannot\nbe extracted by individuals alone, as it lies in the connections and insights\ngarnered from (1) one's own personal data (is your fitness improving? Is your\nhome more energy efficient than the average home of this size?) and (2) one's\nrelationship with larger groups (demographic group voting blocks; friend\nnetwork influence on purchasing). But sometimes these insights have unintended\nconsequences for the person generating the data, especially in terms of loss of\nprivacy, unfairness, inappropriate inferences, information bias, manipulation,\nand discrimination. There are also societal impacts, such as effects on speech\nfreedoms, political manipulation, and amplified harms to weakened and\nunderrepresented communities. To this end, we look at major questions that\npolicymakers should ask and things to consider when addressing these data\nownership concerns.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:32:12 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Banerjee", "Sujata", ""], ["Chen", "Yiling", ""], ["Nissim", "Kobbi", ""], ["Parkes", "David", ""], ["Siek", "Katie", ""], ["Wilcox", "Lauren", ""]]}, {"id": "2012.08572", "submitter": "Nadya Bliss", "authors": "Nadya Bliss, Elizabeth Bradley, Joshua Garland, Filippo Menczer, Scott\n  W. Ruston, Kate Starbird, and Chris Wiggins", "title": "An Agenda for Disinformation Research", "comments": "A Computing Community Consortium (CCC) white paper, 5 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_8", "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the 21st Century information environment, adversarial actors use\ndisinformation to manipulate public opinion. The distribution of false,\nmisleading, or inaccurate information with the intent to deceive is an\nexistential threat to the United States--distortion of information erodes trust\nin the socio-political institutions that are the fundamental fabric of\ndemocracy: legitimate news sources, scientists, experts, and even fellow\ncitizens. As a result, it becomes difficult for society to come together within\na shared reality; the common ground needed to function effectively as an\neconomy and a nation. Computing and communication technologies have facilitated\nthe exchange of information at unprecedented speeds and scales. This has had\ncountless benefits to society and the economy, but it has also played a\nfundamental role in the rising volume, variety, and velocity of disinformation.\nTechnological advances have created new opportunities for manipulation,\ninfluence, and deceit. They have effectively lowered the barriers to reaching\nlarge audiences, diminishing the role of traditional mass media along with the\neditorial oversight they provided. The digitization of information exchange,\nhowever, also makes the practices of disinformation detectable, the networks of\ninfluence discernable, and suspicious content characterizable. New tools and\napproaches must be developed to leverage these affordances to understand and\naddress this growing challenge.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 19:32:36 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Bliss", "Nadya", ""], ["Bradley", "Elizabeth", ""], ["Garland", "Joshua", ""], ["Menczer", "Filippo", ""], ["Ruston", "Scott W.", ""], ["Starbird", "Kate", ""], ["Wiggins", "Chris", ""]]}, {"id": "2012.08678", "submitter": "Peter Washington", "authors": "Peter Washington, Haik Kalantarian, Jack Kent, Arman Husic, Aaron\n  Kline, Emilie Leblanc, Cathy Hou, Cezmi Mutlu, Kaitlyn Dunlap, Yordan Penev,\n  Maya Varma, Nate Stockham, Brianna Chrisman, Kelley Paskov, Min Woo Sun,\n  Jae-Yoon Jung, Catalin Voss, Nick Haber, Dennis P. Wall", "title": "Training an Emotion Detection Classifier using Frames from a Mobile\n  Therapeutic Game for Children with Developmental Disorders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Automated emotion classification could aid those who struggle to recognize\nemotion, including children with developmental behavioral conditions such as\nautism. However, most computer vision emotion models are trained on adult\naffect and therefore underperform on child faces. In this study, we designed a\nstrategy to gamify the collection and the labeling of child affect data in an\neffort to boost the performance of automatic child emotion detection to a level\ncloser to what will be needed for translational digital healthcare. We\nleveraged our therapeutic smartphone game, GuessWhat, which was designed in\nlarge part for children with developmental and behavioral conditions, to gamify\nthe secure collection of video data of children expressing a variety of\nemotions prompted by the game. Through a secure web interface gamifying the\nhuman labeling effort, we gathered and labeled 2,155 videos, 39,968 emotion\nframes, and 106,001 labels on all images. With this drastically expanded\npediatric emotion centric database (>30x larger than existing public pediatric\naffect datasets), we trained a pediatric emotion classification convolutional\nneural network (CNN) classifier of happy, sad, surprised, fearful, angry,\ndisgust, and neutral expressions in children. The classifier achieved 66.9%\nbalanced accuracy and 67.4% F1-score on the entirety of CAFE as well as 79.1%\nbalanced accuracy and 78.0% F1-score on CAFE Subset A, a subset containing at\nleast 60% human agreement on emotions labels. This performance is at least 10%\nhigher than all previously published classifiers, the best of which reached\n56.% balanced accuracy even when combining \"anger\" and \"disgust\" into a single\nclass. This work validates that mobile games designed for pediatric therapies\ncan generate high volumes of domain-relevant datasets to train state of the art\nclassifiers to perform tasks highly relevant to precision health efforts.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 00:08:51 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Washington", "Peter", ""], ["Kalantarian", "Haik", ""], ["Kent", "Jack", ""], ["Husic", "Arman", ""], ["Kline", "Aaron", ""], ["Leblanc", "Emilie", ""], ["Hou", "Cathy", ""], ["Mutlu", "Cezmi", ""], ["Dunlap", "Kaitlyn", ""], ["Penev", "Yordan", ""], ["Varma", "Maya", ""], ["Stockham", "Nate", ""], ["Chrisman", "Brianna", ""], ["Paskov", "Kelley", ""], ["Sun", "Min Woo", ""], ["Jung", "Jae-Yoon", ""], ["Voss", "Catalin", ""], ["Haber", "Nick", ""], ["Wall", "Dennis P.", ""]]}, {"id": "2012.08726", "submitter": "Ning Yu", "authors": "Ning Yu, Vladislav Skripniuk, Dingfan Chen, Larry Davis, Mario Fritz", "title": "Responsible Disclosure of Generative Models Using Scalable\n  Fingerprinting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.CY cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past six years, deep generative models have achieved a qualitatively\nnew level of performance. Generated data has become difficult, if not\nimpossible, to be distinguished from real data. While there are plenty of use\ncases that benefit from this technology, there are also strong concerns on how\nthis new technology can be misused to spoof sensors, generate deep fakes, and\nenable misinformation at scale. Unfortunately, current deep fake detection\nmethods are not sustainable, as the gap between real and fake continues to\nclose. In contrast, our work enables a responsible disclosure of such\nstate-of-the-art generative models, that allows researchers and companies to\nfingerprint their models, so that the generated samples containing a\nfingerprint can be accurately detected and attributed to a source. Our\ntechnique achieves this by an efficient and scalable ad-hoc generation of a\nlarge population of models with distinct fingerprints. Our recommended\noperation point uses a 128-bit fingerprint which in principle results in more\nthan $10^{36}$ identifiable models. Experiments show that our method fulfills\nkey properties of a fingerprinting mechanism and achieves effectiveness in deep\nfake detection and attribution.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 03:51:54 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 04:19:56 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 08:17:25 GMT"}, {"version": "v4", "created": "Tue, 30 Mar 2021 23:51:15 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Yu", "Ning", ""], ["Skripniuk", "Vladislav", ""], ["Chen", "Dingfan", ""], ["Davis", "Larry", ""], ["Fritz", "Mario", ""]]}, {"id": "2012.08895", "submitter": "Harry Nguyen", "authors": "Duc-Trong Le, Xuan-Son Vu, Nhu-Dung To, Huu-Quang Nguyen, Thuy-Trinh\n  Nguyen, Linh Le, Anh-Tuan Nguyen, Minh-Duc Hoang, Nghia Le, Huyen Nguyen and\n  Hoang D. Nguyen", "title": "ReINTEL: A Multimodal Data Challenge for Responsible Information\n  Identification on Social Network Sites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper reports on the ReINTEL Shared Task for Responsible Information\nIdentification on social network sites, which is hosted at the seventh annual\nworkshop on Vietnamese Language and Speech Processing (VLSP 2020). Given a\npiece of news with respective textual, visual content and metadata,\nparticipants are required to classify whether the news is `reliable' or\n`unreliable'. In order to generate a fair benchmark, we introduce a novel\nhuman-annotated dataset of over 10,000 news collected from a social network in\nVietnam. All models will be evaluated in terms of AUC-ROC score, a typical\nevaluation metric for classification. The competition was run on the Codalab\nplatform. Within two months, the challenge has attracted over 60 participants\nand recorded nearly 1,000 submission entries.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 12:17:08 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Le", "Duc-Trong", ""], ["Vu", "Xuan-Son", ""], ["To", "Nhu-Dung", ""], ["Nguyen", "Huu-Quang", ""], ["Nguyen", "Thuy-Trinh", ""], ["Le", "Linh", ""], ["Nguyen", "Anh-Tuan", ""], ["Hoang", "Minh-Duc", ""], ["Le", "Nghia", ""], ["Nguyen", "Huyen", ""], ["Nguyen", "Hoang D.", ""]]}, {"id": "2012.08968", "submitter": "Nicholas Stedmon BA(Hons)", "authors": "Nicholas Stedmon", "title": "The Impact of Cyber Security Threats on the 2020 US Elections", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper will investigate the literature surrounding cyber security threats\nin the 2020 US Elections. It begins with a brief overview of cyber security and\nthe current state of cyber security regarding elections. In the main body of\nthe paper, the focus will be on the literature review of three main areas:\nvoter suppression, voter fraud, and disinformation, considering their impacts\non the outcome of the election and on the voting public. Having evaluated\nsources on each this paper concludes by summarising the areas which have had\nthe greatest impact on the 2020 US elections.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 14:06:32 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Stedmon", "Nicholas", ""]]}, {"id": "2012.09015", "submitter": "Nuno Fachada", "authors": "Nuno Fachada", "title": "ColorShapeLinks: A board game AI competition for educators and students", "comments": "The peer-reviewed version of this paper is published in Computers and\n  Education: Artificial Intelligence at\n  https://doi.org/10.1016/j.caeai.2021.100014. This version is typeset by the\n  author and differs only in pagination and typographical detail", "journal-ref": "Computers and Education: Artificial Intelligence, 2, 100014, 2021", "doi": "10.1016/j.caeai.2021.100014", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ColorShapeLinks is an AI board game competition framework specially designed\nfor students and educators in videogame development, with openness and\naccessibility in mind. The competition is based on an arbitrarily-sized version\nof the Simplexity board game, the motto of which, \"simple to learn, complex to\nmaster\", is curiously also applicable to AI agents. ColorShapeLinks offers\ngraphical and text-based frontends and a completely open and documented\ndevelopment framework built using industry standard tools and following\nsoftware engineering best practices. ColorShapeLinks is not only a competition,\nbut both a game and a framework which educators and students can extend and use\nto host their own competitions. It has been successfully used for running\ninternal competitions in AI classes, as well as for hosting an international AI\ncompetition at the IEEE Conference on Games.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 15:21:29 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 18:05:20 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Fachada", "Nuno", ""]]}, {"id": "2012.09056", "submitter": "Vince Straub", "authors": "Vince J. Straub", "title": "Beyond kinetic harm and towards a dynamic conceptualization of\n  cyberterrorism", "comments": "Under review; 25 pages + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  After more than two decades of discussion, the concept of cyberterrorism\nremains plagued by confusion. This article presents the result of an\nintegrative review which maps the development of the term and situates the\nepistemic communities that have shaped the debate. After critically assessing\nexisting accounts and highlighting the key ethical, social, and legal\ndimensions at stake in preventing cyberterrorist attacks, it calls for a more\ndynamic conceptualization that views cyberterrorism as more abstract, difficult\nto predict, and hard to isolate; and which embraces a different conception of\nsufficient harm. In concluding it proposes a novel definition of\ncyberterrorism, intended to catalyse a new research programme, and sketches a\nroadmap for further research.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 16:23:11 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Straub", "Vince J.", ""]]}, {"id": "2012.09108", "submitter": "Paolo Notaro", "authors": "Paolo Notaro, Jorge Cardoso, and Michael Gerndt", "title": "A Systematic Mapping Study in AIOps", "comments": null, "journal-ref": "International Workshop on Artificial Intelligence for IT\n  Operations (AIOPS) 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  IT systems of today are becoming larger and more complex, rendering their\nhuman supervision more difficult. Artificial Intelligence for IT Operations\n(AIOps) has been proposed to tackle modern IT administration challenges thanks\nto AI and Big Data. However, past AIOps contributions are scattered,\nunorganized and missing a common terminology convention, which renders their\ndiscovery and comparison impractical. In this work, we conduct an in-depth\nmapping study to collect and organize the numerous scattered contributions to\nAIOps in a unique reference index. We create an AIOps taxonomy to build a\nfoundation for future contributions and allow an efficient comparison of AIOps\npapers treating similar problems. We investigate temporal trends and classify\nAIOps contributions based on the choice of algorithms, data sources and the\ntarget components. Our results show a recent and growing interest towards\nAIOps, specifically to those contributions treating failure-related tasks\n(62%), such as anomaly detection and root cause analysis.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 09:05:20 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Notaro", "Paolo", ""], ["Cardoso", "Jorge", ""], ["Gerndt", "Michael", ""]]}, {"id": "2012.09109", "submitter": "Andreas L Opdahl", "authors": "Andreas L Opdahl and Vimala Nunavath", "title": "Big Data", "comments": "Opdahl, A. L., and Nunavath, V. (2020). Big Data. Big Data in\n  Emergency Management: Exploitation Techniques for Social and Mobile Data,\n  15-29", "journal-ref": null, "doi": "10.1007/978-3-030-48099-8", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things, crowdsourcing, social media, public authorities, and\nother sources generate bigger and bigger data sets. Big and open data offers\nmany benefits for emergency management, but also pose new challenges. This\nchapter will review the sources of big data and their characteristics. We then\ndiscuss potential benefits of big data for emergency management along with the\ntechnological and societal challenges it poses. We review central technologies\nfor big-data storage and processing in general, before presenting the Spark\nbig-data engine in more detail. Finally, we review ethical and societal threats\nthat big data pose.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 16:18:52 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Opdahl", "Andreas L", ""], ["Nunavath", "Vimala", ""]]}, {"id": "2012.09110", "submitter": "Kashif Ahmad", "authors": "Kashif Ahmad, Majdi Maabreh, Mohamed Ghaly, Khalil Khan, Junaid Qadir,\n  Ala Al-Fuqaha", "title": "Developing Future Human-Centered Smart Cities: Critical Analysis of\n  Smart City Security, Interpretability, and Ethical Challenges", "comments": "I withdraw this paper, as I uploaded it by mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As we make tremendous advances in machine learning and artificial\nintelligence technosciences, there is a renewed understanding in the AI\ncommunity that we must ensure that humans being are at the center of our\ndeliberations so that we don't end in technology-induced dystopias. As strongly\nargued by Green in his book Smart Enough City, the incorporation of technology\nin city environs does not automatically translate into prosperity, wellbeing,\nurban livability, or social justice. There is a great need to deliberate on the\nfuture of the cities worth living and designing. There are philosophical and\nethical questions involved along with various challenges that relate to the\nsecurity, safety, and interpretability of AI algorithms that will form the\ntechnological bedrock of future cities. Several research institutes on human\ncentered AI have been established at top international universities. Globally\nthere are calls for technology to be made more humane and human-compatible. For\nexample, Stuart Russell has a book called Human Compatible AI. The Center for\nHumane Technology advocates for regulators and technology companies to avoid\nbusiness models and product features that contribute to social problems such as\nextremism, polarization, misinformation, and Internet addiction. In this paper,\nwe analyze and explore key challenges including security, robustness,\ninterpretability, and ethical challenges to a successful deployment of AI or ML\nin human-centric applications, with a particular emphasis on the convergence of\nthese challenges. We provide a detailed review of existing literature on these\nkey challenges and analyze how one of these challenges may lead to others or\nhelp in solving other challenges. The paper also advises on the current\nlimitations, pitfalls, and future directions of research in these domains, and\nhow it can fill the current gaps and lead to better solutions.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 18:54:05 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 17:19:22 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 12:57:19 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Ahmad", "Kashif", ""], ["Maabreh", "Majdi", ""], ["Ghaly", "Mohamed", ""], ["Khan", "Khalil", ""], ["Qadir", "Junaid", ""], ["Al-Fuqaha", "Ala", ""]]}, {"id": "2012.09131", "submitter": "Amir M. Rahmani", "authors": "Amir M. Rahmani, Jocelyn Lai, Salar Jafarlou, Asal Yunusova, Alex. P.\n  Rivera, Sina Labbaf, Sirui Hu, Arman Anzanpour, Nikil Dutt, Ramesh Jain,\n  Jessica L. Borelli", "title": "Personal Mental Health Navigator: Harnessing the Power of Data, Personal\n  Models, and Health Cybernetics to Promote Psychological Well-being", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.CY cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, the regime of mental healthcare has followed an episodic\npsychotherapy model wherein patients seek care from a provider through a\nprescribed treatment plan developed over multiple provider visits. Recent\nadvances in wearable and mobile technology have generated increased interest in\ndigital mental healthcare that enables individuals to address episodic mental\nhealth symptoms. However, these efforts are typically reactive and\nsymptom-focused and do not provide comprehensive, wrap-around, customized\ntreatments that capture an individual's holistic mental health model as it\nunfolds over time. Recognizing that each individual is unique, we present the\nnotion of Personalized Mental Health Navigation (MHN): a therapist-in-the-loop,\ncybernetic goal-based system that deploys a continuous cyclic loop of\nmeasurement, estimation, guidance, to steer the individual's mental health\nstate towards a healthy zone. We outline the major components of MHN that is\npremised on the development of an individual's personal mental health state,\nholistically represented by a high-dimensional cover of multiple knowledge\nlayers such as emotion, biological patterns, sociology, behavior, and\ncognition. We demonstrate the feasibility of the personalized MHN approach via\na 12-month pilot case study for holistic stress management in college students\nand highlight an instance of a therapist-in-the-loop intervention using MHN for\nmonitoring, estimating, and proactively addressing moderately severe depression\nover a sustained period of time. We believe MHN paves the way to transform\nmental healthcare from the current passive, episodic, reactive process (where\nindividuals seek help to address symptoms that have already manifested) to a\ncontinuous and navigational paradigm that leverages a personalized model of the\nindividual, promising to deliver timely interventions to individuals in a\nholistic manner.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 18:34:09 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Rahmani", "Amir M.", ""], ["Lai", "Jocelyn", ""], ["Jafarlou", "Salar", ""], ["Yunusova", "Asal", ""], ["Rivera", "Alex. P.", ""], ["Labbaf", "Sina", ""], ["Hu", "Sirui", ""], ["Anzanpour", "Arman", ""], ["Dutt", "Nikil", ""], ["Jain", "Ramesh", ""], ["Borelli", "Jessica L.", ""]]}, {"id": "2012.09232", "submitter": "Jesslyn Alekseyev", "authors": "Jesslyn Alekseyev (1), Erica Dixon (2), Vilhelm L Andersen Woltz (3),\n  Danny Weitzner (3) ((1) Massachusetts Institute of Technology Lincoln\n  Laboratory, (2) University of Pennsylvania, (3) Massachusetts Institute of\n  Technology)", "title": "Realizing the Promise of Automated Exposure Notification (AEN)\n  Technology to Control the Spread of COVID-19: Recommendations for Smartphone\n  App Deployment, Use, and Iterative Assessment", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using modern cryptographic techniques, privacy-preserving Automated\nExposure Notification (AEN) technologies offer the promise of mitigating\ndisease spread by automatically recording contacts between people over the\nincubation period while maintaining individual data privacy. Today, public\nhealth departments in States and other countries around the world are deploying\nAEN systems at a rapid pace. Though many organizations conducted research prior\nto deploying apps, experience around the world shows that contact-tracing apps\nare installed and used at relatively low levels. This whitepaper is intended to\nprovide usable information for States who are considering the deployment of an\nAEN system, as well as to guide ongoing improvements for States that have\nalready deployed. We outline the human factors considerations related to\nemploying AEN systems with the ultimate goal of controlling the spread of\nCOVID-19, including the GAEN consortium Exposure Notifications (EN) Express\ntool. We will also provide a practical design and implementation guide for\nStates and others designing and deploying AEN systems, as well as a set of\nrecommendations for assessing deployment of contact tracing apps and targeting\nareas of concern to improve efficacy of use during and after initial\ndeployment. As a case study, we consider the commercial app deployed by the\nstate of Pennsylvania (PA) and the ongoing efforts to drive user adoption\nthere.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 19:56:02 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 21:59:14 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Alekseyev", "Jesslyn", ""], ["Dixon", "Erica", ""], ["Woltz", "Vilhelm L Andersen", ""], ["Weitzner", "Danny", ""]]}, {"id": "2012.09300", "submitter": "Elizabeth Bradley", "authors": "Elizabeth Bradley, Madhav Marathe, Melanie Moses, William D Gropp, and\n  Daniel Lopresti", "title": "Pandemic Informatics: Preparation, Robustness, and Resilience; Vaccine\n  Distribution, Logistics, and Prioritization; and Variants of Concern", "comments": "A Computing Community Consortium (CCC) white paper, 8 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_10", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Infectious diseases cause more than 13 million deaths a year, worldwide.\nGlobalization, urbanization, climate change, and ecological pressures have\nsignificantly increased the risk of a global pandemic. The ongoing COVID-19\npandemic-the first since the H1N1 outbreak more than a decade ago and the worst\nsince the 1918 influenza pandemic-illustrates these matters vividly. More than\n47M confirmed infections and 1M deaths have been reported worldwide as of\nNovember 4, 2020 and the global markets have lost trillions of dollars. The\npandemic will continue to have significant disruptive impacts upon the United\nStates and the world for years; its secondary and tertiary impacts might be\nfelt for more than a decade. An effective strategy to reduce the national and\nglobal burden of pandemics must: 1) detect timing and location of occurrence,\ntaking into account the many interdependent driving factors; 2) anticipate\npublic reaction to an outbreak, including panic behaviors that obstruct\nresponders and spread contagion; 3) and develop actionable policies that enable\ntargeted and effective responses.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 22:33:29 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 16:38:05 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 17:34:35 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Bradley", "Elizabeth", ""], ["Marathe", "Madhav", ""], ["Moses", "Melanie", ""], ["Gropp", "William D", ""], ["Lopresti", "Daniel", ""]]}, {"id": "2012.09303", "submitter": "William D. Gropp", "authors": "William Gropp, Sujata Banerjee, and Ian Foster", "title": "Infrastructure for Artificial Intelligence, Quantum and High Performance\n  Computing", "comments": "A Computing Community Consortium (CCC) white paper, 3 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_11", "categories": "cs.CY cs.AI cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High Performance Computing (HPC), Artificial Intelligence (AI)/Machine\nLearning (ML), and Quantum Computing (QC) and communications offer immense\nopportunities for innovation and impact on society. Researchers in these areas\ndepend on access to computing infrastructure, but these resources are in short\nsupply and are typically siloed in support of their research communities,\nmaking it more difficult to pursue convergent and interdisciplinary research.\nSuch research increasingly depends on complex workflows that require different\nresources for each stage. This paper argues that a more-holistic approach to\ncomputing infrastructure, one that recognizes both the convergence of some\ncapabilities and the complementary capabilities from new computing approaches,\nbe it commercial cloud to Quantum Computing, is needed to support computer\nscience research.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 22:41:24 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Gropp", "William", ""], ["Banerjee", "Sujata", ""], ["Foster", "Ian", ""]]}, {"id": "2012.09309", "submitter": "Holly Yanco", "authors": "Henrik Christensen, Maria Gini, Odest Chadwicke Jenkins, and Holly\n  Yanco", "title": "Robotics Enabling the Workforce", "comments": "A Computing Community Consortium (CCC) white paper, 4 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_12", "categories": "cs.RO cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robotics has the potential to magnify the skilled workforce of the nation by\ncomplementing our workforce with automation: teams of people and robots will be\nable to do more than either could alone. The economic engine of the U.S. runs\non the productivity of our people. The rise of automation offers new\nopportunities to enhance the work of our citizens and drive the innovation and\nprosperity of our industries. Most critically, we need research to understand\nhow future robot technologies can best complement our workforce to get the best\nof both human and automated labor in a collaborative team. Investments made in\nrobotics research and workforce development will lead to increased GDP, an\nincreased export-import ratio, a growing middle class of skilled workers, and a\nU.S.-based supply chain that can withstand global pandemics and other\ndisruptions. In order to make the United States a leader in robotics, we need\nto invest in basic research, technology development, K-16 education, and\nlifelong learning.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 23:05:10 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Christensen", "Henrik", ""], ["Gini", "Maria", ""], ["Jenkins", "Odest Chadwicke", ""], ["Yanco", "Holly", ""]]}, {"id": "2012.09332", "submitter": "Tunazzina Islam", "authors": "Tunazzina Islam, Dan Goldwasser", "title": "Do You Do Yoga? Understanding Twitter Users' Types and Motivations using\n  Social and Textual Information", "comments": "accepted at 2021 IEEE 15th International Conference on Semantic\n  Computing (ICSC), 4 pages. Minor changes for camera-ready version. arXiv\n  admin note: text overlap with arXiv:2012.02939", "journal-ref": null, "doi": "10.1109/ICSC50631.2021.00067", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging social media data to understand people's lifestyle choices is an\nexciting domain to explore but requires a multiview formulation of the data. In\nthis paper, we propose a joint embedding model based on the fusion of neural\nnetworks with attention mechanism by incorporating social and textual\ninformation of users to understand their activities and motivations. We use\nwell-being related tweets from Twitter, focusing on 'Yoga'. We demonstrate our\nmodel on two downstream tasks: (i) finding user type such as either\npractitioner or promotional (promoting yoga studio/gym), other; (ii) finding\nuser motivation i.e. health benefit, spirituality, love to tweet/retweet about\nyoga but do not practice yoga.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 00:15:13 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 05:20:56 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 15:50:42 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Islam", "Tunazzina", ""], ["Goldwasser", "Dan", ""]]}, {"id": "2012.09353", "submitter": "Kaicheng Yang", "authors": "Kai-Cheng Yang, Francesco Pierri, Pik-Mai Hui, David Axelrod,\n  Christopher Torres-Lugo, John Bryden, Filippo Menczer", "title": "The COVID-19 Infodemic: Twitter versus Facebook", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The global spread of the novel coronavirus is affected by the spread of\nrelated misinformation -- the so-called COVID-19 Infodemic -- that makes\npopulations more vulnerable to the disease through resistance to mitigation\nefforts. Here we analyze the prevalence and diffusion of links to\nlow-credibility content about the pandemic across two major social media\nplatforms, Twitter and Facebook. We characterize cross-platform similarities\nand differences in popular sources, diffusion patterns, influencers,\ncoordination, and automation. Comparing the two platforms, we find divergence\namong the prevalence of popular low-credibility sources and suspicious videos.\nA minority of accounts and pages exert a strong influence on each platform.\nThese misinformation \"superspreaders\" are often associated with the\nlow-credibility sources and tend to be verified by the platforms. On both\nplatforms, there is evidence of coordinated sharing of Infodemic content. The\novert nature of this manipulation points to the need for societal-level\nsolutions in addition to mitigation strategies within the platforms. However,\nwe highlight limits imposed by inconsistent data-access policies on our\ncapability to study harmful manipulations of information ecosystems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 02:00:43 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 00:22:38 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Yang", "Kai-Cheng", ""], ["Pierri", "Francesco", ""], ["Hui", "Pik-Mai", ""], ["Axelrod", "David", ""], ["Torres-Lugo", "Christopher", ""], ["Bryden", "John", ""], ["Menczer", "Filippo", ""]]}, {"id": "2012.09375", "submitter": "Xiang Cheng", "authors": "Xiang Cheng, Hanchao Yang, Archanaa S Krishnan, Patrick Schaumont and\n  Yaling Yang", "title": "KHOVID: Interoperable Privacy Preserving Digital Contact Tracing", "comments": "14 pages, 7 figures. Submitted to a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During a pandemic, contact tracing is an essential tool to drive down the\ninfection rate within a population. To accelerate the laborious manual contact\ntracing process, digital contact tracing (DCT) tools can track contact events\ntransparently and privately by using the sensing and signaling capabilities of\nthe ubiquitous cell phone. However, an effective DCT must not only preserve\nuser privacy but also augment the existing manual contact tracing process.\nIndeed, not every member of a population may own a cell phone or have a DCT app\ninstalled and enabled. We present KHOVID to fulfill the combined goal of manual\ncontact-tracing interoperability and DCT user privacy. At KHOVID's core is a\nprivacy-friendly mechanism to encode user trajectories using geolocation data.\nManual contact tracing data can be integrated through the same geolocation\nformat. The accuracy of the geolocation data from DCT is improved using\nBluetooth proximity detection, and we propose a novel method to encode\nBluetooth ephemeral IDs. This contribution describes the detailed design of\nKHOVID; presents a prototype implementation including an app and server\nsoftware; and presents a validation based on simulation and field experiments.\nWe also compare the strengths of KHOVID with other, earlier proposals of DCT.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 03:00:53 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Cheng", "Xiang", ""], ["Yang", "Hanchao", ""], ["Krishnan", "Archanaa S", ""], ["Schaumont", "Patrick", ""], ["Yang", "Yaling", ""]]}, {"id": "2012.09433", "submitter": "Ashish Kapoor", "authors": "Ashish Kapoor", "title": "Helping Reduce Environmental Impact of Aviation with Machine Learning", "comments": "Appeared in NeurIPS 2019 Workshop Tackling Climate Change with\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Commercial aviation is one of the biggest contributors towards climate\nchange. We propose to reduce environmental impact of aviation by considering\nsolutions that would reduce the flight time. Specifically, we first consider\nimproving winds aloft forecast so that flight planners could use better\ninformation to find routes that are efficient. Secondly, we propose an aircraft\nrouting method that seeks to find the fastest route to the destination by\nconsidering uncertainty in the wind forecasts and then optimally trading-off\nbetween exploration and exploitation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 08:04:22 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Kapoor", "Ashish", ""]]}, {"id": "2012.09520", "submitter": "Fabrizio Cicala", "authors": "Fabrizio Cicala, Weicheng Wang, Tianhao Wang, Ninghui Li, Elisa\n  Bertino, Faming Liang, Yang Yang", "title": "PURE: A Framework for Analyzing Proximity-based Contact Tracing\n  Protocols", "comments": "35 pages, 10 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many proximity-based tracing (PCT) protocols have been proposed and deployed\nto combat the spreading of COVID-19. In this paper, we take a systematic\napproach to analyze PCT protocols. We identify a list of desired properties of\na contact tracing design from the four aspects of Privacy, Utility, Resiliency,\nand Efficiency (PURE). We also identify two main design choices for PCT\nprotocols: what information patients report to the server, and which party\nperforms the matching. These two choices determine most of the PURE properties\nand enable us to conduct a comprehensive analysis and comparison of the\nexisting protocols.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 11:34:53 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Cicala", "Fabrizio", ""], ["Wang", "Weicheng", ""], ["Wang", "Tianhao", ""], ["Li", "Ninghui", ""], ["Bertino", "Elisa", ""], ["Liang", "Faming", ""], ["Yang", "Yang", ""]]}, {"id": "2012.09590", "submitter": "Daniel Graziotin", "authors": "Marvin Wyrich, Andreas Preikschat, Daniel Graziotin, Stefan Wagner", "title": "The Mind Is a Powerful Place: How Showing Code Comprehensibility Metrics\n  Influences Code Understanding", "comments": "To appear in: Proceedings of the 43rd International Conference on\n  Software Engineering (ICSE '21), Madrid, Spain, 12 pages. 12 pages, 1 figure.\n  Postprint, after peer review", "journal-ref": "2021 IEEE/ACM 43rd International Conference on Software\n  Engineering (ICSE), 2021 pp. 512-523", "doi": "10.1109/ICSE43902.2021.00055", "report-no": null, "categories": "cs.SE cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static code analysis tools and integrated development environments present\ndevelopers with quality-related software metrics, some of which describe the\nunderstandability of source code. Software metrics influence overarching\nstrategic decisions that impact the future of companies and the prioritization\nof everyday software development tasks. Several software metrics, however, lack\nin validation: we just choose to trust that they reflect what they are supposed\nto measure. Some of them were even shown to not measure the quality aspects\nthey intend to measure. Yet, they influence us through biases in our\ncognitive-driven actions. In particular, they might anchor us in our decisions.\nWhether the anchoring effect exists with software metrics has not been studied\nyet. We conducted a randomized and double-blind experiment to investigate the\nextent to which a displayed metric value for source code comprehensibility\nanchors developers in their subjective rating of source code comprehensibility,\nwhether performance is affected by the anchoring effect when working on\ncomprehension tasks, and which individual characteristics might play a role in\nthe anchoring effect. We found that the displayed value of a comprehensibility\nmetric has a significant and large anchoring effect on a developer's code\ncomprehensibility rating. The effect does not seem to affect the time or\ncorrectness when working on comprehension questions related to the code\nsnippets under study. Since the anchoring effect is one of the most robust\ncognitive biases, and we have limited understanding of the consequences of the\ndemonstrated manipulation of developers by non-validated metrics, we call for\nan increased awareness of the responsibility in code quality reporting and for\ncorresponding tools to be based on scientific evidence.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 14:27:45 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 12:52:32 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wyrich", "Marvin", ""], ["Preikschat", "Andreas", ""], ["Graziotin", "Daniel", ""], ["Wagner", "Stefan", ""]]}, {"id": "2012.09995", "submitter": "Nicholas Vincent", "authors": "Nicholas Vincent, Hanlin Li, Nicole Tilly, Stevie Chancellor, Brent\n  Hecht", "title": "Data Leverage: A Framework for Empowering the Public in its Relationship\n  with Technology Companies", "comments": "This is a preprint. The paper will be presented at the 2021\n  Conference on Fairness, Accountability, and Transparency (FAccT 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many powerful computing technologies rely on implicit and explicit data\ncontributions from the public. This dependency suggests a potential source of\nleverage for the public in its relationship with technology companies: by\nreducing, stopping, redirecting, or otherwise manipulating data contributions,\nthe public can reduce the effectiveness of many lucrative technologies. In this\npaper, we synthesize emerging research that seeks to better understand and help\npeople action this \\textit{data leverage}. Drawing on prior work in areas\nincluding machine learning, human-computer interaction, and fairness and\naccountability in computing, we present a framework for understanding data\nleverage that highlights new opportunities to change technology company\nbehavior related to privacy, economic inequality, content moderation and other\nareas of societal concern. Our framework also points towards ways that\npolicymakers can bolster data leverage as a means of changing the balance of\npower between the public and tech companies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 00:46:26 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 18:25:31 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Vincent", "Nicholas", ""], ["Li", "Hanlin", ""], ["Tilly", "Nicole", ""], ["Chancellor", "Stevie", ""], ["Hecht", "Brent", ""]]}, {"id": "2012.10076", "submitter": "Kieran Browne", "authors": "Kieran Browne, Ben Swift", "title": "Semantics and explanation: why counterfactual explanations produce\n  adversarial examples in deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers in explainable AI have made a compelling case for\ncounterfactual modes of explanation. While counterfactual explanations appear\nto be extremely effective in some instances, they are formally equivalent to\nadversarial examples. This presents an apparent paradox for explainability\nresearchers: if these two procedures are formally equivalent, what accounts for\nthe explanatory divide apparent between counterfactual explanations and\nadversarial examples? We resolve this paradox by placing emphasis back on the\nsemantics of counterfactual expressions. Producing satisfactory explanations\nfor deep learning systems will require that we find ways to interpret the\nsemantics of hidden layer representations in deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 07:04:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Browne", "Kieran", ""], ["Swift", "Ben", ""]]}, {"id": "2012.10301", "submitter": "Masha Medvedeva", "authors": "Masha Medvedeva, Martijn Wieling and Michel Vols", "title": "The Danger of Reverse-Engineering of Automated Judicial Decision-Making\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we discuss the implications of using machine learning for\njudicial decision-making in situations where human rights may be infringed. We\nargue that the use of such tools in these situations should be limited due to\ninherent status quo bias and dangers of reverse-engineering. We discuss that\nthese issues already exist in the judicial systems without using machine\nlearning tools, but how introducing them might exacerbate them.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 15:33:24 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Medvedeva", "Masha", ""], ["Wieling", "Martijn", ""], ["Vols", "Michel", ""]]}, {"id": "2012.10311", "submitter": "Tahereh Arabghalizi", "authors": "Tahereh Arabghalizi, Alexandros Labrinidis", "title": "Multi-characteristic Subject Selection from Biased Datasets", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Subject selection plays a critical role in experimental studies, especially\nones with human subjects. Anecdotal evidence suggests that many such studies,\ndone at or near university campus settings suffer from selection bias, i.e.,\nthe too-many-college-kids-as-subjects problem. Unfortunately, traditional\nsampling techniques, when applied over biased data, will typically return\nbiased results. In this paper, we tackle the problem of multi-characteristic\nsubject selection from biased datasets. We present a constrained\noptimization-based method that finds the best possible sampling fractions for\nthe different population subgroups, based on the desired sampling fractions\nprovided by the researcher running the subject selection.We perform an\nextensive experimental study, using a variety of real datasets. Our results\nshow that our proposed method outperforms the baselines for all problem\nvariations by up to 90%.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 15:55:27 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Arabghalizi", "Tahereh", ""], ["Labrinidis", "Alexandros", ""]]}, {"id": "2012.10378", "submitter": "Manoel Horta Ribeiro", "authors": "Manoel Horta Ribeiro, Robert West", "title": "YouNiverse: Large-Scale Channel and Video Metadata from English-Speaking\n  YouTube", "comments": "Data: https://zenodo.org/record/4650046 GitRepo:\n  https://github.com/epfl-dlab/YouNiverse. This paper has been accepted at the\n  15th International Conference on Web and Social Media (ICWSM), please cite\n  accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  YouTube plays a key role in entertaining and informing people around the\nglobe. However, studying the platform is difficult due to the lack of randomly\nsampled data and of systematic ways to query the platform's colossal catalog.\nIn this paper, we present YouNiverse, a large collection of channel and video\nmetadata from English-language YouTube. YouNiverse comprises metadata from over\n136k channels and 72.9M videos published between May 2005 and October 2019, as\nwell as channel-level time-series data with weekly subscriber and view counts.\nLeveraging channel ranks from socialblade.com, an online service that provides\ninformation about YouTube, we are able to assess and enhance the\nrepresentativeness of the sample of channels. Additionally, the dataset also\ncontains a table specifying which videos a set of 449M anonymous users\ncommented on. YouNiverse, publicly available at\nhttps://doi.org/10.5281/zenodo.4650046, will empower the community to do\nresearch with and about YouTube.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 17:46:47 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 14:23:39 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Ribeiro", "Manoel Horta", ""], ["West", "Robert", ""]]}, {"id": "2012.10431", "submitter": "Elias Gr\\\"unewald", "authors": "Elias Gr\\\"unewald and Frank Pallas", "title": "TILT: A GDPR-Aligned Transparency Information Language and Toolkit for\n  Practical Privacy Engineering", "comments": "Accepted for publication at the ACM Conference on Fairness,\n  Accountability, and Transparency 2021 (ACM FAccT'21). This is a preprint\n  manuscript (authors' own version before final copy-editing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.FL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present TILT, a transparency information language and\ntoolkit explicitly designed to represent and process transparency information\nin line with the requirements of the GDPR and allowing for a more automated and\nadaptive use of such information than established, legalese data protection\npolicies do.\n  We provide a detailed analysis of transparency obligations from the GDPR to\nidentify the expressiveness required for a formal transparency language\nintended to meet respective legal requirements. In addition, we identify a set\nof further, non-functional requirements that need to be met to foster practical\nadoption in real-world (web) information systems engineering. On this basis, we\nspecify our formal language and present a respective, fully implemented toolkit\naround it. We then evaluate the practical applicability of our language and\ntoolkit and demonstrate the additional prospects it unlocks through two\ndifferent use cases: a) the inter-organizational analysis of personal\ndata-related practices allowing, for instance, to uncover data sharing networks\nbased on explicitly announced transparency information and b) the presentation\nof formally represented transparency information to users through novel, more\ncomprehensible, and potentially adaptive user interfaces, heightening data\nsubjects' actual informedness about data-related practices and, thus, their\nsovereignty.\n  Altogether, our transparency information language and toolkit allow -\ndifferently from previous work - to express transparency information in line\nwith actual legal requirements and practices of modern (web) information\nsystems engineering and thereby pave the way for a multitude of novel\npossibilities to heighten transparency and user sovereignty in practice.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 18:45:04 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Gr\u00fcnewald", "Elias", ""], ["Pallas", "Frank", ""]]}, {"id": "2012.10710", "submitter": "Mehul Bhatt", "authors": "Vasiliki Kondyli and Mehul Bhatt and Evgenia Spyridonos", "title": "Visuo-Locomotive Complexity as a Component of Parametric Systems for\n  Architecture Design", "comments": "This is a preprint of the contribution published as part of the\n  proceedings of ICoRD 2021: 8th International Conference on Research into\n  Design, IDC School of Design (IIT Mumbai, India). ICoRD 2021,\n  www.idc.iitb.ac.in/icord2021/ - The overall scientific agenda driving this\n  research may be consulted here: The DesignSpace Group / www.design-space.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A people-centred approach for designing large-scale built-up spaces\nnecessitates systematic anticipation of user's embodied visuo-locomotive\nexperience from the viewpoint of human-environment interaction factors\npertaining to aspects such as navigation, wayfinding, usability. In this\ncontext, we develop a behaviour-based visuo-locomotive complexity model that\nfunctions as a key correlate of cognitive performance vis-a-vis internal\nnavigation in built-up spaces. We also demonstrate the model's implementation\nand application as a parametric tool for the identification and manipulation of\nthe architectural morphology along a navigation path as per the parameters of\nthe proposed visuospatial complexity model. We present examples based on an\nempirical study in two healthcare buildings, and showcase the manner in which a\ndynamic and interactive parametric (complexity) model can promote\nbehaviour-based decision-making throughout the design process to maintain\ndesired levels of visuospatial complexity as part of a navigation or wayfinding\nexperience.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 15:11:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Kondyli", "Vasiliki", ""], ["Bhatt", "Mehul", ""], ["Spyridonos", "Evgenia", ""]]}, {"id": "2012.10790", "submitter": "Gordon Burtch", "authors": "Mochen Yang, Edward McFowland III, Gordon Burtch and Gediminas\n  Adomavicius", "title": "Achieving Reliable Causal Inference with Data-Mined Variables: A Random\n  Forest Approach to the Measurement Error Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Combining machine learning with econometric analysis is becoming increasingly\nprevalent in both research and practice. A common empirical strategy involves\nthe application of predictive modeling techniques to 'mine' variables of\ninterest from available data, followed by the inclusion of those variables into\nan econometric framework, with the objective of estimating causal effects.\nRecent work highlights that, because the predictions from machine learning\nmodels are inevitably imperfect, econometric analyses based on the predicted\nvariables are likely to suffer from bias due to measurement error. We propose a\nnovel approach to mitigate these biases, leveraging the ensemble learning\ntechnique known as the random forest. We propose employing random forest not\njust for prediction, but also for generating instrumental variables to address\nthe measurement error embedded in the prediction. The random forest algorithm\nperforms best when comprised of a set of trees that are individually accurate\nin their predictions, yet which also make 'different' mistakes, i.e., have\nweakly correlated prediction errors. A key observation is that these properties\nare closely related to the relevance and exclusion requirements of valid\ninstrumental variables. We design a data-driven procedure to select tuples of\nindividual trees from a random forest, in which one tree serves as the\nendogenous covariate and the other trees serve as its instruments. Simulation\nexperiments demonstrate the efficacy of the proposed approach in mitigating\nestimation biases and its superior performance over three alternative methods\nfor bias correction.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 21:48:23 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yang", "Mochen", ""], ["McFowland", "Edward", "III"], ["Burtch", "Gordon", ""], ["Adomavicius", "Gediminas", ""]]}, {"id": "2012.10866", "submitter": "Liu Wang", "authors": "Huiyi Wang, Liu Wang, Haoyu Wang", "title": "Market-level Analysis of Government-backed COVID-19 Contact Tracing Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To help curb the spread of the COVID-19 pandemic, governments and public\nhealth authorities around the world have launched a number of contact-tracing\napps. Although contact tracing apps have received extensive attentions from the\nresearch community, no existing work has characterized the users' adoption of\ncontact tracing apps from the app market level. In this work, we perform the\nfirst market-level analysis of contact tracing apps. We perform a longitudinal\nempirical study (over 4 months) of eight government-backed COVID-19 contact\ntracing apps in iOS app store. We first collect all the daily meta information\n(e.g., app updates, app rating, app comments, etc.) of these contact tracing\napps from their launch to 2020-07-31. Then we characterize them from release\npractice, app popularity, and mobile users' feedback. Our study reveals various\nissues related to contact tracing apps from the users' perspective, hoping to\nhelp improve the quality of contact tracing apps and thus achieving a high\nlevel of adoption in the population.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 08:43:03 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Wang", "Huiyi", ""], ["Wang", "Liu", ""], ["Wang", "Haoyu", ""]]}, {"id": "2012.10912", "submitter": "Carolin Wienrich Prof. Dr.", "authors": "Carolin Wienrich, Nina Ines D\\\"ollinger and Rebecca Hein", "title": "Mind the Gap: A Framework (BehaveFIT) Guiding The Use of Immersive\n  Technologies in Behavior Change Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The design and evaluation of assisting technologies to support behavior\nchange processes have become an essential topic within the field of\nhuman-computer interaction research in general and the field of immersive\nintervention technologies in particular. The mechanisms and success of behavior\nchange techniques and interventions are broadly investigated in the field of\npsychology. However, it is not always easy to adapt these psychological\nfindings to the context of immersive technologies. The lack of theoretical\nfoundation also leads to a lack of explanation as to why and how immersive\ninterventions support behavior change processes. The Behavioral Framework for\nimmersive Technologies (BehaveFIT) addresses this lack by (1) presenting an\nintelligible categorization and condensation of psychological barriers and\nimmersive features, by (2) suggesting a mapping that shows why and how\nimmersive technologies can help to overcome barriers, and finally by (3)\nproposing a generic prediction path that enables a structured, theory-based\napproach to the development and evaluation of immersive interventions. These\nthree steps explain how BehaveFIT can be used, and include guiding questions\nand one example for each step. Thus, the present paper contributes to guidance\nfor immersive intervention design and evaluation, showing that immersive\ninterventions support behavior change processes and explain and predict 'why'\nand 'how' immersive interventions can bridge the intention-behavior-gap.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 12:48:01 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Wienrich", "Carolin", ""], ["D\u00f6llinger", "Nina Ines", ""], ["Hein", "Rebecca", ""]]}, {"id": "2012.11004", "submitter": "Wilson Ceron", "authors": "Wilson Ceron, Mathias-Felipe de-Lima-Santos and Marcos G. Quiles", "title": "Fake news agenda in the era of COVID-19: Identifying trends through\n  fact-checking content", "comments": null, "journal-ref": "Online Social Networks and Media, 2020", "doi": "10.1016/j.osnem.2020.100116", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The rise of social media has ignited an unprecedented circulation of false\ninformation in our society. It is even more evident in times of crises, such as\nthe COVID-19 pandemic. Fact-checking efforts have expanded greatly and have\nbeen touted as among the most promising solutions to fake news, especially in\ntimes like these. Several studies have reported the development of\nfact-checking organizations in Western societies, albeit little attention has\nbeen given to the Global South. Here, to fill this gap, we introduce a novel\nMarkov-inspired computational method for identifying topics in tweets. In\ncontrast to other topic modeling approaches, our method clusters topics and\ntheir current evolution in a predefined time window. Through these, we\ncollected data from Twitter accounts of two Brazilian fact-checking outlets and\npresented the topics debunked by these initiatives in fortnights throughout the\npandemic. By comparing these organizations, we could identify similarities and\ndifferences in what was shared by them. Our method resulted in an important\ntechnique to cluster topics in a wide range of scenarios, including an\ninfodemic -- a period overabundance of the same information. In particular, the\ndata clearly revealed a complex intertwining between politics and the health\ncrisis during this period. We conclude by proposing a generic model which, in\nour opinion, is suitable for topic modeling and an agenda for future research.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 19:35:25 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ceron", "Wilson", ""], ["de-Lima-Santos", "Mathias-Felipe", ""], ["Quiles", "Marcos G.", ""]]}, {"id": "2012.11055", "submitter": "Christine Geeng", "authors": "Christine Geeng, Tiona Francisco, Jevin West, Franziska Roesner", "title": "Social Media COVID-19 Misinformation Interventions Viewed Positively,\n  But Have Limited Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Amidst COVID-19 misinformation spreading, social media platforms like\nFacebook and Twitter rolled out design interventions, including banners linking\nto authoritative resources and more specific \"false information\" labels. In\nlate March 2020, shortly after these interventions began to appear, we\nconducted an exploratory mixed-methods survey (N = 311) to learn: what are\nsocial media users' attitudes towards these interventions, and to what extent\ndo they self-report effectiveness? We found that most participants indicated a\npositive attitude towards interventions, particularly post-specific labels for\nmisinformation. Still, the majority of participants discovered or corrected\nmisinformation through other means, most commonly web searches, suggesting room\nfor platforms to do more to stem the spread of COVID-19 misinformation.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 00:02:04 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Geeng", "Christine", ""], ["Francisco", "Tiona", ""], ["West", "Jevin", ""], ["Roesner", "Franziska", ""]]}, {"id": "2012.11066", "submitter": "Angela Zhou", "authors": "Nathan Kallus, Angela Zhou", "title": "Fairness, Welfare, and Equity in Personalized Pricing", "comments": "Accepted at FAccT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the interplay of fairness, welfare, and equity considerations in\npersonalized pricing based on customer features. Sellers are increasingly able\nto conduct price personalization based on predictive modeling of demand\nconditional on covariates: setting customized interest rates, targeted\ndiscounts of consumer goods, and personalized subsidies of scarce resources\nwith positive externalities like vaccines and bed nets. These different\napplication areas may lead to different concerns around fairness, welfare, and\nequity on different objectives: price burdens on consumers, price envy, firm\nrevenue, access to a good, equal access, and distributional consequences when\nthe good in question further impacts downstream outcomes of interest. We\nconduct a comprehensive literature review in order to disentangle these\ndifferent normative considerations and propose a taxonomy of different\nobjectives with mathematical definitions. We focus on observational metrics\nthat do not assume access to an underlying valuation distribution which is\neither unobserved due to binary feedback or ill-defined due to overriding\nbehavioral concerns regarding interpreting revealed preferences. In the setting\nof personalized pricing for the provision of goods with positive benefits, we\ndiscuss how price optimization may provide unambiguous benefit by achieving a\n\"triple bottom line\": personalized pricing enables expanding access, which in\nturn may lead to gains in welfare due to heterogeneous utility, and improve\nrevenue or budget utilization. We empirically demonstrate the potential\nbenefits of personalized pricing in two settings: pricing subsidies for an\nelective vaccine, and the effects of personalized interest rates on downstream\noutcomes in microcredit.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 01:01:56 GMT"}, {"version": "v2", "created": "Sun, 27 Dec 2020 17:21:29 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Kallus", "Nathan", ""], ["Zhou", "Angela", ""]]}, {"id": "2012.11646", "submitter": "Marianne Menictas", "authors": "Marianne Menictas and Sabina Tomkins and Susan Murphy", "title": "Fast Physical Activity Suggestions: Efficient Hyperparameter Learning in\n  Mobile Health", "comments": "Neurips 2020 workshop: Machine Learning in Mobile Health. arXiv admin\n  note: substantial text overlap with arXiv:2003.12881", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Users can be supported to adopt healthy behaviors, such as regular physical\nactivity, via relevant and timely suggestions on their mobile devices.\nRecently, reinforcement learning algorithms have been found to be effective for\nlearning the optimal context under which to provide suggestions. However, these\nalgorithms are not necessarily designed for the constraints posed by mobile\nhealth (mHealth) settings, that they be efficient, domain-informed and\ncomputationally affordable. We propose an algorithm for providing physical\nactivity suggestions in mHealth settings. Using domain-science, we formulate a\ncontextual bandit algorithm which makes use of a linear mixed effects model. We\nthen introduce a procedure to efficiently perform hyper-parameter updating,\nusing far less computational resources than competing approaches. Not only is\nour approach computationally efficient, it is also easily implemented with\nclosed form matrix algebraic updates and we show improvements over state of the\nart approaches both in speed and accuracy of up to 99% and 56% respectively.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 19:17:31 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Menictas", "Marianne", ""], ["Tomkins", "Sabina", ""], ["Murphy", "Susan", ""]]}, {"id": "2012.11690", "submitter": "Luiz Giovanini", "authors": "Mirela Silva, Luiz Giovanini, Juliana Fernandes, Daniela Oliveira,\n  Catia S. Silva", "title": "Facebook Ad Engagement in the Russian Active Measures Campaign of 2016", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines 3,517 Facebook ads created by Russia's Internet Research\nAgency (IRA) between June 2015 and August 2017 in its active measures\ndisinformation campaign targeting the 2016 U.S. general election. We aimed to\nunearth the relationship between ad engagement (as measured by ad clicks) and\n41 features related to ads' metadata, sociolinguistic structures, and\nsentiment. Our analysis was three-fold: (i) understand the relationship between\nengagement and features via correlation analysis; (ii) find the most relevant\nfeature subsets to predict engagement via feature selection; and (iii) find the\nsemantic topics that best characterize the dataset via topic modeling. We found\nthat ad expenditure, text size, ad lifetime, and sentiment were the top\nfeatures predicting users' engagement to the ads. Additionally, positive\nsentiment ads were more engaging than negative ads, and sociolinguistic\nfeatures (e.g., use of religion-relevant words) were identified as highly\nimportant in the makeup of an engaging ad. Linear SVM and Logistic Regression\nclassifiers achieved the highest mean F-scores (93.6% for both models),\ndetermining that the optimal feature subset contains 12 and 6 features,\nrespectively. Finally, we corroborate the findings of related works that the\nIRA specifically targeted Americans on divisive ad topics (e.g., LGBT rights,\nAfrican American reparations).\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 21:30:58 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 15:03:21 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Silva", "Mirela", ""], ["Giovanini", "Luiz", ""], ["Fernandes", "Juliana", ""], ["Oliveira", "Daniela", ""], ["Silva", "Catia S.", ""]]}, {"id": "2012.11705", "submitter": "John Hooker", "authors": "Tae Wan Kim, John Hooker, Thomas Donaldson", "title": "Taking Principles Seriously: A Hybrid Approach to Value Alignment", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.05447", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  An important step in the development of value alignment (VA) systems in AI is\nunderstanding how VA can reflect valid ethical principles. We propose that\ndesigners of VA systems incorporate ethics by utilizing a hybrid approach in\nwhich both ethical reasoning and empirical observation play a role. This, we\nargue, avoids committing the \"naturalistic fallacy,\" which is an attempt to\nderive \"ought\" from \"is,\" and it provides a more adequate form of ethical\nreasoning when the fallacy is not committed. Using quantified model logic, we\nprecisely formulate principles derived from deontological ethics and show how\nthey imply particular \"test propositions\" for any given action plan in an AI\nrule base. The action plan is ethical only if the test proposition is\nempirically true, a judgment that is made on the basis of empirical VA. This\npermits empirical VA to integrate seamlessly with independently justified\nethical principles.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 22:05:07 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Kim", "Tae Wan", ""], ["Hooker", "John", ""], ["Donaldson", "Thomas", ""]]}, {"id": "2012.11746", "submitter": "Teruaki Hayashi", "authors": "Teruaki Hayashi and Hiroki Sakaji and Hiroyasu Matsushima and Yoshiaki\n  Fukami and Takumi Shimizu and Yukio Ohsawa", "title": "Data Combination for Problem-solving: A Case of an Open Data Exchange\n  Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In recent years, rather than enclosing data within a single organization,\nexchanging and combining data from different domains has become an emerging\npractice. Many studies have discussed the economic and utility value of data\nand data exchange, but the characteristics of data that contribute to problem\nsolving through data combination have not been fully understood. In big data\nand interdisciplinary data combinations, large-scale data with many variables\nare expected to be used, and value is expected to be created by combining data\nas much as possible. In this study, we conduct three experiments to investigate\nthe characteristics of data, focusing on the relationships between data\ncombinations and variables in each dataset, using empirical data shared by the\nlocal government. The results indicate that even datasets that have a few\nvariables are frequently used to propose solutions for problem solving.\nMoreover, we found that even if the datasets in the solution do not have common\nvariables, there are some well-established solutions to the problems. The\nfindings of this study shed light on mechanisms behind data combination for\nproblem-solving involving multiple datasets and variables.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 23:29:10 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Hayashi", "Teruaki", ""], ["Sakaji", "Hiroki", ""], ["Matsushima", "Hiroyasu", ""], ["Fukami", "Yoshiaki", ""], ["Shimizu", "Takumi", ""], ["Ohsawa", "Yukio", ""]]}, {"id": "2012.12013", "submitter": "Innar Liiv", "authors": "Innar Liiv", "title": "SARS-CoV-2 Coronavirus Data Compression Benchmark", "comments": "6 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a lossless data compression competition that benchmarks\nsolutions (computer programs) by the compressed size of the 44,981 concatenated\nSARS-CoV-2 sequences, with a total uncompressed size of 1,339,868,341 bytes.\nThe data, downloaded on 13 December 2020, from the severe acute respiratory\nsyndrome coronavirus 2 data hub of ncbi.nlm.nih.gov is presented in FASTA and\n2Bit format. The aim of this competition is to encourage multidisciplinary\nresearch to find the shortest lossless description for the sequences and to\ndemonstrate that data compression can serve as an objective and repeatable\nmeasure to align scientific breakthroughs across disciplines. The shortest\ndescription of the data is the best model; therefore, further reducing the size\nof this description requires a fundamental understanding of the underlying\ncontext and data. This paper presents preliminary results with multiple\nwell-known compression algorithms for baseline measurements, and insights\nregarding promising research avenues. The competition's progress will be\nreported at \\url{https://coronavirus.innar.com}, and the benchmark is open for\nall to participate and contribute.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 16:41:59 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Liiv", "Innar", ""]]}, {"id": "2012.12305", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko, Isar Nejadgholi, Kathleen C. Fraser", "title": "Confronting Abusive Language Online: A Survey from the Ethical and Human\n  Rights Perspective", "comments": "published in Journal of Artificial Intelligence Research, 71:\n  431-478, July 2021", "journal-ref": null, "doi": "10.1613/jair.1.12590", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasiveness of abusive content on the internet can lead to severe\npsychological and physical harm. Significant effort in Natural Language\nProcessing (NLP) research has been devoted to addressing this problem through\nabusive content detection and related sub-areas, such as the detection of hate\nspeech, toxicity, cyberbullying, etc. Although current technologies achieve\nhigh classification performance in research studies, it has been observed that\nthe real-life application of this technology can cause unintended harms, such\nas the silencing of under-represented groups. We review a large body of NLP\nresearch on automatic abuse detection with a new focus on ethical challenges,\norganized around eight established ethical principles: privacy, accountability,\nsafety and security, transparency and explainability, fairness and\nnon-discrimination, human control of technology, professional responsibility,\nand promotion of human values. In many cases, these principles relate not only\nto situational ethical codes, which may be context-dependent, but are in fact\nconnected to universal human rights, such as the right to privacy, freedom from\ndiscrimination, and freedom of expression. We highlight the need to examine the\nbroad social impacts of this technology, and to bring ethical and human rights\nconsiderations to every stage of the application life-cycle, from task\nformulation and dataset design, to model training and evaluation, to\napplication deployment. Guided by these principles, we identify several\nopportunities for rights-respecting, socio-technical solutions to detect and\nconfront online abuse, including `nudging', `quarantining', value sensitive\ndesign, counter-narratives, style transfer, and AI-driven public education\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 19:27:11 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 16:53:43 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Nejadgholi", "Isar", ""], ["Fraser", "Kathleen C.", ""]]}, {"id": "2012.12415", "submitter": "Tianshi Li", "authors": "Tianshi Li, Camille Cobb, Jackie (Junrui) Yang, Sagar Baviskar, Yuvraj\n  Agarwal, Beibei Li, Lujo Bauer, Jason I. Hong", "title": "What Makes People Install a COVID-19 Contact-Tracing App? Understanding\n  the Influence of App Design and Individual Difference on Contact-Tracing App\n  Adoption Intention", "comments": "44 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone-based contact-tracing apps are a promising solution to help scale\nup the conventional contact-tracing process. However, low adoption rates have\nbecome a major issue that prevents these apps from achieving their full\npotential. In this paper, we present a national-scale survey experiment ($N =\n1963$) in the U.S. to investigate the effects of app design choices and\nindividual differences on COVID-19 contact-tracing app adoption intentions. We\nfound that individual differences such as prosocialness, COVID-19 risk\nperceptions, general privacy concerns, technology readiness, and demographic\nfactors played a more important role than app design choices such as\ndecentralized design vs. centralized design, location use, app providers, and\nthe presentation of security risks. Certain app designs could exacerbate the\ndifferent preferences in different sub-populations which may lead to an\ninequality of acceptance to certain app design choices (e.g., developed by\nstate health authorities vs. a large tech company) among different groups of\npeople (e.g., people living in rural areas vs. people living in urban areas).\nOur mediation analysis showed that one's perception of the public health\nbenefits offered by the app and the adoption willingness of other people had a\nlarger effect in explaining the observed effects of app design choices and\nindividual differences than one's perception of the app's security and privacy\nrisks. With these findings, we discuss practical implications on the design,\nmarketing, and deployment of COVID-19 contact-tracing apps in the U.S.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 23:46:47 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 06:57:11 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 21:59:50 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Li", "Tianshi", "", "Junrui"], ["Cobb", "Camille", "", "Junrui"], ["Jackie", "", "", "Junrui"], ["Yang", "", ""], ["Baviskar", "Sagar", ""], ["Agarwal", "Yuvraj", ""], ["Li", "Beibei", ""], ["Bauer", "Lujo", ""], ["Hong", "Jason I.", ""]]}, {"id": "2012.12537", "submitter": "Asaf Shabtai", "authors": "Amit Giloni and Edita Grolman and Tanja Hagemann and Ronald Fromm and\n  Sebastian Fischer and Yuval Elovici and Asaf Shabtai", "title": "BENN: Bias Estimation Using Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need to detect bias in machine learning (ML) models has led to the\ndevelopment of multiple bias detection methods, yet utilizing them is\nchallenging since each method: i) explores a different ethical aspect of bias,\nwhich may result in contradictory output among the different methods, ii)\nprovides an output of a different range/scale and therefore, can't be compared\nwith other methods, and iii) requires different input, and therefore a human\nexpert needs to be involved to adjust each method according to the examined\nmodel. In this paper, we present BENN -- a novel bias estimation method that\nuses a pretrained unsupervised deep neural network. Given a ML model and data\nsamples, BENN provides a bias estimation for every feature based on the model's\npredictions. We evaluated BENN using three benchmark datasets and one\nproprietary churn prediction model used by a European Telco and compared it\nwith an ensemble of 21 existing bias estimation methods. Evaluation results\nhighlight the significant advantages of BENN over the ensemble, as it is\ngeneric (i.e., can be applied to any ML model) and there is no need for a\ndomain expert, yet it provides bias estimations that are aligned with those of\nthe ensemble.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 08:25:35 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Giloni", "Amit", ""], ["Grolman", "Edita", ""], ["Hagemann", "Tanja", ""], ["Fromm", "Ronald", ""], ["Fischer", "Sebastian", ""], ["Elovici", "Yuval", ""], ["Shabtai", "Asaf", ""]]}, {"id": "2012.12927", "submitter": "Viktor Von Wyl", "authors": "Justus Benzler, Dan Bogdanov, G\\\"oran Kirchner, Wouter Lueks, Raquel\n  Lucas, Rui Oliveira, Bart Preneel, Marcel Salathe, Carmela Troncoso, Viktor\n  von Wyl", "title": "Towards a common performance and effectiveness terminology for digital\n  proximity tracing applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Digital proximity tracing (DPT) for Sars-CoV-2 pandemic mitigation is a\ncomplex intervention with the primary goal to notify app users about possible\nrisk exposures to infected persons. Policymakers and DPT operators need to know\nwhether their system works as expected in terms of speed or yield (performance)\nand whether DPT is making an effective contribution to pandemic mitigation\n(also in comparison to and beyond established mitigation measures, particularly\nmanual contact tracing). Thereby, performance and effectiveness are not to be\nconfused. Not only are there conceptual differences but also diverse data\nrequirements. This article describes differences between performance and\neffectiveness measures and attempts to develop a terminology and classification\nsystem for DPT evaluation. We discuss key aspects for critical assessments of\nwhether the integration of additional data measurements into DPT apps - beyond\nwhat is required to fulfill its primary notification role - may facilitate an\nunderstanding of performance and effectiveness of planned and deployed DPT\napps. Therefore, the terminology and a classification matrix may offer some\nguidance to DPT system operators regarding which measurements to prioritize.\nDPT developers and operators may also make conscious decisions to integrate\nmeasures for epidemic monitoring but should be aware that this introduces a\nsecondary purpose to DPT that is not part of the original DPT design.\nUltimately, the integration of further information for epidemic monitoring into\nDPT involves a trade-off between data granularity and linkage on the one hand,\nand privacy on the other. Decision-makers should be aware of the trade-off and\ntake it into account when planning and developing DPT notification and\nmonitoring systems or intending to assess the added value of DPT relative to\nexisting contact tracing systems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 19:19:14 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Benzler", "Justus", ""], ["Bogdanov", "Dan", ""], ["Kirchner", "G\u00f6ran", ""], ["Lueks", "Wouter", ""], ["Lucas", "Raquel", ""], ["Oliveira", "Rui", ""], ["Preneel", "Bart", ""], ["Salathe", "Marcel", ""], ["Troncoso", "Carmela", ""], ["von Wyl", "Viktor", ""]]}, {"id": "2012.13016", "submitter": "Lance Eliot", "authors": "Lance Eliot", "title": "Antitrust and Artificial Intelligence (AAI): Antitrust Vigilance\n  Lifecycle and AI Legal Reasoning Autonomy", "comments": "29 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:2010.02726, arXiv:2009.14620", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing interest in the entwining of the field of antitrust\nwith the field of Artificial Intelligence (AI), frequently referred to jointly\nas Antitrust and AI (AAI) in the research literature. This study focuses on the\nsynergies entangling antitrust and AI, doing so to extend the literature by\nproffering the primary ways that these two fields intersect, consisting of: (1)\nthe application of antitrust to AI, and (2) the application of AI to antitrust.\nTo date, most of the existing research on this intermixing has concentrated on\nthe former, namely the application of antitrust to AI, entailing how the\nmarketplace will be altered by the advent of AI and the potential for adverse\nantitrust behaviors arising accordingly. Opting to explore more deeply the\nother side of this coin, this research closely examines the application of AI\nto antitrust and establishes an antitrust vigilance lifecycle to which AI is\npredicted to be substantively infused for purposes of enabling and bolstering\nantitrust detection, enforcement, and post-enforcement monitoring. Furthermore,\na gradual and incremental injection of AI into antitrust vigilance is\nanticipated to occur as significant advances emerge amidst the Levels of\nAutonomy (LoA) for AI Legal Reasoning (AILR).\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 22:58:51 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Eliot", "Lance", ""]]}, {"id": "2012.13061", "submitter": "Patrick Ocheja", "authors": "Patrick Ocheja, Yang Cao, Shiyao Ding, and Masatoshi Yoshikawa", "title": "Quantifying the Privacy-Utility Trade-offs in COVID-19 Contact Tracing\n  Apps", "comments": "12 pages, 11 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How to contain the spread of the COVID-19 virus is a major concern for most\ncountries. As the situation continues to change, various countries are making\nefforts to reopen their economies by lifting some restrictions and enforcing\nnew measures to prevent the spread. In this work, we review some approaches\nthat have been adopted to contain the COVID-19 virus such as contact tracing,\nclusters identification, movement restrictions, and status validation.\nSpecifically, we classify available techniques based on some characteristics\nsuch as technology, architecture, trade-offs (privacy vs utility), and the\nphase of adoption. We present a novel approach for evaluating privacy using\nboth qualitative and quantitative measures of privacy-utility assessment of\ncontact tracing applications. In this new method, we classify utility at three\n(3) distinct levels: no privacy, 100% privacy, and at k where k is set by the\nsystem providing the utility or privacy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 01:37:07 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Ocheja", "Patrick", ""], ["Cao", "Yang", ""], ["Ding", "Shiyao", ""], ["Yoshikawa", "Masatoshi", ""]]}, {"id": "2012.13117", "submitter": "Michael Hucka", "authors": "Task Force on Best Practices for Software Registries: Alain Monteil\n  (INRIA), Alejandra Gonzalez-Beltran (Science and Technology Facilities\n  Council, UK Research and Innovation), Alexandros Ioannidis (CERN), Alice\n  Allen (University of Maryland), Allen Lee (Arizona State University), Anita\n  Bandrowski (University of California at San Diego), Bruce E. Wilson (Oak\n  Ridge National Laboratory), Bryce Mecum (University of California at Santa\n  Barbara), Cai Fan Du (University of Texas at Austin), Carly Robinson\n  (DOE-OSTI), Daniel Garijo (University of Southern California), Daniel S. Katz\n  (University of Illinois at Urbana-Champaign), David Long (Brigham Young\n  University), Genevieve Milliken (NYU Bobst Library), Herv\\'e M\\'enager\n  (Institut Pasteur), Jessica Hausman (NASA Jet Propulsion Laboratory),\n  Jurriaan H. Spaaks (Netherlands eScience Center), Katrina Fenlon (University\n  of Maryland), Kristin Vanderbilt (University of New Mexico), Lorraine Hwang\n  (University of California at Davis), Lynn Davis (DOE-OSTI), Martin Fenner\n  (DataCite), Michael R. Crusoe (CWL), Michael Hucka (California Institute of\n  Technology), Mingfang Wu (Australian Research Data Commons), Neil Chue Hong\n  (University of Edinburgh), Peter Teuben (University of Maryland), Shelley\n  Stall (American Geophysical Union), Stephan Druskat (German Aerospace Center\n  (DLR)/University Jena/Humboldt-Universit\\\"at zu Berlin), Ted Carnevale (Yale\n  University), Thomas Morrell (California Institute of Technology)", "title": "Nine Best Practices for Research Software Registries and Repositories: A\n  Concise Guide", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scientific software registries and repositories serve various roles in their\nrespective disciplines. These resources improve software discoverability and\nresearch transparency, provide information for software citations, and foster\npreservation of computational methods that might otherwise be lost over time,\nthereby supporting research reproducibility and replicability. However,\ndeveloping these resources takes effort, and few guidelines are available to\nhelp prospective creators of registries and repositories. To address this need,\nwe present a set of nine best practices that can help managers define the\nscope, practices, and rules that govern individual registries and repositories.\nThese best practices were distilled from the experiences of the creators of\nexisting resources, convened by a Task Force of the FORCE11 Software Citation\nImplementation Working Group during the years 2019-2020. We believe that\nputting in place specific policies such as those presented here will help\nscientific software registries and repositories better serve their users and\ntheir disciplines.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 05:37:54 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Registries", "Task Force on Best Practices for Software", "", "INRIA"], [":", "", "", "INRIA"], ["Monteil", "Alain", "", "INRIA"], ["Gonzalez-Beltran", "Alejandra", "", "Science and Technology Facilities\n  Council, UK Research and Innovation"], ["Ioannidis", "Alexandros", "", "CERN"], ["Allen", "Alice", "", "University of Maryland"], ["Lee", "Allen", "", "Arizona State University"], ["Bandrowski", "Anita", "", "University of California at San Diego"], ["Wilson", "Bruce E.", "", "Oak\n  Ridge National Laboratory"], ["Mecum", "Bryce", "", "University of California at Santa\n  Barbara"], ["Du", "Cai Fan", "", "University of Texas at Austin"], ["Robinson", "Carly", "", "DOE-OSTI"], ["Garijo", "Daniel", "", "University of Southern California"], ["Katz", "Daniel S.", "", "University of Illinois at Urbana-Champaign"], ["Long", "David", "", "Brigham Young\n  University"], ["Milliken", "Genevieve", "", "NYU Bobst Library"], ["M\u00e9nager", "Herv\u00e9", "", "Institut Pasteur"], ["Hausman", "Jessica", "", "NASA Jet Propulsion Laboratory"], ["Spaaks", "Jurriaan H.", "", "Netherlands eScience Center"], ["Fenlon", "Katrina", "", "University\n  of Maryland"], ["Vanderbilt", "Kristin", "", "University of New Mexico"], ["Hwang", "Lorraine", "", "University of California at Davis"], ["Davis", "Lynn", "", "DOE-OSTI"], ["Fenner", "Martin", "", "DataCite"], ["Crusoe", "Michael R.", "", "CWL"], ["Hucka", "Michael", "", "California Institute of\n  Technology"], ["Wu", "Mingfang", "", "Australian Research Data Commons"], ["Hong", "Neil Chue", "", "University of Edinburgh"], ["Teuben", "Peter", "", "University of Maryland"], ["Stall", "Shelley", "", "American Geophysical Union"], ["Druskat", "Stephan", "", "German Aerospace Center"], ["Carnevale", "Ted", "", "Yale\n  University"], ["Morrell", "Thomas", "", "California Institute of Technology"]]}, {"id": "2012.13393", "submitter": "Melih Bastopcu", "authors": "Melih Bastopcu and Sennur Ulukus", "title": "Timely Tracking of Infection Status of Individuals in a Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT cs.NI eess.SP math.IT physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider real-time timely tracking of infection status (e.g., covid-19) of\nindividuals in a population. In this work, a health care provider wants to\ndetect infected people as well as people who recovered from the disease as\nquickly as possible. In order to measure the timeliness of the tracking\nprocess, we use the long-term average difference between the actual infection\nstatus of the people and their real-time estimate by the health care provider\nbased on the most recent test results. We first find an analytical expression\nfor this average difference for given test rates, and given infection and\nrecovery rates of people. Next, we propose an alternating minimization based\nalgorithm to minimize this average difference. We observe that if the total\ntest rate is limited, instead of testing all members of the population equally,\nonly a portion of the population is tested based on their infection and\nrecovery rates. We also observe that increasing the total test rate helps track\nthe infection status better. In addition, an increased population size\nincreases diversity of people with different infection and recovery rates,\nwhich may be exploited to spend testing capacity more efficiently, thereby\nimproving the system performance. Finally, depending on the health care\nprovider's preferences, test rate allocation can be altered to detect either\nthe infected people or the recovered people more quickly.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 18:49:22 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Bastopcu", "Melih", ""], ["Ulukus", "Sennur", ""]]}, {"id": "2012.13599", "submitter": "Hamed Alhoori", "authors": "Akhil Pandey Akella, Hamed Alhoori, Pavan Ravikanth Kondamudi, Cole\n  Freeman, Haiming Zhou", "title": "Early Indicators of Scientific Impact: Predicting Citations with\n  Altmetrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying important scholarly literature at an early stage is vital to the\nacademic research community and other stakeholders such as technology companies\nand government bodies. Due to the sheer amount of research published and the\ngrowth of ever-changing interdisciplinary areas, researchers need an efficient\nway to identify important scholarly work. The number of citations a given\nresearch publication has accrued has been used for this purpose, but these take\ntime to occur and longer to accumulate. In this article, we use altmetrics to\npredict the short-term and long-term citations that a scholarly publication\ncould receive. We build various classification and regression models and\nevaluate their performance, finding neural networks and ensemble models to\nperform best for these tasks. We also find that Mendeley readership is the most\nimportant factor in predicting the early citations, followed by other factors\nsuch as the academic status of the readers (e.g., student, postdoc, professor),\nfollowers on Twitter, online post length, author count, and the number of\nmentions on Twitter, Wikipedia, and across different countries.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 16:25:07 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Akella", "Akhil Pandey", ""], ["Alhoori", "Hamed", ""], ["Kondamudi", "Pavan Ravikanth", ""], ["Freeman", "Cole", ""], ["Zhou", "Haiming", ""]]}, {"id": "2012.13626", "submitter": "Lauri Lahti", "authors": "Lauri Lahti", "title": "Detecting the patient's need for help with machine learning", "comments": "Corresponding author: Lauri Lahti (email: lauri.lahti@aalto.fi). The\n  first manuscript version of this research article was self-archived\n  (arXiv:2012.13626) on 24 December 2020 and this second manuscript version on\n  23 March 2021. Changes include extensions, clarifications and corrections.\n  This article contains 26 pages, 7 tables and 5 figures. Supplemented with\n  Appendix A (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing machine learning models to support health analytics requires\nincreased understanding about statistical properties of self-rated expression\nstatements. We analyzed self-rated expression statements concerning the\ncoronavirus COVID-19 epidemic to identify statistically significant differences\nbetween groups of respondents and to detect the patient's need for help with\nmachine learning. Our quantitative study gathered the \"need for help\" ratings\nfor twenty health-related expression statements concerning the coronavirus\nepidemic on a 11-point Likert scale, and nine answers about the person's health\nand wellbeing, sex and age. Online respondents between 30 May and 3 August 2020\nwere recruited from Finnish patient and disabled people's organizations, other\nhealth-related organizations and professionals, and educational institutions\n(n=673). We analyzed rating differences and dependencies with Kendall\nrank-correlation and cosine similarity measures and tests of Wilcoxon rank-sum,\nKruskal-Wallis and one-way analysis of variance (ANOVA) between groups, and\ncarried out machine learning experiments with a basic implementation of a\nconvolutional neural network algorithm. We found statistically significant\ncorrelations and high cosine similarity values between various health-related\nexpression statement pairs concerning the \"need for help\" ratings and a\nbackground question pair. We also identified statistically significant rating\ndifferences for several health-related expression statements in respect to\ngroupings based on the answer values of background questions, such as the\nratings of suspecting to have the coronavirus infection and having it depending\non the estimated health condition, quality of life and sex. Our experiments\nwith a convolutional neural network algorithm showed the applicability of\nmachine learning to support detecting the need for help in the patient's\nexpressions.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 20:30:34 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 17:50:47 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Lahti", "Lauri", ""]]}, {"id": "2012.13872", "submitter": "Yaman Kumar Singla", "authors": "Swapnil Parekh, Yaman Kumar Singla, Changyou Chen, Junyi Jessy Li,\n  Rajiv Ratn Shah", "title": "My Teacher Thinks The World Is Flat! Interpreting Automatic Essay\n  Scoring Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant progress has been made in deep-learning based Automatic Essay\nScoring (AES) systems in the past two decades. However, little research has\nbeen put to understand and interpret the black-box nature of these\ndeep-learning based scoring models. Recent work shows that automated scoring\nsystems are prone to even common-sense adversarial samples. Their lack of\nnatural language understanding capability raises questions on the models being\nactively used by millions of candidates for life-changing decisions. With\nscoring being a highly multi-modal task, it becomes imperative for scoring\nmodels to be validated and tested on all these modalities. We utilize recent\nadvances in interpretability to find the extent to which features such as\ncoherence, content and relevance are important for automated scoring mechanisms\nand why they are susceptible to adversarial samples. We find that the systems\ntested consider essays not as a piece of prose having the characteristics of\nnatural flow of speech and grammatical structure, but as `word-soups' where a\nfew words are much more important than the other words. Removing the context\nsurrounding those few important words causes the prose to lose the flow of\nspeech and grammar, however has little impact on the predicted score. We also\nfind that since the models are not semantically grounded with world-knowledge\nand common sense, adding false facts such as ``the world is flat'' actually\nincreases the score instead of decreasing it.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2020 06:19:20 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Parekh", "Swapnil", ""], ["Singla", "Yaman Kumar", ""], ["Chen", "Changyou", ""], ["Li", "Junyi Jessy", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2012.14112", "submitter": "William Wagner", "authors": "William Wagner", "title": "A Technological Perspective on Net Neutrality", "comments": "9 pages, 3 figures, 1 appendix, Keywords - Net Neutrality, Internet,\n  ISP, Provider, Government Regulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper serves as a brief technical examination of Net Neutrality and the\nInternet fundamentals relevant to the discussion. This document seeks to\nprovide sufficient technical perspective that it may inform the political and\neconomic debate surrounding the issue in the United States. Further, this\nresearch demonstrates that existing Internet economics are based strictly on\nusage, and that this model can account for all uses. Finally, I will argue that\nthere should be some legislation and regulation of ISPs with regard to Net\nNeutrality in the U.S.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 06:29:28 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 07:36:54 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Wagner", "William", ""]]}, {"id": "2012.14180", "submitter": "Filippo Brandolini", "authors": "Filippo Brandolini, Guillem Domingo Ribas, Andrea Zerboni, Sam Turner", "title": "A Google Earth Engine-enabled Python approach to improve identification\n  of anthropogenic palaeo-landscape features", "comments": "33 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The necessity of sustainable development for landscapes has emerged as an\nimportant theme in recent decades. Current methods take a holistic approach to\nlandscape heritage and promote an interdisciplinary dialogue to facilitate\ncomplementary landscape management strategies. With the socio-economic values\nof the natural and cultural landscape heritage increasingly recognised\nworldwide, remote sensing tools are being used more and more to facilitate the\nrecording and management of landscape heritage. Satellite remote sensing\ntechnologies have enabled significant improvements in landscape research. The\nadvent of the cloud-based platform of Google Earth Engine has allowed the rapid\nexploration and processing of satellite imagery such as the Landsat and\nCopernicus Sentinel datasets. In this paper, the use of Sentinel-2 satellite\ndata in the identification of palaeo-riverscape features has been assessed in\nthe Po Plain, selected because it is characterized by human exploitation since\nthe Mid-Holocene. A multi-temporal approach has been adopted to investigate the\npotential of satellite imagery to detect buried hydrological and anthropogenic\nfeatures along with Spectral Index and Spectral Decomposition analysis. This\nresearch represents one of the first applications of the GEE Python API in\nlandscape studies. The complete FOSS-cloud protocol proposed here consists of a\nPython code script developed in Google Colab which could be simply adapted and\nreplicated in different areas of the world\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 10:51:45 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Brandolini", "Filippo", ""], ["Ribas", "Guillem Domingo", ""], ["Zerboni", "Andrea", ""], ["Turner", "Sam", ""]]}, {"id": "2012.14274", "submitter": "Kiran Garimella", "authors": "Kirill Martynov, Kiran Garimella, Robert West", "title": "Darks and Stripes: Effects of Clothing on Weight Perception", "comments": "Accepted at the IEEE Journal of Social Computing", "journal-ref": "Journal of Social Computing (Volume: 1, Issue: 1, September 2020)\n  pg. 53-70", "doi": "10.23919/JSC.2020.0006", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many societies, appearing slim is considered attractive. The fashion\nindustry has been attempting to cater to this trend by designing outfits that\ncan enhance the appearance of slimness. Two anecdotal rules, widespread in the\nworld of fashion, are (1) choose dark clothes and (2) avoid horizontal stripes,\nin order to appear slim. Thus far, empirical evidence has been unable to\nconclusively determine the validity of these rules, and there is consequently\nmuch controversy regarding the impact of both color and patterns on the visual\nperception of weight. In this paper, we aim to close this gap by presenting the\nresults from a series of large-scale crowdsourcing studies that investigate the\nabove two claims. We gathered a dataset of around 1,000 images of people from\nthe Web together with their ground-truth weight and height, as well as clothing\nattributes about colors and patterns. To elicit the effects of colors and\npatterns, we asked crowd workers to estimate the weight in each image. For the\nanalysis, we controlled potential confounds by matching images in pairs where\nthe two images differ with respect to color or pattern, but are similar with\nrespect to other relevant aspects. We created image pairs in two ways: first,\nobservationally, i.e., from two real images; and second, experimentally, by\nmanipulating the color or pattern of clothing in a real image via photo\nediting. Based on our analysis, we conclude that (1) dark clothes indeed\ndecrease perceived weight slightly but statistically significantly, and (2)\nhorizontal stripes have no discernible effect compared to solid light-colored\nclothes. These results contribute to advancing the debate around the effect of\nspecific clothing colors and patterns and thus provide empirical grounds for\neveryday fashion decisions. Moreover, our work gives an outlook on the vast\nopportunities of using crowd sourcing in the modern fashion industry.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 16:14:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Martynov", "Kirill", ""], ["Garimella", "Kiran", ""], ["West", "Robert", ""]]}, {"id": "2012.14280", "submitter": "Mohammad Reza Besharati", "authors": "Mohammad Reza Besharati, Mohammad Izadi", "title": "A Reo Based Solution for Engineering the Coordination Protocols for\n  Smart Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart Cities, with their problems and challenges, is an emerging smart\nparadigm. To achieve better quality and usability levels, we need engineering\nsolutions to support smart cities' soft-layer development. Statics, dynamics\nand generative semantics are involved, but segregating Coordination Protocols\nfrom the other semantics could act as a complexity management strategy to\ntackle the inherent complexity of smart city systems. Here we demonstrate how\nwe could engineer the protocols layer of a smart city by using a Reo-Based\nsolution.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:16:02 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 00:55:19 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Besharati", "Mohammad Reza", ""], ["Izadi", "Mohammad", ""]]}, {"id": "2012.14285", "submitter": "Alice Xiang", "authors": "Daniel E. Ho and Alice Xiang", "title": "Affirmative Algorithms: The Legal Grounds for Fairness as Awareness", "comments": "12 pages, 3 figures", "journal-ref": "10/30/20 U. Chi. L. Rev. Online 143,\n  https://lawreviewblog.uchicago.edu/2020/10/30/aa-ho-xiang/", "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While there has been a flurry of research in algorithmic fairness, what is\nless recognized is that modern antidiscrimination law may prohibit the adoption\nof such techniques. We make three contributions. First, we discuss how such\napproaches will likely be deemed \"algorithmic affirmative action,\" posing\nserious legal risks of violating equal protection, particularly under the\nhigher education jurisprudence. Such cases have increasingly turned toward\nanticlassification, demanding \"individualized consideration\" and barring\nformal, quantitative weights for race regardless of purpose. This case law is\nhence fundamentally incompatible with fairness in machine learning. Second, we\nargue that the government-contracting cases offer an alternative grounding for\nalgorithmic fairness, as these cases permit explicit and quantitative\nrace-based remedies based on historical discrimination by the actor. Third,\nwhile limited, this doctrinal approach also guides the future of algorithmic\nfairness, mandating that adjustments be calibrated to the entity's\nresponsibility for historical discrimination causing present-day disparities.\nThe contractor cases provide a legally viable path for algorithmic fairness\nunder current constitutional doctrine but call for more research at the\nintersection of algorithmic fairness and causal inference to ensure that bias\nmitigation is tailored to specific causes and mechanisms of bias.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 22:53:20 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ho", "Daniel E.", ""], ["Xiang", "Alice", ""]]}, {"id": "2012.14294", "submitter": "Alaa Awad Abdellatif", "authors": "Alaa Awad Abdellatif, Lutfi Samara, Amr Mohamed, Aiman Erbad, Carla\n  Fabiana Chiasserini, Mohsen Guizani, Mark Dennis O'Connor, and James Laughton", "title": "I-Health: Leveraging Edge Computing and Blockchain for Epidemic\n  Management", "comments": "A version of this paper has been submitted in IEEE Internet of Things\n  Journal. arXiv admin note: text overlap with arXiv:2006.10843", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epidemic situations typically demand intensive data collection and management\nfrom different locations/entities within a strict time constraint. Such demand\ncan be fulfilled by leveraging the intensive and easy deployment of the\nInternet of Things (IoT) devices. The management and containment of such\nsituations also rely on cross-organizational and national collaboration. Thus,\nthis paper proposes an Intelligent-Health (I-Health) system that aims to\naggregate diverse e-health entities in a unique national healthcare system by\nenabling swift, secure exchange and storage of medical data. In particular, we\ndesign an automated patients monitoring scheme, at the edge, which enables the\nprompt discovery, remote monitoring, and fast emergency response for critical\nmedical events, such as emerging epidemics. Furthermore, we develop a\nblockchain optimization model that aims to optimize medical data sharing\nbetween different health entities to provide effective and secure health\nservices. Finally, we show the effectiveness of our system, in adapting to\ndifferent critical events, while highlighting the benefits of the proposed\nI-Health system.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 23:41:00 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Abdellatif", "Alaa Awad", ""], ["Samara", "Lutfi", ""], ["Mohamed", "Amr", ""], ["Erbad", "Aiman", ""], ["Chiasserini", "Carla Fabiana", ""], ["Guizani", "Mohsen", ""], ["O'Connor", "Mark Dennis", ""], ["Laughton", "James", ""]]}, {"id": "2012.14308", "submitter": "Mohammad Khalil", "authors": "Mohammad Khalil", "title": "MOLAM: A Mobile Multimodal Learning Analytics Conceptual Framework to\n  Support Student Self-Regulated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online distance learning is highly learner-centred, requiring different\nskills and competences from learners, as well as alternative approaches for\ninstructional design, student support, and provision of resources. Learner\nautonomy and self-regulated learning (SRL) in online learning settings are\nconsidered key success factors that predict student performance. SRL comprises\nprocesses of planning, monitoring, action and reflection according to\nZimmerman. And typically focuses on three key features of learners: (1) use of\nSRL strategies, (2) responsiveness to self-oriented feedback about learning\neffectiveness, and (3) motivational processes. SRL has been identified as\nhaving a direct correlation with students success, including improvements in\ngrades and the development of relevant skills and strategies. Such skills and\nstrategies are needed to become a successful lifelong learner. This chapter\nintroduces a Mobile Multimodal Learning Analytics approach (MOLAM). I argue\nthat the development of student Self-Regulated Learning would benefit from the\nadoption of this approach, and that its use would allow continuous measurement\nand provision of in-time support of student SRL in online learning contexts.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2020 18:55:33 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Khalil", "Mohammad", ""]]}, {"id": "2012.14325", "submitter": "Ljupco Kocarev", "authors": "Ljupco Kocarev and Jasna Koteska", "title": "Digital me ontology and ethics", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses ontology and ethics of an AI agent called digital me. We\ndefine digital me as autonomous, decision-making, and learning agent,\nrepresenting an individual and having practically immortal own life. It is\nassumed that digital me is equipped with the big-five personality model,\nensuring that it provides a model of some aspects of a strong AI:\nconsciousness, free will, and intentionality. As computer-based personality\njudgments are more accurate than those made by humans, digital me can judge the\npersonality of the individual represented by the digital me, other individuals'\npersonalities, and other digital me-s. We describe seven ontological qualities\nof digital me: a) double-layer status of Digital Being versus digital me, b)\ndigital me versus real me, c) mind-digital me and body-digital me, d) digital\nme versus doppelganger (shadow digital me), e) non-human time concept, f)\nsocial quality, g) practical immortality. We argue that with the advancement of\nAI's sciences and technologies, there exist two digital me thresholds. The\nfirst threshold defines digital me having some (rudimentarily) form of\nconsciousness, free will, and intentionality. The second threshold assumes that\ndigital me is equipped with moral learning capabilities, implying that, in\nprinciple, digital me could develop their own ethics which significantly\ndiffers from human's understanding of ethics. Finally we discuss the\nimplications of digital me metaethics, normative and applied ethics, the\nimplementation of the Golden Rule in digital me-s, and we suggest two sets of\nnormative principles for digital me: consequentialist and duty based digital me\nprinciples.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 09:54:04 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Kocarev", "Ljupco", ""], ["Koteska", "Jasna", ""]]}, {"id": "2012.14349", "submitter": "Filip Biljecki", "authors": "Abraham Noah Wu, Filip Biljecki", "title": "Roofpedia: Automatic mapping of green and solar roofs for an open\n  roofscape registry and evaluation of urban sustainability", "comments": null, "journal-ref": "Landscape and Urban Planning 214: 104167, 2021", "doi": "10.1016/j.landurbplan.2021.104167", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sustainable roofs, such as those with greenery and photovoltaic panels,\ncontribute to the roadmap for reducing the carbon footprint of cities. However,\nresearch on sustainable urban roofscapes is rather focused on their potential\nand it is hindered by the scarcity of data, limiting our understanding of their\ncurrent content, spatial distribution, and temporal evolution. To tackle this\nissue, we introduce Roofpedia, a set of three contributions: (i) automatic\nmapping of relevant urban roof typology from satellite imagery; (ii) an open\nroof registry mapping the spatial distribution and area of solar and green\nroofs of more than one million buildings across 17 cities; and (iii) the\nRoofpedia Index, a derivative of the registry, to benchmark the cities by the\nextent of sustainable roofscape in term of solar and green roof penetration.\nThis project, partly inspired by its street greenery counterpart `Treepedia',\nis made possible by a multi-step pipeline that combines deep learning and\ngeospatial techniques, demonstrating the feasibility of an automated\nmethodology that generalises successfully across cities with an accuracy of\ndetecting sustainable roofs of up to 100% in some cities. We offer our results\nas an interactive map and open dataset so that our work could aid researchers,\nlocal governments, and the public to uncover the pattern of sustainable\nrooftops across cities, track and monitor the current use of rooftops,\ncomplement studies on their potential, evaluate the effectiveness of existing\nincentives, verify the use of subsidies and fulfilment of climate pledges,\nestimate carbon offset capacities of cities, and ultimately support better\npolicies and strategies to increase the adoption of instruments contributing to\nthe sustainable development of cities.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 13:34:50 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 23:59:10 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 08:02:59 GMT"}, {"version": "v4", "created": "Thu, 24 Jun 2021 12:20:27 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Wu", "Abraham Noah", ""], ["Biljecki", "Filip", ""]]}, {"id": "2012.14372", "submitter": "Stefano M. Iacus", "authors": "Tiziana Carpi, Airo Hino, Stefano Maria Iacus, Giuseppe Porro", "title": "On a Japanese Subjective Well-Being Indicator Based on Twitter data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents for the first time the SWB-J index, a subjective\nwell-being indicator for Japan based on Twitter data. The index is composed by\neight dimensions of subjective well-being and is estimated relying on Twitter\ndata by using human supervised sentiment analysis. The index is then compared\nwith the analogous SWB-I index for Italy, in order to verify possible analogies\nand cultural differences. Further, through structural equation models, a causal\nassumption is tested to see whether the economic and health conditions of the\ncountry influence the well-being latent variable and how this latent dimension\naffects the SWB-J and SWB-I indicators. It turns out that, as expected, the\neconomic and health welfare is only one aspect of the multidimensional\nwell-being that is captured by the Twitter-based indicator.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 17:28:30 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Carpi", "Tiziana", ""], ["Hino", "Airo", ""], ["Iacus", "Stefano Maria", ""], ["Porro", "Giuseppe", ""]]}, {"id": "2012.14396", "submitter": "Bernardo Huberman", "authors": "Jing Wang and Bernardo Huberman", "title": "A Guide to Global Quantum Key Distribution Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CR cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe systems and methods for the deployment of global quantum key\ndistribution (QKD) networks covering transoceanic, long-haul, metro, and access\nsegments of the network. A comparative study of the state-of-the-art QKD\ntechnologies is carried out, including both terrestrial QKD via optical fibers\nand free-space optics, as well as spaceborne solutions via satellites. We\ncompare the pros and cons of various existing QKD technologies, including\nchannel loss, potential interference, distance, connection topology, deployment\ncost and requirements, as well as application scenarios. Technical selection\ncriteria and deployment requirements are developed for various different QKD\nsolutions in each segment of networks. For example, optical fiber-based QKD is\nsuitable for access networks due to its limited distance and compatibility with\npoint-to-multipoint (P2MP) topology; with the help of trusted relays, it can be\nextended to long-haul and metro networks. Spaceborne QKD on the other hand, has\nmuch smaller channel loss and extended transmission distance, which can be used\nfor transoceanic and long-haul networks exploiting satellite-based trusted\nrelays.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 18:21:10 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 04:01:15 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Wang", "Jing", ""], ["Huberman", "Bernardo", ""]]}, {"id": "2012.14419", "submitter": "Alain Chiaradia", "authors": "Lingzhu Zhang, Alain J F Chiaradia", "title": "Urban volumetrics: spatial complexity and wayfinding, extending space\n  syntax to three dimensional space", "comments": "20 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wayfinding behavior and pedestrian movement pattern research relies on\nobjective spatial configuration representation and analysis, such as space\nsyntax, to quantify and control for the difficulty of wayfinding in multi-level\nbuildings and urban built environments. However, the space syntax's\nrepresentation oversimplifies multi-level vertical connections. The more recent\nsegment and angular approaches to space syntax remain un-operationalizable in\nthree dimensional space. The two dimensional axial-map and segment map line\nrepresentations are reviewed to determine their extension to a novel three\ndimensional space line representation. Using an extreme case study research\nstrategy, four representations of a large scale complex multi-level outdoor and\nindoor built environment are tested against observed pedestrian movement\npatterns N = 17,307. Association with the movement pattern increases steadily\nas the representation increases toward high three-dimensional space level of\ndefinition and completeness. A novel hybrid angular-Euclidean analysis was used\nfor the objective description of three dimensional built environment\ncomplexity. The results suggest that pedestrian wayfinding and movement pattern\nresearch in a multi-level built environment should include interdependent\noutdoor and indoor, and use full three-dimensioanal line representation.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 18:56:14 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhang", "Lingzhu", ""], ["Chiaradia", "Alain J F", ""]]}, {"id": "2012.14573", "submitter": "Maria Shishanina", "authors": "Anatoly Sidorov, Maria Shishanina", "title": "Formal Statement of the Decision-making Support Problem in the\n  Management of Municipal Social and Economic Development", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article deals with the process of managing the social and economic\ndevelopment of municipal formations. It highlights characteristics and key\nissues that arise during management at the municipal level. In order to\nminimize the impact of the described issues, it is suggested to consider\nmunicipal social and economic development as a semistructured system which is\nmodelled using a semantic network. As a result, it is concluded that a rating\nof indicators for assessing social and economic development needs to be created\nin order to determine the effectiveness and correlation with the targeted\nindicators.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 02:36:19 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Sidorov", "Anatoly", ""], ["Shishanina", "Maria", ""]]}, {"id": "2012.14867", "submitter": "Jeff Yan", "authors": "Jeff Yan", "title": "Scams in modern societies: how does China differ from the world?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a set of high-profile scams that were well engineered and have hit\npeople hard in China in recent years. We propose a simple but novel theoretical\nframework to examine psychological, situational and social fabric factors that\nhave played a role in these scams. We also use this framework as a tool to\nexplore scam countermeasures. In so doing, we identify how these Chinese scams\ndiffer from their Western counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 17:40:36 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Yan", "Jeff", ""]]}, {"id": "2012.15112", "submitter": "Marcos Oliveira", "authors": "Juhi Kulshrestha, Marcos Oliveira, Orkut Karacalik, Denis Bonnay,\n  Claudia Wagner", "title": "Web Routineness and Limits of Predictability: Investigating Demographic\n  and Behavioral Differences Using Web Tracking Data", "comments": "12 pages, 8 figures. To be published in the proceedings of the\n  International AAAI Conference on Web and Social Media (ICWSM) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT math.IT physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human activities and movements on the Web is not only important\nfor computational social scientists but can also offer valuable guidance for\nthe design of online systems for recommendations, caching, advertising, and\npersonalization. In this work, we demonstrate that people tend to follow\nroutines on the Web, and these repetitive patterns of web visits increase their\nbrowsing behavior's achievable predictability. We present an\ninformation-theoretic framework for measuring the uncertainty and theoretical\nlimits of predictability of human mobility on the Web. We systematically assess\nthe impact of different design decisions on the measurement. We apply the\nframework to a web tracking dataset of German internet users. Our empirical\nresults highlight that individual's routines on the Web make their browsing\nbehavior predictable to 85% on average, though the value varies across\nindividuals. We observe that these differences in the users' predictabilities\ncan be explained to some extent by their demographic and behavioral attributes.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 11:19:10 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Kulshrestha", "Juhi", ""], ["Oliveira", "Marcos", ""], ["Karacalik", "Orkut", ""], ["Bonnay", "Denis", ""], ["Wagner", "Claudia", ""]]}, {"id": "2012.15368", "submitter": "Marcos Oliveira", "authors": "Marcos Oliveira", "title": "More crime in cities? On the scaling laws of crime and the inadequacy of\n  per capita rankings -- a cross-country study", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: To evaluate the relationship between population size and number\nof crimes in cities across twelve countries and assess the impact of per capita\nmeasurements on crime analyses, depending on offense type.\n  Methods: We use data on burglaries and thefts at the city level and evaluate\nthe relationship between crime numbers and population size using probabilistic\nscaling analysis. We estimate the growth exponent of each offense type and use\nKendall rank correlation to assess the impact of a linear growth assumption\n(i.e., per-capita analysis) on cities rankings.\n  Result: In nine out of eleven countries, theft increases superlinearly with\npopulation size; in two of them, it increases linearly. In eight out of ten\ncountries, burglary increases linearly with population size; in two of them, it\nincreases superlinearly. In nonlinear scenarios, using per capita rates to rank\ncities produces substantially different rankings from rankings adjusted for\npopulation size.\n  Conclusions: Comparing cities using per capita crime rates (e.g., crime per\n100,000 people per year) assumes that crime increases linearly with population\nsize. Our findings indicate, however, that this assumption is unfounded,\nimplying that one should be cautious when using per capita rankings. When crime\nincreases nonlinearly with population, per capita rates do not remove\npopulation effects. The contrasting crime growth of burglary and theft also\nsuggests that different crime dynamics at the local level lead to different\nmacro-level features in cities.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 23:36:28 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Oliveira", "Marcos", ""]]}, {"id": "2012.15754", "submitter": "Stefanos Tsimenidis", "authors": "Stefanos Tsimenidis", "title": "Limitations of Deep Neural Networks: a discussion of G. Marcus' critical\n  appraisal of deep learning", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have triggered a revolution in artificial intelligence,\nhaving been applied with great results in medical imaging, semi-autonomous\nvehicles, ecommerce, genetics research, speech recognition, particle physics,\nexperimental art, economic forecasting, environmental science, industrial\nmanufacturing, and a wide variety of applications in nearly every field. This\nsudden success, though, may have intoxicated the research community and blinded\nthem to the potential pitfalls of assigning deep learning a higher status than\nwarranted. Also, research directed at alleviating the weaknesses of deep\nlearning may seem less attractive to scientists and engineers, who focus on the\nlow-hanging fruit of finding more and more applications for deep learning\nmodels, thus letting short-term benefits hamper long-term scientific progress.\nGary Marcus wrote a paper entitled Deep Learning: A Critical Appraisal, and\nhere we discuss Marcus' core ideas, as well as attempt a general assessment of\nthe subject. This study examines some of the limitations of deep neural\nnetworks, with the intention of pointing towards potential paths for future\nresearch, and of clearing up some metaphysical misconceptions, held by numerous\nresearchers, that may misdirect them.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 12:11:19 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Tsimenidis", "Stefanos", ""]]}, {"id": "2012.15816", "submitter": "Silvia Chiappa", "authors": "Luca Oneto, Silvia Chiappa", "title": "Fairness in Machine Learning", "comments": null, "journal-ref": "Recent Trends in Learning From Data. Studies in Computational\n  Intelligence, vol 896. Springer, Cham, 2020", "doi": "10.1007/978-3-030-43883-8_7", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning based systems are reaching society at large and in many\naspects of everyday life. This phenomenon has been accompanied by concerns\nabout the ethical issues that may arise from the adoption of these\ntechnologies. ML fairness is a recently established area of machine learning\nthat studies how to ensure that biases in the data and model inaccuracies do\nnot lead to models that treat individuals unfavorably on the basis of\ncharacteristics such as e.g. race, gender, disabilities, and sexual or\npolitical orientation. In this manuscript, we discuss some of the limitations\npresent in the current reasoning about fairness and in methods that deal with\nit, and describe some work done by the authors to address them. More\nspecifically, we show how causal Bayesian networks can play an important role\nto reason about and deal with fairness, especially in complex unfairness\nscenarios. We describe how optimal transport theory can be used to develop\nmethods that impose constraints on the full shapes of distributions\ncorresponding to different sensitive attributes, overcoming the limitation of\nmost approaches that approximate fairness desiderata by imposing constraints on\nthe lower order moments or other functions of those distributions. We present a\nunified framework that encompasses methods that can deal with different\nsettings and fairness criteria, and that enjoys strong theoretical guarantees.\nWe introduce an approach to learn fair representations that can generalize to\nunseen tasks. Finally, we describe a technique that accounts for legal\nrestrictions about the use of sensitive attributes.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:38:58 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Oneto", "Luca", ""], ["Chiappa", "Silvia", ""]]}, {"id": "2012.15826", "submitter": "Shang-Wen Li", "authors": "Shang-Wen Li", "title": "Educational Content Linking for Enhancing Learning Need Remediation in\n  MOOCs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since its introduction in 2011, there have been over 4000 MOOCs on various\nsubjects on the Web, serving over 35 million learners. MOOCs have shown the\nability to democratize knowledge dissemination and bring the best education in\nthe world to every learner. However, the disparate distances between\nparticipants, the size of the learner population, and the heterogeneity of the\nlearners' backgrounds make it extremely difficult for instructors to interact\nwith the learners in a timely manner, which adversely affects learning\nexperience. To address the challenges, in this thesis, we propose a framework:\neducational content linking. By linking and organizing pieces of learning\ncontent scattered in various course materials into an easily accessible\nstructure, we hypothesize that this framework can provide learners guidance and\nimprove content navigation. Since most instruction and knowledge acquisition in\nMOOCs takes place when learners are surveying course materials, better content\nnavigation may help learners find supporting information to resolve their\nconfusion and thus improve learning outcome and experience. To support our\nconjecture, we present end-to-end studies to investigate our framework around\ntwo research questions: 1) can manually generated linking improve learning? 2)\ncan learning content be generated with machine learning methods? For studying\nthe first question, we built an interface that present learning materials and\nvisualize the linking among them simultaneously. We found the interface enables\nusers to search for desired course materials more efficiently, and retain more\nconcepts more readily. For the second question, we propose an automatic content\nlinking algorithm based on conditional random fields. We demonstrate that\nautomatically generated linking can still lead to better learning, although the\nmagnitude of the improvement over the unlinked interface is smaller.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:51:15 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 15:33:50 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Li", "Shang-Wen", ""]]}, {"id": "2012.15853", "submitter": "Wieslaw Kopec", "authors": "Anna Jaskulska, Kinga Skorupska, Barbara Karpowicz, Cezary Biele,\n  Jaros{\\l}aw Kowalski, Wies{\\l}aw Kope\\'c", "title": "Exploration of Voice User Interfaces for Older Adults - A Pilot Study to\n  Address Progressive Vision Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice User Interfaces (VUIs) owing to recent developments in Artificial\nIntelligence (AI) and Natural Language Processing (NLP), are becoming\nincreasingly intuitive and functional. They are especially promising for older\nadults, also with special needs, as VUIs remove some barriers related to access\nto Information and Communications Technology (ICT) solutions. In this pilot\nstudy we examine interdisciplinary opportunities in the area of VUIs as\nassistive technologies, based on an exploratory study with older adults, and a\nfollow-up in-depth pilot study with two participants regarding the needs of\npeople who are gradually losing their sight at a later age.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:58:32 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Jaskulska", "Anna", ""], ["Skorupska", "Kinga", ""], ["Karpowicz", "Barbara", ""], ["Biele", "Cezary", ""], ["Kowalski", "Jaros\u0142aw", ""], ["Kope\u0107", "Wies\u0142aw", ""]]}]