[{"id": "2005.00033", "submitter": "Firoj Alam", "authors": "Firoj Alam, Shaden Shaar, Fahim Dalvi, Hassan Sajjad, Alex Nikolov,\n  Hamdy Mubarak, Giovanni Da San Martino, Ahmed Abdelali, Nadir Durrani, Kareem\n  Darwish, Preslav Nakov", "title": "Fighting the COVID-19 Infodemic: Modeling the Perspective of\n  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the\n  Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic is ranked\nsecond in the list of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Addressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nThus, here we design, annotate, and release to the research community a new\ndataset for fine-grained disinformation analysis that (i)focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society as a whole, and (iii) covers\nboth English and Arabic. Finally, we show strong evaluation results using\nstate-of-the-art Transformers, thus confirming the practical utility of the\nannotation schema and of the dataset.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 18:04:20 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 13:33:12 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Alam", "Firoj", ""], ["Shaar", "Shaden", ""], ["Dalvi", "Fahim", ""], ["Sajjad", "Hassan", ""], ["Nikolov", "Alex", ""], ["Mubarak", "Hamdy", ""], ["Martino", "Giovanni Da San", ""], ["Abdelali", "Ahmed", ""], ["Durrani", "Nadir", ""], ["Darwish", "Kareem", ""], ["Nakov", "Preslav", ""]]}, {"id": "2005.00093", "submitter": "Stanis{\\l}aw Saganowski", "authors": "Stanis{\\l}aw Saganowski, Przemys{\\l}aw Kazienko, Maciej Dzie\\.zyc,\n  Patrycja Jakim\\'ow, Joanna Komoszy\\'nska, Weronika Michalska, Anna Dutkowiak,\n  Adam Polak, Adam Dziadek, Micha{\\l} Ujma", "title": "Consumer Wearables and Affective Computing for Wellbeing Support", "comments": "Article submited to the International Workshop on e-Health and\n  m-Health Technologies for Ambient Assisted Living and Healthcare, EAI\n  MobiQuitous 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearables equipped with pervasive sensors enable us to monitor physiological\nand behavioral signals in our everyday life. We propose the WellAff system able\nto recognize affective states for wellbeing support. It also includes health\ncare scenarios, in particular patients with chronic kidney disease (CKD)\nsuffering from bipolar disorders. For the need of a large-scale field study, we\nrevised over 50 off-the-shelf devices in terms of usefulness for emotion,\nstress, meditation, sleep, and physical activity recognition and analysis.\nTheir usability directly comes from the types of sensors they possess as well\nas the quality and availability of raw signals. We found there is no versatile\ndevice suitable for all purposes. Using Empatica E4 and Samsung Galaxy Watch,\nwe have recorded physiological signals from 11 participants over many weeks.\nThe gathered data enabled us to train a classifier that accurately recognizes\nstrong affective states.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 20:38:54 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 09:53:57 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Saganowski", "Stanis\u0142aw", ""], ["Kazienko", "Przemys\u0142aw", ""], ["Dzie\u017cyc", "Maciej", ""], ["Jakim\u00f3w", "Patrycja", ""], ["Komoszy\u0144ska", "Joanna", ""], ["Michalska", "Weronika", ""], ["Dutkowiak", "Anna", ""], ["Polak", "Adam", ""], ["Dziadek", "Adam", ""], ["Ujma", "Micha\u0142", ""]]}, {"id": "2005.00112", "submitter": "Wang Ruijie", "authors": "Chaoqi Yang, Ruijie Wang, Fangwei Gao, Dachun Sun, Jiawei Tang, Tarek\n  Abdelzaher", "title": "Analyzing the Design Space of Re-opening Policies and COVID-19 Outcomes\n  in the US", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent re-opening policies in the US, following a period of social distancing\nmeasures, introduced a significant increase in daily COVID-19 infections,\ncalling for a roll-back or substantial revisiting of these policies in many\nstates. The situation is suggestive of difficulties modeling the impact of\npartial distancing/re-opening policies on future epidemic spread for purposes\nof choosing safe alternatives. More specifically, one needs to understand the\nimpact of manipulating the availability of social interaction venues (e.g.,\nschools, workplaces, and retail establishments) on virus spread. We introduce a\nmodel, inspired by social networks research, that answers the above question.\nOur model compartmentalizes interaction venues into categories we call mixing\ndomains, enabling one to predict COVID-19 contagion trends in different\ngeographic regions under different what if assumptions on partial re-opening of\nindividual domains. We apply our model to several highly impacted states\nshowing (i) how accurately it predicts the extent of current resurgence (from\navailable policy descriptions), and (ii) what alternatives might be more\neffective at mitigating the second wave. We further compare policies that rely\non partial venue closure to policies that espouse wide-spread periodic testing\ninstead (i.e., in lieu of social distancing). Our models predict that the\nbenefits of (mandatory) testing out-shadow the benefits of partial venue\nclosure, suggesting that perhaps more efforts should be directed to such a\nmitigation strategy.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:28:19 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 02:44:17 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 02:17:47 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Yang", "Chaoqi", ""], ["Wang", "Ruijie", ""], ["Gao", "Fangwei", ""], ["Sun", "Dachun", ""], ["Tang", "Jiawei", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "2005.00475", "submitter": "Erfaneh Gharavi", "authors": "Erfaneh Gharavi, Neda Nazemi, Faraz Dadgostari", "title": "Early Outbreak Detection for Proactive Crisis Management Using Twitter\n  Data: COVID-19 a Case Study in the US", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During a disease outbreak, timely non-medical interventions are critical in\npreventing the disease from growing into an epidemic and ultimately a pandemic.\nHowever, taking quick measures requires the capability to detect the early\nwarning signs of the outbreak. This work collects Twitter posts surrounding the\n2020 COVID-19 pandemic expressing the most common symptoms of COVID-19\nincluding cough and fever, geolocated to the United States. Through examining\nthe variation in Twitter activities at the state level, we observed a temporal\nlag between the rises in the number of symptom reporting tweets and officially\nreported positive cases which varies between 5 to 19 days.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 16:27:50 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Gharavi", "Erfaneh", ""], ["Nazemi", "Neda", ""], ["Dadgostari", "Faraz", ""]]}, {"id": "2005.00594", "submitter": "Hiroko Oe", "authors": "Hiroko Oe", "title": "Discussion of digital gaming's impact on players' well-being during the\n  COVID-19 lockdown", "comments": "22 pages, 1 figure, and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research discusses how to utilise digital gaming to support the\nwell-being of its users and sustain their physical and mental health during the\nCOVID-19 lockdown in which people's activities are limited. The published\nacademic literature that is written in English and available for access on\nonline databases was reviewed to develop key take-aways and a framework for\ndiscussing how to enhance people's well-being in the COVID-19 lockdown.\nInteraction with other players in virtual communities has been found to have a\npositive influence on the mental health of those suffering from a lack of\nsocietal connection. A framework for further research has also been developed\nthat focuses on the critical situation of the COVID-19 lockdown,as this is an\nurgent topic with a huge impact on our health.Some gaming service providers\nhave been proactive in redesigning game programming to be suitable for the\nlockdown situation, and this enables players to enjoy physical activities even\nat home.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:24:41 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Oe", "Hiroko", ""]]}, {"id": "2005.00631", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Adrian Weller, and Jos\\'e M. F. Moura", "title": "Evaluating and Aggregating Feature-based Model Explanations", "comments": "Accepted at IJCAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A feature-based model explanation denotes how much each input feature\ncontributes to a model's output for a given data point. As the number of\nproposed explanation functions grows, we lack quantitative evaluation criteria\nto help practitioners know when to use which explanation function. This paper\nproposes quantitative evaluation criteria for feature-based explanations: low\nsensitivity, high faithfulness, and low complexity. We devise a framework for\naggregating explanation functions. We develop a procedure for learning an\naggregate explanation function with lower complexity and then derive a new\naggregate Shapley value explanation function that minimizes sensitivity.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:56:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bhatt", "Umang", ""], ["Weller", "Adrian", ""], ["Moura", "Jos\u00e9 M. F.", ""]]}, {"id": "2005.00693", "submitter": "Gerard de Melo", "authors": "Abu Shoeb, Gerard de Melo", "title": "Are Emojis Emotional? A Study to Understand the Association between\n  Emojis and Emotions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the growing ubiquity of emojis in language, there is a need for methods\nand resources that shed light on their meaning and communicative role. One\nconspicuous aspect of emojis is their use to convey affect in ways that may\notherwise be non-trivial to achieve. In this paper, we seek to explore the\nconnection between emojis and emotions by means of a new dataset consisting of\nhuman-solicited association ratings. We additionally conduct experiments to\nassess to what extent such associations can be inferred from existing data,\nsuch that similar associations can be predicted for a larger set of emojis. Our\nexperiments show that this succeeds when high-quality word-level information is\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:04:42 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Shoeb", "Abu", ""], ["de Melo", "Gerard", ""]]}, {"id": "2005.00699", "submitter": "Jieyu Zhao", "authors": "Jieyu Zhao, Subhabrata Mukherjee, Saghar Hosseini, Kai-Wei Chang and\n  Ahmed Hassan Awadallah", "title": "Gender Bias in Multilingual Embeddings and Cross-Lingual Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual representations embed words from many languages into a single\nsemantic space such that words with similar meanings are close to each other\nregardless of the language. These embeddings have been widely used in various\nsettings, such as cross-lingual transfer, where a natural language processing\n(NLP) model trained on one language is deployed to another language. While the\ncross-lingual transfer techniques are powerful, they carry gender bias from the\nsource to target languages. In this paper, we study gender bias in multilingual\nembeddings and how it affects transfer learning for NLP applications. We create\na multilingual dataset for bias analysis and propose several ways for\nquantifying bias in multilingual representations from both the intrinsic and\nextrinsic perspectives. Experimental results show that the magnitude of bias in\nthe multilingual representations changes differently when we align the\nembeddings to different target spaces and that the alignment direction can also\nhave an influence on the bias in transfer learning. We further provide\nrecommendations for using the multilingual word representations for downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 04:34:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Zhao", "Jieyu", ""], ["Mukherjee", "Subhabrata", ""], ["Hosseini", "Saghar", ""], ["Chang", "Kai-Wei", ""], ["Awadallah", "Ahmed Hassan", ""]]}, {"id": "2005.00808", "submitter": "Nina Grgi\\'c-Hla\\v{c}a", "authors": "Nina Grgi\\'c-Hla\\v{c}a, Adrian Weller, Elissa M. Redmiles", "title": "Dimensions of Diversity in Human Perceptions of Algorithmic Fairness", "comments": "Presented at the CSCW 2019 workshop on Team and Group Diversity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms are increasingly involved in making decisions that affect human\nlives. Prior work has explored how people believe algorithmic decisions should\nbe made, but there is little understanding of which individual factors relate\nto variance in these beliefs across people. As an increasing emphasis is put on\noversight boards and regulatory bodies, it is important to understand the\nbiases that may affect human judgements about the fairness of algorithms.\nBuilding on factors found in moral foundations theory and egocentric fairness\nliterature, we explore how people's perceptions of fairness relate to their (i)\ndemographics (age, race, gender, political view), and (ii) personal experiences\nwith the algorithmic task being evaluated. Specifically, we study human beliefs\nabout the fairness of using different features in an algorithm designed to\nassist judges in making decisions about granting bail. Our analysis suggests\nthat political views and certain demographic factors, such as age and gender,\nexhibit a significant relation to people's beliefs about fairness.\nAdditionally, we find that people beliefs about the fairness of using\ndemographic features such as age, gender and race, for making bail decisions\nabout others, vary egocentrically: that is they vary depending on their own\nage, gender and race respectively.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 11:59:39 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Grgi\u0107-Hla\u010da", "Nina", ""], ["Weller", "Adrian", ""], ["Redmiles", "Elissa M.", ""]]}, {"id": "2005.01121", "submitter": "Eric Monteiro", "authors": "Thomas {\\O}sterlie and Eric Monteiro", "title": "Digital Sand: The Becoming of Digital Representations", "comments": null, "journal-ref": "Information and Organization, 30(1), 2020, p.100275", "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The versatility of digital technologies relies on a capacity to represent and\nsubsequently manipulate algorithmically selected physical processes, objects or\nqualities in a domain. Organizationally real digital representations are those\nthat, beyond the mere capacity to, actually get woven into everyday work\npractices. Empirically, we draw on a four-year case study of offshore oil and\ngas production. Our case provides a vivid illustration of Internet of Things\n(IoT) based visualizations and data driven predictions characteristic for\nefforts of digitally transforming industrial process and manufacturing\nenterprises. We contribute by identifying and discussing three mechanisms\nthrough which digital representations become organizationally real: (i) noise\nreduction (the strategies and heuristics to filter out signal from noise), (ii)\nmaterial tethering (grounding the digital representations to a corresponding\nphysical measurement) and (iii) triangulating (in the absence of a direct\ncorrespondence, corroborating digital representations relative to other\nrepresentations).\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:01:45 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["\u00d8sterlie", "Thomas", ""], ["Monteiro", "Eric", ""]]}, {"id": "2005.01127", "submitter": "Sebastian Baltes", "authors": "Paul Ralph, Sebastian Baltes, Gianisa Adisaputri, Richard Torkar,\n  Vladimir Kovalenko, Marcos Kalinowski, Nicole Novielli, Shin Yoo, Xavier\n  Devroey, Xin Tan, Minghui Zhou, Burak Turhan, Rashina Hoda, Hideaki Hata,\n  Gregorio Robles, Amin Milani Fard and Rana Alkadhi", "title": "Pandemic Programming: How COVID-19 affects software developers and how\n  their organizations can help", "comments": "34 pages, 7 tables, 5 figures, to appear in Empirical Software\n  Engineering", "journal-ref": "Empirical Software Engineering, 2020", "doi": "10.1007/s10664-020-09875-y", "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context. As a novel coronavirus swept the world in early 2020, thousands of\nsoftware developers began working from home. Many did so on short notice, under\ndifficult and stressful conditions. Objective. This study investigates the\neffects of the pandemic on developers' wellbeing and productivity. Method. A\nquestionnaire survey was created mainly from existing, validated scales and\ntranslated into 12 languages. The data was analyzed using non-parametric\ninferential statistics and structural equation modeling. Results. The\nquestionnaire received 2225 usable responses from 53 countries. Factor analysis\nsupported the validity of the scales and the structural model achieved a good\nfit (CFI = 0.961, RMSEA = 0.051, SRMR = 0.067). Confirmatory results include:\n(1) the pandemic has had a negative effect on developers' wellbeing and\nproductivity; (2) productivity and wellbeing are closely related; (3) disaster\npreparedness, fear related to the pandemic and home office ergonomics all\naffect wellbeing or productivity. Exploratory analysis suggests that: (1)\nwomen, parents and people with disabilities may be disproportionately affected;\n(2) different people need different kinds of support. Conclusions. To improve\nemployee productivity, software companies should focus on maximizing employee\nwellbeing and improving the ergonomics of employees' home offices. Women,\nparents and disabled persons may require extra support.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:18:46 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 11:50:44 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 10:32:02 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ralph", "Paul", ""], ["Baltes", "Sebastian", ""], ["Adisaputri", "Gianisa", ""], ["Torkar", "Richard", ""], ["Kovalenko", "Vladimir", ""], ["Kalinowski", "Marcos", ""], ["Novielli", "Nicole", ""], ["Yoo", "Shin", ""], ["Devroey", "Xavier", ""], ["Tan", "Xin", ""], ["Zhou", "Minghui", ""], ["Turhan", "Burak", ""], ["Hoda", "Rashina", ""], ["Hata", "Hideaki", ""], ["Robles", "Gregorio", ""], ["Fard", "Amin Milani", ""], ["Alkadhi", "Rana", ""]]}, {"id": "2005.01224", "submitter": "Yixuan Pan", "authors": "Yixuan Pan, Aref Darzi, Aliakbar Kabiri, Guangchen Zhao, Weiyu Luo,\n  Chenfeng Xiong, Lei Zhang", "title": "Quantifying human mobility behavior changes in response to\n  non-pharmaceutical interventions during the COVID-19 outbreak in the United\n  States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever since the first case of the novel coronavirus disease (COVID-19) was\nconfirmed in Wuhan, China, social distancing has been promoted worldwide,\nincluding the United States. It is one of the major community mitigation\nstrategies, also known as non-pharmaceutical interventions. However, our\nunderstanding is remaining limited in how people practice social distancing. In\nthis study, we construct a Social Distancing Index (SDI) to evaluate people's\nmobility pattern changes along with the spread of COVID-19. We utilize an\nintegrated dataset of mobile device location data for the contiguous United\nStates plus Alaska and Hawaii over a 100-day period from January 1, 2020 to\nApril 9, 2020. The major findings are: 1) the declaration of the national\nemergency concerning the COVID-19 outbreak greatly encouraged social distancing\nand the mandatory stay-at-home orders in most states further strengthened the\npractice; 2) the states with more confirmed cases have taken more active and\ntimely responses in practicing social distancing; 3) people in the states with\nfewer confirmed cases did not pay much attention to maintaining social\ndistancing and some states, e.g., Wyoming, North Dakota, and Montana, already\nbegan to practice less social distancing despite the high increasing speed of\nconfirmed cases; 4) some counties with the highest infection rates are not\nperforming much social distancing, e.g., Randolph County and Dougherty County\nin Georgia, and some counties began to practice less social distancing right\nafter the increasing speed of confirmed cases went down, e.g., in Blaine\nCounty, Idaho, which may be dangerous as well.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 00:59:28 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Pan", "Yixuan", ""], ["Darzi", "Aref", ""], ["Kabiri", "Aliakbar", ""], ["Zhao", "Guangchen", ""], ["Luo", "Weiyu", ""], ["Xiong", "Chenfeng", ""], ["Zhang", "Lei", ""]]}, {"id": "2005.01263", "submitter": "Yang Cao", "authors": "Yang Cao, Yonghui Xiao, Shun Takagi, Li Xiong, Masatoshi Yoshikawa,\n  Yilin Shen, Jinfei Liu, Hongxia Jin, and Xiaofeng Xu", "title": "PGLP: Customizable and Rigorous Location Privacy through Policy Graph", "comments": "accepted in the 25th European Symposium on Research in Computer\n  Security (ESORICS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Location privacy has been extensively studied in the literature. However,\nexisting location privacy models are either not rigorous or not customizable,\nwhich limits the trade-off between privacy and utility in many real-world\napplications. To address this issue, we propose a new location privacy notion\ncalled PGLP, i.e., \\textit{Policy Graph based Location Privacy}, providing a\nrich interface to release private locations with customizable and rigorous\nprivacy guarantee. First, we design the privacy metrics of PGLP by extending\ndifferential privacy. Specifically, we formalize a user's location privacy\nrequirements using a \\textit{location policy graph}, which is expressive and\ncustomizable. Second, we investigate how to satisfy an arbitrarily given\nlocation policy graph under adversarial knowledge. We find that a location\npolicy graph may not always be viable and may suffer \\textit{location exposure}\nwhen the attacker knows the user's mobility pattern. We propose efficient\nmethods to detect location exposure and repair the policy graph with optimal\nutility. Third, we design a private location trace release framework that\npipelines the detection of location exposure, policy graph repair, and private\ntrajectory release with customizable and rigorous location privacy. Finally, we\nconduct experiments on real-world datasets to verify the effectiveness of the\nprivacy-utility trade-off and the efficiency of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 04:25:59 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 15:16:37 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Cao", "Yang", ""], ["Xiao", "Yonghui", ""], ["Takagi", "Shun", ""], ["Xiong", "Li", ""], ["Yoshikawa", "Masatoshi", ""], ["Shen", "Yilin", ""], ["Liu", "Jinfei", ""], ["Jin", "Hongxia", ""], ["Xu", "Xiaofeng", ""]]}, {"id": "2005.01442", "submitter": "Almagul Kondybayeva", "authors": "Almagul Baurzhanovna Kondybayeva", "title": "Interactive distributed cloud-based web-server systems for the smart\n  healthcare industry", "comments": "This work is dedicated to the questions of the contemporary medical\n  image visualization, the architecture design of the cloud server systems and\n  the using of methods for the .DICOM data representation for the distributed\n  smart healthcare industry systems. The work is done as a part of the PhD\n  thesis of the author for non-profit/non-commercial, educational/research only\n  reasons under the MIT License", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The work aims to investigate the possible contemporary interactive cloud\nbased solutions in the fields of the applied medicine for the smart Healthcare\nas the data visualization open-source free system distributed under the MIT\nlicense. A comparative study of a number of the well-known implementations of\nthe Ray Casting algorithms was studied. A new method of numerical calculus is\nproposed for calculating the volume -- the method of spheres, as well as a\nproposal for paralleling the algorithm on graphic accelerators in a linearly\nhomogeneous computing environment using the block decomposition methods. For\nthe artifacts control -- algorithm of the cubic interpolation was used. The\ncloud server architecture was proposed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 21:58:03 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kondybayeva", "Almagul Baurzhanovna", ""]]}, {"id": "2005.01459", "submitter": "Aakash Gautam", "authors": "Aakash Gautam, Deborah Tatar, Steve Harrison", "title": "Crafting, Communality, and Computing: Building on Existing Strengths To\n  Support a Vulnerable Population", "comments": "14 pages, 1 figure. In Proceedings of the 2020 CHI Conference on\n  Human Factors in Computing Systems (CHI'20)", "journal-ref": null, "doi": "10.1145/3313831.3376647", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In Nepal, sex-trafficking survivors and the organizations that support them\nhave limited resources to assist the survivors in their on-going journey\ntowards reintegration. We take an asset-based approach wherein we identify and\nbuild on the strengths possessed by such groups. In this work, we present\nreflections from introducing a voice-annotated web application to a group of\nsurvivors. The web application tapped into and built upon two elements of\npre-existing strengths possessed by the survivors -- the social bond between\nthem and knowledge of crafting as taught to them by the organization. Our\nfindings provide insight into the array of factors influencing how the\nsurvivors act in relation to one another as they created novel use practices\nand adapted the technology. Experience with the application seemed to open\nknowledge of computing as a potential source of strength. Finally, we\narticulate three design desiderata that could help promote communal spaces:\nmake activity perceptible to the group, create appropriable steps, and build in\nfun choices.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:17:06 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Gautam", "Aakash", ""], ["Tatar", "Deborah", ""], ["Harrison", "Steve", ""]]}, {"id": "2005.01503", "submitter": "Philip Kulp", "authors": "Philip H. Kulp, Nagi Mei", "title": "An Integrated Framework for Sensing Radio Frequency Spectrum Attacks on\n  Medical Delivery Drones", "comments": "7 pages, 1 figures, 5 tables", "journal-ref": null, "doi": "10.1109/SMC42975.2020.9283478", "report-no": null, "categories": "cs.CY cs.CR cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drone susceptibility to jamming or spoofing attacks of GPS, RF, Wi-Fi, and\noperator signals presents a danger to future medical delivery systems. A\ndetection framework capable of sensing attacks on drones could provide the\ncapability for active responses. The identification of interference attacks has\napplicability in medical delivery, disaster zone relief, and FAA enforcement\nagainst illegal jamming activities. A gap exists in the literature for solo or\nswarm-based drones to identify radio frequency spectrum attacks. Any\nnon-delivery specific function, such as attack sensing, added to a drone\ninvolves a weight increase and additional complexity; therefore, the value must\nexceed the disadvantages. Medical delivery, high-value cargo, and disaster zone\napplications could present a value proposition which overcomes the additional\ncosts. The paper examines types of attacks against drones and describes a\nframework for designing an attack detection system with active response\ncapabilities for improving the reliability of delivery and other medical\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:13:35 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Kulp", "Philip H.", ""], ["Mei", "Nagi", ""]]}, {"id": "2005.01539", "submitter": "Spyridon Samothrakis", "authors": "Spyridon Samothrakis", "title": "Open Loop In Natura Economic Planning", "comments": "10 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The debate between the optimal way of allocating societal surplus (i.e.\nproducts and services) has been raging, in one form or another, practically\nforever; following the collapse of the Soviet Union in 1991, the market became\nthe only legitimate form of organisation -- there was no other alternative.\nWorking within the tradition of Marx, Leontief, Kantorovich, Beer and\nCockshott, we propose what we deem an automated planning system that aims to\noperate on unit level (e.g., factories and citizens), rather than on aggregate\ndemand and sectors. We explain why it is both a viable and desirable\nalternative to current market conditions and position our solution within\ncurrent societal structures. Our experiments show that it would be trivial to\nplan for up to 50K industrial goods and 5K final goods in commodity hardware.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 14:50:01 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 14:28:48 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Samothrakis", "Spyridon", ""]]}, {"id": "2005.01588", "submitter": "R. Iris Bahar", "authors": "R. Iris Bahar, Alex K. Jones, Srinivas Katkoori, Patrick H. Madden,\n  Diana Marculescu, and Igor L. Markov", "title": "Workshops on Extreme Scale Design Automation (ESDA) Challenges and\n  Opportunities for 2025 and Beyond", "comments": "A Computing Community Consortium (CCC) workshop report, 32 pages", "journal-ref": null, "doi": null, "report-no": "ccc2014report_1", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated circuits and electronic systems, as well as design technologies,\nare evolving at a great rate -- both quantitatively and qualitatively. Major\ndevelopments include new interconnects and switching devices with atomic-scale\nuncertainty, the depth and scale of on-chip integration, electronic\nsystem-level integration, the increasing significance of software, as well as\nmore effective means of design entry, compilation, algorithmic optimization,\nnumerical simulation, pre- and post-silicon design validation, and chip test.\nApplication targets and key markets are also shifting substantially from\ndesktop CPUs to mobile platforms to an Internet-of-Things infrastructure. In\nlight of these changes in electronic design contexts and given EDA's\nsignificant dependence on such context, the EDA community must adapt to these\nchanges and focus on the opportunities for research and commercial success. The\nCCC workshop series on Extreme-Scale Design Automation, organized with the\nsupport of ACM SIGDA, studied challenges faced by the EDA community as well as\nnew and exciting opportunities currently available. This document represents a\nsummary of the findings from these meetings.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:58:09 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bahar", "R. Iris", ""], ["Jones", "Alex K.", ""], ["Katkoori", "Srinivas", ""], ["Madden", "Patrick H.", ""], ["Marculescu", "Diana", ""], ["Markov", "Igor L.", ""]]}, {"id": "2005.01790", "submitter": "Corrado Monti", "authors": "Joan Massachs, Corrado Monti, Gianmarco De Francisci Morales,\n  Francesco Bonchi", "title": "Roots of Trumpism: Homophily and Social Feedback in Donald Trump Support\n  on Reddit", "comments": "10 pages. Published at WebSci20", "journal-ref": "Proceedings of the 12th ACM Conference on Web Science (WebSci\n  2020)", "doi": "10.1145/3394231.3397894", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the emergence of support for Donald Trump in Reddit's political\ndiscussion. With almost 800k subscribers, \"r/The_Donald\" is one of the largest\ncommunities on Reddit, and one of the main hubs for Trump supporters. It was\ncreated in 2015, shortly after Donald Trump began his presidential campaign. By\nusing only data from 2012, we predict the likelihood of being a supporter of\nDonald Trump in 2016, the year of the last US presidential elections. To\ncharacterize the behavior of Trump supporters, we draw from three different\nsociological hypotheses: homophily, social influence, and social feedback. We\noperationalize each hypothesis as a set of features for each user, and train\nclassifiers to predict their participation in r/The_Donald.\n  We find that homophily-based and social feedback-based features are the most\npredictive signals. Conversely, we do not observe a strong impact of social\ninfluence mechanisms. We also perform an introspection of the best-performing\nmodel to build a \"persona\" of the typical supporter of Donald Trump on Reddit.\nWe find evidence that the most prominent traits include a predominance of\nmasculine interests, a conservative and libertarian political leaning, and\nlinks with politically incorrect and conspiratorial content.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:00:54 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Massachs", "Joan", ""], ["Monti", "Corrado", ""], ["Morales", "Gianmarco De Francisci", ""], ["Bonchi", "Francesco", ""]]}, {"id": "2005.01794", "submitter": "Shriram Krishnamurthi", "authors": "Shriram Krishnamurthi and Emmanuel Schanzer and Joe Gibbs Politz and\n  Benjamin S. Lerner and Kathi Fisler and Sam Dooman", "title": "Data Science as a Route to AI for Middle- and High-School Students", "comments": "Accepted and presented at the \"Teaching AI in K-12\" Symposium, part\n  of the AAAI 2019 Fall Symposium Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bootstrap Project's Data Science curriculum has trained about 100\nteachers who are using it around the country. It is specifically designed to\naid adoption at a wide range of institutions. It emphasizes valuable curricular\ngoals by drawing on both the education literature and on prior experience with\nother computing outreach projects. It embraces \"three P's\" of data-oriented\nthinking: the promise, pitfalls, and perils. This paper briefly describes the\ncurriculum's design, content, and outcomes, and explains its value on the road\nto AI curricula.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 21:17:01 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Krishnamurthi", "Shriram", ""], ["Schanzer", "Emmanuel", ""], ["Politz", "Joe Gibbs", ""], ["Lerner", "Benjamin S.", ""], ["Fisler", "Kathi", ""], ["Dooman", "Sam", ""]]}, {"id": "2005.01799", "submitter": "Alexandru Topirceanu", "authors": "Alexandru Topirceanu", "title": "Electoral Forecasting Using a Novel Temporal Attenuation Model:\n  Predicting the US Presidential Elections", "comments": "Manuscript with 4 figures, 4 tables, 44 references, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electoral forecasting is an ongoing scientific challenge with high social\nimpact, as current data-driven methods try to efficiently combine statistics\nwith economic indices and machine learning. However, recent studies in network\nscience pinpoint towards the importance of temporal characteristics in the\ndiffusion of opinion. As such, we combine concepts of micro-scale opinion\ndynamics and temporal epidemics, and develop a novel macro-scale temporal\nattenuation (TA) model, which uses pre-election poll data to improve\nforecasting accuracy. Our hypothesis is that the timing of publicizing opinion\npolls plays a significant role in how opinion oscillates, especially right\nbefore elections. Thus, we define the momentum of opinion as a temporal\nfunction which bounces up when opinion is injected in a multi-opinion system of\nvoters, and dampens during states of relaxation. We validate TA on survey data\nfrom the US Presidential Elections between 1968-2016, and TA outperforms\nstatistical methods, as well the best pollsters at their time, in 10 out of 13\npresidential elections. We present two different implementations of the TA\nmodel, which accumulate an average forecasting error of 2.8-3.28 points over\nthe 48-year period. Conversely, statistical methods accumulate 7.48 points\nerror, and the best pollsters accumulate 3.64 points. Overall, TA offers\nincreases of 23-37% in forecasting performance compared to the state of the\nart. We show that the effectiveness of TA does not drop when relatively few\npolls are available; moreover, with increasing availability of pre-election\nsurveys, we believe that our TA model will become a reference alongside other\nmodern election forecasting techniques.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 09:21:52 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Topirceanu", "Alexandru", ""]]}, {"id": "2005.01803", "submitter": "Haewoon Kwak", "authors": "Haewoon Kwak and Jisun An and Yong-Yeol Ahn", "title": "A Systematic Media Frame Analysis of 1.5 Million New York Times Articles\n  from 2000 to 2017", "comments": "10pages, WebSci'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Framing is an indispensable narrative device for news media because even the\nsame facts may lead to conflicting understandings if deliberate framing is\nemployed. Therefore, identifying media framing is a crucial step to\nunderstanding how news media influence the public. Framing is, however,\ndifficult to operationalize and detect, and thus traditional media framing\nstudies had to rely on manual annotation, which is challenging to scale up to\nmassive news datasets. Here, by developing a media frame classifier that\nachieves state-of-the-art performance, we systematically analyze the media\nframes of 1.5 million New York Times articles published from 2000 to 2017. By\nexamining the ebb and flow of media frames over almost two decades, we show\nthat short-term frame abundance fluctuation closely corresponds to major\nevents, while there also exist several long-term trends, such as the gradually\nincreasing prevalence of the ``Cultural identity'' frame. By examining specific\ntopics and sentiments, we identify characteristics and dynamics of each frame.\nFinally, as a case study, we delve into the framing of mass shootings,\nrevealing three major framing patterns. Our scalable, computational approach to\nmassive news datasets opens up new pathways for systematic media framing\nstudies.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 19:25:39 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Kwak", "Haewoon", ""], ["An", "Jisun", ""], ["Ahn", "Yong-Yeol", ""]]}, {"id": "2005.01868", "submitter": "Massimo La Morgia", "authors": "Luca Bufalieri, Massimo La Morgia, Alessandro Mei, Julinda Stefa", "title": "GDPR: When the Right to Access Personal Data Becomes a Threat", "comments": "Accepted for publication at IEEE INTERNATIONAL CONFERENCE ON WEB\n  SERVICES (ICWS) 2020", "journal-ref": null, "doi": "10.1109/ICWS49710.2020.00017", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After one year since the entry into force of the GDPR, all web sites and data\ncontrollers have updated their procedures to store users' data. The GDPR does\nnot only cover how and what data should be saved by the service providers, but\nit also guarantees an easy way to know what data are collected and the freedom\nto export them.\n  In this paper, we carry out a comprehensive study on the right to access data\nprovided by Article 15 of the GDPR. We examined more than 300 data controllers,\nperforming for each of them a request to access personal data. We found that\nalmost each data controller has a slightly different procedure to fulfill the\nrequest and several ways to provide data back to the user, from a structured\nfile like CSV to a screenshot of the monitor. We measure the time needed to\ncomplete the access data request and the completeness of the information\nprovided. After this phase of data gathering, we analyze the authentication\nprocess followed by the data controllers to establish the identity of the\nrequester. We find that 50.4\\% of the data controllers that handled the\nrequest, even if they store the data in compliance with the GDPR, have flaws in\nthe procedure of identifying the users or in the phase of sending the data,\nexposing the users to new threats. With the undesired and surprising result\nthat the GDPR, in its present deployment, has actually decreased the privacy of\nthe users of web services.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 22:01:46 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Bufalieri", "Luca", ""], ["La Morgia", "Massimo", ""], ["Mei", "Alessandro", ""], ["Stefa", "Julinda", ""]]}, {"id": "2005.01924", "submitter": "Jichang Zhao", "authors": "Rui Fan, Ke Xu and Jichang Zhao", "title": "Weak ties strengthen anger contagion in social media", "comments": "This article draws partly from our previous submission\n  arXiv:1608.03656 and is essentially updated with new insights", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing evidence suggests that, similar to face-to-face communications,\nhuman emotions also spread in online social media. However, the mechanisms\nunderlying this emotion contagion, for example, whether different feelings\nspread in unlikely ways or how the spread of emotions relates to the social\nnetwork, is rarely investigated. Indeed, because of high costs and\nspatio-temporal limitations, explorations of this topic are challenging using\nconventional questionnaires or controlled experiments. Because they are\ncollection points for natural affective responses of massive individuals,\nonline social media sites offer an ideal proxy for tackling this issue from the\nperspective of computational social science. In this paper, based on the\nanalysis of millions of tweets in Weibo, surprisingly, we find that anger\ntravels easily along weaker ties than joy, meaning that it can infiltrate\ndifferent communities and break free of local traps because strangers share\nsuch content more often. Through a simple diffusion model, we reveal that\nweaker ties speed up anger by applying both propagation velocity and coverage\nmetrics. To the best of our knowledge, this is the first time that quantitative\nlong-term evidence has been presented that reveals a difference in the\nmechanism by which joy and anger are disseminated. With the extensive\nproliferation of weak ties in booming social media, our results imply that the\ncontagion of anger could be profoundly strengthened to globalize its negative\nimpact.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 02:57:51 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Fan", "Rui", ""], ["Xu", "Ke", ""], ["Zhao", "Jichang", ""]]}, {"id": "2005.01980", "submitter": "Floriana Gargiulo", "authors": "Sylvie Huet1, Floriana Gargiulo, and Felicia Pratto", "title": "Can gender inequality be created without inter-group discrimination?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding human societies requires knowing how they develop gender\nhierarchies which are ubiquitous. We test whether a simple agent-based dynamic\nprocess could create gender inequality. Relying on evidence of gendered status\nconcerns, self-construals, and cognitive habits, our model included a gender\ndifference in how responsive male-like and female-like agents are to others'\nopinions about the level of esteem for someone. We simulate a population who\ninteract in pairs of randomly selected agents to influence each other about\ntheir esteem judgments of self and others. Half the agents are more influenced\nby their relative status rank during the interaction than the others. Without\nprejudice, stereotypes, segregation, or categorization, our model produces\ninter-group inequality of self-esteem and status that is stable, consensual,\nand exhibits characteristics of glass ceiling effects. Outcomes are not\naffected by relative group size. We discuss implications for group orientation\nto dominance and individuals' motivations to exchange.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 07:33:27 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Huet1", "Sylvie", ""], ["Gargiulo", "Floriana", ""], ["Pratto", "Felicia", ""]]}, {"id": "2005.02031", "submitter": "Matthew Gadd", "authors": "Matthew Gadd, Daniele De Martini, Letizia Marchegiani, Paul Newman,\n  Lars Kunze", "title": "Sense-Assess-eXplain (SAX): Building Trust in Autonomous Vehicles in\n  Challenging Real-World Driving Scenarios", "comments": "accepted for publication at the IEEE Intelligent Vehicles Symposium\n  (IV), Workshop on Ensuring and Validating Safety for Automated Vehicles\n  (EVSAV), 2020, project URL:\n  https://ori.ox.ac.uk/projects/sense-assess-explain-sax", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses ongoing work in demonstrating research in mobile\nautonomy in challenging driving scenarios. In our approach, we address\nfundamental technical issues to overcome critical barriers to assurance and\nregulation for large-scale deployments of autonomous systems. To this end, we\npresent how we build robots that (1) can robustly sense and interpret their\nenvironment using traditional as well as unconventional sensors; (2) can assess\ntheir own capabilities; and (3), vitally in the purpose of assurance and trust,\ncan provide causal explanations of their interpretations and assessments. As it\nis essential that robots are safe and trusted, we design, develop, and\ndemonstrate fundamental technologies in real-world applications to overcome\ncritical barriers which impede the current deployment of robots in economically\nand socially important areas. Finally, we describe ongoing work in the\ncollection of an unusual, rare, and highly valuable dataset.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 09:54:58 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Gadd", "Matthew", ""], ["De Martini", "Daniele", ""], ["Marchegiani", "Letizia", ""], ["Newman", "Paul", ""], ["Kunze", "Lars", ""]]}, {"id": "2005.02111", "submitter": "Daniel Kunz", "authors": "Tobias K\\\"olbel and Daniel Kunz", "title": "Mechanisms of intermediary platforms", "comments": "Network Effects, Platform Economics, Matchmakers, Marketplaces,\n  Intermediaries, Platform Monopolies, Coopetition, Economy of Things (EoT),\n  Decentralized Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current digital age of the Internet, with ever-growing networks and\ndata-driven business models, digital platforms and especially marketplaces are\nbecoming increasingly important. These platforms focus primarily on digital\nbusinesses by offering services that bring together consumers and producers.\nDue to added value created for consumers, the profit-driven operators of these\nplatforms Matchmakers are extremely successful and have come to dominate their\nrespective markets. The aim of this article is to understand how Matchmakers\nand coordination networks gain market dominance. The following sections will\ntake a closer look at network and coordination effects as well as intermediary\nplatform mechanisms and entailing disadvantages for users. Considering\nstrategic and business challenges, we suggest a possible solution and strategy\nto avoid dependencies on individual players in the digital economy. We present\na cooperative approach towards a fair and open Economy of Things (EoT) based on\ndecentralized technologies.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 12:55:57 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["K\u00f6lbel", "Tobias", ""], ["Kunz", "Daniel", ""]]}, {"id": "2005.02342", "submitter": "Ryan Steed", "authors": "Ryan Steed, Benjamin Williams", "title": "Heuristic-Based Weak Learning for Automated Decision-Making", "comments": "5 pages, 3 figures. Camera-ready version for Participatory Approaches\n  to Machine Learning @ ICML 2020. Last updated Dec. 2020: fixed bug in Figure\n  3 - \"always intervene\" heuristic should be \"never intervene.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning systems impact many stakeholders and groups of users, often\ndisparately. Prior studies have reconciled conflicting user preferences by\naggregating a high volume of manually labeled pairwise comparisons, but this\ntechnique may be costly or impractical. How can we lower the barrier to\nparticipation in algorithm design? Instead of creating a simplified labeling\ntask for a crowd, we suggest collecting ranked decision-making heuristics from\na focused sample of affected users. With empirical data from two use cases, we\nshow that our weak learning approach, which requires little to no manual\nlabeling, agrees with participants' pairwise choices nearly as often as fully\nsupervised approaches.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 17:22:52 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 18:53:24 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2020 22:55:01 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Steed", "Ryan", ""], ["Williams", "Benjamin", ""]]}, {"id": "2005.02434", "submitter": "Randal E. Bryant", "authors": "Randy Bryant, Mark Hill, Tom Kazior, Daniel Lee, Jie Liu, Klara\n  Nahrstedt, Vijay Narayanan, Jan Rabaey, Hava Siegelmann, Naresh Shanbhag,\n  Naveen Verma, and H.-S. Philip Wong", "title": "Nanotechnology-inspired Information Processing Systems of the Future", "comments": "A Computing Community Consortium (CCC) workshop report, 18 pages", "journal-ref": null, "doi": null, "report-no": "ccc2016report_3", "categories": "cs.CY cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nanoscale semiconductor technology has been a key enabler of the computing\nrevolution. It has done so via advances in new materials and manufacturing\nprocesses that resulted in the size of the basic building block of computing\nsystems - the logic switch and memory devices - being reduced into the\nnanoscale regime. Nanotechnology has provided increased computing functionality\nper unit volume, energy, and cost. In order for computing systems to continue\nto deliver substantial benefits for the foreseeable future to society at large,\nit is critical that the very notion of computing be examined in the light of\nnanoscale realities. In particular, one needs to ask what it means to compute\nwhen the very building block - the logic switch - no longer exhibits the level\nof determinism required by the von Neumann architecture. There needs to be a\nsustained and heavy investment in a nation-wide Vertically Integrated\nSemiconductor Ecosystem (VISE). VISE is a program in which research and\ndevelopment is conducted seamlessly across the entire compute stack - from\napplications, systems and algorithms, architectures, circuits and nanodevices,\nand materials. A nation-wide VISE provides clear strategic advantages in\nensuring the US's global superiority in semiconductors. First, a VISE provides\nthe highest quality seed-corn for nurturing transformative ideas that are\ncritically needed today in order for nanotechnology-inspired computing to\nflourish. It does so by dramatically opening up new areas of semiconductor\nresearch that are inspired and driven by new application needs. Second, a VISE\ncreates a very high barrier to entry from foreign competitors because it is\nextremely hard to establish, and even harder to duplicate.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:52:25 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Bryant", "Randy", ""], ["Hill", "Mark", ""], ["Kazior", "Tom", ""], ["Lee", "Daniel", ""], ["Liu", "Jie", ""], ["Nahrstedt", "Klara", ""], ["Narayanan", "Vijay", ""], ["Rabaey", "Jan", ""], ["Siegelmann", "Hava", ""], ["Shanbhag", "Naresh", ""], ["Verma", "Naveen", ""], ["Wong", "H. -S. Philip", ""]]}, {"id": "2005.02442", "submitter": "Jian Cao", "authors": "Jian Cao, Nicholas Adams-Cohen, R. Michael Alvarez", "title": "Reliable and Efficient Long-Term Social Media Monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media data is now widely used by many academic researchers. However,\nlong-term social media data collection projects, which most typically involve\ncollecting data from public-use APIs, often encounter issues when relying on\nlocal-area network servers (LANs) to collect high-volume streaming social media\ndata over long periods of time. In this technical report, we present a\ncloud-based data collection, pre-processing, and archiving infrastructure, and\nargue that this system mitigates or resolves the problems most typically\nencountered when running social media data collection projects on LANs at\nminimal cloud-computing costs. We show how this approach works in different\ncloud computing architectures, and how to adapt the method to collect streaming\ndata from other social media platforms.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 19:04:56 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 23:19:00 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 18:56:30 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Cao", "Jian", ""], ["Adams-Cohen", "Nicholas", ""], ["Alvarez", "R. Michael", ""]]}, {"id": "2005.02443", "submitter": "Julio Reis", "authors": "Julio C. S. Reis, Philipe de Freitas Melo, Kiran Garimella, Jussara M.\n  Almeida, Dean Eckles, Fabr\\'icio Benevenuto", "title": "A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections", "comments": "7 pages. This is a preprint version of an accepted paper on ICWSM'20.\n  Please, consider to cite the conference version instead of this one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 19:08:26 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Reis", "Julio C. S.", ""], ["Melo", "Philipe de Freitas", ""], ["Garimella", "Kiran", ""], ["Almeida", "Jussara M.", ""], ["Eckles", "Dean", ""], ["Benevenuto", "Fabr\u00edcio", ""]]}, {"id": "2005.02489", "submitter": "Tichakunda Mangono", "authors": "Tichakunda Mangono (1), Peter Smittenaar (1), Yael Caplan (1), Vincent\n  S. Huang (1), Staci Sutermaster (1), Hannah Kemp (1) and Sema K. Sgaier\n  (1,2,3) ((1) Surgo Foundation, Washington DC, USA, (2) Department of Global\n  Health & Population, Harvard T.H. Chan School of Public Health, Boston MA,\n  USA, (3) Department of Global Health, University of Washington, Seattle, WA,\n  USA)", "title": "The Pace and Pulse of the Fight against Coronavirus across the US, A\n  Google Trends Approach", "comments": "19 pages with 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The coronavirus pandemic is impacting our lives at unprecedented speed and\nscale - including how we eat and work, what we worry about, how much we move,\nand our ability to earn. Google Trends can be used as a proxy for what people\nare thinking, needing, and planning. We use it to provide both insights into,\nand potential indicators of, important changes in information-seeking patterns\nduring pandemics like COVID-19. Key questions we address are: (1) What is the\nrelationship between the coronavirus outbreak and internet searches related to\nhealthcare seeking, government support programs, media sources of different\nideologies, planning around social activities, travel, and food, and new\ncoronavirus-specific behaviors and concerns?; (2) How does the popularity of\nsearch terms differ across states and regions and can we explain these\ndifferences?; (3) Can we find distinct, tangible search patterns across states\nsuggestive of policy gaps to inform pandemic response? (4) Does Google Trends\ndata correlate with and potentially precede real-life events? We suggest\nstrategic shifts for policy makers to improve the precision and effectiveness\nof non-pharmaceutical interventions (NPIs) and recommend the development of a\nreal-time dashboard as a decision-making tool. Methods used include trend\nanalysis of US search data; geographic analyses of the differences in search\npopularity across US states during March 1st to April 15th, 2020; and Principal\nComponent Analyses (PCA) to extract search patterns across states.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 20:55:45 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Mangono", "Tichakunda", ""], ["Smittenaar", "Peter", ""], ["Caplan", "Yael", ""], ["Huang", "Vincent S.", ""], ["Sutermaster", "Staci", ""], ["Kemp", "Hannah", ""], ["Sgaier", "Sema K.", ""]]}, {"id": "2005.02729", "submitter": "Mingyi Liu", "authors": "Mingyi Liu, Zhiying Tu, Xiaofei Xu, and Zhongjie Wang", "title": "Community-Based Service Ecosystem Evolution Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prosperity of services and the frequent interaction between services\ncontribute to the formation of the service ecosystem. Service ecosystem is a\ncomplex dynamic system with continuous evolution. Service providers voluntarily\nor compulsorily participate in this evolutionary process and face great\nopportunities and challenges. Existing studies on service ecosystem evolution\nare more about facilitating programmers to use services and have achieved\nremarkable results. However, the exploration of service ecosystem evolution\nfrom the business level is still insufficient. To make up this deficiency, in\nthis paper, we present a method for analyzing service ecosystem evolution\npatterns from the perspective of the service community. Firstly, we train a\nservice community evolution prediction model based on the community evolution\nsequences. Secondly, we explain the prediction model, showing how different\nfactors affect the evolution of the service community. Finally, using the\ninterpretable predictions and prior knowledge, we present how to assist service\nproviders in making business decisions. Experiments on real-world data show\nthat this work can indeed provide business-level insights into service\necosystem evolution. Additionally, all the data and well-documented code used\nin this paper have been fully open source.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 11:00:04 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Liu", "Mingyi", ""], ["Tu", "Zhiying", ""], ["Xu", "Xiaofei", ""], ["Wang", "Zhongjie", ""]]}, {"id": "2005.02795", "submitter": "Mojtaba Noghabaei", "authors": "Mojtaba Noghabaei, Arsalan Heydarian, Vahid Balali, and Kevin Han", "title": "A Survey Study to Understand Industry Vision for Virtual and Augmented\n  Reality Applications in Design and Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With advances in Building Information Modeling (BIM), Virtual Reality (VR)\nand Augmented Reality (AR) technologies have many potential applications in the\nArchitecture, Engineering, and Construction (AEC) industry. However, the AEC\nindustry, relative to other industries, has been slow in adopting AR/VR\ntechnologies, partly due to lack of feasibility studies examining the actual\ncost of implementation versus an increase in profit. The main objectives of\nthis paper are to understand the industry trends in adopting AR/VR technologies\nand identifying gaps between AEC research and industry practices. The\nidentified gaps can lead to opportunities for developing new tools and finding\nnew use cases. To achieve these goals, two rounds of a survey at two different\ntime periods (a year apart) were conducted. Responses from 158 industry experts\nand researchers were analyzed to assess the current state, growth, and saving\nopportunities for AR/VR technologies for the AEC industry. The authors used\nt-test for hypothesis testing. The findings show a significant increase in\nAR/VR utilization in the AEC industry over the past year from 2017 to 2018. The\nindustry experts also anticipate strong growth in the use of AR/VR technologies\nover the next 5 to 10 years.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:16:05 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Noghabaei", "Mojtaba", ""], ["Heydarian", "Arsalan", ""], ["Balali", "Vahid", ""], ["Han", "Kevin", ""]]}, {"id": "2005.02928", "submitter": "Christos Diou", "authors": "Christos Diou, Ioannis Sarafis, Vasileios Papapanagiotou, Leonidas\n  Alagialoglou, Irini Lekka, Dimitrios Filos, Leandros Stefanopoulos, Vasileios\n  Kilintzis, Christos Maramis, Youla Karavidopoulou, Nikos Maglaveras, Ioannis\n  Ioakimidis, Evangelia Charmandari, Penio Kassari, Athanasia Tragomalou,\n  Monica Mars, Thien-An Ngoc Nguyen, Tahar Kechadi, Shane O' Donnell, Gerardine\n  Doyle, Sarah Browne, Grace O' Malley, Rachel Heimeier, Katerina Riviou,\n  Evangelia Koukoula, Konstantinos Filis, Maria Hassapidou, Ioannis Pagkalos,\n  Daniel Ferri, Isabel P\\'erez and Anastasios Delopoulos", "title": "BigO: A public health decision support system for measuring obesogenic\n  behaviors of children in relation to their local environment", "comments": "Accepted version to be published in 2020, 42nd Annual International\n  Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),\n  Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obesity is a complex disease and its prevalence depends on multiple factors\nrelated to the local socioeconomic, cultural and urban context of individuals.\nMany obesity prevention strategies and policies, however, are horizontal\nmeasures that do not depend on context-specific evidence. In this paper we\npresent an overview of BigO (http://bigoprogram.eu), a system designed to\ncollect objective behavioral data from children and adolescent populations as\nwell as their environment in order to support public health authorities in\nformulating effective, context-specific policies and interventions addressing\nchildhood obesity. We present an overview of the data acquisition, indicator\nextraction, data exploration and analysis components of the BigO system, as\nwell as an account of its preliminary pilot application in 33 schools and 2\nclinics in four European countries, involving over 4,200 participants.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 16:06:54 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Diou", "Christos", ""], ["Sarafis", "Ioannis", ""], ["Papapanagiotou", "Vasileios", ""], ["Alagialoglou", "Leonidas", ""], ["Lekka", "Irini", ""], ["Filos", "Dimitrios", ""], ["Stefanopoulos", "Leandros", ""], ["Kilintzis", "Vasileios", ""], ["Maramis", "Christos", ""], ["Karavidopoulou", "Youla", ""], ["Maglaveras", "Nikos", ""], ["Ioakimidis", "Ioannis", ""], ["Charmandari", "Evangelia", ""], ["Kassari", "Penio", ""], ["Tragomalou", "Athanasia", ""], ["Mars", "Monica", ""], ["Nguyen", "Thien-An Ngoc", ""], ["Kechadi", "Tahar", ""], ["Donnell", "Shane O'", ""], ["Doyle", "Gerardine", ""], ["Browne", "Sarah", ""], ["Malley", "Grace O'", ""], ["Heimeier", "Rachel", ""], ["Riviou", "Katerina", ""], ["Koukoula", "Evangelia", ""], ["Filis", "Konstantinos", ""], ["Hassapidou", "Maria", ""], ["Pagkalos", "Ioannis", ""], ["Ferri", "Daniel", ""], ["P\u00e9rez", "Isabel", ""], ["Delopoulos", "Anastasios", ""]]}, {"id": "2005.02954", "submitter": "Benajmin Radford J", "authors": "Benjamin J. Radford", "title": "Multitask Models for Supervised Protests Detection in Texts", "comments": null, "journal-ref": "Working Notes of CLEF 2019 (2019)", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CLEF 2019 ProtestNews Lab tasks participants to identify text relating to\npolitical protests within larger corpora of news data. Three tasks include\narticle classification, sentence detection, and event extraction. I apply\nmultitask neural networks capable of producing predictions for two and three of\nthese tasks simultaneously. The multitask framework allows the model to learn\nrelevant features from the training data of all three tasks. This paper\ndemonstrates performance near or above the reported state-of-the-art for\nautomated political event coding though noted differences in research design\nmake direct comparisons difficult.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:00:46 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Radford", "Benjamin J.", ""]]}, {"id": "2005.02955", "submitter": "Akhila Sri Manasa Venigalla", "authors": "Akhila Sri Manasa Venigalla, Dheeraj Vagavolu and Sridhar Chimalakonda", "title": "Mood of India During Covid-19 -- An Interactive Web Portal Based on\n  Emotion Analysis of Twitter Data", "comments": "13 pages, 4 figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The severe outbreak of Covid-19 pandemic has affected many countries across\nthe world, and disrupted the day to day activities of many people. During such\noutbreaks, understanding the emotional state of citizens of a country could be\nof interest to various organizations to carry out tasks and to take necessary\nmeasures. Several studies have been performed on data available on various\nsocial media platforms and websites to understand the emotions of people\nagainst many events, inclusive of Covid-19, across the world. Twitter and other\nsocial media platforms have been bridging the gap between the citizens and\ngovernment in various countries and are of more prominence in India. Sentiment\nAnalysis of posts on twitter is observed to accurately reveal the sentiments.\nAnalysing real time posts on twitter in India during Covid-19, could help in\nidentifying the mood of the nation. However, most of the existing studies\nrelated to Covid-19, on twitter and other social media platforms are performed\non data posted during a specific interval. We are not aware of any research\nthat identifies emotional state of India on a daily basis. Hence, we present a\nweb portal that aims to display mood of India during Covid-19, based on real\ntime twitter data. This portal also enables users to select date range,\nspecific date and state in India to display mood of people belonging to the\nspecified region, on the specified date or during the specified date range.\nAlso, the number of Covid-19 cases and mood of people at specific cities and\nstates on specific dates is visualized on the country map. As of May 6 2020,\nthe web portal has about 194370 tweets, and each of these tweets are classified\ninto seven categories that include six basic emotions and a neutral category. A\nlist of Trigger Events are also specified, to allow users to view the mood of\nIndia on specific events happening in the country during Covid-19.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:04:43 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Venigalla", "Akhila Sri Manasa", ""], ["Vagavolu", "Dheeraj", ""], ["Chimalakonda", "Sridhar", ""]]}, {"id": "2005.02966", "submitter": "Benajmin Radford J", "authors": "Benjamin J. Radford", "title": "Seeing the Forest and the Trees: Detection and Cross-Document\n  Coreference Resolution of Militarized Interstate Disputes", "comments": null, "journal-ref": "Workshop Proceedings of AESPEN at LREC 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous efforts to automate the detection of social and political events in\ntext have primarily focused on identifying events described within single\nsentences or documents. Within a corpus of documents, these automated systems\nare unable to link event references -- recognize singular events across\nmultiple sentences or documents. A separate literature in computational\nlinguistics on event coreference resolution attempts to link known events to\none another within (and across) documents. I provide a data set for evaluating\nmethods to identify certain political events in text and to link related texts\nto one another based on shared events. The data set, Headlines of War, is built\non the Militarized Interstate Disputes data set and offers headlines classified\nby dispute status and headline pairs labeled with coreference indicators.\nAdditionally, I introduce a model capable of accomplishing both tasks. The\nmulti-task convolutional neural network is shown to be capable of recognizing\nevents and event coreferences given the headlines' texts and publication dates.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:20:14 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Radford", "Benjamin J.", ""]]}, {"id": "2005.02978", "submitter": "Horacio Samaniego", "authors": "Boris Sotomayor-G\\'omez and Horacio Samaniego", "title": "City limits in the age of smartphones and urban scaling", "comments": "13 pages, 7 figures", "journal-ref": "Computers, Environment and Urban Systems (2020), 79: 101423", "doi": "10.1016/j.compenvurbsys.2019.101423", "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban planning still lacks appropriate standards to define city boundaries\nacross urban systems. This issue has historically been left to administrative\ncriteria, which can vary significantly across countries and political systems,\nhindering a comparative analysis across urban systems. However, the wide use of\nInformation and Communication Technologies (ICT) has now allowed the\ndevelopment of new quantitative approaches to unveil how social dynamics\nrelates to urban infrastructure. In fact, ICT provide the potential to portray\nmore accurate descriptions of the urban systems based on the empirical analysis\nof millions of traces left by urbanites across the city. In this work, we apply\ncomputational techniques over a large volume of mobile phone records to define\nurban boundaries, through the analysis of travel patterns and the trajectory of\nurban dwellers in conurbations with more than 100,000 inhabitants in Chile. We\ncreated and analyzed the network of interconnected places inferred from\nindividual travel trajectories. We then ranked each place using a spectral\ncentrality method. This allowed to identify places of higher concurrency and\nfunctional importance for each urban environment. Urban scaling analysis is\nfinally used as a diagnostic tool that allowed to distinguish urban from\nnon-urban spaces. The geographic assessment of our method shows a high\ncongruence with the current and administrative definitions of urban\nagglomerations in Chile. Our results can potentially be considered as a\nfunctional definition of the urban boundary. They also provide a practical\nimplementation of urban scaling and data-driven approaches on cities as complex\nsystems using increasingly larger non-conventional datasets.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 17:31:21 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Sotomayor-G\u00f3mez", "Boris", ""], ["Samaniego", "Horacio", ""]]}, {"id": "2005.03474", "submitter": "Arpita Biswas", "authors": "Arpita Biswas, Suvam Mukherjee", "title": "Ensuring Fairness under Prior Probability Shifts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of fair classification in the presence of\nprior probability shifts, where the training set distribution differs from the\ntest set. This phenomenon can be observed in the yearly records of several\nreal-world datasets, such as recidivism records and medical expenditure\nsurveys. If unaccounted for, such shifts can cause the predictions of a\nclassifier to become unfair towards specific population subgroups. While the\nfairness notion called Proportional Equality (PE) accounts for such shifts, a\nprocedure to ensure PE-fairness was unknown.\n  In this work, we propose a method, called CAPE, which provides a\ncomprehensive solution to the aforementioned problem. CAPE makes novel use of\nprevalence estimation techniques, sampling and an ensemble of classifiers to\nensure fair predictions under prior probability shifts. We introduce a metric,\ncalled prevalence difference (PD), which CAPE attempts to minimize in order to\nensure PE-fairness. We theoretically establish that this metric exhibits\nseveral desirable properties.\n  We evaluate the efficacy of CAPE via a thorough empirical evaluation on\nsynthetic datasets. We also compare the performance of CAPE with several\npopular fair classifiers on real-world datasets like COMPAS (criminal risk\nassessment) and MEPS (medical expenditure panel survey). The results indicate\nthat CAPE ensures PE-fair predictions, while performing well on other\nperformance metrics.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 13:07:05 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Biswas", "Arpita", ""], ["Mukherjee", "Suvam", ""]]}, {"id": "2005.03534", "submitter": "Aakash Gautam", "authors": "Aakash Gautam, Deborah Tatar", "title": "p for political: Participation Without Agency Is Not Enough", "comments": "5 pages, 1 figure. Accepted in the 16th Participatory Design\n  Conference (PDC'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Participatory Design's vision of democratic participation assumes\nparticipants' feelings of agency in envisioning a collective future. But this\nassumption may be leaky when dealing with vulnerable populations. We reflect on\nthe results of a series of activities aimed at supporting\nagentic-future-envisionment with a group of sex-trafficking survivors in Nepal.\nWe observed a growing sense among the survivors that they could play a role in\nbringing about change in their families. They also became aware of how they\ncould interact with available institutional resources. Reflecting on the\nobservations, we argue that building participant agency on the small and\npersonal interactions is necessary before demanding larger Political\nparticipation. In particular, a value of PD, especially for vulnerable\npopulations, can lie in the process itself if it helps participants position\nthemselves as actors in the larger world.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 14:59:59 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Gautam", "Aakash", ""], ["Tatar", "Deborah", ""]]}, {"id": "2005.03535", "submitter": "Patrik Keller", "authors": "Patrik Keller, Martin Florian, Rainer B\\\"ohme", "title": "Collaborative Deanonymization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-seeking cryptocurrency users rely on anonymization techniques like\nCoinJoin and ring transactions. By using such technologies benign users\npotentially provide anonymity to bad actors. We propose overlay protocols to\nresolve the tension between anonymity and accountability in a peer-to-peer\nmanner. Cryptocurrencies can adopt this approach to enable prosecution of\npublicly recognized crimes. We illustrate how the protocols could apply to\nMonero rings and CoinJoin transactions in Bitcoin.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 15:03:19 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 10:52:35 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Keller", "Patrik", ""], ["Florian", "Martin", ""], ["B\u00f6hme", "Rainer", ""]]}, {"id": "2005.03599", "submitter": "Jinfeng Li", "authors": "Jinfeng Li and Xinyi Guo", "title": "COVID-19 Contact-tracing Apps: a Survey on the Global Deployment and\n  Challenges", "comments": "7 pages. The copyright holder for this preprint is the authors. All\n  rights reserved. No reuse allowed without permission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the massive spike in uncertainties triggered by the coronavirus\ndisease (COVID-19), there is an ever-increasing number of national governments\nthat are rolling out contact-tracing Apps to aid the containment of the virus.\nThe first hugely contentious issue facing the Apps is the deployment framework,\ni.e. centralized or decentralized. Based on this, the debate branches out to\nthe corresponding technologies that underpin these architectures, i.e. GPS, QR\ncodes, and Bluetooth. This work conducts a pioneering review of the above\nscenarios and contributes a geolocation mapping of the current deployment. The\nApps vulnerabilities and the directions of research are identified, with a\nspecial focus on the Bluetooth-inspired decentralized paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 16:38:08 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 15:20:15 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Li", "Jinfeng", ""], ["Guo", "Xinyi", ""]]}, {"id": "2005.03909", "submitter": "Bertie Vidgen Dr", "authors": "Bertie Vidgen, Austin Botelho, David Broniatowski, Ella Guest, Matthew\n  Hall, Helen Margetts, Rebekah Tromble, Zeerak Waseem, Scott Hale", "title": "Detecting East Asian Prejudice on Social Media", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of COVID-19 has transformed societies across the world as\ngovernments tackle the health, economic and social costs of the pandemic. It\nhas also raised concerns about the spread of hateful language and prejudice\nonline, especially hostility directed against East Asia. In this paper we\nreport on the creation of a classifier that detects and categorizes social\nmedia posts from Twitter into four classes: Hostility against East Asia,\nCriticism of East Asia, Meta-discussions of East Asian prejudice and a neutral\nclass. The classifier achieves an F1 score of 0.83 across all four classes. We\nprovide our final model (coded in Python), as well as a new 20,000 tweet\ntraining dataset used to make the classifier, two analyses of hashtags\nassociated with East Asian prejudice and the annotation codebook. The\nclassifier can be implemented by other researchers, assisting with both online\ncontent moderation processes and further research into the dynamics, prevalence\nand impact of East Asian prejudice online during this global pandemic.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:53:47 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Vidgen", "Bertie", ""], ["Botelho", "Austin", ""], ["Broniatowski", "David", ""], ["Guest", "Ella", ""], ["Hall", "Matthew", ""], ["Margetts", "Helen", ""], ["Tromble", "Rebekah", ""], ["Waseem", "Zeerak", ""], ["Hale", "Scott", ""]]}, {"id": "2005.03930", "submitter": "Hannah Dee", "authors": "Hannah M. Dee, Jordi Freixenet, Xavier Cufi, Eduard Muntaner Perich,\n  Valentina Poggioni, Marius Marian, Alfredo Milani", "title": "Encouraging early mastery of computational concepts through play", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning to code, and more broadly, learning about computer science is a\ngrowing field of activity and research. Under the label of computational\nthinking, computational concepts are increasingly used as cognitive tools in\nmany subject areas, beyond computer science. Using playful approaches and\ngamification to motivate educational activities, and to encourage exploratory\nlearning is not a new idea since play has been involved in the learning of\ncomputational concepts by children from the very start. There is a tension\nhowever, between learning activities and opportunities that are completely open\nand playful, and learning activities that are structured enough to be easily\nreplicable among contexts, countries and classrooms. This paper describes the\nconception, refinement, design and evaluation of a set of playful computational\nactivities for classrooms or code clubs, that balance the benefits of\nplayfulness with sufficient rigor and structure to enable robust replication.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 09:47:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Dee", "Hannah M.", ""], ["Freixenet", "Jordi", ""], ["Cufi", "Xavier", ""], ["Perich", "Eduard Muntaner", ""], ["Poggioni", "Valentina", ""], ["Marian", "Marius", ""], ["Milani", "Alfredo", ""]]}, {"id": "2005.03957", "submitter": "Ioannis Sarafis", "authors": "Ioannis Sarafis, Christos Diou, Vasileios Papapanagiotou, Leonidas\n  Alagialoglou, Anastasios Delopoulos", "title": "Inferring the Spatial Distribution of Physical Activity in Children\n  Population from Characteristics of the Environment", "comments": "Accepted version to be published in 2020, 42nd Annual International\n  Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),\n  Montreal, Canada", "journal-ref": null, "doi": "10.1109/EMBC44109.2020.9176246", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obesity affects a rising percentage of the children and adolescent\npopulation, contributing to decreased quality of life and increased risk for\ncomorbidities. Although the major causes of obesity are known, the obesogenic\nbehaviors manifest as a result of complex interactions of the individual with\nthe living environment. For this reason, addressing childhood obesity remains a\nchallenging problem for public health authorities. The BigO project\n(https://bigoprogram.eu) relies on large-scale behavioral and environmental\ndata collection to create tools that support policy making and intervention\ndesign. In this work, we propose a novel analysis approach for modeling the\nexpected population behavior as a function of the local environment. We\nexperimentally evaluate this approach in predicting the expected physical\nactivity level in small geographic regions using urban environment\ncharacteristics. Experiments on data collected from 156 children and\nadolescents verify the potential of the proposed approach. Specifically, we\ntrain models that predict the physical activity level in a region, achieving\n81% leave-one-out accuracy. In addition, we exploit the model predictions to\nautomatically visualize heatmaps of the expected population behavior in areas\nof interest, from which we draw useful insights. Overall, the predictive models\nand the automatic heatmaps are promising tools in gaining direct perception for\nthe spatial distribution of the population's behavior, with potential uses by\npublic health authorities.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 11:07:35 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Sarafis", "Ioannis", ""], ["Diou", "Christos", ""], ["Papapanagiotou", "Vasileios", ""], ["Alagialoglou", "Leonidas", ""], ["Delopoulos", "Anastasios", ""]]}, {"id": "2005.04007", "submitter": "Enrico Ronchi", "authors": "Enrico Ronchi, Ruggiero Lovreglio", "title": "EXPOSED: An occupant exposure model for confined spaces to retrofit\n  crowd models during a pandemic", "comments": null, "journal-ref": "Safety Science, 2020", "doi": "10.1016/j.ssci.2020.104834", "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd models can be used for the simulation of people movement in the built\nenvironment. Crowd model outputs have been used for evaluating safety and\ncomfort of pedestrians, inform crowd management and perform forensic\ninvestigations. Microscopic crowd models allow the representation of each\nperson and the obtainment of information concerning their location over time\nand interactions with the physical space/other people. Pandemics such as\nCOVID-19 have posed several questions on safe building usage, given the risk of\ndisease transmission among building occupants. Here we show how crowd modelling\ncan be used to assess occupant exposure in confined spaces. The policies\nadopted concerning building usage and social distancing during a pandemic can\nvary greatly, and they are mostly based on the macroscopic analysis of the\nspread of disease rather than a safety assessment performed at a building\nlevel. The proposed model allows the investigation of occupant exposure in\nbuildings based on the analysis of microscopic people movement. Risk assessment\nis performed by retrofitting crowd models with a universal model for exposure\nassessment which can account for different types of disease transmissions. This\nwork allows policy makers to perform informed decisions concerning building\nusage during a pandemic.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:00:19 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Ronchi", "Enrico", ""], ["Lovreglio", "Ruggiero", ""]]}, {"id": "2005.04126", "submitter": "Omar Reyad", "authors": "M.E. Karar, A.M. Al-Masaad, O. Reyad", "title": "GASDUINO-Wireless Air Quality Monitoring System Using Internet of Things", "comments": "5 pages, 4 figures, 1 table", "journal-ref": "Inf. Sci. Lett. 9(2), 113-117 (2020)", "doi": "10.18576/isl/090208", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Health Effects Institute (HEI) reported recently that the deaths from the\nnegative health effects of the air pollution in the Middle East Region is about\n500,000 people. Therefore, this paper presents a new design and development of\nportable system; called GASDUINO that allows the user to measure the quality of\nair using the Internet of Things (IoT). The main components of developed\nGASDUINO system are the Arduino microcontroller board, Gas sensor (MQ-135),\nAndroid user interface (UI) connected with all things via Remote XY Arduino\ncloud. The developed system can alarm the users about the dangerous levels of\nthe air quality index (AQI) or the particle per million (PPM) levels in the\nrange of 0 to above 200 PPM. The developed GASDUINO system is considered as an\nessential environmental module in the development and sustainability of future\nsmart cities.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:06:20 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Karar", "M. E.", ""], ["Al-Masaad", "A. M.", ""], ["Reyad", "O.", ""]]}, {"id": "2005.04158", "submitter": "Omar Reyad", "authors": "M.E. Karar, M.F. Al-Rasheed, A.F. Al-Rasheed, O. Reyad", "title": "IoT and Neural Network-Based Water Pumping Control System For Smart\n  Irrigation", "comments": "6 pages, 5 figures, 1 table", "journal-ref": "Inf. Sci. Lett. 9(2), 107-112 (2020)", "doi": "10.18576/isl/090207", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article aims at saving the wasted water in the process of irrigation\nusing the Internet of Things (IoT) based on a set of sensors and Multi-Layer\nPerceptron (MLP) neural network. The developed system handles the sensor data\nusing the Arduino board to control the water pump automatically. The sensors\nmeasure the environmental factors; namely temperature, humidity, and soil\nmoisture to estimate the required time for the operation of water irrigation.\nThe water pump control system consists of software and hardware tools such as\nArduino Remote XY interface and electronic sensors in the framework of IoT\ntechnology. The machine learning algorithm such as the MLP neural network plays\nan important role to support the decision of automatic control of IoT-based\nirrigation system, managing the water consumption effectively.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:51:26 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Karar", "M. E.", ""], ["Al-Rasheed", "M. F.", ""], ["Al-Rasheed", "A. F.", ""], ["Reyad", "O.", ""]]}, {"id": "2005.04343", "submitter": "Elissa M. Redmiles", "authors": "Gabriel Kaptchuk, Daniel G. Goldstein, Eszter Hargittai, Jake Hofman,\n  Elissa M. Redmiles", "title": "How good is good enough for COVID19 apps? The influence of benefits,\n  accuracy, and privacy on willingness to adopt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of contact tracing apps are being developed to complement\nmanual contact tracing. A key question is whether users will be willing to\nadopt these contact tracing apps. In this work, we survey over 4,500 Americans\nto evaluate (1) the effect of both accuracy and privacy concerns on reported\nwillingness to install COVID19 contact tracing apps and (2) how different\ngroups of users weight accuracy vs. privacy. Drawing on our findings from these\nfirst two research questions, we (3) quantitatively model how the amount of\npublic health benefit (reduction in infection rate), amount of individual\nbenefit (true-positive detection of exposures to COVID), and degree of privacy\nrisk in a hypothetical contact tracing app may influence American's willingness\nto install. Our work takes a descriptive ethics approach toward offering\nimplications for the development of policy and app designs related to COVID19.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:53:52 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 17:32:30 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 22:56:16 GMT"}, {"version": "v4", "created": "Mon, 18 May 2020 23:13:05 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kaptchuk", "Gabriel", ""], ["Goldstein", "Daniel G.", ""], ["Hargittai", "Eszter", ""], ["Hofman", "Jake", ""], ["Redmiles", "Elissa M.", ""]]}, {"id": "2005.04364", "submitter": "Samson Tan", "authors": "Samson Tan, Shafiq Joty, Min-Yen Kan, Richard Socher", "title": "It's Morphin' Time! Combating Linguistic Discrimination with\n  Inflectional Perturbations", "comments": "To appear in the Proceedings of the 58th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.263", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training on only perfect Standard English corpora predisposes pre-trained\nneural networks to discriminate against minorities from non-standard linguistic\nbackgrounds (e.g., African American Vernacular English, Colloquial Singapore\nEnglish, etc.). We perturb the inflectional morphology of words to craft\nplausible and semantically similar adversarial examples that expose these\nbiases in popular NLP models, e.g., BERT and Transformer, and show that\nadversarially fine-tuning them for a single epoch significantly improves\nrobustness without sacrificing performance on clean data.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 04:01:43 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Tan", "Samson", ""], ["Joty", "Shafiq", ""], ["Kan", "Min-Yen", ""], ["Socher", "Richard", ""]]}, {"id": "2005.04411", "submitter": "Yiqing Hua", "authors": "Yiqing Hua, Thomas Ristenpart, Mor Naaman", "title": "Towards Measuring Adversarial Twitter Interactions against Candidates in\n  the US Midterm Elections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial interactions against politicians on social media such as Twitter\nhave significant impact on society. In particular they disrupt substantive\npolitical discussions online, and may discourage people from seeking public\noffice. In this study, we measure the adversarial interactions against\ncandidates for the US House of Representatives during the run-up to the 2018 US\ngeneral election. We gather a new dataset consisting of 1.7 million tweets\ninvolving candidates, one of the largest corpora focusing on political\ndiscourse. We then develop a new technique for detecting tweets with toxic\ncontent that are directed at any specific candidate.Such technique allows us to\nmore accurately quantify adversarial interactions towards political candidates.\nFurther, we introduce an algorithm to induce candidate-specific adversarial\nterms to capture more nuanced adversarial interactions that previous techniques\nmay not consider toxic. Finally, we use these techniques to outline the breadth\nof adversarial interactions seen in the election, including offensive\nname-calling, threats of violence, posting discrediting information, attacks on\nidentity, and adversarial message repetition.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 10:00:41 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Hua", "Yiqing", ""], ["Ristenpart", "Thomas", ""], ["Naaman", "Mor", ""]]}, {"id": "2005.04543", "submitter": "Yang Liu", "authors": "Yang Liu, Michael Gordon, Juntao Wang, Michael Bishop, Yiling Chen,\n  Thomas Pfeiffer, Charles Twardy and Domenico Viganola", "title": "Replication Markets: Results, Lessons, Challenges and Opportunities in\n  AI Replication", "comments": "Appeared at AAAI workshop on Reproducible AI (RAI), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade saw the emergence of systematic large-scale replication\nprojects in the social and behavioral sciences, (Camerer et al., 2016, 2018;\nEbersole et al., 2016; Klein et al., 2014, 2018; Collaboration, 2015). These\nprojects were driven by theoretical and conceptual concerns about a high\nfraction of \"false positives\" in the scientific publications (Ioannidis, 2005)\n(and a high prevalence of \"questionable research practices\" (Simmons, Nelson,\nand Simonsohn, 2011). Concerns about the credibility of research findings are\nnot unique to the behavioral and social sciences; within Computer Science,\nArtificial Intelligence (AI) and Machine Learning (ML) are areas of particular\nconcern (Lucic et al., 2018; Freire, Bonnet, and Shasha, 2012; Gundersen and\nKjensmo, 2018; Henderson et al., 2018). Given the pioneering role of the\nbehavioral and social sciences in the promotion of novel methodologies to\nimprove the credibility of research, it is a promising approach to analyze the\nlessons learned from this field and adjust strategies for Computer Science, AI\nand ML In this paper, we review approaches used in the behavioral and social\nsciences and in the DARPA SCORE project. We particularly focus on the role of\nhuman forecasting of replication outcomes, and how forecasting can leverage the\ninformation gained from relatively labor and resource-intensive replications.\nWe will discuss opportunities and challenges of using these approaches to\nmonitor and improve the credibility of research areas in Computer Science, AI,\nand ML.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 01:41:56 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Liu", "Yang", ""], ["Gordon", "Michael", ""], ["Wang", "Juntao", ""], ["Bishop", "Michael", ""], ["Chen", "Yiling", ""], ["Pfeiffer", "Thomas", ""], ["Twardy", "Charles", ""], ["Viganola", "Domenico", ""]]}, {"id": "2005.04666", "submitter": "Ali AlSoufi Dr.", "authors": "Khaled Waleed, Ali AlSoufi", "title": "Employees Productivity Measurement and Control -- a Case of a National\n  University", "comments": "6 pages, 6 figures, 4 tables, conference paper. International\n  Conference on Innovation and Intelligence for Informatics, Computing, and\n  Technologies (3ICT), University of Bahrain, Kingdom of Bahrain, September\n  2019", "journal-ref": null, "doi": "10.1109/3ICT.2019.8910311", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An experimental study, that finds the impact of Internet access control on\nthe employees productivity in the National University. The purpose of the study\nis to boost the employee productivity through proper Internet access control.\nThe main objectives are to find the most used web categories by the staff, find\nif relation exists between productivity and none work related internet usage,\nand choose the best level of Internet access control. Before initiating the\nexperiment, Employees Internet usage was monitored and accordingly classified\nthem into the proper Internet access control groups. Then supervisors were\nasked for a pre-test productivity measures for their staff, after that the\nexperiment was initiated for 45 days. Then, a post-test productivity measure\nwas done. Productivity changes were analyzed with the department nature, its\nInternet usage portfolio and its current Internet access control group; then\nthe best level of restriction was found. The result showed that the\nproductivity of departments with low Internet usage was not affected by\nrestricting and none restricting Internet access. However, for high Internet\nusage departments noticeable productivity improvement was there when the\nInternet restriction policy was not affecting work-related websites; but when\nit was affecting work-related websites the productivity decreased.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 13:36:56 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Waleed", "Khaled", ""], ["AlSoufi", "Ali", ""]]}, {"id": "2005.04670", "submitter": "Ali AlSoufi Dr.", "authors": "Mohammed Ghanem, Ali Alsoufi", "title": "Interoperable Framework to Enhance Citizen Services in the Kingdom of\n  Bahrain", "comments": "4 pages, 1 figure, conference paper, 978-1-7281-3012-5/19/$31.00\n  \\c{opyright}2019 IEEE", "journal-ref": "International Conference on Innovation and Intelligence for\n  Informatics, Computing, and Technologies (3ICT), University of Bahrain,\n  Kingdom of Bahrain, September 2019", "doi": "10.1109/3ICT.2019.8910330", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citizen records are scattered between different state organizations. It\nwastes time, effort, and resources for both citizen and organization to\ncollect, maintain, and update records to fulfill citizen services.\nInteroperability is a key element that enables seamless collaboration between\ndifferent entities. It requires non-conventional methods to overcome\ninteroperability challenges such as lack of trust, centralization, and policy\nand technology differences. Blockchain is a disruptive technology with the\npotential to overcome these challenges. The technology designed to enable\npeer-to-peer transactions with elimination of intermediary in a trustless\nenvironment through the control of consensus mechanisms. This research aims to\nexplore the status of interoperability in Bahrain, design an interoperable\nframework, and then test the validity of the framework by implementation of a\nprototype using blockchain technology. The research will be divided into four\nphases; I: Information collection, II: Design and modeling the framework, III:\nImplementation of a prototype, and Phase IV: Measuring the performance of the\nprototype. This research is in progress and it is expected, once is it\ncomplete, to enhance the e-government's plan in the Kingdom of Bahrain to\nprovide better services to citizens and help in the transition from\ne-government to seamless government, which will lead to sustainable citizen\nservices. On the other hand, the findings of the study is expected to improve\nthe social, economical, and environmental sustainability by the increase in\nprocess optimization, reduction of cost and complexity.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:00:54 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Ghanem", "Mohammed", ""], ["Alsoufi", "Ali", ""]]}, {"id": "2005.04682", "submitter": "Nicholas Micallef", "authors": "Mihai Avram, Nicholas Micallef, Sameer Patil, Filippo Menczer", "title": "Exposure to Social Engagement Metrics Increases Vulnerability to\n  Misinformation", "comments": "9 pages, 2 figures", "journal-ref": "HKS Misinformation Review Vol. 1 (No. 5), 2020", "doi": "10.37016/mr-2020-033", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News feeds in virtually all social media platforms include engagement\nmetrics, such as the number of times each post is liked and shared. We find\nthat exposure to these social engagement signals increases the vulnerability of\nusers to misinformation. This finding has important implications for the design\nof social media interactions in the misinformation age. To reduce the spread of\nmisinformation, we call for technology platforms to rethink the display of\nsocial engagement metrics. Further research is needed to investigate whether\nand how engagement metrics can be presented without amplifying the spread of\nlow-credibility information.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 14:55:50 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 07:31:05 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Avram", "Mihai", ""], ["Micallef", "Nicholas", ""], ["Patil", "Sameer", ""], ["Menczer", "Filippo", ""]]}, {"id": "2005.04789", "submitter": "Jichen Zhu", "authors": "Jichen Zhu, Katelyn Alderfer, Brian Smith, Bruce Char, Santiago\n  Onta\\~n\\'on", "title": "Understanding Learners' Problem-Solving Strategies in Concurrent and\n  Parallel Programming: A Game-Based Approach", "comments": "Submitted to CHI Play '20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent and parallel programming (CPP) is an increasingly important\nsubject in Computer Science Education. However, the conceptual shift from\nsequential programming is notoriously difficult to make. Currently, relatively\nlittle research exists on how people learn CPP core concepts. This paper\npresents our results of using Parallel, an educational game about CPP, focusing\non the learners' self-efficacy and how they learn CPP concepts. Based on a\nstudy of 44 undergraduate students, our research shows that (a) self-efficacy\nincreased significantly after playing the game; (b) the problem-solving\nstrategies employed by students playing the game can be classified in three\nmain types: trial and error, single-thread, and multi-threaded strategies, and\n(c) that self-efficacy is correlated with the percentage of time students spend\nin multithreaded problem-solving.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 21:29:10 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Zhu", "Jichen", ""], ["Alderfer", "Katelyn", ""], ["Smith", "Brian", ""], ["Char", "Bruce", ""], ["Onta\u00f1\u00f3n", "Santiago", ""]]}, {"id": "2005.04910", "submitter": "Max Maass", "authors": "Milan Stute, Max Maass, Tom Schons, Marc-Andr\\'e Kaufhold, Christian\n  Reuter, Matthias Hollick", "title": "Empirical Insights for Designing Information and Communication\n  Technology for International Disaster Response", "comments": null, "journal-ref": "International Journal of Disaster Risk Reduction, Volume 47,\n  August 2020, 101598", "doi": "10.1016/j.ijdrr.2020.101598", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the increase in natural disasters in the past years, Disaster Response\nOrganizations (DROs) are faced with the challenge of coping with more and\nlarger operations. Currently appointed Information and Communications\nTechnology (ICT) used for coordination and communication is sometimes outdated\nand does not scale, while novel technologies have the potential to greatly\nimprove disaster response efficiency. To allow adoption of these novel\ntechnologies, ICT system designers have to take into account the particular\nneeds of DROs and characteristics of International Disaster Response (IDR).\nThis work attempts to bring the humanitarian and ICT communities closer\ntogether. In this work, we analyze IDR-related documents and conduct expert\ninterviews. Using open coding, we extract empirical insights and translate the\npeculiarities of DRO coordination and operation into tangible ICT design\nrequirements. This information is based on interviews with active IDR staff as\nwell as DRO guidelines and reports. Ultimately, the goal of this paper is to\nserve as a reference for future ICT research endeavors to support and increase\nthe efficiency of IDR operations.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 08:05:02 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Stute", "Milan", ""], ["Maass", "Max", ""], ["Schons", "Tom", ""], ["Kaufhold", "Marc-Andr\u00e9", ""], ["Reuter", "Christian", ""], ["Hollick", "Matthias", ""]]}, {"id": "2005.04928", "submitter": "Vasileios Papapanagiotou", "authors": "Vasileios Papapanagiotou, Ioannis Sarafis, Christos Diou, Ioannis\n  Ioakimidis, Evangelia Charmandari, Anastasios Delopoulos", "title": "Collecting big behavioral data for measuring behavior against obesity", "comments": "Accepted version to be published in 2020, 42nd Annual International\n  Conference of the IEEE Engineering in Medicine and Biology Society (EMBC),\n  Montreal, Canada", "journal-ref": null, "doi": "10.1109/EMBC44109.2020.9175313", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obesity is currently affecting very large portions of the global population.\nEffective prevention and treatment starts at the early age and requires\nobjective knowledge of population-level behavior on the region/neighborhood\nscale. To this end, we present a system for extracting and collecting\nbehavioral information on the individual-level objectively and automatically.\nThe behavioral information is related to physical activity, types of visited\nplaces, and transportation mode used between them. The system employs\nindicator-extraction algorithms from the literature which we evaluate on\npublicly available datasets. The system has been developed and integrated in\nthe context of the EU-funded BigO project that aims at preventing obesity in\nyoung populations.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 08:51:07 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Papapanagiotou", "Vasileios", ""], ["Sarafis", "Ioannis", ""], ["Diou", "Christos", ""], ["Ioakimidis", "Ioannis", ""], ["Charmandari", "Evangelia", ""], ["Delopoulos", "Anastasios", ""]]}, {"id": "2005.04949", "submitter": "Evgeni Aizenberg", "authors": "Evgeni Aizenberg and Jeroen van den Hoven", "title": "Designing for Human Rights in AI", "comments": "30 pages, 2 figures, pre-print of the paper accepted for publication\n  in the journal Big Data & Society", "journal-ref": "Big Data & Society 7(2) (2020)", "doi": "10.1177/2053951720949566", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of big data, companies and governments are increasingly using\nalgorithms to inform hiring decisions, employee management, policing, credit\nscoring, insurance pricing, and many more aspects of our lives. AI systems can\nhelp us make evidence-driven, efficient decisions, but can also confront us\nwith unjustified, discriminatory decisions wrongly assumed to be accurate\nbecause they are made automatically and quantitatively. It is becoming evident\nthat these technological developments are consequential to people's fundamental\nhuman rights. Despite increasing attention to these urgent challenges in recent\nyears, technical solutions to these complex socio-ethical problems are often\ndeveloped without empirical study of societal context and the critical input of\nsocietal stakeholders who are impacted by the technology. On the other hand,\ncalls for more ethically- and socially-aware AI often fail to provide answers\nfor how to proceed beyond stressing the importance of transparency,\nexplainability, and fairness. Bridging these socio-technical gaps and the deep\ndivide between abstract value language and design requirements is essential to\nfacilitate nuanced, context-dependent design choices that will support moral\nand social values. In this paper, we bridge this divide through the framework\nof Design for Values, drawing on methodologies of Value Sensitive Design and\nParticipatory Design to present a roadmap for proactively engaging societal\nstakeholders to translate fundamental human rights into context-dependent\ndesign requirements through a structured, inclusive, and transparent process.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 09:21:10 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 17:00:46 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Aizenberg", "Evgeni", ""], ["Hoven", "Jeroen van den", ""]]}, {"id": "2005.05086", "submitter": "Daniel Tang", "authors": "Daniel Tang", "title": "Decentralised, privacy-preserving Bayesian inference for mobile phone\n  contact tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many countries are currently gearing up to use smart-phone apps to perform\ncontact tracing as part of the effort to manage the COVID-19 pandemic and\nprevent resurgences of the disease after the initial outbreak. With the\nannouncement of the Apple/Google partnership to introduce contact-tracing\nfunctionality to iOS and Android, it seems likely that this will be adopted in\nmany countries. An important part of the functionality of the app will be to\ndecide whether a person should be advised to self-isolate, be tested or end\nisolation. However, the privacy preserving nature of the Apple/Google contact\ntracing algorithm means that centralised curation of these decisions is not\npossible so each phone must use its own \"risk model\" to inform decisions.\nIdeally, the risk model should use Bayesian inference to decide the best course\nof action given the test results of the user and those of other users. Here we\npresent a decentralised algorithm that estimates the Bayesian posterior\nprobability of viral transmission events and evaluates when a user should be\nnotified, tested or released from isolation while preserving user privacy. The\nalgorithm also allows the disease models on the phones to learn from everyone's\ncontact-tracing data and will allow Epidemiologists to better understand the\ndynamics of the disease. The algorithm is a message passing algorithm, based on\nbelief propagation, so each smart-phone can be used to execute a small part of\nthe algorithm without releasing any sensitive information. In this way, the\nnetwork of all participating smart-phones forms a distributed computation\ndevice that performs Bayesian inference, informs each user when they should\nstart/end isolation or be tested and learns about the disease from user's data.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 13:13:36 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Tang", "Daniel", ""]]}, {"id": "2005.05502", "submitter": "Rui Wang", "authors": "Eliza Huang, Rui Wang, Uma Chandrasekaran, Rose Yu", "title": "Aortic Pressure Forecasting with Deep Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean aortic pressure (MAP) is a major determinant of perfusion in all organs\nsystems. The ability to forecast MAP would enhance the ability of physicians to\nestimate prognosis of the patient and assist in early detection of hemodynamic\ninstability. However, forecasting MAP is challenging because the blood pressure\n(BP) time series is noisy and can be highly non-stationary. The aim of this\nstudy was to forecast the mean aortic pressure five minutes in advance, using\nthe 25 Hz time series data of previous five minutes as input. We provide a\nbenchmark study of different deep learning models for BP forecasting. We\ninvestigate a left ventricular dwelling transvalvular micro-axial device, the\nImpella, in patients undergoing high-risk percutaneous intervention. The\nImpella provides hemodynamic support, thus aiding in native heart function\nrecovery. It is also equipped with pressure sensors to capture high frequency\nMAP measurements at origin, instead of peripherally. Our dataset and the\nclinical application is novel in the BP forecasting field. We performed a\ncomprehensive study on time series with increasing, decreasing, and stationary\ntrends. The experiments show that recurrent neural networks with Legendre\nMemory Unit achieve the best performance with an overall forecasting error of\n1.8 mmHg.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:07:25 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 21:47:58 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 18:53:02 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Huang", "Eliza", ""], ["Wang", "Rui", ""], ["Chandrasekaran", "Uma", ""], ["Yu", "Rose", ""]]}, {"id": "2005.05513", "submitter": "Tavpritesh Sethi", "authors": "Baani Leen Kaur Jolly, Palash Aggrawal, Amogh Gulati, Amarjit Singh\n  Sethi, Ponnurangam Kumaraguru, Tavpritesh Sethi", "title": "Psychometric Analysis and Coupling of Emotions Between State Bulletins\n  and Twitter in India during COVID-19 Infodemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID-19 infodemic has been spreading faster than the pandemic itself. The\nmisinformation riding upon the infodemic wave poses a major threat to people's\nhealth and governance systems. Since social media is the largest source of\ninformation, managing the infodemic not only requires mitigating of\nmisinformation but also an early understanding of psychological patterns\nresulting from it. During the COVID-19 crisis, Twitter alone has seen a sharp\n45% increase in the usage of its curated events page, and a 30% increase in its\ndirect messaging usage, since March 6th 2020. In this study, we analyze the\npsychometric impact and coupling of the COVID-19 infodemic with the official\nbulletins related to COVID-19 at the national and state level in India. We look\nat these two sources with a psycho-linguistic lens of emotions and quantified\nthe extent and coupling between the two. We modified path, a deep skip-gram\nbased open-sourced lexicon builder for effective capture of health-related\nemotions. We were then able to capture the time-evolution of health-related\nemotions in social media and official bulletins. An analysis of lead-lag\nrelationships between the time series of extracted emotions from official\nbulletins and social media using Granger's causality showed that state\nbulletins were leading the social media for some emotions such as Medical\nEmergency. Further insights that are potentially relevant for the policymaker\nand the communicators actively engaged in mitigating misinformation are also\ndiscussed. Our paper also introduces CoronaIndiaDataset2, the first social\nmedia based COVID-19 dataset at national and state levels from India with over\n5.6 million national and 2.6 million state-level tweets. Finally, we present\nour findings as COVibes, an interactive web application capturing psychometric\ninsights captured upon the CoronaIndiaDataset, both at a national and state\nlevel.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 01:51:07 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 16:47:44 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Jolly", "Baani Leen Kaur", ""], ["Aggrawal", "Palash", ""], ["Gulati", "Amogh", ""], ["Sethi", "Amarjit Singh", ""], ["Kumaraguru", "Ponnurangam", ""], ["Sethi", "Tavpritesh", ""]]}, {"id": "2005.05523", "submitter": "Moumen Hamouma", "authors": "Badreddine Benreguia, Hamouma Moumen, and Mohammed Amine Merzoug", "title": "Tracking COVID-19 by Tracking Infectious Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the coronavirus pandemic has and is still causing large numbers of\ndeaths and infected people. Although governments all over the world have taken\nsevere measurements to slow down the virus spreading (e.g., travel\nrestrictions, suspending all sportive, social, and economic activities,\nquarantines, social distancing, etc.), a lot of persons have died and a lot\nmore are still in danger. Indeed, a recently conducted study~\\cite{ref2} has\nreported that 79\\% of the confirmed infections in China were caused by\nundocumented patients who had no symptoms. In the same context, in numerous\nother countries, since coronavirus takes several days before the emergence of\nsymptoms, it has also been reported that the known number of infections is not\nrepresentative of the real number of infected people (the actual number is\nexpected to be much higher). That is to say, asymptomatic patients are the main\nfactor behind the large quick spreading of coronavirus and are also the major\nreason that caused governments to lose control over this critical situation. To\ncontribute to remedying this global pandemic, in this paper, we propose an IoT\n(Internet of Things) investigation system that was specifically designed to\nspot both undocumented patients and infectious places. The goal is to help the\nauthorities to disinfect high-contamination sites and confine persons even if\nthey have no apparent symptoms. The proposed system also allows determining all\npersons who had close contact with infected or suspected patients.\nConsequently, rapid isolation of suspicious cases and more efficient control\nover any pandemic propagation can be achieved.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 02:20:09 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Benreguia", "Badreddine", ""], ["Moumen", "Hamouma", ""], ["Merzoug", "Mohammed Amine", ""]]}, {"id": "2005.05571", "submitter": "Abdulrahman Alzahrani Dr", "authors": "Abdulrahman Alzahrani, Ali Alshehri, Hani Alshahrani, Huirong Fu", "title": "Ransomware in Windows and Android Platforms", "comments": "21 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malware proliferation and sophistication have drastically increased and\nevolved continuously. Recent indiscriminate ransomware victimizations have\nimposed critical needs of effective detection techniques to prevent damages.\nTherefore, ransomware has drawn attention among cyberspace researchers. This\npaper contributes a comprehensive overview of ransomware attacks and summarizes\nexisting detection and prevention techniques in both Windows and Android\nplatforms. Moreover, it highlights the strengths and shortcomings of those\ntechniques and provides a comparison between them. Furthermore, it gives\nrecommendations to users and system administrators.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 06:40:44 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Alzahrani", "Abdulrahman", ""], ["Alshehri", "Ali", ""], ["Alshahrani", "Hani", ""], ["Fu", "Huirong", ""]]}, {"id": "2005.05625", "submitter": "Philipp H. Kindt", "authors": "Philipp H. Kindt, Trinad Chakraborty, Samarjit Chakraborty", "title": "How Reliable is Smartphone-based Electronic Contact Tracing for\n  COVID-19?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY eess.SP q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone-based electronic contact tracing is currently considered an\nessential tool towards easing lockdowns, curfews, and shelter-in-place orders\nissued by most governments around the world in response to the 2020 novel\ncoronavirus (SARS-CoV-2) crisis. While the focus on developing smartphone-based\ncontact tracing applications or apps has been on privacy concerns stemming from\nthe use of such apps, an important question that has not received sufficient\nattention is: How reliable will such smartphone-based electronic contact\ntracing be?\n  This is a technical question related to how two smartphones reliably register\ntheir mutual proximity. Here, we examine in detail the technical prerequisites\nrequired for effective smartphone-based contact tracing. The underlying\nmechanism that any contact tracing app relies on is called Neighbor Discovery\n(ND), which involves smartphones transmitting and scanning for Bluetooth\nsignals to record their mutual presence whenever they are in close proximity.\nThe hardware support and the software protocols used for ND in smartphones,\nhowever, were not designed for reliable contact tracing. In this paper, we\nquantitatively evaluate how reliably can smartphones do contact tracing. Our\nresults point towards the design of a wearable solution for contact tracing\nthat can overcome the shortcomings of a smartphone-based solution to provide\nmore reliable and accurate contact tracing. To the best of our knowledge, this\nis the first study that quantifies, both, the suitability and also the\ndrawbacks of smartphone-based contact tracing. Further, our results can be used\nto parameterize a ND protocol to maximize the reliability of any contact\ntracing app that uses it.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 09:02:53 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 13:48:44 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Kindt", "Philipp H.", ""], ["Chakraborty", "Trinad", ""], ["Chakraborty", "Samarjit", ""]]}, {"id": "2005.05710", "submitter": "Tim A. Majchrzak", "authors": "Gautam Kishore Shahi and Anne Dirkson and Tim A. Majchrzak", "title": "An Exploratory Study of COVID-19 Misinformation on Twitter", "comments": "20 pages, nine figures, four tables. Submitted for peer review,\n  revision 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 pandemic, social media has become a home ground for\nmisinformation. To tackle this infodemic, scientific oversight, as well as a\nbetter understanding by practitioners in crisis management, is needed. We have\nconducted an exploratory study into the propagation, authors and content of\nmisinformation on Twitter around the topic of COVID-19 in order to gain early\ninsights. We have collected all tweets mentioned in the verdicts of\nfact-checked claims related to COVID-19 by over 92 professional fact-checking\norganisations between January and mid-July 2020 and share this corpus with the\ncommunity. This resulted in 1 500 tweets relating to 1 274 false and 276\npartially false claims, respectively. Exploratory analysis of author accounts\nrevealed that the verified twitter handle(including Organisation/celebrity) are\nalso involved in either creating (new tweets) or spreading (retweet) the\nmisinformation. Additionally, we found that false claims propagate faster than\npartially false claims. Compare to a background corpus of COVID-19 tweets,\ntweets with misinformation are more often concerned with discrediting other\ninformation on social media. Authors use less tentative language and appear to\nbe more driven by concerns of potential harm to others. Our results enable us\nto suggest gaps in the current scientific coverage of the topic as well as\npropose actions for authorities and social media users to counter\nmisinformation.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:07:35 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 19:13:30 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Shahi", "Gautam Kishore", ""], ["Dirkson", "Anne", ""], ["Majchrzak", "Tim A.", ""]]}, {"id": "2005.06056", "submitter": "Lucy Simko", "authors": "Lucy Simko (1, 2 and 3), Ryan Calo (2 and 4), Franziska Roesner (1, 2\n  and 3), Tadayoshi Kohno (1, 2 and 3) ((1) Security and Privacy Research Lab,\n  University of Washington, (2) Tech Policy Lab, University of Washington, (3)\n  Paul G. Allen School of Computer Science & Engineering, University of\n  Washington, (4) School of Law, University of Washington)", "title": "COVID-19 Contact Tracing and Privacy: Studying Opinion and Preferences", "comments": "32 pages, 10 figures (including 5 in appendix B), 1 table, 2\n  appendices. NOTE: As of December 4, 2020, this report has been superseded by\n  Report Version 2.0,found at arXiv:2012.01553. Please read and cite Report\n  Version 2.0 instead", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing interest in technology-enabled contact tracing, the process\nof identifying potentially infected COVID-19 patients by notifying all recent\ncontacts of an infected person. Governments, technology companies, and research\ngroups alike recognize the potential for smartphones, IoT devices, and wearable\ntechnology to automatically track \"close contacts\" and identify prior contacts\nin the event of an individual's positive test. However, there is currently\nsignificant public discussion about the tensions between effective\ntechnology-based contact tracing and the privacy of individuals. To inform this\ndiscussion, we present the results of a sequence of online surveys focused on\ncontact tracing and privacy, each with 100 participants. Our first surveys were\non April 1 and 3, and we report primarily on those first two surveys, though we\npresent initial findings from later survey dates as well. Our results present\nthe diversity of public opinion and can inform the public discussion on whether\nand how to leverage technology to reduce the spread of COVID-19. We are\ncontinuing to conduct longitudinal measurements, and will update this report\nover time; citations to this version of the report should reference Report\nVersion 1.0, May 8, 2020. NOTE: As of December 4, 2020, this report has been\nsuperseded by Report Version 2.0, found at arXiv:2012.01553. Please read and\ncite Report Version 2.0 instead.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 21:18:24 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 18:11:20 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Simko", "Lucy", "", "1, 2 and 3"], ["Calo", "Ryan", "", "2 and 4"], ["Roesner", "Franziska", "", "1, 2\n  and 3"], ["Kohno", "Tadayoshi", "", "1, 2 and 3"]]}, {"id": "2005.06070", "submitter": "Ali H\\\"urriyeto\\u{g}lu", "authors": "Ali H\\\"urriyeto\\u{g}lu, Vanni Zavarella, Hristo Tanev, Erdem\n  Y\\\"or\\\"uk, Ali Safaya, Osman Mutlu", "title": "Automated Extraction of Socio-political Events from News (AESPEN):\n  Workshop and Shared Task Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our effort on automated extraction of socio-political events from\nnews in the scope of a workshop and a shared task we organized at Language\nResources and Evaluation Conference (LREC 2020). We believe the event\nextraction studies in computational linguistics and social and political\nsciences should further support each other in order to enable large scale\nsocio-political event information collection across sources, countries, and\nlanguages. The event consists of regular research papers and a shared task,\nwhich is about event sentence coreference identification (ESCI), tracks. All\nsubmissions were reviewed by five members of the program committee. The\nworkshop attracted research papers related to evaluation of machine learning\nmethodologies, language resources, material conflict forecasting, and a shared\ntask participation report in the scope of socio-political event information\ncollection. It has shown us the volume and variety of both the data sources and\nevent information collection approaches related to socio-political events and\nthe need to fill the gap between automated text processing techniques and\nrequirements of social and political sciences.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 22:07:14 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["H\u00fcrriyeto\u011flu", "Ali", ""], ["Zavarella", "Vanni", ""], ["Tanev", "Hristo", ""], ["Y\u00f6r\u00fck", "Erdem", ""], ["Safaya", "Ali", ""], ["Mutlu", "Osman", ""]]}, {"id": "2005.06261", "submitter": "Ehud Shapiro", "authors": "Luca Cardelli, Liav Orgad, Gal Shahaf, Ehud Shapiro and Nimrod Talmon", "title": "Digital Social Contracts: A Foundation for an Egalitarian and Just\n  Digital Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA cs.PL cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Almost two centuries ago Pierre-Joseph Proudhon proposed social contracts --\nvoluntary agreements among free people -- as a foundation from which an\negalitarian and just society can emerge. A \\emph{digital social contract} is\nthe novel incarnation of this concept for the digital age: a voluntary\nagreement between people that is specified, undertaken, and fulfilled in the\ndigital realm. It embodies the notion of \"code-is-law\" in its purest form, in\nthat a digital social contract is in fact a program -- code in a social\ncontracts programming language, which specifies the digital actions parties to\nthe social contract may take; and the parties to the contract are entrusted,\nequally, with the task of ensuring that each party abides by the contract.\nParties to a social contract are identified via their public keys, and the one\nand only type of action a party to a digital social contract may take is a\n\"digital speech act\" -- signing an utterance with her private key and sending\nit to the other parties to the contract. Here, we present a formal definition\nof a digital social contract as agents that communicate asynchronously via\ncrypto-speech acts, where the output of each agent is the input of all the\nother agents. We outline an abstract design for a social contracts programming\nlanguage and show, via programming examples, that key application areas,\nincluding social community; simple sharing-economy applications; egalitarian\ncurrency networks; and democratic community governance, can all be expressed\nelegantly and efficiently as digital social contracts.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 11:45:49 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 09:40:06 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 09:34:56 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 22:33:03 GMT"}, {"version": "v5", "created": "Sun, 19 Jul 2020 18:42:36 GMT"}, {"version": "v6", "created": "Thu, 17 Sep 2020 08:39:43 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Cardelli", "Luca", ""], ["Orgad", "Liav", ""], ["Shahaf", "Gal", ""], ["Shapiro", "Ehud", ""], ["Talmon", "Nimrod", ""]]}, {"id": "2005.06302", "submitter": "Sarah Spiekermann", "authors": "Alexander Novotny, Sarah Spiekermann", "title": "Oblivion of Online Reputation: How Time Cues Improve Online Recruitment", "comments": "obsolete reputation, online crowdsourcing labour markets, right to be\n  forgotten", "journal-ref": null, "doi": "10.1504/IJEB.2017.10003869", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online crowdsourcing labour markets, employers decide which job-seekers to\nhire based on their reputation profiles. If reputation systems neglect the\naspect of time when displaying reputation profiles, though, employers risk\ntaking false decisions, deeming an obsolete reputation to be still relevant. As\na consequence, job-seekers might be unwarrantedly deprived of getting hired for\nnew jobs and can be harmed in their professional careers in the long-run. This\npaper argues that exposing employers to the temporal context of job-seekers'\nreputation leads to better hiring decisions. The visible temporal context in\nreputation systems helps employers to ignore a job-seeker's obsolete\nreputation. An experimental lab study with 335 students shows that current\nreputation systems fall short of making them aware of obsolete reputation. In\ncontrast, graphical time cues improve the social efficiency of hiring\ndecisions.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:23:05 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Novotny", "Alexander", ""], ["Spiekermann", "Sarah", ""]]}, {"id": "2005.06324", "submitter": "Sarah Spiekermann", "authors": "Sarah Spiekermann, Alexander Novotny", "title": "A vision for global privacy bridges: Technical and legal measures for\n  international data markets", "comments": "Information privacy Personal data market Economics of personal\n  information Privacy regulation", "journal-ref": null, "doi": "10.1016/j.clsr.2015.01.009", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From the early days of the information economy, personal data has been its\nmost valuable asset. Despite data protection laws and an acknowledged right to\nprivacy, trading personal information has become a business equated with\n\"trading oil\". Most of this business is done without the knowledge and active\ninformed consent of the people. But as data breaches and abuses are made public\nthrough the media, consumers react. They become irritated about companies' data\nhandling practices, lose trust, exercise political pressure and start to\nprotect their privacy with the help of technical tools. As a result, companies'\nInternet business models that are based on personal data are unsettled. An open\nconflict is arising between business demands for data and a desire for privacy.\nAs of 2015 no true answer is in sight of how to resolve this conflict.\nTechnologists, economists and regulators are struggling to develop technical\nsolutions and policies that meet businesses' demand for more data while still\nmaintaining privacy. Yet, most of the proposed solutions fail to account for\nmarket complexity and provide no pathway to technological and legal\nimplementation. They lack a bigger vision for data use and privacy. To break\nthis vicious cycle, we propose and test such a vision of a personal information\nmarket with privacy. We accumulate technical and legal measures that have been\nproposed by technical and legal scholars over the past two decades. And out of\nthis existing knowledge, we compose something new: a four-space market model\nfor personal data.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:55:50 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Spiekermann", "Sarah", ""], ["Novotny", "Alexander", ""]]}, {"id": "2005.06342", "submitter": "Saraju Mohanty", "authors": "Venkanna Udutalapally and Saraju P. Mohanty and Vishal Pallagani and\n  Vedant Khandelwal", "title": "sCrop: A Internet-of-Agro-Things (IoAT) Enabled Solar Powered Smart\n  Device for Automatic Plant Disease Prediction", "comments": "23 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-of-Things (IoT) is omnipresent, ranging from home solutions to\nturning wheels for the fourth industrial revolution. This article presents the\nnovel concept of Internet-of-Agro-Things (IoAT) with an example of automated\nplant disease prediction. It consists of solar enabled sensor nodes which help\nin continuous sensing and automating agriculture. The existing solutions have\nimplemented a battery powered sensor node. On the contrary, the proposed system\nhas adopted the use of an energy efficient way of powering using solar energy.\nIt is observed that around 80% of the crops are attacked with microbial\ndiseases in traditional agriculture. To prevent this, a health maintenance\nsystem is integrated with the sensor node, which captures the image of the crop\nand performs an analysis with the trained Convolutional Neural Network (CNN)\nmodel. The deployment of the proposed system is demonstrated in a real-time\nenvironment using a microcontroller, solar sensor nodes with a camera module,\nand an mobile application for the farmers visualization of the farms. The\ndeployed prototype was deployed for two months and has achieved a robust\nperformance by sustaining in varied weather conditions and continued to remain\nrust-free. The proposed deep learning framework for plant disease prediction\nhas achieved an accuracy of 99.2% testing accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 05:54:28 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Udutalapally", "Venkanna", ""], ["Mohanty", "Saraju P.", ""], ["Pallagani", "Vishal", ""], ["Khandelwal", "Vedant", ""]]}, {"id": "2005.06380", "submitter": "Pierre Le Bras", "authors": "Pierre Le Bras, Azimeh Gharavi, David A. Robb, Ana F. Vidal, Stefano\n  Padilla, Mike J. Chantler", "title": "Visualising COVID-19 Research", "comments": "11 pages. 10 figures. Preprint paper made available here prior to\n  submission. Update: special characters corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The world has seen in 2020 an unprecedented global outbreak of SARS-CoV-2, a\nnew strain of coronavirus, causing the COVID-19 pandemic, and radically\nchanging our lives and work conditions. Many scientists are working tirelessly\nto find a treatment and a possible vaccine. Furthermore, governments,\nscientific institutions and companies are acting quickly to make resources\navailable, including funds and the opening of large-volume data repositories,\nto accelerate innovation and discovery aimed at solving this pandemic. In this\npaper, we develop a novel automated theme-based visualisation method, combining\nadvanced data modelling of large corpora, information mapping and trend\nanalysis, to provide a top-down and bottom-up browsing and search interface for\nquick discovery of topics and research resources. We apply this method on two\nrecently released publications datasets (Dimensions' COVID-19 dataset and the\nAllen Institute for AI's CORD-19). The results reveal intriguing information\nincluding increased efforts in topics such as social distancing; cross-domain\ninitiatives (e.g. mental health and education); evolving research in medical\ntopics; and the unfolding trajectory of the virus in different territories\nthrough publications. The results also demonstrate the need to quickly and\nautomatically enable search and browsing of large corpora. We believe our\nmethodology will improve future large volume visualisation and discovery\nsystems but also hope our visualisation interfaces will currently aid\nscientists, researchers, and the general public to tackle the numerous issues\nin the fight against the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 15:45:14 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 10:06:39 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Bras", "Pierre Le", ""], ["Gharavi", "Azimeh", ""], ["Robb", "David A.", ""], ["Vidal", "Ana F.", ""], ["Padilla", "Stefano", ""], ["Chantler", "Mike J.", ""]]}, {"id": "2005.06464", "submitter": "Tobias Huber", "authors": "Tobias A. Huber and Didier Sornette", "title": "Boom, Bust, and Bitcoin: Bitcoin-Bubbles As Innovation Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bitcoin represents one of the most interesting technological breakthroughs\nand socio-economic experiments of the last decades. In this paper, we examine\nthe role of speculative bubbles in the process of Bitcoin's technological\nadoption by analyzing its social dynamics. We trace Bitcoin's genesis and\ndissect the nature of its techno-economic innovation. In particular, we present\nan analysis of the techno-economic feedback loops that drive Bitcoin's price\nand network effects. Based on our analysis of Bitcoin, we test and further\nrefine the Social Bubble Hypothesis, which holds that bubbles constitute an\nessential component in the process of technological innovation. We argue that a\nhierarchy of repeating and exponentially increasing series of bubbles and hype\ncycles, which has occurred over the past decade since its inception, has\nbootstrapped Bitcoin into existence.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 10:47:37 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Huber", "Tobias A.", ""], ["Sornette", "Didier", ""]]}, {"id": "2005.06465", "submitter": "Anton Vladzymyrskyy", "authors": "S.P. Morozov, A.E. Andreychenko, N.A. Pavlov, A.V. Vladzymyrskyy, N.V.\n  Ledikhova, V.A. Gombolevskiy, I.A. Blokhin, P.B. Gelezhe, A.V. Gonchar, V.Yu.\n  Chernina", "title": "MosMedData: Chest CT Scans With COVID-19 Related Findings Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This dataset contains anonymised human lung computed tomography (CT) scans\nwith COVID-19 related findings, as well as without such findings. A small\nsubset of studies has been annotated with binary pixel masks depicting regions\nof interests (ground-glass opacifications and consolidations). CT scans were\nobtained between 1st of March, 2020 and 25th of April, 2020, and provided by\nmunicipal hospitals in Moscow, Russia. Permanent link:\nhttps://mosmed.ai/datasets/covid19_1110. This dataset is licensed under a\nCreative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported (CC BY-NC-ND\n3.0) License. Key words: artificial intelligence, COVID-19, machine learning,\ndataset, CT, chest, imaging\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:04:37 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Morozov", "S. P.", ""], ["Andreychenko", "A. E.", ""], ["Pavlov", "N. A.", ""], ["Vladzymyrskyy", "A. V.", ""], ["Ledikhova", "N. V.", ""], ["Gombolevskiy", "V. A.", ""], ["Blokhin", "I. A.", ""], ["Gelezhe", "P. B.", ""], ["Gonchar", "A. V.", ""], ["Chernina", "V. Yu.", ""]]}, {"id": "2005.06558", "submitter": "Benjamin Finley", "authors": "Alexandr Vesselkov, Benjamin Finley, Jouko Vankka", "title": "Russian trolls speaking Russian: Regional Twitter operations and MH17", "comments": "12th ACM Conference on Web Science (WebSci '20), July 6--10, 2020,\n  Southampton, United Kingdom", "journal-ref": null, "doi": "10.1145/3394231.3397898", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of social media in promoting media pluralism was initially viewed as\nwholly positive. However, some governments are allegedly manipulating social\nmedia by hiring online commentators (also known as trolls) to spread propaganda\nand disinformation. In particular, an alleged system of professional trolls\noperating both domestically and internationally exists in Russia. In 2018,\nTwitter released data on accounts identified as Russian trolls, starting a wave\nof research. However, while foreign-targeted English language operations of\nthese trolls have received significant attention, no research has analyzed\ntheir Russian language domestic and regional-targeted activities. We address\nthis gap by characterizing the Russian-language operations of Russian trolls.\nWe first perform a descriptive analysis, and then focus in on the trolls'\noperation related to the crash of Malaysia Airlines flight MH17.\n  Among other things, we find that Russian-language trolls have run 163 hashtag\ncampaigns (where hashtag use grows abruptly within a month). The main political\nsentiments of such campaigns were praising Russia and Putin (29%), criticizing\nUkraine (26%), and criticizing the United States and Obama (9%). Further,\ntrolls actively reshared information with 76% of tweets being retweets or\ncontaining a URL. Additionally, we observe periodic temporal patterns of\ntweeting suggesting that trolls use automation tools. Further, we find that\ntrolls' information campaign on the MH17 crash was the largest in terms of\ntweet count. However, around 68% of tweets posted with MH17 hashtags were\nlikely used simply for hashtag amplification. With these tweets excluded, about\n49% of the tweets suggested to varying levels that Ukraine was responsible for\nthe crash, and only 13% contained disinformation and propaganda presented as\nnews. Interestingly, trolls promoted inconsistent alternative theories for the\ncrash.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 19:48:12 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Vesselkov", "Alexandr", ""], ["Finley", "Benjamin", ""], ["Vankka", "Jouko", ""]]}, {"id": "2005.06585", "submitter": "Kevin Fu", "authors": "Wayne Burleson, Kevin Fu, Denise Anthony, Jorge Guajardo, Carl Gunter,\n  Kyle Ingols, Jean-Baptiste Jeannin, Farinaz Koushanafar, Carl Landwehr, and\n  Susan Squires", "title": "Grand Challenges for Embedded Security Research in a Connected World", "comments": "A Computing Community Consortium (CCC) workshop report, 24 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020report_1", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protecting embedded security is becoming an increasingly challenging research\nproblem for embedded systems due to a number of emerging trends in hardware,\nsoftware, networks, and applications. Without fundamental advances in, and an\nunderstanding of embedded security it will be difficult for future engineers to\nprovide assurance for the Internet of Things (IoT) and Operational Technology\n(OT) in wide ranging applications, from home automation and autonomous\ntransportation to medical devices and factory floors. Common to such\napplications are cyberphysical risks and consequences stemming from a lack of\nembedded security. The Computing Community Consortium (CCC) held a one-day\nvisioning workshop to explore these issues. The workshop focused on five major\napplication areas of embedded systems, namely (1) medical/wearable devices, (2)\nautonomous systems (drones, vehicles, robots), (3) smart homes, (4) industry\nand supply chain, and (5) critical infrastructure. This report synthesizes the\nresults of that workshop and develops a list of strategic goals for research\nand education over the next 5-10 years.\n  Embedded security in connected devices presents challenges that require a\nbroad look at the overall systems design, including human and societal\ndimensions as well as technical. Particular issues related to embedded security\nare a subset of the overall security of the application areas, which must also\nbalance other design criteria such as cost, power, reliability, usability and\nfunction. Recent trends are converging to make the security of embedded systems\nan increasingly important and difficult objective, requiring new\ntrans-disciplinary approaches to solve problems on a 5-10 year horizon.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:01:57 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Burleson", "Wayne", ""], ["Fu", "Kevin", ""], ["Anthony", "Denise", ""], ["Guajardo", "Jorge", ""], ["Gunter", "Carl", ""], ["Ingols", "Kyle", ""], ["Jeannin", "Jean-Baptiste", ""], ["Koushanafar", "Farinaz", ""], ["Landwehr", "Carl", ""], ["Squires", "Susan", ""]]}, {"id": "2005.06599", "submitter": "Pavlos Papadopoulos", "authors": "Orestis Christou and Nikolaos Pitropakis and Pavlos Papadopoulos and\n  Sean McKeown and William J. Buchanan", "title": "Phishing URL Detection Through Top-level Domain Analysis: A Descriptive\n  Approach", "comments": "In Proceedings of the 6th ICISSP", "journal-ref": "ICISSP, Volume 1, pages 289-298 (2020)", "doi": "10.5220/0008902202890298", "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is considered to be one of the most prevalent cyber-attacks because\nof its immense flexibility and alarmingly high success rate. Even with adequate\ntraining and high situational awareness, it can still be hard for users to\ncontinually be aware of the URL of the website they are visiting. Traditional\ndetection methods rely on blocklists and content analysis, both of which\nrequire time-consuming human verification. Thus, there have been attempts\nfocusing on the predictive filtering of such URLs. This study aims to develop a\nmachine-learning model to detect fraudulent URLs which can be used within the\nSplunk platform. Inspired from similar approaches in the literature, we trained\nthe SVM and Random Forests algorithms using malicious and benign datasets found\nin the literature and one dataset that we created. We evaluated the algorithms'\nperformance with precision and recall, reaching up to 85% precision and 87%\nrecall in the case of Random Forests while SVM achieved up to 90% precision and\n88% recall using only descriptive features.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 21:41:29 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Christou", "Orestis", ""], ["Pitropakis", "Nikolaos", ""], ["Papadopoulos", "Pavlos", ""], ["McKeown", "Sean", ""], ["Buchanan", "William J.", ""]]}, {"id": "2005.06604", "submitter": "P. Alison Paprica", "authors": "P. Alison Paprica, Eric Sutherland, Andrea Smith, Michael Brudno,\n  Rosario G. Cartagena, Monique Crichlow, Brian K Courtney, Chris Loken,\n  Kimberlyn M. McGrail, Alex Ryan, Michael J Schull, Adrian Thorogood, Carl\n  Virtanen, Kathleen Yang", "title": "Essential requirements for establishing and operating data trusts:\n  practical guidance based on a working meeting of fifteen Canadian\n  organizations and initiatives", "comments": "17 pages including references, 1 text box", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Introduction: Increasingly, the label data trust is being applied to\nrepeatable mechanisms or approaches to sharing data in a timely, fair, safe and\nequitable way. However, there is a gap in terms of practical guidance about how\nto establish and operate a data trust.\n  Aim and Approach: In December 2019, the Canadian Institute for Health\nInformation and the Vector Institute for Artificial Intelligence convened a\nworking meeting of 19 people representing 15 Canadian organizations/initiatives\ninvolved in data sharing, most of which focus on public sector health data. The\nobjective was to identify essential requirements for the establishment and\noperation of data trusts. Preliminary findings were presented during the\nmeeting then refined as participants and co-authors identified relevant\nliterature and contributed to this manuscript.\n  Results: Twelve (12) minimum specification requirements (min specs) for data\ntrusts were identified. The foundational min spec is that data trusts must meet\nall legal requirements, including legal authority to collect, hold or share\ndata. In addition, there was agreement that data trusts must have (i) an\naccountable governing body which ensures the data trust advances its stated\npurpose and is transparent, (ii) comprehensive data management including\nresponsible parties and clear processes for the collection, storage, access,\ndisclosure and use of data, (iii) training and accountability requirements for\nall data users and (iv) ongoing public and stakeholder engagement.\n  Conclusion / Implications: Based on a review of the literature and advice\nfrom participants from 15 Canadian organizations/initiatives, practical\nguidance in the form of twelve min specs for data trusts were agreed on. Public\nengagement and continued exchange of insights and experience is recommended on\nthis evolving topic.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 20:20:40 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Paprica", "P. Alison", ""], ["Sutherland", "Eric", ""], ["Smith", "Andrea", ""], ["Brudno", "Michael", ""], ["Cartagena", "Rosario G.", ""], ["Crichlow", "Monique", ""], ["Courtney", "Brian K", ""], ["Loken", "Chris", ""], ["McGrail", "Kimberlyn M.", ""], ["Ryan", "Alex", ""], ["Schull", "Michael J", ""], ["Thorogood", "Adrian", ""], ["Virtanen", "Carl", ""], ["Yang", "Kathleen", ""]]}, {"id": "2005.06610", "submitter": "Massimo La Morgia", "authors": "Massimo La Morgia, Alessandro Mei, Francesco Sassi, Julinda Stefa", "title": "Pump and Dumps in the Bitcoin Era: Real Time Detection of Cryptocurrency\n  Market Manipulations", "comments": "Accepted for publication at The 29th International Conference on\n  Computer Communications and Networks (ICCCN 2020)", "journal-ref": null, "doi": "10.1109/ICCCN49398.2020.9209660", "report-no": null, "categories": "cs.CY cs.CR cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, cryptocurrencies are increasingly popular. Even people who\nare not experts have started to invest in these securities and nowadays\ncryptocurrency exchanges process transactions for over 100 billion US dollars\nper month. However, many cryptocurrencies have low liquidity and therefore they\nare highly prone to market manipulation schemes. In this paper, we perform an\nin-depth analysis of pump and dump schemes organized by communities over the\nInternet. We observe how these communities are organized and how they carry out\nthe fraud. Then, we report on two case studies related to pump and dump groups.\nLastly, we introduce an approach to detect the fraud in real time that\noutperforms the current state of the art, so to help investors stay out of the\nmarket when a pump and dump scheme is in action.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:36:18 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["La Morgia", "Massimo", ""], ["Mei", "Alessandro", ""], ["Sassi", "Francesco", ""], ["Stefa", "Julinda", ""]]}, {"id": "2005.06612", "submitter": "Siyuan Liu", "authors": "Xiuyi Fan, Siyuan Liu, Jiarong Chen, Thomas C. Henderson", "title": "An Investigation of COVID-19 Spreading Factors with Explainable AI\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since COVID-19 was first identified in December 2019, various public health\ninterventions have been implemented across the world. As different measures are\nimplemented at different countries at different times, we conduct an assessment\nof the relative effectiveness of the measures implemented in 18 countries and\nregions using data from 22/01/2020 to 02/04/2020. We compute the top one and\ntwo measures that are most effective for the countries and regions studied\nduring the period. Two Explainable AI techniques, SHAP and ECPI, are used in\nour study; such that we construct (machine learning) models for predicting the\ninstantaneous reproduction number ($R_t$) and use the models as surrogates to\nthe real world and inputs that the greatest influence to our models are seen as\nmeasures that are most effective. Across-the-board, city lockdown and contact\ntracing are the two most effective measures. For ensuring $R_t<1$, public\nwearing face masks is also important. Mass testing alone is not the most\neffective measure although when paired with other measures, it can be\neffective. Warm temperature helps for reducing the transmission.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 12:01:12 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Fan", "Xiuyi", ""], ["Liu", "Siyuan", ""], ["Chen", "Jiarong", ""], ["Henderson", "Thomas C.", ""]]}, {"id": "2005.06616", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Varun Gupta, Ekaterina Kochmar, Dung D. Vu, Robert\n  Belfer, Joelle Pineau, Aaron Courville, Laurent Charlin, Yoshua Bengio", "title": "A Large-Scale, Open-Domain, Mixed-Interface Dialogue-Based ITS for STEM", "comments": "6 pages, 1 figure, 1 table, accepted for publication in the 21st\n  International Conference on Artificial Intelligence in Education (AIED 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Korbit, a large-scale, open-domain, mixed-interface,\ndialogue-based intelligent tutoring system (ITS). Korbit uses machine learning,\nnatural language processing and reinforcement learning to provide interactive,\npersonalized learning online. Korbit has been designed to easily scale to\nthousands of subjects, by automating, standardizing and simplifying the content\ncreation process. Unlike other ITS, a teacher can develop new learning modules\nfor Korbit in a matter of hours. To facilitate learning across a widerange of\nSTEM subjects, Korbit uses a mixed-interface, which includes videos,\ninteractive dialogue-based exercises, question-answering, conceptual diagrams,\nmathematical exercises and gamification elements. Korbit has been built to\nscale to millions of students, by utilizing a state-of-the-art cloud-based\nmicro-service architecture. Korbit launched its first course in 2019 on machine\nlearning, and since then over 7,000 students have enrolled. Although Korbit was\ndesigned to be open-domain and highly scalable, A/B testing experiments with\nreal-world students demonstrate that both student learning outcomes and student\nmotivation are substantially improved compared to typical online courses.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 02:45:43 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Gupta", "Varun", ""], ["Kochmar", "Ekaterina", ""], ["Vu", "Dung D.", ""], ["Belfer", "Robert", ""], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""], ["Charlin", "Laurent", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2005.06618", "submitter": "Procheta Sen", "authors": "Procheta Sen, Debasis Ganguly", "title": "Towards Socially Responsible AI: Cognitive Bias-Aware Multi-Objective\n  Learning", "comments": null, "journal-ref": "AAAI 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human society had a long history of suffering from cognitive biases leading\nto social prejudices and mass injustice. The prevalent existence of cognitive\nbiases in large volumes of historical data can pose a threat of being\nmanifested as unethical and seemingly inhuman predictions as outputs of AI\nsystems trained on such data. To alleviate this problem, we propose a\nbias-aware multi-objective learning framework that given a set of identity\nattributes (e.g. gender, ethnicity etc.) and a subset of sensitive categories\nof the possible classes of prediction outputs, learns to reduce the frequency\nof predicting certain combinations of them, e.g. predicting stereotypes such as\n`most blacks use abusive language', or `fear is a virtue of women'. Our\nexperiments conducted on an emotion prediction task with balanced class priors\nshows that a set of baseline bias-agnostic models exhibit cognitive biases with\nrespect to gender, such as women are prone to be afraid whereas men are more\nprone to be angry. In contrast, our proposed bias-aware multi-objective\nlearning methodology is shown to reduce such biases in the predictied emotions.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 17:01:53 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 07:20:09 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Sen", "Procheta", ""], ["Ganguly", "Debasis", ""]]}, {"id": "2005.06619", "submitter": "Ramit Debnath", "authors": "Ramit Debnath and Ronita Bardhan", "title": "India nudges to contain COVID-19 pandemic: a reactive public policy\n  analysis using machine-learning based topic modelling", "comments": "25 pages with 10 figures and 9 tables", "journal-ref": "PLoS ONE 15(9): e0238972 (2020)", "doi": "10.1371/journal.pone.0238972", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  India locked down 1.3 billion people on March 25, 2020 in the wake of\nCOVID-19 pandemic. The economic cost of it was estimated at USD 98 billion,\nwhile the social costs are still unknown. This study investigated how\ngovernment formed reactive policies to fight coronavirus across its policy\nsectors. Primary data was collected from the Press Information Bureau (PIB) in\nthe form press releases of government plans, policies, programme initiatives\nand achievements. A text corpus of 260,852 words was created from 396 documents\nfrom the PIB. An unsupervised machine-based topic modelling using Latent\nDirichlet Allocation (LDA) algorithm was performed on the text corpus. It was\ndone to extract high probability topics in the policy sectors. The\ninterpretation of the extracted topics was made through a nudge theoretic lens\nto derive the critical policy heuristics of the government. Results showed that\nmost interventions were targeted to generate endogenous nudge by using external\ntriggers. Notably, the nudges from the Prime Minister of India was critical in\ncreating herd effect on lockdown and social distancing norms across the nation.\nA similar effect was also observed around the public health (e.g., masks in\npublic spaces; Yoga and Ayurveda for immunity), transport (e.g., old trains\nconverted to isolation wards), micro, small and medium enterprises (e.g., rapid\nproduction of PPE and masks), science and technology sector (e.g., diagnostic\nkits, robots and nano-technology), home affairs (e.g., surveillance and\nlockdown), urban (e.g. drones, GIS-tools) and education (e.g., online\nlearning). A conclusion was drawn on leveraging these heuristics are crucial\nfor lockdown easement planning.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 04:14:09 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 08:09:16 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Debnath", "Ramit", ""], ["Bardhan", "Ronita", ""]]}, {"id": "2005.06620", "submitter": "Daniel Schiff", "authors": "Daniel S. Schiff, Aladdin Ayesh, Laura Musikanski, John C. Havens", "title": "IEEE 7010: A New Standard for Assessing the Well-being Implications of\n  Artificial Intelligence", "comments": "Preprint draft, a version was presented at the 2020 IEEE\n  International Conference on Systems, Man, and Cybernetics (SMC), Special\n  Session on Human Well-Being in the Context of Autonomous and Intelligent\n  Systems. Final version is available at indicated source", "journal-ref": "2020 IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC), Oct. 2020, pp. 2746-2753", "doi": "10.1109/SMC42975.2020.9283454", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) enabled products and services are becoming a\nstaple of everyday life. While governments and businesses are eager to enjoy\nthe benefits of AI innovations, the mixed impact of these autonomous and\nintelligent systems on human well-being has become a pressing issue. This\narticle introduces one of the first international standards focused on the\nsocial and ethical implications of AI: The Institute of Electrical and\nElectronics Engineering (IEEE) Standard (Std) 7010-2020 Recommended Practice\nfor Assessing the Impact of Autonomous and Intelligent Systems on Human\nWell-being. Incorporating well-being factors throughout the lifecycle of AI is\nboth challenging and urgent and IEEE 7010 provides key guidance for those who\ndesign, deploy, and procure these technologies. We begin by articulating the\nbenefits of an approach for AI centered around well-being and the measurement\nof well-being data. Next, we provide an overview of IEEE 7010, including its\nkey principles and how the standard relates to approaches and perspectives in\nplace in the AI community. Finally, we indicate where future efforts are\nneeded.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 17:24:51 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2020 17:32:38 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 19:30:00 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Schiff", "Daniel S.", ""], ["Ayesh", "Aladdin", ""], ["Musikanski", "Laura", ""], ["Havens", "John C.", ""]]}, {"id": "2005.06621", "submitter": "Scott McLachlan Dr", "authors": "Scott McLachlan, Peter Lucas, Kudakwashe Dube, Graham A Hitman, Magda\n  Osman, Evangelia Kyrimi, Martin Neil, Norman E Fenton", "title": "Bluetooth Smartphone Apps: Are they the most private and effective\n  solution for COVID-19 contact tracing?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many digital solutions mainly involving Bluetooth technology are being\nproposed for Contact Tracing Apps (CTA) to reduce the spread of COVID-19.\nConcerns have been raised regarding privacy, consent, uptake required in a\ngiven population, and the degree to which use of CTAs can impact individual\nbehaviours. However, very few groups have taken a holistic approach and\npresented a combined solution. None has presented their CTA in such a way as to\nensure that even the most suggestible member of our community does not become\ncomplacent and assume that CTA operates as an invisible shield, making us and\nour families impenetrable or immune to the disease. We propose to build on some\nof the digital solutions already under development that, with addition of a\nBayesian model that predicts likelihood for infection supplemented by\ntraditional symptom and contact tracing, that can enable us to reach 90% of a\npopulation. When combined with an effective communication strategy and social\ndistancing, we believe solutions like the one proposed here can have a very\nbeneficial effect on containing the spread of this pandemic.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 07:07:00 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 16:52:11 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["McLachlan", "Scott", ""], ["Lucas", "Peter", ""], ["Dube", "Kudakwashe", ""], ["Hitman", "Graham A", ""], ["Osman", "Magda", ""], ["Kyrimi", "Evangelia", ""], ["Neil", "Martin", ""], ["Fenton", "Norman E", ""]]}, {"id": "2005.06622", "submitter": "Martin Cooney", "authors": "Martin Cooney, Sepideh Pashami, Eric J\\\"arpe, Awais Ashfaq", "title": "Avoiding Improper Treatment of Persons with Dementia by Care Robots", "comments": "4 pages. Published. (Submitted: Jan. 22, 2019; Accepted: Jan. 30,\n  2019; Camera-ready submitted: Feb. 6, 2019.)", "journal-ref": "ACM/IEEE International Conference on Human-Robot Interaction (HRI)\n  Workshop on The Dark Side of Human-Robot Interaction: Ethical Considerations\n  and Community Guidelines for the Field of HRI, Daegu, South Korea, March 11,\n  2019", "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phrase \"most cruel and revolting crimes\" has been used to describe some\npoor historical treatment of vulnerable impaired persons by precisely those who\nshould have had the responsibility of protecting and helping them. We believe\nwe might be poised to see history repeat itself, as increasingly human-like\naware robots become capable of engaging in behavior which we would consider\nimmoral in a human--either unknowingly or deliberately. In the current paper we\nfocus in particular on exploring some potential dangers affecting persons with\ndementia (PWD), which could arise from insufficient software or external\nfactors, and describe a proposed solution involving rich causal models and\naccountability measures: Specifically, the Consequences of Needs-driven\nDementia-compromised Behaviour model (C-NDB) could be adapted to be used with\nconversation topic detection, causal networks and multi-criteria decision\nmaking, alongside reports, audits, and deterrents. Our aim is that the\nconsiderations raised could help inform the design of care robots intended to\nsupport well-being in PWD.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 14:34:13 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Cooney", "Martin", ""], ["Pashami", "Sepideh", ""], ["J\u00e4rpe", "Eric", ""], ["Ashfaq", "Awais", ""]]}, {"id": "2005.06626", "submitter": "Essaid Sabir", "authors": "Zineb Mahrez, Essaid Sabir, Elarbi Badidi, Walid Saad, Mohamed Sadik", "title": "Smart Urban Mobility: When Mobility Systems Meet Smart Data", "comments": "18 pages, 8 tables, 2 figures, 125 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cities around the world are expanding dramatically, with urban population\ngrowth reaching nearly 2.5 billion people in urban areas and road traffic\ngrowth exceeding 1.2 billion cars by 2050. The economic contribution of the\ntransport sector represents 5% of the GDP in Europe and costs an average of US\n$482.05 billion in the United States. These figures indicate the rapid rise of\nindustrial cities and the urgent need to move from traditional cities to smart\ncities. This article provides a survey of different approaches and technologies\nsuch as intelligent transportation systems (ITS) that leverage communication\ntechnologies to help maintain road users safe while driving, as well as support\nautonomous mobility through the optimization of control systems. The role of\nITS is strengthened when combined with accurate artificial intelligence models\nthat are built to optimize urban planning, analyze crowd behavior and predict\ntraffic conditions. AI-driven ITS is becoming possible thanks to the existence\nof a large volume of mobility data generated by billions of users through their\nuse of new technologies and online social media. The optimization of urban\nplanning enhances vehicle routing capabilities and solves traffic congestion\nproblems, as discussed in this paper. From an ecological perspective, we\ndiscuss the measures and incentives provided to foster the use of mobility\nsystems. We also underline the role of the political will in promoting open\ndata in the transport sector, considered as an essential ingredient for\ndeveloping technological solutions necessary for cities to become healthier and\nmore sustainable.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 13:53:01 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Mahrez", "Zineb", ""], ["Sabir", "Essaid", ""], ["Badidi", "Elarbi", ""], ["Saad", "Walid", ""], ["Sadik", "Mohamed", ""]]}, {"id": "2005.06630", "submitter": "Ahmed Allam", "authors": "Ahmed Allam, Matthias Dittberner, Anna Sintsova, Dominique Brodbeck,\n  Michael Krauthammer", "title": "Patient Similarity Analysis with Longitudinal Health Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare professionals have long envisioned using the enormous processing\npowers of computers to discover new facts and medical knowledge locked inside\nelectronic health records. These vast medical archives contain time-resolved\ninformation about medical visits, tests and procedures, as well as outcomes,\nwhich together form individual patient journeys. By assessing the similarities\namong these journeys, it is possible to uncover clusters of common disease\ntrajectories with shared health outcomes. The assignment of patient journeys to\nspecific clusters may in turn serve as the basis for personalized outcome\nprediction and treatment selection. This procedure is a non-trivial\ncomputational problem, as it requires the comparison of patient data with\nmulti-dimensional and multi-modal features that are captured at different times\nand resolutions. In this review, we provide a comprehensive overview of the\ntools and methods that are used in patient similarity analysis with\nlongitudinal data and discuss its potential for improving clinical decision\nmaking.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 07:06:02 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Allam", "Ahmed", ""], ["Dittberner", "Matthias", ""], ["Sintsova", "Anna", ""], ["Brodbeck", "Dominique", ""], ["Krauthammer", "Michael", ""]]}, {"id": "2005.06631", "submitter": "Dongqi Wu", "authors": "Guangchun Ruan, Dongqi Wu, Xiangtian Zheng, Haiwang Zhong, Chongqing\n  Kang, Munther A. Dahleh, S. Sivaranjani, Le Xie", "title": "A Cross-Domain Approach to Analyzing the Short-Run Impact of COVID-19 on\n  the U.S. Electricity Sector", "comments": "This paper has been accepted for publication by Joule. The manuscript\n  can also be accessed from EnerarXiv:\n  http://www.enerarxiv.org/page/thesis.html?id=1989", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus disease (COVID-19) has rapidly spread around the globe\nin 2020, with the U.S. becoming the epicenter of COVID-19 cases since late\nMarch. As the U.S. begins to gradually resume economic activity, it is\nimperative for policymakers and power system operators to take a scientific\napproach to understanding and predicting the impact on the electricity sector.\nHere, we release a first-of-its-kind cross-domain open-access data hub,\nintegrating data from across all existing U.S. wholesale electricity markets\nwith COVID-19 case, weather, cellular location, and satellite imaging data.\nLeveraging cross-domain insights from public health and mobility data, we\nuncover a significant reduction in electricity consumption across that is\nstrongly correlated with the rise in the number of COVID-19 cases, degree of\nsocial distancing, and level of commercial activity.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 22:16:13 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 17:05:32 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 23:38:00 GMT"}, {"version": "v4", "created": "Sat, 13 Jun 2020 22:15:56 GMT"}, {"version": "v5", "created": "Sun, 12 Jul 2020 05:39:55 GMT"}, {"version": "v6", "created": "Wed, 19 Aug 2020 02:47:06 GMT"}, {"version": "v7", "created": "Fri, 28 Aug 2020 02:53:08 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Ruan", "Guangchun", ""], ["Wu", "Dongqi", ""], ["Zheng", "Xiangtian", ""], ["Zhong", "Haiwang", ""], ["Kang", "Chongqing", ""], ["Dahleh", "Munther A.", ""], ["Sivaranjani", "S.", ""], ["Xie", "Le", ""]]}, {"id": "2005.06637", "submitter": "Nasir Saeed", "authors": "Nasir Saeed and Ahmed Bader and Tareq Y. Al-Naffouri and Mohamed-Slim\n  Alouini", "title": "When Wireless Communication Faces COVID-19: Combating the Pandemic and\n  Saving the Economy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The year 2020 is experiencing a global health and economic crisis due to the\nCOVID-19 pandemic. Countries across the world are using digital technologies to\nfight this global crisis. These digital technologies, in one way or another,\nstrongly rely on the availability of wireless communication technologies. In\nthis paper, we present the role of wireless communications in the COVID-19\npandemic from different perspectives. First, we show how these technologies are\nhelping to combat this pandemic, including monitoring of the virus spread,\nenabling healthcare automation, and allowing virtual education and\nconferencing. Also, we show the importance of digital inclusiveness in the\npandemic and possible solutions to connect the unconnected. Next, we discuss\nthe challenges faced by wireless technologies, including privacy, security, and\nmisinformation. Then, we present the importance of wireless communication\ntechnologies in the survival of the global economy, such as automation of\nindustries and supply chain, e-commerce, and supporting occupations that are at\nrisk. Finally, we reveal that how the technologies developed during the\npandemic can be helpful in the post-pandemic era.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 12:27:29 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 06:58:24 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Saeed", "Nasir", ""], ["Bader", "Ahmed", ""], ["Al-Naffouri", "Tareq Y.", ""], ["Alouini", "Mohamed-Slim", ""]]}, {"id": "2005.06647", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, Abdallah\n  Shami", "title": "Systematic Ensemble Model Selection Approach for Educational Data Mining", "comments": "47 Pages, 20 figures, 13 tables, accepted in Elsevier's\n  Knowledge-Based Systems", "journal-ref": null, "doi": "10.1016/j.knosys.2020.105992", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A plethora of research has been done in the past focusing on predicting\nstudent's performance in order to support their development. Many institutions\nare focused on improving the performance and the education quality; and this\ncan be achieved by utilizing data mining techniques to analyze and predict\nstudents' performance and to determine possible factors that may affect their\nfinal marks. To address this issue, this work starts by thoroughly exploring\nand analyzing two different datasets at two separate stages of course delivery\n(20 percent and 50 percent respectively) using multiple graphical, statistical,\nand quantitative techniques. The feature analysis provides insights into the\nnature of the different features considered and helps in the choice of the\nmachine learning algorithms and their parameters. Furthermore, this work\nproposes a systematic approach based on Gini index and p-value to select a\nsuitable ensemble learner from a combination of six potential machine learning\nalgorithms. Experimental results show that the proposed ensemble models achieve\nhigh accuracy and low false positive rate at all stages for both datasets.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:25:58 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Nassif", "Ali Bou", ""], ["Shami", "Abdallah", ""]]}, {"id": "2005.06748", "submitter": "Philipp Mayr", "authors": "S\\'ergio Nunes, Suzanne Little, Sumit Bhatia, Ludovico Boratto,\n  Guillaume Cabanac, Ricardo Campos, Francisco M. Couto, Stefano Faralli, Ingo\n  Frommholz, Adam Jatowt, Al\\'ipio Jorge, Mirko Marras, Philipp Mayr, Giovanni\n  Stilo", "title": "ECIR 2020 Workshops: Assessing the Impact of Going Online", "comments": "10 pages, 3 figures, submitted to ACM SIGIR Forum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ECIR 2020 https://ecir2020.org/ was one of the many conferences affected by\nthe COVID-19 pandemic. The Conference Chairs decided to keep the initially\nplanned dates (April 14-17, 2020) and move to a fully online event. In this\nreport, we describe the experience of organizing the ECIR 2020 Workshops in\nthis scenario from two perspectives: the workshop organizers and the workshop\nparticipants. We provide a report on the organizational aspect of these events\nand the consequences for participants. Covering the scientific dimension of\neach workshop is outside the scope of this article.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 06:49:22 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Nunes", "S\u00e9rgio", ""], ["Little", "Suzanne", ""], ["Bhatia", "Sumit", ""], ["Boratto", "Ludovico", ""], ["Cabanac", "Guillaume", ""], ["Campos", "Ricardo", ""], ["Couto", "Francisco M.", ""], ["Faralli", "Stefano", ""], ["Frommholz", "Ingo", ""], ["Jatowt", "Adam", ""], ["Jorge", "Al\u00edpio", ""], ["Marras", "Mirko", ""], ["Mayr", "Philipp", ""], ["Stilo", "Giovanni", ""]]}, {"id": "2005.06834", "submitter": "Sarah Spiekermann", "authors": "Alessandro Acquisti, Sarah Spiekermann", "title": "Do Interruptions Pay Off? Effects of Interruptive Ads on Consumers\n  Willingness to Pay", "comments": "Advertising, Attention, Privacy, Willingness to Pay, Electronic\n  commerce. Electronic copy", "journal-ref": null, "doi": "10.1016/j.intmar.2011.04.003", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the results of a study designed to measure the impact of\ninterruptive advertising on consumers willingness to pay for products bearing\nthe advertiser's brand. Subjects participating in a controlled experiment were\nexposed to ads that diverted their attention from a computer game they were\ntesting. We found that ads significantly lowered subjects willingness to pay\nfor a good associated with the advertised brand. We did not find conclusive\nevidence that providing some level of user control over the appearance of ads\nmitigated the negative impact of ad interruption. Our results contribute to the\nresearch on the economic impact of advertising, and introduce a method of\nmeasuring actual (as opposed to self-reported) willingness to pay in\nexperimental marketing research.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 09:26:57 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Acquisti", "Alessandro", ""], ["Spiekermann", "Sarah", ""]]}, {"id": "2005.06839", "submitter": "Sarah Spiekermann", "authors": "Sarah Spiekermann, Matthias Rothensee and Michael Klafft", "title": "Street Marketing: How Proximity and Context drive Coupon Redemption", "comments": "Coupon campaign, Mobile marketing, Coupon redemption", "journal-ref": null, "doi": "10.1108/07363761111143178", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: In 2009, US coupons set a new record of 367 billion coupons\ndistributed. Yet, while coupon distribution is on the rise, redemption rates\nremain below 1 percent. This paper aims to show how recognizing context\nvariables, such as proximity, weather, part of town and financial incentives\ninterplay to determine a coupon campaigns success. Design/methodology/approach.\nThe paper reports an empirical study conducted in co-operation with a\nrestaurant chain 9.880 Subway coupons were distributed under different\nexperimental context conditions. Redemption behavior was analyzed with the help\nof logistic regressions. Findings: It was found that even though proximity\ndrives coupon redemption, city center campaigns seem to be much more sensitive\nto distance than suburban areas. The further away the distribution place from\nthe restaurant, the less does the amount of monetary incentive determine the\nmotivation to redeem. Practical implications. When designing a coupon campaign\nfor a company, coupon distribution should not follow a -- one is good for all\nstrategy -- even for one marketer within one product category. Instead each\ncoupon strategy should carefully consider contextual influence.\nOriginality/value. This paper is the first to the authors knowledge that\nsystematically investigates the impact of context variables on coupon\nredemption. It focuses on context variables that electronic marketing channels\nwill be able to easily incorporate into personalized mobile marketing\ncampaigns.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 09:37:52 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Spiekermann", "Sarah", ""], ["Rothensee", "Matthias", ""], ["Klafft", "Michael", ""]]}, {"id": "2005.06895", "submitter": "Bing Huang", "authors": "Bing Huang, Athman Bouguettaya", "title": "Service mining for Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A service mining framework is proposed that enables discovering interesting\nrelationships in Internet of Things services bottom-up. The service\nrelationships are modeled based on spatial-temporal aspects, environment,\npeople, and operation. An ontology-based service model is proposed to describe\nservices. We present a set of metrics to evaluate the interestingness of\ndiscovered service relationships. Analytical and simulation results are\npresented to show the effectiveness of the proposed evaluation measures.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 11:58:34 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 01:44:15 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Huang", "Bing", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "2005.06945", "submitter": "Meishan Zhang", "authors": "Shuang Liu and Renjie Guo and Baiyang Zhao and Tao Chen and Meishan\n  Zhang", "title": "APPCorp: A Corpus for Android Privacy Policy Document Structure Analysis", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of mobile devices and the wide adoption of\nmobile Apps, an increasing concern of privacy issues is raised. Privacy policy\nis identified as a proper medium to indicate the legal terms, such as GDPR, and\nto bind legal agreement between service providers and users. However, privacy\npolicies are usually long and vague for end users to read and understand. It is\nthus important to be able to automatically analyze the document structures of\nprivacy policies to assist user understanding. In this work we create a\nmanually labelled corpus containing $167$ privacy policies (of more than $447$K\nwords and $5,276$ annotated paragraphs). We report the annotation process and\ndetails of the annotated corpus. We also benchmark our data corpus with $4$\ndocument classification models, thoroughly analyze the results and discuss\nchallenges and opportunities for the research committee to use the corpus. We\nrelease our labelled corpus as well as the classification models for public\naccess.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 13:25:11 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Liu", "Shuang", ""], ["Guo", "Renjie", ""], ["Zhao", "Baiyang", ""], ["Chen", "Tao", ""], ["Zhang", "Meishan", ""]]}, {"id": "2005.07081", "submitter": "Kevin Lin", "authors": "Kevin Lin", "title": "A Berkeley View of Teaching CS at Scale", "comments": "39 pages;\n  https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-99.html", "journal-ref": null, "doi": null, "report-no": "UCB/EECS-2019-99", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, undergraduate Computer Science (CS) programs across the\nnation have experienced an explosive growth in enrollment as computational\nskills have proven increasingly important across many domains and in the\nworkforce at large. Motivated by this unprecedented student demand, the CS\nprogram at the University of California, Berkeley has tripled the size of its\ngraduating class in five years. The first two introductory courses for majors,\neach taught by one faculty instructor and several hundred student teachers,\ncombine to serve nearly 2,900 students per term. This report presents three\nstrategies that have enabled the effective teaching, delivery, and management\nof large-scale CS courses: (1) the development of autograder infrastructure and\nonline platforms to provide instant feedback with minimal instructor\nintervention and deliver the course at scale; (2) the expansion of academic and\nsocial student support networks resulting from changes in teaching assistant\nresponsibilities and the development of several near-peer mentoring\ncommunities; and (3) the expansion of undergraduate teacher preparation\nprograms to meet the increased demand for qualified student teachers. These\ninterventions have helped both introductory and advanced courses address\ncapacity challenges and expand enrollments while receiving among the highest\nstudent evaluations of teaching in department history. Implications for\ninclusivity and diversity are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 17:33:37 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Lin", "Kevin", ""]]}, {"id": "2005.07252", "submitter": "Brandon Barker", "authors": "Brandon Barker and Susan Mehringer", "title": "Using Containers to Create More Interactive Online Training and\n  Education Materials", "comments": "10 pages, 3 figures, PEARC '20 conference paper", "journal-ref": null, "doi": "10.1145/3311790.3396641", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Containers are excellent hands-on learning environments for computing topics\nbecause they are customizable, portable, and reproducible. The Cornell\nUniversity Center for Advanced Computing has developed the Cornell Virtual\nWorkshop in high performance computing topics for many years, and we have\nalways sought to make the materials as rich and interactive as possible. Toward\nthe goal of building a more hands-on experimental learning experience directly\ninto web-based online training environments, we developed the Cornell Container\nRunner Service, which allows online content developers to build container-based\ninteractive edit and run commands directly into their web pages. Using\ncontainers along with CCRS has the potential to increase learner engagement and\noutcomes.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 20:46:05 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 13:08:49 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Barker", "Brandon", ""], ["Mehringer", "Susan", ""]]}, {"id": "2005.07266", "submitter": "David Pastor-Escuredo", "authors": "David Pastor-Escuredo", "title": "Characterizing information leaders in Twitter during COVID-19 crisis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Information is key during a crisis such as the one produced by the current\nCOVID-19 pandemic as it greatly shapes people opinion, behavior and their\npsychology. Infodemic of misinformation is an important secondary crisis\nassociated to the pandemic. Infodemics can amplify the real negative\nconsequences of the pandemic in different dimensions: social, economic and even\nsanitary. For instance, infodemics can lead to hatred between population groups\nthat fragment the society influencing its response or result in negative habits\nthat help the pandemic propagate. On the contrary, reliable and trustful\ninformation along with messages of hope and solidarity can be used to control\nthe pandemic, build safety nets and help promote resilience. We propose the\nfoundation of a framework to characterize leaders in Twitter based on the\nanalysis of the social graph derived from the activity in this social network.\nCentrality metrics are used to characterize the topology of the network and the\nnodes as potential leaders. These metrics are compared with the user popularity\nmetrics managed by Twitter. We then assess the resulting topology of clusters\nof leaders visually. We propose this tool to be the basis for a system to\ndetect and empower users with a positive influence in the collective behavior\nof the network and the propagation of information.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 21:14:15 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 08:27:12 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Pastor-Escuredo", "David", ""]]}, {"id": "2005.07269", "submitter": "Ritam Guha Mr.", "authors": "Ritam Guha, Anik Sengupta, Ankan Dutta", "title": "Sewage Pooling Test for SARS-CoV-2", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.OT cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CoVID-19 is currently one of the biggest threats to mankind. To date, it is\nthe reason for infections of over 35 lakhs and the death of over 2 lakh human\nbeings. We propose a procedure to detect CoVID-19 affected localities using a\nsewage mass testing and pooling mechanism which has gained ground in recent\ntimes. The proposed method named Sewage Pooling Algorithm tests wastewater\nsamples from sewage systems to pinpoint the regions which are affected by\nmaximum chances of the virus spread. The algorithm also uses a priority-based\nbacktracking procedure to perform testing in sewage links depending on the\nprobability of infection in the sub-areas. For places with very rare CoVID\ncases, we present a gradient-based search method to prune those areas. The\nproposed method has less human intervention and increases the effective\ntests/million people over current in-place methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:00:17 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Guha", "Ritam", ""], ["Sengupta", "Anik", ""], ["Dutta", "Ankan", ""]]}, {"id": "2005.07296", "submitter": "Agnaldo De Souza Batista", "authors": "Agnaldo Batista, Michele Nogueira and Aldri Santos", "title": "E-Health Sensitive Data Dissemination Exploiting Trust and Mobility of\n  Users", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-health services handle a massive amount of sensitive data, requiring\nreliability and privacy. The advent of new technologies drives e-health\nservices into their continuous provision outside traditional care institutions.\nThis creates uncertain and unreliable conditions, resulting in the challenge of\ncontrolling sensitive user data dissemination. Then, there is a gap in\nsensitive data dissemination under situations requiring fast response (e.g.,\ncardiac arrest). This obligates networks to provide reliable sensitive data\ndissemination under user mobility, dynamic network topology, and occasional\ninteractions between the devices. In this article, we propose STEALTH, a system\nthat employs social trust and communities of interest to address these\nchallenges. STEALTH follows two steps: clustering and dissemination. In the\nfirst, STEALTH groups devices based on the interests of their users, forming\ncommunities of interest. A healthcare urgency launches the second, in which\nSTEALTH disseminates user sensitive data to devices belonging to specific\ncommunities, subjected to the level of trust between devices. Simulation\nresults demonstrate that STEALTH ensures data dissemination to people who can\ncontribute toward an efficient service. STEALTH has achieved up to 97.14% of\nreliability in accessing sensitive data with a maximum latency of 170 ms, and\nup to 100% of availability during emergencies.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 23:37:43 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Batista", "Agnaldo", ""], ["Nogueira", "Michele", ""], ["Santos", "Aldri", ""]]}, {"id": "2005.07299", "submitter": "Marc Faddoul", "authors": "Marc Faddoul, Henriette Ruhrmann and Joyce Lee", "title": "A Risk Assessment of a Pretrial Risk Assessment Tool: Tussles,\n  Mitigation Strategies, and Inherent Limits", "comments": "This report was presented at the Information Ethics Roundtable 2019\n  at Northeastern University, see\n  https://cssh.northeastern.edu/philosophy/our-recent-past-talks/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a risk assessment of the Public Safety Assessment (PSA), a\nsoftware used in San Francisco and other jurisdictions to assist judges in\ndeciding whether defendants need to be detained before their trial. With a\nmixed-methods approach including stakeholder interviews and the use of\ntheoretical frameworks, we lay out the values at play as pretrial justice is\nautomated. After identifying value implications of delegating decision making\nto technology, we articulate benefits and limitations of the PSA solution, as\nwell as suggest mitigation strategies. We then draft the Handoff Tree, a novel\nalgorithmic approach to pretrial justice that accommodates some of the inherent\nlimitations of risk assessment tools by design. The model pairs every\nprediction with an associated error rate, and hands off the decision to the\njudge if the uncertainty is too high. By explicitly stating error rate, the\nHandoff Tree aims both to limit the impact of predictive disparity between race\nand gender, and to prompt judges to be more critical of retention\nrecommendations, given the high rate of false positives they often entail.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 23:56:57 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Faddoul", "Marc", ""], ["Ruhrmann", "Henriette", ""], ["Lee", "Joyce", ""]]}, {"id": "2005.07461", "submitter": "Richard Barnes Mr", "authors": "Richard Barnes", "title": "Factors in the Portability of Tokenized Assets on Distributed Ledgers", "comments": "9 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tokenization of assets deployed to distributed ledger technology is\nincreasingly cited to revolutionize financial services by allowing\ntraditionally illiquid assets to be bought and sold on primary and secondary\nmarkets increasing asset liquidity, transparency and reducing transaction\ncompletion time. To realize these benefits it is important the token is\ntransferrable, that is, portable from one distributed ledger to another. In\nthis paper we survey current interoperability architectures and smart contract\nlanguages, identifying factors affecting the portability of tokenized assets.\nWe propose a portability maturity model that can be used to help assess the\ncurrent state of technology and supporting market infrastructure.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:35:08 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Barnes", "Richard", ""]]}, {"id": "2005.07465", "submitter": "Mohammadreza Tavakoli", "authors": "Mohammadreza Tavakoli, Stefan T. Mol, and G\\'abor Kismih\\'ok", "title": "Labour Market Information Driven, Personalized, OER Recommendation\n  System for Lifelong Learners", "comments": "This paper has been accepted to be published in the proceedings of\n  CSEDU 2020 by SciTePress", "journal-ref": null, "doi": "10.5220/0009420300960104", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we suggest a novel method to aid lifelong learners to access\nrelevant OER based learning content to master skills demanded on the labour\nmarket. Our software prototype 1) applies Text Classification and Text Mining\nmethods on vacancy announcements to decompose jobs into meaningful skills\ncomponents, which lifelong learners should target; and 2) creates a hybrid OER\nRecommender System to suggest personalized learning content for learners to\nprogress towards their skill targets. For the first evaluation of this\nprototype we focused on two job areas: Data Scientist, and Mechanical Engineer.\nWe applied our skill extractor approach and provided OER recommendations for\nlearners targeting these jobs. We conducted in-depth, semi-structured\ninterviews with 12 subject matter experts to learn how our prototype performs\nin terms of its objectives, logic, and contribution to learning. More than 150\nrecommendations were generated, and 76.9% of these recommendations were treated\nas useful by the interviewees. Interviews revealed that a personalized OER\nrecommender system, based on skills demanded by labour market, has the\npotential to improve the learning experience of lifelong learners.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:48:15 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Tavakoli", "Mohammadreza", ""], ["Mol", "Stefan T.", ""], ["Kismih\u00f3k", "G\u00e1bor", ""]]}, {"id": "2005.07488", "submitter": "Svitlana H Lytvynova", "authors": "Svitlana H. Lytvynova", "title": "Electronic Textbook as a Component of Smart Kids Technology of Education\n  of Elementary School Pupils", "comments": "16 paper", "journal-ref": "http://icteri.org/icteri-2019/", "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article sets out to analyze national and foreign experience of use of\nelectronic textbooks in the system of education; to justify the use of Smart\nKids technology as a system of methods, forms, and electronic educational game\nresources, electronic textbooks for educational process in the system of\nelementary school. Four forms of implementation of Smart Kids technology (Smart\nCase, Smart Teacher, Smart Class, and Smart Kids) were described con-sidering\nthe facilities of every school as well as the level of information and\ncommunication technology qualification of the elementary school teacher. The\naim of introduction of the technology for each form of teaching, the necessary\nequipment, and means for its implementation in elementary school environment\nwere determined. Based on the procedural approach to work of an elementary\nschool teacher, six stages of introduction of the technology were justified.\nSpe-cific aspects of introduction of blended teaching using the principles of\nSmart Kids technology were defined. The experience of introduction of\nelectronic textbooks to the system of elementary education of Ukraine was\ndescribed, the choice of electronic textbooks by elementary school teachers was\njustified, the comments and suggestions of teachers regarding the arrangement\nof electronic content in E-textbooks were summarized, the main approaches of\nteachers to the choice of an electronic textbook and development of their\ninformation and communication competence were specified. It was identified that\nthe forms, methods, and techniques of use of electronic textbooks in teaching\nelementary school pupils require further justification.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 10:25:51 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Lytvynova", "Svitlana H.", ""]]}, {"id": "2005.07532", "submitter": "Ripon Patgiri", "authors": "Sabuzima Nayak and Ripon Patgiri", "title": "6G Communication Technology: A Vision on Intelligent Healthcare", "comments": "This manuscript is submitted to IEEE for possible publication", "journal-ref": null, "doi": "10.1007/978-981-15-9735-0_1", "report-no": null, "categories": "cs.NI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  6G is a promising communication technology that will dominate the entire\nhealth market from 2030 onward. It will dominate not only health sector but\nalso diverse sectors. It is expected that 6G will revolutionize many sectors\nincluding healthcare. Healthcare will be fully AI-driven and dependent on 6G\ncommunication technology, which will change our perception of lifestyle.\nCurrently, time and space are the key barriers to health care and 6G will be\nable to overcome these barriers. Also, 6G will be proven as a game changing\ntechnology for healthcare. Therefore, in this perspective, we envision\nhealthcare system for the era of 6G communication technology. Also, various new\nmethodologies have to be introduced to enhance our lifestyle, which is\naddressed in this perspective, including Quality of Life (QoL), Intelligent\nWearable Devices (IWD), Intelligent Internet of Medical Things (IIoMT),\nHospital-to-Home (H2H) services, and new business model. In addition, we expose\nthe role of 6G communication technology in telesurgery, Epidemic and Pandemic.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 06:53:05 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Nayak", "Sabuzima", ""], ["Patgiri", "Ripon", ""]]}, {"id": "2005.07534", "submitter": "Matthew Crowson", "authors": "Matthew G. Crowson and Timothy C.Y. Chan", "title": "Machine Learning as a Catalyst for Value-Based Health Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this manuscript, we present an argument that machine learning, a subfield\nof artificial intelligence, can drive improvement in value-based health care\nthrough reducing error in clinical decision making. Much of what has been\npreviously published on machine learning in medicine represent single-use or\nproof-of-concept cases, as well as broad reviews of the advantages and\nlimitations of machine learning. It is timely to look at the broader strategy\nfor artificial intelligence implementation in medicine and emphasize how\nmachine learning can positively influence value-based care.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 13:22:08 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Crowson", "Matthew G.", ""], ["Chan", "Timothy C. Y.", ""]]}, {"id": "2005.07552", "submitter": "Svitlana H Lytvynova", "authors": "Svitlana H. Lytvynova", "title": "System of Computer Modeling and Features of their use in the Educational\n  Process of General Secondary Eeducation", "comments": "17 pages, in Ukrainian", "journal-ref": null, "doi": "10.33407/itlt.v64i2.2111", "report-no": null, "categories": "cs.OH cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article analyzes the historical aspect of the formation of computer\nmodeling as one of the perspective directions of educational process\ndevelopment. The notion of \"system of computer modeling\", conceptual model of\nsystem of computer modeling (SCMod), its components (mathematical, animation,\ngraphic, strategic), functions, principles and purposes of use are grounded.\nThe features of the organization of students work using SCMod, individual and\ngroup work, the formation of subject competencies are described; the aspect of\nstudents' motivation to learning is considered. It is established that\neducational institutions can use SCMod at different levels and stages of\ntraining and in different contexts, which consist of interrelated physical,\nsocial, cultural and technological aspects. It is determined that the use of\nSCMod in general secondary school would increase the capacity of teachers to\nimprove the training of students in natural and mathematical subjects and\ncontribute to the individualization of the learning process, in order to meet\nthe pace, educational interests and capabilities of each particular student. It\nis substantiated that the use of SCMod in the study of natural-mathematical\nsubjects contributes to the formation of subject competencies, develops the\nskills of analysis and decision-making, increases the level of digital\ncommunication, develops vigilance, raises the level of knowledge, increases the\nduration of attention of students. Further research requires the justification\nof the process of forming students' competencies in natural-mathematical\nsubjects and designing cognitive tasks using SCMod.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 10:26:12 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Lytvynova", "Svitlana H.", ""]]}, {"id": "2005.07572", "submitter": "Donald Martin Jr.", "authors": "Donald Martin Jr. (1), Vinodkumar Prabhakaran (1), Jill Kuhlberg (2),\n  Andrew Smart (1), William S. Isaac (3) ((1) Google (2) System Stars (3)\n  DeepMind)", "title": "Participatory Problem Formulation for Fairer Machine Learning Through\n  Community Based System Dynamics", "comments": "Eighth Annual Conference on Learning Representations (ICLR 2020),\n  Virtual Workshop: Machine Learning in Real Life, April 26, 2020, 6 pages, 1\n  figure, fix comment typo, fix author name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on algorithmic fairness has highlighted that the problem\nformulation phase of ML system development can be a key source of bias that has\nsignificant downstream impacts on ML system fairness outcomes. However, very\nlittle attention has been paid to methods for improving the fairness efficacy\nof this critical phase of ML system development. Current practice neither\naccounts for the dynamic complexity of high-stakes domains nor incorporates the\nperspectives of vulnerable stakeholders. In this paper we introduce community\nbased system dynamics (CBSD) as an approach to enable the participation of\ntypically excluded stakeholders in the problem formulation phase of the ML\nsystem development process and facilitate the deep problem understanding\nrequired to mitigate bias during this crucial stage.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 14:41:43 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 03:54:30 GMT"}, {"version": "v3", "created": "Fri, 22 May 2020 13:57:28 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Martin", "Donald", "Jr."], ["Prabhakaran", "Vinodkumar", ""], ["Kuhlberg", "Jill", ""], ["Smart", "Andrew", ""], ["Isaac", "William S.", ""]]}, {"id": "2005.07802", "submitter": "Juan Ignacio Iba\\~nez", "authors": "Juan Ignacio Iba\\~nez, Chris N. Bayer, Paolo Tasca, Jiahua Xu", "title": "REA, Triple-Entry Accounting and Blockchain: Converging Paths to Shared\n  Ledger Systems", "comments": "64 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of shared ledger systems offering a single source of truth has\nrepeatedly called traditional bookkeeping into question. Improving upon the\nlong-standing double-entry systems, solutions such as the Resource-Event-Agent\n(REA) accounting framework, triple-entry accounting (TEA) and blockchain have\nbeen advanced. However, to date, the historical development of shared ledger\nsystems remains murky. This paper conducts a genealogical analysis of shared\nledger systems, in particular tracing the development of REA, TEA and\nblockchain. We show how the REA framework had a distinct influence over\nindependent streams of research in the field of TEA, and how this interaction\nmay be traced to the present incarnation of shared ledger systems in\nblockchain. In doing so, we duly acknowledge the influence of each individual\ncontributing to this development, correct common misconceptions and map out how\nthe paths of REA, TEA and blockchain overlap in the realm of shared ledger\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 22:11:21 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 15:08:15 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 13:16:32 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Iba\u00f1ez", "Juan Ignacio", ""], ["Bayer", "Chris N.", ""], ["Tasca", "Paolo", ""], ["Xu", "Jiahua", ""]]}, {"id": "2005.07849", "submitter": "Jim Samuel", "authors": "Cherilyn Conner, Jim Samuel, Andrey Kretinin, Yana Samuel and Lee\n  Nadeau", "title": "A Picture for the Words! Textual Visualization in Big Data Analytics", "comments": "Early stage output for ongoing work on Textual Analytics, Subsequent\n  Book Chapter accepted, Journal Manuscript ongoing", "journal-ref": null, "doi": "10.13140/RG.2.2.25351.83360", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data Visualization has become an important aspect of big data analytics and\nhas grown in sophistication and variety. We specifically identify the need for\nan analytical framework for data visualization with textual information. Data\nvisualization is a powerful mechanism to represent data, but the usage of\nspecific graphical representations needs to be better understood and classified\nto validate appropriate representation in the contexts of textual data and\navoid distorted depictions of underlying textual data. We identify prominent\ntextual data visualization approaches and discuss their characteristics. We\ndiscuss the use of multiple graph types in textual data visualization,\nincluding the use of quantity, sense, trend and context textual data\nvisualization. We create an explanatory classification framework to position\ntextual data visualization in a unique way so as to provide insights and assist\nin appropriate method or graphical representation classification.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 02:53:58 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Conner", "Cherilyn", ""], ["Samuel", "Jim", ""], ["Kretinin", "Andrey", ""], ["Samuel", "Yana", ""], ["Nadeau", "Lee", ""]]}, {"id": "2005.07891", "submitter": "Fatemah Husain", "authors": "Fatemah Husain, Hasan Abbas", "title": "Education and Technology In Kuwait Democratic Practice", "comments": "The IABPAD Conference Proceedings, Dallas, Texas, April 20-23, 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study discusses the effects of the new technology on the democratic\nsystem by reviewing the political history of democracy in philosophic view. The\nstudy explores the philosophical discussion of democracy and its components\nthat is designed by most influential philosophers whom most of them agreed on\nthe importance of education and knowledge to be the two main components. The\nstudy connects the democratic progress in the State of Kuwait to its roots,\nnamely knowledge and education.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 07:37:49 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Husain", "Fatemah", ""], ["Abbas", "Hasan", ""]]}, {"id": "2005.07898", "submitter": "Fatemah Husain", "authors": "Fatemah Husain, Vivian Motti", "title": "Social Media Usage in Kuwait: A Comparison of Perspectives Between\n  Healthcare Practitioners and Patients", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Media has been transforming numerous activities of everyday life,\nimpacting also healthcare. However, few studies investigate the medical use of\nsocial media by patients and medical practitioners, especially in the Arabian\nGulf region and Kuwait. To understand the behavior of patients and medical\npractitioners in social media toward healthcare and medical purposes, we\nconducted user studies. Through an online survey, we identified a decrease in\npatients and medical practitioners use of social media for medical purposes.\nPatients reported to be more aware than practitioners concerning: health\neducation, health-related network support, and communication activities. While\npractitioners use social media mostly as a source of medical information, for\nclinician marketing and for professional development. The findings highlighted\nthe need to design a social media platform that support healthcare online\ncampaign, professional career identity, medical repository, and social privacy\nsetting to increase users engagements toward medical purposes.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 08:12:03 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Husain", "Fatemah", ""], ["Motti", "Vivian", ""]]}, {"id": "2005.07926", "submitter": "Savvas Zannettou", "authors": "Savvas Zannettou, Mai ElSherief, Elizabeth Belding, Shirin Nilizadeh,\n  Gianluca Stringhini", "title": "Measuring and Characterizing Hate Speech on News Websites", "comments": "Accepted at WebSci'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web has become the main source for news acquisition. At the same time,\nnews discussion has become more social: users can post comments on news\narticles or discuss news articles on other platforms like Reddit. These\nfeatures empower and enable discussions among the users; however, they also act\nas the medium for the dissemination of toxic discourse and hate speech. The\nresearch community lacks a general understanding on what type of content\nattracts hateful discourse and the possible effects of social networks on the\ncommenting activity on news articles. In this work, we perform a large-scale\nquantitative analysis of 125M comments posted on 412K news articles over the\ncourse of 19 months. We analyze the content of the collected articles and their\ncomments using temporal analysis, user-based analysis, and linguistic analysis,\nto shed light on what elements attract hateful comments on news articles. We\nalso investigate commenting activity when an article is posted on either\n4chan's Politically Incorrect board (/pol/) or six selected subreddits. We find\nstatistically significant increases in hateful commenting activity around\nreal-world divisive events like the \"Unite the Right\" rally in Charlottesville\nand political events like the second and third 2016 US presidential debates.\nAlso, we find that articles that attract a substantial number of hateful\ncomments have different linguistic characteristics when compared to articles\nthat do not attract hateful comments. Furthermore, we observe that the post of\na news articles on either /pol/ or the six subreddits is correlated with an\nincrease of (hateful) commenting activity on the news articles.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 09:59:01 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Zannettou", "Savvas", ""], ["ElSherief", "Mai", ""], ["Belding", "Elizabeth", ""], ["Nilizadeh", "Shirin", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "2005.08076", "submitter": "Richard Jiang", "authors": "Fraser Young, L Zhang, Richard Jiang, Han Liu and Conor Wall", "title": "A Deep Learning based Wearable Healthcare IoT Device for AI-enabled\n  Hearing Assistance Automation", "comments": null, "journal-ref": "The 2020 International Conference on Machine Learning and\n  Cybernetics", "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the recent booming of artificial intelligence (AI), particularly deep\nlearning techniques, digital healthcare is one of the prevalent areas that\ncould gain benefits from AI-enabled functionality. This research presents a\nnovel AI-enabled Internet of Things (IoT) device operating from the ESP-8266\nplatform capable of assisting those who suffer from impairment of hearing or\ndeafness to communicate with others in conversations. In the proposed solution,\na server application is created that leverages Google's online speech\nrecognition service to convert the received conversations into texts, then\ndeployed to a micro-display attached to the glasses to display the conversation\ncontents to deaf people, to enable and assist conversation as normal with the\ngeneral population. Furthermore, in order to raise alert of traffic or\ndangerous scenarios, an 'urban-emergency' classifier is developed using a deep\nlearning model, Inception-v4, with transfer learning to detect/recognize\nalerting/alarming sounds, such as a horn sound or a fire alarm, with texts\ngenerated to alert the prospective user. The training of Inception-v4 was\ncarried out on a consumer desktop PC and then implemented into the AI based IoT\napplication. The empirical results indicate that the developed prototype system\nachieves an accuracy rate of 92% for sound recognition and classification with\nreal-time performance.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 19:42:16 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Young", "Fraser", ""], ["Zhang", "L", ""], ["Jiang", "Richard", ""], ["Liu", "Han", ""], ["Wall", "Conor", ""]]}, {"id": "2005.08092", "submitter": "Fotios Fitsilis", "authors": "Fotios Fitsilis", "title": "Imposing Regulation on Advanced Algorithms", "comments": "XXI, 82 pages, 5 figures. Cham: Springer", "journal-ref": null, "doi": "10.1007/978-3-030-27979-0", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This book discusses the necessity and perhaps urgency for the regulation of\nalgorithms on which new technologies rely; technologies that have the potential\nto re-shape human societies. From commerce and farming to medical care and\neducation, it is difficult to find any aspect of our lives that will not be\naffected by these emerging technologies. At the same time, artificial\nintelligence, deep learning, machine learning, cognitive computing, blockchain,\nvirtual reality and augmented reality, belong to the fields most likely to\naffect law and, in particular, administrative law. The book examines\nuniversally applicable patterns in administrative decisions and judicial\nrulings. First, similarities and divergence in behavior among the different\ncases are identified by analyzing parameters ranging from geographical location\nand administrative decisions to judicial reasoning and legal basis. As it turns\nout, in several of the cases presented, sources of general law, such as\ncompetition or labor law, are invoked as a legal basis, due to the lack of\ncurrent specialized legislation. This book also investigates the role and\nsignificance of national and indeed supranational regulatory bodies for\nadvanced algorithms and considers ENISA, an EU agency that focuses on network\nand information security, as an interesting candidate for a European regulator\nof advanced algorithms. Lastly, it discusses the involvement of representative\ninstitutions in algorithmic regulation.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:26:54 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fitsilis", "Fotios", ""]]}, {"id": "2005.08141", "submitter": "Filippo Menczer", "authors": "Wen Chen, Diogo Pacheco, Kai-Cheng Yang and Filippo Menczer", "title": "Neutral bots probe political bias on social media", "comments": "26 pages, 6 figures. Appendix: 10 pages, 5 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms attempting to curb abuse and misinformation have been\naccused of political bias. We deploy neutral social bots who start following\ndifferent news sources on Twitter, and track them to probe distinct biases\nemerging from platform mechanisms versus user interactions. We find no strong\nor consistent evidence of political bias in the news feed. Despite this, the\nnews and information to which U.S. Twitter users are exposed depend strongly on\nthe political leaning of their early connections. The interactions of\nconservative accounts are skewed toward the right, whereas liberal accounts are\nexposed to moderate content shifting their experience toward the political\ncenter. Partisan accounts, especially conservative ones, tend to receive more\nfollowers and follow more automated accounts. Conservative accounts also find\nthemselves in denser communities and are exposed to more low-credibility\ncontent.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 01:20:24 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 14:45:33 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 05:55:49 GMT"}, {"version": "v4", "created": "Tue, 20 Jul 2021 19:02:44 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chen", "Wen", ""], ["Pacheco", "Diogo", ""], ["Yang", "Kai-Cheng", ""], ["Menczer", "Filippo", ""]]}, {"id": "2005.08231", "submitter": "Johanna Johansen Ms", "authors": "Johanna Johansen, Tore Pedersen, Christian Johansen", "title": "Studying the Transfer of Biases from Programmers to Programs", "comments": "40 pages of which 7 pages of Appendix, 26 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is generally agreed that one origin of machine bias is resulting from\ncharacteristics within the dataset on which the algorithms are trained, i.e.,\nthe data does not warrant a generalized inference. We, however, hypothesize\nthat a different `mechanism', hitherto not articulated in the literature, may\nalso be responsible for machine's bias, namely that biases may originate from\n(i) the programmers' cultural background, such as education or line of work, or\n(ii) the contextual programming environment, such as software requirements or\ndeveloper tools. Combining an experimental and comparative design, we studied\nthe effects of cultural metaphors and contextual metaphors, and tested whether\neach of these would `transfer' from the programmer to program, thus\nconstituting a machine bias. The results show (i) that cultural metaphors\ninfluence the programmer's choices and (ii) that `induced' contextual metaphors\ncan be used to moderate or exacerbate the effects of the cultural metaphors.\nThis supports our hypothesis that biases in automated systems do not always\noriginate from within the machine's training data. Instead, machines may also\n`replicate' and `reproduce' biases from the programmers' cultural background by\nthe transfer of cultural metaphors into the programming process. Implications\nfor academia and professional practice range from the micro programming-level\nto the macro national-regulations or educational level, and span across all\nsocietal domains where software-based systems are operating such as the popular\nAI-based automated decision support systems.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:51:06 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 17:06:25 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Johansen", "Johanna", ""], ["Pedersen", "Tore", ""], ["Johansen", "Christian", ""]]}, {"id": "2005.08370", "submitter": "Ricardo Vinuesa", "authors": "Ricardo Vinuesa, Andreas Theodorou, Manuela Battaglini and Virginia\n  Dignum", "title": "A socio-technical framework for digital contact tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their efforts to tackle the COVID-19 crisis, decision makers are\nconsidering the development and use of smartphone applications for contact\ntracing. Even though these applications differ in technology and methods, there\nis an increasing concern about their implications for privacy and human rights.\nHere we propose a framework to evaluate their suitability in terms of impact on\nthe users, employed technology and governance methods. We illustrate its usage\nwith three applications, and with the European Data Protection Board (EDPB)\nguidelines, highlighting their limitations.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 21:05:23 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Vinuesa", "Ricardo", ""], ["Theodorou", "Andreas", ""], ["Battaglini", "Manuela", ""], ["Dignum", "Virginia", ""]]}, {"id": "2005.08381", "submitter": "Ibrahim Habli", "authors": "Ibrahim Habli, Rob Alexander, Richard Hawkins, Mark Sujan, John\n  McDermid, Chiara Picardi, Tom Lawton", "title": "Enhancing Covid-19 Decision-Making by Creating an Assurance Case for\n  Simulation Models", "comments": "6 pages and 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation models have been informing the COVID-19 policy-making process.\nThese models, therefore, have significant influence on risk of societal harms.\nBut how clearly are the underlying modelling assumptions and limitations\ncommunicated so that decision-makers can readily understand them? When making\nclaims about risk in safety-critical systems, it is common practice to produce\nan assurance case, which is a structured argument supported by evidence with\nthe aim to assess how confident we should be in our risk-based decisions. We\nargue that any COVID-19 simulation model that is used to guide critical policy\ndecisions would benefit from being supported with such a case to explain how,\nand to what extent, the evidence from the simulation can be relied on to\nsubstantiate policy conclusions. This would enable a critical review of the\nimplicit assumptions and inherent uncertainty in modelling, and would give the\noverall decision-making process greater transparency and accountability.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 22:07:05 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Habli", "Ibrahim", ""], ["Alexander", "Rob", ""], ["Hawkins", "Richard", ""], ["Sujan", "Mark", ""], ["McDermid", "John", ""], ["Picardi", "Chiara", ""], ["Lawton", "Tom", ""]]}, {"id": "2005.08400", "submitter": "Pedram Hosseini", "authors": "Pedram Hosseini and Poorya Hosseini and David A. Broniatowski", "title": "Content analysis of Persian/Farsi Tweets during COVID-19 pandemic in\n  Iran using NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iran, along with China, South Korea, and Italy was among the countries that\nwere hit hard in the first wave of the COVID-19 spread. Twitter is one of the\nwidely-used online platforms by Iranians inside and abroad for sharing their\nopinion, thoughts, and feelings about a wide range of issues. In this study,\nusing more than 530,000 original tweets in Persian/Farsi on COVID-19, we\nanalyzed the topics discussed among users, who are mainly Iranians, to gauge\nand track the response to the pandemic and how it evolved over time. We applied\na combination of manual annotation of a random sample of tweets and topic\nmodeling tools to classify the contents and frequency of each category of\ntopics. We identified the top 25 topics among which living experience under\nhome quarantine emerged as a major talking point. We additionally categorized\nbroader content of tweets that shows satire, followed by news, is the dominant\ntweet type among the Iranian users. While this framework and methodology can be\nused to track public response to ongoing developments related to COVID-19, a\ngeneralization of this framework can become a useful framework to gauge Iranian\npublic reaction to ongoing policy measures or events locally and\ninternationally.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 23:47:08 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Hosseini", "Pedram", ""], ["Hosseini", "Poorya", ""], ["Broniatowski", "David A.", ""]]}, {"id": "2005.08427", "submitter": "Jenny Blessing", "authors": "Jenny Blessing, Julian Gomez, McCoy Pati\\~no, Tran Nguyen", "title": "Security Survey and Analysis of Vote-by-Mail Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voting by mail has been gaining traction for decades in the United States and\nhas emerged as the preferred voting method during the COVID-19 pandemic. In\nthis paper, we examine the security of electronic systems used in the process\nof voting by mail, including online voter registration and online ballot\ntracking systems. The goals of these systems, to facilitate voter registration\nand increase public confidence in elections, are laudable. They indisputably\nprovide a critical public good. It is for these reasons that understanding the\nsecurity and privacy posture of the mail-in voting process is paramount. We\nfind that online voter registration systems in some states have vulnerabilities\nthat allow adversaries to alter or effectively prevent a voter's registration.\nWe additionally find that ballot tracking systems raise serious privacy\nquestions surrounding ease of access to voter data. While the vulnerabilities\ndiscussed here are unlikely to enable an adversary to modify votes, several\ncould have the effect of disenfranchising voters and reducing voter confidence\nin U.S. elections infrastructure, thereby undermining the very purpose of these\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 02:18:15 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 21:54:53 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Blessing", "Jenny", ""], ["Gomez", "Julian", ""], ["Pati\u00f1o", "McCoy", ""], ["Nguyen", "Tran", ""]]}, {"id": "2005.08502", "submitter": "Yun William Yu", "authors": "Hannah Alsdurf, Edmond Belliveau, Yoshua Bengio, Tristan Deleu,\n  Prateek Gupta, Daphne Ippolito, Richard Janda, Max Jarvie, Tyler Kolody,\n  Sekoul Krastev, Tegan Maharaj, Robert Obryk, Dan Pilat, Valerie Pisano,\n  Benjamin Prud'homme, Meng Qu, Nasim Rahaman, Irina Rish, Jean-Francois\n  Rousseau, Abhinav Sharma, Brooke Struck, Jian Tang, Martin Weiss, Yun William\n  Yu", "title": "COVI White Paper", "comments": "64 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SARS-CoV-2 (Covid-19) pandemic has caused significant strain on public\nhealth institutions around the world. Contact tracing is an essential tool to\nchange the course of the Covid-19 pandemic. Manual contact tracing of Covid-19\ncases has significant challenges that limit the ability of public health\nauthorities to minimize community infections. Personalized peer-to-peer contact\ntracing through the use of mobile apps has the potential to shift the paradigm.\nSome countries have deployed centralized tracking systems, but more\nprivacy-protecting decentralized systems offer much of the same benefit without\nconcentrating data in the hands of a state authority or for-profit\ncorporations. Machine learning methods can circumvent some of the limitations\nof standard digital tracing by incorporating many clues and their uncertainty\ninto a more graded and precise estimation of infection risk. The estimated risk\ncan provide early risk awareness, personalized recommendations and relevant\ninformation to the user. Finally, non-identifying risk data can inform\nepidemiological models trained jointly with the machine learning predictor.\nThese models can provide statistical evidence for the importance of factors\ninvolved in disease transmission. They can also be used to monitor, evaluate\nand optimize health policy and (de)confinement scenarios according to medical\nand economic productivity indicators. However, such a strategy based on mobile\napps and machine learning should proactively mitigate potential ethical and\nprivacy risks, which could have substantial impacts on society (not only\nimpacts on health but also impacts such as stigmatization and abuse of personal\ndata). Here, we present an overview of the rationale, design, ethical\nconsiderations and privacy strategy of `COVI,' a Covid-19 public peer-to-peer\ncontact tracing and risk awareness mobile application developed in Canada.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 07:40:49 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 15:41:17 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Alsdurf", "Hannah", ""], ["Belliveau", "Edmond", ""], ["Bengio", "Yoshua", ""], ["Deleu", "Tristan", ""], ["Gupta", "Prateek", ""], ["Ippolito", "Daphne", ""], ["Janda", "Richard", ""], ["Jarvie", "Max", ""], ["Kolody", "Tyler", ""], ["Krastev", "Sekoul", ""], ["Maharaj", "Tegan", ""], ["Obryk", "Robert", ""], ["Pilat", "Dan", ""], ["Pisano", "Valerie", ""], ["Prud'homme", "Benjamin", ""], ["Qu", "Meng", ""], ["Rahaman", "Nasim", ""], ["Rish", "Irina", ""], ["Rousseau", "Jean-Francois", ""], ["Sharma", "Abhinav", ""], ["Struck", "Brooke", ""], ["Tang", "Jian", ""], ["Weiss", "Martin", ""], ["Yu", "Yun William", ""]]}, {"id": "2005.08505", "submitter": "Manoel Horta Ribeiro", "authors": "Manoel Horta Ribeiro, Kristina Gligori\\'c, Maxime Peyrard, Florian\n  Lemmerich, Markus Strohmaier, Robert West", "title": "Sudden Attention Shifts on Wikipedia During the COVID-19 Crisis", "comments": "Manoel Horta Ribeiro, Kristina Gligori\\'c and Maxime Peyrard\n  contributed equally to this work. Also, this paper has been accepted at the\n  15th International Conference on Web and Social Media (ICWSM), please cite\n  accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how the COVID-19 pandemic, alongside the severe mobility\nrestrictions that ensued, has impacted information access on Wikipedia, the\nworld's largest online encyclopedia. A longitudinal analysis that combines\npageview statistics for 12 Wikipedia language editions with mobility reports\npublished by Apple and Google reveals massive shifts in the volume and nature\nof information seeking patterns during the pandemic. Interestingly, while we\nobserve a transient increase in Wikipedia's pageview volume following mobility\nrestrictions, the nature of information sought was impacted more permanently.\nThese changes are most pronounced for language editions associated with\ncountries where the most severe mobility restrictions were implemented. We also\nfind that articles belonging to different topics behaved differently; e.g.,\nattention towards entertainment-related topics is lingering and even\nincreasing, while the interest in health- and biology-related topics was either\nsmall or transient. Our results highlight the utility of Wikipedia for studying\nhow the pandemic is affecting people's needs, interests, and concerns.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 07:47:50 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 12:01:11 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 08:30:04 GMT"}, {"version": "v4", "created": "Thu, 8 Apr 2021 14:16:46 GMT"}, {"version": "v5", "created": "Mon, 19 Apr 2021 11:00:53 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Ribeiro", "Manoel Horta", ""], ["Gligori\u0107", "Kristina", ""], ["Peyrard", "Maxime", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""], ["West", "Robert", ""]]}, {"id": "2005.08537", "submitter": "Kevin Kotzen", "authors": "Joachim A. Behar, Chengyu Liu, Kevin Kotzen, Kenta Tsutsui, Valentina\n  D.A. Corino, Janmajay Singh, Marco A.F. Pimentel, Philip Warrick, Sebastian\n  Zaunseder, Fernando Andreotti, David Sebag, Georgy Popanitsa, Patrick E.\n  McSharry, Walter Karlen, Chandan Karmakar and Gari D. Clifford", "title": "Remote health monitoring and diagnosis in the time of COVID-19", "comments": "36 pages", "journal-ref": null, "doi": "10.1088/1361-6579/abba0a", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus disease (COVID-19) is caused by the severe acute respiratory\nsyndrome coronavirus 2 (SARS-CoV-2) that is rapidly spreading across the globe.\nThe clinical spectrum of SARS-CoV-2 pneumonia ranges from mild to critically\nill cases and requires early detection and monitoring, within a clinical\nenvironment for critical cases and remotely for mild cases. The fear of\ncontamination in clinical environments has led to a dramatic reduction in\non-site referrals for routine care. There has also been a perceived need to\ncontinuously monitor non-severe COVID- 19 patients, either from their\nquarantine site at home, or dedicated quarantine locations (e.g., hotels).\nThus, the pandemic has driven incentives to innovate and enhance or create new\nroutes for providing healthcare services at distance. In particular, this has\ncreated a dramatic impetus to find innovative ways to remotely and effectively\nmonitor patient health status. In this paper we present a short review of\nremote health monitoring initiatives taken in 19 states during the time of the\npandemic. We emphasize in the discussion particular aspects that are common\nground for the reviewed states, in particular the future impact of the pandemic\non remote health monitoring and consideration on data privacy.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 08:54:38 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 11:49:32 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 10:47:38 GMT"}, {"version": "v4", "created": "Mon, 21 Sep 2020 12:48:56 GMT"}, {"version": "v5", "created": "Thu, 15 Oct 2020 17:31:04 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Behar", "Joachim A.", ""], ["Liu", "Chengyu", ""], ["Kotzen", "Kevin", ""], ["Tsutsui", "Kenta", ""], ["Corino", "Valentina D. A.", ""], ["Singh", "Janmajay", ""], ["Pimentel", "Marco A. F.", ""], ["Warrick", "Philip", ""], ["Zaunseder", "Sebastian", ""], ["Andreotti", "Fernando", ""], ["Sebag", "David", ""], ["Popanitsa", "Georgy", ""], ["McSharry", "Patrick E.", ""], ["Karlen", "Walter", ""], ["Karmakar", "Chandan", ""], ["Clifford", "Gari D.", ""]]}, {"id": "2005.08579", "submitter": "Bj\\\"orn Schuller", "authors": "Gauri Deshpande, Bj\\\"orn Schuller", "title": "An Overview on Audio, Signal, Speech, & Language Processing for COVID-19", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an increased attention towards innovating,\nenhancing, building, and deploying applications of speech signal processing for\nproviding assistance and relief to human mankind from the Coronavirus\n(COVID-19) pandemic. Many AI with speech initiatives are taken to combat with\nthe present situation and also to create a safe and secure environment for the\nfuture. This paper summarises all these efforts taken by the re-search\ncommunity towards helping the individuals and the society in the fight against\nCOVID-19 over the past 3-4 months using speech signal processing. We also\nsummarise the deep techniques used in this direction to come up with capable\nsolutions in a short span of time. This paper further gives an overview of the\ncontributions from non-speech modalities that may complement or serve as\ninspiration for audio and speech analysis. In addition, we discuss our\nobservations with respect to solution usability, challenges, and the\nsignificant technology achievements.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 10:46:30 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Deshpande", "Gauri", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "2005.08618", "submitter": "Jozef Michal Mintal", "authors": "Karol Fabian, Jozef Michal Mintal", "title": "Cognitive Analysis of Security Threats on Social Networking Services:\n  Slovakia in need of stronger action", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper examines some of the ongoing research at the UMB Data and\nSociety Lab hosted at the Faculty of Political Science and International\nRelations at Matej Bel University. It begins with an introduction on the\nnecessity of security threat identification on social networking services\n(SNSs), done by states. The paper follows with a general overview of selected\nprojects of the Lab in this field, and afterwards it introduces a use case\nstudy focused on the announcement of the UK snap general election 2017. The\nmain aim of this paper is to demonstrate some of the possibilities of social\nnetworking services analysis in the field of international relations, with an\nemphasis on disinformation and the necessity of identifying novel digital\nactors in Slovakia. We also outline an easy custom system tasked to collect\nsocial media data, and afterwards process it using various cognitive analytic\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 11:56:05 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fabian", "Karol", ""], ["Mintal", "Jozef Michal", ""]]}, {"id": "2005.08633", "submitter": "Peter Hillmann", "authors": "Peter Hillmann, Bastian K\\\"uhnel, Tobias Uhlig, Gabi Dreo Rodosek, and\n  Oliver Rose", "title": "Optimized Travel to Meetings on a Common Location of Geographical\n  Distributed Participants", "comments": "International Conference on Service Operations and Logistics, and\n  Informatics, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Members of international organizations often meet in person at a common\nlocation for discussions. There is frequently disagreement over the place and\ntime of the meeting due to the different travel efforts of the members. They\nusually travel by plane and their travel expenses depend on the flight\nconnections. This paper presents an approach to calculate the optimized\nlocation and time, where and when distributed partners should meet. The\npresented system considers the requirements and specifications of each\nindividual member. It respects earliest starting time of an event and non night\nflights. The optimized result is evaluated with regard to multiple objectives.\nWe focus on the minimization of costs and travel time. Our search algorithm\nidentifies individual travel data for all members for a potential event. The\noutput provides recommendations for the global best appointments and offers\nfurther information for the partners. Our system saves expenses and time for\nall members and allows adjustment as well as compensation.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:54:28 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Hillmann", "Peter", ""], ["K\u00fchnel", "Bastian", ""], ["Uhlig", "Tobias", ""], ["Rodosek", "Gabi Dreo", ""], ["Rose", "Oliver", ""]]}, {"id": "2005.08663", "submitter": "Arisa Ema", "authors": "Kudo Fumiko, Hiromi Arai and Arisa Ema", "title": "Ethical Issues Regarding the Use of AI Profiling Services for\n  Recruiting: The Japanese Rikunabi Data Scandal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ethical, legal, and social challenges involved in the use of profiling\nservices for recruitment are the focus of many previous studies; however, the\nprocesses vary depending on the social system and cultural practices. In August\n2019, a scandal occurred in Japan in which a recruitment management company was\nfound to have breached users' and students' trust by selling their data to\nclients. By sharing the Japanese recruitment context and associated laws, this\narticle contributes to our understanding of the ethical issues involved in\nartificial intelligence profiling and in handling sensitive personal\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 12:52:53 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fumiko", "Kudo", ""], ["Arai", "Hiromi", ""], ["Ema", "Arisa", ""]]}, {"id": "2005.08669", "submitter": "G\\'abor Kismih\\'ok Dr.", "authors": "G\\'abor Kismih\\'ok, Catherine Zhao, Micha\\'ela C. Schippers, Stefan T.\n  Mol, Scott Harrison and Shady Shehata", "title": "Translating the Concept of Goal Setting into Practice -- What 'Else'\n  does it Require than a Goal Setting Tool?", "comments": "This paper has been accepted to be published in the proceedings of\n  CSEDU 2020 by SciTePress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This conceptual paper reviews the current status of goal setting in the area\nof technology enhanced learning and education. Besides a brief literature\nreview, three current projects on goal setting are discussed. The paper shows\nthat the main barriers for goal setting applications in education are not\nrelated to the technology, the available data or analytical methods, but rather\nthe human factor. The most important bottlenecks are the lack of students goal\nsetting skills and abilities, and the current curriculum design, which,\nespecially in the observed higher education institutions, provides little\nsupport for goal setting interventions.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 12:57:03 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kismih\u00f3k", "G\u00e1bor", ""], ["Zhao", "Catherine", ""], ["Schippers", "Micha\u00e9la C.", ""], ["Mol", "Stefan T.", ""], ["Harrison", "Scott", ""], ["Shehata", "Shady", ""]]}, {"id": "2005.08679", "submitter": "Emiliano De Cristofaro", "authors": "Emiliano De Cristofaro", "title": "An Overview of Privacy in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, providers such as Google, Microsoft, and Amazon have\nstarted to provide customers with access to software interfaces allowing them\nto easily embed machine learning tasks into their applications. Overall,\norganizations can now use Machine Learning as a Service (MLaaS) engines to\noutsource complex tasks, e.g., training classifiers, performing predictions,\nclustering, etc. They can also let others query models trained on their data.\nNaturally, this approach can also be used (and is often advocated) in other\ncontexts, including government collaborations, citizen science projects, and\nbusiness-to-business partnerships. However, if malicious users were able to\nrecover data used to train these models, the resulting information leakage\nwould create serious issues. Likewise, if the inner parameters of the model are\nconsidered proprietary information, then access to the model should not allow\nan adversary to learn such parameters. In this document, we set to review\nprivacy challenges in this space, providing a systematic review of the relevant\nresearch literature, also exploring possible countermeasures. More\nspecifically, we provide ample background information on relevant concepts\naround machine learning and privacy. Then, we discuss possible adversarial\nmodels and settings, cover a wide range of attacks that relate to private\nand/or sensitive information leakage, and review recent results attempting to\ndefend against such attacks. Finally, we conclude with a list of open problems\nthat require more work, including the need for better evaluations, more\ntargeted defenses, and the study of the relation to policy and data protection\nefforts.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 13:05:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["De Cristofaro", "Emiliano", ""]]}, {"id": "2005.08738", "submitter": "Grant McKenzie", "authors": "Grant McKenzie and Benjamin Adams", "title": "A country comparison of place-based activity response to COVID-19\n  policies", "comments": "21 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of the novel Coronavirus Disease in late 2019 (COVID-19) and\nsubsequent pandemic led to an immense disruption in the daily lives of almost\neveryone on the planet. Faced with the consequences of inaction, most national\ngovernments responded with policies that restricted the activities conducted by\ntheir inhabitants. As schools and businesses shuttered, the mobility of these\npeople decreased. This reduction in mobility, and related activities, was\nrecorded through ubiquitous location-enabled personal mobile devices. Patterns\nemerged that varied by place-based activity. In this work the differences in\nthese place-based activity patterns are investigated across nations,\nspecifically focusing on the relationship between government enacted policies\nand changes in community activity patterns. We show that people's activity\nresponse to government action varies widely both across nations as well as\nregionally within them. Three assessment measures are devised and the results\ncorrelate with a number of global indices. We discuss these findings and the\nrelationship between government action and residents' response.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:06:00 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["McKenzie", "Grant", ""], ["Adams", "Benjamin", ""]]}, {"id": "2005.08757", "submitter": "Subhankar Mishra", "authors": "Subhankar Mishra", "title": "Cyberattack on the Microgrids Through Price Modification", "comments": "10 pages, ACM MobiHoc Workshop", "journal-ref": "Proceedings of the ACM Workshop on Internet of Things (IoT)\n  Security: Issues and Innovations, pp. 1-6. 2017", "doi": "10.1145/3084030.3084032", "report-no": null, "categories": "eess.SY cs.CY cs.SI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent massive failures in the power grid acted as a wake up call for all\nutilities and consumers. This leads to aggressive pursue a more intelligent\ngrid which addresses the concerns of reliability, efficiency, security, quality\nand sustainability for the energy consumers and producers alike. One of the\nmany features of the smart grid is a discrete energy system consisting of\ndistributed energy sources capable of operating independently from the main\ngrid known as the microgrid. The main focus of the microgrid is to ensure a\nreliable and affordable energy security. However, it also can be vulnerable to\ncyber attack and we study the effect of price modification of electricity\nattack on the microgrid, given that they are able to operate independently from\nthe main grid. This attack consists of two stages, 1) Separate the microgrids\nfrom the main grid (islanding) and 2) Failing the nodes inside the microgrid.\nEmpirical results on IEEE Bus data help us evaluate our approach under various\nsettings of grid parameters.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:14:45 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Mishra", "Subhankar", ""]]}, {"id": "2005.08817", "submitter": "Jia Xue", "authors": "Jia Xue, Junxiang Chen, Chen Chen, Chengda Zheng, Sijia Li, Tingshao\n  Zhu", "title": "Public discourse and sentiment during the COVID-19 pandemic: using\n  Latent Dirichlet Allocation for topic modeling on Twitter", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0239441", "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study aims to understand Twitter users' discourse and psychological\nreactions to COVID-19. We use machine learning techniques to analyze about 1.9\nmillion Tweets (written in English) related to coronavirus collected from\nJanuary 23 to March 7, 2020. A total of salient 11 topics are identified and\nthen categorized into ten themes, including \"updates about confirmed cases,\"\n\"COVID-19 related death,\" \"cases outside China (worldwide),\" \"COVID-19 outbreak\nin South Korea,\" \"early signs of the outbreak in New York,\" \"Diamond Princess\ncruise,\" \"economic impact,\" \"Preventive measures,\" \"authorities,\" and \"supply\nchain.\" Results do not reveal treatments and symptoms related messages as\nprevalent topics on Twitter. Sentiment analysis shows that fear for the unknown\nnature of the coronavirus is dominant in all topics. Implications and\nlimitations of the study are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 15:50:38 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 17:22:01 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 13:52:36 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Xue", "Jia", ""], ["Chen", "Junxiang", ""], ["Chen", "Chen", ""], ["Zheng", "Chengda", ""], ["Li", "Sijia", ""], ["Zhu", "Tingshao", ""]]}, {"id": "2005.08922", "submitter": "Constantinos Marios Angelopoulos", "authors": "Constantinos Marios Angelopoulos, Amalia Damianou, Vasilios Katos", "title": "DHP Framework: Digital Health Passports Using Blockchain -- Use case on\n  international tourism during the COVID-19 pandemic", "comments": null, "journal-ref": null, "doi": "10.1111/j.1365-2966.2005.08922.x", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to contain the COVID-19 pandemic, several countries enforced\nextended social distancing measures for several weeks, effectively pausing the\nmajority of economic activities. In an effort to resume economic activity\nsafely, several Digital Contact Tracing applications and protocols have been\nintroduced with success. However, DCT is a reactive method, as it aims to break\nexisting chains of disease transmission in a population. Therefore DCT is not\nsuitable for proactively preventing the spread of a disease; an approach that\nrelevant to certain use cases, such as international tourism, where individuals\ntravel across borders. In this work, we first identify the limitations\ncharacterising DCT related to privacy issues, unwillingness of the public to\nuse DCT mobile apps due to privacy concerns, lack of interoperability among\ndifferent DCT applications and protocols, and the assumption that there is\nlimited, local mobility in the population. We then discuss the concept of a\nHealth Passport as a means of verifying that individuals are disease risk-free\nand how it could be used to resume the international tourism sector. Following,\nwe present the DHP Framework that uses a private blockchain and Proof of\nAuthority for issuing Digital Health Passports. The framework provides a\ndistributed infrastructure supporting the issuance of DHPs by foreign health\nsystems and their verification by relevant stakeholders, such as airline\ncompanies and border control authorities. We discuss the attributes of the\nsystem in terms of its usability and performance, security and privacy.\nFinally, we conclude by identifying future extensions of our work on formal\nsecurity and privacy properties that need to be rigorously guaranteed via\nappropriate security protocols.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 17:50:41 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:48:33 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Angelopoulos", "Constantinos Marios", ""], ["Damianou", "Amalia", ""], ["Katos", "Vasilios", ""]]}, {"id": "2005.08952", "submitter": "Tommy Nilsson", "authors": "Tommy Nilsson, Joel E. Fischer, Andy Crabtree, Murray Goulden, Jocelyn\n  Spence, Enrico Costanza", "title": "Visions, Values, and Videos: Revisiting Envisionings in Service of\n  UbiComp Design for the Home", "comments": "DIS'20, July 6-10, 2020, Eindhoven, Netherlands", "journal-ref": null, "doi": "10.1145/3357236.3395476", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  UbiComp has been envisioned to bring about a future dominated by calm\ncomputing technologies making our everyday lives ever more convenient. Yet the\nsame vision has also attracted criticism for encouraging a solitary and passive\nlifestyle. The aim of this paper is to explore and elaborate these tensions\nfurther by examining the human values surrounding future domestic UbiComp\nsolutions. Drawing on envisioning and contravisioning, we probe members of the\npublic (N=28) through the presentation and focus group discussion of two\ncontrasting animated video scenarios, where one is inspired by \"calm\" and the\nother by \"engaging\" visions of future UbiComp technology. By analysing the\nreasoning of our participants, we identify and elaborate a number of relevant\nvalues involved in balancing the two perspectives. In conclusion, we articulate\npractically applicable takeaways in the form of a set of key design questions\nand challenges.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 21:56:26 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 05:51:02 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Nilsson", "Tommy", ""], ["Fischer", "Joel E.", ""], ["Crabtree", "Andy", ""], ["Goulden", "Murray", ""], ["Spence", "Jocelyn", ""], ["Costanza", "Enrico", ""]]}, {"id": "2005.08967", "submitter": "Sarah Spiekermann", "authors": "Jana Korunovska, Bernadette Kamleitner, Sarah Spiekermann", "title": "The Challenges and Impact of Privacy Policy Comprehension", "comments": "privacy policies, privacy threats, secondary-data use, data\n  visibility, comprehension, personal data disclosure, transparency, social\n  network service site. arXiv admin note: text overlap with arXiv:1911.09386", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new information and communication technology providers collect increasing\namounts of personal data, a lot of which is user generated. Unless use policies\nare privacy-friendly, this leaves users vulnerable to privacy risks such as\nexposure through public data visibility or intrusive commercialisation of their\ndata through secondary data use. Due to complex privacy policies, many users of\nonline services unwillingly agree to privacy-intruding practices. To give users\nmore control over their privacy, scholars and regulators have pushed for short,\nsimple, and prominent privacy policies. The premise has been that users will\nsee and comprehend such policies, and then rationally adjust their disclosure\nbehaviour. In this paper, on a use case of social network service site, we show\nthat this premise does not hold. We invited 214 regular Facebook users to join\na new fictitious social network. We experimentally manipulated the\nprivacy-friendliness of an unavoidable and simple privacy policy. Half of our\nparticipants miscomprehended even this transparent privacy policy. When privacy\nthreats of secondary data use were present, users remembered the policies as\nmore privacy-friendly than they actually were and unwittingly uploaded more\ndata. To mitigate such behavioural pitfalls we present design recommendations\nto improve the quality of informed consent.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:16:48 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Korunovska", "Jana", ""], ["Kamleitner", "Bernadette", ""], ["Spiekermann", "Sarah", ""]]}, {"id": "2005.09039", "submitter": "Wuwei Zhang", "authors": "Jeremiah Blocki and Wuwei Zhang", "title": "DALock: Distribution Aware Password Throttling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale online password guessing attacks are wide-spread and continuously\nqualified as one of the top cyber-security risks. The common method for\nmitigating the risk of online cracking is to lock out the user after a fixed\nnumber ($K$) of consecutive incorrect login attempts. Selecting the value of\n$K$ induces a classic security-usability trade-off. When $K$ is too large a\nhacker can (quickly) break into a significant fraction of user accounts, but\nwhen $K$ is too low we will start to annoy honest users by locking them out\nafter a few mistakes. Motivated by the observation that honest user mistakes\ntypically look quite different than the password guesses of an online attacker,\nwe introduce DALock a {\\em distribution aware} password lockout mechanism to\nreduce user annoyance while minimizing user risk. As the name suggests, DALock\nis designed to be aware of the frequency and popularity of the password used\nfor login attacks while standard throttling mechanisms (e.g., $K$-strikes) are\noblivious to the password distribution. In particular, DALock maintains an\nextra \"hit count\" in addition to \"strike count\" for each user which is based on\n(estimates of) the cumulative probability of {\\em all} login attempts for that\nparticular account. We empirically evaluate DALock with an extensive battery of\nsimulations using real world password datasets. In comparison with the\ntraditional $K$-strikes mechanism we find that DALock offers a superior\nsecurity/usability trade-off. For example, in one of our simulations we are\nable to reduce the success rate of an attacker to $0.05\\%$ (compared to $1\\%$\nfor the $10$-strikes mechanism) whilst simultaneously reducing the unwanted\nlockout rate for accounts that are not under attack to just $0.08\\%$ (compared\nto $4\\%$ for the $3$-strikes mechanism).\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 19:15:26 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Blocki", "Jeremiah", ""], ["Zhang", "Wuwei", ""]]}, {"id": "2005.09085", "submitter": "Alexandru Iosup", "authors": "Alexandru Iosup, Catia Trubiani, Anne Koziolek, Jos\\'e Nelson Amaral,\n  Andre B. Bondi, Andreas Brunnert", "title": "Flexibility Is Key in Organizing a Global Professional Conference\n  Online: The ICPE 2020 Experience in the COVID-19 Era", "comments": "18 pages, 32 figures, the 11th ACM/SPEC International Conference on\n  Performance Engineering (ICPE 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizing professional conferences online has never been more timely.\nResponding to the new challenges raised by COVID-19, the organizers of the\nACM/SPEC International Conference on Performance Engineering 2020 had to\naddress the question: How should we organize these conferences online? This\narticle summarizes their successful answer.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 21:00:02 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Iosup", "Alexandru", ""], ["Trubiani", "Catia", ""], ["Koziolek", "Anne", ""], ["Amaral", "Jos\u00e9 Nelson", ""], ["Bondi", "Andre B.", ""], ["Brunnert", "Andreas", ""]]}, {"id": "2005.09091", "submitter": "Isha Ghodgaonkar", "authors": "Isha Ghodgaonkar, Abhinav Goel, Fischer Bordwell, Caleb Tung, Sara\n  Aghajanzadeh, Noah Curran, Ryan Chen, Kaiwen Yu, Sneha Mahapatra, Vishnu\n  Banna, Gore Kao, Kate Lee, Xiao Hu, Nick Eliopolous, Akhil Chinnakotla,\n  Damini Rijhwani, Ashley Kim, Aditya Chakraborty, Mark Daniel Ward,\n  Yung-Hsiang Lu, George K. Thiruvathukal", "title": "Observing Responses to the COVID-19 Pandemic using Worldwide Network\n  Cameras", "comments": "7 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has resulted in a worldwide pandemic, leading to \"lockdown\" policies\nand social distancing. The pandemic has profoundly changed the world.\nTraditional methods for observing these historical events are difficult because\nsending reporters to areas with many infected people can put the reporters'\nlives in danger. New technologies are needed for safely observing responses to\nthese policies. This paper reports using thousands of network cameras deployed\nworldwide for the purpose of witnessing activities in response to the policies.\nThe network cameras can continuously provide real-time visual data (image and\nvideo) without human efforts. Thus, network cameras can be utilized to observe\nactivities without risking the lives of reporters. This paper describes a\nproject that uses network cameras to observe responses to governments' policies\nduring the COVID-19 pandemic (March to April in 2020). The project discovers\nover 30,000 network cameras deployed in 110 countries. A set of computer tools\nare created to collect visual data from network cameras continuously during the\npandemic. This paper describes the methods to discover network cameras on the\nInternet, the methods to collect and manage data, and preliminary results of\ndata analysis. This project can be the foundation for observing the possible\n\"second wave\" in fall 2020. The data may be used for post-pandemic analysis by\nsociologists, public health experts, and meteorologists.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 21:13:54 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ghodgaonkar", "Isha", ""], ["Goel", "Abhinav", ""], ["Bordwell", "Fischer", ""], ["Tung", "Caleb", ""], ["Aghajanzadeh", "Sara", ""], ["Curran", "Noah", ""], ["Chen", "Ryan", ""], ["Yu", "Kaiwen", ""], ["Mahapatra", "Sneha", ""], ["Banna", "Vishnu", ""], ["Kao", "Gore", ""], ["Lee", "Kate", ""], ["Hu", "Xiao", ""], ["Eliopolous", "Nick", ""], ["Chinnakotla", "Akhil", ""], ["Rijhwani", "Damini", ""], ["Kim", "Ashley", ""], ["Chakraborty", "Aditya", ""], ["Ward", "Mark Daniel", ""], ["Lu", "Yung-Hsiang", ""], ["Thiruvathukal", "George K.", ""]]}, {"id": "2005.09100", "submitter": "Kostadin Kushlev", "authors": "Kostadin Kushlev and Matthew R Leitao", "title": "The Effects of Smartphones on Well-Being: Theoretical Integration and\n  Research Agenda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.IT cs.MM econ.GN math.IT q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As smartphones become ever more integrated in peoples lives, a burgeoning new\narea of research has emerged on their well-being effects. We propose that\ndisparate strands of research and apparently contradictory findings can be\nintegrated under three basic hypotheses, positing that smartphones influence\nwell-being by (1) replacing other activities (displacement hypothesis), (2)\ninterfering with concurrent activities (interference hypothesis), and (3)\naffording access to information and activities that would otherwise be\nunavailable (complementarity hypothesis). Using this framework, we highlight\nmethodological issues and go beyond net effects to examine how and when phones\nboost versus hurt well-being. We examine both psychological and contextual\nmediators and moderators of the effects, thus outlining an agenda for future\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 21:25:51 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kushlev", "Kostadin", ""], ["Leitao", "Matthew R", ""]]}, {"id": "2005.09140", "submitter": "Mina Zaminkar", "authors": "Mina Zaminkar and Reza Fotohi", "title": "SoS-RPL: Securing Internet of Things Against Sinkhole Attack Using RPL\n  Protocol-Based Node Rating and Ranking Mechanism", "comments": "26 pages, 11 figures, 10 tables, Wireless Pers Commun (2020)", "journal-ref": null, "doi": "10.1007/s11277-020-07421-z", "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the Internet of Things (IoT) the internet scope is established by the\nintegration of physical things to classify themselves into mutual things. A\nphysical thing can be created by this inventive perception to signify itself in\nthe digital world. Regarding the physical things that are related to the\ninternet, it is worth noting that considering numerous theories and upcoming\npredictions, they mostly require protected structures, moreover, they are at\nrisk of several attacks. IoTs are endowed with particular routing disobedience\ncalled sinkhole attack owing to their distributed features. In these attacks, a\nmalicious node broadcasts illusive information regarding the routings to impose\nitself as a route towards specific nodes for the neighboring nodes and thus,\nattract data traffic. RPL (IP-V6 routing protocol for efficient and low-energy\nnetworks) is a standard routing protocol which is mainly employed in sensor\nnetworks and IoT. This protocol is called SoS-RPL consisting of two key\nsections of the sinkhole detection. In the first section rating and ranking the\nnodes in the RPL is carried out based on distance measurements. The second\nsection is in charge of discovering the misbehavior sources within the IoT\nnetwork through, the Average Packet Transmission RREQ (APT-RREQ). Here, the\ntechnique is assessed through wide simulations performed within the NS-3\nenvironment. Based on the results of the simulation, it is indicated that the\nIoT network behavior metrics are enhanced based on the detection rate,\nfalse-negative rate, false-positive rate, packet delivery rate, maximum\nthroughput, and packet loss rate.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 09:26:09 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zaminkar", "Mina", ""], ["Fotohi", "Reza", ""]]}, {"id": "2005.09199", "submitter": "Mansoor Ahmed-Rengers", "authors": "Mansoor Ahmed-Rengers", "title": "FrameProv: Towards End-To-End Video Provenance", "comments": null, "journal-ref": "New Security Paradigms Workshop, 2019", "doi": "10.1145/3368860.3368866", "report-no": null, "categories": "cs.CR cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video feeds are often deliberately used as evidence, as in the case of CCTV\nfootage; but more often than not, the existence of footage of a supposed event\nis perceived as proof of fact in the eyes of the public at large. This reliance\nrepresents a societal vulnerability given the existence of easy-to-use editing\ntools and means to fabricate entire video feeds using machine learning. And, as\nthe recent barrage of fake news and fake porn videos have shown, this isn't\nmerely an academic concern, it is actively been exploited. I posit that this\nexploitation is only going to get more insidious. In this position paper, I\nintroduce a long term project that aims to mitigate some of the most egregious\nforms of manipulation by embedding trustworthy components in the video\ntransmission chain. Unlike earlier works, I am not aiming to do tamper\ndetection or other forms of forensics -- approaches I think are bound to fail\nin the face of the reality of necessary editing and compression -- instead, the\naim here is to provide a way for the video publisher to prove the integrity of\nthe video feed as well as make explicit any edits they may have performed. To\ndo this, I present a novel data structure, a video-edit specification language\nand supporting infrastructure that provides end-to-end video provenance, from\nthe camera sensor to the viewer. I have implemented a prototype of this system\nand am in talks with journalists and video editors to discuss the best ways\nforward with introducing this idea to the mainstream.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 03:52:21 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ahmed-Rengers", "Mansoor", ""]]}, {"id": "2005.09209", "submitter": "Bashir Rastegarpanah", "authors": "Bashir Rastegarpanah (1), Mark Crovella (1), Krishna P. Gummadi (2)\n  ((1) Boston University, (2) MPI-SWS)", "title": "Fair Inputs and Fair Outputs: The Incompatibility of Fairness in Privacy\n  and Accuracy", "comments": null, "journal-ref": null, "doi": "10.1145/3386392.3399568", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness concerns about algorithmic decision-making systems have been mainly\nfocused on the outputs (e.g., the accuracy of a classifier across individuals\nor groups). However, one may additionally be concerned with fairness in the\ninputs. In this paper, we propose and formulate two properties regarding the\ninputs of (features used by) a classifier. In particular, we claim that fair\nprivacy (whether individuals are all asked to reveal the same information) and\nneed-to-know (whether users are only asked for the minimal information required\nfor the task at hand) are desirable properties of a decision system. We explore\nthe interaction between these properties and fairness in the outputs (fair\nprediction accuracy). We show that for an optimal classifier these three\nproperties are in general incompatible, and we explain what common properties\nof data make them incompatible. Finally we provide an algorithm to verify if\nthe trade-off between the three properties exists in a given dataset, and use\nthe algorithm to show that this trade-off is common in real data.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 04:32:16 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 23:48:21 GMT"}, {"version": "v3", "created": "Sun, 24 May 2020 22:08:23 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Rastegarpanah", "Bashir", "", "Boston University"], ["Crovella", "Mark", "", "Boston University"], ["Gummadi", "Krishna P.", "", "MPI-SWS"]]}, {"id": "2005.09225", "submitter": "David Wadden", "authors": "David Wadden, Tal August, Qisheng Li, Tim Althoff", "title": "The Effect of Moderation on Online Mental Health Conversations", "comments": "Accepted as a full paper at ICWSM 2021. 12 pages, 12 figures, 3\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many people struggling with mental health issues are unable to access\nadequate care due to high costs and a shortage of mental health professionals,\nleading to a global mental health crisis. Online mental health communities can\nhelp mitigate this crisis by offering a scalable, easily accessible alternative\nto in-person sessions with therapists or support groups. However, people\nseeking emotional or psychological support online may be especially vulnerable\nto the kinds of antisocial behavior that sometimes occur in online discussions.\nModeration can improve online discourse quality, but we lack an understanding\nof its effects on online mental health conversations. In this work, we\nleveraged a natural experiment, occurring across 200,000 messages from 7,000\nonline mental health conversations, to evaluate the effects of moderation on\nonline mental health discussions. We found that participation in group mental\nhealth discussions led to improvements in psychological perspective, and that\nthese improvements were larger in moderated conversations. The presence of a\nmoderator increased user engagement, encouraged users to discuss negative\nemotions more candidly, and dramatically reduced bad behavior among chat\nparticipants. Moderation also encouraged stronger linguistic coordination,\nwhich is indicative of trust building. In addition, moderators who remained\nactive in conversations were especially successful in keeping conversations on\ntopic. Our findings suggest that moderation can serve as a valuable tool to\nimprove the efficacy and safety of online mental health conversations. Based on\nthese findings, we discuss implications and trade-offs involved in designing\neffective online spaces for mental health support.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 05:40:59 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 20:55:46 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 22:08:16 GMT"}, {"version": "v4", "created": "Fri, 24 Jul 2020 19:20:09 GMT"}, {"version": "v5", "created": "Tue, 6 Apr 2021 23:35:09 GMT"}, {"version": "v6", "created": "Wed, 14 Apr 2021 04:14:48 GMT"}, {"version": "v7", "created": "Thu, 22 Apr 2021 22:00:35 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Wadden", "David", ""], ["August", "Tal", ""], ["Li", "Qisheng", ""], ["Althoff", "Tim", ""]]}, {"id": "2005.09285", "submitter": "Hiroko Oe", "authors": "Takuji Takemoto, Takashi Ota, Hiroko Oe", "title": "An examination of applicability of face recognition sensors in public\n  facilities", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This study aimed to explore the usability and applicability of face\nrecognition sensors in public spaces to collect customer footfall data, which\ncould then be analysed and evaluated for facility design and planning. Nine\nOMRON sensors were provided for the project and installed at five locations in\na public facility for three months. The project was carried out by a local\nconsortium with the cooperation of local technology-based Small Medium-sized\nEnterprises (SMEs), business organisations, and a local university. Collected\ndata were analysed to develop a report with diagrams, and reveal issues and\npotential for practical application in the future.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 08:31:11 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Takemoto", "Takuji", ""], ["Ota", "Takashi", ""], ["Oe", "Hiroko", ""]]}, {"id": "2005.09417", "submitter": "Robert Myers", "authors": "Robert Myers, Zeyn Saigol", "title": "Pass-Fail Criteria for Scenario-Based Testing of Automated Driving\n  Systems", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MUSICC project has created a proof-of-concept scenario database to be\nused as part of a type approval process for the verification of automated\ndriving systems (ADS). This process must include a highly automated means of\nevaluating test results, as manual review at the scale required is impractical.\n  This paper sets out a framework for assessing an ADS's behavioural safety in\nnormal operation (i.e. performance of the dynamic driving task without\ncomponent failures or malicious actions). Five top-level evaluation criteria\nfor ADS performance are identified. Implementing these requires two types of\noutcome scoring rule: prescriptive (measurable rules which must always be\nfollowed) and risk-based (undesirable outcomes which must not occur too often).\nScoring rules are defined in a programming language and will be stored as part\nof the scenario description.\n  Risk-based rules cannot give a pass/fail decision from a single test case.\nInstead, a framework is defined to reach a decision for each functional\nscenario (set of test cases with common features). This considers statistical\nperformance across many individual tests. Implications of this framework for\nhypothesis testing and scenario selection are identified.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:13:08 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 14:15:12 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Myers", "Robert", ""], ["Saigol", "Zeyn", ""]]}, {"id": "2005.09442", "submitter": "Giulia Caselli", "authors": "Giulia Caselli, Maxence Delorme, Manuel Iori", "title": "Integer Linear Programming for the Tutor Allocation Problem: A Practical\n  Case in a British University", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Tutor Allocation Problem, the objective is to assign a set of tutors\nto a set of workshops in order to maximize tutors' preferences. The problem is\nsolved every year by many universities, each having its own specific set of\nconstraints. In this work, we study the tutor allocation in the School of\nMathematics at the University of Edinburgh, and solve it with an integer linear\nprogramming model. We tested the model on the 2019/2020 case, obtaining a\nsignificant improvement with respect to the manual assignment in use. Further\ntests on randomly created instances show that the model can be used to address\ncases of broad interest. We also provide meaningful insights on how input\nparameters, such as the number of workshop locations and the length of the\ntutors' preference list, might affect the performance of the model and the\naverage number of preferences satisfied.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:45:13 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Caselli", "Giulia", ""], ["Delorme", "Maxence", ""], ["Iori", "Manuel", ""]]}, {"id": "2005.09460", "submitter": "Carole Adam", "authors": "Carole Adam", "title": "VigiFlood: evaluating the impact of a change of perspective on flood\n  vigilance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergency managers receive communication training about the importance of\nbeing 'first, right and credible', and taking into account the psychology of\ntheir audience and their particular reasoning under stress and risk. But we\nbelieve that citizens should be similarly trained about how to deal with risk\ncommunication. In particular, such messages necessarily carry a part of\nuncertainty since most natural risks are difficult to accurately forecast ahead\nof time. Yet, citizens should keep trusting the emergency communicators even\nafter they made forecasting errors in the past.\n  We have designed a serious game called Vigiflood, based on a real case study\nof flash floods hitting the South West of France in October 2018. In this game,\nthe user changes perspective by taking the role of an emergency communicator,\nhaving to set the level of vigilance to alert the population, based on\nuncertain clues. Our hypothesis is that this change of perspective can improve\nthe player's awareness and response to future flood vigilance announcements. We\nevaluated this game through an online survey where people were asked to answer\na questionnaire about flood risk awareness and behavioural intentions before\nand after playing the game, in order to assess its impact.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:05:11 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Adam", "Carole", ""]]}, {"id": "2005.09495", "submitter": "Suzanne Tolmeijer", "authors": "Abraham Bernstein and Claes de Vreese and Natali Helberger and\n  Wolfgang Schulz and Katharina Zweig and Christian Baden and Michael A. Beam\n  and Marc P. Hauer and Lucien Heitz and Pascal J\\\"urgens and Christian\n  Katzenbach and Benjamin Kille and Beate Klimkiewicz and Wiebke Loosen and\n  Judith Moeller and Goran Radanovic and Guy Shani and Nava Tintarev and\n  Suzanne Tolmeijer and Wouter van Atteveldt and Sanne Vrijenhoek and Theresa\n  Zueger", "title": "Diversity in News Recommendations", "comments": "Published as Manifesto from Dagstuhl Perspectives Workshop 19482", "journal-ref": "Dagstuhl Perspectives Workshop: Diversity, Fairness, and\n  Data-Drives Personalization in (News) Recommender Systems, Dagstuhl\n  Manifestos (2021), Vol. 9, Issue 1, pp. 43-61", "doi": "10.4230/DagMan.9.1.43", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  News diversity in the media has for a long time been a foundational and\nuncontested basis for ensuring that the communicative needs of individuals and\nsociety at large are met. Today, people increasingly rely on online content and\nrecommender systems to consume information challenging the traditional concept\nof news diversity. In addition, the very concept of diversity, which differs\nbetween disciplines, will need to be re-evaluated requiring a interdisciplinary\ninvestigation, which requires a new level of mutual cooperation between\ncomputer scientists, social scientists, and legal scholars. Based on the\noutcome of a multidisciplinary workshop, we have the following recommendations,\ndirected at researchers, funders, legislators, regulators, and the media\nindustry: 1. Do more research on news recommenders and diversity. 2. Create a\nsafe harbor for academic research with industry data. 3. Optimize the role of\npublic values in news recommenders. 4. Create a meaningful governance\nframework. 5. Fund a joint lab to spearhead the needed interdisciplinary\nresearch, boost practical innovation, develop. reference solutions, and\ntransfer insights into practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:51:15 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 07:53:24 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Bernstein", "Abraham", ""], ["de Vreese", "Claes", ""], ["Helberger", "Natali", ""], ["Schulz", "Wolfgang", ""], ["Zweig", "Katharina", ""], ["Baden", "Christian", ""], ["Beam", "Michael A.", ""], ["Hauer", "Marc P.", ""], ["Heitz", "Lucien", ""], ["J\u00fcrgens", "Pascal", ""], ["Katzenbach", "Christian", ""], ["Kille", "Benjamin", ""], ["Klimkiewicz", "Beate", ""], ["Loosen", "Wiebke", ""], ["Moeller", "Judith", ""], ["Radanovic", "Goran", ""], ["Shani", "Guy", ""], ["Tintarev", "Nava", ""], ["Tolmeijer", "Suzanne", ""], ["van Atteveldt", "Wouter", ""], ["Vrijenhoek", "Sanne", ""], ["Zueger", "Theresa", ""]]}, {"id": "2005.09502", "submitter": "Zahid Iqbal", "authors": "Zahid Iqbal, Rafia Ilyas, Waseem Shahzad, Irum Inayat", "title": "A comparative study of machine learning techniques used in non-clinical\n  systems for continuous healthcare of independent livings", "comments": "2018 IEEE Symposium on Computer Applications & Industrial Electronics\n  (ISCAIE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New technologies are adapted to made progress in healthcare especially for\nindependent livings. Medication at distance is leading to integrate\ntechnologies with medical. Machine learning methods in collaboration with\nwearable sensor network technology are used to find hidden patterns in data,\ndetect patient movements, observe habits of patient, analyze clinical data of\npatient, find intention of patients and make decision on the bases of gathered\ndata. This research performs comparative study on non-clinical systems in\nhealthcare for independent livings. In this study, these systems are\nsub-divided w.r.t their working into two types: single purpose systems and\nmulti-purpose systems. Systems that are built for single specific purpose (e.g.\ndetect fall, detect emergent state of chronic disease patient) and cannot\nsupport healthcare generically are known as single purpose systems, where\nmulti-purpose systems are built to serve for multiple problems (e.g. heart\nattack etc.) by using single system. This study analyzes usages of machine\nlearning techniques in healthcare systems for independent livings. Answer Set\nProgramming (ASP), Artificial Neural Networks, Classification, Sampling and\nRule Based Reasoning etc. are some state of art techniques used to determine\nemergent situations and observe changes in patient data. Among all methods, ASP\nlogic is used most widely, it is due to its feature to deal with incomplete\ndata. It is also observed that system using ANN shows better accuracy than\nother systems. It is observed that most of the systems created are for single\npurpose. In this work, 10 single purpose systems and 5 multi-purpose systems\nare studied. There is need to create more generic systems that can be used for\npatients with multiple diseases. Also most of the systems created are\nprototypical. There is need to create systems that can serve healthcare\nservices in real world.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:59:50 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Iqbal", "Zahid", ""], ["Ilyas", "Rafia", ""], ["Shahzad", "Waseem", ""], ["Inayat", "Irum", ""]]}, {"id": "2005.09649", "submitter": "Ammar Rashed", "authors": "Ammar Rashed, Mucahid Kutlu, Kareem Darwish, Tamer Elsayed, Cans{\\i}n\n  Bayrak", "title": "Embeddings-Based Clustering for Target Specific Stances: The Case of a\n  Polarized Turkey", "comments": "arXiv admin note: text overlap with arXiv:1909.10213", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On June 24, 2018, Turkey conducted a highly consequential election in which\nthe Turkish people elected their president and parliament in the first election\nunder a new presidential system. During the election period, the Turkish people\nextensively shared their political opinions on Twitter. One aspect of\npolarization among the electorate was support for or opposition to the\nreelection of Recep Tayyip Erdo\\u{g}an. In this paper, we present an\nunsupervised method for target-specific stance detection in a polarized\nsetting, specifically Turkish politics, achieving 90% precision in identifying\nuser stances, while maintaining more than 80% recall. The method involves\nrepresenting users in an embedding space using Google's Convolutional Neural\nNetwork (CNN) based multilingual universal sentence encoder. The\nrepresentations are then projected onto a lower dimensional space in a manner\nthat reflects similarities and are consequently clustered. We show the\neffectiveness of our method in properly clustering users of divergent groups\nacross multiple targets that include political figures, different groups, and\nparties. We perform our analysis on a large dataset of 108M Turkish\nelection-related tweets along with the timeline tweets of 168k Turkish users,\nwho authored 213M tweets. Given the resultant user stances, we are able to\nobserve correlations between topics and compute topic polarization.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 13:52:15 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Rashed", "Ammar", ""], ["Kutlu", "Mucahid", ""], ["Darwish", "Kareem", ""], ["Elsayed", "Tamer", ""], ["Bayrak", "Cans\u0131n", ""]]}, {"id": "2005.09784", "submitter": "Kiran Garimella", "authors": "Kiran Garimella, Dean Eckles", "title": "Images and Misinformation in Political Groups: Evidence from WhatsApp in\n  India", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WhatsApp is a key medium for the spread of news and rumors, often shared as\nimages. We study a large collection of politically-oriented WhatsApp groups in\nIndia, focusing on the period leading up to the 2019 Indian national elections.\nBy labeling samples of random and popular images, we find that around 13% of\nshared images are known misinformation and most fall into three types of\nimages. Machine learning methods can be used to predict whether a viral image\nis misinformation, but are brittle to shifts in content over time.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 23:00:17 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Garimella", "Kiran", ""], ["Eckles", "Dean", ""]]}, {"id": "2005.09837", "submitter": "Jichang Zhao", "authors": "Di Weng, Jichang Zhao", "title": "Positive emotions help rank negative reviews in e-commerce", "comments": "Emotion lexicons are publicly available at\n  https://doi.org/10.6084/m9.figshare.12327680.v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Negative reviews, the poor ratings in postpurchase evaluation, play an\nindispensable role in e-commerce, especially in shaping future sales and firm\nequities. However, extant studies seldom examine their potential value for\nsellers and producers in enhancing capabilities of providing better services\nand products. For those who exploited the helpfulness of reviews in the view of\ne-commerce keepers, the ranking approaches were developed for customers\ninstead. To fill this gap, in terms of combining description texts and emotion\npolarities, the aim of the ranking method in this study is to provide the most\nhelpful negative reviews under a certain product attribute for online sellers\nand producers. By applying a more reasonable evaluating procedure, experts with\nrelated backgrounds are hired to vote for the ranking approaches. Our ranking\nmethod turns out to be more reliable for ranking negative reviews for sellers\nand producers, demonstrating a better performance than the baselines like BM25\nwith a result of 8% higher. In this paper, we also enrich the previous\nunderstandings of emotions in valuing reviews. Specifically, it is surprisingly\nfound that positive emotions are more helpful rather than negative emotions in\nranking negative reviews. The unexpected strengthening from positive emotions\nin ranking suggests that less polarized reviews on negative experience in fact\noffer more rational feedbacks and thus more helpfulness to the sellers and\nproducers. The presented ranking method could provide e-commerce practitioners\nwith an efficient and effective way to leverage negative reviews from online\nconsumers.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 03:34:20 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Weng", "Di", ""], ["Zhao", "Jichang", ""]]}, {"id": "2005.09959", "submitter": "Daniel Graziotin", "authors": "Daniel Graziotin, Per Lenberg, Robert Feldt, Stefan Wagner", "title": "Psychometrics in Behavioral Software Engineering: A Methodological\n  Introduction with Guidelines", "comments": "56 pages (pp. 1-36 for the main paper, pp. 37-56 working example in\n  the appendix), 8 figures in the main paper. Accepted for publication at ACM\n  TOSEM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A meaningful and deep understanding of the human aspects of software\nengineering (SE) requires psychological constructs to be considered. Psychology\ntheory can facilitate the systematic and sound development as well as the\nadoption of instruments (e.g., psychological tests, questionnaires) to assess\nthese constructs. In particular, to ensure high quality, the psychometric\nproperties of instruments need evaluation. In this paper, we provide an\nintroduction to psychometric theory for the evaluation of measurement\ninstruments for SE researchers. We present guidelines that enable using\nexisting instruments and developing new ones adequately. We conducted a\ncomprehensive review of the psychology literature framed by the Standards for\nEducational and Psychological Testing. We detail activities used when\noperationalizing new psychological constructs, such as item pooling, item\nreview, pilot testing, item analysis, factor analysis, statistical property of\nitems, reliability, validity, and fairness in testing and test bias. We provide\nan openly available example of a psychometric evaluation based on our\nguideline. We hope to encourage a culture change in SE research towards the\nadoption of established methods from psychology. To improve the quality of\nbehavioral research in SE, studies focusing on introducing, validating, and\nthen using psychometric instruments need to be more common.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 11:03:46 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 16:13:50 GMT"}, {"version": "v3", "created": "Tue, 20 Apr 2021 10:19:24 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 13:10:37 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Graziotin", "Daniel", ""], ["Lenberg", "Per", ""], ["Feldt", "Robert", ""], ["Wagner", "Stefan", ""]]}, {"id": "2005.10007", "submitter": "Juste Raimbault", "authors": "Juste Raimbault and Eric Denis and Denise Pumain", "title": "Empowering Urban Governance through Urban Science: Multi-scale Dynamics\n  of Urban Systems Worldwide", "comments": "25 pages, 9 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current science of cities can provide a useful foundation for future\nurban policies, provided that these proposals have been validated by correct\nobservations of the diversity of situations in the world. However,\ninternational comparisons of the evolution of cities often produce uncertain\nresults because national territorial frameworks are not always in strict\ncorrespondence with the dynamics of urban systems. We propose to provide\nvarious compositions of systems of cities to better take into account the\ndynamic networking of cities that go beyond regional and national territorial\nboundaries. Different models conceived for explaining city size and urban\ngrowth distributions enable to establish a correspondence between urban\ntrajectories when observed at the level of cities and systems of cities. We\ntest the validity and representativeness of several dynamic models of complex\nurban systems and their variations across regions of the world, at the\nmacroscopic scale of systems of cities. The originality of the approach is in\nconsidering spatial interaction and evolutionary path dependence as major\nfeatures in the general behavior of urban entities. The models studied include\ndiverse and complementary processes, such as economic exchanges, diffusion of\ninnovations and physical network flows. Complex systems' dynamics is in\nprinciple unpredictable, but contextualizing it regarding demographic, income\nand resource components may help in minimizing the forecasting errors.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 12:47:40 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Raimbault", "Juste", ""], ["Denis", "Eric", ""], ["Pumain", "Denise", ""]]}, {"id": "2005.10019", "submitter": "Eduardo Graells-Garrido", "authors": "Eduardo Graells-Garrido, Ricardo Baeza-Yates, Mounia Lalmas", "title": "Every Colour You Are: Stance Prediction and Turnaround in Controversial\n  Issues", "comments": "Accepted at WebSci'20", "journal-ref": null, "doi": "10.1145/3394231.3397907", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web platforms have allowed political manifestation and debate for decades.\nTechnology changes have brought new opportunities for expression, and the\navailability of longitudinal data of these debates entice new questions\nregarding who participates, and who updates their opinion. The aim of this work\nis to provide a methodology to measure these phenomena, and to test this\nmethodology on a specific topic, abortion, as observed on one of the most\npopular micro-blogging platforms. To do so, we followed the discussion on\nTwitter about abortion in two Spanish-speaking countries from 2015 to 2018. Our\nmain insights are two fold. On the one hand, people adopted new technologies to\nexpress their stances, particularly colored variations of heart emojis ([green\nheart] & [purple heart]) in a way that mirrored physical manifestations on\nabortion. On the other hand, even on issues with strong opinions, opinions can\nchange, and these changes show differences in demographic groups. These\nfindings imply that debate on the Web embraces new ways of stance adherence,\nand that changes of opinion can be measured and characterized.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 17:35:00 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Graells-Garrido", "Eduardo", ""], ["Baeza-Yates", "Ricardo", ""], ["Lalmas", "Mounia", ""]]}, {"id": "2005.10061", "submitter": "Ruggero Caravita Dr", "authors": "Ruggero Caravita", "title": "PeopleTraffic: a common framework for harmonizing privacy and epidemic\n  risks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PeopleTraffic is a proposed initiative to develop a real-time, open-data\npopulation density mapping tool open to public institutions, private companies\nand the civil society, providing a common framework for infection spreading\nprevention. The system is based on a real-time people' locations gathering and\nmapping system from available 2G, 3G and 4G mobile networks operators,\nenforcing privacy-by-design through the adoption of an innovative data\nanonymizing algorithm inspired by quantum information de-localizing processes.\nBesides being originally targeted to help balancing social distancing\nregulations during the Phase-2 of the COVID-19 pandemics, PeopleTraffic would\nbe beneficial for any infection spreading prevention event, e.g. supporting\npolicy-makers in strategic decision-making.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 14:09:38 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Caravita", "Ruggero", ""]]}, {"id": "2005.10067", "submitter": "Biplav Srivastava", "authors": "Biplav Srivastava and Francesca Rossi and Sheema Usmani and and\n  Mariana Bernagozzi", "title": "Personalized Chatbot Trustworthiness Ratings", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversation agents, commonly referred to as chatbots, are increasingly\ndeployed in many domains to allow people to have a natural interaction while\ntrying to solve a specific problem. Given their widespread use, it is important\nto provide their users with methods and tools to increase users awareness of\nvarious properties of the chatbots, including non-functional properties that\nusers may consider important in order to trust a specific chatbot. For example,\nusers may want to use chatbots that are not biased, that do not use abusive\nlanguage, that do not leak information to other users, and that respond in a\nstyle which is appropriate for the user's cognitive level.\n  In this paper, we address the setting where a chatbot cannot be modified, its\ntraining data cannot be accessed, and yet a neutral party wants to assess and\ncommunicate its trustworthiness to a user, tailored to the user's priorities\nover the various trust issues. Such a rating can help users choose among\nalternative chatbots, developers test their systems, business leaders price\ntheir offering, and regulators set policies. We envision a personalized rating\nmethodology for chatbots that relies on separate rating modules for each issue,\nand users' detected priority orderings among the relevant trust issues, to\ngenerate an aggregate personalized rating for the trustworthiness of a chatbot.\nThe method is independent of the specific trust issues and is parametric to the\naggregation procedure, thereby allowing for seamless generalization. We\nillustrate its general use, integrate it with a live chatbot, and evaluate it\non four dialog datasets and representative user profiles, validated with user\nsurveys.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 22:42:45 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 01:13:36 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Srivastava", "Biplav", ""], ["Rossi", "Francesca", ""], ["Usmani", "Sheema", ""], ["Bernagozzi", "and Mariana", ""]]}, {"id": "2005.10082", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Rob Walton, Max Van Kleek, Omar\n  Santos, Rafael Mantilla Montalvo, La Treall Maddox", "title": "What country, university or research institute, performed the best on\n  COVID-19? Bibliometric analysis of scientific literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we conduct data mining to discover the countries,\nuniversities and companies, produced or collaborated the most research on\nCovid-19 since the pandemic started. We present some interesting findings, but\ndespite analysing all available records on COVID-19 from the Web of Science\nCore Collection, we failed to reach any significant conclusions on how the\nworld responded to the COVID-19 pandemic. Therefore, we increased our analysis\nto include all available data records on pandemics and epidemics from 1900 to\n2020. We discover some interesting results on countries, universities and\ncompanies, that produced collaborated most the most in research on pandemic and\nepidemics. Then we compared the results with the analysing on COVID-19 data\nrecords. This has created some interesting findings that are explained and\ngraphically visualised in the article.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 14:36:12 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Walton", "Rob", ""], ["Van Kleek", "Max", ""], ["Santos", "Omar", ""], ["Montalvo", "Rafael Mantilla", ""], ["Maddox", "La Treall", ""]]}, {"id": "2005.10187", "submitter": "Leonardo Maccari", "authors": "Leonardo Maccari, Valeria Cagno", "title": "Do we need a Contact Tracing App?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to shed some light on the usefulness of a contact\ntracing smartphone app for the containment of the COVID-19 pandemic. We review\nthe basics of contact tracing during the spread of a virus, we contextualize\nthe numbers to the case of COVID-19 and we analyse the state of the art for\nproximity detection using Bluetooth Low Energy. Our contribution is to assess\nif there is scientific evidence of the benefit of a contact tracing app in\nslowing down the spread of the virus using present technologies. Our conclusion\nis that such evidence is lacking, and we should re-think the introduction of\nsuch a privacy-invasive measure.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:50:57 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 13:50:57 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Maccari", "Leonardo", ""], ["Cagno", "Valeria", ""]]}, {"id": "2005.10191", "submitter": "Ryan Gallagher", "authors": "Ryan J. Gallagher, Jean-Gabriel Young, Brooke Foucault Welles", "title": "A Clarified Typology of Core-Periphery Structure in Networks", "comments": "21 pages, 6 figures, 1 table, updated abstract", "journal-ref": "Science Advances, 7:EABC9800, 2021", "doi": "10.1126/sciadv.abc9800", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Core-periphery structure, the arrangement of a network into a dense core and\nsparse periphery, is a versatile descriptor of various social, biological, and\ntechnological networks. In practice, different core-periphery algorithms are\noften applied interchangeably, despite the fact that they can yield\ninconsistent descriptions of core-periphery structure. For example, two of the\nmost widely used algorithms, the k-cores decomposition and the classic\ntwo-block model of Borgatti and Everett, extract fundamentally different\nstructures: the latter partitions a network into a binary hub-and-spoke layout,\nwhile the former divides it into a layered hierarchy. We introduce a\ncore-periphery typology to clarify these differences, along with Bayesian\nstochastic block modeling techniques to classify networks in accordance with\nthis typology. Empirically, we find a rich diversity of core-periphery\nstructure among networks. Through a detailed case study, we demonstrate the\nimportance of acknowledging this diversity and situating networks within the\ncore-periphery typology when conducting domain-specific analyses.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:57:01 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 15:31:12 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Gallagher", "Ryan J.", ""], ["Young", "Jean-Gabriel", ""], ["Welles", "Brooke Foucault", ""]]}, {"id": "2005.10309", "submitter": "Francesco Buccafurri", "authors": "Francesco Buccafurri, Vincenzo De Angelis, Cecilia Labrini", "title": "A Privacy-Preserving Solution for Proximity Tracing Avoiding Identifier\n  Exchanging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital contact tracing is one of the actions useful, in combination with\nother measures, to manage an epidemic diffusion of an infection disease in an\nafter-lock-down phase. This is a very timely issue, due to the pandemic of\nCOVID-19 we are unfortunately living. Apps for contact tracing aim to detect\nproximity of users and to evaluate the related risk in terms of possible\ncontagious. Existing approaches leverage Bluetooth or GPS, or their\ncombination, even though the prevailing approach is Bluetooth-based and relies\non a decentralized model requiring the mutual exchange of ephemeral identifiers\namong users' smartphones. Unfortunately, a number of security and privacy\nconcerns exist in this kind of solutions, mainly due to the exchange of\nidentifiers, while GPS-based solutions (inherently centralized) may suffer from\nthreats concerning massive surveillance. In this paper, we propose a solution\nleveraging GPS to detect proximity, and Bluetooth only to improve accuracy,\nwithout enabling exchange of identifiers. Unlike related existing solutions, no\ncomplex cryptographic mechanism is adopted, while ensuring that the server does\nnot learn anything about locations of users.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 18:48:20 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Buccafurri", "Francesco", ""], ["De Angelis", "Vincenzo", ""], ["Labrini", "Cecilia", ""]]}, {"id": "2005.10400", "submitter": "Zhichao Jiang", "authors": "Kosuke Imai, Zhichao Jiang", "title": "Principal Fairness for Human and Algorithmic Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the concept of principal stratification from the causal inference\nliterature, we introduce a new notion of fairness, called principal fairness,\nfor human and algorithmic decision-making. The key idea is that one should not\ndiscriminate among individuals who would be similarly affected by the decision.\nUnlike the existing statistical definitions of fairness, principal fairness\nexplicitly accounts for the fact that individuals can be impacted by the\ndecision. We propose an axiomatic assumption that all groups are created equal.\nThis assumption is motivated by a belief that protected attributes such as race\nand gender should have no direct causal effects on potential outcomes. Under\nthis assumption, we show that principal fairness implies all three existing\nstatistical fairness criteria once we account for relevant covariates. This\nresult also highlights the essential role of conditioning covariates in\nresolving the previously recognized tradeoffs between the existing statistical\nfairness criteria. Finally, we discuss how to empirically choose conditioning\ncovariates and then evaluate the principal fairness of a particular decision.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 00:24:54 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 03:48:41 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 00:51:42 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 02:25:12 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Imai", "Kosuke", ""], ["Jiang", "Zhichao", ""]]}, {"id": "2005.10414", "submitter": "Yan Leng", "authors": "Yan Leng, Yujia Zhai, Shaojing Sun, Yifei Wu, Jordan Selzer, Sharon\n  Strover, Julia Fensel, Alex Pentland, Ying Ding", "title": "Analysis of misinformation during the COVID-19 outbreak in China:\n  cultural, social and political entanglements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 resulted in an infodemic, which could erode public trust, impede\nvirus containment, and outlive the pandemic itself. The evolving and fragmented\nmedia landscape is a key driver of the spread of misinformation. Using\nmisinformation identified by the fact-checking platform by Tencent and posts on\nWeibo, our results showed that the evolution of misinformation follows an\nissue-attention cycle, pertaining to topics such as city lockdown, cures, and\npreventions, and school reopening. Sources of authority weigh in on these\ntopics, but their influence is complicated by peoples' pre-existing beliefs and\ncultural practices. Finally, social media has a complicated relationship with\nestablished or legacy media systems. Sometimes they reinforce each other, but\nin general, social media may have a topic cycle of its own making. Our findings\nshed light on the distinct characteristics of misinformation during the\nCOVID-19 and offer insights into combating misinformation in China and across\nthe world at large.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 01:34:08 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Leng", "Yan", ""], ["Zhai", "Yujia", ""], ["Sun", "Shaojing", ""], ["Wu", "Yifei", ""], ["Selzer", "Jordan", ""], ["Strover", "Sharon", ""], ["Fensel", "Julia", ""], ["Pentland", "Alex", ""], ["Ding", "Ying", ""]]}, {"id": "2005.10434", "submitter": "Yu Song", "authors": "Yu Song, Zilong Huang, Chuanyue Shen, Humphrey Shi, and David A Lange", "title": "Deep Learning-Based Automated Image Segmentation for Concrete\n  Petrographic Analysis", "comments": "Accepted as a journal publication by Cement & Concrete Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard petrography test method for measuring air voids in concrete\n(ASTM C457) requires a meticulous and long examination of sample phase\ncomposition under a stereomicroscope. The high expertise and specialized\nequipment discourage this test for routine concrete quality control. Though the\ntask can be alleviated with the aid of color-based image segmentation,\nadditional surface color treatment is required. Recently, deep learning\nalgorithms using convolutional neural networks (CNN) have achieved\nunprecedented segmentation performance on image testing benchmarks. In this\nstudy, we investigated the feasibility of using CNN to conduct concrete\nsegmentation without the use of color treatment. The CNN demonstrated a strong\npotential to process a wide range of concretes, including those not involved in\nmodel training. The experimental results showed that CNN outperforms the\ncolor-based segmentation by a considerable margin, and has comparable accuracy\nto human experts. Furthermore, the segmentation time is reduced to mere\nseconds.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 02:46:29 GMT"}, {"version": "v2", "created": "Sat, 23 May 2020 06:01:27 GMT"}, {"version": "v3", "created": "Thu, 28 May 2020 20:16:26 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Song", "Yu", ""], ["Huang", "Zilong", ""], ["Shen", "Chuanyue", ""], ["Shi", "Humphrey", ""], ["Lange", "David A", ""]]}, {"id": "2005.10542", "submitter": "Mohammadreza Tavakoli", "authors": "Mohammadreza Tavakoli, Mirette Elias, G\\'abor Kismih\\'ok, S\\\"oren Auer", "title": "Quality Prediction of Open Educational Resources A Metadata-based\n  Approach", "comments": "This paper has been accepted to be published in the proceedings of\n  International Conference on Advanced Learning Technologies (ICALT) 2020 by\n  IEEE Computer Society as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the recent decade, online learning environments have accumulated millions\nof Open Educational Resources (OERs). However, for learners, finding relevant\nand high quality OERs is a complicated and time-consuming activity.\nFurthermore, metadata play a key role in offering high quality services such as\nrecommendation and search. Metadata can also be used for automatic OER quality\ncontrol as, in the light of the continuously increasing number of OERs, manual\nquality control is getting more and more difficult. In this work, we collected\nthe metadata of 8,887 OERs to perform an exploratory data analysis to observe\nthe effect of quality control on metadata quality. Subsequently, we propose an\nOER metadata scoring model, and build a metadata-based prediction model to\nanticipate the quality of OERs. Based on our data and model, we were able to\ndetect high-quality OERs with the F1 score of 94.6%.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 09:53:43 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 16:08:59 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 15:26:30 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Tavakoli", "Mohammadreza", ""], ["Elias", "Mirette", ""], ["Kismih\u00f3k", "G\u00e1bor", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "2005.10595", "submitter": "Mohammadreza Tavakoli", "authors": "Mohammadreza Tavakoli, Sherzod Hakimov, Ralph Ewerth, G\\'abor\n  Kismih\\'ok", "title": "A Recommender System For Open Educational Videos Based On Skill\n  Requirements", "comments": "This paper has been accepted to be published in the proceedings of\n  International Conference on Advanced Learning Technologies (ICALT) 2020 by\n  IEEE Computer Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we suggest a novel method to help learners find relevant open\neducational videos to master skills demanded on the labour market. We have\nbuilt a prototype, which 1) applies text classification and text mining methods\non job vacancy announcements to match jobs and their required skills; 2)\npredicts the quality of videos; and 3) creates an open educational video\nrecommender system to suggest personalized learning content to learners.\n  For the first evaluation of this prototype we focused on the area of data\nscience related jobs. Our prototype was evaluated by in-depth, semi-structured\ninterviews. 15 subject matter experts provided feedback to assess how our\nrecommender prototype performs in terms of its objectives, logic, and\ncontribution to learning. More than 250 videos were recommended, and 82.8% of\nthese recommendations were treated as useful by the interviewees. Moreover,\ninterviews revealed that our personalized video recommender system, has the\npotential to improve the learning experience.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 12:12:47 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Tavakoli", "Mohammadreza", ""], ["Hakimov", "Sherzod", ""], ["Ewerth", "Ralph", ""], ["Kismih\u00f3k", "G\u00e1bor", ""]]}, {"id": "2005.10634", "submitter": "Manish Shukla", "authors": "Rajan M A, Manish Shukla, Sachin Lodha", "title": "A Note on Cryptographic Algorithms for Private Data Analysis in Contact\n  Tracing Applications", "comments": "12 Pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is an important measure to counter the COVID-19 pandemic. In\nthe early phase, many countries employed manual contact tracing to contain the\nrate of disease spread, however it has many issues. The manual approach is\ncumbersome, time consuming and also requires active participation of a large\nnumber of people to realize it. In order to overcome these drawbacks, digital\ncontact tracing has been proposed that typically involves deploying a contact\ntracing application on people's mobile devices which can track their movements\nand close social interactions. While studies suggest that digital contact\ntracing is more effective than manual contact tracing, it has been observed\nthat higher adoption rates of the contact tracing app may result in a better\ncontrolled epidemic. This also increases the confidence in the accuracy of the\ncollected data and the subsequent analytics. One key reason for low adoption\nrate of contact tracing applications is the concern about individual privacy.\nIn fact, several studies report that contact tracing applications deployed in\nmultiple countries are not privacy friendly and have potential to be used for\nmass surveillance by the concerned governments. Hence, privacy respecting\ncontact tracing application is the need of the hour that can lead to highly\neffective, efficient contact tracing. As part of this study, we focus on\nvarious cryptographic techniques that can help in addressing the Private Set\nIntersection problem which lies at the heart of privacy respecting contact\ntracing. We analyze the computation and communication complexities of these\ntechniques under the typical client-server architecture utilized by contact\ntracing applications. Further we evaluate those computation and communication\ncomplexity expressions for India scenario and thus identify cryptographic\ntechniques that can be more suitably deployed there.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 06:18:13 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["A", "Rajan M", ""], ["Shukla", "Manish", ""], ["Lodha", "Sachin", ""]]}, {"id": "2005.10948", "submitter": "Tong Yang", "authors": "Tong Yang, Kai Shen, Sixuan He, Enyu Li, Peter Sun, Pingying Chen, Lin\n  Zuo, Jiayue Hu, Yiwen Mo, Weiwei Zhang, Haonan Zhang, Jingxue Chen, Yu Guo", "title": "CovidNet: To Bring Data Transparency in the Era of COVID-19", "comments": "10 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timely, creditable, and fine-granular case information is vital for local\ncommunities and individual citizens to make rational and data-driven responses\nto the COVID-19 pandemic. This paper presents CovidNet, a COVID-19 tracking\nproject associated with a large scale epidemic dataset, which was initiated by\n1Point3Acres. To the best of our knowledge, the project is the only platform\nproviding real-time global case information of more than 4,124 sub-divisions\nfrom over 27 countries worldwide with multi-language supports. The platform\nalso offers interactive visualization tools to analyze the full historical case\ncurves in each region. Initially launched as a voluntary project to bridge the\ndata transparency gap in North America in January 2020, this project by far has\nbecome one of the major independent sources worldwide and has been consumed by\nmany other tracking platforms. The accuracy and freshness of the dataset is a\nresult of the painstaking efforts from our voluntary teamwork, crowd-sourcing\nchannels, and automated data pipelines. As of May 18, 2020, the project website\nhas been visited more than 200 million times and the CovidNet dataset has\nempowered over 522 institutions and organizations worldwide in policy-making\nand academic researches. All datasets are openly accessible for non-commercial\npurposes at https://coronavirus.1point3acres.com via a formal request through\nour APIs.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 00:05:17 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 21:51:19 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 21:32:24 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Yang", "Tong", ""], ["Shen", "Kai", ""], ["He", "Sixuan", ""], ["Li", "Enyu", ""], ["Sun", "Peter", ""], ["Chen", "Pingying", ""], ["Zuo", "Lin", ""], ["Hu", "Jiayue", ""], ["Mo", "Yiwen", ""], ["Zhang", "Weiwei", ""], ["Zhang", "Haonan", ""], ["Chen", "Jingxue", ""], ["Guo", "Yu", ""]]}, {"id": "2005.11005", "submitter": "Teruaki Hayashi", "authors": "Teruaki Hayashi and Gensei Ishimura and Yukio Ohsawa", "title": "Modeling Stakeholder-centric Value Chain of Data to Understand Data\n  Exchange Ecosystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the expectation that new businesses and economic value can\nbe created by combining/exchanging data from different fields has risen.\nHowever, value creation by data exchange involves not only data, but also\ntechnologies and a variety of stakeholders that are integrated and in\ncompetition with one another. This makes the data exchange ecosystem a\nchallenging subject to study. In this paper, we propose a model describing the\nstakeholder-centric value chain (SVC) of data by focusing on the relationships\namong stakeholders in data businesses and discussing creative ways to use them.\nThe SVC model enables the analysis and understanding of the structural\ncharacteristics of the data exchange ecosystem. We identified stakeholders who\ncarry potential risk, those who play central roles in the ecosystem, and the\ndistribution of profit among them using business models collected by the SVC.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 05:04:08 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Hayashi", "Teruaki", ""], ["Ishimura", "Gensei", ""], ["Ohsawa", "Yukio", ""]]}, {"id": "2005.11020", "submitter": "Parvathy Panicker", "authors": "Parvathy Panicker", "title": "Exploring cultural challenges to implementing Educational Technology in\n  the higher education sector in India", "comments": "11 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When learning technologies are introduced in educational environments, it is\nassumed that the educational environment is culture neutral i.e, all\neducational environments have the same challenges, problems and cultural norms.\nHowever, it can be observed that cultural factors can influence the successful\nimplementation and use of learning technologies. In this study the aims were to\nexplore contextual challenges to implementing different educational\ntechnologies and to explore the effects of culture. The results of this survey\nsuggest that Hofstede's cultural measures of uncertainty avoidance, power\ndistance and Individualist/collectivist measures, and Duckworth's Grit measure\nof passion and perseverance have a strong impact on the culture of technology\nuse in India.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 06:13:00 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Panicker", "Parvathy", ""]]}, {"id": "2005.11057", "submitter": "Marcos Charalambides", "authors": "Mark Briers, Marcos Charalambides, Chris Holmes", "title": "Risk scoring calculation for the current NHSx contact tracing app", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider how the NHS COVID-19 application will initially calculate a risk\nscore for an individual based on their recent contact with people who report\nthat they have coronavirus symptoms.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 08:39:46 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Briers", "Mark", ""], ["Charalambides", "Marcos", ""], ["Holmes", "Chris", ""]]}, {"id": "2005.11072", "submitter": "Olivia Erdelyi Dr", "authors": "Olivia J. Erd\\'elyi and Judy Goldsmith", "title": "Regulating Artificial Intelligence: Proposal for a Global Solution", "comments": "25 pages. A preliminary version appeared in the Proceedings of the\n  First AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society,\n  pages 95-101, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With increasing ubiquity of artificial intelligence (AI) in modern societies,\nindividual countries and the international community are working hard to create\nan innovation-friendly, yet safe, regulatory environment. Adequate regulation\nis key to maximize the benefits and minimize the risks stemming from AI\ntechnologies. Developing regulatory frameworks is, however, challenging due to\nAI's global reach and the existence of widespread misconceptions about the\nnotion of regulation. We argue that AI-related challenges cannot be tackled\neffectively without sincere international coordination supported by robust,\nconsistent domestic and international governance arrangements. Against this\nbackdrop, we propose the establishment of an international AI governance\nframework organized around a new AI regulatory agency that -- drawing on\ninterdisciplinary expertise -- could help creating uniform standards for the\nregulation of AI technologies and inform the development of AI policies around\nthe world. We also believe that a fundamental change of mindset on what\nconstitutes regulation is necessary to remove existing barriers that hamper\ncontemporary efforts to develop AI regulatory regimes, and put forward some\nrecommendations on how to achieve this, and what opportunities doing so would\npresent.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:24:07 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Erd\u00e9lyi", "Olivia J.", ""], ["Goldsmith", "Judy", ""]]}, {"id": "2005.11177", "submitter": "Muhammad Imran", "authors": "Umair Qazi, Muhammad Imran, Ferda Ofli", "title": "GeoCoV19: A Dataset of Hundreds of Millions of Multilingual COVID-19\n  Tweets with Location Information", "comments": "10 pages, 5 figures, accepted at ACM SIGSPATIAL Special May 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past several years have witnessed a huge surge in the use of social media\nplatforms during mass convergence events such as health emergencies, natural or\nhuman-induced disasters. These non-traditional data sources are becoming vital\nfor disease forecasts and surveillance when preparing for epidemic and pandemic\noutbreaks. In this paper, we present GeoCoV19, a large-scale Twitter dataset\ncontaining more than 524 million multilingual tweets posted over a period of 90\ndays since February 1, 2020. Moreover, we employ a gazetteer-based approach to\ninfer the geolocation of tweets. We postulate that this large-scale,\nmultilingual, geolocated social media data can empower the research communities\nto evaluate how societies are collectively coping with this unprecedented\nglobal crisis as well as to develop computational methods to address challenges\nsuch as identifying fake news, understanding communities' knowledge gaps,\nbuilding disease forecast and surveillance models, among others.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 13:30:42 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Qazi", "Umair", ""], ["Imran", "Muhammad", ""], ["Ofli", "Ferda", ""]]}, {"id": "2005.11297", "submitter": "Piotr Sapiezynski", "authors": "Piotr Sapiezynski, Johanna Pruessing, Vedran Sekara", "title": "The Fallibility of Contact-Tracing Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the onset of the COVID-19's global spread we have been following the\ndebate around contact tracing apps -- the tech-enabled response to the\npandemic. As corporations, academics, governments, and civil society discuss\nthe right way to implement these apps, we noticed recurring implicit\nassumptions. The proposed solutions are designed for a world where Internet\naccess and smartphone ownership are a given, people are willing and able to\ninstall these apps, and those who receive notifications about potential\nexposure to the virus have access to testing and can isolate safely. In this\nwork we challenge these assumptions. We not only show that there are not enough\nsmartphones worldwide to reach required adoption thresholds but also highlight\na broad lack of internet access, which affects certain groups more: the\nelderly, those with lower incomes, and those with limited ability to socially\ndistance. Unfortunately, these are also the groups that are at the highest\nrisks from COVID-19. We also report that the contact tracing apps that are\nalready deployed on an opt-in basis show disappointing adoption levels. We warn\nabout the potential consequences of over-extending the existing state and\ncorporate surveillance powers. Finally, we describe a multitude of scenarios\nwhere contact tracing apps will not help regardless of access or policy. In\nthis work we call for a comprehensive and equitable policy response that\nprioritizes the needs of the most vulnerable, protects human rights, and\nconsiders long term impact instead of focusing on technology-first fixes.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 17:46:16 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 14:53:31 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 16:46:10 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Sapiezynski", "Piotr", ""], ["Pruessing", "Johanna", ""], ["Sekara", "Vedran", ""]]}, {"id": "2005.11414", "submitter": "Larissa Romualdo Suzuki", "authors": "Larissa Romualdo-Suzuki and Anthony Finkelstein", "title": "Data as Infrastructure for Smart Cities: Linking Data Platforms to\n  Business Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The systems that operate the infrastructure of cities have evolved in a\nfragmented fashion across several generations of technology, causing city\nutilities and services to operate sub-optimally and limiting the creation of\nnew value-added services and restrict opportunities for cost-saving. The\nintegration of cross-domain city data offers a new wave of opportunities to\nmitigate some of these impacts and enables city systems to draw effectively on\ninteroperable data that will be used to deliver smarter cities. Despite the\nconsiderable potential of city data, current smart cities initiatives have\nmainly addressed the problem of data management from a technology perspective,\nand have disregarded stakeholders and data needs. As a consequence, such\ninitiatives are susceptible to failure from inadequate stakeholder input,\nrequirements neglecting, and information fragmentation and overload. They are\nalso likely to be limited in terms of both scalability and future proofing\nagainst technological, commercial and legislative change. This paper proposes a\nsystematic business-modeldriven framework to guide the design of large and\nhighly interconnected data infrastructures which are provided and supported by\nmultiple stakeholders. The framework is used to model, elicit and reason about\nthe requirements of the service, technology, organization, value, and\ngovernance aspects of smart cities. The requirements serve as an input to a\nclosed-loop supply chain model, which is designed and managed to explicitly\nconsider the activities and processes that enables the stakeholders of smart\ncities to efficiently leverage their collective knowledge. We demonstrate how\nour approach can be used to design data infrastructures by examining a series\nof exemplary scenarios and by demonstrating how our approach handles the\nholistic design of a data infrastructure and informs the decision making\nprocess.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 22:53:05 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Romualdo-Suzuki", "Larissa", ""], ["Finkelstein", "Anthony", ""]]}, {"id": "2005.11416", "submitter": "Alessandro Provetti", "authors": "Hugh Lawson-Tancred and Henry C. W. Price and Alessandro Provetti", "title": "COVID-19 Contact Tracing: Eight Privacy Questions Explored", "comments": "Six pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We respond to a recent short paper by de Motjoye et el. on privacy issues\nwith Covid-19 tracking. Their paper, which we discuss here, is structured\naround three \"toy protocols\" for the design of an app which can maximise the\nutility of contact tracing information while minimising the more general risk\nto privacy. On this basis, the paper proceeds to introduce eight questions\nagainst which they should be assessed. The questions raised and the protocols\nproposed effectively amount to the creation of a game with different categories\nof players able to make different moves. It is therefore possible to analyse\nthe model in terms of optimal game design.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 22:56:03 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Lawson-Tancred", "Hugh", ""], ["Price", "Henry C. W.", ""], ["Provetti", "Alessandro", ""]]}, {"id": "2005.11507", "submitter": "Sonali Agarwal", "authors": "Sonali Agarwal, Narinder Singh Punn, Sanjay Kumar Sonbhadra, M.\n  Tanveer, P. Nagabhushan, K K Soundra Pandian and Praveer Saxena", "title": "Unleashing the power of disruptive and emerging technologies amid\n  COVID-19: A detailed review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The unprecedented outbreak of the novel coronavirus (COVID-19), during early\nDecember 2019 in Wuhan, China, has quickly evolved into a global pandemic,\nbecame a matter of grave concern, and placed government agencies worldwide in a\nprecarious position. The scarcity of resources and lack of experiences to\nendure the COVID-19 pandemic, combined with the fear of future consequences has\nestablished the need for adoption of emerging and future technologies to\naddress the upcoming challenges. Since the last five months, the amount of\npandemic impact has reached its pinnacle that is altering everyone's life; and\nhumans are now bound to adopt safe ways to survive under the risk of being\naffected. Technological advances are now accelerating faster than ever before\nto stay ahead of the consequences and acquire new capabilities to build a safer\nworld. Thus, there is a rising need to unfold the power of emerging, future and\ndisruptive technologies to explore all possible ways to fight against COVID-19.\nIn this review article, we attempt to study all emerging, future, and\ndisruptive technologies that can be utilized to mitigate the impact of\nCOVID-19. Building on background insights, detailed technological specific use\ncases to fight against COVID-19 have been discussed in terms of their\nstrengths, weaknesses, opportunities, and threats (SWOT). As concluding\nremarks, we highlight prioritized research areas and upcoming opportunities to\nblur the lines between the physical, digital, and biological domain-specific\nchallenges and also illuminate collaborative research directions for moving\ntowards a post-COVID-19 world.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 10:09:37 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 13:08:23 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 05:16:27 GMT"}, {"version": "v4", "created": "Mon, 17 Aug 2020 10:31:44 GMT"}, {"version": "v5", "created": "Tue, 29 Dec 2020 09:43:36 GMT"}, {"version": "v6", "created": "Mon, 19 Apr 2021 06:07:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Agarwal", "Sonali", ""], ["Punn", "Narinder Singh", ""], ["Sonbhadra", "Sanjay Kumar", ""], ["Tanveer", "M.", ""], ["Nagabhushan", "P.", ""], ["Pandian", "K K Soundra", ""], ["Saxena", "Praveer", ""]]}, {"id": "2005.11556", "submitter": "Fran Casino", "authors": "Thomas K. Dasaklis and Fran Casino and Constantinos Patsakis", "title": "A traceability and auditing framework for electronic equipment reverse\n  logistics based on blockchain: the case of mobile phones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human beings produce electronic waste (e-waste) at an unprecedented pace.\nMobile phones and other inter-connected smart devices make a significant\ncontribution to the generation of e-waste. Reverse logistics (RL) activities\nplay an essential role in managing mobile phones during their end-of-life.\nHowever, remanufacturing and/or refurbishing of mobile phones might prove\ndifficult not only from an operational point of view but also from a data\nmanagement and privacy perspective (due to privacy-related regulatory\nframeworks like the EU General Data Protection Regulation directive). In this\npaper, we propose a distributed trustless and secure framework for electronic\nequipment RL activities based on blockchain technology. We consider the\nremanufacturing/refurbishing recovery option for mobile phones, and we develop\nan autonomous and effective back-end data sharing architecture based on smart\ncontracts/blockchain technology for keeping track of all the\nremanufacturing/refurbishing processes. For demonstrating the applicability of\nour approach, we develop a functional set of smart contracts and a local\nprivate blockchain. The benefits of our framework are further discussed, along\nwith fruitful areas for future research.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 16:11:06 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 08:15:48 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Dasaklis", "Thomas K.", ""], ["Casino", "Fran", ""], ["Patsakis", "Constantinos", ""]]}, {"id": "2005.11580", "submitter": "Honglin Bao", "authors": "Honglin Bao and Wolfgang Banzhaf", "title": "Evolution of Cooperative Hunting in Artificial Multi-layered Societies", "comments": "Conflict of interest with our previous collaborators. Thus, we\n  retract the preprint. We retract all earlier versions of the paper as well,\n  but due to the arXiv policy, previous versions cannot be removed. We ask that\n  you ignore the abstract, earlier versions and do not refer to or distribute\n  them further, and we apologize for any inconvenience caused. Thanks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NE nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of cooperative behavior is a crucial issue in multiagent-based\nsocial simulation. In this paper, an agent-based model is proposed to study the\nevolution of cooperative hunting behaviors in an artificial society. In this\nmodel, the standard hunting game of stag is modified into a new situation with\nsocial hierarchy and penalty. The agent society is divided into multiple layers\nwith supervisors and subordinates. In each layer, the society is divided into\nmultiple clusters. A supervisor controls all subordinates in a cluster locally.\nSubordinates interact with rivals through reinforcement learning, and report\nlearning information to their corresponding supervisor. Supervisors process the\nreported information through repeated affiliation-based aggregation and by\ninformation exchange with other supervisors, then pass down the reprocessed\ninformation to subordinates as guidance. Subordinates, in turn, update learning\ninformation according to guidance, following the \"win stay, lose shift\"\nstrategy. Experiments are carried out to test the evolution of cooperation in\nthis closed-loop semi-supervised emergent system with different parameters. We\nalso study the variations and phase transitions in this game setting.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 18:23:04 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 14:08:15 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 17:14:40 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 18:51:05 GMT"}, {"version": "v5", "created": "Fri, 15 Jan 2021 19:43:23 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Bao", "Honglin", ""], ["Banzhaf", "Wolfgang", ""]]}, {"id": "2005.11634", "submitter": "Ang Li", "authors": "Ang Li, Wei Du, Qinghua Li", "title": "PoliteCamera: Respecting Strangers' Privacy in Mobile Photographing", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-01701-9_13", "report-no": null, "categories": "cs.CR cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera is a standard on-board sensor of modern mobile phones. It makes photo\ntaking popular due to its convenience and high resolution. However, when users\ntake a photo of a scenery, a building or a target person, a stranger may also\nbe unintentionally captured in the photo. Such photos expose the location and\nactivity of strangers, and hence may breach their privacy. In this paper, we\npropose a cooperative mobile photographing scheme called PoliteCamera to\nprotect strangers' privacy. Through the cooperation between a photographer and\na stranger, the stranger's face in a photo can be automatically blurred upon\nhis request when the photo is taken. Since multiple strangers nearby the\nphotographer might send out blurring requests but not all of them are in the\nphoto, an adapted balanced convolutional neural network (ABCNN) is proposed to\ndetermine whether the requesting stranger is in the photo based on facial\nattributes. Evaluations demonstrate that the ABCNN can accurately predict\nfacial attributes and PoliteCamera can provide accurate privacy protection for\nstrangers.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 01:18:13 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Ang", ""], ["Du", "Wei", ""], ["Li", "Qinghua", ""]]}, {"id": "2005.11730", "submitter": "Julian Skirzynski", "authors": "Julian Skirzy\\'nski, Frederic Becker and Falk Lieder", "title": "Automatic Discovery of Interpretable Planning Strategies", "comments": "Submitted to the Special Issue on Reinforcement Learning for Real\n  Life in Machine Learning Journal (2021). Code available at\n  https://github.com/RationalityEnhancement/InterpretableStrategyDiscovery", "journal-ref": null, "doi": "10.1007/s10994-021-05963-2", "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When making decisions, people often overlook critical information or are\noverly swayed by irrelevant information. A common approach to mitigate these\nbiases is to provide decision-makers, especially professionals such as medical\ndoctors, with decision aids, such as decision trees and flowcharts. Designing\neffective decision aids is a difficult problem. We propose that recently\ndeveloped reinforcement learning methods for discovering clever heuristics for\ngood decision-making can be partially leveraged to assist human experts in this\ndesign process. One of the biggest remaining obstacles to leveraging the\naforementioned methods is that the policies they learn are opaque to people. To\nsolve this problem, we introduce AI-Interpret: a general method for\ntransforming idiosyncratic policies into simple and interpretable descriptions.\nOur algorithm combines recent advances in imitation learning and program\ninduction with a new clustering method for identifying a large subset of\ndemonstrations that can be accurately described by a simple, high-performing\ndecision rule. We evaluate our new algorithm and employ it to translate\ninformation-acquisition policies discovered through metalevel reinforcement\nlearning. The results of large behavioral experiments showed that prividing the\ndecision rules generated by AI-Interpret as flowcharts significantly improved\npeople's planning strategies and decisions across three diferent classes of\nsequential decision problems. Moreover, another experiment revealed that this\napproach is significantly more effective than training people by giving them\nperformance feedback. Finally, a series of ablation studies confirmed that\nAI-Interpret is critical to the discovery of interpretable decision rules. We\nconclude that the methods and findings presented herein are an important step\ntowards leveraging automatic strategy discovery to improve human\ndecision-making.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 12:24:52 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 12:55:54 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 05:28:59 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Skirzy\u0144ski", "Julian", ""], ["Becker", "Frederic", ""], ["Lieder", "Falk", ""]]}, {"id": "2005.11957", "submitter": "Tianshi Li", "authors": "Tianshi Li, Jackie (Junrui) Yang, Cori Faklaris, Jennifer King, Yuvraj\n  Agarwal, Laura Dabbish, Jason I. Hong", "title": "Decentralized is not risk-free: Understanding public perceptions of\n  privacy-utility trade-offs in COVID-19 contact-tracing apps", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact-tracing apps have potential benefits in helping health authorities to\nact swiftly to halt the spread of COVID-19. However, their effectiveness is\nheavily dependent on their installation rate, which may be influenced by\npeople's perceptions of the utility of these apps and any potential privacy\nrisks due to the collection and releasing of sensitive user data (e.g., user\nidentity and location). In this paper, we present a survey study that examined\npeople's willingness to install six different contact-tracing apps after\ninforming them of the risks and benefits of each design option (with a\nU.S.-only sample on Amazon Mechanical Turk, $N=208$). The six app designs\ncovered two major design dimensions (centralized vs decentralized, basic\ncontact tracing vs. also providing hotspot information), grounded in our\nanalysis of existing contact-tracing app proposals.\n  Contrary to assumptions of some prior work, we found that the majority of\npeople in our sample preferred to install apps that use a centralized server\nfor contact tracing, as they are more willing to allow a centralized authority\nto access the identity of app users rather than allowing tech-savvy users to\ninfer the identity of diagnosed users. We also found that the majority of our\nsample preferred to install apps that share diagnosed users' recent locations\nin public places to show hotspots of infection. Our results suggest that apps\nusing a centralized architecture with strong security protection to do basic\ncontact tracing and providing users with other useful information such as\nhotspots of infection in public places may achieve a high adoption rate in the\nU.S.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 07:50:51 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Tianshi", "", "Junrui"], ["Jackie", "", "", "Junrui"], ["Yang", "", ""], ["Faklaris", "Cori", ""], ["King", "Jennifer", ""], ["Agarwal", "Yuvraj", ""], ["Dabbish", "Laura", ""], ["Hong", "Jason I.", ""]]}, {"id": "2005.11973", "submitter": "Parvathy Panicker", "authors": "Parvathy Panicker", "title": "Embedding Culture and Grit in the Technology Acceptance Model (TAM) for\n  Higher Education", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementors of learning technologies within education environments often\nfollow strategies that assume the educational environment within which they are\nbeing introduced is culturally neutral. A comprehensive literature review\nincluding 150 papers on educational technology challenges was undertaken. The\npurpose of this review is explore different contextual challenges to the\nadoption of educational technology in the higher education sector. The cultural\nfactors that define the key stakeholders (e.g., teachers, lectures, students\nand support staff) are often ignored when the implementation processes are\nundertaken. Furthermore, it is often assumed that the personnel responsible for\nthe implementation are also culturally neutral and do not possess any\nattributes unique to their culture. It has been shown that cultural factors may\nsignificantly influence the implementation of learning technologies and to\ndesign strategies that fail to consider factors may limit their efficiency and\neffectiveness. The challenges are interrelated and based on the findings, this\nreview proposes a conceptual framework by integrating culture and grit into the\nTechnology Acceptance Model(TAM) for implementing educational technology in\nhigher education. The framework will be useful to guide both practice and\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 08:29:25 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Panicker", "Parvathy", ""]]}, {"id": "2005.12045", "submitter": "Amee Trivedi", "authors": "Amee Trivedi, Camellia Zakaria, Rajesh Balan, Prashant Shenoy", "title": "WiFiTrace: Network-based Contact Tracing for Infectious Diseases Using\n  Passive WiFi Sensing", "comments": "26 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is a well-established and effective approach for the\ncontainment of the spread of infectious diseases. While Bluetooth-based contact\ntracing method using phones has become popular recently, these approaches\nsuffer from the need for a critical mass adoption to be effective. In this\npaper, we present WiFiTrace, a network-centric approach for contact tracing\nthat relies on passive WiFi sensing with no client-side involvement. Our\napproach exploits WiFi network logs gathered by enterprise networks for\nperformance and security monitoring, and utilizes them for reconstructing\ndevice trajectories for contact tracing. Our approach is specifically designed\nto enhance the efficacy of traditional methods, rather than to supplant them\nwith new technology. We designed an efficient graph algorithm to scale our\napproach to large networks with tens of thousands of users. The graph-based\napproach outperforms an indexed PostgresSQL in memory by at least 4.5X without\nany index update overheads or blocking. We have implemented a full prototype of\nour system and deployed it on two large university campuses. We validated our\napproach and demonstrate its efficacy using case studies and detailed\nexperiments using real-world WiFi datasets.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 11:42:22 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 12:49:42 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 13:18:33 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Trivedi", "Amee", ""], ["Zakaria", "Camellia", ""], ["Balan", "Rajesh", ""], ["Shenoy", "Prashant", ""]]}, {"id": "2005.12050", "submitter": "Camellia Zakaria", "authors": "Camellia Zakaria, Amee Trivedi, Emmanuel Cecchet, Michael Chee,\n  Prashant Shenoy, Rajesh Balan", "title": "Analyzing the Impact of Covid-19 Control Policies on Campus Occupancy\n  and Mobility via Passive WiFi Sensing", "comments": "25 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile sensing has played a key role in providing digital solutions to aid\nwith COVID-19 containment policies. These solutions include, among other\nefforts, enforcing social distancing and monitoring crowd movements in indoor\nspaces. However, such solutions may not be effective without mass adoption. As\nmore and more countries reopen from lockdowns, there remains a pressing need to\nminimize crowd movements and interactions, particularly in enclosed spaces.\nThis paper conjectures that analyzing user occupancy and mobility via deployed\nWiFi infrastructure can help institutions monitor and maintain safety\ncompliance according to the public health guidelines. Using smartphones as a\nproxy for user location, our analysis demonstrates how coarse-grained WiFi data\ncan sufficiently reflect indoor occupancy spectrum when different COVID-19\npolicies were enacted. Our work analyzes staff and students' mobility data from\nthree different university campuses. Two of these campuses are in Singapore,\nand the third is in the Northeastern United States. Our results show that\nonline learning, split-team, and other space management policies effectively\nlower occupancy. However, they do not change the mobility for individuals\ntransitioning between spaces. We demonstrate how this data source can be put to\npractical application for institutional crowd control and discuss the\nimplications of our findings for policy-making.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 11:47:08 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 12:53:24 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2021 16:06:16 GMT"}, {"version": "v4", "created": "Sat, 6 Feb 2021 23:43:51 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zakaria", "Camellia", ""], ["Trivedi", "Amee", ""], ["Cecchet", "Emmanuel", ""], ["Chee", "Michael", ""], ["Shenoy", "Prashant", ""], ["Balan", "Rajesh", ""]]}, {"id": "2005.12087", "submitter": "Horia-Nicolai Teodorescu", "authors": "Horia-Nicolai Teodorescu", "title": "Experimental, ad hoc, online, inter-university student e-contest during\n  the pandemic: Lessons learned", "comments": "10 pages, 3 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are reporting on lessons learned from an e-contest for students held\nduring the current pandemic. We compare the e-contest with the 10 previous\neditions of the same but face-to-face contest. While apparently the competition\ndid not suffer because of being a virtual one, some disadvantages were noted.\nThe main conclusions are: the basic interconnectivity means arise no serious\ntechnical issue, but the interconnectivity is more limited than the\nface-to-face one; online jury-competitors interactivity is poorer than\nface-to-face interactivity; human factors, higher uncertainties in the\norganization process, and less time to spend in the process for the local\norganizers are major limiting factors; concerns on the participation and\nevaluation fairness are higher; involuntary gender discrimination seems lower,\nbut persists; there are serious concerns related to privacy, including\ndifferential privacy; some peculiarities of the presented topics and of the\nevaluation process emerged, but it is unclear if they are related to the online\nnature of the competition, to the extra stress on the participants during the\npandemic, to other factors, or are random. While some conclusions may be\nintimately related to the analyzed case, some are general enough for being\nworth to other online competitions.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 13:06:40 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Teodorescu", "Horia-Nicolai", ""]]}, {"id": "2005.12137", "submitter": "Yipeng Hu", "authors": "Yipeng Hu, Joseph Jacob, Geoffrey JM Parker, David J Hawkes, John R\n  Hurst, Danail Stoyanov", "title": "The challenges of deploying artificial intelligence models in a rapidly\n  evolving pandemic", "comments": "Accepted in Nature Machine Intelligence", "journal-ref": null, "doi": "10.1038/s42256-020-0185-2", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic, caused by the severe acute respiratory syndrome\ncoronavirus 2, emerged into a world being rapidly transformed by artificial\nintelligence (AI) based on big data, computational power and neural networks.\nThe gaze of these networks has in recent years turned increasingly towards\napplications in healthcare. It was perhaps inevitable that COVID-19, a global\ndisease propagating health and economic devastation, should capture the\nattention and resources of the world's computer scientists in academia and\nindustry. The potential for AI to support the response to the pandemic has been\nproposed across a wide range of clinical and societal challenges, including\ndisease forecasting, surveillance and antiviral drug discovery. This is likely\nto continue as the impact of the pandemic unfolds on the world's people,\nindustries and economy but a surprising observation on the current pandemic has\nbeen the limited impact AI has had to date in the management of COVID-19. This\ncorrespondence focuses on exploring potential reasons behind the lack of\nsuccessful adoption of AI models developed for COVID-19 diagnosis and\nprognosis, in front-line healthcare services. We highlight the moving clinical\nneeds that models have had to address at different stages of the epidemic, and\nexplain the importance of translating models to reflect local healthcare\nenvironments. We argue that both basic and applied research are essential to\naccelerate the potential of AI models, and this is particularly so during a\nrapidly evolving pandemic. This perspective on the response to COVID-19, may\nprovide a glimpse into how the global scientific community should react to\ncombat future disease outbreaks more effectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 21:11:48 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Hu", "Yipeng", ""], ["Jacob", "Joseph", ""], ["Parker", "Geoffrey JM", ""], ["Hawkes", "David J", ""], ["Hurst", "John R", ""], ["Stoyanov", "Danail", ""]]}, {"id": "2005.12138", "submitter": "Paul Ryan Mr", "authors": "Paul Ryan, Martin Crane and Rob Brennan", "title": "Design Challenges for GDPR RegTech", "comments": null, "journal-ref": "Proceedings of the 22nd International Conference on Enterprise\n  Information Systems - (Volume 2) May 5-7, 2020", "doi": "10.5220/0009464507870795", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Accountability Principle of the GDPR requires that an organisation can\ndemonstrate compliance with the regulations. A survey of GDPR compliance\nsoftware solutions shows significant gaps in their ability to demonstrate\ncompliance. In contrast, RegTech has recently brought great success to\nfinancial compliance, resulting in reduced risk, cost saving and enhanced\nfinancial regulatory compliance. It is shown that many GDPR solutions lack\ninteroperability features such as standard APIs, meta-data or reports and they\nare not supported by published methodologies or evidence to support their\nvalidity or even utility. A proof of concept prototype was explored using a\nregulator based self-assessment checklist to establish if RegTech best practice\ncould improve the demonstration of GDPR compliance. The application of a\nRegTech approach provides opportunities for demonstrable and validated GDPR\ncompliance, notwithstanding the risk reductions and cost savings that RegTech\ncan deliver. This paper demonstrates a RegTech approach to GDPR compliance can\nfacilitate an organisation meeting its accountability obligations.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 18:55:11 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ryan", "Paul", ""], ["Crane", "Martin", ""], ["Brennan", "Rob", ""]]}, {"id": "2005.12140", "submitter": "Subhankar Mishra", "authors": "Aman Singh, Ashish Prajapatia, Vikash Kumar, Subhankar Mishra", "title": "Usage Analysis of Mobile Devices", "comments": "7 pages", "journal-ref": "Procedia computer science 122 (2017): 657-662", "doi": "10.1016/j.procs.2017.11.420", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices have evolved from just communication devices into an\nindispensable part of people's lives in form of smartphones, tablets and smart\nwatches. Devices are now more personal than ever and carry more information\nabout a person than any other. Extracting user behaviour is rather difficult\nand time-consuming as most of the work previously has been manual or requires\nfeature extraction. In this paper, a novel approach of user behavior detection\nis proposed with Deep Learning Network (DNN). Initial approach was to use\nrecurrent neural network (RNN) along with LSTM for completely unsupervised\nanalysis of mobile devices. Next approach is to extract features by using Long\nShort Term Memory (LSTM) to understand the user behaviour, which are then fed\ninto the Convolution Neural Network (CNN). This work mainly concentrates on\ndetection of user behaviour and anomaly detection for usage analysis of mobile\ndevices. Both the approaches are compared against some baseline methods.\nExperiments are conducted on the publicly available dataset to show that these\nmethods can successfully capture the user behaviors.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 12:15:24 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Singh", "Aman", ""], ["Prajapatia", "Ashish", ""], ["Kumar", "Vikash", ""], ["Mishra", "Subhankar", ""]]}, {"id": "2005.12150", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Kevin Page, Max Van Kleek, Omar\n  Santos, La Treall Maddox, Pete Burnap, Eirini Anthi, Carsten Maple", "title": "Design of a dynamic and self adapting system, supported with artificial\n  intelligence, machine learning and real time intelligence for predictive\n  cyber risk analytics in extreme environments, cyber risk in the colonisation\n  of Mars", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": "10.1007/s42797-021-00025-1", "report-no": null, "categories": "cs.CY cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple governmental agencies and private organisations have made\ncommitments for the colonisation of Mars. Such colonisation requires complex\nsystems and infrastructure that could be very costly to repair or replace in\ncases of cyber attacks. This paper surveys deep learning algorithms, IoT cyber\nsecurity and risk models, and established mathematical formulas to identify the\nbest approach for developing a dynamic and self adapting system for predictive\ncyber risk analytics supported with Artificial Intelligence and Machine\nLearning and real time intelligence in edge computing. The paper presents a new\nmathematical approach for integrating concepts for cognition engine design,\nedge computing and Artificial Intelligence and Machine Learning to automate\nanomaly detection. This engine instigates a step change by applying Artificial\nIntelligence and Machine Learning embedded at the edge of IoT networks, to\ndeliver safe and functional real time intelligence for predictive cyber risk\nanalytics. This will enhance capacities for risk analytics and assists in the\ncreation of a comprehensive and systematic understanding of the opportunities\nand threats that arise when edge computing nodes are deployed, and when\nArtificial Intelligence and Machine Learning technologies are migrated to the\nperiphery of the internet and into local IoT networks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:42:45 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 20:36:26 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Page", "Kevin", ""], ["Van Kleek", "Max", ""], ["Santos", "Omar", ""], ["Maddox", "La Treall", ""], ["Burnap", "Pete", ""], ["Anthi", "Eirini", ""], ["Maple", "Carsten", ""]]}, {"id": "2005.12181", "submitter": "Prashant Shenoy", "authors": "Menghong Feng, Noman Bashir, Prashant Shenoy, David Irwin, Beka\n  Kosanovic", "title": "SunDown: Model-driven Per-Panel Solar Anomaly Detection for Residential\n  Arrays", "comments": "13 pages, 13 figures. Extended version of a paper that will appear in\n  the Proceedings of the ACM SIGCAS Conference on Computing and Sustainable\n  Societies (COMPASS '20), June 2020, Ecuador", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant growth in both utility-scale and residential-scale\nsolar installations in recent years, driven by rapid technology improvements\nand falling prices. Unlike utility-scale solar farms that are professionally\nmanaged and maintained, smaller residential-scale installations often lack\nsensing and instrumentation for performance monitoring and fault detection. As\na result, faults may go undetected for long periods of time, resulting in\ngeneration and revenue losses for the homeowner. In this paper, we present\nSunDown, a sensorless approach designed to detect per-panel faults in\nresidential solar arrays. SunDown does not require any new sensors for its\nfault detection and instead uses a model-driven approach that leverages\ncorrelations between the power produced by adjacent panels to detect deviations\nfrom expected behavior. SunDown can handle concurrent faults in multiple panels\nand perform anomaly classification to determine probable causes. Using two\nyears of solar generation data from a real home and a manually generated\ndataset of multiple solar faults, we show that our approach has a MAPE of\n2.98\\% when predicting per-panel output. Our results also show that SunDown is\nable to detect and classify faults, including from snow cover, leaves and\ndebris, and electrical failures with 99.13% accuracy, and can detect multiple\nconcurrent faults with 97.2% accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 15:54:30 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Feng", "Menghong", ""], ["Bashir", "Noman", ""], ["Shenoy", "Prashant", ""], ["Irwin", "David", ""], ["Kosanovic", "Beka", ""]]}, {"id": "2005.12196", "submitter": "Lionel Robert", "authors": "Rasha Alahmad, Lionel Robert", "title": "Artificial Intelligence (AI) and IT identity: Antecedents Identifying\n  with AI Applications", "comments": "10 pages, 1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of Artificial Intelligence and automation, machines have taken\nover many key managerial tasks. Replacing managers with AI systems may have a\nnegative impact on workers outcomes. It is unclear if workers receive the same\nbenefits from their relationships with AI systems, raising the question: What\ndegree does the relationship between AI systems and workers impact worker\noutcomes? We draw on IT identity to understand the influence of identification\nwith AI systems on job performance. From this theoretical perspective, we\npropose a research model and conduct a survey of 97 MTurk workers to test the\nmodel. The findings reveal that work role identity and organizational identity\nare key determinants of identification with AI systems. Furthermore, the\nfindings show that identification with AI systems does increase job\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 10:59:43 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Alahmad", "Rasha", ""], ["Robert", "Lionel", ""]]}, {"id": "2005.12234", "submitter": "Prashant Shenoy", "authors": "Rishikesh Jha, Stephen Lee, Srinivasan Iyengar, Mohammad H.\n  Hajiesmaili, David Irwin, Prashant Shenoy", "title": "Emission-aware Energy Storage Scheduling for a Greener Grid", "comments": "11 pages, 7 figure, This paper will appear in the Proceedings of the\n  ACM International Conference on Future Energy Systems (e-Energy 20) June\n  2020, Australia", "journal-ref": null, "doi": "10.1145/3396851.3397755", "report-no": null, "categories": "eess.SY cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing our reliance on carbon-intensive energy sources is vital for\nreducing the carbon footprint of the electric grid. Although the grid is seeing\nincreasing deployments of clean, renewable sources of energy, a significant\nportion of the grid demand is still met using traditional carbon-intensive\nenergy sources. In this paper, we study the problem of using energy storage\ndeployed in the grid to reduce the grid's carbon emissions. While energy\nstorage has previously been used for grid optimizations such as peak shaving\nand smoothing intermittent sources, our insight is to use distributed storage\nto enable utilities to reduce their reliance on their less efficient and most\ncarbon-intensive power plants and thereby reduce their overall emission\nfootprint. We formulate the problem of emission-aware scheduling of distributed\nenergy storage as an optimization problem, and use a robust optimization\napproach that is well-suited for handling the uncertainty in load predictions,\nespecially in the presence of intermittent renewables such as solar and wind.\nWe evaluate our approach using a state of the art neural network load\nforecasting technique and real load traces from a distribution grid with 1,341\nhomes. Our results show a reduction of >0.5 million kg in annual carbon\nemissions -- equivalent to a drop of 23.3% in our electric grid emissions.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:11:10 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Jha", "Rishikesh", ""], ["Lee", "Stephen", ""], ["Iyengar", "Srinivasan", ""], ["Hajiesmaili", "Mohammad H.", ""], ["Irwin", "David", ""], ["Shenoy", "Prashant", ""]]}, {"id": "2005.12273", "submitter": "Michael Veale", "authors": "Carmela Troncoso, Mathias Payer, Jean-Pierre Hubaux, Marcel Salath\\'e,\n  James Larus, Edouard Bugnion, Wouter Lueks, Theresa Stadler, Apostolos\n  Pyrgelis, Daniele Antonioli, Ludovic Barman, Sylvain Chatel, Kenneth\n  Paterson, Srdjan \\v{C}apkun, David Basin, Jan Beutel, Dennis Jackson, Marc\n  Roeschlin, Patrick Leu, Bart Preneel, Nigel Smart, Aysajan Abidin, Seda\n  G\\\"urses, Michael Veale, Cas Cremers, Michael Backes, Nils Ole Tippenhauer,\n  Reuben Binns, Ciro Cattuto, Alain Barrat, Dario Fiore, Manuel Barbosa, Rui\n  Oliveira, Jos\\'e Pereira", "title": "Decentralized Privacy-Preserving Proximity Tracing", "comments": "46 pages, 6 figures, first published 3 April 2020 on\n  https://github.com/DP-3T/documents where companion documents and code can be\n  found", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document describes and analyzes a system for secure and\nprivacy-preserving proximity tracing at large scale. This system, referred to\nas DP3T, provides a technological foundation to help slow the spread of\nSARS-CoV-2 by simplifying and accelerating the process of notifying people who\nmight have been exposed to the virus so that they can take appropriate measures\nto break its transmission chain. The system aims to minimise privacy and\nsecurity risks for individuals and communities and guarantee the highest level\nof data protection. The goal of our proximity tracing system is to determine\nwho has been in close physical proximity to a COVID-19 positive person and thus\nexposed to the virus, without revealing the contact's identity or where the\ncontact occurred. To achieve this goal, users run a smartphone app that\ncontinually broadcasts an ephemeral, pseudo-random ID representing the user's\nphone and also records the pseudo-random IDs observed from smartphones in close\nproximity. When a patient is diagnosed with COVID-19, she can upload\npseudo-random IDs previously broadcast from her phone to a central server.\nPrior to the upload, all data remains exclusively on the user's phone. Other\nusers' apps can use data from the server to locally estimate whether the\ndevice's owner was exposed to the virus through close-range physical proximity\nto a COVID-19 positive person who has uploaded their data. In case the app\ndetects a high risk, it will inform the user.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 12:32:02 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Troncoso", "Carmela", ""], ["Payer", "Mathias", ""], ["Hubaux", "Jean-Pierre", ""], ["Salath\u00e9", "Marcel", ""], ["Larus", "James", ""], ["Bugnion", "Edouard", ""], ["Lueks", "Wouter", ""], ["Stadler", "Theresa", ""], ["Pyrgelis", "Apostolos", ""], ["Antonioli", "Daniele", ""], ["Barman", "Ludovic", ""], ["Chatel", "Sylvain", ""], ["Paterson", "Kenneth", ""], ["\u010capkun", "Srdjan", ""], ["Basin", "David", ""], ["Beutel", "Jan", ""], ["Jackson", "Dennis", ""], ["Roeschlin", "Marc", ""], ["Leu", "Patrick", ""], ["Preneel", "Bart", ""], ["Smart", "Nigel", ""], ["Abidin", "Aysajan", ""], ["G\u00fcrses", "Seda", ""], ["Veale", "Michael", ""], ["Cremers", "Cas", ""], ["Backes", "Michael", ""], ["Tippenhauer", "Nils Ole", ""], ["Binns", "Reuben", ""], ["Cattuto", "Ciro", ""], ["Barrat", "Alain", ""], ["Fiore", "Dario", ""], ["Barbosa", "Manuel", ""], ["Oliveira", "Rui", ""], ["Pereira", "Jos\u00e9", ""]]}, {"id": "2005.12378", "submitter": "Varoon Mathur", "authors": "Varoon Mathur, Saptarshi Purkayastha, Judy Wawira Gichoya", "title": "Artificial Intelligence for Global Health: Learning From a Decade of\n  Digital Transformation in Health Care", "comments": "Accepted Paper at ICLR 2020 Workshop on Practical ML for Developing\n  Countries", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The health needs of those living in resource-limited settings are a vastly\noverlooked and understudied area in the intersection of machine learning (ML)\nand health care. While the use of ML in health care is more recently\npopularized over the last few years from the advancement of deep learning,\nlow-and-middle income countries (LMICs) have already been undergoing a digital\ntransformation of their own in health care over the last decade, leapfrogging\nmilestones due to the adoption of mobile health (mHealth). With the\nintroduction of new technologies, it is common to start afresh with a top-down\napproach, and implement these technologies in isolation, leading to lack of use\nand a waste of resources. In this paper, we outline the necessary\nconsiderations both from the perspective of current gaps in research, as well\nas from the lived experiences of health care professionals in resource-limited\nsettings. We also outline briefly several key components of successful\nimplementation and deployment of technologies within health systems in LMICs,\nincluding technical and cultural considerations in the development process\nrelevant to the building of machine learning solutions. We then draw on these\nexperiences to address where key opportunities for impact exist in\nresource-limited settings, and where AI/ML can provide the most benefit.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 23:50:17 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 06:54:20 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Mathur", "Varoon", ""], ["Purkayastha", "Saptarshi", ""], ["Gichoya", "Judy Wawira", ""]]}, {"id": "2005.12385", "submitter": "Ning Wang", "authors": "Ning Wang, Fan Luo, Vishal Peddagangireddy, K.P. Subbalakshmi and R.\n  Chandramouli", "title": "Personalized Early Stage Alzheimer's Disease Detection: A Case Study of\n  President Reagan's Speeches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer`s disease (AD)-related global healthcare cost is estimated to be $1\ntrillion by 2050. Currently, there is no cure for this disease; however,\nclinical studies show that early diagnosis and intervention helps to extend the\nquality of life and inform technologies for personalized mental healthcare.\nClinical research indicates that the onset and progression of Alzheimer`s\ndisease lead to dementia and other mental health issues. As a result, the\nlanguage capabilities of patient start to decline. In this paper, we show that\nmachine learning-based unsupervised clustering of and anomaly detection with\nlinguistic biomarkers are promising approaches for intuitive visualization and\npersonalized early stage detection of Alzheimer`s disease. We demonstrate this\napproach on 10 year`s (1980 to 1989) of President Ronald Reagan`s speech data\nset. Key linguistic biomarkers that indicate early-stage AD are identified.\nExperimental results show that Reagan had early onset of Alzheimer`s sometime\nbetween 1983 and 1987. This finding is corroborated by prior work that analyzed\nhis interviews using a statistical technique. The proposed technique also\nidentifies the exact speeches that reflect linguistic biomarkers for early\nstage AD.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 13:26:52 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Wang", "Ning", ""], ["Luo", "Fan", ""], ["Peddagangireddy", "Vishal", ""], ["Subbalakshmi", "K. P.", ""], ["Chandramouli", "R.", ""]]}, {"id": "2005.12387", "submitter": "Zhihan Jiang", "authors": "Zhihan Jiang, Longbiao Chen, Binbin Zhou, Jinchun Huang, Tianqi Xie,\n  Xiaoliang Fan, Cheng Wang", "title": "iTV: Inferring Traffic Violation-Prone Locations with Vehicle\n  Trajectories and Road Environment Data", "comments": "12 pages, 19 figures, accepted by IEEE System Journal", "journal-ref": null, "doi": "10.1109/JSYST.2020.3012743", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic violations like illegal parking, illegal turning, and speeding have\nbecome one of the greatest challenges in urban transportation systems, bringing\npotential risks of traffic congestions, vehicle accidents, and parking\ndifficulties. To maximize the utility and effectiveness of the traffic\nenforcement strategies aiming at reducing traffic violations, it is essential\nfor urban authorities to infer the traffic violation-prone locations in the\ncity. Therefore, we propose a low-cost, comprehensive, and dynamic framework to\ninfer traffic violation-prone locations in cities based on the large-scale\nvehicle trajectory data and road environment data. Firstly, we normalize the\ntrajectory data by map matching algorithms and extract key driving behaviors,\ni.e., turning behaviors, parking behaviors, and speeds of vehicles. Secondly,\nwe restore spatiotemporal contexts of driving behaviors to get corresponding\ntraffic restrictions such as no parking, no turning, and speed restrictions.\nAfter matching the traffic restrictions with driving behaviors, we get the\ntraffic violation distribution. Finally, we extract the spatiotemporal patterns\nof traffic violations, and build a visualization system to showcase the\ninferred traffic violation-prone locations. To evaluate the effectiveness of\nthe proposed method, we conduct extensive studies on large-scale, real-world\nvehicle GPS trajectories collected from two Chinese cities, respectively.\nEvaluation results confirm that the proposed framework infers traffic\nviolation-prone locations effectively and efficiently, providing comprehensive\ndecision supports for traffic enforcement strategies.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 08:52:43 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 15:04:29 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Jiang", "Zhihan", ""], ["Chen", "Longbiao", ""], ["Zhou", "Binbin", ""], ["Huang", "Jinchun", ""], ["Xie", "Tianqi", ""], ["Fan", "Xiaoliang", ""], ["Wang", "Cheng", ""]]}, {"id": "2005.12409", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Max Van Kleek", "title": "Digitalization of COVID-19 pandemic management and cyber risk from\n  connected systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes cyber risks arising from connected systems challenging during the\nmanagement of a pandemic? Assuming that a variety of cyber-physical systems are\nalready operational-collecting, analyzing, and acting on data autonomously-what\nrisks might arise in their application to pandemic management? We already have\nthese systems operational, collecting, and analyzing data autonomously, so how\nwould a pandemic monitoring app be different or riskier? In this review\narticle, we discuss the digitalization of COVID-19 pandemic management and\ncyber risk from connected systems.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:19:28 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Van Kleek", "Max", ""]]}, {"id": "2005.12423", "submitter": "Srijan Kumar", "authors": "Caleb Ziems, Bing He, Sandeep Soni, Srijan Kumar", "title": "Racism is a Virus: Anti-Asian Hate and Counterhate in Social Media\n  during the COVID-19 Crisis", "comments": "The COVID-HATE dataset, classifier, and demo are available at\n  http://claws.cc.gatech.edu/covid", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spread of COVID-19 has sparked racism, hate, and xenophobia in social\nmedia targeted at Chinese and broader Asian communities. However, little is\nknown about how racial hate spreads during a pandemic and the role of\ncounterhate speech in mitigating the spread. Here we study the evolution and\nspread of anti-Asian hate speech through the lens of Twitter. We create\nCOVID-HATE, the largest dataset of anti-Asian hate and counterhate spanning\nthree months, containing over 30 million tweets, and a social network with over\n87 million nodes. By creating a novel hand-labeled dataset of 2,400 tweets, we\ntrain a text classifier to identify hate and counterhate tweets that achieves\nan average AUROC of 0.852. We identify 891,204 hate and 200,198 counterhate\ntweets in COVID-HATE. Using this data to conduct longitudinal analysis, we find\nthat while hateful users are less engaged in the COVID-19 discussions prior to\ntheir first anti-Asian tweet, they become more vocal and engaged afterwards\ncompared to counterhate users. We find that bots comprise 10.4% of hateful\nusers and are more vocal and hateful compared to non-bot users. Comparing bot\naccounts, we show that hateful bots are more successful in attracting followers\ncompared to counterhate bots. Analysis of the social network reveals that\nhateful and counterhate users interact and engage extensively with one another,\ninstead of living in isolated polarized communities. Furthermore, we find that\nhate is contagious and nodes are highly likely to become hateful after being\nexposed to hateful content. Importantly, our analysis reveals that counterhate\nmessages can discourage users from turning hateful in the first place. Overall,\nthis work presents a comprehensive overview of anti-Asian hate and counterhate\ncontent during a pandemic. The COVID-HATE dataset is available at\nhttp://claws.cc.gatech.edu/covid.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 21:58:09 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Ziems", "Caleb", ""], ["He", "Bing", ""], ["Soni", "Sandeep", ""], ["Kumar", "Srijan", ""]]}, {"id": "2005.12503", "submitter": "Jihyung Moon", "authors": "Jihyung Moon, Won Ik Cho, Junbum Lee", "title": "BEEP! Korean Corpus of Online News Comments for Toxic Speech Detection", "comments": "To be published in SocialNLP@ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Toxic comments in online platforms are an unavoidable social issue under the\ncloak of anonymity. Hate speech detection has been actively done for languages\nsuch as English, German, or Italian, where manually labeled corpus has been\nreleased. In this work, we first present 9.4K manually labeled entertainment\nnews comments for identifying Korean toxic speech, collected from a widely used\nonline news platform in Korea. The comments are annotated regarding social bias\nand hate speech since both aspects are correlated. The inter-annotator\nagreement Krippendorff's alpha score is 0.492 and 0.496, respectively. We\nprovide benchmarks using CharCNN, BiLSTM, and BERT, where BERT achieves the\nhighest score on all tasks. The models generally display better performance on\nbias identification, since the hate speech detection is a more subjective\nissue. Additionally, when BERT is trained with bias label for hate speech\ndetection, the prediction score increases, implying that bias and hate are\nintertwined. We make our dataset publicly available and open competitions with\nthe corpus and benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 03:34:01 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Moon", "Jihyung", ""], ["Cho", "Won Ik", ""], ["Lee", "Junbum", ""]]}, {"id": "2005.12547", "submitter": "Gabriele Bernardini", "authors": "Marco D'Orazio, Gabriele Bernardini, Enrico Quagliarini", "title": "Sustainable and resilient strategies for touristic cities against\n  COVID-19: an agent-based approach", "comments": "21 pages; 16 figures; 3 tables; submitted to Safety Science", "journal-ref": null, "doi": "10.1016/j.ssci.2021.105399", "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Touristic cities will suffer from COVID-19 emergency because of its economic\nimpact on their communities. The first emergency phases involved a wide closure\nof such areas to support \"social distancing\" measures (i.e. travels limitation;\nlockdown of (over)crowd-prone activities). In the second phase, individual's\nrisk-mitigation strategies (facial masks) could be properly linked to \"social\ndistancing\" to ensure re-opening touristic cities to visitors. Simulation tools\ncould support the effectiveness evaluation of risk-mitigation measures to look\nfor an economic and social optimum for activities restarting. This work\nmodifies an existing Agent-Based Model to estimate the virus spreading in\ntouristic areas, including tourists and residents' behaviours, movement and\nvirus effects on them according to a probabilistic approach. Consolidated\nproximity-based and exposure-time-based contagion spreading rules are included\naccording to international health organizations and previous calibration\nthrough experimental data. Effects of tourists' capacity (as \"social\ndistancing\"-based measure) and other strategies (i.e. facial mask\nimplementation) are evaluated depending on virus-related conditions (i.e.\ninitial infector percentages). An idealized scenario representing a significant\ncase study has been analysed to demonstrate the tool capabilities and compare\nthe effectiveness of those solutions. Results show that \"social distancing\"\nseems to be more effective at the highest infectors' rates, although represents\nan extreme measure with important economic effects. This measure loses its full\neffectiveness (on the community) as the infectors' rate decreases and\nindividuals' protection measures become predominant (facial masks). The model\ncould be integrated to consider other recurring issues on tourist-related\nfruition and schedule of urban spaces and facilities (e.g. cultural/leisure\nbuildings).\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 07:17:38 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["D'Orazio", "Marco", ""], ["Bernardini", "Gabriele", ""], ["Quagliarini", "Enrico", ""]]}, {"id": "2005.12607", "submitter": "Markus Borg", "authors": "Markus Borg, Joakim Wernberg, Thomas Olsson, Ulrik Franke, Martin\n  Andersson", "title": "Illuminating a Blind Spot in Digitalization -- Software Development in\n  Sweden's Private and Public Sector", "comments": null, "journal-ref": "In Proc. of the 1st International Workshop on Governance in\n  Software Engineering (IEEE/ACM 42nd International Conference on Software\n  Engineering Workshops (ICSEW'20), May 23-29, 2020, Seoul, Republic of Korea)", "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Netscape co-founder Marc Andreessen famously remarked in 2011, software is\neating the world - becoming a pervasive invisible critical infrastructure. Data\non the distribution of software use and development in society is scarce, but\nwe compile results from two novel surveys to provide a fuller picture of the\nrole software plays in the public and private sectors in Sweden, respectively.\nThree out of ten Swedish firms, across industry sectors, develop software\nin-house. The corresponding figure for Sweden's government agencies is four out\nof ten, i.e., the public sector should not be underestimated. The\ndigitalization of society will continue, thus the demand for software\ndevelopers will further increase. Many private firms report that the limited\nsupply of software developers in Sweden is directly affecting their expansion\nplans. Based on our findings, we outline directions that need additional\nresearch to allow evidence-informed policy-making. We argue that such work\nshould ideally be conducted by academic researchers and national statistics\nagencies in collaboration.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 09:55:19 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Borg", "Markus", ""], ["Wernberg", "Joakim", ""], ["Olsson", "Thomas", ""], ["Franke", "Ulrik", ""], ["Andersson", "Martin", ""]]}, {"id": "2005.12640", "submitter": "Fran Casino", "authors": "Thomas K. Dasaklis and Fran Casino and Constantinos Patsakis", "title": "SoK: Blockchain Solutions for Forensics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the digitization of information-intensive processes gains momentum in\nnowadays, the concern is growing about how to deal with the ever-growing\nproblem of cybercrime. To this end, law enforcement officials and security\nfirms use sophisticated digital forensics techniques for analyzing and\ninvestigating cybercrimes. However, multi-jurisdictional mandates,\ninteroperability issues, the massive amount of evidence gathered (multimedia,\ntext etc.) and multiple stakeholders involved (law enforcement agencies,\nsecurity firms etc.) are just a few among the various challenges that hinder\nthe adoption and implementation of sound digital forensics schemes. Blockchain\ntechnology has been recently proposed as a viable solution for developing\nrobust digital forensics mechanisms. In this paper, we provide an overview and\nclassification of the available blockchain-based digital forensic tools, and we\nfurther describe their main features. We also offer a thorough analysis of the\nvarious benefits and challenges of the symbiotic relationship between\nblockchain technology and the current digital forensics approaches, as proposed\nin the available literature. Based on the findings, we identify various\nresearch gaps, and we suggest future research directions that are expected to\nbe of significant value both for academics and practitioners in the field of\ndigital forensics.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:43:04 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Dasaklis", "Thomas K.", ""], ["Casino", "Fran", ""], ["Patsakis", "Constantinos", ""]]}, {"id": "2005.12644", "submitter": "Jason R.C. Nurse Dr", "authors": "Rahime Belen Saglam and Jason R. C. Nurse", "title": "Is your chatbot GDPR compliant? Open issues in agent design", "comments": null, "journal-ref": "CUI 2020: International Conference on Conversational User\n  Interfaces, July, 2020", "doi": "10.1145/3405755.3406131", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents open the world to new opportunities for human\ninteraction and ubiquitous engagement. As their conversational abilities and\nknowledge has improved, these agents have begun to have access to an increasing\nvariety of personally identifiable information and intimate details on their\nuser base. This access raises crucial questions in light of regulations as\nrobust as the General Data Protection Regulation (GDPR). This paper explores\nsome of these questions, with the aim of defining relevant open issues in\nconversational agent design. We hope that this work can provoke further\nresearch into building agents that are effective at user interaction, but also\nrespectful of regulations and user privacy.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 11:54:44 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Saglam", "Rahime Belen", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "2005.12676", "submitter": "Zachary Ratliff", "authors": "Zachary Ratliff and Joud Khoury", "title": "SNARKs to the rescue: proof-of-contact in zero knowledge", "comments": "10 pages, early draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes techniques to help with COVID-19 automated contact\ntracing, and with the restoration efforts. We describe a decentralized protocol\nfor ``proof-of-contact'' in zero knowledge where a person can publish a short\ncryptographic proof attesting to the fact that they have been infected and that\nthey have come in contact with a set of people without revealing any\ninformation about any of the people involved. More importantly, we describe how\nto compose these proofs to support broader functionality such as proofs of\n$n$th-order exposure which can further speed up automated contact tracing. The\ncryptographic proofs are publicly verifiable, and places the burden on the\nperson proving contact and not on third parties or healthcare providers\nrendering the system more decentralized, and accordingly more scalable.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 13:00:37 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 01:57:10 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 14:49:11 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2020 15:39:29 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ratliff", "Zachary", ""], ["Khoury", "Joud", ""]]}, {"id": "2005.12712", "submitter": "Benedikt Kleinmeier", "authors": "Benedikt Kleinmeier, Gerta K\\\"oster, John Drury", "title": "Agent-Based Simulation of Collective Cooperation: From Experiment to\n  Model", "comments": "16 pages, 19 figures, 5 tables, 4 listings, interdisciplinary work\n  between computer science and psychology", "journal-ref": "Journal of the Royal Society Interface (October 2020, Volume 17,\n  Issue 171)", "doi": "10.1098/rsif.2020.0396", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulation models of pedestrian dynamics have become an invaluable tool for\nevacuation planning. Typically crowds are assumed to stream unidirectionally\ntowards a safe area. Simulated agents avoid collisions through mechanisms that\nbelong to each individual, such as being repelled from each other by imaginary\nforces. But classic locomotion models fail when collective cooperation is\ncalled for, notably when an agent, say a first-aid attendant, needs to forge a\npath through a densely packed group. We present a controlled experiment to\nobserve what happens when humans pass through a dense static crowd. We\nformulate and test hypothesis on salient phenomena. We discuss our observations\nin a psychological framework. We derive a model that incorporates: agents'\nperception and cognitive processing of a situation that needs cooperation;\nselection from a portfolio of behaviours, such as being cooperative; and a\nsuitable action, such as swapping places. Agents' ability to successfully get\nthrough a dense crowd emerges as an effect of the psychological model.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 13:29:08 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 09:40:47 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Kleinmeier", "Benedikt", ""], ["K\u00f6ster", "Gerta", ""], ["Drury", "John", ""]]}, {"id": "2005.12731", "submitter": "Daryl DeFord", "authors": "Daryl DeFord, Moon Duchin, and Justin Solomon", "title": "A Computational Approach to Measuring Vote Elasticity and\n  Competitiveness", "comments": "38 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent wave of attention to partisan gerrymandering has come with a push\nto refine or replace the laws that govern political redistricting around the\ncountry. A common element in several states' reform efforts has been the\ninclusion of competitiveness metrics, or scores that evaluate a districting\nplan based on the extent to which district-level outcomes are in play or are\nlikely to be closely contested.\n  In this paper, we examine several classes of competitiveness metrics\nmotivated by recent reform proposals and then evaluate their potential outcomes\nacross large ensembles of districting plans at the Congressional and state\nSenate levels. This is part of a growing literature using MCMC techniques from\napplied statistics to situate plans and criteria in the context of valid\nredistricting alternatives. Our empirical analysis focuses on five\nstates---Utah, Georgia, Wisconsin, Virginia, and Massachusetts---chosen to\nrepresent a range of partisan attributes. We highlight situation-specific\ndifficulties in creating good competitiveness metrics and show that optimizing\ncompetitiveness can produce unintended consequences on other partisan metrics.\nThese results demonstrate the importance of (1) avoiding writing detailed\nmetric constraints into long-lasting constitutional reform and (2) carrying out\ncareful mathematical modeling on real geo-electoral data in each redistricting\ncycle.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:01:31 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["DeFord", "Daryl", ""], ["Duchin", "Moon", ""], ["Solomon", "Justin", ""]]}, {"id": "2005.12732", "submitter": "Daryl DeFord", "authors": "Sophia Caldera, Daryl DeFord, Moon Duchin, Samuel C. Gutekunst, and\n  Cara Nix", "title": "Mathematics of Nested Districts: The Case of Alaska", "comments": "39 pages, 16 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In eight states, a \"nesting rule\" requires that each state Senate district be\nexactly composed of two adjacent state House districts. In this paper we\ninvestigate the potential impacts of these nesting rules with a focus on\nAlaska, where Republicans have a 2/3 majority in the Senate while a\nDemocratic-led coalition controls the House. Treating the current House plan as\nfixed and considering all possible pairings, we find that the choice of\npairings alone can create a swing of 4-5 seats out of 20 against recent voting\npatterns, which is similar to the range observed when using a Markov chain\nprocedure to generate plans without the nesting constraint. The analysis\nenables other insights into Alaska districting, including the partisan latitude\navailable to districters with and without strong rules about nesting and\ncontiguity.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:02:07 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Caldera", "Sophia", ""], ["DeFord", "Daryl", ""], ["Duchin", "Moon", ""], ["Gutekunst", "Samuel C.", ""], ["Nix", "Cara", ""]]}, {"id": "2005.12762", "submitter": "Bel\\'en Sald\\'ias", "authors": "Belen Saldias and Deb Roy", "title": "Exploring aspects of similarity between spoken personal narratives by\n  disentangling them into narrative clause types", "comments": "9 pages, Proceedings of the 2020 ACL Workshop on Narrative\n  Understanding, Storylines, and Events (NUSE). ACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sharing personal narratives is a fundamental aspect of human social behavior\nas it helps share our life experiences. We can tell stories and rely on our\nbackground to understand their context, similarities, and differences. A\nsubstantial effort has been made towards developing storytelling machines or\ninferring characters' features. However, we don't usually find models that\ncompare narratives. This task is remarkably challenging for machines since\nthey, as sometimes we do, lack an understanding of what similarity means. To\naddress this challenge, we first introduce a corpus of real-world spoken\npersonal narratives comprising 10,296 narrative clauses from 594 video\ntranscripts. Second, we ask non-narrative experts to annotate those clauses\nunder Labov's sociolinguistic model of personal narratives (i.e., action,\norientation, and evaluation clause types) and train a classifier that reaches\n84.7% F-score for the highest-agreed clauses. Finally, we match stories and\nexplore whether people implicitly rely on Labov's framework to compare\nnarratives. We show that actions followed by the narrator's evaluation of these\nare the aspects non-experts consider the most. Our approach is intended to help\ninform machine learning methods aimed at studying or representing personal\nnarratives.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 14:34:07 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 13:32:15 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Saldias", "Belen", ""], ["Roy", "Deb", ""]]}, {"id": "2005.12783", "submitter": "Antonio Fern\\'andez Anta", "authors": "Oluwasegun Ojo, Augusto Garc\\'ia-Agundez, Benjamin Girault, Harold\n  Hern\\'andez, Elisa Cabana, Amanda Garc\\'ia-Garc\\'ia, Payman Arabshahi, Carlos\n  Baquero, Paolo Casari, Ednaldo Jos\\'e Ferreira, Davide Frey, Chryssis\n  Georgiou, Mathieu Goessens, Anna Ishchenko, Ernesto Jim\\'enez, Oleksiy\n  Kebkal, Rosa Lillo, Raquel Menezes, Nicolas Nicolaou, Antonio Ortega, Paul\n  Patras, Julian C Roberts, Efstathios Stavrakis, Yuichi Tanaka, Antonio\n  Fern\\'andez Anta", "title": "CoronaSurveys: Using Surveys with Indirect Reporting to Estimate the\n  Incidence and Evolution of Epidemics", "comments": "Presented at The KDD Workshop on Humanitarian Mapping, San Diego,\n  California USA, August 24, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The world is suffering from a pandemic called COVID-19, caused by the\nSARS-CoV-2 virus. National governments have problems evaluating the reach of\nthe epidemic, due to having limited resources and tests at their disposal. This\nproblem is especially acute in low and middle-income countries (LMICs). Hence,\nany simple, cheap and flexible means of evaluating the incidence and evolution\nof the epidemic in a given country with a reasonable level of accuracy is\nuseful. In this paper, we propose a technique based on (anonymous) surveys in\nwhich participants report on the health status of their contacts. This indirect\nreporting technique, known in the literature as network scale-up method,\npreserves the privacy of the participants and their contacts, and collects\ninformation from a larger fraction of the population (as compared to individual\nsurveys). This technique has been deployed in the CoronaSurveys project, which\nhas been collecting reports for the COVID-19 pandemic for more than two months.\nResults obtained by CoronaSurveys show the power and flexibility of the\napproach, suggesting that it could be an inexpensive and powerful tool for\nLMICs.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 11:58:23 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 12:18:50 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Ojo", "Oluwasegun", ""], ["Garc\u00eda-Agundez", "Augusto", ""], ["Girault", "Benjamin", ""], ["Hern\u00e1ndez", "Harold", ""], ["Cabana", "Elisa", ""], ["Garc\u00eda-Garc\u00eda", "Amanda", ""], ["Arabshahi", "Payman", ""], ["Baquero", "Carlos", ""], ["Casari", "Paolo", ""], ["Ferreira", "Ednaldo Jos\u00e9", ""], ["Frey", "Davide", ""], ["Georgiou", "Chryssis", ""], ["Goessens", "Mathieu", ""], ["Ishchenko", "Anna", ""], ["Jim\u00e9nez", "Ernesto", ""], ["Kebkal", "Oleksiy", ""], ["Lillo", "Rosa", ""], ["Menezes", "Raquel", ""], ["Nicolaou", "Nicolas", ""], ["Ortega", "Antonio", ""], ["Patras", "Paul", ""], ["Roberts", "Julian C", ""], ["Stavrakis", "Efstathios", ""], ["Tanaka", "Yuichi", ""], ["Anta", "Antonio Fern\u00e1ndez", ""]]}, {"id": "2005.12806", "submitter": "Nikolaos Misirlis", "authors": "Nikolaos Misirlis, Miriam H. Zwaan, David Weber", "title": "International students' loneliness, depression and stress levels in\n  COVID-19 crisis. The role of social media and the host university", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The move to university life is characterized by strong emotions, some of them\nnegative, such as loneliness, anxiety, and depression. These negative emotions\nare strengthened due to the obligatory lockdown due to the COVID-19 pandemic.\nPrevious research indicates association among the use of social media,\nuniversity satisfaction, and the aforementioned emotions. We report findings\nfrom 248 international undergraduates in The Netherlands, all students at the\nInternational School of Business. Our results indicate strong correlations\nbetween anxiety, loneliness, and COVID-19-related stress with university\nsatisfaction together with social capital. Keywords: COVID-19; Pandemic;\nlockdown; loneliness; depression; anxiety; international students\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 15:39:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Misirlis", "Nikolaos", ""], ["Zwaan", "Miriam H.", ""], ["Weber", "David", ""]]}, {"id": "2005.12830", "submitter": "Jia Xue", "authors": "Jia Xue (University of Toronto), Junxiang Chen (University of\n  Pittsburgh), Ran Hu (University of Toronto), Chen Chen (University of\n  Toronto), ChengDa Zheng (University of Toronto), Xiaoqian Liu (Chinese\n  Academy of Sciences), Tingshao Zhu (China Academy of Science)", "title": "Twitter discussions and emotions about COVID-19 pandemic: a machine\n  learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the study is to examine coronavirus disease (COVID-19)\nrelated discussions, concerns, and sentiments that emerged from tweets posted\nby Twitter users. We analyze 4 million Twitter messages related to the COVID-19\npandemic using a list of 25 hashtags such as \"coronavirus,\" \"COVID-19,\"\n\"quarantine\" from March 1 to April 21 in 2020. We use a machine learning\napproach, Latent Dirichlet Allocation (LDA), to identify popular unigram,\nbigrams, salient topics and themes, and sentiments in the collected Tweets.\nPopular unigrams include \"virus,\" \"lockdown,\" and \"quarantine.\" Popular bigrams\ninclude \"COVID-19,\" \"stay home,\" \"corona virus,\" \"social distancing,\" and \"new\ncases.\" We identify 13 discussion topics and categorize them into five\ndifferent themes, such as \"public health measures to slow the spread of\nCOVID-19,\" \"social stigma associated with COVID-19,\" \"coronavirus news cases\nand deaths,\" \"COVID-19 in the United States,\" and \"coronavirus cases in the\nrest of the world\". Across all identified topics, the dominant sentiments for\nthe spread of coronavirus are anticipation that measures that can be taken,\nfollowed by a mixed feeling of trust, anger, and fear for different topics. The\npublic reveals a significant feeling of fear when they discuss the coronavirus\nnew cases and deaths than other topics. The study shows that Twitter data and\nmachine learning approaches can be leveraged for infodemiology study by\nstudying the evolving public discussions and sentiments during the COVID-19.\nReal-time monitoring and assessment of the Twitter discussion and concerns can\nbe promising for public health emergency responses and planning. Already\nemerged pandemic fear, stigma, and mental health concerns may continue to\ninfluence public trust when there occurs a second wave of COVID-19 or a new\nsurge of the imminent pandemic.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:10:02 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 02:43:13 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Xue", "Jia", "", "University of Toronto"], ["Chen", "Junxiang", "", "University of\n  Pittsburgh"], ["Hu", "Ran", "", "University of Toronto"], ["Chen", "Chen", "", "University of\n  Toronto"], ["Zheng", "ChengDa", "", "University of Toronto"], ["Liu", "Xiaoqian", "", "Chinese\n  Academy of Sciences"], ["Zhu", "Tingshao", "", "China Academy of Science"]]}, {"id": "2005.12884", "submitter": "Junade Ali", "authors": "Junade Ali and Vladimir Dyo", "title": "Cross Hashing: Anonymizing encounters in Decentralised Contact Tracing\n  Protocols", "comments": "Accepted at the 35th International Conference on Information\n  Networking (ICOIN 2021). To be presented between 13-16 January 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 (SARS-CoV-2) epidemic, Contact Tracing emerged as an\nessential tool for managing the epidemic. App-based solutions have emerged for\nContact Tracing, including a protocol designed by Apple and Google (influenced\nby an open-source protocol known as DP3T). This protocol contains two\nwell-documented de-anonymisation attacks. Firstly that when someone is marked\nas having tested positive and their keys are made public, they can be tracked\nover a large geographic area for 24 hours at a time. Secondly, whilst the app\nrequires a minimum exposure duration to register a contact, there is no\ncryptographic guarantee for this property. This means an adversary can scan\nBluetooth networks and retrospectively find who is infected. We propose a novel\n\"cross hashing\" approach to cryptographically guarantee minimum exposure\ndurations. We further mitigate the 24-hour data exposure of infected\nindividuals and reduce computational time for identifying if a user has been\nexposed using $k$-Anonymous buckets of hashes and Private Set Intersection. We\nempirically demonstrate that this modified protocol can offer like-for-like\nefficacy to the existing protocol.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:20:25 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 13:07:49 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 18:20:36 GMT"}, {"version": "v4", "created": "Wed, 18 Nov 2020 18:15:41 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ali", "Junade", ""], ["Dyo", "Vladimir", ""]]}, {"id": "2005.12902", "submitter": "Sergio G\\'omez", "authors": "Aniello Lampo, Javier Borge-Holthoefer, Sergio G\\'omez, Albert\n  Sol\\'e-Ribalta", "title": "Multiple abrupt phase transitions in urban transport congestion", "comments": "32 pages, 25 figures", "journal-ref": "Phys. Rev. Research 3, 013267 (2021)", "doi": "10.1103/PhysRevResearch.3.013267", "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decades, the study of cities has been transformed by new\napproaches combining engineering and complexity sciences. Network theory is\nplaying a central role, facilitating the quantitative analysis of crucial urban\ndynamics, such as mobility, city growth or urban planning. In this work, we\nfocus on the spatial aspects of congestion. Analyzing a large amount of real\ncity networks, we show that the location of the onset of congestion changes\naccording to the considered urban area, defining, in turn, a set of congestion\nregimes separated by abrupt transitions. To help unveiling these spatial\ndependencies of congestion (in terms of network betweenness analysis), we\nintroduce a family of planar road network models composed of a dense urban\ncenter connected to an arboreal periphery. These models, coined as GT and\nDT-MST models, allow us to analytically, numerically and experimentally\ndescribe how and why congestion emerges in particular geographical areas of\nmonocentric cities and, subsequently, to describe the congestion regimes and\nthe factors that promote the appearance of their abrupt transitions. We show\nthat the fundamental ingredient behind the observed abrupt transitions is the\nspatial separation between the urban center and the periphery, and the number\nof separate areas that form the periphery. Elaborating on the implications of\nour results, we show that they may have an influence on the design and\noptimization of road networks regarding urban growth and the management of\ndaily traffic dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 17:58:44 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 15:07:35 GMT"}, {"version": "v3", "created": "Mon, 11 Jan 2021 16:59:03 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Lampo", "Aniello", ""], ["Borge-Holthoefer", "Javier", ""], ["G\u00f3mez", "Sergio", ""], ["Sol\u00e9-Ribalta", "Albert", ""]]}, {"id": "2005.12949", "submitter": "Aetienne Sardon", "authors": "Alexander Lipton, Aetienne Sardon, Fabian Sch\\\"ar, Christian\n  Sch\\\"upbach", "title": "From Tether to Libra: Stablecoins, Digital Currency and the Future of\n  Money", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an overview on stablecoins and introduces a novel\nterminology to help better identify stablecoins with truly disruptive\npotential. It provides a compact definition for stablecoins, identifying the\nunique features that make them distinct from previously known payment systems.\nFurthermore, it surveys the different use cases for stablecoins as well as the\nunderlying economic incentives for creating them. Finally, it outlines critical\nregulatory considerations that constrain stablecoins and summarizes key factors\nthat are driving their rapid development.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 18:13:46 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Lipton", "Alexander", ""], ["Sardon", "Aetienne", ""], ["Sch\u00e4r", "Fabian", ""], ["Sch\u00fcpbach", "Christian", ""]]}, {"id": "2005.13008", "submitter": "Eiji Yamamura", "authors": "Eiji Yamamura., Yoshiro Tsutsui", "title": "Impact of the State of Emergency Declaration for COVID-19 on Preventive\n  Behaviors and Mental Conditions in Japan: Difference in Difference Analysis\n  using Panel Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the COVID-19 epidemic in Japan between March and April 2020, Internet\nsurveys were conducted to construct panel data to investigate changes at the\nindividual level regarding preventive behaviors and mental conditions by\nsurveying the same respondents at different times. Specifically, the\ndifference-in-difference (DID) method was used to explore the impact of the\nCOVID-19 state of emergency declared by the government. Key findings were: (1)\nthe declaration led people to stay home, while also generating anger, fear, and\nanxiety. (2) The effect of the declaration on the promotion of preventive\nbehaviors was larger than the detrimental effect on mental conditions. (3)\nOverall, the effect on women was larger than that on men.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 08:06:36 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Yamamura.", "Eiji", ""], ["Tsutsui", "Yoshiro", ""]]}, {"id": "2005.13107", "submitter": "Zichao Wang", "authors": "Zichao Wang, Yi Gu, Andrew Lan, Richard Baraniuk", "title": "VarFA: A Variational Factor Analysis Framework For Efficient Bayesian\n  Learning Analytics", "comments": "edm 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose VarFA, a variational inference factor analysis framework that\nextends existing factor analysis models for educational data mining to\nefficiently output uncertainty estimation in the model's estimated factors.\nSuch uncertainty information is useful, for example, for an adaptive testing\nscenario, where additional tests can be administered if the model is not quite\ncertain about a students' skill level estimation. Traditional Bayesian\ninference methods that produce such uncertainty information are computationally\nexpensive and do not scale to large data sets. VarFA utilizes variational\ninference which makes it possible to efficiently perform Bayesian inference\neven on very large data sets. We use the sparse factor analysis model as a case\nstudy and demonstrate the efficacy of VarFA on both synthetic and real data\nsets. VarFA is also very general and can be applied to a wide array of factor\nanalysis models.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:03:07 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 20:46:06 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Wang", "Zichao", ""], ["Gu", "Yi", ""], ["Lan", "Andrew", ""], ["Baraniuk", "Richard", ""]]}, {"id": "2005.13164", "submitter": "Nathan Pemberton", "authors": "David Culler, Prabal Dutta, Gabe Fierro, Joseph E. Gonzalez, Nathan\n  Pemberton, Johann Schleier-Smith, K. Shankari, Alvin Wan, Thomas Zachariah", "title": "CoVista: A Unified View on Privacy Sensitive Mobile Contact Tracing\n  Effort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Governments around the world have become increasingly frustrated with tech\ngiants dictating public health policy. The software created by Apple and Google\nenables individuals to track their own potential exposure through collated\nexposure notifications. However, the same software prohibits location tracking,\ndenying key information needed by public health officials for robust contract\ntracing. This information is needed to treat and isolate COVID-19 positive\npeople, identify transmission hotspots, and protect against continued spread of\ninfection. In this article, we present two simple ideas: the lighthouse and the\ncovid-commons that address the needs of public health authorities while\npreserving the privacy-sensitive goals of the Apple and google exposure\nnotification protocols.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 05:09:41 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Culler", "David", ""], ["Dutta", "Prabal", ""], ["Fierro", "Gabe", ""], ["Gonzalez", "Joseph E.", ""], ["Pemberton", "Nathan", ""], ["Schleier-Smith", "Johann", ""], ["Shankari", "K.", ""], ["Wan", "Alvin", ""], ["Zachariah", "Thomas", ""]]}, {"id": "2005.13167", "submitter": "Lingfeng Bao", "authors": "Lingfeng Bao, Tao Li, Xin Xia, Kaiyu Zhu, Hui Li, and Xiaohu Yang", "title": "How does Working from Home Affect Developer Productivity? -- A Case\n  Study of Baidu During COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, working from home (WFH) has become a popular work arrangement due\nto its many potential benefits for both companies and employees (e.g.,\nincreasing job satisfaction and retention of employees). Many previous studies\nhave investigated the impact of working from home on the productivity of\nemployees. However, most of these studies usually use a qualitative analysis\nmethod such as survey and interview, and the studied participants do not work\nfrom home for a long continuing time. Due to the outbreak of coronavirus\ndisease 2019 (COVID-19), a large number of companies asked their employees to\nwork from home, which provides us an opportunity to investigate whether working\nfrom home affects their productivity.\n  In this study, to investigate the difference of developer productivity\nbetween working from home and working onsite, we conduct a quantitative\nanalysis based on a dataset of developers' daily activities from Baidu Inc, one\nof the largest IT companies in China. In total, we collected approximately four\nthousand records of 139 developers' activities of 138 working days. Out of\nthese records, 1,103 records are submitted when developers work from home due\nto COVID-19 pandemic. We find that WFH has both positive and negative impacts\non developer productivity in terms of different metrics, e.g., the number of\nbuilds/commits/code reviews. We also notice that working from home has\ndifferent impacts on projects with different characteristics including\nprogramming language, project type/age/size. For example, working from home has\na negative impact on developer productivity for large projects. Additionally,\nwe find that productivity varies for different developers. Based on these\nfindings, we get some feedbacks from developers of Baidu and understand some\nreasons why WFH has different impacts on developer productivity.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 05:31:26 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 06:40:28 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 23:58:09 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Bao", "Lingfeng", ""], ["Li", "Tao", ""], ["Xia", "Xin", ""], ["Zhu", "Kaiyu", ""], ["Li", "Hui", ""], ["Yang", "Xiaohu", ""]]}, {"id": "2005.13180", "submitter": "Simone Fobi", "authors": "Simone Fobi, Terence Conlon, Jayant Taneja, Vijay Modi", "title": "Learning to segment from misaligned and partial labels", "comments": "This is the extended version of a paper to be published in ACM\n  COMPASS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To extract information at scale, researchers increasingly apply semantic\nsegmentation techniques to remotely-sensed imagery. While fully-supervised\nlearning enables accurate pixel-wise segmentation, compiling the exhaustive\ndatasets required is often prohibitively expensive. As a result, many non-urban\nsettings lack the ground-truth needed for accurate segmentation. Existing open\nsource infrastructure data for these regions can be inexact and non-exhaustive.\nOpen source infrastructure annotations like OpenStreetMaps (OSM) are\nrepresentative of this issue: while OSM labels provide global insights to road\nand building footprints, noisy and partial annotations limit the performance of\nsegmentation algorithms that learn from them. In this paper, we present a novel\nand generalizable two-stage framework that enables improved pixel-wise image\nsegmentation given misaligned and missing annotations. First, we introduce the\nAlignment Correction Network to rectify incorrectly registered open source\nlabels. Next, we demonstrate a segmentation model -- the Pointer Segmentation\nNetwork -- that uses corrected labels to predict infrastructure footprints\ndespite missing annotations. We test sequential performance on the AIRS\ndataset, achieving a mean intersection-over-union score of 0.79; more\nimportantly, model performance remains stable as we decrease the fraction of\nannotations present. We demonstrate the transferability of our method to lower\nquality data, by applying the Alignment Correction Network to OSM labels to\ncorrect building footprints; we also demonstrate the accuracy of the Pointer\nSegmentation Network in predicting cropland boundaries in California from\nmedium resolution data. Overall, our methodology is robust for multiple\napplications with varied amounts of training data present, thus offering a\nmethod to extract reliable information from noisy, partial data.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 06:02:58 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Fobi", "Simone", ""], ["Conlon", "Terence", ""], ["Taneja", "Jayant", ""], ["Modi", "Vijay", ""]]}, {"id": "2005.13225", "submitter": "Wirawan Istiono", "authors": "Wirawan Istiono, Hijrah, Nur Nawaningtyas.P", "title": "Education Games To Learn Basic Algorithm With Near Isometric Projection\n  Method", "comments": "5 pages, 10 Figures, International Journal of Advanced Studies in\n  Computer Science & Engineering IJASCSE Volume 8 Issue 7, 2019", "journal-ref": null, "doi": "10.31227/osf.io/yuzn7", "report-no": null, "categories": "cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Basic programming and algorithm learning is one of the compulsory subjects\nrequired for students majoring in computers. As this lesson is knowledge base,\nit is very important and essential that before learn programmings languages\nstudents must be encourages to learn it to avoid difficulties that by using the\nalgorithm learning games application with Near Isometric Projection, Students\nor prospective students become more interested in learning algorithms and\nprogramming. In this study, basic learning algorithms focused on the material\nSequencing, Overloading, Procedures, Recursive Loops and Conditionals, which\nare made so that it can make it easier for students to learn the basics of\nprogramming algorithms. The simulated results show that proposed Education\nGames with Near Isometric Projection method reach 83.87% statement of agreement\nthat application games to learn basic programming algorithms were interesting\nand helped them to understand basic algorithm after testing using UAT. Testing\nwith User Acceptance Test for 30 students of Multimedia Nusantara University\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 08:10:19 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Istiono", "Wirawan", ""], ["Hijrah", "", ""], ["P", "Nur Nawaningtyas.", ""]]}, {"id": "2005.13404", "submitter": "Benjamin Laufer", "authors": "Benjamin Laufer", "title": "Compounding Injustice: History and Prediction in Carceral\n  Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk assessment algorithms in criminal justice put people's lives at the\ndiscretion of a simple statistical tool. This thesis explores how algorithmic\ndecision-making in criminal policy can exhibit feedback effects, where\ndisadvantage accumulates among those deemed 'high risk' by the state. Evidence\nfrom Philadelphia suggests that risk - and, by extension, criminality - is not\nfundamental or in any way exogenous to political decision-making. A close look\nat the geographical and demographic properties of risk calls into question the\ncurrent practice of prediction in criminal policy. Using court docket summaries\nfrom Philadelphia, we find evidence of a criminogenic effect of incarceration,\neven controlling for existing determinants of 'criminal risk'. With evidence\nthat criminal treatment can influence future criminal convictions, we explore\nthe theoretical implications of compounding effects in repeated carceral\ndecisions.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:51:50 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Laufer", "Benjamin", ""]]}, {"id": "2005.13517", "submitter": "Prashant Shenoy", "authors": "Akhil Soman, Amee Trivedi, David Irwin, Beka Kosanovic, Benjamin\n  McDaniel, Prashant Shenoy", "title": "Peak Forecasting for Battery-based Energy Optimizations in Campus\n  Microgrids", "comments": "5 pages. 4 figures, This paper will appear in the Proceedings of ACM\n  International Conference on Future Energy Systems (e-Energy'20), June 2020", "journal-ref": null, "doi": "10.1145/3396851.3397751", "report-no": null, "categories": "eess.SP cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Battery-based energy storage has emerged as an enabling technology for a\nvariety of grid energy optimizations, such as peak shaving and cost arbitrage.\nA key component of battery-driven peak shaving optimizations is peak\nforecasting, which predicts the hours of the day that see the greatest demand.\nWhile there has been significant prior work on load forecasting, we argue that\nthe problem of predicting periods where the demand peaks for individual\nconsumers or micro-grids is more challenging than forecasting load at a grid\nscale. We propose a new model for peak forecasting, based on deep learning,\nthat predicts the k hours of each day with the highest and lowest demand. We\nevaluate our approach using a two year trace from a real micro-grid of 156\nbuildings and show that it outperforms the state of the art load forecasting\ntechniques adapted for peak predictions by 11-32%. When used for battery-based\npeak shaving, our model yields annual savings of $496,320 for a 4 MWhr battery\nfor this micro-grid.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 17:29:44 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Soman", "Akhil", ""], ["Trivedi", "Amee", ""], ["Irwin", "David", ""], ["Kosanovic", "Beka", ""], ["McDaniel", "Benjamin", ""], ["Shenoy", "Prashant", ""]]}, {"id": "2005.13535", "submitter": "Mohammad Rahaman", "authors": "Mohammad Saiedur Rahaman, Jonathan Liono, Yongli Ren, Jeffrey Chan,\n  Shaw Kudo, Tim Rawling and Flora D. Salim", "title": "An Ambient-Physical System to Infer Concentration in Open-plan Workplace", "comments": "12 pages, 14 figures", "journal-ref": null, "doi": "10.1109/JIOT.2020.2996219", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the core challenges in open-plan workspaces is to ensure a good level\nof concentration for the workers while performing their tasks. Hence, being\nable to infer concentration levels of workers will allow building designers,\nmanagers, and workers to estimate what effect different open-plan layouts will\nhave and to find an optimal one. In this research, we present an\nambient-physical system to investigate the concentration inference problem.\nSpecifically, we deploy a series of pervasive sensors to capture various\nambient and physical signals related to perceived concentration at work. The\npracticality of our system has been tested on two large open-plan workplaces\nwith different designs and layouts. The empirical results highlight promising\napplications of pervasive sensing in occupational concentration inference,\nwhich can be adopted to enhance the capabilities of modern workplaces.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 03:23:35 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Rahaman", "Mohammad Saiedur", ""], ["Liono", "Jonathan", ""], ["Ren", "Yongli", ""], ["Chan", "Jeffrey", ""], ["Kudo", "Shaw", ""], ["Rawling", "Tim", ""], ["Salim", "Flora D.", ""]]}, {"id": "2005.13691", "submitter": "Yichuan Li", "authors": "Kaize Ding, Kai Shu, Yichuan Li, Amrita Bhattacharjee, and Huan Liu", "title": "Challenges in Combating COVID-19 Infodemic -- Data, Tools, and Ethics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the COVID-19 pandemic continues its global devastation, numerous\naccompanying challenges emerge. One important challenge we face is to\nefficiently and effectively use recently gathered data and find computational\ntools to combat the COVID-19 infodemic, a typical information overloading\nproblem. Novel coronavirus presents many questions without ready answers; its\nuncertainty and our eagerness in search of solutions offer a fertile\nenvironment for infodemic. It is thus necessary to combat the infodemic and\nmake a concerted effort to confront COVID-19 and mitigate its negative impact\nin all walks of life when saving lives and maintaining normal orders during\ntrying times. In this position paper of combating the COVID-19 infodemic, we\nillustrate its need by providing real-world examples of rampant conspiracy\ntheories, misinformation, and various types of scams that take advantage of\nhuman kindness, fear, and ignorance. We present three key challenges in this\nfight against the COVID-19 infodemic where researchers and practitioners\ninstinctively want to contribute and help. We demonstrate that these three\nchallenges can and will be effectively addressed by collective wisdom,\ncrowdsourcing, and collaborative research.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 22:41:02 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Ding", "Kaize", ""], ["Shu", "Kai", ""], ["Li", "Yichuan", ""], ["Bhattacharjee", "Amrita", ""], ["Liu", "Huan", ""]]}, {"id": "2005.13701", "submitter": "Joshua Tan", "authors": "Nathan Schneider, Primavera De Filippi, Seth Frey, Joshua Z. Tan, and\n  Amy X. Zhang", "title": "Modular Politics: Toward a Governance Layer for Online Communities", "comments": "In CSCW '21", "journal-ref": "Proc. ACM Hum.-Comput. Interact., Vol. 5, No. CSCW1, Article 16.\n  Publication date: April 2021", "doi": "10.1145/3449090", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Governance in online communities is an increasingly high-stakes challenge,\nand yet many basic features of offline governance legacies--juries, political\nparties, term limits, and formal debates, to name a few--are not in the\nfeature-sets of the software most community platforms use. Drawing on the\nparadigm of Institutional Analysis and Development, this paper proposes a\nstrategy for addressing this lapse by specifying basic features of a\ngeneralizable paradigm for online governance called Modular Politics. Whereas\nclassical governance typologies tend to present a choice among wholesale\nideologies, such as democracy or oligarchy, Modular Politics would enable\nplatform operators and their users to build bottom-up governance processes from\ncomputational components that are modular and composable, highly versatile in\ntheir expressiveness, portable from one context to another, and interoperable\nacross platforms. This kind of approach could implement pre-digital governance\nsystems as well as accelerate innovation in uniquely digital techniques. As\ndiverse communities share and connect their components and data, governance\ncould occur through a ubiquitous network layer. To that end, this paper\nproposes the development of an open standard for networked governance.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 23:05:17 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 17:31:30 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 22:23:54 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Schneider", "Nathan", ""], ["De Filippi", "Primavera", ""], ["Frey", "Seth", ""], ["Tan", "Joshua Z.", ""], ["Zhang", "Amy X.", ""]]}, {"id": "2005.13718", "submitter": "Asia Biega", "authors": "Asia J. Biega, Peter Potash, Hal Daum\\'e III, Fernando Diaz, Mich\\`ele\n  Finck", "title": "Operationalizing the Legal Principle of Data Minimization for\n  Personalization", "comments": "SIGIR 2020 paper: In Proc. of the 43rd International ACM SIGIR\n  Conference on Research and Development in Information Retrieval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Article 5(1)(c) of the European Union's General Data Protection Regulation\n(GDPR) requires that \"personal data shall be [...] adequate, relevant, and\nlimited to what is necessary in relation to the purposes for which they are\nprocessed (`data minimisation')\". To date, the legal and computational\ndefinitions of `purpose limitation' and `data minimization' remain largely\nunclear. In particular, the interpretation of these principles is an open issue\nfor information access systems that optimize for user experience through\npersonalization and do not strictly require personal data collection for the\ndelivery of basic service.\n  In this paper, we identify a lack of a homogeneous interpretation of the data\nminimization principle and explore two operational definitions applicable in\nthe context of personalization. The focus of our empirical study in the domain\nof recommender systems is on providing foundational insights about the (i)\nfeasibility of different data minimization definitions, (ii) robustness of\ndifferent recommendation algorithms to minimization, and (iii) performance of\ndifferent minimization strategies.We find that the performance decrease\nincurred by data minimization might not be substantial, but that it might\ndisparately impact different users---a finding which has implications for the\nviability of different formal minimization definitions. Overall, our analysis\nuncovers the complexities of the data minimization problem in the context of\npersonalization and maps the remaining computational and regulatory challenges.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 00:43:06 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Biega", "Asia J.", ""], ["Potash", "Peter", ""], ["Daum\u00e9", "Hal", "III"], ["Diaz", "Fernando", ""], ["Finck", "Mich\u00e8le", ""]]}, {"id": "2005.13745", "submitter": "Hassan Habibi Gharakheili", "authors": "Ke Hu and Ashfaqur Rahman and Hassan Habibi Gharakheili and Vijay\n  Sivaraman", "title": "HazeDose: Design and Analysis of a Personal Air Pollution Inhaled Dose\n  Estimation System using Wearable Sensors", "comments": "29 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays air pollution becomes one of the biggest world issues in both\ndeveloping and developed countries. Helping individuals understand their air\npollution exposure and health risks, the traditional way is to utilize data\nfrom static monitoring stations and estimate air pollution qualities in a large\narea by government agencies. Data from such sensing system is very sparse and\ncannot reflect real personal exposure. In recent years, several research groups\nhave developed participatory air pollution sensing systems which use wearable\nor portable units coupled with smartphones to crowd-source urban air pollution\ndata. These systems have shown remarkable improvement in spatial granularity\nover government-operated fixed monitoring systems. In this paper, we extend the\nparadigm to HazeDose system, which can personalize the individuals' air\npollution exposure. Specifically, we combine the pollution concentrations\nobtained from an air pollution estimation system with the activity data from\nthe individual's on-body activity monitors to estimate the personal inhalation\ndosage of air pollution. Users can visualize their personalized air pollution\nexposure information via a mobile application. We show that different\nactivities, such as walking, cycling, or driving, impact their dosage, and\ncommuting patterns contribute to a significant proportion of an individual's\ndaily air pollution dosage. Moreover, we propose a dosage minimization\nalgorithm, with the trial results showing that up to 14.1% of a biker's daily\nexposure can be reduced while using alternative routes the driver can inhale\n25.9% less than usual. One heuristic algorithm is also introduced to balance\nthe execution time and dosage reduction for alternative routes scenarios. The\nresults show that up to 20.3% dosage reduction can be achieved when the\nexecution time is almost one seventieth of the original one.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 02:35:13 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Hu", "Ke", ""], ["Rahman", "Ashfaqur", ""], ["Gharakheili", "Hassan Habibi", ""], ["Sivaraman", "Vijay", ""]]}, {"id": "2005.14045", "submitter": "Stefan Hochwarter", "authors": "Stefan Hochwarter and Babak A. Farshchian", "title": "Scaling Participation -- What Does the Concept of Managed Communities\n  Offer for Participatory Design?", "comments": null, "journal-ref": "Proceedings of the 16th Participatory Design Conference 2020 -\n  Participation(s) Otherwise - Vol. 2", "doi": "10.1145/3384772.3385143", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates mechanisms for scaling participation in participatory\ndesign (PD). Specifically, the paper focuses on managed communities, one\nstrategy of generification work. We first give a brief introduction on the\nissue of scaling in PD, followed by exploring the strategy of managed\ncommunities in PD. This exploration is underlined by an ongoing case study in\nthe healthcare sector, and we propose solutions to observed challenges. The\npaper ends with a critical reflection on the possibilities managed communities\noffer for PD. Managed communities have much to offer beyond mere generification\nwork for large-scale information systems, but we need to pay attention to core\nPD values that are in danger of being sidelined in the process.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:22:59 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Hochwarter", "Stefan", ""], ["Farshchian", "Babak A.", ""]]}, {"id": "2005.14050", "submitter": "Hanna Wallach", "authors": "Su Lin Blodgett and Solon Barocas and Hal Daum\\'e III and Hanna\n  Wallach", "title": "Language (Technology) is Power: A Critical Survey of \"Bias\" in NLP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey 146 papers analyzing \"bias\" in NLP systems, finding that their\nmotivations are often vague, inconsistent, and lacking in normative reasoning,\ndespite the fact that analyzing \"bias\" is an inherently normative process. We\nfurther find that these papers' proposed quantitative techniques for measuring\nor mitigating \"bias\" are poorly matched to their motivations and do not engage\nwith the relevant literature outside of NLP. Based on these findings, we\ndescribe the beginnings of a path forward by proposing three recommendations\nthat should guide work analyzing \"bias\" in NLP systems. These recommendations\nrest on a greater recognition of the relationships between language and social\nhierarchies, encouraging researchers and practitioners to articulate their\nconceptualizations of \"bias\"---i.e., what kinds of system behaviors are\nharmful, in what ways, to whom, and why, as well as the normative reasoning\nunderlying these statements---and to center work around the lived experiences\nof members of communities affected by NLP systems, while interrogating and\nreimagining the power relations between technologists and such communities.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:32:08 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 16:44:18 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Blodgett", "Su Lin", ""], ["Barocas", "Solon", ""], ["Daum\u00e9", "Hal", "III"], ["Wallach", "Hanna", ""]]}, {"id": "2005.14051", "submitter": "Istv\\'an Andr\\'as Seres", "authors": "Ferenc B\\'eres, Istv\\'an Andr\\'as Seres, Andr\\'as A. Bencz\\'ur,\n  Mikerah Quintyne-Collins", "title": "Blockchain is Watching You: Profiling and Deanonymizing Ethereum Users", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethereum is the largest public blockchain by usage. It applies an\naccount-based model, which is inferior to Bitcoin's unspent transaction output\nmodel from a privacy perspective. Due to its privacy shortcomings, recently\nseveral privacy-enhancing overlays have been deployed on Ethereum, such as\nnon-custodial, trustless coin mixers and confidential transactions. In our\nprivacy analysis of Ethereum's account-based model, we describe several\npatterns that characterize only a limited set of users and successfully apply\nthese quasi-identifiers in address deanonymization tasks. Using Ethereum Name\nService identifiers as ground truth information, we quantitatively compare\nalgorithms in recent branch of machine learning, the so-called graph\nrepresentation learning, as well as time-of-day activity and transaction fee\nbased user profiling techniques. As an application, we rigorously assess the\nprivacy guarantees of the Tornado Cash coin mixer by discovering strong\nheuristics to link the mixing parties. To the best of our knowledge, we are the\nfirst to propose and implement Ethereum user profiling techniques based on\nquasi-identifiers. Finally, we describe a malicious value-fingerprinting\nattack, a variant of the Danaan-gift attack, applicable for the confidential\ntransaction overlays on Ethereum. By incorporating user activity statistics\nfrom our data set, we estimate the success probability of such an attack.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 14:33:32 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 08:25:43 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["B\u00e9res", "Ferenc", ""], ["Seres", "Istv\u00e1n Andr\u00e1s", ""], ["Bencz\u00far", "Andr\u00e1s A.", ""], ["Quintyne-Collins", "Mikerah", ""]]}, {"id": "2005.14147", "submitter": "Alireza Vafaei Sadr", "authors": "M. Bahraminasr, A. Vafaei Sadr", "title": "IMDb data from Two Generations, from 1979 to 2019; Part one, Dataset\n  Introduction and Preliminary Analysis", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"IMDb\" as a user-regulating and one the most-visited portal has provided an\nopportunity to create an enormous database. Analysis of the information on\nInternet Movie Database - IMDb, either those related to the movie or provided\nby users would help to reveal the determinative factors in the route of success\nfor each movie. As the lack of a comprehensive dataset was felt, we determined\nto do create a compendious dataset for the later analysis using the statistical\nmethods and machine learning models; It comprises of various information\nprovided on IMDb such as rating data, genre, cast and crew, MPAA rating\ncertificate, parental guide details, related movie information, posters, etc,\nfor over 79k titles which is the largest dataset by this date. The present\npaper is the first paper in a series of papers aiming at the mentioned goals,\nby a description of the created dataset and a preliminary analysis including\nsome trend in data, demographic analysis of IMDb scores and their relation of\ngenre MPAA rating certificate has been investigated.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 17:01:06 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 10:01:14 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 21:30:25 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bahraminasr", "M.", ""], ["Sadr", "A. Vafaei", ""]]}, {"id": "2005.14212", "submitter": "Marc Bosch", "authors": "Ben Ortiz and Laura Kahn and Marc Bosch and Philip Bogden and Viveca\n  Pavon-Harr and Onur Savas and Ian McCulloh", "title": "Improving Community Resiliency and Emergency Response With Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New crisis response and management approaches that incorporate the latest\ninformation technologies are essential in all phases of emergency preparedness\nand response, including the planning, response, recovery, and assessment\nphases. Accurate and timely information is as crucial as is rapid and coherent\ncoordination among the responding organizations. We are working towards a\nmultipronged emergency response tool that provide stakeholders timely access to\ncomprehensive, relevant, and reliable information. The faster emergency\npersonnel are able to analyze, disseminate and act on key information, the more\neffective and timelier their response will be and the greater the benefit to\naffected populations. Our tool consists of encoding multiple layers of open\nsource geospatial data including flood risk location, road network strength,\ninundation maps that proxy inland flooding and computer vision semantic\nsegmentation for estimating flooded areas and damaged infrastructure. These\ndata layers are combined and used as input data for machine learning algorithms\nsuch as finding the best evacuation routes before, during and after an\nemergency or providing a list of available lodging for first responders in an\nimpacted area for first. Even though our system could be used in a number of\nuse cases where people are forced from one location to another, we demonstrate\nthe feasibility of our system for the use case of Hurricane Florence in\nLumberton, North Carolina.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:05:08 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Ortiz", "Ben", ""], ["Kahn", "Laura", ""], ["Bosch", "Marc", ""], ["Bogden", "Philip", ""], ["Pavon-Harr", "Viveca", ""], ["Savas", "Onur", ""], ["McCulloh", "Ian", ""]]}, {"id": "2005.14233", "submitter": "Stefan Hochwarter", "authors": "Stefan Hochwarter, Salla Atkins, Vinod K. Diwan, Nabil Zary", "title": "Use and Adaptation of Open Source Software for Capacity Building to\n  Strengthen Health Research in Low- and Middle-Income Countries", "comments": null, "journal-ref": "Informatics for Health: Connected Citizen-Led Wellness and\n  Population Health, 2017", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Health research capacity strengthening is of importance to reach health\ngoals. The ARCADE projects' aim was to strengthen health research across Africa\nand Asia using innovative educational technologies. In the four years of the EU\nfunded projects, challenges also of technical nature were identified. This\narticle reports on a study conducted within the ARCADE projects. The study\nfocused on addressing challenges of video conferencing in resource constrained\nsettings and was conducted using action research. As a result, a plugin for the\nopen source video conferencing system minisip was implemented and evaluated.\nThe study showed that both the audio and video streams could be improved by the\nintroduced plugin, which addressed one technical challenge.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 18:51:49 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Hochwarter", "Stefan", ""], ["Atkins", "Salla", ""], ["Diwan", "Vinod K.", ""], ["Zary", "Nabil", ""]]}, {"id": "2005.14248", "submitter": "Stefan Hochwarter", "authors": "Stefan Hochwarter, Do Duy Cuong, Nguyen Thi Kim Chuc, Mattias Larsson", "title": "Towards an Electronic Health Record System in Vietnam: A Core Readiness\n  Assessment", "comments": null, "journal-ref": "Journal of Health Informatics in Developing Countries, Vol 8, No 2\n  (2014)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have shown that health information technologies have a\npositive impact on health systems. Electronic health record (EHR) systems are\none of the most promising applications, demonstrating a positive effect in high\nincome countries. On the other hand, robust evidence for low and middle income\ncountries is still spare. The aim of this study is to initiate a carefully\nplanned nationwide EHR system in Vietnam by assessing the core readiness. The\nassessment structure is mainly based on previous research, which recommends a\nreadiness assessment prior to to an EHR system implementation. To collect data,\nparticipant observation, document analysis and an in-depth interview were used.\nThis study has revealed new insights into the current situation on EHR in\nVietnam. The Ministry of Health is currently working on improving the\nconditions for future implementation of a Vietnamese EHR system. There are\nissues with the current way of handling health records. These issues are\nencouraging the Ministry of Health to work on identifying the next steps for an\nEHR system implementation. The integration of an EHR system with current\nsystems seems to be challenging as most systems are commercial, closed source\nand very likely have no standardised interface. In conclusion, this study\nidentifies points which need to be further investigated prior to an\nimplementation. Generally, health care workers show good awareness of new\ntechnologies. As the Vietnam's health care system is centrally organised, there\nis the possibility for a nation-wide implementation. This could have a positive\nimpact on the health care system, however, besides rigours planning also\nstandards need to be followed and common interfaces implemented. Finally, this\nassessment has focused on only one level of readiness assessment. Further\nresearch is needed to complete the assessment.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 19:11:51 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Hochwarter", "Stefan", ""], ["Cuong", "Do Duy", ""], ["Chuc", "Nguyen Thi Kim", ""], ["Larsson", "Mattias", ""]]}, {"id": "2005.14517", "submitter": "Zahid Iqbal", "authors": "Affan Idrees, Zahid Iqbal, Maria Ishfaq", "title": "An Efficient Indoor Navigation Technique To Find Optimal Route For\n  Blinds Using QR Codes", "comments": "IEEE 10th Conference on Industrial Electronics and Applications\n  (ICIEA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind navigation is an accessibility application that enables blind to use an\nandroid Smartphone in an easy way for indoor navigation with instructions in\naudio form. We have proposed a prototype which is an indoor navigation\napplication for blinds that uses QR codes. It is developed for android Smart\nphones and does not require any additional hardware for navigation. It provides\nautomatic navigational assistance on pre-defined paths for blind. QR codes are\nplaced on the floor sections after specific distance that acts as an input for\ncurrent location detection and navigation. Whenever a QR code is scanned it\nprovides the user with the information of the current location and asks the\nuser to select the destination and then offers optimal and shortest path using\npath finding algorithms. During navigation whenever the deviation from the\nproposed path is detected it prompts the user and guides back to the right path\nby comparing the current path with the generated path. All of the instructions\nthroughout the application are provided in audio form to the user. The\ninterface of the application is well built for blinds which makes the smart\nphones user-friendly and useable for blind people. The user interacts with the\napplication through a specific set of user-friendly gestures for specific\ninputs and operations. At the end, we have performed comparison between\ndifferent state of art approaches and concluded that our approach is more user\nfriendly, cost effective and produced more accurate results.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 12:19:25 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Idrees", "Affan", ""], ["Iqbal", "Zahid", ""], ["Ishfaq", "Maria", ""]]}, {"id": "2005.14564", "submitter": "Manuel Sebastian Mariani", "authors": "Manuel S. Mariani, Linyuan L\\\"u", "title": "Network-based ranking in social systems: three challenges", "comments": "Perspective article. 9 pages, 3 figures", "journal-ref": "J. Phys. Complex. 1 011001 (2020)", "doi": "10.1088/2632-072X/ab8a61", "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking algorithms are pervasive in our increasingly digitized societies,\nwith important real-world applications including recommender systems, search\nengines, and influencer marketing practices. From a network science\nperspective, network-based ranking algorithms solve fundamental problems\nrelated to the identification of vital nodes for the stability and dynamics of\na complex system. Despite the ubiquitous and successful applications of these\nalgorithms, we argue that our understanding of their performance and their\napplications to real-world problems face three fundamental challenges: (i)\nRankings might be biased by various factors; (2) their effectiveness might be\nlimited to specific problems; and (3) agents' decisions driven by rankings\nmight result in potentially vicious feedback mechanisms and unhealthy systemic\nconsequences. Methods rooted in network science and agent-based modeling can\nhelp us to understand and overcome these challenges.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 13:27:30 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Mariani", "Manuel S.", ""], ["L\u00fc", "Linyuan", ""]]}, {"id": "2005.14658", "submitter": "Cristi\\'an Bravo", "authors": "Luisa Roa, Alejandro Correa-Bahnsen, Gabriel Suarez, Fernando\n  Cort\\'es-Tejada, Mar\\'ia A. Luque and Cristi\\'an Bravo", "title": "Super-App Behavioral Patterns in Credit Risk Models: Financial,\n  Statistical and Regulatory Implications", "comments": "Accepted - v2. 25 pages", "journal-ref": "Expert Systems with Applications: 114486 (2020)", "doi": "10.1016/j.eswa.2020.114486", "report-no": null, "categories": "q-fin.GN cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we present the impact of alternative data that originates from\nan app-based marketplace, in contrast to traditional bureau data, upon credit\nscoring models. These alternative data sources have shown themselves to be\nimmensely powerful in predicting borrower behavior in segments traditionally\nunderserved by banks and financial institutions. Our results, validated across\ntwo countries, show that these new sources of data are particularly useful for\npredicting financial behavior in low-wealth and young individuals, who are also\nthe most likely to engage with alternative lenders. Furthermore, using the\nTreeSHAP method for Stochastic Gradient Boosting interpretation, our results\nalso revealed interesting non-linear trends in the variables originating from\nthe app, which would not normally be available to traditional banks. Our\nresults represent an opportunity for technology companies to disrupt\ntraditional banking by correctly identifying alternative data sources and\nhandling this new information properly. At the same time alternative data must\nbe carefully validated to overcome regulatory hurdles across diverse\njurisdictions.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 01:32:03 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 18:51:22 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Roa", "Luisa", ""], ["Correa-Bahnsen", "Alejandro", ""], ["Suarez", "Gabriel", ""], ["Cort\u00e9s-Tejada", "Fernando", ""], ["Luque", "Mar\u00eda A.", ""], ["Bravo", "Cristi\u00e1n", ""]]}, {"id": "2005.14713", "submitter": "Ashudeep Singh", "authors": "Marco Morik, Ashudeep Singh, Jessica Hong, Thorsten Joachims", "title": "Controlling Fairness and Bias in Dynamic Learning-to-Rank", "comments": "First two authors contributed equally. In Proceedings of the 43rd\n  International ACM SIGIR Conference on Research and Development in Information\n  Retrieval 2020", "journal-ref": null, "doi": "10.1145/3397271.3401100", "report-no": null, "categories": "cs.IR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rankings are the primary interface through which many online platforms match\nusers to items (e.g. news, products, music, video). In these two-sided markets,\nnot only the users draw utility from the rankings, but the rankings also\ndetermine the utility (e.g. exposure, revenue) for the item providers (e.g.\npublishers, sellers, artists, studios). It has already been noted that\nmyopically optimizing utility to the users, as done by virtually all\nlearning-to-rank algorithms, can be unfair to the item providers. We,\ntherefore, present a learning-to-rank approach for explicitly enforcing\nmerit-based fairness guarantees to groups of items (e.g. articles by the same\npublisher, tracks by the same artist). In particular, we propose a learning\nalgorithm that ensures notions of amortized group fairness, while\nsimultaneously learning the ranking function from implicit feedback data. The\nalgorithm takes the form of a controller that integrates unbiased estimators\nfor both fairness and utility, dynamically adapting both as more data becomes\navailable. In addition to its rigorous theoretical foundation and convergence\nguarantees, we find empirically that the algorithm is highly practical and\nrobust.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 17:57:56 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Morik", "Marco", ""], ["Singh", "Ashudeep", ""], ["Hong", "Jessica", ""], ["Joachims", "Thorsten", ""]]}]