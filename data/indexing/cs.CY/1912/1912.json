[{"id": "1912.00176", "submitter": "Anton Kolonin Dr.", "authors": "Anton Kolonin", "title": "Generalized Reputation Computation Ontology and Temporal Graph\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of reliable democratic governance is important for survival of\nany community, and it will be more and critical over time communities with\nlevels of social connectivity in society rapidly increasing with speeds and\nscales of electronic communication. In order to face this challenge, different\nsorts of rating and reputation systems are being develop, however reputation\ngaming and manipulation in such systems appears to be serious problem. We are\nconsidering use of advanced reputation system supporting \"liquid democracy\"\nprinciple with generalized design and underlying ontology fitting different\nsorts of environments such as social networks, financial ecosystems and\nmarketplaces. The suggested system is based on \"weighted liquid rank\" algorithm\nemploying different sorts of explicit and implicit ratings being exchanged by\nmembers of the society. For the purpose, we suggest \"incremental reputation\"\ndesign and graph database used for implementation of the system. Finally, we\npresent evaluation of the system against real social network and financial\nblockchain data.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 10:24:28 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kolonin", "Anton", ""]]}, {"id": "1912.00237", "submitter": "Juana Moreno", "authors": "Fernando Alegre, John Underwoood, Juana Moreno, and Mario Alegre", "title": "Introduction to Computational Thinking: a new high school curriculum\n  using CodeWorld", "comments": "8 pages, accepted for publication in the SIGCSE 2020 Technical\n  Symposium program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Louisiana Department of Education partnered with the Gordon A. Cain\nCenter at LSU to pilot a Computing High School Graduation Pathway. The first\ncourse in the pathway, Introduction to Computational Thinking (ICT), is\ndesigned to teach programming and reinforce mathematical practice skills of\nnine-grade students, with an emphasis on promoting higher order thinking. In\n2017-18, about 200 students and five teachers participated in the pilot, in\n2018-2019 the participation increased to 400 students, and in the current\n2019-2020 year about 800 students in 11 schools are involved. Professional\ndevelopment starts with a five-week intensive summer institute, which is\ncomplemented with follow-up Saturday sessions and coaching support during the\nacademic year. After describing the course content and briefly the teacher\ntraining, we discuss the data we have collected in the last two years. The\noverall student reception of the course has been positive, but the course was\ncategorized by most students as hard. However, the Computing Attitude Survey\nanalysis indicates that the difficulty of the course did not demotivate the\nstudents. The pre-post test content assessments show that students learned not\nonly the language, but also general principles of programming, logic and\nmodeling, as well as use of variables, expressions and functions. Lessons\nlearned during the pilot phase motivated changes, such as emphasizing during PD\nthe need to provide timely feedback to students, provide detailed rubrics for\nthe projects and reorganize the lessons to increase the initial engagement with\nthe material. After two years of running pilots, the course is becoming\nstudent-centered, where most of the code and image samples provided in the\nlessons are based on code created by previous students.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 17:07:04 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Alegre", "Fernando", ""], ["Underwoood", "John", ""], ["Moreno", "Juana", ""], ["Alegre", "Mario", ""]]}, {"id": "1912.00648", "submitter": "Claudio Gambella", "authors": "Claudio Gambella, Julien Monteil, Anton Dekusar, Sergio Cabrero\n  Barros, Andrea Simonetto, and Yassine Lassoued", "title": "A city-scale IoT-enabled ridesharing platform", "comments": null, "journal-ref": "Transportation Letters, 1-7, 2019", "doi": "10.1080/19427867.2019.1694206", "report-no": null, "categories": "cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of on-demand mobility systems is expected to have a tremendous\npotential on the wellness of transportation users in cities. Yet such positive\neffects are reached when the systems under consideration enable seamless\nintegration between data sources that involve a high number of transportation\nactors. In this paper we report on the effort of designing and deploying an\nintegrated system, including algorithms and platforms, that can operate in\ncities, in an Internet of Things (IoT)-aware fashion. The system was evaluated\nby enabling/disabling the IoT components of the system, highlighting the\nnecessity of real-time data integration for efficient mobility services.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 09:29:56 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Gambella", "Claudio", ""], ["Monteil", "Julien", ""], ["Dekusar", "Anton", ""], ["Barros", "Sergio Cabrero", ""], ["Simonetto", "Andrea", ""], ["Lassoued", "Yassine", ""]]}, {"id": "1912.00651", "submitter": "Malte Bonart", "authors": "Malte Bonart and Anastasiia Samokhina and Gernot Heisenberg and\n  Philipp Schaer", "title": "An Investigation of Biases in Web Search Engine Query Suggestions", "comments": "Preprint, Online Information Review, accepted for publication on\n  27-Sep-2019. This work is licensed under a Creative Commons\n  Attribution-NonCommercial 4.0 International License. Any reuse is allowed in\n  accordance with the terms outlined by the licence. For commercial purposes,\n  permission should be sought by contacting permissions@emeraldinsight.com", "journal-ref": null, "doi": "10.1108/OIR-11-2018-0341", "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Survey-based studies suggest that search engines are trusted more than social\nmedia or even traditional news, although cases of false information or\ndefamation are known. In this study, we analyze query suggestion features of\nthree search engines to see if these features introduce some bias into the\nquery and search process that might compromise this trust. We test our approach\non person-related search suggestions by querying the names of politicians from\nthe German Bundestag before the German federal election of 2017.\n  This study introduces a framework to systematically examine and automatically\nanalyze the varieties in different query suggestions for person names offered\nby major search engines. To test our framework, we collected data from the\nGoogle, Bing, and DuckDuckGo query suggestion APIs over a period of four months\nfor 629 different names of German politicians. The suggestions were clustered\nand statistically analyzed with regards to different biases, like gender,\nparty, or age and with regards to the stability of the suggestions over time.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 09:40:33 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Bonart", "Malte", ""], ["Samokhina", "Anastasiia", ""], ["Heisenberg", "Gernot", ""], ["Schaer", "Philipp", ""]]}, {"id": "1912.00690", "submitter": "Benjamin Clavi\\'e", "authors": "Benjamin Clavi\\'e and Kobi Gal", "title": "EduBERT: Pretrained Deep Language Models for Learning Analytics", "comments": "Accepted for poster presentation at the 10th International Learning\n  Analytics and Knowledge (LAK20) Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of large pretrained neural networks to create contextualized word\nembeddings has drastically improved performance on several natural language\nprocessing (NLP) tasks. These computationally expensive models have begun to be\napplied to domain-specific NLP tasks such as re-hospitalization prediction from\nclinical notes. This paper demonstrates that using large pretrained models\nproduces excellent results on common learning analytics tasks. Pre-training\ndeep language models using student forum data from a wide array of online\ncourses improves performance beyond the state of the art on three text\nclassification tasks. We also show that a smaller, distilled version of our\nmodel produces the best results on two of the three tasks while limiting\ncomputational cost. We make both models available to the research community at\nlarge.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:32:53 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Clavi\u00e9", "Benjamin", ""], ["Gal", "Kobi", ""]]}, {"id": "1912.00731", "submitter": "James Pavur", "authors": "James Pavur and Casey Knerr", "title": "GDPArrrrr: Using Privacy Laws to Steal Identities", "comments": "Associated With the Black Hat USA 2019 Briefing \"GDPArrrrr: Using\n  Privacy Laws to Steal Identities\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The General Data Protection Regulation (GDPR) has become a touchstone model\nfor modern privacy law, in part because it empowers consumers with\nunprecedented control over the use of their personal information. However, this\nsame power may be susceptible to abuse by malicious attackers. In this paper,\nwe consider how legal ambiguity surrounding the \"Right of Access\" process may\nbe abused by social engineers. This hypothesis is tested through an adversarial\ncase study of more than 150 businesses. We find that many organizations fail to\nemploy adequate safeguards against Right of Access abuse and thus risk exposing\nsensitive information to unauthorized third parties. This information varied in\nsensitivity from simple public records to Social Security Numbers and account\npasswords. These findings suggest a critical need to improve the implementation\nof the subject access request process. To this end, we propose possible\nremediations which may be appropriate for further consideration by government,\nindustry and individuals.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 12:58:06 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Pavur", "James", ""], ["Knerr", "Casey", ""]]}, {"id": "1912.00747", "submitter": "Ross Gruetzemacher", "authors": "Ross Gruetzemacher, Jess Whittlestone", "title": "The Transformative Potential of Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the concept of transformative AI (TAI) has begun to receive\nattention in the AI policy space. TAI is often framed as an alternative\nformulation to notions of strong AI (e.g. artificial general intelligence or\nsuperintelligence) and reflects increasing consensus that advanced AI which\ndoes not fit these definitions may nonetheless have extreme and long-lasting\nimpacts on society. However, the term TAI is poorly defined and often used\nambiguously. Some use the notion of TAI to describe levels of societal\ntransformation associated with previous 'general purpose technologies' (GPTs)\nsuch as electricity or the internal combustion engine. Others use the term to\nrefer to more drastic levels of transformation comparable to the agricultural\nor industrial revolutions. The notion has also been used much more loosely,\nwith some implying that current AI systems are already having a transformative\nimpact on society. This paper unpacks and analyses the notion of TAI, proposing\na distinction between narrowly transformative AI (NTAI), TAI and radically\ntransformative AI (RTAI), roughly corresponding to associated levels of\nsocietal change. We describe some relevant dimensions associated with each and\ndiscuss what kinds of advances in capabilities they might require. We further\nconsider the relationship between TAI and RTAI and whether we should\nnecessarily expect a period of TAI to precede the emergence of RTAI. This\nanalysis is important as it can help guide discussions among AI policy\nresearchers about how to allocate resources towards mitigating the most extreme\nimpacts of AI and it can bring attention to negative TAI scenarios that are\ncurrently neglected.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 09:37:58 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 14:09:15 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Gruetzemacher", "Ross", ""], ["Whittlestone", "Jess", ""]]}, {"id": "1912.00750", "submitter": "Mansaf Alam Dr", "authors": "Manzoor Ansari, Syed Arshad Ali, Mansaf Alam", "title": "A Synergistic Approach for Internet of Things and Cloud Integration:\n  Current Research and Future Direction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing and Internet of Things have independently changed the course\nof technological development. The use of a synergistic approach that\namalgamates the benefits of both these path breaking technologies into a single\npackage is expected to have flourishing benefits. However, such an integration\nis faced with numerous limitations and challenges. This paper surveys the\ndifferent aspects of each of these technologies and explores the possibilities,\nbenefits, limitations and challenges that rise from the development of a\nconvergent approach. We have also investigated the current research and future\ndirection.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 13:05:26 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ansari", "Manzoor", ""], ["Ali", "Syed Arshad", ""], ["Alam", "Mansaf", ""]]}, {"id": "1912.00757", "submitter": "Nicholas Vincent", "authors": "Nicholas Vincent, Yichun Li, Renee Zha, Brent Hecht", "title": "Mapping the Potential and Pitfalls of \"Data Dividends\" as a Means of\n  Sharing the Profits of Artificial Intelligence", "comments": "This is a working draft. It has not been peer-reviewed and is\n  intended for internal discussion in the computing community", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying strategies to more broadly distribute the economic winnings of AI\ntechnologies is a growing priority in HCI and other fields. One idea gaining\nprominence centers on \"data dividends\", or sharing the profits of AI\ntechnologies with the people who generated the data on which these technologies\nrely. Despite the rapidly growing discussion around data dividends - including\nbacking by prominent politicians - there exists little guidance about how data\ndividends might be designed and little information about if they will work. In\nthis paper, we begin the process of developing a concrete design space for data\ndividends. We additionally simulate the effects of a variety of important\ndesign decisions using well-known datasets and algorithms. We find that\nseemingly innocuous decisions can create counterproductive effects, e.g.\nseverely concentrated dividends and demographic disparities. Overall, the\noutcomes we observe -- both desirable and undesirable -- highlight the need for\ndividend implementers to make design decisions cautiously.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 01:54:47 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Vincent", "Nicholas", ""], ["Li", "Yichun", ""], ["Zha", "Renee", ""], ["Hecht", "Brent", ""]]}, {"id": "1912.00761", "submitter": "Alice Xiang", "authors": "Alice Xiang and Inioluwa Deborah Raji", "title": "On the Legal Compatibility of Fairness Definitions", "comments": "6 pages, Workshop on Human-Centric Machine Learning at the 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Past literature has been effective in demonstrating ideological gaps in\nmachine learning (ML) fairness definitions when considering their use in\ncomplex socio-technical systems. However, we go further to demonstrate that\nthese definitions often misunderstand the legal concepts from which they\npurport to be inspired, and consequently inappropriately co-opt legal language.\nIn this paper, we demonstrate examples of this misalignment and discuss the\ndifferences in ML terminology and their legal counterparts, as well as what\nboth the legal and ML fairness communities can learn from these tensions. We\nfocus this paper on U.S. anti-discrimination law since the ML fairness research\ncommunity regularly references terms from this body of law.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 21:28:46 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Xiang", "Alice", ""], ["Raji", "Inioluwa Deborah", ""]]}, {"id": "1912.00782", "submitter": "Ehsan Toreini", "authors": "Ehsan Toreini, Mhairi Aitken, Kovila Coopamootoo, Karen Elliott,\n  Carlos Gonzalez Zelaya, Aad van Moorsel", "title": "The relationship between trust in AI and trustworthy machine learning\n  technologies", "comments": "This submission has been accepted in ACM FAT* 2020 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build AI-based systems that users and the public can justifiably trust one\nneeds to understand how machine learning technologies impact trust put in these\nservices. To guide technology developments, this paper provides a systematic\napproach to relate social science concepts of trust with the technologies used\nin AI-based services and products. We conceive trust as discussed in the ABI\n(Ability, Benevolence, Integrity) framework and use a recently proposed mapping\nof ABI on qualities of technologies. We consider four categories of machine\nlearning technologies, namely these for Fairness, Explainability, Auditability\nand Safety (FEAS) and discuss if and how these possess the required qualities.\nTrust can be impacted throughout the life cycle of AI-based systems, and we\nintroduce the concept of Chain of Trust to discuss technological needs for\ntrust in different stages of the life cycle. FEAS has obvious relations with\nknown frameworks and therefore we relate FEAS to a variety of international\nPrincipled AI policy and technology frameworks that have emerged in recent\nyears.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:36:13 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 11:59:43 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Toreini", "Ehsan", ""], ["Aitken", "Mhairi", ""], ["Coopamootoo", "Kovila", ""], ["Elliott", "Karen", ""], ["Zelaya", "Carlos Gonzalez", ""], ["van Moorsel", "Aad", ""]]}, {"id": "1912.00783", "submitter": "Valentin Robu PhD", "authors": "Valentin Robu, David Flynn, Merlinda Andoni, Maizura Mokhtar", "title": "Consider ethical and social challenges in smart grid research", "comments": "Preprint of paper published in Nature Machine Intelligence, vol. 1\n  (25 Nov. 2019)", "journal-ref": "Nature Machine Intelligence, vol. 1, 25 November 2019", "doi": "10.1038/s42256-019-0120-6", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence and Machine Learning are increasingly seen as key\ntechnologies for building more decentralised and resilient energy grids, but\nresearchers must consider the ethical and social implications of their use\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 11:06:09 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Robu", "Valentin", ""], ["Flynn", "David", ""], ["Andoni", "Merlinda", ""], ["Mokhtar", "Maizura", ""]]}, {"id": "1912.00893", "submitter": "Luis Guillermo Natera Orozco", "authors": "Luis Natera, D\\'avid Deritei, Anna Vancs\\'o, Orsolya V\\'as\\'arhelyi", "title": "Quantifying Life Quality as Walkability on Urban Networks: The Case of\n  Budapest", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": "10.1007/978-3-030-36683-4_72", "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Life quality in cities is deeply related to the mobility options, and how\neasily one can access different services and attractions. The pedestrian\ninfrastructure network provides the backbone for social life in cities. While\nthere are many approaches to quantify life quality, most do not take\nspecifically into account the walkability of the city, and rather offer a\ncity-wide measure. Here we develop a data-driven, network-based method to\nquantify the liveability of a city. We introduce a life quality index (LQI)\nbased on pedestrian accessibility to amenities and services, safety and\nenvironmental variables. Our computational approach outlines novel ways to\nmeasure life quality in a more granular scale, that can become valuable for\nurban planners, city officials and stakeholders. We apply data-driven methods\nto Budapest, but as having an emphasis on the online and easily available\nquantitative data, the methods can be generalized and applied to any city.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 16:18:39 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 08:56:54 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Natera", "Luis", ""], ["Deritei", "D\u00e1vid", ""], ["Vancs\u00f3", "Anna", ""], ["V\u00e1s\u00e1rhelyi", "Orsolya", ""]]}, {"id": "1912.01077", "submitter": "Nicholas R. J. Frick", "authors": "Nicholas R. J. Frick, Felix Br\\\"unker, Bj\\\"orn Ross, Stefan Stieglitz", "title": "Towards Successful Collaboration: Design Guidelines for AI-based\n  Services enriching Information Systems in Organisations", "comments": "Proceedings of the 30th Australasian Conference on Information\n  Systems (ACIS), Fremantle, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information systems (IS) are widely used in organisations to improve business\nperformance. The steady progression in improving technologies like artificial\nintelligence (AI) and the need of securing future success of organisations lead\nto new requirements for IS. This research in progress firstly introduces the\nterm AI-based services (AIBS) describing AI as a component enriching IS aiming\nat collaborating with employees and assisting in the execution of work-related\ntasks. The study derives requirements from ten expert interviews to successful\ndesign AIBS following Design Science Research (DSR). For a successful\ndeployment of AIBS in organisations the D&M IS Success Model will be considered\nto validated requirements within three major dimensions of quality: Information\nQuality, System Quality, and Service Quality. Amongst others, preliminary\nfindings propose that AIBS must be preferably authentic. Further discussion and\nresearch on AIBS is forced, thus, providing first insights on the deployment of\nAIBS in organisations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 21:16:16 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Frick", "Nicholas R. J.", ""], ["Br\u00fcnker", "Felix", ""], ["Ross", "Bj\u00f6rn", ""], ["Stieglitz", "Stefan", ""]]}, {"id": "1912.01115", "submitter": "Karol Chlasta", "authors": "Karol Chlasta, Krzysztof Wo{\\l}k, Izabela Krejtz", "title": "Automated speech-based screening of depression using deep convolutional\n  neural networks", "comments": "10 pages, 8 figures and 2 tables, HCist 2019 - 8th International\n  Conference on Health and Social Care Information Systems and Technologies\n  (16-18 October 2019, Sousse, Tunisia)", "journal-ref": "Procedia Computer Science 164 (2019) 618-628", "doi": "10.1016/j.procs.2019.12.228", "report-no": null, "categories": "cs.LG cs.CV cs.CY cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection and treatment of depression is essential in promoting\nremission, preventing relapse, and reducing the emotional burden of the\ndisease. Current diagnoses are primarily subjective, inconsistent across\nprofessionals, and expensive for individuals who may be in urgent need of help.\nThis paper proposes a novel approach to automated depression detection in\nspeech using convolutional neural network (CNN) and multipart interactive\ntraining. The model was tested using 2568 voice samples obtained from 77\nnon-depressed and 30 depressed individuals. In experiment conducted, data were\napplied to residual CNNs in the form of spectrograms, images auto-generated\nfrom audio samples. The experimental results obtained using different ResNet\narchitectures gave a promising baseline accuracy reaching 77%.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 22:58:40 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Chlasta", "Karol", ""], ["Wo\u0142k", "Krzysztof", ""], ["Krejtz", "Izabela", ""]]}, {"id": "1912.01252", "submitter": "Sven Banisch", "authors": "Tom Willaert, Sven Banisch, Paul Van Eecke, Katrien Beuls", "title": "Facilitating on-line opinion dynamics by mining expressions of\n  causation. The case of climate change debates on The Guardian", "comments": "This project has received funding from the European Union's Horizon\n  2020 research and innovation programme under grant agreement No 732942\n  (Opinion Dynamics and Cultural Conflict in European Spaces --\n  www.Odycceus.eu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News website comment sections are spaces where potentially conflicting\nopinions and beliefs are voiced. Addressing questions of how to study such\ncultural and societal conflicts through technological means, the present\narticle critically examines possibilities and limitations of machine-guided\nexploration and potential facilitation of on-line opinion dynamics. These\ninvestigations are guided by a discussion of an experimental observatory for\nmining and analyzing opinions from climate change-related user comments on news\narticles from the TheGuardian.com. This observatory combines causal mapping\nmethods with computational text analysis in order to mine beliefs and visualize\nopinion landscapes based on expressions of causation. By (1) introducing\ndigital methods and open infrastructures for data exploration and analysis and\n(2) engaging in debates about the implications of such methods and\ninfrastructures, notably in terms of the leap from opinion observation to\ndebate facilitation, the article aims to make a practical and theoretical\ncontribution to the study of opinion dynamics and conflict in new media\nenvironments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 09:20:41 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Willaert", "Tom", ""], ["Banisch", "Sven", ""], ["Van Eecke", "Paul", ""], ["Beuls", "Katrien", ""]]}, {"id": "1912.01499", "submitter": "Prabin Sharma", "authors": "Prabin Sharma, Sambad Bidari, Kisan Thapa, Antonio Valente, Hugo\n  Paredes", "title": "Towards blind user's indoor navigation: a comparative study of beacons\n  and decawave for indoor accurate location", "comments": "5 Pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many systems for indoor navigation specially built for visually\nimpaired people but only some has good accuracy for navigation. While there are\nsolutions like global navigation satellite systems for the localization\noutdoors, problems arise in urban scenarios and indoors due to insufficient or\nfailed signal reception. To build a support system for navigation for visually\nimpaired people, in this paper we present a comparison of indoor localization\nand navigation system, which performs continuous and real-time processing using\ncommercially available systems (Beacons and Decawave) under the same\nexperimental condition for the performance analysis. Error is calculated and\nanalyzed using Euclidean distance and standard deviation for both the cases. We\nused Navigine Platform for this navigation system which allows both\nTri-lateration as well as Fingerprinting algorithms. For calculating location\nwe have used the concept of Time of Arrival and time of difference of arrivals.\nTaking into concern about the blind people, location is important as well as\naccuracy is necessity because small measurement in the walk is important to\nthem. With this concern, in this paper, we are showing the comparative study of\nbeacons and Decawave. The study and the accuracy tests of those systems for the\nblind people/user's in navigating indoor are presented in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 11:30:32 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 11:24:31 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Sharma", "Prabin", ""], ["Bidari", "Sambad", ""], ["Thapa", "Kisan", ""], ["Valente", "Antonio", ""], ["Paredes", "Hugo", ""]]}, {"id": "1912.01501", "submitter": "Andreas Kamilaris", "authors": "Carlos Granell, Andreas Kamilaris, Alexander Kotsev, Frank O.\n  Ostermann and Sergio Trilles", "title": "Internet of Things in Geospatial Analytics", "comments": "Book chapter at the Manual of Digital Earth Book, ISDE, September\n  2019, Editors: Huadong Guo, Michael F. Goodchild and Alessandro Annoni,\n  (Publisher: Springer, Singapore)", "journal-ref": null, "doi": "10.1007/978-981-32-9915-3", "report-no": null, "categories": "eess.SP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Earth was born with the aim of replicating the real world within the\ndigital world. Many efforts have been made to observe and sense the Earth, both\nfrom space and by using in situ sensors. Focusing on the latter, advances in\nDigital Earth have established vital bridges to exploit these sensors and their\nnetworks by taking location as a key element. The current era of connectivity\nenvisions that everything is connected to everything. The concept of the\nInternet of Things emerged as a holistic proposal to enable an ecosystem of\nvaried, heterogeneous networked objects and devices to speak and interact with\neach other. To make the IoT ecosystem a reality, it is necessary to understand\nthe electronic components, communication protocols, real-time analysis\ntechniques, and the location of the objects and devices. The IoT ecosystem and\nthe Digital Earth jointly form interrelated infrastructures for addressing\nmodern pressing issues and complex challenges. In this chapter, we explore the\nsynergies and frictions in establishing an efficient and permanent\ncollaboration between the two infrastructures, in order to adequately address\nmultidisciplinary and increasingly complex real-world problems. Although there\nare still some pending issues, the identified synergies generate optimism for a\ntrue collaboration between the Internet of Things and the Digital Earth.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 19:09:03 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Granell", "Carlos", ""], ["Kamilaris", "Andreas", ""], ["Kotsev", "Alexander", ""], ["Ostermann", "Frank O.", ""], ["Trilles", "Sergio", ""]]}, {"id": "1912.01842", "submitter": "Aythami Morales", "authors": "Ignacio Serna, Aythami Morales, Julian Fierrez, Manuel Cebrian, Nick\n  Obradovich, Iyad Rahwan", "title": "Algorithmic Discrimination: Formulation and Exploration in Deep\n  Learning-based Face Biometrics", "comments": null, "journal-ref": "AAAI Workshop on Artificial Intelligence Safety (SafeAI), New\n  York, NY, USA, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most popular face recognition benchmarks assume a distribution of\nsubjects without much attention to their demographic attributes. In this work,\nwe perform a comprehensive discrimination-aware experimentation of deep\nlearning-based face recognition. The main aim of this study is focused on a\nbetter understanding of the feature space generated by deep models, and the\nperformance achieved over different demographic groups. We also propose a\ngeneral formulation of algorithmic discrimination with application to face\nbiometrics. The experiments are conducted over the new DiveFace database\ncomposed of 24K identities from six different demographic groups. Two popular\nface recognition models are considered in the experimental framework: ResNet-50\nand VGG-Face. We experimentally show that demographic groups highly represented\nin popular face databases have led to popular pre-trained deep face models\npresenting strong algorithmic discrimination. That discrimination can be\nobserved both qualitatively at the feature space of the deep models and\nquantitatively in large performance differences when applying those models in\ndifferent demographic groups, e.g. for face biometrics.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 08:08:28 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Serna", "Ignacio", ""], ["Morales", "Aythami", ""], ["Fierrez", "Julian", ""], ["Cebrian", "Manuel", ""], ["Obradovich", "Nick", ""], ["Rahwan", "Iyad", ""]]}, {"id": "1912.02182", "submitter": "Maurizio Tesconi", "authors": "Marco Avvenuti, Salvatore Bellomo, Stefano Cresci, Leonardo Nizzoli,\n  Maurizio Tesconi", "title": "Towards better social crisis data with HERMES: Hybrid sensing for\n  EmeRgency ManagEment System", "comments": null, "journal-ref": "Pervasive and Mobile Computing 67, 2020", "doi": "10.1016/j.pmcj.2020.101225", "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People involved in mass emergencies increasingly publish information-rich\ncontents in online social networks (OSNs), thus acting as a distributed and\nresilient network of human sensors. In this work, we present HERMES, a system\ndesigned to enrich the information spontaneously disclosed by OSN users in the\naftermath of disasters. HERMES leverages a mixed data collection strategy,\ncalled hybrid crowdsensing, and state-of-the-art AI techniques. Evaluated in\nreal-world emergencies, HERMES proved to increase: (i) the amount of the\navailable damage information; (ii) the density (up to 7x) and the variety (up\nto 18x) of the retrieved geographic information; (iii) the geographic coverage\n(up to 30%) and granularity.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 14:25:52 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Avvenuti", "Marco", ""], ["Bellomo", "Salvatore", ""], ["Cresci", "Stefano", ""], ["Nizzoli", "Leonardo", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1912.02499", "submitter": "Caterina Urban", "authors": "Caterina Urban, Maria Christakis, Valentin W\\\"ustholz, Fuyuan Zhang", "title": "Perfectly Parallel Fairness Certification of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.CY cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is growing concern that machine-learning models, which\ncurrently assist or even automate decision making, reproduce, and in the worst\ncase reinforce, bias of the training data. The development of tools and\ntechniques for certifying fairness of these models or describing their biased\nbehavior is, therefore, critical. In this paper, we propose a perfectly\nparallel static analysis for certifying causal fairness of feed-forward neural\nnetworks used for classification of tabular data. When certification succeeds,\nour approach provides definite guarantees, otherwise, it describes and\nquantifies the biased behavior. We design the analysis to be sound, in practice\nalso exact, and configurable in terms of scalability and precision, thereby\nenabling pay-as-you-go certification. We implement our approach in an\nopen-source tool and demonstrate its effectiveness on models trained with\npopular datasets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 10:59:28 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 13:31:02 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Urban", "Caterina", ""], ["Christakis", "Maria", ""], ["W\u00fcstholz", "Valentin", ""], ["Zhang", "Fuyuan", ""]]}, {"id": "1912.02629", "submitter": "Marieh Alaghband", "authors": "Niloofar Yousefi, Marie Alaghband, Ivan Garibay", "title": "A Comprehensive Survey on Machine Learning Techniques and User\n  Authentication Approaches for Credit Card Fraud Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase of credit card usage, the volume of credit card misuse also\nhas significantly increased. As a result, financial organizations are working\nhard on developing and deploying credit card fraud detection methods, in order\nto adapt to ever-evolving, increasingly sophisticated defrauding strategies and\nidentifying illicit transactions as quickly as possible to protect themselves\nand their customers. Compounding on the complex nature of such adverse\nstrategies, credit card fraudulent activities are rare events compared to the\nnumber of legitimate transactions. Hence, the challenge to develop fraud\ndetection that are accurate and efficient is substantially intensified and, as\na consequence, credit card fraud detection has lately become a very active area\nof research. In this work, we provide a survey of current techniques most\nrelevant to the problem of credit card fraud detection. We carry out our survey\nin two main parts. In the first part,we focus on studies utilizing classical\nmachine learning models, which mostly employ traditional transnational features\nto make fraud predictions. These models typically rely on some static physical\ncharacteristics, such as what the user knows (knowledge-based method), or what\nhe/she has access to (object-based method). In the second part of our survey,\nwe review more advanced techniques of user authentication, which use behavioral\nbiometrics to identify an individual based on his/her unique behavior while\nhe/she is interacting with his/her electronic devices. These approaches rely on\nhow people behave (instead of what they do), which cannot be easily forged. By\nproviding an overview of current approaches and the results reported in the\nliterature, this survey aims to drive the future research agenda for the\ncommunity in order to develop more accurate, reliable and scalable models of\ncredit card fraud detection.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 21:40:39 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Yousefi", "Niloofar", ""], ["Alaghband", "Marie", ""], ["Garibay", "Ivan", ""]]}, {"id": "1912.02675", "submitter": "Justin Weisz", "authors": "Maryam Ashoori and Justin D. Weisz", "title": "In AI We Trust? Factors That Influence Trustworthiness of AI-infused\n  Decision-Making Processes", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many decision-making processes have begun to incorporate an AI element,\nincluding prison sentence recommendations, college admissions, hiring, and\nmortgage approval. In all of these cases, AI models are being trained to help\nhuman decision makers reach accurate and fair judgments, but little is known\nabout what factors influence the extent to which people consider an AI-infused\ndecision-making process to be trustworthy. We aim to understand how different\nfactors about a decision-making process, and an AI model that supports that\nprocess, influences peoples' perceptions of the trustworthiness of that\nprocess. We report on our evaluation of how seven different factors -- decision\nstakes, decision authority, model trainer, model interpretability, social\ntransparency, and model confidence -- influence ratings of trust in a\nscenario-based study.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 16:02:02 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Ashoori", "Maryam", ""], ["Weisz", "Justin D.", ""]]}, {"id": "1912.02852", "submitter": "Felipe Gonz\\'alez", "authors": "Felipe Gonz\\'alez, Andrea Figueroa, Claudia L\\'opez, Cecilia Arag\\'on", "title": "Information Privacy Opinions on Twitter: A Cross-Language Study", "comments": "Proceeding CSCW '19: Conference Companion Publication of the 2019 on\n  Computer Supported Cooperative Work and Social Computing", "journal-ref": null, "doi": "10.1145/3311957.3359501", "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cambridge Analytica scandal triggered a conversation on Twitter about\ndata practices and their implications. Our research proposes to leverage this\nconversation to extend the understanding of how information privacy is framed\nby users worldwide. We collected tweets about the scandal written in Spanish\nand English between April and July 2018. We created a word embedding to create\na reduced multi-dimensional representation of the tweets in each language. For\neach embedding, we conducted open coding to characterize the semantic contexts\nof key concepts: \"information\", \"privacy\", \"company\" and \"users\" (and their\nSpanish translations). Through a comparative analysis, we found a broader\nemphasis on privacy-related words associated with companies in English. We also\nidentified more terms related to data collection in English and fewer\nassociated with security mechanisms, control, and risks. Our findings hint at\nthe potential of cross-language comparisons of text to extend the understanding\nof worldwide differences in information privacy perspectives.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 19:45:30 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Gonz\u00e1lez", "Felipe", ""], ["Figueroa", "Andrea", ""], ["L\u00f3pez", "Claudia", ""], ["Arag\u00f3n", "Cecilia", ""]]}, {"id": "1912.02943", "submitter": "P. M. Krafft", "authors": "Michael Katell, Meg Young, Bernease Herman, Dharma Dailey, Aaron Tam,\n  Vivian Guetler, Corinne Binz, Daniella Raz, P. M. Krafft", "title": "An Algorithmic Equity Toolkit for Technology Audits by Community\n  Advocates and Activists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wave of recent scholarship documenting the discriminatory harms of\nalgorithmic systems has spurred widespread interest in algorithmic\naccountability and regulation. Yet effective accountability and regulation is\nstymied by a persistent lack of resources supporting public understanding of\nalgorithms and artificial intelligence. Through interactions with a US-based\ncivil rights organization and their coalition of community organizations, we\nidentify a need for (i) heuristics that aid stakeholders in distinguishing\nbetween types of analytic and information systems in lay language, and (ii)\nrisk assessment tools for such systems that begin by making algorithms more\nlegible. The present work delivers a toolkit to achieve these aims. This paper\nboth presents the Algorithmic Equity Toolkit (AEKit) Equity as an artifact, and\ndetails how our participatory process shaped its design. Our work fits within\nhuman-computer interaction scholarship as a demonstration of the value of HCI\nmethods and approaches to problems in the area of algorithmic transparency and\naccountability.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 01:32:16 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Katell", "Michael", ""], ["Young", "Meg", ""], ["Herman", "Bernease", ""], ["Dailey", "Dharma", ""], ["Tam", "Aaron", ""], ["Guetler", "Vivian", ""], ["Binz", "Corinne", ""], ["Raz", "Daniella", ""], ["Krafft", "P. M.", ""]]}, {"id": "1912.03072", "submitter": "Youngnam Lee", "authors": "Youngduck Choi, Youngnam Lee, Dongmin Shin, Junghyun Cho, Seoyon Park,\n  Seewoo Lee, Jineon Baek, Chan Bae, Byungsoo Kim, Jaewe Heo", "title": "EdNet: A Large-Scale Hierarchical Dataset in Education", "comments": "AIED 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With advances in Artificial Intelligence in Education (AIEd) and the\never-growing scale of Interactive Educational Systems (IESs), data-driven\napproach has become a common recipe for various tasks such as knowledge tracing\nand learning path recommendation. Unfortunately, collecting real students'\ninteraction data is often challenging, which results in the lack of public\nlarge-scale benchmark dataset reflecting a wide variety of student behaviors in\nmodern IESs. Although several datasets, such as ASSISTments, Junyi Academy,\nSynthetic and STATICS, are publicly available and widely used, they are not\nlarge enough to leverage the full potential of state-of-the-art data-driven\nmodels and limits the recorded behaviors to question-solving activities. To\nthis end, we introduce EdNet, a large-scale hierarchical dataset of diverse\nstudent activities collected by Santa, a multi-platform self-study solution\nequipped with artificial intelligence tutoring system. EdNet contains\n131,441,538 interactions from 784,309 students collected over more than 2\nyears, which is the largest among the ITS datasets released to the public so\nfar. Unlike existing datasets, EdNet provides a wide variety of student actions\nranging from question-solving to lecture consumption and item purchasing. Also,\nEdNet has a hierarchical structure where the student actions are divided into 4\ndifferent levels of abstractions. The features of EdNet are domain-agnostic,\nallowing EdNet to be extended to different domains easily. The dataset is\npublicly released under Creative Commons Attribution-NonCommercial 4.0\nInternational license for research purposes. We plan to host challenges in\nmultiple AIEd tasks with EdNet to provide a common ground for the fair\ncomparison between different state of the art models and encourage the\ndevelopment of practical and effective methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 11:46:18 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 09:03:18 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 10:09:08 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Choi", "Youngduck", ""], ["Lee", "Youngnam", ""], ["Shin", "Dongmin", ""], ["Cho", "Junghyun", ""], ["Park", "Seoyon", ""], ["Lee", "Seewoo", ""], ["Baek", "Jineon", ""], ["Bae", "Chan", ""], ["Kim", "Byungsoo", ""], ["Heo", "Jaewe", ""]]}, {"id": "1912.03457", "submitter": "Sebastin Santy", "authors": "Pratik Joshi, Christain Barnes, Sebastin Santy, Simran Khanuja, Sanket\n  Shah, Anirudh Srinivasan, Satwik Bhattamishra, Sunayana Sitaram, Monojit\n  Choudhury, Kalika Bali", "title": "Unsung Challenges of Building and Deploying Language Technologies for\n  Low Resource Language Communities", "comments": "Accepted at ICON 2019; 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine and analyze the challenges associated with\ndeveloping and introducing language technologies to low-resource language\ncommunities. While doing so, we bring to light the successes and failures of\npast work in this area, challenges being faced in doing so, and what they have\nachieved. Throughout this paper, we take a problem-facing approach and describe\nessential factors which the success of such technologies hinges upon. We\npresent the various aspects in a manner which clarify and lay out the different\ntasks involved, which can aid organizations looking to make an impact in this\narea. We take the example of Gondi, an extremely-low resource Indian language,\nto reinforce and complement our discussion.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 07:45:43 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Joshi", "Pratik", ""], ["Barnes", "Christain", ""], ["Santy", "Sebastin", ""], ["Khanuja", "Simran", ""], ["Shah", "Sanket", ""], ["Srinivasan", "Anirudh", ""], ["Bhattamishra", "Satwik", ""], ["Sitaram", "Sunayana", ""], ["Choudhury", "Monojit", ""], ["Bali", "Kalika", ""]]}, {"id": "1912.03556", "submitter": "Silvia Bartolucci", "authors": "Silvia Bartolucci, Fabio Caccioli, Pierpaolo Vivo", "title": "A percolation model for the emergence of the Bitcoin Lightning Network", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lightning Network is a so-called second-layer technology built on top of\nthe Bitcoin blockchain to provide \"off-chain\" fast payment channels between\nusers, which means that not all transactions are settled and stored on the main\nblockchain. In this paper, we model the emergence of the Lightning Network as a\n(bond) percolation process and we explore how the distributional properties of\nthe volume and size of transactions per user may impact its feasibility. The\nagents are all able to reciprocally transfer Bitcoins using the main blockchain\nand also - if economically convenient - to open a channel on the Lightning\nNetwork and transact \"off chain\". We base our approach on fitness-dependent\nnetwork models: as in real life, a Lightning channel is opened with a\nprobability that depends on the \"fitness\" of the concurring nodes, which in\nturn depends on wealth and volume of transactions. The emergence of a connected\ncomponent is studied numerically and analytically as a function of the\nparameters, and the phase transition separating regions in the phase space\nwhere the Lightning Network is sustainable or not is elucidated. We\ncharacterize the phase diagram determining the minimal volume of transactions\nthat would make the Lightning Network sustainable for a given level of fees or,\nalternatively, the maximal cost the Lightning ecosystem may impose for a given\naverage volume of transactions. The model includes parameters that could be in\nprinciple estimated from publicly available data once the evolution of the\nLighting Network will have reached a stationary operable state, and is fairly\nrobust against different choices of the distributions of parameters and fitness\nkernels.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2019 20:27:23 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Bartolucci", "Silvia", ""], ["Caccioli", "Fabio", ""], ["Vivo", "Pierpaolo", ""]]}, {"id": "1912.03593", "submitter": "Alex Hanna", "authors": "Alex Hanna, Emily Denton, Andrew Smart, Jamila Smith-Loud", "title": "Towards a Critical Race Methodology in Algorithmic Fairness", "comments": "Conference on Fairness, Accountability, and Transparency (FAT* '20),\n  January 27-30, 2020, Barcelona, Spain", "journal-ref": null, "doi": "10.1145/3351095.3372826", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We examine the way race and racial categories are adopted in algorithmic\nfairness frameworks. Current methodologies fail to adequately account for the\nsocially constructed nature of race, instead adopting a conceptualization of\nrace as a fixed attribute. Treating race as an attribute, rather than a\nstructural, institutional, and relational phenomenon, can serve to minimize the\nstructural aspects of algorithmic unfairness. In this work, we focus on the\nhistory of racial categories and turn to critical race theory and sociological\nwork on race and ethnicity to ground conceptualizations of race for fairness\nresearch, drawing on lessons from public health, biomedical research, and\nsocial survey research. We argue that algorithmic fairness researchers need to\ntake into account the multidimensionality of race, take seriously the processes\nof conceptualizing and operationalizing race, focus on social processes which\nproduce racial inequality, and consider perspectives of those most affected by\nsociotechnical systems.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2019 01:42:23 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Hanna", "Alex", ""], ["Denton", "Emily", ""], ["Smart", "Andrew", ""], ["Smith-Loud", "Jamila", ""]]}, {"id": "1912.03920", "submitter": "Gabriel Moreau", "authors": "Cyrille Bonamy (LEGI), Laurent Lef\\`evre (AVALON), Gabriel Moreau\n  (LEGI)", "title": "High performance computing and energy efficiency: focus on OpenFOAM", "comments": "Vid{\\'e}o\n  https://replay.jres.org/videos/watch/811bb2fe-582e-4996-9643-89401d2c0d2c ,\n  in French, Congr\\`es JRES : Les Journ\\'ees R\\'eseaux de l'Enseignement et de\n  la Recherche, RENATER, Dec 2019, Dijon, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High performance calculation is increasingly used within society. Previously\nreserved for an elite, based on large computing and storage infrastructures, it\nis now a core module for many companies. Indeed, high performance calculation\nmakes it possible to design and optimize many elements for a limited cost\n,compared to the production of prototypes or tests in situ. It is also widely\nused in big data and artificial intelligence.It seems essential to ask about\ntheenvironmental impact of these digital practices. A number of actions have\nalready been initiated in this community: GREEN500; European CoC\neco-responsibility label for Data centres... but these actions generally look\nat specific or even idealised situations and/or software.The software\nqualification process in the field of high performance calculation consists in\nlooking at the scalability of the software. The originality of this study is to\nfocus on energy scalability (calculation return time depending on the power\nconsumed), by considering several architectures (three TOP500 machines and a\nlaboratory cluster).The energy cost of an example calculation could be\nestimated, which shows that the most efficient machine in terms of calculation\ntime is not necessarily the most energy efficient, and depending on the number\nof cores/processes chosen, it is not always the same architecture that is the\nmost energy-efficient. It was therefore possible to show that the longer the\nuser is prepared to wait, the less energy is used by the calculation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 09:35:56 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Bonamy", "Cyrille", "", "LEGI"], ["Lef\u00e8vre", "Laurent", "", "AVALON"], ["Moreau", "Gabriel", "", "LEGI"]]}, {"id": "1912.04255", "submitter": "Piotr Sapiezynski", "authors": "Muhammad Ali, Piotr Sapiezynski, Aleksandra Korolova, Alan Mislove,\n  Aaron Rieke", "title": "Ad Delivery Algorithms: The Hidden Arbiters of Political Messaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Political campaigns are increasingly turning to digital advertising to reach\nvoters. These platforms empower advertisers to target messages to platform\nusers with great precision, including through inferences about those users'\npolitical affiliations. However, prior work has shown that platforms' ad\ndelivery algorithms can selectively deliver ads within these target audiences\nin ways that can lead to demographic skews along race and gender lines, often\nwithout an advertiser's knowledge.\n  In this study, we investigate the impact of Facebook's ad delivery algorithms\non political ads. We run a series of political ads on Facebook and measure how\nFacebook delivers those ads to different groups, depending on an ad's content\n(e.g., the political viewpoint featured) and targeting criteria. We find that\nFacebook's ad delivery algorithms effectively differentiate the price of\nreaching a user based on their inferred political alignment with the advertised\ncontent, inhibiting political campaigns' ability to reach voters with diverse\npolitical views. This effect is most acute when advertisers use small budgets,\nas Facebook's delivery algorithm tends to preferentially deliver to the users\nwho are, according to Facebook's estimation, most relevant.\n  Our findings point to advertising platforms' potential role in political\npolarization and creating informational filter bubbles. Furthermore, some large\nad platforms have recently changed their policies to restrict the targeting\ntools they offer to political campaigns; our findings show that such reforms\nwill be insufficient if the goal is to ensure that political ads are shown to\nusers of diverse political views. Our findings add urgency to calls for more\nmeaningful public transparency into the political advertising ecosystem.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:48:08 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 18:54:06 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 18:53:49 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Ali", "Muhammad", ""], ["Sapiezynski", "Piotr", ""], ["Korolova", "Aleksandra", ""], ["Mislove", "Alan", ""], ["Rieke", "Aaron", ""]]}, {"id": "1912.04381", "submitter": "Dolly Agarwal", "authors": "Dolly Agarwal, Jayant Gupchup, Nishant Baghel", "title": "A Dataset for measuring reading levels in India at scale", "comments": "5 pages, 3 figures, 3 Tables, Paper accepted to ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CY cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One out of four children in India are leaving grade eight without basic\nreading skills. Measuring the reading levels in a vast country like India poses\nsignificant hurdles. Recent advances in machine learning opens up the\npossibility of automating this task. However, the datasets of children's speech\nare not only rare but are primarily in English. To solve this assessment\nproblem and advance deep learning research in regional Indian languages, we\npresent the ASER dataset of children in the age group of 6-14. The dataset\nconsists of 5,301 subjects generating 81,330 labeled audio clips in Hindi,\nMarathi and English. These labels represent expert opinions on the child's\nability to read at a specified level. Using this dataset, we built a simple\nASR-based classifier. Early results indicate that we can achieve a prediction\naccuracy of 86% for the English language. Considering the ASER survey spans\nhalf a million subjects, this dataset can grow to those scales.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:06:22 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 07:57:21 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Agarwal", "Dolly", ""], ["Gupchup", "Jayant", ""], ["Baghel", "Nishant", ""]]}, {"id": "1912.04579", "submitter": "Hemank Lamba", "authors": "Hemank Lamba, Shashank Srikanth, Dheeraj Reddy Pailla, Shwetanshu\n  Singh, Karandeep Juneja, Ponnurangam Kumaraguru", "title": "Driving The Last Mile: Characterizing and Understanding Distracted\n  Driving Posts on Social Networks", "comments": "Accepted at International Conference on Web and Social Media (ICWSM)\n  2020; 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In 2015, 391,000 people were injured due to distracted driving in the US. One\nof the major reasons behind distracted driving is the use of cell-phones,\naccounting for 14% of fatal crashes. Social media applications have enabled\nusers to stay connected, however, the use of such applications while driving\ncould have serious repercussions -- often leading the user to be distracted\nfrom the road and ending up in an accident. In the context of impression\nmanagement, it has been discovered that individuals often take a risk (such as\nteens smoking cigarettes, indulging in narcotics, and participating in unsafe\nsex) to improve their social standing. Therefore, viewing the phenomena of\nposting distracted driving posts under the lens of self-presentation, it can be\nhypothesized that users often indulge in risk-taking behavior on social media\nto improve their impression among their peers. In this paper, we first try to\nunderstand the severity of such social-media-based distractions by analyzing\nthe content posted on a popular social media site where the user is driving and\nis also simultaneously creating content. To this end, we build a deep learning\nclassifier to identify publicly posted content on social media that involves\nthe user driving. Furthermore, a framework proposed to understand factors\nbehind voluntary risk-taking activity observes that younger individuals are\nmore willing to perform such activities, and men (as opposed to women) are more\ninclined to take risks. Grounding our observations in this framework, we test\nthese hypotheses on 173 cities across the world. We conduct spatial and\ntemporal analysis on a city-level and understand how distracted driving content\nposting behavior changes due to varied demographics. We discover that the\nfactors put forth by the framework are significant in estimating the extent of\nsuch behavior.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 08:51:54 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Lamba", "Hemank", ""], ["Srikanth", "Shashank", ""], ["Pailla", "Dheeraj Reddy", ""], ["Singh", "Shwetanshu", ""], ["Juneja", "Karandeep", ""], ["Kumaraguru", "Ponnurangam", ""]]}, {"id": "1912.04786", "submitter": "Javier Hernandez-Ortega", "authors": "Javier Hernandez-Ortega, Roberto Daza, Aythami Morales, Julian\n  Fierrez, Javier Ortega-Garcia", "title": "edBB: Biometrics and Behavior for Assessing Remote Education", "comments": "Preprint of the paper presented to the Workshop on Artificial\n  Intelligence for Education (AI4EDU) of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a platform for student monitoring in remote education consisting\nof a collection of sensors and software that capture biometric and behavioral\ndata. We define a collection of tasks to acquire behavioral data that can be\nuseful for facing the existing challenges in automatic student monitoring\nduring remote evaluation. Additionally, we release an initial database\nincluding data from 20 different users completing these tasks with a set of\nbasic sensors: webcam, microphone, mouse, and keyboard; and also from more\nadvanced sensors: NIR camera, smartwatch, additional RGB cameras, and an EEG\nband. Information from the computer (e.g. system logs, MAC, IP, or web browsing\nhistory) is also stored. During each acquisition session each user completed\nthree different types of tasks generating data of different nature: mouse and\nkeystroke dynamics, face data, and audio data among others. The tasks have been\ndesigned with two main goals in mind: i) analyse the capacity of such biometric\nand behavioral data for detecting anomalies during remote evaluation, and ii)\nstudy the capability of these data, i.e. EEG, ECG, or NIR video, for estimating\nother information about the users such as their attention level, the presence\nof stress, or their pulse rate.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 15:55:11 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Hernandez-Ortega", "Javier", ""], ["Daza", "Roberto", ""], ["Morales", "Aythami", ""], ["Fierrez", "Julian", ""], ["Ortega-Garcia", "Javier", ""]]}, {"id": "1912.04883", "submitter": "Manish Raghavan", "authors": "Rediet Abebe, Solon Barocas, Jon Kleinberg, Karen Levy, Manish\n  Raghavan, David G. Robinson", "title": "Roles for Computing in Social Change", "comments": null, "journal-ref": null, "doi": "10.1145/3351095.3372871", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recent normative turn in computer science has brought concerns about\nfairness, bias, and accountability to the core of the field. Yet recent\nscholarship has warned that much of this technical work treats problematic\nfeatures of the status quo as fixed, and fails to address deeper patterns of\ninjustice and inequality. While acknowledging these critiques, we posit that\ncomputational research has valuable roles to play in addressing social problems\n-- roles whose value can be recognized even from a perspective that aspires\ntoward fundamental social change. In this paper, we articulate four such roles,\nthrough an analysis that considers the opportunities as well as the significant\nrisks inherent in such work. Computing research can serve as a diagnostic,\nhelping us to understand and measure social problems with precision and\nclarity. As a formalizer, computing shapes how social problems are explicitly\ndefined --- changing how those problems, and possible responses to them, are\nunderstood. Computing serves as rebuttal when it illuminates the boundaries of\nwhat is possible through technical means. And computing acts as synecdoche when\nit makes long-standing social problems newly salient in the public eye. We\noffer these paths forward as modalities that leverage the particular strengths\nof computational work in the service of social change, without overclaiming\ncomputing's capacity to solve social problems on its own.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 18:46:42 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 18:42:38 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 09:49:32 GMT"}, {"version": "v4", "created": "Thu, 9 Jul 2020 15:29:07 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Abebe", "Rediet", ""], ["Barocas", "Solon", ""], ["Kleinberg", "Jon", ""], ["Levy", "Karen", ""], ["Raghavan", "Manish", ""], ["Robinson", "David G.", ""]]}, {"id": "1912.04930", "submitter": "Manish Raghavan", "authors": "Solon Barocas, Andrew D. Selbst, Manish Raghavan", "title": "The Hidden Assumptions Behind Counterfactual Explanations and Principal\n  Reasons", "comments": null, "journal-ref": null, "doi": "10.1145/3351095.3372830", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations are gaining prominence within technical, legal,\nand business circles as a way to explain the decisions of a machine learning\nmodel. These explanations share a trait with the long-established \"principal\nreason\" explanations required by U.S. credit laws: they both explain a decision\nby highlighting a set of features deemed most relevant--and withholding others.\n  These \"feature-highlighting explanations\" have several desirable properties:\nThey place no constraints on model complexity, do not require model disclosure,\ndetail what needed to be different to achieve a different decision, and seem to\nautomate compliance with the law. But they are far more complex and subjective\nthan they appear.\n  In this paper, we demonstrate that the utility of feature-highlighting\nexplanations relies on a number of easily overlooked assumptions: that the\nrecommended change in feature values clearly maps to real-world actions, that\nfeatures can be made commensurate by looking only at the distribution of the\ntraining data, that features are only relevant to the decision at hand, and\nthat the underlying model is stable over time, monotonic, and limited to binary\noutcomes.\n  We then explore several consequences of acknowledging and attempting to\naddress these assumptions, including a paradox in the way that\nfeature-highlighting explanations aim to respect autonomy, the unchecked power\nthat feature-highlighting explanations grant decision makers, and a tension\nbetween making these explanations useful and the need to keep the model hidden.\n  While new research suggests several ways that feature-highlighting\nexplanations can work around some of the problems that we identify, the\ndisconnect between features in the model and actions in the real world--and the\nsubjective choices necessary to compensate for this--must be understood before\nthese techniques can be usefully implemented.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 19:09:14 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Barocas", "Solon", ""], ["Selbst", "Andrew D.", ""], ["Raghavan", "Manish", ""]]}, {"id": "1912.04947", "submitter": "Bogdana Rakova", "authors": "Bogdana Rakova, Laura Kahn", "title": "Dynamic Algorithmic Service Agreements Perspective", "comments": "6 pages, 1 figure, To appear in the Proceedings of the AAAI 2020\n  Spring Symposium Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-disciplinary understanding of the concepts of identity, agency,\nrelationships, interactions, and information could help us develop mitigation\nstrategies for responsible human-algorithmic systems in the field of AI. It is\nimperative for us to question the use of the Terms of Service (ToS) agreements\nmodel in the context of algorithmic systems, specifically AI systems that make\ndecisions which affect people and their livelihoods. In this position paper, we\nidentify five areas of concern in traditional ToS agreements by drawing on\nstudies of sociotechnical systems in Science and Technology Studies -\naccommodating and enabling change, co-constitution, reflective directionality,\nfriction, and generativity. We aim to address these ToS shortcomings and\npropose components of a novel Dynamic Algorithmic Service Agreements (DASA)\nframework. The DASA could be employed as a self-regulation framework while also\nenabling additional feedback loops between people and algorithmic systems. Rich\ninteraction frameworks could enable us to better negotiate and cooperate with\nAI systems towards accomplishing the real-world goals we use them for. We\nillustrate the DASA framework in the context of a Recommender System used in\nthe curation of real and synthetic data. We do not intend for the DASA\nframework to replace the ToS model, but instead think it will provide\npractitioners with an alternative point of view for the design of dynamic\ninteraction interfaces for AI systems that account for human identity and\nagency.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 19:45:08 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 18:57:17 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 06:09:49 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Rakova", "Bogdana", ""], ["Kahn", "Laura", ""]]}, {"id": "1912.04953", "submitter": "Bogdana Rakova", "authors": "Bogdana Rakova, Nick DePalma", "title": "Minority report detection in refugee-authored community-driven\n  journalism using RBMs", "comments": "5 pages, 2 figures, In the Proceedings of the AI for Social Good\n  NeurIPS 2018 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work seeks to gather and distribute sensitive information from refugee\nsettlements to stakeholders to help shape policy and help guide action\nnetworks. In this paper, we propose the following 1) a method of data\ncollection through stakeholder organizations experienced in working with\ndisplaced and refugee communities, 2) a method of topic modeling based on Deep\nBoltzmann Machines that identifies topics and issues of interest within the\npopulation, to help enable mapping of human rights violations, and 3) a\nsecondary analysis component that will use the probability of fit to isolate\nminority reports within these stories using anomaly detection techniques.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 19:58:30 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Rakova", "Bogdana", ""], ["DePalma", "Nick", ""]]}, {"id": "1912.05291", "submitter": "Michael Horowitz", "authors": "Michael C. Horowitz, Paul Scharre, and Alexander Velez-Green", "title": "A Stable Nuclear Future? The Impact of Autonomous Systems and Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential for advances in information-age technologies to undermine\nnuclear deterrence and influence the potential for nuclear escalation\nrepresents a critical question for international politics. One challenge is\nthat uncertainty about the trajectory of technologies such as autonomous\nsystems and artificial intelligence (AI) makes assessments difficult. This\npaper evaluates the relative impact of autonomous systems and artificial\nintelligence in three areas: nuclear command and control, nuclear delivery\nplatforms and vehicles, and conventional applications of autonomous systems\nwith consequences for nuclear stability. We argue that countries may be more\nlikely to use risky forms of autonomy when they fear that their second-strike\ncapabilities will be undermined. Additionally, the potential deployment of\nuninhabited, autonomous nuclear delivery platforms and vehicles could raise the\nprospect for accidents and miscalculation. Conventional military applications\nof autonomous systems could simultaneously influence nuclear force postures and\nfirst-strike stability in previously unanticipated ways. In particular, the\nneed to fight at machine speed and the cognitive risk introduced by automation\nbias could increase the risk of unintended escalation. Finally, used properly,\nthere should be many applications of more autonomous systems in nuclear\noperations that can increase reliability, reduce the risk of accidents, and buy\nmore time for decision-makers in a crisis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 13:35:36 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 18:37:36 GMT"}], "update_date": "2019-12-28", "authors_parsed": [["Horowitz", "Michael C.", ""], ["Scharre", "Paul", ""], ["Velez-Green", "Alexander", ""]]}, {"id": "1912.05362", "submitter": "Sylvain Cherrier", "authors": "Hantanirina Felixie, Jean Razafindramintsa, Sylvain Cherrier (LIGM),\n  Thomas Mahatody, Laurent George (LIGM), Victor Manantsoa", "title": "Jason-RS, a Collaboration between Agents and an IoT Platform", "comments": null, "journal-ref": "International Workshop on Networking for Smart Living, Dec 2019,\n  Paris, France", "doi": null, "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we start from the observation that REST services are the most\nused as tools of interoperability and orchestration in the Internet of Things\n(IoT). But REST does not make it possible to inject artificial intelligence\ninto connected objects, ie it cannot allow autonomy and decision-making by the\nobjects themselves. To define an intelligence to a connected object, one can\nuse a Beleive Desire Intention agent (BDI an intelligent agent that adopts\nhuman behavior) such as Jason Agentspeak. But Jason AgentSpeak does not\nguarantee orchestration or choreography between connected objects. There are\nplatforms for service orchestration and choreography in IoT, still the\ninterconnection with artificial intelligence needs to be built. In this\narticle, we propose a new approach called Jason-RS. It is a result of pairing\nJason BDI agent with the web service technologies to exploit the agent capacity\nas a service, Jason-RS turn in Java SE and it does not need any middleware. The\narchitecture that we propose allows to create the link between Artificial\nIntelligence and Services choreography to reduce human intervention in the\nservice choreography. In order to validate the proposed approach, we have\ninterconnected the Iot BeC 3 platform and the REST agent (Jason-RS). The\ndecision-making faculty offered by Jason-RS is derived from the information\nsent by the objects according to the different methods of REST (GET, POST, PUT,\nand DELETE) that Jason-RS offers. As a result, the objects feed the inter-agent\ncollaborations and decision-making inside the agent. Finally, we show that\nJason-RS allows the Web of Objects to power complex systems such as an\nartificial intelligence responsible for processing data. This performance is\npromising.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 14:43:22 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Felixie", "Hantanirina", "", "LIGM"], ["Razafindramintsa", "Jean", "", "LIGM"], ["Cherrier", "Sylvain", "", "LIGM"], ["Mahatody", "Thomas", "", "LIGM"], ["George", "Laurent", "", "LIGM"], ["Manantsoa", "Victor", ""]]}, {"id": "1912.05474", "submitter": "Vivek Singh", "authors": "Vivek Singh, Mary Chayko, Raj Inamdar, and Diana Floegel", "title": "Female Librarians and Male Computer Programmers? Gender Bias in\n  Occupational Images on Digital Media Platforms", "comments": "Article accepted for publication in The Journal of the Association\n  for Information Science and Technology (JASIST)", "journal-ref": null, "doi": "10.1002/ASI.24335", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Media platforms, technological systems, and search engines act as conduits\nand gatekeepers for all kinds of information. They often influence, reflect,\nand reinforce gender stereotypes, including those that represent occupations.\nThis study examines the prevalence of gender stereotypes on digital media\nplatforms and considers how human efforts to create and curate messages\ndirectly may impact these stereotypes. While gender stereotyping in social\nmedia and algorithms has received some examination in recent literature, its\nprevalence in different types of platforms (e.g., wiki vs. news vs. social\nnetwork) and under differing conditions (e.g., degrees of human and machine led\ncontent creation and curation) has yet to be studied. This research explores\nthe extent to which stereotypes of certain strongly gendered professions\n(librarian, nurse, computer programmer, civil engineer) persist and may vary\nacross digital platforms (Twitter, the New York Times online, Wikipedia, and\nShutterstock). The results suggest that gender stereotypes are most likely to\nbe challenged when human beings act directly to create and curate content in\ndigital platforms, and that highly algorithmic approaches for curation showed\nlittle inclination towards breaking stereotypes. Implications for the more\ninclusive design and use of digital media platforms, particularly with regard\nto mediated occupational messaging, are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 17:10:23 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Singh", "Vivek", ""], ["Chayko", "Mary", ""], ["Inamdar", "Raj", ""], ["Floegel", "Diana", ""]]}, {"id": "1912.05511", "submitter": "Hanna Wallach", "authors": "Abigail Z. Jacobs and Hanna Wallach", "title": "Measurement and Fairness", "comments": "11 pages, 1 figure. To be published in the proceedings of the ACM\n  Conference on Fairness, Accountability, and Transparency (FAccT '21)", "journal-ref": null, "doi": "10.1145/3442188.3445901", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose measurement modeling from the quantitative social sciences as a\nframework for understanding fairness in computational systems. Computational\nsystems often involve unobservable theoretical constructs, such as\nsocioeconomic status, teacher effectiveness, and risk of recidivism. Such\nconstructs cannot be measured directly and must instead be inferred from\nmeasurements of observable properties (and other unobservable theoretical\nconstructs) thought to be related to them -- i.e., operationalized via a\nmeasurement model. This process, which necessarily involves making assumptions,\nintroduces the potential for mismatches between the theoretical understanding\nof the construct purported to be measured and its operationalization. We argue\nthat many of the harms discussed in the literature on fairness in computational\nsystems are direct results of such mismatches. We show how some of these harms\ncould have been anticipated and, in some cases, mitigated if viewed through the\nlens of measurement modeling. To do this, we contribute fairness-oriented\nconceptualizations of construct reliability and construct validity that unite\ntraditions from political science, education, and psychology and provide a set\nof tools for making explicit and testing assumptions about constructs and their\noperationalizations. We then turn to fairness itself, an essentially contested\nconstruct that has different theoretical understandings in different contexts.\nWe argue that this contestedness underlies recent debates about fairness\ndefinitions: although these debates appear to be about different\noperationalizations, they are, in fact, debates about different theoretical\nunderstandings of fairness. We show how measurement modeling can provide a\nframework for getting to the core of these debates.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 18:21:38 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 18:20:14 GMT"}, {"version": "v3", "created": "Fri, 12 Mar 2021 21:26:55 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Jacobs", "Abigail Z.", ""], ["Wallach", "Hanna", ""]]}, {"id": "1912.05530", "submitter": "Arash Shaban-Nejad", "authors": "Jon Hael Brenas, Eun Kyong Shin, Arash Shaban-Nejad", "title": "Adverse Childhood Experiences Ontology for Mental Health Surveillance,\n  Research, and Evaluation: Advanced Knowledge Representation and Semantic Web\n  Techniques", "comments": "11 Pages, 10 figures", "journal-ref": "JMIR Ment Health. 2019 May 21;6(5):e13498", "doi": "10.2196/13498", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Adverse Childhood Experiences (ACEs), a set of negative events\nand processes that a person might encounter during childhood and adolescence,\nhave been proven to be linked to increased risks of a multitude of negative\nhealth outcomes and conditions when children reach adulthood and beyond.\n  Objective: To better understand the relationship between ACEs and their\nrelevant risk factors with associated health outcomes and to eventually design\nand implement preventive interventions, access to an integrated coherent\ndataset is needed. Therefore, we implemented a formal ontology as a resource to\nallow the mental health community to facilitate data integration and knowledge\nmodeling and to improve ACEs surveillance and research.\n  Methods: We use advanced knowledge representation and Semantic Web tools and\ntechniques to implement the ontology. The current implementation of the\nontology is expressed in the description logic ALCRIQ(D), a sublogic of Web\nOntology Language (OWL 2).\n  Results: The ACEs Ontology has been implemented and made available to the\nmental health community and the public via the BioPortal repository. Moreover,\nmultiple use-case scenarios have been introduced to showcase and evaluate the\nusability of the ontology in action. The ontology was created to be used by\nmajor actors in the ACEs community with different applications, from the\ndiagnosis of individuals and predicting potential negative outcomes that they\nmight encounter to the prevention of ACEs in a population and designing\ninterventions and policies.\n  Conclusions: The ACEs Ontology provides a uniform and reusable semantic\nnetwork and an integrated knowledge structure for mental health practitioners\nand researchers to improve ACEs surveillance and evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 22:44:40 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Brenas", "Jon Hael", ""], ["Shin", "Eun Kyong", ""], ["Shaban-Nejad", "Arash", ""]]}, {"id": "1912.05538", "submitter": "Robert Soden", "authors": "Robert Soden, Dennis Wagenaar, Dave Luo, Annegien Tijssen", "title": "Taking Ethics, Fairness, and Bias Seriously in Machine Learning for\n  Disaster Risk Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper highlights an important, if under-examined, set of questions about\nthe deployment of machine learning technologies in the field of disaster risk\nmanagement (DRM). While emerging tools show promising capacity to support\nscientific efforts to better understand and mitigate the threats posed by\ndisasters and climate change, our field must undertake a much more careful\nassessment of the potential negative impacts that machine learning technologies\nmay create. We also argue that attention to these issues in the context of\nmachine learning affords the opportunity to have discussions about potential\nethics, bias, and fairness concerns within disaster data more broadly. In what\nfollows, we first describe some of the uses and potential benefits of\nmachine-learning technology in disaster risk management. We then draw on\nresearch from other fields to speculate about potential negative impacts.\nFinally, we outline a research agenda for how our disaster risk management can\nbegin to take these issues seriously and ensure that deployments of\nmachine-learning tools are conducted in a responsible and beneficial manner.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 20:37:45 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 18:17:41 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Soden", "Robert", ""], ["Wagenaar", "Dennis", ""], ["Luo", "Dave", ""], ["Tijssen", "Annegien", ""]]}, {"id": "1912.05606", "submitter": "Holly Rushmeier", "authors": "Holly Rushmeier, Kapil Chalil Madathil, Jessica Hodgins, Beth Mynatt,\n  Tony Derose, Blair Macintyre, and other workshop participants", "title": "Content Generation for Workforce Training", "comments": "A Computing Community Consortium (CCC) workshop report, 21 pages", "journal-ref": null, "doi": null, "report-no": "ccc2019report_7", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient workforce training is needed in today's world in which technology\nis continually changing the nature of work. Students need to be prepared to\nenter the workforce. Employees need to become lifelong learners to stay\nup-to-date in their work and to adapt when job functions are eliminated. The\ntraining needs are across all industries - including manufacturing,\nconstruction, and healthcare. Computing systems, in particular\nVirtual/Augmented Reality systems, have been adopted in many training\napplication and show even more promise in the future. However, there are\nfundamental limitations in today's systems that limit the domains where\ncomputing systems can be applied and the extent to which they can be deployed.\nThese limitations need to be addressed by new computing research. In particular\nresearch is needed at multiple levels:\n  - Application Data Collection Level Requiring High Security and Privacy\nProtections\n  - Training Material Authoring Level\n  - Software Systems Level\n  - Hardware Level\n  To accomplish these research goals, a training community needs to be\nestablished to do research in end-to-end training systems and to create a\ncommunity of learning and domain experts available for consulting for in depth\ncomputing research on individual system components.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 20:25:40 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Rushmeier", "Holly", ""], ["Madathil", "Kapil Chalil", ""], ["Hodgins", "Jessica", ""], ["Mynatt", "Beth", ""], ["Derose", "Tony", ""], ["Macintyre", "Blair", ""], ["participants", "other workshop", ""]]}, {"id": "1912.05652", "submitter": "Siddharth Reddy", "authors": "Siddharth Reddy, Anca D. Dragan, Sergey Levine, Shane Legg, Jan Leike", "title": "Learning Human Objectives by Evaluating Hypothetical Behavior", "comments": "Published at International Conference on Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to align agent behavior with a user's objectives in a reinforcement\nlearning setting with unknown dynamics, an unknown reward function, and unknown\nunsafe states. The user knows the rewards and unsafe states, but querying the\nuser is expensive. To address this challenge, we propose an algorithm that\nsafely and interactively learns a model of the user's reward function. We start\nwith a generative model of initial states and a forward dynamics model trained\non off-policy data. Our method uses these models to synthesize hypothetical\nbehaviors, asks the user to label the behaviors with rewards, and trains a\nneural network to predict the rewards. The key idea is to actively synthesize\nthe hypothetical behaviors from scratch by maximizing tractable proxies for the\nvalue of information, without interacting with the environment. We call this\nmethod reward query synthesis via trajectory optimization (ReQueST). We\nevaluate ReQueST with simulated users on a state-based 2D navigation task and\nthe image-based Car Racing video game. The results show that ReQueST\nsignificantly outperforms prior methods in learning reward models that transfer\nto new environments with different initial state distributions. Moreover,\nReQueST safely trains the reward model to detect unsafe states, and corrects\nreward hacking before deploying the agent.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 18:25:48 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 22:26:35 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Reddy", "Siddharth", ""], ["Dragan", "Anca D.", ""], ["Levine", "Sergey", ""], ["Legg", "Shane", ""], ["Leike", "Jan", ""]]}, {"id": "1912.05662", "submitter": "Roger Immich", "authors": "Diego O. Rodrigues, Frances A. Santos, Geraldo P. Rocha Filho, Ademar\n  T. Akabane, Raquel Cabral, Roger Immich, Wellington L. Junior, Felipe D.\n  Cunha, Daniel L. Guidoni, Thiago H. Silva, Denis Ros\\'ario, Eduardo\n  Cerqueira, Antonio A. F. Loureiro, Leandro A. Villas", "title": "Computa\\c{c}\\~ao Urbana da Teoria \\`a Pr\\'atica: Fundamentos,\n  Aplica\\c{c}\\~oes e Desafios", "comments": "in Portuguese. Simp\\'osio Brasileiro de Redes de Computadores e\n  Sistemas Distribu\\'idos (SBRC) 2019 - Minicursos", "journal-ref": "Simposio Brasileiro de Redes de Computadores e Sistemas\n  Distribuidos (SBRC), 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.HC cs.IR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing of cities has resulted in innumerable technical and managerial\nchallenges for public administrators such as energy consumption, pollution,\nurban mobility and even supervision of private and public spaces in an\nappropriate way. Urban Computing emerges as a promising paradigm to solve such\nchallenges, through the extraction of knowledge, from a large amount of\nheterogeneous data existing in urban space. Moreover, Urban Computing\ncorrelates urban sensing, data management, and analysis to provide services\nthat have the potential to improve the quality of life of the citizens of large\nurban centers. Consider this context, this chapter aims to present the\nfundamentals of Urban Computing and the steps necessary to develop an\napplication in this area. To achieve this goal, the following questions will be\ninvestigated, namely: (i) What are the main research problems of Urban\nComputing?; (ii) What are the technological challenges for the implementation\nof services in Urban Computing?; (iii) What are the main methodologies used for\nthe development of services in Urban Computing?; and (iv) What are the\nrepresentative applications in this field?\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 15:01:58 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rodrigues", "Diego O.", ""], ["Santos", "Frances A.", ""], ["Filho", "Geraldo P. Rocha", ""], ["Akabane", "Ademar T.", ""], ["Cabral", "Raquel", ""], ["Immich", "Roger", ""], ["Junior", "Wellington L.", ""], ["Cunha", "Felipe D.", ""], ["Guidoni", "Daniel L.", ""], ["Silva", "Thiago H.", ""], ["Ros\u00e1rio", "Denis", ""], ["Cerqueira", "Eduardo", ""], ["Loureiro", "Antonio A. F.", ""], ["Villas", "Leandro A.", ""]]}, {"id": "1912.06038", "submitter": "Gabriel Moreau", "authors": "B\\'eatrice Montbroussous (GATE), Jonathan Schaeffer (OSUG), Gabriel\n  Moreau (LEGI), Francoise Berthoud, Gabrielle Feltin (GRICAD)", "title": "Calculate the carbon footprint of your IT assets with EcoDiag, an\n  EcoInfo service", "comments": "in French", "journal-ref": "Congr\\`es JRES : Les Journ\\'ees R\\'eseaux de l'Enseignement et de\n  la Recherche, RENATER, Dec 2019, Dijon, France", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  You hear a lot about environmental issues, you may have initiated positive\npersonal attitudes, you have a group will in your unit, and you are wondering\nabout the environmental impact of digital technology in your professional\nenvironment...EcoDiag is here for you!The CNRS EcoInfo GDS has found that\nassessing the environmental impacts of digital technology is complex and can\ndiscourage the best will, which is why we offer you a simple and effective\nmethod to estimate the carbon footprint of your fleet through this new service\nbased on our experience. We chose an indicator that everyone could understand:\nCO2e emissions (CO2e equivalent). Based on an inventory of the digital services\nused and the unit's computer equipment, our methodology and expertise will\nallow you to establish a global estimate of GHG emissions. This evaluation will\nbe accompanied by recommendations and resources (sheets, guide, material) to\nintegrate this work into a Hc{\\'e}res-type report or use them as part of a more\nglobal carbon assessment for your structure. The provision of advice will allow\nyou to post a policy to reduce GHG emissions generated by digital technology in\nthe following years!Meet us in front of the poster to discover and leave with\nour tool for assessing the environmental impacts of your unit's digital\nactivities. You will have the tools and a recommendation guide to control and\nreduce these impacts in a continuous improvement process. Concrete examples\nfrom two units will illustrate our approach and demonstrate the ease of use of\nthe EcoDiag service.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 15:37:33 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Montbroussous", "B\u00e9atrice", "", "GATE"], ["Schaeffer", "Jonathan", "", "OSUG"], ["Moreau", "Gabriel", "", "LEGI"], ["Berthoud", "Francoise", "", "GRICAD"], ["Feltin", "Gabrielle", "", "GRICAD"]]}, {"id": "1912.06166", "submitter": "Inioluwa Deborah Raji", "authors": "Inioluwa Deborah Raji, Jingying Yang", "title": "ABOUT ML: Annotation and Benchmarking on Understanding and Transparency\n  of Machine Learning Lifecycles", "comments": "Presented at Human-Centric Machine Learning workshop at Neural\n  Information Processing Systems conference 2019; equal contribution from\n  authors, Jingying Yang is the current program lead for the ABOUT ML project\n  at Partnership on AI, more details can be found about the project at\n  https://www.partnershiponai.org/about-ml/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the \"Annotation and Benchmarking on Understanding and Transparency\nof Machine Learning Lifecycles\" (ABOUT ML) project as an initiative to\noperationalize ML transparency and work towards a standard ML documentation\npractice. We make the case for the project's relevance and effectiveness in\nconsolidating disparate efforts across a variety of stakeholders, as well as\nbringing in the perspectives of currently missing voices that will be valuable\nin shaping future conversations. We describe the details of the initiative and\nthe gaps we hope this project will help address.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 19:23:04 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 03:51:50 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 04:10:52 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Raji", "Inioluwa Deborah", ""], ["Yang", "Jingying", ""]]}, {"id": "1912.06171", "submitter": "Aaron Rieke", "authors": "Miranda Bogen, Aaron Rieke, Shazeda Ahmed", "title": "Awareness in Practice: Tensions in Access to Sensitive Attribute Data\n  for Antidiscrimination", "comments": null, "journal-ref": null, "doi": "10.1145/3351095.3372877", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations cannot address demographic disparities that they cannot see.\nRecent research on machine learning and fairness has emphasized that awareness\nof sensitive attributes, such as race and sex, is critical to the development\nof interventions. However, on the ground, the existence of these data cannot be\ntaken for granted.\n  This paper uses the domains of employment, credit, and healthcare in the\nUnited States to surface conditions that have shaped the availability of\nsensitive attribute data. For each domain, we describe how and when private\ncompanies collect or infer sensitive attribute data for antidiscrimination\npurposes. An inconsistent story emerges: Some companies are required by law to\ncollect sensitive attribute data, while others are prohibited from doing so.\nStill others, in the absence of legal mandates, have determined that collection\nand imputation of these data are appropriate to address disparities.\n  This story has important implications for fairness research and its future\napplications. If companies that mediate access to life opportunities are unable\nor hesitant to collect or infer sensitive attribute data, then proposed\ntechniques to detect and mitigate bias in machine learning models might never\nbe implemented outside the lab. We conclude that today's legal requirements and\ncorporate practices, while highly inconsistent across domains, offer lessons\nfor how to approach the collection and inference of sensitive data in\nappropriate circumstances. We urge stakeholders, including machine learning\npractitioners, to actively help chart a path forward that takes both policy\ngoals and technical needs into account.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 19:26:00 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Bogen", "Miranda", ""], ["Rieke", "Aaron", ""], ["Ahmed", "Shazeda", ""]]}, {"id": "1912.06487", "submitter": "Peter Mell", "authors": "Peter Mell", "title": "Augmenting Fiat Currency with an Integrated Managed Cryptocurrency", "comments": "Published in The Fourteenth International Conference on Software\n  Engineering Advances (ICSEA) 2019, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate how the governance features of a managed\ncurrency (e.g., a fiat currency) can be built into a cryptocurrency in order to\nleverage potential benefits found in the use of blockchain technology and smart\ncontracts. The resulting managed cryptocurrency can increase transparency and\nintegrity, while potentially enabling the emergence of novel monetary\ninstruments. It has similarities to cash in that it enables the general public\nto immediately transfer funds to a recipient without intermediary systems being\ninvolved. However, our system is account-based, unlike circulating bank notes\nthat are self-contained. Our design would allow one to satisfy know your\ncustomer laws and be subject to law enforcement actions following legal due\nprocess (e.g., account freezing and fund seizure), while mitigating\ncounterparty risk with checks and balances. Funds can thus be transferred only\nbetween approved and authenticated users. Our system has on-chain governance\ncapabilities using smart contracts deployed on a dedicated, permissioned\nblockchain that has different sets of control mechanisms for who can read data,\nwrite data, and publish blocks. To enable the governance features, only\nauthorized identity proofed entities can submit transactions. To enable\nprivacy, only the block publishers can read the blockchain; the publishers\nmaintain dedicated nodes that provide access controlled partial visibility of\nthe blockchain data. Being permissioned, we can use a simple consensus protocol\nwith no transaction fees. A separate security layer prevents denial of service\nand a balance of power mechanism prevents any small group of entities from\nhaving undue control. While permissioned, we ensure that no one entity controls\nthe blockchain data or block publishing capability through a voting system with\npublicly visible election outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 13:51:41 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Mell", "Peter", ""]]}, {"id": "1912.06883", "submitter": "Reuben Binns Dr", "authors": "Reuben Binns", "title": "On the Apparent Conflict Between Individual and Group Fairness", "comments": "Conference on Fairness, Accountability, and Transparency (FAT* '20),\n  January 27--30, 2020, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A distinction has been drawn in fair machine learning research between\n`group' and `individual' fairness measures. Many technical research papers\nassume that both are important, but conflicting, and propose ways to minimise\nthe trade-offs between these measures. This paper argues that this apparent\nconflict is based on a misconception. It draws on theoretical discussions from\nwithin the fair machine learning research, and from political and legal\nphilosophy, to argue that individual and group fairness are not fundamentally\nin conflict. First, it outlines accounts of egalitarian fairness which\nencompass plausible motivations for both group and individual fairness, thereby\nsuggesting that there need be no conflict in principle. Second, it considers\nthe concept of individual justice, from legal philosophy and jurisprudence\nwhich seems similar but actually contradicts the notion of individual fairness\nas proposed in the fair machine learning literature. The conclusion is that the\napparent conflict between individual and group fairness is more of an artifact\nof the blunt application of fairness measures, rather than a matter of\nconflicting principles. In practice, this conflict may be resolved by a nuanced\nconsideration of the sources of `unfairness' in a particular deployment\ncontext, and the carefully justified application of measures to mitigate it.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 17:13:15 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Binns", "Reuben", ""]]}, {"id": "1912.06922", "submitter": "Brittany Bond", "authors": "Erik P. Duhaime, Brittany M. Bond, Qi Yang, Patrick de Boer, and\n  Thomas W. Malone", "title": "Recruiting Hay to Find Needles: Recursive Incentives and Innovation in\n  Social Networks", "comments": "10 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding innovative solutions to complex problems is often about finding\npeople who have access to novel information and alternative viewpoints.\nResearch has found that most people are connected to each other through just a\nfew degrees of separation, but successful social search is often difficult\nbecause it depends on people using their weak ties to make connections to\ndistant social networks. Recursive incentive schemes have shown promise for\nsocial search by motivating people to use their weak ties to find distant\ntargets, such as specific people or even weather balloons placed at undisclosed\nlocations. Here, we report on a case study of a similar recursive incentive\nscheme for finding innovative ideas. Specifically, we implemented a competition\nto reward individuals(s) who helped refer Grand Prize winner(s) in MIT's\nClimate CoLab, an open innovation platform for addressing global climate\nchange. Using data on over 78,000 CoLab members and over 36,000 people from\nover 100 countries who engaged with the referral contest, we find that people\nwho are referred using this method are more likely than others to submit\nproposals and to submit high quality proposals. Furthermore, we find suggestive\nevidence that among the contributors referred via the contest, those who had\nmore than one degree of separation from a pre-existing CoLab member were more\nlikely to submit high quality proposals. Thus, the results from this case study\nare consistent the theory that people from distant networks are more likely to\nprovide innovative solutions to complex problems. More broadly, the results\nsuggest that rewarding indirect intermediaries in addition to final finders may\npromote effective social network recruitment.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 20:41:01 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Duhaime", "Erik P.", ""], ["Bond", "Brittany M.", ""], ["Yang", "Qi", ""], ["de Boer", "Patrick", ""], ["Malone", "Thomas W.", ""]]}, {"id": "1912.07376", "submitter": "Abeba Birhane", "authors": "Abeba Birhane, Fred Cummins", "title": "Algorithmic Injustices: Towards a Relational Ethics", "comments": "Presented at the Black in AI workshop, @NeurIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has become trivial to point out how decision-making processes in various\nsocial, political and economical sphere are assisted by automated systems.\nImproved efficiency, the hallmark of these systems, drives the mass scale\nintegration of automated systems into daily life. However, as a robust body of\nresearch in the area of algorithmic injustice shows, algorithmic tools embed\nand perpetuate societal and historical biases and injustice. In particular, a\npersistent recurring trend within the literature indicates that society's most\nvulnerable are disproportionally impacted. When algorithmic injustice and bias\nis brought to the fore, most of the solutions on offer 1) revolve around\ntechnical solutions and 2) do not focus centre disproportionally impacted\ngroups. This paper zooms out and draws the bigger picture. It 1) argues that\nconcerns surrounding algorithmic decision making and algorithmic injustice\nrequire fundamental rethinking above and beyond technical solutions, and 2)\noutlines a way forward in a manner that centres vulnerable groups through the\nlens of relational ethics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 14:04:42 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Birhane", "Abeba", ""], ["Cummins", "Fred", ""]]}, {"id": "1912.07421", "submitter": "Frejus Laleye", "authors": "Fr\\'ejus A. A. Laleye, Antonia Blani\\'e, Antoine Brouquet, Dan\n  Behnamou, Ga\\\"el de Chalendar", "title": "Semantic Similarity To Improve Question Understanding in a Virtual\n  Patient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medicine, a communicating virtual patient or doctor allows students to\ntrain in medical diagnosis and develop skills to conduct a medical\nconsultation. In this paper, we describe a conversational virtual standardized\npatient system to allow medical students to simulate a diagnosis strategy of an\nabdominal surgical emergency. We exploited the semantic properties captured by\ndistributed word representations to search for similar questions in the virtual\npatient dialogue system. We created two dialogue systems that were evaluated on\ndatasets collected during tests with students. The first system based on\nhand-crafted rules obtains $92.29\\%$ as $F1$-score on the studied clinical case\nwhile the second system that combines rules and semantic similarity achieves\n$94.88\\%$. It represents an error reduction of $9.70\\%$ as compared to the\nrules-only-based system.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 14:45:56 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Laleye", "Fr\u00e9jus A. A.", ""], ["Blani\u00e9", "Antonia", ""], ["Brouquet", "Antoine", ""], ["Behnamou", "Dan", ""], ["de Chalendar", "Ga\u00ebl", ""]]}, {"id": "1912.07456", "submitter": "Audrey Girouard", "authors": "Audrey Girouard, Jon E. Froehlich, Regan Mandryk and Mark Hancock", "title": "Organizing Family Support Services at ACM Conferences", "comments": "This article is a complement to an abbreviated version published in\n  the April 2020 issue of the Communications of the ACM. This longer version\n  includes significantly more information on our approach to planning family\n  services at CHI2018, decision making, and our pre-conference and\n  post-conference assessments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reflects on our experiences providing family-support services to\na large, interdisciplinary ACM conference (CHI2018) including, the policy\ndecisions, the challenges, and the successes. The article incorporates\nempirical data collected from pre- and post-conference surveys, observed use of\nthe services, and aspirational aims for future conferences. We are discussing\nbest practices and recommendations to facilitate the implementation of child\nsupport services at other conferences. We believe our article will be of great\ninterest to both practitioners and academics in expanding the inclusivity and\nfamily support provided by ACM conferences and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 17:22:01 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Girouard", "Audrey", ""], ["Froehlich", "Jon E.", ""], ["Mandryk", "Regan", ""], ["Hancock", "Mark", ""]]}, {"id": "1912.07579", "submitter": "Piotr Sapiezynski", "authors": "Piotr Sapiezynski, Avijit Ghosh, Levi Kaplan, Alan Mislove, Aaron\n  Rieke", "title": "Algorithms that \"Don't See Color\": Comparing Biases in Lookalike and\n  Special Ad Audiences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, algorithmic models are shaping important decisions in domains such as\ncredit, employment, or criminal justice. At the same time, these algorithms\nhave been shown to have discriminatory effects. Some organizations have tried\nto mitigate these effects by removing demographic features from an algorithm's\ninputs. If an algorithm is not provided with a feature, one might think, then\nits outputs should not discriminate with respect to that feature. This may not\nbe true, however, when there are other correlated features. In this paper, we\nexplore the limits of this approach using a unique opportunity created by a\nlawsuit settlement concerning discrimination on Facebook's advertising\nplatform. Facebook agreed to modify its Lookalike Audiences tool - which\ncreates target sets of users for ads by identifying users who share \"common\nqualities\" with users in a source audience provided by an advertiser - by\nremoving certain demographic features as inputs to its algorithm. The modified\ntool, Special Ad Audiences, is intended to reduce the potential for\ndiscrimination in target audiences. We create a series of Lookalike and Special\nAd audiences based on biased source audiences - i.e., source audiences that\nhave known skew along the lines of gender, age, race, and political leanings.\nWe show that the resulting Lookalike and Special Ad audiences both reflect\nthese biases, despite the fact that Special Ad Audiences algorithm is not\nprovided with the features along which our source audiences are skewed. More\nbroadly, we provide experimental proof that removing demographic features from\na real-world algorithmic system's inputs can fail to prevent biased outputs.\nOrganizations using algorithms to mediate access to life opportunities should\nconsider other approaches to mitigating discriminatory effects.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:48:15 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 02:52:21 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Sapiezynski", "Piotr", ""], ["Ghosh", "Avijit", ""], ["Kaplan", "Levi", ""], ["Mislove", "Alan", ""], ["Rieke", "Aaron", ""]]}, {"id": "1912.07701", "submitter": "Donatas Narbutis", "authors": "Lucia Larise Stavarache (1), Donatas Narbutis (2), Toyotaro Suzumura\n  (3), Ray Harishankar (1), Augustas \\v{Z}altauskas (2) ((1) IBM Global\n  Business Services, (2) IBM Lithuania, Client Innovation Center Baltic, (3)\n  IBM T.J. Watson Research Center)", "title": "Exploring Multi-Banking Customer-to-Customer Relations in AML Context\n  with Poincar\\'e Embeddings", "comments": "NeurIPS 2019 Workshop on Robust AI in Financial Services\n  (https://sites.google.com/view/robust-ai-in-fs-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CY cs.LG cs.SI q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years money laundering schemes have grown in complexity and\nspeed of realization, affecting financial institutions and millions of\ncustomers globally. Strengthened privacy policies, along with in-country\nregulations, make it hard for banks to inner- and cross-share, and report\nsuspicious activities for the AML (Anti-Money Laundering) measures. Existing\ntopologies and models for AML analysis and information sharing are subject to\nmajor limitations, such as compliance with regulatory constraints, extended\ninfrastructure to run high-computation algorithms, data quality and span,\nproving cumbersome and costly to execute, federate, and interpret. This paper\nproposes a new topology for exploring multi-banking customer social relations\nin AML context -- customer-to-customer, customer-to-transaction, and\ntransaction-to-transaction -- using a 3D modeling topological algebra\nformulated through Poincar\\'e embeddings.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 17:38:11 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 12:31:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Stavarache", "Lucia Larise", ""], ["Narbutis", "Donatas", ""], ["Suzumura", "Toyotaro", ""], ["Harishankar", "Ray", ""], ["\u017daltauskas", "Augustas", ""]]}, {"id": "1912.07850", "submitter": "Bj\\\"orn L\\\"utjens", "authors": "Bj\\\"orn L\\\"utjens, Lucas Liebenwein, Katharina Kramer", "title": "Machine Learning-based Estimation of Forest Carbon Stocks to increase\n  Transparency of Forest Preservation Efforts", "comments": "Published at 2019 NeurIPS Workshop on Tackling Climate Change with\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing amount of companies and cities plan to become CO2-neutral,\nwhich requires them to invest in renewable energies and carbon emission\noffsetting solutions. One of the cheapest carbon offsetting solutions is\npreventing deforestation in developing nations, a major contributor in global\ngreenhouse gas emissions. However, forest preservation projects historically\ndisplay an issue of trust and transparency, which drives companies to invest in\ntransparent, but expensive air carbon capture facilities. Preservation projects\ncould conduct accurate forest inventories (tree diameter, species, height etc.)\nto transparently estimate the biomass and amount of stored carbon. However,\ncurrent rainforest inventories are too inaccurate, because they are often based\non a few expensive ground-based samples and/or low-resolution satellite\nimagery. LiDAR-based solutions, used in US forests, are accurate, but\ncost-prohibitive, and hardly-accessible in the Amazon rainforest. We propose\naccurate and cheap forest inventory analyses through Deep Learning-based\nprocessing of drone imagery. The more transparent estimation of stored carbon\nwill create higher transparency towards clients and thereby increase trust and\ninvestment into forest preservation projects.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 07:27:26 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["L\u00fctjens", "Bj\u00f6rn", ""], ["Liebenwein", "Lucas", ""], ["Kramer", "Katharina", ""]]}, {"id": "1912.08101", "submitter": "Christoph Kinkeldey", "authors": "Christoph Kinkeldey, Jean-Daniel Fekete, Tanja Blascheck and Petra\n  Isenberg", "title": "Visualizing and Analyzing Entity Activity on the Bitcoin Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BitConduite, a visual analytics tool for explorative analysis of\nfinancial activity within the Bitcoin network. Bitcoin is the largest\ncryptocurrency worldwide and a phenomenon that challenges the underpinnings of\ntraditional financial systems - its users can send money pseudo-anonymously\nwhile circumventing traditional banking systems. Yet, despite the fact that all\nfinancial transactions in Bitcoin are available in an openly accessible online\nledger - the blockchain - not much is known about how different types of actors\nin the network (we call them entities) actually use Bitcoin. BitConduite offers\nan entity-centered view on transactions, making the data accessible to\nnon-technical experts through a guided workflow for classification of entities\naccording to several activity metrics. Other novelties are the possibility to\ncluster entities by similarity and exploration of transaction data at different\nscales, from large groups of entities down to a single entity and the\nassociated transactions. Two use cases illustrate the workflow of the system\nand its analytic power. We report on feedback regarding the approach and the\nthe software tool gathered during a workshop with domain experts, and we\ndiscuss the potential of the approach based on our findings.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 15:47:57 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 12:14:06 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Kinkeldey", "Christoph", ""], ["Fekete", "Jean-Daniel", ""], ["Blascheck", "Tanja", ""], ["Isenberg", "Petra", ""]]}, {"id": "1912.08189", "submitter": "Przemyslaw Grabowicz", "authors": "Przemyslaw A. Grabowicz, Nicholas Perello, Kenta Takatsu", "title": "Resilience of Supervised Learning Algorithms to Discriminatory Data\n  Perturbations", "comments": "17 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrimination is a focal concern in supervised learning algorithms\naugmenting human decision-making. These systems are trained using historical\ndata, which may have been tainted by discrimination, and may learn biases\nagainst the protected groups. An important question is how to train models\nwithout propagating discrimination. In this study, we i) define and model\ndiscrimination as perturbations of a data-generating process and show how\ndiscrimination can be induced via attributes correlated with the protected\nattributes; ii) introduce a measure of resilience of a supervised learning\nalgorithm to potentially discriminatory data perturbations, iii) propose a\nnovel supervised learning algorithm that inhibits discrimination, and iv) show\nthat it is more resilient to discriminatory perturbations in synthetic and\nreal-world datasets than state-of-the-art learning algorithms. The proposed\nmethod can be used with general supervised learning algorithms and avoids\ninducement of discrimination, while maximizing model accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 18:53:23 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 18:50:51 GMT"}, {"version": "v3", "created": "Tue, 23 Feb 2021 02:40:29 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Grabowicz", "Przemyslaw A.", ""], ["Perello", "Nicholas", ""], ["Takatsu", "Kenta", ""]]}, {"id": "1912.08197", "submitter": "Sungwon Han", "authors": "Sungwon Han, Donghyun Ahn, Hyunji Cha, Jeasurk Yang, Sungwon Park,\n  Meeyoung Cha", "title": "Lightweight and Robust Representation of Economic Scales from Satellite\n  Imagery", "comments": "Accepted for oral presentation at AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satellite imagery has long been an attractive data source that provides a\nwealth of information on human-inhabited areas. While super resolution\nsatellite images are rapidly becoming available, little study has focused on\nhow to extract meaningful information about human habitation patterns and\neconomic scales from such data. We present READ, a new approach for obtaining\nessential spatial representation for any given district from high-resolution\nsatellite imagery based on deep neural networks. Our method combines transfer\nlearning and embedded statistics to efficiently learn critical spatial\ncharacteristics of arbitrary size areas and represent them into a fixed-length\nvector with minimal information loss. Even with a small set of labels, READ can\ndistinguish subtle differences between rural and urban areas and infer the\ndegree of urbanization. An extensive evaluation demonstrates the model\noutperforms the state-of-the-art in predicting economic scales, such as\npopulation density for South Korea (R^2=0.9617), and shows a high potential use\nfor developing countries where district-level economic scales are not known.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 11:53:01 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Han", "Sungwon", ""], ["Ahn", "Donghyun", ""], ["Cha", "Hyunji", ""], ["Yang", "Jeasurk", ""], ["Park", "Sungwon", ""], ["Cha", "Meeyoung", ""]]}, {"id": "1912.08320", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger, Kevin Yu, Yanlai Yang, Mindy Dai, Jie Qiu, Rebekah\n  Tang, Jenny Huang", "title": "Garbage In, Garbage Out? Do Machine Learning Application Papers in\n  Social Computing Report Where Human-Labeled Training Data Comes From?", "comments": "18 pages, includes appendix", "journal-ref": "Proc ACM FAT* 2020", "doi": "10.1145/3351095.3372862", "report-no": null, "categories": "cs.CY cs.CL cs.DL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many machine learning projects for new application areas involve teams of\nhumans who label data for a particular purpose, from hiring crowdworkers to the\npaper's authors labeling the data themselves. Such a task is quite similar to\n(or a form of) structured content analysis, which is a longstanding methodology\nin the social sciences and humanities, with many established best practices. In\nthis paper, we investigate to what extent a sample of machine learning\napplication papers in social computing --- specifically papers from ArXiv and\ntraditional publications performing an ML classification task on Twitter data\n--- give specific details about whether such best practices were followed. Our\nteam conducted multiple rounds of structured content analysis of each paper,\nmaking determinations such as: Does the paper report who the labelers were,\nwhat their qualifications were, whether they independently labeled the same\nitems, whether inter-rater reliability metrics were disclosed, what level of\ntraining and/or instructions were given to labelers, whether compensation for\ncrowdworkers is disclosed, and if the training data is publicly available. We\nfind a wide divergence in whether such practices were followed and documented.\nMuch of machine learning research and education focuses on what is done once a\n\"gold standard\" of training data is available, but we discuss issues around the\nequally-important aspect of whether such data is reliable in the first place.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 23:49:19 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Geiger", "R. Stuart", ""], ["Yu", "Kevin", ""], ["Yang", "Yanlai", ""], ["Dai", "Mindy", ""], ["Qiu", "Jie", ""], ["Tang", "Rebekah", ""], ["Huang", "Jenny", ""]]}, {"id": "1912.08388", "submitter": "Vedant Nanda", "authors": "Vedant Nanda and Pan Xu and Karthik Abinav Sankararaman and John P.\n  Dickerson and Aravind Srinivasan", "title": "Balancing the Tradeoff between Profit and Fairness in Rideshare\n  Platforms During High-Demand Hours", "comments": "8 pages, 4 figures, Accepted at AAAI 2020 & AIES (Oral) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rideshare platforms, when assigning requests to drivers, tend to maximize\nprofit for the system and/or minimize waiting time for riders. Such platforms\ncan exacerbate biases that drivers may have over certain types of requests. We\nconsider the case of peak hours when the demand for rides is more than the\nsupply of drivers. Drivers are well aware of their advantage during the peak\nhours and can choose to be selective about which rides to accept. Moreover, if\nin such a scenario, the assignment of requests to drivers (by the platform) is\nmade only to maximize profit and/or minimize wait time for riders, requests of\na certain type (e.g. from a non-popular pickup location, or to a non-popular\ndrop-off location) might never be assigned to a driver. Such a system can be\nhighly unfair to riders. However, increasing fairness might come at a cost of\nthe overall profit made by the rideshare platform. To balance these conflicting\ngoals, we present a flexible, non-adaptive algorithm, \\lpalg, that allows the\nplatform designer to control the profit and fairness of the system via\nparameters $\\alpha$ and $\\beta$ respectively. We model the matching problem as\nan online bipartite matching where the set of drivers is offline and requests\narrive online. Upon the arrival of a request, we use \\lpalg to assign it to a\ndriver (the driver might then choose to accept or reject it) or reject the\nrequest. We formalize the measures of profit and fairness in our setting and\nshow that by using \\lpalg, the competitive ratios for profit and fairness\nmeasures would be no worse than $\\alpha/e$ and $\\beta/e$ respectively.\nExtensive experimental results on both real-world and synthetic datasets\nconfirm the validity of our theoretical lower bounds. Additionally, they show\nthat $\\lpalg$ under some choice of $(\\alpha, \\beta)$ can beat two natural\nheuristics, Greedy and Uniform, on \\emph{both} fairness and profit.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 05:39:11 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 01:41:53 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Nanda", "Vedant", ""], ["Xu", "Pan", ""], ["Sankararaman", "Karthik Abinav", ""], ["Dickerson", "John P.", ""], ["Srinivasan", "Aravind", ""]]}, {"id": "1912.08473", "submitter": "Daniel Graziotin", "authors": "Falko Koetter, Matthias Blohm, Jens Drawehn, Monika Kochanowski,\n  Joscha Goetzer, Daniel Graziotin, Stefan Wagner", "title": "Conversational Agents for Insurance Companies: From Theory to Practice", "comments": "26 pages, 7 figures. ICAART 2019 extension. Extension of\n  arXiv:1812.07339", "journal-ref": "Koetter F. et al. (2019) Conversational Agents for Insurance\n  Companies: From Theory to Practice. In: Agents and Artificial Intelligence.\n  ICAART 2019. LNCS, vol 11978. Springer, Cham", "doi": "10.1007/978-3-030-37494-5_17", "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in artificial intelligence have renewed interest in conversational\nagents. Additionally to software developers, today all kinds of employees show\ninterest in new technologies and their possible applications for customers.\nGerman insurance companies generally are interested in improving their customer\nservice and digitizing their business processes. In this work we investigate\nthe potential use of conversational agents in insurance companies theoretically\nby determining which classes of agents exist which are of interest to insurance\ncompanies, finding relevant use cases and requirements. We add two practical\nparts: First we develop a showcase prototype for an exemplary insurance\nscenario in claim management. Additionally in a second step, we create a\nprototype focusing on customer service in a chatbot hackathon, fostering\ninnovation in interdisciplinary teams. In this work, we describe the results of\nboth prototypes in detail. We evaluate both chatbots defining criteria for both\nsettings in detail and compare the results and draw conclusions for the\nmaturity of chatbot technology for practical use, describing the opportunities\nand challenges companies, especially small and medium enterprises, face.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 09:26:55 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Koetter", "Falko", ""], ["Blohm", "Matthias", ""], ["Drawehn", "Jens", ""], ["Kochanowski", "Monika", ""], ["Goetzer", "Joscha", ""], ["Graziotin", "Daniel", ""], ["Wagner", "Stefan", ""]]}, {"id": "1912.08590", "submitter": "Kushagra Singh", "authors": "Kushagra Singh, Gurshabad Grover, and Varun Bansal", "title": "How India Censors the Web", "comments": null, "journal-ref": null, "doi": "10.1145/3394231.3397891", "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary ways in which India engages in online censorship is by\nordering Internet Service Providers (ISPs) operating in its jurisdiction to\nblock access to certain websites for its users. This paper reports the\ndifferent techniques Indian ISPs are using to censor websites, and investigates\nwhether website blocklists are consistent across ISPs. We propose a suite of\ntests that prove more robust than previous work in detecting DNS and HTTP based\ncensorship. Our tests also discern the use of SNI inspection for blocking\nwebsites, which is previously undocumented in the Indian context. Using\ninformation from court orders, user reports, and public and leaked government\norders, we compile the largest known list of potentially blocked websites in\nIndia. We pass this list to our tests and run them from connections of six\ndifferent ISPs, which together serve more than 98% of Internet users in India.\nOur findings not only confirm that ISPs are using different techniques to block\nwebsites, but also demonstrate that different ISPs are not blocking the same\nwebsites.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 13:32:53 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 12:31:39 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Singh", "Kushagra", ""], ["Grover", "Gurshabad", ""], ["Bansal", "Varun", ""]]}, {"id": "1912.08786", "submitter": "Thomas Bartz-Beielstein", "authors": "Thomas Bartz-Beielstein", "title": "Why we need an AI-resilient society", "comments": "For associated TEDx video, see https://youtu.be/f6c2ngp7rqY", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial intelligence is considered as a key technology. It has a huge\nimpact on our society. Besides many positive effects, there are also some\nnegative effects or threats. Some of these threats to society are well-known,\ne.g., weapons or killer robots. But there are also threats that are ignored.\nThese unknown-knowns or blind spots affect privacy, and facilitate manipulation\nand mistaken identities. We cannot trust data, audio, video, and identities any\nmore. Democracies are able to cope with known threats, the known-knowns.\nTransforming unknown-knowns to known-knowns is one important cornerstone of\nresilient societies. An AI-resilient society is able to transform threats\ncaused by new AI tecchnologies such as generative adversarial networks.\nResilience can be seen as a positive adaptation of these threats. We propose\nthree strategies how this adaptation can be achieved: awareness, agreements,\nand red flags. This article accompanies the TEDx talk \"Why we urgently need an\nAI-resilient society\", see https://youtu.be/f6c2ngp7rqY.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 18:36:20 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""]]}, {"id": "1912.08868", "submitter": "Rashid Mehdiyev Dr", "authors": "Rashid Mehdiyev, Jean Nava, Karan Sodhi, Saurav Acharya, Annie Ibrahim\n  Rana", "title": "Topic subject creation using unsupervised learning for topic modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the use of Non-Negative Matrix Factorization (NMF) and Latent\nDirichlet Allocation (LDA) algorithms to perform topic mining and labelling\napplied to retail customer communications in attempt to characterize the\nsubject of customers inquiries. In this paper we compare both algorithms in the\ntopic mining performance and propose methods to assign topic subject labels in\nan automated way.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 20:11:03 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Mehdiyev", "Rashid", ""], ["Nava", "Jean", ""], ["Sodhi", "Karan", ""], ["Acharya", "Saurav", ""], ["Rana", "Annie Ibrahim", ""]]}, {"id": "1912.08964", "submitter": "Ross Gruetzemacher", "authors": "Shahar Avin, Ross Gruetzemacher, James Fox", "title": "Exploring AI Futures Through Role Play", "comments": "Accepted to AIES", "journal-ref": null, "doi": "10.1145/3375627.3375817", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present an innovative methodology for studying and teaching the impacts of\nAI through a role play game. The game serves two primary purposes: 1) training\nAI developers and AI policy professionals to reflect on and prepare for future\nsocial and ethical challenges related to AI and 2) exploring possible futures\ninvolving AI technology development, deployment, social impacts, and\ngovernance. While the game currently focuses on the inter relations between\nshort --, mid and long term impacts of AI, it has potential to be adapted for a\nbroad range of scenarios, exploring in greater depths issues of AI policy\nresearch and affording training within organizations. The game presented here\nhas undergone two years of development and has been tested through over 30\nevents involving between 3 and 70 participants. The game is under active\ndevelopment, but preliminary findings suggest that role play is a promising\nmethodology for both exploring AI futures and training individuals and\norganizations in thinking about, and reflecting on, the impacts of AI and\nstrategic mistakes that can be avoided today.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 00:41:11 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Avin", "Shahar", ""], ["Gruetzemacher", "Ross", ""], ["Fox", "James", ""]]}, {"id": "1912.09004", "submitter": "Joseph Chow", "authors": "Susan Jia Xu, Joseph Y. J. Chow", "title": "Online route choice modeling for Mobility-as-a-Service networks with\n  non-separable, congestible link capacity effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the prevalence of MaaS systems, route choice models need to consider\ncharacteristics unique to them. MaaS systems tend to involve service systems\nwith fleets of vehicles; as a result, the available service capacity depends on\nthe choices of other travelers in different parts of the system. We model this\nwith a new concept of \"congestible capacity\"; that is, link capacities are a\nfunction of flow instead of link costs. This dependency is also non-separable;\nthe capacity in one link can depend on flows from multiple links. An\noffline-online estimation method is introduced to capture the structural\neffects that flows have on capacities and the resulting impacts on route choice\nutilities. The method is first applied to obtain unique congestible capacity\nshadow prices in a multimodal network to verify the capability to capture\ncongestion effects on capacities. The capacities are shown to vary and impact\nthe utility of a route. The method is validated using real system data from\nCiti Bike in New York City. The results show that the model can fit to the data\nquite well and performs better than a baseline modeling approach that ignores\ncongestible capacity effects. By relating the route choice to congestible\ncapacities using a random utility model, modelers can monitor and quantify the\nimpacts to traveler consumer surplus in real time. Applications of the model\nand online method include monitoring capacity effects on consumer surplus,\nusing the model to direct incentives programs for rebalancing and other revenue\nmanagement strategies, and to guide resource allocation to mitigate consumer\nsurplus impacts due to disruptions from incidents.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 03:31:18 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 02:23:15 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Xu", "Susan Jia", ""], ["Chow", "Joseph Y. J.", ""]]}, {"id": "1912.09210", "submitter": "Carlo Michele Valensise", "authors": "Carlo Michele Valensise (1), Matteo Cinelli (2), Alessandro Galeazzi\n  (3), Walter Quattrociocchi (4) ((1) Department of Physics, Politecnico di\n  Milano, (2) Applico Lab, CNR-ISC, (3) Department of Information Engineering,\n  University of Brescia, (4) Department of Environmental Sciences, Informatics\n  and Statistics, University of Venice \"Ca' Foscari\")", "title": "Drifts and Shifts: Characterizing the Evolution of Users Interests on\n  Reddit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selective exposure is the main driver for the economy of attention when\nconsuming online content. We select information adhering to our system of\nbeliefs and ignore dissenting information. However, even personal interest is\nlikely to play a role in determining our attention patterns. To understand in\nmore detail the dynamics of interest-driven choices, we address the evolution\nof users' interest on Reddit by means of an analysis on more than 7 million of\nusers. We observe that the lifetime distribution of users on subreddits (online\nthematic communities) is 'short' with respect to the observation period.\nFurthermore, users tend to be active on a very limited number of subreddits\nwith respect to the wide offer of the platform. These aspects indicate the\npresence of a migrating behavior of users among subreddits. To characterize\nthis phenomenon we propose a metric based on a geometrical encoding of the\n'interest space' of the user. The movement of users across subreddits is\ncharacterized by a bursty trend, made of sudden variations. The most frequent\nof them take place between recreational subreddits and those more related to\nnews and politics. We describe this kind of activity with two behaviors called\ninterest drift and interest shift. Our results suggest that selective exposure\nand personal interest coexist in driving content consumption.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 14:20:06 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Valensise", "Carlo Michele", ""], ["Cinelli", "Matteo", ""], ["Galeazzi", "Alessandro", ""], ["Quattrociocchi", "Walter", ""]]}, {"id": "1912.09318", "submitter": "Aaron Alvero", "authors": "AJ Alvero, Noah Arthurs, anthony lising antonio, Benjamin W. Domingue,\n  Ben Gebre-Medhin, Sonia Giebel, Mitchell L. Stevens", "title": "AI and Holistic Review: Informing Human Reading in College Admissions", "comments": "AIES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  College admissions in the United States is carried out by a human-centered\nmethod of evaluation known as holistic review, which typically involves reading\noriginal narrative essays submitted by each applicant. The legitimacy and\nfairness of holistic review, which gives human readers significant discretion\nover determining each applicant's fitness for admission, has been repeatedly\nchallenged in courtrooms and the public sphere. Using a unique corpus of\n283,676 application essays submitted to a large, selective, state university\nsystem between 2015 and 2016, we assess the extent to which applicant\ndemographic characteristics can be inferred from application essays. We find a\nrelatively interpretable classifier (logistic regression) was able to predict\ngender and household income with high levels of accuracy. Findings suggest that\ndata auditing might be useful in informing holistic review, and perhaps other\nevaluative systems, by checking potential bias in human or computational\nreadings.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 21:08:36 GMT"}], "update_date": "2019-12-21", "authors_parsed": [["Alvero", "AJ", ""], ["Arthurs", "Noah", ""], ["antonio", "anthony lising", ""], ["Domingue", "Benjamin W.", ""], ["Gebre-Medhin", "Ben", ""], ["Giebel", "Sonia", ""], ["Stevens", "Mitchell L.", ""]]}, {"id": "1912.09425", "submitter": "Xinyu Xiao", "authors": "Xinyu Xiao, Qiuming Kuang, Shiming Xiang, Junnan Hu, Chunhong Pan", "title": "Precipitation Forecasting via Multi-Scale Deconstructed ConvLSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical Weather Prediction (NWP), is widely used in precipitation\nforecasting, based on complex equations of atmospheric motion requires\nsupercomputers to infer the state of the atmosphere. Due to the complexity of\nthe task and the huge computation, this methodology has the problems of\ninefficiency and non-economic. With the rapid development of meteorological\ntechnology, the collection of plentiful numerical meteorological data offers\nopportunities to develop data-driven models for NMP task. In this paper, we\nconsider to combine NWP with deep learning. Firstly, to improve the\nspatiotemporal modeling of meteorological elements, a deconstruction mechanism\nand the multi-scale filters are composed to propose a multi-scale deconstructed\nConvLSTM (MSD-ConvLSTM). The MSD-ConvLSTM captures and fuses the contextual\ninformation by multi-scale filters with low parameter consumption. Furthermore,\nan encoder-decoder is constructed to encode the features of multiple\nmeteorological elements by deep CNN and decode the spatiotemporal information\nfrom different elements by the MSD-ConvLSTM. Our method demonstrates the\ndata-driven way is significance for the weather prediction, which can be\nconfirmed from the experimental results of precipitation forecasting on the\nEuropean Centre Weather Forecasts (EC) and China Meteorological Forecasts (CM)\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 03:04:03 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 14:51:17 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Xiao", "Xinyu", ""], ["Kuang", "Qiuming", ""], ["Xiang", "Shiming", ""], ["Hu", "Junnan", ""], ["Pan", "Chunhong", ""]]}, {"id": "1912.10389", "submitter": "Eun Seo Jo", "authors": "Eun Seo Jo, Timnit Gebru", "title": "Lessons from Archives: Strategies for Collecting Sociocultural Data in\n  Machine Learning", "comments": "To be published in Conference on Fairness, Accountability, and\n  Transparency FAT* '20, January 27-30, 2020, Barcelona, Spain. ACM, New York,\n  NY, USA, 11 pages", "journal-ref": null, "doi": "10.1145/3351095.3372829", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of work shows that many problems in fairness, accountability,\ntransparency, and ethics in machine learning systems are rooted in decisions\nsurrounding the data collection and annotation process. In spite of its\nfundamental nature however, data collection remains an overlooked part of the\nmachine learning (ML) pipeline. In this paper, we argue that a new\nspecialization should be formed within ML that is focused on methodologies for\ndata collection and annotation: efforts that require institutional frameworks\nand procedures. Specifically for sociocultural data, parallels can be drawn\nfrom archives and libraries. Archives are the longest standing communal effort\nto gather human information and archive scholars have already developed the\nlanguage and procedures to address and discuss many challenges pertaining to\ndata collection such as consent, power, inclusivity, transparency, and ethics &\nprivacy. We discuss these five key approaches in document collection practices\nin archives that can inform data collection in sociocultural ML. By showing\ndata collection practices from another field, we encourage ML research to be\nmore cognizant and systematic in data collection and draw from\ninterdisciplinary expertise.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 05:56:55 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Jo", "Eun Seo", ""], ["Gebru", "Timnit", ""]]}, {"id": "1912.10528", "submitter": "Stanis{\\l}aw Saganowski", "authors": "Stanis{\\l}aw Saganowski, Anna Dutkowiak, Adam Dziadek, Maciej\n  Dzie\\.zyc, Joanna Komoszy\\'nska, Weronika Michalska, Adam Polak, Micha{\\l}\n  Ujma, Przemys{\\l}aw Kazienko", "title": "Emotion Recognition Using Wearables: A Systematic Literature Review Work\n  in progress", "comments": "6 pages, accepted to the Emotion Aware 2020 workshop. Copyright 2019\n  IEEE. Personal use of this material is permitted. Permission from IEEE must\n  be obtained for all other uses, in any current or future media", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearables like smartwatches or wrist bands equipped with pervasive sensors\nenable us to monitor our physiological signals. In this study, we address the\nquestion whether they can help us to recognize our emotions in our everyday\nlife for ubiquitous computing. Using the systematic literature review, we\nidentified crucial research steps and discussed the main limitations and\nproblems in the domain.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 20:37:30 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 11:22:52 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Saganowski", "Stanis\u0142aw", ""], ["Dutkowiak", "Anna", ""], ["Dziadek", "Adam", ""], ["Dzie\u017cyc", "Maciej", ""], ["Komoszy\u0144ska", "Joanna", ""], ["Michalska", "Weronika", ""], ["Polak", "Adam", ""], ["Ujma", "Micha\u0142", ""], ["Kazienko", "Przemys\u0142aw", ""]]}, {"id": "1912.10564", "submitter": "Julia Stoyanovich", "authors": "Julia Stoyanovich and Armanda Lewis", "title": "Teaching Responsible Data Science: Charting New Pedagogical Territory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although numerous ethics courses are available, with many focusing\nspecifically on technology and computer ethics, pedagogical approaches employed\nin these courses rely exclusively on texts rather than on software development\nor data analysis. Technical students often consider these courses unimportant\nand a distraction from the \"real\" material. To develop instructional materials\nand methodologies that are thoughtful and engaging, we must strive for balance:\nbetween texts and coding, between critique and solution, and between\ncutting-edge research and practical applicability. Finding such balance is\nparticularly difficult in the nascent field of responsible data science (RDS),\nwhere we are only starting to understand how to interface between the\nintrinsically different methodologies of engineering and social sciences. In\nthis paper we recount a recent experience in developing and teaching an RDS\ncourse to graduate and advanced undergraduate students in data science. We then\ndive into an area that is critically important to RDS -- transparency and\ninterpretability of machine-assisted decision-making, and tie this area to the\nneeds of emerging RDS curricula. Recounting our own experience, and leveraging\nliterature on pedagogical methods in data science and beyond, we propose the\nnotion of an \"object-to-interpret-with\". We link this notion to \"nutritional\nlabels\" -- a family of interpretability tools that are gaining popularity in\nRDS research and practice. With this work we aim to contribute to the nascent\narea of RDS education, and to inspire others in the community to come together\nto develop a deeper theoretical understanding of the pedagogical needs of RDS,\nand contribute concrete educational materials and methodologies that others can\nuse. All course materials are publicly available at\nhttps://dataresponsibly.github.io/courses.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 00:10:22 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Stoyanovich", "Julia", ""], ["Lewis", "Armanda", ""]]}, {"id": "1912.10795", "submitter": "Matteo Cinelli", "authors": "Matteo Cinelli, Mauro Conti, Livio Finos, Francesco Grisolia, Petra\n  Kralj Novak, Antonio Peruzzi, Maurizio Tesconi, Fabiana Zollo, Walter\n  Quattrociocchi", "title": "(Mis)Information Operations: An Integrated Perspective", "comments": "The paper first appeared in Volume 18, Issue 3 of the Journal of\n  Information Warfare", "journal-ref": "Journal of Information Warfare (2019) 18.2: 83-98", "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive diffusion of social media fosters disintermediation and changes\nthe way users are informed, the way they process reality, and the way they\nengage in public debate. The cognitive layer of users and the related social\ndynamics define the nature and the dimension of informational threats. Users\nshow the tendency to interact with information adhering to their preferred\nnarrative and to ignore dissenting information. Confirmation bias seems to\naccount for users decisions about consuming and spreading content; and, at the\nsame time, aggregation of favored information within those communities\nreinforces group polarization. In this work, the authors address the problem of\n(mis)information operations with a holistic and integrated approach. Cognitive\nweakness induced by this new information environment are considered. Moreover,\n(mis)information operations, with particular reference to the Italian context,\nare considered; and the fact that the phenomenon is more complex than expected\nis highlighted. The paper concludes by providing an integrated research roadmap\naccounting for the possible future technological developments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 13:30:41 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Cinelli", "Matteo", ""], ["Conti", "Mauro", ""], ["Finos", "Livio", ""], ["Grisolia", "Francesco", ""], ["Novak", "Petra Kralj", ""], ["Peruzzi", "Antonio", ""], ["Tesconi", "Maurizio", ""], ["Zollo", "Fabiana", ""], ["Quattrociocchi", "Walter", ""]]}, {"id": "1912.10818", "submitter": "Daniel Acuna", "authors": "Lizhen Liang and Daniel E. Acuna", "title": "Artificial mental phenomena: Psychophysics as a framework to detect\n  perception biases in AI models", "comments": "FAT Conference 2020", "journal-ref": null, "doi": "10.1145/3351095.3375623", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting biases in artificial intelligence has become difficult because of\nthe impenetrable nature of deep learning. The central difficulty is in relating\nunobservable phenomena deep inside models with observable, outside quantities\nthat we can measure from inputs and outputs. For example, can we detect\ngendered perceptions of occupations (e.g., female librarian, male electrician)\nusing questions to and answers from a word embedding-based system? Current\ntechniques for detecting biases are often customized for a task, dataset, or\nmethod, affecting their generalization. In this work, we draw from\nPsychophysics in Experimental Psychology---meant to relate quantities from the\nreal world (i.e., \"Physics\") into subjective measures in the mind (i.e.,\n\"Psyche\")---to propose an intellectually coherent and generalizable framework\nto detect biases in AI. Specifically, we adapt the two-alternative forced\nchoice task (2AFC) to estimate potential biases and the strength of those\nbiases in black-box models. We successfully reproduce previously-known biased\nperceptions in word embeddings and sentiment analysis predictions. We discuss\nhow concepts in experimental psychology can be naturally applied to\nunderstanding artificial mental phenomena, and how psychophysics can form a\nuseful methodological foundation to study fairness in AI.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2019 19:48:48 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Liang", "Lizhen", ""], ["Acuna", "Daniel E.", ""]]}, {"id": "1912.11084", "submitter": "Gian Maria Campedelli", "authors": "Gian Maria Campedelli", "title": "Where Are We? Using Scopus to Map the Literature at the Intersection\n  Between Artificial Intelligence and Research on Crime", "comments": "25 pages, 12 figures, pre-print (currently R&R in JCSS)", "journal-ref": "J Comput Soc Sc (2020)", "doi": "10.1007/s42001-020-00082-9", "report-no": null, "categories": "cs.DL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Research on Artificial Intelligence (AI) applications has spread over many\nscientific disciplines. Scientists have tested the power of intelligent\nalgorithms developed to predict (or learn from) natural, physical and social\nphenomena. This also applies to crime-related research problems. Nonetheless,\nstudies that map the current state of the art at the intersection between AI\nand crime are lacking. What are the current research trends in terms of topics\nin this area? What is the structure of scientific collaboration when\nconsidering works investigating criminal issues using machine learning, deep\nlearning, and AI in general? What are the most active countries in this\nspecific scientific sphere? Using data retrieved from the Scopus database, this\nwork quantitatively analyzes 692 published works at the intersection between AI\nand crime employing network science to respond to these questions. Results show\nthat researchers are mainly focusing on cyber-related criminal topics and that\nrelevant themes such as algorithmic discrimination, fairness, and ethics are\nconsiderably overlooked. Furthermore, data highlight the extremely disconnected\nstructure of co-authorship networks. Such disconnectedness may represent a\nsubstantial obstacle to a more solid community of scientists interested in\nthese topics. Additionally, the graph of scientific collaboration indicates\nthat countries that are more prone to engage in international partnerships are\ngenerally less central in the network. This means that scholars working in\nhighly productive countries (e.g. the United States, China) tend to mostly\ncollaborate domestically. Finally, current issues and future developments\nwithin this scientific area are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 19:55:52 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 23:23:57 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Campedelli", "Gian Maria", ""]]}, {"id": "1912.11095", "submitter": "P. M. Krafft", "authors": "P. M. Krafft, Meg Young, Michael Katell, Karen Huang, Ghislain Bugingo", "title": "Defining AI in Policy versus Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent concern about harms of information technologies motivate consideration\nof regulatory action to forestall or constrain certain developments in the\nfield of artificial intelligence (AI). However, definitional ambiguity hampers\nthe possibility of conversation about this urgent topic of public concern.\nLegal and regulatory interventions require agreed-upon definitions, but\nconsensus around a definition of AI has been elusive, especially in policy\nconversations. With an eye towards practical working definitions and a broader\nunderstanding of positions on these issues, we survey experts and review\npublished policy documents to examine researcher and policy-maker conceptions\nof AI. We find that while AI researchers favor definitions of AI that emphasize\ntechnical functionality, policy-makers instead use definitions that compare\nsystems to human thinking and behavior. We point out that definitions adhering\nclosely to the functionality of AI systems are more inclusive of technologies\nin use today, whereas definitions that emphasize human-like capabilities are\nmost applicable to hypothetical future technologies. As a result of this gap,\nethical and regulatory efforts may overemphasize concern about future\ntechnologies at the expense of pressing issues with existing deployed\ntechnologies.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 20:18:21 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Krafft", "P. M.", ""], ["Young", "Meg", ""], ["Katell", "Michael", ""], ["Huang", "Karen", ""], ["Bugingo", "Ghislain", ""]]}, {"id": "1912.11595", "submitter": "Cullen O'Keefe", "authors": "Cullen O'Keefe, Peter Cihon, Ben Garfinkel, Carrick Flynn, Jade Leung,\n  Allan Dafoe", "title": "The Windfall Clause: Distributing the Benefits of AI for the Common Good", "comments": "Short version to be published in proceedings of AIES", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the transformative potential of AI has become increasingly salient as a\nmatter of public and political interest, there has been growing discussion\nabout the need to ensure that AI broadly benefits humanity. This in turn has\nspurred debate on the social responsibilities of large technology companies to\nserve the interests of society at large. In response, ethical principles and\ncodes of conduct have been proposed to meet the escalating demand for this\nresponsibility to be taken seriously. As yet, however, few institutional\ninnovations have been suggested to translate this responsibility into legal\ncommitments which apply to companies positioned to reap large financial gains\nfrom the development and use of AI. This paper offers one potentially\nattractive tool for addressing such issues: the Windfall Clause, which is an ex\nante commitment by AI firms to donate a significant amount of any eventual\nextremely large profits. By this we mean an early commitment that profits that\na firm could not earn without achieving fundamental, economically\ntransformative breakthroughs in AI capabilities will be donated to benefit\nhumanity broadly, with particular attention towards mitigating any downsides\nfrom deployment of windfall-generating AI.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 05:30:40 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 18:43:43 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["O'Keefe", "Cullen", ""], ["Cihon", "Peter", ""], ["Garfinkel", "Ben", ""], ["Flynn", "Carrick", ""], ["Leung", "Jade", ""], ["Dafoe", "Allan", ""]]}, {"id": "1912.11598", "submitter": "Saurabh Bagchi", "authors": "Saurabh Bagchi, Vaneet Aggarwal, Somali Chaterji, Fred Douglis, Aly El\n  Gamal, Jiawei Han, Brian J. Henz, Hank Hoffmann, Suman Jana, Milind Kulkarni,\n  Felix Xiaozhu Lin, Karen Marais, Prateek Mittal, Shaoshuai Mou, Xiaokang Qiu,\n  and Gesualdo Scutari", "title": "Grand Challenges in Resilience: Autonomous System Resilience through\n  Design and Runtime Measures", "comments": null, "journal-ref": "IEEE Open Journal of the Computer Society, 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of about 80 researchers, practitioners, and federal agency program\nmanagers participated in the NSF-sponsored Grand Challenges in Resilience\nWorkshop held on Purdue campus on March 19-21, 2019. The workshop was divided\ninto three themes: resilience in cyber, cyber-physical, and socio-technical\nsystems. About 30 attendees in all participated in the discussions of cyber\nresilience. This article brings out the substantive parts of the challenges and\nsolution approaches that were identified in the cyber resilience theme. In this\narticle, we put forward the substantial challenges in cyber resilience in a few\nrepresentative application domains and outline foundational solutions to\naddress these challenges. These solutions fall into two broad themes:\nresilience-by-design and resilience-by-reaction. We use examples of autonomous\nsystems as the application drivers motivating cyber resilience. We focus on\nsome autonomous systems in the near horizon (autonomous ground and aerial\nvehicles) and also a little more distant (autonomous rescue and relief).\n  For resilience-by-design, we focus on design methods in software that are\nneeded for our cyber systems to be resilient. In contrast, for\nresilience-by-reaction, we discuss how to make systems resilient by responding,\nreconfiguring, or recovering at runtime when failures happen. We also discuss\nthe notion of adaptive execution to improve resilience, execution transparently\nand adaptively among available execution platforms (mobile/embedded, edge, and\ncloud). For each of the two themes, we survey the current state, and the\ndesired state and ways to get there. We conclude the paper by looking at the\nresearch challenges we will have to solve in the short and the mid-term to make\nthe vision of resilient autonomous systems a reality.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 05:46:43 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 04:27:53 GMT"}, {"version": "v3", "created": "Sat, 9 May 2020 15:32:57 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bagchi", "Saurabh", ""], ["Aggarwal", "Vaneet", ""], ["Chaterji", "Somali", ""], ["Douglis", "Fred", ""], ["Gamal", "Aly El", ""], ["Han", "Jiawei", ""], ["Henz", "Brian J.", ""], ["Hoffmann", "Hank", ""], ["Jana", "Suman", ""], ["Kulkarni", "Milind", ""], ["Lin", "Felix Xiaozhu", ""], ["Marais", "Karen", ""], ["Mittal", "Prateek", ""], ["Mou", "Shaoshuai", ""], ["Qiu", "Xiaokang", ""], ["Scutari", "Gesualdo", ""]]}, {"id": "1912.11945", "submitter": "Alexandra Luccioni", "authors": "Alexandra Luccioni and Yoshua Bengio", "title": "On the Morality of Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much of the existing research on the social and ethical impact of Artificial\nIntelligence has been focused on defining ethical principles and guidelines\nsurrounding Machine Learning (ML) and other Artificial Intelligence (AI)\nalgorithms [IEEE, 2017, Jobin et al., 2019]. While this is extremely useful for\nhelping define the appropriate social norms of AI, we believe that it is\nequally important to discuss both the potential and risks of ML and to inspire\nthe community to use ML for beneficial objectives. In the present article,\nwhich is specifically aimed at ML practitioners, we thus focus more on the\nlatter, carrying out an overview of existing high-level ethical frameworks and\nguidelines, but above all proposing both conceptual and practical principles\nand guidelines for ML research and deployment, insisting on concrete actions\nthat can be taken by practitioners to pursue a more ethical and moral practice\nof ML aimed at using AI for social good.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 23:06:54 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Luccioni", "Alexandra", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1912.12012", "submitter": "Teng Guo", "authors": "Teng Guo, Feng Xia, Shihao Zhen, Xiaomei Bai, Dongyu Zhang, Zitao Liu,\n  Jiliang Tang", "title": "Graduate Employment Prediction with Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The failure of landing a job for college students could cause serious social\nconsequences such as drunkenness and suicide. In addition to academic\nperformance, unconscious biases can become one key obstacle for hunting jobs\nfor graduating students. Thus, it is necessary to understand these unconscious\nbiases so that we can help these students at an early stage with more\npersonalized intervention. In this paper, we develop a framework, i.e., MAYA\n(Multi-mAjor emploYment stAtus) to predict students' employment status while\nconsidering biases. The framework consists of four major components. Firstly,\nwe solve the heterogeneity of student courses by embedding academic performance\ninto a unified space. Then, we apply a generative adversarial network (GAN) to\novercome the class imbalance problem. Thirdly, we adopt Long Short-Term Memory\n(LSTM) with a novel dropout mechanism to comprehensively capture sequential\ninformation among semesters. Finally, we design a bias-based regularization to\ncapture the job market biases. We conduct extensive experiments on a\nlarge-scale educational dataset and the results demonstrate the effectiveness\nof our prediction framework.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 07:30:28 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Guo", "Teng", ""], ["Xia", "Feng", ""], ["Zhen", "Shihao", ""], ["Bai", "Xiaomei", ""], ["Zhang", "Dongyu", ""], ["Liu", "Zitao", ""], ["Tang", "Jiliang", ""]]}, {"id": "1912.12835", "submitter": "Baobao Zhang", "authors": "Baobao Zhang and Allan Dafoe", "title": "U.S. Public Opinion on the Governance of Artificial Intelligence", "comments": "22 pages; 7 figures; 4 tables; accepted for oral presentation at the\n  2020 AAAI/ACM Conference on AI, Ethics, and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has widespread societal implications, yet social\nscientists are only beginning to study public attitudes toward the technology.\nExisting studies find that the public's trust in institutions can play a major\nrole in shaping the regulation of emerging technologies. Using a large-scale\nsurvey (N=2000), we examined Americans' perceptions of 13 AI governance\nchallenges as well as their trust in governmental, corporate, and\nmultistakeholder institutions to responsibly develop and manage AI. While\nAmericans perceive all of the AI governance issues to be important for tech\ncompanies and governments to manage, they have only low to moderate trust in\nthese institutions to manage AI applications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 07:38:38 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhang", "Baobao", ""], ["Dafoe", "Allan", ""]]}, {"id": "1912.12861", "submitter": "Sofia Dokuka", "authors": "Sofia Dokuka, Ivan Zaikin, Kate Furman, Maksim Tsvetovat and Alex\n  Furman", "title": "Wisdom of collaborators: a peer-review approach to performance appraisal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual performance and reputation within a company are major factors that\ninfluence wage distribution, promotion and firing. Due to the complexity and\ncollaborative nature of contemporary business processes, the evaluation of\nindividual impact in the majority of organizations is an ambiguous and\nnon-trivial task. Existing performance appraisal approaches are often affected\nby individuals biased judgements, and organizations are dissatisfied with the\nresults of evaluations. We assert that employees can provide accurate\nmeasurement of their peer performance in a complex collaborative environment.\nWe propose a novel metric, the Peer Rank Score (PRS), that evaluates individual\nreputations and the non-quantifiable individual impact. PRS is based on\npairwise comparisons of employees. We show high robustness of the algorithm on\nsimulations and empirically validate it for a genetic testing company on more\nthan one thousand employees using peer reviews over the course of three years.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 09:23:51 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Dokuka", "Sofia", ""], ["Zaikin", "Ivan", ""], ["Furman", "Kate", ""], ["Tsvetovat", "Maksim", ""], ["Furman", "Alex", ""]]}, {"id": "1912.12999", "submitter": "Laura Kinkead", "authors": "Laura Kinkead, Ahmed Allam, Michael Krauthammer", "title": "AutoDiscern: Rating the Quality of Online Health Information with\n  Hierarchical Encoder Attention-based Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients increasingly turn to search engines and online content before, or in\nplace of, talking with a health professional. Low quality health information,\nwhich is common on the internet, presents risks to the patient in the form of\nmisinformation and a possibly poorer relationship with their physician. To\naddress this, the DISCERN criteria (developed at University of Oxford) are used\nto evaluate the quality of online health information. However, patients are\nunlikely to take the time to apply these criteria to the health websites they\nvisit. We built an automated implementation of the DISCERN instrument (Brief\nversion) using machine learning models. We compared the performance of a\ntraditional model (Random Forest) with that of a hierarchical encoder\nattention-based neural network (HEA) model using two language embeddings, BERT\nand BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores\nacross all criteria of 0.75 and 0.74, respectively, outperforming the Random\nForest model (average F1-macro = 0.69). Overall, the neural network based\nmodels achieved 81% and 86% average accuracy at 100% and 80% coverage,\nrespectively, compared to 94% manual rating accuracy. The attention mechanism\nimplemented in the HEA architectures not only provided 'model explainability'\nby identifying reasonable supporting sentences for the documents fulfilling the\nBrief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the\nsame architecture without an attention mechanism. Our research suggests that it\nis feasible to automate online health information quality assessment, which is\nan important step towards empowering patients to become informed partners in\nthe healthcare process.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:44:41 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 13:52:19 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 16:01:39 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Kinkead", "Laura", ""], ["Allam", "Ahmed", ""], ["Krauthammer", "Michael", ""]]}, {"id": "1912.13050", "submitter": "Michael Mogessie Ashenafi", "authors": "Michael Mogessie Ashenafi", "title": "Online Peer-Assessment Datasets", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Peer-assessment experiments were conducted among first and second year\nstudents at the University of Trento. The experiments spanned an entire\nsemester and were conducted in five computer science courses between 2013 and\n2016. Peer-assessment tasks included question and answer submission as well as\nanswer evaluation tasks. The peer-assessment datasets are complimented by the\nfinal scores of participating students for each course. Teachers were involved\nin filtering out questions submitted by students on a weekly basis. Selected\nquestions were then used in subsequent peer-assessment tasks. However, expert\nratings are not included in the dataset. A major reason for this decision was\nthat peer-assessment tasks were designed with minimal teacher supervision in\nmind. Arguments in favour of this approach are presented. The datasets are\ndesigned in a manner that would allow their utilization in a variety of\nexperiments. They are reported as parsable data structures that, with\nintermediate processing, can be moulded into NLP or ML-ready datasets.\nPotential applications of interest include performance prediction and text\nsimilarity tasks.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 18:48:55 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Ashenafi", "Michael Mogessie", ""]]}, {"id": "1912.13346", "submitter": "Muhammad Anis Al Hilmi", "authors": "Muhammad Anis Al Hilmi, Muhamad Mustamiin, Achmad Nagi, Adi Suheryadi,\n  Fachrul Pralienka Bani Muhammad", "title": "Uji Performa dan Website Responsiveness Institusi dan Smart City se-Jawa\n  Barat", "comments": "Indonesian language, SENTRINOV 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Government through the Ministry of Information and Communication\nTechnology (Kemkominfo) held the 100 Smart Cities Program, an effort to improve\nthe quality of public services. The program produces a Smart City Masterplan to\ndevelop regencies and cities. Access to the website of the regencies-cities\ngovernment that is member of the program is one success indicator of using\ntechnology for the community, because the accessing speed (loading time) and\nresponsiveness of the website is a convenience factor in service users. Hence,\nthe importance of viewing and monitoring public service websites related to\npublic service information in loading time and responsiveness of the website.\nFrom the data of regencies-cities registered in this program, many of them are\nfrom West Java Province, recorded around 11 of the total 26 regencies-cities.\nThis study presents a website assessment using weighting method that focuses on\nloading time and responsiveness to see the performance of community services\nprovided by the municipal governments that are incorporated in a smart city\ncase study in West Java Province. There are six parameters in weighting\nperformance of website used in this study, namely first-contentful-paint,\nfirst-meaningful-paint, speed-index, interactive, first-cpu-idle, and max\npotential first input delay. The weighting value is compared with Google's\ndataset, CrUX (Chrome User Experience Report). The test results show that the\nmajority of websites have an average performance of 38.7 (mobile) 63.6 (web) of\nthe 530 websites incorporated in the smart city, with the best results obtained\nby the City of Bandung.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 01:20:14 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Hilmi", "Muhammad Anis Al", ""], ["Mustamiin", "Muhamad", ""], ["Nagi", "Achmad", ""], ["Suheryadi", "Adi", ""], ["Muhammad", "Fachrul Pralienka Bani", ""]]}]