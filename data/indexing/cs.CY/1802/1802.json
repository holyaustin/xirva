[{"id": "1802.00362", "submitter": "Peter Darch", "authors": "Peter T. Darch", "title": "When Scientists Become Social Scientists: How Citizen Science Projects\n  Learn About Volunteers", "comments": "15 pages", "journal-ref": "Darch, Peter T. (2017), \"When Scientists Become Social Scientists:\n  How Citizen Science Projects Learn About Volunteers\", International Journal\n  of Digital Curation 12(2), pp. 61-75", "doi": "10.2218/ijdc.v12i2.551", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online citizen science projects involve recruitment of volunteers to assist\nresearchers with the creation, curation, and analysis of large datasets.\nEnhancing the quality of these data products is a fundamental concern for teams\nrunning citizen science projects. Decisions about a project's design and\noperations have a critical effect both on whether the project recruits and\nretains enough volunteers, and on the quality of volunteers' work. The\nprocesses by which the team running a project learn about their volunteers play\na critical role in these decisions. Improving these processes will enhance\ndecision-making, resulting in better quality datasets, and more successful\noutcomes for citizen science projects. This paper presents a qualitative case\nstudy, involving interviews and long-term observation, of how the team running\nGalaxy Zoo, a major citizen science project in astronomy, came to know their\nvolunteers and how this knowledge shaped their decision-making processes. This\npaper presents three instances that played significant roles in shaping Galaxy\nZoo team members' understandings of volunteers. Team members integrated\nheterogeneous sources of information to derive new insights into the\nvolunteers. Project metrics and formal studies of volunteers combined with\ntacit understandings gained through on- and offline interactions with\nvolunteers. This paper presents a number of recommendations for practice. These\nrecommendations include strategies for improving how citizen science project\nteam members learn about volunteers, and how teams can more effectively\ncirculate among themselves what they learn.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 15:54:51 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Darch", "Peter T.", ""]]}, {"id": "1802.00396", "submitter": "Slava Jankin Mikhaylov", "authors": "Caleb Pomeroy and Niheer Dasandi and Slava J. Mikhaylov", "title": "Disunited Nations? A Multiplex Network Approach to Detecting Preference\n  Affinity Blocs using Texts and Votes", "comments": "This paper has been withdrawn by the authors. This paper has been\n  superseded by arXiv:1806.00615", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to an emerging literature that models votes and text\nin tandem to better understand polarization of expressed preferences. It\nintroduces a new approach to estimate preference polarization in\nmultidimensional settings, such as international relations, based on\ndevelopments in the natural language processing and network science literatures\n-- namely word embeddings, which retain valuable syntactical qualities of human\nlanguage, and community detection in multilayer networks, which locates densely\nconnected actors across multiple, complex networks. We find that the employment\nof these tools in tandem helps to better estimate states' foreign policy\npreferences expressed in UN votes and speeches beyond that permitted by votes\nalone. The utility of these located affinity blocs is demonstrated through an\napplication to conflict onset in International Relations, though these tools\nwill be of interest to all scholars faced with the measurement of preferences\nand polarization in multidimensional settings.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 17:08:48 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 11:50:04 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Pomeroy", "Caleb", ""], ["Dasandi", "Niheer", ""], ["Mikhaylov", "Slava J.", ""]]}, {"id": "1802.00496", "submitter": "Maria Csernoch", "authors": "Maria Csernoch, Piroska Bir\\'o", "title": "Edu-Edition Spreadsheet Competency Framework", "comments": null, "journal-ref": "Proceedings of the EuSpRIG 2017 Conference \"Spreadsheet Risk\n  Management\", Imperial College, London, pp121-136 ISBN: 978-1-905404-54-4", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the Spreadsheet Competency Framework for finance professionals, in\nthe present paper we introduce the Edu-Edition of the Spreadsheet Competency\nFramework (E2SCF). We claim that building spreadsheet competences should start\nin education, as early as possible, and this process is a lot more effective if\nsupport arrives from expert teachers. The main feature of E2SCF is high\nmathability computer-supported real world problem solving. This approach is\nbased on - from the very beginning of training - a two-directional knowledge\ntransfer, data and error analysis and handling, and the programming aspect of\nspreadsheets. Based on these features, E2SCF is set up for basic and general\nusers to build up firm spreadsheet knowledge and to develop transferable\nproblem solving skills and competences.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 21:34:14 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Csernoch", "Maria", ""], ["Bir\u00f3", "Piroska", ""]]}, {"id": "1802.00575", "submitter": "Hua Wang", "authors": "Pasupathy Vimalachandran, Hua Wang, Yanchun Zhang, Ben Heyward and\n  Yueai Zhao", "title": "Preserving Patient-centred Controls in Electronic Health Record Systems:\n  A Reliance-based Model Implication", "comments": "8 pages for ICOT2017:\n  http://www.colips.org/conferences/icot2017/public.php?page=home.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a consequence of the huge advancement of the Electronic Health Record\n(EHR) in healthcare settings, the My Health Record (MHR) is introduced in\nAustralia. However security and privacy of the MHR system have been encumbering\nthe development of the system. Even though the MHR system is claimed as\npatient-cenred and patient-controlled, there are several instances where\nhealthcare providers (other than the usual provider) and system operators who\nmaintain the system can easily access the system and these unauthorised\naccesses can lead to a breach of the privacy of the patients. This is one of\nthe main concerns of the consumers that affect the uptake of the system. In\nthis paper, we propose a patient centred MHR framework which requests\nauthorisation from the patient to access their sensitive health information.\nThe proposed model increases the involvement and satisfaction of the patients\nin their healthcare and also suggests mobile security system to give an online\npermission to access the MHR system.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 06:35:28 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Vimalachandran", "Pasupathy", ""], ["Wang", "Hua", ""], ["Zhang", "Yanchun", ""], ["Heyward", "Ben", ""], ["Zhao", "Yueai", ""]]}, {"id": "1802.00577", "submitter": "Hua Wang", "authors": "P. Vimalachandran, H. Wang, Y. Zhang, B. Heyward and F. Whittaker", "title": "Ensuring Data Integrity in Electronic Health Records: A Quality Health\n  Care Implication", "comments": "8 pages, ICOT2016: http://www.icot-conference.org/2016/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Electronic Health Record (EHR) system must enable efficient availability\nof meaningful, accurate and complete data to assist improved clinical\nadministration through the development, implementation and optimisation of\nclinical pathways. Therefore data integrity is the driving force in EHR systems\nand is an essential aspect of service delivery at all levels. However,\npreserving data integrity in EHR systems has become a major problem because of\nits consequences in promoting high standards of patient care. In this paper, we\nreview and address the impact of data integrity of the use of EHR system and\nits associated issues. We determine and analyse three phases of data integrity\nof an EHR system. Finally, we also present an appropriate method to preserve\nthe integrity in EHR systems. To analyse and evaluate the data integrity, one\nof the major clinical systems in Australia is considered. This will demonstrate\nthe impact on quality and safety of patient care.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 06:43:46 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Vimalachandran", "P.", ""], ["Wang", "H.", ""], ["Zhang", "Y.", ""], ["Heyward", "B.", ""], ["Whittaker", "F.", ""]]}, {"id": "1802.01029", "submitter": "Michael Veale", "authors": "Michael Veale, Max Van Kleek, Reuben Binns", "title": "Fairness and Accountability Design Needs for Algorithmic Support in\n  High-Stakes Public Sector Decision-Making", "comments": "14 pages, 0 figures, ACM Conference on Human Factors in Computing\n  Systems (CHI'18), April 21--26, Montreal, Canada", "journal-ref": "Proceedings of the 2018 CHI Conference on Human Factors in\n  Computing Systems (2018) 440", "doi": "10.1145/3173574.3174014", "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Calls for heightened consideration of fairness and accountability in\nalgorithmically-informed public decisions---like taxation, justice, and child\nprotection---are now commonplace. How might designers support such human\nvalues? We interviewed 27 public sector machine learning practitioners across 5\nOECD countries regarding challenges understanding and imbuing public values\ninto their work. The results suggest a disconnect between organisational and\ninstitutional realities, constraints and needs, and those addressed by current\nresearch into usable, transparent and 'discrimination-aware' machine\nlearning---absences likely to undermine practical initiatives unless addressed.\nWe see design opportunities in this disconnect, such as in supporting the\ntracking of concept drift in secondary data sources, and in building usable\ntransparency tools to identify risks and incorporate domain knowledge, aimed\nboth at managers and at the 'street-level bureaucrats' on the frontlines of\npublic service. We conclude by outlining ethical challenges and future\ndirections for collaboration in these high-stakes applications.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 20:57:13 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Veale", "Michael", ""], ["Van Kleek", "Max", ""], ["Binns", "Reuben", ""]]}, {"id": "1802.01042", "submitter": "Fardad Haghpanah", "authors": "Fardad Haghpanah", "title": "Transportation Emergency Planning Considering Uncertainty in Event\n  Duration and Drivers' Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic Emergency Management deals with directing the vehicular and\npedestrian traffic around traffic disruptions due to emergencies, such as\naccidents or flooded roadways, aiming to ensure the safety of drivers,\npedestrians, and emergency responders. In this study, a scenario involving the\nlocal flooding of the A1 motorway, one of Italy's main highways connecting\nnorth to the south, is studied. The effect of event duration and drivers'\nresponse rate are investigated on the alternative route activation strategies.\nThe macro and micro itineraries are established, and for different event\ndurations and response rates, the timelines for effective route activation are\nevaluated. According to the results, for events shorter than 1.5 hours, there\nis no need for the activation of alternative routes, and the longer the event,\nthe more alternative routes are needed to minimize the total travel time on the\nflooded route. In addition, increase in the response rate of drivers to use the\nalternative routes leads to the need to activate the micro itinerary after the\nactivation of the macro itinerary. Furthermore, the evacuation of an urban\nregion due to the flood scenario is studied considering different evacuation\nstrategies and residents response time. The results indicate the importance of\noptimal exit point allocation and residents' preparedness to reduce the total\nevacuation time.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 22:14:54 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Haghpanah", "Fardad", ""]]}, {"id": "1802.01110", "submitter": "Claude Tadonki Dr. HDR", "authors": "Claude Tadonki", "title": "HPC Curriculum and Associated Ressources in the Academic Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware support for high-performance computing (HPC) has so far been subject\nto significant advances. The pervasiveness of HPC systems, mainly made up with\nparallel computing units, makes it crucial to spread and vivify effective HPC\ncurricula. Besides didactic considerations, it appears very important to\nimplement HPC hardware infrastructures that will serves for practices, and also\nfor scientific and industrial requests. The latter ensures a valuable\nconnection with surrounding cutting-edge research activities in other topics\n({\\em life sciences, physics, data mining, applied mathematics, finance,\nquantitative economy, engineering sciences}, to name a few), and also with\nindustrial entities and services providers from their requests related to HPC\nmeans and expertise. This aspect is very important as it makes an HPC Center\nbecoming a social actor, while bringing real-life scenarios into the academic\ncontext. The current paper describes the major steps and objectives for a\nconsistent HPC curriculum, with specific analyses of particular contexts;\nsuggests how to technically set up operational HPC infrastructures; and\ndiscusses the connection with end-users, all these in both effective and\nprospective standpoints.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 11:17:14 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Tadonki", "Claude", ""]]}, {"id": "1802.01176", "submitter": "Jose Berengueres Ph.D", "authors": "J. Berengueres", "title": "Valuation of Crypto-Currency Mining Operations", "comments": "8 pages, 3 figures, ledgerjournal vol.3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, the Net Present Value method is used to compare diverging\ninvestment strategies. However, valuating crypto-projects with fiat-based\ncurrency is confusing due to extreme coin appreciation rates as compared to\nfiat interest rates. Here, we provide a net present value method based on using\ncrypto-coin as the underlying asset. Using this method, we compare HODL vs.\nmining, we also provide a sensitivity analysis of profitability\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 19:12:23 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 22:24:25 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Berengueres", "J.", ""]]}, {"id": "1802.01274", "submitter": "Emily Spratt L", "authors": "Emily L. Spratt", "title": "Dream Formulations and Deep Neural Networks: Humanistic Themes in the\n  Iconology of the Machine-Learned Image", "comments": "29 pages, 8 Figures, This paper was originally presented as Dream\n  Formulations and Image Recognition: Algorithms for the Study of Renaissance\n  Art, at Critical Approaches to Digital Art History, The Villa I Tatti, The\n  Harvard University Center for Italian Renaissance Studies and The Newberry\n  Center for Renaissance Studies, Renaissance Society of America Annual\n  Meeting, Chicago, 31 March 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the interpretability of deep learning-enabled image\nrecognition processes in computer vision science in relation to theories in art\nhistory and cognitive psychology on the vision-related perceptual capabilities\nof humans. Examination of what is determinable about the machine-learned image\nin comparison to humanistic theories of visual perception, particularly in\nregard to art historian Erwin Panofsky's methodology for image analysis and\npsychologist Eleanor Rosch's theory of graded categorization according to\nprototypes, finds that there are surprising similarities between the two that\nsuggest that researchers in the arts and the sciences would have much to\nbenefit from closer collaborations. Utilizing the examples of Google's\nDeepDream and the Machine Learning and Perception Lab at Georgia Tech's\nGrad-CAM: Gradient-weighted Class Activation Mapping programs, this study\nsuggests that a revival of art historical research in iconography and formalism\nin the age of AI is essential for shaping the future navigation and\ninterpretation of all machine-learned images, given the rapid developments in\nimage recognition technologies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 05:57:40 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Spratt", "Emily L.", ""]]}, {"id": "1802.01746", "submitter": "Tsung-Ting Kuo", "authors": "Tsung-Ting Kuo and Lucila Ohno-Machado", "title": "ModelChain: Decentralized Privacy-Preserving Healthcare Predictive\n  Modeling Framework on Private Blockchain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-institutional healthcare predictive modeling can accelerate research\nand facilitate quality improvement initiatives, and thus is important for\nnational healthcare delivery priorities. For example, a model that predicts\nrisk of re-admission for a particular set of patients will be more\ngeneralizable if developed with data from multiple institutions. While\nprivacy-protecting methods to build predictive models exist, most are based on\na centralized architecture, which presents security and robustness\nvulnerabilities such as single-point-of-failure (and single-point-of-breach)\nand accidental or malicious modification of records. In this article, we\ndescribe a new framework, ModelChain, to adapt Blockchain technology for\nprivacy-preserving machine learning. Each participating site contributes to\nmodel parameter estimation without revealing any patient health information\n(i.e., only model data, no observation-level data, are exchanged across\ninstitutions). We integrate privacy-preserving online machine learning with a\nprivate Blockchain network, apply transaction metadata to disseminate partial\nmodels, and design a new proof-of-information algorithm to determine the order\nof the online learning process. We also discuss the benefits and potential\nissues of applying Blockchain technology to solve the privacy-preserving\nhealthcare predictive modeling task and to increase interoperability between\ninstitutions, to support the Nationwide Interoperability Roadmap and national\nhealthcare delivery priorities such as Patient-Centered Outcomes Research\n(PCOR).\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 00:51:15 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Kuo", "Tsung-Ting", ""], ["Ohno-Machado", "Lucila", ""]]}, {"id": "1802.01924", "submitter": "Nikolaos K Tselios", "authors": "Christos Katsanos, Michalis Xenos and Nikolaos Tselios", "title": "Tool-mediated HCI Modeling Instruction in a Campus_based Software\n  Quality Course", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Keystroke Level Model (KLM) and Fitts Law constitute core teaching\nsubjects in most HCI courses, as well as many courses on software design and\nevaluation. The KLM Form Analyzer (KLM_FA) has been introduced as a\npractitioner s tool to facilitate web form design and evaluation, based on\nthese established HCI predictive models. It was also hypothesized that KLMFA\ncan also be used for educational purposes, since it provides step by step\ntracing of the KLM modeling for any web form filling task, according to various\ninteraction strategies or users characteristics. In our previous work, we found\nthat KLM-FA supports teaching and learning of HCI modeling in the context of\ndistance education. This paper reports a study investigating the learning\neffectiveness of KLM-FA in the context of campus-based higher education.\nStudents of a software quality course completed a knowledge test after the\nlecture- based instruction (pre-test condition) and after being involved in a\nKLMFA mediated learning activity (post-test condition). They also provided\nposttest ratings for their educational experience and the tool s usability.\nResults showed that KLM-FA can significantly improve learning of the HCI\nmodeling. In addition, participating students rated their perceived educational\nexperience as very satisfactory and the perceived usability of KLM-FA as good\nto excellent.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 13:07:09 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Katsanos", "Christos", ""], ["Xenos", "Michalis", ""], ["Tselios", "Nikolaos", ""]]}, {"id": "1802.01933", "submitter": "Riccardo Guidotti", "authors": "Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Franco Turini,\n  Dino Pedreschi, Fosca Giannotti", "title": "A Survey Of Methods For Explaining Black Box Models", "comments": "This work is currently under review on an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years many accurate decision support systems have been\nconstructed as black boxes, that is as systems that hide their internal logic\nto the user. This lack of explanation constitutes both a practical and an\nethical issue. The literature reports many approaches aimed at overcoming this\ncrucial weakness sometimes at the cost of scarifying accuracy for\ninterpretability. The applications in which black box decision systems can be\nused are various, and each approach is typically developed to provide a\nsolution for a specific problem and, as a consequence, delineating explicitly\nor implicitly its own definition of interpretability and explanation. The aim\nof this paper is to provide a classification of the main problems addressed in\nthe literature with respect to the notion of explanation and the type of black\nbox system. Given a problem definition, a black box type, and a desired\nexplanation this survey should help the researcher to find the proposals more\nuseful for his own work. The proposed classification of approaches to open\nblack box models should also be useful for putting the many research open\nquestions in perspective.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 13:20:02 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 12:29:56 GMT"}, {"version": "v3", "created": "Thu, 21 Jun 2018 08:15:38 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Guidotti", "Riccardo", ""], ["Monreale", "Anna", ""], ["Ruggieri", "Salvatore", ""], ["Turini", "Franco", ""], ["Pedreschi", "Dino", ""], ["Giannotti", "Fosca", ""]]}, {"id": "1802.02188", "submitter": "Barbara McGillivray", "authors": "Barbara McGillivray, Elisa De Ranieri", "title": "Uptake and outcome of manuscripts in Nature journals by review model and\n  author characteristics", "comments": "32 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Double-blind peer review has been proposed as a possible solution to avoid\nimplicit referee bias in academic publishing. The aims of this study are to\nanalyse the demographics of corresponding authors choosing double blind peer\nreview, and to identify differences in the editorial outcome of manuscripts\ndepending on their review model. Data includes 128,454 manuscripts received\nbetween March 2015 and February 2017 by 25 Nature-branded journals. Author\nuptake for double-blind was 12%. We found a small but significant association\nbetween journal tier and review type. We found no statistically significant\ndifference in the distribution of peer review model between males and females.\nWe found that corresponding authors from the less prestigious institutions are\nmore likely to choose double-blind review. In the ten countries with the\nhighest number of submissions, we found a small but significant association\nbetween country and review type. The outcome at both first decision and post\nreview is significantly more negative (i.e. a higher likelihood for rejection)\nfor double than single-blind papers. Authors choose double-blind review more\nfrequently when they submit to more prestigious journals, they are affiliated\nwith less prestigious institutions or they are from specific countries; the\ndouble-blind option is also linked to less successful editorial outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 19:52:00 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["McGillivray", "Barbara", ""], ["De Ranieri", "Elisa", ""]]}, {"id": "1802.02507", "submitter": "Reuben Binns Dr", "authors": "Reuben Binns, Jun Zhao, Max Van Kleek, Nigel Shadbolt", "title": "Measuring third party tracker power across web and mobile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Third-party networks collect vast amounts of data about users via web sites\nand mobile applications. Consolidations among tracker companies can\nsignificantly increase their individual tracking capabilities, prompting\nscrutiny by competition regulators. Traditional measures of market share, based\non revenue or sales, fail to represent the tracking capability of a tracker,\nespecially if it spans both web and mobile. This paper proposes a new approach\nto measure the concentration of tracking capability, based on the reach of a\ntracker on popular websites and apps. Our results reveal that tracker\nprominence and parent-subsidiary relationships have significant impact on\naccurately measuring concentration.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 16:24:56 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Binns", "Reuben", ""], ["Zhao", "Jun", ""], ["Van Kleek", "Max", ""], ["Shadbolt", "Nigel", ""]]}, {"id": "1802.02548", "submitter": "Sam Ganzfried", "authors": "Sheila Alemany, Jonathan Beltran, Adrian Perez, Sam Ganzfried", "title": "Predicting Hurricane Trajectories using a Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hurricanes are cyclones circulating about a defined center whose closed wind\nspeeds exceed 75 mph originating over tropical and subtropical waters. At\nlandfall, hurricanes can result in severe disasters. The accuracy of predicting\ntheir trajectory paths is critical to reduce economic loss and save human\nlives. Given the complexity and nonlinearity of weather data, a recurrent\nneural network (RNN) could be beneficial in modeling hurricane behavior. We\npropose the application of a fully connected RNN to predict the trajectory of\nhurricanes. We employed the RNN over a fine grid to reduce typical truncation\nerrors. We utilized their latitude, longitude, wind speed, and pressure\npublicly provided by the National Hurricane Center (NHC) to predict the\ntrajectory of a hurricane at 6-hour intervals. Results show that this proposed\ntechnique is competitive to methods currently employed by the NHC and can\npredict up to approximately 120 hours of hurricane path.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 08:17:58 GMT"}, {"version": "v2", "created": "Sat, 24 Mar 2018 08:59:55 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 07:30:52 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Alemany", "Sheila", ""], ["Beltran", "Jonathan", ""], ["Perez", "Adrian", ""], ["Ganzfried", "Sam", ""]]}, {"id": "1802.02663", "submitter": "Sridhar Chimalakonda", "authors": "Sridhar Chimalakonda, Kesav V. Nori", "title": "A Patterns Based Approach for Design of Educational Technologies", "comments": "Preprint Submitted to Educational Technology Research and Development\n  Journal, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instructional design is a fundamental base for educational technologies as it\nlays the foundation to facilitate learning and teaching based on pedagogical\nunderpinnings. However, most of the educational technologies today face two\ncore challenges in this context: (i) lack of instructional design as a basis\n(ii) lack of support for a variety of instructional designs. In order to\naddress these challenges, we propose a patterns based approach for design of\neducational technologies. This is in contrast with existing literature that\nfocuses either on patterns in education or in software, and not both. The core\nidea of our approach is to leverage patterns for modeling instructional design\nknowledge and to connect it with patterns in software architecture. We discuss\ndifferent categories of patterns in instructional design. We then present the\nnotion of Pattern-Oriented Instructional Design (POID) as a way to model\ninstructional design as a connection of patterns (GoalPattern, ProcessPattern,\nContentPattern) and integrate it with Pattern-Oriented Software Architecture\n(POSA) based on fundamental principles in software engineering. We demonstrate\nour approach through adult literacy case study (287 million learners, 22 Indian\nLanguages and a variety of instructional designs). The results of our approach\n(both web and mobile versions) are available at http://rice.iiit.ac.in and were\nadopted by National Literacy Mission Authority of Government of India.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 22:41:54 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Chimalakonda", "Sridhar", ""], ["Nori", "Kesav V.", ""]]}, {"id": "1802.02915", "submitter": "Rahul Goel Dr", "authors": "Rahul Goel, Leandro M. T. Garcia, Anna Goodman, Rob Johnson, Rachel\n  Aldred, Manoradhan Murugesan, Soren Brage, Kavi Bhalla, James Woodcock", "title": "Estimating city-level travel patterns using street imagery: a case study\n  of using Google Street View in Britain", "comments": "Paper submitted for peer review. 7 figures. 3 Tables", "journal-ref": null, "doi": "10.1371/journal.pone.0196521", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Street imagery is a promising big data source providing current and\nhistorical images in more than 100 countries. Previous studies used this data\nto audit built environment features. Here we explore a novel application, using\nGoogle Street View (GSV) to predict travel patterns at the city level. We\nsampled 34 cities in Great Britain. In each city, we accessed GSV images from\n1000 random locations from years overlapping with the 2011 Census and the\n2011-2013 Active People Survey (APS). We manually annotated images into seven\ncategories of road users. We developed regression models with the counts of\nimages of road users as predictors. Outcomes included Census-reported commute\nshares of four modes (walking plus public transport, cycling, motorcycle, and\ncar), and APS-reported past-month participation in walking and cycling. In\nbivariate analyses, we found high correlations between GSV counts of cyclists\n(GSV-cyclists) and cycle commute mode share (r=0.92) and past-month cycling\n(r=0.90). Likewise, GSV-pedestrians was moderately correlated with past-month\nwalking for transport (r=0.46), GSV-motorcycles was moderately correlated with\ncommute share of motorcycles (r=0.44), and GSV-buses was highly correlated with\ncommute share of walking plus public transport (r=0.81). GSV-car was not\ncorrelated with car commute mode share (r=-0.12). However, in multivariable\nregression models, all mode shares were predicted well. Cross-validation\nanalyses showed good prediction performance for all the outcomes except\npast-month walking. Street imagery is a promising new big data source to\npredict urban mobility patterns. Further testing across multiple settings is\nwarranted both for cross-sectional and longitudinal assessments.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 15:17:21 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Goel", "Rahul", ""], ["Garcia", "Leandro M. T.", ""], ["Goodman", "Anna", ""], ["Johnson", "Rob", ""], ["Aldred", "Rachel", ""], ["Murugesan", "Manoradhan", ""], ["Brage", "Soren", ""], ["Bhalla", "Kavi", ""], ["Woodcock", "James", ""]]}, {"id": "1802.02953", "submitter": "Christine Borgman", "authors": "Christine L. Borgman", "title": "Open Data, Grey Data, and Stewardship: Universities at the Privacy\n  Frontier", "comments": "Final published version, Sept 30, 2018", "journal-ref": "Borgman, C.L. (2018). Open data, grey data, and stewardship:\n  Universities at the privacy frontier. Berkeley Technology Law Journal, 33:2,\n  365-412", "doi": "10.15779/Z38B56D489", "report-no": null, "categories": "cs.DL cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As universities recognize the inherent value in the data they collect and\nhold, they encounter unforeseen challenges in stewarding those data in ways\nthat balance accountability, transparency, and protection of privacy, academic\nfreedom, and intellectual property. Two parallel developments in academic data\ncollection are converging: (1) open access requirements, whereby researchers\nmust provide access to their data as a condition of obtaining grant funding or\npublishing results in journals; and (2) the vast accumulation of 'grey data'\nabout individuals in their daily activities of research, teaching, learning,\nservices, and administration. The boundaries between research and grey data are\nblurring, making it more difficult to assess the risks and responsibilities\nassociated with any data collection. Many sets of data, both research and grey,\nfall outside privacy regulations such as HIPAA, FERPA, and PII. Universities\nare exploiting these data for research, learning analytics, faculty evaluation,\nstrategic decisions, and other sensitive matters. Commercial entities are\nbesieging universities with requests for access to data or for partnerships to\nmine them. The privacy frontier facing research universities spans open access\npractices, uses and misuses of data, public records requests, cyber risk, and\ncurating data for privacy protection. This paper explores the competing values\ninherent in data stewardship and makes recommendations for practice, drawing on\nthe pioneering work of the University of California in privacy and information\nsecurity, data governance, and cyber risk.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 16:32:53 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 17:41:44 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Borgman", "Christine L.", ""]]}, {"id": "1802.02996", "submitter": "Md Mizanur Rahman", "authors": "Rahul Potharaju, Mizanur Rahman, Bogdan Carbunar", "title": "A Longitudinal Study of Google Play", "comments": null, "journal-ref": "IEEE Transactions on Computational Social Systems (TCSS), Volume\n  4, Issue 3, September 2017", "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difficulty of large scale monitoring of app markets affects our\nunderstanding of their dynamics. This is particularly true for dimensions such\nas app update frequency, control and pricing, the impact of developer actions\non app popularity, as well as coveted membership in top app lists. In this\npaper we perform a detailed temporal analysis on two datasets we have collected\nfrom the Google Play Store, one consisting of 160,000 apps and the other of\n87,223 newly released apps. We have monitored and collected data about these\napps over more than 6 months. Our results show that a high number of these apps\nhave not been updated over the monitoring interval. Moreover, these apps are\ncontrolled by a few developers that dominate the total number of app downloads.\nWe observe that infrequently updated apps significantly impact the median app\nprice. However, a changing app price does not correlate with the download\ncount. Furthermore, we show that apps that attain higher ranks have better\nstability in top app lists. We show that app market analytics can help detect\nemerging threat vectors, and identify search rank fraud and even malware.\nFurther, we discuss the research implications of app market analytics on\nimproving developer and user experiences.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 18:25:22 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Potharaju", "Rahul", ""], ["Rahman", "Mizanur", ""], ["Carbunar", "Bogdan", ""]]}, {"id": "1802.03074", "submitter": "An Yan", "authors": "An Yan, Nicholas Weber", "title": "Mining Open Government Data Used in Scientific Research", "comments": "Accepted to iConference 2018", "journal-ref": "Transforming Digital Worlds. iConference 2018. Lecture Notes in\n  Computer Science, vol 10766. Springer, Cham", "doi": "10.1007/978-3-319-78105-1_34", "report-no": null, "categories": "cs.CY cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the following paper, we describe results from mining citations, mentions,\nand links to open government data (OGD) in peer-reviewed literature. We\ninductively develop a method for categorizing how OGD are used by different\nresearch communities, and provide descriptive statistics about the publication\nyears, publication outlets, and OGD sources. Our results demonstrate that, 1.\nThe use of OGD in research is steadily increasing from 2009 to 2016; 2.\nResearchers use OGD from 96 different open government data portals, with\ndata.gov.uk and data.gov being the most frequent sources; and, 3.Contrary to\nprevious findings, we provide evidence suggesting that OGD from developing\nnations, notably India and Kenya, are being frequently used to fuel scientific\ndiscoveries. The findings of this paper contribute to ongoing research agendas\naimed at tracking the impact of open government data initiatives, and provides\nan initial description of how open government data are valuable to diverse\nscientific research communities.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 23:18:44 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 06:44:10 GMT"}, {"version": "v3", "created": "Sat, 24 Mar 2018 10:04:59 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Yan", "An", ""], ["Weber", "Nicholas", ""]]}, {"id": "1802.03113", "submitter": "Araz Taeihagh", "authors": "Araz Taeihagh", "title": "Crowdsourcing: a new tool for policy-making?", "comments": null, "journal-ref": "Policy Sciences Journal, 50(4):629-647 (2017)", "doi": "10.1007/s11077-017-9303-3", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing is rapidly evolving and applied in situations where ideas,\nlabour, opinion or expertise of large groups of people are used. Crowdsourcing\nis now used in various policy-making initiatives; however, this use has usually\nfocused on open collaboration platforms and specific stages of the policy\nprocess, such as agenda-setting and policy evaluations. Other forms of\ncrowdsourcing have been neglected in policy-making, with a few exceptions. This\narticle examines crowdsourcing as a tool for policy-making, and explores the\nnuances of the technology and its use and implications for different stages of\nthe policy process. The article addresses questions surrounding the role of\ncrowdsourcing and whether it can be considered as a policy tool or as a\ntechnological enabler and investigates the current trends and future directions\nof crowdsourcing.\n  Keywords: Crowdsourcing, Public Policy, Policy Instrument, Policy Tool,\nPolicy Process, Policy Cycle, Open Collaboration, Virtual Labour Markets,\nTournaments, Competition.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 03:34:15 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Taeihagh", "Araz", ""]]}, {"id": "1802.03393", "submitter": "Avi Rosenfeld", "authors": "Avi Rosenfeld, Sigal Sina, David Sarne, Or Avidov, Sarit Kraus", "title": "A Study of WhatsApp Usage Patterns and Prediction Models without Message\n  Content", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet social networks have become a ubiquitous application allowing people\nto easily share text, pictures, and audio and video files. Popular networks\ninclude WhatsApp, Facebook, Reddit and LinkedIn. We present an extensive study\nof the usage of the WhatsApp social network, an Internet messaging application\nthat is quickly replacing SMS messaging. In order to better understand people's\nuse of the network, we provide an analysis of over 6 million messages from over\n100 users, with the objective of building demographic prediction models using\nactivity data. We performed extensive statistical and numerical analysis of the\ndata and found significant differences in WhatsApp usage across people of\ndifferent genders and ages. We also inputted the data into the Weka data mining\npackage and studied models created from decision tree and Bayesian network\nalgorithms. We found that different genders and age demographics had\nsignificantly different usage habits in almost all message and group\nattributes. We also noted differences in users' group behavior and created\nprediction models, including the likelihood a given group would have relatively\nmore file attachments, if a group would contain a larger number of\nparticipants, a higher frequency of activity, quicker response times and\nshorter messages. We were successful in quantifying and predicting a user's\ngender and age demographic. Similarly, we were able to predict different types\nof group usage. All models were built without analyzing message content. We\npresent a detailed discussion about the specific attributes that were contained\nin all predictive models and suggest possible applications based on these\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 13:18:56 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Rosenfeld", "Avi", ""], ["Sina", "Sigal", ""], ["Sarne", "David", ""], ["Avidov", "Or", ""], ["Kraus", "Sarit", ""]]}, {"id": "1802.03613", "submitter": "arXiv Admin", "authors": "Endang Kurniawan, Imam Riadi", "title": "Security level analysis of academic information systems based on\n  standard ISO 27002:2003 using SSE-CMM", "comments": "arXiv admin note: submission has been withdrawn by arXiv\n  administrators due to inappropriate overlap with external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This research was conducted to find out the level of information security in\nan organization to give recommendations improvements in information security\nmanagement at the organization. This research uses the ISO 27002 by involving\nthe entire clause that exists in ISO 27002 check-lists. Based on the analysis\nresults, 13 objective controls and 43 security controls were scattered in 3\nclauses of ISO 27002. From the analysis it was concluded that the maturity\nlevel of information system security governance was 2.51, which means the level\nof security is still at level 2 planned and tracked is planned and tracked\nactively) but is approaching level 3 well defined.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 16:10:10 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 17:47:32 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Kurniawan", "Endang", ""], ["Riadi", "Imam", ""]]}, {"id": "1802.03675", "submitter": "Sandeep Konam", "authors": "Sandeep Konam, Ian Quah, Stephanie Rosenthal, Manuela Veloso", "title": "Understanding Convolutional Networks with APPLE : Automatic Patch\n  Pattern Labeling for Explanation", "comments": "AAAI/ACM Conference on AI, Ethics, and Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the success of deep learning, recent efforts have been focused on\nanalyzing how learned networks make their classifications. We are interested in\nanalyzing the network output based on the network structure and information\nflow through the network layers. We contribute an algorithm for 1) analyzing a\ndeep network to find neurons that are 'important' in terms of the network\nclassification outcome, and 2)automatically labeling the patches of the input\nimage that activate these important neurons. We propose several measures of\nimportance for neurons and demonstrate that our technique can be used to gain\ninsight into, and explain how a network decomposes an image to make its final\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 01:33:33 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Konam", "Sandeep", ""], ["Quah", "Ian", ""], ["Rosenthal", "Stephanie", ""], ["Veloso", "Manuela", ""]]}, {"id": "1802.04023", "submitter": "L. Elisa Celis", "authors": "L. Elisa Celis, Vijay Keswani, Damian Straszak, Amit Deshpande, Tarun\n  Kathuria and Nisheeth K. Vishnoi", "title": "Fair and Diverse DPP-based Data Summarization", "comments": "A short version of this paper appeared in the workshop FAT/ML 2016 -\n  arXiv:1610.07183", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling methods that choose a subset of the data proportional to its\ndiversity in the feature space are popular for data summarization. However,\nrecent studies have noted the occurrence of bias (under- or over-representation\nof a certain gender or race) in such data summarization methods. In this paper\nwe initiate a study of the problem of outputting a diverse and fair summary of\na given dataset. We work with a well-studied determinantal measure of diversity\nand corresponding distributions (DPPs) and present a framework that allows us\nto incorporate a general class of fairness constraints into such distributions.\nComing up with efficient algorithms to sample from these constrained\ndeterminantal distributions, however, suffers from a complexity barrier and we\npresent a fast sampler that is provably good when the input vectors satisfy a\nnatural property. Our experimental results on a real-world and an image dataset\nshow that the diversity of the samples produced by adding fairness constraints\nis not too far from the unconstrained case, and we also provide a theoretical\nexplanation of it.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 13:12:43 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Celis", "L. Elisa", ""], ["Keswani", "Vijay", ""], ["Straszak", "Damian", ""], ["Deshpande", "Amit", ""], ["Kathuria", "Tarun", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1802.04090", "submitter": "Christos Katsanos", "authors": "Alexandros Liapis, Christos Katsanos, Michalis Xenos", "title": "Don't Leave Me Alone: Retrospective Think Aloud supported by Real-time\n  Monitoring of Participant's Physiology", "comments": "International Conference on Human-Computer Interaction (HCII), 11\n  pages, 3 figures", "journal-ref": null, "doi": "10.1007/978-3-319-91238-7_10", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Think aloud protocols are widely applied in user experience studies. In this\npaper, the effect of two different applications of the Retrospective Think\nAloud (RTA) protocol on the number of user-reported usability issues is\nexamined. To this end, 30 users were asked to use the National Cadastre and\nMapping Agency web application and complete a set of tasks, such as measuring\nthe land area of a square in their hometown. The order of tasks was randomized\nper participant. Next, participants were involved in RTA sessions. Each\nparticipant was involved in two different RTA modes: (a) the strict guidance,\nin which the facilitator stayed in the background and prompted participants to\nkeep thinking aloud based on his judgement and experience, and (b) the\nphysiology-supported interventions, in which the facilitator intervened based\non real-time monitoring of user's physiological signals. During each session,\nthree participant's physiological signals were recorded: skin conductance, skin\ntemperature and blood volume pulse. Participants were also asked to provide\nvalence-arousal ratings for each self-reported usability issue. Analysis of the\ncollected data showed that participants in the physiology-supported RTA mode\nreported significantly more usability issues. No significant effect of the RTA\nmode was found on the va-lence-arousal ratings for the reported usability\nissues. Participants' physiological signals during the RTA sessions did not\nalso differ significantly between the two modes.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 14:58:52 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Liapis", "Alexandros", ""], ["Katsanos", "Christos", ""], ["Xenos", "Michalis", ""]]}, {"id": "1802.04100", "submitter": "Marcos Baez", "authors": "Marcos Baez and Fabio Casati", "title": "Agile development for vulnerable populations: lessons learned and\n  recommendations", "comments": null, "journal-ref": null, "doi": "10.1145/3183428.3183439", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we draw attention to the challenges of managing software\nprojects for vulnerable populations, i.e., people potentially exposed to harm\nor not capable of protecting their own interests. The focus on human aspects,\nand particularly, the inclusion of human-centered approaches, has been a\npopular topic in the software engineering community. We argue, however, that\ncurrent literature provides little understanding and guidance on how to\napproach these type of scenarios. Here, we shed some light on the topic by\nreporting on our experiences in developing innovative solutions for the\nresidential care scenario, outlining potential issues and recommendations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 15:11:16 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Baez", "Marcos", ""], ["Casati", "Fabio", ""]]}, {"id": "1802.04102", "submitter": "Gabriele Tolomei", "authors": "Hidayet Aksu and Leonardo Babun and Mauro Conti and Gabriele Tolomei\n  and A. Selcuk Uluagac", "title": "Advertising in the IoT Era: Vision and Challenges", "comments": "Accepted for publication at IEEE Communications Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) extends the idea of interconnecting computers to\na plethora of different devices, collectively referred to as smart devices.\nThese are physical items - i.e., \"things\" - such as wearable devices, home\nappliances, and vehicles, enriched with computational and networking\ncapabilities. Due to the huge set of devices involved - and therefore, its\npervasiveness - IoT is a great platform to leverage for building new\napplications and services or extending existing ones. In this regard, expanding\nonline advertising into the IoT realm is an under-investigated yet promising\nresearch direction, especially considering that traditional Internet\nadvertising market is already worth hundreds of billions of dollars. In this\npaper, we first propose the architecture of an IoT advertising platform\ninspired by the well-known business ecosystem, which the traditional Internet\nadvertising is based on. Additionally, we discuss the key challenges to\nimplement such a platform with a special focus on issues related to\narchitecture, advertisement content delivery, security, and privacy of the\nusers.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 22:15:25 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Aksu", "Hidayet", ""], ["Babun", "Leonardo", ""], ["Conti", "Mauro", ""], ["Tolomei", "Gabriele", ""], ["Uluagac", "A. Selcuk", ""]]}, {"id": "1802.04103", "submitter": "Gordana Dodig Crnkovic", "authors": "Tobias Holstein, Gordana Dodig-Crnkovic and Patrizio Pelliccione", "title": "Ethical and Social Aspects of Self-Driving Cars", "comments": "11 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an envisaged future of transportation, self-driving cars are being\ndiscussed from various perspectives, including social, economical, engineering,\ncomputer science, design, and ethics. On the one hand, self-driving cars\npresent new engineering problems that are being gradually successfully solved.\nOn the other hand, social and ethical problems are typically being presented in\nthe form of an idealized unsolvable decision-making problem, the so-called\ntrolley problem, which is grossly misleading. We argue that an applied\nengineering ethical approach for the development of new technology is what is\nneeded; the approach should be applied, meaning that it should focus on the\nanalysis of complex real-world engineering problems. Software plays a crucial\nrole for the control of self-driving cars; therefore, software engineering\nsolutions should seriously handle ethical and social considerations. In this\npaper we take a closer look at the regulative instruments, standards, design,\nand implementations of components, systems, and services and we present\npractical social and ethical challenges that have to be met, as well as novel\nexpectations for software engineering.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 22:22:08 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Holstein", "Tobias", ""], ["Dodig-Crnkovic", "Gordana", ""], ["Pelliccione", "Patrizio", ""]]}, {"id": "1802.04104", "submitter": "Andr\\'es Eduardo G\\'omez Hernandez Mr", "authors": "Andr\\'es E. G\\'omez, Tiago C. dos Santos, Carlos M. Massera, Arthur de\n  M. Neto and Denis F. Wolf", "title": "Driving Simulator Platform for Development and Evaluation of Safety and\n  Emergency Systems", "comments": "14 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to data from the United Nations, more than 3000 people have died\neach day in the world due to road traffic collision. Considering recent\nresearches, the human error may be considered as the main responsible for these\nfatalities. Because of this, researchers seek alternatives to transfer the\nvehicle control from people to autonomous systems. However, providing this\ntechnological innovation for the people may demand complex challenges in the\nlegal, economic and technological areas. Consequently, carmakers and\nresearchers have divided the driving automation in safety and emergency systems\nthat improve the driver perception on the road. This may reduce the human\nerror. Therefore, the main contribution of this study is to propose a driving\nsimulator platform to develop and evaluate safety and emergency systems, in the\nfirst design stage. This driving simulator platform has an advantage: a\nflexible software structure.This allows in the simulation one adaptation for\ndevelopment or evaluation of a system. The proposed driving simulator platform\nwas tested in two applications: cooperative vehicle system development and the\ninfluence evaluation of a Driving Assistance System (\\textit{DAS}) on a driver.\nIn the cooperative vehicle system development, the results obtained show that\nthe increment of the time delay in the communication among vehicles ($V2V$) is\ndeterminant for the system performance. On the other hand, in the influence\nevaluation of a \\textit{DAS} in a driver, it was possible to conclude that the\n\\textit{DAS'} model does not have the level of influence necessary in a driver\nto avoid an accident.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 11:51:44 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["G\u00f3mez", "Andr\u00e9s E.", ""], ["Santos", "Tiago C. dos", ""], ["Massera", "Carlos M.", ""], ["Neto", "Arthur de M.", ""], ["Wolf", "Denis F.", ""]]}, {"id": "1802.04105", "submitter": "Hua Wang", "authors": "Sarathkumar Rangarajan, Huai Liu, Hua Wang, and Chuan-Long Wang", "title": "Scalable Architecture for Personalized Healthcare Service Recommendation\n  using Big Data Lake", "comments": "15 Pages, 3 figures, 1 table, Presented in Sixth Australasian\n  Symposium on Service Research and Innovation 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The personalized health care service utilizes the relational patient data and\nbig data analytics to tailor the medication recommendations. However, most of\nthe health care data are in unstructured form and it consumes a lot of time and\neffort to pull them into relational form. This study proposes a novel data lake\narchitecture to reduce the data ingestion time and improve the precision of\nhealthcare analytics. It also removes the data silos and enhances the analytics\nby allowing the connectivity to the third-party data providers (such as\nclinical lab results, chemist, insurance company,etc.). The data lake\narchitecture uses the Hadoop Distributed File System (HDFS) to provide the\nstorage for both structured and unstructured data. This study uses K-means\nclustering algorithm to find the patient clusters with similar health\nconditions. Subsequently, it employs a support vector machine to find the most\nsuccessful healthcare recommendations for the each cluster. Our experiment\nresults demonstrate the ability of data lake to reduce the time for ingesting\ndata from various data vendors regardless of its format. Moreover, it is\nevident that the data lake poses the potential to generate clusters of patients\nmore precisely than the existing approaches. It is obvious that the data lake\nprovides a unified storage location for the data in its native format. It can\nalso improve the personalized healthcare medication recommendations by removing\nthe data silos.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 04:26:13 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Rangarajan", "Sarathkumar", ""], ["Liu", "Huai", ""], ["Wang", "Hua", ""], ["Wang", "Chuan-Long", ""]]}, {"id": "1802.04108", "submitter": "Hayder Hbail", "authors": "Hayder Hbail", "title": "Design a multicultural blended e-learning system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most universities in developing countries are using a teaching and learning\napproach known as blended e-learning, however, there was no multicultural-based\nblended e-learning framework. Furthermore, there is no research to show the\nimpact of multicultural blended e-learning on satisfaction of learners. This\nresearch employed two categories of students, the Iranian students and the\nIraqi students studying at Razi University of Iran. These two groups were\ntaught using the multicultural blended e-learning approach. We utilized an open\nsource application named Claroline. Questionnaires were designed and\nadministered to students to collect information about the level of satisfaction\nand the optimal mix of tools that go into blended multicultural-based\ne-learning. The collected information was analyzed using SPSS. We found that\nblended multicultural based e-learning improves the level of satisfaction of\nlearners. In addition, the optimal mix of multicultural blended learning should\nbe comprised 19% still pictures, audio files 23%, video files 31% and text\nfiles 27%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 08:31:01 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Hbail", "Hayder", ""]]}, {"id": "1802.04109", "submitter": "Ismail Kayali", "authors": "Ismail Kayali", "title": "Analysis of Complex System Development Based on Fuzzy Cognitive Mapping", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This article represents one of the contemporary trends in the application of\nthe latest methods of classification in business, where intense competition and\nthe desire to expand drive this science to far-reaching prospects using the\ndiscusses months and the most recent classification and forecasting algorithms\nsuch as SVM, FFM, C4.5, which are used to build better business decision\nsupport models, including basic steps in data pre-processing such as Attributes\nusing Information Gain Ratio and filling missing values with several\nalgorithms:K-Means,K-NearestNeighbor,Linear Regression,Neural Network(Back\nPropagation)\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 12:04:54 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Kayali", "Ismail", ""]]}, {"id": "1802.04112", "submitter": "Swaminathan Gopalswamy", "authors": "Swaminathan Gopalswamy, Sivakumar Rathinam", "title": "Infrastructure Enabled Autonomy: A Distributed Intelligence Architecture\n  for Autonomous Vehicles", "comments": "submitted to the IEEE Intelligent Vehicles Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.MA cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multiple studies have illustrated the potential for dramatic societal,\nenvironmental and economic benefits from significant penetration of autonomous\ndriving. However, all the current approaches to autonomous driving require the\nautomotive manufacturers to shoulder the primary responsibility and liability\nassociated with replacing human perception and decision making with automation,\npotentially slowing the penetration of autonomous vehicles, and consequently\nslowing the realization of the societal benefits of autonomous vehicles. We\npropose here a new approach to autonomous driving that will re-balance the\nresponsibility and liabilities associated with autonomous driving between\ntraditional automotive manufacturers, infrastructure players, and third-party\nplayers. Our proposed distributed intelligence architecture leverages the\nsignificant advancements in connectivity and edge computing in the recent\ndecades to partition the driving functions between the vehicle, edge computers\non the road side, and specialized third-party computers that reside in the\nvehicle. Infrastructure becomes a critical enabler for autonomy. With this\nInfrastructure Enabled Autonomy (IEA) concept, the traditional automotive\nmanufacturers will only need to shoulder responsibility and liability\ncomparable to what they already do today, and the infrastructure and\nthird-party players will share the added responsibility and liabilities\nassociated with autonomous functionalities. We propose a Bayesian Network Model\nbased framework for assessing the risk benefits of such a distributed\nintelligence architecture. An additional benefit of the proposed architecture\nis that it enables \"autonomy as a service\" while still allowing for private\nownership of automobiles.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 23:33:53 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Gopalswamy", "Swaminathan", ""], ["Rathinam", "Sivakumar", ""]]}, {"id": "1802.04117", "submitter": "Yi Wang Mr.", "authors": "Yi Wang, Qixin Chen, Tao Hong, Chongqing Kang", "title": "Review of Smart Meter Data Analytics: Applications, Methodologies, and\n  Challenges", "comments": "IEEE Transactions on Smart Grid, 2018", "journal-ref": null, "doi": "10.1109/TSG.2018.2818167", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The widespread popularity of smart meters enables an immense amount of\nfine-grained electricity consumption data to be collected. Meanwhile, the\nderegulation of the power industry, particularly on the delivery side, has\ncontinuously been moving forward worldwide. How to employ massive smart meter\ndata to promote and enhance the efficiency and sustainability of the power grid\nis a pressing issue. To date, substantial works have been conducted on smart\nmeter data analytics. To provide a comprehensive overview of the current\nresearch and to identify challenges for future research, this paper conducts an\napplication-oriented review of smart meter data analytics. Following the three\nstages of analytics, namely, descriptive, predictive and prescriptive\nanalytics, we identify the key application areas as load analysis, load\nforecasting, and load management. We also review the techniques and\nmethodologies adopted or developed to address each application. In addition, we\nalso discuss some research trends, such as big data issues, novel machine\nlearning technologies, new business models, the transition of energy systems,\nand data privacy and security.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 07:36:37 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 22:22:58 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Wang", "Yi", ""], ["Chen", "Qixin", ""], ["Hong", "Tao", ""], ["Kang", "Chongqing", ""]]}, {"id": "1802.04128", "submitter": "Cl\\'audio Rebelo De S\\'a", "authors": "Dylan te Lindert and Cl\\'audio Rebelo de S\\'a and Carlos Soares and\n  Arno J. Knobbe", "title": "Smart energy management as a means towards improved energy efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The costs associated with refrigerator equipment often represent more than\nhalf of the total energy costs in supermarkets. This presents a good motivation\nfor running these systems efficiently. In this study, we investigate different\nways to construct a reference behavior, which can serve as a baseline for\njudging the performance of energy consumption. We used 3 distinct learning\nmodels: Multiple Linear Regression, Random Forests, and Artificial Neural\nNetworks. During our experiments we used a variation of the sliding window\nmethod in combination with learning curves. We applied this approach on five\ndifferent supermarkets, across Portugal. We are able to create baselines using\noff-the-shelf data mining techniques. Moreover, we found a way to create them\nbased on short term historical data. We believe that our research will serve as\na base for future studies, for which we provide interesting directions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 13:49:25 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Lindert", "Dylan te", ""], ["de S\u00e1", "Cl\u00e1udio Rebelo", ""], ["Soares", "Carlos", ""], ["Knobbe", "Arno J.", ""]]}, {"id": "1802.04143", "submitter": "Araz Taeihagh", "authors": "John Prpic, Araz Taeihagh, and James Melton", "title": "The Fundamentals of Policy Crowdsourcing", "comments": "arXiv admin note: substantial text overlap with arXiv:1702.04213", "journal-ref": "Policy & Internet, 7: 340-361 (2015)", "doi": "10.1002/poi3.102", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the state of the research on crowdsourcing for policy making? This\narticle begins to answer this question by collecting, categorizing, and\nsituating an extensive body of the extant research investigating policy\ncrowdsourcing, within a new framework built on fundamental typologies from each\nfield. We first define seven universal characteristics of the three general\ncrowdsourcing techniques (virtual labor markets, tournament crowdsourcing, open\ncollaboration), to examine the relative trade-offs of each modality. We then\ncompare these three types of crowdsourcing to the different stages of the\npolicy cycle, in order to situate the literature spanning both domains. We\nfinally discuss research trends in crowdsourcing for public policy, and\nhighlight the research gaps and overlaps in the literature.\n  KEYWORDS: crowdsourcing, policy cycle, crowdsourcing trade-offs, policy\nprocesses, policy stages, virtual labor markets, tournament crowdsourcing, open\ncollaboration\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 03:41:41 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Prpic", "John", ""], ["Taeihagh", "Araz", ""], ["Melton", "James", ""]]}, {"id": "1802.04159", "submitter": "Robert Robinson", "authors": "Robert Robinson", "title": "Urban vs. rural divide in HTTPS implementation for hospital websites in\n  Illinois", "comments": "5 pages, 1 table. arXiv admin note: text overlap with\n  arXiv:1712.05376", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Hypertext Transfer Protocol Secure (HTTPS) communications protocol is\nused to secure traffic between a web browser and server. This technology can\nsignificantly reduce the risk of interception and manipulation of web\ninformation for nefarious purposes such as identity theft. Deployment of HTTPS\nhas reached about 50% of all webs sites. Little is known about HTTPS\nimplantation for hospital websites. To investigate the prevalence of HTTPS\nimplementation, we analyzed the websites of the 210 public hospitals in the\nstate of Illinois, USA. HTTPS was implemented to industry standards for 54% of\nall hospital websites in Illinois. Geographical analysis showed an urban vs.\nrural digital divide with 60% of urban hospitals and 40% of rural hospitals\nimplementing HTTPS.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 17:55:27 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Robinson", "Robert", ""]]}, {"id": "1802.04236", "submitter": "Shayan Eskandari", "authors": "Shayan Eskandari, Jeremy Clark, Abdelwahab Hamou-Lhadj", "title": "Buy your coffee with bitcoin: Real-world deployment of a bitcoin point\n  of sale terminal", "comments": "Advanced and Trusted Computing 2016 Intl IEEE Conferences, 8 pages", "journal-ref": null, "doi": "10.1109/UIC-ATC-ScalCom-CBDCom-IoP-SmartWorld.2016.0073", "report-no": null, "categories": "cs.CR cs.CY cs.ET cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss existing approaches for Bitcoin payments, as\nsuitable for a small business for small-value transactions. We develop an\nevaluation framework utilizing security, usability, deployability criteria,,\nexamine several existing systems, tools. Following a requirements engineering\napproach, we designed, implemented a new Point of Sale (PoS) system that\nsatisfies an optimal set of criteria within our evaluation framework. Our open\nsource system, Aunja PoS, has been deployed in a real world cafe since October\n2014.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 18:38:35 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Eskandari", "Shayan", ""], ["Clark", "Jeremy", ""], ["Hamou-Lhadj", "Abdelwahab", ""]]}, {"id": "1802.04252", "submitter": "Karthik R", "authors": "Karthik R, Preetam Satapath, Srivatsa Patnaik, Saurabh Priyadarshi,\n  Rajesh Kumar M", "title": "Automatic Phone Slip Detection System", "comments": "Accepted for publication in Springer LNEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phones are becoming increasingly advanced and the latest ones are\nequipped with many diverse and powerful sensors. These sensors can be used to\nstudy different position and orientation of the phone which can help smartphone\nmanufacture to track about their customers handling from the recorded log. The\ninbuilt sensors such as the accelerometer and gyroscope present in our phones\nare used to obtain data for acceleration and orientation of the phone in the\nthree axes for different phone vulnerable position. From the data obtained\nappropriate features are extracted using various feature extraction techniques.\nThe extracted features are then given to classifier such as neural network to\nclassify them and decide whether the phone is in a vulnerable position to fall\nor it is in a safe position .In this paper we mainly concentrated on various\ncase of handling the smartphone and classified by training the neural network.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 14:51:24 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["R", "Karthik", ""], ["Satapath", "Preetam", ""], ["Patnaik", "Srivatsa", ""], ["Priyadarshi", "Saurabh", ""], ["M", "Rajesh Kumar", ""]]}, {"id": "1802.04255", "submitter": "Eugenio Maria Battaglia", "authors": "Eugenio Maria Battaglia, Jie Mei and Guillaume Dumas", "title": "Systems of Global Governance in the Era of Human-Machine Convergence", "comments": "23 pages, 213 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Technology is increasingly shaping our social structures and is becoming a\ndriving force in altering human biology. Besides, human activities already\nproved to have a significant impact on the Earth system which in turn generates\ncomplex feedback loops between social and ecological systems. Furthermore,\nsince our species evolved relatively fast from small groups of hunter-gatherers\nto large and technology-intensive urban agglomerations, it is not a surprise\nthat the major institutions of human society are no longer fit to cope with the\npresent complexity. In this note we draw foundational parallelisms between\nneurophysiological systems and ICT-enabled social systems, discussing how\nframeworks rooted in biology and physics could provide heuristic value in the\ndesign of evolutionary systems relevant to politics and economics. In this\nregard we highlight how the governance of emerging technology (i.e.\nnanotechnology, biotechnology, information technology, and cognitive science),\nand the one of climate change both presently confront us with a number of\nconnected challenges. In particular: historically high level of inequality; the\nco-existence of growing multipolar cultural systems in an unprecedentedly\nconnected world; the unlikely reaching of the institutional agreements required\nto deviate abnormal trajectories of development. We argue that wise general\nsolutions to such interrelated issues should embed the deep understanding of\nhow to elicit mutual incentives in the socio-economic subsystems of Earth\nsystem in order to jointly concur to a global utility function (e.g. avoiding\nthe reach of planetary boundaries and widespread social unrest). We leave some\nopen questions on how techno-social systems can effectively learn and adapt\nwith respect to our understanding of geopolitical complexity.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 11:55:39 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 13:15:50 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Battaglia", "Eugenio Maria", ""], ["Mei", "Jie", ""], ["Dumas", "Guillaume", ""]]}, {"id": "1802.04257", "submitter": "Vincenzo De Florio", "authors": "De Florio Vincenzo", "title": "A hypothesis in evolutionary biology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic Trivers-Willard hypothesis suggested the existence of means or\nconditions able to influence or control the sex of the offspring. Here I\npropose that mechanisms for the alteration of the gender of the offspring could\npossibly be formulated in terms of a distributed system of messages expressing\na change in the environmental conditions. Such messages would provide the\nbiological organization with global and local assessments of the benefits\nassociated with the reproductive investments associated with either genres of\nthe offspring.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 21:16:12 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Vincenzo", "De Florio", ""]]}, {"id": "1802.04291", "submitter": "Emilio Ferrara", "authors": "Adam Badawy, Emilio Ferrara, Kristina Lerman", "title": "Analyzing the Digital Traces of Political Manipulation: The 2016 Russian\n  Interference Twitter Campaign", "comments": null, "journal-ref": "2018 IEEE/ACM International Conference on Advances in Social\n  Networks Analysis and Mining (ASONAM), Barcelona, Spain, 2018, pp. 258-265", "doi": "10.1109/ASONAM.2018.8508646", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until recently, social media was seen to promote democratic discourse on\nsocial and political issues. However, this powerful communication platform has\ncome under scrutiny for allowing hostile actors to exploit online discussions\nin an attempt to manipulate public opinion. A case in point is the ongoing U.S.\nCongress' investigation of Russian interference in the 2016 U.S. election\ncampaign, with Russia accused of using trolls (malicious accounts created to\nmanipulate) and bots to spread misinformation and politically biased\ninformation. In this study, we explore the effects of this manipulation\ncampaign, taking a closer look at users who re-shared the posts produced on\nTwitter by the Russian troll accounts publicly disclosed by U.S. Congress\ninvestigation. We collected a dataset with over 43 million election-related\nposts shared on Twitter between September 16 and October 21, 2016, by about 5.7\nmillion distinct users. This dataset included accounts associated with the\nidentified Russian trolls. We use label propagation to infer the ideology of\nall users based on the news sources they shared. This method enables us to\nclassify a large number of users as liberal or conservative with precision and\nrecall above 90%. Conservatives retweeted Russian trolls about 31 times more\noften than liberals and produced 36x more tweets. Additionally, most retweets\nof troll content originated from two Southern states: Tennessee and Texas.\nUsing state-of-the-art bot detection techniques, we estimated that about 4.9%\nand 6.2% of liberal and conservative users respectively were bots. Text\nanalysis on the content shared by trolls reveals that they had a mostly\nconservative, pro-Trump agenda. Although an ideologically broad swath of\nTwitter users was exposed to Russian Trolls in the period leading up to the\n2016 U.S. Presidential election, it was mainly conservatives who helped amplify\ntheir message.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 19:00:18 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Badawy", "Adam", ""], ["Ferrara", "Emilio", ""], ["Lerman", "Kristina", ""]]}, {"id": "1802.04337", "submitter": "Sridhar Chimalakonda", "authors": "Sridhar Chimalakonda, Kesav V. Nori", "title": "An Ontology Based Modeling Framework for Design of Educational\n  Technologies", "comments": "Preprint Submitted to International Journal of Artificial\n  Intelligence in Education, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite rapid progress, most of the educational technologies today lack a\nstrong instructional design knowledge basis leading to questionable quality of\ninstruction. In addition, a major challenge is to customize these educational\ntechnologies for a wide range of instructional designs. Ontologies are one of\nthe pertinent mechanisms to represent instructional design in the literature.\nHowever, existing approaches do not support modeling of flexible instructional\ndesigns. To address this problem, in this paper, we propose an ontology based\nframework for systematic modeling of different aspects of instructional design\nknowledge based on domain patterns. As part of the framework, we present\nontologies for modeling goals, instructional processes and instructional\nmaterials. We demonstrate the ontology framework by presenting instances of the\nontology for the large scale case study of adult literacy in India (287 million\nlearners spread across 22 Indian Languages), which requires creation of 1000\nsimilar but varied eLearning Systems based on flexible instructional designs.\nThe implemented framework is available at http://rice.iiit.ac.in and is\ntransferred to National Literacy Mission of Government of India. This framework\ncould be used for modeling instructional design knowledge of systems for\nskills, school education and beyond.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 23:57:44 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Chimalakonda", "Sridhar", ""], ["Nori", "Kesav V.", ""]]}, {"id": "1802.04351", "submitter": "Shayan Eskandari", "authors": "Shayan Eskandari, Jeremy Clark, David Barrera, Elizabeth Stobert", "title": "A first look at the usability of bitcoin key management", "comments": "10 Pages, USEC 15: NDSS Workshop on Usable Security (USEC) 2015, San\n  Diego, CA, USA, February 8, 2015, Internet Society", "journal-ref": null, "doi": "10.14722/usec.2015.23015", "report-no": null, "categories": "cs.CR cs.CY cs.ET cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin users are directly or indirectly forced to deal with public key\ncryptography, which has a number of security and usability challenges that\ndiffer from the password-based authentication underlying most online banking\nservices. Users must ensure that keys are simultaneously accessible, resistant\nto digital theft and resilient to loss. In this paper, we contribute an\nevaluation framework for comparing Bitcoin key management approaches, and\nconduct a broad usability evaluation of six representative Bitcoin clients. We\nfind that Bitcoin shares many of the fundamental challenges of key management\nknown from other domains, but that Bitcoin may present a unique opportunity to\nrethink key management for end users.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:38:04 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Eskandari", "Shayan", ""], ["Clark", "Jeremy", ""], ["Barrera", "David", ""], ["Stobert", "Elizabeth", ""]]}, {"id": "1802.04422", "submitter": "Sorelle Friedler", "authors": "Sorelle A. Friedler, Carlos Scheidegger, Suresh Venkatasubramanian,\n  Sonam Choudhary, Evan P. Hamilton, Derek Roth", "title": "A comparative study of fairness-enhancing interventions in machine\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computers are increasingly used to make decisions that have significant\nimpact in people's lives. Often, these predictions can affect different\npopulation subgroups disproportionately. As a result, the issue of fairness has\nreceived much recent interest, and a number of fairness-enhanced classifiers\nand predictors have appeared in the literature. This paper seeks to study the\nfollowing questions: how do these different techniques fundamentally compare to\none another, and what accounts for the differences? Specifically, we seek to\nbring attention to many under-appreciated aspects of such fairness-enhancing\ninterventions. Concretely, we present the results of an open benchmark we have\ndeveloped that lets us compare a number of different algorithms under a variety\nof fairness measures, and a large number of existing datasets. We find that\nalthough different algorithms tend to prefer specific formulations of fairness\npreservations, many of these measures strongly correlate with one another. In\naddition, we find that fairness-preserving algorithms tend to be sensitive to\nfluctuations in dataset composition (simulated in our benchmark by varying\ntraining-test splits), indicating that fairness interventions might be more\nbrittle than previously thought.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 01:31:51 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Friedler", "Sorelle A.", ""], ["Scheidegger", "Carlos", ""], ["Venkatasubramanian", "Suresh", ""], ["Choudhary", "Sonam", ""], ["Hamilton", "Evan P.", ""], ["Roth", "Derek", ""]]}, {"id": "1802.04625", "submitter": "Santanu Bhattacharya", "authors": "Santanu Bhattacharya, Sai Sri Sathya, Kabir Rustogi, Ramesh Raskar", "title": "Economic Impact of Discoverability of Localities and Addresses in India", "comments": "5 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the earth's population has a poorly defined addressing system, thus\nhaving a poorly discoverable residence, property or business locations on a\nmap. Easily discoverable addresses are important for improving their\nlivelihood, business-incomes, and even service delivery. The economic cycle\nbased on discoverable addresses is self-reinforcing: consumers independently\nidentify and adopt such addresses according to their own convenience and\nbusinesses use algorithms or third-party services to resolve these addresses\ninto geocodes to help better identify their customers' locations.\n  Our paper analyses from the top two industries in India: Logistics and\nFinancial Services, indicate that the lack of a good addressing system costs\nIndia $10-14B annually. As the Indian economy is expected to grow rapidly, the\nbusinesses would proportionately grow, causing the total costs to grow further.\nWe, therefore, need to consider a dramatically new approach to modernize the\naddressing systems to bring in efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 14:00:37 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Bhattacharya", "Santanu", ""], ["Sathya", "Sai Sri", ""], ["Rustogi", "Kabir", ""], ["Raskar", "Ramesh", ""]]}, {"id": "1802.04845", "submitter": "Safeeullah Soomro", "authors": "Fahad Razaque, Nareena Soomro, Shoaib Ahmed Shaikh, Safeeullah Soomro,\n  Javed Ahmed Samo, Natesh Kumar and Huma Dharejo", "title": "Using Naive Bayes Algorithm to Students' bachelor Academic Performances\n  Analysis", "comments": "2017", "journal-ref": "IEEE Proceedings ICETAS 2017", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic Data Mining was one of emerging field which comprise procedure of\nexamined students details by different elements such as earlier semester marks,\nattendance, assignment, discussion, lab work were of used to improved bachelor\nacademic performance of students, and overcome difficulties of low ranks of\nbachelor students. It was extracted useful knowledge from bachelor academic\nstudents data collected from department of Computing. Subsequently\npreprocessing data, which was applied data mining techniques to discover\nclassification and clustering. In this study, classification method was\ndescribed which was based on naive byes algorithm and used for Academic data\nmining. It was supportive to students along with to lecturers for evaluation of\nacademic performance. It was cautionary method for students to progress their\nperformance of study.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 15:24:55 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Razaque", "Fahad", ""], ["Soomro", "Nareena", ""], ["Shaikh", "Shoaib Ahmed", ""], ["Soomro", "Safeeullah", ""], ["Samo", "Javed Ahmed", ""], ["Kumar", "Natesh", ""], ["Dharejo", "Huma", ""]]}, {"id": "1802.04915", "submitter": "Shayan Eskandari", "authors": "Shayan Eskandari, Jeremy Clark, Vignesh Sundaresan, Moe Adham", "title": "On the Feasibility of Decentralized Derivatives Markets", "comments": "15 pages, 1st Workshop on Trusted Smart Contracts In Association with\n  Financial Cryptography 17 April 07, 2017", "journal-ref": "International Conference on Financial Cryptography and Data\n  Security FC 2017: Financial Cryptography and Data Security pp 553-567", "doi": "10.1007/978-3-319-70278-0_35", "report-no": null, "categories": "cs.CR cs.CY cs.ET cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Velocity, a decentralized market deployed on\nEthereum for trading a custom type of derivative option. To enable the smart\ncontract to work, we also implement a price fetching tool called PriceGeth. We\npresent this as a case study, noting challenges in development of the system\nthat might be of independent interest to whose working on smart contract\nimplementations. We also apply recent academic results on the security of the\nSolidity smart contract language in validating our codes security. Finally, we\ndiscuss more generally the use of smart contracts in modelling financial\nderivatives.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 01:27:41 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Eskandari", "Shayan", ""], ["Clark", "Jeremy", ""], ["Sundaresan", "Vignesh", ""], ["Adham", "Moe", ""]]}, {"id": "1802.05030", "submitter": "Jos\\'e Gonz\\'alez Caba\\~nas", "authors": "Jos\\'e Gonz\\'alez Caba\\~nas, \\'Angel Cuevas, Rub\\'en Cuevas", "title": "Facebook Use of Sensitive Data for Advertising in Europe", "comments": null, "journal-ref": "27th USENIX Security Symposium (2018) 479-495", "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upcoming European General Data Protection Regulation (GDPR) prohibits the\nprocessing and exploitation of some categories of personal data (health,\npolitical orientation, sexual preferences, religious beliefs, ethnic origin,\netc.) due to the obvious privacy risks that may be derived from a malicious use\nof such type of information. These categories are referred to as sensitive\npersonal data. Facebook has been recently fined EUR 1.2M in Spain for\ncollecting, storing and processing sensitive personal data for advertising\npurposes. This paper quantifies the portion of Facebook users in the European\nUnion (EU) who are labeled with interests linked to sensitive personal data.\nThe results of our study reveal that Facebook labels 73% EU users with\nsensitive interests. This corresponds to 40% of the overall EU population. We\nalso estimate that a malicious third-party could unveil the identity of\nFacebook users that have been assigned a sensitive interest at a cost as low as\nEUR 0.015 per user. Finally, we propose and implement a web browser extension\nto inform Facebook users of the sensitive interests Facebook has assigned them.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 10:40:36 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Caba\u00f1as", "Jos\u00e9 Gonz\u00e1lez", ""], ["Cuevas", "\u00c1ngel", ""], ["Cuevas", "Rub\u00e9n", ""]]}, {"id": "1802.05050", "submitter": "Chuka Oham", "authors": "Chuka Oham, Salil S. Kanhere, Raja Jurdak and Sanjay Jha", "title": "A Blockchain Based Liability Attribution Framework for Autonomous\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of autonomous vehicles is envisaged to disrupt the auto insurance\nliability model.Compared to the the current model where liability is largely\nattributed to the driver,autonomous vehicles necessitate the consideration of\nother entities in the automotive ecosystem including the auto\nmanufacturer,software provider,service technician and the vehicle owner.The\nproliferation of sensors and connecting technologies in autonomous vehicles\nenables an autonomous vehicle to gather sufficient data for liability\nattribution,yet increased connectivity exposes the vehicle to attacks from\ninteracting entities.These possibilities motivate potential liable entities to\nrepudiate their involvement in a collision event to evade liability. While the\ndata collected from vehicular sensors and vehicular communications is an\nintegral part of the evidence for arbitrating liability in the event of an\naccident,there is also a need to record all interactions between the\naforementioned entities to identify potential instances of negligence that may\nhave played a role in the accident.In this paper,we propose a BlockChain(BC)\nbased framework that integrates the concerned entities in the liability model\nand provides untampered evidence for liability attribution and adjudication.We\nfirst describe the liability attribution model, identify key requirements and\ndescribe the adversarial capabilities of entities. Also,we present a detailed\ndescription of data contributing to evidence.Our framework uses permissioned BC\nand partitions the BC to tailor data access to relevant BC\nparticipants.Finally,we conduct a security analysis to verify that the\nidentified requirements are met and resilience of our proposed framework to\nidentified attacks.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 11:50:42 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Oham", "Chuka", ""], ["Kanhere", "Salil S.", ""], ["Jurdak", "Raja", ""], ["Jha", "Sanjay", ""]]}, {"id": "1802.05101", "submitter": "James Bagrow", "authors": "James P. Bagrow", "title": "Democratizing AI: Non-expert design of prediction tasks", "comments": "17 pages, 6 figures", "journal-ref": "PeerJ Computer Science, 6: e296, 2020", "doi": "10.7717/peerj-cs.296", "report-no": null, "categories": "cs.HC cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-experts have long made important contributions to machine learning (ML)\nby contributing training data, and recent work has shown that non-experts can\nalso help with feature engineering by suggesting novel predictive features.\nHowever, non-experts have only contributed features to prediction tasks already\nposed by experienced ML practitioners. Here we study how non-experts can design\nprediction tasks themselves, what types of tasks non-experts will design, and\nwhether predictive models can be automatically trained on data sourced for\ntheir tasks. We use a crowdsourcing platform where non-experts design\npredictive tasks that are then categorized and ranked by the crowd.\nCrowdsourced data are collected for top-ranked tasks and predictive models are\nthen trained and evaluated automatically using those data. We show that\nindividuals without ML experience can collectively construct useful datasets\nand that predictive models can be learned on these datasets, but challenges\nremain. The prediction tasks designed by non-experts covered a broad range of\ndomains, from politics and current events to health behavior, demographics, and\nmore. Proper instructions are crucial for non-experts, so we also conducted a\nrandomized trial to understand how different instructions may influence the\ntypes of prediction tasks being proposed. In general, understanding better how\nnon-experts can contribute to ML can further leverage advances in Automatic ML\nand has important implications as ML continues to drive workplace automation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 14:16:13 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 20:04:50 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Bagrow", "James P.", ""]]}, {"id": "1802.05196", "submitter": "John Seymour", "authors": "John Seymour and Philip Tully", "title": "Generative Models for Spear Phishing Posts on Social Media", "comments": "Presented at NIPS Workshop on Machine Deception (2017), 4 page limit\n  plus references, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historically, machine learning in computer security has prioritized defense:\nthink intrusion detection systems, malware classification, and botnet traffic\nidentification. Offense can benefit from data just as well. Social networks,\nwith their access to extensive personal data, bot-friendly APIs, colloquial\nsyntax, and prevalence of shortened links, are the perfect venues for spreading\nmachine-generated malicious content. We aim to discover what capabilities an\nadversary might utilize in such a domain. We present a long short-term memory\n(LSTM) neural network that learns to socially engineer specific users into\nclicking on deceptive URLs. The model is trained with word vector\nrepresentations of social media posts, and in order to make a click-through\nmore likely, it is dynamically seeded with topics extracted from the target's\ntimeline. We augment the model with clustering to triage high value targets\nbased on their level of social engagement, and measure success of the LSTM's\nphishing expedition using click-rates of IP-tracked links. We achieve state of\nthe art success rates, tripling those of historic email attack campaigns, and\noutperform humans manually performing the same task.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 16:40:02 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Seymour", "John", ""], ["Tully", "Philip", ""]]}, {"id": "1802.05233", "submitter": "Walid Gomaa", "authors": "Walid Gomaa", "title": "Cyber Physical Systems: Prospects and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cyber physical systems CPSs embodies the conception as well as the\nimplementation of the integration of the state-of-art technologies in sensing,\ncommunication, computing, and control. Such systems incorporate new trends such\nas cloud computing, mobile computing, mobile sensing, new modes of\ncommunications, wearables, etc. In this article we give an exposition of the\narchitecture of a typical CPS system and the prospects of such systems in the\ndevelopment of the modern world. We illustrate the three major challenges faced\nby a CPS system: the need for rigorous numerical computation, the limitation of\nthe current wireless communication bandwidth, and the computation/storage\nlimitation by mobility and energy consumption. We address each one of these\nexposing the current techniques devised to solve each one of them.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 17:42:09 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Gomaa", "Walid", ""]]}, {"id": "1802.05287", "submitter": "Savvas Zannettou", "authors": "Savvas Zannettou, Barry Bradlyn, Emiliano De Cristofaro, Haewoon Kwak,\n  Michael Sirivianos, Gianluca Stringhini, Jeremy Blackburn", "title": "What is Gab? A Bastion of Free Speech or an Alt-Right Echo Chamber?", "comments": "To appear in 3rd Cybersafety Workshop (WWW Companion, 2018)", "journal-ref": null, "doi": "10.1145/3184558.3191531", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, a number of new \"fringe\" communities, like 4chan or\ncertain subreddits, have gained traction on the Web at a rapid pace. However,\nmore often than not, little is known about how they evolve or what kind of\nactivities they attract, despite recent research has shown that they influence\nhow false information reaches mainstream communities. This motivates the need\nto monitor these communities and analyze their impact on the Web's information\necosystem. In August 2016, a new social network called Gab was created as an\nalternative to Twitter. It positions itself as putting \"people and free speech\nfirst'\", welcoming users banned or suspended from other social networks. In\nthis paper, we provide, to the best of our knowledge, the first\ncharacterization of Gab. We collect and analyze 22M posts produced by 336K\nusers between August 2016 and January 2018, finding that Gab is predominantly\nused for the dissemination and discussion of news and world events, and that it\nattracts alt-right users, conspiracy theorists, and other trolls. We also\nmeasure the prevalence of hate speech on the platform, finding it to be much\nhigher than Twitter, but lower than 4chan's Politically Incorrect board.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 19:05:08 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 14:41:27 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Zannettou", "Savvas", ""], ["Bradlyn", "Barry", ""], ["De Cristofaro", "Emiliano", ""], ["Kwak", "Haewoon", ""], ["Sirivianos", "Michael", ""], ["Stringhini", "Gianluca", ""], ["Blackburn", "Jeremy", ""]]}, {"id": "1802.05458", "submitter": "Peter Kokol PhD", "authors": "Peter Kokol", "title": "Point systems in Games for Health: A bibliometric scoping study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Very few details about point systems used in games for health are reported in\nscientific literature. To shed some light on this topic a bibliometric study,\nanalyzing the papers containing terms related to games for health and point\nsystems was performed and a mini taxonomy was derived. The search string game*\nAND health AND (point* OR score) AND system* in a Scopus bibliographic database\nwas used to produce the corpus. We limited the search to articles, reviews and\nconference papers written in English and to topics related to medical, health\nand social subjects. The corpus papers abstracts and titles were analysed by\nVOSviewer and a scientific landscape was generated. The search resulted in a\ncorpus consisting of 354 papers. The derived taxonomy contains three objects;\nvideo games, serious games and educational games. The biblimetric mapping and\ntaxonomy revealed some interesting conclusions: (1) the video games have mostly\nnegative effects on health, (2) the serious games might have both a direct\npositive health effects on users and also indirect effects by improved\ncompetencies of health professionals, and (3) the research is concerned not\nonly to computer based educational games, but also to traditional table games\nand sporting games. Based on the derived taxonomy we can conclude that point\nsystems should reward physical activity and healthy living style and punish\nsedentary activities.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 10:06:59 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Kokol", "Peter", ""]]}, {"id": "1802.05568", "submitter": "Bin Guo", "authors": "Yi Ouyang, Bin Guo, Xinjiang Lu, Qi Han, Tong Guo, Zhiwen Yu", "title": "CompetitiveBike: Competitive Prediction of Bike-Sharing Apps Using\n  Heterogeneous Crowdsourced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, bike-sharing systems have been deployed in many cities,\nwhich provide an economical lifestyle. With the prevalence of bike-sharing\nsystems, a lot of companies join the market, leading to increasingly fierce\ncompetition. To be competitive, bike-sharing companies and app developers need\nto make strategic decisions for mobile apps development. Therefore, it is\nsignificant to predict and compare the popularity of different bike-sharing\napps. However, existing works mostly focus on predicting the popularity of a\nsingle app, the popularity contest among different apps has not been explored\nyet. In this paper, we aim to forecast the popularity contest between Mobike\nand Ofo, two most popular bike-sharing apps in China. We develop\nCompetitiveBike, a system to predict the popularity contest among bike-sharing\napps. Moreover, we conduct experiments on real-world datasets collected from 11\napp stores and Sina Weibo, and the experiments demonstrate the effectiveness of\nour approach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 14:36:09 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Ouyang", "Yi", ""], ["Guo", "Bin", ""], ["Lu", "Xinjiang", ""], ["Han", "Qi", ""], ["Guo", "Tong", ""], ["Yu", "Zhiwen", ""]]}, {"id": "1802.05755", "submitter": "Usman Asghar", "authors": "Usman Asghar, Farid Touati, Damiano Crescini, Alessio Galli, Adel Ben\n  Mnaouer", "title": "Development of Highly Efficient Multi-invariable Wireless Sensor System\n  Design for Energy Harvesting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capillary wireless sensor networks devoted to air quality monitoring have\nprovided vital information on dangerous air conditions. In adopting the\nenvironmentally generated energy as the fundamental energy source the main\nchallenge is the implementation of capillary networks rather than replacing the\nbatteries on a set period of times that leads to functional dilemma of devices\nmanagement and high costs. In this paper we present a battery-less,\nself-governing, multi-parametric sensing platform for air quality monitoring\nthat harvests environment energy for long run. Furthermore study on sensor\nsection with their results have also been described in the paper. A customized\nprocess of calibration to check the sensors' sensitivity and a basic portfolio\nof variant energy sources over the power recovery section could productively\nimprove air quality standards tracing in indoor and outdoor application, in a\nkind of 'set and forget' scenario.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 20:46:04 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Asghar", "Usman", ""], ["Touati", "Farid", ""], ["Crescini", "Damiano", ""], ["Galli", "Alessio", ""], ["Mnaouer", "Adel Ben", ""]]}, {"id": "1802.05762", "submitter": "Karthik Sheshadri", "authors": "Karthik Sheshadri, Chung-Wei Hang, Munindar Singh", "title": "Framing Matters: Predicting Framing Changes and Legislation from Topic\n  News Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News has traditionally been well researched, with studies ranging from\nsentiment analysis to event detection and topic tracking. We extend the focus\nto two surprisingly under-researched aspects of news: \\emph{framing} and\n\\emph{predictive utility}. We demonstrate that framing influences public\nopinion and behavior, and present a simple entropic algorithm to characterize\nand detect framing changes. We introduce a dataset of news topics with framing\nchanges, harvested from manual surveys in previous research. Our approach\nachieves an F-measure of $F_1=0.96$ on our data, whereas dynamic topic modeling\nreturns $F_1=0.1$. We also establish that news has \\emph{predictive utility},\nby showing that legislation in topics of current interest can be foreshadowed\nand predicted from news patterns.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 21:06:24 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Sheshadri", "Karthik", ""], ["Hang", "Chung-Wei", ""], ["Singh", "Munindar", ""]]}, {"id": "1802.05768", "submitter": "Karthik Sheshadri", "authors": "Karthik Sheshadri, Chung-Wei Hang, Munindar Singh", "title": "The Causal Link between News Framing and Legislation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that framing, a subjective aspect of news, is a causal\nprecursor to both significant public perception changes, and to federal\nlegislation. We posit, counter-intuitively, that topic news volume and mean\narticle similarity increase and decrease together. We show that specific\nfeatures of news, such as publishing volume , are predictive of both sustained\npublic attention, measured by annual Google trend data, and federal\nlegislation. We observe that public attention changes are driven primarily by\nperiods of high news volume and mean similarity, which we call \\emph{prenatal\nperiods}. Finally, we demonstrate that framing during prenatal periods may be\ncharacterized by high-utility news \\emph{keywords}.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 21:17:47 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Sheshadri", "Karthik", ""], ["Hang", "Chung-Wei", ""], ["Singh", "Munindar", ""]]}, {"id": "1802.05797", "submitter": "Jaybie de Guzman", "authors": "Jaybie A. de Guzman, Kanchana Thilakarathna, and Aruna Seneviratne", "title": "Security and Privacy Approaches in Mixed Reality: A Literature Survey", "comments": "41 pages, 11 figures, 2 tables (3 tables at the appendix); updated\n  references in page 14", "journal-ref": "ACM Comput. Surv. 52, 6, Article 110 (October 2019), 37 pages", "doi": "10.1145/3359626", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed reality (MR) technology development is now gaining momentum due to\nadvances in computer vision, sensor fusion, and realistic display technologies.\nWith most of the research and development focused on delivering the promise of\nMR, there is only barely a few working on the privacy and security implications\nof this technology. This survey paper aims to put in to light these risks, and\nto look into the latest security and privacy work on MR. Specifically, we list\nand review the different protection approaches that have been proposed to\nensure user and data security and privacy in MR. We extend the scope to include\nwork on related technologies such as augmented reality (AR), virtual reality\n(VR), and human-computer interaction (HCI) as crucial components, if not the\norigins, of MR, as well as numerous related work from the larger area of mobile\ndevices, wearables, and Internet-of-Things (IoT). We highlight the lack of\ninvestigation, implementation, and evaluation of data protection approaches in\nMR. Further challenges and directions on MR security and privacy are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 23:33:45 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 01:55:30 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 04:48:27 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["de Guzman", "Jaybie A.", ""], ["Thilakarathna", "Kanchana", ""], ["Seneviratne", "Aruna", ""]]}, {"id": "1802.06009", "submitter": "Joshua Gardner", "authors": "Josh Gardner, Christopher Brooks", "title": "Dropout Model Evaluation in MOOCs", "comments": null, "journal-ref": "Eighth AAAI Symposium on Educational Advances in Artificial\n  Intelligence (EAAI-18), 2018", "doi": null, "report-no": null, "categories": "stat.AP cs.CY stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of learning analytics needs to adopt a more rigorous approach for\npredictive model evaluation that matches the complex practice of\nmodel-building. In this work, we present a procedure to statistically test\nhypotheses about model performance which goes beyond the state-of-the-practice\nin the community to analyze both algorithms and feature extraction methods from\nraw data. We apply this method to a series of algorithms and feature sets\nderived from a large sample of Massive Open Online Courses (MOOCs). While a\ncomplete comparison of all potential modeling approaches is beyond the scope of\nthis paper, we show that this approach reveals a large gap in dropout\nprediction performance between forum-, assignment-, and clickstream-based\nfeature extraction methods, where the latter is significantly better than the\nformer two, which are in turn indistinguishable from one another. This work has\nmethodological implications for evaluating predictive or AI-based models of\nstudent success, and practical implications for the design and targeting of\nat-risk student models and interventions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:13:39 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Gardner", "Josh", ""], ["Brooks", "Christopher", ""]]}, {"id": "1802.06305", "submitter": "Mohammad Saeid Mahdavinejad", "authors": "Mohammad Saeid Mahdavinejad, Mohammadreza Rezvan, Mohammadamin\n  Barekatain, Peyman Adibi, Payam Barnaghi, Amit P. Sheth", "title": "Machine learning for Internet of Things data analysis: A survey", "comments": "Digital Communications and Networks (2017)", "journal-ref": null, "doi": "10.1016/j.dcan.2017.10.002", "report-no": null, "categories": "cs.LG cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid developments in hardware, software, and communication technologies have\nallowed the emergence of Internet-connected sensory devices that provide\nobservation and data measurement from the physical world. By 2020, it is\nestimated that the total number of Internet-connected devices being used will\nbe between 25 and 50 billion. As the numbers grow and technologies become more\nmature, the volume of data published will increase. Internet-connected devices\ntechnology, referred to as Internet of Things (IoT), continues to extend the\ncurrent Internet by providing connectivity and interaction between the physical\nand cyber worlds. In addition to increased volume, the IoT generates Big Data\ncharacterized by velocity in terms of time and location dependency, with a\nvariety of multiple modalities and varying data quality. Intelligent processing\nand analysis of this Big Data is the key to developing smart IoT applications.\nThis article assesses the different machine learning methods that deal with the\nchallenges in IoT data by considering smart cities as the main use case. The\nkey contribution of this study is presentation of a taxonomy of machine\nlearning algorithms explaining how different techniques are applied to the data\nin order to extract higher level information. The potential and challenges of\nmachine learning for IoT data analytics will also be discussed. A use case of\napplying Support Vector Machine (SVM) on Aarhus Smart City traffic data is\npresented for a more detailed exploration.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 22:37:17 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Mahdavinejad", "Mohammad Saeid", ""], ["Rezvan", "Mohammadreza", ""], ["Barekatain", "Mohammadamin", ""], ["Adibi", "Peyman", ""], ["Barnaghi", "Payam", ""], ["Sheth", "Amit P.", ""]]}, {"id": "1802.06578", "submitter": "Gael Lederrey", "authors": "Gael Lederrey and Robert West", "title": "When Sheep Shop: Measuring Herding Effects in Product Ratings with\n  Natural Experiments", "comments": "Submitted at WWW2018 - April 2018 (10 pages, 6 figures, 6 tables);\n  Added Acknowledgements", "journal-ref": null, "doi": "10.1145/3178876.3186160", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As online shopping becomes ever more prevalent, customers rely increasingly\non product rating websites for making purchase decisions. The reliability of\nonline ratings, however, is potentially compromised by the so-called herding\neffect: when rating a product, customers may be biased to follow other\ncustomers' previous ratings of the same product. This is problematic because it\nskews long-term customer perception through haphazard early ratings. The study\nof herding poses methodological challenges. In particular, observational\nstudies are impeded by the lack of counterfactuals: simply correlating early\nwith subsequent ratings is insufficient because we cannot know what the\nsubsequent ratings would have looked like had the first ratings been different.\nThe methodology introduced here exploits a setting that comes close to an\nexperiment, although it is purely observational---a natural experiment. Our key\nmethodological device consists in studying the same product on two separate\nrating sites, focusing on products that received a high first rating on one\nsite, and a low first rating on the other. This largely controls for confounds\nsuch as a product's inherent quality, advertising, and producer identity, and\nlets us isolate the effect of the first rating on subsequent ratings. In a case\nstudy, we focus on beers as products and jointly study two beer rating sites,\nbut our method applies to any pair of sites across which products can be\nmatched. We find clear evidence of herding in beer ratings. For instance, if a\nbeer receives a very high first rating, its second rating is on average half a\nstandard deviation higher, compared to a situation where the identical beer\nreceives a very low first rating. Moreover, herding effects tend to last a long\ntime and are noticeable even after 20 or more ratings. Our results have\nimportant implications for the design of better rating systems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 10:31:46 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 20:56:36 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Lederrey", "Gael", ""], ["West", "Robert", ""]]}, {"id": "1802.06757", "submitter": "Pau Rodr\\'iguez L\\'opez", "authors": "Guillem Cucurull, Pau Rodr\\'iguez, V. Oguz Yazici, Josep M. Gonfaus,\n  F. Xavier Roca, Jordi Gonz\\`alez", "title": "Deep Inference of Personality Traits by Integrating Image and Word Use\n  in Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media, as a major platform for communication and information exchange,\nis a rich repository of the opinions and sentiments of 2.3 billion users about\na vast spectrum of topics. To sense the whys of certain social user's demands\nand cultural-driven interests, however, the knowledge embedded in the 1.8\nbillion pictures which are uploaded daily in public profiles has just started\nto be exploited since this process has been typically been text-based.\nFollowing this trend on visual-based social analysis, we present a novel\nmethodology based on Deep Learning to build a combined image-and-text based\npersonality trait model, trained with images posted together with words found\nhighly correlated to specific personality traits. So the key contribution here\nis to explore whether OCEAN personality trait modeling can be addressed based\non images, here called \\emph{Mind{P}ics}, appearing with certain tags with\npsychological insights. We found that there is a correlation between those\nposted images and their accompanying texts, which can be successfully modeled\nusing deep neural networks for personality estimation. The experimental results\nare consistent with previous cyber-psychology results based on texts or images.\nIn addition, classification results on some traits show that some patterns\nemerge in the set of images corresponding to a specific text, in essence to\nthose representing an abstract concept. These results open new avenues of\nresearch for further refining the proposed personality model under the\nsupervision of psychology experts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 11:58:58 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Cucurull", "Guillem", ""], ["Rodr\u00edguez", "Pau", ""], ["Yazici", "V. Oguz", ""], ["Gonfaus", "Josep M.", ""], ["Roca", "F. Xavier", ""], ["Gonz\u00e0lez", "Jordi", ""]]}, {"id": "1802.06807", "submitter": "Utkarsh Upadhyay", "authors": "Utkarsh Upadhyay, Abir De, Aasish Pappu, Manuel Gomez-Rodriguez", "title": "On the Complexity of Opinions and Online Discussions", "comments": "Proceedings of 12th ACM International Conference on Web Search and\n  Data Mining", "journal-ref": null, "doi": "10.1145/3289600.3290965", "report-no": null, "categories": "cs.SI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an increasingly polarized world, demagogues who reduce complexity down to\nsimple arguments based on emotion are gaining in popularity. Are opinions and\nonline discussions falling into demagoguery? In this work, we aim to provide\ncomputational tools to investigate this question and, by doing so, explore the\nnature and complexity of online discussions and their space of opinions,\nuncovering where each participant lies.\n  More specifically, we present a modeling framework to construct latent\nrepresentations of opinions in online discussions which are consistent with\nhuman judgements, as measured by online voting. If two opinions are close in\nthe resulting latent space of opinions, it is because humans think they are\nsimilar. Our modeling framework is theoretically grounded and establishes a\nsurprising connection between opinions and voting models and the sign-rank of a\nmatrix. Moreover, it also provides a set of practical algorithms to both\nestimate the dimension of the latent space of opinions and infer where opinions\nexpressed by the participants of an online discussion lie in this space.\nExperiments on a large dataset from Yahoo! News, Yahoo! Finance, Yahoo! Sports,\nand the Newsroom app suggest that unidimensional opinion models may often be\nunable to accurately represent online discussions, provide insights into human\njudgements and opinions, and show that our framework is able to circumvent\nlanguage nuances such as sarcasm or humor by relying on human judgements\ninstead of textual analysis.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 19:02:49 GMT"}, {"version": "v2", "created": "Thu, 20 Dec 2018 16:42:48 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Upadhyay", "Utkarsh", ""], ["De", "Abir", ""], ["Pappu", "Aasish", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1802.06951", "submitter": "Yerlan Amanbek", "authors": "Yerlan Amanbek, Ilyas Balgayev, Kanat Batyrkhanov, Margaret Tan", "title": "Adoption of e-government in the Republic of Kazakhstan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper identifies factors that influence Kazakhstan's e-Government portal\nusage. It determines challenges encountered by citizens while using the portal.\nTargeted respondents for the web-based questionnaire survey were the citizens\nof Kazakhstan. The technology acceptance model was used as a methodology to\nmeasure attitude towards portal usage. In addition, this paper discusses the\nbarriers which were experienced by the respondents and can prevent the\nsuccessful adoption of e-Government initiative. The results of the analysis\ndemonstrate that awareness among citizens is high, i.e. the majority of people\nhave visited it at least once and they perceive the portal to be useful, but\nonly a limited percentage of citizens' use it on the regular basis. Further,\npaper can be used to help IT managers of the portal to improve management of\ninformational content and maintain a more effective adoption among citizens.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 03:48:58 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Amanbek", "Yerlan", ""], ["Balgayev", "Ilyas", ""], ["Batyrkhanov", "Kanat", ""], ["Tan", "Margaret", ""]]}, {"id": "1802.07132", "submitter": "Vaibhav Kulkarni", "authors": "Vaibhav Kulkarni, Arielle Moro, Bertil Chapuis, Benoit Garbinato", "title": "Capstone: Mobility Modeling on Smartphones to Achieve Privacy by Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing location traces with context-aware service providers has privacy\nimplications. Location-privacy preserving mechanisms, such as obfuscation,\nanonymization and cryptographic primitives, have been shown to have impractical\nutility/privacy tradeoff. Another solution for enhancing user privacy is to\nminimize data sharing by executing the tasks conventionally carried out at the\nservice providers' end on the users' smartphones. Although the data volume\nshared with the untrusted entities is significantly reduced, executing\ncomputationally demanding server-side tasks on resource-constrained smartphones\nis often impracticable. To this end, we propose a novel perspective on lowering\nthe computational complexity by treating spatiotemporal trajectories as\nspace-time signals. Lowering the data dimensionality facilitates offloading the\ncomputational tasks onto the digital-signal processors and the usage of the\nnon-blocking signal-processing pipelines. While focusing on the task of user\nmobility modeling, we achieve the following results in comparison to the state\nof the art techniques: (i) mobility models with precision and recall greater\nthan 80%, (ii) reduction in computational complexity by a factor of 2.5, and\n(iii) reduction in power consumption by a factor of 0.5. Furthermore, our\ntechnique does not rely on users' behavioral parameters that usually result in\nprivacy-leakage and conclusive bias in the existing techniques. Using three\nreal-world mobility datasets, we demonstrate that our technique addresses these\nweaknesses while formulating accurate user mobility models.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 17:53:35 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Kulkarni", "Vaibhav", ""], ["Moro", "Arielle", ""], ["Chapuis", "Bertil", ""], ["Garbinato", "Benoit", ""]]}, {"id": "1802.07228", "submitter": "Miles Brundage", "authors": "Miles Brundage, Shahar Avin, Jack Clark, Helen Toner, Peter Eckersley,\n  Ben Garfinkel, Allan Dafoe, Paul Scharre, Thomas Zeitzoff, Bobby Filar, Hyrum\n  Anderson, Heather Roff, Gregory C. Allen, Jacob Steinhardt, Carrick Flynn,\n  Se\\'an \\'O h\\'Eigeartaigh, Simon Beard, Haydn Belfield, Sebastian Farquhar,\n  Clare Lyle, Rebecca Crootof, Owain Evans, Michael Page, Joanna Bryson, Roman\n  Yampolskiy, Dario Amodei", "title": "The Malicious Use of Artificial Intelligence: Forecasting, Prevention,\n  and Mitigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report surveys the landscape of potential security threats from\nmalicious uses of AI, and proposes ways to better forecast, prevent, and\nmitigate these threats. After analyzing the ways in which AI may influence the\nthreat landscape in the digital, physical, and political domains, we make four\nhigh-level recommendations for AI researchers and other stakeholders. We also\nsuggest several promising areas for further research that could expand the\nportfolio of defenses, or make attacks less effective or harder to execute.\nFinally, we discuss, but do not conclusively resolve, the long-term equilibrium\nof attackers and defenders.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 18:07:50 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Brundage", "Miles", ""], ["Avin", "Shahar", ""], ["Clark", "Jack", ""], ["Toner", "Helen", ""], ["Eckersley", "Peter", ""], ["Garfinkel", "Ben", ""], ["Dafoe", "Allan", ""], ["Scharre", "Paul", ""], ["Zeitzoff", "Thomas", ""], ["Filar", "Bobby", ""], ["Anderson", "Hyrum", ""], ["Roff", "Heather", ""], ["Allen", "Gregory C.", ""], ["Steinhardt", "Jacob", ""], ["Flynn", "Carrick", ""], ["h\u00c9igeartaigh", "Se\u00e1n \u00d3", ""], ["Beard", "Simon", ""], ["Belfield", "Haydn", ""], ["Farquhar", "Sebastian", ""], ["Lyle", "Clare", ""], ["Crootof", "Rebecca", ""], ["Evans", "Owain", ""], ["Page", "Michael", ""], ["Bryson", "Joanna", ""], ["Yampolskiy", "Roman", ""], ["Amodei", "Dario", ""]]}, {"id": "1802.07281", "submitter": "Ashudeep Singh", "authors": "Ashudeep Singh, Thorsten Joachims", "title": "Fairness of Exposure in Rankings", "comments": "In Proceedings of the 24th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining, London, UK, 2018", "journal-ref": null, "doi": "10.1145/3219819.3220088", "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rankings are ubiquitous in the online world today. As we have transitioned\nfrom finding books in libraries to ranking products, jobs, job applicants,\nopinions and potential romantic partners, there is a substantial precedent that\nranking systems have a responsibility not only to their users but also to the\nitems being ranked. To address these often conflicting responsibilities, we\npropose a conceptual and computational framework that allows the formulation of\nfairness constraints on rankings in terms of exposure allocation. As part of\nthis framework, we develop efficient algorithms for finding rankings that\nmaximize the utility for the user while provably satisfying a specifiable\nnotion of fairness. Since fairness goals can be application specific, we show\nhow a broad range of fairness constraints can be implemented using our\nframework, including forms of demographic parity, disparate treatment, and\ndisparate impact constraints. We illustrate the effect of these constraints by\nproviding empirical results on two ranking problems.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 19:01:19 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 17:03:24 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Singh", "Ashudeep", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1802.07285", "submitter": "Waqar Detho", "authors": "Waqar Detho", "title": "Developing a system for securely time-stamping and visualizing the\n  changes made to online news content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the Internet is indispensable when it comes to information\ndissemination. People rely on the Internet to inform themselves on current news\nevents, as well as to verify facts. We, as a community, are quickly approaching\nan 'electronic information age' where the majority of information will be\ndistributed electronically and tools to preserve this information will become\nessential. While archiving online digital information is a good way to preserve\nonline information for future generations, it has many disadvantages including\nthe easy manipulation of archived information, e.g. by the archiving authority.\nOnline information is also prone to getting hacked or being taken offline.\nTherefore, it is necessary that archived online news information is securely\ntime-stamped with the date and time when it was first archived in a way that\ncannot be manipulated. The process of 'trusted timestamping' is an established\napproach for claiming that particular digital information existed at a\nparticular 'point in time' in the past. However, traditional approaches for\ntrusted timestamping depend on the time-stamping authority's fidelity. Directly\nembedding the hash of a digital file into the blockchain of a cryptocurrency is\na more recent method that allows for secure time-stamping, since digital\ninformation is stored as part of the transaction information in, e.g.\nBitcoin's, blockchain, and not stored at a centralized time-stamping authority.\nHowever, there is no system yet available, which uses this approach for\narchiving and time-stamping online news articles. Therefore, the aim of this\nthesis is to develop a system that 1) enables decentralized trusted\ntime-stamping of web and news articles as a means of making future manipulation\nof online information identifiable, and 2) allows users to determine the\nauthenticity of articles by checking different versions of the same article\nonline.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 19:05:28 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 12:01:28 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Detho", "Waqar", ""]]}, {"id": "1802.07292", "submitter": "Massimo Stella", "authors": "Massimo Stella, Emilio Ferrara and Manlio De Domenico", "title": "Bots increase exposure to negative and inflammatory content in online\n  social systems", "comments": "8 pages, 5 figures", "journal-ref": "PNAS 115 (49) 12435-12440 (2018)", "doi": "10.1073/pnas.1803470115", "report-no": null, "categories": "physics.soc-ph cs.CY cs.HC cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Societies are complex systems which tend to polarize into sub-groups of\nindividuals with dramatically opposite perspectives. This phenomenon is\nreflected -- and often amplified -- in online social networks where, however,\nhumans are no more the only players, and co-exist alongside with social bots,\ni.e., software-controlled accounts. Analyzing large-scale social data collected\nduring the Catalan referendum for independence on October 1, 2017, consisting\nof nearly 4 millions Twitter posts generated by almost 1 million users, we\nidentify the two polarized groups of Independentists and Constitutionalists and\nquantify the structural and emotional roles played by social bots. We show that\nbots act from peripheral areas of the social system to target influential\nhumans of both groups, bombarding Independentists with violent contents,\nincreasing their exposure to negative and inflammatory narratives and\nexacerbating social conflict online. Our findings stress the importance of\ndeveloping countermeasures to unmask these forms of automated social\nmanipulation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 19:17:19 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 09:05:00 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Stella", "Massimo", ""], ["Ferrara", "Emilio", ""], ["De Domenico", "Manlio", ""]]}, {"id": "1802.07523", "submitter": "Dan McGinn", "authors": "D. McGinn, D McIlwraith and Y.Guo", "title": "Toward Open Data Blockchain Analytics: A Bitcoin Perspective", "comments": "17 pages, 9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bitcoin is the first implementation of what has become known as a 'public\npermissionless' blockchain. Guaranteeing security and protocol conformity\nthrough its elegant combination of cryptographic assurances and game theoretic\neconomic incentives, it permits censorship resistant public read-write access\nto its append-only blockchain database without the need for any mediating\ncentral authority. Not until its advent has such a trusted, transparent,\ncomprehensive and granular data set of digital economic behaviours been\navailable for public network analysis. In this article, by translating the\ncumbersome binary data structure of the Bitcoin blockchain into a high fidelity\ngraph model, we demonstrate through various analyses the often overlooked\nsocial and econometric benefits of employing such a novel open data\narchitecture. Specifically we show (a) how repeated patterns of transaction\nbehaviours can be revealed to link user activity across the blockchain; (b) how\nnewly mined bitcoin can be associated to demonstrate individual accumulations\nof wealth; (c) through application of the naive quantity theory of money that\nBitcoin's disinflationary properties can be revealed and measured; and (d) how\nthe user community can develop coordinated defences against repeated denial of\nservice attacks on the network. All of the aforementioned being exemplary\nbenefits that would be lost with the closed data models of the 'private\npermissioned' distributed ledger architectures that are dominating enterprise\nlevel development due to existing blockchain issues of governance, scalability\nand confidentiality.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 11:33:01 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["McGinn", "D.", ""], ["McIlwraith", "D", ""], ["Guo", "Y.", ""]]}, {"id": "1802.07782", "submitter": "John Kingston", "authors": "John Kingston", "title": "Artificial Intelligence and Legal Liability", "comments": "In: Bramer, Max and Petridis, Miltiadis, eds. Research and\n  Development in Intelligent Systems XXXIII: Incorporating Applications and\n  Innovations in Intelligent Systems XXIV. Springer Verlag, Cambridge, UK, pp.\n  269-279. ISBN 9783319471747", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent issue of a popular computing journal asked which laws would apply if\na self-driving car killed a pedestrian. This paper considers the question of\nlegal liability for artificially intelligent computer systems. It discusses\nwhether criminal liability could ever apply; to whom it might apply; and, under\ncivil law, whether an AI program is a product that is subject to product design\nlegislation or a service to which the tort of negligence applies. The issue of\nsales warranties is also considered. A discussion of some of the practical\nlimitations that AI systems are subject to is also included.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 20:11:28 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Kingston", "John", ""]]}, {"id": "1802.07805", "submitter": "Branden Ghena", "authors": "Joshua Adkins, Branden Ghena, Neal Jackson, Pat Pannuto, Samuel\n  Rohrer, Bradford Campbell, Prabal Dutta", "title": "The Signpost Platform for City-Scale Sensing", "comments": "Published in the proceedings of the 17th ACM/IEEE Conference on\n  Information Processing in Sensor Networks (IPSN'18)", "journal-ref": null, "doi": "10.1109/IPSN.2018.00047", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  City-scale sensing holds the promise of enabling a deeper understanding of\nour urban environments. However, a city-scale deployment requires physical\ninstallation, power management, and communications---all challenging tasks\nstanding between a good idea and a realized one. This indicates the need for a\nplatform that enables easy deployment and experimentation for applications\noperating at city scale. To address these challenges, we present Signpost, a\nmodular, energy-harvesting platform for city-scale sensing. Signpost simplifies\ndeployment by eliminating the need for connection to wired infrastructure and\ninstead harvesting energy from an integrated solar panel. The platform\nfurnishes the key resources necessary to support multiple, pluggable sensor\nmodules while providing fair, safe, and reliable sharing in the face of dynamic\nenergy constraints. We deploy Signpost with several sensor modules, showing the\nviability of an energy-harvesting, multi-tenant, sensing system, and evaluate\nits ability to support sensing applications. We believe Signpost reduces the\ndifficulty inherent in city-scale deployments, enables new experimentation, and\nprovides improved insights into urban health.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 21:03:59 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Adkins", "Joshua", ""], ["Ghena", "Branden", ""], ["Jackson", "Neal", ""], ["Pannuto", "Pat", ""], ["Rohrer", "Samuel", ""], ["Campbell", "Bradford", ""], ["Dutta", "Prabal", ""]]}, {"id": "1802.07810", "submitter": "Forough Poursabzi-Sangdeh", "authors": "Forough Poursabzi-Sangdeh, Daniel G. Goldstein, Jake M. Hofman,\n  Jennifer Wortman Vaughan, Hanna Wallach", "title": "Manipulating and Measuring Model Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With machine learning models being increasingly used to aid decision making\neven in high-stakes domains, there has been a growing interest in developing\ninterpretable models. Although many supposedly interpretable models have been\nproposed, there have been relatively few experimental studies investigating\nwhether these models achieve their intended effects, such as making people more\nclosely follow a model's predictions when it is beneficial for them to do so or\nenabling them to detect when a model has made a mistake. We present a sequence\nof pre-registered experiments(N=3,800) in which we showed participants\nfunctionally identical models that varied only in two factors commonly thought\nto make machine learning models more or less interpretable: the number of\nfeatures and the transparency of the model (i.e., whether the model internals\nare clear or black box). Predictably, participants who saw a clear model with\nfew features could better simulate the model's predictions. However, we did not\nfind that participants more closely followed its predictions. Furthermore,\nshowing participants a clear model meant that they were less able to detect and\ncorrect for the model's sizable mistakes, seemingly due to information\noverload. These counterintuitive findings emphasize the importance of testing\nover intuition when developing interpretable models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 21:11:36 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 01:19:14 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 20:41:48 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 00:17:19 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Poursabzi-Sangdeh", "Forough", ""], ["Goldstein", "Daniel G.", ""], ["Hofman", "Jake M.", ""], ["Vaughan", "Jennifer Wortman", ""], ["Wallach", "Hanna", ""]]}, {"id": "1802.08039", "submitter": "Kyrylo Malakhov", "authors": "K. S. Malakhov, H. A. Mohylnyi, V. V. Semenkov, Yu. L. Tikhonov, S. V.\n  Fylypenko", "title": "Comparative analysis of SVIT and Skype features in e-Learning process", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article discusses capabilities of the SVIT and Skype programs in terms of\nuse in e-Learning process. Also various types of connections, image and sound\nquality were investigated.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 13:45:17 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Malakhov", "K. S.", ""], ["Mohylnyi", "H. A.", ""], ["Semenkov", "V. V.", ""], ["Tikhonov", "Yu. L.", ""], ["Fylypenko", "S. V.", ""]]}, {"id": "1802.08612", "submitter": "Libby Hemphill", "authors": "Libby Hemphill", "title": "More Specificity, More Attention to Social Context: Reframing How We\n  Address \"Bad Actors\"", "comments": "Paper submitted Workshop Paper Submitted to CHI 2018: Understanding\n  \"Bad Actors\" Online", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To address \"bad actors\" online, I argue for more specific definitions of\nacceptable and unacceptable behaviors and explicit attention to the social\nstructures in which behaviors occur.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 15:48:56 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Hemphill", "Libby", ""]]}, {"id": "1802.08674", "submitter": "L. Elisa Celis", "authors": "L. Elisa Celis, Sayash Kapoor, Farnood Salehi, and Nisheeth K. Vishnoi", "title": "An Algorithmic Framework to Control Bias in Bandit-based Personalization", "comments": "A short version of this paper appeared in FAT/ML 2017\n  (arXiv:1707.02260)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is pervasive in the online space as it leads to higher\nefficiency and revenue by allowing the most relevant content to be served to\neach user. However, recent studies suggest that personalization methods can\npropagate societal or systemic biases and polarize opinions; this has led to\ncalls for regulatory mechanisms and algorithms to combat bias and inequality.\nAlgorithmically, bandit optimization has enjoyed great success in learning user\npreferences and personalizing content or feeds accordingly. We propose an\nalgorithmic framework that allows for the possibility to control bias or\ndiscrimination in such bandit-based personalization. Our model allows for the\nspecification of general fairness constraints on the sensitive types of the\ncontent that can be displayed to a user. The challenge, however, is to come up\nwith a scalable and low regret algorithm for the constrained optimization\nproblem that arises. Our main technical contribution is a provably fast and\nlow-regret algorithm for the fairness-constrained bandit optimization problem.\nOur proofs crucially leverage the special structure of our problem. Experiments\non synthetic and real-world data sets show that our algorithmic framework can\ncontrol bias with only a minor loss to revenue.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 18:44:01 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Celis", "L. Elisa", ""], ["Kapoor", "Sayash", ""], ["Salehi", "Farnood", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1802.08826", "submitter": "Muhammad Bilal", "authors": "Muhammad Bilal", "title": "Role of management information system in time saving", "comments": "10 pages, 6 figures, accepted in ICCRT conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Case Study will be used in order to investigate and establish the\nimportance of role of Management Information System in time saving during the\npayment of automobile tax in Sindh through e-filling methods. Moreover it will\nalso highlight the important factors which are involved as barriers and limit\nthe role of MIS in time saving techniques. The approach which is used in this\ncase study is descriptive research type along with the survey. The data used\nwas collected from the specimen of common people working in different\nenvironments along with the officers working at Civic Centre (Automobile Tax\nCollection Branch excise department). The audience included were all well\ninformed by the process and were eligible to give their opinions on the\nfollowing research. A system design is also proposed along with an Erd which\ncan be useful in the coming future. This research could likewise be expanded to\ninclude different of respondents, for example, paid taxpayers and different\ntypes of taxpayers. Paid tax payers are given the rights by their clients to\nprepare their assessment matters. They use the e-filing system for different\ntypes of clients and are more frequent users of the e-filing system than\ntaxpayers who file for themselves. It would be interesting to understand which\nfacets of hazard are larger to them. Different types of taxpayers, for example,\ncompany authorized cars may deal with more complex exchanges than single car\ntaxpayers, consequently, they may emphasize different hazard facets when filing\nin the government form frame electronically\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 09:58:38 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Bilal", "Muhammad", ""]]}, {"id": "1802.08972", "submitter": "Zhiyuan Lin", "authors": "Zhiyuan Lin, Tim Althoff, Jure Leskovec", "title": "I'll Be Back: On the Multiple Lives of Users of a Mobile Activity\n  Tracking Application", "comments": null, "journal-ref": "WWW 2018: The 2018 Web Conference", "doi": "10.1145/3178876.3186062", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile health applications that track activities, such as exercise, sleep,\nand diet, are becoming widely used. While these activity tracking applications\nhave the potential to improve our health, user engagement and retention are\ncritical factors for their success. However, long-term user engagement patterns\nin real-world activity tracking applications are not yet well understood. Here\nwe study user engagement patterns within a mobile physical activity tracking\napplication consisting of 115 million logged activities taken by over a million\nusers over 31 months. Specifically, we show that over 75% of users return and\nre-engage with the application after prolonged periods of inactivity, no matter\nthe duration of the inactivity. We find a surprising result that the\nre-engagement usage patterns resemble those of the start of the initial\nengagement period, rather than being a simple continuation of the end of the\ninitial engagement period. This evidence points to a conceptual model of\nmultiple lives of user engagement, extending the prevalent single life view of\nuser activity. We demonstrate that these multiple lives occur because the users\nhave a variety of different primary intents or goals for using the app. We find\nevidence for users being more likely to stop using the app once they achieved\ntheir primary intent or goal (e.g., weight loss). However, these users might\nreturn once their original intent resurfaces (e.g., wanting to lose newly\ngained weight). Based on insights developed in this work, including a marker of\nimproved primary intent performance, our prediction models achieve 71% ROC AUC.\nOverall, our research has implications for modeling user re-engagement in\nhealth activity tracking applications and has consequences for how\nnotifications, recommendations as well as gamification can be used to increase\nengagement.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 09:13:40 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Lin", "Zhiyuan", ""], ["Althoff", "Tim", ""], ["Leskovec", "Jure", ""]]}, {"id": "1802.08974", "submitter": "Kun Hu", "authors": "Kun Hu, Zhe Li, Ying Liu, Luyin Cheng, Qi Yang, and Yan Li", "title": "A Framework in CRM Customer Lifecycle: Identify Downward Trend and\n  Potential Issues Detection", "comments": "14 pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer retention is one of the primary goals in the area of customer\nrelationship management. A mass of work exists in which machine learning models\nor business rules are established to predict churn. However, targeting users at\nan early stage when they start to show a downward trend is a better strategy.\nIn downward trend prediction, the reasons why customers show a downward trend\nis of great interest in the industry as it helps the business to understand the\npain points that customers suffer and to take early action to prevent them from\nchurning. A commonly used method is to collect feedback from customers by\neither aggressively reaching out to them or by passively hearing from them.\nHowever, it is believed that there are a large number of customers who have\nunpleasant experiences and never speak out. In the literature, there is limited\nresearch work that provides a comprehensive and scientific approach to identify\nthese \"silent suffers\". In this study, we propose a novel two-part framework:\ndeveloping the downward prediction process and establishing the methodology to\nidentify the reasons why customers are in the downward trend. In the first\nprediction part, we focus on predicting the downward trend, which is an earlier\nstage of the customer lifecycle compared to churn. In the second part, we\npropose an approach to figuring out the cause (of the downward trend) based on\na causal inference method and semi-supervised learning. The proposed approach\nis capable of identifying potential silent sufferers. We take bad shopping\nexperiences as inputs to develop the framework and validate it via a marketing\nA/B test in the real world. The test readout demonstrates the effectiveness of\nthe framework by driving 88.5% incremental lift in purchase volume.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 09:28:52 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Hu", "Kun", ""], ["Li", "Zhe", ""], ["Liu", "Ying", ""], ["Cheng", "Luyin", ""], ["Yang", "Qi", ""], ["Li", "Yan", ""]]}, {"id": "1802.09220", "submitter": "Nikolaus Von Bomhard", "authors": "Nikolaus von Bomhard, Bernd Ahlborn, Catherine Mason, Ulrich Mansmann", "title": "The Trusted Server: A secure computational environment for privacy\n  compliant evaluations on plain personal data", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0202752", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A growing framework of legal and ethical requirements limit scientific and\ncommercial evalua-tion of personal data. Typically, pseudonymization,\nencryption, or methods of distributed com-puting try to protect individual\nprivacy. However, computational infrastructures still depend on human system\nadministrators. This introduces severe security risks and has strong impact on\nprivacy: system administrators have unlimited access to the computers that they\nmanage in-cluding encryption keys and pseudonymization-tables. Distributed\ncomputing and data obfuscation technologies reduce but do not eliminate the\nrisk of privacy leakage by administrators. They produce higher implementation\neffort and possible data quality degradation. This paper proposes the Trusted\nServer as an alternative approach that provides a sealed and inaccessible\ncomputational environment in a cryptographically strict sense. During operation\nor by direct physical access to storage media, data stored and processed inside\nthe Trusted Server can by no means be read, manipulated or leaked, other than\nby brute-force. Thus, secure and privacy-compliant data processing or\nevaluation of plain person-related data becomes possible even from multiple\nsources, which want their data kept mutually secret.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 09:50:27 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 08:15:21 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["von Bomhard", "Nikolaus", ""], ["Ahlborn", "Bernd", ""], ["Mason", "Catherine", ""], ["Mansmann", "Ulrich", ""]]}, {"id": "1802.09307", "submitter": "Konrad Hinsen", "authors": "Konrad Hinsen", "title": "Digital Scientific Notations as a Human-Computer Interface in\n  Computer-Aided Research", "comments": null, "journal-ref": null, "doi": "10.7717/peerj-cs.158", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of today's scientific research relies on computers and software not only\nfor administrational tasks, but also for processing scientific information.\nExamples of such computer-aided research are the analysis of experimental data\nor the simulation of phenomena based on theoretical models. With the rapid\nincrease of computational power, scientific software has integrated more and\nmore complex scientific knowledge in a black-box fashion. As a consequence, its\nusers do not know, and don't even have a chance of finding out, which models or\nassumptions their computations are based on. The black-box nature of scientific\nsoftware has thereby become a major cause of mistakes. The present work starts\nwith an analysis of this situation from the point of view of human-computer\ninteraction in scientific research. It identifies the key role of digital\nscientific notations at the human-computer interface, and describes a\nproof-of-concept implementation of such a digital scientific notation for\nscientific models formulated as mathematical equations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 15:51:43 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Hinsen", "Konrad", ""]]}, {"id": "1802.09335", "submitter": "Geoff Boeing", "authors": "Paul Waddell, Geoff Boeing, Max Gardner, Emily Porter", "title": "An Integrated Pipeline Architecture for Modeling Urban Land Use, Travel\n  Demand, and Traffic Assignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating land use, travel demand, and traffic models represents a gold\nstandard for regional planning, but is rarely achieved in a meaningful way,\nespecially at the scale of disaggregate data. In this report, we present a new\npipeline architecture for integrated modeling of urban land use, travel demand,\nand traffic assignment. Our land use model, UrbanSim, is an open-source\nmicrosimulation platform used by metropolitan planning organizations worldwide\nfor modeling the growth and development of cities over long (~30 year) time\nhorizons. UrbanSim is particularly powerful as a scenario analysis tool,\nenabling planners to compare and contrast the impacts of different policy\ndecisions on long term land use forecasts in a statistically rigorous way. Our\ntravel demand model, ActivitySim, is an agent-based modeling platform that\nproduces synthetic origin--destination travel demand data. Finally, we use a\nstatic user equilibrium traffic assignment model based on the Frank-Wolfe\nalgorithm to assign vehicles to specific network paths to make trips between\norigins and destinations. This traffic assignment model runs in a\nhigh-performance computing environment. The resulting congested travel time\ndata can then be fed back into UrbanSim and ActivitySim for the next model run.\nThis technical report introduces this research area, describes this project's\nachievements so far in developing this integrated pipeline, and presents an\nupcoming research agenda.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 00:53:09 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Waddell", "Paul", ""], ["Boeing", "Geoff", ""], ["Gardner", "Max", ""], ["Porter", "Emily", ""]]}, {"id": "1802.09344", "submitter": "Mohammad Khalil", "authors": "Mohammad Khalil", "title": "Learning Analytics in Massive Open Online Courses", "comments": "PhD Thesis, 257 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Educational technology has obtained great importance over the last fifteen\nyears. At present, the umbrella of educational technology incorporates\nmultitudes of engaging online environments and fields. Learning analytics and\nMassive Open Online Courses (MOOCs) are two of the most relevant emerging\ntopics in this domain. Since they are open to everyone at no cost, MOOCs excel\nin attracting numerous participants that can reach hundreds and hundreds of\nthousands. Experts from different disciplines have shown significant interest\nin MOOCs as the phenomenon has rapidly grown. In fact, MOOCs have been proven\nto scale education in disparate areas. Their benefits are crystallized in the\nimprovement of educational outcomes, reduction of costs and accessibility\nexpansion. Due to their unusual massiveness, the large datasets of MOOC\nplatforms require advanced tools and methodologies for further examination. The\nkey importance of learning analytics is reflected here. MOOCs offer diverse\nchallenges and practices for learning analytics to tackle. In view of that,\nthis thesis combines both fields in order to investigate further steps in the\nlearning analytics capabilities in MOOCs. The primary research of this\ndissertation focuses on the integration of learning analytics in MOOCs, and\nthereafter looks into examining students' behavior on one side and bridging\nMOOC issues on the other side. The research was done on the Austrian iMooX\nxMOOC platform. We followed the prototyping and case studies research\nmethodology to carry out the research questions of this dissertation. The main\ncontributions incorporate designing a general learning analytics framework,\nlearning analytics prototype, records of students' behavior in nearly every\nMOOC's variables (discussion forums, interactions in videos, self-assessment\nquizzes, login frequency), a cluster of student engagement...\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 14:09:00 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Khalil", "Mohammad", ""]]}, {"id": "1802.09345", "submitter": "Jinsong Wu", "authors": "Jinsong Wu, Song Guo, Huawei Huang, William Liu, Yong Xiang", "title": "Information and Communications Technologies for Sustainable Development\n  Goals: State-of-the-Art, Needs and Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In September 2015, the United Nations General Assembly accepted the 2030\nDevelopment Agenda, which has included 92 paragraphs, and the Paragraph 91\ndefined 17 sustainable development goals (SDGs) and 169 associated targets. The\ngoal of this paper is to discover the correlations among SDGs and information\nand communications technologies (ICTs). This paper discusses the roles and\nopportunities that ICTs play in pursuing the SDGs. We identify a number of\nresearch gaps to those three pillars, social, economic, and environmental\nperspectives, of sustainable development. After extensive literature reviews on\nthe SDG-related research initiatives and activities, we find that the majority\nof contributions to SDGs recognized by the IEEE and ACM research communities\nhave mainly focused on the technical aspects, while there are lack of the\nholistic social good perspectives. Therefore, there are essential and urgent\nneeds to raise the awareness and call for attentions on how to innovate and\nenergize ICTs in order to best assist all nations to achieve the SDGs by 2030.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 16:13:13 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 18:00:50 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Wu", "Jinsong", ""], ["Guo", "Song", ""], ["Huang", "Huawei", ""], ["Liu", "William", ""], ["Xiang", "Yong", ""]]}, {"id": "1802.09348", "submitter": "Dian Pratiwi", "authors": "Risky Armansyah, Dian Pratiwi", "title": "Game of the Cursed Prince based on Android", "comments": "6 pages, 17 figures", "journal-ref": "International Journal of Computer Applications, Volume 179 -\n  Number 19, 2018", "doi": "10.5120/ijca2018916333", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays Games become an entertainment alternative for various circles,\nindustry and game development business is also a profitable industry. In\nIndonesia the amount of game consumption is very high, especially the console\ngame type RPG (Role Playing Game). The task of this research is developing game\nsoftware using Unity 3D to create an Android-based RPG game app. The story is\npacked with RPG genres so the player can feel the main role of the storys\nimagination. The game to be built is a game titled The Cursed Prince. Users\nwill get the sensation of royal adventure. Multiplayer game system, graphics in\n3D game, The main character in this game is Prince, enemies in this game are\nwizards and monsters, Game is not limited time to complete. And the game can be\nsaved, so it can be reopened. The game of The Cursed Prince can be part of\nIndonesian Industry Gaming development.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 14:24:52 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Armansyah", "Risky", ""], ["Pratiwi", "Dian", ""]]}, {"id": "1802.09352", "submitter": "Elad Yom-Tov", "authors": "Elad Yom-Tov", "title": "Screening for cancer using a learning Internet advertising system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies have shown that the traces people leave when browsing the internet\nmay indicate the onset of diseases such as cancer. Here we show that the\nadaptive engines of advertising systems in conjunction with clinically verified\nquestionnaires can be used to identify people who are suspected of having one\nof three types of solid tumor cancers.\n  In the first study, 308 people were recruited through ads shown on the Bing\nsearch engine to complete a clinically verified risk questionnaire. A\nclassifier trained to predict questionnaire response using only past queries on\nBing reached an Area Under the Curve of 0.64 for all three cancer types,\nverifying that past searches could be used to identify people with suspected\ncancer.\n  The second study was conducted using the Google ads system in the same\nconfiguration as in the first study. However, in this study the ads system was\nset to automatically learn to identify people with suspected cancer. A total of\n70,586 people were shown the ads, and 6,484 clicked and were referred to\ncomplete the clinical questionnaires. People from countries with higher\nInternet access and lower life expectancy tended to click more on the ads. Over\ntime the advertisement system learned to identify people who were likely to\nhave symptoms consistent with suspected cancer, such that the percentage of\npeople completing the questionnaires and found to have suspected cancer reached\napproximately 11\\% at the end of the experiment.\n  These results demonstrate the utility of using search engine queries to\nscreen for possible cancer and the application of modern advertising systems to\nhelp identify people who are likely suffering from serious medical conditions.\nThis is especially true in countries where medical services are less developed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 09:16:55 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 04:52:35 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Yom-Tov", "Elad", ""]]}, {"id": "1802.09353", "submitter": "Johannes Pillmann", "authors": "Johannes Pillmann and Christian Wietfeld and Adrian Zarcula and Thomas\n  Raugust and Daniel Calvo Alonso", "title": "Novel Common Vehicle Information Model (CVIM) for Future Automotive\n  Vehicle Big Data Marketplaces", "comments": null, "journal-ref": "Intelligent Vehicles Symposium (IV), 2017 IEEE", "doi": "10.1109/IVS.2017.7995984", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though connectivity services have been introduced in many of the most\nrecent car models, access to vehicle data is currently limited due to its\nproprietary nature. The European project AutoMat has therefore developed an\nopen Marketplace providing a single point of access for brand-independent\nvehicle data. Thereby, vehicle sensor data can be leveraged for the design and\nimplementation of entirely new services even beyond trafficrelated applications\n(such as hyper-local traffic forecasts). This paper presents the architecture\nfor a Vehicle Big Data Marketplace as enabler of cross-sectorial and innovative\nvehicle data services. Therefore, the novel Common Vehicle Information Model\n(CVIM) is defined as an open and harmonized data model, allowing the\naggregation of brand-independent and generic data sets. Within this work the\nrealization of a prototype CVIM and Marketplace implementation is presented.\nThe two use-cases of local weather prediction and road quality measurements are\nintroduced to show the applicability of the AutoMat concept and prototype to\nnon-automotive application\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 10:37:00 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Pillmann", "Johannes", ""], ["Wietfeld", "Christian", ""], ["Zarcula", "Adrian", ""], ["Raugust", "Thomas", ""], ["Alonso", "Daniel Calvo", ""]]}, {"id": "1802.09355", "submitter": "Shaoshan Liu", "authors": "Jie Tang, Shaoshan Liu, Songwen Pei, Stephane Zuckerman, Chen Liu,\n  Weisong Shi, Jean-Luc Gaudiot", "title": "Teaching Autonomous Driving Using a Modular and Integrated Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving is not one single technology but rather a complex system\nintegrating many technologies, which means that teaching autonomous driving is\na challenging task. Indeed, most existing autonomous driving classes focus on\none of the technologies involved. This not only fails to provide a\ncomprehensive coverage, but also sets a high entry barrier for students with\ndifferent technology backgrounds. In this paper, we present a modular,\nintegrated approach to teaching autonomous driving. Specifically, we organize\nthe technologies used in autonomous driving into modules. This is described in\nthe textbook we have developed as well as a series of multimedia online\nlectures designed to provide technical overview for each module. Then, once the\nstudents have understood these modules, the experimental platforms for\nintegration we have developed allow the students to fully understand how the\nmodules interact with each other. To verify this teaching approach, we present\nthree case studies: an introductory class on autonomous driving for students\nwith only a basic technology background; a new session in an existing embedded\nsystems class to demonstrate how embedded system technologies can be applied to\nautonomous driving; and an industry professional training session to quickly\nbring up experienced engineers to work in autonomous driving. The results show\nthat students can maintain a high interest level and make great progress by\nstarting with familiar concepts before moving onto other modules.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 04:01:51 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 01:50:31 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Tang", "Jie", ""], ["Liu", "Shaoshan", ""], ["Pei", "Songwen", ""], ["Zuckerman", "Stephane", ""], ["Liu", "Chen", ""], ["Shi", "Weisong", ""], ["Gaudiot", "Jean-Luc", ""]]}, {"id": "1802.09358", "submitter": "Erkan Bostanci", "authors": "Egemen Turkyilmaz, Alper Akgul, Erkan Bostanci and Mehmet Serdar Guzel", "title": "Detection of Light Sleep Periods Using an Accelerometer Based Alarm\n  System", "comments": "5 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Light sleep is a sleeping period which occurs within each hour during the\nsleep. This is the period when people are closest to awakening. With this being\nthe case people tend to move more frequently and aggressively during these\nperiods. The characteristics of sleeping stages, detection of light sleep\nperiods and analysis of light sleep periods were clarified. The sleeping\npatterns of different subjects were analyzed. In this paper the most suitable\nmoment for waking a person up will be described. The detection of this moment\nand the development process of a system dedicated to this purpose will be\nexplained, and also some experimental results that are acquired via different\ntests will be shared and analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 12:37:14 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Turkyilmaz", "Egemen", ""], ["Akgul", "Alper", ""], ["Bostanci", "Erkan", ""], ["Guzel", "Mehmet Serdar", ""]]}, {"id": "1802.09393", "submitter": "Henry Edison", "authors": "Henry Edison, Nina M. Sm{\\o}rsg{\\aa}rd, Xiaofeng Wang and Pekka\n  Abrahamsson", "title": "Lean Internal Startups for Software Product Innovation in Large\n  Companies: Enablers and Inhibitors", "comments": null, "journal-ref": "Journal of Systems and Software, 135, pp. 69-87, 2018", "doi": "10.1016/j.jss.2017.09.034", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To compete in this age of disruption, large companies cannot rely on cost\nefficiency, lead time reduction and quality improvement. They are now looking\nfor ways to innovate like startups. Meanwhile, the awareness and use of the\nLean startup approach have grown rapidly amongst the software startup community\nin recent years. This study investigates how Lean internal startup facilitates\nsoftware product innovation in large companies and identifies its enablers and\ninhibitors. A multiple case study approach is followed in the investigation.\nTwo software product innovation projects from two large companies are examined,\nusing a conceptual framework that is based on the method-in-action framework\nand extended with the previously developed Lean-Internal Corporate Venture\nmodel. Seven face-to-face in-depth interviews of the employees with different\nroles are conducted. Within-case analysis and cross-case comparison are applied\nto draw the findings from the cases. A generic process flow summarises the\ncommon key processes of Lean internal startups. The findings suggest that an\ninternal startup that is initiated management or employees faces different\nchallenges. A list of enablers of applying Lean startup in large companies are\nidentified, including top management support and cross-functional team. Both\ncases face different inhibitors due to the different process of inception,\nobjective of the team and type of the product. Our contributions are threefold.\nFirst, this study is one of the first attempt to investigate the use of Lean\nstartup approach in large companies empirically. Second, the study shows the\npotential of the method-in-action framework to investigate the Lean startup\napproach in non-startup context. The third is a general process of Lean\ninternal startup and the evidence of the enablers and inhibitors of\nimplementing it, which are both theory-informed and empirically grounded.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 15:51:04 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Edison", "Henry", ""], ["Sm\u00f8rsg\u00e5rd", "Nina M.", ""], ["Wang", "Xiaofeng", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1802.09548", "submitter": "Nina Grgi\\'c-Hla\\v{c}a", "authors": "Nina Grgi\\'c-Hla\\v{c}a, Elissa M. Redmiles, Krishna P. Gummadi, Adrian\n  Weller", "title": "Human Perceptions of Fairness in Algorithmic Decision Making: A Case\n  Study of Criminal Risk Prediction", "comments": "To appear in the Proceedings of the Web Conference (WWW 2018). Code\n  available at https://fate-computing.mpi-sws.org/procedural_fairness/", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As algorithms are increasingly used to make important decisions that affect\nhuman lives, ranging from social benefit assignment to predicting risk of\ncriminal recidivism, concerns have been raised about the fairness of\nalgorithmic decision making. Most prior works on algorithmic fairness\nnormatively prescribe how fair decisions ought to be made. In contrast, here,\nwe descriptively survey users for how they perceive and reason about fairness\nin algorithmic decision making.\n  A key contribution of this work is the framework we propose to understand why\npeople perceive certain features as fair or unfair to be used in algorithms.\nOur framework identifies eight properties of features, such as relevance,\nvolitionality and reliability, as latent considerations that inform people's\nmoral judgments about the fairness of feature use in decision-making\nalgorithms. We validate our framework through a series of scenario-based\nsurveys with 576 people. We find that, based on a person's assessment of the\neight latent properties of a feature in our exemplar scenario, we can\naccurately (> 85%) predict if the person will judge the use of the feature as\nfair.\n  Our findings have important implications. At a high-level, we show that\npeople's unfairness concerns are multi-dimensional and argue that future\nstudies need to address unfairness concerns beyond discrimination. At a\nlow-level, we find considerable disagreements in people's fairness judgments.\nWe identify root causes of the disagreements, and note possible pathways to\nresolve them.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 19:00:15 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Grgi\u0107-Hla\u010da", "Nina", ""], ["Redmiles", "Elissa M.", ""], ["Gummadi", "Krishna P.", ""], ["Weller", "Adrian", ""]]}, {"id": "1802.09597", "submitter": "Manish Raghavan", "authors": "Manish Raghavan, Ashton Anderson, Jon Kleinberg", "title": "Mapping the Invocation Structure of Online Political Interaction", "comments": "The Web Conference 2018 (WWW 2018)", "journal-ref": null, "doi": "10.1145/3178876.3186129", "report-no": null, "categories": "cs.SI cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The surge in political information, discourse, and interaction has been one\nof the most important developments in social media over the past several years.\nThere is rich structure in the interaction among different viewpoints on the\nideological spectrum. However, we still have only a limited analytical\nvocabulary for expressing the ways in which these viewpoints interact.\n  In this paper, we develop network-based methods that operate on the ways in\nwhich users share content; we construct \\emph{invocation graphs} on Web domains\nshowing the extent to which pages from one domain are invoked by users to reply\nto posts containing pages from other domains. When we locate the domains on a\npolitical spectrum induced from the data, we obtain an embedded graph showing\nhow these interaction links span different distances on the spectrum. The\nstructure of this embedded network, and its evolution over time, helps us\nderive macro-level insights about how political interaction unfolded through\n2016, leading up to the US Presidential election. In particular, we find that\nthe domains invoked in replies spanned increasing distances on the spectrum\nover the months approaching the election, and that there was clear asymmetry\nbetween the left-to-right and right-to-left patterns of linkage.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 20:43:18 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Raghavan", "Manish", ""], ["Anderson", "Ashton", ""], ["Kleinberg", "Jon", ""]]}, {"id": "1802.09685", "submitter": "Khavee Agustus Botangen", "authors": "Khavee Agustus Botangen, Shahper Vodanovich, Jian Yu", "title": "Preservation of Indigenous Culture among Indigenous Migrants through\n  Social Media: the Igorot Peoples", "comments": "10 pages, in Proceedings of the 50th Hawaii International Conference\n  on System Sciences 2017", "journal-ref": "Botangen, K.A., Vodanovich, S. and Yu, J., 2017, January.\n  Preservation of Indigenous Culture among Indigenous Migrants through Social\n  Media: The Igorot Peoples. In Proceedings of the 50th Hawaii International\n  Conference on System Sciences", "doi": "10.24251/HICSS.2017.278", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The value and relevance of indigenous knowledge towards sustainability of\nhuman societies drives for its preservation. This work explored the use of\nFacebook groups to promote indigenous knowledge among Igorot peoples in the\ndiaspora. The virtual communities help intensify the connection of Igorot\nmigrants to their traditional culture despite the challenges of assimilation to\na different society. A survey of posts on 20 Facebook groups identified and\nclassified the indigenous cultural elements conveyed through social media. A\nsubsequent survey of 56 Igorot migrants revealed that popular social media has\na significant role in the exchange, revitalization, practice, and learning of\nindigenous culture; inciting an effective medium to leverage preservation\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 02:13:45 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Botangen", "Khavee Agustus", ""], ["Vodanovich", "Shahper", ""], ["Yu", "Jian", ""]]}, {"id": "1802.10134", "submitter": "Nazim Faour", "authors": "Nazim Faour", "title": "Transparent Voting Platform Based on Permissioned Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Since 2004, different research was handling the challenges in the centralized\nvoting systems, e-voting protocols and recently the decentralized voting. So\nelectronic voting puts forward some difficulties regarding the voter anonymity,\nthe secure casting of the votes and to prevent the voting process from\nfrauding. The Decentralized property of the technology called \"blockchain\"\ncould have the solution for many of the challenges in voting research area and\nbrings a new secure mechanism of safe and transparent voting. In this paper, a\nbroad comparison between ongoing voting systems has studied by analyzing their\nstructure and the drawbacks that should consider in future to improve the whole\nelection process from keeping the privacy of the voter, casting a vote with the\npossibility to check if it was counted correctly to publishing the results. The\nresult of the paper will give a new approach to extend the target of the\nelection from small scale to large scale despite the fact of Ethereum\nlimitation which can cast on the blockchain just five votes per minute. The\nprimary challenge is to find an answer for this question: \"How to balance\nbetween voter privacy and transparency without breaking the important rule\nwhere the voter can proof for a specific candidate that he voted for him in a\nbribe situation?\".\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 14:20:35 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Faour", "Nazim", ""]]}, {"id": "1802.10523", "submitter": "Abu Awal Md Shoeb", "authors": "Abu Awal Md Shoeb", "title": "Is Private Browsing in Modern Web Browsers Really Private?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web browsers are the most common tool to perform various activities over the\ninternet. Along with normal mode, all modern browsers have private browsing\nmode. The name of the mode varies from browser to browser but the purpose of\nthe private mode remains same in every browser. In normal browsing mode, the\nbrowser keeps track of users' activity and related data such as browsing\nhistories, cookies, auto-filled fields, temporary internet files, etc. In\nprivate mode, it is said that no information is stored while browsing or all\ninformation is destroyed after closing the current private session. However,\nsome researchers have already disproved this claim by performing various tests\nin most popular browsers. I have also some personal experience where private\nmode browsing fails to keep all browsing information as private. In this\nposition paper, I take the position against private browsing. By examining\nvarious facts, it is proved that the private browsing mode is not really\nprivate as it is claimed; it does not keep everything private. In following\nsections, I will present the proof to justify my argument. Along with some\nother already performed research work, I will show my personal case studies and\nexperimental data as well.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 16:01:06 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Shoeb", "Abu Awal Md", ""]]}, {"id": "1802.10568", "submitter": "Chlo\\'e-Agathe Azencott", "authors": "Chlo\\'e-Agathe Azencott", "title": "Machine learning and genomics: precision medicine vs. patient privacy", "comments": "13 pages, submitted to Philosophical Transactions A", "journal-ref": null, "doi": "10.1098/rsta.2017.0350", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning can have major societal impact in computational biology\napplications. In particular, it plays a central role in the development of\nprecision medicine, whereby treatment is tailored to the clinical or genetic\nfeatures of the patient. However, these advances require collecting and sharing\namong researchers large amounts of genomic data, which generates much concern\nabout privacy. Researchers, study participants and governing bodies should be\naware of the ways in which the privacy of participants might be compromised, as\nwell as of the large body of research on technical solutions to these issues.\nWe review how breaches in patient privacy can occur, present recent\ndevelopments in computational data protection, and discuss how they can be\ncombined with legal and ethical perspectives to provide secure frameworks for\ngenomic data sharing.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 18:17:00 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 15:47:41 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 10:56:44 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Azencott", "Chlo\u00e9-Agathe", ""]]}]