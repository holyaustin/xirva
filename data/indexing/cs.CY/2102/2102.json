[{"id": "2102.00087", "submitter": "Amjad Dehman", "authors": "Amjad Dehman, Bilal Farooq", "title": "Are Work Zones and Connected Automated Vehicles Ready for a Harmonious\n  Coexistence? A Scoping Review and Research Agenda", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advent of connected and automated vehicles (CAVs) is expected to\ntransform the transportation system. CAV technologies are being developed\nrapidly and they are foreseen to penetrate the market at a rapid pace. On the\nother hand, work zones (WZs) have become common areas on highway systems as a\nresult of the increasing construction and maintenance activities. The near\nfuture will therefore bring the coexistence of CAVs and WZs which makes their\ninteraction inevitable. WZs expose all vehicles to a sudden and complex\ngeometric change in the roadway environment, something that may challenge many\nof CAV navigation capabilities. WZs however also impose a space contraction\nresulting in adverse traffic impacts, something that legitimately calls for\nbenefiting from the highly efficient CAV functions. CAVs should be able to\nreliably traverse WZ geometry and WZs should benefit from CAV intelligent\nfunctions. This paper reviews the state-of-the-art and the key concepts,\nopportunities, and challenges of deploying CAV systems at WZs. The reviewed\nsubjects include traffic performance and behaviour, technologies and\ninfrastructure, and regulatory considerations. Eighteen CAV mobility, safety,\nand environmental concepts and functions were distributed over the WZ area\nwhich was subdivided into five segments: further upstream, approach area,\nqueuing area, WZ activity, and termination area. In addition, among other\ntopics reviewed and discussed are detection of WZ features, smart traffic\ncontrol devices, various technologies at connected WZs, cross-border\nharmonization, liability, insurance, and privacy. The paper also provides a\nresearch agenda with a list of research needs supported by experts rating and\ninputs. The paper aims to provide a bird eye view, but with necessary details\nthat can benefit researchers, practitioners, and transportation agencies.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 22:05:48 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 15:47:52 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Dehman", "Amjad", ""], ["Farooq", "Bilal", ""]]}, {"id": "2102.00089", "submitter": "Mengfan Yao", "authors": "Mengfan Yao, Siqian Zhao, Shaghayegh Sahebi, Reza Feyzi Behnagh", "title": "Stimuli-Sensitive Hawkes Processes for Personalized Student\n  Procrastination Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Student procrastination and cramming for deadlines are major challenges in\nonline learning environments, with negative educational and well-being side\neffects. Modeling student activities in continuous time and predicting their\nnext study time are important problems that can help in creating personalized\ntimely interventions to mitigate these challenges. However, previous attempts\non dynamic modeling of student procrastination suffer from major issues: they\nare unable to predict the next activity times, cannot deal with missing\nactivity history, are not personalized, and disregard important course\nproperties, such as assignment deadlines, that are essential in explaining the\ncramming behavior. To resolve these problems, we introduce a new personalized\nstimuli-sensitive Hawkes process model (SSHP), by jointly modeling all\nstudent-assignment pairs and utilizing their similarities, to predict students'\nnext activity times even when there are no historical observations. Unlike\nregular point processes that assume a constant external triggering effect from\nthe environment, we model three dynamic types of external stimuli, according to\nassignment availabilities, assignment deadlines, and each student's time\nmanagement habits. Our experiments on two synthetic datasets and two real-world\ndatasets show a superior performance of future activity prediction, comparing\nwith state-of-the-art models. Moreover, we show that our model achieves a\nflexible and accurate parameterization of activity intensities in students.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 22:07:07 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Yao", "Mengfan", ""], ["Zhao", "Siqian", ""], ["Sahebi", "Shaghayegh", ""], ["Behnagh", "Reza Feyzi", ""]]}, {"id": "2102.00093", "submitter": "Mengfan Yao", "authors": "Mengfan Yao, Siqian Zhao, Shaghayegh Sahebi, Reza Feyzi Behnagh", "title": "Relaxed Clustered Hawkes Process for Procrastination Modeling in MOOCs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hawkes processes have been shown to be efficient in modeling bursty sequences\nin a variety of applications, such as finance and social network activity\nanalysis. Traditionally, these models parameterize each process independently\nand assume that the history of each point process can be fully observed. Such\nmodels could however be inefficient or even prohibited in certain real-world\napplications, such as in the field of education, where such assumptions are\nviolated. Motivated by the problem of detecting and predicting student\nprocrastination in students Massive Open Online Courses (MOOCs) with missing\nand partially observed data, in this work, we propose a novel personalized\nHawkes process model (RCHawkes-Gamma) that discovers meaningful student\nbehavior clusters by jointly learning all partially observed processes\nsimultaneously, without relying on auxiliary features. Our experiments on both\nsynthetic and real-world education datasets show that RCHawkes-Gamma can\neffectively recover student clusters and their temporal procrastination\ndynamics, resulting in better predictive performance of future student\nactivities. Our further analyses of the learned parameters and their\nassociation with student delays show that the discovered student clusters\nunveil meaningful representations of various procrastination behaviors in\nstudents.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 22:20:38 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Yao", "Mengfan", ""], ["Zhao", "Siqian", ""], ["Sahebi", "Shaghayegh", ""], ["Behnagh", "Reza Feyzi", ""]]}, {"id": "2102.00128", "submitter": "Nil-Jana Akpinar", "authors": "Nil-Jana Akpinar, Maria De-Arteaga, Alexandra Chouldechova", "title": "The effect of differential victim crime reporting on predictive policing\n  systems", "comments": "Conference on Fairness, Accountability, and Transparency (FAccT 2021)", "journal-ref": null, "doi": "10.1145/3442188.3445877", "report-no": null, "categories": "cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Police departments around the world have been experimenting with forms of\nplace-based data-driven proactive policing for over two decades. Modern\nincarnations of such systems are commonly known as hot spot predictive\npolicing. These systems predict where future crime is likely to concentrate\nsuch that police can allocate patrols to these areas and deter crime before it\noccurs. Previous research on fairness in predictive policing has concentrated\non the feedback loops which occur when models are trained on discovered crime\ndata, but has limited implications for models trained on victim crime reporting\ndata. We demonstrate how differential victim crime reporting rates across\ngeographical areas can lead to outcome disparities in common crime hot spot\nprediction models. Our analysis is based on a simulation patterned after\ndistrict-level victimization and crime reporting survey data for Bogot\\'a,\nColombia. Our results suggest that differential crime reporting rates can lead\nto a displacement of predicted hotspots from high crime but low reporting areas\nto high or medium crime and high reporting areas. This may lead to\nmisallocations both in the form of over-policing and under-policing.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 01:57:22 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 22:52:55 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Akpinar", "Nil-Jana", ""], ["De-Arteaga", "Maria", ""], ["Chouldechova", "Alexandra", ""]]}, {"id": "2102.00141", "submitter": "Abhisek Dash", "authors": "Abhisek Dash, Abhijnan Chakraborty, Saptarshi Ghosh, Animesh\n  Mukherjee, Krishna P. Gummadi", "title": "When the Umpire is also a Player: Bias in Private Label Product\n  Recommendations on E-commerce Marketplaces", "comments": "This work has been accepted for presentation at the ACM Conference on\n  Fairness, Accountability, and Transparency 2021 (ACM FAccT 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic recommendations mediate interactions between millions of\ncustomers and products (in turn, their producers and sellers) on large\ne-commerce marketplaces like Amazon. In recent years, the producers and sellers\nhave raised concerns about the fairness of black-box recommendation algorithms\ndeployed on these marketplaces. Many complaints are centered around\nmarketplaces biasing the algorithms to preferentially favor their own `private\nlabel' products over competitors. These concerns are exacerbated as\nmarketplaces increasingly de-emphasize or replace `organic' recommendations\nwith ad-driven `sponsored' recommendations, which include their own private\nlabels. While these concerns have been covered in popular press and have\nspawned regulatory investigations, to our knowledge, there has not been any\npublic audit of these marketplace algorithms. In this study, we bridge this gap\nby performing an end-to-end systematic audit of related item recommendations on\nAmazon. We propose a network-centric framework to quantify and compare the\nbiases across organic and sponsored related item recommendations. Along a\nnumber of our proposed bias measures, we find that the sponsored\nrecommendations are significantly more biased toward Amazon private label\nproducts compared to organic recommendations. While our findings are primarily\ninteresting to producers and sellers on Amazon, our proposed bias measures are\ngenerally useful for measuring link formation bias in any social or content\nnetworks.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 03:24:38 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 04:24:33 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Dash", "Abhisek", ""], ["Chakraborty", "Abhijnan", ""], ["Ghosh", "Saptarshi", ""], ["Mukherjee", "Animesh", ""], ["Gummadi", "Krishna P.", ""]]}, {"id": "2102.00228", "submitter": "Chengwei Zhang", "authors": "Chengwei Zhang, Yangzhou Jiang, Wei Zhang, Chengyu Gu", "title": "MUSE: Multi-Scale Temporal Features Evolution for Knowledge Tracing", "comments": "the AAAI-2021 workshop on Imagining Post-COVID Education with AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transformer based knowledge tracing model is an extensively studied problem\nin the field of computer-aided education. By integrating temporal features into\nthe encoder-decoder structure, transformers can processes the exercise\ninformation and student response information in a natural way. However, current\nstate-of-the-art transformer-based variants still share two limitations. First,\nextremely long temporal features cannot well handled as the complexity of\nself-attention mechanism is O(n2). Second, existing approaches track the\nknowledge drifts under fixed a window size, without considering different\ntemporal-ranges. To conquer these problems, we propose MUSE, which is equipped\nwith multi-scale temporal sensor unit, that takes either local or global\ntemporal features into consideration. The proposed model is capable to capture\nthe dynamic changes in users knowledge states at different temporal-ranges, and\nprovides an efficient and powerful way to combine local and global features to\nmake predictions. Our method won the 5-th place over 3,395 teams in the Riiid\nAIEd Challenge 2020.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 13:52:46 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zhang", "Chengwei", ""], ["Jiang", "Yangzhou", ""], ["Zhang", "Wei", ""], ["Gu", "Chengyu", ""]]}, {"id": "2102.00287", "submitter": "Eva Vanmassenhove", "authors": "Eva Vanmassenhove, Dimitar Shterionov, Matthew Gwilliam", "title": "Machine Translationese: Effects of Algorithmic Bias on Linguistic\n  Complexity in Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies in the field of Machine Translation (MT) and Natural Language\nProcessing (NLP) have shown that existing models amplify biases observed in the\ntraining data. The amplification of biases in language technology has mainly\nbeen examined with respect to specific phenomena, such as gender bias. In this\nwork, we go beyond the study of gender in MT and investigate how bias\namplification might affect language in a broader sense. We hypothesize that the\n'algorithmic bias', i.e. an exacerbation of frequently observed patterns in\ncombination with a loss of less frequent ones, not only exacerbates societal\nbiases present in current datasets but could also lead to an artificially\nimpoverished language: 'machine translationese'. We assess the linguistic\nrichness (on a lexical and morphological level) of translations created by\ndifferent data-driven MT paradigms - phrase-based statistical (PB-SMT) and\nneural MT (NMT). Our experiments show that there is a loss of lexical and\nmorphological richness in the translations produced by all investigated MT\nparadigms for two language pairs (EN<=>FR and EN<=>ES).\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 18:49:11 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Vanmassenhove", "Eva", ""], ["Shterionov", "Dimitar", ""], ["Gwilliam", "Matthew", ""]]}, {"id": "2102.00407", "submitter": "Wenyuan Kong", "authors": "Wenyuan Kong, Teng Fei, Thom Jencks", "title": "Emotion and color in paintings: a novel temporal and spatial\n  quantitative perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As subjective artistic creations, artistic paintings carry emotion of their\ncreators. Emotions expressed in paintings and emotion aroused in spectators by\npaintings are two kinds of emotions that scholars have paid attention to.\nTraditional studies on emotions expressed by paintings are mainly conducted\nfrom qualitative perspectives, with neither quantitative output on the\nemotional values of a painting, nor exploration of trends in the expression of\nemotion in art history. In this research we threat facial expressions in\npaintings as an artistic characteristics of art history and employ cognitive\ncomputation technology to identify the facial emotions in paintings and to\ninvestigate the quantitative measures of paintings from three emotion-related\naspects: the spatial and temporal patterns of painting emotions in art history,\nthe gender difference on the emotion of paintings and the color preference\nassociated with emotions. We discovered that the emotion of happiness has a\ngrowing trend from ancient to modern times in paintings history, and men and\nwomen have different facial expressions patterns along time. As for color\npreference, artists with different culture backgrounds had similar association\npreferences between colors and emotions.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 08:05:33 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kong", "Wenyuan", ""], ["Fei", "Teng", ""], ["Jencks", "Thom", ""]]}, {"id": "2102.00459", "submitter": "Neo Chung-Kit Yiu", "authors": "Neo C.K. Yiu", "title": "Toward Blockchain-Enabled Supply Chain Anti-Counterfeiting and\n  Traceability", "comments": "20 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.22989.36322", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Innovative solutions addressing product anti-counterfeiting and record\nprovenance have been deployed across today's internationally spanning supply\nchain networks. These product anti-counterfeiting solutions are developed and\nimplemented with centralized system architecture relying on centralized\nauthorities or any form of intermediaries. Vulnerabilities of centralized\nproduct anti-counterfeiting solutions could possibly lead to system failure or\nsusceptibility of malicious modifications performed on product records or\nvarious potential attacks to the system components by dishonest participant\nnodes traversing along the supply chain. Blockchain technology has progressed\nfrom merely with a use case of immutable ledger for cryptocurrency transactions\nto a programmable interactive environment of developing decentralized and\nreliable applications addressing different use cases globally. In this\nresearch, so as to facilitate trustworthy data provenance retrieval,\nverification and management, as well as strengthening capability of product\nanti-counterfeiting, key areas of decentralization and feasible mechanisms of\ndeveloping decentralized and distributed product anti-counterfeiting and\ntraceability ecosystems utilizing blockchain technology, are identified via a\nseries of security and threat analyses performed mainly against NFC-Enabled\nAnti-Counterfeiting System (NAS) which is one of the solutions currently\nimplemented in the industry with centralized architecture. A set of fundamental\nsystem requirements are set out for developing a blockchain-enabled autonomous\nand decentralized solution for supply chain anti-counterfeiting and\ntraceability, as a secure and immutable scientific data provenance tracking and\nmanagement platform in which provenance records, providing compelling\nproperties on data integrity of luxurious goods, are recorded and verified\nautomatically, for supply chain industry.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 14:18:37 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Yiu", "Neo C. K.", ""]]}, {"id": "2102.00464", "submitter": "Kelly Wagman", "authors": "Kelly B. Wagman and Lisa Parks", "title": "Beyond the Command: Feminist STS Research and Critical Issues for the\n  Design of Social Machines", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines, from artificially intelligent digital assistants to embodied\nrobots, are becoming more pervasive in everyday life. Drawing on feminist\nscience and technology studies (STS) perspectives, we demonstrate how machine\ndesigners are not just crafting neutral objects, but relationships between\nmachines and humans that are entangled in human social issues such as gender\nand power dynamics. Thus, in order to create a more ethical and just future,\nthe dominant assumptions currently underpinning the design of these\nhuman-machine relations must be challenged and reoriented toward relations of\njustice and inclusivity. This paper contributes the \"social machine\" as a model\nfor technology designers who seek to recognize the importance, diversity and\ncomplexity of the social in their work, and to engage with the agential power\nof machines. In our model, the social machine is imagined as a potentially\nequitable relationship partner that has agency and as an \"other\" that is\ndistinct from, yet related to, humans, objects, and animals. We critically\nexamine and contrast our model with tendencies in robotics that consider robots\nas tools, human companions, animals or creatures, and/or slaves. In doing so,\nwe demonstrate ingrained dominant assumptions about human-machine relations and\nreveal the challenges of radical thinking in the social machine design space.\nFinally, we present two design challenges based on non-anthropomorphic\nfiguration and mutuality, and call for experimentation, unlearning dominant\ntendencies, and reimagining of sociotechnical futures.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 15:00:35 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Wagman", "Kelly B.", ""], ["Parks", "Lisa", ""]]}, {"id": "2102.00625", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Nina Grgi\\'c-Hla\\v{c}a, Meeyoung Cha", "title": "Human Perceptions on Moral Responsibility of AI: A Case Study in\n  AI-Assisted Bail Decision-Making", "comments": "17 Pages, 5 Figures, ACM CHI 2021", "journal-ref": null, "doi": "10.1145/3411764.3445260", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to attribute responsibility for autonomous artificial intelligence (AI)\nsystems' actions has been widely debated across the humanities and social\nscience disciplines. This work presents two experiments ($N$=200 each) that\nmeasure people's perceptions of eight different notions of moral responsibility\nconcerning AI and human agents in the context of bail decision-making. Using\nreal-life adapted vignettes, our experiments show that AI agents are held\ncausally responsible and blamed similarly to human agents for an identical\ntask. However, there was a meaningful difference in how people perceived these\nagents' moral responsibility; human agents were ascribed to a higher degree of\npresent-looking and forward-looking notions of responsibility than AI agents.\nWe also found that people expect both AI and human decision-makers and advisors\nto justify their decisions regardless of their nature. We discuss policy and\nHCI implications of these findings, such as the need for explainable AI in\nhigh-stakes scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 04:07:38 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Lima", "Gabriel", ""], ["Grgi\u0107-Hla\u010da", "Nina", ""], ["Cha", "Meeyoung", ""]]}, {"id": "2102.00656", "submitter": "Pedro Henrique Juliano Nardelli", "authors": "Pedro H. J. Nardelli, Hafiz Majid Hussein, Arun Narayanan, Yongheng\n  Yang", "title": "Virtual Microgrid Management via Software-defined Energy Network for\n  Electricity Sharing", "comments": "This paper was accepted to IEEE Systems, Man, and Cybernetics\n  Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digitalization has led to radical changes in the distribution of goods across\nvarious sectors. The tendency is to move from traditional buyer-seller markets\nto subscription-based on-demand \"smart\" matching platforms enabled by pervasive\nICTs. The driving force behind this lies in the fact that assets, which were\nscarce in the past, are readily abundant, approaching a regime of zero marginal\ncosts. This is also becoming a reality in electrified energy systems due to the\nsubstantial growth of distributed renewable energy sources such as solar and\nwind; the increasing number of small-scale storage units such as batteries and\nheat pumps; and the availability of flexible loads that enable demand-side\nmanagement. In this context, this article proposes a system architecture based\non a logical (cyber) association of spatially distributed (physical) elements\nas an approach to build a virtual microgrid operated as a software-defined\nenergy network (SDEN) that is enabled by packetized energy management. The\nproposed cyber-physical system presumes that electrical energy is shared among\nits members and that the energy sharing is enabled in the cyber domain by\nhandshakes inspired by resource allocation methods utilized in computer\nnetworks, wireless communications, and peer-to-peer Internet applications\n(e.g., BitTorrent). The proposal has twofold benefits: (i) reducing the\ncomplexity of current market-based solutions by removing unnecessary and costly\nmediations and (ii) guaranteeing energy access to all virtual microgrid members\naccording to their individual needs. This article concludes that the proposed\nsolution generally complies with the existing regulations but has highly\ndisruptive potential to organize a dominantly electrified energy system in the\nmid- to long-term, being a technical counterpart to the recently developed\nsocial-oriented microgrid proposals.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 06:09:40 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 02:48:05 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Nardelli", "Pedro H. J.", ""], ["Hussein", "Hafiz Majid", ""], ["Narayanan", "Arun", ""], ["Yang", "Yongheng", ""]]}, {"id": "2102.00848", "submitter": "Sanja \\v{S}\\'cepanovi\\'c", "authors": "Sanja \\v{S}\\'cepanovi\\'c, Sagar Joglekar, Stephen Law, Daniele Quercia", "title": "Jane Jacobs in the Sky: Predicting Urban Vitality with Open Satellite\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY eess.IV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The presence of people in an urban area throughout the day -- often called\n'urban vitality' -- is one of the qualities world-class cities aspire to the\nmost, yet it is one of the hardest to achieve. Back in the 1970s, Jane Jacobs\ntheorized urban vitality and found that there are four conditions required for\nthe promotion of life in cities: diversity of land use, small block sizes, the\nmix of economic activities, and concentration of people. To build proxies for\nthose four conditions and ultimately test Jane Jacobs's theory at scale,\nresearchers have had to collect both private and public data from a variety of\nsources, and that took decades. Here we propose the use of one single source of\ndata, which happens to be publicly available: Sentinel-2 satellite imagery. In\nparticular, since the first two conditions (diversity of land use and small\nblock sizes) are visible to the naked eye from satellite imagery, we tested\nwhether we could automatically extract them with a state-of-the-art\ndeep-learning framework and whether, in the end, the extracted features could\npredict vitality. In six Italian cities for which we had call data records, we\nfound that our framework is able to explain on average 55% of the variance in\nurban vitality extracted from those records.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 21:46:29 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["\u0160\u0107epanovi\u0107", "Sanja", ""], ["Joglekar", "Sagar", ""], ["Law", "Stephen", ""], ["Quercia", "Daniele", ""]]}, {"id": "2102.00981", "submitter": "Bola Abimbola", "authors": "Bola Abimbola", "title": "Cloud Computing Concept and Roots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a particular implementation of distributed computing. It\ninherited many properties of distributed computing such as scalability,\nreliability and distribution transparency. The transparency middle layer\nabstracts the underlying platform away from the end user. Virtualization\ntechnology is the foundation of Cloud computing. Virtual machine provides\nabstraction of the physical server resources and securely isolates different\nusers in multi-tenant environment. To the Cloud services consumer, all the\ncomputing power and resources are accessed through high speed internet access\nby client platforms. This eliminates the cost to build and maintain local data\ncenter. Resource pooling and rapid elasticity are the main characters of Cloud\ncomputing. The scalability of Cloud computing comes from resources which can\nspan multiple data centers and geographic regions. There is virtually no\nlimitation on the amount of resources available from Cloud. New processing and\nstorage resources can be added into the Cloud resource pool seamlessly.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 17:42:46 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 19:03:48 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Abimbola", "Bola", ""]]}, {"id": "2102.01175", "submitter": "Junchuan Fan", "authors": "Junchuan Fan, Kathleen Stewart", "title": "Understanding collective human movement dynamics during large-scale\n  events using big geosocial data analytics", "comments": null, "journal-ref": "Computers, Environment and Urban Systems Volume 87, May 2021,\n  101605", "doi": "10.1016/j.compenvurbsys.2021.101605", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the rapid advancement of information and communication technologies,\nmany researchers have adopted alternative data sources from private data\nvendors to study human movement dynamics in response to large-scale natural or\nsocietal events. Big geosocial data such as georeferenced tweets are publicly\navailable and dynamically evolving as real-world events are happening, making\nit more likely to capture the real-time sentiments and responses of\npopulations. However, precisely-geolocated geosocial data is scarce and biased\ntoward urban population centers. In this research, we developed a big geosocial\ndata analytical framework for extracting human movement dynamics in response to\nlarge-scale events from publicly available georeferenced tweets. The framework\nincludes a two-stage data collection module that collects data in a more\ntargeted fashion in order to mitigate the data scarcity issue of georeferenced\ntweets; in addition, a variable bandwidth kernel density estimation(VB-KDE)\napproach was adopted to fuse georeference information at different spatial\nscales, further augmenting the signals of human movement dynamics contained in\ngeoreferenced tweets. To correct for the sampling bias of georeferenced tweets,\nwe adjusted the number of tweets for different spatial units (e.g., county,\nstate) by population. To demonstrate the performance of the proposed analytic\nframework, we chose an astronomical event that occurred nationwide across the\nUnited States, i.e., the 2017 Great American Eclipse, as an example event and\nstudied the human movement dynamics in response to this event. However, this\nanalytic framework can easily be applied to other types of large-scale events\nsuch as hurricanes or earthquakes.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 21:18:55 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Fan", "Junchuan", ""], ["Stewart", "Kathleen", ""]]}, {"id": "2102.01194", "submitter": "Hailin Sang", "authors": "G. Jogesh Babu, David Banks, Hyunsoon Cho, David Han, Hailin Sang and\n  Shouyi Wang", "title": "A Statistician Teaches Deep Learning", "comments": "19 pages, accepted by Journal of Statistical Theory and Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep learning (DL) has gained much attention and become increasingly popular\nin modern data science. Computer scientists led the way in developing deep\nlearning techniques, so the ideas and perspectives can seem alien to\nstatisticians. Nonetheless, it is important that statisticians become involved\n-- many of our students need this expertise for their careers. In this paper,\ndeveloped as part of a program on DL held at the Statistical and Applied\nMathematical Sciences Institute, we address this culture gap and provide tips\non how to teach deep learning to statistics graduate students. After some\nbackground, we list ways in which DL and statistical perspectives differ,\nprovide a recommended syllabus that evolved from teaching two iterations of a\nDL graduate course, offer examples of suggested homework assignments, give an\nannotated list of teaching resources, and discuss DL in the context of two\nresearch areas.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 04:59:43 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 23:09:23 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Babu", "G. Jogesh", ""], ["Banks", "David", ""], ["Cho", "Hyunsoon", ""], ["Han", "David", ""], ["Sang", "Hailin", ""], ["Wang", "Shouyi", ""]]}, {"id": "2102.01203", "submitter": "A. Feder Cooper", "authors": "A. Feder Cooper, Ellen Abrams", "title": "Emergent Unfairness in Algorithmic Fairness-Accuracy Trade-Off Research", "comments": "To appear in AIES 2021", "journal-ref": null, "doi": "10.1145/3461702.3462519", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Across machine learning (ML) sub-disciplines, researchers make explicit\nmathematical assumptions in order to facilitate proof-writing. We note that,\nspecifically in the area of fairness-accuracy trade-off optimization\nscholarship, similar attention is not paid to the normative assumptions that\nground this approach. Such assumptions presume that 1) accuracy and fairness\nare in inherent opposition to one another, 2) strict notions of mathematical\nequality can adequately model fairness, 3) it is possible to measure the\naccuracy and fairness of decisions independent from historical context, and 4)\ncollecting more data on marginalized individuals is a reasonable solution to\nmitigate the effects of the trade-off. We argue that such assumptions, which\nare often left implicit and unexamined, lead to inconsistent conclusions: While\nthe intended goal of this work may be to improve the fairness of machine\nlearning models, these unexamined, implicit assumptions can in fact result in\nemergent unfairness. We conclude by suggesting a concrete path forward toward a\npotential resolution.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 22:02:14 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 22:33:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Cooper", "A. Feder", ""], ["Abrams", "Ellen", ""]]}, {"id": "2102.01260", "submitter": "Xiong Liu", "authors": "Xiong Liu, Craig E. Thomas, Christian C. Felder", "title": "The impact of external innovation on new drug approvals: A retrospective\n  analysis", "comments": null, "journal-ref": "International Journal of Pharmaceutics, Volume 563, Pages 273-281,\n  2019", "doi": "10.1016/j.ijpharm.2018.12.093", "report-no": "PMID: 30664998", "categories": "cs.CL cs.CY q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pharmaceutical companies are relying more often on external sources of\ninnovation to boost their discovery research productivity. However, more\nin-depth knowledge about how external innovation may translate to successful\nproduct launches is still required in order to better understand how to best\nleverage the innovation ecosystem. We analyzed the pre-approval publication\nhistories for FDA-approved new molecular entities (NMEs) and new biologic\nentities (NBEs) launched by 13 top research pharma companies during the last\ndecade (2006-2016). We found that academic institutions contributed the\nmajority of pre-approval publications and that publication subject matter is\nclosely aligned with the strengths of the respective innovator. We found this\nto also be true for candidate drugs terminated in Phase 3, but the volume of\nliterature on these molecules is substantially less than for approved drugs.\nThis may suggest that approved drugs are often associated with a more robust\ndataset provided by a large number of institutes. Collectively, the results of\nour analysis support the hypothesis that a collaborative research innovation\nenvironment spanning across academia, industry and government is highly\nconducive to successful drug approvals.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 02:21:34 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Liu", "Xiong", ""], ["Thomas", "Craig E.", ""], ["Felder", "Christian C.", ""]]}, {"id": "2102.01265", "submitter": "Angelina Wang", "authors": "Alan Chan and Chinasa T. Okolo and Zachary Terner and Angelina Wang", "title": "The Limits of Global Inclusion in AI Development", "comments": "AAAI 2021 Workshop on Reframing Diversity in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Those best-positioned to profit from the proliferation of artificial\nintelligence (AI) systems are those with the most economic power. Extant global\ninequality has motivated Western institutions to involve more diverse groups in\nthe development and application of AI systems, including hiring foreign labour\nand establishing extra-national data centers and laboratories. However, given\nboth the propensity of wealth to abet its own accumulation and the lack of\ncontextual knowledge in top-down AI solutions, we argue that more focus should\nbe placed on the redistribution of power, rather than just on including\nunderrepresented groups. Unless more is done to ensure that opportunities to\nlead AI development are distributed justly, the future may hold only AI systems\nwhich are unsuited to their conditions of application, and exacerbate\ninequality.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 02:53:40 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chan", "Alan", ""], ["Okolo", "Chinasa T.", ""], ["Terner", "Zachary", ""], ["Wang", "Angelina", ""]]}, {"id": "2102.01270", "submitter": "Huanyi Chen", "authors": "Huanyi Chen, Paul A.S. Ward", "title": "Predicting student performance using data from an auto-grading system", "comments": null, "journal-ref": null, "doi": "10.5555/3370272.3370297", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As online auto-grading systems appear, information obtained from those\nsystems can potentially enable researchers to create predictive models to\npredict student behaviour and performances. In the University of Waterloo, the\nECE 150 (Fundamentals of Programming) Instructional Team wants to get an\ninsight into how to allocate the limited teaching resources better to achieve\nimproved educational outcomes. Currently, the Instructional Team allocates\ntutoring time in a reactive basis. They help students \"as-requested\". This\napproach serves those students with the wherewithal to request help; however,\nmany of the students who are struggling do not reach out for assistance.\nTherefore, we, as the Research Team, want to explore if we can determine\nstudents which need help by looking into the data from our auto-grading system,\nMarmoset.\n  In this paper, we conducted experiments building decision-tree and\nlinear-regression models with various features extracted from the Marmoset\nauto-grading system, including passing rate, testcase outcomes, number of\nsubmissions and submission time intervals (the time interval between the\nstudent's first reasonable submission and the deadline). For each feature, we\ninterpreted the result at the confusion matrix level. Specifically for\npoor-performance students, we show that the linear-regression model using\nsubmission time intervals performs the best among all models in terms of\nPrecision and F-Measure. We also show that for students who are misclassified\ninto poor-performance students, they have the lowest actual grades in the\nlinear-regression model among all models. In addition, we show that for the\nmidterm, the submission time interval of the last assignment before the midterm\npredicts the midterm performance the most. However, for the final exam, the\nmidterm performance contributes the most on the final exam performance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 03:02:39 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chen", "Huanyi", ""], ["Ward", "Paul A. S.", ""]]}, {"id": "2102.01456", "submitter": "Neo Chung-Kit Yiu", "authors": "Neo C.K. Yiu", "title": "Decentralizing Supply Chain Anti-Counterfeiting Systems Using Blockchain\n  Technology", "comments": "21 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.13309.69609", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interesting research problem in supply chain industry is evaluating and\ndetermining provenance of physical goods - demonstrating authenticity of luxury\ngoods. Yet, there have been a few innovative software solutions addressing\nproduct anti-counterfeiting and record provenance of today's goods that are\nproduced and transported in complex and internationally-spanning supply chain\nnetworks. However, these supply chain systems have been implemented with\ncentralized system architecture, relying on centralized authorities or any form\nof intermediaries, and leading to issues such as single-point processing,\nstorage and failure, which could be susceptible to malicious modifications of\nproduct records or various potential attacks to system components by dishonest\nparticipant nodes traversing along the supply chain. Blockchain technology has\nevolved from being merely a decentralized, distributed and immutable ledger of\ncryptocurrency transactions to a programmable interactive environment for\nbuilding decentralized and reliable applications addressing different use cases\nand existing problems in the world. In this research, the Decentralized\nNFC-Enabled Anti-Counterfeiting System (dNAS) is proposed and developed,\ndecentralizing a legacy anti-counterfeiting system of supply chain industry\nusing Blockchain technology, to facilitate trustworthy data provenance\nretrieval, verification and management, as well as strengthening capability of\nproduct anti-counterfeiting in supply chain industry. The proposed dNAS\nutilizes decentralized blockchain network on a consensus protocol compatible\nwith the concept of enterprise consortium, programmable smart contracts and a\ndistributed file storage system to develop a secure and immutable scientific\ndata provenance tracking and management platform on which provenance records,\nproviding compelling properties on data integrity, are validated automatically.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 12:17:10 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Yiu", "Neo C. K.", ""]]}, {"id": "2102.01648", "submitter": "Roman Jurowetzki", "authors": "Roman Jurowetzki, Daniel Hain, Juan Mateos-Garcia, Konstantinos\n  Stathoulopoulos", "title": "The Privatization of AI Research(-ers): Causes and Potential\n  Consequences -- From university-industry interaction to public research\n  brain-drain?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The private sector is playing an increasingly important role in basic\nArtificial Intelligence (AI) R&D. This phenomenon, which is reflected in the\nperception of a brain drain of researchers from academia to industry, is\nraising concerns about a privatisation of AI research which could constrain its\nsocietal benefits. We contribute to the evidence base by quantifying transition\nflows between industry and academia and studying its drivers and potential\nconsequences. We find a growing net flow of researchers from academia to\nindustry, particularly from elite institutions into technology companies such\nas Google, Microsoft and Facebook. Our survival regression analysis reveals\nthat researchers working in the field of deep learning as well as those with\nhigher average impact are more likely to transition into industry. A\ndifference-in-differences analysis of the effect of switching into industry on\na researcher's influence proxied by citations indicates that an initial\nincrease in impact declines as researchers spend more time in industry. This\npoints at a privatisation of AI knowledge compared to a counterfactual where\nthose high-impact researchers had remained in academia. Our findings highlight\nthe importance of strengthening the public AI research sphere in order to\nensure that the future of this powerful technology is not dominated by private\ninterests.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:02:41 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 21:30:23 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Jurowetzki", "Roman", ""], ["Hain", "Daniel", ""], ["Mateos-Garcia", "Juan", ""], ["Stathoulopoulos", "Konstantinos", ""]]}, {"id": "2102.01711", "submitter": "Dr Cesar Salas-Guerra", "authors": "Dr. Cesar R Salas-Guerra", "title": "Skills-based on technological knowledge in the digital economy activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This research seeks to measure the impact of people with technological\nknowledge on regional digital economic activity and the implications of\nprosperous cities' contagion effect on neighbouring ones. The focus of this\nstudy is quantitative, cross-sectional, and its design is correlational-causal.\nThis study covers seven micro-regions of Minas Gerais in Brazil, organized in\n89 municipalities, with 69% urban population and 31% rural. The data used\nconsisted of 4,361 observations obtained in the Brazilian government's public\nrepositories, organized into panel data, and analysed using partial least\nsquares, micro-regional spatial regression, and identification patterns with\nmachine learning. The confirmatory analysis of the regression test establishes\na significant impact between the CE's technological knowledge and the digital\neconomic activity AED through a predictive value of R2 = .749, \\b{eta} = .867,\np = .000 (value t = 18,298). With high notoriety among the variables, public\nand private university institutions (IUPP), professors with doctorates and\nmasters (DCNT), and information technology occupations (CBO). A geographic\nconcentration of companies that demand technology-based skills had effects by\nslowing down the development of small municipalities, suggesting the\ndevelopment of new government technology initiatives that support new business\nmodels based on technological knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 19:03:53 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Salas-Guerra", "Dr. Cesar R", ""]]}, {"id": "2102.01811", "submitter": "Yuval Shahar", "authors": "Yuval Shahar", "title": "The Ethical Implications of Shared Medical Decision Making without\n  Providing Adequate Computational Support to the Care Provider and to the\n  Patient", "comments": "10 pages; no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is a clear need to involve patients in medical decisions. However,\ncognitive psychological research has highlighted the cognitive limitations of\nhumans with respect to 1. Probabilistic assessment of the patient state and of\npotential outcomes of various decisions, 2. Elicitation of the patient utility\nfunction, and 3. Integration of the probabilistic knowledge and of patient\npreferences to determine the optimal strategy. Therefore, without adequate\ncomputational support, current shared decision models have severe ethical\ndeficiencies. An informed consent model unfairly transfers the responsibility\nto a patient who does not have the necessary knowledge, nor the integration\ncapability. A paternalistic model endows with exaggerated power a physician who\nmight not be aware of the patient preferences, is prone to multiple cognitive\nbiases, and whose computational integration capability is bounded. Recent\nprogress in Artificial Intelligence suggests adding a third agent: a computer,\nin all deliberative medical decisions: Non emergency medical decisions in which\nmore than one alternative exists, the patient preferences can be elicited, the\ntherapeutic alternatives might be influenced by these preferences, medical\nknowledge exists regarding the likelihood of the decision outcomes, and there\nis sufficient decision time. Ethical physicians should exploit computational\ndecision support technologies, neither making the decisions solely on their\nown, nor shirking their duty and shifting the responsibility to patients in the\nname of informed consent. The resulting three way (patient, care provider,\ncomputer) human machine model that we suggest emphasizes the patient\npreferences, the physician knowledge, and the computational integration of both\naspects, does not diminish the physician role, but rather brings out the best\nin human and machine.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 00:30:21 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Shahar", "Yuval", ""]]}, {"id": "2102.01979", "submitter": "Viraj Kulkarni", "authors": "Viraj Kulkarni, Manish Gawali, Amit Kharat", "title": "Key Technology Considerations in Developing and Deploying Machine\n  Learning Models in Clinical Radiology Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of machine learning to develop intelligent software tools for\ninterpretation of radiology images has gained widespread attention in recent\nyears. The development, deployment, and eventual adoption of these models in\nclinical practice, however, remains fraught with challenges. In this paper, we\npropose a list of key considerations that machine learning researchers must\nrecognize and address to make their models accurate, robust, and usable in\npractice. Namely, we discuss: insufficient training data, decentralized\ndatasets, high cost of annotations, ambiguous ground truth, imbalance in class\nrepresentation, asymmetric misclassification costs, relevant performance\nmetrics, generalization of models to unseen datasets, model decay, adversarial\nattacks, explainability, fairness and bias, and clinical validation. We\ndescribe each consideration and identify techniques to address it. Although\nthese techniques have been discussed in prior research literature, by freshly\nexamining them in the context of medical imaging and compiling them in the form\nof a laundry list, we hope to make them more accessible to researchers,\nsoftware developers, radiologists, and other stakeholders.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:53:43 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Kulkarni", "Viraj", ""], ["Gawali", "Manish", ""], ["Kharat", "Amit", ""]]}, {"id": "2102.02132", "submitter": "Alarith Uhde", "authors": "Alarith Uhde and Matthias Laschke and Marc Hassenzahl", "title": "Design and Appropriation of Computer-supported Self-scheduling Practices\n  in Healthcare Shift Work", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": "10.1145/3449219", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shift scheduling impacts healthcare workers' well-being because it sets the\nframe for their social life and recreational activities. Since it is complex\nand time-consuming, it has become a target for automation. However, existing\nsystems mostly focus on improving efficiency. The workers' needs and their\nactive participation do not play a pronounced role. Contrasting this trend, we\ndesigned a social practice-based, worker-centered, and well-being-oriented\nself-scheduling system which gives healthcare workers more control during shift\nplanning. In a following nine month appropriation study, we found that workers\nwho were cautious about their social standing in the group or who had a more\nspontaneous personal lifestyle used our system less often than others.\nMoreover, we revealed several conflict prevention practices and suggest to\nshift the focus away from a competitive shift distribution paradigm towards\nsupporting these pro-social practices. We conclude with guidelines to support\nindividual planning practices, self-leadership, and for dealing with conflicts.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 16:18:56 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 17:19:22 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Uhde", "Alarith", ""], ["Laschke", "Matthias", ""], ["Hassenzahl", "Marc", ""]]}, {"id": "2102.02137", "submitter": "Daniele Regoli", "authors": "Alessandro Castelnovo, Riccardo Crupi, Giulia Del Gamba, Greta Greco,\n  Aisha Naseer, Daniele Regoli, Beatriz San Miguel Gonzalez", "title": "BeFair: Addressing Fairness in the Banking Sector", "comments": "6 pages, 3 figures", "journal-ref": "2020 IEEE International Conference on Big Data (Big Data)", "doi": "10.1109/BigData50022.2020.9377894", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Algorithmic bias mitigation has been one of the most difficult conundrums for\nthe data science community and Machine Learning (ML) experts. Over several\nyears, there have appeared enormous efforts in the field of fairness in ML.\nDespite the progress toward identifying biases and designing fair algorithms,\ntranslating them into the industry remains a major challenge. In this paper, we\npresent the initial results of an industrial open innovation project in the\nbanking sector: we propose a general roadmap for fairness in ML and the\nimplementation of a toolkit called BeFair that helps to identify and mitigate\nbias. Results show that training a model without explicit constraints may lead\nto bias exacerbation in the predictions.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 16:37:10 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 10:03:13 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Castelnovo", "Alessandro", ""], ["Crupi", "Riccardo", ""], ["Del Gamba", "Giulia", ""], ["Greco", "Greta", ""], ["Naseer", "Aisha", ""], ["Regoli", "Daniele", ""], ["Gonzalez", "Beatriz San Miguel", ""]]}, {"id": "2102.02279", "submitter": "Kush Varshney", "authors": "Yu Tao and Kush R. Varshney", "title": "Insiders and Outsiders in Research on Machine Learning and Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A subset of machine learning research intersects with societal issues,\nincluding fairness, accountability and transparency, as well as the use of\nmachine learning for social good. In this work, we analyze the scholars\ncontributing to this research at the intersection of machine learning and\nsociety through the lens of the sociology of science. By analyzing the\nauthorship of all machine learning papers posted to arXiv, we show that\ncompared to researchers from overrepresented backgrounds (defined by gender and\nrace/ethnicity), researchers from underrepresented backgrounds are more likely\nto conduct research at this intersection than other kinds of machine learning\nresearch. This state of affairs leads to contention between two perspectives on\ninsiders and outsiders in the scientific enterprise: outsiders being those\noutside the group being studied, and outsiders being those who have not\nparticipated as researchers in an area historically. This contention manifests\nas an epistemic question on the validity of knowledge derived from lived\nexperience in machine learning research, and predicts boundary work that we see\nin a real-world example.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 20:19:51 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Tao", "Yu", ""], ["Varshney", "Kush R.", ""]]}, {"id": "2102.02320", "submitter": "Zaid Khan", "authors": "Zaid Khan and Yun Fu", "title": "One Label, One Billion Faces: Usage and Consistency of Racial Categories\n  in Computer Vision", "comments": "Published as a conference paper at the 4th ACM Conference on\n  Fairness, Accountability, and Transparency (FAccT 2021)", "journal-ref": null, "doi": "10.1145/3442188.3445920", "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision is widely deployed, has highly visible, society altering\napplications, and documented problems with bias and representation. Datasets\nare critical for benchmarking progress in fair computer vision, and often\nemploy broad racial categories as population groups for measuring group\nfairness. Similarly, diversity is often measured in computer vision datasets by\nascribing and counting categorical race labels. However, racial categories are\nill-defined, unstable temporally and geographically, and have a problematic\nhistory of scientific use. Although the racial categories used across datasets\nare superficially similar, the complexity of human race perception suggests the\nracial system encoded by one dataset may be substantially inconsistent with\nanother. Using the insight that a classifier can learn the racial system\nencoded by a dataset, we conduct an empirical study of computer vision datasets\nsupplying categorical race labels for face images to determine the\ncross-dataset consistency and generalization of racial categories. We find that\neach dataset encodes a substantially unique racial system, despite nominally\nequivalent racial categories, and some racial categories are systemically less\nconsistent than others across datasets. We find evidence that racial categories\nencode stereotypes, and exclude ethnic groups from categories on the basis of\nnonconformity to stereotypes. Representing a billion humans under one racial\ncategory may obscure disparities and create new ones by encoding stereotypes of\nracial systems. The difficulty of adequately converting the abstract concept of\nrace into a tool for measuring fairness underscores the need for a method more\nflexible and culturally aware than racial categories.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 22:50:04 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Khan", "Zaid", ""], ["Fu", "Yun", ""]]}, {"id": "2102.02601", "submitter": "Neo Chung-Kit Yiu", "authors": "Neo C.K. Yiu", "title": "An Empirical Analysis of Implementing Enterprise Blockchain Protocols in\n  Supply Chain Anti-Counterfeiting and Traceability", "comments": "18 pages", "journal-ref": null, "doi": "10.13140/RG.2.2.20322.04805", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of innovative software solutions, addressing product\nanti-counterfeiting and record provenance of the wider supply chain industry,\nhave been implemented. However, these solutions have been developed with\ncentralized system architecture which could be susceptible to malicious\nmodifications on states of product records and various potential security\nattacks leading to system failure and downtime. Blockchain technology has been\nenabling decentralized trust with a network of distributed peer nodes to\nmaintain consistent shared states via a decentralized consensus reached, with\nwhich an idea of developing decentralized and reliable solutions has been\nbasing on. A Decentralized NFC-Enabled Anti-Counterfeiting System (dNAS) was\ntherefore proposed and developed, decentralizing a legacy anti-counterfeiting\nsystem of supply chain industry utilizing enterprise blockchain protocols and\nenterprise consortium, to facilitate trustworthy data provenance retrieval,\nverification and management, as well as strengthening capability of product\nanti-counterfeiting and traceability in supply chain industry. The adoption of\nenterprise blockchain protocols and implementations has been surging in supply\nchain industry given its advantages in scalability, governance and\ncompatibility with existing supply chain systems and networks, but development\nand adoption of decentralized solutions could also impose additional\nimplications to supply chain integrity, in terms of security, privacy and\nconfidentiality. In this research, an empirical analysis performed against\ndecentralized solutions, including dNAS, summarizes the effectiveness,\nlimitations and future opportunities of developing decentralized solutions\nbuilt around existing enterprise blockchain protocols and implementations for\nsupply chain anti-counterfeiting and traceability.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 13:31:33 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Yiu", "Neo C. K.", ""]]}, {"id": "2102.02625", "submitter": "Robin Bloomfield", "authors": "Robin Bloomfield, Gareth Fletcher, Heidy Khlaaf, Luke Hinde, Philippa\n  Ryan", "title": "Safety Case Templates for Autonomous Systems", "comments": "136 pages, 57 figures", "journal-ref": null, "doi": null, "report-no": "Adelard D/1294/87004/1", "categories": "cs.SE cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report documents safety assurance argument templates to support the\ndeployment and operation of autonomous systems that include machine learning\n(ML) components. The document presents example safety argument templates\ncovering: the development of safety requirements, hazard analysis, a safety\nmonitor architecture for an autonomous system including at least one ML\nelement, a component with ML and the adaptation and change of the system over\ntime. The report also presents generic templates for argument defeaters and\nevidence confidence that can be used to strengthen, review, and adapt the\ntemplates as necessary. This report is made available to get feedback on the\napproach and on the templates. This work was sponsored by the UK Dstl under the\nR-cloud framework.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 15:49:37 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 12:50:15 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Bloomfield", "Robin", ""], ["Fletcher", "Gareth", ""], ["Khlaaf", "Heidy", ""], ["Hinde", "Luke", ""], ["Ryan", "Philippa", ""]]}, {"id": "2102.02729", "submitter": "Dongrui Wu", "authors": "Dongrui Wu, Weili Fang, Yi Zhang, Liuqing Yang, Xiaodong Xu, Hanbin\n  Luo and Xiang Yu", "title": "Adversarial Attacks and Defenses in Physiological Computing: A\n  Systematic Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physiological computing uses human physiological data as system inputs in\nreal time. It includes, or significantly overlaps with, brain-computer\ninterfaces, affective computing, adaptive automation, health informatics, and\nphysiological signal based biometrics. Physiological computing increases the\ncommunication bandwidth from the user to the computer, but is also subject to\nvarious types of adversarial attacks, in which the attacker deliberately\nmanipulates the training and/or test examples to hijack the machine learning\nalgorithm output, leading to possibly user confusion, frustration, injury, or\neven death. However, the vulnerability of physiological computing systems has\nnot been paid enough attention to, and there does not exist a comprehensive\nreview on adversarial attacks to it. This paper fills this gap, by providing a\nsystematic review on the main research areas of physiological computing,\ndifferent types of adversarial attacks and their applications to physiological\ncomputing, and the corresponding defense strategies. We hope this review will\nattract more research interests on the vulnerability of physiological computing\nsystems, and more importantly, defense strategies to make them more secure.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 16:40:12 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 22:24:25 GMT"}, {"version": "v3", "created": "Thu, 11 Feb 2021 17:15:30 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Wu", "Dongrui", ""], ["Fang", "Weili", ""], ["Zhang", "Yi", ""], ["Yang", "Liuqing", ""], ["Xu", "Xiaodong", ""], ["Luo", "Hanbin", ""], ["Yu", "Xiang", ""]]}, {"id": "2102.02878", "submitter": "Dimitris Floros Mr", "authors": "Dimitris Floros (1), Mulugu V. Brahmajothi (2), Alexandros-Stavros\n  Iliopoulos (3), Nikos Pitsianis (1 and 4), Xiaobai Sun (4) ((1) Aristotle\n  University of Thessaloniki, (2) Duke University Medical Center, (3)\n  Massachusetts Institute of Technology, (4) Duke University)", "title": "Challenges in biomarker discovery and biorepository for Gulf-war-disease\n  studies: a novel data platform solution", "comments": "Authorship disagreement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aims: Our Gulf War Illness (GWI) study conducts combinatorial screening of\nmany interactive neural and humoral biomarkers in order to establish\npredictive, diagnostic, and therapeutic targets. We encounter obstacles at\nevery stage of the biomarker discovery process, from sample acquisition,\nbio-marker extraction to multi-aspect, multi-way interaction analysis, due to\nthe study complexity and lack of support for complex data problem solutions. We\nintroduce a novel data platform, named ROSALIND, to overcome the challenges,\nfoster healthy and vital collaborations and advance scientific inquiries.\n  Main methods: ROSALIND is a researcher-centered, study-specific data\nplatform. It provides vital support of individual creativity and effort in\ncollaborative research. We follow the principles etched in the platform name -\nROSALIND stands for resource organisms with self-governed accessibility,\nlinkability, integrability, neutrality, and dependability. We translate, encode\nand implement the principles in the platform with novel use of advanced\nconcepts and techniques to ensure and protect data integrity and research\nintegrity. From a researcher's vantage point, ROSALIND embodies nuance\nutilities and advanced functionalities in one system, beyond conventional\nstorage, archive and data management.\n  Key findings: The deployment of ROSALIND in our GWI study in recent 12 months\nhas accelerated the pace of data experiment and analysis, removed numerous\nerror sources, and increased research quality and productivity.\n  Significance: ROSALIND seems the first to address data integrity and research\nintegrity in tandem with digital measures and means. It also promises a new\ntype of distributed research networks with individualized data platforms\nconnected in various self-organized collaboration configurations.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:38:30 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 17:43:43 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2021 22:58:58 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Floros", "Dimitris", "", "1 and 4"], ["Brahmajothi", "Mulugu V.", "", "1 and 4"], ["Iliopoulos", "Alexandros-Stavros", "", "1 and 4"], ["Pitsianis", "Nikos", "", "1 and 4"], ["Sun", "Xiaobai", ""]]}, {"id": "2102.02928", "submitter": "Nirav Ajmeri", "authors": "Veljko Dubljevi\\'c (1), George F. List (1), Jovan Milojevich (2),\n  Nirav Ajmeri (3), William Bauer (1), Munindar P. Singh (1), Eleni Bardaka\n  (1), Thomas Birkland (1), Charles Edwards (4), Roger Mayer (1), Ioan Muntean\n  (5), Thomas Powers (6), Hesham Rakha (7), Vance Ricks (8), M. Shoaib Samandar\n  (1) ((1) North Carolina State University, (2) Oklahoma State University, (3)\n  University of Bristol, (4) University of North Carolina at Chapel Hill, (5)\n  University of North Carolina at Asheville, (6) University of Delaware, (7)\n  Virginia Tech, (8) Guilford College)", "title": "Toward a Rational and Ethical Sociotechnical System of Autonomous\n  Vehicles: A Novel Application of Multi-Criteria Decision Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expansion of artificial intelligence (AI) and autonomous systems has\nshown the potential to generate enormous social good while also raising serious\nethical and safety concerns. AI technology is increasingly adopted in\ntransportation. A survey of various in-vehicle technologies found that\napproximately 64% of the respondents used a smartphone application to assist\nwith their travel. The top-used applications were navigation and real-time\ntraffic information systems. Among those who used smartphones during their\ncommutes, the top-used applications were navigation and entertainment. There is\na pressing need to address relevant social concerns to allow for the\ndevelopment of systems of intelligent agents that are informed and cognizant of\nethical standards. Doing so will facilitate the responsible integration of\nthese systems in society. To this end, we have applied Multi-Criteria Decision\nAnalysis (MCDA) to develop a formal Multi-Attribute Impact Assessment (MAIA)\nquestionnaire for examining the social and ethical issues associated with the\nuptake of AI. We have focused on the domain of autonomous vehicles (AVs)\nbecause of their imminent expansion. However, AVs could serve as a stand-in for\nany domain where intelligent, autonomous agents interact with humans, either on\nan individual level (e.g., pedestrians, passengers) or a societal level.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 23:52:31 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Dubljevi\u0107", "Veljko", ""], ["List", "George F.", ""], ["Milojevich", "Jovan", ""], ["Ajmeri", "Nirav", ""], ["Bauer", "William", ""], ["Singh", "Munindar P.", ""], ["Bardaka", "Eleni", ""], ["Birkland", "Thomas", ""], ["Edwards", "Charles", ""], ["Mayer", "Roger", ""], ["Muntean", "Ioan", ""], ["Powers", "Thomas", ""], ["Rakha", "Hesham", ""], ["Ricks", "Vance", ""], ["Samandar", "M. Shoaib", ""]]}, {"id": "2102.03054", "submitter": "Sahil Verma", "authors": "Sahil Verma, Michael Ernst, Rene Just", "title": "Removing biased data to improve fairness and accuracy", "comments": "16 pages, 5 Figures, 8 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning systems are often trained using data collected from\nhistorical decisions. If past decisions were biased, then automated systems\nthat learn from historical data will also be biased. We propose a black-box\napproach to identify and remove biased training data. Machine learning models\ntrained on such debiased data (a subset of the original training data) have low\nindividual discrimination, often 0%. These models also have greater accuracy\nand lower statistical disparity than models trained on the full historical\ndata. We evaluated our methodology in experiments using 6 real-world datasets.\nOur approach outperformed seven previous approaches in terms of individual\ndiscrimination and accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:34:45 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Verma", "Sahil", ""], ["Ernst", "Michael", ""], ["Just", "Rene", ""]]}, {"id": "2102.03226", "submitter": "Boris D\\\"udder", "authors": "Boris D\\\"udder and Haiqin Wu and Michael Henke and Natalia Straub and\n  Tan G\\\"urpinar and Philipp Asterios Ioannidis and Vladislav Fomin and\n  Raimundas Matulevi\\v{c}ius and Mubashar Iqbal", "title": "BlockNet Report: Curriculum Guidance Document", "comments": "BlockChain Network Online Education for interdisciplinary European\n  Competence Transfer (BlockNet), funded by Erasmus+ KA2 program. Project No:\n  2018-1-LT01-KA203-047044, pages 49", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a challenging topic since it is novel and fosters potential\ninnovation. The blockchain is attractive for various disciplines, and, because\nof its cross-cutting nature, needs knowledge stemming from various disciplines.\nThe devised curriculum can be instantiated specifically to meet the needs of\nstudents' groups from various disciplines. The pedagogical innovation of the\nproject is the inclusion of interdisciplinary project groups with participant's\ninteraction via online platforms for project-based learning activities. MOOCs\nand SNOCs allow blended-learning for interdisciplinary and geographically\ndistributed student groups.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 15:17:32 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["D\u00fcdder", "Boris", ""], ["Wu", "Haiqin", ""], ["Henke", "Michael", ""], ["Straub", "Natalia", ""], ["G\u00fcrpinar", "Tan", ""], ["Ioannidis", "Philipp Asterios", ""], ["Fomin", "Vladislav", ""], ["Matulevi\u010dius", "Raimundas", ""], ["Iqbal", "Mubashar", ""]]}, {"id": "2102.03561", "submitter": "Edward Oughton", "authors": "Edward Oughton", "title": "Policy options for digital infrastructure strategies: A simulation model\n  for broadband universal service in Africa", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Internet access is essential for economic development and helping to deliver\nthe Sustainable Development Goals, especially as even basic broadband can\nrevolutionize available economic opportunities. Yet, more than one billion\npeople still live without internet access. Governments must make strategic\nchoices to connect these citizens, but currently have few independent,\ntransparent and scientifically reproducible assessments to rely on. This paper\ndevelops open-source software to test broadband universal service strategies\nwhich meet the 10 Mbps target being considered by the UN Broadband Commission.\nThe private and government costs of different infrastructure decisions are\nquantified in six East and West African countries (C\\^ote D`Ivoire, Mali,\nSenegal, Kenya, Tanzania and Uganda). The results provide strong evidence that\n`leapfrogging` straight to 4G in unconnected areas is the least-cost option for\nproviding broadband universal service, with savings between 13-51% over 3G. The\nresults also demonstrate how the extraction of spectrum and tax revenues in\nunviable markets provide no net benefit, as for every $1 taken in revenue, a $1\ninfrastructure subsidy is required from government to achieve broadband\nuniversal service. Importantly, the use of a Shared Rural Network in unviable\nlocations provides impressive cost savings (up to 78%), while retaining the\nbenefits of dynamic infrastructure competition in viable urban and suburban\nareas. This paper provides evidence to design national and international\npolicies aimed at broadband universal service.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 11:09:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Oughton", "Edward", ""]]}, {"id": "2102.03569", "submitter": "Wanyue Xu", "authors": "Zuobai Zhang, Wanyue Xu, Zhongzhi Zhang and Guanrong Chen", "title": "Opinion Dynamics Incorporating Higher-Order Interactions", "comments": "submitted to IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issue of opinion sharing and formation has received considerable\nattention in the academic literature, and a few models have been proposed to\nstudy this problem. However, existing models are limited to the interactions\namong nearest neighbors, ignoring those second, third, and higher-order\nneighbors, despite the fact that higher-order interactions occur frequently in\nreal social networks. In this paper, we develop a new model for opinion\ndynamics by incorporating long-range interactions based on higher-order random\nwalks. We prove that the model converges to a fixed opinion vector, which may\ndiffer greatly from those models without higher-order interactions. Since\ndirect computation of the equilibrium opinion is computationally expensive,\nwhich involves the operations of huge-scale matrix multiplication and\ninversion, we design a theoretically convergence-guaranteed estimation\nalgorithm that approximates the equilibrium opinion vector nearly linearly in\nboth space and time with respect to the number of edges in the graph. We\nconduct extensive experiments on various social networks, demonstrating that\nthe new algorithm is both highly efficient and effective.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 11:42:48 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 02:49:41 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zhang", "Zuobai", ""], ["Xu", "Wanyue", ""], ["Zhang", "Zhongzhi", ""], ["Chen", "Guanrong", ""]]}, {"id": "2102.03656", "submitter": "Vibhor Agarwal", "authors": "Vibhor Agarwal, Yash Vekaria, Pushkal Agarwal, Sangeeta Mahapatra,\n  Shounak Set, Sakthi Balan Muthiah, Nishanth Sastry, Nicolas Kourtellis", "title": "Under the Spotlight: Web Tracking in Indian Partisan News Websites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  India is experiencing intense political partisanship and sectarian divisions.\nThe paper performs, to the best of our knowledge, the first comprehensive\nanalysis on the Indian online news media with respect to tracking and\npartisanship. We build a dataset of 103 online, mostly mainstream news\nwebsites. With the help of two experts, alongside data from the Media Ownership\nMonitor of the Reporters without Borders, we label these websites according to\ntheir partisanship (Left, Right, or Centre). We study and compare user tracking\non these sites with different metrics: numbers of cookies, cookie\nsynchronizations, device fingerprinting, and invisible pixel-based tracking. We\nfind that Left and Centre websites serve more cookies than Right-leaning\nwebsites. However, through cookie synchronization, more user IDs are\nsynchronized in Left websites than Right or Centre. Canvas fingerprinting is\nused similarly by Left and Right, and less by Centre. Invisible pixel-based\ntracking is 50% more intense in Centre-leaning websites than Right, and 25%\nmore than Left. Desktop versions of news websites deliver more cookies than\ntheir mobile counterparts. A handful of third-parties are tracking users in\nmost websites in this study. This paper, by demonstrating intense web tracking,\nhas implications for research on overall privacy of users visiting partisan\nnews websites in India.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 19:57:08 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 07:36:07 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Agarwal", "Vibhor", ""], ["Vekaria", "Yash", ""], ["Agarwal", "Pushkal", ""], ["Mahapatra", "Sangeeta", ""], ["Set", "Shounak", ""], ["Muthiah", "Sakthi Balan", ""], ["Sastry", "Nishanth", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2102.03679", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "A Review of Product Safety Regulations in the European Union", "comments": "Revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product safety has been a concern in Europe ever since the early 1960s.\nDespite the long and relatively stable historical lineage of product safety\nregulations, new technologies, changes in the world economy, and other major\ntransformations have in recent years brought product safety again to the\nforefront of policy debates. As reforms are also underway, there is a\nmotivation to review the complex safety policy framework in the European Union\n(EU). Thus, building on deliberative policy analysis and interpretative\nliterature review, this paper reviews the safety policy for non-food consumer\nproducts in the EU. The review covers the historical background and the main\nlaws, administration and enforcement, standardization and harmonization, laws\nenacted for specific products, notifications delivered by national safety\nauthorities, recalls of dangerous products, and the liability of these. Based\non the review and analysis of these themes and the associated literature, some\ncurrent policy challenges are further discussed.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 23:04:17 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 07:40:07 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "2102.03717", "submitter": "Muhammad Aurangzeb Ahmad", "authors": "Ming Yuan, Vikas Kumar, Muhammad Aurangzeb Ahmad, Ankur Teredesai", "title": "Assessing Fairness in Classification Parity of Machine Learning Models\n  in Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness in AI and machine learning systems has become a fundamental problem\nin the accountability of AI systems. While the need for accountability of AI\nmodels is near ubiquitous, healthcare in particular is a challenging field\nwhere accountability of such systems takes upon additional importance, as\ndecisions in healthcare can have life altering consequences. In this paper we\npresent preliminary results on fairness in the context of classification parity\nin healthcare. We also present some exploratory methods to improve fairness and\nchoosing appropriate classification algorithms in the context of healthcare.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 04:46:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Yuan", "Ming", ""], ["Kumar", "Vikas", ""], ["Ahmad", "Muhammad Aurangzeb", ""], ["Teredesai", "Ankur", ""]]}, {"id": "2102.03964", "submitter": "Tai Liu", "authors": "Tai Liu, Zain Tariq, Barath Raghavan, Jay Chen", "title": "Migration in the Stencil Pluralist Cloud Architecture", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A debate in the research community has buzzed in the background for years:\nshould large-scale Internet services be centralized or decentralized?\nNow-common centralized cloud and web services have downsides -- user lock-in\nand loss of privacy and data control -- that are increasingly apparent.\nHowever, their decentralized counterparts have struggled to gain adoption,\nsuffer from their own problems of scalability and trust, and eventually may\nresult in the exact same lock-in they intended to prevent. In this paper, we\nexplore the design of a pluralist cloud architecture, Stencil, one that can\nserve as a narrow waist for user-facing services such as social media. We aim\nto enable pluralism via a unifying set of abstractions that support migration\nfrom one service to a competing service. We find that migrating linked data\nintroduces many challenges in both source and destination services as links are\nsevered. We show how Stencil enables correct and efficient data migration\nbetween services, how it supports the deployment of new services, and how\nStencil could be incrementally deployed.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 02:15:14 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Liu", "Tai", ""], ["Tariq", "Zain", ""], ["Raghavan", "Barath", ""], ["Chen", "Jay", ""]]}, {"id": "2102.03977", "submitter": "Sainyam Galhotra", "authors": "Sainyam Galhotra, Sandhya Saisubramanian and Shlomo Zilberstein", "title": "Learning to Generate Fair Clusters from Demonstrations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fair clustering is the process of grouping similar entities together, while\nsatisfying a mathematically well-defined fairness metric as a constraint. Due\nto the practical challenges in precise model specification, the prescribed\nfairness constraints are often incomplete and act as proxies to the intended\nfairness requirement, leading to biased outcomes when the system is deployed.\nWe examine how to identify the intended fairness constraint for a problem based\non limited demonstrations from an expert. Each demonstration is a clustering\nover a subset of the data.\n  We present an algorithm to identify the fairness metric from demonstrations\nand generate clusters using existing off-the-shelf clustering techniques, and\nanalyze its theoretical properties. To extend our approach to novel fairness\nmetrics for which clustering algorithms do not currently exist, we present a\ngreedy method for clustering. Additionally, we investigate how to generate\ninterpretable solutions using our approach. Empirical evaluation on three\nreal-world datasets demonstrates the effectiveness of our approach in quickly\nidentifying the underlying fairness and interpretability constraints, which are\nthen used to generate fair and interpretable clusters.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 03:09:33 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Saisubramanian", "Sandhya", ""], ["Zilberstein", "Shlomo", ""]]}, {"id": "2102.04031", "submitter": "Dibyendu Mishra", "authors": "Dibyendu Mishra, Syeda Zainab Akbar, Arshia Arya, Saloni Dash, Rynaa\n  Grover, Joyojeet Pal", "title": "Rihanna versus Bollywood: Twitter Influencers and the Indian Farmers'\n  Protest", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A tweet from popular entertainer and businesswoman, Rihanna, bringing\nattention to farmers' protests around Delhi set off heightened activity on\nIndian social media. An immediate consequence was the weighing in by Indian\npoliticians, entertainers, media and other influencers on the issue. In this\npaper, we use data from Twitter and an archive of debunked misinformation\nstories to understand some of the patterns around influencer engagement with a\npolitical issue. We found that more followed influencers were less likely to\ncome out in support of the tweet. We also find that the later engagement of\nmajor influencers on the side of the government's position shows suggestion's\nof collusion. Irrespective of their position on the issue, influencers who\nengaged saw a significant rise in their following after their tweets. While a\nnumber of tweets thanked Rihanna for raising awareness on the issue, she was\nsystematically trolled on the grounds of her gender, race, nationality and\nreligion. Finally, we observed how misinformation existing prior to the tweet\nset up the grounds for alternative narratives that emerged.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 07:08:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Mishra", "Dibyendu", ""], ["Akbar", "Syeda Zainab", ""], ["Arya", "Arshia", ""], ["Dash", "Saloni", ""], ["Grover", "Rynaa", ""], ["Pal", "Joyojeet", ""]]}, {"id": "2102.04119", "submitter": "Georg Ahnert", "authors": "Georg Ahnert, Ivan Smirnov, Florian Lemmerich, Claudia Wagner, Markus\n  Strohmaier", "title": "The FairCeptron: A Framework for Measuring Human Perceptions of\n  Algorithmic Fairness", "comments": "For source code of the implementation, see\n  https://github.com/cssh-rwth/fairceptron", "journal-ref": null, "doi": "10.1145/3450614.3463291", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measures of algorithmic fairness often do not account for human perceptions\nof fairness that can substantially vary between different sociodemographics and\nstakeholders. The FairCeptron framework is an approach for studying perceptions\nof fairness in algorithmic decision making such as in ranking or\nclassification. It supports (i) studying human perceptions of fairness and (ii)\ncomparing these human perceptions with measures of algorithmic fairness. The\nframework includes fairness scenario generation, fairness perception\nelicitation and fairness perception analysis. We demonstrate the FairCeptron\nframework by applying it to a hypothetical university admission context where\nwe collect human perceptions of fairness in the presence of minorities. An\nimplementation of the FairCeptron framework is openly available, and it can\neasily be adapted to study perceptions of algorithmic fairness in other\napplication contexts. We hope our work paves the way towards elevating the role\nof studies of human fairness perceptions in the process of designing\nalgorithmic decision making systems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 10:47:24 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Ahnert", "Georg", ""], ["Smirnov", "Ivan", ""], ["Lemmerich", "Florian", ""], ["Wagner", "Claudia", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2102.04196", "submitter": "Manjesh Kumar Hanawal", "authors": "Vinod S. Khandkar and Manjesh K. Hanawal", "title": "Challenges in Net Neutrality Violation Detection: A Case Study of Wehe\n  Tool", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The debate on \"Net-neutrality\" and events pointing towards its possible\nviolations have led to the development of tools to detect deliberate traffic\ndiscrimination on the Internet. Given the complex nature of the Internet,\nneutrality violations are not easy to detect, and tools developed so far suffer\nfrom various limitations. In this paper, we study many challenges in detecting\nthe violations and discuss possible approaches to mitigate them. As a case\nstudy, we focus on the tool Wehe \\cite{wehe} and discuss its limitations and\npropose the aspects that need to be strengthened.\n  Wehe is the most recent tool to detect neutrality violations. Despite Wehe's\nvast utility and possible influences over policy decisions, its mechanisms are\nnot yet fully validated by researchers other than original tool developers. We\nseek to fill this gap by conducting a thorough and in-depth validation of Wehe.\nOur validation uses the Wehe App, a client-server setup mimicking Wehe's\nbehavior and its theoretical arguments. We validated the Wehe app for its\nmethodology, traffic discrimination detection, and operational environments. We\nfound that the critical weaknesses of the Wehe App are due to its design\nchoices of using port number 80, overlooking the effect of background traffic,\nand the direct performance comparison.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2021 15:42:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Khandkar", "Vinod S.", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2102.04201", "submitter": "Jennifer Cobbe Dr", "authors": "Jennifer Cobbe, Michelle Seng Ah Lee, Jatinder Singh", "title": "Reviewable Automated Decision-Making: A Framework for Accountable\n  Algorithmic Systems", "comments": null, "journal-ref": "ACM Conference on Fairness, Accountability, and Transparency\n  (FAccT 21), March 2021, Virtual Event, Canada", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces reviewability as a framework for improving the\naccountability of automated and algorithmic decision-making (ADM) involving\nmachine learning. We draw on an understanding of ADM as a socio-technical\nprocess involving both human and technical elements, beginning before a\ndecision is made and extending beyond the decision itself. While explanations\nand other model-centric mechanisms may assist some accountability concerns,\nthey often provide insufficient information of these broader ADM processes for\nregulatory oversight and assessments of legal compliance. Reviewability\ninvolves breaking down the ADM process into technical and organisational\nelements to provide a systematic framework for determining the contextually\nappropriate record-keeping mechanisms to facilitate meaningful review - both of\nindividual decisions and of the process as a whole. We argue that a\nreviewability framework, drawing on administrative law's approach to reviewing\nhuman decision-making, offers a practical way forward towards more a more\nholistic and legally-relevant form of accountability for ADM.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 18:15:34 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 11:48:42 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Cobbe", "Jennifer", ""], ["Lee", "Michelle Seng Ah", ""], ["Singh", "Jatinder", ""]]}, {"id": "2102.04204", "submitter": "Dario Ortega Anderez", "authors": "Dario Ortega Anderez, Eiman Kanjo, Amna Amnwar, Shane Johnson, David\n  Lucy", "title": "The Rise of Technology in Crime Prevention: Opportunities, Challenges\n  and Practitioners Perspectives", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Criminal activity is a prevalent issue in contemporary culture and society,\nwith most nations facing unacceptable levels of crime. Technological innovation\nhas been one of the main driving forces leading to the continuous improvement\nof crime control and crime prevention strategies (e.g. GPS tracking and\ntagging, video surveillance, etc.). Given this, it is a moral obligation for\nthe research community to consider how the contemporary technological\ndevelopments (i.e. Internet of Things (IoT), Machine Learning, Edge\nComputing)might help reduce crime worldwide. In line with this, this paper\nprovides a discussion of how a sample of contemporary hardware and\nsoftware-based technologies might help further reduce criminal actions. After a\nthorough analysis of a wide array of technologies and a number of workshops\nwith organisations of interest, we believe that the adoption of novel\ntechnologies by vulnerable individuals, victim support organisations and law\nenforcement can help reduce the occurrence of criminal activity.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 16:02:40 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Anderez", "Dario Ortega", ""], ["Kanjo", "Eiman", ""], ["Amnwar", "Amna", ""], ["Johnson", "Shane", ""], ["Lucy", "David", ""]]}, {"id": "2102.04206", "submitter": "Shreekanth Prabhu", "authors": "Shreekanth M Prabhu", "title": "Transforming India's Agricultural Sector using Ontology-based Tantra\n  Framework", "comments": "21 pages, 3 figures, 14 Tables. Submitted to International Journal of\n  Sustainable Agricultural Management and Informatics and under review since\n  April 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Food production is a critical activity in which every nation would like to be\nself-sufficient. India is one of the largest producers of food grains in the\nworld. In India, nearly 70 percent of rural households still depend on\nagriculture for their livelihood. Keeping farmers happy is particularly\nimportant in India as farmers form a large vote bank which politicians dare not\ndisappoint. At the same time, Governments need to balance the interest of\nfarmers with consumers, intermediaries and society at large. The whole\nagriculture sector is highly information-intensive. Even with enormous\ncollection of data and statistics from different arms of Government, there\ncontinue to be information gaps. In this paper we look at how Tantra Social\nInformation Management Framework can help analyze the agricultural sector and\ntransform the same using a holistic approach. Advantage of Tantra Framework\napproach is that it looks at societal information as a whole without limiting\nit to only the sector at hand. Tantra Framework makes use of concepts from\nZachman Framework to manage aspects of social information through different\nperspectives and concepts from Unified Foundational Ontology (UFO) to represent\ninterrelationships between aspects. Further, Tantra Framework interoperates\nwith models such as Balanced Scorecard, Theory of Change and Theory of\nSeparations. Finally, we model Indian Agricultural Sector as a business\necosystem and look at approaches to steer transformation from within.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 04:05:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Prabhu", "Shreekanth M", ""]]}, {"id": "2102.04209", "submitter": "Michael Stuart", "authors": "Michael T. Stuart and Markus Kneer", "title": "Guilty Artificial Minds", "comments": "20 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concepts of blameworthiness and wrongness are of fundamental importance\nin human moral life. But to what extent are humans disposed to blame\nartificially intelligent agents, and to what extent will they judge their\nactions to be morally wrong? To make progress on these questions, we adopted\ntwo novel strategies. First, we break down attributions of blame and wrongness\ninto more basic judgments about the epistemic and conative state of the agent,\nand the consequences of the agent's actions. In this way, we are able to\nexamine any differences between the way participants treat artificial agents in\nterms of differences in these more basic judgments. our second strategy is to\ncompare attributions of blame and wrongness across human, artificial, and group\nagents (corporations). Others have compared attributions of blame and wrongness\nbetween human and artificial agents, but the addition of group agents is\nsignificant because these agents seem to provide a clear middle-ground between\nhuman agents (for whom the notions of blame and wrongness were created) and\nartificial agents (for whom the question remains open).\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 21:37:35 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Stuart", "Michael T.", ""], ["Kneer", "Markus", ""]]}, {"id": "2102.04211", "submitter": "Davide Taibi", "authors": "Dimitri Ognibene, Davide Taibi, Udo Kruschwitz, Rodrigo Souza Wilkens,\n  Davinia Hernandez-Leo, Emily Theophilou, Lidia Scifo, Rene Alejandro Lobo,\n  Francesco Lomonaco, Sabrina Eimler, H. Ulrich Hoppe, Nils Malzahn", "title": "Challenging Social Media Threats using Collective Well-being Aware\n  Recommendation Algorithms and an Educational Virtual Companion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Social media (SM) have become an integral part of our lives, expanding our\ninter-linking capabilities to new levels. There is plenty to be said about\ntheir positive effects. On the other hand however, some serious negative\nimplications of SM have repeatedly been highlighted in recent years, pointing\nat various SM threats for society, and its teenagers in particular: from common\nissues (e.g. digital addiction and polarization) and manipulative influences of\nalgorithms to teenager-specific issues (e.g. body stereotyping). The full\nimpact of current SM platform design -- both at an individual and societal\nlevel -- asks for a comprehensive evaluation and conceptual improvement. We\nextend measures of Collective Well-Being (CWB) to SM communities. As users'\nrelationships and interactions are a central component of CWB, education is\ncrucial to improve CWB. We thus propose a framework based on an adaptive\n\"social media virtual companion\" for educating and supporting the entire\nstudents' community to interact with SM. The virtual companion will be powered\nby a Recommender System (CWB-RS) that will optimize a CWB metric instead of\nengagement or platform profit, which currently largely drives recommender\nsystems thereby disregarding any societal collateral effect. CWB-RS will\noptimize CWB both in the short term, by balancing the level of SM threat the\nstudents are exposed to, as well as in the long term, by adopting an\nIntelligent Tutor System role and enabling adaptive and personalized sequencing\nof playful learning activities. This framework offers an initial step on\nunderstanding how to design SM systems and embedded educational interventions\nthat favor a more healthy and positive society.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 15:58:18 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 23:45:59 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 04:26:22 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ognibene", "Dimitri", ""], ["Taibi", "Davide", ""], ["Kruschwitz", "Udo", ""], ["Wilkens", "Rodrigo Souza", ""], ["Hernandez-Leo", "Davinia", ""], ["Theophilou", "Emily", ""], ["Scifo", "Lidia", ""], ["Lobo", "Rene Alejandro", ""], ["Lomonaco", "Francesco", ""], ["Eimler", "Sabrina", ""], ["Hoppe", "H. Ulrich", ""], ["Malzahn", "Nils", ""]]}, {"id": "2102.04212", "submitter": "Fateme Nikseresht", "authors": "Abigale Kim, Fateme Nikseresht, Janine M. Dutcher, Michael Tumminia,\n  Daniella Villalba, Sheldon Cohen, Kasey Creswel, David Creswell, Anind K.\n  Dey, Jennifer Mankoff and Afsaneh Doryab", "title": "Understanding health and behavioral trends of successful students\n  through machine learning models", "comments": "10 pages, 6 plots", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study analyzes patterns of physical, mental, lifestyle, and personality\nfactors in college students in different periods over the course of a semester\nand models their relationships with students' academic performance. The data\nanalyzed was collected through smartphones and Fitbit. The use of machine\nlearning models derived from the gathered data was employed to observe the\nextent of students' behavior associated with their GPA, lifestyle, physical\nhealth, mental health, and personality attributes. A mutual agreement method\nwas used in which rather than looking at the accuracy of results, the model\nparameters and weights of features were used to find common behavioral trends.\nFrom the results of the model creation, it was determined that the most\nsignificant indicator of academic success defined as a higher GPA, was the\nplaces a student spent their time. Lifestyle and personality factors were\ndeemed more significant than mental and physical factors. This study will\nprovide insight into the impact of different factors and the timing of those\nfactors on students' academic performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2021 17:18:17 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kim", "Abigale", ""], ["Nikseresht", "Fateme", ""], ["Dutcher", "Janine M.", ""], ["Tumminia", "Michael", ""], ["Villalba", "Daniella", ""], ["Cohen", "Sheldon", ""], ["Creswel", "Kasey", ""], ["Creswell", "David", ""], ["Dey", "Anind K.", ""], ["Mankoff", "Jennifer", ""], ["Doryab", "Afsaneh", ""]]}, {"id": "2102.04213", "submitter": "Manh-Tung Ho Mr.", "authors": "Mantello Peter, Manh-Tung Ho, Minh-Hoang Nguyen, Quan-Hoang Vuong", "title": "My Boss the Computer: A Bayesian analysis of socio-demographic and\n  cross-cultural determinants of attitude toward the Non-Human Resource\n  Management", "comments": "58 pages, 9 tables, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human resource management technologies have moved from biometric surveillance\nto emotional artificial intelligence (AI) that monitor employees' engagement\nand productivity, analyze video interviews and CVs of job applicants. The rise\nof the US$20 billion emotional AI industry will transform the future workplace.\nYet, besides no international consensus on the principles or standards for such\ntechnologies, there is a lack of cross-cultural research on future job seekers'\nattitude toward such use of AI technologies. This study collects a\ncross-sectional dataset of 1,015 survey responses of international students\nfrom 48 countries and 8 regions worldwide. A majority of the respondents (52%)\nare concerned about being managed by AI. Following the hypothetico-deductivist\nphilosophy of science, we use the MCMC Hamiltonian approach and conduct a\ndetailed comparison of 10 Bayesian network models with the PSIS-LOO method. We\nconsistently find having a higher income, being male, majoring in business,\nand/or self-rated familiarity with AI correlate with a more positive view of\nemotional AI in the workplace. There is also a stark cross-cultural and\ncross-regional difference. Our analysis shows people from economically less\ndeveloped regions (Africa, Oceania, Central Asia) tend to exhibit less concern\nfor AI managers. And for East Asian countries, 64% of the Japanese, 56% of the\nSouth Korean, and 42% of the Chinese professed the trusting attitude. In\ncontrast, an overwhelming majority of 75% of the European and Northern American\npossesses the worrying/neutral attitude toward being managed by AI. Regarding\nreligion, Muslim students correlate with the most concern toward emotional AI\nin the workplace. When religiosity is higher, the correlation becomes stronger\nfor Muslim and Buddhist students.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2021 09:53:12 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Peter", "Mantello", ""], ["Ho", "Manh-Tung", ""], ["Nguyen", "Minh-Hoang", ""], ["Vuong", "Quan-Hoang", ""]]}, {"id": "2102.04215", "submitter": "Jamie Harris", "authors": "Jamie Harris (1) and Jacy Reese Anthis (1 and 2) ((1) Sentience\n  Institute, (2) University of Chicago)", "title": "The Moral Consideration of Artificial Entities: A Literature Review", "comments": "27 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ethicists, policy-makers, and the general public have questioned whether\nartificial entities such as robots warrant rights or other forms of moral\nconsideration. There is little synthesis of the research on this topic so far.\nWe identify 294 relevant research or discussion items in our literature review\nof this topic. There is widespread agreement among scholars that some\nartificial entities could warrant moral consideration in the future, if not\nalso the present. The reasoning varies, such as concern for the effects on\nartificial entities and concern for the effects on human society. Beyond the\nconventional consequentialist, deontological, and virtue ethicist ethical\nframeworks, some scholars encourage \"information ethics\" and\n\"social-relational\" approaches, though there are opportunities for more\nin-depth ethical research on the nuances of moral consideration of artificial\nentities. There is limited relevant empirical data collection, primarily in a\nfew psychological studies on current moral and social attitudes of humans\ntowards robots and other artificial entities. This suggests an important gap\nfor social science research on how artificial entities will be integrated into\nsociety and the factors that will determine how the interests of sentient\nartificial entities are considered.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2021 11:07:00 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Harris", "Jamie", "", "1 and 2"], ["Anthis", "Jacy Reese", "", "1 and 2"]]}, {"id": "2102.04216", "submitter": "Anusha Bompelli", "authors": "Anusha Bompelli, Yanshan Wang, Ruyuan Wan, Esha Singh, Yuqi Zhou, Lin\n  Xu, David Oniani, Bhavani Singh Agnikula Kshatriya, Joyce (Joy) E.\n  Balls-Berry, and Rui Zhang", "title": "Social and behavioral determinants of health in the era of artificial\n  intelligence with electronic health records: A scoping review", "comments": "32 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: There is growing evidence that social and behavioral determinants\nof health (SBDH) play a substantial effect in a wide range of health outcomes.\nElectronic health records (EHRs) have been widely employed to conduct\nobservational studies in the age of artificial intelligence (AI). However,\nthere has been little research into how to make the most of SBDH information\nfrom EHRs. Methods: A systematic search was conducted in six databases to find\nrelevant peer-reviewed publications that had recently been published. Relevance\nwas determined by screening and evaluating the articles. Based on selected\nrelevant studies, a methodological analysis of AI algorithms leveraging SBDH\ninformation in EHR data was provided. Results: Our synthesis was driven by an\nanalysis of SBDH categories, the relationship between SBDH and\nhealthcare-related statuses, and several NLP approaches for extracting SDOH\nfrom clinical literature. Discussion: The associations between SBDH and health\noutcomes are complicated and diverse; several pathways may be involved. Using\nNatural Language Processing (NLP) technology to support the extraction of SBDH\nand other clinical ideas simplifies the identification and extraction of\nessential concepts from clinical data, efficiently unlocks unstructured data,\nand aids in the resolution of unstructured data-related issues. Conclusion:\nDespite known associations between SBDH and disease, SBDH factors are rarely\ninvestigated as interventions to improve patient outcomes. Gaining knowledge\nabout SBDH and how SBDH data can be collected from EHRs using NLP approaches\nand predictive models improves the chances of influencing health policy change\nfor patient wellness, and ultimately promoting health and health equity.\n  Keywords: Social and Behavioral Determinants of Health, Artificial\nIntelligence, Electronic Health Records, Natural Language Processing,\nPredictive Model\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 09:03:39 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 17:50:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Bompelli", "Anusha", "", "Joy"], ["Wang", "Yanshan", "", "Joy"], ["Wan", "Ruyuan", "", "Joy"], ["Singh", "Esha", "", "Joy"], ["Zhou", "Yuqi", "", "Joy"], ["Xu", "Lin", "", "Joy"], ["Oniani", "David", "", "Joy"], ["Kshatriya", "Bhavani Singh Agnikula", "", "Joy"], ["Joyce", "", "", "Joy"], ["Balls-Berry", "E.", ""], ["Zhang", "Rui", ""]]}, {"id": "2102.04217", "submitter": "Rajvardhan Oak", "authors": "Rajvardhan Oak", "title": "The Fault in the Stars: Understanding the Underground Market of Amazon\n  Reviews", "comments": "This is a work in progress!", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent times, the Internet has been plagued by a tremendous amount of\nmisinformation. Online markets such as Amazon are also not free from\nmisinformation. In this work, we study the misinformation propagated to\nconsumers through the form of Amazon reviews. There exists a vast underground\nmarket where reviews by real Amazon users are purchased and sold. While such a\npractice violates Amazon's terms of service, we observe that there exists a\ncomplex network consisting of thousands of sellers and agents, who provide a\nrebate to consumers for leaving positive reviews to over $5000$ products. Based\non interviews with members involved in the reviews market, we understand the\nworking of this market, and the tactics used to avoid detection by Amazon. We\nalso present a set of recommendations of features that Amazon and similar\nonline markets can take into consideration to detect such reviews.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2021 05:30:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Oak", "Rajvardhan", ""]]}, {"id": "2102.04221", "submitter": "John Richards", "authors": "Bran Knowles and John T. Richards", "title": "The Sanction of Authority: Promoting Public Trust in AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trusted AI literature to date has focused on the trust needs of users who\nknowingly interact with discrete AIs. Conspicuously absent from the literature\nis a rigorous treatment of public trust in AI. We argue that public distrust of\nAI originates from the under-development of a regulatory ecosystem that would\nguarantee the trustworthiness of the AIs that pervade society. Drawing from\nstructuration theory and literature on institutional trust, we offer a model of\npublic trust in AI that differs starkly from models driving Trusted AI efforts.\nThis model provides a theoretical scaffolding for Trusted AI research which\nunderscores the need to develop nothing less than a comprehensive and visibly\nfunctioning regulatory ecosystem. We elaborate the pivotal role of externally\nauditable AI documentation within this model and the work to be done to ensure\nit is effective, and outline a number of actions that would promote public\ntrust in AI. We discuss how existing efforts to develop AI documentation within\norganizations -- both to inform potential adopters of AI components and support\nthe deliberations of risk and ethics review boards -- is necessary but\ninsufficient assurance of the trustworthiness of AI. We argue that being\naccountable to the public in ways that earn their trust, through elaborating\nrules for AI and developing resources for enforcing these rules, is what will\nultimately make AI trustworthy enough to be woven into the fabric of our\nsociety.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2021 22:01:30 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Knowles", "Bran", ""], ["Richards", "John T.", ""]]}, {"id": "2102.04227", "submitter": "Victor Von Wachter", "authors": "Victor von Wachter, Johannes Rude Jensen, Omri Ross", "title": "Measuring Asset Composability as a Proxy for DeFi Integration", "comments": "Blockchain, DeFi, Asset Composability, Ethereum", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decentralized financial (DeFi) applications on the Ethereum blockchain are\nhighly interoperable because they share a single state in a deterministic\ncomputational environment. Stakeholders can deposit claims on assets, referred\nto as 'liquidity shares', across applications producing effects equivalent to\nrehypothecation in traditional financial systems. We seek to understand the\ndegree to which this practice may contribute to financial integration on\nEthereum by examining transactions in 'composed' derivatives for the assets\nDAI, USDC, USDT, ETH and tokenized BTC for the full set of 344.8 million\nEthereum transactions computed in 2020. We identify a salient trend for\n'composing' assets in multiple sequential generations of derivatives and\ncomment on potential systemic implications for the Ethereum network.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 09:57:33 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 16:47:15 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["von Wachter", "Victor", ""], ["Jensen", "Johannes Rude", ""], ["Ross", "Omri", ""]]}, {"id": "2102.04234", "submitter": "Elija Perrier", "authors": "Elija Perrier", "title": "Computability, Complexity, Consistency and Controllability: A Four C's\n  Framework for cross-disciplinary Ethical Algorithm Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ethical consequences of, constraints upon and regulation of algorithms\narguably represent the defining challenges of our age, asking us to reckon with\nthe rise of computational technologies whose potential to radically\ntransforming social and individual orders and identity in unforeseen ways is\nalready being realised. Yet despite the multidisciplinary impact of this\nalgorithmic turn, there remains some way to go in motivating the\ncrossdisciplinary collaboration that is crucial to advancing feasible proposals\nfor the ethical design, implementation and regulation of algorithmic and\nautomated systems. In this work, we provide a framework to assist\ncross-disciplinary collaboration by presenting a Four C's Framework covering\nkey computational considerations researchers across such diverse fields should\nconsider when approaching these questions: (i) computability, (ii) complexity,\n(iii) consistency and (iv) controllability. In addition, we provide examples of\nhow insights from ethics, philosophy and population ethics are relevant to and\ntranslatable within sciences concerned with the study and design of algorithms.\nOur aim is to set out a framework which we believe is useful for fostering\ncross-disciplinary understanding of pertinent issues in ethical algorithmic\nliterature which is relevant considering the feasibility of ethical algorithmic\ngovernance, especially the impact of computational constraints upon algorithmic\ngovernance.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 17:03:22 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Perrier", "Elija", ""]]}, {"id": "2102.04235", "submitter": "Fernando Almeida Dr.", "authors": "Fernando Almeida and Jos\\'e Monteiro", "title": "The Challenges of Assessing and Evaluating the Students at Distance", "comments": "8 pages, 10 references", "journal-ref": "Journal of Online Higher Education, 2021", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic has caused a strong effect on higher education\ninstitutions with the closure of classroom teaching activities. In this\nunprecedented crisis, of global proportion, educators and families had to deal\nwith unpredictability and learn new ways of teaching. This short essay aims to\nexplore the challenges posed to Portuguese higher education institutions and to\nanalyze the challenges posed to evaluation models. To this end, the relevance\nof formative and summative assessment models in distance education is explored\nand the perception of teachers and students about the practices adopted in\nremote assessment is discussed. On the teachers' side, there is a high concern\nabout adopting fraud-free models, and an excessive focus on the summative\nassessment component that in the distance learning model has less preponderance\nwhen compared to the gradual monitoring and assessment processes of the\nstudents, while on the students' side, problems arise regarding equipment to\nfollow the teaching sessions and concerns about their privacy, particularly\nwhen intrusive IT solutions request the access to their cameras, audio, and\ndesktop.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 13:13:45 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Almeida", "Fernando", ""], ["Monteiro", "Jos\u00e9", ""]]}, {"id": "2102.04250", "submitter": "Duc Kinh Le Tran", "authors": "Duc Kinh Le Tran", "title": "Riiid! Answer Correctness Prediction Kaggle Challenge: 4th Place\n  Solution Summary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents my solution to the challenge \"Riiid! Answer Correctness\nPrediction\" on Kaggle hosted by Riiid Labs (2020), which scores 0.817 (AUC) and\nranks 4th on the final private leaderboard. It is a single transformer-based\nmodel heavily inspired from previous works such as SAKT, SAINT and SAINT+.\nNovel ingredients that I believed to have made a difference are the time-aware\nattention mechanism, the concatenation of the embeddings of the input sequences\nand the embedding of continuous features.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:55:51 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Tran", "Duc Kinh Le", ""]]}, {"id": "2102.04251", "submitter": "Dhivya Chandrasekaran", "authors": "Mahzabeen Emu, Dhivya Chandrasekaran, Vijay Mago and Salimur Choudhury", "title": "Validating Optimal COVID-19 Vaccine Distribution Models", "comments": "14 pages, 16 figures, submitted to ICCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the approval of vaccines for the coronavirus disease by many countries\nworldwide, most developed nations have begun, and developing nations are\ngearing up for the vaccination process. This has created an urgent need to\nprovide a solution to optimally distribute the available vaccines once they are\nreceived by the authorities. In this paper, we propose a clustering-based\nsolution to select optimal distribution centers and a Constraint Satisfaction\nProblem framework to optimally distribute the vaccines taking into\nconsideration two factors namely priority and distance. We demonstrate the\nefficiency of the proposed models using real-world data obtained from the\ndistrict of Chennai, India. The model provides the decision making authorities\nwith optimal distribution centers across the district and the optimal\nallocation of individuals across these distribution centers with the\nflexibility to accommodate a wide range of demographics.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 21:54:47 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Emu", "Mahzabeen", ""], ["Chandrasekaran", "Dhivya", ""], ["Mago", "Vijay", ""], ["Choudhury", "Salimur", ""]]}, {"id": "2102.04252", "submitter": "Tianfan Fu", "authors": "Tianfan Fu, Kexin Huang, Cao Xiao, Lucas M. Glass, Jimeng Sun", "title": "HINT: Hierarchical Interaction Network for Trial Outcome Prediction\n  Leveraging Web Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical trials are crucial for drug development but are time consuming,\nexpensive, and often burdensome on patients. More importantly, clinical trials\nface uncertain outcomes due to issues with efficacy, safety, or problems with\npatient recruitment. If we were better at predicting the results of clinical\ntrials, we could avoid having to run trials that will inevitably fail more\nresources could be devoted to trials that are likely to succeed. In this paper,\nwe propose Hierarchical INteraction Network (HINT) for more general, clinical\ntrial outcome predictions for all diseases based on a comprehensive and diverse\nset of web data including molecule information of the drugs, target disease\ninformation, trial protocol and biomedical knowledge. HINT first encode these\nmulti-modal data into latent embeddings, where an imputation module is designed\nto handle missing data. Next, these embeddings will be fed into the knowledge\nembedding module to generate knowledge embeddings that are pretrained using\nexternal knowledge on pharmaco-kinetic properties and trial risk from the web.\nThen the interaction graph module will connect all the embedding via domain\nknowledge to fully capture various trial components and their complex relations\nas well as their influences on trial outcomes. Finally, HINT learns a dynamic\nattentive graph neural network to predict trial outcome. Comprehensive\nexperimental results show that HINT achieves strong predictive performance,\nobtaining 0.772, 0.607, 0.623, 0.703 on PR-AUC for Phase I, II, III, and\nindication outcome prediction, respectively. It also consistently outperforms\nthe best baseline method by up to 12.4\\% on PR-AUC.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 15:09:07 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Fu", "Tianfan", ""], ["Huang", "Kexin", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Sun", "Jimeng", ""]]}, {"id": "2102.04255", "submitter": "Nathan Lambert", "authors": "McKane Andrus, Sarah Dean, Thomas Krendl Gilbert, Nathan Lambert, Tom\n  Zick", "title": "AI Development for the Public Interest: From Abstraction Traps to\n  Sociotechnical Risks", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite interest in communicating ethical problems and social contexts within\nthe undergraduate curriculum to advance Public Interest Technology (PIT) goals,\ninterventions at the graduate level remain largely unexplored. This may be due\nto the conflicting ways through which distinct Artificial Intelligence (AI)\nresearch tracks conceive of their interface with social contexts. In this paper\nwe track the historical emergence of sociotechnical inquiry in three distinct\nsubfields of AI research: AI Safety, Fair Machine Learning (Fair ML) and\nHuman-in-the-Loop (HIL) Autonomy. We show that for each subfield, perceptions\nof PIT stem from the particular dangers faced by past integration of technical\nsystems within a normative social order. We further interrogate how these\nhistories dictate the response of each subfield to conceptual traps, as defined\nin the Science and Technology Studies literature. Finally, through a\ncomparative analysis of these currently siloed fields, we present a roadmap for\na unified approach to sociotechnical graduate pedagogy in AI.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:54:20 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Andrus", "McKane", ""], ["Dean", "Sarah", ""], ["Gilbert", "Thomas Krendl", ""], ["Lambert", "Nathan", ""], ["Zick", "Tom", ""]]}, {"id": "2102.04256", "submitter": "Jack Bandy", "authors": "Jack Bandy", "title": "Problematic Machine Behavior: A Systematic Literature Review of\n  Algorithm Audits", "comments": "To Appear in the Proceedings of the ACM (PACM) Human-Computer\n  Interaction, CSCW '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While algorithm audits are growing rapidly in commonality and public\nimportance, relatively little scholarly work has gone toward synthesizing prior\nwork and strategizing future research in the area. This systematic literature\nreview aims to do just that, following PRISMA guidelines in a review of over\n500 English articles that yielded 62 algorithm audit studies. The studies are\nsynthesized and organized primarily by behavior (discrimination, distortion,\nexploitation, and misjudgement), with codes also provided for domain (e.g.\nsearch, vision, advertising, etc.), organization (e.g. Google, Facebook,\nAmazon, etc.), and audit method (e.g. sock puppet, direct scrape,\ncrowdsourcing, etc.). The review shows how previous audit studies have exposed\npublic-facing algorithms exhibiting problematic behavior, such as search\nalgorithms culpable of distortion and advertising algorithms culpable of\ndiscrimination. Based on the studies reviewed, it also suggests some behaviors\n(e.g. discrimination on the basis of intersectional identities), domains (e.g.\nadvertising algorithms), methods (e.g. code auditing), and organizations (e.g.\nTwitter, TikTok, LinkedIn) that call for future audit attention. The paper\nconcludes by offering the common ingredients of successful audits, and\ndiscussing algorithm auditing in the context of broader research working toward\nalgorithmic justice.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 19:21:11 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Bandy", "Jack", ""]]}, {"id": "2102.04257", "submitter": "Kevin McKee", "authors": "Nenad Tomasev, Kevin R. McKee, Jackie Kay, Shakir Mohamed", "title": "Fairness for Unobserved Characteristics: Insights from Technological\n  Impacts on Queer Communities", "comments": "Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\n  Society (AIES 2021)", "journal-ref": null, "doi": "10.1145/3461702.3462540", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in algorithmic fairness have largely omitted sexual orientation and\ngender identity. We explore queer concerns in privacy, censorship, language,\nonline safety, health, and employment to study the positive and negative\neffects of artificial intelligence on queer communities. These issues\nunderscore the need for new directions in fairness research that take into\naccount a multiplicity of considerations, from privacy preservation, context\nsensitivity and process fairness, to an awareness of sociotechnical impact and\nthe increasingly important role of inclusive and participatory research\nprocesses. Most current approaches for algorithmic fairness assume that the\ntarget characteristics for fairness--frequently, race and legal gender--can be\nobserved or recorded. Sexual orientation and gender identity are prototypical\ninstances of unobserved characteristics, which are frequently missing, unknown\nor fundamentally unmeasurable. This paper highlights the importance of\ndeveloping new approaches for algorithmic fairness that break away from the\nprevailing assumption of observed characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 18:52:54 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 21:04:58 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 16:39:10 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Tomasev", "Nenad", ""], ["McKee", "Kevin R.", ""], ["Kay", "Jackie", ""], ["Mohamed", "Shakir", ""]]}, {"id": "2102.04333", "submitter": "Tan Guerpinar", "authors": "Boris Duedder, Vladislav Fomin, Tan Guerpinar, Michael Henke, Philipp\n  Asterios Ioannidis, Viktorija Janaviciene, Raimundas Matulevicius, Mubashar\n  Iqbal, Natalia Straub", "title": "BlockNet Report: Exploring the Blockchain Skills Concept and Best\n  Practice Use Cases", "comments": "arXiv admin note: text overlap with arXiv:2102.03226", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to explore the practical potential and needs of interdisciplinary\nknowledge and competence requirements of Blockchain technology, the project\nactivity \"Development of Interdisciplinary Blockchain Skills Concept\" starts\nwith the literature review identifying the state of the art of Blockchain in\nSupply Chain Management and Logistics, Business and Finance, as well as\nComputer Science and IT-Security. The project activity further explores the\nacademic and industry landscape of existing initiatives in education which\noffer Blockchain courses. Moreover, job descriptions and adverts are analyzed\nin order to specify today's competence requirements from enterprises. To\ndiscuss and define the future required competence, expert workshops are\norganized to validate the findings by academic experts. Based on the research\noutcome and validation, an interdisciplinary approach for Blockchain competence\nis developed.\n  A second part focuses on the development of the Blockchain Best Practices\nactivity while conducting qualitative empirical research based on case studies\nwith industry representatives. Therefore, company interviews, based on the\ntheoretical basis of Output 1, explore existing Blockchain use cases in\ndifferent sectors. Due to the interdisciplinary importance of Blockchain\ntechnology, these skills will be defined by different perspectives of\nBlockchain from across multiple mentioned disciplines. The use cases and\ncompanies for the interviews will be selected based on various sampling\ncriteria to gain results valid for a broad scale. The analysis of the various\nuse cases will be conducted and defined in a standardized format to identify\nthe key drivers and competence requirements for Blockchain technology\napplications and their adoption. On the one hand, this approach ensures\ncomparability, on the other hand, it facilitates the development of a\nstructured and systematic framework.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:40:09 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Duedder", "Boris", ""], ["Fomin", "Vladislav", ""], ["Guerpinar", "Tan", ""], ["Henke", "Michael", ""], ["Ioannidis", "Philipp Asterios", ""], ["Janaviciene", "Viktorija", ""], ["Matulevicius", "Raimundas", ""], ["Iqbal", "Mubashar", ""], ["Straub", "Natalia", ""]]}, {"id": "2102.04458", "submitter": "Myung Suh Choi", "authors": "Alim Al Ayub Ahmed, Ayman Aljabouh, Praveen Kumar Donepudi, Myung Suh\n  Choi", "title": "Detecting Fake News Using Machine Learning : A Systematic Literature\n  Review", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Internet is one of the important inventions and a large number of persons are\nits users. These persons use this for different purposes. There are different\nsocial media platforms that are accessible to these users. Any user can make a\npost or spread the news through the online platforms. These platforms do not\nverify the users or their posts. So some of the users try to spread fake news\nthrough these platforms. These news can be propaganda against an individual,\nsociety, organization or political party. A human being is unable to detect all\nthese fake news. So there is a need for machine learning classifiers that can\ndetect these fake news automatically. Use of machine learning classifiers for\ndetecting fake news is described in this systematic literature review.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 21:36:00 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Ahmed", "Alim Al Ayub", ""], ["Aljabouh", "Ayman", ""], ["Donepudi", "Praveen Kumar", ""], ["Choi", "Myung Suh", ""]]}, {"id": "2102.04460", "submitter": "Iuliana Marin", "authors": "Iuliana Marin, Nicolae Goga", "title": "Securing the Network for a Smart Bracelet System", "comments": null, "journal-ref": "2018 22nd International Conference on System Theory, Control and\n  Computing (ICSTCC)", "doi": "10.1109/ICSTCC.2018.8540704", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital instruments play a vital role in our daily life. It is a routine to\nproduce business papers, watch the news program, write articles and blogs,\nmanage healthcare systems, to purchase online, to send messages and all this is\nprocessed by making observations and then manipulating, receiving and availing\nthe diverse data. This electronic data provides the foundation of real time\ndata. All this transmission of data needs to be secured. Security is essential\nfor healthcare systems as the present one where the blood pressure recordings\nprovided by the smart bracelet are sent to the user's mobile phone via\nBluetooth. The bracelet monitors the pregnant women, but also other users who\nwish to have their blood pressure under control. The system's server analyses\nthe recordings and announces the user, as well as the associated persons to the\nuser in case of an emergency. The doctors, the medical staff, user and user's\nfamily and caregivers have access to the health recordings belonging to the\nmonitored user. Security is a main feature of the electronic healthcare system\nbased on the smart bracelet.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 11:50:02 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Marin", "Iuliana", ""], ["Goga", "Nicolae", ""]]}, {"id": "2102.04512", "submitter": "Aryan Mahindra", "authors": "Aryan Mahindra, Anshuman Sharma, Priyanshi Katiyar, Rohan Sukumaran,\n  Ishaan Singh, Albert Johnson, Kasia Jakimowicz, Akarsh Venkatasubramanian,\n  Chandan CV, Shailesh Advani, Rohan Iyer, Sheshank Shankar, Saurish\n  Srivastava, Sethuraman TV, Abhishek Singh, Ramesh Raskar", "title": "Paper card-based vs application-based vaccine credentials: a comparison", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this early draft, we provide an overview on similarities and differences\nin the implementation of a paper card-based vaccine credential system and an\napp-based vaccine credential system. A vaccine credential's primary goal is to\nregulate entry and ensure safety of individuals within densely packed public\nlocations and workspaces. This is critical for containing the rapid spread of\nCovid-19 in densely packed public locations since a single individual can\ninfect a large majority of people in a crowd. A vaccine credential can also\nprovide information such as an individual's Covid-19 vaccination history and\nadverse symptom reaction history to judge their potential impact on the overall\nhealth of individuals within densely packed public locations and workspaces.\nAfter completing the comparisons, we believe a card-based implementation will\nbenefit regions with less socioeconomic mobility, limited resources, and\nstagnant administrations. An app-based implementation on the other hand will\nbenefit regions with equitable internet access and lower technological divide.\nWe also believe an interoperable system of both credential systems will work\nbest for regions with enormous working-class populations and dense housing\nclusters.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 20:14:53 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 03:36:01 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 21:47:02 GMT"}, {"version": "v4", "created": "Thu, 29 Apr 2021 22:37:03 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Mahindra", "Aryan", ""], ["Sharma", "Anshuman", ""], ["Katiyar", "Priyanshi", ""], ["Sukumaran", "Rohan", ""], ["Singh", "Ishaan", ""], ["Johnson", "Albert", ""], ["Jakimowicz", "Kasia", ""], ["Venkatasubramanian", "Akarsh", ""], ["CV", "Chandan", ""], ["Advani", "Shailesh", ""], ["Iyer", "Rohan", ""], ["Shankar", "Sheshank", ""], ["Srivastava", "Saurish", ""], ["TV", "Sethuraman", ""], ["Singh", "Abhishek", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2102.04527", "submitter": "Michael Stuart", "authors": "Markus Kneer and Michael T. Stuart", "title": "Playing the Blame Game with Robots", "comments": "5 pages, 2 figures, 2 tables, HRI'21", "journal-ref": null, "doi": "10.1145/3434074.3447202", "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent research shows -- somewhat astonishingly -- that people are willing to\nascribe moral blame to AI-driven systems when they cause harm [1]-[4]. In this\npaper, we explore the moral-psychological underpinnings of these findings. Our\nhypothesis was that the reason why people ascribe moral blame to AI systems is\nthat they consider them capable of entertaining inculpating mental states (what\nis called mens rea in the law). To explore this hypothesis, we created a\nscenario in which an AI system runs a risk of poisoning people by using a novel\ntype of fertilizer. Manipulating the computational (or quasi-cognitive)\nabilities of the AI system in a between-subjects design, we tested whether\npeople's willingness to ascribe knowledge of a substantial risk of harm (i.e.,\nrecklessness) and blame to the AI system. Furthermore, we investigated whether\nthe ascription of recklessness and blame to the AI system would influence the\nperceived blameworthiness of the system's user (or owner). In an experiment\nwith 347 participants, we found (i) that people are willing to ascribe blame to\nAI systems in contexts of recklessness, (ii) that blame ascriptions depend\nstrongly on the willingness to attribute recklessness and (iii) that the\nlatter, in turn, depends on the perceived \"cognitive\" capacities of the system.\nFurthermore, our results suggest (iv) that the higher the computational\nsophistication of the AI system, the more blame is shifted from the human user\nto the AI system.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 20:53:42 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kneer", "Markus", ""], ["Stuart", "Michael T.", ""]]}, {"id": "2102.04558", "submitter": "Muhammad Anshari", "authors": "Muhammad Anshari", "title": "E-Health Management Services in Supporting Empowerment", "comments": "4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Web technology provides healthcare providers the ability to broaden their\nservices beyond the usual practices, and thus provides a particular\nadvantageous environment to achieve complex e-health goals. This paper\ndiscusses how a Web 2.0 application will help healthcare provider to extend and\nenhance their services by involving and empowering their customers.Web 2.0\nreferes to the next generations of Web technology that empowers users to\ngenerate contents over Internet. The Web 2.0 also refers to the Web as a\nplatform to perform any task online. The Web 2.0 allows customers to have\ngreater control of information flow from interactions between healthcare\nproviders with its customers and among customers themselves. The study employed\nquantitative methods to depict expectations of customers in Indonesia towards\nhealthcare services that can offer empowerment and social media and sharing.\nThe questionnaires were fairly distributed to the groups of healthcare staffs\nand customers (patients) who regularly visit healthcare centres. The survey\nrevealed that features of Web 2.0 in e-health services such as consultation\nonline, sharing in social networks, empowerment in detailing personal health\nrecords are highly appreciated by customers. Regardless of the limitations of\nthe survey, the public has responded with a great support for the capabilities\nof Web 2.0 listed from the questionnaires. The findings provide initial ideas\nand recommendation for a future direction of prototype of social networks in\ne-health services.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 22:21:35 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Anshari", "Muhammad", ""]]}, {"id": "2102.04567", "submitter": "Maur\\'icio Gruppi", "authors": "Maur\\'icio Gruppi, Benjamin D. Horne and Sibel Adal{\\i}", "title": "NELA-GT-2020: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "comments": "6 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2003.08444", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an updated version of the NELA-GT-2019 dataset,\nentitled NELA-GT-2020. NELA-GT-2020 contains nearly 1.8M news articles from 519\nsources collected between January 1st, 2020 and December 31st, 2020. Just as\nwith NELA-GT-2018 and NELA-GT-2019, these sources come from a wide range of\nmainstream news sources and alternative news sources. Included in the dataset\nare source-level ground truth labels from Media Bias/Fact Check (MBFC) covering\nmultiple dimensions of veracity. Additionally, new in the 2020 dataset are the\nTweets embedded in the collected news articles, adding an extra layer of\ninformation to the data. The NELA-GT-2020 dataset can be found at\nhttps://doi.org/10.7910/DVN/CHMUYZ.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 22:55:37 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Gruppi", "Maur\u00edcio", ""], ["Horne", "Benjamin D.", ""], ["Adal\u0131", "Sibel", ""]]}, {"id": "2102.04714", "submitter": "Andrea Aler Tubella", "authors": "Andrea Aler Tubella, Andreas Theodorou and Juan Carlos Nieves", "title": "Interrogating the Black Box: Transparency through Information-Seeking\n  Dialogues", "comments": "Accepted at AAMAS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is preoccupied with the following question: given a (possibly\nopaque) learning system, how can we understand whether its behaviour adheres to\ngovernance constraints? The answer can be quite simple: we just need to \"ask\"\nthe system about it. We propose to construct an investigator agent to query a\nlearning agent -- the suspect agent -- to investigate its adherence to a given\nethical policy in the context of an information-seeking dialogue, modeled in\nformal argumentation settings. This formal dialogue framework is the main\ncontribution of this paper. Through it, we break down compliance checking\nmechanisms into three modular components, each of which can be tailored to\nvarious needs in a vast amount of ways: an investigator agent, a suspect agent,\nand an acceptance protocol determining whether the responses of the suspect\nagent comply with the policy. This acceptance protocol presents a fundamentally\ndifferent approach to aggregation: rather than using quantitative methods to\ndeal with the non-determinism of a learning system, we leverage the use of\nargumentation semantics to investigate the notion of properties holding\nconsistently. Overall, we argue that the introduced formal dialogue framework\nopens many avenues both in the area of compliance checking and in the analysis\nof properties of opaque systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 09:14:04 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Tubella", "Andrea Aler", ""], ["Theodorou", "Andreas", ""], ["Nieves", "Juan Carlos", ""]]}, {"id": "2102.04808", "submitter": "Yassine Himeur", "authors": "Yassine Himeur and Abdullah Alsalemi and Faycal Bensaali and Abbes\n  Amira", "title": "Smart non-intrusive appliance identification using a novel local power\n  histogramming descriptor with an improved k-nearest neighbors classifier", "comments": "20 pages, 5 tables, 7 figures", "journal-ref": "Sustainable Cities and Society Volume 67, 102764, 2021", "doi": "10.1016/j.scs.2021.102764", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-intrusive load monitoring (NILM) is a key cost-effective technology for\nmonitoring power consumption and contributing to several challenges encountered\nwhen transiting to an efficient, sustainable, and competitive energy efficiency\nenvironment. This paper proposes a smart NILM system based on a novel local\npower histogramming (LPH) descriptor, in which appliance power signals are\ntransformed into 2D space and short histograms are extracted to represent each\ndevice. Specifically, short local histograms are drawn to represent individual\nappliance consumption signatures and robustly extract appliance-level data from\nthe aggregated power signal. Furthermore, an improved k-nearest neighbors\n(IKNN) algorithm is presented to reduce the learning computation time and\nimprove the classification performance. This results in highly improving the\ndiscrimination ability between appliances belonging to distinct categories. A\ndeep evaluation of the proposed LPH-IKNN based solution is investigated under\ndifferent data sets, in which the proposed scheme leads to promising\nperformance. An accuracy of up to 99.65% and 98.51% has been achieved on GREEND\nand UK-DALE data sets, respectively. While an accuracy of more than 96% has\nbeen attained on both WHITED and PLAID data sets. This proves the validity of\nusing 2D descriptors to accurately identify appliances and create new\nperspectives for the NILM problem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 13:12:20 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Himeur", "Yassine", ""], ["Alsalemi", "Abdullah", ""], ["Bensaali", "Faycal", ""], ["Amira", "Abbes", ""]]}, {"id": "2102.04881", "submitter": "Florian E. Dorner", "authors": "Florian E. Dorner", "title": "Measuring Progress in Deep Reinforcement Learning Sample Efficiency", "comments": "26 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampled environment transitions are a critical input to deep reinforcement\nlearning (DRL) algorithms. Current DRL benchmarks often allow for the cheap and\neasy generation of large amounts of samples such that perceived progress in DRL\ndoes not necessarily correspond to improved sample efficiency. As simulating\nreal world processes is often prohibitively hard and collecting real world\nexperience is costly, sample efficiency is an important indicator for\neconomically relevant applications of DRL. We investigate progress in sample\nefficiency on Atari games and continuous control tasks by comparing the number\nof samples that a variety of algorithms need to reach a given performance level\naccording to training curves in the corresponding publications. We find\nexponential progress in sample efficiency with estimated doubling times of\naround 10 to 18 months on Atari, 5 to 24 months on state-based continuous\ncontrol and of around 4 to 9 months on pixel-based continuous control depending\non the specific task and performance level.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 15:27:47 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Dorner", "Florian E.", ""]]}, {"id": "2102.04936", "submitter": "Fred Morstatter", "authors": "Rajiv Sethi, Julie Seager, Emily Cai, Daniel M. Benjamin, Fred\n  Morstatter", "title": "Models, Markets, and the Forecasting of Elections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine probabilistic forecasts for battleground states in the 2020 US\npresidential election, using daily data from two sources over seven months: a\nmodel published by The Economist, and prices from the PredictIt exchange. We\nfind systematic differences in accuracy over time, with markets performing\nbetter several months before the election, and the model performing better as\nthe election approached. A simple average of the two forecasts performs better\nthan either one of them overall, even though no average can outperform both\ncomponent forecasts for any given state-date pair. This effect arises because\nthe model and the market make different kinds of errors in different states:\nthe model was confidently wrong in some cases, while the market was excessively\nuncertain in others. We conclude that there is value in using hybrid\nforecasting methods, and propose a market design that incorporates model\nforecasts via a trading bot to generate synthetic predictions. We also propose\nand conduct a profitability test that can be used as a novel criterion for the\nevaluation of forecasting performance.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 19:05:07 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2021 20:05:41 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 23:28:13 GMT"}, {"version": "v4", "created": "Tue, 25 May 2021 16:34:04 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Sethi", "Rajiv", ""], ["Seager", "Julie", ""], ["Cai", "Emily", ""], ["Benjamin", "Daniel M.", ""], ["Morstatter", "Fred", ""]]}, {"id": "2102.05038", "submitter": "SeungKee Jeon", "authors": "SeungKee Jeon", "title": "Last Query Transformer RNN for knowledge tracing", "comments": "kaggle competition 'Riiid! Answer Correctness Prediction' 1st place\n  solution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an efficient model to predict a student's answer\ncorrectness given his past learning activities. Basically, I use both\ntransformer encoder and RNN to deal with time series input. The novel point of\nthe model is that it only uses the last input as query in transformer encoder,\ninstead of all sequence, which makes QK matrix multiplication in transformer\nEncoder to have O(L) time complexity, instead of O(L^2). It allows the model to\ninput longer sequence. Using this model I achieved the 1st place in the 'Riiid!\nAnswer Correctness Prediction' competition hosted on kaggle.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:10:31 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Jeon", "SeungKee", ""]]}, {"id": "2102.05085", "submitter": "Andrew Smart", "authors": "Atoosa Kasirzadeh, Andrew Smart", "title": "The Use and Misuse of Counterfactuals in Ethical Machine Learning", "comments": "9 pages, 1 table, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of counterfactuals for considerations of algorithmic fairness and\nexplainability is gaining prominence within the machine learning community and\nindustry. This paper argues for more caution with the use of counterfactuals\nwhen the facts to be considered are social categories such as race or gender.\nWe review a broad body of papers from philosophy and social sciences on social\nontology and the semantics of counterfactuals, and we conclude that the\ncounterfactual approach in machine learning fairness and social explainability\ncan require an incoherent theory of what social categories are. Our findings\nsuggest that most often the social categories may not admit counterfactual\nmanipulation, and hence may not appropriately satisfy the demands for\nevaluating the truth or falsity of counterfactuals. This is important because\nthe widespread use of counterfactuals in machine learning can lead to\nmisleading results when applied in high-stakes domains. Accordingly, we argue\nthat even though counterfactuals play an essential part in some causal\ninferences, their use for questions of algorithmic fairness and social\nexplanations can create more problems than they resolve. Our positive result is\na set of tenets about using counterfactuals for fairness and explanations in\nmachine learning.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 19:28:41 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Kasirzadeh", "Atoosa", ""], ["Smart", "Andrew", ""]]}, {"id": "2102.05230", "submitter": "Hideaki Hata", "authors": "Hideaki Hata, Nicole Novielli, Sebastian Baltes, Raula Gaikovina Kula,\n  Christoph Treude", "title": "GitHub Discussions: An Exploratory Study of Early Adoption", "comments": "37 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Discussions is a new feature of GitHub for asking questions or discussing\ntopics outside of specific Issues or Pull Requests. Before being available to\nall projects in December 2020, it had been tested on selected open source\nsoftware projects. To understand how developers use this novel feature, how\nthey perceive it, and how it impacts the development processes, we conducted a\nmixed-methods study based on early adopters of GitHub discussions from January\nuntil July 2020. We found that: (1) errors, unexpected behavior, and code\nreviews are prevalent discussion categories; (2) there is a positive\nrelationship between project member involvement and discussion frequency; (3)\ndevelopers consider GitHub Discussions useful but face the problem of topic\nduplication between Discussions and Issues; (4) Discussions play a crucial role\nin advancing the development of projects; and (5) positive sentiment in\nDiscussions is more frequent than in Stack Overflow posts. Our findings are a\nfirst step towards data-informed guidance for using GitHub Discussions, opening\nup avenues for future work on this novel communication channel.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 02:49:03 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 10:43:24 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Hata", "Hideaki", ""], ["Novielli", "Nicole", ""], ["Baltes", "Sebastian", ""], ["Kula", "Raula Gaikovina", ""], ["Treude", "Christoph", ""]]}, {"id": "2102.05290", "submitter": "Ryo Kawaoka", "authors": "Ryo Kawaoka, Daiki Chiba, Takuya Watanabe, Mitsuaki Akiyama, Tatsuya\n  Mori", "title": "A First Look at COVID-19 Domain Names: Origin and Implications", "comments": "9 pages, 4 figures, 4 tables. Accepted at the Passive and Active\n  Measurement Conference 2021 (PAM 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work takes a first look at domain names related to COVID-19 (Cov19doms\nin short), using a large-scale registered Internet domain name database, which\naccounts for 260M of distinct domain names registered for 1.6K of distinct\ntop-level domains. We extracted 167K of Cov19doms that have been registered\nbetween the end of December 2019 and the end of September 2020. We attempt to\nanswer the following research questions through our measurement study: RQ1: Is\nthe number of Cov19doms registrations correlated with the COVID-19 outbreaks?,\nRQ2: For what purpose do people register Cov19doms? Our chief findings are as\nfollows: (1) Similar to the global COVID-19 pandemic observed around April\n2020, the number of Cov19doms registrations also experienced the drastic\ngrowth, which, interestingly, pre-ceded the COVID-19 pandemic by about a month,\n(2) 70 % of active Cov19doms websites with visible content provided useful\ninformation such as health, tools, or product sales related to COVID-19, and\n(3) non-negligible number of registered Cov19doms was used for malicious\npurposes. These findings imply that it has become more challenging to\ndistinguish domain names registered for legitimate purposes from others and\nthat it is crucial to pay close attention to how Cov19doms will be used/misused\nin the future.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:19:36 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Kawaoka", "Ryo", ""], ["Chiba", "Daiki", ""], ["Watanabe", "Takuya", ""], ["Akiyama", "Mitsuaki", ""], ["Mori", "Tatsuya", ""]]}, {"id": "2102.05374", "submitter": "Pierre Le Bras", "authors": "Tanya Howden, Pierre Le Bras, Thomas S. Methven, Stefano Padilla, Mike\n  J. Chantler", "title": "Enhancing Reading Strategies by Exploring A Theme-based Approach to\n  Literature Surveys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Searching large digital repositories can be extremely frustrating, as common\nlist-based formats encourage users to adopt a convenience-sampling approach\nthat favours chance discovery and random search, over meaningful exploration.\nWe have designed a methodology that allows users to visually and thematically\nexplore corpora, while developing personalised holistic reading strategies. We\ndescribe the results of a three-phase qualitative study, in which experienced\nresearchers used our interactive visualisation approach to analyse a set of\npublications and select relevant themes and papers. Using in-depth\nsemi-structured interviews and stimulated recall, we found that users: (i)\nselected papers that they otherwise would not have read, (ii) developed a more\ncoherent reading strategy, and (iii) understood the thematic structure and\nrelationships between papers more effectively. Finally, we make six design\nrecommendations to enhance current digital repositories that we have shown\nencourage users to adopt a more holistic and thematic research approach.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 10:36:45 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Howden", "Tanya", ""], ["Bras", "Pierre Le", ""], ["Methven", "Thomas S.", ""], ["Padilla", "Stefano", ""], ["Chantler", "Mike J.", ""]]}, {"id": "2102.05445", "submitter": "Ciro Cattuto", "authors": "Vittoria Colizza, Eva Grill, Rafael Mikolajczyk, Ciro Cattuto, Adam\n  Kucharski, Steven Riley, Michelle Kendall, Katrina Lythgoe, Lucie\n  Abeler-D\\\"orner, Chris Wymant, David Bonsall, Luca Ferretti, Christophe\n  Fraser", "title": "Epidemiological and public health requirements for COVID-19 contact\n  tracing apps and their evaluation", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI physics.soc-ph q-bio.PE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital contact tracing is a public health intervention. It should be\nintegrated with local health policy, provide rapid and accurate notifications\nto exposed individuals, and encourage high app uptake and adherence to\nquarantine. Real-time monitoring and evaluation of effectiveness of app-based\ncontact tracing is key for improvement and public trust.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:08:34 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Colizza", "Vittoria", ""], ["Grill", "Eva", ""], ["Mikolajczyk", "Rafael", ""], ["Cattuto", "Ciro", ""], ["Kucharski", "Adam", ""], ["Riley", "Steven", ""], ["Kendall", "Michelle", ""], ["Lythgoe", "Katrina", ""], ["Abeler-D\u00f6rner", "Lucie", ""], ["Wymant", "Chris", ""], ["Bonsall", "David", ""], ["Ferretti", "Luca", ""], ["Fraser", "Christophe", ""]]}, {"id": "2102.05470", "submitter": "Alberto Bracci", "authors": "Alberto Bracci, Matthieu Nadini, Maxwell Aliapoulios, Damon McCoy, Ian\n  Gray, Alexander Teytelboym, Angela Gallo, Andrea Baronchelli", "title": "Dark Web Marketplaces and COVID-19: The vaccines", "comments": "For the \"before the vaccine\" report see\n  https://doi.org/10.1140/epjds/s13688-021-00259-w", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing COVID-19 vaccination campaign has so far targeted less than 10%\nof the world population, and, even in countries where the campaign has started,\nmany citizens will not receive their doses for many months. There is clear\nevidence that previous shortages of COVID-19 related goods (e.g., masks and\nCOVID-19 tests) and services pushed customers, and vendors, towards illicit\nonline trade occurring on dark web marketplaces. Is this happening also with\nvaccines? Here, we report on our effort to continuously monitor 164 dark web\nmarketplaces. By April 20, we found 214 listings offering a COVID-19 vaccine,\n77 of which offering officially approved vaccines and 25 fabricated proofs of\nvaccination. The number of currently active listings is 34, including eight\nlistings offering the Pfizer/BioNTech vaccine, six the Moderna, two the\nAstraZeneca/Oxford, two the Sputinik V vaccine, and nine offering fabricated\nproofs of vaccination. Illicit trade of uncertified COVID-19 vaccines poses a\nconcrete threat to public health and risks to undermine public confidence\ntowards vaccination.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:52:54 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 11:10:24 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 14:58:09 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bracci", "Alberto", ""], ["Nadini", "Matthieu", ""], ["Aliapoulios", "Maxwell", ""], ["McCoy", "Damon", ""], ["Gray", "Ian", ""], ["Teytelboym", "Alexander", ""], ["Gallo", "Angela", ""], ["Baronchelli", "Andrea", ""]]}, {"id": "2102.05851", "submitter": "Joseph Chow", "authors": "Bingqing Liu, Theodoros P. Pantelidis, Stephanie Tam, Joseph Y. J.\n  Chow", "title": "An electric vehicle charging station access equilibrium model with M/D/C\n  queueing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the dependency of electric vehicle (EV) fleets on charging station\navailability, charging infrastructure remains limited in many cities. Three\ncontributions are made. First, we propose an EV-to-charging station user\nequilibrium (UE) assignment model with a M/D/C queue approximation as a\nnondifferentiable nonlinear program. Second, to address the\nnon-differentiability of the queue delay function, we propose an original\nsolution algorithm based on the derivative-free Method of Successive Averages.\nComputational tests with a toy network show that the model converges to a UE. A\nworking code in Python is provided free on Github with detailed test cases.\nThird, the model is applied to the large-scale case study of NYC DCAS fleet and\nEV charging station configuration as of July 8, 2020, which includes unique,\nreal data for 563 Level 2 chargers and 4 DCFCs owned by NYC and 1484 EVs owned\nby NYC fleets distributed over 512 TAZs. The arrival rates of the assignment\nmodel are calibrated in the base scenario to fit an observed average\nutilization ratio of 7.6% in NYC. The model is then applied to compare charging\nstation investment policies of DCFCs to Level 2 charging stations based on two\nalternative criteria. Results suggest a policy based on selecting locations\nwith high utilization ratio instead of with high queue delay.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 05:23:36 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Liu", "Bingqing", ""], ["Pantelidis", "Theodoros P.", ""], ["Tam", "Stephanie", ""], ["Chow", "Joseph Y. J.", ""]]}, {"id": "2102.06109", "submitter": "Sean McGregor", "authors": "Claire Leibowicz, Sean McGregor, Aviv Ovadya", "title": "The Deepfake Detection Dilemma: A Multistakeholder Exploration of\n  Adversarial Dynamics in Synthetic Media", "comments": "11 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Synthetic media detection technologies label media as either synthetic or\nnon-synthetic and are increasingly used by journalists, web platforms, and the\ngeneral public to identify misinformation and other forms of problematic\ncontent. As both well-resourced organizations and the non-technical general\npublic generate more sophisticated synthetic media, the capacity for purveyors\nof problematic content to adapt induces a \\newterm{detection dilemma}: as\ndetection practices become more accessible, they become more easily\ncircumvented. This paper describes how a multistakeholder cohort from academia,\ntechnology platforms, media entities, and civil society organizations active in\nsynthetic media detection and its socio-technical implications evaluates the\ndetection dilemma. Specifically, we offer an assessment of detection contexts\nand adversary capacities sourced from the broader, global AI and media\nintegrity community concerned with mitigating the spread of harmful synthetic\nmedia. A collection of personas illustrates the intersection between\nunsophisticated and highly-resourced sponsors of misinformation in the context\nof their technical capacities. This work concludes that there is no \"best\"\napproach to navigating the detector dilemma, but derives a set of implications\nfrom multistakeholder input to better inform detection process decisions and\npolicies, in practice.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 16:44:09 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Leibowicz", "Claire", ""], ["McGregor", "Sean", ""], ["Ovadya", "Aviv", ""]]}, {"id": "2102.06362", "submitter": "Wenjing Chu", "authors": "Wenjing Chu", "title": "A Decentralized Approach Towards Responsible AI in Social Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For AI technology to fulfill its full promises, we must design effective\nmechanisms into the AI systems to support responsible AI behavior and curtail\npotential irresponsible use, e.g. in areas of privacy protection, human\nautonomy, robustness, and prevention of biases and discrimination in automated\ndecision making. In this paper, we present a framework that provides\ncomputational facilities for parties in a social ecosystem to produce the\ndesired responsible AI behaviors. To achieve this goal, we analyze AI systems\nat the architecture level and propose two decentralized cryptographic\nmechanisms for an AI system architecture: (1) using Autonomous Identity to\nempower human users, and (2) automating rules and adopting conventions within\nsocial institutions. We then propose a decentralized approach and outline the\nkey concepts and mechanisms based on Decentralized Identifier (DID) and\nVerifiable Credentials (VC) for a general-purpose computational infrastructure\nto realize these mechanisms. We argue the case that a decentralized approach is\nthe most promising path towards Responsible AI from both the computer science\nand social science perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 06:33:42 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Chu", "Wenjing", ""]]}, {"id": "2102.06505", "submitter": "Kristoffer Nielbo", "authors": "Kristoffer L. Nielbo, Frida Haestrup, Kenneth C. Enevoldsen, Peter B.\n  Vahlstrup, Rebekah B. Baglini, Andreas Roepstorff", "title": "When no news is bad news -- Detection of negative events from news media\n  content", "comments": "arXiv admin note: text overlap with arXiv:2101.02956", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the first wave of Covid-19 information decoupling could be observed in\nthe flow of news media content. The corollary of the content alignment within\nand between news sources experienced by readers (i.e., all news transformed\ninto Corona-news), was that the novelty of news content went down as media\nfocused monotonically on the pandemic event. This all-important Covid-19 news\ntheme turned out to be quite persistent as the pandemic continued, resulting in\nthe, from a news media's perspective, paradoxical situation where the same news\nwas repeated over and over. This information phenomenon, where novelty\ndecreases and persistence increases, has previously been used to track change\nin news media, but in this study we specifically test the claim that new\ninformation decoupling behavior of media can be used to reliably detect change\nin news media content originating in a negative event, using a Bayesian\napproach to change point detection.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:14:44 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Nielbo", "Kristoffer L.", ""], ["Haestrup", "Frida", ""], ["Enevoldsen", "Kenneth C.", ""], ["Vahlstrup", "Peter B.", ""], ["Baglini", "Rebekah B.", ""], ["Roepstorff", "Andreas", ""]]}, {"id": "2102.06516", "submitter": "Jonathan Bright", "authors": "Lisa Oswald, Jonathan Bright", "title": "How do climate change skeptics engage with opposing views? Understanding\n  mechanisms of social identity and cognitive dissonance in an online forum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does engagement with opposing views help break down ideological `echo\nchambers'; or does it backfire and reinforce them? This question remains\ncritical as academics, policymakers and activists grapple with the question of\nhow to regulate political discussion on social media. In this study, we\ncontribute to the debate by examining the impact of opposing views within a\nmajor climate change skeptic online community on Reddit. A large sample of\nposts (N = 3000) was manually coded as either dissonant or consonant which\nallowed the automated classification of the full dataset of more than 50,000\nposts, with codes inferred from linked websites. We find that ideologically\ndissonant submissions act as a stimulant to activity in the community: they\nreceived more attention (comments) than consonant submissions, even though they\nreceived lower scores through up-voting and down-voting. Users who engaged with\ndissonant submissions were also more likely to return to the forum. Consistent\nwith identity theory, confrontation with opposing views triggered activity in\nthe forum, particularly among users that are highly engaged with the community.\nIn light of the findings, theory of social identity and echo chambers is\ndiscussed and enhanced.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:39:00 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Oswald", "Lisa", ""], ["Bright", "Jonathan", ""]]}, {"id": "2102.06619", "submitter": "Alessio Cardillo", "authors": "Mariana Macedo and Laura Lotero and Alessio Cardillo and Ronaldo\n  Menezes and Hugo Barbosa", "title": "Differences in the spatial landscape of urban mobility: gender and\n  socioeconomic perspectives", "comments": "main + supplementary material. Submitted for publication. Comments\n  are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of our routines and activities are linked to our ability to move; be it\ncommuting to work, shopping for groceries, or meeting friends. Yet, factors\nthat limit the individuals' ability to fully realise their mobility needs will\nultimately affect the opportunities they can have access to (e.g. cultural\nactivities, professional interactions). One important aspect frequently\noverlooked in human mobility studies is how gender-centred issues can amplify\nother sources of mobility disadvantages (e.g. socioeconomic inequalities),\nunevenly affecting the pool of opportunities men and women have access to. In\nthis work, we leverage on a combination of computational, statistical, and\ninformation-theoretical approaches to investigate the existence of systematic\ndiscrepancies in the mobility diversity (i.e. the diversity of travel\ndestinations) of (1) men and women from different socioeconomic backgrounds,\nand (2) work and non-work travels. Our analysis is based on datasets containing\nmultiple instances of large-scale, official, travel surveys carried out in\nthree major metropolitan areas in South America: Medell\\'in and Bogot\\'a in\nColombia, and S\\~ao Paulo in Brazil. Our results indicate the presence of\ngeneral discrepancies in the urban mobility diversities related to the gender\nand socioeconomic characteristics of the individuals. Lastly, this paper sheds\nnew light on the possible origins of gender-level human mobility inequalities,\ncontributing to the general understanding of disaggregated patterns in human\nmobility.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 16:55:40 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 04:38:16 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Macedo", "Mariana", ""], ["Lotero", "Laura", ""], ["Cardillo", "Alessio", ""], ["Menezes", "Ronaldo", ""], ["Barbosa", "Hugo", ""]]}, {"id": "2102.06674", "submitter": "Jesus Emeterio Navarro-Barrientos", "authors": "Alexander Reichenbach and J.-Emeterio Navarro-B", "title": "A model for traffic incident prediction using emergency braking data", "comments": "6 pages, 7 figures, accepted for publication in the 32nd IEEE\n  Intelligent Vehicles Symposium (https://2021.ieee-iv.org/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a model for traffic incident prediction. Specifically,\nwe address the fundamental problem of data scarcity in road traffic accident\nprediction by training our model on emergency braking events instead of\naccidents. Based on relevant risk factors for traffic accidents and\ncorresponding data categories, we evaluate different options for preprocessing\nsparse data and different Machine Learning models. Furthermore, we present a\nprototype implementing a traffic incident prediction model for Germany based on\nemergency braking data from Mercedes-Benz vehicles as well as weather, traffic\nand road data, respectively. After model evaluation and optimisation, we found\nthat a Random Forest model trained on artificially balanced (under-sampled)\ndata provided the highest classification accuracy of 85% on the original\nimbalanced data. Finally, we present our conclusions and discuss further work;\nfrom gathering more data over a longer period of time to build stronger\nclassification systems, to addition of internal factors such as the driver's\nvisual and cognitive attention.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 18:17:12 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 22:14:29 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Reichenbach", "Alexander", ""], ["Navarro-B", "J. -Emeterio", ""]]}, {"id": "2102.06764", "submitter": "Vedant Nanda", "authors": "Valeriia Cherepanova and Vedant Nanda and Micah Goldblum and John P.\n  Dickerson and Tom Goldstein", "title": "Technical Challenges for Training Fair Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning algorithms have been widely deployed across applications,\nmany concerns have been raised over the fairness of their predictions,\nespecially in high stakes settings (such as facial recognition and medical\nimaging). To respond to these concerns, the community has proposed and\nformalized various notions of fairness as well as methods for rectifying unfair\nbehavior. While fairness constraints have been studied extensively for\nclassical models, the effectiveness of methods for imposing fairness on deep\nneural networks is unclear. In this paper, we observe that these large models\noverfit to fairness objectives, and produce a range of unintended and\nundesirable consequences. We conduct our experiments on both facial recognition\nand automated medical diagnosis datasets using state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 20:36:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cherepanova", "Valeriia", ""], ["Nanda", "Vedant", ""], ["Goldblum", "Micah", ""], ["Dickerson", "John P.", ""], ["Goldstein", "Tom", ""]]}, {"id": "2102.06836", "submitter": "Venkatesh Sivaraman", "authors": "Julia Wu, Venkatesh Sivaraman, Dheekshita Kumar, Juan M. Banda and\n  David Sontag", "title": "Pulse of the Pandemic: Iterative Topic Filtering for Clinical\n  Information Extraction from Social Media", "comments": "24 pages, 5 figures. To be published in the Journal of Biomedical\n  Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid evolution of the COVID-19 pandemic has underscored the need to\nquickly disseminate the latest clinical knowledge during a public-health\nemergency. One surprisingly effective platform for healthcare professionals\n(HCPs) to share knowledge and experiences from the front lines has been social\nmedia (for example, the \"#medtwitter\" community on Twitter). However,\nidentifying clinically-relevant content in social media without manual labeling\nis a challenge because of the sheer volume of irrelevant data. We present an\nunsupervised, iterative approach to mine clinically relevant information from\nsocial media data, which begins by heuristically filtering for HCP-authored\ntexts and incorporates topic modeling and concept extraction with MetaMap. This\napproach identifies granular topics and tweets with high clinical relevance\nfrom a set of about 52 million COVID-19-related tweets from January to mid-June\n2020. We also show that because the technique does not require manual labeling,\nit can be used to identify emerging topics on a week-to-week basis. Our method\ncan aid in future public-health emergencies by facilitating knowledge transfer\namong healthcare workers in a rapidly-changing information environment, and by\nproviding an efficient and unsupervised way of highlighting potential areas for\nclinical research.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 01:01:04 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 15:50:35 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wu", "Julia", ""], ["Sivaraman", "Venkatesh", ""], ["Kumar", "Dheekshita", ""], ["Banda", "Juan M.", ""], ["Sontag", "David", ""]]}, {"id": "2102.07022", "submitter": "Ivan Sendin", "authors": "Ivan da Silva Sendin and Rodrigo Sanches Miani", "title": "Towards reliable and transparent vaccine phase III trials with smart\n  contracts", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transforming a vaccine concept into a real vaccine product is a complicated\nprocess and includes finding suitable antigens and regulatory, technical, and\nmanufacturing obstacles. A relevant issue within this scope is the clinical\ntrial process. Monitoring and ensuring the integrity of trial data using the\ntraditional system is not always feasible. The search for a vaccine against the\ncoronavirus SARS-CoV-2 illustrates this situation. The scientific credibility\nof findings from several vaccines' clinical trials contributed to distorted\nperceptions concerning the benefits and risks of the drug. This scenario is\nideal for applying technologies such as Blockchain and Smart Contracts in\nhealthcare issues. This paper proposes a protocol based on Smart Contracts,\nnamed VaccSC, to enable transparency, accounting, and confidentiality to Phase\nIII of vaccine experiments. The protocol was implemented in Solidity language,\nand results show that the VaccSC enables double-blindness, randomization, and\nthe auditability of clinical data, even in the presence of dishonest\nparticipants.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 22:38:36 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sendin", "Ivan da Silva", ""], ["Miani", "Rodrigo Sanches", ""]]}, {"id": "2102.07119", "submitter": "Stefan Hochwarter", "authors": "Stefan Hochwarter", "title": "Sociotechnical Challenges of eHealth Technology for Patient\n  Self-Management: A Systematic Review", "comments": "Volume 5 HEALTHINF", "journal-ref": "Proceedings of the 14th International Joint Conference on\n  Biomedical Engineering Systems and Technologies (2021)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Ageing of society and increase of time spent with chronic conditions\nchallenge the traditional long-term care model. Assistive technology and\neHealth are seen to play an important role when addressing these challenges.\nOne prominent example are patient self-management systems. These systems not\nonly transform the way patients with chronic conditions interact with the\nhealthcare system, but also change work practices of care providers. This\nliterature review addresses sociotechnical challenges of eHealth technologies\nwith a strong collaborative component. As a result, four themes are identified\nand discussed.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 10:17:26 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hochwarter", "Stefan", ""]]}, {"id": "2102.07288", "submitter": "Tarun Mangla", "authors": "Tarun Mangla (1), Esther Showalter (2), Vivek Adarsh (2), Kipp Jones\n  (3), Morgan Vigil-Hayes (4), Elizabeth Belding (2), Ellen Zegura (5) ((1)\n  University of Chicago, (2) University of California, Santa Barbara (3)\n  Skyhook, (4) Northern Arizona University, (5) Georgia Institute of\n  Technology)", "title": "A Tale of Three Datasets: Towards Characterizing Mobile Broadband Access\n  in the United States", "comments": "9 pages, 4 figures, submitted to: Communications of the ACM -\n  Contributed Article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding and improving mobile broadband deployment is critical to\nbridging the digital divide and targeting future investments. Yet accurately\nmapping mobile coverage is challenging. In 2019, the Federal Communications\nCommission (FCC) released a report on the progress of mobile broadband\ndeployment in the United States. This report received a significant amount of\ncriticism with claims that the cellular coverage, mainly available through\nLong-Term Evolution (LTE), was over-reported in some areas, especially those\nthat are rural and/or tribal [12]. We evaluate the validity of this criticism\nusing a quantitative analysis of both the dataset from which the FCC based its\nreport and a crowdsourced LTE coverage dataset. Our analysis is focused on the\nstate of New Mexico, a region characterized by diverse mix of\ndemographics-geography and poor broadband access. We then performed a\ncontrolled measurement campaign in northern New Mexico during May 2019. Our\nfindings reveal significant disagreement between the crowdsourced dataset and\nthe FCC dataset regarding the presence of LTE coverage in rural and tribal\ncensus blocks, with the FCC dataset reporting higher coverage than the\ncrowdsourced dataset. Interestingly, both the FCC and the crowdsourced data\nreport higher coverage compared to our on-the-ground measurements. Based on\nthese findings, we discuss our recommendations for improved LTE coverage\nmeasurements, whose importance has only increased in the COVID-19 era of\nperforming work and school from home, especially in rural and tribal areas.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 00:54:29 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Mangla", "Tarun", ""], ["Showalter", "Esther", ""], ["Adarsh", "Vivek", ""], ["Jones", "Kipp", ""], ["Vigil-Hayes", "Morgan", ""], ["Belding", "Elizabeth", ""], ["Zegura", "Ellen", ""]]}, {"id": "2102.07306", "submitter": "Mohammad Al-Ramahi", "authors": "Ramya Daddanala, Vekata Mannava, Lo'ai Tawlbeh, Mohammad Al-Ramahi", "title": "Vehicle to Vehicle (V2V) Communication Protocol: Components, Benefits,\n  Challenges, Safety and Machine Learning Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vehicle to vehicle communication is a new technology that enables vehicles on\nroads to communicate with each other to reduce traffic, accidents and ensure\nthe safety of people. The main objective of vehicle-to-vehicle communication\nprotocol is to create an effective communication system for intelligent\ntransport systems. The advancement in technology made vehicle industries to\ndevelop automatic vehicles that can share real-time information and protect\neach other from accidents. This research paper gives an explanation about the\nvehicle-to-vehicle communication process, benefits, and the challenges in\nenabling vehicle-to-vehicle communication as well as safety and machine\nlearning applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 02:24:24 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Daddanala", "Ramya", ""], ["Mannava", "Vekata", ""], ["Tawlbeh", "Lo'ai", ""], ["Al-Ramahi", "Mohammad", ""]]}, {"id": "2102.07385", "submitter": "Tiziano Piccardi", "authors": "Tiziano Piccardi, Miriam Redi, Giovanni Colavizza, Robert West", "title": "On the Value of Wikipedia as a Gateway to the Web", "comments": "The Web Conference WWW 2021, 12 pages", "journal-ref": null, "doi": "10.1145/3442381.3450136", "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By linking to external websites, Wikipedia can act as a gateway to the Web.\nTo date, however, little is known about the amount of traffic generated by\nWikipedia's external links. We fill this gap in a detailed analysis of usage\nlogs gathered from Wikipedia users' client devices. Our analysis proceeds in\nthree steps: First, we quantify the level of engagement with external links,\nfinding that, in one month, English Wikipedia generated 43M clicks to external\nwebsites, in roughly even parts via links in infoboxes, cited references, and\narticle bodies. Official links listed in infoboxes have by far the highest\nclick-through rate (CTR), 2.47% on average. In particular, official links\nassociated with articles about businesses, educational institutions, and\nwebsites have the highest CTR, whereas official links associated with articles\nabout geographical content, television, and music have the lowest CTR. Second,\nwe investigate patterns of engagement with external links, finding that\nWikipedia frequently serves as a stepping stone between search engines and\nthird-party websites, effectively fulfilling information needs that search\nengines do not meet. Third, we quantify the hypothetical economic value of the\nclicks received by external websites from English Wikipedia, by estimating that\nthe respective website owners would need to pay a total of $7--13 million per\nmonth to obtain the same volume of traffic via sponsored search. Overall, these\nfindings shed light on Wikipedia's role not only as an important source of\ninformation, but also as a high-traffic gateway to the broader Web ecosystem.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 08:08:36 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Piccardi", "Tiziano", ""], ["Redi", "Miriam", ""], ["Colavizza", "Giovanni", ""], ["West", "Robert", ""]]}, {"id": "2102.07849", "submitter": "Sara Abdali", "authors": "Sara Abdali, Rutuja Gurav, Siddharth Menon, Daniel Fonseca, Negin\n  Entezari, Neil Shah, Evangelos E. Papalexakis", "title": "Identifying Misinformation from Website Screenshots", "comments": null, "journal-ref": "The International AAAI Conference on Web and Social Media (ICWSM)\n  2021", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can the look and the feel of a website give information about the\ntrustworthiness of an article? In this paper, we propose to use a promising,\nyet neglected aspect in detecting the misinformativeness: the overall look of\nthe domain webpage. To capture this overall look, we take screenshots of news\narticles served by either misinformative or trustworthy web domains and\nleverage a tensor decomposition based semi-supervised classification technique.\nThe proposed approach i.e., VizFake is insensitive to a number of image\ntransformations such as converting the image to grayscale, vectorizing the\nimage and losing some parts of the screenshots. VizFake leverages a very small\namount of known labels, mirroring realistic and practical scenarios, where\nlabels (especially for known misinformative articles), are scarce and quickly\nbecome dated. The F1 score of VizFake on a dataset of 50k screenshots of news\narticles spanning more than 500 domains is roughly 85% using only 5% of ground\ntruth labels. Furthermore, tensor representations of VizFake, obtained in an\nunsupervised manner, allow for exploratory analysis of the data that provides\nvaluable insights into the problem. Finally, we compare VizFake with deep\ntransfer learning, since it is a very popular black-box approach for image\nclassification and also well-known text text-based methods. VizFake achieves\ncompetitive accuracy with deep transfer learning models while being two orders\nof magnitude faster and not requiring laborious hyper-parameter tuning.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 21:05:11 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 22:32:32 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Abdali", "Sara", ""], ["Gurav", "Rutuja", ""], ["Menon", "Siddharth", ""], ["Fonseca", "Daniel", ""], ["Entezari", "Negin", ""], ["Shah", "Neil", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2102.07857", "submitter": "Sara Abdali", "authors": "Sara Abdali, Neil Shah, Evangelos E. Papalexakis", "title": "KNH: Multi-View Modeling with K-Nearest Hyperplanes Graph for\n  Misinformation Detection", "comments": null, "journal-ref": "Second International TrueFact Workshop 2020: Making a Credible Web\n  for Tomorrow", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graphs are one of the most efficacious structures for representing datapoints\nand their relations, and they have been largely exploited for different\napplications. Previously, the higher-order relations between the nodes have\nbeen modeled by a generalization of graphs known as hypergraphs. In\nhypergraphs, the edges are defined by a set of nodes i.e., hyperedges to\ndemonstrate the higher order relationships between the data. However, there is\nno explicit higher-order generalization for nodes themselves. In this work, we\nintroduce a novel generalization of graphs i.e., K-Nearest Hyperplanes graph\n(KNH) where the nodes are defined by higher order Euclidean subspaces for\nmulti-view modeling of the nodes. In fact, in KNH, nodes are hyperplanes or\nmore precisely m-flats instead of datapoints. We experimentally evaluate the\nKNH graph on two multi-aspect datasets for misinformation detection. The\nexperimental results suggest that multi-view modeling of articles using KNH\ngraph outperforms the classic KNN graph in terms of classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 21:41:12 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Abdali", "Sara", ""], ["Shah", "Neil", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "2102.07900", "submitter": "Shaoshan Liu", "authors": "Shaoshan Liu, Jean-Luc Gaudiot, Hironori Kasahara", "title": "Engineering Education in the Age of Autonomous Machines", "comments": "to appear in IEEE Computer Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, we have observed a huge supply-demand gap for\nautonomous driving engineers. The core problem is that autonomous driving is\nnot one single technology but rather a complex system integrating many\ntechnologies, and no one single academic department can provide comprehensive\neducation in this field. We advocate to create a cross-disciplinary program to\nexpose students with technical background in computer science, computer\nengineering, electrical engineering, as well as mechanical engineering. On top\nof the cross-disciplinary technical foundation, a capstone project that\nprovides students with hands-on experiences of working with a real autonomous\nvehicle is required to consolidate the technical foundation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 00:44:14 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Liu", "Shaoshan", ""], ["Gaudiot", "Jean-Luc", ""], ["Kasahara", "Hironori", ""]]}, {"id": "2102.08004", "submitter": "Kurtis Haut", "authors": "Taylan Sen, Kurtis Haut, Denis Lomakin and Ehsan Hoque", "title": "A Mental Trespass? Unveiling Truth, Exposing Thoughts and Threatening\n  Civil Liberties with Non-Invasive AI Lie Detection", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Imagine an app on your phone or computer that can tell if you are being\ndishonest, just by processing affective features of your facial expressions,\nbody movements, and voice. People could ask about your political preferences,\nyour sexual orientation, and immediately determine which of your responses are\nhonest and which are not. In this paper we argue why artificial\nintelligence-based, non-invasive lie detection technologies are likely to\nexperience a rapid advancement in the coming years, and that it would be\nirresponsible to wait any longer before discussing its implications. Legal and\npopular perspectives are reviewed to evaluate the potential for these\ntechnologies to cause societal harm. To understand the perspective of a\nreasonable person, we conducted a survey of 129 individuals, and identified\nconsent and accuracy as the major factors in their decision-making process\nregarding the use of these technologies. In our analysis, we distinguish two\ntypes of lie detection technology, accurate truth metering and accurate thought\nexposing. We generally find that truth metering is already largely within the\nscope of existing US federal and state laws, albeit with some notable\nexceptions. In contrast, we find that current regulation of thought exposing\ntechnologies is ambiguous and inadequate to safeguard civil liberties. In order\nto rectify these shortcomings, we introduce the legal concept of mental\ntrespass and use this concept as the basis for proposed regulation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 08:09:38 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Sen", "Taylan", ""], ["Haut", "Kurtis", ""], ["Lomakin", "Denis", ""], ["Hoque", "Ehsan", ""]]}, {"id": "2102.08054", "submitter": "Kurtis Haut", "authors": "Kurtis Haut, Caleb Wohn, Victor Antony, Aidan Goldfarb, Melissa Welsh,\n  Dillanie Sumanthiran, Ji-ze Jang, Md. Rafayet Ali and Ehsan Hoque", "title": "Could you become more credible by being White? Assessing Impact of Race\n  on Credibility with Deepfakes", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Computer mediated conversations (e.g., videoconferencing) is now the new\nmainstream media. How would credibility be impacted if one could change their\nrace on the fly in these environments? We propose an approach using Deepfakes\nand a supporting GAN architecture to isolate visual features and alter racial\nperception. We then crowd-sourced over 800 survey responses to measure how\ncredibility was influenced by changing the perceived race. We evaluate the\neffect of showing a still image of a Black person versus a still image of a\nWhite person using the same audio clip for each survey. We also test the effect\nof showing either an original video or an altered video where the appearance of\nthe person in the original video is modified to appear more White. We measure\ncredibility as the percent of participant responses who believed the speaker\nwas telling the truth. We found that changing the race of a person in a static\nimage has negligible impact on credibility. However, the same manipulation of\nrace on a video increases credibility significantly (61\\% to 73\\% with p $<$\n0.05). Furthermore, a VADER sentiment analysis over the free response survey\nquestions reveals that more positive sentiment is used to justify the\ncredibility of a White individual in a video.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 10:05:11 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Haut", "Kurtis", ""], ["Wohn", "Caleb", ""], ["Antony", "Victor", ""], ["Goldfarb", "Aidan", ""], ["Welsh", "Melissa", ""], ["Sumanthiran", "Dillanie", ""], ["Jang", "Ji-ze", ""], ["Ali", "Md. Rafayet", ""], ["Hoque", "Ehsan", ""]]}, {"id": "2102.08086", "submitter": "Edward Oughton", "authors": "Edward J. Oughton and Ashutosh Jha", "title": "Supportive 5G Infrastructure Policies are Essential for Universal 6G:\n  Assessment using an Open-source Techno-economic Simulation Model utilizing\n  Remote Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY cs.NI q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Work has now begun on the sixth generation of cellular technologies (`6G`)\nand cost-efficient global broadband coverage is already becoming a key pillar.\nIndeed, we are still far from providing universal and affordable broadband\nconnectivity, despite this being a key part of the Sustainable Development\nGoals (Target 9.c). Currently, both Mobile Network Operators and governments\nstill lack independent analysis of the strategies that can help achieve this\ntarget with the cellular technologies available (4G and 5G). Therefore, this\npaper undertakes quantitative assessment demonstrating how current 5G policies\naffect universal broadband, as well as drawing conclusions over how decisions\nmade now affect future evolution to 6G. Using a method based on an open-source\ntechno-economic codebase, combining remote sensing with least-cost network\nalgorithms, performance analytics are provided for different 4G and 5G\nuniversal broadband strategies. As an example, the assessment approach is\napplied to India, the world`s second-largest mobile market and a country with\nvery high spectrum prices. The results demonstrate the trade-offs between\ntechnological decisions. This includes demonstrating how important current\ninfrastructure policy is, particularly given fiber backhaul will be essential\nfor delivering 6G quality of service. We find that by eliminating the spectrum\nlicensing costs, 100% 5G population coverage can viably be achieved using fiber\nbackhaul. Therefore, supportive infrastructure policies are essential in\nproviding a superior foundation for evolution to future cellular generation,\nsuch as 6G.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 11:15:46 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 12:18:45 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 10:45:46 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Oughton", "Edward J.", ""], ["Jha", "Ashutosh", ""]]}, {"id": "2102.08132", "submitter": "Chris Norval", "authors": "Chris Norval, Jennifer Cobbe, Jatinder Singh", "title": "Towards an accountable Internet of Things: A call for reviewability", "comments": "To appear in: Privacy by Design for the Internet of Things. Cite as:\n  Norval C, Cobbe J, and Singh, J. Towards an accountable Internet of Things: A\n  call for reviewability. In Privacy by Design for the Internet of Things:\n  Building accountability and security; London, UK: IET; 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the IoT becomes increasingly ubiquitous, concerns are being raised about\nhow IoT systems are being built and deployed. Connected devices will generate\nvast quantities of data, which drive algorithmic systems and result in\nreal-world consequences. Things will go wrong, and when they do, how do we\nidentify what happened, why they happened, and who is responsible? Given the\ncomplexity of such systems, where do we even begin?\n  This chapter outlines aspects of accountability as they relate to IoT, in the\ncontext of the increasingly interconnected and data-driven nature of such\nsystems. Specifically, we argue the urgent need for mechanisms - legal,\ntechnical, and organisational - that facilitate the review of IoT systems. Such\nmechanisms work to support accountability, by enabling the relevant\nstakeholders to better understand, assess, interrogate and challenge the\nconnected environments that increasingly pervade our world.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 13:09:07 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 13:57:23 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Norval", "Chris", ""], ["Cobbe", "Jennifer", ""], ["Singh", "Jatinder", ""]]}, {"id": "2102.08137", "submitter": "Hongyan Wu", "authors": "Jie Zhang, Kazumitsu Nawata, Hongyan Wu", "title": "Spatio-Temporal Multi-step Prediction of Influenza Outbreaks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Flu circulates all over the world. The worldwide infection places a\nsubstantial burden on people's health every year. Regardless of the\ncharacteristic of the worldwide circulation of flu, most previous studies\nfocused on regional prediction of flu outbreaks. The methodology of considering\nthe spatio-temporal correlation could help forecast flu outbreaks more\nprecisely. Furthermore, forecasting a long-term flu outbreak, and understanding\nflu infection trends more accurately could help hospitals, clinics, and\npharmaceutical companies to better prepare for annual flu outbreaks. Predicting\na sequence of values in the future, namely, the multi-step prediction of flu\noutbreaks should cause concern. Therefore, we highlight the importance of\ndeveloping spatio-temporal methodologies to perform multi-step prediction of\nworldwide flu outbreaks. We compared the MAPEs of SVM, RF, LSTM models of\npredicting flu data of the 1-4 weeks ahead with and without other countries'\nflu data. We found the LSTM models achieved the lowest MAPEs in most cases. As\nfor countries in the Southern hemisphere, the MAPEs of predicting flu data with\nother countries are higher than those of predicting without other countries.\nFor countries in the Northern hemisphere, the MAPEs of predicting flu data of\nthe 2-4 weeks ahead with other countries are lower than those of predicting\nwithout other countries; and the MAPEs of predicting flu data of the 1-weeks\nahead with other countries are higher than those of predicting without other\ncountries, except for the UK. In this study, we performed the spatio-temporal\nmulti-step prediction of influenza outbreaks. The methodology considering the\nspatio-temporal features improves the multi-step prediction of flu outbreaks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 13:17:11 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Zhang", "Jie", ""], ["Nawata", "Kazumitsu", ""], ["Wu", "Hongyan", ""]]}, {"id": "2102.08262", "submitter": "Andry Alamsyah", "authors": "Alisya Putri Rabbani, Andry Alamsyah, Sri Widiyanesti", "title": "An Effort to Measure Customer Relationship Performance in Indonesia's\n  Fintech Industry", "comments": "5 pages, 2 figures, 5 tables", "journal-ref": "The 11th SCBTII 2020 : Sustainable Collaboration in Business,\n  Technology, Information and Innovation presents Virtual International\n  Conference", "doi": null, "report-no": null, "categories": "econ.GN cs.CY cs.LG cs.SI q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The availability of social media simplifies the companies-customers\nrelationship. An effort to engage customers in conversation networks using\nsocial media is called Social Customer Relationship Management (SCRM). Social\nNetwork Analysis helps to understand network characteristics and how active the\nconversation network on social media. Calculating its network properties is\nbeneficial for measuring customer relationship performance. Financial\nTechnology, a new emerging industry that provides digital-based financial\nservices utilize social media to interact with its customers. Measuring SCRM\nperformance is needed in order to stay competitive among others. Therefore, we\naim to explore the SCRM performance of the Indonesia Fintech company. In terms\nof discovering the market majority thought in conversation networks, we perform\nsentiment analysis by classifying into positive and negative opinion. As case\nstudies, we investigate Twitter conversations about GoPay, OVO, Dana, and\nLinkAja during the observation period from 1st October until 1st November 2019.\nThe result of this research is beneficial for business intelligence purposes\nespecially in managing relationships with customers.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 16:33:46 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Rabbani", "Alisya Putri", ""], ["Alamsyah", "Andry", ""], ["Widiyanesti", "Sri", ""]]}, {"id": "2102.08368", "submitter": "David Jurgens", "authors": "Jiajun Bao, Junjie Wu, Yiming Zhang, Eshwar Chandrasekharan, and David\n  Jurgens", "title": "Conversations Gone Alright: Quantifying and Predicting Prosocial\n  Outcomes in Online Conversations", "comments": "Accepted for Publication at the Web Conference 2021; 12 pages", "journal-ref": null, "doi": "10.1145/3442381.3450122", "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online conversations can go in many directions: some turn out poorly due to\nantisocial behavior, while others turn out positively to the benefit of all.\nResearch on improving online spaces has focused primarily on detecting and\nreducing antisocial behavior. Yet we know little about positive outcomes in\nonline conversations and how to increase them-is a prosocial outcome simply the\nlack of antisocial behavior or something more? Here, we examine how\nconversational features lead to prosocial outcomes within online discussions.\nWe introduce a series of new theory-inspired metrics to define prosocial\noutcomes such as mentoring and esteem enhancement. Using a corpus of 26M Reddit\nconversations, we show that these outcomes can be forecasted from the initial\ncomment of an online conversation, with the best model providing a relative 24%\nimprovement over human forecasting performance at ranking conversations for\npredicted outcome. Our results indicate that platforms can use these early cues\nin their algorithmic ranking of early conversations to prioritize better\noutcomes.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:53:41 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Bao", "Jiajun", ""], ["Wu", "Junjie", ""], ["Zhang", "Yiming", ""], ["Chandrasekharan", "Eshwar", ""], ["Jurgens", "David", ""]]}, {"id": "2102.08436", "submitter": "Emilio Ferrara", "authors": "Ho-Chun Herbert Chang, Emily Chen, Meiqing Zhang, Goran Muric, Emilio\n  Ferrara", "title": "Social Bots and Social Media Manipulation in 2020: The Year in Review", "comments": "Book Chapter submitted for the Handbook of Computational Social\n  Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The year 2020 will be remembered for two events of global significance: the\nCOVID-19 pandemic and 2020 U.S. Presidential Election. In this chapter, we\nsummarize recent studies using large public Twitter data sets on these issues.\nWe have three primary objectives. First, we delineate epistemological and\npractical considerations when combining the traditions of computational\nresearch and social science research. A sensible balance should be struck when\nthe stakes are high between advancing social theory and concrete, timely\nreporting of ongoing events. We additionally comment on the computational\nchallenges of gleaning insight from large amounts of social media data. Second,\nwe characterize the role of social bots in social media manipulation around the\ndiscourse on the COVID-19 pandemic and 2020 U.S. Presidential Election. Third,\nwe compare results from 2020 to prior years to note that, although bot accounts\nstill contribute to the emergence of echo-chambers, there is a transition from\nstate-sponsored campaigns to domestically emergent sources of distortion.\nFurthermore, issues of public health can be confounded by political\norientation, especially from localized communities of actors who spread\nmisinformation. We conclude that automation and social media manipulation pose\nissues to a healthy and democratic discourse, precisely because they distort\nrepresentation of pluralism within the public sphere.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 20:18:59 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Chang", "Ho-Chun Herbert", ""], ["Chen", "Emily", ""], ["Zhang", "Meiqing", ""], ["Muric", "Goran", ""], ["Ferrara", "Emilio", ""]]}, {"id": "2102.08510", "submitter": "Damjan Vukcevic", "authors": "Michelle Blom, Philip B. Stark, Peter J. Stuckey, Vanessa Teague and\n  Damjan Vukcevic", "title": "Auditing Hamiltonian Elections", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presidential primaries are a critical part of the United States Presidential\nelectoral process, since they are used to select the candidates in the\nPresidential election. While methods differ by state and party, many primaries\ninvolve proportional delegate allocation using the so-called Hamilton method.\nIn this paper we show how to conduct risk-limiting audits for delegate\nallocation elections using variants of the Hamilton method where the viability\nof candidates is determined either by a plurality vote or using instant runoff\nvoting. Experiments on real-world elections show that we can audit primary\nelections to high confidence (small risk limits) usually at low cost.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 00:20:26 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 13:06:15 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Blom", "Michelle", ""], ["Stark", "Philip B.", ""], ["Stuckey", "Peter J.", ""], ["Teague", "Vanessa", ""], ["Vukcevic", "Damjan", ""]]}, {"id": "2102.08537", "submitter": "Galen Weld", "authors": "Galen Weld, Maria Glenski, Tim Althoff", "title": "Political Bias and Factualness in News Sharing across more than 100,000\n  Online Communities", "comments": "12 pages, 7 figures. To appear at ICWSM 2021, camera ready version\n  included here", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As civil discourse increasingly takes place online, misinformation and the\npolarization of news shared in online communities have become ever more\nrelevant concerns with real world harms across our society. Studying online\nnews sharing at scale is challenging due to the massive volume of content which\nis shared by millions of users across thousands of communities. Therefore,\nexisting research has largely focused on specific communities or specific\ninterventions, such as bans. However, understanding the prevalence and spread\nof misinformation and polarization more broadly, across thousands of online\ncommunities, is critical for the development of governance strategies,\ninterventions, and community design. Here, we conduct the largest study of news\nsharing on reddit to date, analyzing more than 550 million links spanning 4\nyears. We use non-partisan news source ratings from Media Bias/Fact Check to\nannotate links to news sources with their political bias and factualness. We\nfind that, compared to left-leaning communities, right-leaning communities have\n105% more variance in the political bias of their news sources, and more links\nto relatively-more biased sources, on average. We observe that reddit users'\nvoting and re-sharing behaviors generally decrease the visibility of extremely\nbiased and low factual content, which receives 20% fewer upvotes and 30% fewer\nexposures from crossposts than more neutral or more factual content. This\nsuggests that reddit is more resilient to low factual content than Twitter. We\nshow that extremely biased and low factual content is very concentrated, with\n99% of such content being shared in only 0.5% of communities, giving credence\nto the recent strategy of community-wide bans and quarantines.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 02:35:13 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 19:07:43 GMT"}, {"version": "v3", "created": "Wed, 7 Apr 2021 05:06:05 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Weld", "Galen", ""], ["Glenski", "Maria", ""], ["Althoff", "Tim", ""]]}, {"id": "2102.08545", "submitter": "Mohamed Alrshah", "authors": "Entisar Alhadi Al Ghawail and Sadok Ben Yahia and Mohamed A. Alrshah", "title": "Challenges of Applying E-Learning in the Libyan Higher Education System", "comments": "6 pages", "journal-ref": null, "doi": "10.30534/ijatcse/2019/0681.42019", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The adoption of ICT in classrooms is very important in order to improve\neducation quality, promote effective management of knowledge, and improve\ndelivery of knowledge in higher education. Some of the Libyan universities have\nalready started using E-learning in classrooms, but many challenges are still\nhindering that adoption. This paper endeavors to find the obstacles that may\nface the adoption of E-learning in Libya and sketches out the possible\nsolutions. Further, it highlights the potentials for the adoption of E-learning\nin the higher education system in Libya using both qualitative and quantitative\napproaches. Both questioner and interview have been used on a focused group to\ncollect the data. Teachers and students at Al Asmarya Islamic University have\nbeen selected as a sample for this study. This paper reveals that the\nchallenges hindering teachers and students from using ICT and E-learning are:\nthe lack of knowledge about ICT and E-learning, the lack of ICT infrastructure,\nand the lack of financial support. However, the participants show a high level\nof interest in applying the ICT and E-learning in the university despite the\nunsuitability of the environment.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 03:20:46 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ghawail", "Entisar Alhadi Al", ""], ["Yahia", "Sadok Ben", ""], ["Alrshah", "Mohamed A.", ""]]}, {"id": "2102.08557", "submitter": "Rajagopal Venkatesaramani", "authors": "Rajagopal Venkatesaramani, Bradley A. Malin, Yevgeniy Vorobeychik", "title": "Re-identification of Individuals in Genomic Datasets Using Public Face\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  DNA sequencing is becoming increasingly commonplace, both in medical and\ndirect-to-consumer settings. To promote discovery, collected genomic data is\noften de-identified and shared, either in public repositories, such as OpenSNP,\nor with researchers through access-controlled repositories. However, recent\nstudies have suggested that genomic data can be effectively matched to\nhigh-resolution three-dimensional face images, which raises a concern that the\nincreasingly ubiquitous public face images can be linked to shared genomic\ndata, thereby re-identifying individuals in the genomic data. While these\ninvestigations illustrate the possibility of such an attack, they assume that\nthose performing the linkage have access to extremely well-curated data. Given\nthat this is unlikely to be the case in practice, it calls into question the\npragmatic nature of the attack. As such, we systematically study this\nre-identification risk from two perspectives: first, we investigate how\nsuccessful such linkage attacks can be when real face images are used, and\nsecond, we consider how we can empower individuals to have better control over\nthe associated re-identification risk. We observe that the true risk of\nre-identification is likely substantially smaller for most individuals than\nprior literature suggests. In addition, we demonstrate that the addition of a\nsmall amount of carefully crafted noise to images can enable a controlled\ntrade-off between re-identification success and the quality of shared images,\nwith risk typically significantly lowered even with noise that is imperceptible\nto humans.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 03:54:25 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Venkatesaramani", "Rajagopal", ""], ["Malin", "Bradley A.", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2102.08692", "submitter": "Giulia Cisotto", "authors": "Giulia Cisotto, Andrea Trentini, Italo Zoppis, Alessio Zanga, Sara\n  Manzoni, Giada Pietrabissa, Anna Guerrini Usubini, and Gianluca Castelnuovo", "title": "ACTA: A Mobile-Health Solution for Integrated Nudge-Neurofeedback\n  Training for Senior Citizens", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SY eess.SP eess.SY q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the worldwide population gets increasingly aged, in-home telemedicine and\nmobile-health solutions represent promising services to promote active and\nindependent aging and to contribute to a paradigm shift towards patient-centric\nhealthcare. In this work, we present ACTA (Advanced Cognitive Training for\nAging), a prototype mobile-health solution to provide advanced cognitive\ntraining for senior citizens with mild cognitive impairments. We disclose here\nthe conceptualization of ACTA as the integration of two promising\nrehabilitation strategies: the \"Nudge theory\", from the cognitive domain, and\nthe neurofeedback, from the neuroscience domain. Moreover, in ACTA we exploit\nthe most advanced machine learning techniques to deliver customized and fully\nadaptive support to the elderly, while training in an ecological environment.\nACTA represents the next-step beyond SENIOR, an earlier mobile-health project\nfor cognitive training based on Nudge theory, currently ongoing in Lombardy\nRegion. Beyond SENIOR, ACTA represents a highly-usable, accessible, low-cost,\nnew-generation mobile-health solution to promote independent aging and\neffective motor-cognitive training support, while empowering the elderly in\ntheir own aging.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 11:12:23 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Cisotto", "Giulia", ""], ["Trentini", "Andrea", ""], ["Zoppis", "Italo", ""], ["Zanga", "Alessio", ""], ["Manzoni", "Sara", ""], ["Pietrabissa", "Giada", ""], ["Usubini", "Anna Guerrini", ""], ["Castelnuovo", "Gianluca", ""]]}, {"id": "2102.08779", "submitter": "Emmanouil Papadogiannakis", "authors": "Emmanouil Papadogiannakis, Panagiotis Papadopoulos, Nicolas Kourtellis\n  and Evangelos P. Markatos", "title": "User Tracking in the Post-cookie Era: How Websites Bypass GDPR Consent\n  to Track Users", "comments": "12 pages, To be published at The Web Conference 2021 (WWW 2021).\n  Please cite the WWW version", "journal-ref": null, "doi": "10.1145/3442381.3450056", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the past few years, mostly as a result of the GDPR and the CCPA,\nwebsites have started to present users with cookie consent banners. These\nbanners are web forms where the users can state their preference and declare\nwhich cookies they would like to accept, if such option exists. Although\nrequesting consent before storing any identifiable information is a good start\ntowards respecting the user privacy, yet previous research has shown that\nwebsites do not always respect user choices. Furthermore, considering the ever\ndecreasing reliance of trackers on cookies and actions browser vendors take by\nblocking or restricting third-party cookies, we anticipate a world where\nstateless tracking emerges, either because trackers or websites do not use\ncookies, or because users simply refuse to accept any.\n  In this paper, we explore whether websites use more persistent and\nsophisticated forms of tracking in order to track users who said they do not\nwant cookies. Such forms of tracking include first-party ID leaking, ID\nsynchronization, and browser fingerprinting. Our results suggest that websites\ndo use such modern forms of tracking even before users had the opportunity to\nregister their choice with respect to cookies. To add insult to injury, when\nusers choose to raise their voice and reject all cookies, user tracking only\nintensifies. As a result, users' choices play very little role with respect to\ntracking: we measured that more than 75% of tracking activities happened before\nusers had the opportunity to make a selection in the cookie consent banner, or\nwhen users chose to reject all cookies.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:11:10 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Papadogiannakis", "Emmanouil", ""], ["Papadopoulos", "Panagiotis", ""], ["Kourtellis", "Nicolas", ""], ["Markatos", "Evangelos P.", ""]]}, {"id": "2102.08803", "submitter": "Till Massing", "authors": "Till Massing, Natalie Reckmann, Jens Klenke, Benjamin Otto, Christoph\n  Hanck, Michael Goedicke", "title": "Effects of Early Warning Emails on Student Performance", "comments": "arXiv admin note: text overlap with arXiv:1906.09864", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We use learning data of an e-assessment platform for an introductory\nmathematical statistics course to predict the probability of passing the final\nexam for each student. Based on these estimated probabilities we sent warning\nemails to students in the next cohort with a low predicted probability to pass.\nWe analyze the effect of this treatment and propose statistical models to\nquantify the effect of the email notification. We detect a small but\nimprecisely estimated effect suggesting effectiveness of such interventions\nonly when administered more intensively.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 15:03:16 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Massing", "Till", ""], ["Reckmann", "Natalie", ""], ["Klenke", "Jens", ""], ["Otto", "Benjamin", ""], ["Hanck", "Christoph", ""], ["Goedicke", "Michael", ""]]}, {"id": "2102.08933", "submitter": "David Jilk", "authors": "David J. Jilk", "title": "An Objective Laboratory Protocol for Evaluating Cognition of Non-Human\n  Systems Against Human Cognition", "comments": "14 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I describe and reduce to practice an objective protocol for\nevaluating the cognitive capabilities of a non-human system against human\ncognition in a laboratory environment. This is important because the existence\nof a non-human system with cognitive capabilities comparable to those of humans\nmight make once-philosophical questions of safety and ethics immediate and\nurgent. Past attempts to devise evaluation methods, such as the Turing Test and\nmany others, have not met this need; most of them either emphasize a single\naspect of human cognition or a single theory of intelligence, fail to capture\nthe human capacity for generality and novelty, or require success in the\nphysical world. The protocol is broadly Bayesian, in that its primary output is\na confidence statistic in relation to a claim. Further, it provides insight\ninto the areas where and to what extent a particular system falls short of\nhuman cognition, which can help to drive further progress or precautions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 18:40:49 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Jilk", "David J.", ""]]}, {"id": "2102.09021", "submitter": "M\\'arton Karsai", "authors": "J\\'ulia Koltai, Orsolya V\\'as\\'arhelyi, Gergely R\\\"ost and M\\'arton\n  Karsai", "title": "Monitoring behavioural responses during pandemic via reconstructed\n  contact matrices from online and representative surveys", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The unprecedented behavioural responses of societies have been evidently\nshaping the COVID-19 pandemic, yet it is a significant challenge to accurately\nmonitor the continuously changing social mixing patterns in real-time. Contact\nmatrices, usually stratified by age, summarise interaction motifs efficiently,\nbut their collection relies on conventional representative survey techniques,\nwhich are expensive and slow to obtain. Here we report a data collection effort\ninvolving over $2.3\\%$ of the Hungarian population to simultaneously record\ncontact matrices through a longitudinal online and sequence of representative\nphone surveys. To correct non-representative biases characterising the online\ndata, by using census data and the representative samples we develop a\nreconstruction method to provide a scalable, cheap, and flexible way to\ndynamically obtain closer-to-representative contact matrices. Our results\ndemonstrate the potential of combined online-offline data collections to\nunderstand the changing behavioural responses determining the future evolution\nof the outbreak, and inform epidemic models with crucial data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 20:39:59 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 20:06:28 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Koltai", "J\u00falia", ""], ["V\u00e1s\u00e1rhelyi", "Orsolya", ""], ["R\u00f6st", "Gergely", ""], ["Karsai", "M\u00e1rton", ""]]}, {"id": "2102.09066", "submitter": "Zhihong (Iris) Shen", "authors": "Boya Xie, Zhihong Shen, Kuansan Wang", "title": "Is preprint the future of science? A thirty year journey of online\n  preprint services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Preprint is a version of a scientific paper that is publicly distributed\npreceding formal peer review. Since the launch of arXiv in 1991, preprints have\nbeen increasingly distributed over the Internet as opposed to paper copies. It\nallows open online access to disseminate the original research within a few\ndays, often at a very low operating cost. This work overviews how preprint has\nbeen evolving and impacting the research community over the past thirty years\nalongside the growth of the Web. In this work, we first report that the number\nof preprints has exponentially increased 63 times in 30 years, although it only\naccounts for 4% of research articles. Second, we quantify the benefits that\npreprints bring to authors: preprints reach an audience 14 months earlier on\naverage and associate with five times more citations compared with a\nnon-preprint counterpart. Last, to address the quality concern of preprints, we\ndiscover that 41% of preprints are ultimately published at a peer-reviewed\ndestination, and the published venues are as influential as papers without a\npreprint version. Additionally, we discuss the unprecedented role of preprints\nin communicating the latest research data during recent public health\nemergencies. In conclusion, we provide quantitative evidence to unveil the\npositive impact of preprints on individual researchers and the community.\nPreprints make scholarly communication more efficient by disseminating\nscientific discoveries more rapidly and widely with the aid of Web\ntechnologies. The measurements we present in this study can help researchers\nand policymakers make informed decisions about how to effectively use and\nresponsibly embrace a preprint culture.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 23:08:01 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Xie", "Boya", ""], ["Shen", "Zhihong", ""], ["Wang", "Kuansan", ""]]}, {"id": "2102.09094", "submitter": "Adam D. Lelkes", "authors": "Adam D. Lelkes, Vinh Q. Tran, Cong Yu", "title": "Quiz-Style Question Generation for News Stories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A large majority of American adults get at least some of their news from the\nInternet. Even though many online news products have the goal of informing\ntheir users about the news, they lack scalable and reliable tools for measuring\nhow well they are achieving this goal, and therefore have to resort to noisy\nproxy metrics (e.g., click-through rates or reading time) to track their\nperformance.\n  As a first step towards measuring news informedness at a scale, we study the\nproblem of quiz-style multiple-choice question generation, which may be used to\nsurvey users about their knowledge of recent news. In particular, we formulate\nthe problem as two sequence-to-sequence tasks: question-answer generation (QAG)\nand distractor, or incorrect answer, generation (DG). We introduce NewsQuizQA,\nthe first dataset intended for quiz-style question-answer generation,\ncontaining 20K human written question-answer pairs from 5K news article\nsummaries. Using this dataset, we propose a series of novel techniques for\napplying large pre-trained Transformer encoder-decoder models, namely PEGASUS\nand T5, to the tasks of question-answer generation and distractor generation.\n  We show that our models outperform strong baselines using both automated\nmetrics and human raters. We provide a case study of running weekly quizzes on\nreal-world users via the Google Surveys platform over the course of two months.\nWe found that users generally found the automatically generated questions to be\neducational and enjoyable. Finally, to serve the research community, we are\nreleasing the NewsQuizQA dataset.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 01:06:58 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Lelkes", "Adam D.", ""], ["Tran", "Vinh Q.", ""], ["Yu", "Cong", ""]]}, {"id": "2102.09102", "submitter": "Andry Alamsyah", "authors": "Farid Naufal Aslam, Andry Alamsyah", "title": "The Small World Phenomenon and Network Analysis of ICT Startup\n  Investment in Indonesia and Singapore", "comments": "7 pages, 4 figures, 2 tables", "journal-ref": "The 7th Smart Collaboration for Business in Technology and\n  Information Industry Conference 2016", "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The internet's rapid growth stimulates the emergence of start-up companies\nbased on information technology and telecommunication (ICT) in Indonesia and\nSingapore. As the number of start-ups and its investor growth, the network of\nits relationship become larger and complex, but on the other side feel small.\nEveryone in the ICT start-up investment network can be reached in short steps,\nled to a phenomenon called small-world phenomenon, a principle that we are all\nconnected by a short chain of relationships. We investigate the pattern of the\nrelationship between a start-up with its investor and the small world\ncharacteristics using network analysis methodology. The research is conducted\nby creating the ICT start-up investment network model of each country and\ncalculate its small-world network properties to see the characteristic of the\nnetworks. Then we compare and analyze the result of each network model. The\nresult of this research is to give knowledge about the current condition of ICT\nstart-up investment in Indonesia and Singapore. The research is beneficial for\nbusiness intelligence purposes to support decision-making related to ICT\nstart-up investment.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 01:20:54 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Aslam", "Farid Naufal", ""], ["Alamsyah", "Andry", ""]]}, {"id": "2102.09103", "submitter": "Kunal Khadilkar", "authors": "Kunal Khadilkar, Ashiqur R. KhudaBukhsh, Tom M. Mitchell", "title": "Gender Bias, Social Bias and Representation: 70 Years of B$^H$ollywood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an outreach in more than 90 countries, a market share of 2.1 billion\ndollars and a target audience base of at least 1.2 billion people, Bollywood,\naka the Mumbai film industry, is a formidable entertainment force. While the\nnumber of lives Bollywood can potentially touch is massive, no comprehensive\nNLP study on the evolution of social and gender biases in Bollywood dialogues\nexists. Via a substantial corpus of movie dialogues spanning a time horizon of\n70 years, we seek to understand the portrayal of women, in a broader context\nstudying subtle social signals, and analyze the evolving trends in geographic\nand religious representation in India. Our argument is simple -- popular movie\ncontent reflects social norms and beliefs in some form or shape. In this\nproject, we propose to analyze such trends over 70 years of Bollywood movies\ncontrasting them with their Hollywood counterpart and critically acclaimed\nworld movies.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 01:27:24 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Khadilkar", "Kunal", ""], ["KhudaBukhsh", "Ashiqur R.", ""], ["Mitchell", "Tom M.", ""]]}, {"id": "2102.09107", "submitter": "Andry Alamsyah", "authors": "Andry Alamsyah, Nurlisa Laksmiani, Lies Anisa Rahimi", "title": "A Core of E-Commerce Customer Experience based on Conversational Data\n  using Network Text Methodology", "comments": "9 pages, 1 figure, 4 tables", "journal-ref": "International Journal of Business, 2018, 23(3)", "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  E-commerce provides an efficient and effective way to exchange goods between\nsellers and customers. E-commerce has been a popular method for doing business,\nbecause of its simplicity of having commerce activity transparently available,\nincluding customer voice and opinion about their own experience. Those\nexperiences can be a great benefit to understand customer experience\ncomprehensively, both for sellers and future customers. This paper applies to\ne-commerces and customers in Indonesia. Many Indonesian customers expressed\ntheir voice to open social network services such as Twitter and Facebook, where\na large proportion of data is in the form of conversational data. By\nunderstanding customer behavior through open social network service, we can\nhave descriptions about the e-commerce services level in Indonesia. Thus, it is\nrelated to the government's effort to improve the Indonesian digital economy\necosystem. A method for finding core topics in large-scale internet\nunstructured text data is needed, where the method should be fast but\nsufficiently accurate. Processing large-scale data is not a straightforward\njob, it often needs special skills of people and complex software and hardware\ncomputer system. We propose a fast methodology of text mining methods based on\nfrequently appeared words and their word association to form network text\nmethodology. This method is adapted from Social Network Analysis by the model\nrelationships between words instead of actors.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 01:33:14 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Alamsyah", "Andry", ""], ["Laksmiani", "Nurlisa", ""], ["Rahimi", "Lies Anisa", ""]]}, {"id": "2102.09258", "submitter": "Marta Gomez-Barrero", "authors": "Marta Gomez-Barrero, Pawel Drozdowski, Christian Rathgeb, Jose Patino,\n  Massimmiliano Todisco, Andras Nautsch, Naser Damer, Jannis Priesnitz,\n  Nicholas Evans, Christoph Busch", "title": "Biometrics in the Era of COVID-19: Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Since early 2020 the COVID-19 pandemic has had a considerable impact on many\naspects of daily life. A range of different measures have been implemented\nworldwide to reduce the rate of new infections and to manage the pressure on\nnational health services. A primary strategy has been to reduce gatherings and\nthe potential for transmission through the prioritisation of remote working and\neducation. Enhanced hand hygiene and the use of facial masks have decreased the\nspread of pathogens when gatherings are unavoidable. These particular measures\npresent challenges for reliable biometric recognition, e.g. for facial-, voice-\nand hand-based biometrics. At the same time, new challenges create new\nopportunities and research directions, e.g. renewed interest in non-constrained\niris or periocular recognition, touch-less fingerprint- and vein-based\nauthentication and the use of biometric characteristics for disease detection.\nThis article presents an overview of the research carried out to address those\nchallenges and emerging opportunities.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 10:32:59 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Gomez-Barrero", "Marta", ""], ["Drozdowski", "Pawel", ""], ["Rathgeb", "Christian", ""], ["Patino", "Jose", ""], ["Todisco", "Massimmiliano", ""], ["Nautsch", "Andras", ""], ["Damer", "Naser", ""], ["Priesnitz", "Jannis", ""], ["Evans", "Nicholas", ""], ["Busch", "Christoph", ""]]}, {"id": "2102.09342", "submitter": "Xiaohang Xu", "authors": "Xiaohang Xu, Hao Peng, Lichao Sun, Md Zakirul Alam Bhuiyan, Lianzhong\n  Liu, Lifang He", "title": "FedMood: Federated Learning on Mobile Health Data for Mood Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depression is one of the most common mental illness problems, and the\nsymptoms shown by patients are not consistent, making it difficult to diagnose\nin the process of clinical practice and pathological research. Although\nresearchers hope that artificial intelligence can contribute to the diagnosis\nand treatment of depression, the traditional centralized machine learning needs\nto aggregate patient data, and the data privacy of patients with mental illness\nneeds to be strictly confidential, which hinders machine learning algorithms\nclinical application. To solve the problem of privacy of the medical history of\npatients with depression, we implement federated learning to analyze and\ndiagnose depression. First, we propose a general multi-view federated learning\nframework using multi-source data, which can extend any traditional machine\nlearning model to support federated learning across different institutions or\nparties. Secondly, we adopt late fusion methods to solve the problem of\ninconsistent time series of multi-view data. Finally, we compare the federated\nframework with other cooperative learning frameworks in performance and discuss\nthe related results.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 15:19:08 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 12:06:53 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 07:37:54 GMT"}, {"version": "v4", "created": "Fri, 2 Apr 2021 02:06:09 GMT"}, {"version": "v5", "created": "Thu, 8 Apr 2021 05:30:13 GMT"}, {"version": "v6", "created": "Thu, 20 May 2021 13:38:21 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Xu", "Xiaohang", ""], ["Peng", "Hao", ""], ["Sun", "Lichao", ""], ["Bhuiyan", "Md Zakirul Alam", ""], ["Liu", "Lianzhong", ""], ["He", "Lifang", ""]]}, {"id": "2102.09343", "submitter": "Naveen Sundar Govindarajulu", "authors": "Selmer Bringsjord and Naveen Sundar Govindarajulu and Michael Giancola", "title": "AI Can Stop Mass Shootings, and More", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to build directly upon our longstanding, prior r&d in AI/machine\nethics in order to attempt to make real the blue-sky idea of AI that can thwart\nmass shootings, by bringing to bear its ethical reasoning. The r&d in question\nis overtly and avowedly logicist in form, and since we are hardly the only ones\nwho have established a firm foundation in the attempt to imbue AI's with their\nown ethical sensibility, the pursuit of our proposal by those in different\nmethodological camps should, we believe, be considered as well. We seek herein\nto make our vision at least somewhat concrete by anchoring our exposition to\ntwo simulations, one in which the AI saves the lives of innocents by locking\nout a malevolent human's gun, and a second in which this malevolent agent is\nallowed by the AI to be neutralized by law enforcement. Along the way, some\nobjections are anticipated, and rebutted.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 06:55:59 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Bringsjord", "Selmer", ""], ["Govindarajulu", "Naveen Sundar", ""], ["Giancola", "Michael", ""]]}, {"id": "2102.09346", "submitter": "Iuliana Marin", "authors": "Iuliana Marin, Andrei Vasilateanu, Bujor Pavaloiu, Nicolae Goga", "title": "User Requirements and Analysis of Preeclampsia Detection done through a\n  Smart Bracelet", "comments": null, "journal-ref": "12th International Technology, Education and Development\n  Conference 2018", "doi": "10.21125/inted.2018.2080", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical students along with the medical staff have to monitor the state of\nthe patients by using modern devices which have to offer precise results in a\nshort amount of time, so that the intervention to be done as soon as possible.\nE-learning systems for blood pressure monitoring are used and new methods of\npatient observation, evaluation and treatment are applied compared to classical\nintervention. Based on this, medical students can improve their knowledge for\nthe practical training.\n  In the medical activities specialized devices occupy an important place. A\ndevice that can monitor the blood pressure is a smart bracelet that\nincorporates a pressure sensor along the wrist for continuous recording of\nblood pressure values. This enables the prediction of the emergency disorders\nusing a decision support system. It facilitates the learning of new\nintervention approaches and boosts the responsiveness among learners. According\nto the World Health Organization, hypertensive disorders affect about 10% of\npregnant women worldwide and are an important cause of disability and long-term\ndeath among mothers and children. This paper is based on a survey completed by\npersons of different ages and having various specialization domains regarding\nthe use of smart bracelets for detecting preeclampsia. The aim is to decide\nupon its popularity among people and to determine the user requirements. The\npregnant women will be constantly monitored, doctors can update the diagnosis\nof the patient. The medical students can learn from the critical situations and\nbenefit from these cases while learning. The results of the survey showed that\nmost of the interviewed persons consider the existence of such a device to be\nvery useful, mostly the female individuals would feel more comfortable to have\ntheir blood pressure monitored during pregnancy.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 17:23:36 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Marin", "Iuliana", ""], ["Vasilateanu", "Andrei", ""], ["Pavaloiu", "Bujor", ""], ["Goga", "Nicolae", ""]]}, {"id": "2102.09350", "submitter": "Mehmet Yavuz", "authors": "Mehmet Can Yavuz", "title": "Multilingual, Temporal and Sentimental Distant-Reading of City Events", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leibniz's Monadology mentions perceptional and sentimental variations of the\nindividual in the city. It is the interaction of people with people and events.\nFilm festivals are highly sentimental events of multicultural cities. Each\nmovie has a different sentimental effect and the interactions with the movies\nhave reflections that can be observed on social media. This analysis aims to\napply distant reading on Berlinale tweets collected during the festival. On\ncontrary to close reading, distant reading let authors to observe patterns in\nlarge collection of data. The analysis is temporal and sentimental in\nmultilingual domain and strongly positive and negative time intervals are\nanalysed. For this purpose, we trained a deep sentiment network with\nmultilingual embeddings. These multilingual embeddings are aligned in latent\nspace. We trained the network with a multilingual dataset in three languages\nEnglish, German and Spanish. The trained algorithm has a 0.78 test score and\napplied on Tweets with Berlinale hashtag during the festival. Although the\nsentimental analysis does not reflect the award-winning films, we observe\nweekly routine on the relationship between sentimentality, which can mislead a\nclose reading analysis. We have also remarks on popularity of the director or\nactors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2021 10:57:11 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Yavuz", "Mehmet Can", ""]]}, {"id": "2102.09364", "submitter": "Jessica Morley", "authors": "Jessica Morley, Anat Elhalal, Francesca Garcia, Libby Kinsey, Jakob\n  Mokander, Luciano Floridi", "title": "Ethics as a service: a pragmatic operationalisation of AI Ethics", "comments": "21 pages, first draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the range of potential uses for Artificial Intelligence (AI), in\nparticular machine learning (ML), has increased, so has awareness of the\nassociated ethical issues. This increased awareness has led to the realisation\nthat existing legislation and regulation provides insufficient protection to\nindividuals, groups, society, and the environment from AI harms. In response to\nthis realisation, there has been a proliferation of principle-based ethics\ncodes, guidelines and frameworks. However, it has become increasingly clear\nthat a significant gap exists between the theory of AI ethics principles and\nthe practical design of AI systems. In previous work, we analysed whether it is\npossible to close this gap between the what and the how of AI ethics through\nthe use of tools and methods designed to help AI developers, engineers, and\ndesigners translate principles into practice. We concluded that this method of\nclosure is currently ineffective as almost all existing translational tools and\nmethods are either too flexible (and thus vulnerable to ethics washing) or too\nstrict (unresponsive to context). This raised the question: if, even with\ntechnical guidance, AI ethics is challenging to embed in the process of\nalgorithmic design, is the entire pro-ethical design endeavour rendered futile?\nAnd, if no, then how can AI ethics be made useful for AI practitioners? This is\nthe question we seek to address here by exploring why principles and technical\ntranslational tools are still needed even if they are limited, and how these\nlimitations can be potentially overcome by providing theoretical grounding of a\nconcept that has been termed Ethics as a Service.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 21:29:25 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Morley", "Jessica", ""], ["Elhalal", "Anat", ""], ["Garcia", "Francesca", ""], ["Kinsey", "Libby", ""], ["Mokander", "Jakob", ""], ["Floridi", "Luciano", ""]]}, {"id": "2102.09365", "submitter": "Pawe{\\l} Weichbroth", "authors": "Mieczys{\\l}aw L. Owoc, Agnieszka Sawicka, Pawe{\\l} Weichbroth", "title": "Artificial Intelligence Technologies in Education: Benefits, Challenges\n  and Strategies of Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Since the education sector is associated with highly dynamic business\nenvironments which are controlled and maintained by information systems, recent\ntechnological advancements and the increasing pace of adopting artificial\nintelligence (AI) technologies constitute a need to identify and analyze the\nissues regarding their implementation in education sector. However, a study of\nthe contemporary literature reveled that relatively little research has been\nundertaken in this area. To fill this void, we have identified the benefits and\nchallenges of implementing artificial intelligence in the education sector,\npreceded by a short discussion on the concepts of AI and its evolution over\ntime. Moreover, we have also reviewed modern AI technologies for learners and\neducators, currently available on the software market, evaluating their\nusefulness. Last but not least, we have developed a strategy implementation\nmodel, described by a five-stage, generic process, along with the corresponding\nconfiguration guide. To verify and validate their design, we separately\ndeveloped three implementation strategies for three different higher education\norganizations. We believe that the obtained results will contribute to better\nunderstanding the specificities of AI systems, services and tools, and\nafterwards pave a smooth way in their implementation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:09:41 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Owoc", "Mieczys\u0142aw L.", ""], ["Sawicka", "Agnieszka", ""], ["Weichbroth", "Pawe\u0142", ""]]}, {"id": "2102.09366", "submitter": "Kai-Kristian Kemell", "authors": "Kai-Kristian Kemell, Polina Feshchenko, Joonas Himmanen, Abrar\n  Hossain, Furqan Jameel, Raffaele Luigi Puca, Teemu Vitikainen, Joni Kultanen,\n  Juhani Risku, Johannes Impi\\\"o, Anssi Sorvisto, Pekka Abrahamsson", "title": "Software startup education: gamifying growth hacking", "comments": null, "journal-ref": "In Proceedings of the 2nd ACM SIGSOFT International Workshop on\n  Software-Intensive Business: Start-ups, Platforms, and Ecosystems (IWSiB\n  2019). Association for Computing Machinery, New York, NY, USA, 25-30", "doi": "10.1145/3340481.3342734", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Startups seek to create highly scalable business models. For startups, growth\nis thus vital. Growth hacking is a marketing strategy advocated by various\nstartup practitioner experts. It focuses on using low cost practices while\nutilizing existing platforms in creative ways to gain more users for the\nservice. Though topics related to growth hacking such as marketing on a general\nlevel have been extensively studied in the past, growth hacking as a\npractitioner-born topic has not seen much interesting among the academia. To\nboth spark interest in growth hacking, and to facilitate teaching growth\nhacking in the academia, we present two board games intended to serve as an\nengaging introduction to growth hacking for students.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 11:30:32 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kemell", "Kai-Kristian", ""], ["Feshchenko", "Polina", ""], ["Himmanen", "Joonas", ""], ["Hossain", "Abrar", ""], ["Jameel", "Furqan", ""], ["Puca", "Raffaele Luigi", ""], ["Vitikainen", "Teemu", ""], ["Kultanen", "Joni", ""], ["Risku", "Juhani", ""], ["Impi\u00f6", "Johannes", ""], ["Sorvisto", "Anssi", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "2102.09368", "submitter": "Niels Doorn", "authors": "Lex Bijlsma, Niels Doorn, Harrie Passier, Harold Pootjes, Sylvia\n  Stuurman", "title": "How do students test software units?", "comments": "ICSE 2021 - JSEET - Joint Track on Software Engineering Education and\n  Training", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We gained insight into ideas and beliefs on testing of students who finished\nan introductory course on programming without any formal education on testing.\nWe asked students to fill in a small survey, to do four exercises and to fill\nin a second survey. We interviewed eleven of these students in semi-structured\ninterviews, to obtain more in-depth insight. The main outcome is that students\ndo not test systematically, while most of them think they do test\nsystematically. One of the misconceptions we found is that most students can\nonly think of test cases based on programming code. Even if no code was\nprovided (black-box testing), students try to come up with code to base their\ntest cases on.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 07:02:59 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Bijlsma", "Lex", ""], ["Doorn", "Niels", ""], ["Passier", "Harrie", ""], ["Pootjes", "Harold", ""], ["Stuurman", "Sylvia", ""]]}, {"id": "2102.09369", "submitter": "Sweta Swarnam", "authors": "Sweta Swarnam", "title": "Effect of Social Media Use on Mental Health during Lockdown in India", "comments": "15 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This research paper studies about the role of social media use and increase\nthe risk factor of mental health during covid 19 or lockdown. Although few\nstudies have been conducted on the role about the effect of social media use on\nmental health during lockdown and impact on human reactive nature during\nlockdown. As a rapidly spreading pandemic, a biomedical disease has serious\nphysical and tremendous mental health implications. An occupational community\nof internal migrant workers is one of the most vulnerable, but neglected, and\nis likely to develop psychological ill-effects due to COVID-19's double whammy\nimpact. Mental health is a crucial aspect that needs to be addressed during\nthis lock-down as all modes of communication revolve around the virus. There\nare many difficulties with the unprecedented changes that have occurred so\nquickly due to the pandemic and stay-at - home confinement to achieve social\ndistance and mitigate the risk of infection. These include impaired health,\nwell-being, and sleep as a result of daily routine disruption, anxiety, worry,\nisolation, greater stress on family and work, and excessive screen time. An\nessential part of our overall health and well-being is mental and emotional\nhealth. An important skill is managing emotions and maintaining emotional\nbalance. It helps you face challenges and stress when you manage your emotional\nhealth. Lack of skills in emotional regulation may lead to poor mental health\nand relationship difficulties. It is as important to look after our mental\nhealth as it is to look after our physical health. For mental health\nprofessionals, the pandemic has also brought many ethical challenges.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 14:52:33 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Swarnam", "Sweta", ""]]}, {"id": "2102.09372", "submitter": "Sheshank Shankar", "authors": "Joseph Bae, Rohan Sukumaran, Sheshank Shankar, Anshuman Sharma, Ishaan\n  Singh, Haris Nazir, Colin Kang, Saurish Srivastava, Parth Patwa, Abhishek\n  Singh, Priyanshi Katiyar, Vitor Pamplona, Ramesh Raskar", "title": "Mobile Apps Prioritizing Privacy, Efficiency and Equity: A Decentralized\n  Approach to COVID-19 Vaccination Coordination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this early draft, we describe a decentralized, app-based approach to\nCOVID-19 vaccine distribution that facilitates zero knowledge verification,\ndynamic vaccine scheduling, continuous symptoms reporting, access to aggregate\nanalytics based on population trends and more. To ensure equity, our solution\nis developed to work with limited internet access as well. In addition, we\ndescribe the six critical functions that we believe last mile vaccination\nmanagement platforms must perform, examine existing vaccine management systems,\nand present a model for privacy-focused, individual-centric solutions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 05:37:36 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Bae", "Joseph", ""], ["Sukumaran", "Rohan", ""], ["Shankar", "Sheshank", ""], ["Sharma", "Anshuman", ""], ["Singh", "Ishaan", ""], ["Nazir", "Haris", ""], ["Kang", "Colin", ""], ["Srivastava", "Saurish", ""], ["Patwa", "Parth", ""], ["Singh", "Abhishek", ""], ["Katiyar", "Priyanshi", ""], ["Pamplona", "Vitor", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2102.09373", "submitter": "Parinaz Barakhshan", "authors": "Parinaz Barakhshan, Rudolf Eigenmann", "title": "Exchanging Best Practices and Tools for Supporting Computational and\n  Data-Intensive Research, The Xpert Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present best practices and tools for professionals who support\ncomputational and data intensive (CDI) research projects. The practices\nresulted from an initiative that brings together national projects and\nuniversity teams that include individual or groups of such professionals. We\nfocus particularly on practices that differ from those in a general software\nengineering context. The paper also describes the initiative , the Xpert\nNetwork , where participants exchange successes, challenges, and general\ninformation about their activities, leading to increased productivity,\nefficiency, and coordination in the ever growing community of scientists that\nuse computational and data-intensive research methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 05:00:57 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Barakhshan", "Parinaz", ""], ["Eigenmann", "Rudolf", ""]]}, {"id": "2102.09377", "submitter": "Zachary Pardos", "authors": "Zhi Li, Cheng Ren, Xianyou Li, and Zachary A. Pardos", "title": "Learning Skill Equivalencies Across Platform Taxonomies", "comments": "Accepted to Learning Analytics and Knowledge (LAK-2021)", "journal-ref": null, "doi": "10.1145/3448139.3448173", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessment and reporting of skills is a central feature of many digital\nlearning platforms. With students often using multiple platforms,\ncross-platform assessment has emerged as a new challenge. While technologies\nsuch as Learning Tools Interoperability (LTI) have enabled communication\nbetween platforms, reconciling the different skill taxonomies they employ has\nnot been solved at scale. In this paper, we introduce and evaluate a\nmethodology for finding and linking equivalent skills between platforms by\nutilizing problem content as well as the platform's clickstream data. We\npropose six models to represent skills as continuous real-valued vectors and\nleverage machine translation to map between skill spaces. The methods are\ntested on three digital learning platforms: ASSISTments, Khan Academy, and\nCognitive Tutor. Our results demonstrate reasonable accuracy in skill\nequivalency prediction from a fine-grained taxonomy to a coarse-grained one,\nachieving an average recall@5 of 0.8 between the three platforms. Our skill\ntranslation approach has implications for aiding in the tedious, manual process\nof taxonomy to taxonomy mapping work, also called crosswalks, within the\ntutoring as well as standardized testing worlds.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:49:39 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 01:55:32 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Li", "Zhi", ""], ["Ren", "Cheng", ""], ["Li", "Xianyou", ""], ["Pardos", "Zachary A.", ""]]}, {"id": "2102.09387", "submitter": "Jorge Melegati", "authors": "Jorge Melegati, Eduardo Guerra, Xiaofeng Wang", "title": "HyMap: eliciting hypotheses in early-stage software startups using\n  cognitive mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Software startups develop innovative, software-intensive products.\nGiven the uncertainty associated with such an innovative context,\nexperimentation is a valuable approach for these companies, especially in the\nearly stages of the development, when implementing unnecessary features\nrepresents a higher risk for companies' survival. Nevertheless, researchers\nhave argued that the lack of clearly defined practices led to limited adoption\nof experimentation. In this regard, the first step is to define the hypotheses\nbased on which teams will create experiments. Objective: We aim to develop a\nsystematic technique to identify hypotheses for early-stage software startups.\nMethods: We followed a Design Science approach consisted of three cycles in the\nconstruction phase, that involved seven startups in total, and an evaluation of\nthe final artifact within three startups. Results: We developed the HyMap, a\nhypotheses elicitation technique based on cognitive mapping. It consists of a\nvisual language to depict a cognitive map representing the founder's\nunderstanding of the product, and a process to elicit this map consisted of a\nseries of questions the founder must answer. Our evaluation showed that the\nartifacts are clear, easy to use, and useful leading to hypotheses and\nfacilitating founders to visualize their idea. Conclusion: Our study\ncontributes to both descriptive and prescriptive bodies of knowledge. Regarding\nthe first, it provides a better understanding of the guidance founders use to\ndevelop their startups and, for the latter, a technique to identify hypotheses\nin early-stage software startups.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 17:29:47 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Melegati", "Jorge", ""], ["Guerra", "Eduardo", ""], ["Wang", "Xiaofeng", ""]]}, {"id": "2102.09391", "submitter": "Michael Jordan", "authors": "Ani Adhikari, John DeNero, Michael I. Jordan", "title": "Interleaving Computational and Inferential Thinking: Data Science for\n  Undergraduates at Berkeley", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The undergraduate data science curriculum at the University of California,\nBerkeley is anchored in five new courses that emphasize computational thinking,\ninferential thinking, and working on real-world problems. We believe that\ninterleaving these elements within our core courses is essential to preparing\nstudents to engage in data-driven inquiry at the scale that contemporary\nscientific and industrial applications demand. This new curriculum is already\nreshaping the undergraduate experience at Berkeley, where these courses have\nbecome some of the most popular on campus and have led to a surging interest in\na new undergraduate major and minor program in data science.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 22:51:24 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 00:15:43 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 04:05:45 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Adhikari", "Ani", ""], ["DeNero", "John", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2102.09392", "submitter": "Jacob Swambo MSci", "authors": "Jacob Swambo and Antoine Poinsot", "title": "Risk Framework for Bitcoin Custody Operation with the Revault Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our contributions with this paper are twofold. First, we elucidate the\nmethodological requirements for a risk framework of custodial operations and\nargue for the value of this type of risk model as complementary with\ncryptographic and blockchain security models. Second, we present a risk model\nin the form of a library of attack-trees for Revault -- an open-source custody\nprotocol. The model can be used by organisations as a risk quantification\nframework for a thorough security analysis in their specific deployment\ncontext. Our work exemplifies an approach that can be used independent of which\ncustody protocol is being considered, including complex protocols with multiple\nstakeholders and active defence infrastructure.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 11:26:15 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 10:45:34 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Swambo", "Jacob", ""], ["Poinsot", "Antoine", ""]]}, {"id": "2102.09400", "submitter": "Ben Clegg", "authors": "Benjamin Clegg (1), Maria-Cruz Villa-Uriol (1), Phil McMinn (1),\n  Gordon Fraser (2) ((1) University of Sheffield, (2) University of Passau)", "title": "Gradeer: An Open-Source Modular Hybrid Grader", "comments": "To appear at ICSE-JSEET 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated assessment has been shown to greatly simplify the process of\nassessing students' programs. However, manual assessment still offers benefits\nto both students and tutors. We introduce Gradeer, a hybrid assessment tool,\nwhich allows tutors to leverage the advantages of both automated and manual\nassessment. The tool features a modular design, allowing new grading\nfunctionality to be added. Gradeer directly assists manual grading, by\nautomatically loading code inspectors, running students' programs, and allowing\ngrading to be stopped and resumed in place at a later time. We used Gradeer to\nassess an end of year assignment for an introductory Java programming course,\nand found that its hybrid approach offers several benefits.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 21:36:43 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Clegg", "Benjamin", "", "University of Sheffield"], ["Villa-Uriol", "Maria-Cruz", "", "University of Sheffield"], ["McMinn", "Phil", "", "University of Sheffield"], ["Fraser", "Gordon", "", "University of Passau"]]}, {"id": "2102.09401", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris, Ian Cole and Francesc X. Prenafeta-Boldu", "title": "Blockchain in agriculture", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.07391", "journal-ref": "Book Chapter. Food Technology Disruptions Book, Elsevier, Charis\n  Galanakis (Editor), January 2021. (ISBN: 9780128214749)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain is an emerging digital technology allowing ubiquitous financial\ntransactions among distributed untrusted parties, without the need of\nintermediaries such as banks. This chapter examines the impact of blockchain\ntechnology in agriculture and food supply chain, presents existing ongoing\nprojects and initiatives, and discusses overall implications, challenges and\npotential, with a critical view over the maturity of these projects. Our\nfindings indicate that blockchain is a promising technology towards a\ntransparent supply chain of food, with many ongoing initiatives in various food\nproducts and food-related issues, but many barriers and challenges still exist,\nwhich hinder its wider popularity among farmers and systems. These challenges\ninvolve technical aspects, education, policies and regulatory frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 15:28:37 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Cole", "Ian", ""], ["Prenafeta-Boldu", "Francesc X.", ""]]}, {"id": "2102.09461", "submitter": "Manion Anderson", "authors": "Manion Anderson, Merve Bodur, Scott Rathwell, Vahid Sarhangian", "title": "Optimization Helps Scheduling Nursing Staff at the Long-Term Care Homes\n  of the City of Toronto", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The City of Toronto Long Term Care Homes & Services (LTCH&S) division is one\nof the largest providers of long-term care in the Canadian province of Ontario,\nproviding care to 2,640 residents at 10 homes across Toronto. Our collaboration\nwith LTCH&S was initiated to facilitate the increasingly challenging task of\nscheduling nursing staff and reduce high absenteeism rate observed among the\npart-time nurses. We developed a spreadsheet-based scheduling tool to automate\nthe generation of schedules and incorporate nurses' preferences for different\nshifts into the schedules. At the core of the scheduling tool is a hierarchical\noptimization model that generates a feasible schedule with the highest total\npreference score while satisfying the maximum possible demand. Feasible\nschedules had to abide by a set of complex seniority requirements which\nprioritized more senior nurses when allocating the available shifts. Our\nscheduling tool was implemented in a 391-bed home in Toronto. The tool allowed\nnursing managers to generate feasible schedules within a fraction of an hour,\nin contrast to the status-quo manual approach which could took up to tens of\nhours. In addition, the schedules successfully accounted for preferences with\non average above 94% of the allocated shifts ranked as most preferred.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 00:10:35 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Anderson", "Manion", ""], ["Bodur", "Merve", ""], ["Rathwell", "Scott", ""], ["Sarhangian", "Vahid", ""]]}, {"id": "2102.09548", "submitter": "Kexin Huang", "authors": "Kexin Huang, Tianfan Fu, Wenhao Gao, Yue Zhao, Yusuf Roohani, Jure\n  Leskovec, Connor W. Coley, Cao Xiao, Jimeng Sun, Marinka Zitnik", "title": "Therapeutics Data Commons: Machine Learning Datasets and Tasks for\n  Therapeutics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY q-bio.BM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for therapeutics is an emerging field with incredible\nopportunities for innovation and expansion. Despite the initial success, many\nkey challenges remain open. Here, we introduce Therapeutics Data Commons (TDC),\nthe first unifying framework to systematically access and evaluate machine\nlearning across the entire range of therapeutics. At its core, TDC is a\ncollection of curated datasets and learning tasks that can translate\nalgorithmic innovation into biomedical and clinical implementation. To date,\nTDC includes 66 machine learning-ready datasets from 22 learning tasks,\nspanning the discovery and development of safe and effective medicines. TDC\nalso provides an ecosystem of tools, libraries, leaderboards, and community\nresources, including data functions, strategies for systematic model\nevaluation, meaningful data splits, data processors, and molecule generation\noracles. All datasets and learning tasks are integrated and accessible via an\nopen-source library. We envision that TDC can facilitate algorithmic and\nscientific advances and accelerate development, validation, and transition into\nproduction and clinical implementation. TDC is a continuous, open-source\ninitiative, and we invite contributions from the research community. TDC is\npublicly available at https://tdcommons.ai.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:50:31 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Huang", "Kexin", ""], ["Fu", "Tianfan", ""], ["Gao", "Wenhao", ""], ["Zhao", "Yue", ""], ["Roohani", "Yusuf", ""], ["Leskovec", "Jure", ""], ["Coley", "Connor W.", ""], ["Xiao", "Cao", ""], ["Sun", "Jimeng", ""], ["Zitnik", "Marinka", ""]]}, {"id": "2102.09674", "submitter": "Berenike Vollmer BVollmer", "authors": "Berenike Vollmer", "title": "NATOs Mission-Critical Space Capabilities under Threat: Cybersecurity\n  Gaps in the Military Space Asset Supply Chain", "comments": "93 pages, 6 Tables, 19 High-Level Interviews; Research collaboration\n  with NATO Cooperative Cyber Defence Centre of Excellence (CCDCOE) Tallinn,\n  Estonia; Keywords: NATO, military, cybersecurity, space, SATCOM, supply\n  chain, intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The North Atlantic Treaty Organizations (NATO) public-private Space Asset\nSupply Chain (SASC) currently exhibits significant cybersecurity gaps. It is\nwell-established that data obtained from space assets is fundamental to NATO,\nas they allow for the facilitation of its missions, self-defence and effective\ndeterrence of its adversaries. Any hostile cyber operation, suspending control\nover a space asset, severely impacts both NATO missions and allied Member\nStates national security. This threat is exacerbated by NATOs mostly\nunregulated cyber SASC. Hence, this thesis answers a twofold research question:\na) What are current cybersecurity gaps along NATOs global SASC; and b) How can\nNATO and its allied Member States gain greater control over such gaps to\nsafeguard the supply of NATO mission-critical information? An ontological field\nstudy is carried out by conducting nineteen semi-structured interviews with\nhigh-level representatives from relevant public, private and academic\norganizations. This research was undertaken in collaboration with the NATO\nCooperative Cyber Defence Centre of Excellence (CCDCOE) in Tallinn, Estonia.\nThis thesis concludes that current cybersecurity gaps along NATOs SASC are\ncaused by cyber vulnerabilities such as legacy systems or the use of\nCommercial-Off-the-Shelf (COTS) technology. Inadequate cyber SASC management is\ncaused by hindrances such as misaligned classification levels and significant\nunderstaffing. On this basis, NATO should consider two major collaboration\ninitiatives: a) Raising Awareness throughout the whole of the NATO system, and\nb) Pushing forward the creation of regulation through a standardized security\nframework on SASC cybersecurity. Doing so would enable NATO and its Member\nStates to recognise cyberthreats to mission-critical data early on along its\ncyber SASC, and thus increase transparency, responsibility, and liability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:45:09 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Vollmer", "Berenike", ""]]}, {"id": "2102.09904", "submitter": "Michael Bommarito Ii", "authors": "Ethan Bommarito, Michael J Bommarito II", "title": "An Empirical Analysis of the R Package Ecosystem", "comments": "20 pages, 3 figures, 23 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CY cs.SE physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this research, we present a comprehensive, longitudinal empirical summary\nof the R package ecosystem, including not just CRAN, but also Bioconductor and\nGitHub. We analyze more than 25,000 packages, 150,000 releases, and 15 million\nfiles across two decades, providing comprehensive counts and trends for common\nmetrics across packages, releases, authors, licenses, and other important\nmetadata. We find that the historical growth of the ecosystem has been robust\nunder all measures, with a compound annual growth rate of 29% for active\npackages, 28% for new releases, and 26% for active maintainers. As with many\nsimilar social systems, we find a number of highly right-skewed distributions\nwith practical implications, including the distribution of releases per\npackage, packages and releases per author or maintainer, package and maintainer\ndependency in-degree, and size per package and release. For example, the top\nfive packages are imported by nearly 25% of all packages, and the top ten\nmaintainers support packages that are imported by over half of all packages. We\nalso highlight the dynamic nature of the ecosystem, recording both dramatic\nacceleration and notable deceleration in the growth of R. From a licensing\nperspective, we find a notable majority of packages are distributed under\ncopyleft licensing or omit licensing information entirely. The data, methods,\nand calculations herein provide an anchor for public discourse and industry\ndecisions related to R and CRAN, serving as a foundation for future research on\nthe R software ecosystem and \"data science\" more broadly.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 12:55:18 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Bommarito", "Ethan", ""], ["Bommarito", "Michael J", "II"]]}, {"id": "2102.09905", "submitter": "Lotfi Ben Othmane", "authors": "Lotfi ben Othmane and Ameerah-Muhsina Jamil", "title": "Self-Confidence of Undergraduate Students in Designing Software\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Contributions: This paper investigates the relations between undergraduate\nsoftware architecture students' self-confidence and their course expectations,\ncognitive levels, preferred learning methods, and critical thinking.\nBackground: these students, often, lack self-confidence in their ability to use\ntheir knowledge to design software architectures. Intended Outcomes:\nSelf-confidence is expected to be related to the students' course expectations,\ncognitive levels, preferred learning methods, and critical thinking.\nApplication Design: We developed a questionnaire with open-ended questions to\nassess the self-confidence levels and related factors, which was taken by\none-hundred ten students in two semesters. The students answers were coded and\nanalyzed afterward. Findings: We found that self-confidence is weakly\nassociated with the students' course expectations and critical thinking and\nindependent from their cognitive levels and preferred learning methods. The\nresults suggest that to improve the self-confidence of the students, the\ninstructors should ensure that the students' have \"correct\" course expectations\nand work on improving the students' critical thinking capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 06:06:30 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Othmane", "Lotfi ben", ""], ["Jamil", "Ameerah-Muhsina", ""]]}, {"id": "2102.09974", "submitter": "Luisa Fernanda Roa Ballen", "authors": "Luisa Roa, Andr\\'es Rodr\\'iguez-Rey, Alejandro Correa-Bahnsen, Carlos\n  Valencia", "title": "Supporting Financial Inclusion with Graph Machine Learning and Super-App\n  Alternative Data", "comments": "Accepted to be appeared in IntelliSys2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY q-fin.GN", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The presence of Super-Apps have changed the way we think about the\ninteractions between users and commerce. It then comes as no surprise that it\nis also redefining the way banking is done. The paper investigates how\ndifferent interactions between users within a Super-App provide a new source of\ninformation to predict borrower behavior. To this end, two experiments with\ndifferent graph-based methodologies are proposed, the first uses graph based\nfeatures as input in a classification model and the second uses graph neural\nnetworks. Our results show that variables of centrality, behavior of\nneighboring users and transactionality of a user constituted new forms of\nknowledge that enhance statistical and financial performance of credit risk\nmodels. Furthermore, opportunities are identified for Super-Apps to redefine\nthe definition of credit risk by contemplating all the environment that their\nplatforms entail, leading to a more inclusive financial system.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 15:13:06 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Roa", "Luisa", ""], ["Rodr\u00edguez-Rey", "Andr\u00e9s", ""], ["Correa-Bahnsen", "Alejandro", ""], ["Valencia", "Carlos", ""]]}, {"id": "2102.10006", "submitter": "Neo Chung-Kit Yiu", "authors": "Neo C.K. Yiu", "title": "An Overview of Forks and Coordination in Blockchain Development", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.36579.07207", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a continuously developing technology that has made digital\ntransactions and related computing operations more transparent and secure\nthrough globally distributed and decentralized management of states, as well as\nthe strong immutability of blocks mined and transactions validated in a network\nenabled by the blockchain technology. This manuscript is aimed at elaborating\nthe concept of blockchain technology alongside its coordination and\nimplementation with other emerging technologies, such as smart contract, which\nworks with different blockchain frameworks, as well as enabling anonymous\ntransactions and decentralized consensus amongst different untrusting parties.\nThe discussion of blockchain forks is also covered in this manuscript,\ndepicting fork events created in the blockchain process, their brief history,\ntypes, and impacts upon the blockchain development and operation.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:18:16 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Yiu", "Neo C. K.", ""]]}, {"id": "2102.10087", "submitter": "Monika Singh", "authors": "Monika Singh", "title": "Essential Characteristics of Approximate matching algorithms: A Survey\n  of Practitioners Opinions and requirement regarding Approximate Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital forensic investigation has become more challenging due to the rapid\ngrowth in the volume of encountered data. It is difficult for an investigator\nto examine the entire volume of encountered data manually. Approximate Matching\nalgorithms are being used to serve the purpose by automatically filtering\ncorrelated and relevant data that an investigator needs to examine manually.\nPresently there are several prominent approximate matching tools and technique\nthose are being used to assist critical investigation process. However, to\nmeasure the guarantees of a tool, it is important to understand the exact\nrequirement of an investigator regarding these algorithms. This paper presents\nthe findings of a closed survey conducted among a highly experienced group of\nfederal state and local law enforcement practitioners and researchers, aimed to\nunderstand the practitioner and researcher's opinion regarding approximate\nmatching algorithms. The study provides the baseline attributes of approximate\nmatching tools that a scheme should possess to meet the real requirement of an\ninvestigator.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:40:27 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Singh", "Monika", ""]]}, {"id": "2102.10090", "submitter": "Thorsten Ruprechter", "authors": "Thorsten Ruprechter, Manoel Horta Ribeiro, Tiago Santos, Florian\n  Lemmerich, Markus Strohmaier, Robert West, Denis Helic", "title": "Volunteer contributions to Wikipedia increased during COVID-19 mobility\n  restrictions", "comments": "Main manuscript (pages 1-13) and Supplementary Information (pages\n  14-31)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia, the largest encyclopedia ever created, is a global initiative\ndriven by volunteer contributions. When the COVID-19 pandemic broke out and\nmobility restrictions ensued across the globe, it was unclear whether Wikipedia\nvolunteers would become less active in the face of the pandemic, or whether\nthey would rise to meet the increased demand for high-quality information\ndespite the added stress inflicted by this crisis. Analyzing 223 million edits\ncontributed from 2018 to 2020 across twelve Wikipedia language editions, we\nfind that Wikipedia's global volunteer community responded remarkably to the\npandemic, substantially increasing both productivity and the number of\nnewcomers who joined the community. For example, contributions to the English\nWikipedia increased by over 20% compared to the expectation derived from\npre-pandemic data. Our work sheds light on the response of a global volunteer\npopulation to the COVID-19 crisis, providing valuable insights into the\nbehavior of critical online communities under stress.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:46:16 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Ruprechter", "Thorsten", ""], ["Ribeiro", "Manoel Horta", ""], ["Santos", "Tiago", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""], ["West", "Robert", ""], ["Helic", "Denis", ""]]}, {"id": "2102.10133", "submitter": "Leny Vinceslas", "authors": "Leny Vinceslas, Hirsh Pithadia, Safak Dogan, Srikumar Sundareshwar,\n  Ahmet M. Kondoz", "title": "Abstracting data in distributed ledger systems for higher level\n  analytics and visualizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By design, distributed ledger technologies persist low-level data which makes\nconducting complex business analysis of the recorded operations challenging.\nExisting blockchain visualization and analytics tools such as block explorers\ntend to rely on this low-level data and complex interfacing to provide enriched\nlevel of analytics. The ability to derive richer analytics could be improved\nthrough the availability of a higher level abstraction of the data. This\narticle proposes an abstraction layer architecture that enables the design of\nhigh-level analytics of distributed ledger systems and the decentralized\napplications that run on top. Based on the analysis of existing initiatives and\nidentification of the relevant user requirements, this work aims to establish\nkey insights and specifications to improve the auditability and intuitiveness\nof distributed ledger systems by leveraging the development of future user\ninterfaces. To illustrate the benefits offered by the proposed abstraction\nlayer architecture, a regulated sector use case is explored.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 19:34:12 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Vinceslas", "Leny", ""], ["Pithadia", "Hirsh", ""], ["Dogan", "Safak", ""], ["Sundareshwar", "Srikumar", ""], ["Kondoz", "Ahmet M.", ""]]}, {"id": "2102.10349", "submitter": "Kweku Kwegyir-Aggrey", "authors": "Kweku Kwegyir-Aggrey, Rebecca Santorella, Sarah M. Brown", "title": "Everything is Relative: Understanding Fairness with Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To study discrimination in automated decision-making systems, scholars have\nproposed several definitions of fairness, each expressing a different fair\nideal. These definitions require practitioners to make complex decisions\nregarding which notion to employ and are often difficult to use in practice\nsince they make a binary judgement a system is fair or unfair instead of\nexplaining the structure of the detected unfairness. We present an optimal\ntransport-based approach to fairness that offers an interpretable and\nquantifiable exploration of bias and its structure by comparing a pair of\noutcomes to one another. In this work, we use the optimal transport map to\nexamine individual, subgroup, and group fairness. Our framework is able to\nrecover well known examples of algorithmic discrimination, detect unfairness\nwhen other metrics fail, and explore recourse opportunities.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 13:57:53 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kwegyir-Aggrey", "Kweku", ""], ["Santorella", "Rebecca", ""], ["Brown", "Sarah M.", ""]]}, {"id": "2102.10448", "submitter": "Panagiotis Kourtesis", "authors": "Panagiotis Kourtesis, Simona Collina, Leonidas A.A. Doumas, and Sarah\n  E. MacPherson", "title": "An ecologically valid examination of event-based and time-based\n  prospective memory using immersive virtual reality: the effects of delay and\n  task type on everyday prospective memory", "comments": "9 Figures, 4 Tables", "journal-ref": null, "doi": "10.1080/09658211.2021.1904996", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent research has focused on assessing either event- or time-based\nprospective memory (PM) using laboratory tasks. Yet, the findings pertaining to\nPM performance on laboratory tasks are often inconsistent with the findings on\ncorresponding naturalistic experiments. Ecologically valid neuropsychological\ntasks resemble the complexity and cognitive demands of everyday tasks, offer an\nadequate level of experimental control, and allow a generalisation of the\nfindings to everyday performance. The Virtual Reality Everyday Assessment Lab\n(VR-EAL), an immersive virtual reality neuropsychological battery with enhanced\necological validity, was implemented to comprehensively assess everyday PM\n(i.e., focal and non-focal event-based, and time-based). The effects of the\nlength of delay between encoding and initiating the PM intention and the type\nof PM task on everyday PM performance were examined. The results revealed that\neveryday PM performance was affected by the length of delay rather than the\ntype of PM task. The effect of the length of delay differentially affected\nperformance on the focal, non-focal, and time-based tasks and was proportional\nto the PM cue focality (i.e., semantic relationship with the intended action).\nThis study also highlighted methodological considerations such as the\ndifferentiation between functioning and ability, distinction of cue attributes,\nand the necessity of ecological validity.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 21:24:12 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Kourtesis", "Panagiotis", ""], ["Collina", "Simona", ""], ["Doumas", "Leonidas A. A.", ""], ["MacPherson", "Sarah E.", ""]]}, {"id": "2102.10468", "submitter": "Panagiotis Adamopoulos", "authors": "Panagiotis Adamopoulos, Anindya Ghose, Alexander Tuzhilin", "title": "Heterogeneous Demand Effects of Recommendation Strategies in a Mobile\n  Application: Evidence from Econometric Models and Machine-Learning\n  Instruments", "comments": "Forthcoming at MIS Quarterly", "journal-ref": "MIS Quarterly, 2021", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the effectiveness of various recommendation\nstrategies in the mobile channel and their impact on consumers' utility and\ndemand levels for individual products. We find significant differences in\neffectiveness among various recommendation strategies. Interestingly,\nrecommendation strategies that directly embed social proofs for the recommended\nalternatives outperform other recommendations. Besides, recommendation\nstrategies combining social proofs with higher levels of induced awareness due\nto the prescribed temporal diversity have an even stronger effect on the mobile\nchannel. In addition, we examine the heterogeneity of the demand effect across\nitems, users, and contextual settings, further verifying empirically the\naforementioned information and persuasion mechanisms and generating rich\ninsights. We also facilitate the estimation of causal effects in the presence\nof endogeneity using machine-learning methods. Specifically, we develop novel\neconometric instruments that capture product differentiation (isolation) based\non deep-learning models of user-generated reviews. Our empirical findings\nextend the current knowledge regarding the heterogeneous impact of recommender\nsystems, reconcile contradictory prior results in the related literature, and\nhave significant business implications.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 22:58:54 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Adamopoulos", "Panagiotis", ""], ["Ghose", "Anindya", ""], ["Tuzhilin", "Alexander", ""]]}, {"id": "2102.10521", "submitter": "Ajayi Ekuase-Anwansedo", "authors": "Ajayi Ekuase-Anwansedo, Susannah F. Craig, Jose Noguera", "title": "How to Survive a Learning Management System (LMS) Implementation? A\n  Stakeholder Analysis Approach", "comments": null, "journal-ref": "In Proceedings of the 2018 ACM SIGUCCS Annual Conference (pp.\n  165-168) 2018", "doi": "10.1145/3235715.3235735", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To survive a learning management system (LMS) implementation an understanding\nof the needs of the various stakeholders is necessary. The goal of every LMS\nimplementation is to ensure the use of the system by instructors and students\nto enhance teaching and communication thereby enhancing learning outcomes of\nthe students. If the teachers and students do not use the system, the system is\nuseless. This research is motivated by the importance of identifying and\nunderstanding various stakeholders involved in the LMS implementation process\nin order to anticipate possible challenges and identify critical success\nfactors essential for the effective implementation and adoption of a new LMS\nsystem. To this end, we define the term stakeholder. We conducted a stakeholder\nanalysis to identify the key stakeholders in an LMS implementation process. We\nthen analyze their goals and needs, and how they collaborate in the\nimplementation process. The findings of this work will provide institutions of\nhigher learning an overview of the implementation process and useful insights\ninto the needs of the stakeholders, which will in turn ensure an increase in\nthe level of success achieved when implementing a LMS.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:10:30 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ekuase-Anwansedo", "Ajayi", ""], ["Craig", "Susannah F.", ""], ["Noguera", "Jose", ""]]}, {"id": "2102.10522", "submitter": "Ajayi Ekuase-Anwansedo", "authors": "Ajayi Ekuase-Anwansedo, Akai Smith", "title": "Effect of Cloud Based Learning Management System on The Learning\n  Management System Implementation Process: Faculty and Student Perspectives", "comments": null, "journal-ref": "In Proceedings of the 2019 ACM SIGUCCS Annual Conference (pp.\n  176-179) 2019", "doi": "10.1145/3347709.3347835", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of E-learning in Universities has grown rapidly over the years to\ninclude not just only a learning management system but also tools initially not\ndesigned for learning such as Facebook and advanced learning tools, for example\ngames, simulations and virtualization. As a result, Cloud-based LMS is being\ntouted as the next evolution of the traditional LMS. It is hoped that Cloud\nbased LMS will resolve some of the challenges associated with the traditional\nLMS implementation process. In a previous study, we reported that lack of\ninvolvement of faculty and students in the LMS implementation process results\nin the limited use of the LMS by faculty and students. The question then is,\nWill the cloud-based LMS resolve these issues? We conducted a review of\nliterature and presented an overview of the traditional LMS, cloud computing\nand the cloudbased LMS and we described how the cloud computing LMS resolve\nissues raised by faculty and students. we find that even though, cloud-based\nLMS resolve most of the technical issues associated with the traditional LMS,\nsome of the human issues were not resolved. We hope that this study draws\nattention to non-technical issues associated with the LMS implementation\nprocess.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:12:04 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ekuase-Anwansedo", "Ajayi", ""], ["Smith", "Akai", ""]]}, {"id": "2102.10523", "submitter": "Ajayi Ekuase-Anwansedo", "authors": "Ajayi Ekuase-Anwansedo, Jose Noguera, Brandon Dumas", "title": "Transitioning from Blackboard to Moodle amidst Natural Disaster: Faculty\n  and Students Perceptions", "comments": null, "journal-ref": "In Proceedings of the 2017 ACM SIGUCCS Annual Conference (pp.\n  19-22) 2017", "doi": "10.1145/3123458.3123467", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Higher educational institutions continuously look for ways to improve the\nquality of their eLearning services and adapt learning solutions to suit the\nneeds of the institution. During the 2016 Fall Semester, a university located\nin the Southern part of United States decided to transition from the Blackboard\nlearning management system (LMS) to the Moodle learning management system.\nTypically such a transition presents a huge challenge for the University staff,\nfaculty, and students. Additionally, on August 2016, what CNN themedthe worst\nnatural disaster, to strike the United States since Hurricane Sandy, occurred\nin Louisiana during the transition. This led to massive disruptions in\nactivities throughout the state. This paper examines the perceptions of both\nfaculty and student on the transition from one LMS to another and also what\nimpact, if any, the natural disaster had on the process. Faculty and students\nwere surveyed to gain understanding of how they perceived the transitioning\nprocess, their perception of both systems, their preferences, and why.\nFurthermore, we identified issues peculiar to transitioning during a natural\ndisaster. The results of this study can be used to anticipate issues that may\nbe associated with transitioning from one LMS to the other and issues peculiar\nto transitioning amidst a natural disaster. It can also be used to identify\nareas for improvement.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:17:30 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ekuase-Anwansedo", "Ajayi", ""], ["Noguera", "Jose", ""], ["Dumas", "Brandon", ""]]}, {"id": "2102.10531", "submitter": "Sukanta Das Dr.", "authors": "Souvik Roy and Milan Mukherjee and Priyadarsini Sinha and Sukanta Das\n  and Subhasis Bandopadhyay and Abhik Mukherjee", "title": "Exploring the dynamics of protest against National Register of Citizens\n  & Citizenship Amendment Act through online social media: the Indian\n  experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generic fluidity observed in the nature of political protest movements\nacross the world during the last decade weigh heavily with the presence of\nsocial media. As such, there is a possibility to study the contemporary\nmovements with an interdisciplinary approach combining computational analytics\nwith social science perspectives. The present study has put efforts to\nunderstand such dynamics in the context of the ongoing nationwide movement in\nIndia opposing the NRC-CAA enactment. The transformative nature of individual\ndiscontent into collective mobilization, especially with a reflective\nintervention in social media across a sensitive region of the nation state, is\npresented here with a combination of qualitative (fieldwork) and quantitative\n(computing) techniques. The study is augmented further by the primary data\ngeneration coupled with real-time application of analytical approaches.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:56:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Roy", "Souvik", ""], ["Mukherjee", "Milan", ""], ["Sinha", "Priyadarsini", ""], ["Das", "Sukanta", ""], ["Bandopadhyay", "Subhasis", ""], ["Mukherjee", "Abhik", ""]]}, {"id": "2102.10538", "submitter": "Zhenyu Han", "authors": "Zhenyu Han, Fengli Xu, Yong Li, Tao Jiang, Depeng Jin, Jianhua Lu,\n  James A. Evans", "title": "Policy-Aware Mobility Model Explains the Growth of COVID-19 in Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the continued spread of coronavirus, the task of forecasting distinctive\nCOVID-19 growth curves in different cities, which remain inadequately explained\nby standard epidemiological models, is critical for medical supply and\ntreatment. Predictions must take into account non-pharmaceutical interventions\nto slow the spread of coronavirus, including stay-at-home orders, social\ndistancing, quarantine and compulsory mask-wearing, leading to reductions in\nintra-city mobility and viral transmission. Moreover, recent work associating\ncoronavirus with human mobility and detailed movement data suggest the need to\nconsider urban mobility in disease forecasts. Here we show that by\nincorporating intra-city mobility and policy adoption into a novel\nmetapopulation SEIR model, we can accurately predict complex COVID-19 growth\npatterns in U.S. cities ($R^2$ = 0.990). Estimated mobility change due to\npolicy interventions is consistent with empirical observation from Apple\nMobility Trends Reports (Pearson's R = 0.872), suggesting the utility of\nmodel-based predictions where data are limited. Our model also reproduces urban\n\"superspreading\", where a few neighborhoods account for most secondary\ninfections across urban space, arising from uneven neighborhood populations and\nheightened intra-city churn in popular neighborhoods. Therefore, our model can\nfacilitate location-aware mobility reduction policy that more effectively\nmitigates disease transmission at similar social cost. Finally, we demonstrate\nour model can serve as a fine-grained analytic and simulation framework that\ninforms the design of rational non-pharmaceutical interventions policies.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 07:39:17 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Han", "Zhenyu", ""], ["Xu", "Fengli", ""], ["Li", "Yong", ""], ["Jiang", "Tao", ""], ["Jin", "Depeng", ""], ["Lu", "Jianhua", ""], ["Evans", "James A.", ""]]}, {"id": "2102.10635", "submitter": "Arun Das", "authors": "Shadi Ghafghazi, Amarie Carnett, Leslie Neely, Arun Das, Paul Rad", "title": "AI-Augmented Behavior Analysis for Children with Developmental\n  Disabilities: Building Towards Precision Treatment", "comments": "Accepted to IEEE SMC Magazine. Updated IEEE copyright policy to\n  thanks section on Page 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autism spectrum disorder is a developmental disorder characterized by\nsignificant social, communication, and behavioral challenges. Individuals\ndiagnosed with autism, intellectual, and developmental disabilities (AUIDD)\ntypically require long-term care and targeted treatment and teaching. Effective\ntreatment of AUIDD relies on efficient and careful behavioral observations done\nby trained applied behavioral analysts (ABAs). However, this process\noverburdens ABAs by requiring the clinicians to collect and analyze data,\nidentify the problem behaviors, conduct pattern analysis to categorize and\npredict categorical outcomes, hypothesize responsiveness to treatments, and\ndetect the effects of treatment plans. Successful integration of digital\ntechnologies into clinical decision-making pipelines and the advancements in\nautomated decision-making using Artificial Intelligence (AI) algorithms\nhighlights the importance of augmenting teaching and treatments using novel\nalgorithms and high-fidelity sensors. In this article, we present an\nAI-Augmented Learning and Applied Behavior Analytics (AI-ABA) platform to\nprovide personalized treatment and learning plans to AUIDD individuals. By\ndefining systematic experiments along with automated data collection and\nanalysis, AI-ABA can promote self-regulative behavior using reinforcement-based\naugmented or virtual reality and other mobile platforms. Thus, AI-ABA could\nassist clinicians to focus on making precise data-driven decisions and increase\nthe quality of individualized interventions for individuals with AUIDD.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 16:15:40 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 16:23:46 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ghafghazi", "Shadi", ""], ["Carnett", "Amarie", ""], ["Neely", "Leslie", ""], ["Das", "Arun", ""], ["Rad", "Paul", ""]]}, {"id": "2102.10961", "submitter": "Raju Singh", "authors": "Raju", "title": "Mutation Testing framework for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is an article or technical note which is intended to provides an insight\njourney of Machine Learning Systems (MLS) testing, its evolution, current\nparadigm and future work. Machine Learning Models, used in critical\napplications such as healthcare industry, Automobile, and Air Traffic control,\nShare Trading etc., and failure of ML Model can lead to severe consequences in\nterms of loss of life or property. To remediate this, developers, scientists,\nand ML community around the world, must build a highly reliable test\narchitecture for critical ML application. At the very foundation layer, any\ntest model must satisfy the core testing attributes such as test properties and\nits components. This attribute comes from the software engineering, but the\nsame cannot be applied in as-is form to the ML testing and we will tell you\nwhy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 18:02:31 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Raju", "", ""]]}, {"id": "2102.11009", "submitter": "Justin Lane", "authors": "Justin E. Lane, Kevin McCaffree, F. LeRon Shults", "title": "The Moral Foundations of Left-Wing Authoritarianism: On the Character,\n  Cohesion, and Clout of Tribal Equalitarian Discourse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Left-wing authoritarianism remains far less understood than right-wing\nauthoritarianism. We contribute to the literature on the former, which\ntypically relies on surveys, using a new social media analytics approach. We\nuse a list of 60 terms to provide an exploratory sketch of the outlines of a\npolitical ideology (tribal equalitarianism) with origins in 19th and 20th\ncentury social philosophy. We then use analyses of the English Corpus of Google\nBooks (over 8 million books) and scraped unique tweets from Twitter (n =\n202,852) to conduct a series of investigations to discern the extent to which\nthis ideology is cohesive amongst the public, reveals signatures of\nauthoritarianism and has been growing in popularity. Though exploratory, our\nresults provide some evidence of left-wing authoritarianism in two forms (1) a\nuniquely conservative moral signature amongst ostensible liberals using\nmeasures from Moral Foundations Theory and (2) a substantial prevalence of\nanger, relative to anxiety or sadness. In general, results indicate that this\nworldview is growing in popularity, is increasingly cohesive, and shows\nsignatures of authoritarianism.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 14:06:25 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Lane", "Justin E.", ""], ["McCaffree", "Kevin", ""], ["Shults", "F. LeRon", ""]]}, {"id": "2102.11027", "submitter": "Alina Lazar", "authors": "Ling Jin, C. Anna Spurlock, Sam Borgeson, Alina Lazar, Daniel Fredman,\n  Annika Todd, Alexander Sim, Kesheng Wu", "title": "Investigating Underlying Drivers of Variability in Residential Energy\n  Usage Patterns with Daily Load Shape Clustering of Smart Meter Data", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residential customers have traditionally not been treated as individual\nentities due to the high volatility in residential consumption patterns as well\nas a historic focus on aggregated loads from the utility and system feeder\nperspective. Large-scale deployment of smart meters has motivated increasing\nstudies to explore disaggregated daily load patterns, which can reveal\nimportant heterogeneity across different time scales, weather conditions, as\nwell as within and across individual households. This paper aims to shed light\non the mechanisms by which electricity consumption patterns exhibit variability\nand the different constraints that may affect demand-response (DR) flexibility.\nWe systematically evaluate the relationship between daily time-of-use patterns\nand their variability to external and internal influencing factors, including\ntime scales of interest, meteorological conditions, and household\ncharacteristics by application of an improved version of the adaptive K-means\nclustering method to profile \"household-days\" of a summer peaking utility. We\nfind that for this summer-peaking utility, outdoor temperature is the most\nimportant external driver of the load shape variability relative to seasonality\nand day-of-week. The top three consumption patterns represent approximately 50%\nof usage on the highest temperature days. The variability in summer load shapes\nacross customers can be explained by the responsiveness of the households to\noutside temperature. Our results suggest that depending on the influencing\nfactors, not all the consumption variability can be readily translated to\nconsumption flexibility. Such information needs to be further explored in\nsegmenting customers for better program targeting and tailoring to meet the\nneeds of the rapidly evolving electricity grid.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 16:56:27 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Jin", "Ling", ""], ["Spurlock", "C. Anna", ""], ["Borgeson", "Sam", ""], ["Lazar", "Alina", ""], ["Fredman", "Daniel", ""], ["Todd", "Annika", ""], ["Sim", "Alexander", ""], ["Wu", "Kesheng", ""]]}, {"id": "2102.11147", "submitter": "Jos\\'e Manuel Redondo L\\'opez", "authors": "Jose Manuel Redondo", "title": "Improving Concept Learning Through Specialized Digital Fanzines", "comments": "10 pages, 3 figures, ICSE 2021 conference, Joint Track on Software\n  Engineering Education and Training (JSEET)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specialized digital fanzines were successfully used to facilitate learning\nproblematic concepts in an undergraduate programming course, dynamically\nadapting to student needs. The design of these fanzines favors creating and\nreading them quickly by establishing a common graphical layout, rules, and\nfocusing in the most problematic parts of the concepts. This paper details the\nagile fanzine creation procedure, the way problematic concepts were identified\nand quickly handled, and how this approach was implemented in an actual course,\nso it could be applied to other courses with similar needs.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:18:28 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Redondo", "Jose Manuel", ""]]}, {"id": "2102.11171", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Yunze Pan, Yunqi Zhang, Adam C. Champion, Zhaohui Shen,\n  Dong Xuan, Zhiqiang Lin, Ness B. Shroff", "title": "WLAN-Log-Based Superspreader Detection in the COVID-19 Pandemic", "comments": "Accepted to Elsevier High-Confidence Computing Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying \"superspreaders\" of disease is a pressing concern for society\nduring pandemics such as COVID-19. Superspreaders represent a group of people\nwho have much more social contacts than others. The widespread deployment of\nWLAN infrastructure enables non-invasive contact tracing via people's\nubiquitous mobile devices. This technology offers promise for detecting\nsuperspreaders. In this paper, we propose a general framework for\nWLAN-log-based superspreader detection. In our framework, we first use WLAN\nlogs to construct contact graphs by jointly considering human symmetric and\nasymmetric interactions. Next, we adopt three vertex centrality measurements\nover the contact graphs to generate three groups of superspreader candidates.\nFinally, we leverage SEIR simulation to determine groups of superspreaders\namong these candidates, who are the most critical individuals for the spread of\ndisease based on the simulation results. We have implemented our framework and\nevaluate it over a WLAN dataset with 41 million log entries from a large-scale\nuniversity. Our evaluation shows superspreaders exist on university campuses.\nThey change over the first few weeks of a semester, but stabilize throughout\nthe rest of the term. The data also demonstrate that both symmetric and\nasymmetric contact tracing can discover superspreaders, but the latter performs\nbetter with daily contact graphs. Further, the evaluation shows no consistent\ndifferences among three vertex centrality measures for long-term (i.e., weekly)\ncontact graphs, which necessitates the inclusion of SEIR simulation in our\nframework. We believe our proposed framework and these results may provide\ntimely guidance for public health administrators regarding effective testing,\nintervention, and vaccination policies.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 16:49:17 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 04:52:45 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Zhang", "Cheng", ""], ["Pan", "Yunze", ""], ["Zhang", "Yunqi", ""], ["Champion", "Adam C.", ""], ["Shen", "Zhaohui", ""], ["Xuan", "Dong", ""], ["Lin", "Zhiqiang", ""], ["Shroff", "Ness B.", ""]]}, {"id": "2102.11211", "submitter": "Jip Van Stijn", "authors": "Jip van Stijn", "title": "Moral Decision-Making in Medical Hybrid Intelligent Systems: A Team\n  Design Patterns Approach to the Bias Mitigation and Data Sharing Design\n  Problems", "comments": "87 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Increasing automation in the healthcare sector calls for a Hybrid\nIntelligence (HI) approach to closely study and design the collaboration of\nhumans and autonomous machines. Ensuring that medical HI systems'\ndecision-making is ethical is key. The use of Team Design Patterns (TDPs) can\nadvance this goal by describing successful and reusable configurations of\ndesign problems in which decisions have a moral component, as well as through\nfacilitating communication in multidisciplinary teams designing HI systems. For\nthis research, TDPs were developed to describe a set of solutions for two\ndesign problems in a medical HI system: (1) mitigating harmful biases in\nmachine learning algorithms and (2) sharing health and behavioral patient data\nwith healthcare professionals and system developers. The Socio-Cognitive\nEngineering methodology was employed, integrating operational demands, human\nfactors knowledge, and a technological analysis into a set of TDPs. A survey\nwas created to assess the usability of the patterns on their understandability,\neffectiveness, and generalizability. The results showed that TDPs are a useful\nmethod to unambiguously describe solutions for diverse HI design problems with\na moral component on varying abstraction levels, that are usable by a\nheterogeneous group of multidisciplinary researchers. Additionally, results\nindicated that the SCE approach and the developed questionnaire are suitable\nmethods for creating and assessing TDPs. The study concludes with a set of\nproposed improvements to TDPs, including their integration with Interaction\nDesign Patterns, the inclusion of several additional concepts, and a number of\nmethodological improvements. Finally, the thesis recommends directions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:09:43 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["van Stijn", "Jip", ""]]}, {"id": "2102.11235", "submitter": "Duilio Balsamo", "authors": "Duilio Balsamo, Paolo Bajardi, Alberto Salomone, Rossano Schifanella", "title": "Patterns of Routes of Administration and Drug Tampering for Nonmedical\n  Opioid Consumption: Data Mining and Content Analysis of Reddit Discussions", "comments": null, "journal-ref": "J Med Internet Res 2021;23(1):e21212", "doi": "10.2196/21212", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The complex unfolding of the US opioid epidemic in the last 20 years has been\nthe subject of a large body of medical and pharmacological research, and it has\nsparked a multidisciplinary discussion on how to implement interventions and\npolicies to effectively control its impact on public health. This study\nleverages Reddit as the primary data source to investigate the opioid crisis.\nWe aimed to find a large cohort of Reddit users interested in discussing the\nuse of opioids, trace the temporal evolution of their interest, and extensively\ncharacterize patterns of the nonmedical consumption of opioids, with a focus on\nroutes of administration and drug tampering. We used a semiautomatic\ninformation retrieval algorithm to identify subreddits discussing nonmedical\nopioid consumption, finding over 86,000 Reddit users potentially involved in\nfirsthand opioid usage. We developed a methodology based on word embedding to\nselect alternative colloquial and nonmedical terms referring to opioid\nsubstances, routes of administration, and drug-tampering methods. We modeled\nthe preferences of adoption of substances and routes of administration,\nestimating their prevalence and temporal unfolding, observing relevant trends\nsuch as the surge in synthetic opioids like fentanyl and an increasing interest\nin rectal administration. Ultimately, through the evaluation of odds ratios\nbased on co-mentions, we measured the strength of association between opioid\nsubstances, routes of administration, and drug tampering, finding evidence of\nunderstudied abusive behaviors like chewing fentanyl patches and dissolving\nbuprenorphine sublingually. We believe that our approach may provide a novel\nperspective for a more comprehensive understanding of nonmedical abuse of\nopioids substances and inform the prevention, treatment, and control of the\npublic health effects.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:14:48 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Balsamo", "Duilio", ""], ["Bajardi", "Paolo", ""], ["Salomone", "Alberto", ""], ["Schifanella", "Rossano", ""]]}, {"id": "2102.11276", "submitter": "Shivangi Singhal Ms", "authors": "Shivangi Singhal, Rajiv Ratn Shah, Ponnurangam Kumaraguru", "title": "Factorization of Fact-Checks for Low Resource Indian Languages", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advancement in technology and accessibility of internet to each\nindividual is revolutionizing the real time information. The liberty to express\nyour thoughts without passing through any credibility check is leading to\ndissemination of fake content in the ecosystem. It can have disastrous effects\non both individuals and society as a whole. The amplification of fake news is\nbecoming rampant in India too. Debunked information often gets republished with\na replacement description, claiming it to depict some different incidence. To\ncurb such fabricated stories, it is necessary to investigate such deduplicates\nand false claims made in public. The majority of studies on automatic\nfact-checking and fake news detection is restricted to English only. But for a\ncountry like India where only 10% of the literate population speak English,\nrole of regional languages in spreading falsity cannot be undermined. In this\npaper, we introduce FactDRIL: the first large scale multilingual Fact-checking\nDataset for Regional Indian Languages. We collect an exhaustive dataset across\n7 months covering 11 low-resource languages. Our propose dataset consists of\n9,058 samples belonging to English, 5,155 samples to Hindi and remaining 8,222\nsamples are distributed across various regional languages, i.e. Bangla,\nMarathi, Malayalam, Telugu, Tamil, Oriya, Assamese, Punjabi, Urdu, Sinhala and\nBurmese. We also present the detailed characterization of three M's\n(multi-lingual, multi-media, multi-domain) in the FactDRIL accompanied with the\ncomplete list of other varied attributes making it a unique dataset to study.\nLastly, we present some potential use cases of the dataset. We expect this\ndataset will be a valuable resource and serve as a starting point to fight\nproliferation of fake news in low resource languages.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 16:47:41 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Singhal", "Shivangi", ""], ["Shah", "Rajiv Ratn", ""], ["Kumaraguru", "Ponnurangam", ""]]}, {"id": "2102.11314", "submitter": "Yuval Shahar", "authors": "Erez Shalom, Ayelet Goldstein, Elior Ariel, Moshe Sheinberger, Valerie\n  Jones, Boris Van Schooten, and Yuval Shahar", "title": "Distributed Application of Guideline-Based Decision Support through\n  Mobile Devices: Implementation and Evaluation", "comments": "8 Tables and 16 figures in the main text; two Appendices, one\n  including 1 figure, the other including 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Traditionally Guideline(GL)based Decision Support Systems (DSSs) use a\ncentralized infrastructure to generate recommendations to care providers.\nHowever, managing patients at home is preferable, reducing costs and empowering\npatients. We aimed to design, implement, and demonstrate the feasibility of a\nnew architecture for a distributed DSS that provides patients with\npersonalized, context-sensitive, evidence based guidance through their mobile\ndevice, and increases the robustness of the distributed application of the GL,\nwhile maintaining access to the patient longitudinal record and to an up to\ndate evidence based GL repository. We have designed and implemented a novel\nprojection and callback (PCB) model, in which small portions of the evidence\nbased GL procedural knowledge, adapted to the patient preferences and to their\ncurrent context, are projected from a central DSS server, to a local DSS on the\npatient mobile device that applies that knowledge. When appropriate, as defined\nby a temporal pattern within the projected plan, the local DSS calls back the\ncentral DSS, requesting further assistance, possibly another projection. Thus,\nthe GL specification includes two levels: one for the central DSS, one for the\nlocal DSS. We successfully evaluated the PCB model within the MobiGuide EU\nproject by managing Gestational Diabetes Mellitus patients in Spain, and Atrial\nFibrillation patients in Italy. Significant differences exist between the two\nGL representations, suggesting additional ways to characterize GLs. Mean time\nbetween the central and local interactions was quite different for the two GLs:\n3.95 days for gestational diabetes, 23.80 days for atrial fibrillation. Most\ninteractions, 83%, were due to projections to the mDSS. Others were data\nnotifications, mostly to change context. Robustness was demonstrated through\nsuccessful recovery from multiple local DSS crashes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 19:20:03 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Shalom", "Erez", ""], ["Goldstein", "Ayelet", ""], ["Ariel", "Elior", ""], ["Sheinberger", "Moshe", ""], ["Jones", "Valerie", ""], ["Van Schooten", "Boris", ""], ["Shahar", "Yuval", ""]]}, {"id": "2102.11558", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris, Jean-Baptiste Filippi, Chirag Padubidri, Jesper\n  Provoost, Savvas Karatsiolis, Ian Cole, Wouter Couwenbergh and Evi Demetriou", "title": "EscapeWildFire: Assisting People to Escape Wildfires in Real-Time", "comments": "6th IEEE International Workshop on Pervasive Context-Aware Smart\n  Cities and Intelligent Transport System (PerAwareCity), Proc. of PerCom 2021,\n  Kassel, Germany, March, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past couple of decades, the number of wildfires and area of land\nburned around the world has been steadily increasing, partly due to climatic\nchanges and global warming. Therefore, there is a high probability that more\npeople will be exposed to and endangered by forest fires. Hence there is an\nurgent need to design pervasive systems that effectively assist people and\nguide them to safety during wildfires. This paper presents EscapeWildFire, a\nmobile application connected to a backend system which models and predicts\nwildfire geographical progression, assisting citizens to escape wildfires in\nreal-time. A small pilot indicates the correctness of the system. The code is\nopen-source; fire authorities around the world are encouraged to adopt this\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 08:58:37 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Filippi", "Jean-Baptiste", ""], ["Padubidri", "Chirag", ""], ["Provoost", "Jesper", ""], ["Karatsiolis", "Savvas", ""], ["Cole", "Ian", ""], ["Couwenbergh", "Wouter", ""], ["Demetriou", "Evi", ""]]}, {"id": "2102.11567", "submitter": "Nils K\\\"obis C", "authors": "Nils K\\\"obis, Christopher Starke, Iyad Rahwan", "title": "Artificial Intelligence as an Anti-Corruption Tool (AI-ACT) --\n  Potentials and Pitfalls for Top-down and Bottom-up Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Corruption continues to be one of the biggest societal challenges of our\ntime. New hope is placed in Artificial Intelligence (AI) to serve as an\nunbiased anti-corruption agent. Ever more available (open) government data\npaired with unprecedented performance of such algorithms render AI the next\nfrontier in anti-corruption. Summarizing existing efforts to use AI-based\nanti-corruption tools (AI-ACT), we introduce a conceptual framework to advance\nresearch and policy. It outlines why AI presents a unique tool for top-down and\nbottom-up anti-corruption approaches. For both approaches, we outline in detail\nhow AI-ACT present different potentials and pitfalls for (a) input data, (b)\nalgorithmic design, and (c) institutional implementation. Finally, we venture a\nlook into the future and flesh out key questions that need to be addressed to\ndevelop AI-ACT while considering citizens' views, hence putting \"society in the\nloop\".\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 09:14:19 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["K\u00f6bis", "Nils", ""], ["Starke", "Christopher", ""], ["Rahwan", "Iyad", ""]]}, {"id": "2102.11625", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "Assessing the Readability of Policy Documents on the Digital Single\n  Market of the European Union", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, literature skills are necessary. Engineering and other technical\nprofessions are not an exception from this requirement. Traditionally,\ntechnical reading and writing have been framed with a limited scope, containing\ndocumentation, specifications, standards, and related text types. Nowadays,\nhowever, the scope covers also other text types, including legal, policy, and\nrelated documents. Given this motivation, this paper evaluates the readability\nof 201 legislations and related policy documents in the European Union (EU).\nThe digital single market (DSM) provides the context and five classical\nreadability indices the methods. The empirical results indicate that (i)\ngenerally a Ph.D. level education is required to comprehend the DSM laws and\npolicy documents. Although (ii) the results vary across the five indices used,\n(iii) readability has slightly improved over time.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 11:01:11 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "2102.11652", "submitter": "Panagiotis Kourtesis", "authors": "Panagiotis Kourtesis and Sarah E. MacPherson", "title": "An ecologically valid examination of event-based and time-based\n  prospective memory using immersive virtual reality: the influence of\n  attention, memory, and executive function processes on real-world prospective\n  memory", "comments": "4 Figures , 4 Tables. arXiv admin note: text overlap with\n  arXiv:2102.10448", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Studies on prospective memory (PM) predominantly assess either event- or\ntime-based PM by implementing non-ecological laboratory-based tasks. The\nresults deriving from these paradigms have provided findings that are\ndiscrepant with ecologically valid research paradigms that converge on the\ncomplexity and cognitive demands of everyday tasks. The Virtual Reality\nEveryday Assessment Lab (VR-EAL), an immersive virtual reality (VR)\nneuropsychological battery with enhanced ecological validity, was implemented\nto assess everyday event- and time-based PM, as well as the influence of other\ncognitive functions on everyday PM functioning. The results demonstrated the\nimportance of delayed recognition, planning, and visuospatial attention on\neveryday PM. Delayed recognition and planning ability were found to be central\nin event- and time-based PM respectively. In order of importance, delayed\nrecognition, visuospatial attention speed, and planning ability were found to\nbe involved in event-based PM functioning. Comparably, planning, visuospatial\nattention accuracy, delayed recognition, and multitasking/task-shifting ability\nwere found to be involved in time-based PM functioning. These findings further\nsuggest the importance of ecological validity in the study of PM, which may be\nachieved using immersive VR paradigms.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 12:19:34 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Kourtesis", "Panagiotis", ""], ["MacPherson", "Sarah E.", ""]]}, {"id": "2102.11724", "submitter": "Lu Cheng", "authors": "Lu Cheng, Ruocheng Guo, Huan Liu", "title": "Causal Mediation Analysis with Hidden Confounders", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important problem in causal inference is to break down the total effect of\ntreatment into different causal pathways and quantify the causal effect in each\npathway. Causal mediation analysis (CMA) is a formal statistical approach for\nidentifying and estimating these causal effects. Central to CMA is the\nsequential ignorability assumption that implies all pre-treatment confounders\nare measured and they can capture different types of confounding, e.g.,\npost-treatment confounders and hidden confounders. Typically unverifiable in\nobservational studies, this assumption restrains both the coverage and\npracticality of conventional methods. This work, therefore, aims to circumvent\nthe stringent assumption by following a causal graph with a unified confounder\nand its proxy variables. Our core contribution is an algorithm that combines\ndeep latent-variable models and proxy strategy to jointly infer a unified\nsurrogate confounder and estimate different causal effects in CMA from observed\nvariables. Empirical evaluations using both synthetic and semi-synthetic\ndatasets validate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:46:11 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Cheng", "Lu", ""], ["Guo", "Ruocheng", ""], ["Liu", "Huan", ""]]}, {"id": "2102.11957", "submitter": "Ramya Srinivasan", "authors": "Ramya Srinivasan, Kanji Uchino", "title": "Quantifying Confounding Bias in Generative Art: A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years, AI generated art has become very popular. From generating\nart works in the style of famous artists like Paul Cezanne and Claude Monet to\nsimulating styles of art movements like Ukiyo-e, a variety of creative\napplications have been explored using AI. Looking from an art historical\nperspective, these applications raise some ethical questions. Can AI model\nartists' styles without stereotyping them? Does AI do justice to the\nsocio-cultural nuances of art movements? In this work, we take a first step\ntowards analyzing these issues. Leveraging directed acyclic graphs to represent\npotential process of art creation, we propose a simple metric to quantify\nconfounding bias due to the lack of modeling the influence of art movements in\nlearning artists' styles. As a case study, we consider the popular cycleGAN\nmodel and analyze confounding bias across various genres. The proposed metric\nis more effective than state-of-the-art outlier detection method in\nunderstanding the influence of art movements in artworks. We hope our work will\nelucidate important shortcomings of computationally modeling artists' styles\nand trigger discussions related to accountability of AI generated art.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 21:59:30 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Srinivasan", "Ramya", ""], ["Uchino", "Kanji", ""]]}, {"id": "2102.12013", "submitter": "Jianfeng Chi", "authors": "Jianfeng Chi, Yuan Tian, Geoffrey J. Gordon, Han Zhao", "title": "Understanding and Mitigating Accuracy Disparity in Regression", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread deployment of large-scale prediction systems in\nhigh-stakes domains, e.g., face recognition, criminal justice, etc., disparity\nin prediction accuracy between different demographic subgroups has called for\nfundamental understanding on the source of such disparity and algorithmic\nintervention to mitigate it. In this paper, we study the accuracy disparity\nproblem in regression. To begin with, we first propose an error decomposition\ntheorem, which decomposes the accuracy disparity into the distance between\nmarginal label distributions and the distance between conditional\nrepresentations, to help explain why such accuracy disparity appears in\npractice. Motivated by this error decomposition and the general idea of\ndistribution alignment with statistical distances, we then propose an algorithm\nto reduce this disparity, and analyze its game-theoretic optima of the proposed\nobjective functions. To corroborate our theoretical findings, we also conduct\nexperiments on five benchmark datasets. The experimental results suggest that\nour proposed algorithms can effectively mitigate accuracy disparity while\nmaintaining the predictive power of the regression models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 01:24:50 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 01:41:56 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Chi", "Jianfeng", ""], ["Tian", "Yuan", ""], ["Gordon", "Geoffrey J.", ""], ["Zhao", "Han", ""]]}, {"id": "2102.12076", "submitter": "Lana Sinapayen", "authors": "Lana Sinapayen", "title": "Perspective: Purposeful Failure in Artificial Life and Artificial\n  Intelligence", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex systems fail. I argue that failures can be a blueprint characterizing\nliving organisms and biological intelligence, a control mechanism to increase\ncomplexity in evolutionary simulations, and an alternative to classical fitness\noptimization. Imitating biological successes in Artificial Life and Artificial\nIntelligence can be misleading; imitating failures offers a path towards\nunderstanding and emulating life it in artificial systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 05:43:44 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Sinapayen", "Lana", ""]]}, {"id": "2102.12258", "submitter": "Nicolas Schreuder", "authors": "Nicolas Schreuder and Evgenii Chzhen", "title": "Classification with abstention but without disparities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification with abstention has gained a lot of attention in recent years\nas it allows to incorporate human decision-makers in the process. Yet,\nabstention can potentially amplify disparities and lead to discriminatory\npredictions. The goal of this work is to build a general purpose classification\nalgorithm, which is able to abstain from prediction, while avoiding disparate\nimpact. We formalize this problem as risk minimization under fairness and\nabstention constraints for which we derive the form of the optimal classifier.\nBuilding on this result, we propose a post-processing classification algorithm,\nwhich is able to modify any off-the-shelf score-based classifier using only\nunlabeled sample. We establish finite sample risk, fairness, and abstention\nguarantees for the proposed algorithm. In particular, it is shown that fairness\nand abstention constraints can be achieved independently from the initial\nclassifier as long as sufficiently many unlabeled data is available. The risk\nguarantee is established in terms of the quality of the initial classifier. Our\npost-processing scheme reduces to a sparse linear program allowing for an\nefficient implementation, which we provide. Finally, we validate our method\nempirically showing that moderate abstention rates allow to bypass the\nrisk-fairness trade-off.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 12:43:55 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Schreuder", "Nicolas", ""], ["Chzhen", "Evgenii", ""]]}, {"id": "2102.12300", "submitter": "Andry Alamsyah", "authors": "Andry Alamsyah, Fariz Denada Sudrajat, Herry Irawan", "title": "Property Business Classification Model Based on Indonesia E-Commerce\n  Data", "comments": "6 pages, 3 figures, 4 tables", "journal-ref": "The 8th International Conference on Sustainable Collaboration in\n  Business, Technology, Information and Innovation, 2017", "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online property business or known as e-commerce is currently experiencing an\nincrease in home sales. Indonesia's e-commerce property business has positive\ntrending shown by the increasing sales of more than 500% from 2011 to 2015. A\nprediction of the property price is important to help investors or the public\nto have accurate information before buying property. One of the methods for\nprediction is a classification based on several distinctive property industry\nattributes, such as building size, land size, number of rooms, and location.\nToday, data is easily obtained, there are many open data from E-commerce sites.\nE-commerce contains information about homes and other properties advertised to\nsell. People also regularly visit the site to find the right property or to\nsell the property using price information which collectively available as open\ndata. To predict the property sales, this research employed two different\nclassification methods in Data Mining which are Decision Tree and k-NN\nclassification. We compare which model classification is better to predict\nproperty price and their attributes. We use Indonesia's biggest property-based\ne-commerce site Rumah123.com as our open data source, and choose location\nBandung in our experiment. The accuracy result of the decision tree is 75% and\nKNN is 71%, other than that k-NN can explore more data patterns than the\nDecision Tree.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:29:34 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Alamsyah", "Andry", ""], ["Sudrajat", "Fariz Denada", ""], ["Irawan", "Herry", ""]]}, {"id": "2102.12406", "submitter": "Charlotte Stix", "authors": "Charlotte Stix", "title": "Actionable Principles for Artificial Intelligence Policy: Three Pathways", "comments": null, "journal-ref": "Sci Eng Ethics 27, 15 (2021)", "doi": "10.1007/s11948-020-00277-3", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the development of governmental policy for artificial intelligence (AI)\nthat is informed by ethics, one avenue currently pursued is that of drawing on\nAI Ethics Principles. However, these AI Ethics Principles often fail to be\nactioned in governmental policy. This paper proposes a novel framework for the\ndevelopment of Actionable Principles for AI. The approach acknowledges the\nrelevance of AI Ethics Principles and homes in on methodological elements to\nincrease their practical implementability in policy processes. As a case study,\nelements are extracted from the development process of the Ethics Guidelines\nfor Trustworthy AI of the European Commissions High Level Expert Group on AI.\nSubsequently, these elements are expanded on and evaluated in light of their\nability to contribute to a prototype framework for the development of\nActionable Principles for AI. The paper proposes the following three\npropositions for the formation of such a prototype framework: (1) preliminary\nlandscape assessments; (2) multi-stakeholder participation and cross-sectoral\nfeedback; and, (3) mechanisms to support implementation and\noperationalizability.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 16:57:35 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Stix", "Charlotte", ""]]}, {"id": "2102.12511", "submitter": "Hady Elsahar Dr", "authors": "Lucie-Aim\\'ee Kaffee, Hady Elsahar", "title": "References in Wikipedia: The Editors' Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  References are an essential part of Wikipedia. Each statement in Wikipedia\nshould be referenced. In this paper, we explore the creation and collection of\nreferences for new Wikipedia articles from an editors' perspective. We map out\nthe workflow of editors when creating a new article, emphasising how they\nselect references.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 19:04:17 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 12:40:58 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Kaffee", "Lucie-Aim\u00e9e", ""], ["Elsahar", "Hady", ""]]}, {"id": "2102.12523", "submitter": "Chunjong Park", "authors": "Chunjong Park, Morelle Arian, Xin Liu, Leon Sasson, Jeffrey Kahn,\n  Shwetak Patel, Alex Mariakakis, Tim Althoff", "title": "Online Mobile App Usage as an Indicator of Sleep Behavior and Job\n  Performance", "comments": null, "journal-ref": null, "doi": "10.1145/3442381.3450093", "report-no": null, "categories": "cs.HC cs.CY q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sleep is critical to human function, mediating factors like memory, mood,\nenergy, and alertness; therefore, it is commonly conjectured that a good\nnight's sleep is important for job performance. However, both real-world sleep\nbehavior and job performance are hard to measure at scale. In this work, we\nshow that people's everyday interactions with online mobile apps can reveal\ninsights into their job performance in real-world contexts. We present an\nobservational study in which we objectively tracked the sleep behavior and job\nperformance of salespeople (N = 15) and athletes (N = 19) for 18 months, using\na mattress sensor and online mobile app. We first demonstrate that cumulative\nsleep measures are correlated with job performance metrics, showing that an\nhour of daily sleep loss for a week was associated with a 9.0% and 9.5%\nreduction in performance of salespeople and athletes, respectively. We then\nexamine the utility of online app interaction time as a passively collectible\nand scalable performance indicator. We show that app interaction time is\ncorrelated with the performance of the athletes, but not the salespeople. To\nsupport that our app-based performance indicator captures meaningful variation\nin psychomotor function and is robust against potential confounds, we conducted\na second study to evaluate the relationship between sleep behavior and app\ninteraction time in a cohort of 274 participants. Using a generalized additive\nmodel to control for per-participant random effects, we demonstrate that\nparticipants who lost one hour of daily sleep for a week exhibited 5.0% slower\napp interaction times. We also find that app interaction time exhibits\nmeaningful chronobiologically consistent correlations with sleep history, time\nawake, and circadian rhythms. Our findings reveal an opportunity for online app\ndevelopers to generate new insights regarding cognition and productivity.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 19:30:39 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Park", "Chunjong", ""], ["Arian", "Morelle", ""], ["Liu", "Xin", ""], ["Sasson", "Leon", ""], ["Kahn", "Jeffrey", ""], ["Patel", "Shwetak", ""], ["Mariakakis", "Alex", ""], ["Althoff", "Tim", ""]]}, {"id": "2102.12726", "submitter": "Chuliang Chi", "authors": "Yingbai Hu (3 and 2), Jian Li (1 and 2), Yongquan Chen (1 and 2),\n  Qiwen Wang (2 and 1), Chuliang Chi (2 and 1), Heng Zhang (2 and 1), Qing Gao\n  (2 and 1), Yuanmin Lan (6 and 2), Zheng Li (4 and 2), Zonggao Mu (5 and 2),\n  Zhenglong Sun (1 and 2), Alois Knoll (3) ((1) Robotics and Intelligent\n  Manufacturing & School of Science and Engineering, The Chinese University of\n  Hong Kong, Shenzhen, China, (2) Shenzhen Institute of Artificial Intelligence\n  and Robotics for Society, China, (3) Chair of Robotics, Artificial\n  Intelligence and Real-time Systems, Technische Universit M\\\"unchen,\n  M\\\"unchen, Germany, (4) Department of surgery, and Chow Yuk Ho Technology\n  Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong\n  Kong, (5) School of Mechanical Engineering, Shandong University of\n  Technology, Zibo, China, (6) Longgang District People's Hospital of Shenzhen,\n  China.)", "title": "Design and Control of a Highly Redundant Rigid-Flexible Coupling Robot\n  to Assist the COVID-19 Oropharyngeal-Swab Sampling", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of novel coronavirus pneumonia (COVID-19) has caused mortality\nand morbidity worldwide. Oropharyngeal-swab (OP-swab) sampling is widely used\nfor the diagnosis of COVID-19 in the world. To avoid the clinical staff from\nbeing affected by the virus, we developed a 9-degree-of-freedom (DOF)\nrigid-flexible coupling (RFC) robot to assist the COVID-19 OP-swab sampling.\nThis robot is composed of a visual system, UR5 robot arm, micro-pneumatic\nactuator and force-sensing system. The robot is expected to reduce risk and\nfree up the clinical staff from the long-term repetitive sampling work.\nCompared with a rigid sampling robot, the developed force-sensing RFC robot can\nfacilitate OP-swab sampling procedures in a safer and softer way. In addition,\na varying-parameter zeroing neural network-based optimization method is also\nproposed for motion planning of the 9-DOF redundant manipulator. The developed\nrobot system is validated by OP-swab sampling on both oral cavity phantoms and\nvolunteers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 08:08:48 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Hu", "Yingbai", "", "3 and 2"], ["Li", "Jian", "", "1 and 2"], ["Chen", "Yongquan", "", "1 and 2"], ["Wang", "Qiwen", "", "2 and 1"], ["Chi", "Chuliang", "", "2 and 1"], ["Zhang", "Heng", "", "2 and 1"], ["Gao", "Qing", "", "2 and 1"], ["Lan", "Yuanmin", "", "6 and 2"], ["Li", "Zheng", "", "4 and 2"], ["Mu", "Zonggao", "", "5 and 2"], ["Sun", "Zhenglong", "", "1 and 2"], ["Knoll", "Alois", ""]]}, {"id": "2102.12799", "submitter": "Massimo Stella", "authors": "Massimo Stella", "title": "Cognitive network science for understanding online social cognitions: A\n  brief review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media are digitalising massive amounts of users' cognitions in terms\nof timelines and emotional content. Such Big Data opens unprecedented\nopportunities for investigating cognitive phenomena like perception,\npersonality and information diffusion but requires suitable interpretable\nframeworks. Since social media data come from users' minds, worthy candidates\nfor this challenge are cognitive networks, models of cognition giving structure\nto mental conceptual associations. This work outlines how cognitive network\nscience can open new, quantitative ways for understanding cognition through\nonline media, like: (i) reconstructing how users semantically and emotionally\nframe events with contextual knowledge unavailable to machine learning, (ii)\ninvestigating conceptual salience/prominence through knowledge structure in\nsocial discourse; (iii) studying users' personality traits like\nopenness-to-experience, curiosity, and creativity through language in posts;\n(iv) bridging cognitive/emotional content and social dynamics via multilayer\nnetworks comparing the mindsets of influencers and followers. These\nadvancements combine cognitive-, network- and computer science to understand\ncognitive mechanisms in both digital and real-world settings but come with\nlimitations concerning representativeness, individual variability and data\nintegration. Such aspects are discussed along the ethical implications of\nmanipulating socio-cognitive data. In the future, reading cognitions through\nnetworks and social media can expose cognitive biases amplified by online\nplatforms and relevantly inform policy making, education and markets about\nmassive, complex cognitive trends.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 11:53:28 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Stella", "Massimo", ""]]}, {"id": "2102.12837", "submitter": "Manoel Horta Ribeiro", "authors": "Robin Mami\\'e, Manoel Horta Ribeiro, Robert West", "title": "Are Anti-Feminist Communities Gateways to the Far Right? Evidence from\n  Reddit and YouTube", "comments": "Code and reproducibility data are available at\n  \\url{https://doi.org/10.5281/zenodo.4420983}. This paper has been accepted at\n  the 13th ACM Web Science Conference (WebSci'21), please cite accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have suggested that \"the Manosphere,\" a conglomerate of\nmen-centered online communities, may serve as a gateway to far right movements.\nIn that context, this paper quantitatively studies the migratory patterns\nbetween a variety of groups within the Manosphere and the Alt-right, a loosely\nconnected far right movement that has been particularly active in mainstream\nsocial networks. Our analysis leverages over 300 million comments spread\nthrough Reddit (in 115 subreddits) and YouTube (in 526 channels) to investigate\nwhether the audiences of channels and subreddits associated with these\ncommunities have converged between 2006 and 2018. In addition to subreddits\nrelated to the communities of interest, we also collect data on counterparts:\nother groups of users which we use for comparison (e.g., for YouTube we use a\nset of media channels). Besides measuring the similarity in the commenting user\nbases of these communities, we perform a migration study, calculating to which\nextent users in the Manosphere gradually engage with Alt-right content. Our\nresults suggest that there is a large overlap between the user bases of the\nAlt-right and of the Manosphere and that members of the Manosphere have a\nbigger chance to engage with far right content than carefully chosen\ncounterparts. However, our analysis also shows that migration and user base\noverlap varies substantially across different platforms and within the\nManosphere. Members of some communities (e.g., Men's Rights Activists)\ngradually engage with the Alt-right significantly more than counterparts on\nboth Reddit and YouTube, whereas for other communities, this engagement happens\nmostly on Reddit (e.g., Pick Up Artists). Overall, our work paints a nuanced\npicture of the pipeline between the Manosphere and the Alt-right, which may\ninform platforms' policies and moderation decisions regarding these\ncommunities.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 13:22:27 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 14:11:06 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Mami\u00e9", "Robin", ""], ["Ribeiro", "Manoel Horta", ""], ["West", "Robert", ""]]}, {"id": "2102.13076", "submitter": "Francesco Bodria", "authors": "Francesco Bodria, Fosca Giannotti, Riccardo Guidotti, Francesca\n  Naretto, Dino Pedreschi, Salvatore Rinzivillo", "title": "Benchmarking and Survey of Explanation Methods for Black Box Models", "comments": "This work is currently under review on an international journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread adoption of black-box models in Artificial Intelligence has\nenhanced the need for explanation methods to reveal how these obscure models\nreach specific decisions. Retrieving explanations is fundamental to unveil\npossible biases and to resolve practical or ethical issues. Nowadays, the\nliterature is full of methods with different explanations. We provide a\ncategorization of explanation methods based on the type of explanation\nreturned. We present the most recent and widely used explainers, and we show a\nvisual comparison among explanations and a quantitative benchmarking.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 18:50:29 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Bodria", "Francesco", ""], ["Giannotti", "Fosca", ""], ["Guidotti", "Riccardo", ""], ["Naretto", "Francesca", ""], ["Pedreschi", "Dino", ""], ["Rinzivillo", "Salvatore", ""]]}, {"id": "2102.13167", "submitter": "Alireza Karduni", "authors": "Alireza Karduni, Ryan Wesslen, Douglas Markant, Wenwen Dou", "title": "Images, Emotions, and Credibility: Effect of Emotional Facial Images on\n  Perceptions of News Content Bias and Source Credibility in Social Media", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Images are an indispensable part of the news content we consume. Highly\nemotional images from sources of misinformation can greatly influence our\njudgements. We present two studies on the effects of emotional facial images on\nusers' perception of bias in news content and the credibility of sources. In\nstudy 1, we investigate the impact of happy and angry facial images on users'\ndecisions. In study 2, we focus on sources' systematic emotional treatment of\nspecific politicians. Our results show that depending on the political\norientation of the source, the cumulative effect of angry facial emotions\nimpacts users' perceived content bias and source credibility. When sources\nsystematically portray specific politicians as angry, users are more likely to\nfind those sources as less credible and their content as more biased. These\nresults highlight how implicit visual propositions manifested by emotions in\nfacial expressions might have a substantial effect on our trust of news content\nand sources.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 20:47:21 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Karduni", "Alireza", ""], ["Wesslen", "Ryan", ""], ["Markant", "Douglas", ""], ["Dou", "Wenwen", ""]]}, {"id": "2102.13613", "submitter": "Bernhard Haslhofer", "authors": "Bernhard Haslhofer and Rainer St\\\"utz and Matteo Romiti and Ross King", "title": "GraphSense: A General-Purpose Cryptoasset Analytics Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is currently an increasing demand for cryptoasset analysis tools among\ncryptoasset service providers, the financial industry in general, as well as\nacross academic fields. At the moment, one can choose between commercial\nservices or low-level open-source tools providing programmatic access. In this\npaper, we present the design and implementation of another option: the\nGraphSense Cryptoasset Analytics Platform, which can be used for interactive\ninvestigations of monetary flows and, more importantly, for executing advanced\nanalytics tasks using a standard data science tool stack. By providing a\ngrowing set of open-source components, GraphSense could ultimately become an\ninstrument for scientific investigations in academia and a possible response to\nemerging compliance and regulation challenges for businesses and organizations\ndealing with cryptoassets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 17:31:12 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Haslhofer", "Bernhard", ""], ["St\u00fctz", "Rainer", ""], ["Romiti", "Matteo", ""], ["King", "Ross", ""]]}]