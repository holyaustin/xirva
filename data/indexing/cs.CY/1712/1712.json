[{"id": "1712.00236", "submitter": "Yi Liu", "authors": "Yi Liu", "title": "Flexible Installability of Android Apps with App-level Virtualization\n  based Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of smartphones, users are heavily dependent on mobile\napplications for daily work and entertainments. However, mobile apps are\nbecoming more and more complicated with more features and increasing size, part\nof which may be redundant to users. Due to the limitation of current\ninstallation mechanism, users have to download full-size applications instead\nof enjoy only the wanted features. Such full-size apps may consume more\nresources, including CPU, memory, and energy, which may hurt users' enthusiasm\nfor further installation. We first conduct an empirical study to characterize\nused features when users interact with mobile applications, and find that users\nonly consume a small set features of target apps. To address this problem, we\npresent AppStarscream, which offers to decompose and run Android apps with\napp-level virtualization. We have implemented a prototype system and evaluated\nit with real-world apps showing that AppStarscream is efficient and practical.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 09:02:42 GMT"}, {"version": "v2", "created": "Thu, 15 Feb 2018 07:19:38 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Liu", "Yi", ""]]}, {"id": "1712.00507", "submitter": "Janani Kalyanam", "authors": "Janani Kalyanam and Timothy Mackey", "title": "Detection and Characterization of Illegal Marketing and Promotion of\n  Prescription Drugs on Twitter", "comments": "NIPS 2017 Workshop Machine Learning for Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Illicit online pharmacies allow the purchase of prescription drugs online\nwithout a prescription. Such pharmacies leverage social media platforms such as\nTwit- ter as a promotion and marketing tool with the intent of reaching out to\na larger, potentially younger demographics of the population. Given the serious\nnegative health effects that arise from abusing such drugs, it is important to\nidentify the relevant content on social media and exterminate their presence as\nquickly as pos- sible. In response, we collected all the tweets that contained\nthe names of certain preselected controlled substances over a period of 5\nmonths. We found that an unsupervised topic modeling based methodology is able\nto identify tweets that promote and market controlled substances with high\nprecision. We also study the meta-data characteristics of such tweets and the\nusers who post them and find that they have several distinguishing\ncharacteristics that sets them apart. We were able to train supervised methods\nand achieve high performance in detecting such content and the users who post\nthem.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 22:34:07 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Kalyanam", "Janani", ""], ["Mackey", "Timothy", ""]]}, {"id": "1712.00659", "submitter": "Stanislav Sobolevsky", "authors": "Stanislav Sobolevsky, Ekaterina Levitskaya, Henry Chan, Shefali\n  Enaker, Joe Bailey, Marc Postle, Yuriy Loukachev, Melinda Rolfs, Constantine\n  Kontokosta", "title": "Impact Of Urban Technology Deployments On Local Commercial Activity", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While smart city innovations seem to be a common and necessary response to\nincreasing challenges of urbanization, foreseeing their impact on complex urban\nsystem is critical for informed decision making. Moreover, often the effect of\nurban interventions goes beyond the original expectations, including multiple\nindirect impacts. The present study considers the impact of two urban\ndeployments, Citi Bike (bike sharing system) and LinkNYC kiosks, on the local\ncommercial activity in the affected neighborhoods of New York City. The study\nuses anonymized and aggregated insights provided through a grant from the\nMastercard Center for Inclusive Growth in order to provide initial data-driven\nevidence towards the hypothesis that proximity of Citi Bike stations\nincentivizes local sales at eating places, while LinkNYC kiosks help people,\nespecially visitors, to navigate local businesses and thus incentivize\ncommercial activity in different business categories.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 20:09:59 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Sobolevsky", "Stanislav", ""], ["Levitskaya", "Ekaterina", ""], ["Chan", "Henry", ""], ["Enaker", "Shefali", ""], ["Bailey", "Joe", ""], ["Postle", "Marc", ""], ["Loukachev", "Yuriy", ""], ["Rolfs", "Melinda", ""], ["Kontokosta", "Constantine", ""]]}, {"id": "1712.00676", "submitter": "Jay Billings", "authors": "Jay Jay Billings, Alexander J. McCaskey, Geoffroy Vallee, and Greg\n  Watson", "title": "Will humans even write code in 2040 and what would that mean for extreme\n  heterogeneity in computing?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming trends suggest that software development will undergo a radical\nchange in the future: the combination of machine learning, artificial\nintelligence, natural language processing, and code generation technologies\nwill improve in such a way that machines, instead of humans, will write most of\ntheir own code by 2040. This poses a number of interesting challenges for\nscientific research, especially as the hardware on which this Machine Generated\nCode will run becomes extremely heterogeneous. Indeed, extreme heterogeneity\nmay drive the creation of this technology because it will allow humans to cope\nwith the difficulty of programming different devices efficiently and easily.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 22:57:48 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 16:11:58 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Billings", "Jay Jay", ""], ["McCaskey", "Alexander J.", ""], ["Vallee", "Geoffroy", ""], ["Watson", "Greg", ""]]}, {"id": "1712.00846", "submitter": "Thamme Gowda", "authors": "Kyle Hundman, Thamme Gowda, Mayank Kejriwal, and Benedikt Boecking", "title": "Always Lurking: Understanding and Mitigating Bias in Online Human\n  Trafficking Detection", "comments": "Submitted to 2018 AAAI 1st conference on AI, Ethics, and Society.\n  Awaiting review", "journal-ref": "AAAI/ACM First conference on Artificial Intelligence, Ethics, and\n  Society, New Orleans, USA, February 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web-based human trafficking activity has increased in recent years but it\nremains sparsely dispersed among escort advertisements and difficult to\nidentify due to its often-latent nature. The use of intelligent systems to\ndetect trafficking can thus have a direct impact on investigative resource\nallocation and decision-making, and, more broadly, help curb a widespread\nsocial problem. Trafficking detection involves assigning a normalized score to\na set of escort advertisements crawled from the Web -- a higher score indicates\na greater risk of trafficking-related (involuntary) activities. In this paper,\nwe define and study the problem of trafficking detection and present a\ntrafficking detection pipeline architecture developed over three years of\nresearch within the DARPA Memex program. Drawing on multi-institutional data,\nsystems, and experiences collected during this time, we also conduct post hoc\nbias analyses and present a bias mitigation plan. Our findings show that, while\nautomatic trafficking detection is an important application of AI for social\ngood, it also provides cautionary lessons for deploying predictive machine\nlearning algorithms without appropriate de-biasing. This ultimately led to\nintegration of an interpretable solution into a search system that contains\nover 100 million advertisements and is used by over 200 law enforcement\nagencies to investigate leads.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 22:34:43 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Hundman", "Kyle", ""], ["Gowda", "Thamme", ""], ["Kejriwal", "Mayank", ""], ["Boecking", "Benedikt", ""]]}, {"id": "1712.01066", "submitter": "Tribhuvanesh Orekondy", "authors": "Tribhuvanesh Orekondy, Mario Fritz, Bernt Schiele", "title": "Connecting Pixels to Privacy and Utility: Automatic Redaction of Private\n  Information in Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Images convey a broad spectrum of personal information. If such images are\nshared on social media platforms, this personal information is leaked which\nconflicts with the privacy of depicted persons. Therefore, we aim for automated\napproaches to redact such private information and thereby protect privacy of\nthe individual. By conducting a user study we find that obfuscating the image\nregions related to the private information leads to privacy while retaining\nutility of the images. Moreover, by varying the size of the regions different\nprivacy-utility trade-offs can be achieved. Our findings argue for a \"redaction\nby segmentation\" paradigm. Hence, we propose the first sizable dataset of\nprivate images \"in the wild\" annotated with pixel and instance level labels\nacross a broad range of privacy classes. We present the first model for\nautomatic redaction of diverse private information.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 13:35:39 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Orekondy", "Tribhuvanesh", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""]]}, {"id": "1712.01213", "submitter": "Zulfat Miftakhutdinov", "authors": "Elena Tutubalina, Zulfat Miftahutdinov", "title": "An Encoder-Decoder Model for ICD-10 Coding of Death Certificates", "comments": null, "journal-ref": "KFU at CLEF eHealth 2017 Task 1: ICD-10 Coding of English Death\n  Certificates with Recurrent Neural Networks, CEUR Workshop Proceedings, Vol\n  1866, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information extraction from textual documents such as hospital records and\nhealthrelated user discussions has become a topic of intense interest. The task\nof medical concept coding is to map a variable length text to medical concepts\nand corresponding classification codes in some external system or ontology. In\nthis work, we utilize recurrent neural networks to automatically assign ICD-10\ncodes to fragments of death certificates written in English. We develop\nend-to-end neural architectures directly tailored to the task, including basic\nencoder-decoder architecture for statistical translation. In order to\nincorporate prior knowledge, we concatenate cosine similarities vector among\nthe text and dictionary entry to the encoded state. Being applied to a standard\nbenchmark from CLEF eHealth 2017 challenge, our model achieved F-measure of\n85.01% on a full test set with significant improvement as compared to the\naverage score of 62.2% for all official participants approaches.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 17:39:51 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Tutubalina", "Elena", ""], ["Miftahutdinov", "Zulfat", ""]]}, {"id": "1712.01469", "submitter": "Weisheng Zhong", "authors": "Weisheng Zhong, Fanglan Chen, Kaiqun Fu, Chang-Tien Lu", "title": "SAFEBIKE: A Bike-sharing Route Recommender with Availability Prediction\n  and Safe Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents SAFEBIKE, a novel route recommendation system for\nbike-sharing service that utilizes station information to infer the number of\navailable bikes in dock and recommend bike routes according to multiple factors\nsuch as distance and safety level. The system consists of a station level\navailability predictor that predicts bikes and docks amount at each station,\nand an efficient route recommendation service that considers safety and\nbike/dock availability factors. It targets users who are concerned about route\nsafeness and station availability. We demonstrate the system by utilizing Citi\nBike station availability and New York City crime data of Manhattan to show the\neffectiveness of our approach. Integrated with real-time station availability\nand historical crime data resources, our proposed system can effectively\nrecommend an optimal bike route and improve the travel experience of bike\nusers.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 03:57:38 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Zhong", "Weisheng", ""], ["Chen", "Fanglan", ""], ["Fu", "Kaiqun", ""], ["Lu", "Chang-Tien", ""]]}, {"id": "1712.01691", "submitter": "Pedram Gharani", "authors": "Pedram Gharani, Brian Suffoletto, Tammy Chung, Hassan Karimi", "title": "An Artificial Neural Network for Gait Analysis to Estimate Blood Alcohol\n  Content Level", "comments": "arXiv admin note: text overlap with arXiv:1711.03410", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Impairments in gait occur after alcohol consumption, and, if detected in\nreal-time, could guide the delivery of \"just-in-time\" injury prevention\ninterventions. We aimed to identify the salient features of gait that could be\nused for estimating blood alcohol content (BAC) level in a typical drinking\nenvironment. We recruited 10 young adults with a history of heavy drinking to\ntest our research app. During four consecutive Fridays and Saturdays, every\nhour from 8pm to 12am, they were prompted to use the app to report alcohol\nconsumption and complete a 5-step straight-line walking task, during which\n3-axis acceleration and angular velocity data was sampled at a frequency of 100\nHz. BAC for each subject was calculated. From sensor signals, 24 features were\ncalculated using a sliding window technique, including energy, mean, and\nstandard deviation. Using an artificial neural network (ANN), we performed\nregression analysis to define a model determining association between gait\nfeatures and BACs. 70\\% of data was used as a training dataset, and the results\nwere tested and validated using the rest of samples. We evaluated different\ntraining algorithms for the neural network and the result showed that a\nBayesian regularization neural network (BRNN) was the most efficient and\naccurate. Analyses support the use of the tandem gait task paired with our\napproach to reliably estimate BAC based on gait features. Results from this\nwork could be useful in designing effective prevention interventions to reduce\nrisky behaviors during periods of alcohol consumption.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 03:18:11 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 17:02:54 GMT"}, {"version": "v3", "created": "Thu, 14 Dec 2017 14:35:22 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Gharani", "Pedram", ""], ["Suffoletto", "Brian", ""], ["Chung", "Tammy", ""], ["Karimi", "Hassan", ""]]}, {"id": "1712.01767", "submitter": "Jan S\\\"urmeli", "authors": "Uwe Der, Stefan J\\\"ahnichen, Jan S\\\"urmeli", "title": "Self-sovereign Identity $-$ Opportunities and Challenges for the Digital\n  Revolution", "comments": "Preprint, English Translation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interconnectedness of people, services and devices is a defining aspect\nof the digital revolution, and, secure digital identities are an important\nprerequisite for secure and legally compliant information exchange. Existing\napproaches to realize a secure identity management focus on central providers\nof identities such as national authorities or online service providers. Hence,\nchanging residence or service provider often means to start over and creating\nnew identities, because procedures for data portability are missing.\nSelf-sovereign digital identities are instead created and managed by\nindividuals, and enable them to maintain their digital identities independent\nfrom residence, national eID infrastructure and market-dominating service\nproviders.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 17:16:31 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Der", "Uwe", ""], ["J\u00e4hnichen", "Stefan", ""], ["S\u00fcrmeli", "Jan", ""]]}, {"id": "1712.01930", "submitter": "Kyriaki Kalimeri", "authors": "Kyriaki Kalimeri, Mariano G. Beiro, Matteo Delfino, Robert Raleigh and\n  Ciro Cattuto", "title": "Predicting Demographics, Moral Foundations, and Human Values from\n  Digital Behaviors", "comments": null, "journal-ref": null, "doi": "10.1016/j.chb.2018.11.024", "report-no": null, "categories": "cs.CY cs.AI cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal electronic devices including smartphones give access to behavioural\nsignals that can be used to learn about the characteristics and preferences of\nindividuals. In this study, we explore the connection between demographic and\npsychological attributes and the digital behavioural records, for a cohort of\n7,633 people, closely representative of the US population with respect to\ngender, age, geographical distribution, education, and income. Along with the\ndemographic data, we collected self-reported assessments on validated\npsychometric questionnaires for moral traits and basic human values and\ncombined this information with passively collected multi-modal digital data\nfrom web browsing behaviour and smartphone usage. A machine learning framework\nwas then designed to infer both the demographic and psychological attributes\nfrom the behavioural data. In a cross-validated setting, our models predicted\ndemographic attributes with good accuracy as measured by the weighted AUROC\nscore (Area Under the Receiver Operating Characteristic), but were less\nperformant for the moral traits and human values. These results call for\nfurther investigation since they are still far from unveiling individuals'\npsychological fabric. This connection, along with the most predictive features\nthat we provide for each attribute, might prove useful for designing\npersonalised services, communication strategies, and interventions, and can be\nused to sketch a portrait of people with a similar worldview.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:20:34 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 14:33:55 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 16:08:49 GMT"}, {"version": "v4", "created": "Wed, 21 Nov 2018 15:21:02 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Kalimeri", "Kyriaki", ""], ["Beiro", "Mariano G.", ""], ["Delfino", "Matteo", ""], ["Raleigh", "Robert", ""], ["Cattuto", "Ciro", ""]]}, {"id": "1712.02282", "submitter": "Subhashis Banerjee", "authors": "Potnuru Kishen Suraj, Ankesh Gupta, Makkunda Sharma, Sourabh Bikas\n  Paul, Subhashis Banerjee", "title": "On monitoring development indicators using high resolution satellite\n  images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a machine learning based tool for accurate prediction of\nsocio-economic indicators from daytime satellite imagery. The diverse set of\nindicators are often not intuitively related to observable features in\nsatellite images, and are not even always well correlated with each other. Our\npredictive tool is more accurate than using night light as a proxy, and can be\nused to predict missing data, smooth out noise in surveys, monitor development\nprogress of a region, and flag potential anomalies. Finally, we use predicted\nvariables to do robustness analysis of a regression study of high rate of\nstunting in India.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 16:53:14 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 15:00:48 GMT"}, {"version": "v3", "created": "Mon, 25 Jun 2018 14:04:52 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Suraj", "Potnuru Kishen", ""], ["Gupta", "Ankesh", ""], ["Sharma", "Makkunda", ""], ["Paul", "Sourabh Bikas", ""], ["Banerjee", "Subhashis", ""]]}, {"id": "1712.02398", "submitter": "Alice Allen", "authors": "Alice Allen, Peter Teuben, G. Bruce Berriman, Kimberly DuPrie, Keith\n  Shortridge, Rein Warmels", "title": "Software metadata: How much is enough?", "comments": "4 pages; to be published in ADASS XXVII (held Oct 22-26, 2017 in\n  Santiago, Chile) proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Broad efforts are underway to capture metadata about research software and\nretain it across services; notable in this regard is the CodeMeta project. What\nmetadata are important to have about (research) software? What metadata are\nuseful for searching for codes? What would you like to learn about astronomy\nsoftware? This BoF sought to gather information on metadata most desired by\nresearchers and users of astro software and others interested in registering,\nindexing, capturing, and doing research on this software. Information from this\nBoF could conceivably result in changes to the Astrophysics Source Code Library\n(ASCL) or other resources for the benefit of the community or provide input\ninto other projects concerned with software metadata.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 20:15:07 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Allen", "Alice", ""], ["Teuben", "Peter", ""], ["Berriman", "G. Bruce", ""], ["DuPrie", "Kimberly", ""], ["Shortridge", "Keith", ""], ["Warmels", "Rein", ""]]}, {"id": "1712.02547", "submitter": "Yunlong Wang", "authors": "Yunlong Wang, Lingdan Wu, Jan-Philipp Lange, Ahmed Fadhil, Harald\n  Reiterer", "title": "Persuasive Technology in Reducing Prolonged Sedentary Behavior at Work:\n  A Systematic Review", "comments": null, "journal-ref": "Smart Health 7-8 (2018) 19-30", "doi": "10.1016/j.smhl.2018.05.002", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prolonged sedentary behavior is prevalent among office workers and has been\nfound to be detrimental to health. Preventing and reducing prolonged sedentary\nbehavior require interventions, and persuasive technology is expected to make a\ncontribution in this domain. In this paper, we use the framework of persuasive\nsystem design (PSD) principles to investigate the utilization and effectiveness\nof persuasive technology in intervention studies at reducing sedentary behavior\nat work. This systematic review reveals that reminders are the most frequently\nused PSD principle. The analysis on reminders shows that hourly PC reminders\nalone have no significant effect on reducing sedentary behavior at work, while\ncoupling with education or other informative session seems to be promising.\nDetails of deployed persuasive technology with behavioral theories and user\nexperience evaluation are expected to be reported explicitly in the future\nintervention studies.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 09:29:38 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 17:13:27 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 19:19:07 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Wang", "Yunlong", ""], ["Wu", "Lingdan", ""], ["Lange", "Jan-Philipp", ""], ["Fadhil", "Ahmed", ""], ["Reiterer", "Harald", ""]]}, {"id": "1712.02741", "submitter": "Xiao Chen", "authors": "Xiao Chen, Zhen (Sean) Qian, Ram Rajagopal, Todd Stiers, Christopher\n  Flores, Robert Kavaler, and Floyd Williams III", "title": "Parking Sensing and Information System: Sensors, Deployment, and\n  Evaluation", "comments": null, "journal-ref": "Chen, Xiao, et al. \"Parking Sensing and Information System:\n  Sensors, Deployment, and Evaluation.\" Transportation Research Record: Journal\n  of the Transportation Research Board 2559 (2016): 81-89", "doi": "10.3141/2559-10", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a smart parking sensing and information system that\ndisseminates the parking availability information for public users in a\ncost-effective and efficient manner. The hardware framework of the system is\nbuilt on advanced wireless sensor networks and cloud service over the Internet,\nand the system is highly scalable. The parking information provided to the\nusers is set in the form of occupancy rates and expected cruising time. Both\nare obtained from our analytical algorithm processing both historical and\nreal-time data, and are thereafter visualized in a color theme. The entire\nparking system is deployed and extensively evaluated at Stanford University\nParking Structure-1.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 17:38:35 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Chen", "Xiao", "", "Sean"], ["Zhen", "", "", "Sean"], ["Qian", "", ""], ["Rajagopal", "Ram", ""], ["Stiers", "Todd", ""], ["Flores", "Christopher", ""], ["Kavaler", "Robert", ""], ["Williams", "Floyd", "III"]]}, {"id": "1712.02926", "submitter": "Yuan Yuan", "authors": "Yuan Yuan, Tracy Xiao Liu, Chenhao Tan, Jie Tang", "title": "Online Red Packets: A Large-scale Empirical Study of Gift Giving on\n  WeChat", "comments": "20 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC cs.MM econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gift giving is a ubiquitous social phenomenon, and red packets have been used\nas monetary gifts in Asian countries for thousands of years. In recent years,\nonline red packets have become widespread in China through the WeChat platform.\nExploiting a unique dataset consisting of 61 million group red packets and\nseven million users, we conduct a large-scale, data-driven study to understand\nthe spread of red packets and the effect of red packets on group activity. We\nfind that the cash flows between provinces are largely consistent with\nprovincial GDP rankings, e.g., red packets are sent from users in the south to\nthose in the north. By distinguishing spontaneous from reciprocal red packets,\nwe reveal the behavioral patterns in sending red packets: males, seniors, and\npeople with more in-group friends are more inclined to spontaneously send red\npackets, while red packets from females, youths, and people with less in-group\nfriends are more reciprocal. Furthermore, we use propensity score matching to\nstudy the external effects of red packets on group dynamics. We show that red\npackets increase group participation and strengthen in-group relationships,\nwhich partly explain the benefits and motivations for sending red packets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 03:15:58 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Yuan", "Yuan", ""], ["Liu", "Tracy Xiao", ""], ["Tan", "Chenhao", ""], ["Tang", "Jie", ""]]}, {"id": "1712.02975", "submitter": "Chen Zhu", "authors": "Chen Zhu, Hengshu Zhu, Hui Xiong, Pengliang Ding, Fang Xie", "title": "Recruitment Market Trend Analysis with Sequential Latent Variable Models", "comments": "11 pages, 30 figure, SIGKDD 2016", "journal-ref": null, "doi": "10.1145/2939672.2939689", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recruitment market analysis provides valuable understanding of\nindustry-specific economic growth and plays an important role for both\nemployers and job seekers. With the rapid development of online recruitment\nservices, massive recruitment data have been accumulated and enable a new\nparadigm for recruitment market analysis. However, traditional methods for\nrecruitment market analysis largely rely on the knowledge of domain experts and\nclassic statistical models, which are usually too general to model large-scale\ndynamic recruitment data, and have difficulties to capture the fine-grained\nmarket trends. To this end, in this paper, we propose a new research paradigm\nfor recruitment market analysis by leveraging unsupervised learning techniques\nfor automatically discovering recruitment market trends based on large-scale\nrecruitment data. Specifically, we develop a novel sequential latent variable\nmodel, named MTLVM, which is designed for capturing the sequential dependencies\nof corporate recruitment states and is able to automatically learn the latent\nrecruitment topics within a Bayesian generative framework. In particular, to\ncapture the variability of recruitment topics over time, we design hierarchical\ndirichlet processes for MTLVM. These processes allow to dynamically generate\nthe evolving recruitment topics. Finally, we implement a prototype system to\nempirically evaluate our approach based on real-world recruitment data in\nChina. Indeed, by visualizing the results from MTLVM, we can successfully\nreveal many interesting findings, such as the popularity of LBS related jobs\nreached the peak in the 2nd half of 2014, and decreased in 2015.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 08:06:03 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Zhu", "Chen", ""], ["Zhu", "Hengshu", ""], ["Xiong", "Hui", ""], ["Ding", "Pengliang", ""], ["Xie", "Fang", ""]]}, {"id": "1712.03012", "submitter": "Claudio Pinhanez", "authors": "Claudio Pinhanez", "title": "Computer Interfaces to Organizations: Perspectives on Borg-Human\n  Interaction Design", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We use the term borg to refer to the complex organizations composed of\npeople, machines, and processes with which users frequently interact using\ncomputer interfaces and websites. Unlike interfaces to pure machines, we\ncontend that borg-human interaction (BHI) happens in a context combining the\nanthropomorphization of the interface, conflict with users, and dramatization\nof the interaction process. We believe this context requires designers to\nconstruct the human facet of the borg, a structure encompassing the borg's\npersonality, social behavior, and embodied actions; and the strategies to\nco-create dramatic narratives with the user. To design the human facet of a\nborg, different concepts and models are explored and discussed, borrowing ideas\nfrom psychology, sociology, and arts. Based on those foundations, we propose\nsix design methodologies to complement traditional computer-human interface\ndesign techniques, including play-and-freeze enactment of conflicts and the use\nof giant puppets as interface prototypes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 10:37:25 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Pinhanez", "Claudio", ""]]}, {"id": "1712.03069", "submitter": "John MacCormick", "authors": "John MacCormick", "title": "Strategies for basing the CS theory course on non-decision problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational and complexity theory are core components of the computer\nscience curriculum, and in the vast majority of cases are taught using decision\nproblems as the main paradigm. For experienced practitioners, decision problems\nare the best tool. But for undergraduates encountering the material for the\nfirst time, we present evidence that non-decision problems (such as\noptimization problems and search problems) are preferable. In addition, we\ndescribe technical definitions and pedagogical strategies that have been used\nsuccessfully for teaching the theory course using non-decision problems as the\ncentral concept.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 14:02:31 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["MacCormick", "John", ""]]}, {"id": "1712.03073", "submitter": "Mengwei Xu", "authors": "Mengwei Xu, Feng Qian, Mengze Zhu, Feifan Huang, Saumay Pushp, Xuanzhe\n  Liu", "title": "DeepWear: Adaptive Local Offloading for On-Wearable Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their on-body and ubiquitous nature, wearables can generate a wide\nrange of unique sensor data creating countless opportunities for deep learning\ntasks. We propose DeepWear, a deep learning (DL) framework for wearable devices\nto improve the performance and reduce the energy footprint. DeepWear\nstrategically offloads DL tasks from a wearable device to its paired handheld\ndevice through local network. Compared to the remote-cloud-based offloading,\nDeepWear requires no Internet connectivity, consumes less energy, and is robust\nto privacy breach. DeepWear provides various novel techniques such as\ncontext-aware offloading, strategic model partition, and pipelining support to\nefficiently utilize the processing capacity from nearby paired handhelds.\nDeployed as a user-space library, DeepWear offers developer-friendly APIs that\nare as simple as those in traditional DL libraries such as TensorFlow. We have\nimplemented DeepWear on the Android OS and evaluated it on COTS smartphones and\nsmartwatches with real DL models. DeepWear brings up to 5.08X and 23.0X\nexecution speedup, as well as 53.5% and 85.5% energy saving compared to\nwearable-only and handheld-only strategies, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 16:58:32 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 04:10:20 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 00:55:32 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Xu", "Mengwei", ""], ["Qian", "Feng", ""], ["Zhu", "Mengze", ""], ["Huang", "Feifan", ""], ["Pushp", "Saumay", ""], ["Liu", "Xuanzhe", ""]]}, {"id": "1712.03074", "submitter": "Carlo Rodrigues Kleber", "authors": "L.S. Oyama, C.K.S. Rodrigues, S.P. Peres, and B. Goldiez", "title": "Terrain Database Correlation Assessment Using an Open Source Tool", "comments": "12 pages, I/ITSEC 2017", "journal-ref": "Interservice/Industry Training, Simulation, and Education\n  Conference (I/ITSEC) 2017, Paper No. 17004 Page 1 of 12", "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Configuring networked simulators for training military teams in a distributed\nenvironment requires the usage of a set of terrain databases to represent the\nsame training area. The results of simulation exercises can be degraded if the\nterrain databases are poorly correlated. A number of methodologies for\ndetermining the correlation between terrain databaHowever, there are few\ncomputational tools for this task and most of them were developed to address\ngovernment needs, have limited availability, and handle specific digital\nformats. The goal of this paper is thus to present a novel open source tool\ndeveloped as part of an academic research project.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 17:16:48 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Oyama", "L. S.", ""], ["Rodrigues", "C. K. S.", ""], ["Peres", "S. P.", ""], ["Goldiez", "B.", ""]]}, {"id": "1712.03076", "submitter": "Anh Nguyen Duc", "authors": "Anh Nguyen Duc, Pekka Abrahamsson", "title": "Exploring the outsourcing relationship in software startups: A multiple\n  case study", "comments": "This is the author's version of the work. Copyright owner's version\n  can be accessed at https://doi.org/10.1145/3084226.3084248", "journal-ref": null, "doi": "10.1145/3084226.3084248", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software startups are becoming increasingly popular in software industry as\nwell as other sectors of economy. Startups that lack necessary competences\noften seek for external resources from outsourcing partners. Little is known\nhow this outsourcing relationship works and whether it makes sense to outsource\nthe technical competence to an external party. This is among the first\ninvestigations on the outsourcing relationships in software startups. By\nconducting exploratory case studies at six startups, we found a mixed\nexperience with outsourcing. The experimental nature of an early product\ndevelopment makes outsourcing a feasible option, although startups often suffer\nfrom its uncertainty and managing commitments from partners. Results further\npropose that early contract-based activities could be transformed into a\nlong-term partnership by adopting a startup boundary spanner s role,\nestablishing an inter-personal relationship and maintaining a mutual\ncommitment.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 22:25:24 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Duc", "Anh Nguyen", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1712.03077", "submitter": "Hassan Khosravi", "authors": "Hassan Khosravi", "title": "Recommendation in Personalised Peer-Learning Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation in Personalised Peer Learning Environments (RiPPLE) is an\nadaptive, crowdsourced, web-based, student-facing, open-source platform that\nemploys exemplary techniques from the fields of machine learning,\ncrowdsourcing, learning analytics and recommender systems to provide\npersonalised content and learning support at scale. RiPPLE presents students\nwith a repository of tagged multiple-choice questions and provides instant\nfeedback in response to student answers. The repository of the questions is\ncreated in partnership with the students through the use of crowdsourcing.\nRiPPLE uses students responses to the questions to approximate their knowledge\nstates. Based on their knowledge state and learning needs, each student is\nrecommended a set of personalised questions. For students that are interested\nin providing learning support, seeking learning support or finding study\npartners, RiPPLE recommends peer learning sessions based on their availability,\nknowledge state and preferences. This paper describes the RiPPLE interface and\nan implementation of that interface that has been built at the University of\nQueensland. The RiPPLE platform and a reference implementation are released as\nan open-source package under the Apache 2.0 license via GitHub.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 09:25:56 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 00:17:53 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Khosravi", "Hassan", ""]]}, {"id": "1712.03079", "submitter": "Adrian Kent", "authors": "Adrian Kent", "title": "Replication Ethics", "comments": "Accepted version. Extended introduction. Para added to emphasize that\n  replications are assumed to be effectively deterministic and thus identical", "journal-ref": "Futures 107 (2019) 89-97", "doi": "10.1016/j.futures.2019.01.001", "report-no": null, "categories": "cs.CY physics.hist-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose some future technology enables the same consciously experienced human\nlife to be repeated, identically or nearly so, N times, in series or in\nparallel. Is this roughly N times as valuable as enabling the same life once,\nbecause each life has value and values are additive? Or is it of roughly equal\nvalue as enabling the life once, because only one life is enabled, albeit in a\nphysically unusual way? Does it matter whether the lives are contemporaneous or\nsuccessive? We argue that these questions highlight a hitherto neglected facet\nof population ethics that may become relevant in the not necessarily far\ndistant future.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 11:45:01 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 22:24:22 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 16:47:04 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Kent", "Adrian", ""]]}, {"id": "1712.03080", "submitter": "Ion Dronic", "authors": "Ion Dronic", "title": "A path to AI", "comments": "6 pages", "journal-ref": null, "doi": "10.14569/issn.2156-5570", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build a safe system that would replicate and perhaps transcend human-level\nintelligence, three basic modules: objective, agent, and perception are\nproposed for development. The objective module would ensure that the system\nacts in humanity's interest, not against it. It would have two components: a\nnetwork of machine learning agents to address the problem of value alignment\nand a distributed ledger to propose a mechanism to mitigate the existential\nthreat. The agent module would further develop the Dyna concept and benefit\nfrom a treatise in sociology to build the missing link of artificial general\nintelligence - a world simulator. The perception module would estimate the\nstate of the world and benefit from existing machine learning algorithms\nenhanced by a new paradigm in hardware design - a quantum computer. This paper\ndescribes a way in which such a system could be built, analyzing the current\nstate of the art and providing alternative directions for research rather than\nconcrete, industry-ready solutions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 16:47:23 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 10:39:53 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Dronic", "Ion", ""]]}, {"id": "1712.03081", "submitter": "Ismael Rafols", "authors": "Montserrat Esta\\~nol, Francesco Masucci, Alessandro Mosca and Ismael\n  R\\`afols", "title": "Mapping knowledge with ontologies: the case of obesity", "comments": "2017 Science and Technology Indicators Proceeedings, 10 pages, 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientometric techniques have been remarkably successful at mapping science\nbut they face important difficulties when mapping research for societal\nproblems possibly because they they are derived only from scientific documents\nand thus do not rely on non-academic expert knowledge. Here we aim to explore\nhow ontologies can be used in science mapping, thus enriching current\nalgorithmic techniques with systematic domain expert knowledge. This study\nintroduces the methodology behind the construction of an ontology and tests\npotential uses in science mapping. We use obesity as a topic of case study.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 17:54:46 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Esta\u00f1ol", "Montserrat", ""], ["Masucci", "Francesco", ""], ["Mosca", "Alessandro", ""], ["R\u00e0fols", "Ismael", ""]]}, {"id": "1712.03086", "submitter": "Mayank Kejriwal", "authors": "Mayank Kejriwal, Jiayuan Ding, Runqi Shao, Anoop Kumar, Pedro Szekely", "title": "FlagIt: A System for Minimally Supervised Human Trafficking Indicator\n  Mining", "comments": "6 pages, published in Workshop on Learning with Limited Labeled Data\n  co-held with NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe and study the indicator mining problem in the\nonline sex advertising domain. We present an in-development system, FlagIt\n(Flexible and adaptive generation of Indicators from text), which combines the\nbenefits of both a lightweight expert system and classical semi-supervision\n(heuristic re-labeling) with recently released state-of-the-art unsupervised\ntext embeddings to tag millions of sentences with indicators that are highly\ncorrelated with human trafficking. The FlagIt technology stack is open source.\nOn preliminary evaluations involving five indicators, FlagIt illustrates\npromising performance compared to several alternatives. The system is being\nactively developed, refined and integrated into a domain-specific search system\nused by over 200 law enforcement agencies to combat human trafficking, and is\nbeing aggressively extended to mine at least six more indicators with minimal\nprogramming effort. FlagIt is a good example of a system that operates in\nlimited label settings, and that requires creative combinations of established\nmachine learning techniques to produce outputs that could be used by real-world\nnon-technical analysts.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 21:15:48 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Kejriwal", "Mayank", ""], ["Ding", "Jiayuan", ""], ["Shao", "Runqi", ""], ["Kumar", "Anoop", ""], ["Szekely", "Pedro", ""]]}, {"id": "1712.03087", "submitter": "Chen Zhu", "authors": "Tong Xu, Hengshu Zhu, Chen Zhu, Pan Li, Hui Xiong", "title": "Measuring the Popularity of Job Skills in Recruitment Market: A\n  Multi-Criteria Approach", "comments": "8 pages, 14 figures, AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To cope with the accelerating pace of technological changes, talents are\nurged to add and refresh their skills for staying in active and gainful\nemployment. This raises a natural question: what are the right skills to learn?\nIndeed, it is a nontrivial task to measure the popularity of job skills due to\nthe diversified criteria of jobs and the complicated connections within job\nskills. To that end, in this paper, we propose a data driven approach for\nmodeling the popularity of job skills based on the analysis of large-scale\nrecruitment data. Specifically, we first build a job skill network by exploring\na large corpus of job postings. Then, we develop a novel Skill Popularity based\nTopic Model (SPTM) for modeling the generation of the skill network. In\nparticular, SPTM can integrate different criteria of jobs (e.g., salary levels,\ncompany size) as well as the latent connections within skills, thus we can\neffectively rank the job skills based on their multi-faceted popularity.\nExtensive experiments on real-world recruitment data validate the effectiveness\nof SPTM for measuring the popularity of job skills, and also reveal some\ninteresting rules, such as the popular job skills which lead to high-paid\nemployment.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 11:18:40 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Xu", "Tong", ""], ["Zhu", "Hengshu", ""], ["Zhu", "Chen", ""], ["Li", "Pan", ""], ["Xiong", "Hui", ""]]}, {"id": "1712.03131", "submitter": "Luciano Abriata", "authors": "Luciano A. Abriata", "title": "Concurrent interactive visualization and handling of molecular\n  structures over the Internet in web browsers", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This preprint presents a web app (essentially a web page-based program) with\nwhich two or more users (peers) can view and handle 3D molecular structures in\na concurrent, interactive way through their web browsers. This means they can\nshare orientation and zoom level, commands and other operations in almost real\ntime over the Internet through standard web pages. This web app, open source\nand built with the open source components JSmol for molecular visualization and\nPeer.js for WebRTC connection, provides a practical tool for online\ncollaboration and teaching at a distance. More broadly, it illustrates the\nstrong integrability of technologies for client-side web programming, and paves\nthe way for similar apps for concurrent work in other disciplines. Web app is\navailable at:\nhttp://lucianoabriata.altervista.org/jsinscience/concurrent-jsmol/concurrent-jsmol-visualization.html\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:41:37 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 07:27:28 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Abriata", "Luciano A.", ""]]}, {"id": "1712.03163", "submitter": "Valdemar \\v{S}v\\'abensk\\'y", "authors": "Valdemar \\v{S}v\\'abensk\\'y and Jan Vykopal", "title": "Challenges Arising from Prerequisite Testing in Cybersecurity Games", "comments": "ACM SIGCSE 2018 conference, 6 pages, 4 figures, 4 tables", "journal-ref": null, "doi": "10.1145/3159450.3159454", "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity games are an attractive and popular method of active learning.\nHowever, the majority of current games are created for advanced players, which\noften leads to frustration in less experienced learners. Therefore, we decided\nto focus on a diagnostic assessment of participants entering the games. We\nassume that information about the players' knowledge, skills, and experience\nenables tutors or learning environments to suitably assist participants with\ngame challenges and maximize learning in their virtual adventure. In this\npaper, we present a pioneering experiment examining the predictive value of a\nshort quiz and self-assessment for identifying learners' readiness before\nplaying a cybersecurity game. We hypothesized that these predictors would model\nplayers' performance. A linear regression analysis showed that the game\nperformance can be accurately predicted by well-designed prerequisite testing,\nbut not by self-assessment. At the same time, we identified major challenges\nrelated to the design of pretests for cybersecurity games: calibrating test\nquestions with respect to the skills relevant for the game, minimizing the\nquiz's length while maximizing its informative value, and embedding the pretest\nin the game. Our results are relevant for educational researchers and\ncybersecurity instructors of students at all learning levels.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 16:36:02 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["\u0160v\u00e1bensk\u00fd", "Valdemar", ""], ["Vykopal", "Jan", ""]]}, {"id": "1712.03186", "submitter": "Gustavo Maciel Dias Vieira", "authors": "Rafael R. Machado, Gustavo M. D. Vieira", "title": "UEFI BIOS Accessibility for the Visually Impaired", "comments": "6 pages", "journal-ref": "SBESC '17: Proceedings of the VII Brazilian Symposium on Computing\n  Systems Engineering, IEEE Computer Society, 2017, 155-160", "doi": "10.1109/SBESC.2017.27", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People with some kind of disability face a high level of difficulty for\neveryday tasks because, in many cases, accessibility was not considered\nnecessary when the task or process was designed. An example of this scenario is\na computer's BIOS configuration screens, which do not consider the specific\nneeds, such as screen readers, of visually impaired people. This paper proposes\nthe idea that it is possible to make the pre-operating system environment\naccessible to visually impaired people. We report our work-in-progress in\ncreating a screen reader prototype, accessing audio cards compatible with the\nHigh Definition Audio specification in systems running UEFI compliant firmware.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 17:47:11 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Machado", "Rafael R.", ""], ["Vieira", "Gustavo M. D.", ""]]}, {"id": "1712.03586", "submitter": "Reuben Binns Dr", "authors": "Reuben Binns", "title": "Fairness in Machine Learning: Lessons from Political Philosophy", "comments": null, "journal-ref": "Proceedings of Machine Learning Research 81:149-159, 2018\n  Conference on Fairness, Accountability, and Transparency", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What does it mean for a machine learning model to be `fair', in terms which\ncan be operationalised? Should fairness consist of ensuring everyone has an\nequal probability of obtaining some benefit, or should we aim instead to\nminimise the harms to the least advantaged? Can the relevant ideal be\ndetermined by reference to some alternative state of affairs in which a\nparticular social pattern of discrimination does not exist? Various definitions\nproposed in recent literature make different assumptions about what terms like\ndiscrimination and fairness mean and how they can be defined in mathematical\nterms. Questions of discrimination, egalitarianism and justice are of\nsignificant interest to moral and political philosophers, who have expended\nsignificant efforts in formalising and defending these central concepts. It is\ntherefore unsurprising that attempts to formalise `fairness' in machine\nlearning contain echoes of these old philosophical debates. This paper draws on\nexisting work in moral and political philosophy in order to elucidate emerging\ndebates about fair machine learning.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 20:39:03 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 14:10:09 GMT"}, {"version": "v3", "created": "Tue, 23 Mar 2021 17:37:15 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Binns", "Reuben", ""]]}, {"id": "1712.03650", "submitter": "Samira Samadi", "authors": "Samira Samadi, Santosh Vempala, Adam Tauman Kalai", "title": "Usability of Humanly Computable Passwords", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reusing passwords across multiple websites is a common practice that\ncompromises security. Recently, Blum and Vempala have proposed password\nstrategies to help people calculate, in their heads, passwords for different\nsites without dependence on third-party tools or external devices. Thus far,\nthe security and efficiency of these \"mental algorithms\" has been analyzed only\ntheoretically. But are such methods usable? We present the first usability\nstudy of humanly computable password strategies, involving a learning phase (to\nlearn a password strategy), then a rehearsal phase (to login to a few\nwebsites), and multiple follow-up tests. In our user study, with training,\nparticipants were able to calculate a deterministic eight-character password\nfor an arbitrary new website in under 20 seconds.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 05:52:47 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 21:59:00 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Samadi", "Samira", ""], ["Vempala", "Santosh", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1712.03659", "submitter": "Hoang Dinh Thai DTH", "authors": "Kongrath Suankaewmanee, Dinh Thai Hoang, Dusit Niyato, Suttinee\n  Sawadsitang, Ping Wang, and Zhu Han", "title": "Performance Analysis and Application of Mobile Blockchain", "comments": "6 pages, 10 figures, IEEE ICNC Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile security has become more and more important due to the boom of mobile\ncommerce (m-commerce). However, the development of m-commerce is facing many\nchallenges regarding data security problems. Recently, blockchain has been\nintroduced as an effective security solution deployed successfully in many\napplications in practice, such as, Bitcoin, cloud computing, and\nInternet-of-Things. However, the blockchain technology has not been adopted and\nimplemented widely in m-commerce because its mining processes usually require\nto be performed on standard computing units, e.g., computers. Therefore, in\nthis paper, we introduce a new m-commerce application using blockchain\ntechnology, namely, MobiChain, to secure transactions in the m-commerce.\nEspecially, in the MobiChain application, the mining processes can be executed\nefficiently on mobile devices using our proposed Android core module. Through\nreal experiments, we evaluate the performance of the proposed model and show\nthat blockchain will be an efficient security solution for future m-commerce.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 06:49:40 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Suankaewmanee", "Kongrath", ""], ["Hoang", "Dinh Thai", ""], ["Niyato", "Dusit", ""], ["Sawadsitang", "Suttinee", ""], ["Wang", "Ping", ""], ["Han", "Zhu", ""]]}, {"id": "1712.03724", "submitter": "Sarthak Ahuja", "authors": "Rakesh R Pimplikar, Kushal Mukherjee, Gyana Parija, Harit Vishwakarma,\n  Ramasuri Narayanam, Sarthak Ahuja, Rohith D Vallam, Ritwik Chaudhuri, Joydeep\n  Mondal", "title": "Cogniculture: Towards a Better Human-Machine Co-evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in Artificial Intelligence is breaking technology barriers every\nday. New algorithms and high performance computing are making things possible\nwhich we could only have imagined earlier. Though the enhancements in AI are\nmaking life easier for human beings day by day, there is constant fear that AI\nbased systems will pose a threat to humanity. People in AI community have\ndiverse set of opinions regarding the pros and cons of AI mimicking human\nbehavior. Instead of worrying about AI advancements, we propose a novel idea of\ncognitive agents, including both human and machines, living together in a\ncomplex adaptive ecosystem, collaborating on human computation for producing\nessential social goods while promoting sustenance, survival and evolution of\nthe agents' life cycle. We highlight several research challenges and technology\nbarriers in achieving this goal. We propose a governance mechanism around this\necosystem to ensure ethical behaviors of all cognitive agents. Along with a\nnovel set of use-cases of Cogniculture, we discuss the road map ahead for this\njourney.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 11:31:28 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Pimplikar", "Rakesh R", ""], ["Mukherjee", "Kushal", ""], ["Parija", "Gyana", ""], ["Vishwakarma", "Harit", ""], ["Narayanam", "Ramasuri", ""], ["Ahuja", "Sarthak", ""], ["Vallam", "Rohith D", ""], ["Chaudhuri", "Ritwik", ""], ["Mondal", "Joydeep", ""]]}, {"id": "1712.03903", "submitter": "Dan Liu", "authors": "Dan Liu, Ching Yee Suen, Olga Ormandjieva", "title": "A Novel Way of Identifying Cyber Predators", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks with Long Short-Term Memory cell (LSTM-RNN) have\nimpressive ability in sequence data processing, particularly for language model\nbuilding and text classification. This research proposes the combination of\nsentiment analysis, new approach of sentence vectors and LSTM-RNN as a novel\nway for Sexual Predator Identification (SPI). LSTM-RNN language model is\napplied to generate sentence vectors which are the last hidden states in the\nlanguage model. Sentence vectors are fed into another LSTM-RNN classifier, so\nas to capture suspicious conversations. Hidden state enables to generate\nvectors for sentences never seen before. Fasttext is used to filter the\ncontents of conversations and generate a sentiment score so as to identify\npotential predators. The experiment achieves a record-breaking accuracy and\nprecision of 100% with recall of 81.10%, exceeding the top-ranked result in the\nSPI competition.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:24:13 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Liu", "Dan", ""], ["Suen", "Ching Yee", ""], ["Ormandjieva", "Olga", ""]]}, {"id": "1712.04100", "submitter": "Boleslaw Szymanski", "authors": "D. Asher, J. Caylor, M. Mittrick, J. Richardson, E. Heilman, E.\n  Bowman, G. Korniss, B. Szymanski", "title": "The Investigation of Social Media Data Thresholds for Opinion Formation", "comments": null, "journal-ref": "Proc. 22nd International Command and Control Research & Technology\n  Symposium, paper 27, Los Angeles, CA, Nov. 2017", "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive use of social media has grown to over two billion users to\ndate, and is commonly utilized as a means to share information and shape world\nevents. Evidence suggests that passive social media usage (i.e., viewing\nwithout taking action) has an impact on the user's perspective. This empirical\ninfluence over perspective could have significant impact on social events.\nTherefore, it is important to understand how social media contributes to the\nformation of an individual's perspective. A set of experimental tasks were\ndesigned to investigate empirically derived thresholds for opinion formation as\na result of passive interactions with different social media data types (i.e.,\nvideos, images, and messages). With a better understanding of how humans\npassively interact with social media information, a paradigm can be developed\nthat allows the exploitation of this interaction and plays a significant role\nin future military plans and operations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 02:15:16 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Asher", "D.", ""], ["Caylor", "J.", ""], ["Mittrick", "M.", ""], ["Richardson", "J.", ""], ["Heilman", "E.", ""], ["Bowman", "E.", ""], ["Korniss", "G.", ""], ["Szymanski", "B.", ""]]}, {"id": "1712.04309", "submitter": "Andrea Gorrini", "authors": "Christian Berzi, Andrea Gorrini, Giuseppe Vizzari", "title": "Mining the Social Media Data for a Bottom-Up Evaluation of Walkability", "comments": "Pre-print of a paper presented at the 12th International Conference\n  on Traffic and Granular Flow - TGF 2017, 19-22 July 2017, Washington DC, USA\n  (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urbanization represents a huge opportunity for computer applications enabling\ncities to be managed more efficiently while, at the same time, improving the\nlife quality of their citizens. One of the potential application of this kind\nof systems is a bottom-up evaluation of the level of walkability of the city\n(namely the level of usefulness, comfort, safety and attractiveness of an urban\narea for walking). This is based on the usage of data from social media for the\ncomputation of structured indicators describing the actual usage of areas by\npedestrians. This paper will present an experimentation of analysis of data\nabout the city of Milano (Italy) acquired from Flickr and Foursquare. The over\n500 thousand points, which represent the photos and the POIs collected from the\nabove mentioned social meda, were clustered through an iterative approach based\non the DBSCAN algorithm, in order to achieve homogeneous areas defined by the\nactual activity of inhabitants and tourists rather than by a top down\nadministrative procedure and to supply useful indications on the level of\nwalkability of the city of Milan.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:31:13 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Berzi", "Christian", ""], ["Gorrini", "Andrea", ""], ["Vizzari", "Giuseppe", ""]]}, {"id": "1712.04314", "submitter": "Yuri G. Gordienko", "authors": "Serhii Hamotskyi, Sergii Stirenko, Yuri Gordienko, Anis Rojbi", "title": "Generating and Estimating Nonverbal Alphabets for Situated and\n  Multimodal Communications", "comments": "5 pages, 5 figures", "journal-ref": "International Journal of Systems Applications Engineering and\n  Development, 11, 232-236 (2017)", "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the formalized approach for generating and\nestimating symbols (and alphabets), which can be communicated by the wide range\nof non-verbal means based on specific user requirements (medium, priorities,\ntype of information that needs to be conveyed). The short characterization of\nbasic terms and parameters of such symbols (and alphabets) with approaches to\ngenerate them are given. Then the framework, experimental setup, and some\nmachine learning methods to estimate usefulness and effectiveness of the\nnonverbal alphabets and systems are presented. The previous results demonstrate\nthat usage of multimodal data sources (like wearable accelerometer, heart\nmonitor, muscle movements sensors, braincomputer interface) along with machine\nlearning approaches can provide the deeper understanding of the usefulness and\neffectiveness of such alphabets and systems for nonverbal and situated\ncommunication. The symbols (and alphabets) generated and estimated by such\nmethods may be useful in various applications: from synthetic languages and\nconstructed scripts to multimodal nonverbal and situated interaction between\npeople and artificial intelligence systems through Human-Computer Interfaces,\nsuch as mouse gestures, touchpads, body gestures, eyetracking cameras,\nwearables, and brain-computing interfaces, especially in applications for\nelderly care and people with disabilities.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:38:34 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Hamotskyi", "Serhii", ""], ["Stirenko", "Sergii", ""], ["Gordienko", "Yuri", ""], ["Rojbi", "Anis", ""]]}, {"id": "1712.04640", "submitter": "Amal Saha", "authors": "Amal K Saha", "title": "Review of Design of Speech Recognition and Text Analytics based Digital\n  Banking Customer Interface and Future Directions of Technology Adoption", "comments": "Keywords. speech recognition; natural language processing;\n  low-resource language; digital banking; cognitive banking; conversational\n  user interface; artificial intelligence (AI); machine learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Banking is one of the most significant adopters of cutting-edge information\ntechnologies. Since its modern era beginning in the form of paper based\naccounting maintained in the branch, adoption of computerized system made it\npossible to centralize the processing in data centre and improve customer\nexperience by making a more available and efficient system. The latest twist in\nthis evolution is adoption of natural language processing and speech\nrecognition in the user interface between the human and the system and use of\nmachine learning and advanced analytics, in general, for backend processing as\nwell. The paper reviews the progress of technology adoption in the field and\ncomments on the maturity level of solutions involving less studied or\nlow-resource languages like Hindi and also other Indian, regional languages.\nFurthermore, it also provides an analysis from a prototype built by us. The\nfuture directions of this area are also highlighted.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 07:43:40 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Saha", "Amal K", ""]]}, {"id": "1712.04649", "submitter": "Theodosios Mourouzis", "authors": "Theodosis Mourouzis, Chrysostomos Filipou", "title": "The Blockchain Revolution: Insights from Top-Management", "comments": "26 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an exploration of Blockchain technology that is growing in popularity\nand it seems to be able to disrupt a plethora of industries. A research is\nbeing conducted to examine Blockchain potential to be adopted by enterprises\nfrom different sectors as well as the parameters that could affect its\nadoption. Mostly known as the technology that underpins Bitcoin, this concept\nraised a significant interest within various markets. Blockchain offers a new\napproach to valued information management and sharing and it is introduced as a\nsolution against the inefficiencies that affect the industry. Experts,\ninfrastructure providers and banks can now work on this technology and explore\nits uses. This is a new technology journey with obstacles that will need to be\novercome and it can not be clear yet what will eventually arise. Professionals\nfrom around the world express their views on the adoption of Blockchain by\norganisations and how these plan to support its deployment. Thoughts are shared\nin terms of the required budget and the parameters that can impact its\nadoption. There is a great interest in Blockchain technology and its\nrevolutionary potential to modernize the world economy and this is only the\nbeginning.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 08:14:19 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Mourouzis", "Theodosis", ""], ["Filipou", "Chrysostomos", ""]]}, {"id": "1712.05376", "submitter": "Robert Robinson", "authors": "Robert Robinson", "title": "Prevalence of DNSSEC for hospital websites in Illinois", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The domain name system translates human friendly web addresses to a computer\nreadable internet protocol address. This basic infrastructure is insecure and\ncan be manipulated. Deployment of technology to secure the DNS system has been\nslow, reaching about 20% of all web sites based in the USA. Little is known\nabout the efforts hospitals and health systems make to secure the domain name\nsystem for their websites. To investigate the prevalence of implementing Domain\nName System Security Extensions (DNSSEC), we analyzed the websites of the 210\npublic hospitals in the state of Illinois, USA. Only one Illinois hospital\nwebsite was found to have implemented DNSSEC by December, 2017.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 18:17:08 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Robinson", "Robert", ""]]}, {"id": "1712.05380", "submitter": "Ronald de Wolf", "authors": "Ronald de Wolf", "title": "The Potential Impact of Quantum Computers on Society", "comments": "9 pages LaTeX", "journal-ref": "Ethics and Information Technology, 19(4):271-276, 2017", "doi": null, "report-no": null, "categories": "cs.CY quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the potential impact that the nascent technology of\nquantum computing may have on society. It focuses on three areas: cryptography,\noptimization, and simulation of quantum systems. We will also discuss some\nethical aspects of these developments, and ways to mitigate the risks.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 18:24:41 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["de Wolf", "Ronald", ""]]}, {"id": "1712.05545", "submitter": "Nipun Wijerathne", "authors": "Nipun Wijerathne, Sanjana Kadaba Viswanath, Marakkalage Sumudu Hasala,\n  Victoria Beltran, Chau Yuen, Hock Beng Lim", "title": "Towards Comfortable Cycling: A Practical Approach to Monitor the\n  Conditions in Cycling Paths", "comments": "6 pages, 5 figures, Accepted by IEEE 4th World Forum on Internet of\n  Things (WF-IoT) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a no brainer. Using bicycles to commute is the most sustainable form\nof transport, is the least expensive to use and are pollution-free. Towns and\ncities have to be made bicycle-friendly to encourage their wide usage.\nTherefore, cycling paths should be more convenient, comfortable, and safe to\nride. This paper investigates a smartphone application, which passively\nmonitors the road conditions during cyclists ride. To overcome the problems of\nmonitoring roads, we present novel algorithms that sense the rough cycling\npaths and locate road bumps. Each event is detected in real time to improve the\nuser friendliness of the application. Cyclists may keep their smartphones at\nany random orientation and placement. Moreover, different smartphones sense the\nsame incident dissimilarly and hence report discrepant sensor values. We\nfurther address the aforementioned difficulties that limit such crowd-sourcing\napplication. We evaluate our sensing application on cycling paths in Singapore,\nand show that it can successfully detect such bad road conditions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 05:51:28 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Wijerathne", "Nipun", ""], ["Viswanath", "Sanjana Kadaba", ""], ["Hasala", "Marakkalage Sumudu", ""], ["Beltran", "Victoria", ""], ["Yuen", "Chau", ""], ["Lim", "Hock Beng", ""]]}, {"id": "1712.05627", "submitter": "Chris Culnane Dr", "authors": "Chris Culnane, Benjamin I. P. Rubinstein, Vanessa Teague", "title": "Health Data in an Open World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the aim of informing sound policy about data sharing and privacy, we\ndescribe successful re-identification of patients in an Australian\nde-identified open health dataset. As in prior studies of similar datasets, a\nfew mundane facts often suffice to isolate an individual. Some people can be\nidentified by name based on publicly available information. Decreasing the\nprecision of the unit-record level data, or perturbing it statistically, makes\nre-identification gradually harder at a substantial cost to utility. We also\nexamine the value of related datasets in improving the accuracy and confidence\nof re-identification. Our re-identifications were performed on a 10% sample\ndataset, but a related open Australian dataset allows us to infer with high\nconfidence that some individuals in the sample have been correctly\nre-identified. Finally, we examine the combination of the open datasets with\nsome commercial datasets that are known to exist but are not in our possession.\nWe show that they would further increase the ease of re-identification.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 11:36:24 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Culnane", "Chris", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Teague", "Vanessa", ""]]}, {"id": "1712.05748", "submitter": "Emma Pierson", "authors": "Emma Pierson, Tim Althoff, Jure Leskovec", "title": "Modeling Individual Cyclic Variation in Human Behavior", "comments": "Accepted at WWW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cycles are fundamental to human health and behavior. However, modeling cycles\nin time series data is challenging because in most cases the cycles are not\nlabeled or directly observed and need to be inferred from multidimensional\nmeasurements taken over time. Here, we present CyHMMs, a cyclic hidden Markov\nmodel method for detecting and modeling cycles in a collection of\nmultidimensional heterogeneous time series data. In contrast to previous cycle\nmodeling methods, CyHMMs deal with a number of challenges encountered in\nmodeling real-world cycles: they can model multivariate data with discrete and\ncontinuous dimensions; they explicitly model and are robust to missing data;\nand they can share information across individuals to model variation both\nwithin and between individual time series. Experiments on synthetic and\nreal-world health-tracking data demonstrate that CyHMMs infer cycle lengths\nmore accurately than existing methods, with 58% lower error on simulated data\nand 63% lower error on real-world data compared to the best-performing\nbaseline. CyHMMs can also perform functions which baselines cannot: they can\nmodel the progression of individual features/symptoms over the course of the\ncycle, identify the most variable features, and cluster individual time series\ninto groups with distinct characteristics. Applying CyHMMs to two real-world\nhealth-tracking datasets -- of menstrual cycle symptoms and physical activity\ntracking data -- yields important insights including which symptoms to expect\nat each point during the cycle. We also find that people fall into several\ngroups with distinct cycle patterns, and that these groups differ along\ndimensions not provided to the model. For example, by modeling missing data in\nthe menstrual cycles dataset, we are able to discover a medically relevant\ngroup of birth control users even though information on birth control is not\ngiven to the model.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 16:51:16 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 17:39:50 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 23:07:43 GMT"}, {"version": "v4", "created": "Fri, 20 Apr 2018 08:02:38 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Pierson", "Emma", ""], ["Althoff", "Tim", ""], ["Leskovec", "Jure", ""]]}, {"id": "1712.05796", "submitter": "Chris Callison-Burch", "authors": "Kotaro Hara, Abi Adams, Kristy Milland, Saiph Savage, Chris\n  Callison-Burch, Jeffrey Bigham", "title": "A Data-Driven Analysis of Workers' Earnings on Amazon Mechanical Turk", "comments": "Conditionally accepted for inclusion in the 2018 ACM Conference on\n  Human Factors in Computing Systems (CHI'18) Papers program", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of people are working as part of on-line crowd work, which\nhas been characterized by its low wages; yet, we know little about wage\ndistribution and causes of low/high earnings. We recorded 2,676 workers\nperforming 3.8 million tasks on Amazon Mechanical Turk. Our task-level analysis\nrevealed that workers earned a median hourly wage of only ~\\$2/h, and only 4%\nearned more than \\$7.25/h. The average requester pays more than \\$11/h,\nalthough lower-paying requesters post much more work. Our wage calculations are\ninfluenced by how unpaid work is included in our wage calculations, e.g., time\nspent searching for tasks, working on tasks that are rejected, and working on\ntasks that are ultimately not submitted. We further explore the characteristics\nof tasks and working patterns that yield higher hourly wages. Our analysis\ninforms future platform design and worker tools to create a more positive\nfuture for crowd work.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 22:08:23 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 16:40:11 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Hara", "Kotaro", ""], ["Adams", "Abi", ""], ["Milland", "Kristy", ""], ["Savage", "Saiph", ""], ["Callison-Burch", "Chris", ""], ["Bigham", "Jeffrey", ""]]}, {"id": "1712.05837", "submitter": "Mizanur Rahman", "authors": "Mizanur Rahman, Mashrur Chowdhury, Anjan Rayamajhi, Kakan Dey, and\n  James Martin", "title": "Adaptive Queue Prediction Algorithm for an Edge Centric Cyber Physical\n  System Platform in a Connected Vehicle Environment", "comments": "Will be published in the \"2018 Transportation Research Board\n  Conference Proceedings.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the early days of connected vehicles (CVs), data will be collected only\nfrom a limited number of CVs (i.e., low CV penetration rate) and not from other\nvehicles (i.e., non-connected vehicles). Moreover, the data loss rate in the\nwireless CV environment contributes to the unavailability of data from the\nlimited number of CVs. Thus, it is very challenging to predict traffic\nbehavior, which changes dynamically over time, with the limited CV data. The\nprimary objective of this study was to develop an adaptive queue prediction\nalgorithm to predict real-time queue status in the CV environment in an\nedge-centric cyber-physical system (CPS), which is a relatively new CPS\nconcept. The adaptive queue prediction algorithm was developed using a machine\nlearning algorithm with a real-time feedback system. The algorithm was\nevaluated using SUMO (i.e., Simulation of Urban Mobility) and ns3 (Network\nSimulator 3) simulation platforms to illustrate the efficacy of the algorithm\non a roadway network in Clemson, South Carolina, USA. The performance of the\nadaptive queue prediction application was measured in terms of queue detection\naccuracy with varying CV penetration levels and data loss rates. The analyses\nrevealed that the adaptive queue prediction algorithm with feedback system\noutperforms without feedback system algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 20:17:12 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Rahman", "Mizanur", ""], ["Chowdhury", "Mashrur", ""], ["Rayamajhi", "Anjan", ""], ["Dey", "Kakan", ""], ["Martin", "James", ""]]}, {"id": "1712.05838", "submitter": "Mizanur Rahman", "authors": "Mashrur Chowdhury, Mizanur Rahman, Anjan Rayamajhi, Sakib Khan,\n  Mhafuzul Islam, Zadid Khan and James Martin", "title": "Lessons Learned from the Real-world Deployment of a Connected Vehicle\n  Testbed", "comments": "Will be published in the 2018 Transportation Research Board\n  Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connected vehicle (CV) system promises unprecedented safety, mobility,\nenvironmental, economic and social benefits, which can be unlocked using the\nenormous amount of data shared between vehicles and infrastructure (e.g.,\ntraffic signals, centers). Real world CV deployments including pilot\ndeployments help solve technical issues and observe potential benefits, both of\nwhich support the broader adoption of the CV system. This study focused on the\nClemson University Connected Vehicle Testbed (CUCVT) with the goal of sharing\nthe lessons learned from the CUCVT deployment. The motivation of this study was\nto enhance early CV deployments with the objective of depicting the lessons\nlearned from the CUCVT testbed, which includes unique features to support\nmultiple CV applications running simultaneously. The lessons learned in the\nCUCVT testbed are described at three different levels: i) the development of\nsystem architecture and prototyping in a controlled environment, ii) the\ndeployment of the CUCVT testbed, and iii) the validation of the CV application\nexperiments in the CUCVT. Our field experiments with a CV application validated\nthe functionalities needed for running multiple diverse CV applications\nsimultaneously under heterogeneous wireless networking, and realtime and non\nreal time data analytics requirements. The unique deployment experiences,\nrelated to heterogeneous wireless networks, real time data aggregation, a\ndistribution using broker system and data archiving with big data management\ntools, gained from the CUCVT testbed, could be used to advance CV research and\nguide public and private agencies for the deployment of CVs in the real world.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 19:24:19 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Chowdhury", "Mashrur", ""], ["Rahman", "Mizanur", ""], ["Rayamajhi", "Anjan", ""], ["Khan", "Sakib", ""], ["Islam", "Mhafuzul", ""], ["Khan", "Zadid", ""], ["Martin", "James", ""]]}, {"id": "1712.05840", "submitter": "Daniel Bj\\\"orkegren", "authors": "Daniel Bj\\\"orkegren and Darrell Grissen", "title": "Behavior Revealed in Mobile Phone Usage Predicts Loan Repayment", "comments": null, "journal-ref": null, "doi": "10.1093/wber/lhz006", "report-no": null, "categories": "cs.CY q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many households in developing countries lack formal financial histories,\nmaking it difficult for firms to extend credit, and for potential borrowers to\nreceive it. However, many of these households have mobile phones, which\ngenerate rich data about behavior. This article shows that behavioral\nsignatures in mobile phone data predict default, using call records matched to\nrepayment outcomes for credit extended by a South American telecom. On a sample\nof individuals with (thin) financial histories, our method actually outperforms\nmodels using credit bureau information, both within time and when tested on a\ndifferent time period. But our method also attains similar performance on those\nwithout financial histories, who cannot be scored using traditional methods.\nIndividuals in the highest quintile of risk by our measure are 2.8 times more\nlikely to default than those in the lowest quintile. The method forms the basis\nfor new forms of credit that reach the unbanked.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 05:28:07 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 01:42:11 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 17:13:57 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Bj\u00f6rkegren", "Daniel", ""], ["Grissen", "Darrell", ""]]}, {"id": "1712.05841", "submitter": "Jose Horta", "authors": "Jos\\'e Horta (1), Daniel Kofman, David Menga (2) ((1) LINCS, INFRES\n  (2) EDF R\\&D)", "title": "Novel paradigms for advanced distribution grid energy management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electricity distribution grid was not designed to cope with load dynamics\nimposed by high penetration of electric vehicles, neither to deal with the\nincreasing deployment of distributed Renewable Energy Sources. Distribution\nSystem Operators (DSO) will increasingly rely on flexible Distributed Energy\nResources (flexible loads, controllable generation and storage) to keep the\ngrid stable and to ensure quality of supply. In order to properly integrate\ndemand-side flexibility, DSOs need new energy management architectures, capable\nof fostering collaboration with wholesale market actors and pro-sumers. We\npropose the creation of Virtual Distribution Grids (VDG) over a common physical\ninfrastructure , to cope with heterogeneity of resources and actors, and with\nthe increasing complexity of distribution grid management and related resources\nallocation problems. Focusing on residential VDG, we propose an agent-based\nhierarchical architecture for providing Demand-Side Management services through\na market-based approach, where households transact their surplus/lack of energy\nand their flexibility with neighbours, aggregators, utilities and DSOs. For\nimplementing the overall solution, we consider fine-grained control of smart\nhomes based on Inter-net of Things technology. Homes seamlessly transact\nself-enforcing smart contracts over a blockchain-based generic platform.\nFinally, we extend the architecture to solve existing problems on smart home\ncontrol, beyond energy management.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 08:12:04 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Horta", "Jos\u00e9", ""], ["Kofman", "Daniel", ""], ["Menga", "David", ""]]}, {"id": "1712.05843", "submitter": "Ding Li", "authors": "Ding Li, Dongjin Song", "title": "Detecting Low Rating Android Apps Before They Have Reached the Market", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the popularity of the Android system, Android app markets enjoy a\nbooming prosperity in recent years. One critical problem for modern Android app\nmarkets is how to prevent apps that are going to receive low ratings from\nreaching end users. For this purpose, traditional approaches have to publish an\napp first and then collect enough user ratings and reviews so as to determine\nwhether the app is favored by end users or not. In this way, however, the\nreputation of the app market has already been damaged. To address this problem,\nwe propose a novel technique, i.e., Sextant , to detect low rating Android apps\nbased on the .apk files.With our proposed technique, an Android app market can\nprevent from risking its reputation on exposing low rating apps to users.\nSextant is developed based on novel static analysis techniques as well as\nmachine learning techniques. In our study, our proposed approach can achieve on\naverage 90.50% precision and 94.31% recall.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 20:53:59 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Li", "Ding", ""], ["Song", "Dongjin", ""]]}, {"id": "1712.05959", "submitter": "Alexandru-Ionu\\c{t} B\\u{a}beanu", "authors": "Alexandru-Ionu\\c{t} B\\u{a}beanu, Jorinde van de Vis, Diego\n  Garlaschelli", "title": "Ultrametricity increases the predictability of cultural dynamics", "comments": "13 pages, 7 figures", "journal-ref": "New J. Phys. 20, 103026 (2018)", "doi": "10.1088/1367-2630/aae566", "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quantitative understanding of societies requires useful combinations of\nempirical data and mathematical models. Models of cultural dynamics aim at\nexplaining the emergence of culturally homogeneous groups through social\ninfluence. Traditionally, the initial cultural traits of individuals are chosen\nuniformly at random, the emphasis being on characterizing the model outcomes\nthat are independent of these (`annealed') initial conditions. Here, motivated\nby an increasing interest in forecasting social behavior in the real world, we\nreverse the point of view and focus on the effect of specific (`quenched')\ninitial conditions, including those obtained from real data, on the final\ncultural state. We study the predictability, rigorously defined in an\ninformation-theoretic sense, of the \\emph{social content} of the final cultural\ngroups (i.e. who ends up in which group) from the knowledge of the initial\ncultural traits. We find that, as compared to random and shuffled initial\nconditions, the hierarchical ultrametric-like organization of empirical\ncultural states significantly increases the predictability of the final social\ncontent by largely confining cultural convergence within the lower levels of\nthe hierarchy. Moreover, predictability correlates with the compatibility of\nshort-term social coordination and long-term cultural diversity, a property\nthat has been recently found to be strong and robust in empirical data. We also\nintroduce a null model generating initial conditions that retain the\nultrametric representation of real data. Using this ultrametric model,\npredictability is highly enhanced with respect to the random and shuffled\ncases, confirming the usefulness of the empirical hierarchical organization of\nculture for forecasting the outcome of social influence models.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 13:26:29 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["B\u0103beanu", "Alexandru-Ionu\u0163", ""], ["van de Vis", "Jorinde", ""], ["Garlaschelli", "Diego", ""]]}, {"id": "1712.06034", "submitter": "James Taylor", "authors": "James Taylor", "title": "Study on the Best Uses of Technology in Support of Project-Based\n  Learning", "comments": "8 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Project-Based Learning (PBL) is a teaching technique in which authentic,\nreal-world projects are used as the primary vehicle to drive the student's\nlearning experience. This technique has been found to be very effective, but\nits overall adoption rate is relatively low, in part due to teachers'\nunfamiliarity with how to best use technology to successfully implement it.\nThis research study involved a comprehensive survey of supportive technology\ntools, as well as secondary survey research from students and teachers with\nactual experience in PBL. The goal was to determine which types of technology\ntools were most supportive of PBL. Overall, the study found that teachers and\nstudents are mostly aligned with regards to the importance of technology and\nthe effectiveness of various types of tools. Tools which fostered collaboration\namongst teacher and students were ultimately deemed the most effective, but\ncontent-development and assessment tools were also found to be particularly\nhelpful.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 23:50:30 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Taylor", "James", ""]]}, {"id": "1712.06414", "submitter": "Misha Teplitskiy", "authors": "Feng Shi, Misha Teplitskiy, Eamon Duede, James Evans", "title": "The Wisdom of Polarized Crowds", "comments": null, "journal-ref": "Nature Human Behavior. 2019", "doi": "10.1038/s41562-019-0541-6", "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.DL stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As political polarization in the United States continues to rise, the\nquestion of whether polarized individuals can fruitfully cooperate becomes\npressing. Although diversity of individual perspectives typically leads to\nsuperior team performance on complex tasks, strong political perspectives have\nbeen associated with conflict, misinformation and a reluctance to engage with\npeople and perspectives beyond one's echo chamber. It is unclear whether\nself-selected teams of politically diverse individuals will create higher or\nlower quality outcomes. In this paper, we explore the effect of team political\ncomposition on performance through analysis of millions of edits to Wikipedia's\nPolitical, Social Issues, and Science articles. We measure editors' political\nalignments by their contributions to conservative versus liberal articles. A\nsurvey of editors validates that those who primarily edit liberal articles\nidentify more strongly with the Democratic party and those who edit\nconservative ones with the Republican party. Our analysis then reveals that\npolarized teams---those consisting of a balanced set of politically diverse\neditors---create articles of higher quality than politically homogeneous teams.\nThe effect appears most strongly in Wikipedia's Political articles, but is also\nobserved in Social Issues and even Science articles. Analysis of article \"talk\npages\" reveals that politically polarized teams engage in longer, more\nconstructive, competitive, and substantively focused but linguistically diverse\ndebates than political moderates. More intense use of Wikipedia policies by\npolitically diverse teams suggests institutional design principles to help\nunleash the power of politically polarized teams.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 21:40:29 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Shi", "Feng", ""], ["Teplitskiy", "Misha", ""], ["Duede", "Eamon", ""], ["Evans", "James", ""]]}, {"id": "1712.06850", "submitter": "Johan Mazel", "authors": "Johan Mazel, Richard Garnier, Kensuke Fukuda", "title": "A comparison of web privacy protection techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comparison of web privacy protection techniques\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 10:21:36 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Mazel", "Johan", ""], ["Garnier", "Richard", ""], ["Fukuda", "Kensuke", ""]]}, {"id": "1712.07512", "submitter": "Anil Kumar Singh", "authors": "Anil Kumar Singh and Akhilesh Sudhakar", "title": "Ethical Questions in NLP Research: The (Mis)-Use of Forensic Linguistics", "comments": "4 pages, submitted to AIES-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ideas from forensic linguistics are now being used frequently in Natural\nLanguage Processing (NLP), using machine learning techniques. While the role of\nforensic linguistics was more benign earlier, it is now being used for purposes\nwhich are questionable. Certain methods from forensic linguistics are employed,\nwithout considering their scientific limitations and ethical concerns. While we\ntake the specific case of forensic linguistics as an example of such trends in\nNLP and machine learning, the issue is a larger one and present in many other\nscientific and data-driven domains. We suggest that such trends indicate that\nsome of the applied sciences are exceeding their legal and scientific briefs.\nWe highlight how carelessly implemented practices are serving to short-circuit\nthe due processes of law as well breach ethical codes.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 15:03:04 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Singh", "Anil Kumar", ""], ["Sudhakar", "Akhilesh", ""]]}, {"id": "1712.07711", "submitter": "Mario Coccia", "authors": "Mario Coccia", "title": "A New Classification of Technologies", "comments": "figure 1 table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study here suggests a classification of technologies based on taxonomic\ncharacteristics of interaction between technologies in complex systems that is\nnot a studied research field in economics of technical change. The proposed\ntaxonomy here categorizes technologies in four typologies, in a broad analogy\nwith the ecology: 1) technological parasitism is a relationship between two\ntechnologies T1 and T2 in a complex system S where one technology T1 benefits\nfrom the interaction with T2, whereas T2 has a negative side from interaction\nwith T1; 2) technological commensalism is a relationship between two\ntechnologies in S where one technology benefits from the other without\naffecting it; 3) technological mutualism is a relationship in which each\ntechnology benefits from the activity of the other within complex systems; 4)\ntechnological symbiosis is a long-term interaction between two (or more)\ntechnologies that evolve together in complex systems. This taxonomy\nsystematizes the typologies of interactive technologies within complex systems\nand predicts their evolutionary pathways that generate stepwise coevolutionary\nprocesses of complex systems of technology. This study here begins the process\nof generalizing, as far as possible, critical typologies of interactive\ntechnologies that explain the long-run evolution of technology. The theoretical\nframework developed here opens the black box of the interaction between\ntechnologies that affects, with different types of technologies, the\nevolutionary pathways of complex systems of technology over time and space.\nOverall, then, this new theoretical framework may be useful for bringing a new\nperspective to categorize the gradient of benefit to technologies from\ninteraction with other technologies that can be a ground work for development\nof more sophisticated concepts to clarify technological and economic change in\nhuman society.\n", "versions": [{"version": "v1", "created": "Mon, 11 Dec 2017 17:25:03 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Coccia", "Mario", ""]]}, {"id": "1712.07752", "submitter": "Rajesh Chidambaram", "authors": "Rajesh Chidambaram", "title": "Towards an unanimous international regulatory body for responsible use\n  of Artificial Intelligence [UIRB-AI]", "comments": "The paper covers a diverse range of topics but doesn't get into the\n  details of any and hence the proposals remain pragmatically irrelevant", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI), is once again in the phase of drastic\nadvancements. Unarguably, the technology itself can revolutionize the way we\nlive our everyday life. But the exponential growth of technology poses a\ndaunting task for policy researchers and law makers in making amendments to the\nexisting norms. In addition, not everyone in the society is studying the\npotential socio-economic intricacies and cultural drifts that AI can bring\nabout. It is prudence to reflect from our historical past to propel the\ndevelopment of technology in the right direction. To benefit the society of the\npresent and future, I scientifically explore the societal impact of AI. While\nthere are many public and private partnerships working on similar aspects, here\nI describe the necessity for an Unanimous International Regulatory Body for all\napplications of AI (UIRB-AI). I also discuss the benefits and drawbacks of such\nan organization. To combat any drawbacks in the formation of an UIRB-AI, both\nidealistic and pragmatic perspectives are discussed alternatively. The paper\nfurther advances the discussion by proposing novel policies on how such\norganization should be structured and how it can bring about a win-win\nsituation for everyone in the society.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 00:29:48 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 16:39:50 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 22:24:09 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Chidambaram", "Rajesh", ""]]}, {"id": "1712.07924", "submitter": "Emil Wiedemann", "authors": "Meike Zehlike and Philipp Hacker and Emil Wiedemann", "title": "Matching Code and Law: Achieving Algorithmic Fairness with Optimal\n  Transport", "comments": "Vastly extended new version, now including computational experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasingly, discrimination by algorithms is perceived as a societal and\nlegal problem. As a response, a number of criteria for implementing algorithmic\nfairness in machine learning have been developed in the literature. This paper\nproposes the Continuous Fairness Algorithm (CFA$\\theta$) which enables a\ncontinuous interpolation between different fairness definitions. More\nspecifically, we make three main contributions to the existing literature.\nFirst, our approach allows the decision maker to continuously vary between\nspecific concepts of individual and group fairness. As a consequence, the\nalgorithm enables the decision maker to adopt intermediate ``worldviews'' on\nthe degree of discrimination encoded in algorithmic processes, adding nuance to\nthe extreme cases of ``we're all equal'' (WAE) and ``what you see is what you\nget'' (WYSIWYG) proposed so far in the literature. Second, we use optimal\ntransport theory, and specifically the concept of the barycenter, to maximize\ndecision maker utility under the chosen fairness constraints. Third, the\nalgorithm is able to handle cases of intersectionality, i.e., of\nmulti-dimensional discrimination of certain groups on grounds of several\ncriteria. We discuss three main examples (credit applications; college\nadmissions; insurance contracts) and map out the legal and policy implications\nof our approach. The explicit formalization of the trade-off between individual\nand group fairness allows this post-processing approach to be tailored to\ndifferent situational contexts in which one or the other fairness criterion may\ntake precedence. Finally, we evaluate our model experimentally.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 13:08:03 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 10:25:54 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Zehlike", "Meike", ""], ["Hacker", "Philipp", ""], ["Wiedemann", "Emil", ""]]}, {"id": "1712.08076", "submitter": "Vasileios Lampos", "authors": "Vasileios Lampos", "title": "Assessing public health interventions using Web content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public health interventions are a fundamental tool for mitigating the spread\nof an infectious disease. However, it is not always possible to obtain a\nconclusive estimate for the impact of an intervention, especially in situations\nwhere the effects are fragmented in population parts that are under-represented\nwithin traditional public health surveillance schemes. To this end, online user\nactivity can be used as a complementary sensor to establish alternative\nmeasures. Here, we provide a summary of our research on formulating statistical\nframeworks for assessing public health interventions based on data from social\nmedia and search engines (Lampos et al., 2015 [20]; Wagner et al., 2017 [37]).\nOur methodology has been applied in two real-world case studies: the 2013/14\nand 2014/15 flu vaccination campaigns in England, where school-age children\nwere vaccinated in a number of locations aiming to reduce the overall\ntransmission of the virus. Disease models from online data combined with\nhistorical patterns of disease prevalence across different areas allowed us to\nquantify the impact of the intervention. In addition, a qualitative evaluation\nof our impact estimates demonstrated that they were in line with independent\nassessments from public health authorities.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 16:47:52 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Lampos", "Vasileios", ""]]}, {"id": "1712.08238", "submitter": "Karthik Dinakar", "authors": "Chelsea Barabas, Karthik Dinakar, Joichi Ito, Madars Virza, Jonathan\n  Zittrain", "title": "Interventions over Predictions: Reframing the Ethical Debate for\n  Actuarial Risk Assessment", "comments": "Accepted paper (not camera-ready version) of FATML 2018 conference,\n  Fairness, Accountability and Transparency in Machine Learning, 2018,\n  Proceedings of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Actuarial risk assessments might be unduly perceived as a neutral way to\ncounteract implicit bias and increase the fairness of decisions made at almost\nevery juncture of the criminal justice system, from pretrial release to\nsentencing, parole and probation. In recent times these assessments have come\nunder increased scrutiny, as critics claim that the statistical techniques\nunderlying them might reproduce existing patterns of discrimination and\nhistorical biases that are reflected in the data. Much of this debate is\ncentered around competing notions of fairness and predictive accuracy, resting\non the contested use of variables that act as \"proxies\" for characteristics\nlegally protected against discrimination, such as race and gender. We argue\nthat a core ethical debate surrounding the use of regression in risk\nassessments is not simply one of bias or accuracy. Rather, it's one of purpose.\nIf machine learning is operationalized merely in the service of predicting\nindividual future crime, then it becomes difficult to break cycles of\ncriminalization that are driven by the iatrogenic effects of the criminal\njustice system itself. We posit that machine learning should not be used for\nprediction, but rather to surface covariates that are fed into a causal model\nfor understanding the social, structural and psychological drivers of crime. We\npropose an alternative application of machine learning and causal inference\naway from predicting risk scores to risk mitigation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 22:27:39 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2018 20:52:15 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Barabas", "Chelsea", ""], ["Dinakar", "Karthik", ""], ["Ito", "Joichi", ""], ["Virza", "Madars", ""], ["Zittrain", "Jonathan", ""]]}, {"id": "1712.08341", "submitter": "Daniel Graziotin", "authors": "Per Lenberg, Robert Feldt, Lucas Gren, Lars G\\\"oran Wallgren Tengberg,\n  Inga Tidefors, Daniel Graziotin", "title": "Qualitative software engineering research -- reflections and guidelines", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers are increasingly recognizing the importance of human aspects in\nsoftware development and since qualitative methods are used to, in-depth,\nexplore human behavior, we believe that studies using such techniques will\nbecome more common.\n  Existing qualitative software engineering guidelines do not cover the full\nbreadth of qualitative methods and knowledge on using them found in the social\nsciences. The aim of this study was thus to extend the software engineering\nresearch community's current body of knowledge regarding available qualitative\nmethods and provide recommendations and guidelines for their use.\n  With the support of an epistemological argument and a literature review, we\nsuggest that future research would benefit from (1) utilizing a broader set of\nresearch methods, (2) more strongly emphasizing reflexivity, and (3) employing\nqualitative guidelines and quality criteria.\n  We present an overview of three qualitative methods commonly used in social\nsciences but rarely seen in software engineering research, namely\ninterpretative phenomenological analysis, narrative analysis, and discourse\nanalysis. Furthermore, we discuss the meaning of reflexivity in relation to the\nsoftware engineering context and suggest means of fostering it.\n  Our paper will help software engineering researchers better select and then\nguide the application of a broader set of qualitative research methods.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 08:40:19 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 13:55:20 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lenberg", "Per", ""], ["Feldt", "Robert", ""], ["Gren", "Lucas", ""], ["Tengberg", "Lars G\u00f6ran Wallgren", ""], ["Tidefors", "Inga", ""], ["Graziotin", "Daniel", ""]]}, {"id": "1712.08647", "submitter": "Taha Yasseri", "authors": "Dong Nguyen and Barbara McGillivray and Taha Yasseri", "title": "Emo, Love, and God: Making Sense of Urban Dictionary, a Crowd-Sourced\n  Online Dictionary", "comments": "Accepted, to appear in Royal Society Open Science. Data available\n  upon request", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet facilitates large-scale collaborative projects and the emergence\nof Web 2.0 platforms, where producers and consumers of content unify, has\ndrastically changed the information market. On the one hand, the promise of the\n\"wisdom of the crowd\" has inspired successful projects such as Wikipedia, which\nhas become the primary source of crowd-based information in many languages. On\nthe other hand, the decentralized and often un-monitored environment of such\nprojects may make them susceptible to low quality content. In this work, we\nfocus on Urban Dictionary, a crowd-sourced online dictionary. We combine\ncomputational methods with qualitative annotation and shed light on the overall\nfeatures of Urban Dictionary in terms of growth, coverage and types of content.\nWe measure a high presence of opinion-focused entries, as opposed to the\nmeaning-focused entries that we expect from traditional dictionaries.\nFurthermore, Urban Dictionary covers many informal, unfamiliar words as well as\nproper nouns. Urban Dictionary also contains offensive content, but highly\noffensive content tends to receive lower scores through the dictionary's voting\nsystem. The low threshold to include new material in Urban Dictionary enables\nquick recording of new words and new meanings, but the resulting heterogeneous\ncontent can pose challenges in using Urban Dictionary as a source to study\nlanguage innovation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 20:27:11 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 13:52:54 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Nguyen", "Dong", ""], ["McGillivray", "Barbara", ""], ["Yasseri", "Taha", ""]]}, {"id": "1712.08976", "submitter": "Alexander Kott", "authors": "Alexander Kott, David Alberts", "title": "How do you Command an Army of Intelligent Things?", "comments": "This is a version of the article that appears in IEEE Computer as:\n  Kott, Alexander, and David S. Alberts. \"How Do You Command an Army of\n  Intelligent Things?.\" Computer 12 (2017): 96-100", "journal-ref": "Computer 12 (2017): 96-100", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within a decade, probably less, we will need to find ways to work effectively\nwith ever growing numbers of intelligent things, including robots and\nintelligent agents. The networked workforce of the near future will thus\nconsist of not only interconnected and interdependent humans but also of\nintelligent things. This raises a number of challenging issues, none more\ncompelling and urgent than finding an answer to the question \"How to manage\nthis new organizational form?\" We consider these issues in a particularly\nchallenging domain of human endeavor -- warfare. Command and Control (C2) is\nthe term applied to management or governance of military organizations and\nendeavors. We consider how human and other intelligent entities can best\ncontribute to ensuring that the decision makers, whether human or machine, have\nthe information they require and make good use of this information to\naccomplish C2 functions. Commanders or managers of mixed human-thing\norganizations will face several challenges that the discussion above has\nhighlighted. Things are challenged in a number of areas and will need humans to\nprovide these capabilities. These include their ability to explain, build\ntrust, bond, understand personal agendas, emotions, politics, and negotiate.\nThings and people both to some extent have difficulty anticipating and coping\nwith the unusual and unexpected and to think of out-of-the-box solutions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 00:44:14 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Kott", "Alexander", ""], ["Alberts", "David", ""]]}, {"id": "1712.08980", "submitter": "Alexander Kott", "authors": "Alexander Kott, Ananthram Swami, Bruce J West", "title": "The Internet of Battle Things", "comments": "This is a version of the article that appears in IEEE Computer as:\n  Kott, Alexander, Ananthram Swami, and Bruce J. West. \"The Internet of Battle\n  Things.\" Computer 49.12 (2016): 70-75", "journal-ref": "Computer 49.12 (2016): 70-75", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The battlefield of the future will be densely populated by a variety of\nentities (\"things\") -- some intelligent and some only marginally so --\nperforming a broad range of tasks: sensing, communicating, acting, and\ncollaborating with each other and human warfighters. We call this the Internet\nof Battle Things, IoBT. In some ways, IoBT is already becoming a reality, but\n20-30 years from now it is likely to become a dominant presence in warfare. To\nbecome a reality, however, this bold vision will have to overcome a number of\nmajor challenges. As one example of such a challenge, the communications among\nthings will have to be flexible and adaptive to rapidly changing situations and\nmilitary missions. In this paper, we explore this and several other major\nchallenges of IoBT, and outline key research directions and approaches towards\nsolving these challenges.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 01:03:56 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Kott", "Alexander", ""], ["Swami", "Ananthram", ""], ["West", "Bruce J", ""]]}, {"id": "1712.09037", "submitter": "Sanaullah Manzoor", "authors": "Sanaullah Manzoor, Farhan Ahmad, Suleman Mazhar", "title": "Mobile Phone Based Portable Field Sensor System for Real-Time In-situ\n  River Water Quality Monitoring During Endangered Dolphin Monitoring Surveys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phone based potable water quality assessment device is developed to\nanalyze and study water pollution level at Indus river. Indus river is habitat\nof endangered Indus river dolphin and water pollution is one of major causes of\nsurvivability threats for this specie. We tested device performance at the six\nlocations of Lahore canal. pH of canal water deviates from the normal range of\nthe irrigation water. In future, we will study correlation between water\npollution level and habitat usage of Indus river dolphin using water quality\nassessment device and hydrophone array based passive acoustic monitoring (PAM)\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 08:18:08 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Manzoor", "Sanaullah", ""], ["Ahmad", "Farhan", ""], ["Mazhar", "Suleman", ""]]}, {"id": "1712.09124", "submitter": "Emma Pierson", "authors": "Emma Pierson", "title": "Demographics and discussion influence views on algorithmic fairness", "comments": "Expands previous version by adding longitudinal survey data; earlier\n  results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of algorithmic fairness has highlighted ethical questions which may\nnot have purely technical answers. For example, different algorithmic fairness\nconstraints are often impossible to satisfy simultaneously, and choosing\nbetween them requires value judgments about which people may disagree.\nAchieving consensus on algorithmic fairness will be difficult unless we\nunderstand why people disagree in the first place. Here we use a series of\nsurveys to investigate how two factors affect disagreement: demographics and\ndiscussion. First, we study whether disagreement on algorithmic fairness\nquestions is caused partially by differences in demographic backgrounds. This\nis a question of interest because computer science is demographically\nnon-representative. If beliefs about algorithmic fairness correlate with\ndemographics, and algorithm designers are demographically non-representative,\ndecisions made about algorithmic fairness may not reflect the will of the\npopulation as a whole. We show, using surveys of three separate populations,\nthat there are gender differences in beliefs about algorithmic fairness. For\nexample, women are less likely to favor including gender as a feature in an\nalgorithm which recommends courses to students if doing so would make female\nstudents less likely to be recommended science courses. Second, we investigate\nwhether people's views on algorithmic fairness can be changed by discussion and\nshow, using longitudinal surveys of students in two computer science classes,\nthat they can.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 20:05:32 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 01:35:04 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Pierson", "Emma", ""]]}, {"id": "1712.09347", "submitter": "Harishchandra Dubey", "authors": "Debanjan Borthakur and Harishchandra Dubey and Nicholas Constant and\n  Leslie Mahler and Kunal Mankodiya", "title": "Smart Fog: Fog Computing Framework for Unsupervised Clustering Analytics\n  in Wearable Internet of Things", "comments": "5 pages, 3 figures. 5th IEEE Global Conference on Signal and\n  Information Processing GlobalSIP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of wearables in smart telehealth generates heterogeneous\nmedical big data. Cloud and fog services process these data for assisting\nclinical procedures. IoT based ehealthcare have greatly benefited from\nefficient data processing. This paper proposed and evaluated use of low\nresource machine learning on Fog devices kept close to the wearables for smart\nhealthcare. In state of the art telecare systems, the signal processing and\nmachine learning modules are deployed in the cloud for processing physiological\ndata. We developed a prototype of Fog-based unsupervised machine learning big\ndata analysis for discovering patterns in physiological data. We employed Intel\nEdison and Raspberry Pi as Fog computer in proposed architecture. We performed\nvalidation studies on real-world pathological speech data from in home\nmonitoring of patients with Parkinson's disease (PD). Proposed architecture\nemployed machine learning for analysis of pathological speech data obtained\nfrom smartwatches worn by the patients with PD. Results showed that proposed\narchitecture is promising for low-resource clinical machine learning. It could\nbe useful for other applications within wearable IoT for smart telehealth\nscenarios by translating machine learning approaches from the cloud backend to\nedge computing devices such as Fog.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 02:08:39 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Borthakur", "Debanjan", ""], ["Dubey", "Harishchandra", ""], ["Constant", "Nicholas", ""], ["Mahler", "Leslie", ""], ["Mankodiya", "Kunal", ""]]}, {"id": "1712.09359", "submitter": "Renato Fabbri", "authors": "Renato Fabbri", "title": "Basic concepts and tools for the Toki Pona minimal and constructed\n  language: description of the language and main issues; analysis of the\n  vocabulary; text synthesis and syntax highlighting; Wordnet synsets", "comments": "Python and Vim scripts in this repository:\n  https://github.com/ttm/prv/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A minimal constructed language (conlang) is useful for experiments and\ncomfortable for making tools. The Toki Pona (TP) conlang is minimal both in the\nvocabulary (with only 14 letters and 124 lemmas) and in the (about) 10 syntax\nrules. The language is useful for being a used and somewhat established minimal\nconlang with at least hundreds of fluent speakers. This article exposes current\nconcepts and resources for TP, and makes available Python (and Vim) scripted\nroutines for the analysis of the language, synthesis of texts, syntax\nhighlighting schemes, and the achievement of a preliminary TP Wordnet. Focus is\non the analysis of the basic vocabulary, as corpus analyses were found. The\nsynthesis is based on sentence templates, relates to context by keeping track\nof used words, and renders larger texts by using a fixed number of phonemes\n(e.g. for poems) and number of sentences, words and letters (e.g. for\nparagraphs). Syntax highlighting reflects morphosyntactic classes given in the\nofficial dictionary and different solutions are described and implemented in\nthe well-established Vim text editor. The tentative TP Wordnet is made\navailable in three patterns of relations between synsets and word lemmas. In\nsummary, this text holds potentially novel conceptualizations about, and tools\nand results in analyzing, synthesizing and syntax highlighting the TP language.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 18:43:32 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 14:10:05 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2018 00:18:33 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Fabbri", "Renato", ""]]}, {"id": "1712.09424", "submitter": "Jan Vykopal", "authors": "Jan Vykopal, Radek O\\v{s}lej\\v{s}ek, Karol\\'ina Bursk\\'a, Krist\\'ina\n  Z\\'akop\\v{c}anov\\'a", "title": "Timely Feedback in Unstructured Cybersecurity Exercises", "comments": "6 pages; SIGCSE '18, Baltimore, MD, USA", "journal-ref": null, "doi": "10.1145/3159450.3159561", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber defence exercises are intensive, hands-on learning events for teams of\nprofessionals who gain or develop their skills to successfully prevent and\nrespond to cyber attacks. The exercises mimic the real-life, routine operation\nof an organization which is being attacked by an unknown offender. Teams of\nlearners receive very limited immediate feedback from the instructors during\nthe exercise; they can usually see only a scoreboard showing the aggregated\ngain or loss of points for particular tasks. An in-depth analysis of learners'\nactions requires considerable human effort, which results in days or weeks of\ndelay. The intensive experience is thus not followed by proper feedback\nfacilitating actual learning, and this diminishes the effect of the exercise.\n  In this initial work, we investigate how to provide valuable feedback to\nlearners right after the exercise without any unnecessary delay. Based on the\nscoring system of a cyber defence exercise, we have developed a new feedback\ntool that presents an interactive, personalized timeline of exercise events. We\ndeployed this tool during an international exercise, where we monitored\nparticipants' interactions and gathered their reflections. The results show\nthat learners did use the new tool and rated it positively. Since this new\nfeature is not bound to a particular defence exercise, it can be applied to all\nexercises that employ scoring based on the evaluation of individual exercise\nobjectives. As a result, it enables the learner to immediately reflect on the\nexperience gained.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 21:29:19 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Vykopal", "Jan", ""], ["O\u0161lej\u0161ek", "Radek", ""], ["Bursk\u00e1", "Karol\u00edna", ""], ["Z\u00e1kop\u010danov\u00e1", "Krist\u00edna", ""]]}, {"id": "1712.09527", "submitter": "Karan Aggarwal", "authors": "Karan Aggarwal, Shafiq Joty, Luis F. Luque, Jaideep Srivastava", "title": "Co-Morbidity Exploration on Wearables Activity Data Using Unsupervised\n  Pre-training and Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical activity and sleep play a major role in the prevention and\nmanagement of many chronic conditions. It is not a trivial task to understand\ntheir impact on chronic conditions. Currently, data from electronic health\nrecords (EHRs), sleep lab studies, and activity/sleep logs are used. The rapid\nincrease in the popularity of wearable health devices provides a significant\nnew data source, making it possible to track the user's lifestyle real-time\nthrough web interfaces, both to consumer as well as their healthcare provider,\npotentially. However, at present there is a gap between lifestyle data (e.g.,\nsleep, physical activity) and clinical outcomes normally captured in EHRs. This\nis a critical barrier for the use of this new source of signal for healthcare\ndecision making. Applying deep learning to wearables data provides a new\nopportunity to overcome this barrier.\n  To address the problem of the unavailability of clinical data from a major\nfraction of subjects and unrepresentative subject populations, we propose a\nnovel unsupervised (task-agnostic) time-series representation learning\ntechnique called act2vec. act2vec learns useful features by taking into account\nthe co-occurrence of activity levels along with periodicity of human activity\npatterns. The learned representations are then exploited to boost the\nperformance of disorder-specific supervised learning models. Furthermore, since\nmany disorders are often related to each other, a phenomenon referred to as\nco-morbidity, we use a multi-task learning framework for exploiting the shared\nstructure of disorder inducing life-style choices partially captured in the\nwearables data. Empirical evaluation using actigraphy data from 4,124 subjects\nshows that our proposed method performs and generalizes substantially better\nthan the conventional time-series symbolic representational methods and\ntask-specific deep learning models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 08:45:37 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Aggarwal", "Karan", ""], ["Joty", "Shafiq", ""], ["Luque", "Luis F.", ""], ["Srivastava", "Jaideep", ""]]}, {"id": "1712.10008", "submitter": "Dr. Nitin", "authors": "Shubhankar Gupta, Nitin", "title": "Development of Security Detection Model for the Security of Social Blogs\n  and Chatting from Hostile Users", "comments": "11 pages", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 9, No 5, October 2017", "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Worldwide, a large number of people interact with each other by means of\nonline chatting. There has been a significant rise in the number of platforms,\nboth social and professional, such as WhatsApp, Facebook,and Twitter, which\nallow people to share their experiences, views and knowledge with others. Sadly\nenough, with online communication getting embedded into our daily\ncommunication, incivility and misbehaviour has taken on many nuances from\nprofessional misbehaviour to professional decay. Generally flaming starts with\nthe exchange of rude messages and comments, which in turn triggers to higher\nscale of flaming. To prevent online communication from getting downgraded, it\nis essential to keep away the hostile users from communication platforms. This\npaper presents a Security Detection Model and a tool which checks and prevents\nonline flaming. It detects the presence of flaming while chatting or posting\nblogs, and censors swear words as well as blocks the users from flaming.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 18:15:57 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Gupta", "Shubhankar", ""], ["Nitin", "", ""]]}, {"id": "1712.10009", "submitter": "Gane Samb Lo", "authors": "Gane Samb Lo", "title": "VB and R codes using Households databases available in the NSI's : A\n  prelude to statistical applied studies", "comments": "42 pages, 3 figures", "journal-ref": null, "doi": "10.16929/ajas/206", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the main features of the households databases we can find in most\nof our National Statistics Institute. We provide algorithms aimed at extracting\na diversity of variables on which different statistical procedures may be\napplied. Here, we particularly focus on the scaled income, as a beginning.\nAssociated codes (MS Visual Basic and R codes) have been successfully tested\nand delivered in the text and in a separate file\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 19:29:07 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Lo", "Gane Samb", ""]]}, {"id": "1712.10068", "submitter": "Joss Wright", "authors": "Martin Dittus and Joss Wright and Mark Graham", "title": "Platform Criminalism: The 'Last-Mile' Geography of the Darknet Market\n  Supply Chain", "comments": null, "journal-ref": null, "doi": "10.1145/3178876.3186094", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Does recent growth of darknet markets signify a slow reorganisation of the\nillicit drug trade? Where are darknet markets situated in the global drug\nsupply chain? In principle, these platforms allow producers to sell directly to\nend users, bypassing traditional trafficking routes. And yet, there is evidence\nthat many offerings originate from a small number of highly active consumer\ncountries, rather than from countries that are primarily known for drug\nproduction. In a large-scale empirical study, we determine the darknet trading\ngeography of three plant-based drugs across four of the largest darknet\nmarkets, and compare it to the global footprint of production and consumption\nfor these drugs. We present strong evidence that cannabis and cocaine vendors\nare primarily located in a small number of consumer countries, rather than\nproducer countries, suggesting that darknet trading happens at the 'last mile',\npossibly leaving old trafficking routes intact. A model to explain trading\nvolumes of opiates is inconclusive. We cannot find evidence for significant\nproduction-side offerings across any of the drug types or marketplaces. Our\nevidence further suggests that the geography of darknet market trades is\nprimarily driven by existing consumer demand, rather than new demand fostered\nby individual markets.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 22:00:40 GMT"}, {"version": "v2", "created": "Mon, 1 Jan 2018 21:32:24 GMT"}, {"version": "v3", "created": "Sun, 11 Mar 2018 22:49:13 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Dittus", "Martin", ""], ["Wright", "Joss", ""], ["Graham", "Mark", ""]]}, {"id": "1712.10157", "submitter": "Vincent Labatut", "authors": "Nejat Arinik (1), Rosa Figueiredo (1), Vincent Labatut (1) ((1) LIA)", "title": "Signed Graph Analysis for the Interpretation of Voting Behavior", "comments": null, "journal-ref": "International Conference on Knowledge Technologies and Data-driven\n  Business (i-KNOW), Oct 2017, Graz, Austria. 2017, International Workshop on\n  Social Network Analysis and Digital Humanities (SnanDig).\n  http://ceur-ws.org/Vol-2025/paper_rssna_1.pdf", "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a signed graph, each link is labeled with either a positive or a negative\nsign. This is particularly appropriate to model polarized systems. Such a graph\ncan be characterized through the notion of structural balance, which relies on\nthe partitioning of the graph into internally solidary but mutually hostile\nsubgroups. In this work, we show that signed graphs can be used to model and\nunderstand voting behavior. We take advantage of data from the European\nParliament to confront two variants of structural balance, and illustrate how\ntheir use can help better understanding the studied system.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 09:14:23 GMT"}, {"version": "v2", "created": "Fri, 19 Jan 2018 16:18:50 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Arinik", "Nejat", "", "LIA"], ["Figueiredo", "Rosa", "", "LIA"], ["Labatut", "Vincent", "", "LIA"]]}, {"id": "1712.10243", "submitter": "Tomasz Ostwald", "authors": "Tomasz Ostwald (Salient Works)", "title": "Threat Modeling Data Analysis in Socio-technical Systems", "comments": "Presented at the Data For Good Exchange 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our decision-making processes are becoming more data driven, based on data\nfrom multiple sources, of different types, processed by a variety of\ntechnologies. As technology becomes more relevant for decision processes, the\nmore likely they are to be subjects of attacks aimed at disrupting their\nexecution or changing their outcome. With the increasing complexity and\ndependencies on technical components, such attempts grow more sophisticated and\ntheir impact will be more severe. This is especially important in scenarios\nwith shared goals, which had to be previously agreed to, or decisions with\nbroad social impact. We need to think about our decisions-making and underlying\ndata analysis processes in a systemic way to correctly evaluate benefits and\nrisks of specific solutions and to design them to be resistant to attacks. To\nreach these goals, we can apply experiences from threat modeling analysis used\nin software security. We will need to adapt these practices to new types of\nthreats, protecting different assets and operating in socio-technical systems.\nWith these changes, threat modeling can become a foundation for implementing\ndetailed technical, organizational or legal mitigations and making our\ndecisions more reliable and trustworthy.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 14:47:44 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Ostwald", "Tomasz", "", "Salient Works"]]}, {"id": "1712.10281", "submitter": "Mahmoud Fayed", "authors": "Mahmoud Samir Fayed", "title": "General-Purpose Visual Language and Information System with Case-Studies\n  in Developing Business Applications", "comments": "Master of Science Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning computer programming has been always challenging. Since the sixties\nof the last century, many researchers developed Visual Programming Languages\n(VPLs) to help in this regard. In this thesis, ten VPLs were specifically\nselected, studied, experimented with, and evaluated. A total of fifteen metrics\nwere used to evaluate the tools. Comparisons, classification, and gap analysis\nwere then presented. A list of requirements for a general-purpose VPL and a\nguide to help the novice programmer choose the right tool were generated and\nfinally the PWCT (Programming Without Coding Technology, a novel\ngeneral-purpose visual programming language) is developed and presented. PWCT\nhas been launched as a Sourceforge project, which currently has more than\n230,000 downloads for the language and more than 19,500,000 downloads for\nsamples, tutorials and movies. Many business applications and projects are\ndeveloped using PWCT, Also we developed the Supernova programming language and\nthe Ring programming language using PWCT to prove that it can be used for\nadvanced and large projects. Feedback from developers and results from the\nstudies indicate that PWCT is a very appealing, competitive, and powerful\nlanguage.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 20:51:55 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 22:03:35 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 15:04:13 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Fayed", "Mahmoud Samir", ""]]}]