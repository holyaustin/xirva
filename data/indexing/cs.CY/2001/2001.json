[{"id": "2001.00006", "submitter": "Travis LaCroix", "authors": "Travis LaCroix and Yoshua Bengio", "title": "Learning from Learning Machines: Optimisation, Rules, and Social Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an analogy between machine learning systems and economic entities in\nthat they are both adaptive, and their behaviour is specified in a more-or-less\nexplicit way. It appears that the area of AI that is most analogous to the\nbehaviour of economic entities is that of morally good decision-making, but it\nis an open question as to how precisely moral behaviour can be achieved in an\nAI system. This paper explores the analogy between these two complex systems,\nand we suggest that a clearer understanding of this apparent analogy may help\nus forward in both the socio-economic domain and the AI domain: known results\nin economics may help inform feasible solutions in AI safety, but also known\nresults in AI may inform economic policy. If this claim is correct, then the\nrecent successes of deep learning for AI suggest that more implicit\nspecifications work better than explicit ones for solving such problems.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 17:42:06 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["LaCroix", "Travis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2001.00034", "submitter": "Bernardo Furtado", "authors": "Bernardo Alves Furtado", "title": "Contributions of Talent, Perspective, Context and Luck to Success", "comments": "9 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a controlled simulation within a competitive sum-zero environment\nas a proxy for disaggregating components of success. Given a simulation of the\nRisk board game, we consider (a) Talent to be one of three rule-based\nstrategies used by players; (b) Context as the setting of each run of the game\nwith opponents' strategies, goals and luck; and (c) Perspective as the\nobjective of each player. Success is attained when a first player conquers its\ngoal. We simulate 100,000 runs of an agent-based model and analyze the results.\nThe simulation results strongly suggest that luck, talent and context are all\nrelevant to determine success. Perspective -- as the description of the goal\nthat defines success -- is not. As such, we present a quantitative,\nreproducible environment in which we are able to significantly separate the\nconcepts, reproducing previous results of the literature and adding arguments\nfor context and perspective. Finally, we also find that the simulation offers\ninsights on the relevance of resilience and opportunity.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 19:00:33 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:28:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Furtado", "Bernardo Alves", ""]]}, {"id": "2001.00078", "submitter": "Gillian Hadfield", "authors": "Jack Clark and Gillian K. Hadfield", "title": "Regulatory Markets for AI Safety", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model for regulation to achieve AI safety: global regulatory\nmarkets. We first sketch the model in general terms and provide an overview of\nthe costs and benefits of this approach. We then demonstrate how the model\nmight work in practice: responding to the risk of adversarial attacks on AI\nmodels employed in commercial drones.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 19:21:54 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Clark", "Jack", ""], ["Hadfield", "Gillian K.", ""]]}, {"id": "2001.00079", "submitter": "Ajay Shrestha", "authors": "Ajay Kumar Shrestha and Julita Vassileva", "title": "User Acceptance of Usable Blockchain-Based Research Data Sharing System:\n  An Extended TAM Based Study", "comments": "To appear in IEEE TPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology has evolved as a promising means to transform data\nmanagement models in many domains including healthcare, agricultural research,\ntourism domains etc. In the research community, a usable blockchain-based\nsystem can allow users to create a proof of ownership and provenance of the\nresearch work, share research data without losing control and ownership of it,\nprovide incentives for sharing and give users full transparency and control\nover who access their data, when and for what purpose. The initial adoption of\nsuch blockchain-based systems is necessary for continued use of the services,\nbut their user acceptance behavioral model has not been well investigated in\nthe literature. In this paper, we take the Technology Acceptance Model (TAM) as\na foundation and extend the external constructs to uncover how the perceived\nease of use, perceived usability, quality of the system and perceived enjoyment\ninfluence the intention to use the blockchain-based system. We based our study\non user evaluation of a prototype of a blockchain-based research data sharing\nframework using a TAM validated questionnaire. Our results show that, overall,\nall the individual constructs of the behavior model significantly influence the\nintention to use the system while their collective effect is found to be\ninsignificant. The quality of the system and the perceived enjoyment have\nstronger influence on the perceived usefulness. However, the effect of\nperceived ease of use on the perceived usefulness is not supported. Finally, we\ndiscuss the implications of our findings.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2019 06:49:34 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Shrestha", "Ajay Kumar", ""], ["Vassileva", "Julita", ""]]}, {"id": "2001.00081", "submitter": "Patrick Kelley", "authors": "Patrick Gage Kelley, Yongwei Yang, Courtney Heldreth, Christopher\n  Moessner, Aaron Sedley, Andreas Kramm, David T. Newman, and Allison Woodruff", "title": "Exciting, Useful, Worrying, Futuristic: Public Perception of Artificial\n  Intelligence in 8 Countries", "comments": "12 pages, 2 figures, 3 tables. AIES 2021: Proceedings of the AAAI/ACM\n  Conference on AI, Ethics, and Society", "journal-ref": null, "doi": "10.1145/3461702.3462605", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the influence and use of artificial intelligence (AI) have grown and its\ntransformative potential has become more apparent, many questions have been\nraised regarding the economic, political, social, and ethical implications of\nits use. Public opinion plays an important role in these discussions,\ninfluencing product adoption, commercial development, research funding, and\nregulation. In this paper we present results of an in-depth survey of public\nopinion of artificial intelligence conducted with 10,005 respondents spanning\neight countries and six continents. We report widespread perception that AI\nwill have significant impact on society, accompanied by strong support for the\nresponsible development and use of AI, and also characterize the public's\nsentiment towards AI with four key themes (exciting, useful, worrying, and\nfuturistic) whose prevalence distinguishes response to AI in different\ncountries.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 10:27:05 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 17:20:34 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kelley", "Patrick Gage", ""], ["Yang", "Yongwei", ""], ["Heldreth", "Courtney", ""], ["Moessner", "Christopher", ""], ["Sedley", "Aaron", ""], ["Kramm", "Andreas", ""], ["Newman", "David T.", ""], ["Woodruff", "Allison", ""]]}, {"id": "2001.00082", "submitter": "Naveen Mohan", "authors": "Naveen Mohan, Per Roos, Johan Svahn, Martin T\\\"orngren, Sagar Behere", "title": "ATRIUM -- Architecting Under Uncertainty for ISO 26262 compliance", "comments": "Added preprint copyright notice", "journal-ref": null, "doi": "10.1109/SYSCON.2017.7934819", "report-no": null, "categories": "cs.CY cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ISO 26262 is currently the dominant standard for assuring functional\nsafety of electrical and electronic systems in the automotive industry. The\nFunctional Safety Concept (FSC) subphase in the standard requires the\nPreliminary Architectural Assumptions (PAA) for allocation of functional safety\nrequirements (FSRs). This paper justifies the need for, and defines a process\nATRIUM, for consistent design of the PAA. ATRIUM is subsequently applied in an\nindustrial case study for a function enabling highly automated driving at one\nof the largest heavy vehicle manufacturers in Europe, Scania CV AB. The\nfindings from this study, which contributed to ATRIUM's institutionalization at\nScania, are presented. The benefits of the proposed process include (i) a fast\nand flexible way to refine the PAA, and a framework to (ii) incorporate\ninformation from legacy systems into safety design and (iii) rigorously track\nand document the assumptions and rationale behind architectural decisions under\nuncertain information. The contributions of this paper are the (i) analysis of\nthe problem (ii) the process ATRIUM and (iii) findings and the discussion from\nthe case study at Scania.\n  Keywords: ISO 26262, functional safety, automation, HCV, HGV, architectures,\nhighly automated driving, ATRIUM, decision making, architecting, uncertainty\nmanagement\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 12:15:13 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Mohan", "Naveen", ""], ["Roos", "Per", ""], ["Svahn", "Johan", ""], ["T\u00f6rngren", "Martin", ""], ["Behere", "Sagar", ""]]}, {"id": "2001.00088", "submitter": "Andrew Perrault", "authors": "Andrew Perrault, Fei Fang, Arunesh Sinha, Milind Tambe", "title": "AI for Social Impact: Learning and Planning in the Data-to-Deployment\n  Pipeline", "comments": "To appear, AI Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the maturing of AI and multiagent systems research, we have a tremendous\nopportunity to direct these advances towards addressing complex societal\nproblems. In pursuit of this goal of AI for Social Impact, we as AI researchers\nmust go beyond improvements in computational methodology; it is important to\nstep out in the field to demonstrate social impact. To this end, we focus on\nthe problems of public safety and security, wildlife conservation, and public\nhealth in low-resource communities, and present research advances in multiagent\nsystems to address one key cross-cutting challenge: how to effectively deploy\nour limited intervention resources in these problem domains. We present case\nstudies from our deployments around the world as well as lessons learned that\nwe hope are of use to researchers who are interested in AI for Social Impact.\nIn pushing this research agenda, we believe AI can indeed play an important\nrole in fighting social injustice and improving society.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:10:56 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Perrault", "Andrew", ""], ["Fang", "Fei", ""], ["Sinha", "Arunesh", ""], ["Tambe", "Milind", ""]]}, {"id": "2001.00089", "submitter": "Candice Schumann", "authors": "Debjani Saha, Candice Schumann, Duncan C. McElfresh, John P.\n  Dickerson, Michelle L. Mazurek, Michael Carl Tschantz", "title": "Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in machine learning has manifested injustice in several areas, such as\nmedicine, hiring, and criminal justice. In response, computer scientists have\ndeveloped myriad definitions of fairness to correct this bias in fielded\nalgorithms. While some definitions are based on established legal and ethical\nnorms, others are largely mathematical. It is unclear whether the general\npublic agrees with these fairness definitions, and perhaps more importantly,\nwhether they understand these definitions. We take initial steps toward\nbridging this gap between ML researchers and the public, by addressing the\nquestion: does a lay audience understand a basic definition of ML fairness? We\ndevelop a metric to measure comprehension of three such\ndefinitions--demographic parity, equal opportunity, and equalized odds. We\nevaluate this metric using an online survey, and investigate the relationship\nbetween comprehension and sentiment, demographics, and the definition itself.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 00:58:54 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 16:23:08 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 21:13:01 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Saha", "Debjani", ""], ["Schumann", "Candice", ""], ["McElfresh", "Duncan C.", ""], ["Dickerson", "John P.", ""], ["Mazurek", "Michelle L.", ""], ["Tschantz", "Michael Carl", ""]]}, {"id": "2001.00090", "submitter": "Somali Chaterji", "authors": "Somali Chaterji, Parinaz Naghizadeh, Muhammad Ashraful Alam, Saurabh\n  Bagchi, Mung Chiang, David Corman, Brian Henz, Suman Jana, Na Li, Shaoshuai\n  Mou, Meeko Oishi, Chunyi Peng, Tiark Rompf, Ashutosh Sabharwal, Shreyas\n  Sundaram, James Weimer, Jennifer Weller", "title": "Resilient Cyberphysical Systems and their Application Drivers: A\n  Technology Roadmap", "comments": "36 pages, 2 figures, NSF-supported workshop on Grand Challenges in\n  Resilience, held at Purdue, March 20-21, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberphysical systems (CPS) are ubiquitous in our personal and professional\nlives, and they promise to dramatically improve micro-communities (e.g., urban\nfarms, hospitals), macro-communities (e.g., cities and metropolises), urban\nstructures (e.g., smart homes and cars), and living structures (e.g., human\nbodies, synthetic genomes). The question that we address in this article\npertains to designing these CPS systems to be resilient-from-the-ground-up, and\nthrough progressive learning, resilient-by-reaction. An optimally designed\nsystem is resilient to both unique attacks and recurrent attacks, the latter\nwith a lower overhead. Overall, the notion of resilience can be thought of in\nthe light of three main sources of lack of resilience, as follows: exogenous\nfactors, such as natural variations and attack scenarios; mismatch between\nengineered designs and exogenous factors ranging from DDoS (distributed\ndenial-of-service) attacks or other cybersecurity nightmares, so called \"black\nswan\" events, disabling critical services of the municipal electrical grids and\nother connected infrastructures, data breaches, and network failures; and the\nfragility of engineered designs themselves encompassing bugs, human-computer\ninteractions (HCI), and the overall complexity of real-world systems. In the\npaper, our focus is on design and deployment innovations that are broadly\napplicable across a range of CPS application areas.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 01:33:01 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Chaterji", "Somali", ""], ["Naghizadeh", "Parinaz", ""], ["Alam", "Muhammad Ashraful", ""], ["Bagchi", "Saurabh", ""], ["Chiang", "Mung", ""], ["Corman", "David", ""], ["Henz", "Brian", ""], ["Jana", "Suman", ""], ["Li", "Na", ""], ["Mou", "Shaoshuai", ""], ["Oishi", "Meeko", ""], ["Peng", "Chunyi", ""], ["Rompf", "Tiark", ""], ["Sabharwal", "Ashutosh", ""], ["Sundaram", "Shreyas", ""], ["Weimer", "James", ""], ["Weller", "Jennifer", ""]]}, {"id": "2001.00228", "submitter": "L. A. Barba", "authors": "Lorena A. Barba", "title": "Engineers Code: reusable open learning modules for engineering\n  computations", "comments": "7 pages, 1 figure", "journal-ref": "Computing in Science & Engineering 22(4): 26-35 (2020)", "doi": "10.1109/MCSE.2020.2976002", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undergraduate programs in science and engineering include at least one course\nin basic programming, but seldom presented in a contextualized format, where\ncomputing is a tool for thinking and learning in the discipline. We have\ncreated a series of learning modules to embed computing in engineering\neducation, and share this content under permissive public licenses. The modules\nare created as a set of lessons using Jupyter notebooks, and complemented by\nonline courses in the Open edX platform, using new integrations we developed.\nLearning sequences in the online course pull content dynamically from public\nJupyter notebooks and assessments are auto-graded on-the-fly, using our Jupyter\nViewer and Jupyter Grader third-party extensions for Open edX (XBlocks). The\nlearning content is modularized and designed for reuse in various formats. In\none of these formats---short but intense workshops---our university library is\nleveraging the curriculum to offer extra-curricular training for all, at high\ndemands.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:49:16 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Barba", "Lorena A.", ""]]}, {"id": "2001.00249", "submitter": "Amanda Coston", "authors": "Maria De-Arteaga, Tejumade Afonja, Amanda Coston", "title": "Proceedings of NeurIPS 2019 Workshop on Machine Learning for the\n  Developing World: Challenges and Risks of ML4D", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the proceedings of the 3rd ML4D workshop which was help in Vancouver,\nCanada on December 13, 2019 as part of the Neural Information Processing\nSystems conference.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 17:39:42 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 17:20:24 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["De-Arteaga", "Maria", ""], ["Afonja", "Tejumade", ""], ["Coston", "Amanda", ""]]}, {"id": "2001.00301", "submitter": "Joshua I. James", "authors": "Jiyoon Ham, Joshua I. James", "title": "A Feature Comparison of Modern Digital Forensic Imaging Software", "comments": "6 pages, 1 figure", "journal-ref": "The Journal of The Institute of Internet, Broadcasting and\n  Communication 19-6: 15-20 (2019)", "doi": "10.7236/JIIBC.2019.19.6.15", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental processes in digital forensic investigation, such as disk\nimaging, were developed when digital investigation was relatively young. As\ndigital forensic processes and procedures matured, these fundamental tools,\nthat are the pillars of the reset of the data processing and analysis phases of\nan investigation, largely stayed the same. This work is a study of modern\ndigital forensic imaging software tools. Specifically, we will examine the\nfeature sets of modern digital forensic imaging tools, as well as their\ndevelopment and release cycles to understand patterns of fundamental tool\ndevelopment. Based on this survey, we show the weakness in current digital\ninvestigation fundamental software development and maintenance over time. We\nalso provide recommendations on how to improve fundamental tools.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 02:42:31 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ham", "Jiyoon", ""], ["James", "Joshua I.", ""]]}, {"id": "2001.00329", "submitter": "Dallas Card", "authors": "Dallas Card and Noah A. Smith", "title": "On Consequentialism and Fairness", "comments": "Updating to published version", "journal-ref": "Front. Artif. Intell., 08 May 2020", "doi": "10.3389/frai.2020.00034", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on fairness in machine learning has primarily emphasized how to\ndefine, quantify, and encourage \"fair\" outcomes. Less attention has been paid,\nhowever, to the ethical foundations which underlie such efforts. Among the\nethical perspectives that should be taken into consideration is\nconsequentialism, the position that, roughly speaking, outcomes are all that\nmatter. Although consequentialism is not free from difficulties, and although\nit does not necessarily provide a tractable way of choosing actions (because of\nthe combined problems of uncertainty, subjectivity, and aggregation), it\nnevertheless provides a powerful foundation from which to critique the existing\nliterature on machine learning fairness. Moreover, it brings to the fore some\nof the tradeoffs involved, including the problem of who counts, the pros and\ncons of using a policy, and the relative value of the distant future. In this\npaper we provide a consequentialist critique of common definitions of fairness\nwithin machine learning, as well as a machine learning perspective on\nconsequentialism. We conclude with a broader discussion of the issues of\nlearning and randomization, which have important implications for the ethics of\nautomated decision making systems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 05:39:48 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 04:36:44 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Card", "Dallas", ""], ["Smith", "Noah A.", ""]]}, {"id": "2001.00350", "submitter": "Brian Ryu", "authors": "Brian K. Ryu", "title": "The Demise of Single-Authored Publications in Computer Science: A\n  Citation Network Analysis", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this study, I analyze the DBLP bibliographic database to study role of\nsingle author publications in the computer science literature between 1940 and\n2019. I examine the demographics and reception by computing the population\nfraction, citation statistics, and PageRank scores of single author\npublications over the years. Both the population fraction and reception have\nbeen continuously declining since the 1940s. The overall decaying trend of\nsingle author publications is qualitatively consistent with those observed in\nother scientific disciplines, though the diminution is taking place several\ndecades later than those in the natural sciences. Additionally, I analyze the\nscope and volume of single author publications, using page length and reference\ncount as first-order approximations of the scope of publications. Although both\nmetrics on average show positive correlations with citation count, single\nauthor papers show no significant difference in page or reference counts\ncompared to the rest of the publications, suggesting that there exist other\nfactors that impact the citations of single author publications.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 07:47:44 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Ryu", "Brian K.", ""]]}, {"id": "2001.00367", "submitter": "Weiqiang Sun", "authors": "Jiapeng Dong and Pengju Wang and Weiqiang Sun", "title": "Cost of Dietary Data Acquisition with Smart Group Catering", "comments": "Will be presented on the Computing Conference 2020, London, Jul. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The need for dietary data management is growing with public awareness of food\nintakes. As a result, there are increasing deployments of smart canteens where\ndietary data is collected through either Radio Frequency Identification (RFID)\nor Computer Vision(CV)-based solutions. As human labor is involved in both\ncases, manpower allocation is critical to data quality. Where manpower\nrequirements are underestimated, data quality is compromised. This paper has\nstudied the relation between the quality of dietary data and the manpower\ninvested, using numerical simulations based on real data collected from\nmultiple smart canteens. We found that in both RFID and CV-based systems, the\nlong-term cost of dietary data acquisition is dominated by manpower. Our study\nprovides a comprehensive understanding of the cost composition for dietary data\nacquisition and useful insights toward future cost effective systems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 09:25:57 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Dong", "Jiapeng", ""], ["Wang", "Pengju", ""], ["Sun", "Weiqiang", ""]]}, {"id": "2001.00463", "submitter": "Toby Shevlane", "authors": "Toby Shevlane, Allan Dafoe", "title": "The Offense-Defense Balance of Scientific Knowledge: Does Publishing AI\n  Research Reduce Misuse?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing concern over the potential misuse of artificial intelligence\n(AI) research. Publishing scientific research can facilitate misuse of the\ntechnology, but the research can also contribute to protections against misuse.\nThis paper addresses the balance between these two effects. Our theoretical\nframework elucidates the factors governing whether the published research will\nbe more useful for attackers or defenders, such as the possibility for adequate\ndefensive measures, or the independent discovery of the knowledge outside of\nthe scientific community. The balance will vary across scientific fields.\nHowever, we show that the existing conversation within AI has imported concepts\nand conclusions from prior debates within computer security over the disclosure\nof software vulnerabilities. While disclosure of software vulnerabilities often\nfavours defence, this cannot be assumed for AI research. The AI research\ncommunity should consider concepts and policies from a broad set of adjacent\nfields, and ultimately needs to craft policy well-suited to its particular\nchallenges.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 10:20:44 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 23:24:21 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Shevlane", "Toby", ""], ["Dafoe", "Allan", ""]]}, {"id": "2001.00476", "submitter": "Filipe Zabala Mr.", "authors": "Filipe J. Zabala and Fabiano F. Silveira", "title": "Decades of Jurimetrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Jurimetrics: decades of history, decades to-be auspicious. A Brazilian point\nof view on the trajectory of this forgotten concept in the quantitative\napproach of the law, with code and examples in free software.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 17:36:46 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Zabala", "Filipe J.", ""], ["Silveira", "Fabiano F.", ""]]}, {"id": "2001.00565", "submitter": "Philipp Schaer", "authors": "Andr\\'e Calero Valdez and Lena Adam and Dennis Assenmacher and Laura\n  Burbach and Malte Bonart and Lena Frischlich and Philipp Schaer", "title": "Computational Methods in Professional Communication", "comments": null, "journal-ref": "2019 IEEE International Professional Communication Conference\n  (ProComm), Aachen, Germany, 2019, pp. 275-285", "doi": "10.1109/ProComm.2019.00063", "report-no": null, "categories": "cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The digitization of the world has also led to a digitization of communication\nprocesses. Traditional research methods fall short in understanding\ncommunication in digital worlds as the scope has become too large in volume,\nvariety, and velocity to be studied using traditional approaches. In this\npaper, we present computational methods and their use in public and mass\ncommunication research and how those could be adapted to professional\ncommunication research. The paper is a proposal for a panel in which the\npanelists, each an expert in their field, will present their current work using\ncomputational methods and will discuss transferability of these methods to\nprofessional communication.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 18:57:42 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Valdez", "Andr\u00e9 Calero", ""], ["Adam", "Lena", ""], ["Assenmacher", "Dennis", ""], ["Burbach", "Laura", ""], ["Bonart", "Malte", ""], ["Frischlich", "Lena", ""], ["Schaer", "Philipp", ""]]}, {"id": "2001.00604", "submitter": "Carlos Sarraute PhD", "authors": "Antonio Vazquez Brust, Tomas Olego, German Rosati, Carolina Lang,\n  Guillermo Bozzoli, Diego Weinberg, Roberto Chuit, Martin A. Minnoni, Carlos\n  Sarraute", "title": "Detecting Areas of Potential High Prevalence of Chagas in Argentina", "comments": "Proceedings of the 2019 World Wide Web Conference. May 13-17, 2019.\n  San Francisco, CA, USA", "journal-ref": null, "doi": "10.1145/3308560.3316485", "report-no": null, "categories": "cs.SI cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A map of potential prevalence of Chagas disease (ChD) with high spatial\ndisaggregation is presented. It aims to detect areas outside the Gran Chaco\necoregion (hyperendemic for the ChD), characterized by high affinity with ChD\nand high health vulnerability.\n  To quantify potential prevalence, we developed several indicators: an\nAffinity Index which quantifies the degree of linkage between endemic areas of\nChD and the rest of the country. We also studied favorable habitability\nconditions for Triatoma infestans, looking for areas where the predominant\nmaterials of floors, roofs and internal ceilings favor the presence of the\ndisease vector.\n  We studied determinants of a more general nature that can be encompassed\nunder the concept of Health Vulnerability Index. These determinants are\nassociated with access to health providers and the socio-economic level of\ndifferent segments of the population.\n  Finally we constructed a Chagas Potential Prevalence Index (ChPPI) which\ncombines the affinity index, the health vulnerability index, and the population\ndensity. We show and discuss the maps obtained. These maps are intended to\nassist public health specialists, decision makers of public health policies and\npublic officials in the development of cost-effective strategies to improve\naccess to diagnosis and treatment of ChD.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 19:34:58 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Brust", "Antonio Vazquez", ""], ["Olego", "Tomas", ""], ["Rosati", "German", ""], ["Lang", "Carolina", ""], ["Bozzoli", "Guillermo", ""], ["Weinberg", "Diego", ""], ["Chuit", "Roberto", ""], ["Minnoni", "Martin A.", ""], ["Sarraute", "Carlos", ""]]}, {"id": "2001.00964", "submitter": "Inioluwa Deborah Raji", "authors": "Inioluwa Deborah Raji, Timnit Gebru, Margaret Mitchell, Joy\n  Buolamwini, Joonseok Lee, Emily Denton", "title": "Saving Face: Investigating the Ethical Concerns of Facial Recognition\n  Auditing", "comments": "Accepted to AAAI/ACM AI Ethics and Society conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although essential to revealing biased performance, well intentioned attempts\nat algorithmic auditing can have effects that may harm the very populations\nthese measures are meant to protect. This concern is even more salient while\nauditing biometric systems such as facial recognition, where the data is\nsensitive and the technology is often used in ethically questionable manners.\nWe demonstrate a set of five ethical concerns in the particular case of\nauditing commercial facial processing technology, highlighting additional\ndesign considerations and ethical tensions the auditor needs to be aware of so\nas not exacerbate or complement the harms propagated by the audited system. We\ngo further to provide tangible illustrations of these concerns, and conclude by\nreflecting on what these concerns mean for the role of the algorithmic audit\nand the fundamental product limitations they reveal.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 20:03:44 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Raji", "Inioluwa Deborah", ""], ["Gebru", "Timnit", ""], ["Mitchell", "Margaret", ""], ["Buolamwini", "Joy", ""], ["Lee", "Joonseok", ""], ["Denton", "Emily", ""]]}, {"id": "2001.00973", "submitter": "Inioluwa Deborah Raji", "authors": "Inioluwa Deborah Raji, Andrew Smart, Rebecca N. White, Margaret\n  Mitchell, Timnit Gebru, Ben Hutchinson, Jamila Smith-Loud, Daniel Theron,\n  Parker Barnes", "title": "Closing the AI Accountability Gap: Defining an End-to-End Framework for\n  Internal Algorithmic Auditing", "comments": "Accepted to ACM FAT* (Fariness, Accountability and Transparency)\n  conference 2020. Full workable templates for the documents of the SMACTR\n  framework presented in the paper can be found here\n  https://drive.google.com/drive/folders/1GWlq8qGZXb2lNHxWBuo2wl-rlHsjNPM0?usp=sharing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rising concern for the societal implications of artificial intelligence\nsystems has inspired a wave of academic and journalistic literature in which\ndeployed systems are audited for harm by investigators from outside the\norganizations deploying the algorithms. However, it remains challenging for\npractitioners to identify the harmful repercussions of their own systems prior\nto deployment, and, once deployed, emergent issues can become difficult or\nimpossible to trace back to their source. In this paper, we introduce a\nframework for algorithmic auditing that supports artificial intelligence system\ndevelopment end-to-end, to be applied throughout the internal organization\ndevelopment lifecycle. Each stage of the audit yields a set of documents that\ntogether form an overall audit report, drawing on an organization's values or\nprinciples to assess the fit of decisions made throughout the process. The\nproposed auditing framework is intended to contribute to closing the\naccountability gap in the development and deployment of large-scale artificial\nintelligence systems by embedding a robust process to ensure audit integrity.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 20:19:04 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Raji", "Inioluwa Deborah", ""], ["Smart", "Andrew", ""], ["White", "Rebecca N.", ""], ["Mitchell", "Margaret", ""], ["Gebru", "Timnit", ""], ["Hutchinson", "Ben", ""], ["Smith-Loud", "Jamila", ""], ["Theron", "Daniel", ""], ["Barnes", "Parker", ""]]}, {"id": "2001.01029", "submitter": "Cole Freeman", "authors": "Cole Freeman, Hamed Alhoori, Murtuza Shahzad", "title": "Measuring the Diversity of Facebook Reactions to Research", "comments": "17 pages, 3 figures, ACM Group", "journal-ref": null, "doi": "10.1145/3375192", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online and in the real world, communities are bonded together by emotional\nconsensus around core issues. Emotional responses to scientific findings often\nplay a pivotal role in these core issues. When there is too much diversity of\nopinion on topics of science, emotions flare up and give rise to conflict. This\nconflict threatens positive outcomes for research. Emotions have the power to\nshape how people process new information. They can color the public's\nunderstanding of science, motivate policy positions, even change lives. And yet\nlittle work has been done to evaluate the public's emotional response to\nscience using quantitative methods. In this paper, we use a dataset of\nresponses to scholarly articles on Facebook to analyze the dynamics of\nemotional valence, intensity, and diversity. We present a novel way of\nweighting click-based reactions that increases their comprehensibility, and use\nthese weighted reactions to develop new metrics of aggregate emotional\nresponses. We use our metrics along with LDA topic models and statistical\ntesting to investigate how users' emotional responses differ from one\nscientific topic to another. We find that research articles related to gender,\ngenetics, or agricultural/environmental sciences elicit significantly different\nemotional responses from users than other research topics. We also find that\nthere is generally a positive response to scientific research on Facebook, and\nthat articles generating a positive emotional response are more likely to be\nwidely shared---a conclusion that contradicts previous studies of other social\nmedia platforms.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 03:41:44 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Freeman", "Cole", ""], ["Alhoori", "Hamed", ""], ["Shahzad", "Murtuza", ""]]}, {"id": "2001.01296", "submitter": "Pedro Ramaciotti Morales", "authors": "Pedro Ramaciotti Morales, Robin Lamarche-Perrin, Raphael\n  Fournier-S'niehotta, Remy Poulain, Lionel Tabourier, and Fabien Tarissan", "title": "Measuring Diversity in Heterogeneous Information Networks", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.IR cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diversity is a concept relevant to numerous domains of research varying from\necology, to information theory, and to economics, to cite a few. It is a notion\nthat is steadily gaining attention in the information retrieval, network\nanalysis, and artificial neural networks communities. While the use of\ndiversity measures in network-structured data counts a growing number of\napplications, no clear and comprehensive description is available for the\ndifferent ways in which diversities can be measured. In this article, we\ndevelop a formal framework for the application of a large family of diversity\nmeasures to heterogeneous information networks (HINs), a flexible, widely-used\nnetwork data formalism. This extends the application of diversity measures,\nfrom systems of classifications and apportionments, to more complex relations\nthat can be better modeled by networks. In doing so, we not only provide an\neffective organization of multiple practices from different domains, but also\nunearth new observables in systems modeled by heterogeneous information\nnetworks. We illustrate the pertinence of our approach by developing different\napplications related to various domains concerned by both diversity and\nnetworks. In particular, we illustrate the usefulness of these new proposed\nobservables in the domains of recommender systems and social media studies,\namong other fields.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 19:21:50 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 18:21:04 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 12:23:01 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Morales", "Pedro Ramaciotti", ""], ["Lamarche-Perrin", "Robin", ""], ["Fournier-S'niehotta", "Raphael", ""], ["Poulain", "Remy", ""], ["Tabourier", "Lionel", ""], ["Tarissan", "Fabien", ""]]}, {"id": "2001.01306", "submitter": "Honghui Shi", "authors": "Mang Tik Chiu, Xingqian Xu, Yunchao Wei, Zilong Huang, Alexander\n  Schwing, Robert Brunner, Hrant Khachatrian, Hovnatan Karapetyan, Ivan Dozier,\n  Greg Rose, David Wilson, Adrian Tudor, Naira Hovakimyan, Thomas S. Huang,\n  Honghui Shi", "title": "Agriculture-Vision: A Large Aerial Image Database for Agricultural\n  Pattern Analysis", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning in visual recognition tasks has driven\nadvancements in multiple fields of research. Particularly, increasing attention\nhas been drawn towards its application in agriculture. Nevertheless, while\nvisual pattern recognition on farmlands carries enormous economic values,\nlittle progress has been made to merge computer vision and crop sciences due to\nthe lack of suitable agricultural image datasets. Meanwhile, problems in\nagriculture also pose new challenges in computer vision. For example, semantic\nsegmentation of aerial farmland images requires inference over extremely\nlarge-size images with extreme annotation sparsity. These challenges are not\npresent in most of the common object datasets, and we show that they are more\nchallenging than many other aerial image datasets. To encourage research in\ncomputer vision for agriculture, we present Agriculture-Vision: a large-scale\naerial farmland image dataset for semantic segmentation of agricultural\npatterns. We collected 94,986 high-quality aerial images from 3,432 farmlands\nacross the US, where each image consists of RGB and Near-infrared (NIR)\nchannels with resolution as high as 10 cm per pixel. We annotate nine types of\nfield anomaly patterns that are most important to farmers. As a pilot study of\naerial agricultural semantic segmentation, we perform comprehensive experiments\nusing popular semantic segmentation models; we also propose an effective model\ndesigned for aerial agricultural pattern recognition. Our experiments\ndemonstrate several challenges Agriculture-Vision poses to both the computer\nvision and agriculture communities. Future versions of this dataset will\ninclude even more aerial images, anomaly patterns and image channels. More\ninformation at https://www.agriculture-vision.com.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 20:19:33 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 04:13:08 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Chiu", "Mang Tik", ""], ["Xu", "Xingqian", ""], ["Wei", "Yunchao", ""], ["Huang", "Zilong", ""], ["Schwing", "Alexander", ""], ["Brunner", "Robert", ""], ["Khachatrian", "Hrant", ""], ["Karapetyan", "Hovnatan", ""], ["Dozier", "Ivan", ""], ["Rose", "Greg", ""], ["Wilson", "David", ""], ["Tudor", "Adrian", ""], ["Hovakimyan", "Naira", ""], ["Huang", "Thomas S.", ""], ["Shi", "Honghui", ""]]}, {"id": "2001.01391", "submitter": "Said Varlioglu", "authors": "Murat Ozer, Nelly Elsayed, Said Varlioglu, Chengcheng Li", "title": "A Rule-Based Model for Victim Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a novel automated model, called Vulnerability\nIndex for Population at Risk (VIPAR) scores, to identify rare populations for\ntheir future shooting victimizations. Likewise, the focused deterrence approach\nidentifies vulnerable individuals and offers certain types of treatments (e.g.,\noutreach services) to prevent violence in communities. The proposed rule-based\nengine model is the first AI-based model for victim prediction. This paper aims\nto compare the list of focused deterrence strategy with the VIPAR score list\nregarding their predictive power for the future shooting victimizations.\nDrawing on the criminological studies, the model uses age, past criminal\nhistory, and peer influence as the main predictors of future violence. Social\nnetwork analysis is employed to measure the influence of peers on the outcome\nvariable. The model also uses logistic regression analysis to verify the\nvariable selections. Our empirical results show that VIPAR scores predict 25.8%\nof future shooting victims and 32.2% of future shooting suspects, whereas\nfocused deterrence list predicts 13% of future shooting victims and 9.4% of\nfuture shooting suspects. The model outperforms the intelligence list of\nfocused deterrence policies in predicting the future fatal and non-fatal\nshootings. Furthermore, we discuss the concerns about the presumption of\ninnocence right.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 04:29:59 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 20:10:21 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Ozer", "Murat", ""], ["Elsayed", "Nelly", ""], ["Varlioglu", "Said", ""], ["Li", "Chengcheng", ""]]}, {"id": "2001.01511", "submitter": "Evangelos Pournaras", "authors": "Evangelos Pournaras", "title": "Decentralization in Digital Societies -- A Design Paradox", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital societies come with a design paradox: On the one hand, technologies,\nsuch as Internet of Things, pervasive and ubiquitous systems, allow a\ndistributed local intelligence in interconnected devices of our everyday life\nsuch as smart phones, smart thermostats, self-driving cars, etc. On the other\nhand, Big Data collection and storage is managed in a highly centralized\nfashion, resulting in privacy-intrusion, surveillance actions, discriminatory\nand segregation social phenomena. What is the difference between a distributed\nand a decentralized system design? How \"decentralized\" is the processing of our\ndata nowadays? Does centralized design undermine autonomy? Can the level of\ndecentralization in the implemented technologies influence ethical and social\ndimensions, such as social justice? Can decentralization convey sustainability?\nAre there parallelisms between the decentralization of digital technology and\nthe decentralization of urban development?\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 12:10:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Pournaras", "Evangelos", ""]]}, {"id": "2001.01697", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Rupak Sarkar, Hirak Sarkar, Sayantan Mahinder, Ashiqur R. KhudaBukhsh", "title": "Social Media Attributions in the Context of Water Crisis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution of natural disasters/collective misfortune is a widely-studied\npolitical science problem. However, such studies are typically survey-centric\nor rely on a handful of experts to weigh in on the matter. In this paper, we\nexplore how can we use social media data and an AI-driven approach to\ncomplement traditional surveys and automatically extract attribution factors.\nWe focus on the most-recent Chennai water crisis which started off as a\nregional issue but rapidly escalated into a discussion topic with global\nimportance following alarming water-crisis statistics. Specifically, we present\na novel prediction task of attribution tie detection which identifies the\nfactors held responsible for the crisis (e.g., poor city planning, exploding\npopulation etc.). On a challenging data set constructed from YouTube comments\n(72,098 comments posted by 43,859 users on 623 relevant videos to the crisis),\nwe present a neural classifier to extract attribution ties that achieved a\nreasonable performance (Accuracy: 81.34\\% on attribution detection and 71.19\\%\non attribution resolution).\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 18:20:09 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Sarkar", "Rupak", ""], ["Sarkar", "Hirak", ""], ["Mahinder", "Sayantan", ""], ["KhudaBukhsh", "Ashiqur R.", ""]]}, {"id": "2001.01818", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Claire Wang, Fei Fang", "title": "Artificial Intelligence for Social Good: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence for social good (AI4SG) is a research theme that aims\nto use and advance artificial intelligence to address societal issues and\nimprove the well-being of the world. AI4SG has received lots of attention from\nthe research community in the past decade with several successful applications.\nBuilding on the most comprehensive collection of the AI4SG literature to date\nwith over 1000 contributed papers, we provide a detailed account and analysis\nof the work under the theme in the following ways. (1) We quantitatively\nanalyze the distribution and trend of the AI4SG literature in terms of\napplication domains and AI techniques used. (2) We propose three conceptual\nmethods to systematically group the existing literature and analyze the eight\nAI4SG application domains in a unified framework. (3) We distill five research\ntopics that represent the common challenges in AI4SG across various application\ndomains. (4) We discuss five issues that, we hope, can shed light on the future\ndevelopment of the AI4SG research.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:16:28 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Wang", "Claire", ""], ["Fang", "Fei", ""]]}, {"id": "2001.01819", "submitter": "Austin Wright", "authors": "Austin P. Wright, Omar Shaikh, Haekyu Park, Will Epperson, Muhammed\n  Ahmed, Stephane Pinel, Diyi Yang, Duen Horng Chau", "title": "RECAST: Interactive Auditing of Automatic Toxicity Detection Models", "comments": "8 Pages, 3 figures, The eighth International Workshop of Chinese CHI\n  Proceedings", "journal-ref": null, "doi": "10.1145/3403676.3403691", "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As toxic language becomes nearly pervasive online, there has been increasing\ninterest in leveraging the advancements in natural language processing (NLP),\nfrom very large transformer models to automatically detecting and removing\ntoxic comments. Despite the fairness concerns, lack of adversarial robustness,\nand limited prediction explainability for deep learning systems, there is\ncurrently little work for auditing these systems and understanding how they\nwork for both developers and users. We present our ongoing work, RECAST, an\ninteractive tool for examining toxicity detection models by visualizing\nexplanations for predictions and providing alternative wordings for detected\ntoxic speech.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:17:52 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 15:36:18 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Wright", "Austin P.", ""], ["Shaikh", "Omar", ""], ["Park", "Haekyu", ""], ["Epperson", "Will", ""], ["Ahmed", "Muhammed", ""], ["Pinel", "Stephane", ""], ["Yang", "Diyi", ""], ["Chau", "Duen Horng", ""]]}, {"id": "2001.01964", "submitter": "Salvatore Corrente", "authors": "Francesca Abastante, Salvatore Corrente, Salvatore Greco, Isabella\n  Lami, Beatrice Mecca", "title": "Multiple criteria decision analysis with the SRF-II method to compare\n  hypotheses of adaptive reuse for an iconic historical building", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper shows how Multiple Criteria Decision Aiding (MCDA) tools can\nsupport the analyses of six hypotheses of adaptive reuse of an iconic\nhistorical building in Turin, Italy (called Stock Exchange) to identify the\npreferred alternative. In the last two years, the debate around the\nrequalification of the building has been huge for several reasons: it is\nperceived as a \"monument\" by citizens; it shows architectural and typological\nvalues nationally recognized; it involves public and private interests. In this\ncontext, interacting with experts involved in the ongoing discussion, we\nconsider a recently proposed conjunction of four MCDA methods, namely: Multiple\nCriteria Hierarchy Process (MCHP), permitting to consider structural\nrelationships between criteria; ELECTRE III, considering three types of\ninteraction effects between criteria (strengthening, weakening and antagonistic\neffects); the imprecise SRF method, supplying an easily understandable approach\nto collect information from the DM; and Stochastic Multicriteria Acceptability\nAnalysis (SMAA), providing robust recommendation, in terms of rankings and\nrelations of preference, indifference and incomparability between project\nalternatives, at each level of the hierarchy. We propose a modification of the\nSRF methodology, called SFR-II, to increase the reliability of the decision aid\nprocedure, which could constitute a significant advance for the same SRF\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 10:51:27 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Abastante", "Francesca", ""], ["Corrente", "Salvatore", ""], ["Greco", "Salvatore", ""], ["Lami", "Isabella", ""], ["Mecca", "Beatrice", ""]]}, {"id": "2001.02431", "submitter": "Marco Mamprin Mr.", "authors": "Marco Mamprin, Jo M. Zelis, Pim A.L. Tonino, Svitlana Zinger, Peter\n  H.N. de With", "title": "Gradient Boosting on Decision Trees for Mortality Prediction in\n  Transcatheter Aortic Valve Implantation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current prognostic risk scores in cardiac surgery are based on statistics and\ndo not yet benefit from machine learning. Statistical predictors are not robust\nenough to correctly identify patients who would benefit from Transcatheter\nAortic Valve Implantation (TAVI). This research aims to create a machine\nlearning model to predict one-year mortality of a patient after TAVI. We adopt\na modern gradient boosting on decision trees algorithm, specifically designed\nfor categorical features. In combination with a recent technique for model\ninterpretations, we developed a feature analysis and selection stage, enabling\nto identify the most important features for the prediction. We base our\nprediction model on the most relevant features, after interpreting and\ndiscussing the feature analysis results with clinical experts. We validated our\nmodel on 270 TAVI cases, reaching an AUC of 0.83. Our approach outperforms\nseveral widespread prognostic risk scores, such as logistic EuroSCORE II, the\nSTS risk score and the TAVI2-score, which are broadly adopted by cardiologists\nworldwide.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 10:04:42 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Mamprin", "Marco", ""], ["Zelis", "Jo M.", ""], ["Tonino", "Pim A. L.", ""], ["Zinger", "Svitlana", ""], ["de With", "Peter H. N.", ""]]}, {"id": "2001.02479", "submitter": "Michael Veale", "authors": "Midas Nouwens, Ilaria Liccardi, Michael Veale, David Karger, Lalana\n  Kagal", "title": "Dark Patterns after the GDPR: Scraping Consent Pop-ups and Demonstrating\n  their Influence", "comments": "13 pages, 3 figures. To appear in the Proceedings of CHI '20 CHI\n  Conference on Human Factors in Computing Systems, April 25--30, 2020,\n  Honolulu, HI, USA", "journal-ref": null, "doi": "10.1145/3313831.3376321", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New consent management platforms (CMPs) have been introduced to the web to\nconform with the EU's General Data Protection Regulation, particularly its\nrequirements for consent when companies collect and process users' personal\ndata. This work analyses how the most prevalent CMP designs affect people's\nconsent choices. We scraped the designs of the five most popular CMPs on the\ntop 10,000 websites in the UK (n=680). We found that dark patterns and implied\nconsent are ubiquitous; only 11.8% meet the minimal requirements that we set\nbased on European law. Second, we conducted a field experiment with 40\nparticipants to investigate how the eight most common designs affect consent\nchoices. We found that notification style (banner or barrier) has no effect;\nremoving the opt-out button from the first page increases consent by 22--23\npercentage points; and providing more granular controls on the first page\ndecreases consent by 8--20 percentage points. This study provides an empirical\nbasis for the necessary regulatory action to enforce the GDPR, in particular\nthe possibility of focusing on the centralised, third-party CMP services as an\neffective way to increase compliance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 12:36:29 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Nouwens", "Midas", ""], ["Liccardi", "Ilaria", ""], ["Veale", "Michael", ""], ["Karger", "David", ""], ["Kagal", "Lalana", ""]]}, {"id": "2001.02650", "submitter": "Benjamin Nguyen Ph.D.", "authors": "Benjamin Nguyen, Claude Castelluccia", "title": "Techniques d'anonymisation tabulaire : concepts et mise en oeuvre", "comments": "20 pages, in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document, we present a state of the art of anonymization techniques\nfor classical tabular datasets. This article is geared towards a general public\nhaving some knowledge of mathematics and computer science, but with no need for\nspecific knowledge in anonymization. The objective of this document it to\nexplain anonymization concepts in order to be able to sanitize a dataset and\ncompute reindentification risk. The document contains a large number of\nexamples to help understand the calculations.\n  -----\n  Dans ce document, nous pr\\'esentons l'\\'etat de l'art des techniques\nd'anonymisation pour des bases de donn\\'ees classiques (i.e. des tables), \\`a\ndestination d'un public technique ayant une formation universitaire de base en\nmath\\'ematiques et informatique, mais non sp\\'ecialiste. L'objectif de ce\ndocument est d'expliquer les concepts permettant de r\\'ealiser une\nanonymisation de donn\\'ees tabulaires, et de calculer les risques de\nr\\'eidentification. Le document est largement compos\\'e d'exemples permettant\nau lecteur de comprendre comment mettre en oeuvre les calculs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 17:50:09 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Nguyen", "Benjamin", ""], ["Castelluccia", "Claude", ""]]}, {"id": "2001.02802", "submitter": "Md. Aminur Rab Ratul", "authors": "Md. Aminur Rab Ratul", "title": "A Comparative Study on Crime in Denver City Based on Machine Learning\n  and Data Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To ensure the security of the general mass, crime prevention is one of the\nmost higher priorities for any government. An accurate crime prediction model\ncan help the government, law enforcement to prevent violence, detect the\ncriminals in advance, allocate the government resources, and recognize problems\ncausing crimes. To construct any future-oriented tools, examine and understand\nthe crime patterns in the earliest possible time is essential. In this paper, I\nanalyzed a real-world crime and accident dataset of Denver county, USA, from\nJanuary 2014 to May 2019, which containing 478,578 incidents. This project aims\nto predict and highlights the trends of occurrence that will, in return,\nsupport the law enforcement agencies and government to discover the preventive\nmeasures from the prediction rates. At first, I apply several statistical\nanalysis supported by several data visualization approaches. Then, I implement\nvarious classification algorithms such as Random Forest, Decision Tree,\nAdaBoost Classifier, Extra Tree Classifier, Linear Discriminant Analysis,\nK-Neighbors Classifiers, and 4 Ensemble Models to classify 15 different classes\nof crimes. The outcomes are captured using two popular test methods: train-test\nsplit, and k-fold cross-validation. Moreover, to evaluate the performance\nflawlessly, I also utilize precision, recall, F1-score, Mean Squared Error\n(MSE), ROC curve, and paired-T-test. Except for the AdaBoost classifier, most\nof the algorithms exhibit satisfactory accuracy. Random Forest, Decision Tree,\nEnsemble Model 1, 3, and 4 even produce me more than 90% accuracy. Among all\nthe approaches, Ensemble Model 4 presented superior results for every\nevaluation basis. This study could be useful to raise the awareness of peoples\nregarding the occurrence locations and to assist security agencies to predict\nfuture outbreaks of violence in a specific area within a particular time.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 01:36:11 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Ratul", "Md. Aminur Rab", ""]]}, {"id": "2001.03071", "submitter": "Chris Dulhanty", "authors": "Chris Dulhanty, Alexander Wong", "title": "Investigating the Impact of Inclusion in Face Recognition Training Data\n  on Individual Face Identification", "comments": "2020 AAAI/ACM Conference on AI, Ethics, and Society (AIES 20) | V2\n  updated latex character rendering issues", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern face recognition systems leverage datasets containing images of\nhundreds of thousands of specific individuals' faces to train deep\nconvolutional neural networks to learn an embedding space that maps an\narbitrary individual's face to a vector representation of their identity. The\nperformance of a face recognition system in face verification (1:1) and face\nidentification (1:N) tasks is directly related to the ability of an embedding\nspace to discriminate between identities. Recently, there has been significant\npublic scrutiny into the source and privacy implications of large-scale face\nrecognition training datasets such as MS-Celeb-1M and MegaFace, as many people\nare uncomfortable with their face being used to train dual-use technologies\nthat can enable mass surveillance. However, the impact of an individual's\ninclusion in training data on a derived system's ability to recognize them has\nnot previously been studied. In this work, we audit ArcFace, a\nstate-of-the-art, open source face recognition system, in a large-scale face\nidentification experiment with more than one million distractor images. We find\na Rank-1 face identification accuracy of 79.71% for individuals present in the\nmodel's training data and an accuracy of 75.73% for those not present. This\nmodest difference in accuracy demonstrates that face recognition systems using\ndeep learning work better for individuals they are trained on, which has\nserious privacy implications when one considers all major open source face\nrecognition training datasets do not obtain informed consent from individuals\nduring their collection.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 15:50:28 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 21:17:59 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Dulhanty", "Chris", ""], ["Wong", "Alexander", ""]]}, {"id": "2001.03203", "submitter": "Jason Radford", "authors": "Jason Radford and Kenneth Joseph", "title": "Theory In, Theory Out: The uses of social theory in machine learning for\n  social science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research at the intersection of machine learning and the social sciences has\nprovided critical new insights into social behavior. At the same time, a\nvariety of critiques have been raised ranging from technical issues with the\ndata used and features constructed, problematic assumptions built into models,\ntheir limited interpretability, and their contribution to bias and inequality.\nWe argue such issues arise primarily because of the lack of social theory at\nvarious stages of the model building and analysis. In the first half of this\npaper, we walk through how social theory can be used to answer the basic\nmethodological and interpretive questions that arise at each stage of the\nmachine learning pipeline. In the second half, we show how theory can be used\nto assess and compare the quality of different social learning models,\nincluding interpreting, generalizing, and assessing the fairness of models. We\nbelieve this paper can act as a guide for computer and social scientists alike\nto navigate the substantive questions involved in applying the tools of machine\nlearning to social data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 20:04:25 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 17:29:04 GMT"}, {"version": "v3", "created": "Wed, 15 Jan 2020 16:11:10 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Radford", "Jason", ""], ["Joseph", "Kenneth", ""]]}, {"id": "2001.03246", "submitter": "Jeffrey Ding", "authors": "Jeffrey Ding and Allan Dafoe", "title": "The Logic of Strategic Assets: From Oil to Artificial Intelligence", "comments": "Added references and corrected typos", "journal-ref": null, "doi": "10.1080/09636412.2021.1915583", "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What resources and technologies are strategic? This question is often the\nfocus of policy and theoretical debates, where the label \"strategic\" designates\nthose assets that warrant the attention of the highest levels of the state. But\nthese conversations are plagued by analytical confusion, flawed heuristics, and\nthe rhetorical use of \"strategic\" to advance particular agendas. We aim to\nimprove these conversations through conceptual clarification, introducing a\ntheory based on important rivalrous externalities for which socially optimal\nbehavior will not be produced alone by markets or individual national security\nentities. We distill and theorize the most important three forms of these\nexternalities, which involve cumulative-, infrastructure-, and\ndependency-strategic logics. We then employ these logics to clarify three\nimportant cases: the Avon 2 engine in the 1950s, the U.S.-Japan technology\nrivalry in the late 1980s, and contemporary conversations about artificial\nintelligence.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 22:16:05 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:16:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ding", "Jeffrey", ""], ["Dafoe", "Allan", ""]]}, {"id": "2001.03367", "submitter": "Gian Maria Campedelli", "authors": "Gian Maria Campedelli, Iain Cruickshank, and Kathleen M. Carley", "title": "A Complex Networks Approach to Find Latent Clusters of Terrorist Groups", "comments": "24 pages, 8 figures", "journal-ref": "Appl Netw Sci 4, 59 (2019)", "doi": "10.1007/s41109-019-0184-6", "report-no": null, "categories": "cs.CY cs.SI stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given the extreme heterogeneity of actors and groups participating in\nterrorist actions, investigating and assessing their characteristics can be\nimportant to extract relevant information and enhance the knowledge on their\nbehaviors. The present work will seek to achieve this goal via a complex\nnetworks approach. This approach will allow finding latent clusters of similar\nterror groups using information on their operational characteristics.\nSpecifically, using open access data of terrorist attacks occurred worldwide\nfrom 1997 to 2016, we build a multi-partite network that includes terrorist\ngroups and related information on tactics, weapons, targets, active regions. We\npropose a novel algorithm for cluster formation that expands our earlier work\nthat solely used Gower's coefficient of similarity via the application of Von\nNeumann entropy for mode-weighting. This novel approach is compared with our\nprevious Gower-based method and a heuristic clustering technique that only\nfocuses on groups' ideologies. The comparative analysis demonstrates that the\nentropy-based approach tends to reliably reflect the structure of the data that\nnaturally emerges from the baseline Gower-based method. Additionally, it\nprovides interesting results in terms of behavioral and ideological\ncharacteristics of terrorist groups. We furthermore show that the\nideology-based procedure tends to distort or hide existing patterns. Among the\nmain statistical results, our work reveals that groups belonging to opposite\nideologies can share very common behaviors and that Islamist/jihadist groups\nhold peculiar behavioral characteristics with respect to the others.\nLimitations and potential work directions are also discussed, introducing the\nidea of a dynamic entropy-based framework.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 10:08:30 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Campedelli", "Gian Maria", ""], ["Cruickshank", "Iain", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "2001.03494", "submitter": "Gian Maria Campedelli", "authors": "Gian Maria Campedelli, Francesco Calderoni, Mario Paolucci, Tommaso\n  Comunale, Daniele Vilone, Federico Cecconi, and Giulia Andrighetto", "title": "A Policy-oriented Agent-based Model of Recruitment into Organized Crime", "comments": "15 pages, 2 figures. Paper accepted and in press for the Proceedings\n  of the 2019 Social Simulation Conference (Mainz, Germany)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY cs.SI nlin.CD", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Criminal organizations exploit their presence on territories and local\ncommunities to recruit new workforce in order to carry out their criminal\nactivities and business. The ability to attract individuals is crucial for\nmaintaining power and control over the territories in which these groups are\nsettled. This study proposes the formalization, development and analysis of an\nagent-based model (ABM) that simulates a neighborhood of Palermo (Sicily) with\nthe aim to understand the pathways that lead individuals to recruitment into\norganized crime groups (OCGs). Using empirical data on social, economic and\ncriminal conditions of the area under analysis, we use a multi-layer network\napproach to simulate this scenario. As the final goal, we test different\npolicies to counter recruitment into OCGs. These scenarios are based on two\ndifferent dimensions of prevention and intervention: (i) primary and secondary\nsocialization and (ii) law enforcement targeting strategies.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:06:52 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Campedelli", "Gian Maria", ""], ["Calderoni", "Francesco", ""], ["Paolucci", "Mario", ""], ["Comunale", "Tommaso", ""], ["Vilone", "Daniele", ""], ["Cecconi", "Federico", ""], ["Andrighetto", "Giulia", ""]]}, {"id": "2001.03511", "submitter": "Johannes Himmelreich", "authors": "Johannes Himmelreich", "title": "Ethics of Technology needs more Political Philosophy", "comments": null, "journal-ref": "Communications of the ACM 63(1) (2020) 33-35", "doi": "10.1145/3339905", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing debate on the ethics of self-driving cars typically focuses on\ntwo approaches to answering ethical questions: moral philosophy and social\nscience. I argue that these two approaches are both lacking. We should neither\ndeduce answers from individual moral theories nor should we expect social\nscience to give us complete answers. To supplement these approaches, we should\nturn to political philosophy. The issues we face are collective decisions that\nwe make together rather than individual decisions we make in light of what we\neach have reason to value. Political philosophy adds three basic concerns to\nour conceptual toolkit: reasonable pluralism, human agency, and legitimacy.\nThese three concerns have so far been largely overlooked in the debate on the\nethics of self-driving cars.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:27:02 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Himmelreich", "Johannes", ""]]}, {"id": "2001.03513", "submitter": "Luoying Yang", "authors": "Luoying Yang, Zhou Xu, Jiebo Luo", "title": "Measuring Female Representation and Impact in Films over Time", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Women have always been underrepresented in movies and not until recently has\nthe representation of women in movies improved. To investigate the improvement\nof female representation and its relationship with a movie's success, we\npropose a new measure, the female cast ratio, and compare it to the commonly\nused Bechdel test result. We employ generalized linear regression with $L_1$\npenalty and a Random Forest model to identify the predictors that influence\nfemale representation, and evaluate the relationship between female\nrepresentation and a movie's success in three aspects: revenue/budget ratio,\nrating, and popularity. Three important findings in our study have highlighted\nthe difficulties women in the film industry face both upstream and downstream.\nFirst, female filmmakers, especially female screenplay writers, are\ninstrumental for movies to have better female representation, but the\npercentage of female filmmakers has been very low. Second, movies that have the\npotential to tell insightful stories about women are often provided with lower\nbudgets, and this usually causes the films to in turn receive more criticism.\nFinally, the demand for better female representation from moviegoers has also\nnot been strong enough to compel the film industry to change, as movies that\nhave poor female representation can still be very popular and successful in the\nbox office.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 15:29:18 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 14:12:37 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 02:58:52 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Yang", "Luoying", ""], ["Xu", "Zhou", ""], ["Luo", "Jiebo", ""]]}, {"id": "2001.03573", "submitter": "Matthijs Maas", "authors": "Peter Cihon, Matthijs M. Maas, Luke Kemp", "title": "Should Artificial Intelligence Governance be Centralised? Design Lessons\n  from History", "comments": "A shorter version of the paper is to be published in the proceedings\n  of AAAI/ACM AIES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can effective international governance for artificial intelligence remain\nfragmented, or is there a need for a centralised international organisation for\nAI? We draw on the history of other international regimes to identify\nadvantages and disadvantages in centralising AI governance. Some\nconsiderations, such as efficiency and political power, speak in favour of\ncentralisation. Conversely, the risk of creating a slow and brittle institution\nspeaks against it, as does the difficulty in securing participation while\ncreating stringent rules. Other considerations depend on the specific design of\na centralised institution. A well-designed body may be able to deter forum\nshopping and ensure policy coordination. However, forum shopping can be\nbeneficial and a fragmented landscape of institutions can be self-organising.\nCentralisation entails trade-offs and the details matter. We conclude with two\ncore recommendations. First, the outcome will depend on the exact design of a\ncentral institution. A well-designed centralised regime covering a set of\ncoherent issues could be beneficial. But locking-in an inadequate structure may\npose a fate worse than fragmentation. Second, for now fragmentation will likely\npersist. This should be closely monitored to see if it is self-organising or\nsimply inadequate.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 17:34:31 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Cihon", "Peter", ""], ["Maas", "Matthijs M.", ""], ["Kemp", "Luke", ""]]}, {"id": "2001.03942", "submitter": "Christopher M. Poskitt", "authors": "Oka Kurniawan, Norman Tiong Seng Lee, Christopher M. Poskitt", "title": "Securing Bring-Your-Own-Device (BYOD) Programming Exams", "comments": "Accepted by SIGCSE 2020", "journal-ref": "In Proc. ACM Technical Symposium on Computer Science Education\n  (SIGCSE 2020), pages 880-886. ACM, 2020", "doi": "10.1145/3328778.3366907", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional pen and paper exams are inadequate for modern university\nprogramming courses as they are misaligned with pedagogies and learning\nobjectives that target practical coding ability. Unfortunately, many\ninstitutions lack the resources or space to be able to run assessments in\ndedicated computer labs. This has motivated the development of\nbring-your-own-device (BYOD) exam formats, allowing students to program in a\nsimilar environment to how they learnt, but presenting instructors with\nsignificant additional challenges in preventing plagiarism and cheating. In\nthis paper, we describe a BYOD exam solution based on lockdown browsers,\nsoftware which temporarily turns students' laptops into secure workstations\nwith limited system or internet access. We combine the use of this technology\nwith a learning management system and cloud-based programming tool to\nfacilitate conceptual and practical programming questions that can be tackled\nin an interactive but controlled environment. We reflect on our experience of\nimplementing this solution for a major undergraduate programming course,\nhighlighting our principal lesson that policies and support mechanisms are as\nimportant to consider as the technology itself.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 15:01:13 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Kurniawan", "Oka", ""], ["Lee", "Norman Tiong Seng", ""], ["Poskitt", "Christopher M.", ""]]}, {"id": "2001.04034", "submitter": "Yekai Xu", "authors": "Yekai Xu, Qingqian He, Shiguang Ni", "title": "Evaluating Online Public Sentiments towards China: A Case Study of\n  English and Chinese Twitter Discourse during the 2019 Chinese National Day", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As the Internet gradually penetrates into people's daily lives and empowers\neveryone to demonstrate and exchange opinions and sentiments online, individual\ncitizens are increasingly participating in the agenda-setting of public affairs\nand the design and implementation of official policies. The current study\ndescribes an approach to analyze online public sentiments using social media\ndata and provides an example of Twitter discourse during the 2019 Chinese\nNational Day. Over 300,000 tweets were collected between Sept 30 and Oct 3, and\na hybrid method of SVM and dictionary was applied to evaluate the sentiments of\nthe collected tweets. This method avoids complex structures while yielding an\naverage accuracy of over 96% in most classifiers used in the study. The results\nindicate alignment between the time of National Day celebration activities and\nthe expressed sentiments revealed in both English and Chinese tweets, although\nthe sentiments of the two languages tend to be in different directions. The\nsentiment of tweets also diverges from nation to nation, but is generally\nconsistent with the country's official relations with China to varying degrees.\nThe linguistic features of the tweets suggest different concerns for Twitter\nusers who have different sentiments towards China. At last, possible directions\nfor further studies are indicated.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 02:09:45 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 09:29:55 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Xu", "Yekai", ""], ["He", "Qingqian", ""], ["Ni", "Shiguang", ""]]}, {"id": "2001.04335", "submitter": "Jessica Whittlestone", "authors": "Carina Prunkl and Jess Whittlestone", "title": "Beyond Near- and Long-Term: Towards a Clearer Account of Research\n  Priorities in AI Ethics and Society", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One way of carving up the broad \"AI ethics and society\" research space that\nhas emerged in recent years is to distinguish between \"near-term\" and\n\"long-term\" research. While such ways of breaking down the research space can\nbe useful, we put forward several concerns about the near/long-term distinction\ngaining too much prominence in how research questions and priorities are\nframed. We highlight some ambiguities and inconsistencies in how the\ndistinction is used, and argue that while there are differing priorities within\nthis broad research community, these differences are not well-captured by the\nnear/long-term distinction. We unpack the near/long-term distinction into four\ndifferent dimensions, and propose some ways that researchers can communicate\nmore clearly about their work and priorities using these dimensions. We suggest\nthat moving towards a more nuanced conversation about research priorities can\nhelp establish new opportunities for collaboration, aid the development of more\nconsistent and coherent research agendas, and enable identification of\npreviously neglected research areas.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:22:42 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 12:18:20 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Prunkl", "Carina", ""], ["Whittlestone", "Jess", ""]]}, {"id": "2001.04509", "submitter": "Lionel Robert", "authors": "Na Du, Feng Zhou, Elizabeth Pulver, Dawn M. Tilbury, Lionel P. Robert,\n  Anuj K. Pradhan, X. Jessie Yang", "title": "Examining the Effects of Emotional Valence and Arousal on Takeover\n  Performance in Conditionally Automated Driving", "comments": "28 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In conditionally automated driving, drivers have difficulty in takeover\ntransitions as they become increasingly decoupled from the operational level of\ndriving. Factors influencing takeover performance, such as takeover lead time\nand the engagement of non-driving related tasks, have been studied in the past.\nHowever, despite the important role emotions play in human-machine interaction\nand in manual driving, little is known about how emotions influence drivers\ntakeover performance. This study, therefore, examined the effects of emotional\nvalence and arousal on drivers takeover timeliness and quality in conditionally\nautomated driving. We conducted a driving simulation experiment with 32\nparticipants. Movie clips were played for emotion induction. Participants with\ndifferent levels of emotional valence and arousal were required to take over\ncontrol from automated driving, and their takeover time and quality were\nanalyzed. Results indicate that positive valence led to better takeover quality\nin the form of a smaller maximum resulting acceleration and a smaller maximum\nresulting jerk. However, high arousal did not yield an advantage in takeover\ntime. This study contributes to the literature by demonstrating how emotional\nvalence and arousal affect takeover performance. The benefits of positive\nemotions carry over from manual driving to conditionally automated driving\nwhile the benefits of arousal do not.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:28:15 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Du", "Na", ""], ["Zhou", "Feng", ""], ["Pulver", "Elizabeth", ""], ["Tilbury", "Dawn M.", ""], ["Robert", "Lionel P.", ""], ["Pradhan", "Anuj K.", ""], ["Yang", "X. Jessie", ""]]}, {"id": "2001.04513", "submitter": "Wouter Van Heeswijk PhD", "authors": "W.J.A. van Heeswijk", "title": "Donald Duck Holiday Game: A numerical analysis of a Game of the Goose\n  role-playing variant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 1996 Donald Duck Holiday Game is a role-playing variant of the historical\nGame of the Goose, involving characters with unique attributes, event squares,\nand random event cards. The objective of the game is to reach the camping\nbefore any other player does. We develop a Monte Carlo simulation model that\nautomatically plays the game and enables analyzing its key characteristics. We\nassess the game on various metrics relevant to each playability. Numerical\nanalysis shows that, on average, the game takes between 69 and 123 rounds to\ncomplete, depending on the number of players. However, durations over one hour\n(translated to human play time) occur over 25% of the games, which might reduce\nthe quality of the gaming experience. Furthermore, we show that two characters\nare about 30% likely to win than the other three, primarily due to being\nexposed to fewer random events. We argue that the richer narrative of\nrole-playing games may extend the duration for which the game remains\nenjoyable, such that the metrics cannot directly be compared to those of the\ntraditional Game-of-the-Goose. Based on our analysis, we provide several\nsuggestions to improve the game balance with only slight modifications. In a\nbroader sense, we demonstrate that a basic Monte Carlo simulation suffices to\nanalyze Game-of-the-Goose role-playing variants, verify how they score on\ncriteria that contribute to an enjoyable game, and detect possible anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:39:48 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["van Heeswijk", "W. J. A.", ""]]}, {"id": "2001.04574", "submitter": "Joshua I. James", "authors": "Min Jin Park, Joshua I. James", "title": "Preliminary Study of a Google Home Mini", "comments": "12 pages, 6 figures, 3 tables", "journal-ref": "Journal of Digital Forensics 13-3: 163-174 (2019).\n  https://kdfs.jams.or.kr/jams/download/KCI_FI002513079.pdf", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many artificial intelligence (AI) speakers have recently come to market.\nBeginning with Amazon Echo, many companies producing their own speaker\ntechnologies. Due to the limitations of technology, most speakers have similar\nfunctions, but the way of handling the data of each speaker is different. In\nthe case of Amazon echo, the API of the cloud is open for any developers to\ndevelop their API. The Amazon Echo has been around for a while, and much\nresearch has been done on it. However, not much research has been done on\nGoogle Home Mini analysis for digital investigations. In this paper, we will\nconduct some initial research on the data storing and security methods of\nGoogle Home Mini.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 00:12:04 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Park", "Min Jin", ""], ["James", "Joshua I.", ""]]}, {"id": "2001.04777", "submitter": "Manuel Sebastian Mariani", "authors": "Manuel S. Mariani, Yanina Gimenez, Jorge Brea, Martin Minnoni, Ren\\'e\n  Algesheimer, Claudio J. Tessone", "title": "The wisdom of the few: Predicting collective success from individual\n  behavior", "comments": "Main text (pp. 1-13), Online appendix (pp. 14-34)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we predict top-performing products, services, or businesses by only\nmonitoring the behavior of a small set of individuals? Although most previous\nstudies focused on the predictive power of \"hub\" individuals with many social\ncontacts, which sources of customer behavioral data are needed to address this\nquestion remains unclear, mostly due to the scarcity of available datasets that\nsimultaneously capture individuals' purchasing patterns and social\ninteractions. Here, we address this question in a unique, large-scale dataset\nthat combines individuals' credit-card purchasing history with their social and\nmobility traits across an entire nation. Surprisingly, we find that the\npurchasing history alone enables the detection of small sets of ``discoverers\"\nwhose early purchases offer reliable success predictions for the\nbrick-and-mortar stores they visit. In contrast with the assumptions by most\nexisting studies on word-of-mouth processes, the hubs selected by social\nnetwork centrality are not consistently predictive of success. Our findings\nshow that companies and organizations with access to large-scale purchasing\ndata can detect the discoverers and leverage their behavior to anticipate\nmarket trends, without the need for social network data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:52:44 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 10:05:36 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 09:33:46 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Mariani", "Manuel S.", ""], ["Gimenez", "Yanina", ""], ["Brea", "Jorge", ""], ["Minnoni", "Martin", ""], ["Algesheimer", "Ren\u00e9", ""], ["Tessone", "Claudio J.", ""]]}, {"id": "2001.04825", "submitter": "Shahpar Yakhchi", "authors": "Shahpar Yakhchi (1), Amin Beheshti (1), Seyed Mohssen Ghafari (1),\n  Mehmet Orgun (1) ((1) Macquarie University- Sydney-Australia)", "title": "Enabling the Analysis of Personality Aspects in Recommender Systems", "comments": "This article contains 3 figures and 14 pages", "journal-ref": "Twenty-Third Pacific Asia Conference on Information Systems, China\n  2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Recommender Systems mainly focus on exploiting users' feedback,\ne.g., ratings, and reviews on common items to detect similar users. Thus, they\nmight fail when there are no common items of interest among users. We call this\nproblem the Data Sparsity With no Feedback on Common Items (DSW-n-FCI).\nPersonality-based recommender systems have shown a great success to identify\nsimilar users based on their personality types. However, there are only a few\npersonality-based recommender systems in the literature which either discover\npersonality explicitly through filling a questionnaire that is a tedious task,\nor neglect the impact of users' personal interests and level of knowledge, as a\nkey factor to increase recommendations' acceptance. Differently, we identifying\nusers' personality type implicitly with no burden on users and incorporate it\nalong with users' personal interests and their level of knowledge. Experimental\nresults on a real-world dataset demonstrate the effectiveness of our model,\nespecially in DSW-n-FCI situations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 23:02:07 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Yakhchi", "Shahpar", "", "Macquarie University- Sydney-Australia"], ["Beheshti", "Amin", "", "Macquarie University- Sydney-Australia"], ["Ghafari", "Seyed Mohssen", "", "Macquarie University- Sydney-Australia"], ["Orgun", "Mehmet", "", "Macquarie University- Sydney-Australia"]]}, {"id": "2001.04930", "submitter": "Jason Pittman", "authors": "Jason M. Pittman, Nikki Robinson", "title": "Shades of Perception- User Factors in Identifying Password Strength", "comments": "18 pages, 6 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study was to measure whether participant education,\nprofession, and technical skill level exhibited a relationship with\nidentification of password strength. Participants reviewed 50 passwords and\nlabeled each as weak or strong. A Chi-square test of independence was used to\nmeasure relationships between education, profession, technical skill level\nrelative to the frequency of weak and strong password identification. The\nresults demonstrate significant relationships across all variable combinations\nexcept for technical skill and strong passwords which demonstrated no\nrelationship. This research has three limitations. Data collection was\ndependent upon participant self-reporting and has limited externalized power.\nFurther, the instrument was constructed under the assumption that all\nparticipants could read English and understood the concept of password\nstrength. Finally, we did not control for external tool use (i.e., password\nstrength meter). The results build upon existing literature insofar as the\noutcomes add to the collective understanding of user perception of passwords in\nspecific and authentication in general. Whereas prior research has explored\nsimilar areas, such work has done so by having participants create passwords.\nThis work measures perception of pre-generated passwords. The results\ndemonstrate a need for further investigation into why users continue to rely on\nweak passwords. The originality of this work rests in soliciting a broad\nspectrum of participants and measuring potential correlations between\nparticipant education, profession, and technical skill level.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:45:40 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Pittman", "Jason M.", ""], ["Robinson", "Nikki", ""]]}, {"id": "2001.05046", "submitter": "Abeba Birhane", "authors": "Abeba Birhane and Jelle van Dijk", "title": "Robot Rights? Let's Talk about Human Welfare Instead", "comments": "Accepted to the AIES 2020 conference in New York, February 2020. The\n  final version of this paper will appear in Proceedings of the 2020 AAAI/ACM\n  Conference on AI, Ethics, and Society", "journal-ref": null, "doi": "10.1145/3375627.3375855", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 'robot rights' debate, and its related question of 'robot\nresponsibility', invokes some of the most polarized positions in AI ethics.\nWhile some advocate for granting robots rights on a par with human beings,\nothers, in a stark opposition argue that robots are not deserving of rights but\nare objects that should be our slaves. Grounded in post-Cartesian philosophical\nfoundations, we argue not just to deny robots 'rights', but to deny that\nrobots, as artifacts emerging out of and mediating human being, are the kinds\nof things that could be granted rights in the first place. Once we see robots\nas mediators of human being, we can understand how the `robots rights' debate\nis focused on first world problems, at the expense of urgent ethical concerns,\nsuch as machine bias, machine elicited human labour exploitation, and erosion\nof privacy all impacting society's least privileged individuals. We conclude\nthat, if human being is our starting point and human welfare is the primary\nconcern, the negative impacts emerging from machinic systems, as well as the\nlack of taking responsibility by people designing, selling and deploying such\nmachines, remains the most pressing ethical discussion in AI.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:54:29 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Birhane", "Abeba", ""], ["van Dijk", "Jelle", ""]]}, {"id": "2001.05068", "submitter": "Aaron Tucker", "authors": "Aaron D. Tucker, Markus Anderljung, and Allan Dafoe", "title": "Social and Governance Implications of Improved Data Efficiency", "comments": "7 pages, 2 figures, accepted to Artificial Intelligence Ethics and\n  Society 2020", "journal-ref": null, "doi": "10.1145/3375627.3375863", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many researchers work on improving the data efficiency of machine learning.\nWhat would happen if they succeed? This paper explores the social-economic\nimpact of increased data efficiency. Specifically, we examine the intuition\nthat data efficiency will erode the barriers to entry protecting incumbent\ndata-rich AI firms, exposing them to more competition from data-poor firms. We\nfind that this intuition is only partially correct: data efficiency makes it\neasier to create ML applications, but large AI firms may have more to gain from\nhigher performing AI systems. Further, we find that the effect on privacy, data\nmarkets, robustness, and misuse are complex. For example, while it seems\nintuitive that misuse risk would increase along with data efficiency -- as more\nactors gain access to any level of capability -- the net effect crucially\ndepends on how much defensive measures are improved. More investigation into\ndata efficiency, as well as research into the \"AI production function\", will be\nkey to understanding the development of the AI industry and its societal\nimpacts.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:26:12 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Tucker", "Aaron D.", ""], ["Anderljung", "Markus", ""], ["Dafoe", "Allan", ""]]}, {"id": "2001.05324", "submitter": "Camille Roth", "authors": "Camille Roth and Antoine Mazi\\`eres and Telmo Menezes", "title": "Tubes & Bubbles -- Topological confinement of YouTube recommendations", "comments": "10 pages, 7 figures, 1 table", "journal-ref": "PLOS ONE 15(4): e0231703 (2020)", "doi": "10.1371/journal.pone.0231703", "report-no": null, "categories": "cs.SI cs.CY nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of recommendation algorithms in online user confinement is at the\nheart of a fast-growing literature. Recent empirical studies generally suggest\nthat filter bubbles may principally be observed in the case of explicit\nrecommendation (based on user-declared preferences) rather than implicit\nrecommendation (based on user activity). We focus on YouTube which has become a\nmajor online content provider but where confinement has until now been\nlittle-studied in a systematic manner. Starting from a diverse number of seed\nvideos, we first describe the properties of the sets of suggested videos in\norder to design a sound exploration protocol able to capture latent\nrecommendation graphs recursively induced by these suggestions. These graphs\nform the background of potential user navigations along non-personalized\nrecommendations. From there, be it in topological, topical or temporal terms,\nwe show that the landscape of what we call mean-field YouTube recommendations\nis often prone to confinement dynamics. Moreover, the most confined\nrecommendation graphs i.e., potential bubbles, seem to be organized around sets\nof videos that garner the highest audience and thus plausibly viewing time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:51:20 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Roth", "Camille", ""], ["Mazi\u00e8res", "Antoine", ""], ["Menezes", "Telmo", ""]]}, {"id": "2001.05375", "submitter": "Florian Buettner", "authors": "Florian Buettner, John Piorkowski, Ian McCulloh, Ulli Waltinger", "title": "AAAI FSS-19: Human-Centered AI: Trustworthiness of AI Models and Data\n  Proceedings", "comments": "Proceedings for AAAI 2019 Fall Symposium Series - Human-centered AI:\n  Trustworthiness of AI Models & Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To facilitate the widespread acceptance of AI systems guiding decision-making\nin real-world applications, it is key that solutions comprise trustworthy,\nintegrated human-AI systems. Not only in safety-critical applications such as\nautonomous driving or medicine, but also in dynamic open world systems in\nindustry and government it is crucial for predictive models to be\nuncertainty-aware and yield trustworthy predictions. Another key requirement\nfor deployment of AI at enterprise scale is to realize the importance of\nintegrating human-centered design into AI systems such that humans are able to\nuse systems effectively, understand results and output, and explain findings to\noversight committees.\n  While the focus of this symposium was on AI systems to improve data quality\nand technical robustness and safety, we welcomed submissions from broadly\ndefined areas also discussing approaches addressing requirements such as\nexplainable models, human trust and ethical aspects of AI.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:30:29 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Buettner", "Florian", ""], ["Piorkowski", "John", ""], ["McCulloh", "Ian", ""], ["Waltinger", "Ulli", ""]]}, {"id": "2001.05514", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris, Nicolo Botteghi", "title": "The Penetration of Internet of Things in Robotics: Towards a Web of\n  Robotic Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Internet of Things (IoT) penetrates different domains and application\nareas, it has recently entered also the world of robotics. Robotics constitutes\na modern and fast-evolving technology, increasingly being used in industrial,\ncommercial and domestic settings. IoT, together with the Web of Things (WoT)\ncould provide many benefits to robotic systems. Some of the benefits of IoT in\nrobotics have been discussed in related work. This paper moves one step\nfurther, studying the actual current use of IoT in robotics, through various\nreal-world examples encountered through a bibliographic research. The paper\nalso examines the potential ofWoT, together with robotic systems, investigating\nwhich concepts, characteristics, architectures, hardware, software and\ncommunication methods of IoT are used in existing robotic systems, which\nsensors and actions are incorporated in IoT-based robots, as well as in which\napplication areas. Finally, the current application of WoT in robotics is\nexamined and discussed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:05:04 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Botteghi", "Nicolo", ""]]}, {"id": "2001.05690", "submitter": "Mark Burgess", "authors": "Jan A. Bergstra and Mark Burgess", "title": "Candidate Software Process Flaws for the Boeing 737 Max MCAS Algorithm\n  and Risks for a Proposed Upgrade", "comments": "Sequel to arXiv:2001.01543 [cs.OH]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By reasoning about the claims and speculations promised as part of the public\ndiscourse, we analyze the hypothesis that flaws in software engineering played\na critical role in the Boeing 737 MCAS incidents. We use promise-based\nreasoning to discuss how, from an outsider's perspective, one may assemble\nclues about what went wrong. Rather than looking for a Rational Alternative\nDesign (RAD), as suggested by Wendel, we look for candidate flaws in the\nsoftware process. We describe four such potential flaws. Recently, Boeing has\ncirculated information on its envisaged MCAS algorithm upgrade. We cast this as\na promise to resolve the flaws, i.e. to provide a RAD for the B737 Max. We\noffer an assessment of B-Max-New based on the public discourse.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 08:28:13 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Bergstra", "Jan A.", ""], ["Burgess", "Mark", ""]]}, {"id": "2001.05871", "submitter": "Vivian Lai", "authors": "Vivian Lai, Han Liu, Chenhao Tan", "title": "\"Why is 'Chicago' deceptive?\" Towards Building Model-Driven Tutorials\n  for Humans", "comments": "26 pages, 48 figures, CHI 2020", "journal-ref": null, "doi": "10.1145/10.1145/3313831.3376873", "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support human decision making with machine learning models, we often need\nto elucidate patterns embedded in the models that are unsalient, unknown, or\ncounterintuitive to humans. While existing approaches focus on explaining\nmachine predictions with real-time assistance, we explore model-driven\ntutorials to help humans understand these patterns in a training phase. We\nconsider both tutorials with guidelines from scientific papers, analogous to\ncurrent practices of science communication, and automatically selected examples\nfrom training data with explanations. We use deceptive review detection as a\ntestbed and conduct large-scale, randomized human-subject experiments to\nexamine the effectiveness of such tutorials. We find that tutorials indeed\nimprove human performance, with and without real-time assistance. In\nparticular, although deep learning provides superior predictive performance\nthan simple models, tutorials and explanations from simple models are more\nuseful to humans. Our work suggests future directions for human-centered\ntutorials and explanations towards a synergy between humans and AI.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:00:00 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Lai", "Vivian", ""], ["Liu", "Han", ""], ["Tan", "Chenhao", ""]]}, {"id": "2001.05955", "submitter": "Matus Medo", "authors": "Mat\\'u\\v{s} Medo, Manuel S. Mariani, Linyuan L\\\"u", "title": "Simple regularities in the dynamics of online news impact", "comments": "11 pages, 6 figures + Supporting Information (18 pages, 16 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online news can quickly reach and affect millions of people, yet we do not\nknow yet whether there exist potential dynamical regularities that govern their\nimpact on the public. We use data from two major news outlets, BBC and New York\nTimes, where the number of user comments can be used as a proxy of news impact.\nWe find that the impact dynamics of online news articles does not exhibit\npopularity patterns found in many other social and information systems. In\nparticular, we find that a simple exponential distribution yields a better fit\nto the empirical news impact distributions than a power-law distribution. This\nobservation is explained by the lack or limited influence of the otherwise\nomnipresent rich-get-richer mechanism in the analyzed data. The temporal\ndynamics of the news impact exhibits a universal exponential decay which allows\nus to collapse individual news trajectories into an elementary single curve. We\nalso show how daily variations of user activity directly influence the dynamics\nof the article impact. Our findings challenge the universal applicability of\npopularity dynamics patterns found in other social contexts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 17:34:17 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 14:28:37 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Medo", "Mat\u00fa\u0161", ""], ["Mariani", "Manuel S.", ""], ["L\u00fc", "Linyuan", ""]]}, {"id": "2001.05961", "submitter": "Sagar Joglekar", "authors": "Sagar Joglekar, Daniele Quercia, Miriam Redi, Luca Maria Aiello,\n  Tobias Kauer, Nishanth Sastry", "title": "FaceLift: A transparent deep learning framework to beautify urban scenes", "comments": null, "journal-ref": null, "doi": "10.1098/rsos.190987", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the area of computer vision, deep learning techniques have recently been\nused to predict whether urban scenes are likely to be considered beautiful: it\nturns out that these techniques are able to make accurate predictions. Yet they\nfall short when it comes to generating actionable insights for urban design. To\nsupport urban interventions, one needs to go beyond predicting beauty, and\ntackle the challenge of recreating beauty. Unfortunately, deep learning\ntechniques have not been designed with that challenge in mind. Given their\n\"black-box nature\", these models cannot be directly used to explain why a\nparticular urban scene is deemed to be beautiful. To partly fix that, we\npropose a deep learning framework called Facelift, that is able to both\nbeautify existing urban scenes (Google Street views) and explain which urban\nelements make those transformed scenes beautiful. To quantitatively evaluate\nour framework, we cannot resort to any existing metric (as the research problem\nat hand has never been tackled before) and need to formulate new ones. These\nnew metrics should ideally capture the presence/absence of elements that make\nurban spaces great. Upon a review of the urban planning literature, we identify\nfive main metrics: walkability, green spaces, openness, landmarks and visual\ncomplexity. We find that, across all the five metrics, the beautified scenes\nmeet the expectations set by the literature on what great spaces tend to be\nmade of. This result is further confirmed by a 20-participant expert survey in\nwhich FaceLift have been found to be effective in promoting citizen\nparticipation. All this suggests that, in the future, as our framework's\ncomponents are further researched and become better and more sophisticated, it\nis not hard to imagine technologies that will be able to accurately and\nefficiently support architects and planners in the design of spaces we\nintuitively love.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 17:48:24 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Joglekar", "Sagar", ""], ["Quercia", "Daniele", ""], ["Redi", "Miriam", ""], ["Aiello", "Luca Maria", ""], ["Kauer", "Tobias", ""], ["Sastry", "Nishanth", ""]]}, {"id": "2001.06089", "submitter": "Daniel Steinberg", "authors": "Daniel Steinberg, Alistair Reid and Simon O'Callaghan", "title": "Fairness Measures for Regression via Probabilistic Classification", "comments": "Accepted to the 2nd Ethics of Data Science Conference 2020 (March,\n  Sydney, Australia)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness involves expressing notions such as equity, or\nreasonable treatment, as quantifiable measures that a machine learning\nalgorithm can optimise. Most work in the literature to date has focused on\nclassification problems where the prediction is categorical, such as accepting\nor rejecting a loan application. This is in part because classification\nfairness measures are easily computed by comparing the rates of outcomes,\nleading to behaviours such as ensuring that the same fraction of eligible men\nare selected as eligible women. But such measures are computationally difficult\nto generalise to the continuous regression setting for problems such as\npricing, or allocating payments. The difficulty arises from estimating\nconditional densities (such as the probability density that a system will\nover-charge by a certain amount). For the regression setting we introduce\ntractable approximations of the independence, separation and sufficiency\ncriteria by observing that they factorise as ratios of different conditional\nprobabilities of the protected attributes. We introduce and train machine\nlearning classifiers, distinct from the predictor, as a mechanism to estimate\nthese probabilities from the data. This naturally leads to model agnostic,\ntractable approximations of the criteria, which we explore experimentally.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:53:26 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 03:46:01 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Steinberg", "Daniel", ""], ["Reid", "Alistair", ""], ["O'Callaghan", "Simon", ""]]}, {"id": "2001.06509", "submitter": "Dakuo Wang", "authors": "Jaimie Drozdal, Justin Weisz, Dakuo Wang, Gaurav Dass, Bingsheng Yao,\n  Changruo Zhao, Michael Muller, Lin Ju, Hui Su", "title": "Trust in AutoML: Exploring Information Needs for Establishing Trust in\n  Automated Machine Learning Systems", "comments": "IUI 2020", "journal-ref": null, "doi": "10.1145/3377325.3377501", "report-no": null, "categories": "cs.LG cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore trust in a relatively new area of data science: Automated Machine\nLearning (AutoML). In AutoML, AI methods are used to generate and optimize\nmachine learning models by automatically engineering features, selecting\nmodels, and optimizing hyperparameters. In this paper, we seek to understand\nwhat kinds of information influence data scientists' trust in the models\nproduced by AutoML? We operationalize trust as a willingness to deploy a model\nproduced using automated methods. We report results from three studies --\nqualitative interviews, a controlled experiment, and a card-sorting task -- to\nunderstand the information needs of data scientists for establishing trust in\nAutoML systems. We find that including transparency features in an AutoML tool\nincreased user trust and understandability in the tool; and out of all proposed\nfeatures, model performance metrics and visualizations are the most important\ninformation to data scientists when establishing their trust with an AutoML\ntool.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 19:50:54 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Drozdal", "Jaimie", ""], ["Weisz", "Justin", ""], ["Wang", "Dakuo", ""], ["Dass", "Gaurav", ""], ["Yao", "Bingsheng", ""], ["Zhao", "Changruo", ""], ["Muller", "Michael", ""], ["Ju", "Lin", ""], ["Su", "Hui", ""]]}, {"id": "2001.06528", "submitter": "Haydn Belfield", "authors": "Haydn Belfield", "title": "Activism by the AI Community: Analysing Recent Achievements and Future\n  Prospects", "comments": "Forthcoming in Proceedings of the 2020 AAAI/ACM Conference on\n  Artificial Intelligence, Ethics and Society. 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The artificial intelligence community (AI) has recently engaged in activism\nin relation to their employers, other members of the community, and their\ngovernments in order to shape the societal and ethical implications of AI. It\nhas achieved some notable successes, but prospects for further political\norganising and activism are uncertain. We survey activism by the AI community\nover the last six years; apply two analytical frameworks drawing upon the\nliterature on epistemic communities, and worker organising and bargaining; and\nexplore what they imply for the future prospects of the AI community. Success\nthus far has hinged on a coherent shared culture, and high bargaining power due\nto the high demand for a limited supply of AI talent. Both are crucial to the\nfuture of AI activism and worthy of sustained attention.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 20:53:10 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Belfield", "Haydn", ""]]}, {"id": "2001.06547", "submitter": "Andres Abeliuk", "authors": "Andr\\'es Abeliuk, Zhishen Huang, Emilio Ferrara, Kristina Lerman", "title": "Predictability limit of partially observed systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications from finance to epidemiology and cyber-security require accurate\nforecasts of dynamic phenomena, which are often only partially observed. We\ndemonstrate that a system's predictability degrades as a function of temporal\nsampling, regardless of the adopted forecasting model. We quantify the loss of\npredictability due to sampling, and show that it cannot be recovered by using\nexternal signals. We validate the generality of our theoretical findings in\nreal-world partially observed systems representing infectious disease\noutbreaks, online discussions, and software development projects. On a variety\nof prediction tasks---forecasting new infections, the popularity of topics in\nonline discussions, or interest in cryptocurrency projects---predictability\nirrecoverably decays as a function of sampling, unveiling fundamental\npredictability limits in partially observed systems.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 22:06:53 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Abeliuk", "Andr\u00e9s", ""], ["Huang", "Zhishen", ""], ["Ferrara", "Emilio", ""], ["Lerman", "Kristina", ""]]}, {"id": "2001.06615", "submitter": "Mitchell Burger", "authors": "Mitchell Burger", "title": "The Risk to Population Health Equity Posed by Automated Decision\n  Systems: A Narrative Review", "comments": "22 pages (12 pages excluding references), 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence is already ubiquitous, and is increasingly being used\nto autonomously make ever more consequential decisions. However, there has been\nrelatively little research into the consequences for equity of the use of\nnarrow AI and automated decision systems in medicine and public health. A\nnarrative review using a hermeneutic approach was undertaken to explore current\nand future uses of AI in medicine and public health, issues that have emerged,\nand longer-term implications for population health. Accounts in the literature\nreveal a tremendous expectation on AI to transform medical and public health\npractices, especially regarding precision medicine and precision public health.\nAutomated decisions being made about disease detection, diagnosis, treatment,\nand health funding allocation have significant consequences for individual and\npopulation health and wellbeing. Meanwhile, it is evident that issues of bias,\nincontestability, and erosion of privacy have emerged in sensitive domains\nwhere narrow AI and automated decision systems are in common use. As the use of\nautomated decision systems expands, it is probable that these same issues will\nmanifest widely in medicine and public health applications. Bias,\nincontestability, and erosion of privacy are mechanisms by which existing\nsocial, economic and health disparities are perpetuated and amplified. The\nimplication is that there is a significant risk that use of automated decision\nsystems in health will exacerbate existing population health inequities. The\nindustrial scale and rapidity with which automated decision systems can be\napplied to whole populations heightens the risk to population health equity.\nThere is a need therefore to design and implement automated decision systems\nwith care, monitor their impact over time, and develop capacities to respond to\nissues as they emerge.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 06:52:47 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Burger", "Mitchell", ""]]}, {"id": "2001.06700", "submitter": "Carlos Sarraute PhD", "authors": "Maria \\'Oskarsd\\'ottir, Cristi\\'an Bravo, Wouter Verbeke, Carlos\n  Sarraute, Bart Baesens, Jan Vanthienen", "title": "A Comparative Study of Social Network Classifiers for Predicting Churn\n  in the Telecommunication Industry", "comments": "2016 IEEE/ACM International Conference on Advances in Social Networks\n  Analysis and Mining (ASONAM)", "journal-ref": null, "doi": "10.1109/ASONAM.2016.7752384", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Relational learning in networked data has been shown to be effective in a\nnumber of studies. Relational learners, composed of relational classifiers and\ncollective inference methods, enable the inference of nodes in a network given\nthe existence and strength of links to other nodes. These methods have been\nadapted to predict customer churn in telecommunication companies showing that\nincorporating them may give more accurate predictions. In this research, the\nperformance of a variety of relational learners is compared by applying them to\na number of CDR datasets originating from the telecommunication industry, with\nthe goal to rank them as a whole and investigate the effects of relational\nclassifiers and collective inference methods separately. Our results show that\ncollective inference methods do not improve the performance of relational\nclassifiers and the best performing relational classifier is the network-only\nlink-based classifier, which builds a logistic model using link-based measures\nfor the nodes in the network.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 17:05:53 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["\u00d3skarsd\u00f3ttir", "Maria", ""], ["Bravo", "Cristi\u00e1n", ""], ["Verbeke", "Wouter", ""], ["Sarraute", "Carlos", ""], ["Baesens", "Bart", ""], ["Vanthienen", "Jan", ""]]}, {"id": "2001.06701", "submitter": "Carlos Sarraute PhD", "authors": "Mar\\'ia \\'Oskarsd\\'ottir, Cristi\\'an Bravo, Wouter Verbeke, Carlos\n  Sarraute, Bart Baesens, Jan Vanthienen", "title": "Social Network Analytics for Churn Prediction in Telco: Model Building,\n  Evaluation and Network Architecture", "comments": null, "journal-ref": "Expert Systems with Applications, Volume 85, 1 November 2017,\n  Pages 204-220", "doi": "10.1016/j.eswa.2017.05.028", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social network analytics methods are being used in the telecommunication\nindustry to predict customer churn with great success. In particular it has\nbeen shown that relational learners adapted to this specific problem enhance\nthe performance of predictive models.\n  In the current study we benchmark different strategies for constructing a\nrelational learner by applying them to a total of eight distinct call-detail\nrecord datasets, originating from telecommunication organizations across the\nworld. We statistically evaluate the effect of relational classifiers and\ncollective inference methods on the predictive power of relational learners, as\nwell as the performance of models where relational learners are combined with\ntraditional methods of predicting customer churn in the telecommunication\nindustry.\n  Finally we investigate the effect of network construction on model\nperformance; our findings imply that the definition of edges and weights in the\nnetwork does have an impact on the results of the predictive models. As a\nresult of the study, the best configuration is a non-relational learner\nenriched with network variables, without collective inference, using binary\nweights and undirected networks. In addition, we provide guidelines on how to\napply social networks analytics for churn prediction in the telecommunication\nindustry in an optimal way, ranging from network architecture to model building\nand evaluation.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 17:09:22 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["\u00d3skarsd\u00f3ttir", "Mar\u00eda", ""], ["Bravo", "Cristi\u00e1n", ""], ["Verbeke", "Wouter", ""], ["Sarraute", "Carlos", ""], ["Baesens", "Bart", ""], ["Vanthienen", "Jan", ""]]}, {"id": "2001.06923", "submitter": "Xiangyu Zhao", "authors": "Xiangyu Zhao and Jiliang Tang", "title": "Exploring Spatio-Temporal and Cross-Type Correlations for Crime\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crime prediction plays an impactful role in enhancing public security and\nsustainable development of urban. With recent advances in data collection and\nintegration technologies, a large amount of urban data with rich crime-related\ninformation and fine-grained spatio-temporal logs has been recorded. Such\nhelpful information can boost our understandings about the temporal evolution\nand spatial factors of urban crimes and can enhance accurate crime prediction.\nIn this paper, we perform crime prediction exploiting the cross-type and\nspatio-temporal correlations of urban crimes. In particular, we verify the\nexistence of correlations among different types of crime from temporal and\nspatial perspectives, and propose a coherent framework to mathematically model\nthese correlations for crime prediction. The extensive experimental results on\nreal-world data validate the effectiveness of the proposed framework. Further\nexperiments have been conducted to understand the importance of different\ncorrelations in crime prediction.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 00:34:53 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 02:20:36 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Tang", "Jiliang", ""]]}, {"id": "2001.07038", "submitter": "Ana Freire", "authors": "Ana Freire, Lorenzo Porcaro and Emilia G\\'omez", "title": "Measuring Diversity of Artificial Intelligence Conferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of diversity of the Artificial Intelligence (AI) field is nowadays a\nconcern, and several initiatives such as funding schemes and mentoring programs\nhave been designed to overcome it. However, there is no indication on how these\ninitiatives actually impact AI diversity in the short and long term. This work\nstudies the concept of diversity in this particular context and proposes a\nsmall set of diversity indicators (i.e. indexes) of AI scientific events. These\nindicators are designed to quantify the diversity of the AI field and monitor\nits evolution. We consider diversity in terms of gender, geographical location\nand business (understood as the presence of academia versus industry). We\ncompute these indicators for the different communities of a conference:\nauthors, keynote speakers and organizing committee. From these components we\ncompute a summarized diversity indicator for each AI event. We evaluate the\nproposed indexes for a set of recent major AI conferences and we discuss their\nvalues and limitations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 10:09:50 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 10:34:58 GMT"}, {"version": "v3", "created": "Mon, 1 Feb 2021 15:45:35 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 17:08:41 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Freire", "Ana", ""], ["Porcaro", "Lorenzo", ""], ["G\u00f3mez", "Emilia", ""]]}, {"id": "2001.07282", "submitter": "Joseph Chow", "authors": "Theodoros P. Pantelidis, Li Li, Tai-Yu Ma, Joseph Y. J. Chow, Saif\n  Eddin G. Jabari", "title": "A node-charge graph-based online carshare rebalancing policy with\n  capacitated electric charging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Viability of electric car-sharing operations depends on rebalancing\nalgorithms. Earlier methods in the literature suggest a trend toward non-myopic\nalgorithms using queueing principles. We propose a new rebalancing policy using\ncost function approximation. The cost function is modeled as a p-median\nrelocation problem with minimum cost flow conservation and path-based charging\nstation capacities on a static node-charge graph structure. The cost function\nis NP-complete, so a heuristic is proposed that ensures feasible solutions that\ncan be solved in an online system. The algorithm is validated in a case study\nof electric carshare in Brooklyn, New York, with demand data shared from BMW\nReachNow operations in September 2017 (262 vehicle fleet, 231 pickups per day,\n303 traffic analysis zones (TAZs)) and charging station location data (18\ncharging stations with 4 port capacities). The proposed non-myopic rebalancing\nheuristic reduces the cost increase compared to myopic rebalancing by 38%.\nOther managerial insights are further discussed.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 23:28:29 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 13:39:46 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 15:45:32 GMT"}, {"version": "v4", "created": "Mon, 15 Mar 2021 01:54:36 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Pantelidis", "Theodoros P.", ""], ["Li", "Li", ""], ["Ma", "Tai-Yu", ""], ["Chow", "Joseph Y. J.", ""], ["Jabari", "Saif Eddin G.", ""]]}, {"id": "2001.07311", "submitter": "Wenjie Hu", "authors": "Wenjie Hu, Yang Yang, Jianbo Wang, Xuanwen Huang, Ziqiang Cheng", "title": "Understanding Electricity-Theft Behavior via Multi-Source Data", "comments": "11 pages, 8 figures, WWW'20 full paper", "journal-ref": null, "doi": "10.1145/3366423.3380291", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electricity theft, the behavior that involves users conducting illegal\noperations on electrical meters to avoid individual electricity bills, is a\ncommon phenomenon in the developing countries. Considering its harmfulness to\nboth power grids and the public, several mechanized methods have been developed\nto automatically recognize electricity-theft behaviors. However, these methods,\nwhich mainly assess users' electricity usage records, can be insufficient due\nto the diversity of theft tactics and the irregularity of user behaviors.\n  In this paper, we propose to recognize electricity-theft behavior via\nmulti-source data. In addition to users' electricity usage records, we analyze\nuser behaviors by means of regional factors (non-technical loss) and climatic\nfactors (temperature) in the corresponding transformer area. By conducting\nanalytical experiments, we unearth several interesting patterns: for instance,\nelectricity thieves are likely to consume much more electrical power than\nnormal users, especially under extremely high or low temperatures. Motivated by\nthese empirical observations, we further design a novel hierarchical framework\nfor identifying electricity thieves. Experimental results based on a real-world\ndataset demonstrate that our proposed model can achieve the best performance in\nelectricity-theft detection (e.g., at least +3.0% in terms of F0.5) compared\nwith several baselines. Last but not least, our work has been applied by the\nState Grid of China and used to successfully catch electricity thieves in\nHangzhou with a precision of 15% (an improvement form 0% attained by several\nother models the company employed) during monthly on-site investigation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 02:15:07 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Hu", "Wenjie", ""], ["Yang", "Yang", ""], ["Wang", "Jianbo", ""], ["Huang", "Xuanwen", ""], ["Cheng", "Ziqiang", ""]]}, {"id": "2001.07487", "submitter": "Emiliano De Cristofaro", "authors": "Antonis Papasavva, Savvas Zannettou, Emiliano De Cristofaro, Gianluca\n  Stringhini, Jeremy Blackburn", "title": "Raiders of the Lost Kek: 3.5 Years of Augmented 4chan Posts from the\n  Politically Incorrect Board", "comments": null, "journal-ref": "Published at the 14th International AAAI Conference on Web and\n  Social Media (ICWSM 2020). Please cite the ICWSM version", "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a dataset with over 3.3M threads and 134.5M posts from\nthe Politically Incorrect board (/pol/) of the imageboard forum 4chan, posted\nover a period of almost 3.5 years (June 2016-November 2019). To the best of our\nknowledge, this represents the largest publicly available 4chan dataset,\nproviding the community with an archive of posts that have been permanently\ndeleted from 4chan and are otherwise inaccessible. We augment the data with a\nset of additional labels, including toxicity scores and the named entities\nmentioned in each post. We also present a statistical analysis of the dataset,\nproviding an overview of what researchers interested in using it can expect, as\nwell as a simple content analysis, shedding light on the most prominent\ndiscussion topics, the most popular entities mentioned, and the toxicity level\nof each post. Overall, we are confident that our work will motivate and assist\nresearchers in studying and understanding 4chan, as well as its role on the\ngreater Web. For instance, we hope this dataset may be used for cross-platform\nstudies of social media, as well as being useful for other types of research\nlike natural language processing. Finally, our dataset can assist qualitative\nwork focusing on in-depth case studies of specific narratives, events, or\nsocial theories.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 12:52:24 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 13:57:35 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Papasavva", "Antonis", ""], ["Zannettou", "Savvas", ""], ["De Cristofaro", "Emiliano", ""], ["Stringhini", "Gianluca", ""], ["Blackburn", "Jeremy", ""]]}, {"id": "2001.07549", "submitter": "Paul Rosen", "authors": "Zachariah Beasley and Alon Friedman and Les Piegl and Paul Rosen", "title": "Leveraging Peer Feedback to Improve Visualization Education", "comments": null, "journal-ref": "2020 IEEE Pacific Visualization Symposium (PacificVis)", "doi": "10.1109/PacificVis48177.2020.1261", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer review is a widely utilized pedagogical feedback mechanism for engaging\nstudents, which has been shown to improve educational outcomes. However, we\nfind limited discussion and empirical measurement of peer review in\nvisualization coursework. In addition to engagement, peer review provides\ndirect and diverse feedback and reinforces recently-learned course concepts\nthrough critical evaluation of others' work. In this paper, we discuss the\nconstruction and application of peer review in a computer science visualization\ncourse, including: projects that reuse code and visualizations in a\nfeedback-guided, continual improvement process and a peer review rubric to\nreinforce key course concepts. To measure the effectiveness of the approach, we\nevaluate student projects, peer review text, and a post-course questionnaire\nfrom 3 semesters of mixed undergraduate and graduate courses. The results\nindicate that course concepts are reinforced with peer review---82% reported\nlearning more because of peer review, and 75% of students recommended\ncontinuing it. Finally, we provide a road-map for adapting peer review to other\nvisualization courses to produce more highly engaged students.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 21:46:58 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 16:04:30 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Beasley", "Zachariah", ""], ["Friedman", "Alon", ""], ["Piegl", "Les", ""], ["Rosen", "Paul", ""]]}, {"id": "2001.07600", "submitter": "Manoel Horta Ribeiro", "authors": "Manoel Horta Ribeiro, Jeremy Blackburn, Barry Bradlyn, Emiliano De\n  Cristofaro, Gianluca Stringhini, Summer Long, Stephanie Greenberg, Savvas\n  Zannettou", "title": "The Evolution of the Manosphere Across the Web", "comments": "To appear at the 15th International AAAI Conference on Web and Social\n  Media (ICWSM 2021) -- please cite accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a large-scale characterization of the Manosphere, a\nconglomerate of Web-based misogynist movements roughly focused on \"men's\nissues,\" which has seen significant growth over the past years. We do so by\ngathering and analyzing 28.8M posts from 6 forums and 51 subreddits. Overall,\nwe paint a comprehensive picture of the evolution of the Manosphere on the Web,\nshowing the links between its different communities over the years. We find\nthat milder and older communities, such as Pick Up Artists and Men's Rights\nActivists, are giving way to more extremist ones like Incels and Men Going\nTheir Own Way, with a substantial migration of active users. Moreover, our\nanalysis suggests that these newer communities are more toxic and misogynistic\nthan the former.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:14:13 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 09:41:30 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2020 14:26:43 GMT"}, {"version": "v4", "created": "Sun, 30 Aug 2020 12:24:00 GMT"}, {"version": "v5", "created": "Thu, 8 Apr 2021 10:55:12 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Ribeiro", "Manoel Horta", ""], ["Blackburn", "Jeremy", ""], ["Bradlyn", "Barry", ""], ["De Cristofaro", "Emiliano", ""], ["Stringhini", "Gianluca", ""], ["Long", "Summer", ""], ["Greenberg", "Stephanie", ""], ["Zannettou", "Savvas", ""]]}, {"id": "2001.07630", "submitter": "Irawan Nurhas", "authors": "Irawan Nurhas, Bayu Rima Aditya, Stefan Geisler, Jan Pawlowski", "title": "Why Does Cultural Diversity Foster Technology-enabled Intergenerational\n  Collaboration?", "comments": "8 Pages, 5th Information System International Conference (ISICO)", "journal-ref": "Procedia Computer Science, 2020", "doi": "10.1016/j.procs.2019.11.094", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Globalization and information technology enable people to join the movement\nof global citizenship and work without borders. However, different type of\nbarriers existed that could affect collaboration in todays work environment, in\nwhich different generations are involved. Although researchers have identified\nseveral technical barriers to intergenerational collaboration (iGOAL), the\ninfluence of cultural diversity on iGOAL has rarely been studied. Therefore,\nusing a quantitative study approach, this paper investigates the impact of\ndifferences in cultural background on perceived technical and operational\nbarriers to iGOAL. Our study reveals six barriers to IGC that are perceived\ndifferently by culturally diverse people (CDP) and non-CDP. Furthermore, CDP\ncan foster IGC because CDP consider the barriers to be of less of a reason to\navoid working with different generations than do non-CDP.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:21:13 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Nurhas", "Irawan", ""], ["Aditya", "Bayu Rima", ""], ["Geisler", "Stefan", ""], ["Pawlowski", "Jan", ""]]}, {"id": "2001.07864", "submitter": "John Villasenor", "authors": "Pratyush Garg, John Villasenor and Virginia Foggo", "title": "Fairness Metrics: A Comparative Analysis", "comments": "10 pages (preprint), corrected typos and slight structural changes\n  (results unchanged)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic fairness is receiving significant attention in the academic and\nbroader literature due to the increasing use of predictive algorithms,\nincluding those based on artificial intelligence. One benefit of this trend is\nthat algorithm designers and users have a growing set of fairness measures to\nchoose from. However, this choice comes with the challenge of identifying how\nthe different fairness measures relate to one another, as well as the extent to\nwhich they are compatible or mutually exclusive. We describe some of the most\nwidely used fairness metrics using a common mathematical framework and present\nnew results on the relationships among them. The results presented herein can\nhelp place both specialists and non-specialists in a better position to\nidentify the metric best suited for their application and goals.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 03:27:37 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 17:06:54 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Garg", "Pratyush", ""], ["Villasenor", "John", ""], ["Foggo", "Virginia", ""]]}, {"id": "2001.07944", "submitter": "Luke Storry", "authors": "Luke Storry", "title": "augKlimb: Interactive Data-Led Augmentation of Bouldering Training", "comments": "Written as a MEng Masters thesis at the University of Bristol.\n  Received an award for the highest mark of the year. (49 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climbing is a popular and growing sport, especially indoors, where climbers\ncan train on man-made routes using artificial holds. Both strength and good\ntechnique is required to successfully reach the top of a climb, and often\ncoaches work to improve technique so less strength is required, enabling a\nclimber to ascent more difficult climbs.\n  Various aspects of adding computer-interaction to climbing have been studied\nin recent years, but there is a large space for research into lightweight tools\nto aid recreational intermediate climbers, both with trickier climbs and to\nimprove their own technique.\n  In this CS Masters final project, I explored which form of data-capture and\noutput-features could improve a climber's training, and analysed how climbers\nresponded to viewing their data throughout a climbing session, then conducted a\nuser-centred design to build a lightweight mobile application for intermediate\nclimbers. A variety of hardware and software solutions were explored, tested\nand developed through series of surveys, discussions, wizard-of-oz studies and\nprototyping, resulting in a system that most closely meets the needs of local\nindoor boulderers given the project's time scope.\n  This consists of an iteratively developed interactive mobile app that: can\nrecord, graph, and score the acceleration of a climber, as both a training tool\nand gamification incentive for good technique; can link a video recording to\nthe acceleration graph, to enable frame-by-frame inspection of weaknesses; is\nfully approved and distributed on the Google play Store and currently being\nregularly used by 15 local climbers. Then I conducted a final usability study,\ncomprising a thematic analysis of forty minutes's worth of interview\ntranscripts, to gain a deep understanding of the app's impact on the climbers\nusing it, along with its benefits and limitations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 10:26:59 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Storry", "Luke", ""]]}, {"id": "2001.08132", "submitter": "Jun Sun", "authors": "Jun Sun, Mat\\'u\\v{s} Medo, Steffen Staab", "title": "Time-invariant degree growth in preferential attachment network models", "comments": "9 pages, 5 figures. Editorially approved for publication in Phys.\n  Rev. E", "journal-ref": "Physical Review E (Volume 101, Issue 2, February 2020)", "doi": "10.1103/PhysRevE.101.022309", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preferential attachment drives the evolution of many complex networks. Its\nanalytical studies mostly consider the simplest case of a network that grows\nuniformly in time despite the accelerating growth of many real networks.\nMotivated by the observation that the average degree growth of nodes is\ntime-invariant in empirical network data, we study the degree dynamics in the\nrelevant class of network models where preferential attachment is combined with\nheterogeneous node fitness and aging. We propose a novel analytical framework\nbased on the time-invariance of the studied systems and show that it is\nself-consistent only for two special network growth forms: the uniform and\nexponential network growth. Conversely, the breaking of such time-invariance\nexplains the winner-takes-all effect in some model settings, revealing the\nconnection between the Bose-Einstein condensation in the Bianconi-Barab\\'{a}si\nmodel and similar gelation in superlinear preferential attachment. Aging is\nnecessary to reproduce realistic node degree growth curves and can prevent the\nwinner-takes-all effect under weak conditions. Our results are verified by\nextensive numerical simulations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:31:11 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Sun", "Jun", ""], ["Medo", "Mat\u00fa\u0161", ""], ["Staab", "Steffen", ""]]}, {"id": "2001.08194", "submitter": "Ryo Suzuki", "authors": "Ryo Suzuki, Jun Kato, Koji Yatani", "title": "ClassCode: An Interactive Teaching and Learning Environment for\n  Programming Education in Classrooms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming education is becoming important as demands on computer literacy\nand coding skills are growing. Despite the increasing popularity of interactive\nonline learning systems, many programming courses in schools have not changed\ntheir teaching format from the conventional classroom setting. We see two\nresearch opportunities here. Students may have diverse expertise and experience\nin programming. Thus, particular content and teaching speed can be disengaging\nfor experienced students or discouraging for novice learners. In a large\nclassroom, instructors cannot oversee the learning progress of each student,\nand have difficulty matching teaching materials with the comprehension level of\nindividual students. We present ClassCode, a web-based environment tailored to\nprogramming education in classrooms. Students can take online tutorials\nprepared by instructors at their own pace. They can then deepen their\nunderstandings by performing interactive coding exercises interleaved within\ntutorials. ClassCode tracks all interactions by each student, and summarizes\nthem to instructors. This serves as a progress report, facilitating the\ninstructors to provide additional explanations in-situ or revise course\nmaterials. Our user evaluation through a small lecture and expert review by\ninstructors and teaching assistants confirm the potential of ClassCode by\nuncovering how it could address issues in existing programming courses at\nuniversities.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:28:16 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Suzuki", "Ryo", ""], ["Kato", "Jun", ""], ["Yatani", "Koji", ""]]}, {"id": "2001.08211", "submitter": "Chris Xiaoxuan Lu", "authors": "Chris Xiaoxuan Lu, Yang Li, Yuanbo Xiangli and Zhengxiong Li", "title": "Nowhere to Hide: Cross-modal Identity Leakage between Biometrics and\n  Devices", "comments": "12 pages", "journal-ref": null, "doi": "10.1145/3366423.3380108", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Along with the benefits of Internet of Things (IoT) come potential privacy\nrisks, since billions of the connected devices are granted permission to track\ninformation about their users and communicate it to other parties over the\nInternet. Of particular interest to the adversary is the user identity which\nconstantly plays an important role in launching attacks. While the exposure of\na certain type of physical biometrics or device identity is extensively\nstudied, the compound effect of leakage from both sides remains unknown in\nmulti-modal sensing environments. In this work, we explore the feasibility of\nthe compound identity leakage across cyber-physical spaces and unveil that\nco-located smart device IDs (e.g., smartphone MAC addresses) and physical\nbiometrics (e.g., facial/vocal samples) are side channels to each other. It is\ndemonstrated that our method is robust to various observation noise in the wild\nand an attacker can comprehensively profile victims in multi-dimension with\nnearly zero analysis effort. Two real-world experiments on different biometrics\nand device IDs show that the presented approach can compromise more than 70\\%\nof device IDs and harvests multiple biometric clusters with ~94% purity at the\nsame time.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 22:26:12 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Lu", "Chris Xiaoxuan", ""], ["Li", "Yang", ""], ["Xiangli", "Yuanbo", ""], ["Li", "Zhengxiong", ""]]}, {"id": "2001.08293", "submitter": "Kostantinos Papadamou Mr", "authors": "Kostantinos Papadamou, Savvas Zannettou, Jeremy Blackburn, Emiliano De\n  Cristofaro, Gianluca Stringhini, and Michael Sirivianos", "title": "\"How over is it?\" Understanding the Incel Community on YouTube", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  YouTube is by far the largest host of user-generated video content worldwide.\nAlas, the platform also hosts inappropriate, toxic, and hateful content. One\ncommunity that has often been linked to sharing and publishing hateful and\nmisogynistic content is the so-called Involuntary Celibates (Incels), a loosely\ndefined movement ostensibly focusing on men's issues. In this paper, we set out\nto analyze the Incel community on YouTube by focusing on this community's\nevolution over the last decade and understanding whether YouTube's\nrecommendation algorithm steers users towards Incel-related videos. We collect\nvideos shared on Incel communities within Reddit and perform a data-driven\ncharacterization of the content posted on YouTube. Among other things, we find\nthat the Incel community on YouTube is getting traction and that during the\nlast decade, the number of Incel-related videos and comments rose\nsubstantially. We also find that users have a 6.3% of being suggested an\nIncel-related video by YouTube's recommendation algorithm within five hops when\nstarting from a non-Incel-related video. Overall, our findings paint an\nalarming picture of online radicalization: not only Incel activity is\nincreasing over time, but platforms may also play an active role in steering\nusers towards such extreme content.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 21:47:54 GMT"}, {"version": "v2", "created": "Sat, 25 Jan 2020 12:40:34 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 11:55:45 GMT"}, {"version": "v4", "created": "Tue, 16 Jun 2020 08:17:04 GMT"}, {"version": "v5", "created": "Sun, 17 Jan 2021 16:35:06 GMT"}, {"version": "v6", "created": "Tue, 18 May 2021 09:24:47 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Papadamou", "Kostantinos", ""], ["Zannettou", "Savvas", ""], ["Blackburn", "Jeremy", ""], ["De Cristofaro", "Emiliano", ""], ["Stringhini", "Gianluca", ""], ["Sirivianos", "Michael", ""]]}, {"id": "2001.08333", "submitter": "Clarence Chen", "authors": "Clarence Chen, Zachary Pardos", "title": "Applying Recent Innovations from NLP to MOOC Student Course Trajectory\n  Modeling", "comments": "4 pages, 0 figures, accepted to EDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents several strategies that can improve neural network-based\npredictive methods for MOOC student course trajectory modeling, applying\nmultiple ideas previously applied to tackle NLP (Natural Language Processing)\ntasks. In particular, this paper investigates LSTM networks enhanced with two\nforms of regularization, along with the more recently introduced Transformer\narchitecture.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:36:57 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 19:11:26 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Chen", "Clarence", ""], ["Pardos", "Zachary", ""]]}, {"id": "2001.08435", "submitter": "Savvas Zannettou", "authors": "Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire,\n  Jeremy Blackburn", "title": "The Pushshift Reddit Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media data has become crucial to the advancement of scientific\nunderstanding. However, even though it has become ubiquitous, just collecting\nlarge-scale social media data involves a high degree of engineering skill set\nand computational resources. In fact, research is often times gated by data\nengineering problems that must be overcome before analysis can proceed. This\nhas resulted recognition of datasets as meaningful research contributions in\nand of themselves. Reddit, the so called \"front page of the Internet,\" in\nparticular has been the subject of numerous scientific studies. Although Reddit\nis relatively open to data acquisition compared to social media platforms like\nFacebook and Twitter, the technical barriers to acquisition still remain. Thus,\nReddit's millions of subreddits, hundreds of millions of users, and hundreds of\nbillions of comments are at the same time relatively accessible, but time\nconsuming to collect and analyze systematically. In this paper, we present the\nPushshift Reddit dataset. Pushshift is a social media data collection,\nanalysis, and archiving platform that since 2015 has collected Reddit data and\nmade it available to researchers. Pushshift's Reddit dataset is updated in\nreal-time, and includes historical data back to Reddit's inception. In addition\nto monthly dumps, Pushshift provides computational tools to aid in searching,\naggregating, and performing exploratory analysis on the entirety of the\ndataset. The Pushshift Reddit dataset makes it possible for social media\nresearchers to reduce time spent in the data collection, cleaning, and storage\nphases of their projects.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:31:29 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Baumgartner", "Jason", ""], ["Zannettou", "Savvas", ""], ["Keegan", "Brian", ""], ["Squire", "Megan", ""], ["Blackburn", "Jeremy", ""]]}, {"id": "2001.08438", "submitter": "Savvas Zannettou", "authors": "Jason Baumgartner, Savvas Zannettou, Megan Squire, Jeremy Blackburn", "title": "The Pushshift Telegram Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Messaging platforms, especially those with a mobile focus, have become\nincreasingly ubiquitous in society. These mobile messaging platforms can have\ndeceivingly large user bases, and in addition to being a way for people to stay\nin touch, are often used to organize social movements, as well as a place for\nextremists and other ne'er-do-well to congregate. In this paper, we present a\ndataset from one such mobile messaging platform: Telegram. Our dataset is made\nup of over 27.8K channels and 317M messages from 2.2M unique users. To the best\nof our knowledge, our dataset comprises the largest and most complete of its\nkind. In addition to the raw data, we also provide the source code used to\ncollect it, allowing researchers to run their own data collection instance. We\nbelieve the Pushshift Telegram dataset can help researchers from a variety of\ndisciplines interested in studying online social movements, protests, political\nextremism, and disinformation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:37:33 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Baumgartner", "Jason", ""], ["Zannettou", "Savvas", ""], ["Squire", "Megan", ""], ["Blackburn", "Jeremy", ""]]}, {"id": "2001.08614", "submitter": "Tiziano Piccardi", "authors": "Tiziano Piccardi, Miriam Redi, Giovanni Colavizza, Robert West", "title": "Quantifying Engagement with Citations on Wikipedia", "comments": "The Web Conference WWW 2020, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikipedia, the free online encyclopedia that anyone can edit, is one of the\nmost visited sites on the Web and a common source of information for many\nusers. As an encyclopedia, Wikipedia is not a source of original information,\nbut was conceived as a gateway to secondary sources: according to Wikipedia's\nguidelines, facts must be backed up by reliable sources that reflect the full\nspectrum of views on the topic. Although citations lie at the very heart of\nWikipedia, little is known about how users interact with them. To close this\ngap, we built client-side instrumentation for logging all interactions with\nlinks leading from English Wikipedia articles to cited references during one\nmonth, and conducted the first analysis of readers' interaction with citations\non Wikipedia. We find that overall engagement with citations is low: about one\nin 300 page views results in a reference click (0.29% overall; 0.56% on\ndesktop; 0.13% on mobile). Matched observational studies of the factors\nassociated with reference clicking reveal that clicks occur more frequently on\nshorter pages and on pages of lower quality, suggesting that references are\nconsulted more commonly when Wikipedia itself does not contain the information\nsought by the user. Moreover, we observe that recent content, open access\nsources and references about life events (births, deaths, marriages, etc) are\nparticularly popular. Taken together, our findings open the door to a deeper\nunderstanding of Wikipedia's role in a global information economy where\nreliability is ever less certain, and source attribution ever more vital.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:52:36 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 17:38:32 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Piccardi", "Tiziano", ""], ["Redi", "Miriam", ""], ["Colavizza", "Giovanni", ""], ["West", "Robert", ""]]}, {"id": "2001.08686", "submitter": "Genevieve Gorrell", "authors": "Genevieve Gorrell, Mehmet E Bakir, Ian Roberts, Mark A Greenwood,\n  Kalina Bontcheva", "title": "Online Abuse toward Candidates during the UK General Election 2019:\n  Working Paper", "comments": "Second draft, January 30th 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The 2019 UK general election took place against a background of rising online\nhostility levels toward politicians and concerns about its impact on democracy.\nWe collected 4.2 million tweets sent to or from election candidates in the six\nweek period spanning from the start of November until shortly after the\nDecember 12th election. We found abuse in 4.46\\% of replies received by\ncandidates, up from 3.27\\% in the matching period for the 2017 UK general\nelection. Abuse levels have also been climbing month on month throughout 2019.\nAbuse also escalated throughout the campaign period.\n  Abuse focused mainly on a small number of high profile politicians. Abuse is\n\"spiky\", triggered by external events such as debates, or certain tweets. Abuse\nincreases when politicians discuss inflammatory topics such as borders and\nimmigration. There may also be a backlash on topics such as social justice.\nSome tweets may become viral targets for personal abuse. On average, men\nreceived more general and political abuse; women received more sexist abuse.\nMPs choosing not to stand again had received more abuse during 2019.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 17:28:40 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 17:33:21 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Gorrell", "Genevieve", ""], ["Bakir", "Mehmet E", ""], ["Roberts", "Ian", ""], ["Greenwood", "Mark A", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "2001.08767", "submitter": "Anay Mehrotra", "authors": "L. Elisa Celis and Anay Mehrotra and Nisheeth K. Vishnoi", "title": "Interventions for Ranking in the Presence of Implicit Bias", "comments": "This paper will appear at the ACM FAT* 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit bias is the unconscious attribution of particular qualities (or lack\nthereof) to a member from a particular social group (e.g., defined by gender or\nrace). Studies on implicit bias have shown that these unconscious stereotypes\ncan have adverse outcomes in various social contexts, such as job screening,\nteaching, or policing. Recently, (Kleinberg and Raghavan, 2018) considered a\nmathematical model for implicit bias and showed the effectiveness of the Rooney\nRule as a constraint to improve the utility of the outcome for certain cases of\nthe subset selection problem. Here we study the problem of designing\ninterventions for the generalization of subset selection -- ranking -- that\nrequires to output an ordered set and is a central primitive in various social\nand computational contexts. We present a family of simple and interpretable\nconstraints and show that they can optimally mitigate implicit bias for a\ngeneralization of the model studied in (Kleinberg and Raghavan, 2018).\nSubsequently, we prove that under natural distributional assumptions on the\nutilities of items, simple, Rooney Rule-like, constraints can also surprisingly\nrecover almost all the utility lost due to implicit biases. Finally, we augment\nour theoretical results with empirical findings on real-world distributions\nfrom the IIT-JEE (2009) dataset and the Semantic Scholar Research corpus.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:11:31 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Celis", "L. Elisa", ""], ["Mehrotra", "Anay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2001.08777", "submitter": "Alexandria LeClerc", "authors": "Glencora Borradaile, Brett Burkhardt, Alexandria LeClerc", "title": "Whose Tweets are Surveilled for the Police: An Audit of Social-Media\n  Monitoring Tool via Log Files", "comments": "21 Pages, 2 figures. To to be Published in FAT* 2020 Proceedings", "journal-ref": null, "doi": "10.1145/3351095.3372841", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media monitoring by law enforcement is becoming commonplace, but\nlittle is known about what software packages for it do. Through public records\nrequests, we obtained log files from the Corvallis (Oregon) Police Department's\nuse of social media monitoring software called DigitalStakeout. These log files\ninclude the results of proprietary searches by DigitalStakeout that were\nrunning over a period of 13 months and include 7240 social media posts. In this\npaper, we focus on the Tweets logged in this data and consider the racial and\nethnic identity (through manual coding) of the users that are therein flagged\nby DigitalStakeout. We observe differences in the demographics of the users\nwhose Tweets are flagged by DigitalStakeout compared to the demographics of the\nTwitter users in the region, however, our sample size is too small to determine\nsignificance. Further, the demographics of the Twitter users in the region do\nnot seem to reflect that of the residents of the region, with an apparent\nhigher representation of Black and Hispanic people. We also reconstruct the\nkeywords related to a Narcotics report set up by DigitalStakeout for the\nCorvallis Police Department and find that these keywords flag Tweets unrelated\nto narcotics or flag Tweets related to marijuana, a drug that is legal for\nrecreational use in Oregon. Almost all of the keywords have a common meaning\nunrelated to narcotics (e.g.\\ broken, snow, hop, high) that call into question\nthe utility that such a keyword based search could have to law enforcement.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:35:12 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Borradaile", "Glencora", ""], ["Burkhardt", "Brett", ""], ["LeClerc", "Alexandria", ""]]}, {"id": "2001.08810", "submitter": "Valerio Lorini", "authors": "Valerio Lorini, Javier Rando, Diego Saez-Trumper, Carlos Castillo", "title": "Uneven Coverage of Natural Disasters in Wikipedia: the Case of Flood", "comments": "17 pages, submitted to ISCRAM 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The usage of non-authoritative data for disaster management presents the\nopportunity of accessing timely information that might not be available through\nother means, as well as the challenge of dealing with several layers of biases.\nWikipedia, a collaboratively-produced encyclopedia, includes in-depth\ninformation about many natural and human-made disasters, and its editors are\nparticularly good at adding information in real-time as a crisis unfolds. In\nthis study, we focus on the English version of Wikipedia, that is by far the\nmost comprehensive version of this encyclopedia. Wikipedia tends to have good\ncoverage of disasters, particularly those having a large number of fatalities.\nHowever, we also show that a tendency to cover events in wealthy countries and\nnot cover events in poorer ones permeates Wikipedia as a source for\ndisaster-related information. By performing careful automatic content analysis\nat a large scale, we show how the coverage of floods in Wikipedia is skewed\ntowards rich, English-speaking countries, in particular the US and Canada. We\nalso note how coverage of floods in countries with the lowest income, as well\nas countries in South America, is substantially lower than the coverage of\nfloods in middle-income countries. These results have implications for systems\nusing Wikipedia or similar collaborative media platforms as an information\nsource for detecting emergencies or for gathering valuable information for\ndisaster response.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:13:34 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Lorini", "Valerio", ""], ["Rando", "Javier", ""], ["Saez-Trumper", "Diego", ""], ["Castillo", "Carlos", ""]]}, {"id": "2001.08832", "submitter": "Carlos Sarraute PhD", "authors": "Daniel Fernandez, Ariel Futoransky, Gustavo Ajzenman, Matias\n  Travizano, Carlos Sarraute", "title": "Wibson Protocol for Secure Data Exchange and Batch Payments", "comments": "arXiv admin note: text overlap with arXiv:1812.09966", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wibson is a blockchain-based, decentralized data marketplace that provides\nindividuals a way to securely and anonymously sell information in a trusted\nenvironment. The combination of the Wibson token and blockchain-enabled smart\ncontracts hopes to allow Data Sellers and Data Buyers to transact with each\nother directly while providing individuals the ability to maintain anonymity as\ndesired.\n  The Wibson marketplace will provide infrastructure and financial incentives\nfor individuals to securely sell personal information without sacrificing\npersonal privacy. Data Buyers receive information from willing and actively\nparticipating individuals with the benefit of knowing that the personal\ninformation should be accurate and current.\n  We present here two different components working together to achieve an\nefficient decentralized marketplace. The first is a smart contract called Data\nExchange, which stores references to Data Orders that different Buyers open in\norder to show to the market that they are interested in buying certain types of\ndata, and provides secure mechanisms to perform the transactions. The second is\nused to process payments from Buyers to Sellers and intermediaries, and is\ncalled Batch Payments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:20:39 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 14:41:58 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Fernandez", "Daniel", ""], ["Futoransky", "Ariel", ""], ["Ajzenman", "Gustavo", ""], ["Travizano", "Matias", ""], ["Sarraute", "Carlos", ""]]}, {"id": "2001.08845", "submitter": "Anna Feldman", "authors": "Kei Yin Ng, Anna Feldman, Jing Peng", "title": "Linguistic Fingerprints of Internet Censorship: the Case of SinaWeibo", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how the linguistic components of blogposts collected from\nSina Weibo, a Chinese microblogging platform, might affect the blogposts'\nlikelihood of being censored. Our results go along with King et al. (2013)'s\nCollective Action Potential (CAP) theory, which states that a blogpost's\npotential of causing riot or assembly in real life is the key determinant of it\ngetting censored. Although there is not a definitive measure of this construct,\nthe linguistic features that we identify as discriminatory go along with the\nCAP theory. We build a classifier that significantly outperforms non-expert\nhumans in predicting whether a blogpost will be censored. The crowdsourcing\nresults suggest that while humans tend to see censored blogposts as more\ncontroversial and more likely to trigger action in real life than the\nuncensored counterparts, they in general cannot make a better guess than our\nmodel when it comes to `reading the mind' of the censors in deciding whether a\nblogpost should be censored. We do not claim that censorship is only determined\nby the linguistic features. There are many other factors contributing to\ncensorship decisions. The focus of the present paper is on the linguistic form\nof blogposts. Our work suggests that it is possible to use linguistic\nproperties of social media posts to automatically predict if they are going to\nbe censored.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 23:08:24 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Ng", "Kei Yin", ""], ["Feldman", "Anna", ""], ["Peng", "Jing", ""]]}, {"id": "2001.08930", "submitter": "Piero Bonatti", "authors": "Piero A. Bonatti, Sabrina Kirrane, Iliana M. Petrova, Luigi Sauro", "title": "Machine Understandable Policies and GDPR Compliance Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The European General Data Protection Regulation (GDPR) calls for technical\nand organizational measures to support its implementation. Towards this end,\nthe SPECIAL H2020 project aims to provide a set of tools that can be used by\ndata controllers and processors to automatically check if personal data\nprocessing and sharing complies with the obligations set forth in the GDPR. The\nprimary contributions of the project include: (i) a policy language that can be\nused to express consent, business policies, and regulatory obligations; and\n(ii) two different approaches to automated compliance checking that can be used\nto demonstrate that data processing performed by data controllers / processors\ncomplies with consent provided by data subjects, and business processes comply\nwith regulatory obligations set forth in the GDPR.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:41:47 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Bonatti", "Piero A.", ""], ["Kirrane", "Sabrina", ""], ["Petrova", "Iliana M.", ""], ["Sauro", "Luigi", ""]]}, {"id": "2001.08949", "submitter": "Vittoria de Nitto Person\\`e", "authors": "Vittoria de Nitto Person\\`e (University of Rome Tor Vergata, Rome,\n  Italy)", "title": "Teaching Performance Modeling in the era of millennials", "comments": "7 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance Modeling (PM) teaching started in the early 70s and reached its\npeak in the 80s. From those years and until today computing systems have deeply\nchanged. Moreover, in the last two decades an economical crisis has involved\nthe educational system, while the new generations show new learning modes. In\nthis time, new literature has developed about learning and teaching. Rarely\nhighlighting the critical issues. Higher learning is changing its role maybe\nunawares. In this paper, the author starts from a close examination of the\nstate of the art of PM courses in Universities around the world and tries to\nhighlight the main critical issues of teaching nowadays. The paper has not the\naim to give answers but mainly that to open the way to reflections and\ndiscussions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 11:33:51 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Person\u00e8", "Vittoria de Nitto", "", "University of Rome Tor Vergata, Rome,\n  Italy"]]}, {"id": "2001.09183", "submitter": "Tamara Bonaci", "authors": "Filipp Demenschonok, Jason Harrigan, and Tamara Bonaci", "title": "An Overview of Fingerprint-Based Authentication: Liveness Detection and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide an overview of fingerprint sensing methods used for\nauthentication. We analyze the current fingerprint sensing technologies, from\nalgorithmic, as well as from hardware perspectives. We then focus on methods to\ndetect physical liveness, defined as techniques that can be used to ensure that\na living human user is attempting to authenticate on a system. We analyze how\neffective these methods are at preventing attacks where a malicious entity\ntries to trick a fingerprint-based authentication system to accept a fake\nfinger as a real one (spoofing attacks). We then identify broader attack points\nagainst biometric data, such as fingerprints. Finally, we propose novel\nmeasures to protect fingerprint data.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 20:07:53 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Demenschonok", "Filipp", ""], ["Harrigan", "Jason", ""], ["Bonaci", "Tamara", ""]]}, {"id": "2001.09233", "submitter": "Kit Rodolfa", "authors": "Kit T. Rodolfa, Erika Salomon, Lauren Haynes, Ivan Higuera Mendieta,\n  Jamie Larson, Rayid Ghani", "title": "Case Study: Predictive Fairness to Reduce Misdemeanor Recidivism Through\n  Social Service Interventions", "comments": "12 pages, 4 figures, 1 algorithm. The definitive Version of Record\n  will be published in the proceedings of the Conference on Fairness,\n  Accountability, and Transparency (FAT* '20), January 27-30, 2020, Barcelona,\n  Spain", "journal-ref": null, "doi": "10.1145/3351095.3372863", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The criminal justice system is currently ill-equipped to improve outcomes of\nindividuals who cycle in and out of the system with a series of misdemeanor\noffenses. Often due to constraints of caseload and poor record linkage, prior\ninteractions with an individual may not be considered when an individual comes\nback into the system, let alone in a proactive manner through the application\nof diversion programs. The Los Angeles City Attorney's Office recently created\na new Recidivism Reduction and Drug Diversion unit (R2D2) tasked with reducing\nrecidivism in this population. Here we describe a collaboration with this new\nunit as a case study for the incorporation of predictive equity into machine\nlearning based decision making in a resource-constrained setting. The program\nseeks to improve outcomes by developing individually-tailored social service\ninterventions (i.e., diversions, conditional plea agreements, stayed\nsentencing, or other favorable case disposition based on appropriate social\nservice linkage rather than traditional sentencing methods) for individuals\nlikely to experience subsequent interactions with the criminal justice system,\na time and resource-intensive undertaking that necessitates an ability to focus\nresources on individuals most likely to be involved in a future case. Seeking\nto achieve both efficiency (through predictive accuracy) and equity (improving\noutcomes in traditionally under-served communities and working to mitigate\nexisting disparities in criminal justice outcomes), we discuss the equity\noutcomes we seek to achieve, describe the corresponding choice of a metric for\nmeasuring predictive fairness in this context, and explore a set of options for\nbalancing equity and efficiency when building and selecting machine learning\nmodels in an operational public policy setting.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 23:52:55 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Rodolfa", "Kit T.", ""], ["Salomon", "Erika", ""], ["Haynes", "Lauren", ""], ["Mendieta", "Ivan Higuera", ""], ["Larson", "Jamie", ""], ["Ghani", "Rayid", ""]]}, {"id": "2001.09265", "submitter": "Sukanta Das Dr.", "authors": "Souvik Roy and Abhik Mukherjee and Sukanta Das", "title": "Elementary Cellular Automata along with delay sensitivity can model\n  communal riot dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the potential of elementary cellular automata to model the\ndynamics of riot. Here, to model such dynamics, we introduce probabilistic loss\nof information and delay perturbation in the updating scheme of automata to\ncapture sociological parameters - presence of anti-riot population and\norganizational presence of communal forces in the rioting society respectively.\nMoreover, delay has also been incorporated in the model to capture the\nnon-local interaction of neighbours. Finally, the model is verified by a recent\nevent of riot that occurred in Baduria of West Bengal, India.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 05:23:04 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Roy", "Souvik", ""], ["Mukherjee", "Abhik", ""], ["Das", "Sukanta", ""]]}, {"id": "2001.09410", "submitter": "Han Xiao", "authors": "Han Xiao, Bruno Ordozgoiti, Aristides Gionis", "title": "Searching for polarization in signed graphs: a local spectral approach", "comments": "11 pages, 6 figures, accepted by WWW 2020, April 20-24, 2020, Taipei,\n  Taiwan", "journal-ref": null, "doi": "10.1145/3366423.3380121", "report-no": null, "categories": "cs.SI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signed graphs have been used to model interactions in social net-works, which\ncan be either positive (friendly) or negative (antagonistic). The model has\nbeen used to study polarization and other related phenomena in social networks,\nwhich can be harmful to the process of democratic deliberation in our society.\nAn interesting and challenging task in this application domain is to detect\npolarized communities in signed graphs. A number of different methods have been\nproposed for this task. However, existing approaches aim at finding globally\noptimal solutions. Instead, in this paper we are interested in finding\npolarized communities that are related to a small set of seed nodes provided as\ninput. Seed nodes may consist of two sets, which constitute the two sides of a\npolarized structure.\n  In this paper we formulate the problem of finding local polarized communities\nin signed graphs as a locally-biased eigen-problem. By viewing the eigenvector\nassociated with the smallest eigenvalue of the Laplacian matrix as the solution\nof a constrained optimization problem, we are able to incorporate the local\ninformation as an additional constraint. In addition, we show that the\nlocally-biased vector can be used to find communities with approximation\nguarantee with respect to a local analogue of the Cheeger constant on signed\ngraphs. By exploiting the sparsity in the input graph, an indicator vector for\nthe polarized communities can be found in time linear to the graph size.\n  Our experiments on real-world networks validate the proposed algorithm and\ndemonstrate its usefulness in finding local structures in this semi-supervised\nmanner.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 06:30:16 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Xiao", "Han", ""], ["Ordozgoiti", "Bruno", ""], ["Gionis", "Aristides", ""]]}, {"id": "2001.09434", "submitter": "Rohit Gupta", "authors": "Rohit Gupta and Rohit Panda", "title": "Block the blocker: Studying the effects of Anti Ad-blocking", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advertisements generate huge chunks of revenues for websites and online\nbusinesses. Ad-blocker and tracker blocking programs have gained momentum in\nthe last few years with massive debates raging on privacy concerns and\nimproving user experience online. Acceptable Ads programme and Anti Ad-blockers\nare primary elements emerging in recent years that combat ad-blockers.\n  In this paper, we discuss at length data collection of top websites in the\nworld, Germany, DACH region and news category. We generate feature based A/B\ntesting metrics and employ classifier evaluations on them along with then\nanalysing the result. Our paper also discusses how Anti Ad-blockers impact the\neconomic, legal and ethical usage in Germany along with the recent changes in\nGDPR while taking a look at Acceptable ads programme and Whitelisting.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 10:58:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Gupta", "Rohit", ""], ["Panda", "Rohit", ""]]}, {"id": "2001.09473", "submitter": "Marco Viviani", "authors": "Gabriella Pasi and Marco Viviani", "title": "Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues", "comments": "Article accepted and presented at ITASEC 2020: Italian Conference on\n  Cybersecurity. February 4-7, 2020, Ancona, Italy. https://itasec.it/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 15:42:43 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pasi", "Gabriella", ""], ["Viviani", "Marco", ""]]}, {"id": "2001.09479", "submitter": "Rizwan Ahmed Khan", "authors": "Shahid Munir Shah, Rizwan Ahmed Khan", "title": "Secondary Use of Electronic Health Record: Opportunities and Challenges", "comments": null, "journal-ref": "IEEE Access 2020", "doi": "10.1109/ACCESS.2020.3011099", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In present technological era, healthcare providers generate huge amount of\nclinical data on daily basis. Generated clinical data is stored digitally in\nthe form of Electronic Health Records (EHR) as a central data repository of\nhospitals. Data contained in EHR is not only used for the patients' primary\ncare but also for various secondary purposes such as clinical research,\nautomated disease surveillance and clinical audits for quality enhancement.\nUsing EHR data for secondary purposes without consent or in some cases even\nwith consent creates privacy issues for individuals. Secondly, EHR data is also\nmade accessible to various stake holders including different government\nagencies at various geographical sites through wired or wireless networks.\nSharing of EHR across multiples agencies makes it vulnerable to cyber attacks\nand also makes it difficult to implement strict privacy laws as in some cases\ndata is shared with organization that is governed by specific regional law.\nPrivacy of an individual could be severely affected when their sensitive\nprivate information contained in EHR is leaked or exposed to public. Data leak\ncan cause financial losses or an individuals may encounter social boycott if\ntheir medical condition is exposed in public. To protect patients personal data\nfrom such threats, there exists different privacy regulations such as GDPR,\nHIPAA and MHR. However, continually evolving state-of-the-art techniques in\nmachine learning, data analytics and hacking are making it even more difficult\nto completely protect individual's / patient's privacy. In this article, we\nhave systematically examined various secondary uses of EHR with the aim to\nhighlight how these secondary uses effect patients' privacy. Secondly, we have\ncritically analyzed GDPR and highlighted possible areas of improvement,\nconsidering escalating use of technology and different secondary uses of EHR.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 16:22:53 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Shah", "Shahid Munir", ""], ["Khan", "Rizwan Ahmed", ""]]}, {"id": "2001.09723", "submitter": "Jennifer Cobbe Dr", "authors": "Seyyed Ahmad Javadi, Richard Cloete, Jennifer Cobbe, Michelle Seng Ah\n  Lee and Jatinder Singh", "title": "Monitoring Misuse for Accountable 'Artificial Intelligence as a Service'", "comments": null, "journal-ref": "Proceedings of the 2020 AAAI/ACM Conference on AI, Ethics, and\n  Society (AIES '20), ACM, New York, NY, USA, 2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI is increasingly being offered 'as a service' (AIaaS). This entails service\nproviders offering customers access to pre-built AI models and services, for\ntasks such as object recognition, text translation, text-to-voice conversion,\nand facial recognition, to name a few. The offerings enable customers to easily\nintegrate a range of powerful AI-driven capabilities into their applications.\nCustomers access these models through the provider's APIs, sending particular\ndata to which models are applied, the results of which returned. However, there\nare many situations in which the use of AI can be problematic. AIaaS services\ntypically represent generic functionality, available 'at a click'. Providers\nmay therefore, for reasons of reputation or responsibility, seek to ensure that\nthe AIaaS services they offer are being used by customers for 'appropriate'\npurposes. This paper introduces and explores the concept whereby AIaaS\nproviders uncover situations of possible service misuse by their customers.\nIllustrated through topical examples, we consider the technical usage patterns\nthat could signal situations warranting scrutiny, and raise some of the legal\nand technical challenges of monitoring for misuse. In all, by introducing this\nconcept, we indicate a potential area for further inquiry from a range of\nperspectives.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 18:14:33 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Javadi", "Seyyed Ahmad", ""], ["Cloete", "Richard", ""], ["Cobbe", "Jennifer", ""], ["Lee", "Michelle Seng Ah", ""], ["Singh", "Jatinder", ""]]}, {"id": "2001.09738", "submitter": "Daniyal Liaqat", "authors": "Daniyal Liaqat, Robert Wu, Salaar Liaqat, Eyal de Lara, Andrea\n  Gershon, Frank Rudzicz", "title": "The Ground Truth Trade-Off in Wearable Sensing Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perez et al's study using the Apple Watch to identify atrial fibrillation\n(AF) is a watershed moment in large-scale machine learning for wearable\ncomputing. Identifying relevant patients will be tremendously important to\nresearch in healthcare. For a condition like AF, this could reduce stroke risk\nby two thirds. In the study by Perez et al, only 450 out of 420,000 individuals\nhad ground truth data. Their study excluded 417,000 participants using the\nirregular pulse notification. This design decision means their study was only\nable to report positive predictive value (PPV) and unable to explore\nsensitivity or specificity. In this editorial, we explore the difficulty of\nobtaining ground truth data and its implications for study design.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:57:14 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Liaqat", "Daniyal", ""], ["Wu", "Robert", ""], ["Liaqat", "Salaar", ""], ["de Lara", "Eyal", ""], ["Gershon", "Andrea", ""], ["Rudzicz", "Frank", ""]]}, {"id": "2001.09740", "submitter": "Hoda Sedighi", "authors": "Hoda Sedighi", "title": "Classification of human activity recognition using smartphones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have been the most popular and widely used devices among means of\ncommunication. Nowadays, human activity recognition is possible on mobile\ndevices by embedded sensors, which can be exploited to manage user behavior on\nmobile devices by predicting user activity. To reach this aim, storing activity\ncharacteristics, Classification, and mapping them to a learning algorithm was\nstudied in this research. In this study, we applied categorization through deep\nbelief network to test and training data, which resulted in 98.25% correct\ndiagnosis in training data and 93.01% in test data. Therefore, in this study,\nwe prove that the deep belief network is a suitable method for this particular\npurpose.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 16:08:07 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Sedighi", "Hoda", ""]]}, {"id": "2001.09742", "submitter": "Duncan McElfresh", "authors": "Duncan C McElfresh, Samuel Dooley, Yuan Cui, Kendra Griesman, Weiqin\n  Wang, Tyler Will, Neil Sehgal, John P Dickerson", "title": "Can an Algorithm be My Healthcare Proxy?", "comments": "Accepted for a poster presentation at the 4th International Workshop\n  on Health Intelligence (W3PHIAI-20), colocated with AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning for death is not a process in which everyone participates. Yet a\nlack of planning can have vast impacts on a patient's well-being, the\nwell-being of her family, and the medical community as a whole. Advance Care\nPlanning (ACP) has been a field in the United States for a half-century. Many\nmodern techniques prompting patients to think about end of life (EOL) involve\nshort surveys or questionnaires. Different surveys are targeted to different\npopulations (based off of likely disease progression or cultural factors, for\ninstance), are designed with different intentions, and are administered in\ndifferent ways. There has been recent work using technology to increase the\nnumber of people using advance care planning tools. However, modern techniques\nfrom machine learning and artificial intelligence could be employed to make\nadditional changes to the current ACP process. In this paper we will discuss\nsome possible ways in which these tools could be applied. We will discuss\npossible implications of these applications through vignettes of patient\nscenarios. We hope that this paper will encourage thought about appropriate\napplications of artificial intelligence in ACP as well as implementation of AI\nin order to ensure intentions are honored.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 13:31:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["McElfresh", "Duncan C", ""], ["Dooley", "Samuel", ""], ["Cui", "Yuan", ""], ["Griesman", "Kendra", ""], ["Wang", "Weiqin", ""], ["Will", "Tyler", ""], ["Sehgal", "Neil", ""], ["Dickerson", "John P", ""]]}, {"id": "2001.09743", "submitter": "Tam Nguyen", "authors": "Tam N. Nguyen", "title": "Understanding Our People at Scale", "comments": "29 pages APA style (8 reference pages), 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human psychology plays an important role in organizational performance.\nHowever, understanding our employees is a difficult task due to issues such as\npsychological complexities, unpredictable dynamics, and the lack of data.\nLeveraging evidence-based psychology knowledge, this paper proposes a hybrid\nmachine learning plus ontology-based reasoning system for detecting human\npsychological artifacts at scale. This unique architecture provides a balance\nbetween system's processing speed and explain-ability. System outputs can be\nfurther consumed by graph science and/or model management system for optimizing\nbusiness processes, understanding team dynamics, predicting insider threats,\nmanaging talents, and beyond.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 18:35:57 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Nguyen", "Tam N.", ""]]}, {"id": "2001.09745", "submitter": "Oleksii Konashevych", "authors": "Oleksii Konashevych", "title": "Constraints and Benefits of the Blockchain Use for Real Estate and\n  Property Rights", "comments": "This document needs major revision and is not going to be updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent social media posts and news may create a perception of big\nsuccess in the use of blockchain for the real estate industry, land\nregistration and protection of titles and property rights. A sobering outlook\nis crucial because misleading concepts may bury the whole idea of blockchain\nuse. The paper aims to research the possibilities of blockchain and other\ndistributed ledger technologies (DLT) and applicability of these technologies\nfor different purposes in real estate, property rights and public registries.\nBlockchain, which is distinguished from permissioned systems as the technology\nof the immutable ledger that does not require authorities, is a new word in\ngovernance. However, this technology has some principal features that can\nrestrain its implementation at the state level, and thus require further\nresearch and development. The application of blockchain requires a proper\narchitecture of overlaid technologies to support changes of outdated and\nmistaken data, address issues of digital identity and privacy, legal compliance\nand enforceability of smart contracts and scalability of the ledger. This paper\nshows the constraints of the technology's properties which were not explained\nbefore in the context of title rights and land registration even though\ntechnological limits are known in more specific technical sources. Along with\nthe known benefits this meant to help to avoid misinterpretation of some DLT\nfeatures by non-technical people. A multidisciplinary approach in analysing the\ntechnology and laws helped to better understand what can and cannot be\nbeneficial for public registries and the protection of property rights. The\npresented outcomes can be laid down as requirements for the technical protocols\naimed at addressing the issues of DLT and public policies to put blockchain at\nthe service of society.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 04:11:01 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 21:57:43 GMT"}, {"version": "v3", "created": "Fri, 24 Apr 2020 02:32:23 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Konashevych", "Oleksii", ""]]}, {"id": "2001.09746", "submitter": "Nuno Henriques", "authors": "Nuno A. C. Henriques, Helder Coelho, Leonel Garcia-Marques", "title": "SensAI+Expanse Emotional Valence Prediction Studies with Cognition and\n  Memory Integration", "comments": "Accepted as regular paper in COGNITIVE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The humans are affective and cognitive beings relying on memories for their\nindividual and social identities. Also, human dyadic bonds require some common\nbeliefs such as empathetic behaviour for better interaction. In this sense,\nresearch studies involving human-agent interaction should resource on affect,\ncognition, and memory integration. The developed artificial agent system\n(SensAI+Expanse) includes machine learning algorithms, heuristics, and memory\nas cognition aids towards emotional valence prediction on the interacting\nhuman. Further, an adaptive empathy score is always present in order to engage\nthe human in a recognisable interaction outcome. [...] The agent is resilient\non collecting data, adapts its cognitive processes to each human individual in\na learning best effort for proper contextualised prediction. The current study\nmake use of an achieved adaptive process. Also, the use of individual\nprediction models with specific options of the learning algorithm and\nevaluation metric from a previous research study. The accomplished solution\nincludes a highly performant prediction ability, an efficient energy use, and\nfeature importance explanation for predicted probabilities. Results of the\npresent study show evidence of significant emotional valence behaviour\ndifferences between some age ranges and gender combinations. Therefore, this\nwork contributes with an artificial intelligent agent able to assist on\ncognitive science studies. This ability is about affective disturbances by\nmeans of predicting human emotional valence contextualised in space and time.\nMoreover, contributes with learning processes and heuristics fit to the task\nincluding economy of cognition and memory to cope with the environment.\nFinally, these contributions include an achieved age and gender neutrality on\npredicting emotional valence states in context and with very good performance\nfor each individual.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 18:17:57 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 16:27:19 GMT"}, {"version": "v3", "created": "Tue, 10 Mar 2020 15:11:24 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Henriques", "Nuno A. C.", ""], ["Coelho", "Helder", ""], ["Garcia-Marques", "Leonel", ""]]}, {"id": "2001.09747", "submitter": "Dirk Hartmann", "authors": "Dirk Hartmann, Herman van der Auweraer", "title": "Digital Twins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Twins are one of the hottest digital trends. In this contribution we\nwill shortly review the concept of Digital Twins and the chances for novel\nindustrial applications. Mathematics are a key enabler and the impact will be\nhighlighted along four specific examples addressing Digital Product Twins\ndemocratizing Design, Digital Production Twins enabling robots to mill, Digital\nProduction Twins driving industrialization of additive manufacturing, and\nDigital Performance Twins boosting operations. We conclude the article with an\noutlook on the next wave of Digital Twins, Executable Digital Twins, and will\nreview the associated challenges and opportunities for mathematics.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 19:20:47 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Hartmann", "Dirk", ""], ["van der Auweraer", "Herman", ""]]}, {"id": "2001.09748", "submitter": "Patrick Schwab", "authors": "Patrick Schwab, Walter Karlen", "title": "A Deep Learning Approach to Diagnosing Multiple Sclerosis from\n  Smartphone Data", "comments": null, "journal-ref": null, "doi": "10.1109/JBHI.2020.3021143", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sclerosis (MS) affects the central nervous system with a wide range\nof symptoms. MS can, for example, cause pain, changes in mood and fatigue, and\nmay impair a person's movement, speech and visual functions. Diagnosis of MS\ntypically involves a combination of complex clinical assessments and tests to\nrule out other diseases with similar symptoms. New technologies, such as\nsmartphone monitoring in free-living conditions, could potentially aid in\nobjectively assessing the symptoms of MS by quantifying symptom presence and\nintensity over long periods of time. Here, we present a deep-learning approach\nto diagnosing MS from smartphone-derived digital biomarkers that uses a novel\ncombination of a multilayer perceptron with neural soft attention to improve\nlearning of patterns in long-term smartphone monitoring data. Using data from a\ncohort of 774 participants, we demonstrate that our deep-learning models are\nable to distinguish between people with and without MS with an area under the\nreceiver operating characteristic curve of 0.88 (95% CI: 0.70, 0.88). Our\nexperimental results indicate that digital biomarkers derived from smartphone\ndata could in the future be used as additional diagnostic criteria for MS.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2020 15:29:16 GMT"}, {"version": "v2", "created": "Sat, 18 Jul 2020 12:12:43 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 07:32:28 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Schwab", "Patrick", ""], ["Karlen", "Walter", ""]]}, {"id": "2001.09750", "submitter": "Richard Benjamins Victor", "authors": "Richard Benjamins and Idoia Salazar", "title": "Towards a framework for understanding societal and ethical implications\n  of Artificial Intelligence", "comments": "Published as chapter in book \"Vulnerabilidad y cultura digital\" by\n  Dykinson. Pages 87-98, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is one of the most discussed technologies today.\nThere are many innovative applications such as the diagnosis and treatment of\ncancer, customer experience, new business, education, contagious diseases\npropagation and optimization of the management of humanitarian catastrophes.\nHowever, with all those opportunities also comes great responsibility to ensure\ngood and fair practice of AI. The objective of this paper is to identify the\nmain societal and ethical challenges implied by a massive uptake of AI. We have\nsurveyed the literature for the most common challenges and classified them in\nseven groups: 1) Non-desired effects, 2) Liability, 3) Unknown consequences, 4)\nRelation people-robots, 5) Concentration of power and wealth, 6) Intentional\nbad uses, and 7) AI for weapons and warfare. The challenges should be dealt\nwith in different ways depending on their origin; some have technological\nsolutions, while others require ethical, societal, or political answers.\nDepending on the origin, different stakeholders might need to act. Whatever the\nidentified stakeholder, not treating those issues will lead to uncertainty and\nunforeseen consequences with potentially large negative societal impact,\nhurting especially the most vulnerable groups of societies. Technology is\nhelping to take better decisions, and AI is promoting data-driven decisions in\naddition to experience- and intuition-based discussion, with many improvements\nhappening. However, the negative side effects of this technology need to be\nwell understood and acted upon before we launch them massively into the world.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 17:55:15 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Benjamins", "Richard", ""], ["Salazar", "Idoia", ""]]}, {"id": "2001.09751", "submitter": "Dianbo Liu Dr", "authors": "Jianfei Cui, He Zhu, Hao Deng, Ziwei Chen, Dianbo Liu", "title": "Federated machine learning with Anonymous Random Hybridization (FeARH)\n  on medical records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sometimes electrical medical records are restricted and difficult to\ncentralize for machine learning, which could only be trained in distributed\nmanner that involved many institutions in the process. However, sometimes some\ninstitutions are likely to figure out the private data used for training\ncertain models based on the parameters they obtained, which is a violation of\nprivacy and certain regulations. Under those circumstances, we develop an\nalgorithm, called 'federated machine learning with anonymous random\nhybridization'(abbreviated as 'FeARH'), using mainly hybridization algorithm to\neliminate connections between medical record data and models' parameters, which\navoid untrustworthy institutions from stealing patients' private medical\nrecords. Based on our experiment, our new algorithm has similar AUCROC and\nAUCPR result compared with machine learning in centralized manner and original\nfederated machine learning, at the same time, our algorithm can greatly reduce\ndata transfer size in comparison with original federated machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2019 07:44:25 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 08:21:24 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Cui", "Jianfei", ""], ["Zhu", "He", ""], ["Deng", "Hao", ""], ["Chen", "Ziwei", ""], ["Liu", "Dianbo", ""]]}, {"id": "2001.09753", "submitter": "Lionel Robert", "authors": "Weiwen Leung, Zheng Zhang, Daviti Jibuti, Jinhao Zhao, Maximillian\n  Klein, Casey Pierce, Lionel Robert, Haiyi Zhu", "title": "Race, Gender and Beauty: The Effect of Information Provision on Online\n  Hiring Biases", "comments": "11 page, 2 figures, 38rd ACM Conference on Human Factors in Computing\n  Systems, CHI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We conduct a study of hiring bias on a simulation platform where we ask\nAmazon MTurk participants to make hiring decisions for a mathematically\nintensive task. Our findings suggest hiring biases against Black workers and\nless attractive workers and preferences towards Asian workers female workers\nand more attractive workers. We also show that certain UI designs including\nprovision of candidates information at the individual level and reducing the\nnumber of choices can significantly reduce discrimination. However provision of\ncandidates information at the subgroup level can increase discrimination. The\nresults have practical implications for designing better online freelance\nmarketplaces.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 16:44:17 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Leung", "Weiwen", ""], ["Zhang", "Zheng", ""], ["Jibuti", "Daviti", ""], ["Zhao", "Jinhao", ""], ["Klein", "Maximillian", ""], ["Pierce", "Casey", ""], ["Robert", "Lionel", ""], ["Zhu", "Haiyi", ""]]}, {"id": "2001.09755", "submitter": "Alarith Uhde", "authors": "Alarith Uhde (1), Nadine Schlicker (2), Dieter P. Wallach (2), Marc\n  Hassenzahl (1) ((1) Siegen University, (2) Ergosign GmbH)", "title": "Fairness and Decision-making in Collaborative Shift Scheduling Systems", "comments": "10 pages, 3 figures, to be published at CHI'20", "journal-ref": null, "doi": "10.1145/3313831.3376656", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The strains associated with shift work decrease healthcare workers'\nwell-being. However, shift schedules adapted to their individual needs can\npartially mitigate these problems. From a computing perspective, shift\nscheduling was so far mainly treated as an optimization problem with little\nattention given to the preferences, thoughts, and feelings of the healthcare\nworkers involved. In the present study, we explore fairness as a central,\nhuman-oriented attribute of shift schedules as well as the scheduling process.\nThree in-depth qualitative interviews and a validating vignette study revealed\nthat while on an abstract level healthcare workers agree on equality as the\nguiding norm for a fair schedule, specific scheduling conflicts should foremost\nbe resolved by negotiating the importance of individual needs. We discuss\nelements of organizational fairness, including transparency and team spirit.\nFinally, we present a sketch for fair scheduling systems, summarizing key\nfindings for designers in a readily usable way.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 15:00:49 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 09:58:39 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Uhde", "Alarith", "", "Siegen University"], ["Schlicker", "Nadine", "", "Ergosign GmbH"], ["Wallach", "Dieter P.", "", "Ergosign GmbH"], ["Hassenzahl", "Marc", "", "Siegen University"]]}, {"id": "2001.09758", "submitter": "Richard Victor Benjamins", "authors": "Richard Benjamins", "title": "Towards organizational guidelines for the responsible use of AI", "comments": "Accepted for ECAI 2020. 2 pages. http://ecai2020.eu/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, several large companies have published ethical\nprinciples of Artificial Intelligence (AI). National governments, the European\nCommission, and inter-governmental organizations have come up with requirements\nto ensure the good use of AI. However, individual organizations that want to\njoin this effort, are faced with many unsolved questions. This paper proposes\nguidelines for organizations committed to the responsible use of AI, but lack\nthe required knowledge and experience. The guidelines consist of two parts: i)\nhelping organizations to decide what principles to adopt, and ii) a methodology\nfor implementing the principles in organizational processes. In case of future\nAI regulation, organizations following this approach will be well-prepared.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:48:23 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 11:26:57 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Benjamins", "Richard", ""]]}, {"id": "2001.09762", "submitter": "Vasileios Iosifidis", "authors": "Eirini Ntoutsi, Pavlos Fafalios, Ujwal Gadiraju, Vasileios Iosifidis,\n  Wolfgang Nejdl, Maria-Esther Vidal, Salvatore Ruggieri, Franco Turini, Symeon\n  Papadopoulos, Emmanouil Krasanakis, Ioannis Kompatsiaris, Katharina\n  Kinder-Kurlanda, Claudia Wagner, Fariba Karimi, Miriam Fernandez, Harith\n  Alani, Bettina Berendt, Tina Kruegel, Christian Heinze, Klaus Broelemann,\n  Gjergji Kasneci, Thanassis Tiropanis, Steffen Staab", "title": "Bias in Data-driven AI Systems -- An Introductory Survey", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI-based systems are widely employed nowadays to make decisions that have\nfar-reaching impacts on individuals and society. Their decisions might affect\neveryone, everywhere and anytime, entailing concerns about potential human\nrights issues. Therefore, it is necessary to move beyond traditional AI\nalgorithms optimized for predictive performance and embed ethical and legal\nprinciples in their design, training and deployment to ensure social good while\nstill benefiting from the huge potential of the AI technology. The goal of this\nsurvey is to provide a broad multi-disciplinary overview of the area of bias in\nAI systems, focusing on technical challenges and solutions as well as to\nsuggest new research directions towards approaches well-grounded in a legal\nframe. In this survey, we focus on data-driven AI, as a large part of AI is\npowered nowadays by (big) data and powerful Machine Learning (ML) algorithms.\nIf otherwise not specified, we use the general term bias to describe problems\nrelated to the gathering or processing of data that might result in prejudiced\ndecisions on the bases of demographic features like race, sex, etc.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 09:39:09 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Ntoutsi", "Eirini", ""], ["Fafalios", "Pavlos", ""], ["Gadiraju", "Ujwal", ""], ["Iosifidis", "Vasileios", ""], ["Nejdl", "Wolfgang", ""], ["Vidal", "Maria-Esther", ""], ["Ruggieri", "Salvatore", ""], ["Turini", "Franco", ""], ["Papadopoulos", "Symeon", ""], ["Krasanakis", "Emmanouil", ""], ["Kompatsiaris", "Ioannis", ""], ["Kinder-Kurlanda", "Katharina", ""], ["Wagner", "Claudia", ""], ["Karimi", "Fariba", ""], ["Fernandez", "Miriam", ""], ["Alani", "Harith", ""], ["Berendt", "Bettina", ""], ["Kruegel", "Tina", ""], ["Heinze", "Christian", ""], ["Broelemann", "Klaus", ""], ["Kasneci", "Gjergji", ""], ["Tiropanis", "Thanassis", ""], ["Staab", "Steffen", ""]]}, {"id": "2001.09763", "submitter": "Antonio Bucchiarone Dr.", "authors": "Antonio Bucchiarone, Sandro Battisti, Annapaola Marconi, Roberto\n  Maldacea, and Diego Cardona Ponce", "title": "Autonomous Shuttle-as-a-Service (ASaaS): Challenges, Opportunities, and\n  Social Implications", "comments": "20 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern cities are composed of complex socio-technical systems that exist to\nprovide services effectively to their residents and visitors. In this context,\nsmart mobility systems aim to support the efficient exploitation of the city\ntransport facilities as well as sustainable mobility within the urban\nenvironment. People need to travel quickly and conveniently between locations\nat different scales, ranging from a trip of a few blocks within a city to a\njourney across cities or further. At the same time, goods need to be timely\ndelivered considering the needs of both the users and the businesses. While\nmost of the mobility and delivery solutions can cover significant distances and\nmultiple requests, they suffer when the requests come from the growing\nneighborhoods and hard-to-reach areas such as city centers, corporate\nheadquarters, and hospitals. In the last few years, several cities indicated\ninterest in using Autonomous Vehicles (AV) for the \"last-mile\" mobility\nservices. With them, it seems to be easier to get people and goods around using\nfewer vehicles. In this context, Autonomous Shuttles (AS) are beginning to be\nthought of as a new mobility/delivery service into the city center where narrow\nstreets are not easily served by traditional buses. They allow them to serve\ncritical areas with minimal new infrastructure and reducing noise and\npollution. The goal of this article is to present an innovative vision on the\nintroduction of the Autonomous Shuttles-as-a service (ASaaS) concept as the key\npillar for the realization of innovative and sustainable proximity mobility.\nThrough a set of real application scenarios, we present our view, and we\ndiscuss a set of challenges, opportunities, and social implications that this\nway to reimage the mobility of the future introduces.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 12:34:03 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bucchiarone", "Antonio", ""], ["Battisti", "Sandro", ""], ["Marconi", "Annapaola", ""], ["Maldacea", "Roberto", ""], ["Ponce", "Diego Cardona", ""]]}, {"id": "2001.09764", "submitter": "Yigit Alparslan", "authors": "Yigit Alparslan and Ioanna Panagiotou and Willow Livengood and Robert\n  Kane and Andrew Cohen", "title": "Perfecting the Crime Machine", "comments": "11 pages, 55 figures, fixed typos, added references in Introduction\n  section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study explores using different machine learning techniques and workflows\nto predict crime related statistics, specifically crime type in Philadelphia.\nWe use crime location and time as main features, extract different features\nfrom the two features that our raw data has, and build models that would work\nwith large number of class labels. We use different techniques to extract\nvarious features including combining unsupervised learning techniques and try\nto predict the crime type. Some of the models that we use are Support Vector\nMachines, Decision Trees, Random Forest, K-Nearest Neighbors. We report that\nthe Random Forest as the best performing model to predict crime type with an\nerror log loss of 2.3120.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 23:25:40 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 21:13:15 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Alparslan", "Yigit", ""], ["Panagiotou", "Ioanna", ""], ["Livengood", "Willow", ""], ["Kane", "Robert", ""], ["Cohen", "Andrew", ""]]}, {"id": "2001.09765", "submitter": "Benjamin Birnbaum", "authors": "Benjamin Birnbaum, Nathan Nussbaum, Katharina Seidl-Rathkopf, Monica\n  Agrawal, Melissa Estevez, Evan Estola, Joshua Haimson, Lucy He, Peter Larson,\n  Paul Richardson", "title": "Model-assisted cohort selection with bias analysis for generating\n  large-scale cohorts from the EHR for oncology research", "comments": "Word count: Abstract, 254; text, 3934 Keywords: electronic health\n  record; machine learning; cancer; real-world evidence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Objective Electronic health records (EHRs) are a promising source of data for\nhealth outcomes research in oncology. A challenge in using EHR data is that\nselecting cohorts of patients often requires information in unstructured parts\nof the record. Machine learning has been used to address this, but even\nhigh-performing algorithms may select patients in a non-random manner and bias\nthe resulting cohort. To improve the efficiency of cohort selection while\nmeasuring potential bias, we introduce a technique called Model-Assisted Cohort\nSelection (MACS) with Bias Analysis and apply it to the selection of metastatic\nbreast cancer (mBC) patients. Materials and Methods We trained a model on\n17,263 patients using term-frequency inverse-document-frequency (TF-IDF) and\nlogistic regression. We used a test set of 17,292 patients to measure algorithm\nperformance and perform Bias Analysis. We compared the cohort generated by MACS\nto the cohort that would have been generated without MACS as reference\nstandard, first by comparing distributions of an extensive set of clinical and\ndemographic variables and then by comparing the results of two analyses\naddressing existing example research questions. Results Our algorithm had an\narea under the curve (AUC) of 0.976, a sensitivity of 96.0%, and an abstraction\nefficiency gain of 77.9%. During Bias Analysis, we found no large differences\nin baseline characteristics and no differences in the example analyses.\nConclusion MACS with bias analysis can significantly improve the efficiency of\ncohort selection on EHR data while instilling confidence that outcomes research\nperformed on the resulting cohort will not be biased.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 22:58:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Birnbaum", "Benjamin", ""], ["Nussbaum", "Nathan", ""], ["Seidl-Rathkopf", "Katharina", ""], ["Agrawal", "Monica", ""], ["Estevez", "Melissa", ""], ["Estola", "Evan", ""], ["Haimson", "Joshua", ""], ["He", "Lucy", ""], ["Larson", "Peter", ""], ["Richardson", "Paul", ""]]}, {"id": "2001.09766", "submitter": "Lok Chan", "authors": "Lok Chan, Kenzie Doyle, Duncan McElfresh, Vincent Conitzer, John P.\n  Dickerson, Jana Schaich Borg, Walter Sinnott-Armstrong", "title": "Artificial Artificial Intelligence: Measuring Influence of AI\n  'Assessments' on Moral Decision-Making", "comments": null, "journal-ref": "Proceedings of the 2020 AAAI/ACM Conference on AI, Ethics, and\n  Society (AIES '20)", "doi": "10.1145/3375627.3375870", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given AI's growing role in modeling and improving decision-making, how and\nwhen to present users with feedback is an urgent topic to address. We\nempirically examined the effect of feedback from false AI on moral\ndecision-making about donor kidney allocation. We found some evidence that\njudgments about whether a patient should receive a kidney can be influenced by\nfeedback about participants' own decision-making perceived to be given by AI,\neven if the feedback is entirely random. We also discovered different effects\nbetween assessments presented as being from human experts and assessments\npresented as being from AI.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 14:15:18 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chan", "Lok", ""], ["Doyle", "Kenzie", ""], ["McElfresh", "Duncan", ""], ["Conitzer", "Vincent", ""], ["Dickerson", "John P.", ""], ["Borg", "Jana Schaich", ""], ["Sinnott-Armstrong", "Walter", ""]]}, {"id": "2001.09768", "submitter": "Iason Gabriel", "authors": "Iason Gabriel", "title": "Artificial Intelligence, Values and Alignment", "comments": null, "journal-ref": "Minds and Machines 2020", "doi": "10.1007/s11023-020-09539-2", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper looks at philosophical questions that arise in the context of AI\nalignment. It defends three propositions. First, normative and technical\naspects of the AI alignment problem are interrelated, creating space for\nproductive engagement between people working in both domains. Second, it is\nimportant to be clear about the goal of alignment. There are significant\ndifferences between AI that aligns with instructions, intentions, revealed\npreferences, ideal preferences, interests and values. A principle-based\napproach to AI alignment, which combines these elements in a systematic way,\nhas considerable advantages in this context. Third, the central challenge for\ntheorists is not to identify 'true' moral principles for AI; rather, it is to\nidentify fair principles for alignment, that receive reflective endorsement\ndespite widespread variation in people's moral beliefs. The final part of the\npaper explores three ways in which fair principles for AI alignment could\npotentially be identified.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 10:32:16 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 12:03:19 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Gabriel", "Iason", ""]]}, {"id": "2001.09770", "submitter": "G\\'erald Rocher", "authors": "G\\'erald Rocher, Jean-Yves Tigli, St\\'ephane Lavirotte and Nhan Le\n  Thanh", "title": "Overview and Challenges of Ambient Systems, Towards a Constructivist\n  Approach to their Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From a closed and controlled environment, neglecting all the external\ndisturbances, information processing systems are now exposed to the complexity\nand the aleas of the physical environment, open and uncontrolled. Indeed, as\nenvisioned by Mark Weiser as early as 1991, the progresses made on wireless\ncommunications, energy storage and the miniaturization of computer components,\nmade it possible the fusion of the physical and digital worlds. This fusion is\nembodied in a set of concepts such as Internet of Things, Pervasive Computing,\nUbiquitous Computing, etc. From a synthesis of these different concepts, we\nshow that beyond the simple collection of environmental data from sensors, the\npurpose of the information processing systems underlying these concepts is to\ncarry out relevant actions that the processing of these data suggests in our\nenvironment. However, due to the complexity of these systems and the inability\nto predict the effects of their actions, the responsibility for these actions\nstill often remains with users. Mark Weiser's vision of disappearing computing\nis still far from being a reality. This situation calls for an epistemological\nrupture that is proposed to be concretized through the systemic approach which\nfinds its foundations in constructivism. It is no longer a question of\npredicting but of evaluating in vivo the effectiveness of these systems. The\nperspectives for such an approach are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 14:37:49 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Rocher", "G\u00e9rald", ""], ["Tigli", "Jean-Yves", ""], ["Lavirotte", "St\u00e9phane", ""], ["Thanh", "Nhan Le", ""]]}, {"id": "2001.09773", "submitter": "Zachary Lipton", "authors": "Sina Fazelpour, Zachary C. Lipton", "title": "Algorithmic Fairness from a Non-ideal Perspective", "comments": "Accepted for publication at the AAAI/ACM Conference on Artificial\n  Intelligence, Ethics, and Society (AIES) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent breakthroughs in predictive modeling, practitioners in\nboth industry and government have turned to machine learning with hopes of\noperationalizing predictions to drive automated decisions. Unfortunately, many\nsocial desiderata concerning consequential decisions, such as justice or\nfairness, have no natural formulation within a purely predictive framework. In\nefforts to mitigate these problems, researchers have proposed a variety of\nmetrics for quantifying deviations from various statistical parities that we\nmight expect to observe in a fair world and offered a variety of algorithms in\nattempts to satisfy subsets of these parities or to trade off the degree to\nwhich they are satisfied against utility. In this paper, we connect this\napproach to \\emph{fair machine learning} to the literature on ideal and\nnon-ideal methodological approaches in political philosophy. The ideal approach\nrequires positing the principles according to which a just world would operate.\nIn the most straightforward application of ideal theory, one supports a\nproposed policy by arguing that it closes a discrepancy between the real and\nthe perfectly just world. However, by failing to account for the mechanisms by\nwhich our non-ideal world arose, the responsibilities of various\ndecision-makers, and the impacts of proposed policies, naive applications of\nideal thinking can lead to misguided interventions. In this paper, we\ndemonstrate a connection between the fair machine learning literature and the\nideal approach in political philosophy, and argue that the increasingly\napparent shortcomings of proposed fair machine learning algorithms reflect\nbroader troubles faced by the ideal approach. We conclude with a critical\ndiscussion of the harms of misguided solutions, a reinterpretation of\nimpossibility results, and directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 18:44:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Fazelpour", "Sina", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2001.09778", "submitter": "Emilia Gomez", "authors": "Emilio G\\'omez-Gonz\\'alez, Emilia Gomez, Javier M\\'arquez-Rivas,\n  Manuel Guerrero-Claro, Isabel Fern\\'andez-Lizaranzu, Mar\\'ia Isabel\n  Relimpio-L\\'opez, Manuel E. Dorado, Mar\\'ia Jos\\'e Mayorga-Buiza, Guillermo\n  Izquierdo-Ayuso, Luis Capit\\'an-Morales", "title": "Artificial intelligence in medicine and healthcare: a review and\n  classification of current and near-future applications and their ethical and\n  social Impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper provides an overview of the current and near-future applications\nof Artificial Intelligence (AI) in Medicine and Health Care and presents a\nclassification according to their ethical and societal aspects, potential\nbenefits and pitfalls, and issues that can be considered controversial and are\nnot deeply discussed in the literature.\n  This work is based on an analysis of the state of the art of research and\ntechnology, including existing software, personal monitoring devices, genetic\ntests and editing tools, personalized digital models, online platforms,\naugmented reality devices, and surgical and companion robotics. Motivated by\nour review, we present and describe the notion of 'extended personalized\nmedicine', we then review existing applications of AI in medicine and\nhealthcare and explore the public perception of medical AI systems, and how\nthey show, simultaneously, extraordinary opportunities and drawbacks that even\nquestion fundamental medical concepts. Many of these topics coincide with\nurgent priorities recently defined by the World Health Organization for the\ncoming decade. In addition, we study the transformations of the roles of\ndoctors and patients in an age of ubiquitous information, identify the risk of\na division of Medicine into 'fake-based', 'patient-generated', and\n'scientifically tailored', and draw the attention of some aspects that need\nfurther thorough analysis and public debate.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 15:39:42 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 14:46:51 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["G\u00f3mez-Gonz\u00e1lez", "Emilio", ""], ["Gomez", "Emilia", ""], ["M\u00e1rquez-Rivas", "Javier", ""], ["Guerrero-Claro", "Manuel", ""], ["Fern\u00e1ndez-Lizaranzu", "Isabel", ""], ["Relimpio-L\u00f3pez", "Mar\u00eda Isabel", ""], ["Dorado", "Manuel E.", ""], ["Mayorga-Buiza", "Mar\u00eda Jos\u00e9", ""], ["Izquierdo-Ayuso", "Guillermo", ""], ["Capit\u00e1n-Morales", "Luis", ""]]}, {"id": "2001.09784", "submitter": "Dana Pessach", "authors": "Dana Pessach and Erez Shmueli", "title": "Algorithmic Fairness", "comments": "31 pages, 1 figure, This is a survey article that reviews the field\n  of algorithmic fairness", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of decisions regarding the daily lives of human beings\nare being controlled by artificial intelligence (AI) algorithms in spheres\nranging from healthcare, transportation, and education to college admissions,\nrecruitment, provision of loans and many more realms. Since they now touch on\nmany aspects of our lives, it is crucial to develop AI algorithms that are not\nonly accurate but also objective and fair. Recent studies have shown that\nalgorithmic decision-making may be inherently prone to unfairness, even when\nthere is no intention for it. This paper presents an overview of the main\nconcepts of identifying, measuring and improving algorithmic fairness when\nusing AI algorithms. The paper begins by discussing the causes of algorithmic\nbias and unfairness and the common definitions and measures for fairness.\nFairness-enhancing mechanisms are then reviewed and divided into pre-process,\nin-process and post-process mechanisms. A comprehensive comparison of the\nmechanisms is then conducted, towards a better understanding of which\nmechanisms should be used in different scenarios. The paper then describes the\nmost commonly used fairness-related datasets in this field. Finally, the paper\nends by reviewing several emerging research sub-fields of algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 19:01:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pessach", "Dana", ""], ["Shmueli", "Erez", ""]]}, {"id": "2001.09786", "submitter": "Somali Chaterji", "authors": "Somali Chaterji, Nathan DeLay, John Evans, Nathan Mosier, Bernard\n  Engel, Dennis Buckmaster and Ranveer Chandra", "title": "Artificial Intelligence for Digital Agriculture at Scale: Techniques,\n  Policies, and Challenges", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital agriculture has the promise to transform agricultural throughput. It\ncan do this by applying data science and engineering for mapping input factors\nto crop throughput, while bounding the available resources. In addition, as the\ndata volumes and varieties increase with the increase in sensor deployment in\nagricultural fields, data engineering techniques will also be instrumental in\ncollection of distributed data as well as distributed processing of the data.\nThese have to be done such that the latency requirements of the end users and\napplications are satisfied. Understanding how farm technology and big data can\nimprove farm productivity can significantly increase the world's food\nproduction by 2050 in the face of constrained arable land and with the water\nlevels receding. While much has been written about digital agriculture's\npotential, little is known about the economic costs and benefits of these\nemergent systems. In particular, the on-farm decision making processes, both in\nterms of adoption and optimal implementation, have not been adequately\naddressed. For example, if some algorithm needs data from multiple data owners\nto be pooled together, that raises the question of data ownership. This paper\nis the first one to bring together the important questions that will guide the\nend-to-end pipeline for the evolution of a new generation of digital\nagricultural solutions, driving the next revolution in agriculture and\nsustainability under one umbrella.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 06:02:38 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Chaterji", "Somali", ""], ["DeLay", "Nathan", ""], ["Evans", "John", ""], ["Mosier", "Nathan", ""], ["Engel", "Bernard", ""], ["Buckmaster", "Dennis", ""], ["Chandra", "Ranveer", ""]]}, {"id": "2001.09795", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Patrick Uhr, Fabian Merges, Sanaz Mohammad Hassani,\n  Madjid Fathi", "title": "Practical Approach of Knowledge Management in Medical Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge organization, infrastructure, and knowledge-based activities are\nall subjects that help in the creation of business strategies for the new\nenterprise. In this paper, the first basics of knowledge-based systems are\nstudied. Practical issues and challenges of Knowledge Management (KM)\nimplementations are then illustrated. Finally, a comparison of different\nknowledge-based projects is presented along with abstracted information on\ntheir implementation, techniques, and results. Most of these projects are in\nthe field of medical science. Based on our study and evaluation of different KM\nprojects, we conclude that KM is being used in every science, industry, and\nbusiness. But its importance in medical science and assisted living projects\nare highlighted nowadays with the most of research institutes. Most medical\ncenters are interested in using knowledge-based services like portals and\nlearning techniques of knowledge for their future innovations and supports.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:39:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Uhr", "Patrick", ""], ["Merges", "Fabian", ""], ["Hassani", "Sanaz Mohammad", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.09796", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Alexander Holland, Madjid Fathi", "title": "Knowledge Integration of Collaborative Product Design Using Cloud\n  Computing Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pivotal key to the success of manufacturing enterprises is a sustainable\nand innovative product design and development. In collaborative design,\nstakeholders are heterogeneously distributed chain-like. Due to the growing\nvolume of data and knowledge, effective management of the knowledge acquired in\nthe product design and development is one of the key challenges facing most\nmanufacturing enterprises. Opportunities for improving efficiency and\nperformance of IT-based product design applications through centralization of\nresources such as knowledge and computation have increased in the last few\nyears with the maturation of technologies such as SOA, virtualization, grid\ncomputing, and/or cloud computing. The main focus of this paper is the concept\nof ongoing research in providing the knowledge integration service for\ncollaborative product design and development using cloud computing\ninfrastructure. Potentials of the cloud computing to support the Knowledge\nintegration functionalities as a Service by providing functionalities such as\nknowledge mapping, merging, searching, and transferring in product design\nprocedure are described in this paper. Proposed knowledge integration services\nsupport users by giving real-time access to knowledge resources. The framework\nhas the advantage of availability, efficiency, cost reduction, less time to\nresult, and scalability.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:44:27 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Holland", "Alexander", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.09797", "submitter": "Mahdi Bohlouli", "authors": "Mahdi Bohlouli, Nikolaos Mittas, George Kakarontzas, Theodosios\n  Theodosiou, Lefteris Angelis, Madjid Fathi", "title": "Competence Assessment as an Expert System for Human Resource Management:\n  A Mathematical Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient human resource management needs accurate assessment and\nrepresentation of available competences as well as effective mapping of\nrequired competences for specific jobs and positions. In this regard,\nappropriate definition and identification of competence gaps express\ndifferences between acquired and required competences. Using a detailed\nquantification scheme together with a mathematical approach is a way to support\naccurate competence analytics, which can be applied in a wide variety of\nsectors and fields. This article describes the combined use of software\ntechnologies and mathematical and statistical methods for assessing and\nanalyzing competences in human resource information systems. Based on a\nstandard competence model, which is called a Professional, Innovative and\nSocial competence tree, the proposed framework offers flexible tools to experts\nin real enterprise environments, either for evaluation of employees towards an\noptimal job assignment and vocational training or for recruitment processes.\nThe system has been tested with real human resource data sets in the frame of\nthe European project called ComProFITS.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:37:15 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Bohlouli", "Mahdi", ""], ["Mittas", "Nikolaos", ""], ["Kakarontzas", "George", ""], ["Theodosiou", "Theodosios", ""], ["Angelis", "Lefteris", ""], ["Fathi", "Madjid", ""]]}, {"id": "2001.09954", "submitter": "Luca Maria Aiello", "authors": "Minje Choi, Luca Maria Aiello, Krisztian Zsolt Varga, Daniele Quercia", "title": "Ten Social Dimensions of Conversations and Relationships", "comments": "12 pages, 7 tables, 7 figures", "journal-ref": "In Proceedings of the Web Conference 2020 (WWW'20)", "doi": "10.1145/3366423.3380224", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decades of social science research identified ten fundamental dimensions that\nprovide the conceptual building blocks to describe the nature of human\nrelationships. Yet, it is not clear to what extent these concepts are expressed\nin everyday language and what role they have in shaping observable dynamics of\nsocial interactions. After annotating conversational text through\ncrowdsourcing, we trained NLP tools to detect the presence of these types of\ninteraction from conversations, and applied them to 160M messages written by\ngeo-referenced Reddit users, 290k emails from the Enron corpus and 300k lines\nof dialogue from movie scripts. We show that social dimensions can be predicted\npurely from conversations with an AUC up to 0.98, and that the combination of\nthe predicted dimensions suggests both the types of relationships people\nentertain (conflict vs. support) and the types of real-world communities\n(wealthy vs. deprived) they shape.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:20:34 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Choi", "Minje", ""], ["Aiello", "Luca Maria", ""], ["Varga", "Krisztian Zsolt", ""], ["Quercia", "Daniele", ""]]}, {"id": "2001.09955", "submitter": "Sandipan Sikdar", "authors": "Sandipan Sikdar, Rachneet Singh Sachdeva, Johannes Wachs, Florian\n  Lemmerich and Markus Strohmaier", "title": "The Effects of Gender Signals and Performance in Online Product Reviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work quantifies the effects of signaling and performing gender on the\nsuccess of reviews written on the popular amazon shopping platform. Highly\nrated reviews play an important role in e-commerce since they are prominently\ndisplayed below products. Differences in how gender-signaling and\ngender-performing review authors are received can lead to important biases in\nwhat content and perspectives are represented among top reviews. To investigate\nthis, we extract signals of author gender from user names, distinguishing\nreviews where the author's likely gender can be inferred. Using reviews\nauthored by these gender-signaling authors, we train a deep-learning classifier\nto quantify the gendered writing style or gendered performance of reviews\nwritten by authors who do not send clear gender signals via their user name. We\ncontrast the effects of gender signaling and performance on review success\nusing matching experiments. While we find no general trend that gendered\nsignals or performances influence overall review success, we find strong\ncontext-specific effects. For example, reviews in product categories such as\nElectronics or Computers are perceived as less helpful when authors signal that\nthey are likely woman, but are received as more helpful in categories such as\nBeauty or Clothing. In addition to these interesting findings, our work\nprovides a general chain of tools for studying gender-specific effects across\nvarious social media platforms.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:20:51 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 09:32:36 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Sikdar", "Sandipan", ""], ["Sachdeva", "Rachneet Singh", ""], ["Wachs", "Johannes", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2001.10173", "submitter": "Araz Taeihagh", "authors": "Si Ying Tan, Araz Taeihagh", "title": "Smart City Governance in Developing Countries: A Systematic Literature\n  Review", "comments": null, "journal-ref": "Sustainability 2020, 12(3), 899", "doi": "10.3390/su12030899", "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart cities that make broad use of digital technologies have been touted as\npossible solutions for the population pressures faced by many cities in\ndeveloping countries and may help meet the rising demand for services and\ninfrastructure. Nevertheless, the high financial cost involved in\ninfrastructure maintenance, the substantial size of the informal economies, and\nvarious governance challenges are curtailing government idealism regarding\nsmart cities. This review examines the state of smart city development in\ndeveloping countries, which includes understanding the conceptualisations,\nmotivations, and unique drivers behind (and barriers to) smarty city\ndevelopment. A total of 56 studies were identified from a systematic literature\nreview from an initial pool of 3928 social sciences literature identified from\ntwo academic databases. Data were analysed using thematic synthesis and\nthematic analysis. The review found that technology-enabled smart cities in\ndeveloping countries can only be realised when concurrent socioeconomic, human,\nlegal, and regulatory reforms are instituted. Governments need to step up their\nefforts to fulfil the basic infrastructure needs of citizens, raise more\nrevenue, construct clear regulatory frameworks to mitigate the technological\nrisks involved, develop human capital, ensure digital inclusivity, and promote\nenvironmental sustainability. A supportive ecosystem that encourages citizen\nparticipation, nurtures start-ups, and promotes public-private partnerships\nneeds to be created to realise their smart city vision.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 05:24:38 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Tan", "Si Ying", ""], ["Taeihagh", "Araz", ""]]}, {"id": "2001.10256", "submitter": "Tiziano Piccardi", "authors": "Blagoj Mitrevski, Tiziano Piccardi, Robert West", "title": "WikiHist.html: English Wikipedia's Full Revision History in HTML Format", "comments": "Dataset paper, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikipedia is written in the wikitext markup language. When serving content,\nthe MediaWiki software that powers Wikipedia parses wikitext to HTML, thereby\ninserting additional content by expanding macros (templates and mod-ules).\nHence, researchers who intend to analyze Wikipediaas seen by its readers should\nwork with HTML, rather than wikitext. Since Wikipedia's revision history is\npublicly available exclusively in wikitext format, researchers have had to\nproduce HTML themselves, typically by using Wikipedia's REST API for ad-hoc\nwikitext-to-HTML parsing. This approach, however, (1) does not scale to very\nlarge amounts ofdata and (2) does not correctly expand macros in historical\narticle revisions. We solve these problems by developing a parallelized\narchitecture for parsing massive amounts of wikitext using local instances of\nMediaWiki, enhanced with the capacity of correct historical macro expansion. By\ndeploying our system, we produce and release WikiHist.html, English Wikipedia's\nfull revision history in HTML format. We highlight the advantages of\nWikiHist.html over raw wikitext in an empirical analysis of Wikipedia's\nhyperlinks, showing that over half of the wiki links present in HTML are\nmissing from raw wikitext and that the missing links are important for user\nnavigation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 10:44:43 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 11:21:10 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 17:21:28 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Mitrevski", "Blagoj", ""], ["Piccardi", "Tiziano", ""], ["West", "Robert", ""]]}, {"id": "2001.10285", "submitter": "Rion Brattig Correia", "authors": "Rion Brattig Correia and Ian B. Wood and Johan Bollen and Luis M.\n  Rocha", "title": "Mining social media data for biomedical signals and health-related\n  behavior", "comments": "To appear in the Annual Review of Biomedical Data Science", "journal-ref": "Annual Review of Biomedical Data Science, 3:1 (2020)", "doi": "10.1146/annurev-biodatasci-030320-040844", "report-no": null, "categories": "cs.CY cs.SI q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media data has been increasingly used to study biomedical and\nhealth-related phenomena. From cohort level discussions of a condition to\nplanetary level analyses of sentiment, social media has provided scientists\nwith unprecedented amounts of data to study human behavior and response\nassociated with a variety of health conditions and medical treatments. Here we\nreview recent work in mining social media for biomedical, epidemiological, and\nsocial phenomena information relevant to the multilevel complexity of human\nhealth. We pay particular attention to topics where social media data analysis\nhas shown the most progress, including pharmacovigilance, sentiment analysis\nespecially for mental health, and other areas. We also discuss a variety of\ninnovative uses of social media data for health-related applications and\nimportant limitations in social media data access and use.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 12:08:22 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Correia", "Rion Brattig", ""], ["Wood", "Ian B.", ""], ["Bollen", "Johan", ""], ["Rocha", "Luis M.", ""]]}, {"id": "2001.10289", "submitter": "Serena Tardelli", "authors": "Leonardo Nizzoli, Serena Tardelli, Marco Avvenuti, Stefano Cresci,\n  Maurizio Tesconi and Emilio Ferrara", "title": "Charting the Landscape of Online Cryptocurrency Manipulation", "comments": null, "journal-ref": "IEEE Access 8, 2020", "doi": "10.1109/ACCESS.2020.3003370", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrencies represent one of the most attractive markets for financial\nspeculation. As a consequence, they have attracted unprecedented attention on\nsocial media. Besides genuine discussions and legitimate investment\ninitiatives, several deceptive activities have flourished. In this work, we\nchart the online cryptocurrency landscape across multiple platforms. To reach\nour goal, we collected a large dataset, composed of more than 50M messages\npublished by almost 7M users on Twitter, Telegram and Discord, over three\nmonths. We performed bot detection on Twitter accounts sharing invite links to\nTelegram and Discord channels, and we discovered that more than 56% of them\nwere bots or suspended accounts. Then, we applied topic modeling techniques to\nTelegram and Discord messages, unveiling two different deception schemes -\n\"pump-and-dump\" and \"Ponzi\" - and identifying the channels involved in these\nfrauds. Whereas on Discord we found a negligible level of deception, on\nTelegram we retrieved 296 channels involved in pump-and-dump and 432 involved\nin Ponzi schemes, accounting for a striking 20% of the total. Moreover, we\nobserved that 93% of the invite links shared by Twitter bots point to Telegram\npump-and-dump channels, shedding light on a little-known social bot activity.\nCharting the landscape of online cryptocurrency manipulation can inform\nactionable policies to fight such abuse.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 12:19:09 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Nizzoli", "Leonardo", ""], ["Tardelli", "Serena", ""], ["Avvenuti", "Marco", ""], ["Cresci", "Stefano", ""], ["Tesconi", "Maurizio", ""], ["Ferrara", "Emilio", ""]]}, {"id": "2001.10581", "submitter": "M\\'arcio Silva", "authors": "M\\'arcio Silva, Lucas Santos de Oliveira, Athanasios Andreou, Pedro\n  Olmo Vaz de Melo, Oana Goga and Fabr\\'icio Benevenuto", "title": "Facebook Ads Monitor: An Independent Auditing System for Political Ads\n  on Facebook", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2016 United States presidential election was marked by the abuse of\ntargeted advertising on Facebook. Concerned with the risk of the same kind of\nabuse to happen in the 2018 Brazilian elections, we designed and deployed an\nindependent auditing system to monitor political ads on Facebook in Brazil. To\ndo that we first adapted a browser plugin to gather ads from the timeline of\nvolunteers using Facebook. We managed to convince more than 2000 volunteers to\nhelp our project and install our tool. Then, we use a Convolution Neural\nNetwork (CNN) to detect political Facebook ads using word embeddings. To\nevaluate our approach, we manually label a data collection of 10k ads as\npolitical or non-political and then we provide an in-depth evaluation of\nproposed approach for identifying political ads by comparing it with classic\nsupervised machine learning methods. Finally, we deployed a real system that\nshows the ads identified as related to politics. We noticed that not all\npolitical ads we detected were present in the Facebook Ad Library for political\nads. Our results emphasize the importance of enforcement mechanisms for\ndeclaring political ads and the need for independent auditing platforms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 20:34:06 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 13:26:33 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Silva", "M\u00e1rcio", ""], ["de Oliveira", "Lucas Santos", ""], ["Andreou", "Athanasios", ""], ["de Melo", "Pedro Olmo Vaz", ""], ["Goga", "Oana", ""], ["Benevenuto", "Fabr\u00edcio", ""]]}, {"id": "2001.10589", "submitter": "Mahdi Miraz", "authors": "Mahdi H. Miraz and Maaruf Ali", "title": "Blockchain Enabled Smart Contract Based Applications: Deficiencies with\n  the Software Development Life Cycle Models", "comments": null, "journal-ref": "Baltica Journal, Vol. 33, Issue 1, 20th January 2020, ISSN:\n  0067-3064, pp. 101-116, Available:\n  http://www.balticajournal.com/baltica/index.php/jTracker/index/IL1qQ", "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent popularity of Blockchain and other Distributed Ledger\nTechnologies (DLT), blockchain enabled smart contract applications has\nattracted increased research focus. However, the immutability of the blocks,\nwhere the smart contracts are stored, causes conflicts with the traditional\nSoftware Development Life Cycle (SDLC) models usually followed by software\nengineers. This clearly shows the unsuitability of the application of SDLC in\ndesigning blockchain enabled smart contract based applications. This research\narticle addresses this current problem by first exploring the six traditional\nSDLC models, clearly identifying the conflicts in a table with the application\nof smart contracts and advocates that there is an urgent need to develop new\nstandard model(s) to address the arising issues. The concept of both block\nimmutability and contract is introduced. This is further set in a historical\ncontext from legacy smart contracts and blockchain enabled smart contracts\nextending to the difference between \"shallow smart contracts\" and \"deep smart\ncontracts\". To conclude, the traditional SDLC models are unsuitable for\nblockchain enabled smart contract-based applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 03:48:46 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Miraz", "Mahdi H.", ""], ["Ali", "Maaruf", ""]]}, {"id": "2001.10608", "submitter": "Noah Apthorpe", "authors": "Noah Apthorpe, Pardis Emami-Naeini, Arunesh Mathur, Marshini Chetty,\n  Nick Feamster", "title": "You, Me, and IoT: How Internet-Connected Consumer Devices Affect\n  Interpersonal Relationships", "comments": "26 pages, 5 figures, 5 tables. Updated version with additional\n  examples and minor revisions. Original title: \"You, Me, and IoT: How\n  Internet-Connected Home Devices Affect Interpersonal Relationships\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-connected consumer devices have rapidly increased in popularity;\nhowever, relatively little is known about how these technologies are affecting\ninterpersonal relationships in multi-occupant households. In this study, we\nconduct 13 semi-structured interviews and survey 508 individuals from a variety\nof backgrounds to discover and categorize how consumer IoT devices are\naffecting interpersonal relationships in the United States. We highlight\nseveral themes, providing large-scale exploratory data about the pervasiveness\nof interpersonal costs and benefits of consumer IoT devices. These results also\ninform follow-up studies and design priorities for future IoT technologies to\namplify positive and reduce negative interpersonal effects.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 22:03:56 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 19:27:54 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Apthorpe", "Noah", ""], ["Emami-Naeini", "Pardis", ""], ["Mathur", "Arunesh", ""], ["Chetty", "Marshini", ""], ["Feamster", "Nick", ""]]}, {"id": "2001.10613", "submitter": "Juan-Manuel Torres-Moreno", "authors": "Alexandre Nadjem and Juan-Manuel Torres-Moreno and Marc El-B\\`eze and\n  Guillaume Marrel and Beno\\^it Bonte", "title": "Predicting Personalized Academic and Career Roads: First Steps Toward a\n  Multi-Uses Recommender System", "comments": "4 pages, 3 figures, 4 tables", "journal-ref": "Digital Tools & Uses Congress (DTUC '18), pp 1--4, 2018, Paris,\n  France", "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nobody knows what one's do in the future and everyone will have had a\ndifferent answer to the question : how do you see yourself in five years after\nyour current job/diploma? In this paper we introduce concepts, large categories\nof fields of studies or job domains in order to represent the vision of the\nfuture of the user's trajectory. Then, we show how they can influence the\nprediction when proposing him a set of next steps to take.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 11:00:54 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Nadjem", "Alexandre", ""], ["Torres-Moreno", "Juan-Manuel", ""], ["El-B\u00e8ze", "Marc", ""], ["Marrel", "Guillaume", ""], ["Bonte", "Beno\u00eet", ""]]}, {"id": "2001.10615", "submitter": "Karla Saldana Ochoa", "authors": "Diana Alvarez-Marin and Karla Saldana Ochoa", "title": "Indexical Cities: Articulating Personal Models of Urban Preference with\n  Geotagged Data", "comments": "29 pages 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to assess the potential of liking a city or a neighborhood before ever\nhaving been there. The concept of urban quality has until now pertained to\nglobal city ranking, where cities are evaluated under a grid of given\nparameters, or either to empirical and sociological approaches, often\nconstrained by the amount of available information. Using state of the art\nmachine learning techniques and thousands of geotagged satellite and\nperspective images from diverse urban cultures, this research characterizes\npersonal preference in urban spaces and predicts a spectrum of unknown likeable\nplaces for a specific observer. Unlike most urban perception studies, our\nintention is not by any means to provide an objective measure of urban quality,\nbut rather to portray personal views of the city or Cities of Indexes.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 11:00:19 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Alvarez-Marin", "Diana", ""], ["Ochoa", "Karla Saldana", ""]]}, {"id": "2001.10617", "submitter": "Manikandan Ravikiran", "authors": "Manikandan Ravikiran", "title": "Systematic Review of Approaches to Improve Peer Assessment at Scale", "comments": "This is a review assignment, work on progress. Expected to be updated\n  regularly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Peer Assessment is a task of analysis and commenting on student's writing by\npeers, is core of all educational components both in campus and in MOOC's.\nHowever, with the sheer scale of MOOC's & its inherent personalised open ended\nlearning, automatic grading and tools assisting grading at scale is highly\nimportant. Previously we presented survey on tasks of post classification,\nknowledge tracing and ended with brief review on Peer Assessment (PA), with\nsome initial problems. In this review we shall continue review on PA from\nperspective of improving the review process itself. As such rest of this review\nfocus on three facets of PA namely Auto grading and Peer Assessment Tools (we\nshall look only on how peer reviews/auto-grading is carried), strategies to\nhandle Rogue Reviews, Peer Review Improvement using Natural Language\nProcessing. The consolidated set of papers and resources so used are released\nin https://github.com/manikandan-ravikiran/cs6460-Survey-2.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:59:24 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Ravikiran", "Manikandan", ""]]}, {"id": "2001.10622", "submitter": "Jukka Ruohonen", "authors": "Jukka Ruohonen", "title": "A Dip Into a Deep Well: Online Political Advertisements, Valence, and\n  European Electoral Campaigning", "comments": null, "journal-ref": "Proceedings of the 2nd Multidisciplinary International Symposium\n  on Disinformation in Open Online Media (MISDOOM 2020), Leiden (online),\n  Springer, pp. 37-51", "doi": "10.1007/978-3-030-61841-4_3", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online political advertisements have become an important element in electoral\ncampaigning throughout the world. At the same time, concepts such as\ndisinformation and manipulation have emerged as a global concern. Although\nthese concepts are distinct from online political ads and data-driven electoral\ncampaigning, they tend to share a similar trait related to valence, the\nintrinsic attractiveness or averseness of a message. Given this background, the\npaper examines online political ads by using a dataset collected from Google's\ntransparency reports. The examination is framed to the mid-2019 situation in\nEurope, including the European Parliament elections in particular. According to\nthe results based on sentiment analysis of the textual ads displayed via\nGoogle's advertisement machinery, (i) most of the political ads have expressed\npositive sentiments, although these vary greatly between (ii) European\ncountries as well as across (iii) European political parties. In addition to\nthese results, the paper contributes to the timely discussion about data-driven\nelectoral campaigning and its relation to politics and democracy.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 22:33:45 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 12:53:36 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ruohonen", "Jukka", ""]]}, {"id": "2001.10926", "submitter": "Francesco Pierri", "authors": "Francesco Pierri, Alessandro Artoni, Stefano Ceri", "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:14:47 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Pierri", "Francesco", ""], ["Artoni", "Alessandro", ""], ["Ceri", "Stefano", ""]]}, {"id": "2001.10994", "submitter": "Carlos Sarraute PhD", "authors": "Mar\\'ia \\'Oskarsd\\'ottir, Cristi\\'an Bravo, Carlos Sarraute, Bart\n  Baesens, Jan Vanthienen", "title": "Credit Scoring for Good: Enhancing Financial Inclusion with\n  Smartphone-Based Microlending", "comments": "Thirty Ninth International Conference on Information Systems (ICIS),\n  December 14, 2018, San Francisco, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Globally, two billion people and more than half of the poorest adults do not\nuse formal financial services. Consequently, there is increased emphasis on\ndeveloping financial technology that can facilitate access to financial\nproducts for the unbanked. In this regard, smartphone-based microlending has\nemerged as a potential solution to enhance financial inclusion.\n  We propose a methodology to improve the predictive performance of credit\nscoring models used by these applications. Our approach is composed of several\nsteps, where we mostly focus on engineering appropriate features from the user\ndata. Thereby, we construct pseudo-social networks to identify similar people\nand combine complex network analysis with representation learning. Subsequently\nwe build credit scoring models using advanced machine learning techniques with\nthe goal of obtaining the most accurate credit scores, while also taking into\nconsideration ethical and privacy regulations to avoid unfair discrimination. A\nsuccessful deployment of our proposed methodology could improve the performance\nof microlending smartphone applications and help enhance financial wellbeing\nworldwide.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:07:32 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["\u00d3skarsd\u00f3ttir", "Mar\u00eda", ""], ["Bravo", "Cristi\u00e1n", ""], ["Sarraute", "Carlos", ""], ["Baesens", "Bart", ""], ["Vanthienen", "Jan", ""]]}, {"id": "2001.11131", "submitter": "Jason R.C. Nurse Dr", "authors": "Meredydd Williams, Kelvin K. K. Yao, Jason R. C. Nurse", "title": "Developing an Augmented Reality Tourism App through User-Centred Design\n  (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.GR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmented Reality (AR) bridges the gap between the physical and virtual\nworld. Through overlaying graphics on natural environments, users can immerse\nthemselves in a tailored environment. This offers great benefits to mobile\ntourism, where points of interest (POIs) can be annotated on a smartphone\nscreen. While a variety of apps currently exist, usability issues can\ndiscourage users from embracing AR. Interfaces can become cluttered with icons,\nwith POI occlusion posing further challenges. In this paper, we use\nuser-centred design (UCD) to develop an AR tourism app. We solicit requirements\nthrough a synthesis of domain analysis, tourist observation and semi-structured\ninterviews. Whereas previous user-centred work has designed mock-ups, we\niteratively develop a full Android app. This includes overhead maps and route\nnavigation, in addition to a detailed AR browser. The final product is\nevaluated by 20 users, who participate in a tourism task in a UK city. Users\nregard the system as usable and intuitive, and suggest the addition of further\ncustomisation. We finish by critically analysing the challenges of a\nuser-centred methodology.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 23:35:32 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Williams", "Meredydd", ""], ["Yao", "Kelvin K. K.", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "2001.11258", "submitter": "Ashiqur KhudaBukhsh Ashiqur Rahman KhudaBukhsh", "authors": "Ashiqur R. KhudaBukhsh, Shriphani Palakodety, Jaime G. Carbonell", "title": "Harnessing Code Switching to Transcend the Linguistic Barrier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code mixing (or code switching) is a common phenomenon observed in\nsocial-media content generated by a linguistically diverse user-base. Studies\nshow that in the Indian sub-continent, a substantial fraction of social media\nposts exhibit code switching. While the difficulties posed by code mixed\ndocuments to further downstream analyses are well-understood, lending\nvisibility to code mixed documents under certain scenarios may have utility\nthat has been previously overlooked. For instance, a document written in a\nmixture of multiple languages can be partially accessible to a wider audience;\nthis could be particularly useful if a considerable fraction of the audience\nlacks fluency in one of the component languages. In this paper, we provide a\nsystematic approach to sample code mixed documents leveraging a polyglot\nembedding based method that requires minimal supervision. In the context of the\n2019 India-Pakistan conflict triggered by the Pulwama terror attack, we\ndemonstrate an untapped potential of harnessing code mixing for human\nwell-being: starting from an existing hostility diffusing \\emph{hope speech}\nclassifier solely trained on English documents, code mixed documents are\nutilized as a bridge to retrieve \\emph{hope speech} content written in a\nlow-resource but widely used language - Romanized Hindi. Our proposed pipeline\nrequires minimal supervision and holds promise in substantially reducing web\nmoderation efforts.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:25:06 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 02:31:14 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["KhudaBukhsh", "Ashiqur R.", ""], ["Palakodety", "Shriphani", ""], ["Carbonell", "Jaime G.", ""]]}, {"id": "2001.11552", "submitter": "Amir Karami", "authors": "Amir Karami, Cynthia Nicole White, Kayla Ford, Suzanne Swan, Melek\n  Yildiz Spinel", "title": "Unwanted Advances in Higher Education: Uncovering Sexual Harassment\n  Experiences in Academia with Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL cs.CY cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sexual harassment in academia is often a hidden problem because victims are\nusually reluctant to report their experiences. Recently, a web survey was\ndeveloped to provide an opportunity to share thousands of sexual harassment\nexperiences in academia. Using an efficient approach, this study collected and\ninvestigated more than 2,000 sexual harassment experiences to better understand\nthese unwanted advances in higher education. This paper utilized text mining to\ndisclose hidden topics and explore their weight across three variables:\nharasser gender, institution type, and victim's field of study. We mapped the\ntopics on five themes drawn from the sexual harassment literature and found\nthat more than 50% of the topics were assigned to the unwanted sexual attention\ntheme. Fourteen percent of the topics were in the gender harassment theme, in\nwhich insulting, sexist, or degrading comments or behavior was directed towards\nwomen. Five percent of the topics involved sexual coercion (a benefit is\noffered in exchange for sexual favors), 5% involved sex discrimination, and 7%\nof the topics discussed retaliation against the victim for reporting the\nharassment, or for simply not complying with the harasser. Findings highlight\nthe power differential between faculty and students, and the toll on students\nwhen professors abuse their power. While some topics did differ based on type\nof institution, there were no differences between the topics based on gender of\nharasser or field of study. This research can be beneficial to researchers in\nfurther investigation of this paper's dataset, and to policymakers in improving\nexisting policies to create a safe and supportive environment in academia.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 07:37:45 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Karami", "Amir", ""], ["White", "Cynthia Nicole", ""], ["Ford", "Kayla", ""], ["Swan", "Suzanne", ""], ["Spinel", "Melek Yildiz", ""]]}, {"id": "2001.11585", "submitter": "Geoff Boeing", "authors": "Geoff Boeing, Max Besbris, Ariela Schachter, John Kuk", "title": "Housing Search in the Age of Big Data: Smarter Cities or the Same Old\n  Blind Spots?", "comments": null, "journal-ref": null, "doi": "10.1080/10511482.2019.1684336", "report-no": null, "categories": "stat.AP cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Housing scholars stress the importance of the information environment in\nshaping housing search behavior and outcomes. Rental listings have increasingly\nmoved online over the past two decades and, in turn, online platforms like\nCraigslist are now central to the search process. Do these technology platforms\nserve as information equalizers or do they reflect traditional information\ninequalities that correlate with neighborhood sociodemographics? We synthesize\nand extend analyses of millions of US Craigslist rental listings and find they\nsupply significantly different volumes, quality, and types of information in\ndifferent communities. Technology platforms have the potential to broaden,\ndiversify, and equalize housing search information, but they rely on landlord\nbehavior and, in turn, likely will not reach this potential without a\nsignificant redesign or policy intervention. Smart cities advocates hoping to\nbuild better cities through technology must critically interrogate technology\nplatforms and big data for systematic biases.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 22:10:29 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Boeing", "Geoff", ""], ["Besbris", "Max", ""], ["Schachter", "Ariela", ""], ["Kuk", "John", ""]]}, {"id": "2001.11777", "submitter": "Lionel Robert", "authors": "Lionel P. Robert, Rasha Alahmad, Connor Esterwood, Sangmi Kim,\n  Sangseok You, Qiaoning Zhang", "title": "A Review of Personality in Human Robot Interactions", "comments": "70 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personality has been identified as a vital factor in understanding the\nquality of human robot interactions. Despite this the research in this area\nremains fragmented and lacks a coherent framework. This makes it difficult to\nunderstand what we know and identify what we do not. As a result our knowledge\nof personality in human robot interactions has not kept pace with the\ndeployment of robots in organizations or in our broader society. To address\nthis shortcoming, this paper reviews 83 articles and 84 separate studies to\nassess the current state of human robot personality research. This review: (1)\nhighlights major thematic research areas, (2) identifies gaps in the\nliterature, (3) derives and presents major conclusions from the literature and\n(4) offers guidance for future research.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:28:37 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 21:57:37 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Robert", "Lionel P.", ""], ["Alahmad", "Rasha", ""], ["Esterwood", "Connor", ""], ["Kim", "Sangmi", ""], ["You", "Sangseok", ""], ["Zhang", "Qiaoning", ""]]}, {"id": "2001.11810", "submitter": "Antti Knutas", "authors": "Antti Knutas, Andrew Petersen", "title": "The Effect of Civic Knowledge and Attitudes on CS Student Work\n  Preferences", "comments": null, "journal-ref": "In Proceedings of the 19th Koli Calling International Conference\n  on Computing Education Research. ACM. 37, 1-2", "doi": "10.1145/3364510.3366159", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an investigation in the connection between computing students'\ncivic knowledge, attitude, or self-efficacy and their willingness to work on\ncivic technologies. Early results indicate that these factors are related to a\nwillingness to accept government work in technology but not non-profit work\nfocused on civic technologies.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 14:12:11 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Knutas", "Antti", ""], ["Petersen", "Andrew", ""]]}]