[{"id": "1903.00156", "submitter": "Nazgol Tavabi", "authors": "Nazgol Tavabi, Nathan Bartley, Andr\\'es Abeliuk, Sandeep Soni, Emilio\n  Ferrara, Kristina Lerman", "title": "Characterizing Activity on the Deep and Dark Web", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep and darkweb (d2web) refers to limited access web sites that require\nregistration, authentication, or more complex encryption protocols to access\nthem. These web sites serve as hubs for a variety of illicit activities: to\ntrade drugs, stolen user credentials, hacking tools, and to coordinate attacks\nand manipulation campaigns. Despite its importance to cyber crime, the d2web\nhas not been systematically investigated. In this paper, we study a large\ncorpus of messages posted to 80 d2web forums over a period of more than a year.\nWe identify topics of discussion using LDA and use a non-parametric HMM to\nmodel the evolution of topics across forums. Then, we examine the dynamic\npatterns of discussion and identify forums with similar patterns. We show that\nour approach surfaces hidden similarities across different forums and can help\nidentify anomalous events in this rich, heterogeneous data.\n", "versions": [{"version": "v1", "created": "Fri, 1 Mar 2019 05:01:04 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Tavabi", "Nazgol", ""], ["Bartley", "Nathan", ""], ["Abeliuk", "Andr\u00e9s", ""], ["Soni", "Sandeep", ""], ["Ferrara", "Emilio", ""], ["Lerman", "Kristina", ""]]}, {"id": "1903.00663", "submitter": "Eric Monteiro", "authors": "Eric Monteiro and Elena Parmiggiani", "title": "Synthetic Knowing: The Politics of the Internet of Things", "comments": null, "journal-ref": "MIS Quarterly, 2019, vol. 43, no. 1, pp. 167 - 184", "doi": "10.25300/MISQ/2019/13799", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All knowing is material. The challenge for Information Systems (IS) research\nis to specify how knowing is material by drawing on theoretical\ncharacterizations of the digital. Synthetic knowing is knowing informed by\ntheorizing digital materiality. We focus on two defining qualities:\nliquefaction (unhinging digital representations from physical objects,\nqualities, or processes) and open-endedness (extendable and generative). The\nInternet of Things (IoT) is crucial because sensors are vehicles of\nliquefaction. Their expanding scope for real-time seeing, hearing, tasting,\nsmelling, and touching increasingly mimics phenomenologically perceived\nreality. Empirically, we present a longitudinal case study of IoT-rendered\nmarine environmental monitoring by an oil and gas company operating in the\npolitically contested Arctic. We characterize synthetic knowing into four\nconcepts, the former three tied to liquefaction and the latter to\nopen-endedness: (i) the objects of knowing are algorithmic phenomena; (ii) the\nsensors increasingly conjure up phenomenological reality; (iii) knowing is\nscoped (configurable); and (iv) open knowing/data is politically charged.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 09:30:23 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Monteiro", "Eric", ""], ["Parmiggiani", "Elena", ""]]}, {"id": "1903.00713", "submitter": "Paula Fraga-Lamas Dr.", "authors": "Paula Fraga-Lamas, Peio Lopez-Iturri, Mikel Celaya-Echarri, Oscar\n  Blanco-Novoa, Leyre Azpilicueta, Jos\\'e Varela-Barbeito, Francisco Falcone\n  and Tiago M. Fern\\'andez-Caram\\'es", "title": "Design and Validation of a Bluetooth 5 Fog Computing Based Industrial\n  CPS Architecture for Intelligent Industry 4.0 Shipyard Workshops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navantia, one of Europe's largest shipbuilders, is creating a fog\ncomputing-based Industrial Cyber-Physical System (ICPS) for remote monitoring\nin real-time of their pipe workshops. Such a monitoring process, which involves\npipe traceability and tracking, is a unique industrial challenge, given their\nmetallic content, massive quantity and heterogeneous typology, as well as to\nthe number of complex processes involved. Pipe improved location, from\nproduction and through their lifetime, can provide significant productivity and\nsafety benefits to shipyards and foster innovative applications in process\nplanning. Bluetooth 5 represents a cost-effective opportunity to cope with this\nharsh environment, since it has been significantly enhanced in terms of low\npower consumption, range, speed and broadcasting capacity. Thus, this article\nproposes a Bluetooth 5 fog computing-based ICPS architecture that is designed\nto support physically-distributed and low-latency Industry 4.0 applications\nthat off-load network traffic and computational resource consumption from the\ncloud. In order to validate the proposed ICPS design, one of Navantia's pipe\nworkshops has been modeled through an in-house-developed 3D ray launching radio\nplanning simulator that considers three main intrinsic characteristics: the\nnumber of pipes, the main working areas with their corresponding machines, and\nthe daily workforce. The radio propagation results obtained by the simulation\ntool are validated through empirical measurements. These results aim to provide\nguidelines for ICPS developers, network operators and planners to investigate\nfurther complex industrial deployments based on Bluetooth 5.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 14:50:16 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Fraga-Lamas", "Paula", ""], ["Lopez-Iturri", "Peio", ""], ["Celaya-Echarri", "Mikel", ""], ["Blanco-Novoa", "Oscar", ""], ["Azpilicueta", "Leyre", ""], ["Varela-Barbeito", "Jos\u00e9", ""], ["Falcone", "Francisco", ""], ["Fern\u00e1ndez-Caram\u00e9s", "Tiago M.", ""]]}, {"id": "1903.00732", "submitter": "Daniel S. Katz", "authors": "Daniel S. Katz, Kenton McHenry, Caleb Reinking, and Robert Haines", "title": "Research Software Development & Management in Universities: Case Studies\n  from Manchester's RSDS Group, Illinois' NCSA, and Notre Dame's CRC", "comments": "2019 Intl. Work. on Soft. Eng. for Science (SE4Science), May 28,\n  2019, with ICSE'19", "journal-ref": null, "doi": "10.1109/SE4Science.2019.00009", "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern research in the sciences, engineering, humanities, and other fields\ndepends on software, and specifically, research software. Much of this research\nsoftware is developed in universities, by faculty, postdocs, students, and\nstaff. In this paper, we focus on the role of university staff. We examine\nthree different, independently-developed models under which these staff are\norganized and perform their work, and comparatively analyze these models and\ntheir consequences on the staff and on the software, considering how the\ndifferent models support software engineering practices and processes. This\ninformation can be used by software engineering researchers to understand the\npractices of such organizations and by universities who want to set up similar\norganizations and to better produce and maintain research software.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 16:40:54 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Katz", "Daniel S.", ""], ["McHenry", "Kenton", ""], ["Reinking", "Caleb", ""], ["Haines", "Robert", ""]]}, {"id": "1903.00780", "submitter": "Alex Beutel", "authors": "Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Li Wei, Yi Wu, Lukasz\n  Heldt, Zhe Zhao, Lichan Hong, Ed H. Chi, Cristos Goodrow", "title": "Fairness in Recommendation Ranking through Pairwise Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are one of the most pervasive applications of machine\nlearning in industry, with many services using them to match users to products\nor information. As such it is important to ask: what are the possible fairness\nrisks, how can we quantify them, and how should we address them? In this paper\nwe offer a set of novel metrics for evaluating algorithmic fairness concerns in\nrecommender systems. In particular we show how measuring fairness based on\npairwise comparisons from randomized experiments provides a tractable means to\nreason about fairness in rankings from recommender systems. Building on this\nmetric, we offer a new regularizer to encourage improving this metric during\nmodel training and thus improve fairness in the resulting rankings. We apply\nthis pairwise regularization to a large-scale, production recommender system\nand show that we are able to significantly improve the system's pairwise\nfairness.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 22:29:42 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Beutel", "Alex", ""], ["Chen", "Jilin", ""], ["Doshi", "Tulsee", ""], ["Qian", "Hai", ""], ["Wei", "Li", ""], ["Wu", "Yi", ""], ["Heldt", "Lukasz", ""], ["Zhao", "Zhe", ""], ["Hong", "Lichan", ""], ["Chi", "Ed H.", ""], ["Goodrow", "Cristos", ""]]}, {"id": "1903.00831", "submitter": "Sourav Mukherjee", "authors": "Sourav Mukherjee", "title": "How IT allows E-Participation in Policy-Making Process", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": "10.6084/m9.figshare.7796063.v2", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the art and practice of government policy-making, public work, and\ncitizen participation, many governments adopt information and communication\ntechnologies (ICT) as a vehicle to facilitate their relationship with citizens.\nThis participation process is widely known as E-Participation or Electronic\nParticipation. This article focuses on different performance indicators and the\nrelevant tools for each level. Despite the growing scientific and pragmatic\nsignificance of e-participation, that area still was not able to grow as it was\nexpected. Our diverse set of knowledge and e-participation policies and its\nimplementation is very limited. This is the key reason why e-participation\ninitiatives in practice often fall short of expectations. This study collects\nthe existing perceptions from the various interdisciplinary scientific\nliterature to determine a unifying definition and demonstrates the strong\nabilities of e-participation and other related components which have great\npotential in the coming years.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 04:43:40 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 19:48:56 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Mukherjee", "Sourav", ""]]}, {"id": "1903.00934", "submitter": "Jamilu Awwalu", "authors": "Suleiman Adamu, Jamilu Awwalu", "title": "The Role of Artificial Intelligence (AI) in Adaptive eLearning System\n  (AES) Content Formation: Risks and Opportunities involved", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) plays varying roles in supporting both existing\nand emerging technologies. In the area of Learning and Tutoring, it plays key\nrole in Intelligent Tutoring Systems (ITS). The fusion of ITS with Adaptive\nHypermedia and Multimedia (AHAM) form the backbone of Adaptive eLearning\nSystems (AES) which provides personalized experiences to learners. This\nexperience is important because it facilitates the accurate delivery of the\nlearning modules in specific to the learner capacity and readiness. AES types\nvary, with Adaptive Web Based eLearning Systems (AWBES) being the popular type\nbecause of wider access offered by the web technology.The retrieval and\naggregation of contents for any eLearning system is critical whichis determined\nby the relevance of learning material to the needs of the learner.In this\npaper, we discuss components of AES, role of AI in AES content aggregation,\npossible risks and available opportunities.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 16:10:54 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Adamu", "Suleiman", ""], ["Awwalu", "Jamilu", ""]]}, {"id": "1903.01045", "submitter": "Hasan Poonawala", "authors": "Baoyang Song, Hasan Poonawala, Laura Wynter, Sebastien Blandin", "title": "Robust commuter movement inference from connected mobile devices", "comments": "International Conference on Data Mining 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preponderance of connected devices provides unprecedented opportunities\nfor fine-grained monitoring of the public infrastructure. However while\nclassical models expect high quality application-specific data streams, the\npromise of the Internet of Things (IoT) is that of an abundance of disparate\nand noisy datasets from connected devices. In this context, we consider the\nproblem of estimation of the level of service of a city-wide public transport\nnetwork. We first propose a robust unsupervised model for train movement\ninference from wifi traces, via the application of robust clustering methods to\na one dimensional spatio-temporal setting. We then explore the extent to which\nthe demand-supply gap can be estimated from connected devices. We propose a\nclassification model of real-time commuter patterns, including both a batch\ntraining phase and an online learning component. We describe our deployment\narchitecture and assess our system accuracy on a large-scale anonymized dataset\ncomprising more than 10 billion records.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 02:18:31 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Song", "Baoyang", ""], ["Poonawala", "Hasan", ""], ["Wynter", "Laura", ""], ["Blandin", "Sebastien", ""]]}, {"id": "1903.01190", "submitter": "Wolfgang Slany", "authors": "Bernadette Spieler, Libora Oates-Indruchova, Wolfgang Slany", "title": "Female Students in Computer Science Education: Understanding\n  Stereotypes, Negative Impacts, and Positive Motivation", "comments": "22 pages", "journal-ref": null, "doi": "10.1615/JWomenMinorScienEng.2020028567", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although female students engage in coding courses, only a small percentage of\nthem plan to pursue computer science (CS) as a major when choosing a career\npath. Gender differences in interests, sense-of belonging, self-efficacy, and\nengagement in CS are already present at an early age. This article presents an\noverview of gender stereotypes in CS and summarizes negative impressions female\nstudents between 12 and 15 experience during CS classes, as well as influences\nthat may be preventing girls from taking an interest in CS. The study herein\ndraws on a systematic review of 28 peer-reviewed articles published since 2006.\nThe findings of the review point to the existence of the stereotypical image of\na helpless, uninterested, and unhappy \"Girl in Computer Science\". It may be\neven more troubling a construct than that of the geeky, nerdy male counterpart,\nas it is rooted in the notion that women are technologically inept and\nill-suited for CS careers. Thus, girls think they must be naturally\nhyper-intelligent in order to pursue studies in CS, as opposed to motivated,\ninterested, and focused to succeed in those fields. Second, based on the\nreview, suggestions for inclusive CS education were summarized. The authors\nargue that in order to make CS more inclusive for girls, cultural implications,\nas well as stereotypization in CS classrooms and CS education, need to be\nrecognized as harmful. These stereotypes and cultural ideas should be\neliminated by empowering female students through direct encouragement,\nmentoring programs, or girls-only initiatives.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 11:49:20 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 17:28:16 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Spieler", "Bernadette", ""], ["Oates-Indruchova", "Libora", ""], ["Slany", "Wolfgang", ""]]}, {"id": "1903.01209", "submitter": "Hoda Heidari", "authors": "Hoda Heidari, Vedant Nanda, and Krishna P. Gummadi", "title": "On the Long-term Impact of Algorithmic Decision Policies: Effort\n  Unfairness and Feature Segregation through Social Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing notions of algorithmic fairness are one-shot: they ensure some\nform of allocative equality at the time of decision making, but do not account\nfor the adverse impact of the algorithmic decisions today on the long-term\nwelfare and prosperity of certain segments of the population. We take a broader\nperspective on algorithmic fairness. We propose an effort-based measure of\nfairness and present a data-driven framework for characterizing the long-term\nimpact of algorithmic policies on reshaping the underlying population.\nMotivated by the psychological literature on \\emph{social learning} and the\neconomic literature on equality of opportunity, we propose a micro-scale model\nof how individuals may respond to decision-making algorithms. We employ\nexisting measures of segregation from sociology and economics to quantify the\nresulting macro-scale population-level change. Importantly, we observe that\ndifferent models may shift the group-conditional distribution of qualifications\nin different directions. Our findings raise a number of important questions\nregarding the formalization of fairness for decision-making models.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 12:38:00 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 13:15:44 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Heidari", "Hoda", ""], ["Nanda", "Vedant", ""], ["Gummadi", "Krishna P.", ""]]}, {"id": "1903.01333", "submitter": "Michalis Xenos", "authors": "Michalis Xenos, Vasiliki Velli", "title": "A Serious Game for Introducing Software Engineering Ethics to University\n  Students", "comments": null, "journal-ref": "ICL2018, 21st International Conference on Interactive\n  Collaborative Learning, pp. 263-274, Kos, Greece, 25-28 September 2018", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a game based on storytelling, in which the players are\nfaced with ethical dilemmas related to software engineering specific issues.\nThe players' choices have consequences on how the story unfolds and could lead\nto various alternative endings. This Ethics Game was used as a tool to mediate\nthe learning activity and it was evaluated by 144 students during a Software\nEngineering Course on the 2017-2018 academic year. This evaluation was based on\na within-subject pre-post design methodology and provided insights on the\nstudents learning gain (academic performance), as well as on the students'\nperceived educational experience. In addition, it provided the results of the\nstudents' usability evaluation of the Ethics Game. The results indicated that\nthe students did improve their knowledge about software engineering ethics by\nplaying this game. Also, they considered this game to be a useful educational\ntool and of high usability. Female students had statistically significant\nhigher knowledge gain and higher evaluation scores than male students, while no\nstatistically significant differences were measured in groups based on the year\nof study.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 16:26:26 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Xenos", "Michalis", ""], ["Velli", "Vasiliki", ""]]}, {"id": "1903.01396", "submitter": "Tahar Kechadi M", "authors": "Yoan Chabot, Aur\\'elie Bertaux, Christophe Nicollea, Tahar Kechadi", "title": "A complete formalized knowledge representation model for advanced\n  digital forensics timeline analysis", "comments": null, "journal-ref": "Digital Investigation Volume 11, Supplement 2, August 2014, Pages\n  S95-S105", "doi": "10.1016/j.diin.2014.05.009", "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Having a clear view of events that occurred over time is a difficult\nobjective to achieve in digital investigations (DI). Event reconstruction,\nwhich allows investigators to understand the timeline of a crime, is one of the\nmost important step of a DI process. This complex task requires exploration of\na large amount of events due to the pervasiveness of new technologies nowadays.\nAny evidence produced at the end of the investigative process must also meet\nthe requirements of the courts, such as reproducibility, verifiability,\nvalidation, etc. For this purpose, we propose a new methodology, supported by\ntheoretical concepts, that can assist investigators through the whole process\nincluding the construction and the interpretation of the events describing the\ncase. The proposed approach is based on a model which integrates knowledge of\nexperts from the fields of digital forensics and software development to allow\na semantically rich representation of events related to the incident. The main\npurpose of this model is to allow the analysis of these events in an automatic\nand efficient way. This paper describes the approach and then focuses on the\nmain conceptual and formal aspects: a formal incident modelization and\noperators for timeline reconstruction and analysis.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 13:25:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Chabot", "Yoan", ""], ["Bertaux", "Aur\u00e9lie", ""], ["Nicollea", "Christophe", ""], ["Kechadi", "Tahar", ""]]}, {"id": "1903.01403", "submitter": "Daniel Crawl", "authors": "Ilkay Altintas, Shweta Purawat, Daniel Crawl, Alok Singh, Kyle Marcus", "title": "Towards A Methodology and Framework for Workflow-Driven Team Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific workflows are powerful tools for management of scalable\nexperiments, often composed of complex tasks running on distributed resources.\nExisting cyberinfrastructure provides components that can be utilized within\nrepeatable workflows. However, data and computing advances continuously change\nthe way scientific workflows get developed and executed, pushing the scientific\nactivity to be more data-driven, heterogeneous and collaborative. Workflow\ndevelopment today depends on the effective collaboration and communication of a\ncross-disciplinary team, not only with humans but also with analytical systems\nand infrastructure. This paper presents a collaboration-centered reference\narchitecture to extend workflow systems with dynamic, predictable and\nprogrammable interfaces to systems and infrastructure while bridging the\nexploratory and scalable activities in the scientific process. We also present\na conceptual design towards the development of methodologies and tools for\neffective workflow-driven collaborations, namely the PPoDS methodology and the\nSmartFlows Toolkit for smart utilization of workflows in a rapidly evolving\ncyberinfrastructure ecosystem.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 21:46:49 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Altintas", "Ilkay", ""], ["Purawat", "Shweta", ""], ["Crawl", "Daniel", ""], ["Singh", "Alok", ""], ["Marcus", "Kyle", ""]]}, {"id": "1903.01406", "submitter": "Peter Snyder", "authors": "Panagiotis Papadopoulos and Peter Snyder and Dimitrios Athanasakis and\n  Benjamin Livshits", "title": "Keeping out the Masses: Understanding the Popularity and Implications of\n  Internet Paywalls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Funding the production of quality online content is a pressing problem for\ncontent producers. The most common funding method, online advertising, is rife\nwith well-known performance and privacy harms, and an intractable subject-agent\nconflict: many users do not want to see advertisements, depriving the site of\nneeded funding.\n  Because of these negative aspects of advertisement-based funding, paywalls\nare an increasingly popular alternative for websites. This shift to a\n\"pay-for-access\" web is one that has potentially huge implications for the web\nand society. Instead of a system where information (nominally) flows freely,\npaywalls create a web where high quality information is available to fewer and\nfewer people, leaving the rest of the web users with less information, that\nmight be also less accurate and of lower quality. Despite the potential\nsignificance of a move from an \"advertising-but-open\" web to a \"paywalled\" web,\nwe find this issue understudied.\n  This work addresses this gap in our understanding by measuring how widely\npaywalls have been adopted, what kinds of sites use paywalls, and the\ndistribution of policies enforced by paywalls. A partial list of our findings\ninclude that (i) paywall use is accelerating (2x more paywalls every 6 months),\n(ii) paywall adoption differs by country (e.g. 18.75% in US, 12.69% in\nAustralia), (iii) paywalls change how users interact with sites (e.g. higher\nbounce rates, less incoming links), (iv) the median cost of an annual paywall\naccess is $108 per site, and (v) paywalls are in general trivial to circumvent.\n  Finally, we present the design of a novel, automated system for detecting\nwhether a site uses a paywall, through the combination of runtime browser\ninstrumentation and repeated programmatic interactions with the site. We intend\nthis classifier to augment future, longitudinal measurements of paywall use and\nbehavior.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 22:04:03 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 16:23:06 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 19:13:14 GMT"}, {"version": "v4", "created": "Thu, 7 May 2020 15:14:55 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Papadopoulos", "Panagiotis", ""], ["Snyder", "Peter", ""], ["Athanasakis", "Dimitrios", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1903.01704", "submitter": "Hiroshi Hayano", "authors": "Hiroshi Hayano, Masanori Takano, Soichiro Morishita, Mitsuo Yoshida,\n  Kyoji Umemura", "title": "Analysis of the Influence of Internet TV Station on Wikipedia Page Views", "comments": "The 3rd International Workshop on Application of Big Data for\n  Computational Social Science (ABCSS2018)", "journal-ref": null, "doi": "10.1109/BigData.2018.8622239", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We aim to investigate the influence of television on the web; if the\ninfluence is strong, a viral effect may be expected. In this paper, we focus on\nthe Internet TV station and on Wikipedia use as exploratory behavior on the\nweb. We analyzed the influence of Internet TV station on Wikipedia page views.\nOur aim is to clarify the characteristics of page views as related to Internet\nTV station in order to index outward impact and develop a prediction model. The\nresults indicate that there is a correlation between TV viewership and page\nviews. Moreover we find that the time lag between TV and web gradually reduce\nas broadcasts begin after 9:00; after 23:00, page views tend to be maximized\nduring the broadcast itself. We also differentiate between page views on PC and\non mobile and find that PC pages tend to be accessed more during the daytime.\nIn addition, we consider the number of broadcasts per program, and observe that\nviewership tends to stabilize as the number of broadcasts increases but that\npage views tend to decrease.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:25:24 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Hayano", "Hiroshi", ""], ["Takano", "Masanori", ""], ["Morishita", "Soichiro", ""], ["Yoshida", "Mitsuo", ""], ["Umemura", "Kyoji", ""]]}, {"id": "1903.01728", "submitter": "Xueyao Zhang", "authors": "Xueyao Zhang, Juan Cao, Xirong Li, Qiang Sheng, Lei Zhong, Kai Shu", "title": "Mining Dual Emotion for Fake News Detection", "comments": "Accepted by WWW 2021", "journal-ref": null, "doi": "10.1145/3442381.3450004", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion plays an important role in detecting fake news online. When\nleveraging emotional signals, the existing methods focus on exploiting the\nemotions of news contents that conveyed by the publishers (i.e., publisher\nemotion). However, fake news often evokes high-arousal or activating emotions\nof people, so the emotions of news comments aroused in the crowd (i.e., social\nemotion) should not be ignored. Furthermore, it remains to be explored whether\nthere exists a relationship between publisher emotion and social emotion (i.e.,\ndual emotion), and how the dual emotion appears in fake news. In this paper, we\nverify that dual emotion is distinctive between fake and real news and propose\nDual Emotion Features to represent dual emotion and the relationship between\nthem for fake news detection. Further, we exhibit that our proposed features\ncan be easily plugged into existing fake news detectors as an enhancement.\nExtensive experiments on three real-world datasets (one in English and the\nothers in Chinese) show that our proposed feature set: 1) outperforms the\nstate-of-the-art task-related emotional features; 2) can be well compatible\nwith existing fake news detectors and effectively improve the performance of\ndetecting fake news.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 08:52:33 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 02:47:16 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 17:11:35 GMT"}, {"version": "v4", "created": "Sun, 14 Feb 2021 08:23:51 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Zhang", "Xueyao", ""], ["Cao", "Juan", ""], ["Li", "Xirong", ""], ["Sheng", "Qiang", ""], ["Zhong", "Lei", ""], ["Shu", "Kai", ""]]}, {"id": "1903.01861", "submitter": "Toomas Hinnosaar", "authors": "Marit Hinnosaar, Toomas Hinnosaar, Michael Kummer, Olga Slivko", "title": "Externalities in Knowledge Production: Evidence from a Randomized Field\n  Experiment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY cs.GT q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are there positive or negative externalities in knowledge production? Do\ncurrent contributions to knowledge production increase or decrease the future\ngrowth of knowledge? We use a randomized field experiment, which added relevant\ncontent to some pages in Wikipedia while leaving similar pages unchanged. We\nfind that the addition of content has a negligible impact on the subsequent\nlong-run growth of content. Our results have implications for information\nseeding and incentivizing contributions, implying that additional content does\nnot generate sizable externalities by inspiring nor discouraging future\ncontributions.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 12:17:10 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Hinnosaar", "Marit", ""], ["Hinnosaar", "Toomas", ""], ["Kummer", "Michael", ""], ["Slivko", "Olga", ""]]}, {"id": "1903.02166", "submitter": "Jon McCormack", "authors": "Jon McCormack, Toby Gifford, Patrick Hutchings", "title": "Autonomy, Authenticity, Authorship and Intention in computer generated\n  art", "comments": "Accepted for EvoMUSART 2019: 8th International Conference on\n  Computational Intelligence in Music, Sound, Art and Design. April 2019,\n  Leipzig, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines five key questions surrounding computer generated art.\nDriven by the recent public auction of a work of `AI Art' we selectively\nsummarise many decades of research and commentary around topics of autonomy,\nauthenticity, authorship and intention in computer generated art, and use this\nresearch to answer contemporary questions often asked about art made by\ncomputers that concern these topics. We additionally reflect on whether current\ntechniques in deep learning and Generative Adversarial Networks significantly\nchange the answers provided by many decades of prior research.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 04:06:20 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["McCormack", "Jon", ""], ["Gifford", "Toby", ""], ["Hutchings", "Patrick", ""]]}, {"id": "1903.02618", "submitter": "Yousra Javed", "authors": "Yousra Javed, Boyd Davis, Mohamed Shehab", "title": "Seniors' Media Preference for Receiving Internet Security Information: A\n  Pilot Study", "comments": "5 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing use of Internet by older adults and their low computer\nand Internet security literacy, their susceptibility to online fraud has also\nincreased. This suggests in turn that there are still too few Internet\neducation materials targeting seniors. We take a first step towards developing\ninteractive security information materials for seniors by determining which\nmedia they prefer and can easily comprehend. We studied the reception of two\nmedia, text and audio, as they communicated information about email-based\nphishing attacks. Our preliminary study of 34 seniors shows that the\nparticipants personally preferred the text over the audio. However, the\ncomprehension score was not significantly different for participants who read\nthe phishing training text script as compared to the participants who listened\nto the phishing training audio script.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 21:24:35 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Javed", "Yousra", ""], ["Davis", "Boyd", ""], ["Shehab", "Mohamed", ""]]}, {"id": "1903.02706", "submitter": "Amir Karami", "authors": "Amir Karami, Vishal Shah, Reza Vaezi, Amit Bansal", "title": "Twitter Speaks: A Case of National Disaster Situational Awareness", "comments": "17 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have been faced with a series of natural disasters\ncausing a tremendous amount of financial, environmental, and human losses. The\nunpredictable nature of natural disasters' behavior makes it hard to have a\ncomprehensive situational awareness (SA) to support disaster management. Using\nopinion surveys is a traditional approach to analyze public concerns during\nnatural disasters; however, this approach is limited, expensive, and\ntime-consuming. Luckily the advent of social media has provided scholars with\nan alternative means of analyzing public concerns. Social media enable users\n(people) to freely communicate their opinions and disperse information\nregarding current events including natural disasters. This research emphasizes\nthe value of social media analysis and proposes an analytical framework:\nTwitter Situational Awareness (TwiSA). This framework uses text mining methods\nincluding sentiment analysis and topic modeling to create a better SA for\ndisaster preparedness, response, and recovery. TwiSA has also effectively\ndeployed on a large number of tweets and tracks the negative concerns of people\nduring the 2015 South Carolina flood.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 03:02:00 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Karami", "Amir", ""], ["Shah", "Vishal", ""], ["Vaezi", "Reza", ""], ["Bansal", "Amit", ""]]}, {"id": "1903.03019", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Matt Dixon, Nalin Asanka Gamagedara Arachchilage, James Nicholson", "title": "Engaging Users with Educational Games: The Case of Phishing", "comments": "4", "journal-ref": "CHI '19 Extended Abstracts on Human Factors in Computing Systems\n  Proceedings (CHI 2019), 2019", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing continues to be a difficult problem for individuals and\norganisations. Educational games and simulations have been increasingly\nacknowledged as enormous and powerful teaching tools, yet little work has\nexamined how to engage users with these games. We explore this problem by\nconducting workshops with 9 younger adults and reporting on their expectations\nfor cybersecurity educational games. We find a disconnect between casual and\nserious gamers, where casual gamers prefer simple games incorporating humour\nwhile serious gamers demand a congruent narrative or storyline. Importantly,\nboth demographics agree that educational games should prioritise gameplay over\ninformation provision - i.e. the game should be a game with educational\ncontent. We discuss the implications for educational games developers.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 16:12:14 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Dixon", "Matt", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""], ["Nicholson", "James", ""]]}, {"id": "1903.03171", "submitter": "Scott H. Hawley", "authors": "Scott H. Hawley", "title": "Challenges for an Ontology of Artificial Intelligence", "comments": "20 pages, accepted for publication in Journal of the American\n  Scientific Affiliation. In press, expected publication March 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Of primary importance in formulating a response to the increasing prevalence\nand power of artificial intelligence (AI) applications in society are questions\nof ontology. Questions such as: What \"are\" these systems? How are they to be\nregarded? How does an algorithm come to be regarded as an agent? We discuss\nthree factors which hinder discussion and obscure attempts to form a clear\nontology of AI: (1) the various and evolving definitions of AI, (2) the\ntendency for pre-existing technologies to be assimilated and regarded as\n\"normal,\" and (3) the tendency of human beings to anthropomorphize. This list\nis not intended as exhaustive, nor is it seen to preclude entirely a clear\nontology, however, these challenges are a necessary set of topics for\nconsideration. Each of these factors is seen to present a 'moving target' for\ndiscussion, which poses a challenge for both technical specialists and\nnon-practitioners of AI systems development (e.g., philosophers and\ntheologians) to speak meaningfully given that the corpus of AI structures and\ncapabilities evolves at a rapid pace. Finally, we present avenues for moving\nforward, including opportunities for collaborative synthesis for scholars in\nphilosophy and science.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 19:30:56 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Hawley", "Scott H.", ""]]}, {"id": "1903.03189", "submitter": "Stephen Cranefield", "authors": "Stephen Cranefield and Frank Dignum", "title": "Incorporating social practices in BDI agent systems", "comments": "An extended abstract of this paper has been accepted for the\n  Eighteenth International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When agents interact with humans, either through embodied agents or because\nthey are embedded in a robot, it would be easy if they could use fixed\ninteraction protocols as they do with other agents. However, people do not keep\nfixed protocols in their day-to-day interactions and the environments are often\ndynamic, making it impossible to use fixed protocols. Deliberating about\ninteractions from fundamentals is not very scalable either, because in that\ncase all possible reactions of a user have to be considered in the plans. In\nthis paper we argue that social practices can be used as an inspiration for\ndesigning flexible and scalable interaction mechanisms that are also robust.\nHowever, using social practices requires extending the traditional BDI\ndeliberation cycle to monitor landmark states and perform expected actions by\nleveraging existing plans. We define and implement this mechanism in Jason\nusing a periodically run meta-deliberation plan, supported by a\nmetainterpreter, and illustrate its use in a realistic scenario.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 21:32:27 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Cranefield", "Stephen", ""], ["Dignum", "Frank", ""]]}, {"id": "1903.03219", "submitter": "Sourav Mukherjee", "authors": "Sourav Mukherjee", "title": "Benefits of AWS in Modern Cloud", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": "10.5281/zenodo.2587217", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article gives an overview of the benefits of AWS in the modern cloud.\nCloud computing is performing well in todays World and boosting the ability to\nuse the internet more than ever. Cloud computing gradually developed a method\nto use the benefits of it in most of the organizations. It is very demanding in\nall businesses tasked with improving the quality of service reducing costs as\nthe organization pays for the service only what they consume based on the\nincoming and outgoing traffic.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 23:28:09 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 19:48:39 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Mukherjee", "Sourav", ""]]}, {"id": "1903.03286", "submitter": "Thushari Atapattu", "authors": "Thushari Atapattu, Katrina Falkner, Menasha Thilakaratne, Lavendini\n  Sivaneasharajah, Rangana Jayashanka", "title": "An Identification of Learners' Confusion through Language and Discourse\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The substantial growth of online learning, in particular, Massively Open\nOnline Courses (MOOCs), supports research into the development of better models\nfor effective learning. Learner 'confusion' is among one of the identified\naspects which impacts the overall learning process, and ultimately, course\nattrition. Confusion for a learner is an individual state of bewilderment and\nuncertainty of how to move forward. The majority of recent works neglect the\n'individual' factor and measure the influence of community-related aspects\n(e.g. votes, views) for confusion classification. While this is a useful\nmeasure, as the popularity of one's post can indicate that many other students\nhave similar confusion regarding course topics, these models neglect the\npersonalised context, such as individual's affect or emotions. Certain\nphysiological aspects (e.g. facial expressions, heart rate) have been utilised\nto classify confusion in small to medium classrooms. However, these techniques\nare challenging to adopt to MOOCs. To bridge this gap, we propose an approach\nsolely based on language and discourse aspects of learners, which outperforms\nthe previous models. We contribute through the development of a novel\nlinguistic feature set that is predictive for confusion classification. We\ntrain the confusion classifier using one domain, successfully applying it\nacross other domains.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 05:03:31 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Atapattu", "Thushari", ""], ["Falkner", "Katrina", ""], ["Thilakaratne", "Menasha", ""], ["Sivaneasharajah", "Lavendini", ""], ["Jayashanka", "Rangana", ""]]}, {"id": "1903.03308", "submitter": "Swati Goel", "authors": "Swati Goel, Ashton Anderson, Leila Zia", "title": "Thanks for Stopping By: A Study of \"Thanks\" Usage on Wikimedia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Thanks feature on Wikipedia, also known as \"Thanks\", is a tool with which\neditors can quickly and easily send one other positive feedback. The aim of\nthis project is to better understand this feature: its scope, the\ncharacteristics of a typical \"Thanks\" interaction, and the effects of receiving\na thank on individual editors. We study the motivational impacts of \"Thanks\"\nbecause maintaining editor engagement is a central problem for crowdsourced\nrepositories of knowledge such as Wikimedia. Our main findings are that most\neditors have not been exposed to the Thanks feature (meaning they have never\ngiven nor received a thank), thanks are typically sent upwards (from less\nexperienced to more experienced editors), and receiving a thank is correlated\nwith having high levels of editor engagement. Though the prevalence of \"Thanks\"\nusage varies by editor experience, the impact of receiving a thank seems mostly\nconsistent for all users. We empirically demonstrate that receiving a thank has\na strong positive effect on short-term editor activity across the board and\nprovide preliminary evidence that thanks could compound to have long-term\neffects as well.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 07:15:36 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Goel", "Swati", ""], ["Anderson", "Ashton", ""], ["Zia", "Leila", ""]]}, {"id": "1903.03375", "submitter": "Javier Borge-Holthoefer", "authors": "Mar\\'ia J. Palazzi, Jordi Cabot, Javier Luis C\\'anovas Izquierdo,\n  Albert Sol\\'e-Ribalta, Javier Borge-Holthoefer", "title": "Online division of labour: emergent structures in Open Source Software", "comments": "11 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development Open Source Software fundamentally depends on the\nparticipation and commitment of volunteer developers to progress. Several works\nhave presented strategies to increase the on-boarding and engagement of new\ncontributors, but little is known on how these diverse groups of developers\nself-organise to work together. To understand this, one must consider that, on\none hand, platforms like GitHub provide a virtually unlimited development\nframework: any number of actors can potentially join to contribute in a\ndecentralised, distributed, remote, and asynchronous manner. On the other,\nhowever, it seems reasonable that some sort of hierarchy and division of labour\nmust be in place to meet human biological and cognitive limits, and also to\nachieve some level of efficiency. These latter features (hierarchy and division\nof labour) should translate into recognisable structural arrangements when\nprojects are represented as developer-file bipartite networks. In this paper we\nanalyse a set of popular open source projects from GitHub, placing the accent\non three key properties: nestedness, modularity and in-block nestedness -which\ntypify the emergence of heterogeneities among contributors, the emergence of\nsubgroups of developers working on specific subgroups of files, and a mixture\nof the two previous, respectively. These analyses show that indeed projects\nevolve into internally organised blocks. Furthermore, the distribution of sizes\nof such blocks is bounded, connecting our results to the celebrated Dunbar\nnumber both in off- and on-line environments. Our analyses create a link\nbetween bio-cognitive constraints, group formation and online working\nenvironments, opening up a rich scenario for future research on (online) work\nteam assembly.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 11:29:56 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Palazzi", "Mar\u00eda J.", ""], ["Cabot", "Jordi", ""], ["Izquierdo", "Javier Luis C\u00e1novas", ""], ["Sol\u00e9-Ribalta", "Albert", ""], ["Borge-Holthoefer", "Javier", ""]]}, {"id": "1903.03414", "submitter": "Bo Zhang", "authors": "Jinyu Yang, Bo Zhang", "title": "Artificial Intelligence in Intelligent Tutoring Robots: A Systematic\n  Review and Design Guidelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study provides a systematic review of the recent advances in designing\nthe intelligent tutoring robot (ITR), and summarises the status quo of applying\nartificial intelligence (AI) techniques. We first analyse the environment of\nthe ITR and propose a relationship model for describing interactions of ITR\nwith the students, the social milieu and the curriculum. Then, we transform the\nrelationship model into the perception-planning-action model for exploring what\nAI techniques are suitable to be applied in the ITR. This article provides\ninsights on promoting human-robot teaching-learning process and AI-assisted\neducational techniques, illustrating the design guidelines and future research\nperspectives in intelligent tutoring robots.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 07:39:58 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Yang", "Jinyu", ""], ["Zhang", "Bo", ""]]}, {"id": "1903.03425", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "The Ethics of AI Ethics -- An Evaluation of Guidelines", "comments": "16 pages, 1 table", "journal-ref": "Minds & Machines, 2020", "doi": "10.1007/s11023-020-09517-8", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current advances in research, development and application of artificial\nintelligence (AI) systems have yielded a far-reaching discourse on AI ethics.\nIn consequence, a number of ethics guidelines have been released in recent\nyears. These guidelines comprise normative principles and recommendations aimed\nto harness the \"disruptive\" potentials of new AI technologies. Designed as a\ncomprehensive evaluation, this paper analyzes and compares these guidelines\nhighlighting overlaps but also omissions. As a result, I give a detailed\noverview of the field of AI ethics. Finally, I also examine to what extent the\nrespective ethical principles and values are implemented in the practice of\nresearch, development and application of AI systems - and how the effectiveness\nin the demands of AI ethics can be improved.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 15:50:35 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 08:44:31 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "1903.03609", "submitter": "Yang Zhang", "authors": "Yang Zhang, Mingming Lu", "title": "Based on Graph-VAE Model to Predict Student's Score", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OECD pointed out that the best way to keep students up to school is to\nintervene as early as possible [1]. Using education big data and deep learning\nto predict student's score provides new resources and perspectives for early\nintervention. Previous forecasting schemes often requires manual filter of\nfeatures , a large amount of prior knowledge and expert knowledge. Deep\nlearning can automatically extract features without manual intervention to\nachieve better predictive performance. In this paper, the graph neural network\nmatrix filling model (Graph-VAE) based on deep learning can automatically\nextract features without a large amount of prior knowledge. The experiment\nproves that our model is better than the traditional solution in the student's\nscore dataset, and it better describes the correlation and difference between\nthe students and the curriculum, and dimensionality reducing the vector of\ncoding result is visualized, the clustering effect is consistent with the real\ndata distribution clustering. In addition, we use gradient-based attribution\nmethods to analyze the key factors that influence performance prediction.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 03:12:46 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zhang", "Yang", ""], ["Lu", "Mingming", ""]]}, {"id": "1903.03683", "submitter": "Julia Stoyanovich", "authors": "Serge Abiteboul, Julia Stoyanovich", "title": "Transparency, Fairness, Data Protection, Neutrality: Data Management\n  Challenges in the Face of New Regulation", "comments": "To appear in the ACM Journal of Data and Information Quality (JDIQ)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data revolution continues to transform every sector of science, industry\nand government. Due to the incredible impact of data-driven technology on\nsociety, we are becoming increasingly aware of the imperative to use data and\nalgorithms responsibly -- in accordance with laws and ethical norms. In this\narticle we discuss three recent regulatory frameworks: the European Union's\nGeneral Data Protection Regulation (GDPR), the New York City Automated\nDecisions Systems (ADS) Law, and the Net Neutrality principle, that aim to\nprotect the rights of individuals who are impacted by data collection and\nanalysis. These frameworks are prominent examples of a global trend:\nGovernments are starting to recognize the need to regulate data-driven\nalgorithmic technology.\n  Our goal in this paper is to bring these regulatory frameworks to the\nattention of the data management community, and to underscore the technical\nchallenges they raise and which we, as a community, are well-equipped to\naddress. The main take-away of this article is that legal and ethical norms\ncannot be incorporated into data-driven systems as an afterthought. Rather, we\nmust think in terms of responsibility by design, viewing it as a systems\nrequirement.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 22:12:12 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Abiteboul", "Serge", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "1903.03695", "submitter": "Ashwini Tonge", "authors": "Ashwini Tonge and Cornelia Caragea", "title": "Image Privacy Prediction Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Images today are increasingly shared online on social networking sites such\nas Facebook, Flickr, Foursquare, and Instagram. Despite that current social\nnetworking sites allow users to change their privacy preferences, this is often\na cumbersome task for the vast majority of users on the Web, who face\ndifficulties in assigning and managing privacy settings. Thus, automatically\npredicting images' privacy to warn users about private or sensitive content\nbefore uploading these images on social networking sites has become a necessity\nin our current interconnected world.\n  In this paper, we explore learning models to automatically predict\nappropriate images' privacy as private or public using carefully identified\nimage-specific features. We study deep visual semantic features that are\nderived from various layers of Convolutional Neural Networks (CNNs) as well as\ntextual features such as user tags and deep tags generated from deep CNNs.\nParticularly, we extract deep (visual and tag) features from four pre-trained\nCNN architectures for object recognition, i.e., AlexNet, GoogLeNet, VGG-16, and\nResNet, and compare their performance for image privacy prediction. Results of\nour experiments on a Flickr dataset of over thirty thousand images show that\nthe learning models trained on features extracted from ResNet outperform the\nstate-of-the-art models for image privacy prediction. We further investigate\nthe combination of user tags and deep tags derived from CNN architectures using\ntwo settings: (1) SVM on the bag-of-tags features; and (2) text-based CNN. Our\nresults show that even though the models trained on the visual features perform\nbetter than those trained on the tag features, the combination of deep visual\nfeatures with image tags shows improvements in performance over the individual\nfeature sets.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 23:12:12 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Tonge", "Ashwini", ""], ["Caragea", "Cornelia", ""]]}, {"id": "1903.03851", "submitter": "Dmitry Namiot", "authors": "Dmitry Namiot, Oleg Pokusaev, Vasily Kupriyanovsky", "title": "Analysis of the use of smart cards on the urban railway", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article analyzes the patterns of use of railway stations in the Moscow\nregion. The basis for the analysis is the data of smart cards on the entrances\nand exits of passengers. The technical tool is time series similarity analysis.\nAs a result, the work identifies the main patterns of user behavior on the use\nof railway stations (railway transport). The results of the work were used in\nthe design of new lines of urban railways. Obviously, the use patterns reflect\nthe current state of the transport system and the urban environment.\nAccordingly, the recorded changes in usage patterns can serve as indicators and\nmetrics for changes in the urban environment.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 18:56:00 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Namiot", "Dmitry", ""], ["Pokusaev", "Oleg", ""], ["Kupriyanovsky", "Vasily", ""]]}, {"id": "1903.04102", "submitter": "Meir Friedenberg", "authors": "Meir Friedenberg, Joseph Y. Halpern", "title": "Blameworthiness in Multi-Agent Settings", "comments": "Appears in AAAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a formal definition of blameworthiness in settings where multiple\nagents can collaborate to avoid a negative outcome. We first provide a method\nfor ascribing blameworthiness to groups relative to an epistemic state (a\ndistribution over causal models that describe how the outcome might arise). We\nthen show how we can go from an ascription of blameworthiness for groups to an\nascription of blameworthiness for individuals using a standard notion from\ncooperative game theory, the Shapley value. We believe that getting a good\nnotion of blameworthiness in a group setting will be critical for designing\nautonomous agents that behave in a moral manner.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 02:26:30 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Friedenberg", "Meir", ""], ["Halpern", "Joseph Y.", ""]]}, {"id": "1903.04174", "submitter": "Valdemar \\v{S}v\\'abensk\\'y", "authors": "Valdemar \\v{S}v\\'abensk\\'y, Jan Vykopal", "title": "Gathering Insights from Teenagers' Hacking Experience with Authentic\n  Cybersecurity Tools", "comments": "IEEE FIE 2018 conference, 4 pages, 1 figure, 1 table", "journal-ref": null, "doi": "10.1109/FIE.2018.8658840", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Work-In-Progress Paper for the Innovative Practice Category presents a\nnovel experiment in active learning of cybersecurity. We introduced a new\nworkshop on hacking for an existing science-popularizing program at our\nuniversity. The workshop participants, 28 teenagers, played a cybersecurity\ngame designed for training undergraduates and professionals in penetration\ntesting. Unlike in learning environments that are simplified for young\nlearners, the game features a realistic virtual network infrastructure. This\nallows exploring security tools in an authentic scenario, which is complemented\nby a background story. Our research aim is to examine how young players\napproach using cybersecurity tools by interacting with the professional game. A\npreliminary analysis of the game session showed several challenges that the\nworkshop participants faced. Nevertheless, they reported learning about\nsecurity tools and exploits, and 61% of them reported wanting to learn more\nabout cybersecurity after the workshop. Our results support the notion that\nyoung learners should be allowed more hands-on experience with security topics,\nboth in formal education and informal extracurricular events.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 08:43:44 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["\u0160v\u00e1bensk\u00fd", "Valdemar", ""], ["Vykopal", "Jan", ""]]}, {"id": "1903.04272", "submitter": "Oliver Hohlfeld", "authors": "Helge Reelfs, Timon Mohaupt, Oliver Hohlfeld, Niklas Henckell", "title": "Hashtag Usage in a Geographically-Local Microblogging App", "comments": null, "journal-ref": "WWW Companion 2019 (WWW LocWeb 2019 Workshop)", "doi": "10.1145/3308560.3316537", "report-no": null, "categories": "cs.SI cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies for the first time the usage and propagation of hashtags\nin a new and fundamentally different type of social media that is i) without\nprofiles and ii) location-based to only show nearby posted content. Our study\nis based on analyzing the mobile-only Jodel microblogging app, which has an\nestablished user base in several European countries and Saudi Arabia. All posts\nare user to user anonymous (i.e., no displayed user handles) and are only\ndisplayed in the proximity of the user's location (up to 20 km). It thereby\nforms local communities and opens the question of how information propagates\nwithin and between these communities. We tackle this question by applying\nestablished metrics for Twitter hashtags to a ground-truth data set of Jodel\nposts within Germany that spans three years. We find the usage of hashtags in\nJodel to differ from Twitter; despite embracing local communication in its\ndesign, Jodel hashtags are mostly used country-wide.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 13:06:32 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Reelfs", "Helge", ""], ["Mohaupt", "Timon", ""], ["Hohlfeld", "Oliver", ""], ["Henckell", "Niklas", ""]]}, {"id": "1903.04369", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Max Van Kleek, Omar Santos, Uchenna\n  Ani", "title": "Artificial intelligence in cyber physical systems", "comments": null, "journal-ref": null, "doi": "10.1007/s00146-020-01049-0", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article conducts a literature review of current and future challenges in\nthe use of artificial intelligence (AI) in cyber physical systems. The\nliterature review is focused on identifying a conceptual framework for\nincreasing resilience with AI through automation supporting both, a technical\nand human level. The methodology applied resembled a literature review and\ntaxonomic analysis of complex internet of things (IoT) interconnected and\ncoupled cyber physical systems. There is an increased attention on propositions\non models, infrastructures and frameworks of IoT in both academic and technical\npapers. These reports and publications frequently represent a juxtaposition of\nother related systems and technologies (e.g. Industrial Internet of Things,\nCyber Physical Systems, Industry 4.0 etc.). We review academic and industry\npapers published between 2010 and 2020. The results determine a new\nhierarchical cascading conceptual framework for analysing the evolution of AI\ndecision-making in cyber physical systems. We argue that such evolution is\ninevitable and autonomous because of the increased integration of connected\ndevices (IoT) in cyber physical systems. To support this argument, taxonomic\nmethodology is adapted and applied for transparency and justifications of\nconcepts selection decisions through building summary maps that are applied for\ndesigning the hierarchical cascading conceptual framework.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 15:25:02 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 13:48:26 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Van Kleek", "Max", ""], ["Santos", "Omar", ""], ["Ani", "Uchenna", ""]]}, {"id": "1903.04428", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David C De Roure, Jason RC Nurse, Rafael Mantilla\n  Montalvo, Stacy Cannady, Omar Santos, Peter Burnap, Carsten Maple", "title": "Future developments in standardisation of cyber risk in the Internet of\n  Things (IoT)", "comments": null, "journal-ref": "SN Appl. Sci. 2, 169 (2020)", "doi": "10.1007/s42452-019-1931-0", "report-no": "Radanliev, P., Roure, D. De., R.C. Nurse, J., Montalvo, R.M.,\n  Cannady, S., Santos, O., Maddox, La., Burnap, P., and Maple, C., l. Future\n  developments in standardisation of cyber risk in the Internet of Things\n  (IoT). SN Appl Sci. 2020;(2: 169):1--16", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research article, we explore the use of a design process for adapting\nexisting cyber risk assessment standards to allow the calculation of economic\nimpact from IoT cyber risk. The paper presents a new model that includes a\ndesign process with new risk assessment vectors, specific for IoT cyber risk.\nTo design new risk assessment vectors for IoT, the study applied a range of\nmethodologies, including literature review, empirical study and comparative\nstudy, followed by theoretical analysis and grounded theory. An epistemological\nframework emerges from applying the constructivist grounded theory methodology\nto draw on knowledge from existing cyber risk frameworks, models and\nmethodologies. This framework presents the current gaps in cyber risk standards\nand policies, and defines the design principles of future cyber risk impact\nassessment. The core contribution of the article therefore, being the\npresentation of a new model for impact assessment of IoT cyber risk.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 16:45:02 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 05:39:26 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David C", ""], ["Nurse", "Jason RC", ""], ["Montalvo", "Rafael Mantilla", ""], ["Cannady", "Stacy", ""], ["Santos", "Omar", ""], ["Burnap", "Peter", ""], ["Maple", "Carsten", ""]]}, {"id": "1903.04844", "submitter": "Sudhir Routray", "authors": "Sudhir Routray, Abhishek Javali, Laxmi Sharma, Richa Tengshe, Sutapa\n  Sarkar, and Aritri Ghosh", "title": "Satellite Based IoT for MC Applications", "comments": "6 Pages, 1 Figure, Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years, world has witnessed the ubiquitous applications of\nInternet of things (IoT) for many different scenarios. There are several\ncritical applications where the results are essential and the mission has to be\nsuccessful at any cost. Such applications are well known as mission critical\napplications. These applications are really critical and deal with very serious\nsituations such as disaster management, rescue operations and military\napplications. IoT can provide both accuracy and sustainability in these\napplications. IoT in fact, is suitable for several critical applications\nbecause it can be deployed at locations where human presence is not possible\ndue to the dangers to human life. In such cases, collection of information can\nbe done through IoT sensors and it can be sent directly to the processing hubs.\nThese days we find several mission critical applications where both increased\nreliability and coverage have very high priorities. Hybridization of IoT and\nsatellite networks can be a game changer in these applications. In this\narticle, we present the general features of mission critical IoT and the\nmotivation for connecting it with the satellite networks. Then we present the\nmain deployment related issues of these hybrid networks. We focused on the\nhybridization aspects of narrowband IoT (NBIoT) with the satellite networks.\nBecause NBIoT has the energy efficiency which can make the satellite based IoT\nnetworks sustainable in the long term.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 11:17:59 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Routray", "Sudhir", ""], ["Javali", "Abhishek", ""], ["Sharma", "Laxmi", ""], ["Tengshe", "Richa", ""], ["Sarkar", "Sutapa", ""], ["Ghosh", "Aritri", ""]]}, {"id": "1903.04879", "submitter": "Indraneil Paul Mr.", "authors": "Indraneil Paul, Abhinav Khattar, Shaan Chopra, Ponnurangam Kumaraguru,\n  Manish Gupta", "title": "What sets Verified Users apart? Insights, Analysis and Prediction of\n  Verified Users on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network and publishing platforms, such as Twitter, support the concept\nof a secret proprietary verification process, for handles they deem worthy of\nplatform-wide public interest. In line with significant prior work which\nsuggests that possessing such a status symbolizes enhanced credibility in the\neyes of the platform audience, a verified badge is clearly coveted among public\nfigures and brands. What are less obvious are the inner workings of the\nverification process and what being verified represents. This lack of clarity,\ncoupled with the flak that Twitter received by extending aforementioned status\nto political extremists in 2017, backed Twitter into publicly admitting that\nthe process and what the status represented needed to be rethought.\n  With this in mind, we seek to unravel the aspects of a user's profile which\nlikely engender or preclude verification. The aim of the paper is two-fold:\nFirst, we test if discerning the verification status of a handle from profile\nmetadata and content features is feasible. Second, we unravel the features\nwhich have the greatest bearing on a handle's verification status. We collected\na dataset consisting of profile metadata of all 231,235 verified\nEnglish-speaking users (as of July 2018), a control sample of 175,930\nnon-verified English-speaking users and all their 494 million tweets over a one\nyear collection period. Our proposed models are able to reliably identify\nverification status (Area under curve AUC > 99%). We show that number of public\nlist memberships, presence of neutral sentiment in tweets and an authoritative\nlanguage style are the most pertinent predictors of verification status.\n  To the best of our knowledge, this work represents the first attempt at\ndiscerning and classifying verification worthy users on Twitter.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 12:56:22 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Paul", "Indraneil", ""], ["Khattar", "Abhinav", ""], ["Chopra", "Shaan", ""], ["Kumaraguru", "Ponnurangam", ""], ["Gupta", "Manish", ""]]}, {"id": "1903.05072", "submitter": "Eduardo Graells-Garrido", "authors": "Yerka Freire and Eduardo Graells-Garrido", "title": "Characterization of Local Attitudes Toward Immigration Using Social\n  Media", "comments": "8 pages, accepted at Latin American Web Congress 2019 (co-located\n  with The Web Conference)", "journal-ref": null, "doi": "10.1145/3308560.3316455", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Migration is a worldwide phenomenon that may generate different reactions in\nthe population. Attitudes vary from those that support multiculturalism and\ncommunion between locals and foreigners, to contempt and hatred toward\nimmigrants. Since anti-immigration attitudes are often materialized in acts of\nviolence and discrimination, it is important to identify factors that\ncharacterize these attitudes. However, doing so is expensive and impractical,\nas traditional methods require enormous efforts to collect data. In this paper,\nwe propose to leverage Twitter to characterize local attitudes toward\nimmigration, with a case study on Chile, where immigrant population has\ndrastically increased in recent years. Using semi-supervised topic modeling, we\nsituated 49K users into a spectrum ranging from in-favor to against\nimmigration. We characterized both sides of the spectrum in two aspects: the\nemotions and lexical categories relevant for each attitude, and the discussion\nnetwork structure. We found that the discussion is mostly driven by Haitian\nimmigration; that there are temporal trends in tendency and polarity of\ndiscussion; and that assortative behavior on the network differs with respect\nto attitude. These insights may inform policy makers on how people feel with\nrespect to migration, with potential implications on communication of policy\nand the design of interventions to improve inter-group relations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 17:35:06 GMT"}], "update_date": "2019-03-13", "authors_parsed": [["Freire", "Yerka", ""], ["Graells-Garrido", "Eduardo", ""]]}, {"id": "1903.05112", "submitter": "Kieran Kalair", "authors": "Kieran Kalair and Colm Connaughton", "title": "Empirical analysis of the variability in the flow-density relationship\n  for smart motorways", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental diagram is an assumed functional relationship between traffic\nflow and traffic density. In practice, this relationship is noisy and exhibits\nsignificant statistical variability. On smart motorways, this variability is\nincreased by variable speed limits that are not captured by the fundamental\ndiagram. To study this variability, it is appropriate to consider the joint\nprobability distribution function (pdf) of density and flow. We perform an\nempirical study of the variability in the relationship between flow and density\nusing 74 days of data from 64 sections of London's M25. The objectives are to\ndetermine how much of the variability in the flow-density relationship results\nfrom variable speed limits and to assess whether particular functional forms of\nthe fundamental diagram are systematically preferred. Empirically, the joint\npdf of flow and density is strongly bimodal, illustrating that traffic flows\nare often found in high-density or low-density regimes but rarely in between.\nWe find that the high-density regime is strongly affected by variable speed\nlimits whereas the low-density regime is not. The Daganzo-Newell (triangular)\nmodel of the fundamental diagram systematically fits best to the data. However,\nthe optimal parameters vary with location. Clustering analysis of these\nparameters suggests three qualitatively different types of flow-density\nrelationships applying to different sections of the M25. These clusters have\nnatural interpretations in terms of the frequency and severity of flow\nbreakdown. Accident rates also depend on cluster type suggesting possible links\nto other properties of traffic flows beyond the flow-density relationship.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 18:01:21 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Kalair", "Kieran", ""], ["Connaughton", "Colm", ""]]}, {"id": "1903.05152", "submitter": "Noah Apthorpe", "authors": "Noah Apthorpe, Sarah Varghese, Nick Feamster", "title": "Evaluating the Contextual Integrity of Privacy Regulation: Parents' IoT\n  Toy Privacy Norms Versus COPPA", "comments": "18 pages, 1 table, 4 figures, 2 appendices", "journal-ref": "28th USENIX Security Symposium (2019)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased concern about data privacy has prompted new and updated data\nprotection regulations worldwide. However, there has been no rigorous way to\ntest whether the practices mandated by these regulations actually align with\nthe privacy norms of affected populations. Here, we demonstrate that surveys\nbased on the theory of contextual integrity provide a quantifiable and scalable\nmethod for measuring the conformity of specific regulatory provisions to\nprivacy norms. We apply this method to the U.S. Children's Online Privacy\nProtection Act (COPPA), surveying 195 parents and providing the first data that\nCOPPA's mandates generally align with parents' privacy expectations for\nInternet-connected \"smart\" children's toys. Nevertheless, variations in the\nacceptability of data collection across specific smart toys, information types,\nparent ages, and other conditions emphasize the importance of detailed\ncontextual factors to privacy norms, which may not be adequately captured by\nCOPPA.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:04:25 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Apthorpe", "Noah", ""], ["Varghese", "Sarah", ""], ["Feamster", "Nick", ""]]}, {"id": "1903.05155", "submitter": "Ben Nassi", "authors": "Ben Nassi, Asaf Shabtai, Ryusuke Masuoka, Yuval Elovici", "title": "SoK - Security and Privacy in the Age of Drones: Threats, Challenges,\n  Solution Mechanisms, and Scientific Gaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of drone technology in the past nine years since the first\ncommercial drone was introduced at CES 2010 has caused many individuals and\nbusinesses to adopt drones for various purposes. We are currently living in an\nera in which drones are being used for pizza delivery, the shipment of goods,\nand filming, and they are likely to provide an alternative for transportation\nin the near future. However, drones also pose a significant challenge in terms\nof security and privacy within society (for both individuals and\norganizations), and many drone related incidents are reported on a daily basis.\nThese incidents have called attention to the need to detect and disable drones\nused for malicious purposes and opened up a new area of research and\ndevelopment for academia and industry, with a market that is expected to reach\n$1.85 billion by 2024. While some of the knowledge used to detect UAVs has been\nadopted for drone detection, new methods have been suggested by industry and\nacademia alike to deal with the challenges associated with detecting the very\nsmall and fast flying objects. In this paper, we describe new societal threats\nto security and privacy created by drones, and present academic and industrial\nmethods used to detect and disable drones. We review methods targeted at areas\nthat restrict drone flights and analyze their effectiveness with regard to\nvarious factors (e.g., weather, birds, ambient light, etc.). We present the\nchallenges arising in areas that allow drone flights, introduce the methods\nthat exist for dealing with these challenges, and discuss the scientific gaps\nthat exist in this area. Finally, we review methods used to disable drones,\nanalyze their effectiveness, and present their expected results. Finally, we\nsuggest future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 19:10:40 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Nassi", "Ben", ""], ["Shabtai", "Asaf", ""], ["Masuoka", "Ryusuke", ""], ["Elovici", "Yuval", ""]]}, {"id": "1903.05207", "submitter": "Kailash Chandra", "authors": "Kailash Chandra and Shyamal Suhana Chandra", "title": "Teaching Programming Concepts by Developing Games", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to program could possibly be analogous to acquiring expertise in\nabstract mathematics, which may be boring or dull for a majority of students.\nThus, among the countless options to approach learning coding [1-14], acquiring\nconcepts through game creation could possibly be the most enriching experience\nfor students. Consequently, it is important to select a lucid and familiar game\nfor students. Then, the following step is to choose a language that introduces\nthe basic concepts of object-oriented programming really well. For this paper,\nwe chose the game of Tic-Tac-Toe, which is straight-forward for most people.\nThe programming language chosen here is C++.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:51:19 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Chandra", "Kailash", ""], ["Chandra", "Shyamal Suhana", ""]]}, {"id": "1903.05221", "submitter": "Cristina Turcu", "authors": "Cornel Turcu, Cristina Turcu", "title": "Improving the quality of healthcare through Internet of Things", "comments": "ICT Management for Global Competitiveness and Economic Growth in\n  Emerging Economies (ICTM), Wroclaw, Poland, October 23-24, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to outline how the adoption of Internet of Things (IoT)\nin healthcare can create real economic value and improve the patient\nexperience. Thus, getting the maximum benefits requires understanding both the\nIoT paradigm and the enabling technologies, and how IoT can be applied in the\nfield of healthcare. We will mention some open challenging issues to be\naddressed by the research community, and not only. Besides the real barriers in\nadopting the Internet of Things, there are some advantages regard collecting\nand processing patient data, and monitoring the daily health states of\nindividuals, just to name a few. These aspects could revolutionize the\nhealthcare industry.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 21:20:48 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Turcu", "Cornel", ""], ["Turcu", "Cristina", ""]]}, {"id": "1903.05372", "submitter": "Qianru Zhou", "authors": "Qianru Zhou, Stephen McLaughlin, Alasdair J. G. Gray, Shangbin Wu,\n  Chengxiang Wang", "title": "Lost Silence: An emergency response early detection service through\n  continuous processing of telecommunication data streams", "comments": "15 pages, 4 figures, WSP ISWC 2017 conference", "journal-ref": "ISWC WSP 2017, pp. 33--47", "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection of significant traumatic events, e.g. a terrorist attack or a\nship capsizing, is important to ensure that a prompt emergency response can\noccur. In the modern world telecommunication systems could play a key role in\nensuring a successful emergency response by detecting such incidents through\nsignificant changes in calls and access to the networks. In this paper a\nmethodology is illustrated to detect such incidents immediately (with the delay\nin the order of milliseconds), by processing semantically annotated streams of\ndata in cellular telecommunication systems. In our methodology, live\ninformation about the position and status of phones are encoded as RDF streams.\nWe propose an algorithm that processes streams of RDF annotated\ntelecommunication data to detect abnormality. Our approach is exemplified in\nthe context of a passenger cruise ship capsizing. However, the approach is\nreadily translatable to other incidents. Our evaluation results show that with\na properly chosen window size, such incidents can be detected efficiently and\neffectively.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:24:55 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Zhou", "Qianru", ""], ["McLaughlin", "Stephen", ""], ["Gray", "Alasdair J. G.", ""], ["Wu", "Shangbin", ""], ["Wang", "Chengxiang", ""]]}, {"id": "1903.05376", "submitter": "Lior Rokach", "authors": "Saar Tal, Bracha Shapira, Lior Rokach", "title": "Personal Dynamic Cost-Aware Sensing for Latent Context Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, the usage of mobile devices has gone far beyond simple\nactivities like calling and texting. Today, smartphones contain multiple\nembedded sensors and are able to collect useful sensing data about the user and\ninfer the user's context. The more frequent the sensing, the more accurate the\ncontext. However, continuous sensing results in huge energy consumption,\ndecreasing the battery's lifetime. We propose a novel approach for cost-aware\nsensing when performing continuous latent context detection. The suggested\nmethod dynamically determines user's sensors sampling policy based on three\nfactors: (1) User's last known context; (2) Predicted information loss using\nKL-Divergence; and (3) Sensors' sampling costs. The objective function aims at\nminimizing both sampling cost and information loss. The method is based on\nvarious machine learning techniques including autoencoder neural networks for\nlatent context detection, linear regression for information loss prediction,\nand convex optimization for determining the optimal sampling policy. To\nevaluate the suggested method, we performed a series of tests on real-world\ndata recorded at a high-frequency rate; the data was collected from six mobile\nphone sensors of twenty users over the course of a week. Results show that by\napplying a dynamic sampling policy, our method naturally balances information\nloss and energy consumption and outperforms the static approach.% We compared\nthe performance of our method with another state of the art dynamic sampling\nmethod and demonstrate its consistent superiority in various measures. %Our\nmethods outperformed, and were able to improve we achieved better results in\neither sampling cost or information loss, and in some cases we improved both.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 09:34:43 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Tal", "Saar", ""], ["Shapira", "Bracha", ""], ["Rokach", "Lior", ""]]}, {"id": "1903.05440", "submitter": "Mark Levene", "authors": "Andrius Mudinas and Dell Zhang and Mark Levene", "title": "Market Trend Prediction using Sentiment Analysis: Lessons Learned and\n  Paths Forward", "comments": "10 pages, 4 figues, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial market forecasting is one of the most attractive practical\napplications of sentiment analysis. In this paper, we investigate the potential\nof using sentiment \\emph{attitudes} (positive vs negative) and also sentiment\n\\emph{emotions} (joy, sadness, etc.) extracted from financial news or tweets to\nhelp predict stock price movements. Our extensive experiments using the\n\\emph{Granger-causality} test have revealed that (i) in general sentiment\nattitudes do not seem to Granger-cause stock price changes; and (ii) while on\nsome specific occasions sentiment emotions do seem to Granger-cause stock price\nchanges, the exhibited pattern is not universal and must be looked at on a case\nby case basis. Furthermore, it has been observed that at least for certain\nstocks, integrating sentiment emotions as additional features into the machine\nlearning based market trend prediction model could improve its accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 12:19:45 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Mudinas", "Andrius", ""], ["Zhang", "Dell", ""], ["Levene", "Mark", ""]]}, {"id": "1903.05783", "submitter": "Fatemehsadat Tabei", "authors": "Chae Ho Cho, Fatemehsadat Tabei, Tra Nguyen Phan, Yeesock Kim and Jo\n  Woon Chong", "title": "A Novel Re-Targetable Application Development Platform for Healthcare\n  Mobile Applications", "comments": null, "journal-ref": "International Journal of Computer Science and Software Engineering\n  (IJCSSE), Volume 6, Issue 9,Page: 196-201, September 2017", "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid enhancement of central power unit CPU performance enables the\ndevelopment of computationally-intensive healthcare mobile applications for\nsmartphones and wearable devices. However, computationally intensive mobile\napplications require significant application development time during the\napplication porting procedure when the number of considering target devices\noperating systems OSs is large. In this paper, we propose a novel retargetable\napplication development platform for healthcare mobile applications, which\nreduces application development time with maintaining the performance of the\nalgorithm. Although the number of applications target OSs increases, the amount\nof time required for the code conversion step in the application porting\nprocedure remains constant in the proposed retargetable platform. Experimental\nresults show that our proposed retargetable platform gives reduced application\ndevelopment time compared to the conventional platform with maintaining the\nperformance of the mobile application.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 01:16:30 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Cho", "Chae Ho", ""], ["Tabei", "Fatemehsadat", ""], ["Phan", "Tra Nguyen", ""], ["Kim", "Yeesock", ""], ["Chong", "Jo Woon", ""]]}, {"id": "1903.05872", "submitter": "Markus Schr\\\"oder", "authors": "Markus Schr\\\"oder, Christian Jilek, Andreas Dengel", "title": "Interactive Concept Mining on Personal Data -- Bootstrapping Semantic\n  Services", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic services (e.g. Semantic Desktops) are still afflicted by a cold\nstart problem: in the beginning, the user's personal information sphere, i.e.\nfiles, mails, bookmarks, etc., is not represented by the system. Information\nextraction tools used to kick-start the system typically create 1:1\nrepresentations of the different information items. Higher level concepts, for\nexample found in file names, mail subjects or in the content body of these\nitems, are not extracted. Leaving these concepts out may lead to\nunderperformance, having to many of them (e.g. by making every found term a\nconcept) will clutter the arising knowledge graph with non-helpful relations.\nIn this paper, we present an interactive concept mining approach proposing\nconcept candidates gathered by exploiting given schemata of usual personal\ninformation management applications and analysing the personal information\nsphere using various metrics. To heed the subjective view of the user, a\ngraphical user interface allows to easily rank and give feedback on proposed\nconcept candidates, thus keeping only those actually considered relevant. A\nprototypical implementation demonstrates major steps of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 09:37:53 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Schr\u00f6der", "Markus", ""], ["Jilek", "Christian", ""], ["Dengel", "Andreas", ""]]}, {"id": "1903.06039", "submitter": "Robert Haines", "authors": "Mario Rosado de Souza, Robert Haines, Markel Vigo, Caroline Jay", "title": "What Makes Research Software Sustainable? An Interview Study With\n  Research Software Engineers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software is now a vital scientific instrument, providing the tools for data\ncollection and analysis across disciplines from bioinformatics and\ncomputational physics, to the humanities. The software used in research is\noften home-grown and bespoke: it is constructed for a particular project, and\nrarely maintained beyond this, leading to rapid decay, and frequent\n`reinvention of the wheel'. Understanding how to develop sustainable research\nsoftware, such that it is suitable for future reuse, is therefore of interest\nto both researchers and funders, but how to achieve this remains an open\nquestion. Here we report the results of an interview study examining how\nresearch software engineers -- the people actively developing software in an\nacademic research environment -- subjectively define software sustainability.\nThematic analysis of the data reveals two interacting dimensions:\n\\emph{intrinsic sustainability}, which relates to internal qualities of\nsoftware, such as modularity, encapsulation and testability, and\n\\emph{extrinsic sustainability}, concerning cultural and organisational\nfactors, including how software is resourced, supported and shared. Research\nsoftware engineers believe an increased focus on quality and discoverability\nare key factors in increasing the sustainability of academic research software.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:29:44 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["de Souza", "Mario Rosado", ""], ["Haines", "Robert", ""], ["Vigo", "Markel", ""], ["Jay", "Caroline", ""]]}, {"id": "1903.06045", "submitter": "Mohammed Hadi", "authors": "Mohammed Hadi, Ahmed Lawey, Taisir El-Gorashi, Jaafar Elmirghani", "title": "Using Machine Learning and Big Data Analytics to Prioritize Outpatients\n  in HetNets", "comments": "6 pages, 4 figures, IEEE INFOCOM 2019 accepted conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce machine learning approaches that are used to\nprioritize outpatients (OP) according to their current health state, resulting\nin self-optimizing heterogeneous networks (HetNet) that intelligently adapt\naccording to users' needs. We use a na\\\"ive Bayesian classifier to analyze data\nacquired from OPs' medical records, alongside data from medical Internet of\nThings (IoT) sensors that provide the current state of the OP. We use this\nmachine learning algorithm to calculate the likelihood of a life-threatening\nmedical condition, in this case an imminent stroke. An OP is assigned\nhigh-powered resource blocks (RBs) according to the seriousness of their\ncurrent health state, enabling them to remain connected and send their critical\ndata to the designated medical facility with minimal delay. Using a mixed\ninteger linear programming formulation (MILP), we present two approaches to\noptimizing the uplink side of a HetNet in terms of user-RB assignment: a\nWeighted Sum Rate Maximization (WSRMax) approach and a Proportional Fairness\n(PF) approach. Using these approaches, we illustrate the utility of the\nproposed system in terms of providing reliable connectivity to medical IoT\nsensors, enabling the OPs to maintain the quality and speed of their\nconnection. Moreover, we demonstrate how system response can change according\nto alterations in the OPs' medical conditions.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 14:32:02 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hadi", "Mohammed", ""], ["Lawey", "Ahmed", ""], ["El-Gorashi", "Taisir", ""], ["Elmirghani", "Jaafar", ""]]}, {"id": "1903.06095", "submitter": "Bridget Tenner", "authors": "Bridget Eileen Tenner and Gregory S. Warrington", "title": "Accumulation charts for instant-runoff elections", "comments": "to appear in Notices of the AMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new graphical format for instant-runoff voting election results.\nWe call this proposal an \"accumulation chart.\" This model, a modification of\nstandard bar charts, is easy to understand, clearly indicates the winner,\ndepicts the instant-runoff algorithm, and summarizes the votes cast. Moreover,\nit includes the pedigree of each accumulated vote and gives a clear depiction\nof candidates' coalitions.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 16:06:42 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 16:44:46 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Tenner", "Bridget Eileen", ""], ["Warrington", "Gregory S.", ""]]}, {"id": "1903.06274", "submitter": "Thomais Asvestopoulou", "authors": "Thomais Asvestopoulou, Victoria Manousaki, Antonis Psistakis, Ioannis\n  Smyrnakis, Vassilios Andreadakis, Ioannis M. Aslanides, Maria Papadopouli", "title": "DysLexML: Screening Tool for Dyslexia Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eye movements during text reading can provide insights about reading\ndisorders. Via eye-trackers, we can measure when, where and how eyes move with\nrelation to the words they read. Machine Learning (ML) algorithms can decode\nthis information and provide differential analysis. This work developed\nDysLexML, a screening tool for developmental dyslexia that applies various ML\nalgorithms to analyze fixation points recorded via eye-tracking during silent\nreading of children. It comparatively evaluated its performance using\nmeasurements collected in a systematic field study with 69 native Greek\nspeakers, children, 32 of which were diagnosed as dyslexic by the official\ngovernmental agency for diagnosing learning and reading difficulties in Greece.\nWe examined a large set of features based on statistical properties of\nfixations and saccadic movements and identified the ones with prominent\npredictive power, performing dimensionality reduction. Specifically, DysLexML\nachieves its best performance using linear SVM, with an a accuracy of 97 %,\nwith a small feature set, namely saccade length, number of short forward\nmovements, and number of multiply fixated words. Furthermore, we analyzed the\nimpact of noise on the fixation positions and showed that DysLexML is accurate\nand robust in the presence of noise. These encouraging results set the basis\nfor developing screening tools in less controlled, larger-scale environments,\nwith inexpensive eye-trackers, potentially reaching a larger population for\nearly intervention.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 21:44:52 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Asvestopoulou", "Thomais", ""], ["Manousaki", "Victoria", ""], ["Psistakis", "Antonis", ""], ["Smyrnakis", "Ioannis", ""], ["Andreadakis", "Vassilios", ""], ["Aslanides", "Ioannis M.", ""], ["Papadopouli", "Maria", ""]]}, {"id": "1903.06281", "submitter": "Peter Eckersley", "authors": "Sky Croeser and Peter Eckersley", "title": "Theories of Parenting and their Application to Artificial Intelligence", "comments": null, "journal-ref": "Also in Proc. AI, Ethics and Society 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning (ML) systems have advanced, they have acquired more power\nover humans' lives, and questions about what values are embedded in them have\nbecome more complex and fraught. It is conceivable that in the coming decades,\nhumans may succeed in creating artificial general intelligence (AGI) that\nthinks and acts with an open-endedness and autonomy comparable to that of\nhumans. The implications would be profound for our species; they are now widely\ndebated not just in science fiction and speculative research agendas but\nincreasingly in serious technical and policy conversations.\n  Much work is underway to try to weave ethics into advancing ML research. We\nthink it useful to add the lens of parenting to these efforts, and specifically\nradical, queer theories of parenting that consciously set out to nurture agents\nwhose experiences, objectives and understanding of the world will necessarily\nbe very different from their parents'. We propose a spectrum of principles\nwhich might underpin such an effort; some are relevant to current ML research,\nwhile others will become more important if AGI becomes more likely. These\nprinciples may encourage new thinking about the development, design, training,\nand release into the world of increasingly autonomous agents.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 22:13:14 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Croeser", "Sky", ""], ["Eckersley", "Peter", ""]]}, {"id": "1903.06367", "submitter": "Fang Zhou", "authors": "Fang Zhou, Linyuan L\\\"u, Manuel Sebastian Mariani", "title": "Fast influencers in complex networks", "comments": "Including the appendix, total 21 pages, 15 figures, 1 table, accepted\n  by Communications in Nonlinear Science and Numerical Simulation", "journal-ref": "Communications in Nonlinear Science and Numerical Simulation\n  74,(2019), 69-83", "doi": "10.1016/j.cnsns.2019.01.032", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influential nodes in complex networks are typically defined as those nodes\nthat maximize the asymptotic reach of a spreading process of interest. However,\nfor practical applications such as viral marketing and online information\nspreading, one is often interested in maximizing the reach of the process in a\nshort amount of time. The traditional definition of influencers in\nnetwork-related studies from diverse research fields narrows down the focus to\nthe late-time state of the spreading processes, leaving the following question\nunsolved: which nodes are able to initiate large-scale spreading processes, in\na limited amount of time? Here, we find that there is a fundamental difference\nbetween the nodes -- which we call \"fast influencers\" -- that initiate the\nlargest-reach processes in a short amount of time, and the traditional,\n\"late-time\" influencers. Stimulated by this observation, we provide an\nextensive benchmarking of centrality metrics with respect to their ability to\nidentify both the fast and late-time influencers. We find that local network\nproperties can be used to uncover the fast influencers. In particular, a\nparsimonious, local centrality metric (which we call social capital) achieves\noptimal or nearly-optimal performance in the fast influencer identification for\nall the analyzed empirical networks. Local metrics tend to be also competitive\nin the traditional, late-time influencer identification task.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 05:24:38 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Zhou", "Fang", ""], ["L\u00fc", "Linyuan", ""], ["Mariani", "Manuel Sebastian", ""]]}, {"id": "1903.06469", "submitter": "Dima Kagan", "authors": "Dima Kagan, Thomas Chesney, Michael Fire", "title": "Using Data Science to Understand the Film Industry's Gender Gap", "comments": null, "journal-ref": "Palgrave Commun 6, 92 (2020)", "doi": "10.1057/s41599-020-0436-1", "report-no": null, "categories": "cs.SI cs.CY physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science can offer answers to a wide range of social science questions.\nHere we turn attention to the portrayal of women in movies, an industry that\nhas a significant influence on society, impacting such aspects of life as\nself-esteem and career choice. To this end, we fused data from the online movie\ndatabase IMDb with a dataset of movie dialogue subtitles to create the largest\navailable corpus of movie social networks (15,540 networks). Analyzing this\ndata, we investigated gender bias in on-screen female characters over the past\ncentury. We find a trend of improvement in all aspects of women`s roles in\nmovies, including a constant rise in the centrality of female characters. There\nhas also been an increase in the number of movies that pass the well-known\nBechdel test, a popular--albeit flawed--measure of women in fiction. Here we\npropose a new and better alternative to this test for evaluating female roles\nin movies. Our study introduces fresh data, an open-code framework, and novel\ntechniques that present new opportunities in the research and analysis of\nmovies.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 11:22:56 GMT"}, {"version": "v2", "created": "Sun, 24 Mar 2019 19:04:04 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 16:17:34 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kagan", "Dima", ""], ["Chesney", "Thomas", ""], ["Fire", "Michael", ""]]}, {"id": "1903.06619", "submitter": "Seyyedyousef Oleyaeimotlagh", "authors": "Seyyed Yousef Oleyaei-Motlagh and Adan Ernesto Vela", "title": "Inferring demand from partially observed data to address the mismatch\n  between demand and supply of taxis in the presence of rain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing mismatch in supply and demand of taxis is an important effort to\nunderstand passengers' demand. In this paper, we have analyzed the effect of\nrain on the demand for yellow taxis in city-wide as well as in a point of\ninterest in New York City. Because a pickup event is a realized demand, we\nstudied empty travel time, the number of pickups per driver, the average amount\nof income per drive indices to infer demand from taxis data of 2013. Findings\nhighlight that the higher demand exists because of many short-trips during the\nrain. This paper illustrates the change in passengers' demand increased by the\nonset of weather condition.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 16:04:02 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Oleyaei-Motlagh", "Seyyed Yousef", ""], ["Vela", "Adan Ernesto", ""]]}, {"id": "1903.06640", "submitter": "Genoveva Vargas-Solar", "authors": "G\\'eraldine Castel (ILCEA4), Genoveva Vargas-Solar (ILCEA4), Javier\n  Espinosa-Oviedo (TU Delft)", "title": "Analyzing digital politics: Challenges and experiments in a dual\n  perspective", "comments": "Ing{\\'e}ni{\\'e}rie des Syst{\\`e}mes d'Information, Lavoisier, In\n  press", "journal-ref": null, "doi": "10.3166/RCMA.25.1-n", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social networks have become in the last decade central to political life.\nHowever, to those interested in analysing the communication strategies of\nparties and candidates at election time, the introduction of the Internet into\nthe political sphere has proved a mixed blessing. Indeed, while retrieving,\nconsulting, and archiving original documents pertaining to a specific campaign\nhave become easier, faster, and achievable on a larger scale, thus opening up a\npromising El Dorado for research in this area, studying online campaigns has\nalso inevitably introduced new technical, methodological and legal challenges\nwhich have turned out to be increasingly complex for academics in the\nhumanities and social sciences to solve on their own.This paper therefore\nproposes to provide feedback on experience and experimental validation from a\nmultidisciplinary project called POLIWEB devoted to the comparative analysis of\npolitical campaigns on social media in the run up to the 2014 elections to the\nEuropean Parliament in France and in the United Kingdom. Together with\nobservations from a humanities' perspective on issues related to such a\nproject, this paper also presents experimental results concerning three of the\ndata collection life cycle phases: collection, cleaning, and storage. The\noutcome is a data collection ready to be analysed for various purposes meant to\naddress the political science topic under consideration.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 09:56:18 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Castel", "G\u00e9raldine", "", "ILCEA4"], ["Vargas-Solar", "Genoveva", "", "ILCEA4"], ["Espinosa-Oviedo", "Javier", "", "TU Delft"]]}, {"id": "1903.06675", "submitter": "Bal\\'azs Dobi", "authors": "Bal\\'azs Dobi and Andr\\'as Zempl\\'eni", "title": "Markov Chain-based Cost-Optimal Control Charts for Healthcare Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control charts have traditionally been used in industrial statistics, but are\nconstantly seeing new areas of application, especially in the age of Industry\n4.0. This paper introduces a new method, which is suitable for applications in\nthe healthcare sector, especially for monitoring a health-characteristic of a\npatient. We adapt a Markov chain-based approach and develop a method in which\nnot only the shift size (i.e. the degradation of the patient's health) can be\nrandom, but the effect of the repair (i.e. treatment) and time between\nsamplings (i.e. visits) too. This means that we do not use many often-present\nassumptions which are usually not applicable for medical treatments. The\naverage cost of the protocol, which is determined by the time between samplings\nand the control limit, can be estimated using the stationary distribution of\nthe Markov chain.\n  Furthermore, we incorporate the standard deviation of the cost into the\noptimisation procedure, which is often very important from a process control\nviewpoint. The sensitivity of the optimal parameters and the resulting average\ncost and cost standard deviation on different parameter values is investigated.\nWe demonstrate the usefulness of the approach for real-life data of patients\ntreated in Hungary: namely the monitoring of cholesterol level of patients with\ncardiovascular event risk. The results showed that the optimal parameters from\nour approach can be somewhat different from the original medical parameters.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 13:01:06 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Dobi", "Bal\u00e1zs", ""], ["Zempl\u00e9ni", "Andr\u00e1s", ""]]}, {"id": "1903.06726", "submitter": "Huaxiu Yao", "authors": "Huaxiu Yao, Defu Lian, Yi Cao, Yifan Wu, Tao Zhou", "title": "Predicting Academic Performance for College Students: A Campus Behavior\n  Perspective", "comments": "Accepted by ACM TIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting abnormal behaviors of students in time and providing personalized\nintervention and guidance at the early stage is important in educational\nmanagement. Academic performance prediction is an important building block to\nenabling this pre-intervention and guidance. Most of the previous studies are\nbased on questionnaire surveys and self-reports, which suffer from small sample\nsize and social desirability bias. In this paper, we collect longitudinal\nbehavioral data from 6,597 students' smart cards and propose three major types\nof discriminative behavioral factors, diligence, orderliness, and sleep\npatterns. Empirical analysis demonstrates these behavioral factors are strongly\ncorrelated with academic performance. Furthermore, motivated by social\ninfluence theory, we analyze the correlation between each student's academic\nperformance with his/her behaviorally similar students'. Statistical tests\nindicate this correlation is significant. Based on these factors, we further\nbuild a multi-task predictive framework based on a learning-to-rank algorithm\nfor academic performance prediction. This framework captures inter-semester\ncorrelation, inter-major correlation and integrates student similarity to\npredict students' academic performance. The experiments on a large-scale\nreal-world dataset show the effectiveness of our methods for predicting\nacademic performance and the effectiveness of proposed behavioral factors.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 18:10:00 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Yao", "Huaxiu", ""], ["Lian", "Defu", ""], ["Cao", "Yi", ""], ["Wu", "Yifan", ""], ["Zhou", "Tao", ""]]}, {"id": "1903.06756", "submitter": "Ibrahim AlZuabi", "authors": "Ibrahim Mousa AlZuabi, Assef Jafar and Kadan Aljoumaa", "title": "Predicting customer's gender and age depending on mobile phone data", "comments": null, "journal-ref": null, "doi": "10.1186/s40537-019-0180-9", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of data driven solution, the customer demographic attributes, such\nas gender and age, play a core role that may enable companies to enhance the\noffers of their services and target the right customer in the right time and\nplace. In the marketing campaign, the companies want to target the real user of\nthe GSM (global system for mobile communications), not the line owner. Where\nsometimes they may not be the same. This work proposes a method that predicts\nusers' gender and age based on their behavior, services and contract\ninformation. We used call detail records (CDRs), customer relationship\nmanagement (CRM) and billing information as a data source to analyze telecom\ncustomer behavior, and applied different types of machine learning algorithms\nto provide marketing campaigns with more accurate information about customer\ndemographic attributes. This model is built using reliable data set of 18,000\nusers provided by SyriaTel Telecom Company, for training and testing. The model\napplied by using big data technology and achieved 85.6% accuracy in terms of\nuser gender prediction and 65.5% of user age prediction. The main contribution\nof this work is the improvement in the accuracy in terms of user gender\nprediction and user age prediction based on mobile phone data and end-to-end\nsolution that approaches customer data from multiple aspects in the telecom\ndomain.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 07:46:13 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["AlZuabi", "Ibrahim Mousa", ""], ["Jafar", "Assef", ""], ["Aljoumaa", "Kadan", ""]]}, {"id": "1903.06772", "submitter": "Robert Haines", "authors": "Julio C\\'esar Cort\\'es R\\'ios, Kamilla Kopec-Harding, Sukru Eraslan,\n  Christopher Page, Robert Haines, Caroline Jay, Suzanne M. Embury", "title": "A Methodology for Using GitLab for Software Engineering Learning\n  Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To bridge the digital skills gap, we need to train more people in Software\nEngineering techniques. This paper reports on a project exploring the way\nstudents solve tasks using collaborative development platforms and version\ncontrol systems, such as GitLab, to find patterns and evaluation metrics that\ncan be used to improve the course content and reflect on the most common issues\nthe students are facing. In this paper, we explore Learning Analytics\napproaches that can be used with GitLab and similar tools, and discuss the\nchallenges raised when applying those approaches in Software Engineering\nEducation, with the objective of building a pipeline that supports the full\nLearning Analytics cycle, from data extraction to data analysis. We focus in\nparticular on the data anonymisation step of the proposed pipeline to explore\nthe available alternatives to satisfy the data protection requirements when\nhandling personal information in academic environments for research purposes.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 19:22:28 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["R\u00edos", "Julio C\u00e9sar Cort\u00e9s", ""], ["Kopec-Harding", "Kamilla", ""], ["Eraslan", "Sukru", ""], ["Page", "Christopher", ""], ["Haines", "Robert", ""], ["Jay", "Caroline", ""], ["Embury", "Suzanne M.", ""]]}, {"id": "1903.07021", "submitter": "Adam Poulsen", "authors": "Adam Poulsen, Michael Anderson, Susan L. Anderson, Ben Byford, Fabio\n  Fossa, Erica L. Neely, Alejandro Rosas, Alan Winfield", "title": "Responses to a Critique of Artificial Moral Agents", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of machine ethics is concerned with the question of how to embed\nethical behaviors, or a means to determine ethical behaviors, into artificial\nintelligence (AI) systems. The goal is to produce artificial moral agents\n(AMAs) that are either implicitly ethical (designed to avoid unethical\nconsequences) or explicitly ethical (designed to behave ethically). Van\nWynsberghe and Robbins' (2018) paper Critiquing the Reasons for Making\nArtificial Moral Agents critically addresses the reasons offered by machine\nethicists for pursuing AMA research; this paper, co-authored by machine\nethicists and commentators, aims to contribute to the machine ethics\nconversation by responding to that critique. The reasons for developing AMAs\ndiscussed in van Wynsberghe and Robbins (2018) are: it is inevitable that they\nwill be developed; the prevention of harm; the necessity for public trust; the\nprevention of immoral use; such machines are better moral reasoners than\nhumans, and building these machines would lead to a better understanding of\nhuman morality. In this paper, each co-author addresses those reasons in turn.\nIn so doing, this paper demonstrates that the reasons critiqued are not shared\nby all co-authors; each machine ethicist has their own reasons for researching\nAMAs. But while we express a diverse range of views on each of the six reasons\nin van Wynsberghe and Robbins' critique, we nevertheless share the opinion that\nthe scientific study of AMAs has considerable value.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 03:18:24 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Poulsen", "Adam", ""], ["Anderson", "Michael", ""], ["Anderson", "Susan L.", ""], ["Byford", "Ben", ""], ["Fossa", "Fabio", ""], ["Neely", "Erica L.", ""], ["Rosas", "Alejandro", ""], ["Winfield", "Alan", ""]]}, {"id": "1903.07171", "submitter": "Alice Baird", "authors": "Alice Baird, Simone Hantke, Bj\\\"orn Schuller", "title": "Responsible and Representative Multimodal Data Acquisition and Analysis:\n  On Auditability, Benchmarking, Confidence, Data-Reliance & Explainability", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The ethical decisions behind the acquisition and analysis of audio, video or\nphysiological human data, harnessed for (deep) machine learning algorithms, is\nan increasing concern for the Artificial Intelligence (AI) community. In this\nregard, herein we highlight the growing need for responsible, and\nrepresentative data collection and analysis, through a discussion of modality\ndiversification. Factors such as Auditability, Benchmarking, Confidence,\nData-reliance, and Explainability (ABCDE), have been touched upon within the\nmachine learning community, and here we lay out these ABCDE sub-categories in\nrelation to the acquisition and analysis of multimodal data, to weave through\nthe high priority ethical concerns currently under discussion for AI. To this\nend, we propose how these five subcategories can be included in early planning\nof such acquisition paradigms.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 21:13:22 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Baird", "Alice", ""], ["Hantke", "Simone", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1903.07195", "submitter": "Wieslaw Kopec", "authors": "Jaros{\\l}aw Kowalski, Anna Jaskulska, Kinga Skorupska, Katarzyna\n  Abramczuk, Cezary Biele, Wies{\\l}aw Kope\\'c, Krzysztof Marasek", "title": "Older Adults and Voice Interaction: A Pilot Study with Google Home", "comments": null, "journal-ref": null, "doi": "10.1145/3290607.3312973", "report-no": null, "categories": "cs.HC cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the results of an exploratory study examining the\npotential of voice assistants (VA) for some groups of older adults in the\ncontext of Smart Home Technology (SHT). To research the aspect of older adults'\ninteraction with voice user interfaces (VUI) we organized two workshops and\ngathered insights concerning possible benefits and barriers to the use of VA\ncombined with SHT by older adults. Apart from evaluating the participants'\ninteraction with the devices during the two workshops we also discuss some\nimprovements to the VA interaction paradigm.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2019 23:12:45 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kowalski", "Jaros\u0142aw", ""], ["Jaskulska", "Anna", ""], ["Skorupska", "Kinga", ""], ["Abramczuk", "Katarzyna", ""], ["Biele", "Cezary", ""], ["Kope\u0107", "Wies\u0142aw", ""], ["Marasek", "Krzysztof", ""]]}, {"id": "1903.07383", "submitter": "Lucas Gren", "authors": "Andreas B\\\"ackevik, Erik Thol\\'en and Lucas Gren", "title": "Social Identity in Software Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agile approach has become very popular over the last decade, which\nrequires good communication and teamwork within teams as well as with outside\nstakeholders. Therefore, social interaction is central for a software\ndevelopment team to be successful. Such social interactions form social\nidentities and social structures in both teams and organizations. This study\ninvestigates possible effects that the social identity of individuals may have\non the effectiveness of software development through seven in-dept interviews.\nThe qualitative data from interviews were analyzed and summarized using\nsummative content analysis, and the seven individuals also answered a\nquestionnaire on social identity taken from social psychology research. The\nqualitative result shows that aspects of social identity affect software\ndevelopers' behavior, and that we need to build cross-functional stable teams\nover time also from a pure social identity perspective in addition to the\nproduct related aspects to avoid a decreased effectiveness. However, we did not\nsee clear connections to our operationalization of effectiveness in this study,\nand the quantitative analysis was also inconclusive, but we see value in our\nsuggested method when investigating social identity in software development.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 12:17:27 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["B\u00e4ckevik", "Andreas", ""], ["Thol\u00e9n", "Erik", ""], ["Gren", "Lucas", ""]]}, {"id": "1903.07539", "submitter": "Adolfo Gustavo Serra-Seca-Neto", "authors": "Myrian Noguera Salinas, Maria Claudia Figueiredo Pereira Emer, Adolfo\n  Gustavo Serra Seca Neto", "title": "Short Datathon for the Interdisciplinary Development of Data Analysis\n  and Visualization Skills", "comments": "12th International Workshop on Cooperative and Human Aspects of\n  Software Engineering (CHASE 2019) - Short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding the major fraud problems in the world and interpreting the data\navailable for analysis is a current challenge that requires interdisciplinary\nknowledge to complement the knowledge of computer professionals. Collaborative\nevents (called Hackathons, Datathons, Codefests, Hack Days, etc.) have become\nrelevant in several fields. Examples of fields which are explored in these\nevents include startup development, open civic innovation, corporate\ninnovation, and social issues. These events have features that favor knowledge\nexchange to solve challenges. In this paper, we present an event format called\nShort Datathon, a Hackathon for the development of exploratory data analysis\nand visualization skills. Our goal is to evaluate if participating in a Short\nDatathon can help participants learn basic data analysis and visualization\nconcepts. We evaluated the Short Datathon in two case studies, with a total of\n20 participants, carried out at the Federal University of Technology -\nParan\\'a. In both case studies we addressed the issue of tax evasion using real\nworld data. We describe, as a result of this work, the qualitative aspects of\nthe case studies and the perception of the participants obtained through\nquestionnaires. Participants stated that the event helped them understand more\nabout data analysis and visualization and that the experience with people from\nother areas during the event made data analysis more efficient. Further studies\nare necessary to evolve the format of the event and to evaluate its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 16:25:19 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Salinas", "Myrian Noguera", ""], ["Emer", "Maria Claudia Figueiredo Pereira", ""], ["Neto", "Adolfo Gustavo Serra Seca", ""]]}, {"id": "1903.07673", "submitter": "Daniel Schwabe", "authors": "Daniel Schwabe, Carlos Laufer", "title": "Trust and Privacy in Knowledge Graphs", "comments": "Pre print of paper in the WWW-19 WORKSHOP ON KNOWLEDGE GRAPH\n  TECHNOLOGY AND APPLICATIONS workshop", "journal-ref": null, "doi": "10.1145/3308560.3317705", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the KG Usage framework, which allows the introduction of\nKG features to support Trust, Privacy and Transparency concerns regarding the\nuse of its contents by applications. A real-world example is presented and used\nto illustrate how the framework can be used.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 18:58:51 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Schwabe", "Daniel", ""], ["Laufer", "Carlos", ""]]}, {"id": "1903.07724", "submitter": "Tiago Cunha", "authors": "Tiago Cunha, David Jurgens, Chenhao Tan, Daniel Romero", "title": "Are All Successful Communities Alike? Characterizing and Predicting the\n  Success of Online Communities", "comments": "To appear at The Web Conference 2019", "journal-ref": null, "doi": "10.1145/3308558.3313689", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of online communities has created exciting opportunities to\nstudy the mechanisms that explain group success. While a growing body of\nresearch investigates community success through a single measure -- typically,\nthe number of members -- we argue that there are multiple ways of measuring\nsuccess. Here, we present a systematic study to understand the relations\nbetween these success definitions and test how well they can be predicted based\non community properties and behaviors from the earliest period of a community's\nlifetime. We identify four success measures that are desirable for most\ncommunities: (i) growth in the number of members; (ii) retention of members;\n(iii) long term survival of the community; and (iv) volume of activities within\nthe community. Surprisingly, we find that our measures do not exhibit very high\ncorrelations, suggesting that they capture different types of success.\nAdditionally, we find that different success measures are predicted by\ndifferent attributes of online communities, suggesting that success can be\nachieved through different behaviors. Our work sheds light on the basic\nunderstanding of what success represents in online communities and what\npredicts it. Our results suggest that success is multi-faceted and cannot be\nmeasured nor predicted by a single measurement. This insight has practical\nimplications for the creation of new online communities and the design of\nplatforms that facilitate such communities.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 21:11:17 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Cunha", "Tiago", ""], ["Jurgens", "David", ""], ["Tan", "Chenhao", ""], ["Romero", "Daniel", ""]]}, {"id": "1903.07730", "submitter": "Travis Whetsell", "authors": "Travis A. Whetsell, Michael J. Leiblein, Caroline S. Wagner", "title": "Between Promise and Performance: Science and Technology Policy\n  Implementation through Network Governance", "comments": "Science and Public Policy, forthcoming; 40 pages, 4 figures, 4 tables", "journal-ref": null, "doi": "10.1093/scipol/scz048", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research analyzes the effects of U.S. science and technology policy on\nthe technological performance of organizations in a global strategic alliance\nnetwork. During the mid-1980s the U.S. semiconductor industry appeared to be\ncollapsing. Industry leaders and policymakers moved to support and protect U.S.\nfirms by creating a program called Sematech. While many scholars regard\nSematech as a success, how the program succeeded remains unclear. This study\nre-contextualizes Sematech as a network administrative organization which\nlowered cooperation costs and enhanced resource combination for innovation at\nthe cutting edge. This study combines network analysis and longitudinal\nregression techniques to test the effects of public policy on organizational\nnetwork position and technological performance in an unbalanced panel of\nsemiconductor firms between 1986 and 2001. This research suggests governments\nmight achieve policy through inter-organizational innovations aimed at the\ndevelopment and administration of robust governance networks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 21:26:47 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 10:29:43 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Whetsell", "Travis A.", ""], ["Leiblein", "Michael J.", ""], ["Wagner", "Caroline S.", ""]]}, {"id": "1903.08255", "submitter": "James Unwin", "authors": "Vincent Huang and James Unwin", "title": "Markov Chain Models of Refugee Migration Data", "comments": "21 Pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of Markov chains to modelling refugee crises is explored,\nfocusing on local migration of individuals at the level of cities and days. As\nan explicit example we apply the Markov chains migration model developed here\nto UNHCR data on the Burundi refugee crisis. We compare our method to a\nstate-of-the-art `agent-based' model of Burundi refugee movements, and\nhighlight that Markov chain approaches presented here can improve the match to\ndata while simultaneously being more algorithmically efficient.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 20:58:02 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Huang", "Vincent", ""], ["Unwin", "James", ""]]}, {"id": "1903.08644", "submitter": "Christos Katsanos", "authors": "Christos Katsanos, Nikolaos Tselios, Nikolaos Avouris, Stavros\n  Demetriadis, Ioannis Stamelos, Lefteris Angelis", "title": "Cross-study Reliability of the Open Card Sorting Method", "comments": "ACM CHI Conference on Human Factors in Computing Systems (CHI) 2019", "journal-ref": null, "doi": "10.1145/3290607.3312999", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information architecture forms the foundation of users' navigation\nexperience. Open card sorting is a widely-used method to create information\narchitectures based on users' groupings of the content. However, little is\nknown about the method's cross-study reliability: Does it produce consistent\ncontent groupings for similar profile participants involved in different card\nsort studies? This paper presents an empirical evaluation of the method's\ncross-study reliability. Six card sorts involving 140 participants were\nconducted: three open sorts for a travel website, and three for an eshop.\nResults showed that participants provided highly similar card sorting data for\nthe same content. A rather high agreement of the produced navigation schemes\nwas also found. These findings provide support for the cross-study reliability\nof the open card sorting method.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 20:17:49 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Katsanos", "Christos", ""], ["Tselios", "Nikolaos", ""], ["Avouris", "Nikolaos", ""], ["Demetriadis", "Stavros", ""], ["Stamelos", "Ioannis", ""], ["Angelis", "Lefteris", ""]]}, {"id": "1903.08915", "submitter": "Tao Bi", "authors": "Tao Bi, Yiyi Zhang, Chongyang Wang, Amid Ayobi", "title": "Characterizing HCI Research in China: Streams, Methodologies and Future\n  Directions", "comments": null, "journal-ref": "CHI 2019 workshop: HCI in China: Research Agenda, Education\n  Curriculum, Industry Partnership, and Communities Building", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This position paper takes the first step to attempt to present the initial\ncharacterization of HCI research in China. We discuss the current streams and\nmethodologies of Chinese HCI research based on two well-known HCI theories:\nMicro/Marco-HCI and the Three Paradigms of HCI. We evaluate the discussion with\na survey of Chinese publications at CHI 2019, which shows HCI research in China\nhas less attention to Macro-HCI topics and the third paradigms of HCI\n(Phenomenologically situated Interaction). We then propose future HCI research\ndirections such as paying more attention to Macro-HCI topics and third paradigm\nof HCI, combining research methodologies from multiple HCI paradigms, including\nemergent users who have less access to technology, and addressing the cultural\ndimensions in order to provide better technical solutions and support.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 10:41:43 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 09:50:27 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Bi", "Tao", ""], ["Zhang", "Yiyi", ""], ["Wang", "Chongyang", ""], ["Ayobi", "Amid", ""]]}, {"id": "1903.08934", "submitter": "Yukun Bao", "authors": "Aboobucker Ilmudeen and Yukun Bao", "title": "Mediating role of managing information technology and its impact on firm\n  performance: insight from China", "comments": null, "journal-ref": "Industrial Management & Data Systems, 118(4), 912-929 (2018)", "doi": "10.1108/IMDS-06-2017-0252", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Managing IT with firm performance has always been a debatable topic\nin literature and practice. Prior studies examining the above relationship have\nreported mixed results and have yet ignored the eminent managing IT practices.\nThe purpose of this paper is to empirically investigate the relevance of ValIT\n2.0 practice in managing IT investment, and its mediating role in the firm\nperformance context. Design,methodology,approach:This paper developed on two\nthemes of literature. First managing IT as a firm's IT capability in order to\ngenerate value from IT investment. Second IT as a firm's resource under\nresource-based view offers firm's competence that deploys potentials in\nachieving firm performance. The structural equation modeling with PLS\ntechniques used for analyzing data collected from 176 organization's IT, and\nbusiness executives in China. Findings: The results of this study show\nempirical evidence that Val-IT's components (value governance, portfolio\nmanagement, and investment management) are significantly linked to the\nmanagement of IT, and it found to be a significant mediator between Val-IT\ncomponents and firm performance. Research implications: This research\ncontributes to the literature and practice by way of highlighting the value\ngeneration through managing IT on firm performance. Originality: This study is\nfully based on ValIT 2.0 with the firm performance where the managing IT\nmediate this relationship in a country-specific study in China. This study adds\nto the Chinese information system literature which suffers the lack of\nempirical studies in the context of management of IT research.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 11:44:27 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Ilmudeen", "Aboobucker", ""], ["Bao", "Yukun", ""]]}, {"id": "1903.09209", "submitter": "Efr\\'en Cruz Cort\\'es", "authors": "Efr\\'en Cruz Cort\\'es, Debashis Ghosh", "title": "A Simulation Based Dynamic Evaluation Framework for System-wide\n  Algorithmic Fairness", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose the use of Agent Based Models (ABMs) inside a reinforcement\nlearning framework in order to better understand the relationship between\nautomated decision making tools, fairness-inspired statistical constraints, and\nthe social phenomena giving rise to discrimination towards sensitive groups.\nThere have been many instances of discrimination occurring due to the\napplications of algorithmic tools by public and private institutions. Until\nrecently, these practices have mostly gone unchecked. Given the large-scale\ntransformation these new technologies elicit, a joint effort of social sciences\nand machine learning researchers is necessary. Much of the research has been\ndone on determining statistical properties of such algorithms and the data they\nare trained on. We aim to complement that approach by studying the social\ndynamics in which these algorithms are implemented. We show how bias can be\naccumulated and reinforced through automated decision making, and the\npossibility of finding a fairness inducing policy. We focus on the case of\nrecidivism risk assessment by considering simplified models of arrest. We find\nthat if we limit our attention to what is observed and manipulated by these\nalgorithmic tools, we may determine some blatantly unfair practices as fair,\nillustrating the advantage of analyzing the otherwise elusive property with a\nsystem-wide model. We expect the introduction of agent based simulation\ntechniques will strengthen collaboration with social scientists, arriving at a\nbetter understanding of the social systems affected by technology and to\nhopefully lead to concrete policy proposals that can be presented to\npolicymakers for a true systemic transformation.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 19:22:14 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Cort\u00e9s", "Efr\u00e9n Cruz", ""], ["Ghosh", "Debashis", ""]]}, {"id": "1903.09297", "submitter": "Hussein Abbass A", "authors": "Alexander Gee and Hussein Abbass", "title": "Transparent Machine Education of Neural Networks for Swarm Shepherding\n  Using Curriculum Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm control is a difficult problem due to the need to guide a large number\nof agents simultaneously. We cast the problem as a shepherding problem, similar\nto biological dogs guiding a group of sheep towards a goal. The shepherd needs\nto deal with complex and dynamic environments and make decisions in order to\ndirect the swarm from one location to another. In this paper, we design a novel\ncurriculum to teach an artificial intelligence empowered agent to shepherd in\nthe presence of the large state space associated with the shepherding problem\nand in a transparent manner. The results show that a properly designed\ncurriculum could indeed enhance the speed of learning and the complexity of\nlearnt behaviours.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 00:04:04 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Gee", "Alexander", ""], ["Abbass", "Hussein", ""]]}, {"id": "1903.09300", "submitter": "Cristina Turcu", "authors": "Cristina Turcu, Cornel Turcu, Iuliana Chiuchisan", "title": "Blockchain and its Potential in Education", "comments": "International Conference on Virtual Learning - ICVL, Alba Iulia,\n  Romania, October 26-28, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proposed paper presents a literature review regarding the status of\nintegrating the dynamic blockchain technology in the educational field.\nBlockchain is a relatively new technology and the same is its implementation in\neducation. The emerging need in this area of research, which still is in its\ninfancy, is justified by the possible use cases; some of these cases are in\npiloting phase, while others have already been adopted by educational\ninstitutions. This paper focuses on extending knowledge about blockchain and on\nidentifying the benefits, risks and the associated challenges regarding the\nsuccessful implementation of blockchain-based solutions in the field of\neducation, fully in line with standards and guidelines for quality assurance.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:55:26 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Turcu", "Cristina", ""], ["Turcu", "Cornel", ""], ["Chiuchisan", "Iuliana", ""]]}, {"id": "1903.09304", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas, Junichi Murata, Hirotaka Takano", "title": "Tackling Unit Commitment and Load Dispatch Problems Considering All\n  Constraints with Evolutionary Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CE cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unit commitment and load dispatch problems are important and complex problems\nin power system operations that have being traditionally solved separately. In\nthis paper, both problems are solved together without approximations or\nsimplifications. In fact, the problem solved has a massive amount of\ngrid-connected photovoltaic units, four pump-storage hydro plants as energy\nstorage units and ten thermal power plants, each with its own set of operation\nrequirements that need to be satisfied. To face such a complex constrained\noptimization problem an adaptive repair method is proposed. By including a\ngiven repair method itself as a parameter to be optimized, the proposed\nadaptive repair method avoid any bias in repair choices. Moreover, this results\nin a repair method that adapt to the problem and will improve together with the\nsolution during optimization. Experiments are conducted revealing that the\nproposed method is capable of surpassing exact method solutions on a simplified\nversion of the problem with approximations as well as solve the otherwise\nintractable complete problem without simplifications. Moreover, since the\nproposed approach can be applied to other problems in general and it may not be\nobvious how to choose the constraint handling for a certain constraint, a\nguideline is provided explaining the reasoning behind. Thus, this paper open\nfurther possibilities to deal with the ever changing types of generation units\nand other similarly complex operation/schedule optimization problems with many\ndifficult constraints.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2019 01:45:53 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Murata", "Junichi", ""], ["Takano", "Hirotaka", ""]]}, {"id": "1903.09305", "submitter": "Supreeth Shastri", "authors": "Supreeth Shastri, Melissa Wasserman, Vijay Chidambaram", "title": "The Seven Sins of Personal-Data Processing Systems under GDPR", "comments": "Accepted for publication at USENIX HotCloud 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, our society is being plagued by unprecedented levels of\nprivacy and security breaches. To rein in this trend, the European Union, in\n2018, introduced a comprehensive legislation called the General Data Protection\nRegulation (GDPR). In this paper, we review GDPR from a system design\nperspective, and identify how its regulations conflict with the design,\narchitecture, and operation of modern systems. We illustrate these conflicts\nvia the seven GDPR sins: storing data forever; reusing data indiscriminately;\nwalled gardens and black markets; risk-agnostic data processing; hiding data\nbreaches; making unexplainable decisions; treating security as a secondary\ngoal. Our findings reveal a deep-rooted tussle between GDPR requirements and\nhow modern systems have evolved. We believe that achieving compliance requires\ncomprehensive, grounds up solutions, and anything short would amount to fixing\na leaky faucet in a sinking ship.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 03:46:28 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 15:25:53 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Shastri", "Supreeth", ""], ["Wasserman", "Melissa", ""], ["Chidambaram", "Vijay", ""]]}, {"id": "1903.09308", "submitter": "Thomas Winters", "authors": "Thomas Winters and Kory W. Mathewson", "title": "Automatically Generating Engaging Presentation Slide Decks", "comments": "To appear at EvoMusArt 2019", "journal-ref": null, "doi": "10.1007/978-3-030-16667-0_9", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Talented public speakers have thousands of hours of practice. One means of\nimproving public speaking skills is practice through improvisation, e.g.\npresenting an improvised presentation using an unseen slide deck. We present\nTEDRIC, a novel system capable of generating coherent slide decks based on a\nsingle topic suggestion. It combines semantic word webs with text and image\ndata sources to create an engaging slide deck with an overarching theme. We\nfound that audience members perceived the quality of improvised presentations\nusing these generated slide decks to be on par with presentations using human\ncreated slide decks for the Improvised TED Talk performance format. TEDRIC is\nthus a valuable new creative tool for improvisers to perform with, and for\nanyone looking to improve their presentation skills.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2019 10:56:53 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Winters", "Thomas", ""], ["Mathewson", "Kory W.", ""]]}, {"id": "1903.09312", "submitter": "Hector Barco Cobalea", "authors": "Hector Barco Cobalea (1 and 2), Iraia Oribe Garcia (1 and 2), Maria\n  Virginia Vargas Viedma (1 and 2), Cruz Enrique Borges (1 and 2), Cristina\n  Martin Andonegui (1 and 2), Ainhoa Alonso Vicario (1 and 2) ((1) DeustoTech -\n  Fundacion Deusto (2) Facultad Ingenieria, Universidad de Deusto)", "title": "New methodology for facilitating the food wastage quantification.\n  Identifying gaps and data inconsistencies", "comments": "Accepted Manuscript version", "journal-ref": "Journal of Environmental Management. 2019", "doi": "10.1016/j.jenvman.2018.11.037", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The work aims at providing a new methodology to facilitate the process of\nquantifying the food waste according to European standards all along the\nagrifood chain combining information that is becoming available at local level.\n  This new methodology generates straightforward and easy-to-interpret results\nfor the decision making process in the framework of the quantification of the\nfood waste at local and supralocal scale and it provides adequate procedures\nwhich are easy adaptable to the specific circumstances in each municipality.\nMoreover, this method could have applications for larger territorial contexts,\nas the national scale, detecting possible points for improvement of the current\nofficial figures at this respect.\n", "versions": [{"version": "v1", "created": "Thu, 7 Mar 2019 13:23:54 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 07:47:12 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Cobalea", "Hector Barco", "", "1 and 2"], ["Garcia", "Iraia Oribe", "", "1 and 2"], ["Viedma", "Maria Virginia Vargas", "", "1 and 2"], ["Borges", "Cruz Enrique", "", "1 and 2"], ["Andonegui", "Cristina Martin", "", "1 and 2"], ["Vicario", "Ainhoa Alonso", "", "1 and 2"]]}, {"id": "1903.09485", "submitter": "Yukun Bao", "authors": "Nattaporn Thongsri, Liang Shen and Yukun Bao", "title": "Investigating factors affecting learners perception toward online\n  learning evidence from ClassStart application in Thailand", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twenty-First Century Education is a design of instructional culture that\nempowers learner-centered through the philosophy of \"Less teaching but more\nlearning\". Due to the development of technology enhance learning in developing\ncountries such as Thailand, online learning is rapidly growing in the\nelectronic learning market. ClassStart is a learning management system\ndeveloped to support Thailand's educational management and to promote the\nstudent-centred learning processes. It also allows the instructor to analyse\nindividual learners through system-generated activities. The study of online\nlearning acceptance is primarily required to successfully achieve online\nlearning system development. However, the behavioural intention of students to\nuse online learning systems has not been well examined, in particular, by\nfocusing specific but representative applications such as ClassStart in this\nstudy. This research takes the usage of ClassStart as research scenario and\ninvestigates the individual acceptance of technology through the Unified Theory\nof Acceptance and Use of Technology, as well as technological quality through\nthe Delone and McLean IS success model. A total of 307 undergraduate students\nusing ClassStart responded to the survey. The Partial Least Squares method, a\nstatistics analysis technique based on the Structural Equation Model (SEM), was\nused to analyze the data. It was found that performance expectancy, social\ninfluence, information quality and system quality have the significant effect\non intention to use ClassStart.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2019 15:32:12 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Thongsri", "Nattaporn", ""], ["Shen", "Liang", ""], ["Bao", "Yukun", ""]]}, {"id": "1903.09518", "submitter": "Arthur Gaudron", "authors": "Gaudron Arthur (CAOR)", "title": "Trial of an AI: Empowering people to explore law and science challenges", "comments": null, "journal-ref": "IFIM's International Journal on Law & Regulation of Artificial\n  Intelligence & Robotics, 2019, 1 (1)", "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence represents many things: a new market to conquer or a\nquality label for tech companies, a threat for traditional industries, a menace\nfor democracy, or a blessing for our busy everyday life. The press abounds in\nexamples illustrating these aspects, but one should draw not hasty and\npremature conclusions. The first successes in AI have been a surprise for\nsociety at large-including researchers in the field. Today, after the initial\nstupefaction, we have examples of the system reactions: traditional companies\nare heavily investing in AI, social platforms are monitored during elections,\ndata collection is more and more regulated, etc. The resilience of an\norganization (i.e. its capacity to resist to a shock) relies deeply on the\nperception of its environment. Future problems have to be anticipated, while\nunforeseen events occurring have to be quickly identified in order to be\nmitigated as fast as possible. The author states that this clear perception\nstarts with a common definition of AI in terms of capacities and limits. AI\npractitioners should make notions and concepts accessible to the general public\nand the impacted fields (e.g. industries, law, education). It is a truism that\nonly law experts would have the potential to estimate IA impacts on judicial\nsystem. However, questions remain on how to connect different kind of expertise\nand what is the appropriate level of detail required for the knowledge\nexchanges. And the same consideration is true for dissemination towards\nsociety. Ultimately, society will live with decisions made by the \"experts\". It\nsounds wise to involve society in the decision process rather than risking to\npay consequences later. Therefore, society also needs the key concepts to\nunderstand AI impact on their life. This was the purpose of the trial of an IA\nthat took place in October 2018 at the Court of Appeal of Paris: gathering\nexperts from various fields to expose challenges in law and science towards a\ngeneral public.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 07:22:29 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Arthur", "Gaudron", "", "CAOR"]]}, {"id": "1903.09614", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Ayse Seyyide Kaptaner, Nur Sevencan", "title": "Optimizing the Access to Healthcare Services in Dense Refugee Hosting\n  Urban Areas: A Case for Istanbul", "comments": "version to submit for D4R competition", "journal-ref": null, "doi": "10.1007/978-3-030-12554-7_20", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With over 3.5 million refugees, Turkey continues to host the world's largest\nrefugee population. This introduced several challenges in many areas including\naccess to healthcare system. Refugees have legal rights to free healthcare\nservices in Turkey's public hospitals. With the aim of increasing healthcare\naccess for refugees, we looked at where the lack of infrastructure is felt the\nmost. Our study attempts to address these problems by assessing whether Migrant\nHealth Centers' locations are optimal. The aim of this study is to improve\nrefugees' access to healthcare services in Istanbul by improving the locations\nof health facilities available to them. We used call data records provided by\nTurk Telekom.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 11:41:46 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Kaptaner", "Ayse Seyyide", ""], ["Sevencan", "Nur", ""]]}, {"id": "1903.09639", "submitter": "Varoon Mathur", "authors": "Cody Griffith, Varoon Mathur, Catherine Lin, Kevin Zhu", "title": "Understanding Childhood Vulnerability in The City of Surrey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the community conditions that best support universal access and\nimproved childhood outcomes allows ultimately to improve decision-making in the\nareas of planning and investment across the early stages of childhood\ndevelopment. Here we describe two different data-driven approaches to\nvisualizing the lived experiences of children throughout the City of Surrey,\ncombining data derived from both public and private sources. In one approach,\nwe find specifically that the Early Development Instrument measuring childhood\nvulnerabilities across varying domains can be used to cluster neighborhoods,\nand that census variables can help explain similarities between neighborhoods\nwithin these clusters. In our second approach, we use program registration data\nfrom the City of Surrey's Community and Recreation Services Division. We also\nfind a critical age of entry and exit for each program related to early\nchildhood development and beyond, and find that certain neighborhoods and\nrecreational programs have larger retention rates than others. This report\ndetails the journey of using data to tell the story of these neighborhoods, and\nprovides a lens to which community initiatives can be strategically crafted\nthrough their use.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:23:24 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Griffith", "Cody", ""], ["Mathur", "Varoon", ""], ["Lin", "Catherine", ""], ["Zhu", "Kevin", ""]]}, {"id": "1903.10080", "submitter": "Jonathan Spring", "authors": "Jonathan M. Spring and Phyllis Illari", "title": "Review of human decision-making during computer security incident\n  analysis", "comments": "58 pages, 45 pages excluding bibliography and glossary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review practical advice on decision-making during computer security\nincident response. Scope includes standards from the IETF, ISO, FIRST, and the\nUS intelligence community. To focus on human decision-making, the scope is the\nevidence collection, analysis, and reporting phases of response. The results\nindicate both strengths and gaps. A strength is available advice on how to\naccomplish many specific tasks. However, there is little guidance on how to\nprioritize tasks in limited time or how to interpret, generalize, and\nconvincingly report results. Future work should focus on these gaps in\nexplication and specification of decision-making during incident analysis.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 23:36:04 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Spring", "Jonathan M.", ""], ["Illari", "Phyllis", ""]]}, {"id": "1903.10180", "submitter": "Christoph Gote", "authors": "Christoph Gote, Ingo Scholtes, Frank Schweitzer", "title": "git2net - Mining Time-Stamped Co-Editing Networks from Large git\n  Repositories", "comments": "MSR 2019, 12 pages, 10 figures", "journal-ref": "MSR '19 Proceedings of the 16th International Conference on Mining\n  Software Repositories, 2019, Pages 433-444", "doi": "10.1109/MSR.2019.00070", "report-no": null, "categories": "cs.SE cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data from software repositories have become an important foundation for the\nempirical study of software engineering processes. A recurring theme in the\nrepository mining literature is the inference of developer networks capturing\ne.g. collaboration, coordination, or communication from the commit history of\nprojects. Most of the studied networks are based on the co-authorship of\nsoftware artefacts defined at the level of files, modules, or packages. While\nthis approach has led to insights into the social aspects of software\ndevelopment, it neglects detailed information on code changes and code\nownership, e.g. which exact lines of code have been authored by which\ndevelopers, that is contained in the commit log of software projects.\nAddressing this issue, we introduce git2net, a scalable python software that\nfacilitates the extraction of fine-grained co-editing networks in large git\nrepositories. It uses text mining techniques to analyse the detailed history of\ntextual modifications within files. This information allows us to construct\ndirected, weighted, and time-stamped networks, where a link signifies that one\ndeveloper has edited a block of source code originally written by another\ndeveloper. Our tool is applied in case studies of an Open Source and a\ncommercial software project. We argue that it opens up a massive new source of\nhigh-resolution data on human collaboration patterns.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 08:49:26 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Gote", "Christoph", ""], ["Scholtes", "Ingo", ""], ["Schweitzer", "Frank", ""]]}, {"id": "1903.10208", "submitter": "Lupingllp Liu", "authors": "Luping Liu, Xiaohai He, Liang Liu, Lingbo Qing, Yong Fang, Jiayong Liu", "title": "Capturing the symptoms of malicious code in electronic documents by\n  file's entropy signal combined with Machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract-Email cyber-attacks based on malicious documents have become the\npopular techniques in today's sophisticated attacks. In the past, persistent\nefforts have been made to detect such attacks. But there are still some common\ndefects in the existing methods including unable to capture unknown attacks,\nhigh overhead of resource and time, and just can be used to detect specific\nformats of documents. In this study, a new Framework named ESRMD (Entropy\nsignal Reflects the Malicious document) is proposed, which can detect malicious\ndocument based on the entropy distribution of the file. In essence, ESRMD is a\nmachine learning classifier. What makes it distinctive is that it extracts\nglobal and structural entropy features from the entropy of the malicious\ndocuments rather than the structural data or metadata of the file, enduing it\nthe ability to deal with various document formats and against the\nparser-confusion and obfuscated attacks. In order to assess the validity of the\nmodel, we conducted extensive experiments on a collected dataset with 10381\nsamples in it, which contains malware (51.47%) and benign (48.53%) samples. The\nresults show that our model can achieve a good performance on the true positive\nrate, precision and ROC with the value of 96.00%, 96.69% and 99.2%\nrespectively. We also compared ESRMD with some leading antivirus engines and\nprevalent tools. The results showed that our framework can achieve a better\nperformance compared with these engines and tools.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 09:52:08 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Liu", "Luping", ""], ["He", "Xiaohai", ""], ["Liu", "Liang", ""], ["Qing", "Lingbo", ""], ["Fang", "Yong", ""], ["Liu", "Jiayong", ""]]}, {"id": "1903.10375", "submitter": "Ben Zorn", "authors": "Greg Morrisett, Shwetak Patel, Jennifer Rexford, and Benjamin Zorn", "title": "Evolving Academia/Industry Relations in Computing Research", "comments": "A Computing Community Consortium (CCC) white paper, 12 pages", "journal-ref": null, "doi": null, "report-no": "ccc2019whitepaper_1", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, the CCC co-sponsored an industry round table that produced the\ndocument \"The Future of Computing Research: Industry-Academic Collaborations\".\nSince then, several important trends in computing research have emerged, and\nthis document considers how those trends impact the interaction between\nacademia and industry in computing fields. We reach the following conclusions:\n- In certain computing disciplines, such as currently artificial intelligence,\nwe observe significant increases in the level of interaction between professors\nand companies, which take the form of extended joint appointments. -\nIncreasingly, companies are highly motivated to engage both professors and\ngraduate students working in specific technical areas because companies view\ncomputing research and technical talent as a core aspect of their business\nsuccess. - There is also the further potential for principles and values from\nthe academy (e.g., ethics, human-centered approaches, etc.) informing products\nand R&D roadmaps in new ways through these unique joint arrangements. - This\nincreasing connection between faculty, students, and companies has the\npotential to change (either positively or negatively) numerous things,\nincluding: the academic culture in computing research universities, the\nresearch topics that faculty and students pursue, the ability of universities\nto train undergraduate and graduate students, etc. This report is the first\nstep in engaging the broader computing research community, raising awareness of\nthe opportunities, complexities and challenges of this trend but further work\nis required. We recommend follow-up to measure the degree and impact of this\ntrend and to establish best practices that are shared widely among computing\nresearch institutions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 14:49:48 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 18:48:13 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Morrisett", "Greg", ""], ["Patel", "Shwetak", ""], ["Rexford", "Jennifer", ""], ["Zorn", "Benjamin", ""]]}, {"id": "1903.10561", "submitter": "Alex Wang", "authors": "Chandler May, Alex Wang, Shikha Bordia, Samuel R. Bowman, Rachel\n  Rudinger", "title": "On Measuring Social Biases in Sentence Encoders", "comments": "NAACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Word Embedding Association Test shows that GloVe and word2vec word\nembeddings exhibit human-like implicit biases based on gender, race, and other\nsocial constructs (Caliskan et al., 2017). Meanwhile, research on learning\nreusable text representations has begun to explore sentence-level texts, with\nsome sentence encoders seeing enthusiastic adoption. Accordingly, we extend the\nWord Embedding Association Test to measure bias in sentence encoders. We then\ntest several sentence encoders, including state-of-the-art methods such as ELMo\nand BERT, for the social biases studied in prior work and two important biases\nthat are difficult or impossible to test at the word level. We observe mixed\nresults including suspicious patterns of sensitivity that suggest the test's\nassumptions may not hold in general. We conclude by proposing directions for\nfuture work on measuring bias in sentence encoders.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 19:30:21 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["May", "Chandler", ""], ["Wang", "Alex", ""], ["Bordia", "Shikha", ""], ["Bowman", "Samuel R.", ""], ["Rudinger", "Rachel", ""]]}, {"id": "1903.10610", "submitter": "Qing Ke", "authors": "Qing Ke", "title": "An analysis of the evolution of science-technology linkage in\n  biomedicine", "comments": "13 pages, 6 figures, 7 tables", "journal-ref": "Journal of Informetrics 14, 101074 (2020)", "doi": "10.1016/j.joi.2020.101074", "report-no": null, "categories": "cs.DL cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demonstrating the practical value of public research has been an important\nsubject in science policy. Here we present a detailed study on the evolution of\nthe citation linkage between life science related patents and biomedical\nresearch over a 37-year period. Our analysis relies on a newly-created dataset\nthat systematically links millions of non-patent references to biomedical\npapers. We find a large disparity in the volume of science linkage among\ntechnology sectors, with biotechnology and drug patents dominating it. The\nlinkage has been growing exponentially over a long period of time, doubling\nevery 2.9 years. The U.S. has been the largest producer of cited science for\nyears, receiving nearly half of the citations. More than half of citations goes\nto universities. We use a new paper-level indicator to quantify to what extent\na paper is basic research or clinical medicine. We find that the cited papers\nare likely to be basic research, yet a significant portion of papers cited in\npatents that are related to FDA-approved drugs are clinical research. The U.S.\nNational Institute of Health continues to be an important funder of cited\nscience. For the majority of companies, more than half of citations in their\npatents are authored by public research. Taken together, these results indicate\na continuous linkage of public science to private sector inventions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 21:57:56 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 21:46:36 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Ke", "Qing", ""]]}, {"id": "1903.10670", "submitter": "Xiaoxi Chelsy Xie", "authors": "Xiaoxi Chelsy Xie, Isaac Johnson, Anne Gomez", "title": "Detecting and Gauging Impact on Wikipedia Page Views", "comments": null, "journal-ref": null, "doi": "10.1145/3308560.3316751", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding how various external campaigns or events affect readership on\nWikipedia is important to efforts aimed at improving awareness and access to\nits content. In this paper, we consider how to build time-series models aimed\nat predicting page views on Wikipedia with the goal of detecting whether there\nare significant changes to the existing trends. We test these models on two\ndifferent events: a video campaign aimed at increasing awareness of Hindi\nWikipedia in India and the page preview feature roll-out---a means of accessing\nWikipedia content without actually visiting the pages---on English and German\nWikipedia. Our models effectively estimate the impact of page preview roll-out,\nbut do not detect a significant change following the video campaign in India.\nWe also discuss the utility of other geographies or language editions for\npredicting page views from a given area on a given language edition.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 04:27:20 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Xie", "Xiaoxi Chelsy", ""], ["Johnson", "Isaac", ""], ["Gomez", "Anne", ""]]}, {"id": "1903.10862", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Feifei Liu and Chengyu Liu", "title": "Active Stacking for Heart Rate Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart rate estimation from electrocardiogram signals is very important for\nthe early detection of cardiovascular diseases. However, due to large\nindividual differences and varying electrocardiogram signal quality, there does\nnot exist a single reliable estimation algorithm that works well on all\nsubjects. Every algorithm may break down on certain subjects, resulting in a\nsignificant estimation error. Ensemble regression, which aggregates the outputs\nof multiple base estimators for more reliable and stable estimates, can be used\nto remedy this problem. Moreover, active learning can be used to optimally\nselect a few trials from a new subject to label, based on which a stacking\nensemble regression model can be trained to aggregate the base estimators. This\npaper proposes four active stacking approaches, and demonstrates that they all\nsignificantly outperform three common unsupervised ensemble regression\napproaches, and a supervised stacking approach which randomly selects some\ntrials to label. Remarkably, our active stacking approaches only need three or\nfour labeled trials from each subject to achieve an average root mean squared\nestimation error below three beats per minute, making them very convenient for\nreal-world applications. To our knowledge, this is the first research on active\nstacking, and its application to heart rate estimation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 13:26:34 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Wu", "Dongrui", ""], ["Liu", "Feifei", ""], ["Liu", "Chengyu", ""]]}, {"id": "1903.11205", "submitter": "Zahratu Shabrina", "authors": "Zahratu Shabrina, Elsa Arcaute, Michael Batty", "title": "Airbnb's disruption of the housing structure in London", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores Airbnb, a peer-to-peer platform for short-term rental of\nhousing accommodation, examining the geographical pattern of those\nestablishments using data from London. Our purpose is to analyse whether or not\nthe diversity of dwelling types correlate with the distribution of listings. We\nuse a measure of spread based on entropy to indicate the diversity of dwelling\ntypes and look at its relationship with the distribution of Airbnb\nestablishments, as well as the type of home ownership using correlation\nanalysis. It is important to note that our study only considers domestic\nbuilding types, and excludes any information on the diversity of land uses. Two\nimportant findings emerge from our analysis. Firstly, the spatial location of\nAirbnb rentals is negatively correlated with the diversity of dwelling types,\nand positively correlated with a single dwelling type, which corresponds in\ngeneral to purpose built flats, conversions and flats in commercial buildings.\nSecondly, Airbnb is associated with areas that have a high proportion of\nprivately rented properties, detracting more than 1.4% of the housing supply\ninto short-term rentals. Such a phenomenon can reach up to 20% in some\nneighbourhoods, further exacerbating the process of gentrification. Finally, we\ndiscuss the implications of these findings as instruments to inform policies\nassociated with the 'sharing' economy in relation to the disruption of the\nhousing structure.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 00:49:15 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 23:03:48 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 10:17:39 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Shabrina", "Zahratu", ""], ["Arcaute", "Elsa", ""], ["Batty", "Michael", ""]]}, {"id": "1903.11461", "submitter": "Kristoffer Nielbo", "authors": "Melvin Wevers, Jianbo Gao, Kristoffer L. Nielbo", "title": "Tracking the Consumption Junction: Temporal Dependencies between\n  Articles and Advertisements in Dutch Newspapers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historians have regularly debated whether advertisements can be used as a\nviable source to study the past. Their main concern centered on the question of\nagency. Were advertisements a reflection of historical events and societal\ndebates, or were ad makers instrumental in shaping society and the ways people\ninteracted with consumer goods? Using techniques from econometrics (Granger\ncausality test) and complexity science (Adaptive Fractal Analysis), this paper\nanalyzes to what extent advertisements shaped or reflected society. We found\nevidence that indicate a fundamental difference between the dynamic behavior of\nword use in articles and advertisements published in a century of Dutch\nnewspapers. Articles exhibit persistent trends that are likely to be reflective\nof communicative memory. Contrary to this, advertisements have a more irregular\nbehavior characterized by short bursts and fast decay, which, in part, mirrors\nthe dynamic through which advertisers introduced terms into public discourse.\nOn the issue of whether advertisements shaped or reflected society, we found\nparticular product types that seemed to be collectively driven by a causality\ngoing from advertisements to articles. Generally, we found support for a\ncomplex interaction pattern dubbed the consumption junction. Finally, we\ndiscovered noteworthy patterns in terms of causality and long-range\ndependencies for specific product groups. All in, this study shows how methods\nfrom econometrics and complexity science can be applied to humanities data to\nimprove our understanding of complex cultural-historical phenomena such as the\nrole of advertising in society.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 14:53:02 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Wevers", "Melvin", ""], ["Gao", "Jianbo", ""], ["Nielbo", "Kristoffer L.", ""]]}, {"id": "1903.11579", "submitter": "Yelena Mejova", "authors": "Yelena Mejova and Kyriaki Kalimeri", "title": "Effect of Values and Technology Use on Exercise: Implications for\n  Personalized Behavior Change Interventions", "comments": null, "journal-ref": "27th Conference on User Modeling, Adaptation and Personalization\n  (UMAP) 2019", "doi": "10.1145/3320435.3320451", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology has recently been recruited in the war against the ongoing obesity\ncrisis; however, the adoption of Health & Fitness applications for regular\nexercise is a struggle. In this study, we present a unique demographically\nrepresentative dataset of 15k US residents that combines technology use logs\nwith surveys on moral views, human values, and emotional contagion. Combining\nthese data, we provide a holistic view of individuals to model their physical\nexercise behavior. First, we show which values determine the adoption of Health\n& Fitness mobile applications, finding that users who prioritize the value of\npurity and de-emphasize values of conformity, hedonism, and security are more\nlikely to use such apps. Further, we achieve a weighted AUROC of .673 in\npredicting whether individual exercises, and we also show that the application\nusage data allows for substantially better classification performance (.608)\ncompared to using basic demographics (.513) or internet browsing data (.546).\nWe also find a strong link of exercise to respondent socioeconomic status, as\nwell as the value of happiness. Using these insights, we propose actionable\ndesign guidelines for persuasive technologies targeting health behavior\nmodification.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 17:47:13 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Mejova", "Yelena", ""], ["Kalimeri", "Kyriaki", ""]]}, {"id": "1903.12012", "submitter": "Jing Chen", "authors": "Xiangyan Tang, Liang Wang, Jieren Cheng, Jing Chen", "title": "Forecasting model based on information-granulated GA-SVR and ARIMA for\n  producer price index", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy of predicting the Producer Price Index (PPI) plays an\nindispensable role in government economic work. However, it is difficult to\nforecast the PPI. In our research, we first propose an unprecedented hybrid\nmodel based on fuzzy information granulation that integrates the GA-SVR and\nARIMA (Autoregressive Integrated Moving Average Model) models. The\nfuzzy-information-granulation-based GA-SVR-ARIMA hybrid model is intended to\ndeal with the problem of imprecision in PPI estimation. The proposed model\nadopts the fuzzy information-granulation algorithm to\npre-classification-process monthly training samples of the PPI, and produced\nthree different sequences of fuzzy information granules, whose Support Vector\nRegression (SVR) machine forecast models were separately established for their\nGenetic Algorithm (GA) optimization parameters. Finally, the residual errors of\nthe GA-SVR model were rectified through ARIMA modeling, and the PPI estimate\nwas reached. Research shows that the PPI value predicted by this hybrid model\nis more accurate than that predicted by other models, including ARIMA, GRNN,\nand GA-SVR, following several comparative experiments. Research also indicates\nthe precision and validation of the PPI prediction of the hybrid model and\ndemonstrates that the model has consistent ability to leverage the forecasting\nadvantage of GA-SVR in non-linear space and of ARIMA in linear space.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2019 14:40:43 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Tang", "Xiangyan", ""], ["Wang", "Liang", ""], ["Cheng", "Jieren", ""], ["Chen", "Jing", ""]]}, {"id": "1903.12064", "submitter": "Nicolas Tempelmeier", "authors": "Nicolas Tempelmeier, Yannick Rietz, Iryna Lishchuk, Tina Kruegel, Olaf\n  Mumm, Vanessa Miriam Carlow, Stefan Dietze, Elena Demidova", "title": "Data4UrbanMobility: Towards Holistic Data Analytics for Mobility\n  Applications in Urban Regions", "comments": null, "journal-ref": "Companion Proceedings of The Web Conference 2019", "doi": "10.1145/3308560.3317055", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing availability of mobility-related data, such as\nGPS-traces, Web queries and climate conditions, there is a growing demand to\nutilize this data to better understand and support urban mobility needs.\nHowever, data available from the individual actors, such as providers of\ninformation, navigation and transportation systems, is mostly restricted to\nisolated mobility modes, whereas holistic data analytics over integrated data\nsources is not sufficiently supported. In this paper we present our ongoing\nresearch in the context of holistic data analytics to support urban mobility\napplications in the Data4UrbanMobility (D4UM) project. First, we discuss\nchallenges in urban mobility analytics and present the D4UM platform we are\ncurrently developing to facilitate holistic urban data analytics over\nintegrated heterogeneous data sources along with the available data sources.\nSecond, we present the MiC app - a tool we developed to complement available\ndatasets with intermodal mobility data (i.e. data about journeys that involve\nmore than one mode of mobility) using a citizen science approach. Finally, we\npresent selected use cases and discuss our future work.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 17:00:34 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Tempelmeier", "Nicolas", ""], ["Rietz", "Yannick", ""], ["Lishchuk", "Iryna", ""], ["Kruegel", "Tina", ""], ["Mumm", "Olaf", ""], ["Carlow", "Vanessa Miriam", ""], ["Dietze", "Stefan", ""], ["Demidova", "Elena", ""]]}, {"id": "1903.12069", "submitter": "Dominik Heider", "authors": "Sebastian Sp\\\"anig, Agnes Emberger-Klein, Jan-Peter Sowa, Ali Canbay,\n  Klaus Menrad, Dominik Heider", "title": "The Virtual Doctor: An Interactive Artificial Intelligence based on Deep\n  Learning for Non-Invasive Prediction of Diabetes", "comments": "16 pages, 4 figues", "journal-ref": "Artificial Intelligence in Medicine 2019", "doi": "10.1016/j.artmed.2019.101706", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) will pave the way to a new era in medicine.\nHowever, currently available AI systems do not interact with a patient, e.g.,\nfor anamnesis, and thus are only used by the physicians for predictions in\ndiagnosis or prognosis. However, these systems are widely used, e.g., in\ndiabetes or cancer prediction. In the current study, we developed an AI that is\nable to interact with a patient (virtual doctor) by using a speech recognition\nand speech synthesis system and thus can autonomously interact with the\npatient, which is particularly important for, e.g., rural areas, where the\navailability of primary medical care is strongly limited by low population\ndensities. As a proof-of-concept, the system is able to predict type 2 diabetes\nmellitus (T2DM) based on non-invasive sensors and deep neural networks.\nMoreover, the system provides an easy-to-interpret probability estimation for\nT2DM for a given patient. Besides the development of the AI, we further\nanalyzed the acceptance of young people for AI in healthcare to estimate the\nimpact of such system in the future.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2019 13:41:46 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Sp\u00e4nig", "Sebastian", ""], ["Emberger-Klein", "Agnes", ""], ["Sowa", "Jan-Peter", ""], ["Canbay", "Ali", ""], ["Menrad", "Klaus", ""], ["Heider", "Dominik", ""]]}, {"id": "1903.12070", "submitter": "Snehanshu Banerjee", "authors": "Snehanshu Banerjee, Mansoureh Jeihani, Danny D. Brown, and Samira\n  Ahangari", "title": "Comprehensive Analysis of Dynamic Message Sign Impact on Driver\n  Behavior: A Random Forest Approach", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the potential effects of different Dynamic Message\nSigns (DMSs) on driver behavior using a full-scale high-fidelity driving\nsimulator. Different DMSs are categorized by their content, structure, and type\nof messages. A random forest algorithm is used for three separate behavioral\nanalyses; a route diversion analysis, a route choice analysis and a compliance\nanalysis; to identify the potential and relative influences of different DMSs\non these aspects of driver behavior. A total of 390 simulation runs are\nconducted using a sample of 65 participants from diverse socioeconomic\nbackgrounds. Results obtained suggest that DMSs displaying lane closure and\ndelay information with advisory messages are most influential with regards to\ndiversion while color-coded DMSs and DMSs with avoid route advice are the top\ncontributors impacting route choice decisions and DMS compliance. In this\nfirst-of-a-kind study, based on the responses to the pre and post simulation\nsurveys as well as results obtained from the analysis of\ndriving-simulation-session data, the authors found that color-blind-friendly,\ncolor-coded DMSs are more effective than alphanumeric DMSs - especially in\nscenarios that demand high compliance from drivers. The increased effectiveness\nmay be attributed to reduced comprehension time and ease with which such DMSs\nare understood by a greater percentage of road users.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 02:10:28 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Banerjee", "Snehanshu", ""], ["Jeihani", "Mansoureh", ""], ["Brown", "Danny D.", ""], ["Ahangari", "Samira", ""]]}, {"id": "1903.12071", "submitter": "Ariel Rosenfeld", "authors": "Ariel Rosenfeld, David Benrimoh, Caitrin Armstrong, Nykan Mirchi,\n  Timothe Langlois-Therrien, Colleen Rollins, Myriam Tanguay-Sela, Joseph\n  Mehltretter, Robert Fratila, Sonia Israel, Emily Snook, Kelly Perlman, Akiva\n  Kleinerman, Bechara Saab, Mark Thoburn, Cheryl Gabbay and Amit\n  Yaniv-Rosenfeld", "title": "Big Data Analytics and AI in Mental Healthcare", "comments": "Chapter in the \"Big Data in Healthcare\" book (Elsevier) [exp. 2019]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health conditions cause a great deal of distress or impairment;\ndepression alone will affect 11% of the world's population. The application of\nArtificial Intelligence (AI) and big-data technologies to mental health has\ngreat potential for personalizing treatment selection, prognosticating,\nmonitoring for relapse, detecting and helping to prevent mental health\nconditions before they reach clinical-level symptomatology, and even delivering\nsome treatments. However, unlike similar applications in other fields of\nmedicine, there are several unique challenges in mental health applications\nwhich currently pose barriers towards the implementation of these technologies.\nSpecifically, there are very few widely used or validated biomarkers in mental\nhealth, leading to a heavy reliance on patient and clinician derived\nquestionnaire data as well as interpretation of new signals such as digital\nphenotyping. In addition, diagnosis also lacks the same objective 'gold\nstandard' as in other conditions such as oncology, where clinicians and\nresearchers can often rely on pathological analysis for confirmation of\ndiagnosis. In this chapter we discuss the major opportunities, limitations and\ntechniques used for improving mental healthcare through AI and big-data. We\nexplore both the computational, clinical and ethical considerations and best\npractices as well as lay out the major researcher directions for the near\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 20:47:29 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Rosenfeld", "Ariel", ""], ["Benrimoh", "David", ""], ["Armstrong", "Caitrin", ""], ["Mirchi", "Nykan", ""], ["Langlois-Therrien", "Timothe", ""], ["Rollins", "Colleen", ""], ["Tanguay-Sela", "Myriam", ""], ["Mehltretter", "Joseph", ""], ["Fratila", "Robert", ""], ["Israel", "Sonia", ""], ["Snook", "Emily", ""], ["Perlman", "Kelly", ""], ["Kleinerman", "Akiva", ""], ["Saab", "Bechara", ""], ["Thoburn", "Mark", ""], ["Gabbay", "Cheryl", ""], ["Yaniv-Rosenfeld", "Amit", ""]]}, {"id": "1903.12074", "submitter": "William La Cava", "authors": "William La Cava, Christopher Bauer, Jason H. Moore, Sarah A\n  Pendergrass", "title": "Interpretation of machine learning predictions for patient outcomes in\n  electronic health records", "comments": "10 pages, 5 figures, submitted to AMIA Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records are an increasingly important resource for\nunderstanding the interactions between patient health, environment, and\nclinical decisions. In this paper we report an empirical study of predictive\nmodeling of several patient outcomes using three state-of-the-art machine\nlearning methods. Our primary goal is to validate the models by interpreting\nthe importance of predictors in the final models. Central to interpretation is\nthe use of feature importance scores, which vary depending on the underlying\nmethodology. In order to assess feature importance, we compared univariate\nstatistical tests, information-theoretic measures, permutation testing, and\nnormalized coefficients from multivariate logistic regression models. In\ngeneral we found poor correlation between methods in their assessment of\nfeature importance, even when their performance is comparable and relatively\ngood. However, permutation tests applied to random forest and gradient boosting\nmodels showed the most agreement, and the importance scores matched the\nclinical interpretation most frequently.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2019 19:05:37 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["La Cava", "William", ""], ["Bauer", "Christopher", ""], ["Moore", "Jason H.", ""], ["Pendergrass", "Sarah A", ""]]}, {"id": "1903.12075", "submitter": "Eduard Paul Enoiu", "authors": "Eduard Paul Enoiu", "title": "An Empirical Exploration on the Supervision of PhD Students Closely\n  Collaborating with Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an increase of PhD students working in industry, there is a need to\nunderstand what factors are influencing supervision for industrial students.\nThis paper aims at exploring the challenges and good approaches to supervision\nof industrial PhD students. Data was collected through semi-structured\ninterviews of six PhD students and supervisors with experience in PhD studies\nat several organizations in the embedded software industry in Sweden. The data\nwas anonymized and it was analyzed by means of thematic analysis. The results\nindicate that there are many challenges and opportunities to improve the\nsupervision of industrial PhD students.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2019 10:15:20 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Enoiu", "Eduard Paul", ""]]}, {"id": "1903.12076", "submitter": "Rogier Van De Wetering", "authors": "Rogier van de Wetering, Rik Bos", "title": "Toward a fitness landscape model of firms' IT-enabled dynamic\n  capabilities", "comments": "8 pages, 1 figure", "journal-ref": "2019 Encyclopedia of Organizational Knowledge, Administration, and\n  Technologies", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter presents, extends and integrates a complexity science\nperspective and applies this to IT-enabled dynamic capabilities (ITDCs) of\nfirms. By doing so, this chapter leverages statistical survey data and uses\nthem as parameters for a simulation using the NK-model. This NK-model creates\nstochastically generated fitness landscapes that are parameterized using a\nfinite number of (N) elements, or capabilities, and (K) complex interactions\nbetween those capabilities, and studies the performance (fitness) of systems.\nWe simulate firm efforts to adaptively explore and walk through a fitness\nlandscape of possible strategies of inter-related capabilities to reach toward\nhigher levels of fitness of ITDCs. Also, our fitness landscape model provides\nrealistic scenarios with a nexus of possible business strategies that can be\nemployed considering the current status, interdependency, and alignment among\ncapabilities in the organization. Our work suggests that firms achieve the\nhighest fitness values when the interdependency among the individual\ncapabilities is relatively small.\n", "versions": [{"version": "v1", "created": "Mon, 11 Mar 2019 14:01:38 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["van de Wetering", "Rogier", ""], ["Bos", "Rik", ""]]}, {"id": "1903.12079", "submitter": "Charith Perera", "authors": "Nader Sohrabi Safa, Carsten Maple, Steve Furnell, Muhammad Ajmal Azad,\n  Charith Perera, Mohammad Dabbagh, Mehdi Sookhak", "title": "Deterrence and Prevention-based Model to Mitigate Information Security\n  Insider Threats in Organisations", "comments": null, "journal-ref": "Future Generation Computer Systems (FGCS) 2019", "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies show that information security breaches and privacy\nviolations are important issues for organisations and people. It is\nacknowledged that decreasing the risk in this domain requires consideration of\nthe technological aspects of information security alongside human aspects.\nEmployees intentionally or unintentionally account for a significant portion of\nthe threats to information assets in organisations. This research presents a\nnovel conceptual framework to mitigate the risk of insiders using deterrence\nand prevention approaches. Deterrence factors discourage employees from\nengaging in information security misbehaviour in organisations, and situational\ncrime prevention factors encourage them to prevent information security\nmisconduct. Our findings show that perceived sanctions certainty and severity\nsignificantly influence individuals' attitudes and deter them from information\nsecurity misconduct. In addition, the output revealed that increasing the\neffort, risk and reducing the reward (benefits of crime) influence the\nemployees' attitudes towards prevent information security misbehaviour.\nHowever, removing excuses and reducing provocations do not significantly\ninfluence individuals' attitudes towards prevent information security\nmisconduct. Finally, the output of the data analysis also showed that\nsubjective norms, perceived behavioural control and attitude influence\nindividuals' intentions, and, ultimately, their behaviour towards avoiding\ninformation security misbehaviour.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 13:32:05 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Safa", "Nader Sohrabi", ""], ["Maple", "Carsten", ""], ["Furnell", "Steve", ""], ["Azad", "Muhammad Ajmal", ""], ["Perera", "Charith", ""], ["Dabbagh", "Mohammad", ""], ["Sookhak", "Mehdi", ""]]}, {"id": "1903.12080", "submitter": "Carl Chalmers", "authors": "C. Chalmers, P.Fergus, C. Aday Curbelo Montanez, S.Sikdar, F.Ball and\n  B. Kendall", "title": "Detecting Activities of Daily Living and Routine Behaviours in Dementia\n  Patients Living Alone Using Smart Meter Load Disaggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of an ageing population is a significant public health concern.\nThis has led to an increase in the number of people living with progressive\nneurodegenerative disorders like dementia. Consequently, the strain this is\nplaces on health and social care services means providing 24-hour monitoring is\nnot sustainable. Technological intervention is being considered, however no\nsolution exists to non-intrusively monitor the independent living needs of\npatients with dementia. As a result many patients hit crisis point before\nintervention and support is provided. In parallel, patient care relies on\nfeedback from informal carers about significant behavioural changes. Yet, not\nall people have a social support network and early intervention in dementia\ncare is often missed. The smart meter rollout has the potential to change this.\nUsing machine learning and signal processing techniques, a home energy supply\ncan be disaggregated to detect which home appliances are turned on and off.\nThis will allow Activities of Daily Living (ADLs) to be assessed, such as\neating and drinking, and observed changes in routine to be detected for early\nintervention. The primary aim is to help reduce deterioration and enable\npatients to stay in their homes for longer. A Support Vector Machine (SVM) and\nRandom Decision Forest classifier are modelled using data from three test\nhomes. The trained models are then used to monitor two patients with dementia\nduring a six-month clinical trial undertaken in partnership with Mersey Care\nNHS Foundation Trust. In the case of load disaggregation for appliance\ndetection, the SVM achieved (AUC=0.86074, Sen=0.756 and Spec=0.92838). While\nthe Decision Forest achieved (AUC=0.9429, Sen=0.9634 and Spec=0.9634). ADLs are\nalso analysed to identify the behavioural patterns of the occupant while\ndetecting alterations in routine.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2019 11:54:19 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Chalmers", "C.", ""], ["Fergus", "P.", ""], ["Montanez", "C. Aday Curbelo", ""], ["Sikdar", "S.", ""], ["Ball", "F.", ""], ["Kendall", "B.", ""]]}, {"id": "1903.12084", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Max Van Kleek, Uchenna Ani, Pete\n  Burnap, Eirini Anthi, Jason R. C. Nurse, Omar Santos, Rafael Mantilla\n  Montalvo, LaTreall Maddox", "title": "Dynamic real-time risk analytics of uncontrollable states in complex\n  internet of things systems, cyber risk at the edge", "comments": null, "journal-ref": null, "doi": "10.1007/s10669-020-09792-x", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) triggers new types of cyber risks. Therefore,\nthe integration of new IoT devices and services requires a self-assessment of\nIoT cyber security posture. By security posture this article refers to the\ncybersecurity strength of an organisation to predict, prevent and respond to\ncyberthreats. At present, there is a gap in the state of the art, because there\nare no self-assessment methods for quantifying IoT cyber risk posture. To\naddress this gap, an empirical analysis is performed of 12 cyber risk\nassessment approaches. The results and the main findings from the analysis is\npresented as the current and a target risk state for IoT systems, followed by\nconclusions and recommendations on a transformation roadmap, describing how IoT\nsystems can achieve the target state with a new goal-oriented dependency model.\nBy target state, we refer to the cyber security target that matches the generic\nsecurity requirements of an organisation. The research paper studies and adapts\nfour alternatives for IoT risk assessment and identifies the goal-oriented\ndependency modelling as a dominant approach among the risk assessment models\nstudied. The new goal-oriented dependency model in this article enables the\nassessment of uncontrollable risk states in complex IoT systems and can be used\nfor a quantitative self-assessment of IoT cyber risk posture.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2019 12:18:33 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 21:18:09 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Van Kleek", "Max", ""], ["Ani", "Uchenna", ""], ["Burnap", "Pete", ""], ["Anthi", "Eirini", ""], ["Nurse", "Jason R. C.", ""], ["Santos", "Omar", ""], ["Montalvo", "Rafael Mantilla", ""], ["Maddox", "LaTreall", ""]]}, {"id": "1903.12262", "submitter": "Negar Rostamzadeh", "authors": "Misha Benjamin, Paul Gagnon, Negar Rostamzadeh, Chris Pal, Yoshua\n  Bengio, Alex Shee", "title": "Towards Standardization of Data Licenses: The Montreal Data License", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a taxonomy for the licensing of data in the fields of\nartificial intelligence and machine learning. The paper's goal is to build\ntowards a common framework for data licensing akin to the licensing of open\nsource software. Increased transparency and resolving conceptual ambiguities in\nexisting licensing language are two noted benefits of the approach proposed in\nthe paper. In parallel, such benefits may help foster fairer and more efficient\nmarkets for data through bringing about clearer tools and concepts that better\ndefine how data can be used in the fields of AI and ML. The paper's approach is\nsummarized in a new family of data license language - \\textit{the Montreal Data\nLicense (MDL)}. Alongside this new license, the authors and their collaborators\nhave developed a web-based tool to generate license language espousing the\ntaxonomies articulated in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 00:28:59 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Benjamin", "Misha", ""], ["Gagnon", "Paul", ""], ["Rostamzadeh", "Negar", ""], ["Pal", "Chris", ""], ["Bengio", "Yoshua", ""], ["Shee", "Alex", ""]]}, {"id": "1903.12264", "submitter": "Timur Osadchiy", "authors": "Timur Osadchiy, Ivan Poliakov, Patrick Olivier, Maisie Rowland, Emma\n  Foster", "title": "Validation of a recommender system for prompting omitted foods in online\n  dietary assessment surveys", "comments": null, "journal-ref": "PervasiveHealth 2019 Proceedings of the 13th EAI International\n  Conference on Pervasive Computing Technologies for Healthcare", "doi": "10.1145/3329189.3329191", "report-no": "ISBN: 978-1-4503-6126-2", "categories": "cs.CY cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recall assistance methods are among the key aspects that improve the accuracy\nof online dietary assessment surveys. These methods still mainly rely on\nexperience of trained interviewers with nutritional background, but data driven\napproaches could improve cost-efficiency and scalability of automated dietary\nassessment. We evaluated the effectiveness of a recommender algorithm developed\nfor an online dietary assessment system called Intake24, that automates the\nmultiple-pass 24-hour recall method. The recommender builds a model of eating\nbehavior from recalls collected in past surveys. Based on foods they have\nalready selected, the model is used to remind respondents of associated foods\nthat they may have omitted to report. The performance of prompts generated by\nthe model was compared to that of prompts hand-coded by nutritionists in two\ndietary studies. The results of our studies demonstrate that the recommender\nsystem is able to capture a higher number of foods omitted by respondents of\nonline dietary surveys than prompts hand-coded by nutritionists. However, the\nconsiderably lower precision of generated prompts indicates an opportunity for\nfurther improvement of the system.\n", "versions": [{"version": "v1", "created": "Wed, 20 Mar 2019 16:42:54 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Osadchiy", "Timur", ""], ["Poliakov", "Ivan", ""], ["Olivier", "Patrick", ""], ["Rowland", "Maisie", ""], ["Foster", "Emma", ""]]}, {"id": "1903.12388", "submitter": "Leyang Xue", "authors": "Peng Zhang, Leyang Xue, An Zeng", "title": "Predictability of diffusion-based recommender systems", "comments": null, "journal-ref": null, "doi": "10.1016/j.knosys.2019.104921", "report-no": null, "categories": "physics.soc-ph cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recommendation methods based on network diffusion have been shown to\nperform well in both recommendation accuracy and diversity. Nowdays, numerous\nextensions have been made to further improve the performance of such methods.\nHowever, to what extent can items be predicted by diffusion-based algorithms\nstill lack of understanding. Here, we mainly propose a method to quantify the\npredictability of diffusion-based algorithms. Accordingly, we conduct\nexperiments on Movielens and Netflix data sets. The results show that the\nhigher recommendation accuracy based on diffusion algorithms can still be\nachieved by optimizing the way of resource allocation on a density network. On\na sparse network, the possibility of improving accuracy is relatively low due\nto the fact that the current accuracy of diffusion-based methods is very close\nits predictability. In this case, we find that the predictability can be\nimproved significantly by multi-steps diffusion, especially for users with less\nhistorical information. In contrast to common belief, there are plausible\ncircumstances where the higher predictability of diffusion-based methods do not\ncorrespond to those users with more historical recording. Thus, we proposed the\ndiffusion coverage and item average degree to explain this phenomenon. In\naddition, we demonstrate the recommendation accuracy in real online system is\noverestimated by random partition used in the literature, suggesting the\nrecommendation in real online system may be a harder task.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 08:24:31 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zhang", "Peng", ""], ["Xue", "Leyang", ""], ["Zeng", "An", ""]]}, {"id": "1903.12551", "submitter": "Yukun Bao", "authors": "Aboobucker Ilmudeen, Yukun Bao", "title": "What obstruct customer acceptance of internet banking? Security and\n  privacy, risk, trust and website usability and the role of moderators", "comments": null, "journal-ref": "The Journal of High Technology Management Research, 29(1), 109-123\n  (2018)", "doi": "10.1016/j.hitech.2018.04.010", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparatively a little attention has been paid to the factors that obstruct\nthe acceptance of Internet banking in Sri Lanka. This research assimilates\nconstructs such as security and privacy, perceived trust, perceived risk, and\nwebsite usability. To test the conceptual model, we collected 186 valid\nresponses from customers who use Internet banking in Sri Lanka. The structural\nequation modelling technique is applied and hypotheses are validated. The\nfindings show perceived trust and website usability are the possible\nobstructing factors that highly concerned by Internet banking customers. While\nsecurity and privacy, and perceived risk are not significant and these are not\nhighly concerned by customers in Internet banking acceptance. The age and\ngender reveal the moderating effect in each exogenous latent constructs\nrelationship. The practical and managerial implications of the findings are\nalso discussed. This country specific study contributes to the advancement of\nInternet banking acceptance, and offers some useful insights to researchers,\npractitioners and policy makers on how to enhance Internet banking acceptance\nfor country similar in context.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 11:44:36 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Ilmudeen", "Aboobucker", ""], ["Bao", "Yukun", ""]]}, {"id": "1903.12553", "submitter": "Bruno Tavares", "authors": "Bruno Tavares, Filipe Figueiredo Correia, Andr\\'e Restivo, Jo\\~ao\n  Pascoal Faria, Ademar Aguiar", "title": "A survey of blockchain frameworks and applications", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.34042.95685", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The applications of the blockchain technology are still being discov-ered.\nWhen a new potential disruptive technology emerges, there is a tendency to try\nto solve every problem with that technology. However, it is still necessary to\ndetermine what approach is the best for each type of application. To find how\ndistributed ledgers solve existing problems, this study looks for blockchain\nframeworks in the academic world. Identifying the existing frameworks can\ndemonstrate where the interest in the technology exists and where it can be\nmiss-ing. This study encountered several blockchain frameworks in development.\nHowever, there are few references to operational needs, testing, and deploy of\nthe technology. With the widespread use of the technology, either integrating\nwith pre-existing solutions, replacing legacy systems, or new implementations,\nthe need for testing, deploying, exploration, and maintenance is expected to\nin-tensify.\n", "versions": [{"version": "v1", "created": "Sun, 24 Mar 2019 19:10:29 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Tavares", "Bruno", ""], ["Correia", "Filipe Figueiredo", ""], ["Restivo", "Andr\u00e9", ""], ["Faria", "Jo\u00e3o Pascoal", ""], ["Aguiar", "Ademar", ""]]}, {"id": "1903.12554", "submitter": "Valentina Presutti", "authors": "Tayeb Abderrahmani Ghor, Esha Agrawal, Mehwish Alam, Omar Alqawasmeh,\n  Claudia D'amato, Amina Annane, Amr Azzam, Andrew Berezovskyi, Russa Biswas,\n  Mathias Bonduel, Quentin Brabant, Cristina-iulia Bucur, Elena Camossi,\n  Valentina Anita Carriero, Shruthi Chari, David Chaves Fraga, Fiorela Ciroku,\n  Michael Cochez, Hubert Curien, Vincenzo Cutrona, Rahma Dandan, Danilo Dess,\n  Valerio Di Carlo, Ahmed El Amine Djebri, Marieke Van Erp, Faiq Miftakhul\n  Falakh, Alba Fernndez Izquierdo, Giuseppe Futia, Aldo Gangemi, Simone\n  Gasperoni, Arnaud Grall, Lars Heling, Pierre Henri, Noura Herradi, Subhi\n  Issa, Samaneh Jozashoori, Nyoman Juniarta, Lucie-aime Kaffee, Ilkcan Keles,\n  Prashant Khare, Viktor Kovtun, Valentina Leone, Siying Li, Sven Lieber,\n  Pasquale Lisena, Tatiana Makhalova, Ludovica Marinucci, Thomas Minier,\n  Benjamin Moreau, Alberto Moya Loustaunau, Durgesh Nandini, Sylwia Ozdowska,\n  Amanda Pacini De Moura, Swati Padhee, Guillermo Palma, Pedro Del Pozo Jimnez,\n  Valentina Presutti, Roberto Reda, Ettore Rizza, Henry Rosales-mndez,\n  Sebastian Rudolph, Harald Sack, Luca Sciullo, Humasak Simanjuntak, Carlo\n  Stomeo, Thiviyan Thanapalasingam, Tabea Tietz, Dalia Varanka, Maria-esther\n  Vidal, Michael Wolowyk, Maximilian Zocholl", "title": "Linked Open Data Validity -- A Technical Report from ISWS 2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linked Open Data (LOD) is the publicly available RDF data in the Web. Each\nLOD entity is identfied by a URI and accessible via HTTP. LOD encodes\nglobalscale knowledge potentially available to any human as well as artificial\nintelligence that may want to benefit from it as background knowledge for\nsupporting their tasks. LOD has emerged as the backbone of applications in\ndiverse fields such as Natural Language Processing, Information Retrieval,\nComputer Vision, Speech Recognition, and many more. Nevertheless, regardless of\nthe specific tasks that LOD-based tools aim to address, the reuse of such\nknowledge may be challenging for diverse reasons, e.g. semantic heterogeneity,\nprovenance, and data quality. As aptly stated by Heath et al. Linked Data might\nbe outdated, imprecise, or simply wrong\": there arouses a necessity to\ninvestigate the problem of linked data validity. This work reports a\ncollaborative effort performed by nine teams of students, guided by an equal\nnumber of senior researchers, attending the International Semantic Web Research\nSchool (ISWS 2018) towards addressing such investigation from different\nperspectives coupled with different approaches to tackle the issue.\n", "versions": [{"version": "v1", "created": "Tue, 26 Mar 2019 09:20:05 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Ghor", "Tayeb Abderrahmani", ""], ["Agrawal", "Esha", ""], ["Alam", "Mehwish", ""], ["Alqawasmeh", "Omar", ""], ["D'amato", "Claudia", ""], ["Annane", "Amina", ""], ["Azzam", "Amr", ""], ["Berezovskyi", "Andrew", ""], ["Biswas", "Russa", ""], ["Bonduel", "Mathias", ""], ["Brabant", "Quentin", ""], ["Bucur", "Cristina-iulia", ""], ["Camossi", "Elena", ""], ["Carriero", "Valentina Anita", ""], ["Chari", "Shruthi", ""], ["Fraga", "David Chaves", ""], ["Ciroku", "Fiorela", ""], ["Cochez", "Michael", ""], ["Curien", "Hubert", ""], ["Cutrona", "Vincenzo", ""], ["Dandan", "Rahma", ""], ["Dess", "Danilo", ""], ["Di Carlo", "Valerio", ""], ["Djebri", "Ahmed El Amine", ""], ["Van Erp", "Marieke", ""], ["Falakh", "Faiq Miftakhul", ""], ["Izquierdo", "Alba Fernndez", ""], ["Futia", "Giuseppe", ""], ["Gangemi", "Aldo", ""], ["Gasperoni", "Simone", ""], ["Grall", "Arnaud", ""], ["Heling", "Lars", ""], ["Henri", "Pierre", ""], ["Herradi", "Noura", ""], ["Issa", "Subhi", ""], ["Jozashoori", "Samaneh", ""], ["Juniarta", "Nyoman", ""], ["Kaffee", "Lucie-aime", ""], ["Keles", "Ilkcan", ""], ["Khare", "Prashant", ""], ["Kovtun", "Viktor", ""], ["Leone", "Valentina", ""], ["Li", "Siying", ""], ["Lieber", "Sven", ""], ["Lisena", "Pasquale", ""], ["Makhalova", "Tatiana", ""], ["Marinucci", "Ludovica", ""], ["Minier", "Thomas", ""], ["Moreau", "Benjamin", ""], ["Loustaunau", "Alberto Moya", ""], ["Nandini", "Durgesh", ""], ["Ozdowska", "Sylwia", ""], ["De Moura", "Amanda Pacini", ""], ["Padhee", "Swati", ""], ["Palma", "Guillermo", ""], ["Jimnez", "Pedro Del Pozo", ""], ["Presutti", "Valentina", ""], ["Reda", "Roberto", ""], ["Rizza", "Ettore", ""], ["Rosales-mndez", "Henry", ""], ["Rudolph", "Sebastian", ""], ["Sack", "Harald", ""], ["Sciullo", "Luca", ""], ["Simanjuntak", "Humasak", ""], ["Stomeo", "Carlo", ""], ["Thanapalasingam", "Thiviyan", ""], ["Tietz", "Tabea", ""], ["Varanka", "Dalia", ""], ["Vidal", "Maria-esther", ""], ["Wolowyk", "Michael", ""], ["Zocholl", "Maximilian", ""]]}]