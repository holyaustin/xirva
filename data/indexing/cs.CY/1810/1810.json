[{"id": "1810.00027", "submitter": "Cameron Mura", "authors": "Anthony C Fletcher and Cameron Mura", "title": "Ten Quick Tips for Using a Raspberry Pi", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1006959", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much of biology (and, indeed, all of science) is becoming increasingly\ncomputational. We tend to think of this in regards to algorithmic approaches\nand software tools, as well as increased computing power. There has also been a\nshift towards slicker, packaged solutions--which mirrors everyday life, from\nsmart phones to smart homes. As a result, it's all too easy to be detached from\nthe fundamental elements that power these changes, and to see solutions as\n\"black boxes\". The major goal of this piece is to use the example of the\nRaspberry Pi--a small, general-purpose computer--as the central component in a\nhighly developed ecosystem that brings together elements like external\nhardware, sensors and controllers, state-of-the-art programming practices, and\nbasic electronics and physics, all in an approachable and useful way. External\ndevices and inputs are easily connected to the Pi, and it can, in turn, control\nattached devices very simply. So whether you want to use it to manage\nlaboratory equipment, sample the environment, teach bioinformatics, control\nyour home security or make a model lunar lander, it's all built from the same\nbasic principles. To quote Richard Feynman, \"What I cannot create, I do not\nunderstand\".\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:20:51 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 02:44:56 GMT"}, {"version": "v3", "created": "Wed, 28 Nov 2018 22:49:13 GMT"}, {"version": "v4", "created": "Fri, 8 Feb 2019 23:29:50 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Fletcher", "Anthony C", ""], ["Mura", "Cameron", ""]]}, {"id": "1810.00031", "submitter": "Alejandro Noriega-Campero", "authors": "Alejandro Noriega-Campero, Michiel A. Bakker, Bernardo Garcia-Bulle,\n  Alex Pentland", "title": "Active Fairness in Algorithmic Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Society increasingly relies on machine learning models for automated decision\nmaking. Yet, efficiency gains from automation have come paired with concern for\nalgorithmic discrimination that can systematize inequality. Recent work has\nproposed optimal post-processing methods that randomize classification\ndecisions for a fraction of individuals, in order to achieve fairness measures\nrelated to parity in errors and calibration. These methods, however, have\nraised concern due to the information inefficiency, intra-group unfairness, and\nPareto sub-optimality they entail. The present work proposes an alternative\nactive framework for fair classification, where, in deployment, a\ndecision-maker adaptively acquires information according to the needs of\ndifferent groups or individuals, towards balancing disparities in\nclassification performance. We propose two such methods, where information\ncollection is adapted to group- and individual-level needs respectively. We\nshow on real-world datasets that these can achieve: 1) calibration and single\nerror parity (e.g., equal opportunity); and 2) parity in both false positive\nand false negative rates (i.e., equal odds). Moreover, we show that by\nleveraging their additional degree of freedom, active approaches can\nsubstantially outperform randomization-based classifiers previously considered\noptimal, while avoiding limitations such as intra-group unfairness.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 18:28:26 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 16:42:51 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Noriega-Campero", "Alejandro", ""], ["Bakker", "Michiel A.", ""], ["Garcia-Bulle", "Bernardo", ""], ["Pentland", "Alex", ""]]}, {"id": "1810.00267", "submitter": "Wieslaw Kopec", "authors": "Kinga Skorupska, Manuel Nu\\~nez, Wies{\\l}aw Kope\\'c, Rados{\\l}aw\n  Nielek", "title": "Older Adults and Crowdsourcing: Android TV App for Evaluating TEDx\n  Subtitle Quality", "comments": null, "journal-ref": null, "doi": "10.1145/3274428", "report-no": null, "categories": "cs.HC cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the insights from an exploratory qualitative pilot\nstudy testing the feasibility of a solution that would encourage older adults\nto participate in online crowdsourcing tasks in a non-computer scenario.\nTherefore, we developed an Android TV application using Amara API to retrieve\nsubtitles for TEDx talks which allows the participants to detect and categorize\nerrors to support the quality of the translation and transcription processes.\nIt relies on the older adults' innate skills as long-time native language users\nand the motivating factors of this socially and personally beneficial task. The\nstudy allowed us to verify the underlying concept of using Smart TVs as\ninterfaces for crowdsourcing, as well as possible barriers, including the\ninterface, configuration issues, topics and the process itself. We have also\nassessed the older adults' interaction and engagement with this TV-enabled\nonline crowdsourcing task and we are convinced that the design of our setup\naddresses some key barriers to crowdsourcing by older adults. It also validates\navenues for further research in this area focused on such considerations as\nautonomy and freedom of choice, familiarity, physical and cognitive comfort as\nwell as building confidence and the edutainment value.\n", "versions": [{"version": "v1", "created": "Sat, 29 Sep 2018 21:18:42 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Skorupska", "Kinga", ""], ["Nu\u00f1ez", "Manuel", ""], ["Kope\u0107", "Wies\u0142aw", ""], ["Nielek", "Rados\u0142aw", ""]]}, {"id": "1810.00281", "submitter": "Quanyan Zhu", "authors": "Quanyan Zhu, Stefan Rass, Peter Schartner", "title": "Community-Based Security for the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With more and more devices becoming connectable to the internet, the number\nof services but also a lot of threats increases dramatically. Security is often\na secondary matter behind functionality and comfort, but the problem has\nalready been recognized. Still, with many IoT devices being deployed already,\nsecurity will come step-by-step and through updates, patches and new versions\nof apps and IoT software. While these updates can be safely retrieved from app\nstores, the problems kick in via jailbroken devices and with the variety of\nuntrusted sources arising on the internet. Since hacking is typically a\ncommunity effort? these days, security could be a community goal too. The\nchallenges are manifold, and one reason for weak or absent security on IoT\ndevices is their weak computational power. In this chapter, we discuss a\ncommunity based security mechanism in which devices mutually aid each other in\nsecure software management. We discuss game-theoretic methods of community\nformation and light-weight cryptographic means to accomplish authentic software\ndeployment inside the IoT device community.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 00:24:22 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zhu", "Quanyan", ""], ["Rass", "Stefan", ""], ["Schartner", "Peter", ""]]}, {"id": "1810.00290", "submitter": "Quanyan Zhu", "authors": "Quanyan Zhu", "title": "Cyber Insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This chapter will first present a principal-agent game-theoretic model to\ncapture the interactions between one insurer and one user. The insurer is\ndeemed as the principal who does not have incomplete information about user's\nsecurity policies. The user, which refers to the infrastructure operator or the\ncustomer, implements his local protection and pays a premium to the insurer.\nThe insurer designs an incentive compatible insurance mechanism that includes\nthe premium and the coverage policy, while the user determines whether to\nparticipate in the insurance and his effort to defend against attacks. The\nchapter will also focus on an attack-aware cyber insurance model by introducing\nthe adversarial behaviors into the framework. The behavior of an attacker\ndetermines the type of cyber threats, e.g. denial of service (DoS) attacks,\ndata breaches, phishing and spoofing. The distinction of threat types plays a\nrole in determining the type of losses and the coverage policies. The data\nbreaches can lead to not only financial losses but also damage of the\nreputations. The coverage may only cover certain agreed percentage of the\nfinancial losses.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 01:31:33 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 20:29:25 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Zhu", "Quanyan", ""]]}, {"id": "1810.01114", "submitter": "Marlo H\\\"aring", "authors": "Marlo H\\\"aring, Wiebke Loosen, Walid Maalej", "title": "Who is Addressed in this Comment? Automatically Classifying\n  Meta-Comments in News Comments", "comments": "Accepted for publication to the 21st ACM Conference on\n  Computer-Supported Cooperative Work and Social Computing (CSCW18)", "journal-ref": null, "doi": "10.1145/3274336", "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User comments have become an essential part of online journalism. However,\nnewsrooms are often overwhelmed by the vast number of diverse comments, for\nwhich a manual analysis is barely feasible. Identifying meta-comments that\naddress or mention newsrooms, individual journalists, or moderators and that\nmay call for reactions is particularly critical. In this paper, we present an\nautomated approach to identify and classify meta-comments. We compare comment\nclassification based on manually extracted features with an end-to-end learning\napproach. We develop, optimize, and evaluate multiple classifiers on a comment\ndataset of the large German online newsroom SPIEGEL Online and the 'One Million\nPosts' corpus of DER STANDARD, an Austrian newspaper. Both optimized\nclassification approaches achieved encouraging $F_{0.5}$ values between 76% and\n91%. We report on the most significant classification features with the results\nof a qualitative analysis and discuss how our work contributes to making\nparticipation in online journalism more constructive.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 08:32:08 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["H\u00e4ring", "Marlo", ""], ["Loosen", "Wiebke", ""], ["Maalej", "Walid", ""]]}, {"id": "1810.01272", "submitter": "Philip Feldman", "authors": "Philip Feldman, Aaron Dant, and Wayne Lutters", "title": "Disrupting the Coming Robot Stampedes: Designing Resilient Information\n  Ecologies", "comments": "5 pages, 2 figures", "journal-ref": "14th International Conference, iConference 2019", "doi": "10.1007/978-3-030-15742-5", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machines are designed to communicate widely and efficiently. Humans, less so.\nWe evolved social structures that function best as small subgroups interacting\nwithin larger populations. Technology changes this dynamic, by allowing all\nindividuals to be connected at the speed of light. A dense, tightly connected\npopulation can behave like a single agent. In animals, this happens in\nconstrained areas where stampedes can easily form. Machines do not need these\nkinds of conditions. The very techniques used to design best-of-breed solutions\nmay increase the risk of dangerous mass behaviors among homogeneous machines.\nIn this paper we argue that ecologically-based design principles such as the\npresence of diversity are a broadly effective strategy to defend against\nunintended consequences at scale.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 14:15:47 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 18:07:57 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Feldman", "Philip", ""], ["Dant", "Aaron", ""], ["Lutters", "Wayne", ""]]}, {"id": "1810.02003", "submitter": "Govind Ramnarayan", "authors": "Ran Canetti, Aloni Cohen, Nishanth Dikkala, Govind Ramnarayan, Sarah\n  Scheffler, Adam Smith", "title": "From Soft Classifiers to Hard Decisions: How fair can we be?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular methodology for building binary decision-making classifiers in the\npresence of imperfect information is to first construct a non-binary \"scoring\"\nclassifier that is calibrated over all protected groups, and then to\npost-process this score to obtain a binary decision. We study the feasibility\nof achieving various fairness properties by post-processing calibrated scores,\nand then show that deferring post-processors allow for more fairness conditions\nto hold on the final decision. Specifically, we show:\n  1. There does not exist a general way to post-process a calibrated classifier\nto equalize protected groups' positive or negative predictive value (PPV or\nNPV). For certain \"nice\" calibrated classifiers, either PPV or NPV can be\nequalized when the post-processor uses different thresholds across protected\ngroups, though there exist distributions of calibrated scores for which the two\nmeasures cannot be both equalized. When the post-processing consists of a\nsingle global threshold across all groups, natural fairness properties, such as\nequalizing PPV in a nontrivial way, do not hold even for \"nice\" classifiers.\n  2. When the post-processing is allowed to `defer' on some decisions (that is,\nto avoid making a decision by handing off some examples to a separate process),\nthen for the non-deferred decisions, the resulting classifier can be made to\nequalize PPV, NPV, false positive rate (FPR) and false negative rate (FNR)\nacross the protected groups. This suggests a way to partially evade the\nimpossibility results of Chouldechova and Kleinberg et al., which preclude\nequalizing all of these measures simultaneously. We also present different\ndeferring strategies and show how they affect the fairness properties of the\noverall system.\n  We evaluate our post-processing techniques using the COMPAS data set from\n2016.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 23:16:09 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 16:36:11 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Canetti", "Ran", ""], ["Cohen", "Aloni", ""], ["Dikkala", "Nishanth", ""], ["Ramnarayan", "Govind", ""], ["Scheffler", "Sarah", ""], ["Smith", "Adam", ""]]}, {"id": "1810.02456", "submitter": "Cesar A. Uribe", "authors": "Angelia Nedi\\'c and Alex Olshevsky and C\\'esar A. Uribe", "title": "Graph-Theoretic Analysis of Belief System Dynamics under Logic\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CY cs.MA cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion formation cannot be modeled solely as an ideological deduction from a\nset of principles; rather, repeated social interactions and logic constraints\namong statements are consequential in the construct of belief systems. We\naddress three basic questions in the analysis of social opinion dynamics: (i)\nWill a belief system converge? (ii) How long does it take to converge? (iii)\nWhere does it converge? We provide graph-theoretic answers to these questions\nfor a model of opinion dynamics of a belief system with logic constraints. Our\nresults make plain the implicit dependence of the convergence properties of a\nbelief system on the underlying social network and on the set of logic\nconstraints that relate beliefs on different statements. Moreover, we provide\nan explicit analysis of a variety of commonly used large-scale network models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 23:30:26 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 20:38:54 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Nedi\u0107", "Angelia", ""], ["Olshevsky", "Alex", ""], ["Uribe", "C\u00e9sar A.", ""]]}, {"id": "1810.02684", "submitter": "Vahid Moosavi", "authors": "Joao P. Leitao, Mohamed Zaghloul and Vahid Moosavi", "title": "Modeling overland flow from local inflows in almost no-time, using Self\n  Organizing Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physically-based overland flow models are computationally demanding,\nhindering their use for real-time applications. Therefore, the development of\nfast (and reasonably accurate) overland flow models is needed if they are to be\nused to support flood mitigation decision making. In this study, we investigate\nthe potential of Self-Organizing Maps to rapidly generate water depth and flood\nextent results. To conduct the study, we developed a flood-simulation specific\nSOM, using cellular automata flood model results and a synthetic DEM and inflow\nhydrograph. The preliminary results showed that water depth and flood extent\nresults produced by the SOM are reasonably accurate and obtained in a very\nshort period of time. Based on this, it seems that SOMs have the potential to\nprovide critical flood information to support real-time flood mitigation\ndecisions. The findings presented would however require further investigations\nto obtain general conclusions; these further investigations may include the\nconsideration of real terrain representations, real water supply networks and\nrealistic inflows from pipe bursts.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 18:54:29 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Leitao", "Joao P.", ""], ["Zaghloul", "Mohamed", ""], ["Moosavi", "Vahid", ""]]}, {"id": "1810.02685", "submitter": "Sabah Al-Fedaghi Dr.", "authors": "Sabah Al-Fedaghi", "title": "Thinging Ethics for Software Engineers", "comments": "11 pages, 21 figures", "journal-ref": "International Journal of Computer Science and Information\n  Security, Vol. 16, No. 9, September 2018", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ethical systems are usually described as principles for distinguishing right\nfrom wrong and forming beliefs about proper conduct. Ethical topics are\ncomplex, with excessively verbose accounts of mental models and intensely\ningrained philosophical assumptions. From practical experience, in teaching\nethics for software engineering students, an explanation of ethics alone often\ncannot provide insights of behavior and thought for students. Additionally, it\nseems that there has been no exploration into the development of a conceptual\npresentation of ethics that appeals to computer engineers. This is particularly\nclear in the area of software engineering, which focuses on software and\nassociated tools such as algorithms, diagramming, documentation, modeling and\ndesign as applied to various types of data and conceptual artifacts. It seems\nthat software engineers look at ethical materials as a collection of ideas and\nnotions that lack systemization and uniformity. Accordingly, this paper\nexplores a thinging schematization for ethical theories that can serve a role\nsimilar to that of modeling languages (e.g., UML). In this approach, thinging\nmeans actualization (existence, presence, being) of things and mechanisms that\ndefine a boundary around some region of ethically related reality, separating\nit from everything else. The resultant diagrammatic representation then\ndeveloped to model the process of making ethical decisions in that region.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 18:57:45 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Al-Fedaghi", "Sabah", ""]]}, {"id": "1810.02688", "submitter": "Philippe Besse", "authors": "Philippe Besse (IMT), Brendan Guillouet (IMT), B\\'eatrice Laurent\n  (IMT)", "title": "Wikistat 2.0: Educational Resources for Artificial Intelligence", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data, data science, deep learning, artificial intelligence are the key\nwords of intense hype related with a job market in full evolution, that impose\nto adapt the contents of our university professional trainings. Which\nartificial intelligence is mostly concerned by the job offers? Which\nmethodologies and technologies should be favored in the training programs?\nWhich objectives, tools and educational resources do we needed to put in place\nto meet these pressing needs? We answer these questions in describing the\ncontents and operational resources in the Data Science orientation of the\nspecialty Applied Mathematics at INSA Toulouse. We focus on basic mathematics\ntraining (Optimization, Probability, Statistics), associated with the practical\nimplementation of the most performing statistical learning algorithms, with the\nmost appropriate technologies and on real examples. Considering the huge\nvolatility of the technologies, it is imperative to train students in\nseft-training, this will be their technological watch tool when they will be in\nprofessional activity. This explains the structuring of the educational site\ngithub.com/wikistat into a set of tutorials. Finally, to motivate the thorough\npractice of these tutorials, a serious game is organized each year in the form\nof a prediction contest between students of Master degrees in Applied\nMathematics for IA.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 08:27:59 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 13:07:57 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Besse", "Philippe", "", "IMT"], ["Guillouet", "Brendan", "", "IMT"], ["Laurent", "B\u00e9atrice", "", "IMT"]]}, {"id": "1810.02689", "submitter": "Alun Preece", "authors": "Alun Preece, Rob Ashelford, Harry Armstrong and Dave Braines", "title": "Hows and Whys of Artificial Intelligence for Public Sector Decisions:\n  Explanation and Evaluation", "comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA; corrected typos in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation has always been a key challenge in the development of artificial\nintelligence (AI) based software, due to the technical complexity of the\nsoftware artifact and, often, its embedding in complex sociotechnical\nprocesses. Recent advances in machine learning (ML) enabled by deep neural\nnetworks has exacerbated the challenge of evaluating such software due to the\nopaque nature of these ML-based artifacts. A key related issue is the\n(in)ability of such systems to generate useful explanations of their outputs,\nand we argue that the explanation and evaluation problems are closely linked.\nThe paper models the elements of a ML-based AI system in the context of public\nsector decision (PSD) applications involving both artificial and human\nintelligence, and maps these elements against issues in both evaluation and\nexplanation, showing how the two are related. We consider a number of common\nPSD application patterns in the light of our model, and identify a set of key\nissues connected to explanation and evaluation in each case. Finally, we\npropose multiple strategies to promote wider adoption of AI/ML technologies in\nPSD, where each is distinguished by a focus on different elements of our model,\nallowing PSD policy makers to adopt an approach that best fits their context\nand concerns.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 09:38:13 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 21:41:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Preece", "Alun", ""], ["Ashelford", "Rob", ""], ["Armstrong", "Harry", ""], ["Braines", "Dave", ""]]}, {"id": "1810.02690", "submitter": "V\\'ictor Mayoral Vilches", "authors": "Gorka Olalde Mendia, Lander Usategui San Juan, Xabier Perez Bascaran,\n  Asier Bilbao Calvo, Alejandro Hern\\'andez Cordero, Irati Zamalloa Ugarte,\n  Aday Mu\\~niz Rosas, David Mayoral Vilches, Unai Ayucar Carbajo, Laura Alzola\n  Kirschgens, V\\'ictor Mayoral Vilches and Endika Gil-Uriarte", "title": "Robotics CTF (RCTF), a playground for robot hacking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots state of insecurity is onstage. There is an emerging concern about\nmajor robot vulnerabilities and their adverse consequences. However, there is\nstill a considerable gap between robotics and cybersecurity domains. For the\npurpose of filling that gap, the present technical report presents the Robotics\nCTF (RCTF), an online playground to challenge robot security from any browser.\nWe describe the architecture of the RCTF and provide 9 scenarios where hackers\ncan challenge the security of different robotic setups. Our work empowers\nsecurity researchers to a) reproduce virtual robotic scenarios locally and b)\nchange the networking setup to mimic real robot targets. We advocate for hacker\npowered security in robotics and contribute by open sourcing our scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 10:12:01 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 11:20:27 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 06:46:49 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Mendia", "Gorka Olalde", ""], ["Juan", "Lander Usategui San", ""], ["Bascaran", "Xabier Perez", ""], ["Calvo", "Asier Bilbao", ""], ["Cordero", "Alejandro Hern\u00e1ndez", ""], ["Ugarte", "Irati Zamalloa", ""], ["Rosas", "Aday Mu\u00f1iz", ""], ["Vilches", "David Mayoral", ""], ["Carbajo", "Unai Ayucar", ""], ["Kirschgens", "Laura Alzola", ""], ["Vilches", "V\u00edctor Mayoral", ""], ["Gil-Uriarte", "Endika", ""]]}, {"id": "1810.02724", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Human Indignity: From Legal AI Personhood to Selfish Memes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is possible to rely on current corporate law to grant legal personhood to\nArtificially Intelligent (AI) agents. In this paper, after introducing pathways\nto AI personhood, we analyze consequences of such AI empowerment on human\ndignity, human safety and AI rights. We emphasize possibility of creating\nselfish memes and legal system hacking in the context of artificial entities.\nFinally, we consider some potential solutions for addressing described\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 20:01:43 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "1810.03005", "submitter": "Balazs Vedres", "authors": "Balazs Vedres, Orsolya Vasarhelyi", "title": "Gendered behavior as a disadvantage in open source software development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Women are severely marginalized in software development, especially in open\nsource. In this article we argue that disadvantage is more due to gendered\nbehavior than to categorical discrimination: women are at a disadvantage\nbecause of what they do, rather than because of who they are. Using data on\nentire careers of users from GitHub.com, we develop a measure to capture the\ngendered pattern of behavior: We use a random forest prediction of being female\n(as opposed to being male) by behavioral choices in the level of activity,\nspecialization in programming languages, and choice of partners. We test\ndifferences in success and survival along both categorical gender and the\ngendered pattern of behavior. We find that 84.5% of women's disadvantage\n(compared to men) in success and 34.8% of their disadvantage in survival are\ndue to the female pattern of their behavior. Men are also disadvantaged along\ntheir interquartile range of the female pattern of their behavior, and users\nwho don't reveal their gender suffer an even more drastic disadvantage in\nsurvival probability. Moreover, we do not see evidence for any reduction of\nthese inequalities in time. Our findings are robust to noise in gender\nrecognition, and to taking into account particular programming languages, or\ndecision tree classes of gendered behavior. Our results suggest that fighting\ncategorical gender discrimination will have a limited impact on gender\ninequalities in open source software development, and that gender hiding is not\na viable strategy for women.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 14:15:31 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Vedres", "Balazs", ""], ["Vasarhelyi", "Orsolya", ""]]}, {"id": "1810.03046", "submitter": "Arjun Pakrashi", "authors": "Arjun Pakrashi, Elham Alghamdi, Brian Mac Namee, Derek Greene", "title": "MeetupNet Dublin: Discovering Communities in Dublin's Meetup Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meetup.com is a global online platform which facilitates the organisation of\nmeetups in different parts of the world. A meetup group typically focuses on\none specific topic of interest, such as sports, music, language, or technology.\nHowever, many users of this platform attend multiple meetups. On this basis, we\ncan construct a co-membership network for a given location. This network\nencodes how pairs of meetups are connected to one another via common members.\nIn this work we demonstrate that, by applying techniques from social network\nanalysis to this type of representation, we can reveal the underlying meetup\ncommunity structure, which is not immediately apparent from the platform's\nwebsite. Specifically, we map the landscape of Dublin's meetup communities, to\nexplore the interests and activities of meetup.com users in the city.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2018 20:30:13 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 12:48:23 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Pakrashi", "Arjun", ""], ["Alghamdi", "Elham", ""], ["Mac Namee", "Brian", ""], ["Greene", "Derek", ""]]}, {"id": "1810.03163", "submitter": "James Bagrow", "authors": "Daniel Berenberg and James P. Bagrow", "title": "Efficient Crowd Exploration of Large Networks: The Case of Causal\n  Attribution", "comments": "25 pages, 14 figures, in CSCW'18", "journal-ref": "PACM on Human-Computer Interaction, Vol. 2, No. CSCW, Article 24.\n  Publication date: November 2018", "doi": "10.1145/3274293", "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately and efficiently crowdsourcing complex, open-ended tasks can be\ndifficult, as crowd participants tend to favor short, repetitive \"microtasks\".\nWe study the crowdsourcing of large networks where the crowd provides the\nnetwork topology via microtasks. Crowds can explore many types of social and\ninformation networks, but we focus on the network of causal attributions, an\nimportant network that signifies cause-and-effect relationships. We conduct\nexperiments on Amazon Mechanical Turk (AMT) testing how workers propose and\nvalidate individual causal relationships and introduce a method for independent\ncrowd workers to explore large networks. The core of the method, Iterative\nPathway Refinement, is a theoretically-principled mechanism for efficient\nexploration via microtasks. We evaluate the method using synthetic networks and\napply it on AMT to extract a large-scale causal attribution network, then\ninvestigate the structure of this network as well as the activity patterns and\nefficiency of the workers who constructed this network. Worker interactions\nreveal important characteristics of causal perception and the network data they\ngenerate can improve our understanding of causality and causal inference.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 15:43:49 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Berenberg", "Daniel", ""], ["Bagrow", "James P.", ""]]}, {"id": "1810.03426", "submitter": "Jennifer Gustetic", "authors": "Jennifer L Gustetic, Jason Crusan, Steve Rader, Sam Ortega", "title": "Outcome-Driven Open Innovation at NASA", "comments": "Space Policy (2015)", "journal-ref": null, "doi": "10.1016/j.spacepol.2015.06.002", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an increasingly connected and networked world, the National Aeronautics\nand Space Administration (NASA) recognizes the value of the public as a\nstrategic partner in addressing some of our most pressing challenges. The\nagency is working to more effectively harness the expertise, ingenuity, and\ncreativity of individual members of the public by enabling, accelerating, and\nscaling the use of open innovation approaches including prizes, challenges, and\ncrowdsourcing. As NASA's use of open innovation tools to solve a variety of\ntypes of problems and advance of number of outcomes continues to grow,\nchallenge design is also becoming more sophisticated as our expertise and\ncapacity (personnel, platforms, and partners) grows and develops. NASA has\nrecently pivoted from talking about the benefits of challenge-driven\napproaches, to the outcomes these types of activities yield. Challenge design\nshould be informed by desired outcomes that align with NASA's mission. This\npaper provides several case studies of NASA open innovation activities and maps\nthe outcomes of those activities to a successful set of outcomes that\nchallenges can help drive alongside traditional tools such as contracts, grants\nand partnerships.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 13:16:09 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Gustetic", "Jennifer L", ""], ["Crusan", "Jason", ""], ["Rader", "Steve", ""], ["Ortega", "Sam", ""]]}, {"id": "1810.03611", "submitter": "Marc-Etienne Brunet", "authors": "Marc-Etienne Brunet, Colleen Alkalay-Houlihan, Ashton Anderson,\n  Richard Zemel", "title": "Understanding the Origins of Bias in Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of machine learning systems not only promises great technical\nprogress, but risks societal harm. As a recent example, researchers have shown\nthat popular word embedding algorithms exhibit stereotypical biases, such as\ngender bias. The widespread use of these algorithms in machine learning\nsystems, from automated translation services to curriculum vitae scanners, can\namplify stereotypes in important contexts. Although methods have been developed\nto measure these biases and alter word embeddings to mitigate their biased\nrepresentations, there is a lack of understanding in how word embedding bias\ndepends on the training data. In this work, we develop a technique for\nunderstanding the origins of bias in word embeddings. Given a word embedding\ntrained on a corpus, our method identifies how perturbing the corpus will\naffect the bias of the resulting embedding. This can be used to trace the\norigins of word embedding bias back to the original training documents. Using\nour method, one can investigate trends in the bias of the underlying corpus and\nidentify subsets of documents whose removal would most reduce bias. We\ndemonstrate our techniques on both a New York Times and Wikipedia corpus and\nfind that our influence function-based approximations are very accurate.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 18:00:00 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 18:26:54 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Brunet", "Marc-Etienne", ""], ["Alkalay-Houlihan", "Colleen", ""], ["Anderson", "Ashton", ""], ["Zemel", "Richard", ""]]}, {"id": "1810.03660", "submitter": "Jacopo Staiano", "authors": "Oscar Araque, Lorenzo Gatti, Jacopo Staiano, Marco Guerini", "title": "DepecheMood++: a Bilingual Emotion Lexicon Built Through Simple Yet\n  Powerful Techniques", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several lexica for sentiment analysis have been developed and made available\nin the NLP community. While most of these come with word polarity annotations\n(e.g. positive/negative), attempts at building lexica for finer-grained emotion\nanalysis (e.g. happiness, sadness) have recently attracted significant\nattention. Such lexica are often exploited as a building block in the process\nof developing learning models for which emotion recognition is needed, and/or\nused as baselines to which compare the performance of the models. In this work,\nwe contribute two new resources to the community: a) an extension of an\nexisting and widely used emotion lexicon for English; and b) a novel version of\nthe lexicon targeting Italian. Furthermore, we show how simple techniques can\nbe used, both in supervised and unsupervised experimental settings, to boost\nperformances on datasets and tasks of varying degree of domain-specificity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2018 19:05:23 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Araque", "Oscar", ""], ["Gatti", "Lorenzo", ""], ["Staiano", "Jacopo", ""], ["Guerini", "Marco", ""]]}, {"id": "1810.03824", "submitter": "Tobias Weber", "authors": "Tobias Weber and Dieter Kranzlm\\\"uller", "title": "How FAIR can you get? Image Retrieval as a Use Case to calculate FAIR\n  Metrics", "comments": "This is a preprint for a paper accepted for the 2018 IEEE conference", "journal-ref": null, "doi": "10.1109/eScience.2018.00027", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large number of services for research data management strive to adhere to\nthe FAIR guiding principles for scientific data management and stewardship. To\nevaluate these services and to indicate possible improvements, use-case-centric\nmetrics are needed as an addendum to existing metric frameworks. The retrieval\nof spatially and temporally annotated images can exemplify such a use case. The\nprototypical implementation indicates that currently no research data\nrepository achieves the full score. Suggestions on how to increase the score\ninclude automatic annotation based on the metadata inside the image file and\nsupport for content negotiation to retrieve the images. These and other\ninsights can lead to an improvement of data integration workflows, resulting in\na better and more FAIR approach to manage research data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 06:07:29 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Weber", "Tobias", ""], ["Kranzlm\u00fcller", "Dieter", ""]]}, {"id": "1810.04039", "submitter": "Mason Swofford", "authors": "Mason Swofford, John Peruzzi, and Marynel V\\'azquez", "title": "Conversational Group Detection With Deep Convolutional Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Detection of interacting and conversational groups from images has\napplications in video surveillance and social robotics. In this paper we build\non prior attempts to find conversational groups by detection of social\ngathering spaces called o-spaces used to assign people to groups. As our\ncontributions to the task, we are the first paper to incorporate features\nextracted from the room layout image, and the first to incorporate a deep\nnetwork to generate an image representation of the proposed o-spaces.\nSpecifically, this novel network builds on the PointNet architecture which\nallows unordered inputs of variable sizes. We present accuracies which\ndemonstrate the ability to rival and sometimes outperform the best models, but\ndue to a data imbalance issue we do not yet outperform existing models in our\ntest results.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 20:27:26 GMT"}, {"version": "v2", "created": "Sun, 5 May 2019 16:52:03 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Swofford", "Mason", ""], ["Peruzzi", "John", ""], ["V\u00e1zquez", "Marynel", ""]]}, {"id": "1810.04575", "submitter": "Fabio Sabatini", "authors": "Andrea Geraci, Mattia Nardotto, Tommaso Reggiani, Fabio Sabatini", "title": "Broadband Internet and Social Capital", "comments": "Internet & Society; Economics", "journal-ref": null, "doi": null, "report-no": "IZA DP No. 11855", "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how the diffusion of broadband Internet affects social capital using\ntwo data sets from the UK. Our empirical strategy exploits the fact that\nbroadband access has long depended on customers' position in the voice\ntelecommunication infrastructure that was designed in the 1930s. The actual\nspeed of an Internet connection, in fact, rapidly decays with the distance of\nthe dwelling from the specific node of the network serving its area. Merging\nunique information about the topology of the voice network with geocoded\nlongitudinal data about individual social capital, we show that access to\nbroadband Internet caused a significant decline in forms of offline interaction\nand civic engagement. Overall, our results suggest that broadband penetration\nsubstantially crowded out several aspects of social capital.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2018 07:19:14 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Geraci", "Andrea", ""], ["Nardotto", "Mattia", ""], ["Reggiani", "Tommaso", ""], ["Sabatini", "Fabio", ""]]}, {"id": "1810.04576", "submitter": "Xiaoqi Tan", "authors": "Xiaoqi Tan, Alberto Leon-Garcia", "title": "Autonomous Mobility and Energy Service Management in Future Smart\n  Cities: An Overview", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of transportation electrification, autonomous driving and\nshared mobility in urban mobility systems, and increasing penetrations of\ndistributed energy resources and autonomous demand-side management techniques\nin energy systems, tremendous opportunities, as well as challenges, are\nemerging in the forging of a sustainable and converged urban mobility and\nenergy future. This paper is motivated by these disruptive transformations and\ngives an overview of managing autonomous mobility and energy services in future\nsmart cities. First, we propose a three-layer architecture for the convergence\nof future mobility and energy systems. For each layer, we give a brief overview\nof the disruptive transformations that directly contribute to the rise of\nautonomous mobility-on-demand (AMoD) systems. Second, we propose the concept of\nautonomous flexibility-on-demand (AFoD), as an energy service platform built\ndirectly on existing infrastructures of AMoD systems. In the vision of AFoD,\nautonomous electric vehicles provide charging flexibilities as a service on\ndemand in energy systems. Third, we analyze and compare AMoD and AFoD, and we\nidentify four key decisions that, if appropriately coordinated, will create a\nsynergy between AMoD and AFoD. Finally, we discuss key challenges towards the\nsuccess of AMoD and AFoD in future smart cities and present some key research\ndirections regarding the system-wide coordination between AMoD and AFoD.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2018 16:32:29 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Tan", "Xiaoqi", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "1810.04699", "submitter": "Yining Hu", "authors": "Yining Hu, Madhusanka Liyanage, Ahsan Mansoor, Kanchana Thilakarathna,\n  Guillaume Jourjon, Aruna Seneviratne", "title": "Blockchain-based Smart Contracts - Applications and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A blockchain-based smart contract or a \"smart contract\" for short, is a\ncomputer program intended to digitally facilitate the negotiation or\ncontractual terms directly between users when certain conditions are met. With\nthe advance in blockchain technology, smart contracts are being used to serve a\nwide range of purposes ranging from self-managed identities on public\nblockchains to automating business collaboration on permissioned blockchains.\nIn this paper, we present a comprehensive survey of smart contracts with a\nfocus on existing applications and challenges they face.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 15:12:42 GMT"}, {"version": "v2", "created": "Sat, 8 Jun 2019 06:10:47 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Hu", "Yining", ""], ["Liyanage", "Madhusanka", ""], ["Mansoor", "Ahsan", ""], ["Thilakarathna", "Kanchana", ""], ["Jourjon", "Guillaume", ""], ["Seneviratne", "Aruna", ""]]}, {"id": "1810.04964", "submitter": "Wolfgang Leister", "authors": "Wolfgang Leister and Ingvar Tj{\\o}stheim", "title": "Which Generation Shows the Most Prudent Data Sharing Behaviour?", "comments": "presented at Amsterdam Privacy Conference (APC) 2018, 4.-8. October\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We report from a study performed in ten European countries, where we asked\nabout attitudes and behaviour towards data sharing behaviour. We looked into\nthe differences between members of age groups. We find that there are more\nsimilarities than differences between the age groups, with the exception of\nyoung people more often tending to use fake information for privacy reasons.\nWhen analysing whether users change privacy settings as an indicator of\nawareness, we find that both the younger and the older users have lower\nawareness than the members of the middle-aged. The use of learning and\npractising tools seems the right way to increase the privacy and data sharing\nawareness of citizen.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 11:51:19 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Leister", "Wolfgang", ""], ["Tj\u00f8stheim", "Ingvar", ""]]}, {"id": "1810.05347", "submitter": "Xiao Li", "authors": "Xiao Li, Hanchen Xu, Jinming Zhang, Hua-hua Chang", "title": "Optimal Hierarchical Learning Path Design with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-learning systems are capable of providing more adaptive and efficient\nlearning experiences for students than the traditional classroom setting. A key\ncomponent of such systems is the learning strategy, the algorithm that designs\nthe learning paths for students based on information such as the students'\ncurrent progresses, their skills, learning materials, and etc. In this paper,\nwe address the problem of finding the optimal learning strategy for an\nE-learning system. To this end, we first develop a model for students'\nhierarchical skills in the E-learning system. Based on the hierarchical skill\nmodel and the classical cognitive diagnosis model, we further develop a\nframework to model various proficiency levels of hierarchical skills. The\noptimal learning strategy on top of the hierarchical structure is found by\napplying a model-free reinforcement learning method, which does not require\ninformation on students' learning transition process. The effectiveness of the\nproposed framework is demonstrated via numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 04:03:20 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Li", "Xiao", ""], ["Xu", "Hanchen", ""], ["Zhang", "Jinming", ""], ["Chang", "Hua-hua", ""]]}, {"id": "1810.05365", "submitter": "Wei Cai", "authors": "Wei Cai, Zehua Wang, Jason B. Ernst, Zhen Hong, Chen Feng, Victor C.M.\n  Leung", "title": "Decentralized Applications: The Blockchain-Empowered Software System", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2870644", "report-no": null, "categories": "cs.DC cs.CR cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Blockchain technology has attracted tremendous attention in both academia and\ncapital market. However, overwhelming speculations on thousands of available\ncryptocurrencies and numerous initial coin offering (ICO) scams have also\nbrought notorious debates on this emerging technology. This paper traces the\ndevelopment of blockchain systems to reveal the importance of decentralized\napplications (dApps) and the future value of blockchain. We survey the\nstate-of-the-art dApps and discuss the direction of blockchain development to\nfulfill the desirable characteristics of dApps. The readers will gain an\noverview of dApp research and get familiar with recent developments in the\nblockchain.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 05:41:31 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Cai", "Wei", ""], ["Wang", "Zehua", ""], ["Ernst", "Jason B.", ""], ["Hong", "Zhen", ""], ["Feng", "Chen", ""], ["Leung", "Victor C. M.", ""]]}, {"id": "1810.05421", "submitter": "Carlos R. Del-Blanco Dr", "authors": "Carlos R. del Blanco and Ivan Garc\\'ia-Magari\\~no", "title": "The use of blogs in the education field: A qualitative systematic review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI physics.ed-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blogs have become one of the most successful tools of the Web 2.0 because of\ntheir ease of use and the availability of open platforms. They have quickly\nspread in the education field thanks to the many attractive qualities that have\nbeen attributed to them, such as collaboration, communication, enhancing of\nprofessional writing, and the improvement of information-gathering skills.\nHowever, many of the studies that have addressed this issue were not based on\nan empirical research, and therefore they are unreliable. On the other hand,\nthe studies that do have conducted an empirical research have usually relied on\nparticipant self-reported data (surveys, interviews, and contents of blogs),\nwhich can significantly bias the positive results usually reported on the use\nof blogs. Another source of bias and inaccuracy in the reported results is that\nmost of the studies lacked control group, i.e they do not follow an\nexperimental design. The purpose of this review is to examine the current state\nof the studies related to the evaluation of the blog effects in the education\nfield. The methods to select the studies and perform the corresponding analysis\nhave followed a qualitative systematic approach. The selection has been\nrestricted to empirical and peer-reviewed studies published between January\n2011 and June 2013. The findings have been integrated and compared using the\nGrounded Theory, giving rise to a set of categories that have structured the\nresults of the review.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 09:15:47 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["del Blanco", "Carlos R.", ""], ["Garc\u00eda-Magari\u00f1o", "Ivan", ""]]}, {"id": "1810.05485", "submitter": "Johannes Wachs", "authors": "Johannes Wachs, Taha Yasseri, Bal\\'azs Lengyel, J\\'anos Kert\\'esz", "title": "Social capital predicts corruption risk in towns", "comments": "Submitted", "journal-ref": "Royal Society Open Science, 2019", "doi": "10.1098/rsos.182103", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corruption is a social plague: gains accrue to small groups, while its costs\nare borne by everyone. Significant variation in its level between and within\ncountries suggests a relationship between social structure and the prevalence\nof corruption, yet, large scale empirical studies thereof have been missing due\nto lack of data. In this paper we relate the structural characteristics of\nsocial capital of towns with corruption in their local governments. Using\ndatasets from Hungary, we quantify corruption risk by suppressed competition\nand lack of transparency in the town's awarded public contracts. We\ncharacterize social capital using social network data from a popular online\nplatform. Controlling for social, economic, and political factors, we find that\nsettlements with fragmented social networks, indicating an excess of\n\\textit{bonding social capital} have higher corruption risk and towns with more\ndiverse external connectivity, suggesting a surplus of \\textit{bridging social\ncapital} are less exposed to corruption. We interpret fragmentation as\nfostering in-group favoritism and conformity, which increase corruption, while\ndiversity facilitates impartiality in public life and stifles corruption.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 12:58:11 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Wachs", "Johannes", ""], ["Yasseri", "Taha", ""], ["Lengyel", "Bal\u00e1zs", ""], ["Kert\u00e9sz", "J\u00e1nos", ""]]}, {"id": "1810.05541", "submitter": "Van Hoa Nguyen Dr", "authors": "Van Hoa Nguyen and Yvon Besanger and Quoc Tuan Tran and Minh Tri Le", "title": "On the applicability of distributed ledger architectures to peer-to-peer\n  energy trading framework", "comments": "IEEE EEEIC 2018, Palermo, Italy, June 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more distributed renewable energy resources are integrated to the\ngrid, the traditional consumers have become the prosumers who can sell back\ntheir surplus energy to the others who are in energy shortage. This\npeer-to-peer (P2P) energy transaction framework benefits the end users,\nfinancially and in term of energy security; and the network operators, in term\nof flexibility in DRES management, peak load shifting and regulation of\nvoltage/frequency. Environmentally, P2P energy transaction also helps to reduce\ncarbon footprint, reduces DRES payback period and incentivizes the installation\nof DRES. The current centralized market model is no longer suitable and it is\ntherefore necessary to develop an adapted decentralized architecture for the\nadvanced P2P energy transaction framework intra/inter-microgrid. In this paper,\nwe discuss several distributed ledger approaches for such framework:\nBlockchain, Block Lattice and Directed Acyclic Graph (the Tangle). The\ntechnical advantages of these architectures as well as the persistent\nchallenges are then considered.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 11:34:22 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Nguyen", "Van Hoa", ""], ["Besanger", "Yvon", ""], ["Tran", "Quoc Tuan", ""], ["Le", "Minh Tri", ""]]}, {"id": "1810.05903", "submitter": "Joseph Y. Halpern", "authors": "Joseph Y. Halpern and Max Kleiman-Weiner", "title": "Towards Formal Definitions of Blameworthiness, Intention, and Moral\n  Responsibility", "comments": "Appears in AAAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide formal definitions of degree of blameworthiness and intention\nrelative to an epistemic state (a probability over causal models and a utility\nfunction on outcomes). These, together with a definition of actual causality,\nprovide the key ingredients for moral responsibility judgments. We show that\nthese definitions give insight into commonsense intuitions in a variety of\npuzzling cases from the literature.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 17:56:03 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Halpern", "Joseph Y.", ""], ["Kleiman-Weiner", "Max", ""]]}, {"id": "1810.05944", "submitter": "Pedro Saleiro", "authors": "Weiqiang Lin, Pedro Saleiro, Natasa Milic-Frayling, Eugene Ch'ng", "title": "Social Media Brand Engagement as a Proxy for E-commerce Activities: A\n  Case Study of Sina Weibo and JD", "comments": "WI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce platforms facilitate sales of products while product vendors\nengage in Social Media Activities (SMA) to drive E-commerce Platform Activities\n(EPA) of consumers, enticing them to search, browse and buy products. The\nfrequency and timing of SMA are expected to affect levels of EPA, increasing\nthe number of brand related queries, clickthrough, and purchase orders. This\npaper applies cross-sectional data analysis to explore such beliefs and\ndemonstrates weak-to-moderate correlations between daily SMA and EPA volumes.\nFurther correlation analysis, using 30-day rolling windows, shows a high\nvariability in correlation of SMA-EPA pairs and calls into question the\npredictive potential of SMA in relation to EPA. Considering the moderate\ncorrelation of selected SMA and EPA pairs (e.g., Post-Orders), we investigate\nwhether SMA features can predict changes in the EPA levels, instead of precise\nEPA daily volumes. We define such levels in terms of EPA distribution quantiles\n(2, 3, and 5 levels) over training data. We formulate the EPA quantile\npredictions as a multi-class categorization problem. The experiments with\nRandom Forest and Logistic Regression show a varied success, performing better\nthan random for the top quantiles of purchase orders and for the lowest\nquantile of search and clickthrough activities. Similar results are obtained\nwhen predicting multi-day cumulative EPA levels (1, 3, and 7 days). Our results\nhave considerable practical implications but, most importantly, urge the common\nbeliefs to be re-examined, seeking a stronger evidence of SMA effects on EPA.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 23:44:33 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Lin", "Weiqiang", ""], ["Saleiro", "Pedro", ""], ["Milic-Frayling", "Natasa", ""], ["Ch'ng", "Eugene", ""]]}, {"id": "1810.06152", "submitter": "Manoj M", "authors": "John Sherlock, Manoj Muniswamaiah, Lauren Clarke, Shawn Cicoria", "title": "Review of Barriers for Federated Identity Adoption for Users and\n  Organizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A look at Identity as a Service (IDaaS) and Federated Identity Management\n(FIM) and acceptance amongst organizations, users, and general population.\nWhile FIM has shown acceptance amongst educational, commercial and government\norganizations, the general population acting has not seen the level of trust as\nthe former. What are the barriers or enablers for acceptance that might allow,\nin the extreme example, the ability to logon to a bank with your Facebook\ncredentials and transact business?\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 02:05:43 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Sherlock", "John", ""], ["Muniswamaiah", "Manoj", ""], ["Clarke", "Lauren", ""], ["Cicoria", "Shawn", ""]]}, {"id": "1810.06519", "submitter": "Brett Israelsen", "authors": "Brett W Israelsen, Nisar R Ahmed, Eric Frew, Dale Lawrence, Brian\n  Argrow", "title": "Factorized Machine Self-Confidence for Decision-Making Agents", "comments": "title change, leaving as stand-alone tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic assurances from advanced autonomous systems assist human users in\nunderstanding, trusting, and using such systems appropriately. Designing these\nsystems with the capacity of assessing their own capabilities is one approach\nto creating an algorithmic assurance. The idea of `machine self-confidence' is\nintroduced for autonomous systems. Using a factorization based framework for\nself-confidence assessment, one component of self-confidence, called\n`solver-quality', is discussed in the context of Markov decision processes for\nautonomous systems. Markov decision processes underlie much of the theory of\nreinforcement learning, and are commonly used for planning and decision making\nunder uncertainty in robotics and autonomous systems. A `solver quality' metric\nis formally defined in the context of decision making algorithms based on\nMarkov decision processes. A method for assessing solver quality is then\nderived, drawing inspiration from empirical hardness models. Finally, numerical\nexperiments for an unmanned autonomous vehicle navigation problem under\ndifferent solver, parameter, and environment conditions indicate that the\nself-confidence metric exhibits the desired properties. Discussion of results,\nand avenues for future investigation are included.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 17:06:38 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:31:04 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Israelsen", "Brett W", ""], ["Ahmed", "Nisar R", ""], ["Frew", "Eric", ""], ["Lawrence", "Dale", ""], ["Argrow", "Brian", ""]]}, {"id": "1810.06745", "submitter": "Michael Bossetta", "authors": "Anamaria Dutceac Segesten, Michael Bossetta", "title": "Can Euroscepticism Contribute to a European Public Sphere? The\n  Europeanization of Media Discourses about Euroscepticism across Six Countries", "comments": "29 pages, 2 figures, 4 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares the media discourses about Euroscepticism in 2014 across\nsix countries (United Kingdom, Ireland, France, Spain, Sweden, and Denmark). We\nassess the extent to which the mass media's reporting of Euroscepticism\nindicates the Europeanization of public spheres. Using a mixed-methods approach\ncombining LDA topic modeling and qualitative coding, we find that approximately\n70 per cent of print articles mentioning \"Euroscepticism\" or \"Eurosceptic\" are\nframed in a non-domestic (i.e. European) context. In five of the six cases\nstudied, articles exhibiting a European context are strikingly similar in\ncontent, with the British case as the exception. However, coverage of British\nEuroscepticism drives Europeanization in other Member States. Bivariate\nlogistic regressions further reveal three macro-level structural variables that\nsignificantly correlate with a Europeanized media discourse: newspaper type\n(tabloid or broadsheet), presence of a strong Eurosceptic party, and\nrelationship to the EU budget (net contributor or receiver of EU funds).\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 23:06:03 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Segesten", "Anamaria Dutceac", ""], ["Bossetta", "Michael", ""]]}, {"id": "1810.07252", "submitter": "Mouhammd Alkasassbeh", "authors": "Mouhammd Alkasassbeh, Samail Al-Daleen", "title": "Classification of malware based on file content and characteristics", "comments": "12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, the industry of malware has come to be a market which brings on\nloads of money by investing and implementing high end technology to escape\ntraditional detection while vendors of anti-malware spend thousands if not\nmillions of dollars to stop the malware breach since it not only causes\nfinancial losses but also emotional ones. This paper study the classification\nof malware based on file content and characteristics, this was done through use\nof Clamp Integrated dataset that includes 5210 instances. There are different\nalgorithms were applied using Weka software, which are; ZeroR, bayesNet, SMO,\nKNN, J48, as well as Random Forest. The obtained results showed that Random\nForest that achieved the highest overall accuracy of (99.0979%). This means\nthat Random Forest algorithm is efficient to be used in malware classification\nbased on file content and characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 07:57:23 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Alkasassbeh", "Mouhammd", ""], ["Al-Daleen", "Samail", ""]]}, {"id": "1810.07273", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger, Aaron Halfaker", "title": "Operationalizing Conflict and Cooperation between Automated Software\n  Agents in Wikipedia: A Replication and Expansion of 'Even Good Bots Fight'", "comments": "33 pages. In ACM CSCW 2018", "journal-ref": "Proc ACM on Human Computer Interaction. 1(2), Article 49. CSCW\n  2018", "doi": "10.1145/3134684", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper replicates, extends, and refutes conclusions made in a study\npublished in PLoS ONE (\"Even Good Bots Fight\"), which claimed to identify\nsubstantial levels of conflict between automated software agents (or bots) in\nWikipedia using purely quantitative methods. By applying an integrative\nmixed-methods approach drawing on trace ethnography, we place these alleged\ncases of bot-bot conflict into context and arrive at a better understanding of\nthese interactions. We found that overwhelmingly, the interactions previously\ncharacterized as problematic instances of conflict are typically better\ncharacterized as routine, productive, even collaborative work. These results\nchallenge past work and show the importance of qualitative/quantitative\ncollaboration. In our paper, we present quantitative metrics and qualitative\nheuristics for operationalizing bot-bot conflict. We give thick descriptions of\nkinds of events that present as bot-bot reverts, helping distinguish conflict\nfrom non-conflict. We computationally classify these kinds of events through\npatterns in edit summaries. By interpreting found/trace data in the\nsocio-technical contexts in which people give that data meaning, we gain more\nfrom quantitative measurements, drawing deeper understandings about the\ngovernance of algorithmic systems in Wikipedia. We have also released our data\ncollection, processing, and analysis pipeline, to facilitate computational\nreproducibility of our findings and to help other researchers interested in\nconducting similar mixed-method scholarship in other platforms and contexts.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 20:59:19 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Geiger", "R. Stuart", ""], ["Halfaker", "Aaron", ""]]}, {"id": "1810.07290", "submitter": "Christoph Becker", "authors": "Christoph Becker", "title": "An analysis of Principle 1.2 in the new ACM Code Of Ethics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The new ACM Code of Ethics is a much-needed update, but introduced changes to\na central principle that have not been discussed widely enough. This commentary\naims to contribute to an improvement of the ethical standards we want computing\nprofessionals to aspire to by analyzing how changes introduced to Principle\n1.2, Avoid Harm, affect the Code as a whole.\n  The analysis shows that the principle is now internally inconsistent in\nstructure and externally inconsistent with Principle 2.3. It condones\nintentional harm too broadly and does not oblige those responsible to seek\nexternal justification. The existing Principle 2.3 clearly suggests that\nPrinciple 1.2 is unethical.\n  As a consequence, the change introduced to Principle 1.2 in the new Code of\nEthics nullifies the good intention of the code; counteracts the many good\nchanges introduced in all three drafts; and places the ACM in a dangerous moral\nposition.\n  This short paper explains why and recommends concrete actions.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:58:41 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Becker", "Christoph", ""]]}, {"id": "1810.07460", "submitter": "Jan Romportl", "authors": "Eva Zackova and Jan Romportl", "title": "What might matter in autonomous cars adoption: first person versus third\n  person scenarios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discussion between the automotive industry, governments, ethicists,\npolicy makers and general public about autonomous cars' moral agency is\nwidening, and therefore we see the need to bring more insight into what\nmeta-factors might actually influence the outcomes of such discussions, surveys\nand plebiscites. In our study, we focus on the psychological (personality\ntraits), practical (active driving experience), gender and rhetoric/framing\nfactors that might impact and even determine respondents' a priori preferences\nof autonomous cars' operation. We conducted an online survey (N=430) to collect\ndata that show that the third person scenario is less biased than the first\nperson scenario when presenting ethical dilemma related to autonomous cars.\nAccording to our analysis, gender bias should be explored in more extensive\nfuture studies as well. We recommend any participatory technology assessment\ndiscourse to use the third person scenario and to direct attention to the way\nany autonomous car related debate is introduced, especially in terms of\nlinguistic and communication aspects and gender.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 10:24:22 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Zackova", "Eva", ""], ["Romportl", "Jan", ""]]}, {"id": "1810.07646", "submitter": "Steven Swanson", "authors": "Steven Swanson", "title": "Trial by Flyer: Building Quadcopters From Scratch in a Ten-Week Capstone\n  Course", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our experience teaching an intensive capstone course in which\npairs of students build the hardware and software for a remote-controller\nquad-rotor aircraft (i.e., a quadcopter or \"drone\") from scratch in one 10-week\nquarter. The course covers printed circuit board (PCB) design and assembly,\nbasic control theory and sensor fusion, and embedded systems programming. To\nreduce the workload on course staff and provide higher-quality feedback on\nstudent designs, we have implemented an automated PCB design checking\ntool/autograder. We describe the course content in detail, identify the\nchallenges it presents to students and course staff, and propose changes to\nfurther increase student success and improve the scalability of the course.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2018 05:28:36 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 00:31:12 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2019 20:16:10 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Swanson", "Steven", ""]]}, {"id": "1810.07767", "submitter": "Suryanto Nugroho", "authors": "Suryanto Nugroho, Prihandoko", "title": "Architecture of Text Mining Application in Analyzing Public Sentiments\n  of West Java Governor Election using Naive Bayes Classification", "comments": "5 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection of West Java governor is one event that seizes the attention of\nthe public is no exception to social media users. Public opinion on a\nprospective regional leader can help predict electability and tendency of\nvoters. Data that can be used by the opinion mining process can be obtained\nfrom Twitter. Because the data is very varied form and very unstructured, it\nmust be managed and uninformed using data pre-processing techniques into\nsemi-structured data. This semi-structured information is followed by a\nclassification stage to categorize the opinion into negative or positive\nopinions. The research methodology uses a literature study where the research\nwill examine previous research on a similar topic. The purpose of this study is\nto find the right architecture to develop it into the application of twitter\nopinion mining to know public sentiments toward the election of the governor of\nwest java. The result of this research is that Twitter opinion mining is part\nof text mining where opinions in Twitter if they want to be classified, must go\nthrough the preprocessing text stage first. The preprocessing step required\nfrom twitter data is cleansing, case folding, POS Tagging and stemming. The\nresulting text mining architecture is an architecture that can be used for text\nmining research with different topics.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 07:14:10 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Nugroho", "Suryanto", ""], ["Prihandoko", "", ""]]}, {"id": "1810.07780", "submitter": "Juan Tapiador", "authors": "Haoyu Wang, Zhe Liu, Jingyue Liang, Narseo Vallina-Rodriguez, Yao Guo,\n  Li Li, Juan Tapiador, Jingcun Cao, Guoai Xu", "title": "Beyond Google Play: A Large-Scale Comparative Study of Chinese Android\n  App Markets", "comments": "To appear in the Proceedings of the 2018 Internet Measurement\n  Conference (IMC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  China is one of the largest Android markets in the world. As Chinese users\ncannot access Google Play to buy and install Android apps, a number of\nindependent app stores have emerged and compete in the Chinese app market. Some\nof the Chinese app stores are pre-installed vendor-specific app markets (e.g.,\nHuawei, Xiaomi and OPPO), whereas others are maintained by large tech companies\n(e.g., Baidu, Qihoo 360 and Tencent). The nature of these app stores and the\ncontent available through them vary greatly, including their trustworthiness\nand security guarantees.\n  As of today, the research community has not studied the Chinese Android\necosystem in depth. To fill this gap, we present the first large-scale\ncomparative study that covers more than 6 million Android apps downloaded from\n16 Chinese app markets and Google Play. We focus our study on catalog\nsimilarity across app stores, their features, publishing dynamics, and the\nprevalence of various forms of misbehavior (including the presence of fake,\ncloned and malicious apps). Our findings also suggest heterogeneous developer\nbehavior across app stores, in terms of code maintenance, use of third-party\nservices, and so forth. Overall, Chinese app markets perform substantially\nworse when taking active measures to protect mobile users and legit developers\nfrom deceptive and abusive actors, showing a significantly higher prevalence of\nmalware, fake, and cloned apps than Google Play.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 11:20:03 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Wang", "Haoyu", ""], ["Liu", "Zhe", ""], ["Liang", "Jingyue", ""], ["Vallina-Rodriguez", "Narseo", ""], ["Guo", "Yao", ""], ["Li", "Li", ""], ["Tapiador", "Juan", ""], ["Cao", "Jingcun", ""], ["Xu", "Guoai", ""]]}, {"id": "1810.07781", "submitter": "Federica Calanca", "authors": "Federica Calanca, Luiza Sayfullina, Lara Minkus, Claudia Wagner, Eric\n  Malmi", "title": "Responsible team players wanted: an analysis of soft skill requirements\n  in job advertisements", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past decades the importance of soft skills for labour market\noutcomes has grown substantially. This carries implications for labour market\ninequality, since previous research shows that soft skills are not valued\nequally across race and gender. This work explores the role of soft skills in\njob advertisements by drawing on methods from computational science as well as\non theoretical and empirical insights from economics, sociology and psychology.\nWe present a semi-automatic approach based on crowdsourcing and text mining for\nextracting a list of soft skills. We find that soft skills are a crucial\ncomponent of job ads, especially of low-paid jobs and jobs in female-dominated\nprofessions. Our work shows that soft skills can serve as partial predictors of\nthe gender composition in job categories and that not all soft skills receive\nequal wage returns at the labour market. Especially \"female\" skills are\nfrequently associated with wage penalties. Our results expand the growing\nliterature on the association of soft skills on wage inequality and highlight\ntheir importance for occupational gender segregation at labour markets.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 10:28:45 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 18:28:18 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Calanca", "Federica", ""], ["Sayfullina", "Luiza", ""], ["Minkus", "Lara", ""], ["Wagner", "Claudia", ""], ["Malmi", "Eric", ""]]}, {"id": "1810.07791", "submitter": "Dominika Woszczyk", "authors": "Dominika Woszczyk, Gerasimos Spanakis", "title": "MaaSim: A Liveability Simulation for Improving the Quality of Life in\n  Cities", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Urbanism is no longer planned on paper thanks to powerful models and 3D\nsimulation platforms. However, current work is not open to the public and lacks\nan optimisation agent that could help in decision making. This paper describes\nthe creation of an open-source simulation based on an existing Dutch\nliveability score with a built-in AI module. Features are selected using\nfeature engineering and Random Forests. Then, a modified scoring function is\nbuilt based on the former liveability classes. The score is predicted using\nRandom Forest for regression and achieved a recall of 0.83 with 10-fold\ncross-validation. Afterwards, Exploratory Factor Analysis is applied to select\nthe actions present in the model. The resulting indicators are divided into 5\ngroups, and 12 actions are generated. The performance of four optimisation\nalgorithms is compared, namely NSGA-II, PAES, SPEA2 and eps-MOEA, on three\nestablished criteria of quality: cardinality, the spread of the solutions,\nspacing, and the resulting score and number of turns. Although all four\nalgorithms show different strengths, eps-MOEA is selected to be the most\nsuitable for this problem. Ultimately, the simulation incorporates the model\nand the selected AI module in a GUI written in the Kivy framework for Python.\nTests performed on users show positive responses and encourage further\ninitiatives towards joining technology and public applications.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 15:19:41 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Woszczyk", "Dominika", ""], ["Spanakis", "Gerasimos", ""]]}, {"id": "1810.07829", "submitter": "Nicole Radziwill", "authors": "Nicole M. Radziwill", "title": "Quality 4.0: Let's Get Digital - The many ways the fourth industrial\n  revolution is reshaping the way we think about quality", "comments": null, "journal-ref": "Radziwill, Nicole M. (2018, October). Let's Get Digital: The many\n  ways the fourth industrial revolution is reshaping the way we think about\n  quality. Quality Progress, ASQ, p. 24-29", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technology landscape is richer and more promising than ever before. In\nmany ways, cloud computing, big data, virtual reality (VR), augmented reality\n(AR), blockchain, additive manufacturing, artificial intelligence (AI), machine\nlearning (ML), Internet Protocol Version 6 (IPv6), cyber-physical systems and\nthe Internet of Things (IoT) all represent new frontiers. These technologies\ncan help improve product and service quality, and organizational performance.\nIn many regions, the internet is now as ubiquitous as electricity. Components\nare relatively cheap. A robust ecosystem of open-source software libraries\nmeans that engineers can solve problems 100 times faster than just two decades\nago. This digital transformation is leading us toward connected intelligent\nautomation: smart, hyperconnected agents deployed in environments where humans\nand machines cooperate, and leverage data, to achieve shared goals. This is not\nthe worlds first industrial revolution. In fact, it is its fourth, and the\ndisruptive changes it will bring suggest we will need a fresh perspective on\nquality to adapt to it.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 23:06:06 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Radziwill", "Nicole M.", ""]]}, {"id": "1810.08036", "submitter": "Oscar Augusto Tellez Sanchez", "authors": "Oscar Tellez (DISP, INSA Lyon), Laurent Daguet (DISP, INSA Lyon),\n  Fabien Lehu\\'ed\\'e (LS2N, IMT Atlantique), Thibaud Monteiro (DISP, INSA\n  Lyon), Geovanny Osorio Montoya (OVE), Olivier P\\'eton (LS2N, IMT Atlantique),\n  Samuel Vercraene (DISP, INSA Lyon)", "title": "{\\'E}tude pour l'analyse et l'optimisation du transport des personnes en\n  situation de handicap", "comments": "in French", "journal-ref": "Conf{\\'e}rence francophone en gestion et ing{\\'e}nierie de\n  syst{\\`e}mes hospitaliers (GISEH), Aug 2018, Geneve, France", "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From 2010, the medical transport has become one of the top ten priorities of\nthe risk management plan in France because of the increase in the cost. For\nsocial and medico-social institutions (MSI), this cost represents the second\nafter that of the wages. In this context, the project NOMAd aims an overall\nimprovement of the daily transport of people between their home and their\n(MSI). To this end, we propose the sharing of transport between several ESMS.\nThis mutualization of transport makes possible to gather and optimize routes in\na certain geographical area. The challenge is to improve economic performance\nwhile maintaining economic, social and environmental goals. From a scientific\npoint of view, the studied problem is called the Time-Consistent-Dial-a-Ride\nProblem and aims to find a compromise between the objectives of the cost of\ntransport and the consistency of the service. Given the complexity of the\nproblem, we seek, first of all, to solve the problem for half a day. Then we\nconsider the whole week. To solve these problems, we use the Large Neighborhood\nSearch meta-heuristic and a master problem based on the Set Covering Problem.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 08:13:01 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Tellez", "Oscar", "", "DISP, INSA Lyon"], ["Daguet", "Laurent", "", "DISP, INSA Lyon"], ["Lehu\u00e9d\u00e9", "Fabien", "", "LS2N, IMT Atlantique"], ["Monteiro", "Thibaud", "", "DISP, INSA\n  Lyon"], ["Montoya", "Geovanny Osorio", "", "OVE"], ["P\u00e9ton", "Olivier", "", "LS2N, IMT Atlantique"], ["Vercraene", "Samuel", "", "DISP, INSA Lyon"]]}, {"id": "1810.08043", "submitter": "Teemu Lepp\\\"anen", "authors": "Markus Harju, Teemu Lepp\\\"anen, Ilkka Virtanen", "title": "Interaction and Student Dropout in Massive Open Online Courses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive Open Online Courses (MOOC) are seen as a next step in distance online\nlearning. In the MOOC vision, large numbers of students can access the course\ncontent over the Internet and complete courses at their own pace while\ninteracting with their peers and instructors online. Despite the initial\nenthusiasm about MOOCs, large number of students were observed dropping out of\nthe online courses. In this paper, we pinpoint the reasons behind the high\nstudent dropout rate and discuss how the interaction capabilities of MOOCs\ncontributed towards the low completion rate.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 08:22:37 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Harju", "Markus", ""], ["Lepp\u00e4nen", "Teemu", ""], ["Virtanen", "Ilkka", ""]]}, {"id": "1810.08055", "submitter": "Peter Rose", "authors": "Adam Rule, Amanda Birmingham, Cristal Zuniga, Ilkay Altintas,\n  Shih-Cheng Huang, Rob Knight, Niema Moshiri, Mai H. Nguyen, Sara Brin\n  Rosenthal, Fernando P\\'erez, Peter W. Rose", "title": "Ten Simple Rules for Reproducible Research in Jupyter Notebooks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reproducibility of computational studies is a hallmark of scientific\nmethodology. It enables researchers to build with confidence on the methods and\nfindings of others, reuse and extend computational pipelines, and thereby drive\nscientific progress. Since many experimental studies rely on computational\nanalyses, biologists need guidance on how to set up and document reproducible\ndata analyses or simulations.\n  In this paper, we address several questions about reproducibility. For\nexample, what are the technical and non-technical barriers to reproducible\ncomputational studies? What opportunities and challenges do computational\nnotebooks offer to overcome some of these barriers? What tools are available\nand how can they be used effectively?\n  We have developed a set of rules to serve as a guide to scientists with a\nspecific focus on computational notebook systems, such as Jupyter Notebooks,\nwhich have become a tool of choice for many applications. Notebooks combine\ndetailed workflows with narrative text and visualization of results. Combined\nwith software repositories and open source licensing, notebooks are powerful\ntools for transparent, collaborative, reproducible, and reusable data analyses.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 07:42:14 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Rule", "Adam", ""], ["Birmingham", "Amanda", ""], ["Zuniga", "Cristal", ""], ["Altintas", "Ilkay", ""], ["Huang", "Shih-Cheng", ""], ["Knight", "Rob", ""], ["Moshiri", "Niema", ""], ["Nguyen", "Mai H.", ""], ["Rosenthal", "Sara Brin", ""], ["P\u00e9rez", "Fernando", ""], ["Rose", "Peter W.", ""]]}, {"id": "1810.08091", "submitter": "Mike Thelwall Prof", "authors": "Mike Thelwall, Emma Stuart", "title": "She's Reddit: A source of statistically significant gendered interest\n  information?", "comments": "Thelwall, M. & Stuart, E. (in press). She's Reddit: A source of\n  statistically significant gendered interest information? Information\n  Processing & Management", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about gender differences in interests is necessary to disentangle\nthe effects of discrimination and choice when gender inequalities occur, such\nas in employment. This article assesses gender differences in interests within\nthe popular social news and entertainment site Reddit. A method to detect terms\nthat are statistically significantly used more by males or females in 181\nmillion comments in 100 subreddits shows that gender affects both the selection\nof subreddits and activities within most of them. The method avoids the hidden\ngender biases of topic modelling for this task. Although the method reveals\nstatistically significant gender differences in interests for topics that are\nextensively discussed on Reddit, it cannot give definitive causes, and\nimitation and sharing within the site mean that additional checking is needed\nto verify the results. Nevertheless, with care, Reddit can serve as a useful\nsource of insights into gender differences in interests.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 07:16:45 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Thelwall", "Mike", ""], ["Stuart", "Emma", ""]]}, {"id": "1810.08188", "submitter": "Massimiliano Dal Mas", "authors": "Massimiliano Dal Mas", "title": "Web Application for Collaborative Semantic Web Information Architecture", "comments": "7 pages, 3 figures, 2 tables, for details see:\n  http://www.maxdalmas.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper is analyzed the prototyping of the information visualization on\na Web Application for community purposes in a collaborative environment\nrepresenting an evolution of the actual social networks like Facebook,\nInstagram, Twitter, Linkedin, VirgilioPeople,... The intent of this work is to\nidentify the most common features of Web App for the information visualization\nbased on the Semantic Web and discuss how they support the user's requirements\nin a \"collaborative\" environment. A solution for the context-aware development\nof UI is based on \"joint meaning\" understood as a joint construal of the\ncreator of the community contents and the user of the community contents thanks\nto the context and interface adaptation using the faced taxonomy with the\nSemantic Web. A proof-of concept prototype allows showing that the proposed\nmethodological approach can also easily be applied to existing presentation\ncomponents, built with different languages and/or component technologies.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2018 17:54:13 GMT"}], "update_date": "2018-10-19", "authors_parsed": [["Mas", "Massimiliano Dal", ""]]}, {"id": "1810.08540", "submitter": "Ansh Patel", "authors": "Ansh Patel", "title": "Fairness for Whom? Critically reframing fairness with Nash Welfare\n  Product", "comments": "Submitted to FAT* 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on disparate impact in machine learning applications have\nsparked a debate around the concept of fairness along with attempts to\nformalize its different criteria. Many of these approaches focus on reducing\nprediction errors while maximizing sole utility of the institution. This work\nseeks to reconceptualize and critically frame the existing discourse on\nfairness by underlining the implicit biases embedded in common understandings\nof fairness in the literature and how they contrast with its corresponding\neconomic and legal definitions. This paper expands the concept of utility and\nfairness by bringing in concepts from established literature in welfare\neconomics and game theory. We then translate these concepts for the algorithmic\nprediction domain by defining a formalization of Nash Welfare Product that\nseeks to expand utility by collapsing that of the institution using the\nprediction tool and the individual subject to the prediction into one function.\nWe then apply a modulating function that makes the fairness and welfare\ntrade-offs explicit based on designated policy goals and then apply it to a\ntemporal model to take into account the effects of decisions beyond the scope\nof one-shot predictions. We apply this on a binary classification problem and\npresent results of a multi-epoch simulation based on the UCI Adult Income\ndataset and a test case analysis of the ProPublica recidivism dataset that show\nthat expanding the concept of utility results in a fairer distribution\ncorrecting for the embedded biases in the dataset without sacrificing the\nclassifier accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2018 15:12:56 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Patel", "Ansh", ""]]}, {"id": "1810.08666", "submitter": "Lindah Kotut", "authors": "Lindah Kotut, Michael Horning, Derek Haqq, Shuo Niu, Timothy Stelter,\n  D. Scott McCrickard", "title": "Tensions on Trails: Understanding Differences between Group and\n  Community Needs in Outdoor Settings", "comments": "Paper submitted to CSCW 2018 Rural Computing Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper compares the needs of groups and communities in outdoor settings,\nseeking to identify subtle but important differences in the ways that their\nneeds can be supported. We first examine the questions of who uses technology\nin outdoor settings, what their technological uses and needs are, and what\nconflicts exist between different trail users regarding technology use and\nexperience. We then consider selected categories of people to understand their\ndistinct needs when acting as groups and as communities. We conclude that it is\nimportant to explore the tensions between groups and communities to identify\ndesign opportunities.\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2018 20:34:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Kotut", "Lindah", ""], ["Horning", "Michael", ""], ["Haqq", "Derek", ""], ["Niu", "Shuo", ""], ["Stelter", "Timothy", ""], ["McCrickard", "D. Scott", ""]]}, {"id": "1810.08783", "submitter": "Marta Poblet", "authors": "Oleksii Konashevych, Marta Poblet", "title": "Is Blockchain Hashing an Effective Method for Electronic Governance?", "comments": "Short paper, 31st International Conference on Legal Knowledge and\n  Information Systems (JURIX 2018) Groningen (The Netherlands), 12-14 December", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Governments across the world are testing different uses of the blockchain for\nthe delivery of their public services. Blockchain hashing - or the insertion of\ndata in the blockchain - is one of the potential applications of the blockchain\nin this space. With this method, users can apply special scripts to add their\ndata to blockchain transactions, ensuring both immutability and publicity.\nBlockchain hashing also secures the integrity of the original data stored on\ncentral governmental databases. The paper starts by analysing possible\nscenarios of hashing on the blockchain and assesses in which cases it may work\nand in which it is less likely to add value to a public administration. Second,\nthe paper also compares this method with traditional digital signatures using\nPKI (Public Key Infrastructure) and discusses standardisation in each domain.\nThird, it also addresses issues related to concepts such as distributed ledger\ntechnology and permissioned blockchains. Finally, it raises the question of\nwhether blockchain hashing is an effective solution for electronic governance,\nand concludes that its value is controversial, even if it is improved by PKI\nand other security measures. In this regard, we claim that governments need\nfirst to identify pain points in governance, and then consider the trade-offs\nof the blockchain as a potential solution versus other alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 20 Oct 2018 10:02:52 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Konashevych", "Oleksii", ""], ["Poblet", "Marta", ""]]}, {"id": "1810.08988", "submitter": "Nora Connor", "authors": "Nora Connor and Aaron Clauset", "title": "Predicting the outcomes of policy diffusion from U.S. states to federal\n  law", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the United States, national policies often begin as state laws, which then\nspread from state to state until they gain momentum to become enacted as a\nnational policy. However, not every state policy reaches the national level.\nPrevious work has suggested that state-level policies are more likely to become\nnational policies depending on their geographic origin, their category of\nlegislation, or some characteristic of their initiating states, such as wealth,\nurbanicity, or ideological liberalism. Here, we tested these hypotheses by\ndivorcing the set of traits from the states' identities and building predictive\nforecasting models of state policies becoming national policies. Using a large,\nlongitudinal data set of state level policies and their traits, we train models\nto predict (i) whether policies become national policy, and (ii) how many\nstates must pass a given policy before it becomes national. Using these models\nas components, we then develop a logistic growth model to forecast when a\ncurrently spreading state-level policy is likely to pass at the national level.\nOur results indicate that traits of initiating states are not systematically\ncorrelated with becoming national policy and they predict neither how many\nstates must enact a policy before it becomes national nor whether it ultimately\nbecomes a national law. In contrast, the cumulative number of state-level\nadoptions of a policy is reasonably predictive of when a policy becomes\nnational. For the policies of same sex marriage and methamphetamine precursor\nlaws, we investigate how well the logistic growth model could forecast the\nprobable time horizon for true national action. We close with a data-driven\nforecast of when marijuana legalization and \"stand your ground\" laws will\nbecome national policy.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 16:51:00 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Connor", "Nora", ""], ["Clauset", "Aaron", ""]]}, {"id": "1810.09590", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger", "title": "The Lives of Bots", "comments": "Originally published in 2011", "journal-ref": "Book chapter in __Wikipedia: A Critical Point of View__ (Institute\n  of Network Cultures, Amsterdam), 2011", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automated software agents --- or bots --- have long been an important part of\nhow Wikipedia's volunteer community of editors write, edit, update, monitor,\nand moderate content. In this paper, I discuss the complex social and technical\nenvironment in which Wikipedia's bots operate. This paper focuses on the\nestablishment and role of English Wikipedia's bot policies and the Bot\nApprovals Group, a volunteer committee that reviews applications for new bots\nand helps resolve conflicts between Wikipedians about automation. In\nparticular, I examine an early bot controversy over the first bot in Wikipedia\nto automatically enforce a social norm about how Wikipedian editors ought to\ninteract in discussion spaces. As I show, bots enforce many rules in Wikipedia,\nbut humans produce these bots and negotiate rules around their operation.\nBecause of the openness of Wikipedia's processes around automation, we can\nvividly observe the often-invisible human work involved in such algorithmic\nsystems --- in stark contrast to most other user-generated content platforms.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 23:04:05 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Geiger", "R. Stuart", ""]]}, {"id": "1810.09832", "submitter": "Rediet Abebe", "authors": "Rediet Abebe, Kira Goldner", "title": "Mechanism Design for Social Good", "comments": "AI Matters, 2018", "journal-ref": null, "doi": "10.1145/3284751.328476", "report-no": null, "categories": "cs.GT cs.AI cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Across various domains--such as health, education, and housing--improving\nsocietal welfare involves allocating resources, setting policies, targeting\ninterventions, and regulating activities. These solutions have an immense\nimpact on the day-to-day lives of individuals, whether in the form of access to\nquality healthcare, labor market outcomes, or how votes are accounted for in a\ndemocratic society. Problems that can have an out-sized impact on individuals\nwhose opportunities have historically been limited often pose conceptual and\ntechnical challenges, requiring insights from many disciplines. Conversely, the\nlack of interdisciplinary approach can leave these urgent needs unaddressed and\ncan even exacerbate underlying socioeconomic inequalities. To realize the\nopportunities in these domains, we need to correctly set objectives and reason\nabout human behavior and actions. Doing so requires a deep grounding in the\nfield of interest and collaboration with domain experts who understand the\nsocietal implications and feasibility of proposed solutions. These insights can\nplay an instrumental role in proposing algorithmically-informed policies.\n  In this article, we describe the Mechanism Design for Social Good (MD4SG)\nresearch agenda, which involves using insights from algorithms, optimization,\nand mechanism design to improve access to opportunity. The MD4SG research\ncommunity takes an interdisciplinary, multi-stakeholder approach to improve\nsocietal welfare. We discuss three exciting research avenues within MD4SG\nrelated to improving access to opportunity in the developing world, labor\nmarkets and discrimination, and housing. For each of these, we showcase ongoing\nwork, underline new directions, and discuss potential for implementing existing\nwork in practice.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2018 18:41:52 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Abebe", "Rediet", ""], ["Goldner", "Kira", ""]]}, {"id": "1810.09841", "submitter": "Kristina Lerman", "authors": "Peter G Fennell, Zhiya Zuo, Kristina Lerman", "title": "Predicting and Explaining Behavioral Data with Structured Feature Space\n  Decomposition", "comments": "Code and replication data available at\n  https://github.com/peterfennell/S3D", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling human behavioral data is challenging due to its scale, sparseness\n(few observations per individual), heterogeneity (differently behaving\nindividuals), and class imbalance (few observations of the outcome of\ninterest). An additional challenge is learning an interpretable model that not\nonly accurately predicts outcomes, but also identifies important factors\nassociated with a given behavior. To address these challenges, we describe a\nstatistical approach to modeling behavioral data called the structured\nsum-of-squares decomposition (S3D). The algorithm, which is inspired by\ndecision trees, selects important features that collectively explain the\nvariation of the outcome, quantifies correlations between the features, and\npartitions the subspace of important features into smaller, more homogeneous\nblocks that correspond to similarly-behaving subgroups within the population.\nThis partitioned subspace allows us to predict and analyze the behavior of the\noutcome variable both statistically and visually, giving a medium to examine\nthe effect of various features and to create explainable predictions. We apply\nS3D to learn models of online activity from large-scale data collected from\ndiverse sites, such as Stack Exchange, Khan Academy, Twitter, Duolingo, and\nDigg. We show that S3D creates parsimonious models that can predict outcomes in\nthe held-out data at levels comparable to state-of-the-art approaches, but in\naddition, produces interpretable models that provide insights into behaviors.\nThis is important for informing strategies aimed at changing behavior,\ndesigning social systems, but also for explaining predictions, a critical step\ntowards minimizing algorithmic bias.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 17:52:30 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Fennell", "Peter G", ""], ["Zuo", "Zhiya", ""], ["Lerman", "Kristina", ""]]}, {"id": "1810.09842", "submitter": "Micha{\\l} Okulewicz", "authors": "Micha{\\l} Okulewicz, Weronika Aniper, Bart{\\l}omiej Dach, Piotr\n  Filarski, Piotr Jenczyk, Julita O{\\l}tusek", "title": "Bringing Together Project Simulation and Psychometric Tests: A Business\n  Game Proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article identifies a gap between the existence of a various psychometric\ntests approaches and other team performance assessment tools (e.g. business and\nmanagement games). As a response to the lack of tools able to utilize the\nknowledge about the behaviour patterns expressed in work environment and\ndescriptive business games, the article presents a game proposal. The mechanics\nof the proposed game should allow for a quantifiable assessment of an\nindividual in the simulated project development environment, making it possible\nto evaluate not only the team's performance, but the impact of actions of the\nindividual players and their interactions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2018 10:31:18 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Okulewicz", "Micha\u0142", ""], ["Aniper", "Weronika", ""], ["Dach", "Bart\u0142omiej", ""], ["Filarski", "Piotr", ""], ["Jenczyk", "Piotr", ""], ["O\u0142tusek", "Julita", ""]]}, {"id": "1810.09843", "submitter": "Martin Westerkamp", "authors": "Martin Westerkamp and Friedhelm Victor and Axel K\\\"upper", "title": "Blockchain-based Supply Chain Traceability: Token Recipes model\n  Manufacturing Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing consumer awareness as well as manufacturers' internal quality\nrequirements lead to novel demands on supply chain traceability. Existing\ncentralized solutions suffer from isolated data storage and lacking trust when\nmultiple parties are involved. Decentralized blockchain-based approaches\nattempt to overcome these shortcomings by creating digital representations of\nphysical goods to facilitate tracking across multiple entities. However, they\ncurrently do not capture the transformation of goods in manufacturing\nprocesses. Therefore, the relation between ingredients and product is lost,\nlimiting the ability to trace a product's provenance. We propose a\nblockchain-based supply chain traceability system using smart contracts. In\nsuch contracts, manufacturers define the composition of products in the form of\nrecipes. Each ingredient of the recipe is a non-fungible token that corresponds\nto a batch of physical goods. When the recipe is applied, its ingredients are\nconsumed and a new token is produced. This mechanism preserves the traceability\nof product transformations. The system is implemented for the Ethereum Virtual\nMachine and is applicable to any blockchain configuration that supports it. Our\nevaluation reveals that the gas costs scale linearly with the number of\nproducts considered in the system. This leads to the conclusion that the\nsolution can handle complex use cases.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 08:28:14 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Westerkamp", "Martin", ""], ["Victor", "Friedhelm", ""], ["K\u00fcpper", "Axel", ""]]}, {"id": "1810.09845", "submitter": "Bhairav Mehta", "authors": "Bhairav Mehta, Adithya Ramanathan", "title": "A Scalable, Flexible Augmentation of the Student Education Process", "comments": "Accepted to NIPS 2018 AI for Social Good Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel intelligent tutoring system which builds upon\nwell-established hypotheses in educational psychology and incorporates them\ninside of a scalable software architecture. Specifically, we build upon the\nknown benefits of knowledge vocalization, parallel learning, and immediate\nfeedback in the context of student learning. We show that open-source data\ncombined with state-of-the-art techniques in deep learning and natural language\nprocessing can apply the benefits of these three factors at scale, while still\noperating at the granularity of individual student needs and recommendations.\nAdditionally, we allow teachers to retain full control of the outputs of the\nalgorithms, and provide student statistics to help better guide classroom\ndiscussions towards topics that would benefit from more in-person review and\ncoverage. Our experiments and pilot programs show promising results, and cement\nour hypothesis that the system is flexible enough to serve a wide variety of\npurposes in both classroom and classroom-free settings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2018 04:47:52 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 21:51:25 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Mehta", "Bhairav", ""], ["Ramanathan", "Adithya", ""]]}, {"id": "1810.09851", "submitter": "Manoj Muniswamaiah", "authors": "John Sherlock, Manoj Muniswamaiah, Lauren Clarke, Shawn Cicoria", "title": "Classification of Titanic Passenger Data and Chances of Surviving the\n  Disaster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the Titanic disaster occurred just over 100 years ago, it still\nattracts researchers looking for understanding as to why some passengers\nsurvived while others perished. With the use of a modern data mining tools\n(Weka) and an available dataset we take a look at what factors or\nclassifications of passengers have a persuasive relationship towards survival\nfor passengers that took that fateful trip on April 10, 1912. The analysis\nlooks to identify characteristics of passengers cabin class, age, point of\ndeparture and that relationship to the chance of survival for the disaster.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 03:08:33 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Sherlock", "John", ""], ["Muniswamaiah", "Manoj", ""], ["Clarke", "Lauren", ""], ["Cicoria", "Shawn", ""]]}, {"id": "1810.09859", "submitter": "Tiago Sousa", "authors": "Tiago Sousa, Tiago Soares, Pierre Pinson, Fabio Moret, Thomas Baroche,\n  Etienne Sorin", "title": "Peer-to-peer and community-based markets: A comprehensive review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of more proactive consumers, the so-called \"prosumers\", with\nproduction and storage capabilities, is empowering the consumers and bringing\nnew opportunities and challenges to the operation of power systems in a market\nenvironment. Recently, a novel proposal for the design and operation of\nelectricity markets has emerged: these so-called peer-to-peer (P2P) electricity\nmarkets conceptually allow the prosumers to directly share their electrical\nenergy and investment. Such P2P markets rely on a consumer-centric and\nbottom-up perspective by giving the opportunity to consumers to freely choose\nthe way they are to source their electric energy. A community can also be\nformed by prosumers who want to collaborate, or in terms of operational energy\nmanagement. This paper contributes with an overview of these new P2P markets\nthat starts with the motivation, challenges, market designs moving to the\npotential future developments in this field, providing recommendations while\nconsidering a test-case.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2018 10:07:19 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 09:57:58 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Sousa", "Tiago", ""], ["Soares", "Tiago", ""], ["Pinson", "Pierre", ""], ["Moret", "Fabio", ""], ["Baroche", "Thomas", ""], ["Sorin", "Etienne", ""]]}, {"id": "1810.10322", "submitter": "Petar Radanliev", "authors": "Petar Radanliev", "title": "Economic impact of IoT cyber risk -- Analysing past and present to\n  predict the future developments in IoT risk analysis and IoT cyber insurance", "comments": "https://ieeexplore.ieee.org/document/8379690;\n  https://digital-library.theiet.org/content/conferences/10.1049/cp.2018.0003.\n  arXiv admin note: substantial text overlap with arXiv:1809.05229", "journal-ref": null, "doi": "10.1049/cp.2018.0003", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is focused on mapping the current evolution of Internet of Things\n(IoT) and its associated cyber risks for the Industry 4.0 (I4.0) sector. We\nreport the results of a qualitative empirical study that correlates academic\nliterature with 14 - I4.0 frameworks and initiatives. We apply the grounded\ntheory approach to synthesise the findings from our literature review, to\ncompare the cyber security frameworks and cyber security quantitative impact\nassessment models, with the world leading I4.0 technological trends. From the\nfindings, we build a new impact assessment model of IoT cyber risk in Industry\n4.0. We therefore advance the efforts of integrating standards and governance\ninto Industry 4.0 and offer a better understanding of economics impact\nassessment models for I4.0.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2018 09:00:46 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 21:47:55 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Radanliev", "Petar", ""]]}, {"id": "1810.10723", "submitter": "Jun Yang Dr.", "authors": "Min Chen, Jun Yang, Long Hu, M. Shamim Hossain, and Ghulam Muhammad", "title": "Urban Healthcare Big Data System Based on Crowdsourced and Cloud-Based\n  Air Quality Indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-accelerating process of globalization enables more than half the\npopulation to live in cities. Thus, the air quality in cities exerts critical\ninfluence on the health status of more and more urban residents. In this\narticle, based on urban air quality data collected through meteorological\nsites, mobile crowdsourcing, and IoT sensing, along with users' body signals,\nwe propose an urban healthcare big data system named UH-BigDataSys. In this\narticle, we first introduce a method of integrating multi-source air quality\ndata for the data preparation of artificial-intelligence-based smart urban\nservices. Then a testbed of UH-BigDataSys is set up with the deployment of\nair-quality-aware healthcare applications. Finally, we provide health guidance\nfor urban residents in aspects of respiratory diseases, outdoor travel, sleep\nquality, and so on. The ultimate goal of UH-BigDataSys is for urban residents\nto lead healthier lives.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 05:28:35 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Chen", "Min", ""], ["Yang", "Jun", ""], ["Hu", "Long", ""], ["Hossain", "M. Shamim", ""], ["Muhammad", "Ghulam", ""]]}, {"id": "1810.10731", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, David R. O'Brien, Kendra Albert, Salome\n  Vilojen", "title": "Law and Adversarial Machine Learning", "comments": "Minor edits. Corrected typos, Added references. 4 pages, submitted to\n  NIPS 2018 Workshop on Security in Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When machine learning systems fail because of adversarial manipulation, how\nshould society expect the law to respond? Through scenarios grounded in\nadversarial ML literature, we explore how some aspects of computer crime,\ncopyright, and tort law interface with perturbation, poisoning, model stealing\nand model inversion attacks to show how some attacks are more likely to result\nin liability than others. We end with a call for action to ML researchers to\ninvest in transparent benchmarks of attacks and defenses; architect ML systems\nwith forensics in mind and finally, think more about adversarial machine\nlearning in the context of civil liberties. The paper is targeted towards ML\nresearchers who have no legal background.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 06:17:34 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 02:45:10 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 02:02:46 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["O'Brien", "David R.", ""], ["Albert", "Kendra", ""], ["Vilojen", "Salome", ""]]}, {"id": "1810.10771", "submitter": "Irene Celino", "authors": "Irene Celino, Gloria Re Calegari", "title": "An Incremental Truth Inference Approach to Aggregate Crowdsourcing\n  Contributions in Games with a Purpose", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce our approach for incremental truth inference over the\ncontributions provided by players of Games with a Purpose: we motivate the need\nfor such a method with the specificity of GWAP vs. traditional crowdsourcing;\nwe explain and formalize the proposed process and we explain its positive\nconsequences; finally, we illustrate the results of an experimental comparison\nwith state-of-the-art approaches, performed on data collected through two\ndifferent GWAPs, thus showing the properties of our proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 08:43:29 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Celino", "Irene", ""], ["Calegari", "Gloria Re", ""]]}, {"id": "1810.10958", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "SilentPhone: Inferring User Unavailability based Opportune Moments to\n  Minimize Call Interruptions", "comments": "EAI Endorsed Transactions on Mobile Communications and Applications,\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of cell phones has made them the most personal and\nubiquitous communication devices nowadays. Typically, the ringing notifications\nof mobile phones are used to inform the users about the incoming calls.\nHowever, the notifications of inappropriate incoming calls sometimes cause\ninterruptions not only for the users but also the surrounding people. In this\npaper, we present a data-driven approach to infer the opportune moments for\nsuch phone call interruptions based on user's unavailability, i.e., when a user\nis unable to answer the incoming phone calls, by analyzing individual's past\nphone log data, and to discover the corresponding phone silent mode configuring\nrules for the purpose of minimizing call interruptions in an automated\nintelligent system. Experiments on the real mobile phone datasets show that our\napproach is able to identify the opportune moments for call interruptions and\ngenerates corresponding silent mode configuring rules by capturing the dominant\nbehavior of individual users' at various times-of-the-day and days-of-the week.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2018 14:56:02 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "1810.11185", "submitter": "Timothy NeCamp", "authors": "Timothy NeCamp, Josh Gardner, Christopher Brooks", "title": "Beyond A/B Testing: Sequential Randomization for Developing\n  Interventions in Scaled Digital Learning Environments", "comments": null, "journal-ref": "2019, The 9th International Learning Analytics & Knowledge\n  Conference, Tempe, AZ, USA. ACM, New York, NY, USA", "doi": "10.1145/3303772.3303812", "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized experiments ensure robust causal inference that are critical to\neffective learning analytics research and practice. However, traditional\nrandomized experiments, like A/B tests, are limiting in large scale digital\nlearning environments. While traditional experiments can accurately compare two\ntreatment options, they are less able to inform how to adapt interventions to\ncontinually meet learners' diverse needs. In this work, we introduce a trial\ndesign for developing adaptive interventions in scaled digital learning\nenvironments -- the sequential randomized trial (SRT). With the goal of\nimproving learner experience and developing interventions that benefit all\nlearners at all times, SRTs inform how to sequence, time, and personalize\ninterventions. In this paper, we provide an overview of SRTs, and we illustrate\nthe advantages they hold compared to traditional experiments. We describe a\nnovel SRT run in a large scale data science MOOC. The trial results\ncontextualize how learner engagement can be addressed through inclusive\nculturally targeted reminder emails. We also provide practical advice for\nresearchers who aim to run their own SRTs to develop adaptive interventions in\nscaled digital learning environments.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 04:15:51 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 02:46:46 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["NeCamp", "Timothy", ""], ["Gardner", "Josh", ""], ["Brooks", "Christopher", ""]]}, {"id": "1810.11295", "submitter": "Bhaskar Das", "authors": "Bhaskar Das, Jalal Almhana", "title": "Real-time Context-aware Learning System for IoT Applications", "comments": "34 pages, 12 figures, Journal article", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a real-time context-aware learning system along with the\narchitecture that runs on the mobile devices, provide services to the user and\nmanage the IoT devices. In this system, an application running on mobile\ndevices collected data from the sensors, learned about the user-defined\ncontext, made predictions in real-time and manage IoT devices accordingly.\nHowever, the computational power of the mobile devices makes it challenging to\nrun machine learning algorithms with acceptable accuracy. To solve this issue,\nsome authors have run machine learning algorithms on the server and transmitted\nthe results to the mobile devices. Although the context-aware predictions made\nby the server are more accurate than their mobile counterpart, it heavily\ndepends on the network connection for the delivery of the results to the\ndevices, which negatively affects real-time context-learning. Therefore, in\nthis work, we describe a context-learning algorithm for mobile devices which is\nless demanding on the computational resources and maintains the accuracy of the\nprediction by updating itself from the learning parameters obtained from the\nserver periodically. Experimental results show that the proposed light-weight\ncontext-learning algorithm can achieve mean accuracy up to 97.51% while mean\nexecution time requires only 11ms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 12:50:56 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Das", "Bhaskar", ""], ["Almhana", "Jalal", ""]]}, {"id": "1810.11383", "submitter": "Milan Cvitkovic", "authors": "Milan Cvitkovic", "title": "Some Requests for Machine Learning Research from the East African Tech\n  Scene", "comments": "Presented at NIPS 2018 Workshop on Machine Learning for the\n  Developing World", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on 46 in-depth interviews with scientists, engineers, and CEOs, this\ndocument presents a list of concrete machine research problems, progress on\nwhich would directly benefit tech ventures in East Africa.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2018 02:53:14 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 01:03:50 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Cvitkovic", "Milan", ""]]}, {"id": "1810.11704", "submitter": "Noah Giansiracusa", "authors": "Noah Giansiracusa and Cameron Ricciardi", "title": "Computational geometry and the U.S. Supreme Court", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the United States Supreme Court as an illuminative context in which to\ndiscuss three different spatial voting preference models: an instance of the\nwidely used single-peaked preferences, and two models that are more novel in\nwhich vote outcomes have a strength in addition to a location. We introduce\neach model from a formal axiomatic perspective, briefly discuss practical\nmotivation for each in terms of judicial behavior, prove mathematical\nrelationships among the voting coalitions compatible with each model, and then\nstudy the two-dimensional setting by presenting computational tools for working\nwith the models and by exploring these with judicial voting data from the\nSupreme Court.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 20:57:06 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Giansiracusa", "Noah", ""], ["Ricciardi", "Cameron", ""]]}, {"id": "1810.11732", "submitter": "Labib Terrissa", "authors": "Safa Meraghni, Labib Sadek Terrissa, Soheyb Ayad, Noureddine Zerhouni,\n  Christophe Varnier", "title": "Post-prognostics decision in Cyber-Physical Systems", "comments": "6 pages, 4 figures, 2018 IEEE Ic_ASET", "journal-ref": null, "doi": "10.1109/ASET.2018.8379859", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prognostics and Health Management (PHM) offers several benefits for\npredictive maintenance. It predicts the future behavior of a system as well as\nits Remaining Useful Life (RUL). This RUL is used to planned the maintenance\noperation to avoid the failure, the stop time and optimize the cost of the\nmaintenance and failure. However, with the development of the industry the\nassets are nowadays distributed this is why the PHM needs to be developed using\nthe new IT. In our work we propose a PHM solution based on Cyber physical\nsystem where the physical side is connected to the analyze process of the PHM\nwhich are developed in the cloud to be shared and to benefit of the cloud\ncharacteristics\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 23:47:39 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Meraghni", "Safa", ""], ["Terrissa", "Labib Sadek", ""], ["Ayad", "Soheyb", ""], ["Zerhouni", "Noureddine", ""], ["Varnier", "Christophe", ""]]}, {"id": "1810.11947", "submitter": "Bin Song", "authors": "Yue Zhang, Fang Tian, Bin Song, and Xiaojiang Du", "title": "Social Vehicle Swarms: A Novel Perspective on Social-aware Vehicular\n  Communication Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of vehicles is a promising area related to D2D communication and\ninternet of things. We present a novel perspective for vehicular\ncommunications, social vehicle swarms, to study and analyze socially aware\ninternet of vehicles with the assistance of an agent-based model intended to\nreveal hidden patterns behind superficial data. After discussing its\ncomponents, namely its agents, environments, and rules, we introduce supportive\ntechnology and methods, deep reinforcement learning, privacy preserving data\nmining and sub-cloud computing, in order to detect the most significant and\ninteresting information for each individual effectively, which is the key\ndesire. Finally, several relevant research topics and challenges are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 04:14:17 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Zhang", "Yue", ""], ["Tian", "Fang", ""], ["Song", "Bin", ""], ["Du", "Xiaojiang", ""]]}, {"id": "1810.12035", "submitter": "Philipp Morgner", "authors": "Philipp Morgner and Zinaida Benenson", "title": "Exploring Security Economics in IoT Standardization Efforts", "comments": "NDSS Workshop on Decentralized IoT Security and Standards (DISS)\n  2018, 18 February 2018, San Diego, CA, USA", "journal-ref": null, "doi": "10.14722/diss.2018.23009", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) propagates the paradigm of interconnecting\nbillions of heterogeneous devices by various manufacturers. To enable IoT\napplications, the communication between IoT devices follows specifications\ndefined by standard developing organizations. In this paper, we present a case\nstudy that investigates disclosed insecurities of the popular IoT standard\nZigBee, and derive general lessons about security economics in IoT\nstandardization efforts. We discuss the motivation of IoT standardization\nefforts that are primarily driven from an economic perspective, in which large\ninvestments in security are not considered necessary since the consumers do not\nreward them. Success at the market is achieved by being quick-to-market,\nproviding functional features and offering easy integration for complementors.\nNevertheless, manufacturers should not only consider economic reasons but also\nsee their responsibility to protect humans and technological infrastructures\nfrom being threatened by insecure IoT products. In this context, we propose a\nnumber of recommendations to strengthen the security design in future IoT\nstandardization efforts, ranging from the definition of a precise security\nmodel to the enforcement of an update policy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 10:07:17 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Morgner", "Philipp", ""], ["Benenson", "Zinaida", ""]]}, {"id": "1810.12345", "submitter": "Carlos Henrique Gomes Ferreira", "authors": "Carlos H. G. Ferreira, Breno de Souza Matos and Jusssara M. Almeida", "title": "Analyzing Ideological Communities in Congressional Voting Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-01129-1_16", "report-no": null, "categories": "cs.SI cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We here study the behavior of political party members aiming at identifying\nhow ideological communities are created and evolve over time in diverse\n(fragmented and non-fragmented) party systems. Using public voting data of both\nBrazil and the US, we propose a methodology to identify and characterize\nideological communities, their member polarization, and how such communities\nevolve over time, covering a 15-year period. Our results reveal very distinct\npatterns across the two case studies, in terms of both structural and dynamic\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 18:49:04 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Ferreira", "Carlos H. G.", ""], ["Matos", "Breno de Souza", ""], ["Almeida", "Jusssara M.", ""]]}, {"id": "1810.12379", "submitter": "S Uskudarli", "authors": "T. B. Dinesh and S. Uskudarli", "title": "Renarration for All", "comments": null, "journal-ref": "IIITB Data Science Communications, vol 1, (2016)", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accessibility of content for all has been a key goal of the Web since its\nconception. However, true accessibility -- access to relevant content in the\nglobal context -- has been elusive for reasons that extend beyond physical\naccessibility issues. Among them are the spoken languages, literacy levels,\nexpertise, and culture. These issues are highly significant, since information\nmay not reach those who are the most in need of it. For example, the minimum\nwage laws that are published in legalese on government sites and the\nlow-literate and immigrant populations. While some organizations and volunteers\nwork on bridging such gaps by creating and disseminating alternative versions\nof such content, Web scale solutions much be developed to take advantage of its\ndistributed dissemination capabilities. This work examines content\naccessibility from the perspective of inclusiveness. For this purpose, a human\nin the loop approach for renarrating Web content is proposed, where a\nrenarrator creates an alternative narrative of some Web content with the intent\nof extending its reach. A renarration relates some Web content with an\nalternative version by means of transformations like simplification,\nelaboration, translation, or production of audio and video material. This work\npresents a model and a basic architecture for supporting renarrations along\nwith various scenarios. We also discuss the potentials of the W3C specification\nfor Web Annotation Data Model towards a more inclusive and decentralized social\nweb.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 19:42:41 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Dinesh", "T. B.", ""], ["Uskudarli", "S.", ""]]}, {"id": "1810.12847", "submitter": "Bettina Berendt", "authors": "Bettina Berendt", "title": "AI for the Common Good?! Pitfalls, challenges, and Ethics Pen-Testing", "comments": "to appear in Paladyn. Journal of Behavioral Robotics; accepted on\n  27-10-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many AI researchers and practitioners have embarked on research\nvisions that involve doing AI for \"Good\". This is part of a general drive\ntowards infusing AI research and practice with ethical thinking. One frequent\ntheme in current ethical guidelines is the requirement that AI be good for all,\nor: contribute to the Common Good. But what is the Common Good, and is it\nenough to want to be good? Via four lead questions, I will illustrate\nchallenges and pitfalls when determining, from an AI point of view, what the\nCommon Good is and how it can be enhanced by AI. The questions are: What is the\nproblem / What is a problem?, Who defines the problem?, What is the role of\nknowledge?, and What are important side effects and dynamics? The illustration\nwill use an example from the domain of \"AI for Social Good\", more specifically\n\"Data Science for Social Good\". Even if the importance of these questions may\nbe known at an abstract level, they do not get asked sufficiently in practice,\nas shown by an exploratory study of 99 contributions to recent conferences in\nthe field. Turning these challenges and pitfalls into a positive\nrecommendation, as a conclusion I will draw on another characteristic of\ncomputer-science thinking and practice to make these impediments visible and\nattenuate them: \"attacks\" as a method for improving design. This results in the\nproposal of ethics pen-testing as a method for helping AI designs to better\ncontribute to the Common Good.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:41:22 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 12:34:32 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Berendt", "Bettina", ""]]}, {"id": "1810.12850", "submitter": "Robson Bonidia", "authors": "Robson P. Bonidia, Luiz A. L. Rodrigues, Anderson P. Avila-Santos,\n  Danilo S. Sanches, and Jacques D. Brancher", "title": "Computational Intelligence in Sports: A Systematic Literature Review", "comments": null, "journal-ref": "Advances in Human-Computer Interaction\n  (https://www.hindawi.com/journals/ahci/2018/3426178/)", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, data mining studies are being successfully conducted to estimate\nseveral parameters in a variety of domains. Data mining techniques have\nattracted the attention of the information industry and society as a whole, due\nto a large amount of data and the imminent need to turn it into useful\nknowledge. However, the effective use of data in some areas is still under\ndevelopment, as is the case in sports, which in recent years, has presented a\nslight growth; consequently, many sports organizations have begun to see that\nthere is a wealth of unexplored knowledge in the data extracted by them.\nTherefore, this article presents a systematic review of sports data mining.\nRegarding years 2010 to 2018, 31 types of research were found in this topic.\nBased on these studies, we present the current panorama, themes, the database\nused, proposals, algorithms, and research opportunities. Our findings provide a\nbetter understanding of the sports data mining potentials, besides motivating\nthe scientific community to explore this timely and interesting topic.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:46:08 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Bonidia", "Robson P.", ""], ["Rodrigues", "Luiz A. L.", ""], ["Avila-Santos", "Anderson P.", ""], ["Sanches", "Danilo S.", ""], ["Brancher", "Jacques D.", ""]]}, {"id": "1810.12859", "submitter": "Jaejun Lee", "authors": "Jaejun Lee, Raphael Tang, Jimmy Lin", "title": "JavaScript Convolutional Neural Networks for Keyword Spotting in the\n  Browser: An Experimental Analysis", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Used for simple commands recognition on devices from smart routers to mobile\nphones, keyword spotting systems are everywhere. Ubiquitous as well are web\napplications, which have grown in popularity and complexity over the last\ndecade with significant improvements in usability under cross-platform\nconditions. However, despite their obvious advantage in natural language\ninteraction, voice-enabled web applications are still far and few between. In\nthis work, we attempt to bridge this gap by bringing keyword spotting\ncapabilities directly into the browser. To our knowledge, we are the first to\ndemonstrate a fully-functional implementation of convolutional neural networks\nin pure JavaScript that runs in any standards-compliant browser. We also apply\nnetwork slimming, a model compression technique, to explore the\naccuracy-efficiency tradeoffs, reporting latency measurements on a range of\ndevices and software. Overall, our robust, cross-device implementation for\nkeyword spotting realizes a new paradigm for serving neural network\napplications, and one of our slim models reduces latency by 66% with a minimal\ndecrease in accuracy of 4% from 94% to 90%.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 16:58:36 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Lee", "Jaejun", ""], ["Tang", "Raphael", ""], ["Lin", "Jimmy", ""]]}, {"id": "1810.12909", "submitter": "Vincent Gauthier", "authors": "Ghazaleh Khodabandelou and Vincent Gauthier and Marco Fiore and Mounim\n  El-Yacoubi", "title": "Estimation of Static and Dynamic Urban Populations with Mobile Network\n  Metadata", "comments": null, "journal-ref": "IEEE Transaction on Mobile Computing, 2018", "doi": "10.1109/tmc.2018.2871156", "report-no": null, "categories": "cs.NI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication-enabled devices routinely carried by individuals have become\npervasive, opening unprecedented opportunities for collecting digital metadata\nabout the mobility of large populations. In this paper, we propose a novel\nmethodology for the estimation of people density at metropolitan scales, using\nsubscriber presence metadata collected by a mobile operator. Our approach suits\nthe estimation of static population densities, i.e., of the distribution of\ndwelling units per urban area contained in traditional censuses. More\nimportantly, it enables the estimation of dynamic population densities, i.e.,\nthe time-varying distributions of people in a conurbation. By leveraging\nsubstantial real-world mobile network metadata and ground-truth information, we\ndemonstrate that the accuracy of our solution is superior to that granted by\nstate-of-the-art methods in practical heterogeneous urban scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2018 14:21:25 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Khodabandelou", "Ghazaleh", ""], ["Gauthier", "Vincent", ""], ["Fiore", "Marco", ""], ["El-Yacoubi", "Mounim", ""]]}, {"id": "1810.13040", "submitter": "Dan Sholler", "authors": "Dan Sholler, Karthik Ram, Carl Boettiger, Daniel S. Katz", "title": "Enforcing public data archiving policies in academic publishing: A study\n  of ecology journals", "comments": "35 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the quality and efficiency of research, groups within the\nscientific community seek to exploit the value of data sharing. Funders,\ninstitutions, and specialist organizations are developing and implementing\nstrategies to encourage or mandate data sharing within and across disciplines,\nwith varying degrees of success. Academic journals in ecology and evolution\nhave adopted several types of public data archiving policies requiring authors\nto make data underlying scholarly manuscripts freely available. Yet anecdotes\nfrom the community and studies evaluating data availability suggest that these\npolicies have not obtained the desired effects, both in terms of quantity and\nquality of available datasets. We conducted a qualitative, interview-based\nstudy with journal editorial staff and other stakeholders in the academic\npublishing process to examine how journals enforce data archiving policies. We\nspecifically sought to establish who editors and other stakeholders perceive as\nresponsible for ensuring data completeness and quality in the peer review\nprocess. Our analysis revealed little consensus with regard to how data\narchiving policies should be enforced and who should hold authors accountable\nfor dataset submissions. Themes in interviewee responses included hopefulness\nthat reviewers would take the initiative to review datasets and trust in\nauthors to ensure the completeness and quality of their datasets. We highlight\nproblematic aspects of these thematic responses and offer potential starting\npoints for improvement of the public data archiving process.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 00:00:27 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Sholler", "Dan", ""], ["Ram", "Karthik", ""], ["Boettiger", "Carl", ""], ["Katz", "Daniel S.", ""]]}, {"id": "1810.13141", "submitter": "Sebastien Henry", "authors": "Thierno Diallo (Quartz), S\\'ebastien Henry (DISP), Yacine Ouzrout\n  (DISP)", "title": "Towards a more efficient use of process and product traceability data\n  for continuous improvement of industrial performances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays all industrial sectors are increasingly faced with the explosion in\nthe amount of data. Therefore, it raises the question of the efficient use of\nthis large amount of data. In this research work, we are concerned with process\nand product traceability data. In some sectors (e.g. pharmaceutical and\nagro-food), the collection and storage of these data are required. Beyond this\nconstraint (regulatory and / or contractual), we are interested in the use of\nthese data for continuous improvements of industrial performances. Two research\naxes were identified: product recall and responsiveness towards production\nhazards. For the first axis, a procedure for product recall exploiting\ntraceability data will be propose. The development of detection and prognosis\nfunctions combining process and product data is envisaged for the second axis.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 07:59:07 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Diallo", "Thierno", "", "Quartz"], ["Henry", "S\u00e9bastien", "", "DISP"], ["Ouzrout", "Yacine", "", "DISP"]]}, {"id": "1810.13193", "submitter": "Yacine Ouzrout", "authors": "Napaporn Reeveerakul (LIESP), Ridha Derrouiche (LIESP), Nopasit\n  Chakpitak (CAMT), Yacine Ouzrout (LIESP), Napat Harnpornchai, Abdelaziz\n  Bouras (LIESP)", "title": "A Decision Support Framework for Manufacturing Improvement and\n  Relocation Prevention in Thailand: Supply Chain Perspective", "comments": null, "journal-ref": "International Conference on Industrial Engineering and Systems\n  Management, May 2009, Montreal, Canada. pp.9, 2009", "doi": null, "report-no": "Lyon 2", "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The low economic growth and competition among neighbouring countries has\ncaused Foreign Direct nvestments (FDIs) to relocate their businesses. In order\nto prevent further business relocation, this aper proposes an integrated\nframework based on the supply chain to help analyse decision making for plant\nsituations and enhance manufacturing perrformance. The context of this\nperspective is pplied to manufacturers located in the industrial state region\nof Lumphun province, Thailand. Data collection and review of literature was\nused to identify the factors that influence industrial investment. The SCOR\nmodel was used to define the parameters, which here then used in Arena\nsimulation. The simulation needs to describe factors affected on industrial\nerformance. From this result, an integrated analysis model was built and the\nimportance of supply chain collaboration was identified. A Multi Agent System\n(MAS) was suggested to enhance of the effective nteraction between supply\nchain' agents. It is in order to mitigate risks among them.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 10:11:59 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Reeveerakul", "Napaporn", "", "LIESP"], ["Derrouiche", "Ridha", "", "LIESP"], ["Chakpitak", "Nopasit", "", "CAMT"], ["Ouzrout", "Yacine", "", "LIESP"], ["Harnpornchai", "Napat", "", "LIESP"], ["Bouras", "Abdelaziz", "", "LIESP"]]}, {"id": "1810.13332", "submitter": "Sebastien Henry", "authors": "Siraprapa Wattanakul (DISP), S\\'ebastien Henry (DISP), Mohand Lounes\n  Bentaha (DISP), Napaporn Reeveerakul, Yacine Ouzrout (DISP)", "title": "Improving risk management by using smart containers for real-time\n  traceability", "comments": null, "journal-ref": "9th International Conference on Logistics and Transport (ICLT\n  2017), Nov 2017, Bangkok, Thailand. 2017", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research proposes implications of application functions by using the\nchain traceability data acquired from the Smart Object attached with Extended\nReal-time Data (SO-ERD: e.g. smart container, smart pallet, etc.) to improve\nrisk management at the level of the logistics chain. Recent applications using\ntraceability data and major issues in traceability systems have been explored\nby an academic literature. Information is classified by the usage of current\ntraceability data for supporting risk detection and decisions in operational,\ntactical, and strategical levels. It is found that real-time data has been a\nsignificant impact on the usage for the transportation activity in all decision\nlevels such the function of food quality control and collaborative planning\namong partners. However, there are some uncertainties in the aggregation of\nevent-based traceability data captured by various partners which are preventing\nthe adoption of data usage for the chain. Under the environment of Industry 4.0\nand the Internet of Things (IoT), the SO-ERD enables independent data tracing\nthrough the chain in real-time. Its data has potential to overcome current\nissues and improve the supply chain risk management. Therefore, Implications of\nrisk management are proposed with the usage of SO-ERD data based on the\nliterature review which reveals current concerns of decision functions in the\nsupply chain. The implications can be an impact to the domain needs.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:22:28 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Wattanakul", "Siraprapa", "", "DISP"], ["Henry", "S\u00e9bastien", "", "DISP"], ["Bentaha", "Mohand Lounes", "", "DISP"], ["Reeveerakul", "Napaporn", "", "DISP"], ["Ouzrout", "Yacine", "", "DISP"]]}]