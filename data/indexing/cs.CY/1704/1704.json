[{"id": "1704.00119", "submitter": "Meysam Alizadeh", "authors": "Meysam Alizadeh, Ingmar Weber, Claudio Cioffi-Revilla, Santo\n  Fortunato, Michael Macy", "title": "Psychological and Personality Profiles of Political Extremists", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global recruitment into radical Islamic movements has spurred renewed\ninterest in the appeal of political extremism. Is the appeal a rational\nresponse to material conditions or is it the expression of psychological and\npersonality disorders associated with aggressive behavior, intolerance,\nconspiratorial imagination, and paranoia? Empirical answers using surveys have\nbeen limited by lack of access to extremist groups, while field studies have\nlacked psychological measures and failed to compare extremists with contrast\ngroups. We revisit the debate over the appeal of extremism in the U.S. context\nby comparing publicly available Twitter messages written by over 355,000\npolitical extremist followers with messages written by non-extremist U.S.\nusers. Analysis of text-based psychological indicators supports the moral\nfoundation theory which identifies emotion as a critical factor in determining\npolitical orientation of individuals. Extremist followers also differ from\nothers in four of the Big Five personality traits.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 04:31:37 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Alizadeh", "Meysam", ""], ["Weber", "Ingmar", ""], ["Cioffi-Revilla", "Claudio", ""], ["Fortunato", "Santo", ""], ["Macy", "Michael", ""]]}, {"id": "1704.00148", "submitter": "Khuong An Nguyen", "authors": "Khuong An Nguyen, Chris Watkins, Zhiyuan Luo", "title": "Co-location Epidemic Tracking on London Public Transports Using Low\n  Power Mobile Magnetometer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The public transports provide an ideal means to enable contagious diseases\ntransmission. This paper introduces a novel idea to detect co-location of\npeople in such environment using just the ubiquitous geomagnetic field sensor\non the smart phone. Essentially, given that all passengers must share the same\njourney between at least two consecutive stations, we have a long window to\nmatch the user trajectory. Our idea was assessed over a painstakingly survey of\nover 150 kilometres of travelling distance, covering different parts of London,\nusing the overground trains, the underground tubes and the buses.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 09:26:02 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Nguyen", "Khuong An", ""], ["Watkins", "Chris", ""], ["Luo", "Zhiyuan", ""]]}, {"id": "1704.00172", "submitter": "Manoel Horta Ribeiro", "authors": "Sagar Sen, Manoel Horta Ribeiro, Raquel C. de Melo Minardi, Wagner\n  Meira Jr., Mari Nigard", "title": "Portinari: A Data Exploration Tool to Personalize Cervical Cancer\n  Screening", "comments": "Conference paper published at ICSE 2017 Buenos Aires, at the Software\n  Engineering in Society Track. 10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Socio-technical systems play an important role in public health screening\nprograms to prevent cancer. Cervical cancer incidence has significantly\ndecreased in countries that developed systems for organized screening engaging\nmedical practitioners, laboratories and patients. The system automatically\nidentifies individuals at risk of developing the disease and invites them for a\nscreening exam or a follow-up exam conducted by medical professionals. A triage\nalgorithm in the system aims to reduce unnecessary screening exams for\nindividuals at low-risk while detecting and treating individuals at high-risk.\nDespite the general success of screening, the triage algorithm is a\none-size-fits all approach that is not personalized to a patient. This can\neasily be observed in historical data from screening exams. Often patients rely\non personal factors to determine that they are either at high risk or not at\nrisk at all and take action at their own discretion. Can exploring patient\ntrajectories help hypothesize personal factors leading to their decisions? We\npresent Portinari, a data exploration tool to query and visualize future\ntrajectories of patients who have undergone a specific sequence of screening\nexams. The web-based tool contains (a) a visual query interface (b) a backend\ngraph database of events in patients' lives (c) trajectory visualization using\nsankey diagrams. We use Portinari to explore diverse trajectories of patients\nfollowing the Norwegian triage algorithm. The trajectories demonstrated\nvariable degrees of adherence to the triage algorithm and allowed\nepidemiologists to hypothesize about the possible causes.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 14:24:21 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Sen", "Sagar", ""], ["Ribeiro", "Manoel Horta", ""], ["Minardi", "Raquel C. de Melo", ""], ["Meira", "Wagner", "Jr."], ["Nigard", "Mari", ""]]}, {"id": "1704.00384", "submitter": "Peter Corcoran", "authors": "Peter M. Corcoran", "title": "Third time is the charm - Why the World just might be ready for the\n  Internet of Things this time around", "comments": "Originally submitted to WF_IoT 2016 but was not considered to be an\n  'archival' paper by the reviewers; it seems they didn't feel they could\n  \"learn\" from the historical past of the IoT, especially from past mistakes in\n  introducing IoT technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technology to connect 'things' to the Internet has existed for more than\n20 years, so if we take a look back at recent history we might well be tempted\nto ask the question why will IoT 'happen' this time around. In this paper we\nexamine the origins of the Internet of Things, answer the question \"Why Now?\",\nand look forward to the next wave of disruptive technologies that will be\ncoming to a device near you in the next few years.\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 23:14:37 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Corcoran", "Peter M.", ""]]}, {"id": "1704.00556", "submitter": "Hassan Khosravi", "authors": "Hassan Khosravi, Kendra Cooper, Kirsty Kitto", "title": "RiPLE: Recommendation in Peer-Learning Environments Based on Knowledge\n  Gaps and Interests", "comments": "25 pages, 7 figures. The paper is accepted for publication in the\n  Journal of Educational Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various forms of Peer-Learning Environments are increasingly being used in\npost-secondary education, often to help build repositories of student generated\nlearning objects. However, large classes can result in an extensive repository,\nwhich can make it more challenging for students to search for suitable objects\nthat both reflect their interests and address their knowledge gaps. Recommender\nSystems for Technology Enhanced Learning (RecSysTEL) offer a potential solution\nto this problem by providing sophisticated filtering techniques to help\nstudents to find the resources that they need in a timely manner. Here, a new\nRecSysTEL for Recommendation in Peer-Learning Environments (RiPLE) is\npresented. The approach uses a collaborative filtering algorithm based upon\nmatrix factorization to create personalized recommendations for individual\nstudents that address their interests and their current knowledge gaps. The\napproach is validated using both synthetic and real data sets. The results are\npromising, indicating RiPLE is able to provide sensible personalized\nrecommendations for both regular and cold-start users under reasonable\nassumptions about parameters and user behavior.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 12:59:24 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Khosravi", "Hassan", ""], ["Cooper", "Kendra", ""], ["Kitto", "Kirsty", ""]]}, {"id": "1704.00725", "submitter": "Hector Zenil", "authors": "Hector Zenil", "title": "Reprogramming Matter, Life, and Purpose", "comments": "Invited contribution to 'Computing in the year 2065', A. Adamatzky\n  (Ed.), Springer Verlag and published in the International Journal of\n  Unconventional Computing, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reprogramming matter may sound far-fetched, but we have been doing it with\nincreasing power and staggering efficiency for at least 60 years, and for\ncenturies we have been paving the way toward the ultimate reprogrammed fate of\nthe universe, the vessel of all programs. How will we be doing it in 60 years'\ntime and how will it impact life and the purpose both of machines and of\nhumans?\n", "versions": [{"version": "v1", "created": "Sun, 2 Apr 2017 10:45:29 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 23:30:18 GMT"}, {"version": "v3", "created": "Thu, 11 May 2017 18:22:23 GMT"}, {"version": "v4", "created": "Sun, 13 Aug 2017 17:15:49 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Zenil", "Hector", ""]]}, {"id": "1704.00783", "submitter": "Gopal P. Sarma", "authors": "Gopal P. Sarma", "title": "Brief Notes on Hard Takeoff, Value Alignment, and Coherent Extrapolated\n  Volition", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  I make some basic observations about hard takeoff, value alignment, and\ncoherent extrapolated volition, concepts which have been central in analyses of\nsuperintelligent AI systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 19:45:04 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 20:32:30 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Sarma", "Gopal P.", ""]]}, {"id": "1704.00801", "submitter": "Luiz Capretz Dr.", "authors": "Pradeep Waychal and Luiz Fernando Capretz", "title": "Need for a Soft Dimension", "comments": "3rd International Conference on Software Engineering, Geneva,\n  Switzerland, March 2017", "journal-ref": null, "doi": "10.5121/csit.2017.70414", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is impossible to separate the human factors from software engineering\nexpertise during software development, because software is developed by people\nand for people. The intangible nature of software has made it a difficult\nproduct to successfully create, and an examination of the many reasons for\nmajor software system failures show that the reasons for failures eventually\ncome down to human issues. Software developers, immersed as they are in the\ntechnological aspect of the product, can quickly learn lessons from\ntechnological failures and readily come up with solutions to avoid them in the\nfuture, yet they do not learn lessons from human aspects in software\nengineering. Dealing with human errors is much more difficult for developers\nand often this aspect is overlooked in the evaluation process as developers\nmove on to issues that they are more comfortable solving. A major reason for\nthis oversight is that software psychology (the softer side) has not developed\nas extensively.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 20:38:25 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Waychal", "Pradeep", ""], ["Capretz", "Luiz Fernando", ""]]}, {"id": "1704.00939", "submitter": "Jacopo Staiano", "authors": "Youness Mansar, Lorenzo Gatti, Sira Ferradans, Marco Guerini, Jacopo\n  Staiano", "title": "Fortia-FBK at SemEval-2017 Task 5: Bullish or Bearish? Inferring\n  Sentiment towards Brands from Financial News Headlines", "comments": "6 pages, 1 figure; accepted for publication at the International\n  Workshop on Semantic Evaluation (SemEval-2017) to be held in conjunction with\n  ACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a methodology to infer Bullish or Bearish\nsentiment towards companies/brands. More specifically, our approach leverages\naffective lexica and word embeddings in combination with convolutional neural\nnetworks to infer the sentiment of financial news headlines towards a target\ncompany. Such architecture was used and evaluated in the context of the SemEval\n2017 challenge (task 5, subtask 2), in which it obtained the best performance.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 10:01:47 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Mansar", "Youness", ""], ["Gatti", "Lorenzo", ""], ["Ferradans", "Sira", ""], ["Guerini", "Marco", ""], ["Staiano", "Jacopo", ""]]}, {"id": "1704.00961", "submitter": "Ruck Thawonmas", "authors": "Pujana Paliyawan, Takahiro Kusano, Yuto Nakagawa, Tomohiro Harada,\n  Ruck Thawonmas", "title": "Adaptive Motion Gaming AI for Health Promotion", "comments": "A revised version of our paper for 2017 AAAI Spring Symposium Series\n  (Well-Being AI: From Machine Learning to Subjective Oriented Computing), San\n  Francisco,USA, Mar. 27-29, 2017. Revised contents, due to our correction of\n  (8), are highlighted in red. Many apologies, but the effectiveness of the\n  proposed method/approach in the paper still holds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a design of a non-player character (AI) for promoting\nbalancedness in use of body segments when engaging in full-body motion gaming.\nIn our experiment, we settle a battle between the proposed AI and a player by\nusing FightingICE, a fighting game platform for AI development. A middleware\ncalled UKI is used to allow the player to control the game by using body motion\ninstead of the keyboard and mouse. During gameplay, the proposed AI analyze\nhealth states of the player; it determines its next action by predicting how\neach candidate action, recommended by a Monte-Carlo tree search algorithm, will\ninduce the player to move, and how the player's health tends to be affected.\nOur result demonstrates successful improvement in balancedness in use of body\nsegments on 4 out of 5 subjects.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 11:29:02 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Paliyawan", "Pujana", ""], ["Kusano", "Takahiro", ""], ["Nakagawa", "Yuto", ""], ["Harada", "Tomohiro", ""], ["Thawonmas", "Ruck", ""]]}, {"id": "1704.00973", "submitter": "Maria Chiara Caschera Dr.", "authors": "Fernando Ferri, Patrizia Grifoni, Maria Chiara Caschera, Arianna\n  D'Ulizia, Caterina Pratico", "title": "KRC: KnowInG crowdsourcing platform supporting creativity and innovation", "comments": "15 pages", "journal-ref": "AISS (Advances in Information Sciences and Service Sciences),\n  Volume 5 Issue 16, November, 2013, Pages 1-15, ISSN 1976-3700 (Print)\n  2233-9345 (Online),GlobalCIS (Convergence Information Society, Republic of\n  Korea)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deep financial and economic crisis, which still characterizes these\nyears, requires searching for tools in order to enhance knowledge sharing,\ncreativity and innovation. The Internet is one of these tools that represents a\npractically infinite source of resources. In this perspective, the KnowInG\nproject, funded by the STC programme MED, is aimed at developing the KnowInG\nResource Centre (KRC), a sociotechnical system that works as a multiplier of\ninnovation. KRC was conceived as a crowdsourcing platform allowing people,\nuniversities, research centres, organizations and companies to be active actors\nof creative and innovation processes from a local to a transnational level.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 12:18:50 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Ferri", "Fernando", ""], ["Grifoni", "Patrizia", ""], ["Caschera", "Maria Chiara", ""], ["D'Ulizia", "Arianna", ""], ["Pratico", "Caterina", ""]]}, {"id": "1704.01117", "submitter": "Yoji Yamato", "authors": "Yoji Yamato", "title": "A study of posture judgement on vehicles using wearable acceleration\n  sensor", "comments": "2 pages, in Japanese, 2 figures, The 2017 IEICE General Conference,\n  BS-3-1, Mar. 2017", "journal-ref": "The 2017 IEICE General Conference, BS-3-1, Mar. 2017. (c) 2017\n  IEICE", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study methods to estimate drivers' posture in vehicles using acceleration\ndata of wearable sensor and conduct field tests. To prevent fatal accidents,\ndemands for safety management of bus and taxi are high. However, acceleration\nof vehicles is added to wearable sensor in vehicles. Therefore, we study\nmethods to estimate driving posture using acceleration data acquired from shirt\ntype wearable sensor hitoe and conduct field tests.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 23:36:02 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Yamato", "Yoji", ""]]}, {"id": "1704.01130", "submitter": "M\\'aria Csernoch", "authors": "M\\'aria Csernoch, Piroska Bir\\'o", "title": "Teaching methods are erroneous: approaches which lead to erroneous\n  end-user computing", "comments": "14 pages, 7 figures & tables", "journal-ref": "Proceedings of the EuSpRIG 2016 Conference \"Spreadsheet Risk\n  Management\" ISBN: 978-1-905404-53-7 pp 1-14", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If spreadsheets are not erroneous then who, or what, is? Research has found\nthat end-users are. If end-users are erroneous then why are they? Research has\nfound that responsibility lies with human beings' fast and slow thinking modes\nand the inappropriate way they use them. If we are aware of this peculiarity of\nhuman thinking, then why do we not teach students how to train their brains?\nThis is the main problem, this is the weakest link in the process: teaching. We\nhave to make teachers realize that end-users are erroneous because of the\nerroneous teaching approaches to end-user computing. The proportion of fast and\nslow thinking modes is not constant, and teachers are mistaken when they apply\nthe same proportion in both the teaching and end-user roles. Teachers should\nbelieve in the incremental nature of science and have high self-efficacy to\nmake students understand and appreciate science. This is not currently the case\nin ICT and CS, and it is high time fundamental changes were introduced.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 18:01:35 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Csernoch", "M\u00e1ria", ""], ["Bir\u00f3", "Piroska", ""]]}, {"id": "1704.01217", "submitter": "Harsh Taneja", "authors": "Harsh Taneja, Angela Xiao Wu, Stephanie Edgerly", "title": "Rethinking the Generational Gap in Online News Use: An Infrastructural\n  Perspective", "comments": "Harsh Taneja and Angela Xiao Wu are co-first authors. Cite as:\n  Taneja, H., Wu, A. X., & Edgerly, S. (Forthcoming). Rethinking the\n  Generational Gap in Online News Use: An Infrastructural Perspective. New\n  Media & Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our study investigates the role of infrastructures in shaping online news\nusage by contrasting use patterns of two social groups,millennials and\nboomers,that are specifically located in news infrastructures. Typically based\non self reported data, popular press and academics tend to highlight the\ngenerational gap in news usage and link it to divergence in values and\npreferences of the two age cohorts. In contrast, we conduct relational analyses\nof shared usage obtained from passively metered usage data across a vast range\nof online news outlets for millennials and boomers. We compare each cohort's\nusage networks comprising various types of news websites. Our analyses reveal a\nsmaller than commonly assumed generational gap in online news usage, with\ncharacteristics that manifest the multifarious effects of the infrastructural\naspect of the media environment, alongside those of preferences.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 23:21:44 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Taneja", "Harsh", ""], ["Wu", "Angela Xiao", ""], ["Edgerly", "Stephanie", ""]]}, {"id": "1704.01266", "submitter": "Parag Chandakkar", "authors": "Archana Paladugu, Parag S. Chandakkar, Peng Zhang and Baoxin Li", "title": "Supporting Navigation of Outdoor Shopping Complexes for\n  Visually-impaired Users through Multi-modal Data Fusion", "comments": "ICME 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outdoor shopping complexes (OSC) are extremely difficult for people with\nvisual impairment to navigate. Existing GPS devices are mostly designed for\nroadside navigation and seldom transition well into an OSC-like setting. We\nreport our study on the challenges faced by a blind person in navigating OSC\nthrough developing a new mobile application named iExplore. We first report an\nexploratory study aiming at deriving specific design principles for building\nthis system by learning the unique challenges of the problem. Then we present a\nmethodology that can be used to derive the necessary information for the\ndevelopment of iExplore, followed by experimental validation of the technology\nby a group of visually impaired users in a local outdoor shopping center. User\nfeedback and other experiments suggest that iExplore, while at its very initial\nphase, has the potential of filling a practical gap in existing assistive\ntechnologies for the visually impaired.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 04:24:41 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Paladugu", "Archana", ""], ["Chandakkar", "Parag S.", ""], ["Zhang", "Peng", ""], ["Li", "Baoxin", ""]]}, {"id": "1704.01347", "submitter": "Juhi Kulshrestha", "authors": "Juhi Kulshrestha, Motahhare Eslami, Johnnatan Messias, Muhammad Bilal\n  Zafar, Saptarshi Ghosh, Krishna P. Gummadi, Karrie Karahalios", "title": "Quantifying Search Bias: Investigating Sources of Bias for Political\n  Searches in Social Media", "comments": "In Proceedings of ACM Conference on Computer Supported Cooperative\n  Work & Social Computing (CSCW), Portland, USA, February 2017", "journal-ref": null, "doi": "10.1145/2998181.2998321", "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search systems in online social media sites are frequently used to find\ninformation about ongoing events and people. For topics with multiple competing\nperspectives, such as political events or political candidates, bias in the top\nranked results significantly shapes public opinion. However, bias does not\nemerge from an algorithm alone. It is important to distinguish between the bias\nthat arises from the data that serves as the input to the ranking system and\nthe bias that arises from the ranking system itself. In this paper, we propose\na framework to quantify these distinct biases and apply this framework to\npolitics-related queries on Twitter. We found that both the input data and the\nranking system contribute significantly to produce varying amounts of bias in\nthe search results and in different ways. We discuss the consequences of these\nbiases and possible mechanisms to signal this bias in social media search\nsystems' interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 10:12:56 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Kulshrestha", "Juhi", ""], ["Eslami", "Motahhare", ""], ["Messias", "Johnnatan", ""], ["Zafar", "Muhammad Bilal", ""], ["Ghosh", "Saptarshi", ""], ["Gummadi", "Krishna P.", ""], ["Karahalios", "Karrie", ""]]}, {"id": "1704.01414", "submitter": "Tomaso Aste", "authors": "Giuseppe Pappalardo, T. Di Matteo, Guido Caldarelli and Tomaso Aste", "title": "Blockchain Inefficiency in the Bitcoin Peers Network", "comments": "15 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate Bitcoin network monitoring the dynamics of blocks and\ntransactions. We unveil that 43\\% of the transactions are still not included in\nthe Blockchain after 1h from the first time they were seen in the network and\n20\\% of the transactions are still not included in the Blockchain after 30\ndays, revealing therefore great inefficiency in the Bitcoin system. However, we\nobserve that most of these `forgotten' transactions have low values and in\nterms of transferred value the system is less inefficient with 93\\% of the\ntransactions value being included into the Blockchain within 3h. The fact that\na sizeable fraction of transactions is not processed timely casts serious\ndoubts on the usability of the Bitcoin Blockchain for reliable time-stamping\npurposes and calls for a debate about the right systems of incentives which a\npeer-to-peer unintermediated system should introduce to promote efficient\ntransaction recording.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 13:35:36 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Pappalardo", "Giuseppe", ""], ["Di Matteo", "T.", ""], ["Caldarelli", "Guido", ""], ["Aste", "Tomaso", ""]]}, {"id": "1704.01422", "submitter": "Jisun An", "authors": "Jisun An and Haewoon Kwak", "title": "Data-driven Approach to Measuring the Level of Press Freedom Using Media\n  Attention Diversity from Unfiltered News", "comments": "The paper will be published in NECO'17, a workshop co-located with\n  ICWSM'17. Please cite the NECO'17 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Published by Reporters Without Borders every year, the Press Freedom Index\n(PFI) reflects the fear and tension in the newsroom pushed by the government\nand private sectors. While the PFI is invaluable in monitoring media\nenvironments worldwide, the current survey-based method has inherent\nlimitations to updates in terms of cost and time. In this work, we introduce an\nalternative way to measure the level of press freedom using media attention\ndiversity compiled from Unfiltered News.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 13:41:22 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["An", "Jisun", ""], ["Kwak", "Haewoon", ""]]}, {"id": "1704.01425", "submitter": "Jisun An", "authors": "Jisun An and Haewoon Kwak", "title": "What Gets Media Attention and How Media Attention Evolves Over Time -\n  Large-scale Empirical Evidence from 196 Countries", "comments": "The paper will be published in ICWSM'17. Please cite the ICWSM'17\n  paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that news topics, covered more frequently and over longer periods\nof time, are considered to be important to the public. Hence, what gets media\nattention and how media attention evolves over time has been studied for\ndecades in communication study. However, previous studies are confined to a few\ncountries or a few topics, mainly due to lack of longitudinal global data. In\nthis work, we use a large-scale news data compiled from 196 countries to\nprovide empirical analyses of media attention dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 13:49:10 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["An", "Jisun", ""], ["Kwak", "Haewoon", ""]]}, {"id": "1704.01442", "submitter": "Juhi Kulshrestha", "authors": "Juhi Kulshrestha, Muhammad Bilal Zafar, Lisette Espin-Noboa, Krishna\n  P. Gummadi, Saptarshi Ghosh", "title": "Characterizing Information Diets of Social Media Users", "comments": "In Proceeding of International AAAI Conference on Web and Social\n  Media (ICWSM), Oxford, UK, May 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread adoption of social media sites like Twitter and Facebook,\nthere has been a shift in the way information is produced and consumed.\nEarlier, the only producers of information were traditional news organizations,\nwhich broadcast the same carefully-edited information to all consumers over\nmass media channels. Whereas, now, in online social media, any user can be a\nproducer of information, and every user selects which other users she connects\nto, thereby choosing the information she consumes. Moreover, the personalized\nrecommendations that most social media sites provide also contribute towards\nthe information consumed by individual users. In this work, we define a concept\nof information diet -- which is the topical distribution of a given set of\ninformation items (e.g., tweets) -- to characterize the information produced\nand consumed by various types of users in the popular Twitter social media. At\na high level, we find that (i) popular users mostly produce very specialized\ndiets focusing on only a few topics; in fact, news organizations (e.g.,\nNYTimes) produce much more focused diets on social media as compared to their\nmass media diets, (ii) most users' consumption diets are primarily focused\ntowards one or two topics of their interest, and (iii) the personalized\nrecommendations provided by Twitter help to mitigate some of the topical\nimbalances in the users' consumption diets, by adding information on diverse\ntopics apart from the users' primary topics of interest.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 14:15:33 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Kulshrestha", "Juhi", ""], ["Zafar", "Muhammad Bilal", ""], ["Espin-Noboa", "Lisette", ""], ["Gummadi", "Krishna P.", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "1704.01802", "submitter": "Henrique Oliveira Santos", "authors": "Henrique Santos, Vasco Furtado, Paulo Pinheiro, Deborah L. McGuinness", "title": "Contextual Data Collection for Smart Cities", "comments": "In Proceedings of the 6th Workshop on Semantics for Smarter Cities\n  (S4SC 2015), Bethlehem, PA, USA, October 11-12, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of Smart Cities initiatives, national, regional and local governments\nall over the globe are under the mandate of being more open regarding how they\nshare their data. Under this mandate, many of these governments are publishing\ndata under the umbrella of open government data, which includes measurement\ndata from city-wide sensor networks. Furthermore, many of these data are\npublished in so-called data portals as documents that may be spreadsheets,\ncomma-separated value (CSV) data files, or plain documents in PDF or Word\ndocuments. The sharing of these documents may be a convenient way for the data\nprovider to convey and publish data but it is not the ideal way for data\nconsumers to reuse the data. For example, the problems of reusing the data may\nrange from difficulty opening a document that is provided in any format that is\nnot plain text, to the actual problem of understanding the meaning of each\npiece of knowledge inside of the document. Our proposal tackles those\nchallenges by identifying metadata that has been regarded to be relevant for\nmeasurement data and providing a schema for this metadata. We further leverage\nthe Human-Aware Sensor Network Ontology (HASNetO) to build an architecture for\ndata collected in urban environments. We discuss the use of HASNetO and the\nsupporting infrastructure to manage both data and metadata in support of the\nCity of Fortaleza, a large metropolitan area in Brazil.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 12:21:57 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Santos", "Henrique", ""], ["Furtado", "Vasco", ""], ["Pinheiro", "Paulo", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1704.01806", "submitter": "Henrique Oliveira Santos", "authors": "Paulo Pinheiro, Deborah L. McGuinness, Henrique Santos", "title": "Human-Aware Sensor Network Ontology: Semantic Support for Empirical Data\n  Collection", "comments": "In Proceedings of the 5th Workshop on Linked Science 2015 - Best\n  Practices and the Road Ahead (LISC 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant efforts have been made to understand and document knowledge\nrelated to scientific measurements. Many of those efforts resulted in one or\nmore high-quality ontologies that describe some aspects of scientific\nmeasurements, but not in a comprehensive and coherently integrated manner. For\ninstance, we note that many of these high-quality ontologies are not properly\naligned, and more challenging, that they have different and often conflicting\nconcepts and approaches for encoding knowledge about empirical measurements. As\na result of this lack of an integrated view, it is often challenging for\nscientists to determine whether any two scientific measurements were taken in\nsemantically compatible manners, thus making it difficult to decide whether\nmeasurements should be analyzed in combination or not. In this paper, we\npresent the Human-Aware Sensor Network Ontology that is a comprehensive\nalignment and integration of a sensing infrastructure ontology and a provenance\nontology. HASNetO has been under development for more than one year, and has\nbeen reviewed, shared and used by multiple scientific communities. The ontology\nhas been in use to support the data management of a number of large-scale\necological monitoring activities (observations) and empirical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 12:36:45 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Pinheiro", "Paulo", ""], ["McGuinness", "Deborah L.", ""], ["Santos", "Henrique", ""]]}, {"id": "1704.01855", "submitter": "Henrique Oliveira Santos", "authors": "Henrique Santos, Vasco Furtado", "title": "A Service-Oriented Architecture for Assisting the Authoring of Semantic\n  Crowd Maps", "comments": "In Advances in Artificial Intelligence - SBIA 2012", "journal-ref": null, "doi": "10.1007/978-3-642-34459-6_4", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there are increasingly more initiatives for the generation of\nsemantic knowledge based on user participation, there is still a shortage of\nplatforms for regular users to create applications on which semantic data can\nbe exploited and generated automatically. We propose an architecture, called\nSemantic Maps (SeMaps), for assisting the authoring and hosting of applications\nin which the maps combine the aggregation of a Geographic Information System\nand crowd-generated content (called here crowd maps). In these systems, the\ndigital map works as a blackboard for accommodating stories told by people\nabout events they want to share with others typically participating in their\nsocial networks. SeMaps offers an environment for the creation and maintenance\nof sites based on crowd maps with the possibility for the user to characterize\nsemantically that which s/he intends to mark on the map. The designer of a\ncrowd map, by informing a linguistic expression that designates what has to be\nmarked on the maps, is guided in a process that aims to associate a concept\nfrom a common-sense base to this linguistic expression. Thus, the crowd maps\nstart to have dominion over common-sense inferential relations that define the\nmeaning of the marker, and are able to make inferences about the network of\nlinked data. This makes it possible to generate maps that have the power to\nperform inferences and access external sources (such as DBpedia) that\nconstitute information that is useful and appropriate to the context of the\nmap. In this paper we describe the architecture of SeMaps and how it was\napplied in a crowd map authoring tool.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 14:22:56 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Santos", "Henrique", ""], ["Furtado", "Vasco", ""]]}, {"id": "1704.01946", "submitter": "Henrique Oliveira Santos", "authors": "Henrique Santos, Victor Dantas, Vasco Furtado, Paulo Pinheiro, Deborah\n  L. McGuinness", "title": "From Data to City Indicators: A Knowledge Graph for Supporting Automatic\n  Generation of Dashboards", "comments": "Accepted at the 14th Extended Semantic Web Conference (ESWC 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of Smart Cities, indicator definitions have been used to\ncalculate values that enable the comparison among different cities. The\ncalculation of an indicator values has challenges as the calculation may need\nto combine some aspects of quality while addressing different levels of\nabstraction. Knowledge graphs (KGs) have been used successfully to support\nflexible representation, which can support improved understanding and data\nanalysis in similar settings. This paper presents an operational description\nfor a city KG, an indicator ontology that support indicator discovery and data\nvisualization and an application capable of performing metadata analysis to\nautomatically build and display dashboards according to discovered indicators.\nWe describe our implementation in an urban mobility setting.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 17:29:16 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Santos", "Henrique", ""], ["Dantas", "Victor", ""], ["Furtado", "Vasco", ""], ["Pinheiro", "Paulo", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1704.02319", "submitter": "Andre Anjos", "authors": "Andr\\'e Anjos, Laurent El-Shafey and S\\'ebastien Marcel", "title": "BEAT: An Open-Source Web-Based Open-Science Platform", "comments": "References to papers published on the platform incorporated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased interest in computational sciences, machine learning (ML),\npattern recognition (PR) and big data, governmental agencies, academia and\nmanufacturers are overwhelmed by the constant influx of new algorithms and\ntechniques promising improved performance, generalization and robustness.\nSadly, result reproducibility is often an overlooked feature accompanying\noriginal research publications, competitions and benchmark evaluations. The\nmain reasons behind such a gap arise from natural complications in research and\ndevelopment in this area: the distribution of data may be a sensitive issue;\nsoftware frameworks are difficult to install and maintain; Test protocols may\ninvolve a potentially large set of intricate steps which are difficult to\nhandle. Given the raising complexity of research challenges and the constant\nincrease in data volume, the conditions for achieving reproducible research in\nthe domain are also increasingly difficult to meet.\n  To bridge this gap, we built an open platform for research in computational\nsciences related to pattern recognition and machine learning, to help on the\ndevelopment, reproducibility and certification of results obtained in the\nfield. By making use of such a system, academic, governmental or industrial\norganizations enable users to easily and socially develop processing\ntoolchains, re-use data, algorithms, workflows and compare results from\ndistinct algorithms and/or parameterizations with minimal effort. This article\npresents such a platform and discusses some of its key features, uses and\nlimitations. We overview a currently operational prototype and provide design\ninsights.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 07:18:55 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 07:53:11 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Anjos", "Andr\u00e9", ""], ["El-Shafey", "Laurent", ""], ["Marcel", "S\u00e9bastien", ""]]}, {"id": "1704.02602", "submitter": "Ferda Ofli", "authors": "Dat Tien Nguyen, Firoj Alam, Ferda Ofli, Muhammad Imran", "title": "Automatic Image Filtering on Social Networks Using Deep Learning and\n  Perceptual Hashing During Crises", "comments": "Accepted for publication in the 14th International Conference on\n  Information Systems For Crisis Response and Management (ISCRAM), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extensive use of social media platforms, especially during disasters,\ncreates unique opportunities for humanitarian organizations to gain situational\nawareness and launch relief operations accordingly. In addition to the textual\ncontent, people post overwhelming amounts of imagery data on social networks\nwithin minutes of a disaster hit. Studies point to the importance of this\nonline imagery content for emergency response. Despite recent advances in the\ncomputer vision field, automatic processing of the crisis-related social media\nimagery data remains a challenging task. It is because a majority of which\nconsists of redundant and irrelevant content. In this paper, we present an\nimage processing pipeline that comprises de-duplication and relevancy filtering\nmechanisms to collect and filter social media image content in real-time during\na crisis event. Results obtained from extensive experiments on real-world\ncrisis datasets demonstrate the significance of the proposed pipeline for\noptimal utilization of both human and machine computing resources.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 13:34:27 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Nguyen", "Dat Tien", ""], ["Alam", "Firoj", ""], ["Ofli", "Ferda", ""], ["Imran", "Muhammad", ""]]}, {"id": "1704.02799", "submitter": "Mohammad Azzeh", "authors": "Israa Ahmed Zriqat, Ahmad Mousa Altamimi, Mohammad Azzeh", "title": "A Comparative Study for Predicting Heart Diseases Using Data Mining\n  Classification Methods", "comments": null, "journal-ref": "ISSN 1947-5500", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the precision of heart diseases detection has been investigated by\nmany researchers in the literature. Such improvement induced by the\noverwhelming health care expenditures and erroneous diagnosis. As a result,\nvarious methodologies have been proposed to analyze the disease factors aiming\nto decrease the physicians practice variation and reduce medical costs and\nerrors. In this paper, our main motivation is to develop an effective\nintelligent medical decision support system based on data mining techniques. In\nthis context, five data mining classifying algorithms, with large datasets,\nhave been utilized to assess and analyze the risk factors statistically related\nto heart diseases in order to compare the performance of the implemented\nclassifiers (e.g., Na\\\"ive Bayes, Decision Tree, Discriminant, Random Forest,\nand Support Vector Machine). To underscore the practical viability of our\napproach, the selected classifiers have been implemented using MATLAB tool with\ntwo datasets. Results of the conducted experiments showed that all\nclassification algorithms are predictive and can give relatively correct\nanswer. However, the decision tree outperforms other classifiers with an\naccuracy rate of 99.0% followed by Random forest. That is the case because both\nof them have relatively same mechanism but the Random forest can build ensemble\nof decision tree. Although ensemble learning has been proved to produce\nsuperior results, but in our case the decision tree has outperformed its\nensemble version.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 11:03:14 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Zriqat", "Israa Ahmed", ""], ["Altamimi", "Ahmad Mousa", ""], ["Azzeh", "Mohammad", ""]]}, {"id": "1704.03330", "submitter": "Tiago Simas", "authors": "Tiago Simas, Michal Ficek, Albert Diaz-Guilera, Pere Obrador, Pablo R.\n  Rodriguez", "title": "Food-bridging: a new network construction to unveil the principles of\n  cooking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript we propose, analyse, and discuss a possible new principle\nbehind traditional cuisine: the Food-bridging hypothesis and its comparison\nwith the food-pairing hypothesis using the same dataset and graphical models\nemployed in the food-pairing study by Ahn et al. [Scientific Reports, 1:196\n(2011)].\n  The Food-bridging hypothesis assumes that if two ingredients do not share a\nstrong molecular or empirical affinity, they may become affine through a chain\nof pairwise affinities. That is, in a graphical model as employed by Ahn et\nal., a chain represents a path that joints the two ingredients, the shortest\npath represents the strongest pairwise chain of affinities between the two\ningredients.\n  Food-pairing and Food-bridging are different hypotheses that may describe\npossible mechanisms behind the recipes of traditional cuisines. Food-pairing\nintensifies flavour by mixing ingredients in a recipe with similar chemical\ncompounds, and food-bridging smoothes contrast between ingredients. Both\nfood-pairing and food-bridging are observed in traditional cuisines, as shown\nin this work.\n  We observed four classes of cuisines according to food-pairing and\nfood-bridging: (1) East Asian cuisines, at one extreme, tend to avoid\nfood-pairing as well as food-bridging; and (4) Latin American cuisines, at the\nother extreme, follow both principles. For the two middle classes: (2)\nSoutheastern Asian cuisines, avoid food-pairing and follow food-bridging; and\n(3) Western cuisines, follow food-pairing and avoid food-bridging.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 23:10:41 GMT"}, {"version": "v2", "created": "Fri, 14 Apr 2017 07:06:09 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Simas", "Tiago", ""], ["Ficek", "Michal", ""], ["Diaz-Guilera", "Albert", ""], ["Obrador", "Pere", ""], ["Rodriguez", "Pablo R.", ""]]}, {"id": "1704.03354", "submitter": "Flavio Calmon", "authors": "Flavio P. Calmon, Dennis Wei, Karthikeyan Natesan Ramamurthy, and Kush\n  R. Varshney", "title": "Optimized Data Pre-Processing for Discrimination Prevention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-discrimination is a recognized objective in algorithmic decision making.\nIn this paper, we introduce a novel probabilistic formulation of data\npre-processing for reducing discrimination. We propose a convex optimization\nfor learning a data transformation with three goals: controlling\ndiscrimination, limiting distortion in individual data samples, and preserving\nutility. We characterize the impact of limited sample size in accomplishing\nthis objective, and apply two instances of the proposed optimization to\ndatasets, including one on real-world criminal recidivism. The results\ndemonstrate that all three criteria can be simultaneously achieved and also\nreveal interesting patterns of bias in American society.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:26:00 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Calmon", "Flavio P.", ""], ["Wei", "Dennis", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1704.03361", "submitter": "Mart\\'i Cuquet", "authors": "Mart\\'i Cuquet, Guillermo Vega-Gorgojo, Hans Lammerant, Rachel Finn,\n  Umair ul Hassan", "title": "Societal impacts of big data: challenges and opportunities in Europe", "comments": "17 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the risks and opportunities of big data and the potential\nsocial benefits it can bring. The research is based on an analysis of the\nsocietal impacts observed in a set of six case studies across different\nEuropean sectors. These impacts are divided into economic, social and ethical,\nlegal and political impacts, and affect areas such as improved efficiency,\ninnovation and decision making, changing business models, dependency on public\nfunding, participation, equality, discrimination and trust, data protection and\nintellectual property rights, private and public tensions and losing control to\nactors abroad. A special focus is given to the risks and opportunities coming\nfrom the legal framework and how to counter the negative impacts of big data.\nRecommendations are presented for four specific legal frameworks: copyright and\ndatabase protection, protection of trade secrets, privacy and data protection\nand anti-discrimination. In addition, the potential social benefits of big data\nare exemplified in six domains: improved decision making and event detection;\ndata-driven innovations and new business models; direct social, environmental\nand other citizen benefits; citizen participation, transparency and public\ntrust; privacy-aware data practices; and big data for identifying\ndiscrimination. Several best practices are suggested to capture these benefits.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:34:24 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Cuquet", "Mart\u00ed", ""], ["Vega-Gorgojo", "Guillermo", ""], ["Lammerant", "Hans", ""], ["Finn", "Rachel", ""], ["Hassan", "Umair ul", ""]]}, {"id": "1704.03867", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Mumtaz Abdul Hameed, Nalin Asanka Gamagedara Arachchilage", "title": "A Conceptual Model for the Organisational Adoption of Information System\n  Security Innovations", "comments": "38 pages. arXiv admin note: substantial text overlap with\n  arXiv:1609.07911", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information System (IS) Security threats is still a major concern for many\norganisations. However, most organisations fall short in achieving a successful\nadoption and implementation of IS security measures. In this paper, we\ndeveloped a theoretical model for the adoption process of IS Security\ninnovations in organisations. The model was derived by combining four\ntheoretical models of innovation adoption, namely: Diffusion of Innovation\ntheory (DOI), the Technology Acceptance Model (TAM), the Theory of Planned\nBehaviour (TPB) and the Technology-Organisation-Environment (TOE) framework.\nThe model depicts IS security innovation adoption in organisations, as two\ndecision proceedings. The adoption process from the initiation stage until the\nacquisition of innovation is considered as a decision made by organisation\nwhile the process of innovation assimilation is assumed as a result of the user\nacceptance of innovation within the organisation. In addition, the model\ndescribes the IS Security adoption process progressing in three sequential\nstages, i.e. pre-adoption, adoption- decision and post-adoption phases. The\nmodel also introduces several factors that influence the different stages of IS\nSecurity innovation adoption process. This study contributes to IS security\nliterature by proposing an overall model of IS security adoption that includes\norganisational adoption and user acceptance of innovation in a single\nillustration. Also, IS security adoption model proposed in this study provides\nimportant practical implications for research and practice.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 17:57:00 GMT"}, {"version": "v2", "created": "Thu, 4 May 2017 06:41:25 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Hameed", "Mumtaz Abdul", ""], ["Arachchilage", "Nalin Asanka Gamagedara", ""]]}, {"id": "1704.04137", "submitter": "Yu-I Ha", "authors": "Yu-I Ha, Sejeong Kwon, Meeyoung Cha and Jungseock Joo", "title": "Fashion Conversation Data on Instagram", "comments": "10 pages, 6 figures, This paper will be presented at ICWSM'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fashion industry is establishing its presence on a number of\nvisual-centric social media like Instagram. This creates an interesting clash\nas fashion brands that have traditionally practiced highly creative and\neditorialized image marketing now have to engage with people on the platform\nthat epitomizes impromptu, realtime conversation. What kinds of fashion images\ndo brands and individuals share and what are the types of visual features that\nattract likes and comments? In this research, we take both quantitative and\nqualitative approaches to answer these questions. We analyze visual features of\nfashion posts first via manual tagging and then via training on convolutional\nneural networks. The classified images were examined across four types of\nfashion brands: mega couture, small couture, designers, and high street. We\nfind that while product-only images make up the majority of fashion\nconversation in terms of volume, body snaps and face images that portray\nfashion items more naturally tend to receive a larger number of likes and\ncomments by the audience. Our findings bring insights into building an\nautomated tool for classifying or generating influential fashion information.\nWe make our novel dataset of {24,752} labeled images on fashion conversations,\ncontaining visual and textual cues, available for the research community.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 13:49:50 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Ha", "Yu-I", ""], ["Kwon", "Sejeong", ""], ["Cha", "Meeyoung", ""], ["Joo", "Jungseock", ""]]}, {"id": "1704.04579", "submitter": "Nicole Radziwill", "authors": "Nicole M. Radziwill, Morgan C. Benton", "title": "Evaluating Quality of Chatbots and Intelligent Conversational Agents", "comments": "Software Quality Professional, June 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatbots are one class of intelligent, conversational software agents\nactivated by natural language input (which can be in the form of text, voice,\nor both). They provide conversational output in response, and if commanded, can\nsometimes also execute tasks. Although chatbot technologies have existed since\nthe 1960s and have influenced user interface development in games since the\nearly 1980s, chatbots are now easier to train and implement. This is due to\nplentiful open source code, widely available development platforms, and\nimplementation options via Software as a Service (SaaS). In addition to\nenhancing customer experiences and supporting learning, chatbots can also be\nused to engineer social harm - that is, to spread rumors and misinformation, or\nattack people for posting their thoughts and opinions online. This paper\npresents a literature review of quality issues and attributes as they relate to\nthe contemporary issue of chatbot development and implementation. Finally,\nquality assessment approaches are reviewed, and a quality assessment method\nbased on these attributes and the Analytic Hierarchy Process (AHP) is proposed\nand examined.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 04:47:25 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Radziwill", "Nicole M.", ""], ["Benton", "Morgan C.", ""]]}, {"id": "1704.04720", "submitter": "Soham De", "authors": "Soham De, Dana S. Nau, Michele J. Gelfand", "title": "Understanding Norm Change: An Evolutionary Game-Theoretic Approach\n  (Extended Version)", "comments": "In 2017 International Conference on Autonomous Agents & Multiagent\n  Systems (AAMAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human societies around the world interact with each other by developing and\nmaintaining social norms, and it is critically important to understand how such\nnorms emerge and change. In this work, we define an evolutionary game-theoretic\nmodel to study how norms change in a society, based on the idea that different\nstrength of norms in societies translate to different game-theoretic\ninteraction structures and incentives. We use this model to study, both\nanalytically and with extensive agent-based simulations, the evolutionary\nrelationships of the need for coordination in a society (which is related to\nits norm strength) with two key aspects of norm change: cultural inertia\n(whether or how quickly the population responds when faced with conditions that\nmake a norm change desirable), and exploration rate (the willingness of agents\nto try out new strategies). Our results show that a high need for coordination\nleads to both high cultural inertia and a low exploration rate, while a low\nneed for coordination leads to low cultural inertia and high exploration rate.\nThis is the first work, to our knowledge, on understanding the evolutionary\ncausal relationships among these factors.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 04:21:10 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["De", "Soham", ""], ["Nau", "Dana S.", ""], ["Gelfand", "Michele J.", ""]]}, {"id": "1704.04739", "submitter": "Mart\\'i Cuquet", "authors": "Christian Junker, Zaenal Akbar, Mart\\'i Cuquet", "title": "The network structure of visited locations according to geotagged social\n  media photos", "comments": "8 pages, 3 figures", "journal-ref": "PRO-VE 2017: Collaboration in a Data-Rich World, pp. 276-283\n  (2017)", "doi": "10.1007/978-3-319-65151-4_26", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Businesses, tourism attractions, public transportation hubs and other points\nof interest are not isolated but part of a collaborative system. Making such\ncollaborative network surface is not always an easy task. The existence of\ndata-rich environments can assist in the reconstruction of collaborative\nnetworks. They shed light into how their members operate and reveal a potential\nfor value creation via collaborative approaches. Social media data are an\nexample of a means to accomplish this task. In this paper, we reconstruct a\nnetwork of tourist locations using fine-grained data from Flickr, an online\ncommunity for photo sharing. We have used a publicly available set of Flickr\ndata provided by Yahoo! Labs. To analyse the complex structure of tourism\nsystems, we have reconstructed a network of visited locations in Europe,\nresulting in around 180,000 vertices and over 32 million edges. An analysis of\nthe resulting network properties reveals its complex structure.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 09:30:59 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Junker", "Christian", ""], ["Akbar", "Zaenal", ""], ["Cuquet", "Mart\u00ed", ""]]}, {"id": "1704.04846", "submitter": "Aneesha Bakharia Dr", "authors": "Aneesha Bakharia", "title": "PerspectivesX: A Proposed Tool to Scaffold Collaborative Learning\n  Activities within MOOCs", "comments": "Accepted as a Work In Progress paper at EMOOC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work-in-progress paper, we introduce the PerspectivesX tool which\naims to scaffold collaborative learning activities within MOOCs. The\nPerspectivesX tool has been designed to promote learner knowledge construction\nand curation for a range of multi-perspective elaboration techniques (e.g.,\nSWOT analysis and Six Thinking Hats). The PerspectivesX tool is designed to\nstore learner submissions in a searchable knowledge base which is able to be\npersisted across course re-runs and promotes the use of natural language\nprocessing techniques to allow course moderators to provide scalable feedback.\nIn this paper we outline the design principles that structured collaborative\nlearning tools need to adhere to, design a prototype tool (PerspectivesX) and\nevaluate whether MOOC platform extension frameworks are able to support the\nimplementation of the tool.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 01:54:01 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Bakharia", "Aneesha", ""]]}, {"id": "1704.04979", "submitter": "Vahid Moosavi", "authors": "Vahid Moosavi", "title": "Urban Data Streams and Machine Learning: A Case of Swiss Real Estate\n  Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-fin.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how using publicly available data streams and machine\nlearning algorithms one can develop practical data driven services with no\ninput from domain experts as a form of prior knowledge. We report the initial\nsteps toward development of a real estate portal in Switzerland. Based on\ncontinuous web crawling of publicly available real estate advertisements and\nusing building data from Open Street Map, we developed a system, where we\nroughly estimate the rental and sale price indexes of 1.7 million buildings\nacross the country. In addition to these rough estimates, we developed a web\nbased API for accurate automated valuation of rental prices of individual\nproperties and spatial sensitivity analysis of rental market. We tested several\nestablished function approximation methods against the test data to check the\nquality of the rental price estimations and based on our experiments, Random\nForest gives very reasonable results with the median absolute relative error of\n6.57 percent, which is comparable with the state of the art in the industry. We\nargue that while recently there have been successful cases of real estate\nportals, which are based on Big Data, majority of the existing solutions are\nexpensive, limited to certain users and mostly with non-transparent underlying\nsystems. As an alternative we discuss, how using the crawled data sets and\nother open data sets provided from different institutes it is easily possible\nto develop data driven services for spatial and temporal sensitivity analysis\nin the real estate market to be used for different stakeholders. We believe\nthat this kind of digital literacy can disrupt many other existing business\nconcepts across many domains.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 09:28:55 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Moosavi", "Vahid", ""]]}, {"id": "1704.04982", "submitter": "Utku Kose", "authors": "Aslihan Tufekci, Yahya Balaman, Utku Kose", "title": "Designing a Web-based interactive audio library automation system for\n  visually-impaired people and evaluation of its usability", "comments": "22 pages, 9 figures, 7 tables", "journal-ref": "Journal of Multidisciplinary Developments, 1(1), 2016, 38-59", "doi": null, "report-no": null, "categories": "cs.CY cs.DL cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The aim of this study is to introduce an application that enables information\nsharing and communication between visually-impaired individuals and\nable-bodied. For the purposes of the study, web-based audio library automation\nwas designed and the usability of the system was analyzed regarding the\nvolunteers who record audio books and the visually-impaired individuals. The\nvisually-impaired individuals who took part in the test procedures in order to\nmake a general evaluation of the system reported that the system was\ntheoretically necessary and successful. As for the usability aspect, positive\ncomments were received regarding the automation system developed. The authors\nbelieve that the current study is likely to be an alternative reference source\nfor the related literature and further research studies to be conducted in the\nfield.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 18:14:19 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Tufekci", "Aslihan", ""], ["Balaman", "Yahya", ""], ["Kose", "Utku", ""]]}, {"id": "1704.04985", "submitter": "Zineb Ait Haddouchane", "authors": "Zineb Ait Haddouchane, Soumia Bakkali, Souad Ajana, Karim Gassemi", "title": "The application of the competency-based approach to assess the training\n  and employment adequacy problem", "comments": "18 pages, 2 figures, 1 table", "journal-ref": "Volume 5, N{\\deg} 1, March 2017, International Journal of\n  Education (IJE)", "doi": "10.5121/ije.2017.5101", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This review paper fits in the context of the adequate matching of training to\nemployment, which is one of the main challenges that universities around the\nworld strive to meet. In higher education, the revision of curricula\nnecessitates a return to the skills required by the labor market to train\nskilled labors.\n  In this research, we started with the presentation of the conceptual\nframework. Then we quoted different currents that discussed the problematic of\nthe job training match from various perspectives. We proceeded to choose some\nstudies that have attempted to remedy this problem by adopting the\ncompetency-based approach that involves the referential line. This approach has\nas a main characteristic the attainment of the match between training and\nemployment. Therefore, it is a relevant solution for this problem. We\nscrutinized the selected studies, presenting their objectives, methodologies\nand results, and we provided our own analysis. Then, we focused on the Moroccan\ncontext through observations and studies already conducted. And finally, we\nintroduced the problematic of our future project.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 11:11:12 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Haddouchane", "Zineb Ait", ""], ["Bakkali", "Soumia", ""], ["Ajana", "Souad", ""], ["Gassemi", "Karim", ""]]}, {"id": "1704.04988", "submitter": "Yuri Gordienko G.", "authors": "Yu. Gordienko, S. Stirenko, O. Alienin, K. Skala, Z. Soyat, A. Rojbi,\n  J.R. L\\'opez Benito, E. Artetxe Gonz\\'alez, U. Lushchyk, L. Sajn, A. Llorente\n  Coto, G. Jervan", "title": "Augmented Coaching Ecosystem for Non-obtrusive Adaptive Personalized\n  Elderly Care on the Basis of Cloud-Fog-Dew Computing Paradigm", "comments": "6 pages, 2 figures, 40th International Convention on Information and\n  Communication Technology, Electronics and Microelectronics (MIPRO) Opatija,\n  Croatia (2017)", "journal-ref": "Proceedings of MIPRO 2017 40th Jubilee International Convention\n  (Opatija, Croatia) 387-392, ISBN 978-953-233-093-9", "doi": "10.23919/MIPRO.2017.7973449", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concept of the augmented coaching ecosystem for non-obtrusive adaptive\npersonalized elderly care is proposed on the basis of the integration of new\nand available ICT approaches. They include the multimodal user interface\n(MMUI), augmented reality (AR), machine learning (ML), Internet of Things\n(IoT), and machine-to-machine (M2M) interactions. The ecosystem is based on the\nCloud-Fog-Dew computing paradigm services, providing a full symbiosis by\nintegrating the whole range from low-level sensors up to high-level services\nusing integration efficiency inherent in synergistic use of applied\ntechnologies. Inside of this ecosystem, all of them are encapsulated in the\nfollowing network layers: Dew, Fog, and Cloud computing layer. Instead of the\n\"spaghetti connections\", \"mosaic of buttons\", \"puzzles of output data\", etc.,\nthe proposed ecosystem provides the strict division in the following dataflow\nchannels: consumer interaction channel, machine interaction channel, and\ncaregiver interaction channel. This concept allows to decrease the physical,\ncognitive, and mental load on elderly care stakeholders by decreasing the\nsecondary human-to-human (H2H), human-to-machine (H2M), and machine-to-human\n(M2H) interactions in favor of M2M interactions and distributed Dew Computing\nservices environment. It allows to apply this non-obtrusive augmented reality\necosystem for effective personalized elderly care to preserve their physical,\ncognitive, mental and social well-being.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 11:55:44 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Gordienko", "Yu.", ""], ["Stirenko", "S.", ""], ["Alienin", "O.", ""], ["Skala", "K.", ""], ["Soyat", "Z.", ""], ["Rojbi", "A.", ""], ["Benito", "J. R. L\u00f3pez", ""], ["Gonz\u00e1lez", "E. Artetxe", ""], ["Lushchyk", "U.", ""], ["Sajn", "L.", ""], ["Coto", "A. Llorente", ""], ["Jervan", "G.", ""]]}, {"id": "1704.05084", "submitter": "Poonam Yadav Dr", "authors": "Poonam Yadav and John Darlington", "title": "Conceptual Frameworks for Building Online Citizen Science Projects", "comments": null, "journal-ref": "Human Computation (2016) 3:1:213-223 ISSN: 2330-8001, DOI:\n  10.15346/hc.v3i1.12", "doi": "10.15346/hc.v3i1.12", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, citizen science has grown in popularity due to a number of\nreasons, including the emphasis on informal learning and creativity potential\nassociated with these initiatives. Citizen science projects address research\nquestions from various domains, ranging from Ecology to Astronomy. Due to the\nadvancement of communication technologies, which makes outreach and engagement\nof wider communities easier, scientists are keen to turn their own research\ninto citizen science projects. However, the development, deployment and\nmanagement of these projects remains challenging. One of the most important\nchallenges is building the project itself. There is no single tool or\nframework, which guides the step-by-step development of the project, since\nevery project has specific characteristics, such as geographical constraints or\nvolunteers' mode of participation. Therefore, in this article, we present a\nseries of conceptual frameworks for categorisation, decision and deployment,\nwhich guide a citizen science project creator in every step of creating a new\nproject starting from the research question to project deployment. The\nframeworks are designed with consideration to the properties of already\nexisting citizen science projects and could be easily extended to include other\ndimensions, which are not currently perceived.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 18:20:54 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Yadav", "Poonam", ""], ["Darlington", "John", ""]]}, {"id": "1704.05543", "submitter": "Sreecharan Sankaranarayanan", "authors": "Gaurav Singh Tomar, Sreecharan Sankaranarayanan, Xu Wang and Carolyn\n  Penstein Ros\\'e", "title": "Coordinating Collaborative Chat in Massive Open Online Courses", "comments": "8 pages", "journal-ref": "Proceedings of the International Conference of the Learning\n  Sciences 2016, Volume 1, pp 607-614", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An earlier study of a collaborative chat intervention in a Massive Open\nOnline Course (MOOC) identified negative effects on attrition stemming from a\nrequirement for students to be matched with exactly one partner prior to\nbeginning the activity. That study raised questions about how to orchestrate a\ncollaborative chat intervention in a MOOC context in order to provide the\nbenefit of synchronous social engagement without the coordination difficulties.\nIn this paper we present a careful analysis of an intervention designed to\novercome coordination difficulties by welcoming students into the chat on a\nrolling basis as they arrive rather than requiring them to be matched with a\npartner before beginning. The results suggest the most positive impact when\nexperiencing a chat with exactly one partner rather than more or less. A\nqualitative analysis of the chat data reveals differential experiences between\nthese configurations that suggests a potential explanation for the effect and\nraises questions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 21:57:10 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Tomar", "Gaurav Singh", ""], ["Sankaranarayanan", "Sreecharan", ""], ["Wang", "Xu", ""], ["Ros\u00e9", "Carolyn Penstein", ""]]}, {"id": "1704.05573", "submitter": "Yoji Yamato", "authors": "Yoji Yamato", "title": "Proposal of Vital Data Analysis Platform using Wearable Sensor", "comments": "6 pages, 2 figures, 5th IIAE International Conference on Industrial\n  Application Engineering 2017 (ICIAE2017), pp.138-143, Mar. 2017", "journal-ref": "5th IIAE International Conference on Industrial Application\n  Engineering 2017 (ICIAE2017), pp.138-143, Mar. 2017", "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a vital data analysis platform which resolves\nexisting problems to utilize vital data for real-time actions. Recently, IoT\ntechnologies have been progressed but in the healthcare area, real-time actions\nbased on analyzed vital data are not considered sufficiently yet. The causes\nare proper use of analyzing methods of stream / micro batch processing and\nnetwork cost. To resolve existing problems, we propose our vital data analysis\nplatform. Our platform collects vital data of Electrocardiograph and\nacceleration using an example of wearable vital sensor and analyzes them to\nextract posture, fatigue and relaxation in smart phones or cloud. Our platform\ncan show analyzed dangerous posture or fatigue level change. We implemented the\nplatform. And we are now preparing a field test.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 01:16:24 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Yamato", "Yoji", ""]]}, {"id": "1704.05730", "submitter": "Evaggelia Pitoura", "authors": "Evaggelia Pitoura, Panayiotis Tsaparas, Giorgos Flouris, Irini\n  Fundulaki, Panagiotis Papadakos, Serge Abiteboul, Gerhard Weikum", "title": "On Measuring Bias in Online Information", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in online information has recently become a pressing issue, with search\nengines, social networks and recommendation services being accused of\nexhibiting some form of bias. In this vision paper, we make the case for a\nsystematic approach towards measuring bias. To this end, we discuss formal\nmeasures for quantifying the various types of bias, we outline the system\ncomponents necessary for realizing them, and we highlight the related research\nchallenges and open problems.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 13:41:50 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 07:52:26 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Pitoura", "Evaggelia", ""], ["Tsaparas", "Panayiotis", ""], ["Flouris", "Giorgos", ""], ["Fundulaki", "Irini", ""], ["Papadakos", "Panagiotis", ""], ["Abiteboul", "Serge", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1704.05815", "submitter": "Thomas Louail", "authors": "Thomas Louail and Marc Barthelemy", "title": "Headphones on the wire", "comments": "10 pages, 4 figures + SI (13 pages and 13 Supplementary figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a dataset providing the complete information on the effective\nplays of thousands of music listeners during several months. Our analysis\nconfirms a number of properties previously highlighted by research based on\ninterviews and questionnaires, but also uncover new statistical patterns, both\nat the individual and collective levels. In particular, we show that\nindividuals follow common listening rhythms characterized by the same\nfluctuations, alternating heavy and light listening periods, and can be\nclassified in four groups of similar sizes according to their temporal habits\n--- 'early birds', 'working hours listeners', 'evening listeners' and 'night\nowls'. We provide a detailed radioscopy of the listeners' interplay between\nrepeated listening and discovery of new content. We show that different genres\nencourage different listening habits, from Classical or Jazz music with a more\nbalanced listening among different songs, to Hip Hop and Dance with a more\nheterogeneous distribution of plays. Finally, we provide measures of how\ndistant people are from each other in terms of common songs. In particular, we\nshow that the number of songs $S$ a DJ should play to a random audience of size\n$N$ such that everyone hears at least one song he/she currently listens to, is\nof the form $S\\sim N^\\alpha$ where the exponent depends on the music genre and\nis in the range $[0.5,0.8]$. More generally, our results show that the recent\naccess to virtually infinite catalogs of songs does not promote exploration for\nnovelty, but that most users favor repetition of the same songs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 16:51:32 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Louail", "Thomas", ""], ["Barthelemy", "Marc", ""]]}, {"id": "1704.06127", "submitter": "Nikolaos K Tselios", "authors": "Anastasia Revythi and Nikolaos Tselios", "title": "Extension of Technology Acceptance Model by using System Usability Scale\n  to assess behavioral intention to use e-learning", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study examines the acceptance of technology and behavioral intention to\nuse learning management systems (LMS). In specific, the aim of this research is\nto examine whether students ultimately accept and use educational learning\nsystems such as e-class and the impact of behavioral intention on their\ndecision to use them. An extended version of technology acceptance model has\nbeen proposed and used by employing the System Usability Scale to measure\nperceived ease of use. 345 university students participated in the study and\nthe data analysis was based on partial least squares method. The results were\nconfirmed in most of the research hypotheses. In particular, social norm,\nsystem access and self-efficacy significantly affect behavioral intention to\nuse. As a result, it is suggested that e-learning developers and stakeholders\nshould focus on these factors to increase acceptance and effectiveness of\nlearning management systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 13:18:08 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 13:29:13 GMT"}, {"version": "v3", "created": "Tue, 6 Feb 2018 13:07:25 GMT"}, {"version": "v4", "created": "Mon, 7 May 2018 22:23:13 GMT"}, {"version": "v5", "created": "Fri, 1 Jun 2018 14:50:03 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Revythi", "Anastasia", ""], ["Tselios", "Nikolaos", ""]]}, {"id": "1704.06549", "submitter": "Frans A. Oliehoek", "authors": "Frans A. Oliehoek, Rahul Savani, Elliot Adderton, Xia Cui, David\n  Jackson, Phil Jimmieson, John Christopher Jones, Keith Kennedy, Ben Mason,\n  Adam Plumbley, Luke Dawson", "title": "LiftUpp: Support to develop learner performance", "comments": "Short 4-page version to appear at AIED 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various motivations exist to move away from the simple assessment of\nknowledge towards the more complex assessment and development of competence.\nHowever, to accommodate such a change, high demands are put on the supporting\ne-infrastructure in terms of intelligently collecting and analysing data. In\nthis paper, we discuss these challenges and how they are being addressed by\nLiftUpp, a system that is now used in 70% of UK dental schools, and is finding\nwider applications in physiotherapy, medicine and veterinary science. We\ndescribe how data is collected for workplace-based development in dentistry\nusing a dedicated iPad app, which enables an integrated approach to linking and\nassessing work flows, skills and learning outcomes. Furthermore, we detail how\nthe various forms of collected data can be fused, visualized and integrated\nwith conventional forms of assessment. This enables curriculum integration,\nimproved real-time student feedback, support for administration, and informed\ninstructional planning. Together these facets contribute to better support for\nthe development of learners' competence in situated learning setting, as well\nas an improved experience. Finally, we discuss several directions for future\nresearch on intelligent teaching systems that are afforded by using the design\npresent within LiftUpp.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 14:04:28 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Oliehoek", "Frans A.", ""], ["Savani", "Rahul", ""], ["Adderton", "Elliot", ""], ["Cui", "Xia", ""], ["Jackson", "David", ""], ["Jimmieson", "Phil", ""], ["Jones", "John Christopher", ""], ["Kennedy", "Keith", ""], ["Mason", "Ben", ""], ["Plumbley", "Adam", ""], ["Dawson", "Luke", ""]]}, {"id": "1704.06802", "submitter": "Thanh Thoa Pham Thi Dr.", "authors": "Thanh Thoa Pham Thi, Joe Timoney, Shyram Ravichandran, Peter Mooney,\n  Adam Winstanley", "title": "Bike Renting Data Analysis: The Case of Dublin City", "comments": "GISRUK 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public bike renting is more and more popular in cities to incentivise a\nreduction in car journeys and to boost the use of green transportation\nalternatives. One of the challenges of this application is to effectively plan\nthe resources usage. This paper presents some analysis of Dublin bike renting\nscheme based on statistics and data mining. It provides available bike patterns\nat the most interesting bike stations, that is, the busiest and the quietest\nstations. Consistency checking with new data reinforces confidence in the\npatterns obtained. Identifying available bike patterns helps to better address\nuser needs such as organising the rebalancing of the bike numbers between\nstations in advance of demand.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 13:49:43 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Thi", "Thanh Thoa Pham", ""], ["Timoney", "Joe", ""], ["Ravichandran", "Shyram", ""], ["Mooney", "Peter", ""], ["Winstanley", "Adam", ""]]}, {"id": "1704.06840", "submitter": "Damian Straszak", "authors": "L. Elisa Celis and Damian Straszak and Nisheeth K. Vishnoi", "title": "Ranking with Fairness Constraints", "comments": "appeared in ICALP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking algorithms are deployed widely to order a set of items in\napplications such as search engines, news feeds, and recommendation systems.\nRecent studies, however, have shown that, left unchecked, the output of ranking\nalgorithms can result in decreased diversity in the type of content presented,\npromote stereotypes, and polarize opinions. In order to address such issues, we\nstudy the following variant of the traditional ranking problem when, in\naddition, there are fairness or diversity constraints. Given a collection of\nitems along with 1) the value of placing an item in a particular position in\nthe ranking, 2) the collection of sensitive attributes (such as gender, race,\npolitical opinion) of each item and 3) a collection of constraints that, for\neach k, bound the number of items with each attribute that are allowed to\nappear in the top k positions of the ranking, the goal is to output a ranking\nthat maximizes the value with respect to the original rank quality metric while\nrespecting the constraints. This problem encapsulates various well-studied\nproblems related to bipartite and hypergraph matching as special cases and\nturns out to be hard to approximate even with simple constraints. Our main\ntechnical contributions are fast exact and approximation algorithms along with\ncomplementary hardness results that, together, come close to settling the\napproximability of this constrained ranking maximization problem. Unlike prior\nwork on the constrained matching problems, our algorithm runs in linear time,\neven when the number of constraints is large, its approximation ratio does not\ndepend on the number of constraints, and it produces solutions with small\nconstraint violations. Our results rely on insights about the constrained\nmatching problem when the objective satisfies properties that appear in common\nranking metrics such as Discounted Cumulative Gain, Spearman's rho or\nBradley-Terry.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 19:31:29 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 17:39:44 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 10:33:10 GMT"}, {"version": "v4", "created": "Mon, 30 Jul 2018 16:30:07 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Celis", "L. Elisa", ""], ["Straszak", "Damian", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1704.06860", "submitter": "Hien To", "authors": "Hien To, Cyrus Shahabi", "title": "Location Privacy in Spatial Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial crowdsourcing (SC) is a new platform that engages individuals in\ncollecting and analyzing environmental, social and other spatiotemporal\ninformation. With SC, requesters outsource their spatiotemporal tasks to a set\nof workers, who will perform the tasks by physically traveling to the tasks'\nlocations. This chapter identifies privacy threats toward both workers and\nrequesters during the two main phases of spatial crowdsourcing, tasking and\nreporting. Tasking is the process of identifying which tasks should be assigned\nto which workers. This process is handled by a spatial crowdsourcing server\n(SC-server). The latter phase is reporting, in which workers travel to the\ntasks' locations, complete the tasks and upload their reports to the SC-server.\nThe challenge is to enable effective and efficient tasking as well as reporting\nin SC without disclosing the actual locations of workers (at least until they\nagree to perform a task) and the tasks themselves (at least to workers who are\nnot assigned to those tasks). This chapter aims to provide an overview of the\nstate-of-the-art in protecting users' location privacy in spatial\ncrowdsourcing. We provide a comparative study of a diverse set of solutions in\nterms of task publishing modes (push vs. pull), problem focuses (tasking and\nreporting), threats (server, requester and worker), and underlying technical\napproaches (from pseudonymity, cloaking, and perturbation to exchange-based and\nencryption-based techniques). The strengths and drawbacks of the techniques are\nhighlighted, leading to a discussion of open problems and future work.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 00:09:11 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["To", "Hien", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "1704.06903", "submitter": "Takuto Sakamoto", "authors": "Hiroki Takikawa and Takuto Sakamoto", "title": "Moral Foundations of Political Discourse: Comparative Analysis of the\n  Speech Records of the US Congress and the Japanese Diet", "comments": "Originally submitted to the 3rd International Conference on\n  Computational Social Science (IC2S2), July 10-13, 2017; 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a growing body of study on the relationship between\npublic/political discourse and its moral-emotional foundations. Most of the\nstudies, however, have been confined to a single country's context, lacking\ncross-cultural perspectives. Taking a comparative perspective, we examined the\nemotional and moral structures of political and public discussion observed in\nthe U.S. and Japan by employing extensive text data that cover these two\ncountries. Specifically, we conducted dictionary-based sentiment and moral\nanalyses of floor debate in the U.S. Congress and the Japanese Diet over a long\nperiod of time. The analyses revealed intriguing cross-national patterns in the\nmoral-emotional framework employed in parliamentary deliberations, which cast\ndoubt on some of the dominant arguments in the field, including, among others,\nJ. Haidt's moral foundation hypothesis.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 09:44:25 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Takikawa", "Hiroki", ""], ["Sakamoto", "Takuto", ""]]}, {"id": "1704.07185", "submitter": "Joss Wright", "authors": "Alexander Darer, Oliver Farnan, Joss Wright", "title": "FilteredWeb: A Framework for the Automated Search-Based Discovery of\n  Blocked URLs", "comments": "To appear in \"Network Traffic Measurement and Analysis Conference\n  2017\" (TMA2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various methods have been proposed for creating and maintaining lists of\npotentially filtered URLs to allow for measurement of ongoing internet\ncensorship around the world. Whilst testing a known resource for evidence of\nfiltering can be relatively simple, given appropriate vantage points,\ndiscovering previously unknown filtered web resources remains an open\nchallenge.\n  We present a new framework for automating the process of discovering filtered\nresources through the use of adaptive queries to well-known search engines. Our\nsystem applies information retrieval algorithms to isolate characteristic\nlinguistic patterns in known filtered web pages; these are then used as the\nbasis for web search queries. The results of these queries are then checked for\nevidence of filtering, and newly discovered filtered resources are fed back\ninto the system to detect further filtered content.\n  Our implementation of this framework, applied to China as a case study, shows\nthat this approach is demonstrably effective at detecting significant numbers\nof previously unknown filtered web pages, making a significant contribution to\nthe ongoing detection of internet filtering as it develops.\n  Our tool is currently deployed and has been used to discover 1355 domains\nthat are poisoned within China as of Feb 2017 - 30 times more than are\ncontained in the most widely-used public filter list. Of these, 759 are outside\nof the Alexa Top 1000 domains list, demonstrating the capability of this\nframework to find more obscure filtered content. Further, our initial analysis\nof filtered URLs, and the search terms that were used to discover them, gives\nfurther insight into the nature of the content currently being blocked in\nChina.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 12:47:35 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Darer", "Alexander", ""], ["Farnan", "Oliver", ""], ["Wright", "Joss", ""]]}, {"id": "1704.07759", "submitter": "Gianluca Stringhini", "authors": "Emeric Bernard-Jones, Jeremiah Onaolapo, Gianluca Stringhini", "title": "Email Babel: Does Language Affect Criminal Activity in Compromised\n  Webmail Accounts?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We set out to understand the effects of differing language on the ability of\ncybercriminals to navigate webmail accounts and locate sensitive information in\nthem. To this end, we configured thirty Gmail honeypot accounts with English,\nRomanian, and Greek language settings. We populated the accounts with email\nmessages in those languages by subscribing them to selected online newsletters.\nWe hid email messages about fake bank accounts in fifteen of the accounts to\nmimic real-world webmail users that sometimes store sensitive information in\ntheir accounts. We then leaked credentials to the honey accounts via paste\nsites on the Surface Web and the Dark Web, and collected data for fifteen days.\nOur statistical analyses on the data show that cybercriminals are more likely\nto discover sensitive information (bank account information) in the Greek\naccounts than the remaining accounts, contrary to the expectation that Greek\nought to constitute a barrier to the understanding of non-Greek visitors to the\nGreek accounts. We also extracted the important words among the emails that\ncybercriminals accessed (as an approximation of the keywords that they searched\nfor within the honey accounts), and found that financial terms featured among\nthe top words. In summary, we show that language plays a significant role in\nthe ability of cybercriminals to access sensitive information hidden in\ncompromised webmail accounts.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 16:07:34 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Bernard-Jones", "Emeric", ""], ["Onaolapo", "Jeremiah", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "1704.07826", "submitter": "Sam Lavigne", "authors": "Sam Lavigne, Brian Clifton, Francis Tseng", "title": "Predicting Financial Crime: Augmenting the Predictive Policing Arsenal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Financial crime is a rampant but hidden threat. In spite of this, predictive\npolicing systems disproportionately target \"street crime\" rather than white\ncollar crime. This paper presents the White Collar Crime Early Warning System\n(WCCEWS), a white collar crime predictive model that uses random forest\nclassifiers to identify high risk zones for incidents of financial crime.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 14:32:24 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Lavigne", "Sam", ""], ["Clifton", "Brian", ""], ["Tseng", "Francis", ""]]}, {"id": "1704.07894", "submitter": "Herman Averyanov", "authors": "G.P. Averyanov, V.V. Dmitrieva, N.P. Kornev, A.A. Fadeev (National\n  Research Nuclear University MEPhI)", "title": "Information Scientific and Educational Resource \"Electrophysics\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper discusses an advanced level information system to support\neducational, research and scientific activities of the Department\n\"Electrophysical Facilities\" (DEF) of the National Research Nuclear University\n\"MEPhI\" (NRNU MEPhI), which is used for training of specialists of the course\n\"Physics of Charged Particle Beams and Accelerator Technology\".\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 06:37:27 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Averyanov", "G. P.", "", "National\n  Research Nuclear University MEPhI"], ["Dmitrieva", "V. V.", "", "National\n  Research Nuclear University MEPhI"], ["Kornev", "N. P.", "", "National\n  Research Nuclear University MEPhI"], ["Fadeev", "A. A.", "", "National\n  Research Nuclear University MEPhI"]]}, {"id": "1704.07895", "submitter": "Navid Akar", "authors": "Navid Akar, Hossein Lotfizadeh", "title": "A New Integrated FQFD Approach for Improving Quality and Reliability of\n  Solar Drying Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Saffron is the most expensive spice and is significantly valuable in non-oil\nexport. Drying process of saffron is considered as a critical control point\nwith major effects on quality and safety parameters. A suitable drying method\ncovering standards and market requirements while it is costlty benefitial and\nsaves energy is desirable. Solar drying could be introduced as an appropriate\nprocedure in rural and collecting sites of saffron since major micorobial and\nchemical factors of saffron can be preserved and achieved by using a renewable\nenergy source. So, a precise system taking advantage of management, engineering\nand food technology sciences could be developed. Since there was no published\nrecord of integrated methods of Analytical Hierarchy Process (AHP) and Fuzzy\nQuality Function Deployment (FQFD) applied to solar energy drying systems, in\nthis paper, Fuzzy Quality Function Deployment as a quality management tool by\nemphasizing technical and customer requirements has been implemented in order\nto improve quality parameters, optimizing technological expenses and market\nexpansion strategy. Subsequently, Analytical Hierarchy Process based on survey\nfrom customers and logical pair-wise comparison are employed to decrease costs\nand increase the efficiency and the effectiveness of economic indicators. Using\nthe integrated approach of AHP and FQFD in solar drying systems in saffron\nindustry will result in cost benefit, quality improvement, the customer\nsatisfaction enhancement, and the increase in saffron exports.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 07:44:05 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Akar", "Navid", ""], ["Lotfizadeh", "Hossein", ""]]}, {"id": "1704.07905", "submitter": "Sandip Roy Mr.", "authors": "Sandip Roy, Debabrata Sarddar", "title": "The Role of Cloud of Things in Smart Cities", "comments": "16 pages, 14 figures", "journal-ref": "International Journal of Computer Science and Information Security\n  (IJCSIS), Vol. 14, No. 11, November 2016", "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent demographic trends indicate towards a rapidly increasing\npopulation growth and a significant portion of this increased population now\nprefer to live mostly in cities. In connection with this, it has become the\nresponsibility of the government to ensure a quality standard of living in the\ncities and also make sure that these facilities trickle down to the next\ngeneration. A program named Smart City Mission has been started for this\npurpose. With an extremely diverse population, that is only second to China in\nthe world in terms of size, the Indian government has engaged in serious\nthinking for a better city planning and providing numerous opportunities for\nthe citizenry. It was, therefore, planned that the Smart City Mission program\nwill be able to provide a highly responsive infrastructure, network security, a\ngood living environment and the like. Internet of things (IoT) application in\nsmart cities turns out to be the most challenging in this phase. The\ninformation available in the internet has made accessible to many devices\nthrough IoT and it also aware the citizen in many aspects. But with the\nincreasing number of devices and information, it is now becoming increasingly\ndifficult to depend on IoT to manage things in the internet space with a\nsimilar degree of ease. As a result, cloud-based technologies have given\npreferences over the existing one and IoT has been replaced by the newly\nintroduced Cloud of Things (CoT) paradigm. This paper intends to connect\ndifferent smart city applications for the betterment of city life with the\nCloud of Things (CoT). Our proposed smart city architecture is based on Cloud\nof Things, and the focus is also given to identify the existing as well as the\nforthcoming challenges for the concerned program of the government. By\nidentifying the difficulties it is expected that the project will be\nmaterialized with a great success.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 19:08:07 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Roy", "Sandip", ""], ["Sarddar", "Debabrata", ""]]}, {"id": "1704.08193", "submitter": "Spiros Denaxas", "authors": "Vaclav Papez, Spiros Denaxas, Harry Hemingway", "title": "Evaluating openEHR for storing computable representations of electronic\n  health record phenotyping algorithms", "comments": "30th IEEE International Symposium on Computer-Based Medical Systems -\n  IEEE CBMS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Health Records (EHR) are data generated during routine clinical\ncare. EHR offer researchers unprecedented phenotypic breadth and depth and have\nthe potential to accelerate the pace of precision medicine at scale. A main EHR\nuse-case is creating phenotyping algorithms to define disease status, onset and\nseverity. Currently, no common machine-readable standard exists for defining\nphenotyping algorithms which often are stored in human-readable formats. As a\nresult, the translation of algorithms to implementation code is challenging and\nsharing across the scientific community is problematic. In this paper, we\nevaluate openEHR, a formal EHR data specification, for computable\nrepresentations of EHR phenotyping algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 20:54:19 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 07:18:10 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Papez", "Vaclav", ""], ["Denaxas", "Spiros", ""], ["Hemingway", "Harry", ""]]}, {"id": "1704.08389", "submitter": "Lydia Manikonda", "authors": "Lydia Manikonda, Cameron Dudley, Subbarao Kambhampati", "title": "Tweeting AI: Perceptions of AI-Tweeters (AIT) vs Expert AI-Tweeters\n  (EAIT)", "comments": "New results at arXiv:1709.09534", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advancements in Artificial Intelligence (AI), various\norganizations and individuals started debating about the progress of AI as a\nblessing or a curse for the future of the society. This paper conducts an\ninvestigation on how the public perceives the progress of AI by utilizing the\ndata shared on Twitter. Specifically, this paper performs a comparative\nanalysis on the understanding of users from two categories -- general\nAI-Tweeters (AIT) and the expert AI-Tweeters (EAIT) who share posts about AI on\nTwitter. Our analysis revealed that users from both the categories express\ndistinct emotions and interests towards AI. Users from both the categories\nregard AI as positive and are optimistic about the progress of AI but the\nexperts are more negative than the general AI-Tweeters. Characterization of\nusers manifested that `London' is the popular location of users from where they\ntweet about AI. Tweets posted by AIT are highly retweeted than posts made by\nEAIT that reveals greater diffusion of information from AIT.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 00:37:05 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 02:06:08 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Manikonda", "Lydia", ""], ["Dudley", "Cameron", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "1704.08990", "submitter": "Mark Scanlon", "authors": "Mark Scanlon, Xiaoyu Du, David Lillis", "title": "EviPlant: An efficient digital forensic challenge creation, manipulation\n  and distribution solution", "comments": "Digital Forensic Research Workshop Europe 2017", "journal-ref": "Digital Investigation, Volume 20, Supplement, March 2017, Pages\n  S29-S36, ISSN 1742-2876", "doi": "10.1016/j.diin.2017.01.010", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Education and training in digital forensics requires a variety of suitable\nchallenge corpora containing realistic features including regular\nwear-and-tear, background noise, and the actual digital traces to be discovered\nduring investigation. Typically, the creation of these challenges requires\noverly arduous effort on the part of the educator to ensure their viability.\nOnce created, the challenge image needs to be stored and distributed to a class\nfor practical training. This storage and distribution step requires significant\ntime and resources and may not even be possible in an online/distance learning\nscenario due to the data sizes involved. As part of this paper, we introduce a\nmore capable methodology and system as an alternative to current approaches.\nEviPlant is a system designed for the efficient creation, manipulation, storage\nand distribution of challenges for digital forensics education and training.\nThe system relies on the initial distribution of base disk images, i.e., images\ncontaining solely base operating systems. In order to create challenges for\nstudents, educators can boot the base system, emulate the desired activity and\nperform a \"diffing\" of resultant image and the base image. This diffing process\nextracts the modified artefacts and associated metadata and stores them in an\n\"evidence package\". Evidence packages can be created for different personae,\ndifferent wear-and-tear, different emulated crimes, etc., and multiple evidence\npackages can be distributed to students and integrated into the base images. A\nnumber of additional applications in digital forensic challenge creation for\ntool testing and validation, proficiency testing, and malware analysis are also\ndiscussed as a result of using EviPlant.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 16:13:35 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Scanlon", "Mark", ""], ["Du", "Xiaoyu", ""], ["Lillis", "David", ""]]}, {"id": "1704.08991", "submitter": "Erwan Le Merrer", "authors": "Erwan Le Merrer and Gilles Tr\\'edan", "title": "The topological face of recommendation: models and application to bias\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation plays a key role in e-commerce and in the entertainment\nindustry. We propose to consider successive recommendations to users under the\nform of graphs of recommendations. We give models for this representation.\nMotivated by the growing interest for algorithmic transparency, we then propose\na first application for those graphs, that is the potential detection of\nintroduced recommendation bias by the service provider. This application relies\non the analysis of the topology of the extracted graph for a given user; we\npropose a notion of recommendation coherence with regards to the topological\nproximity of recommended items (under the measure of items' k-closest\nneighbors, reminding the \"small-world\" model by Watts & Stroggatz). We finally\nillustrate this approach on a model and on Youtube crawls, targeting the\nprediction of \"Recommended for you\" links (i.e., biased or not by Youtube).\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 16:15:11 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Merrer", "Erwan Le", ""], ["Tr\u00e9dan", "Gilles", ""]]}]