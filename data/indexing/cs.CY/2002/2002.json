[{"id": "2002.00045", "submitter": "Martin \\v{S}echn\\'y", "authors": "Martin \\v{S}echn\\'y", "title": "Open IT tools for inquiry-based physics education", "comments": "3 pages, 5 figures, shorter version of this paper has been accepted\n  at the 24th conference of Slovak physicists (2019)", "journal-ref": "A. Dzubinska, M. Reiffers (ed.): 24th conference of Slovak\n  physicists - proceedings. Slovak Physical Society, Kosice, Slovakia (2019)\n  ISBN 978-80-89855-10-0", "doi": "10.5281/zenodo.3877075", "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In case of inquiry-based education, the priority is the pupil's activity,\ndeveloping his/her practical and research skills. We can use the knowledge and\nskills obtained by the pupil from other subjects. Applied informatics into\nphysics seems to be a suitable application of digital literacy. Open IT tools\nare the ones of the available IT tools that bring several benefits to promote\nfreedom of inquiry. An overview of open IT tools for physics education includes\nmicroprocessor kits with a variety of analog and digital electronic components,\na large number of application software, simulation software, programming\nlanguages, libraries and development environments, web tools, virtual\nlaboratories, data catalogs, hypertext documents and other auxiliary resources.\nSuch open IT tools together with suitable open educational resources will be\napplicable in physics, mathematics, informatics and other subjects.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 20:20:31 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["\u0160echn\u00fd", "Martin", ""]]}, {"id": "2002.00115", "submitter": "Andreas Grammenos", "authors": "Andreas Grammenos, Aravindh Raman, Timm B\\\"ottger, Zafar Gilani,\n  Gareth Tyson", "title": "Dissecting the Workload of a Major Adult Video Portal", "comments": "14 pages, 7 figures, Accepted at PAM 2020", "journal-ref": null, "doi": "10.1007/978-3-030-44081-7_16", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adult content constitutes a major source of Internet traffic. As with many\nother platforms, these sites are incentivized to engage users and maintain them\non the site. This engagement (e.g., through recommendations) shapes the\njourneys taken through such sites. Using data from a large content delivery\nnetwork, we explore session journeys within an adult website. We take two\nperspectives. We first inspect the corpus available on these platforms.\nFollowing this, we investigate the session access patterns. We make a number of\nobservations that could be exploited for optimizing delivery, e.g., that users\noften skip within video streams.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 00:36:19 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Grammenos", "Andreas", ""], ["Raman", "Aravindh", ""], ["B\u00f6ttger", "Timm", ""], ["Gilani", "Zafar", ""], ["Tyson", "Gareth", ""]]}, {"id": "2002.00213", "submitter": "Mohamed Akrout", "authors": "Mohamed Akrout, Robert Steinbauer", "title": "Machine Ethics: The Creation of a Virtuous Machine", "comments": "Accepted for the seventh World Congress of the International Society\n  of Business, Economics, and Ethics (ISBEE) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) was initially developed as an implicit moral\nagent to solve simple and clearly defined tasks where all options are\npredictable. However, it is now part of our daily life powering cell phones,\ncameras, watches, thermostats, vacuums, cars, and much more. This has raised\nnumerous concerns and some scholars and practitioners stress the dangers of AI\nand argue against its development as moral agents that can reason about ethics\n(e.g., Bryson 2008; Johnson and Miller 2008; Sharkey 2017; Tonkens 2009; van\nWynsberghe and Robbins 2019). Even though we acknowledge the potential threat,\nin line with most other scholars (e.g., Anderson and Anderson 2010; Moor 2006;\nScheutz 2016; Wallach 2010), we argue that AI advancements cannot be stopped\nand developers need to prepare AI to sustain explicit moral agents and face\nethical dilemmas in complex and morally salient environments.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:13:56 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 19:04:37 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Akrout", "Mohamed", ""], ["Steinbauer", "Robert", ""]]}, {"id": "2002.00223", "submitter": "Sodiq Adewole", "authors": "Sodiq Adewole, Erfaneh Gharavi, Benjamin Shpringer, Martin Bolger,\n  Vaibhav Sharma, Sung Ming Yang, Donald E. Brown", "title": "Dialogue-based simulation for cultural awareness training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing simulations designed for cultural and interpersonal skill training\nrely on pre-defined responses with a menu option selection interface. Using a\nmultiple-choice interface and restricting trainees' responses may limit the\ntrainees' ability to apply the lessons in real life situations. This systems\nalso uses a simplistic evaluation model, where trainees' selected options are\nmarked as either correct or incorrect. This model may not capture sufficient\ninformation that could drive an adaptive feedback mechanism to improve\ntrainees' cultural awareness. This paper describes the design of a\ndialogue-based simulation for cultural awareness training. The simulation,\nbuilt around a disaster management scenario involving a joint coalition between\nthe US and the Chinese armies. Trainees were able to engage in realistic\ndialogue with the Chinese agent. Their responses, at different points, get\nevaluated by different multi-label classification models. Based on training on\nour dataset, the models score the trainees' responses for cultural awareness in\nthe Chinese culture. Trainees also get feedback that informs the cultural\nappropriateness of their responses. The result of this work showed the\nfollowing; i) A feature-based evaluation model improves the design, modeling\nand computation of dialogue-based training simulation systems; ii) Output from\ncurrent automatic speech recognition (ASR) systems gave comparable end results\ncompared with the output from manual transcription; iii) A multi-label\nclassification model trained as a cultural expert gave results which were\ncomparable with scores assigned by human annotators.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:40:17 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Adewole", "Sodiq", ""], ["Gharavi", "Erfaneh", ""], ["Shpringer", "Benjamin", ""], ["Bolger", "Martin", ""], ["Sharma", "Vaibhav", ""], ["Yang", "Sung Ming", ""], ["Brown", "Donald E.", ""]]}, {"id": "2002.00224", "submitter": "Scott McLachlan Dr", "authors": "Scott McLachlan, Kudakwashe Dube, Graham A Hitman, Norman E Fenton,\n  Evangelia Kyrimi", "title": "Bayesian Networks in Healthcare: Distribution by Medical Condition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian networks (BNs) have received increasing research attention that is\nnot matched by adoption in practice and yet have potential to significantly\nbenefit healthcare. Hitherto, research works have not investigated the types of\nmedical conditions being modelled with BNs, nor whether any differences exist\nin how and why they are applied to different conditions. This research seeks to\nidentify and quantify the range of medical conditions for which\nhealthcare-related BN models have been proposed, and the differences in\napproach between the most common medical conditions to which they have been\napplied. We found that almost two-thirds of all healthcare BNs are focused on\nfour conditions: cardiac, cancer, psychological and lung disorders. We believe\nthat a lack of understanding regarding how BNs work and what they are capable\nof exists, and that it is only with greater understanding and promotion that we\nmay ever realise the full potential of BNs to effect positive change in daily\nhealthcare practice.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:41:20 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 07:18:20 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["McLachlan", "Scott", ""], ["Dube", "Kudakwashe", ""], ["Hitman", "Graham A", ""], ["Fenton", "Norman E", ""], ["Kyrimi", "Evangelia", ""]]}, {"id": "2002.00593", "submitter": "Kosuke Sato", "authors": "Masaki Suyama and Kosuke Sato", "title": "Investigation into Open-Ended Fitness Landscape through Evolutionary\n  Logical Circuits", "comments": "This document is a preprint. We expect changes in the peer review\n  process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cumulative cultural evolution is what made humanity to thrive in various\necological and demographic environments. Solutions to the tasks that humans\nneeded to solve could be mapped onto a task space which could take the form of\neither closed or open-ended fitness landscape, with the former being modeled\nmore extensively than the latter in studies of cultural evolution. In this\narticle, we modified a simulation by Arthur and Polak (2006) that modeled\nopen-ended fitness landscape by using a computer simulation that builds logical\ncircuits with circuits that were built in earlier trials. We used this\nsimulation to clarify the nature of open-ended fitness landscape and to\ninvestigate whether the speed of accumulation of culture is increased by an\nincrease in group size. The results indicated that group size increased the\nspeed of accumulation but is limited than expected. Also, when two types of\naccumulation, invention and improvement, were distinguished the nature of the\ntwo differed. In improvement, the trajectory followed a convex function with\nproductivity of one agent decreasing as group size increased. In invention, the\ntrajectory showed a continuous pattern of rapid increase followed by a plateau.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 08:21:24 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 03:35:16 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Suyama", "Masaki", ""], ["Sato", "Kosuke", ""]]}, {"id": "2002.00842", "submitter": "Songyang Zhang", "authors": "Songyang Zhang, Tolga Aktas, Jiebo Luo", "title": "Mi YouTube es Su YouTube? Analyzing the Cultures using YouTube\n  Thumbnails of Popular Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  YouTube, a world-famous video sharing website, maintains a list of the top\ntrending videos on the platform. Due to its huge amount of users, it enables\nresearchers to understand people's preference by analyzing the trending videos.\nTrending videos vary from country to country. By analyzing such differences and\nchanges, we can tell how users' preferences differ over locations. Previous\nwork focuses on analyzing such culture preferences from videos' metadata, while\nthe culture information hidden within the visual content has not been\ndiscovered. In this study, we explore culture preferences among countries using\nthe thumbnails of YouTube trending videos. We first process the thumbnail\nimages of the videos using object detectors. The collected object information\nis then used for various statistical analysis. In particular, we examine the\ndata from three perspectives: geographical locations, video genres and users'\nreactions. Experimental results indicate that the users from similar cultures\nshares interests in watching similar videos on YouTube. Our study demonstrates\nthat discovering the culture preference through the thumbnails can be an\neffective mechanism for video social media analysis.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 20:15:57 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Zhang", "Songyang", ""], ["Aktas", "Tolga", ""], ["Luo", "Jiebo", ""]]}, {"id": "2002.00854", "submitter": "Zhaoya Gong", "authors": "Zhaoya Gong, Tengteng Cai, Jean-Claude Thill, Scott Hale, Mark Graham", "title": "Measuring relative opinion from location-based social media: A case\n  study of the 2016 U.S. presidential election", "comments": null, "journal-ref": "PLoS ONE 15(5): e0233660 (2020)", "doi": "10.1371/journal.pone.0233660", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media has become an emerging alternative to opinion polls for public\nopinion collection, while it is still posing many challenges as a passive data\nsource, such as structurelessness, quantifiability, and representativeness.\nSocial media data with geotags provide new opportunities to unveil the\ngeographic locations of users expressing their opinions. This paper aims to\nanswer two questions: 1) whether quantifiable measurement of public opinion can\nbe obtained from social media and 2) whether it can produce better or\ncomplementary measures compared to opinion polls. This research proposes a\nnovel approach to measure the relative opinion of Twitter users towards public\nissues in order to accommodate more complex opinion structures and take\nadvantage of the geography pertaining to the public issues. To ensure that this\nnew measure is technically feasible, a modeling framework is developed\nincluding building a training dataset by adopting a state-of-the-art approach\nand devising a new deep learning method called Opinion-Oriented Word Embedding.\nWith a case study of the tweets selected for the 2016 U.S. presidential\nelection, we demonstrate the predictive superiority of our relative opinion\napproach and we show how it can aid visual analytics and support opinion\npredictions. Although the relative opinion measure is proved to be more robust\ncompared to polling, our study also suggests that the former can advantageously\ncomplement the later in opinion prediction.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 16:01:48 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 23:05:01 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Gong", "Zhaoya", ""], ["Cai", "Tengteng", ""], ["Thill", "Jean-Claude", ""], ["Hale", "Scott", ""], ["Graham", "Mark", ""]]}, {"id": "2002.00934", "submitter": "Pushkal Agarwal", "authors": "Pushkal Agarwal, Sagar Joglekar, Panagiotis Papadopoulos, Nishanth\n  Sastry, Nicolas Kourtellis", "title": "Stop Tracking Me Bro! Differential Tracking Of User Demographics On\n  Hyper-partisan Websites", "comments": "Published at The Web Conference 2020 (WWW 2020). Please cite the WWW\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Websites with hyper-partisan, left or right-leaning focus offer content that\nis typically biased towards the expectations of their target audience. Such\ncontent often polarizes users, who are repeatedly primed to specific (extreme)\ncontent, usually reflecting hard party lines on political and socio-economic\ntopics. Though this polarization has been extensively studied with respect to\ncontent, it is still unknown how it associates with the online tracking\nexperienced by browsing users, especially when they exhibit certain demographic\ncharacteristics. For example, it is unclear how such websites enable the\nad-ecosystem to track users based on their gender or age. In this paper, we\ntake a first step to shed light and measure such potential differences in\ntracking imposed on users when visiting specific party-line's websites. For\nthis, we design and deploy a methodology to systematically probe such websites\nand measure differences in user tracking. This methodology allows us to create\nuser personas with specific attributes like gender and age and automate their\nbrowsing behavior in a consistent and repeatable manner. Thus, we\nsystematically study how personas are being tracked by these websites and their\nthird parties, especially if they exhibit particular demographic properties.\nOverall, we test 9 personas on 556 hyper-partisan websites and find that\nright-leaning websites tend to track users more intensely than left-leaning,\ndepending on user demographics, using both cookies and cookie synchronization\nmethods and leading to more costly delivered ads.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 18:35:57 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 19:07:44 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Agarwal", "Pushkal", ""], ["Joglekar", "Sagar", ""], ["Papadopoulos", "Panagiotis", ""], ["Sastry", "Nishanth", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2002.01030", "submitter": "Mohammad Hadi Goldani", "authors": "Mohammad Hadi Goldani, Saeedeh Momtazi, Reza Safabakhsh", "title": "Detecting Fake News with Capsule Neural Networks", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news is dramatically increased in social media in recent years. This has\nprompted the need for effective fake news detection algorithms. Capsule neural\nnetworks have been successful in computer vision and are receiving attention\nfor use in Natural Language Processing (NLP). This paper aims to use capsule\nneural networks in the fake news detection task. We use different embedding\nmodels for news items of different lengths. Static word embedding is used for\nshort news items, whereas non-static word embeddings that allow incremental\nup-training and updating in the training phase are used for medium length or\nlarge news statements. Moreover, we apply different levels of n-grams for\nfeature extraction. Our proposed architectures are evaluated on two recent\nwell-known datasets in the field, namely ISOT and LIAR. The results show\nencouraging performance, outperforming the state-of-the-art methods by 7.8% on\nISOT and 3.1% on the validation set, and 1% on the test set of the LIAR\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 22:13:07 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Goldani", "Mohammad Hadi", ""], ["Momtazi", "Saeedeh", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "2002.01081", "submitter": "Naoki Shibata", "authors": "Babatunde Ojetunde, Naoki Shibata, Juntao Gao", "title": "Secure Payment System Utilizing MANET for Disaster Areas", "comments": null, "journal-ref": "in IEEE Transactions on Systems, Man, and Cybernetics: Systems,\n  vol. 49, no. 12, pp. 2651-2663, Dec. 2019", "doi": "10.1109/TSMC.2017.2752203", "report-no": null, "categories": "cs.DC cs.CY cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile payment system in a disaster area have the potential to provide\nelectronic transactions for people purchasing recovery goods like foodstuffs,\nclothes, and medicine. Conversely, to enable transactions in a disaster area,\ncurrent payment systems need communication infrastructures (such as wired\nnetworks and cellular networks) which may be ruined during such disasters as\nlarge-scale earthquakes and flooding and thus cannot be depended on in a\ndisaster area. In this paper, we introduce a new mobile payment system\nutilizing infrastructureless MANETs to enable transactions that permit users to\nshop in disaster areas. Specifically, we introduce an endorsement-based\nmechanism to provide payment guarantees for a customer-to-merchant transaction\nand a multilevel endorsement mechanism with a lightweight scheme based on Bloom\nfilter and Merkle tree to reduce communication overheads. Our mobile payment\nsystem achieves secure transaction by adopting various schemes such as\nlocation-based mutual monitoring scheme and blind signature, while our newly\nintroduce event chain mechanism prevents double spending attacks. As validated\nby simulations, the proposed mobile payment system is useful in a disaster\narea, achieving high transaction completion ratio, 65% - 90% for all scenario\ntested, and is storage-efficient for mobile devices with an overall average of\n7MB merchant message size.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 01:38:14 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Ojetunde", "Babatunde", ""], ["Shibata", "Naoki", ""], ["Gao", "Juntao", ""]]}, {"id": "2002.01559", "submitter": "Anne L. Washington", "authors": "Anne L. Washington, Rachel S. Kuo", "title": "Whose Side are Ethics Codes On? Power, Responsibility and the Social\n  Good", "comments": "Conference on Fairness, Accountability, and Transparency (FAT* '20),\n  January 27-30, 2020, Barcelona, Spain. Corrected", "journal-ref": null, "doi": "10.1145/3351095.3372844", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The moral authority of ethics codes stems from an assumption that they serve\na unified society, yet this ignores the political aspects of any shared\nresource. The sociologist Howard S. Becker challenged researchers to clarify\ntheir power and responsibility in the classic essay: Whose Side Are We On.\nBuilding on Becker's hierarchy of credibility, we report on a critical\ndiscourse analysis of data ethics codes and emerging conceptualizations of\nbeneficence, or the \"social good\", of data technology. The analysis revealed\nthat ethics codes from corporations and professional associations conflated\nconsumers with society and were largely silent on agency. Interviews with\ncommunity organizers about social change in the digital era supplement the\nanalysis, surfacing the limits of technical solutions to concerns of\nmarginalized communities. Given evidence that highlights the gulf between the\ndocuments and lived experiences, we argue that ethics codes that elevate\nconsumers may simultaneously subordinate the needs of vulnerable populations.\nUnderstanding contested digital resources is central to the emerging field of\npublic interest technology. We introduce the concept of digital differential\nvulnerability to explain disproportionate exposures to harm within data\ntechnology and suggest recommendations for future ethics codes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 22:05:09 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Washington", "Anne L.", ""], ["Kuo", "Rachel S.", ""]]}, {"id": "2002.01578", "submitter": "Geoff Boeing", "authors": "Geoff Boeing, Jake Wegmann, Junfeng Jiao", "title": "Rental Housing Spot Markets: How Online Information Exchanges Can\n  Supplement Transacted-Rents Data", "comments": null, "journal-ref": "Journal of Planning Education and Research, 2020", "doi": "10.1177/0739456X20904435", "report-no": null, "categories": "econ.GN cs.CY q-fin.EC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional US rental housing data sources such as the American Community\nSurvey and the American Housing Survey report on the transacted market - what\nexisting renters pay each month. They do not explicitly tell us about the spot\nmarket - i.e., the asking rents that current homeseekers must pay to acquire\nhousing - though they are routinely used as a proxy. This study compares\ngovernmental data to millions of contemporaneous rental listings and finds that\nasking rents diverge substantially from these most recent estimates.\nConventional housing data understate current market conditions and\naffordability challenges, especially in cities with tight and expensive rental\nmarkets.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 23:23:35 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Boeing", "Geoff", ""], ["Wegmann", "Jake", ""], ["Jiao", "Junfeng", ""]]}, {"id": "2002.01840", "submitter": "Antti Knutas", "authors": "Annika Wolff, Antti Knutas, Paula Savolainen", "title": "What prevents Finnish women from applying to software engineering roles?\n  A preliminary analysis of survey data", "comments": null, "journal-ref": "International Conference on Software Engineering: Software\n  Engineering Education and Training (ICSE-SEET'20), May 23-29, 2020, Seoul,\n  Republic of Korea", "doi": "10.1145/3377814.3381708", "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finland is considered a country with a good track record in gender equality.\nWhilst statistics support the notion that Finland is performing well compared\nto many other countries in terms of workplace equality, there are still many\nareas for improvement. This paper focuses on the problems that some women face\nin obtaining software engineering roles. We report a preliminary analysis of\nsurvey data from 252 respondents. These are mainly women who have shown an\ninterest in gaining programming roles by joining the Mimmit koodaa initiative,\nwhich aims to increase equality and diversity within the software industry. The\nsurvey sought to understand what early experiences may influence later career\nchoices and feelings of efficacy and confidence needed to pursue\ntechnology-related careers. These initial findings reveal that women's feelings\nof computing self-efficacy and attitudes towards software engineering are\nshaped by early experiences. More negative experiences decrease the likelihood\nof working in software engineering roles in the future, despite expressing an\ninterest in the field.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 16:03:25 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Wolff", "Annika", ""], ["Knutas", "Antti", ""], ["Savolainen", "Paula", ""]]}, {"id": "2002.01955", "submitter": "Byungsoo Jeon", "authors": "Byungsoo Jeon, Namyong Park", "title": "Dropout Prediction over Weeks in MOOCs by Learning Representations of\n  Clicks and Videos", "comments": "Accepted at AAAI 2020 AI4Edu Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses a key challenge in MOOC dropout prediction, namely to\nbuild meaningful representations from clickstream data. While a variety of\nfeature extraction techniques have been explored extensively for such purposes,\nto our knowledge, no prior works have explored modeling of educational content\n(e.g. video) and their correlation with the learner's behavior (e.g.\nclickstream) in this context. We bridge this gap by devising a method to learn\nrepresentation for videos and the correlation between videos and clicks. The\nresults indicate that modeling videos and their correlation with clicks bring\nstatistically significant improvements in predicting dropout.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 19:10:01 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Jeon", "Byungsoo", ""], ["Park", "Namyong", ""]]}, {"id": "2002.02219", "submitter": "Farzam Fanitabasi", "authors": "Farzam Fanitabasi, Edward Gaere, Evangelos Pournaras", "title": "A Self-Integration Testbed for Decentralized Socio-technical Systems", "comments": null, "journal-ref": null, "doi": "10.1016/j.future.2020.07.036", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things comes along with new challenges for experimenting,\ntesting, and operating decentralized socio-technical systems at large-scale. In\nsuch systems, autonomous agents interact locally with their users, and remotely\nwith other agents to make intelligent collective choices. Via these\ninteractions they self-regulate the consumption and production of distributed\nresources. While such complex systems are often deployed and operated using\ncentralized computing infrastructures, the socio-technical nature of these\ndecentralized systems requires new value-sensitive design paradigms; empowering\ntrust, transparency, and alignment with citizens' social values, such as\nprivacy preservation, autonomy, and fairness among citizens' choices.\nCurrently, instruments and tools to study such systems and guide the\nprototyping process from simulation to live deployment are missing, or not\npractical in this distributed socio-technical context. This paper bridges this\ngap by introducing a novel testbed architecture for decentralized\nsocio-technical systems running on IoT. This new architecture is designed for a\nseamless reusability of (i) application-independent decentralized services by\nan IoT application, and (ii) different IoT applications by the same\ndecentralized service. This dual self-integration promises IoT applications\nthat are simpler to prototype, and can interoperate with decentralized services\nduring runtime to self-integrate more complex functionality. Such integration\nprovides stronger validation of IoT applications, and improves resource\nutilization. Pressure and crash tests during continuous operations of several\nweeks, with more than 80K network joining and leaving of agents, 2.4M parameter\nchanges, and 100M communicated messages, confirm the robustness and\npracticality of the testbed architecture.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 12:18:28 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 09:25:48 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Fanitabasi", "Farzam", ""], ["Gaere", "Edward", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "2002.02316", "submitter": "Carlos Sarraute PhD", "authors": "Hartwig Mayer, Ismael Bejarano, Daniel Fernandez, Gustavo Ajzenman,\n  Nicolas Ayala, Nahuel Santoalla, Carlos Sarraute, Ariel Futoransky", "title": "BatPay: a gas efficient protocol for the recurrent micropayment of ERC20\n  tokens", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  BatPay is a proxy scaling solution for the transfer of ERC20 tokens. It is\nsuitable for micropayments in one-to-many and few-to-many scenarios, including\ndigital markets and the distribution of rewards and dividends. In BatPay, many\nsimilar operations are bundled together into a single transaction in order to\noptimize gas consumption on the Ethereum blockchain. In addition, some costly\nverifications are replaced by a challenge game, pushing most of the computing\ncost off-chain. This results in a gas reduction of the transfer costs of three\norders of magnitude, achieving around 1700 transactions per second on the\nEthereum blockchain. Furthermore, it includes many relevant features, like\nmeta-transactions for end-user operation without ether, and key-locked payments\nfor atomic exchange of digital goods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 15:43:52 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Mayer", "Hartwig", ""], ["Bejarano", "Ismael", ""], ["Fernandez", "Daniel", ""], ["Ajzenman", "Gustavo", ""], ["Ayala", "Nicolas", ""], ["Santoalla", "Nahuel", ""], ["Sarraute", "Carlos", ""], ["Futoransky", "Ariel", ""]]}, {"id": "2002.02763", "submitter": "Andr\\'e Paul Neto-Bradley", "authors": "Andr\\'e Paul Neto-Bradley (1), Ruchi Choudhary (1 and 2), Amir Bazaz\n  (3) ((1) University of Cambridge, (2) Alan Turing Institute, (3) Indian\n  Institute for Human Settlements)", "title": "Slipping through the net: can data science approaches help target clean\n  cooking policy interventions?", "comments": "42 pages, 7 figures", "journal-ref": "Energy Policy 144C (2020) 111650", "doi": "10.1016/j.enpol.2020.111650", "report-no": null, "categories": "physics.soc-ph cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reliance on solid biomass cooking fuels in India has negative health and\nsocio-economic consequences for households, yet policies aimed at promoting\nuptake of LPG for cooking have not always been effective at promoting sustained\ntransition to cleaner cooking amongst intended beneficiaries. This paper uses a\ntwo step approach combining predictive and descriptive analyses of the IHDS\npanel dataset to identify different groups of households that switched stove\nbetween 2004/5 and 2011/12. A tree-based ensemble machine learning predictive\nanalysis identifies key determinants of a switch from biomass to non-biomass\nstoves. A descriptive clustering analysis is used to identify groups of\nstove-switching households that follow different transition pathways. There are\nthree key findings of this study: Firstly non-income determinants of stove\nswitching do not have a linear effect on stove switching, in particular\nvariables on time of use and appliance ownership which offer a proxy for\nhousehold energy practices; secondly location specific factors including\nregion, infrastructure availability, and dwelling quality are found to be key\ndeterminants and as a result policies must be tailored to take into account\nlocal variations; thirdly clean cooking interventions must enact a range of\nmeasures to address the barriers faced by households on different energy\ntransition pathways.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 18:09:30 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 11:51:52 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Neto-Bradley", "Andr\u00e9 Paul", "", "1 and 2"], ["Choudhary", "Ruchi", "", "1 and 2"], ["Bazaz", "Amir", ""]]}, {"id": "2002.03024", "submitter": "Shane Mueller", "authors": "Shane T. Mueller", "title": "Cognitive Anthropomorphism of AI: How Humans and Computers Classify\n  Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern AI image classifiers have made impressive advances in recent years,\nbut their performance often appears strange or violates expectations of users.\nThis suggests humans engage in cognitive anthropomorphism: expecting AI to have\nthe same nature as human intelligence. This mismatch presents an obstacle to\nappropriate human-AI interaction. To delineate this mismatch, I examine known\nproperties of human classification, in comparison to image classifier systems.\nBased on this examination, I offer three strategies for system design that can\naddress the mismatch between human and AI classification: explainable AI, novel\nmethods for training users, and new algorithms that match human cognition.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 21:49:58 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mueller", "Shane T.", ""]]}, {"id": "2002.03060", "submitter": "Yongzhen Wang", "authors": "Yongzhen Wang, Xiaozhong Liu, Yingnan Ju, Katy B\\\"orner, Jun Lin,\n  Changlong Sun, Luo Si", "title": "Chinese E-Romance: Analyzing and Visualizing 7.92 Million Alibaba\n  Valentine's Day Purchases", "comments": "14 pages, 3 figures, 3 tables", "journal-ref": null, "doi": "10.2478/dim-2021-0006", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The days that precede Valentine's Day are characterized by extensive gift\nshopping activities all across the globe. In China, where much shopping takes\nplace online, there has been an explosive growth in e-commerce sales during\nValentine's Day over the recent years. This exploratory study investigates the\nextent to which each product category and each shopper group can exhibit\nromantic love within China's e-market throughout the 2 weeks leading up to 2019\nValentine's Day. Massive data from Alibaba, the biggest e-commerce retailer\nworldwide, are utilized to formulate an innovative romance index (RI) to\nquantitatively measure e-romantic values for products and shoppers. On this\nbasis, millions of shoppers, along with their millions of products purchased\naround Valentine's Day, are analyzed as a case study to demonstrate their love\nconsumption and romantic gift-giving. The results of the analysis are then\nillustrated to help understand Chinese e-romance based on the perspectives of\ndifferent product categories and shopper groups. This empirical information\nvisualization also contributes to improving the segmentation, targeting, and\npositioning of China's e-market for Valentine's Day.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 01:15:02 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 22:26:59 GMT"}, {"version": "v3", "created": "Thu, 12 Nov 2020 16:02:29 GMT"}, {"version": "v4", "created": "Fri, 7 May 2021 05:48:33 GMT"}, {"version": "v5", "created": "Mon, 12 Jul 2021 03:11:07 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wang", "Yongzhen", ""], ["Liu", "Xiaozhong", ""], ["Ju", "Yingnan", ""], ["B\u00f6rner", "Katy", ""], ["Lin", "Jun", ""], ["Sun", "Changlong", ""], ["Si", "Luo", ""]]}, {"id": "2002.03062", "submitter": "Meia Chita-Tegmark", "authors": "Meia Chita-Tegmark and Matthias Scheutz (Tufts)", "title": "Assistive robots for the social management of health: a framework for\n  robot design and human-robot interaction research", "comments": "21 pages, 2 figs", "journal-ref": "International Journal of Social Robotics, 1-21 (March 2020)", "doi": "10.1007/s12369-020-00634-z", "report-no": null, "categories": "cs.HC cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a close connection between health and the quality of one's social\nlife. Strong social bonds are essential for health and wellbeing, but often\nhealth conditions can detrimentally affect a person's ability to interact with\nothers. This can become a vicious cycle resulting in further decline in health.\nFor this reason, the social management of health is an important aspect of\nhealthcare. We propose that socially assistive robots (SARs) could help people\nwith health conditions maintain positive social lives by supporting them in\nsocial interactions. This paper makes three contributions, as detailed below.\nWe develop a framework of social mediation functions that robots could perform,\nmotivated by the special social needs that people with health conditions have.\nIn this framework we identify five types of functions that SARs could perform:\na) changing how the person is perceived, b) enhancing the social behavior of\nthe person, c) modifying the social behavior of others, d) providing structure\nfor interactions, and e) changing how the person feels. We thematically\norganize and review the existing literature on robots supporting human-human\ninteractions, in both clinical and non-clinical settings, and explain how the\nfindings and design ideas from these studies can be applied to the functions\nidentified in the framework. Finally, we point out and discuss challenges in\ndesigning SARs for supporting social interactions, and highlight opportunities\nfor future robot design and HRI research on the mediator role of robots.\n", "versions": [{"version": "v1", "created": "Sat, 8 Feb 2020 01:32:21 GMT"}, {"version": "v2", "created": "Mon, 30 Mar 2020 03:06:00 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Chita-Tegmark", "Meia", "", "Tufts"], ["Scheutz", "Matthias", "", "Tufts"]]}, {"id": "2002.03387", "submitter": "Samir Passi", "authors": "Samir Passi, Steven J. Jackson", "title": "Data Vision: Learning to See Through Algorithmic Abstraction", "comments": null, "journal-ref": "In Proceedings of the 2017 ACM Conference on Computer Supported\n  Cooperative Work and Social Computing. ACM, New York, NY, USA, 2436-2447", "doi": "10.1145/2998181.2998331", "report-no": null, "categories": "cs.HC cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to see through data is central to contemporary forms of algorithmic\nknowledge production. While often represented as a mechanical application of\nrules, making algorithms work with data requires a great deal of situated work.\nThis paper examines how the often-divergent demands of mechanization and\ndiscretion manifest in data analytic learning environments. Drawing on research\nin CSCW and the social sciences, and ethnographic fieldwork in two data\nlearning environments, we show how an algorithm's application is seen sometimes\nas a mechanical sequence of rules and at other times as an array of situated\ndecisions. Casting data analytics as a rule-based (rather than rule-bound)\npractice, we show that effective data vision requires would-be analysts to\nstraddle the competing demands of formal abstraction and empirical contingency.\nWe conclude by discussing how the notion of data vision can help better\nleverage the role of human work in data analytic learning, research, and\npractice.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:46:18 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Passi", "Samir", ""], ["Jackson", "Steven J.", ""]]}, {"id": "2002.03389", "submitter": "Samir Passi", "authors": "Samir Passi, Steven J. Jackson", "title": "Trust in Data Science: Collaboration, Translation, and Accountability in\n  Corporate Data Science Projects", "comments": null, "journal-ref": "Proc. ACM Hum.-Comput. Interact. 2, CSCW, Article 136 (November\n  2018), 28 pages", "doi": "10.1145/3274405", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trustworthiness of data science systems in applied and real-world\nsettings emerges from the resolution of specific tensions through situated,\npragmatic, and ongoing forms of work. Drawing on research in CSCW, critical\ndata studies, and history and sociology of science, and six months of immersive\nethnographic fieldwork with a corporate data science team, we describe four\ncommon tensions in applied data science work: (un)equivocal numbers,\n(counter)intuitive knowledge, (in)credible data, and (in)scrutable models. We\nshow how organizational actors establish and re-negotiate trust under messy and\nuncertain analytic conditions through practices of skepticism, assessment, and\ncredibility. Highlighting the collaborative and heterogeneous nature of\nreal-world data science, we show how the management of trust in applied\ncorporate data science settings depends not only on pre-processing and\nquantification, but also on negotiation and translation. We conclude by\ndiscussing the implications of our findings for data science research and\npractice, both within and beyond CSCW.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 15:50:50 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Passi", "Samir", ""], ["Jackson", "Steven J.", ""]]}, {"id": "2002.03438", "submitter": "Lav Varshney", "authors": "Lav R. Varshney, Nitish Shirish Keskar, and Richard Socher", "title": "Limits of Detecting Text Generated by Large-Scale Language Models", "comments": "ITA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some consider large-scale language models that can generate long and coherent\npieces of text as dangerous, since they may be used in misinformation\ncampaigns. Here we formulate large-scale language model output detection as a\nhypothesis testing problem to classify text as genuine or generated. We show\nthat error exponents for particular language models are bounded in terms of\ntheir perplexity, a standard measure of language generation performance. Under\nthe assumption that human language is stationary and ergodic, the formulation\nis extended from considering specific language models to considering maximum\nlikelihood language models, among the class of k-order Markov approximations;\nerror probabilities are characterized. Some discussion of incorporating\nsemantic side information is also given.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 19:53:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Varshney", "Lav R.", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "2002.03466", "submitter": "Filipo Sharevski", "authors": "Filipo Sharevski, Paige Treebridge, Peter Jachim, Audrey Li, Adam\n  Babin, Jessica Westbrook", "title": "Meet Malexa, Alexa's Malicious Twin: Malware-Induced Misperception\n  Through Intelligent Voice Assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports the findings of a study where users (N=220) interacted\nwith Malexa, Alexa's malicious twin. Malexa is an intelligent voice assistant\nwith a simple and seemingly harmless third-party skill that delivers news\nbriefings to users. The twist, however, is that Malexa covertly rewords these\nbriefings to intentionally introduce misperception about the reported events.\nThis covert rewording is referred to as a Malware-Induced Misperception (MIM)\nattack. It differs from squatting or invocation hijacking attacks in that it is\nfocused on manipulating the \"content\" delivered through a third-party skill\ninstead of the skill's \"invocation logic.\" Malexa, in the study, reworded\nregulatory briefings to make a government response sound more accidental or\nlenient than the original news delivered by Alexa. The results show that users\nwho interacted with Malexa perceived that the government was less friendly to\nworking people and more in favor of big businesses. The results also show that\nMalexa is capable of inducing misperceptions regardless of the user's gender,\npolitical ideology or frequency of interaction with intelligent voice\nassistants. We discuss the implications in the context of using Malexa as a\ncovert \"influencer\" in people's living or working environments.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 22:44:06 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sharevski", "Filipo", ""], ["Treebridge", "Paige", ""], ["Jachim", "Peter", ""], ["Li", "Audrey", ""], ["Babin", "Adam", ""], ["Westbrook", "Jessica", ""]]}, {"id": "2002.03681", "submitter": "Athanasios Mazarakis", "authors": "Athanasios Mazarakis and Paula Br\\\"auer", "title": "First Directions for Using Gamification to Motivate for Open Access", "comments": "10 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most scientists are aware that, in addition to the traditional and\nsubscription-based publication model, there is also the possibility of\npublishing their research in open access. Various surveys show that scientists\nare in favour of this new model. Nevertheless, the transition to open access\nhas been very slow so far. In order to accelerate this process, we are looking\nfor new opportunities to create incentives for researchers to deal with the\ntopic of open access. In a field study with 28 participants the effects of the\ngame design elements badge and progress bar on the motivation when working on\nan online quiz on the topic of open access are examined. In our study both game\ndesign elements provide a statistically significant increase in the number of\nquestions answered compared to a control group. This suggests that gamification\nis useful to motivate for open access.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 12:29:12 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Mazarakis", "Athanasios", ""], ["Br\u00e4uer", "Paula", ""]]}, {"id": "2002.03806", "submitter": "Mehran Makhtoumi", "authors": "Mehran Makhtoumi", "title": "Fairness in Slot Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent interpretations of fairness in slot allocation of flights are\nconsidered as the word equity and upon these interpretations for fairness,\naviation agencies as airspace administrators along with stakeholders have been\napplying ground delay problem procedure with ration by schedule and compression\nalgorithms as fair distribution of slots among them in reduced capacity\nairports. The drawback of these approaches is that the slots to be allocated to\nflights are all of the equal size or duration since the flights to be assigned\nto slots can not be differentiated. In fact, the absence of a scientific\nframework of fairness in air traffic management has led to the different\ncontradictory interpretations for it. As proposed in this study, fairness is\nthe minimum deviation from the planned outcome in terms of time, quantity and\nquality under the optimum share management rule for each stakeholder. To\nachieve fairness in slot allocation of the airport under reduced and normal\ncapacity, a new allocation rule of ration by fairness is proposed in which the\nelements of time, quantity and quality are proposed to be the original time of\ndeparture or arrival, slot size or duration, and airspace safety and preflight\nchecklist, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 11:37:36 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Makhtoumi", "Mehran", ""]]}, {"id": "2002.03810", "submitter": "Carlos Sarraute PhD", "authors": "Ariel Futoransky, Carlos Sarraute, Ariel Waissbein, Matias Travizano,\n  Daniel Fernandez", "title": "WibsonTree: Efficiently Preserving Seller's Privacy in a Decentralized\n  Data Marketplace", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a cryptographic primitive called WibsonTree designed to preserve\nusers' privacy by allowing them to demonstrate predicates on their personal\nattributes, without revealing the values of those attributes. We suppose that\nthere are three types of agents --buyers, sellers and notaries-- who interact\nin a decentralized privacy-preserving data marketplace (dPDM) such as the\nWibson marketplace. We introduce the WibsonTree protocol as an efficient\ncryptographic primitive that enables the exchange of private information while\npreserving the seller's privacy. Using our primitive, a data seller can\nefficiently prove that he/she belongs to the target audience of a buyer's data\nrequest, without revealing any additional information.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 14:39:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Futoransky", "Ariel", ""], ["Sarraute", "Carlos", ""], ["Waissbein", "Ariel", ""], ["Travizano", "Matias", ""], ["Fernandez", "Daniel", ""]]}, {"id": "2002.03841", "submitter": "Hussein Abbass A", "authors": "Hussein A. Abbass, Sondoss Elsawah, Eleni Petraki, Robert Hunjet", "title": "Machine Education: Designing semantically ordered and ontologically\n  guided modular neural networks", "comments": "IEEE Symposium Series on Computational Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature on machine teaching, machine education, and curriculum design\nfor machines is in its infancy with sparse papers on the topic primarily\nfocusing on data and model engineering factors to improve machine learning. In\nthis paper, we first discuss selected attempts to date on machine teaching and\neducation. We then bring theories and methodologies together from human\neducation to structure and mathematically define the core problems in lesson\ndesign for machine education and the modelling approaches required to support\nthe steps for machine education. Last, but not least, we offer an\nontology-based methodology to guide the development of lesson plans to produce\ntransparent and explainable modular learning machines, including neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 09:43:40 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Abbass", "Hussein A.", ""], ["Elsawah", "Sondoss", ""], ["Petraki", "Eleni", ""], ["Hunjet", "Robert", ""]]}, {"id": "2002.03885", "submitter": "Filipo Sharevski", "authors": "Filipo Sharevski, Paige Treebridge, Peter Jachim, Audrey Li, Adam\n  Babin, Jessica Westbrook", "title": "Beyond Trolling: Malware-Induced Misperception Attacks on Polarized\n  Facebook Discourse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media trolling is a powerful tactic to manipulate public opinion on\nissues with a high moral component. Troll farms, as evidenced in the past,\ncreated fabricated content to provoke or silence people to share their opinion\non social media during the US presidential election in 2016. In this paper, we\nintroduce an alternate way of provoking or silencing social media discourse by\nmanipulating how users perceive authentic content. This manipulation is\nperformed by man-in-the-middle malware that covertly rearranges the linguistic\ncontent of an authentic social media post and comments. We call this attack\nMalware-Induced Misperception (MIM) because the goal is to socially engineer\nspiral-of-silence conditions on social media by inducing perception. We\nconducted experimental tests in controlled settings (N = 311) where a malware\ncovertly altered selected words in a Facebook post about the freedom of\npolitical expression on college campuses. The empirical results (1) confirm the\nprevious findings about the presence of the spiral-of-silence effect on social\nmedia; and (2) demonstrate that inducing misperception is an effective tactic\nto silence or provoke targeted users on Facebook to express their opinion on a\npolarizing political issue.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 15:55:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Sharevski", "Filipo", ""], ["Treebridge", "Paige", ""], ["Jachim", "Peter", ""], ["Li", "Audrey", ""], ["Babin", "Adam", ""], ["Westbrook", "Jessica", ""]]}, {"id": "2002.04020", "submitter": "Michael Soltys", "authors": "Michael Soltys", "title": "Cloudifying the Curriculum with AWS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cloud has become a principal paradigm of computing in the last ten years,\nand Computer Science curricula must be updated to reflect that reality. This\npaper examines simple ways to accomplish curriculum cloudification using Amazon\nWeb Services (AWS), for Computer Science and other disciplines such as\nBusiness, Communication and Mathematics.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 18:47:35 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Soltys", "Michael", ""]]}, {"id": "2002.04258", "submitter": "Manuel Gomez Rodriguez", "authors": "Vahid Balazadeh Meresht and Abir De and Adish Singla and Manuel\n  Gomez-Rodriguez", "title": "Learning to Switch Between Machines and Humans", "comments": "Added support for unknown transition probabilities and multiple teams", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents have been mostly developed and evaluated under\nthe assumption that they will operate in a fully autonomous manner -- they will\ntake all actions. In this work, our goal is to develop algorithms that, by\nlearning to switch control between machine and human agents, allow existing\nreinforcement learning agents to operate under different automation levels. To\nthis end, we first formally define the problem of learning to switch control\namong agents in a team via a 2-layer Markov decision process. Then, we develop\nan online learning algorithm that uses upper confidence bounds on the agents'\npolicies and the environment's transition probabilities to find a sequence of\nswitching policies. We prove that the total regret of our algorithm with\nrespect to the optimal switching policy is sublinear in the number of learning\nsteps. Moreover, we also show that our algorithm can be used to find multiple\nsequences of switching policies across several independent teams of agents\noperating in similar environments, where it greatly benefits from maintaining\nshared confidence bounds for the environments' transition probabilities.\nSimulation experiments in obstacle avoidance in a semi-autonomous driving\nscenario illustrate our theoretical findings and demonstrate that, by\nexploiting the specific structure of the problem, our proposed algorithm is\nsuperior to problem-agnostic algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 08:50:52 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 08:43:23 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Meresht", "Vahid Balazadeh", ""], ["De", "Abir", ""], ["Singla", "Adish", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2002.04333", "submitter": "Stratis Tsirtsis", "authors": "Stratis Tsirtsis and Manuel Gomez-Rodriguez", "title": "Decisions, Counterfactual Explanations and Strategic Behavior", "comments": "Transportation of mass experiment in main. Clarification of model\n  assumptions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.GT cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data-driven predictive models are increasingly used to inform decisions,\nit has been argued that decision makers should provide explanations that help\nindividuals understand what would have to change for these decisions to be\nbeneficial ones. However, there has been little discussion on the possibility\nthat individuals may use the above counterfactual explanations to invest effort\nstrategically and maximize their chances of receiving a beneficial decision. In\nthis paper, our goal is to find policies and counterfactual explanations that\nare optimal in terms of utility in such a strategic setting. We first show\nthat, given a pre-defined policy, the problem of finding the optimal set of\ncounterfactual explanations is NP-hard. Then, we show that the corresponding\nobjective is nondecreasing and satisfies submodularity and this allows a\nstandard greedy algorithm to enjoy approximation guarantees. In addition, we\nfurther show that the problem of jointly finding both the optimal policy and\nset of counterfactual explanations reduces to maximizing a non-monotone\nsubmodular function. As a result, we can use a recent randomized algorithm to\nsolve the problem, which also offers approximation guarantees. Finally, we\ndemonstrate that, by incorporating a matroid constraint into the problem\nformulation, we can increase the diversity of the optimal set of counterfactual\nexplanations and incentivize individuals across the whole spectrum of the\npopulation to self improve. Experiments on synthetic and real lending and\ncredit card data illustrate our theoretical findings and show that the\ncounterfactual explanations and decision policies found by our algorithms\nachieve higher utility than several competitive baselines.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 12:04:41 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 11:28:00 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 16:55:44 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Tsirtsis", "Stratis", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2002.04533", "submitter": "Haoqian Zhang", "authors": "Haoqian Zhang, Yancheng Zhao, Abhishek Paryani, Ke Yi", "title": "Infnote: A Decentralized Information Sharing Platform Based on\n  Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet censorship has been implemented in several countries to prevent\ncitizens from accessing information and to suppress discussion of specific\ntopics. This paper presents Infnote, a platform that helps eliminate the\nproblem of sharing content in these censorship regimes. Infnote is a\ndecentralized information sharing system based on blockchain and peer-to-peer\nnetwork, aiming to provide an easy-to-use medium for users to share their\nthoughts, insights and views freely without worrying about data tampering and\ndata loss. Infnote provides a solution that is able to work on any level of\nInternet censorship. Infnote uses multi-chains architecture to support various\nindependent applications or different functions in an application.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 16:35:40 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Zhang", "Haoqian", ""], ["Zhao", "Yancheng", ""], ["Paryani", "Abhishek", ""], ["Yi", "Ke", ""]]}, {"id": "2002.04587", "submitter": "Jinghui Cheng", "authors": "Nasim Sharbatdar, Yassine Lamine, Brigitte Milord, Catherine Morency,\n  Jinghui Cheng", "title": "Capturing the Practices, Challenges, and Needs of Transportation\n  Decision-Makers", "comments": "7 pages, 0 figures, ACM CHI LBW Paper (2020). For personas created in\n  the project, see https://github.com/HCDLab/TDMPersonas", "journal-ref": null, "doi": "10.1145/3334480.3382864", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation decision-makers from government agencies play an important\nrole in addressing the traffic network conditions, which in turn, have a major\nimpact on the well-being of citizens. The practices, challenges, and needs of\nthis group of practitioners are less represented in the HCI literature. We\naddress this gap through an interview study with 19 practitioners from\nTransports Qu\\'ebec, a government agency responsible for transportation\ninfrastructures in Qu\\'ebec, Canada. We found that this group of\ndecision-makers can most benefit from research about data analysis tools and\nplatforms that (1) provide information to support data quality awareness, (2)\nare interoperable with other tools in the complex workflow of the\npractitioners, and (3) support intuitive and customizable visual analytics.\nThese implications can also be informative to the design of tools supporting\nother decision-making tasks and domains.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 18:30:01 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Sharbatdar", "Nasim", ""], ["Lamine", "Yassine", ""], ["Milord", "Brigitte", ""], ["Morency", "Catherine", ""], ["Cheng", "Jinghui", ""]]}, {"id": "2002.04631", "submitter": "Pardis Emami-Naeini", "authors": "Pardis Emami-Naeini, Yuvraj Agarwal, Lorrie Faith Cranor, Hanan Hibshi", "title": "Ask the Experts: What Should Be on an IoT Privacy and Security Label?", "comments": "To appear at the 41st IEEE Symposium on Security and Privacy (S&P'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about the privacy and security of Internet of Things (IoT)\ndevices is not readily available to consumers who want to consider it before\nmaking purchase decisions. While legislators have proposed adding succinct,\nconsumer accessible, labels, they do not provide guidance on the content of\nthese labels. In this paper, we report on the results of a series of interviews\nand surveys with privacy and security experts, as well as consumers, where we\nexplore and test the design space of the content to include on an IoT privacy\nand security label. We conduct an expert elicitation study by following a\nthree-round Delphi process with 22 privacy and security experts to identify the\nfactors that experts believed are important for consumers when comparing the\nprivacy and security of IoT devices to inform their purchase decisions. Based\non how critical experts believed each factor is in conveying risk to consumers,\nwe distributed these factors across two layers---a primary layer to display on\nthe product package itself or prominently on a website, and a secondary layer\navailable online through a web link or a QR code. We report on the experts'\nrationale and arguments used to support their choice of factors. Moreover, to\nstudy how consumers would perceive the privacy and security information\nspecified by experts, we conducted a series of semi-structured interviews with\n15 participants, who had purchased at least one IoT device (smart home device\nor wearable). Based on the results of our expert elicitation and consumer\nstudies, we propose a prototype privacy and security label to help consumers\nmake more informed IoT-related purchase decisions.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 19:01:14 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Emami-Naeini", "Pardis", ""], ["Agarwal", "Yuvraj", ""], ["Cranor", "Lorrie Faith", ""], ["Hibshi", "Hanan", ""]]}, {"id": "2002.04788", "submitter": "Hao Wang", "authors": "Hao Wang, Hsiang Hsu, Mario Diaz, Flavio P. Calmon", "title": "To Split or Not to Split: The Impact of Disparate Treatment in\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disparate treatment occurs when a machine learning model yields different\ndecisions for individuals based on a sensitive attribute (e.g., age, sex). In\ndomains where prediction accuracy is paramount, it could potentially be\nacceptable to fit a model which exhibits disparate treatment. To evaluate the\neffect of disparate treatment, we compare the performance of split classifiers\n(i.e., classifiers trained and deployed separately on each group) with\ngroup-blind classifiers (i.e., classifiers which do not use a sensitive\nattribute). We introduce the benefit-of-splitting for quantifying the\nperformance improvement by splitting classifiers. Computing the\nbenefit-of-splitting directly from its definition could be intractable since it\ninvolves solving optimization problems over an infinite-dimensional functional\nspace. Under different performance measures, we (i) prove an equivalent\nexpression for the benefit-of-splitting which can be efficiently computed by\nsolving small-scale convex programs; (ii) provide sharp upper and lower bounds\nfor the benefit-of-splitting which reveal precise conditions where a\ngroup-blind classifier will always suffer from a non-trivial performance gap\nfrom the split classifiers. In the finite sample regime, splitting is not\nnecessarily beneficial and we provide data-dependent bounds to understand this\neffect. Finally, we validate our theoretical results through numerical\nexperiments on both synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 04:05:31 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 16:13:28 GMT"}, {"version": "v3", "created": "Wed, 30 Jun 2021 21:05:16 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Hao", ""], ["Hsu", "Hsiang", ""], ["Diaz", "Mario", ""], ["Calmon", "Flavio P.", ""]]}, {"id": "2002.05051", "submitter": "Simone Raponi", "authors": "Simone Raponi, Savio Sciancalepore, Gabriele Oligeri, Roberto Di\n  Pietro", "title": "Road Traffic Poisoning of Navigation Apps: Threats and Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assisted-navigation applications have a relevant impact on our daily life.\nHowever, technological progress in virtualization technologies and\nSoftware-Defined Radios recently enabled new attack vectors, namely, road\ntraffic poisoning. These attacks open up several dreadful scenarios, which are\naddressed in this contribution by identifying the associated challenges and\nproposing innovative countermeasures.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 15:37:58 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 13:49:41 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 16:33:52 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Raponi", "Simone", ""], ["Sciancalepore", "Savio", ""], ["Oligeri", "Gabriele", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "2002.05149", "submitter": "Daniel Elton", "authors": "Daniel C. Elton", "title": "Self-explaining AI as an alternative to interpretable AI", "comments": "10pgs, 2 column format", "journal-ref": null, "doi": "10.1007/978-3-030-52152-3_10", "report-no": null, "categories": "cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to explain decisions made by AI systems is highly sought after,\nespecially in domains where human lives are at stake such as medicine or\nautonomous vehicles. While it is often possible to approximate the input-output\nrelations of deep neural networks with a few human-understandable rules, the\ndiscovery of the double descent phenomena suggests that such approximations do\nnot accurately capture the mechanism by which deep neural networks work. Double\ndescent indicates that deep neural networks typically operate by smoothly\ninterpolating between data points rather than by extracting a few high level\nrules. As a result, neural networks trained on complex real world data are\ninherently hard to interpret and prone to failure if asked to extrapolate. To\nshow how we might be able to trust AI despite these problems we introduce the\nconcept of self-explaining AI. Self-explaining AIs are capable of providing a\nhuman-understandable explanation of each decision along with confidence levels\nfor both the decision and explanation. For this approach to work, it is\nimportant that the explanation actually be related to the decision, ideally\ncapturing the mechanism used to arrive at the explanation. Finally, we argue it\nis important that deep learning based systems include a \"warning light\" based\non techniques from applicability domain analysis to warn the user if a model is\nasked to extrapolate outside its training distribution. For a video\npresentation of this talk see https://www.youtube.com/watch?v=Py7PVdcu7WY& .\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 18:50:11 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 17:13:25 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 18:56:25 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 15:26:15 GMT"}, {"version": "v5", "created": "Wed, 17 Jun 2020 13:38:58 GMT"}, {"version": "v6", "created": "Thu, 2 Jul 2020 19:03:24 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Elton", "Daniel C.", ""]]}, {"id": "2002.05188", "submitter": "Eric Silverman", "authors": "Umberto Gostoli, Eric Silverman", "title": "Social and Child Care Provision in Kinship Networks: an Agent-Based\n  Model", "comments": "24 pages, 20 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0242779", "report-no": null, "categories": "cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing for the needs of the vulnerable is a critical component of social\nand health policy-making. In particular, caring for children and for vulnerable\nolder people is vital to the wellbeing of millions of families throughout the\nworld. In most developed countries, this care is provided through both formal\nand informal means, and is therefore governed by complex policies that interact\nin non-obvious ways with other areas of policy-making. In this paper we present\nan agent-based model of social and child care provision in the UK, in which\nagents can provide informal care or pay for private care for their relatives.\nAgents make care decisions based on numerous factors including their health\nstatus, employment, financial situation, and social and physical distance to\nthose in need. Simulation results show that the model can produce plausible\npatterns of care need and availability, and therefore can provide an important\naid to this complex area of policy-making. We conclude that the model's use of\nkinship networks for distributing care and the explicit modelling of\ninteractions between social care and child care will enable policy-makers to\ndevelop more informed policy interventions in these critical areas.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:31:39 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 15:13:08 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Gostoli", "Umberto", ""], ["Silverman", "Eric", ""]]}, {"id": "2002.05193", "submitter": "Momin M. Malik", "authors": "Momin M. Malik", "title": "A Hierarchy of Limitations in Machine Learning", "comments": "68 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG econ.EM math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  \"All models are wrong, but some are useful\", wrote George E. P. Box (1979).\nMachine learning has focused on the usefulness of probability models for\nprediction in social systems, but is only now coming to grips with the ways in\nwhich these models are wrong---and the consequences of those shortcomings. This\npaper attempts a comprehensive, structured overview of the specific conceptual,\nprocedural, and statistical limitations of models in machine learning when\napplied to society. Machine learning modelers themselves can use the described\nhierarchy to identify possible failure points and think through how to address\nthem, and consumers of machine learning models can know what to question when\nconfronted with the decision about if, where, and how to apply machine\nlearning. The limitations go from commitments inherent in quantification\nitself, through to showing how unmodeled dependencies can lead to\ncross-validation being overly optimistic as a way of assessing model\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 19:39:29 GMT"}, {"version": "v2", "created": "Sat, 29 Feb 2020 21:04:27 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Malik", "Momin M.", ""]]}, {"id": "2002.05300", "submitter": "Roger Immich", "authors": "Flavia Pisani, Fabiola M. C. de Oliveira, Eduardo S. Gama, Roger\n  Immich, Luiz F. Bittencourt, and Edson Borin", "title": "Fog Computing on Constrained Devices: Paving the Way for the Future IoT", "comments": "http://ebooks.iospress.nl/volumearticle/53823", "journal-ref": "IOS Press Advances in Edge Computing: Massive Parallel Processing\n  and Applications, Series Advances in Parallel Computing, Volume 35 (2020).\n  ISBN978-1-64368-062-0 (print) | 978-1-64368-063-7 (online)", "doi": "10.3233/APC200003", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the long term, the Internet of Things (IoT) is expected to become an\nintegral part of people's daily lives. In light of this technological\nadvancement, an ever-growing number of objects with limited hardware may become\nconnected to the Internet. In this chapter, we explore the importance of these\nconstrained devices as well as how we can use them in conjunction with fog\ncomputing to change the future of the IoT. First, we present an overview of the\nconcepts of constrained devices, IoT, and fog and mist computing, and then we\npresent a classification of applications according to the amount of resources\nthey require (e.g., processing power and memory). After that, we tie in these\ntopics with a discussion of what can be expected in a future where constrained\ndevices and fog computing are used to push the IoT to new limits. Lastly, we\ndiscuss some challenges and opportunities that these technologies may bring.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 01:12:31 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 17:52:55 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Pisani", "Flavia", ""], ["de Oliveira", "Fabiola M. C.", ""], ["Gama", "Eduardo S.", ""], ["Immich", "Roger", ""], ["Bittencourt", "Luiz F.", ""], ["Borin", "Edson", ""]]}, {"id": "2002.05342", "submitter": "Hamza Sami Ullah", "authors": "J. Ahmad and H. Sami Ullah and S. Aslam", "title": "Understanding the Impact of Customer Reviews on Hotel Rating: An\n  Empirical Research", "comments": "13 pages, 13 Figures and 16 References", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ascent of the Internet has caused numerous adjustments in our lives. The\nInternet has radically changed the manner in which we carry on with our lives,\nthe manner in which we spend our occasions, how we speak with one another day\nby day, and how we buy items. The development of the Internet among users has\ncreated content on the Internet by sources, for example, web-based life,\nreviews site, online journals, item fan page and some more. This has a lead on\nto another method for arranging an occasion or searching for a reasonable hotel\nto remain. Thus, hotel review sites have turned into a famous stage for\nvisitors to share their experiences, reviews, and suggestions on hotels, which\nthey have visited. In Europe, the hotel business has been a standout amongst\nthe most vital monetary developments of the nation. The essential objective of\na hotel is to satisfy the customers, to have the capacity to give a high\ncaliber of administration and give them a vital affair while remaining at the\nhotel. The motivation behind this examination is to comprehend and recognize\nthe scope of elements, which may add as per the general inclination of\ncustomers and in addition through their reviews to decide the measures of\ncustomers' desires. Information was gathered from online review sites, for\nexample, Booking.com. Text analytics is utilized to analyze the contents\ngathered.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 04:36:57 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 09:38:20 GMT"}, {"version": "v3", "created": "Sat, 22 Feb 2020 15:40:03 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ahmad", "J.", ""], ["Ullah", "H. Sami", ""], ["Aslam", "S.", ""]]}, {"id": "2002.05411", "submitter": "Juan Camilo Vasquez Correa J. C. Vasquez-Correa", "authors": "C. D. Rios-Urrego, J. C. V\\'asquez-Correa, J. F. Vargas-Bonilla, E.\n  N\\\"oth, F. Lopera, J. R. Orozco-Arroyave", "title": "Analysis and Evaluation of Handwriting in Patients with Parkinson's\n  Disease Using kinematic, Geometrical, and Non-linear Features", "comments": null, "journal-ref": "Computer methods and programs in biomedicine, 173, 43-52 (2019)", "doi": "10.1016/j.cmpb.2019.03.005", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background and objectives: Parkinson's disease is a neurological disorder\nthat affects the motor system producing lack of coordination, resting tremor,\nand rigidity. Impairments in handwriting are among the main symptoms of the\ndisease. Handwriting analysis can help in supporting the diagnosis and in\nmonitoring the progress of the disease. This paper aims to evaluate the\nimportance of different groups of features to model handwriting deficits that\nappear due to Parkinson's disease; and how those features are able to\ndiscriminate between Parkinson's disease patients and healthy subjects.\n  Methods: Features based on kinematic, geometrical and non-linear dynamics\nanalyses were evaluated to classify Parkinson's disease and healthy subjects.\nClassifiers based on K-nearest neighbors, support vector machines, and random\nforest were considered.\n  Results: Accuracies of up to $93.1\\%$ were obtained in the classification of\npatients and healthy control subjects. A relevance analysis of the features\nindicated that those related to speed, acceleration, and pressure are the most\ndiscriminant. The automatic classification of patients in different stages of\nthe disease shows $\\kappa$ indexes between $0.36$ and $0.44$. Accuracies of up\nto $83.3\\%$ were obtained in a different dataset used only for validation\npurposes.\n  Conclusions: The results confirmed the negative impact of aging in the\nclassification process when we considered different groups of healthy subjects.\nIn addition, the results reported with the separate validation set comprise a\nstep towards the development of automated tools to support the diagnosis\nprocess in clinical practice.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 09:54:41 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Rios-Urrego", "C. D.", ""], ["V\u00e1squez-Correa", "J. C.", ""], ["Vargas-Bonilla", "J. F.", ""], ["N\u00f6th", "E.", ""], ["Lopera", "F.", ""], ["Orozco-Arroyave", "J. R.", ""]]}, {"id": "2002.05500", "submitter": "Marco De Nadai", "authors": "Marco De Nadai, Bruno Lepri and Nuria Oliver", "title": "Understanding individual behaviour: from virtual to physical patterns", "comments": "To appear in the Proceedings of the 24th European Conference on\n  Artificial Intelligence (ECAI), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As \"Big Data\" has become pervasive, an increasing amount of research has\nconnected the dots between human behaviour in the offline and online worlds.\nConsequently, researchers have exploited these new findings to create models\nthat better predict different aspects of human life and recommend future\nbehaviour. To date, however, we do not yet fully understand the similarities\nand differences of human behaviour in these virtual and physical worlds. Here,\nwe analyse and discuss the mobility and application usage of 400,000\nindividuals over eight months. We find an astonishing similarity between\npeople's mobility in the physical space and how they move from app to app in\nsmartphones. Our data shows that individuals use and visit a finite number of\napps and places, but they keep exploring over time. In particular, two distinct\nprofiles of individuals emerge: those that keep changing places and services,\nand those that are stable over time, named as \"explorers\" and \"keepers\". We see\nthese findings as crucial to enrich a discussion for the potentials and the\nchallenges of building human-centric AI systems, which might leverage recent\nresults in Computational Social Science.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 14:04:07 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["De Nadai", "Marco", ""], ["Lepri", "Bruno", ""], ["Oliver", "Nuria", ""]]}, {"id": "2002.05636", "submitter": "Ryan Steed", "authors": "Ryan Steed and Aylin Caliskan", "title": "A Set of Distinct Facial Traits Learned by Machines Is Not Predictive of\n  Appearance Bias in the Wild", "comments": "11 pages, 7 figures. Revision for AI Ethics", "journal-ref": "AI Ethics (2021)", "doi": "10.1007/s43681-020-00035-y", "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Research in social psychology has shown that people's biased, subjective\njudgments about another's personality based solely on their appearance are not\npredictive of their actual personality traits. But researchers and companies\noften utilize computer vision models to predict similarly subjective\npersonality attributes such as \"employability.\" We seek to determine whether\nstate-of-the-art, black box face processing technology can learn human-like\nappearance biases. With features extracted with FaceNet, a widely used face\nrecognition framework, we train a transfer learning model on human subjects'\nfirst impressions of personality traits in other faces as measured by social\npsychologists. We find that features extracted with FaceNet can be used to\npredict human appearance bias scores for deliberately manipulated faces but not\nfor randomly generated faces scored by humans. Additionally, in contrast to\nwork with human biases in social psychology, the model does not find a\nsignificant signal correlating politicians' vote shares with perceived\ncompetence bias. With Local Interpretable Model-Agnostic Explanations (LIME),\nwe provide several explanations for this discrepancy. Our results suggest that\nsome signals of appearance bias documented in social psychology are not\nembedded by the machine learning techniques we investigate. We shed light on\nthe ways in which appearance bias could be embedded in face processing\ntechnology and cast further doubt on the practice of predicting subjective\ntraits based on appearances.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:09:27 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 12:39:57 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 17:15:05 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Steed", "Ryan", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2002.05646", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, Magnus Nystr\\\"om, John Lambert, Andrew\n  Marshall, Mario Goertzel, Andi Comissoneru, Matt Swann, Sharon Xia", "title": "Adversarial Machine Learning -- Industry Perspectives", "comments": "Minor Typos corrected 7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on interviews with 28 organizations, we found that industry\npractitioners are not equipped with tactical and strategic tools to protect,\ndetect and respond to attacks on their Machine Learning (ML) systems. We\nleverage the insights from the interviews and we enumerate the gaps in\nperspective in securing machine learning systems when viewed in the context of\ntraditional software security development. We write this paper from the\nperspective of two personas: developers/ML engineers and security incident\nresponders who are tasked with securing ML systems as they are designed,\ndeveloped and deployed ML systems. The goal of this paper is to engage\nresearchers to revise and amend the Security Development Lifecycle for\nindustrial-grade software in the adversarial ML era.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 02:28:34 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 17:33:37 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 16:02:28 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Nystr\u00f6m", "Magnus", ""], ["Lambert", "John", ""], ["Marshall", "Andrew", ""], ["Goertzel", "Mario", ""], ["Comissoneru", "Andi", ""], ["Swann", "Matt", ""], ["Xia", "Sharon", ""]]}, {"id": "2002.05648", "submitter": "Ram Shankar Siva Kumar", "authors": "Kendra Albert, Jonathon Penney, Bruce Schneier, Ram Shankar Siva Kumar", "title": "Politics of Adversarial Machine Learning", "comments": "Authors ordered alphabetically; 4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to their security properties, adversarial machine-learning\nattacks and defenses have political dimensions. They enable or foreclose\ncertain options for both the subjects of the machine learning systems and for\nthose who deploy them, creating risks for civil liberties and human rights. In\nthis paper, we draw on insights from science and technology studies,\nanthropology, and human rights literature, to inform how defenses against\nadversarial attacks can be used to suppress dissent and limit attempts to\ninvestigate machine learning systems. To make this concrete, we use real-world\nexamples of how attacks such as perturbation, model inversion, or membership\ninference can be used for socially desirable ends. Although the predictions of\nthis analysis may seem dire, there is hope. Efforts to address human rights\nconcerns in the commercial spyware industry provide guidance for similar\nmeasures to ensure ML systems serve democratic, not authoritarian ends\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 01:15:39 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 20:34:56 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 04:59:52 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Albert", "Kendra", ""], ["Penney", "Jonathon", ""], ["Schneier", "Bruce", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "2002.05650", "submitter": "Hamza Sami Ullah", "authors": "N. Arjomand and H. Sami Ullah and S. Aslam", "title": "A Review of Blockchain-based Smart Grid: Applications,Opportunities, and\n  Future Directions", "comments": "12 pages, 4 Figures, 50 References. 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Smart Grid (SG) concept presented an unprecedented opportunity to move\nthe energy sector to more availability, reliability, and efficiency to improve\nour economic and environmental conditions. Renewable energy sources (Solar &\nWind) are such technologies that are used in the smart grid to figure out the\nenvironmental and economic issues and challenges. Smart grids provide energy in\ndifferent crowded sectors with the efficient and timely transmission of\nelectricity. But the traditional power grids follow a centralized approach for\nenergy transactions with a large number of growing connections and become more\nchallenging to handle power disturbance in the grid. Blockchain as a\ndecentralized and distributed technology provides promising applications in the\nsmart grid infrastructure with its excellent and salient features. In this\npaper, we provide a concise review of blockchain architecture, concepts, and\napplications in smart grids. Different potential opportunities for blockchain\ntechnology with smart grids are also discussed. Some future directions\nconcluded the paper.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:00:10 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 20:56:52 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Arjomand", "N.", ""], ["Ullah", "H. Sami", ""], ["Aslam", "S.", ""]]}, {"id": "2002.05651", "submitter": "Peter Henderson", "authors": "Peter Henderson, Jieru Hu, Joshua Romoff, Emma Brunskill, Dan\n  Jurafsky, Joelle Pineau", "title": "Towards the Systematic Reporting of the Energy and Carbon Footprints of\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate reporting of energy and carbon usage is essential for understanding\nthe potential climate impacts of machine learning research. We introduce a\nframework that makes this easier by providing a simple interface for tracking\nrealtime energy consumption and carbon emissions, as well as generating\nstandardized online appendices. Utilizing this framework, we create a\nleaderboard for energy efficient reinforcement learning algorithms to\nincentivize responsible research in this area as an example for other areas of\nmachine learning. Finally, based on case studies using our framework, we\npropose strategies for mitigation of carbon emissions and reduction of energy\nconsumption. By making accounting easier, we hope to further the sustainable\ndevelopment of machine learning experiments and spur more research into energy\nefficient algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 05:12:59 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Henderson", "Peter", ""], ["Hu", "Jieru", ""], ["Romoff", "Joshua", ""], ["Brunskill", "Emma", ""], ["Jurafsky", "Dan", ""], ["Pineau", "Joelle", ""]]}, {"id": "2002.05652", "submitter": "Aman Agarwal", "authors": "Aman Agarwal, Shimon Edelman", "title": "Functionally Effective Conscious AI Without Suffering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insofar as consciousness has a functional role in facilitating learning and\nbehavioral control, the builders of autonomous AI systems are likely to attempt\nto incorporate it into their designs. The extensive literature on the ethics of\nAI is concerned with ensuring that AI systems, and especially autonomous\nconscious ones, behave ethically. In contrast, our focus here is on the rarely\ndiscussed complementary aspect of engineering conscious AI: how to avoid\ncondemning such systems, for whose creation we would be solely responsible, to\nunavoidable suffering brought about by phenomenal self-consciousness. We\noutline two complementary approaches to this problem, one motivated by a\nphilosophical analysis of the phenomenal self, and the other by certain\ncomputational concepts in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 17:59:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Agarwal", "Aman", ""], ["Edelman", "Shimon", ""]]}, {"id": "2002.05655", "submitter": "Subhro Das", "authors": "Subhro Das, Sebastian Steffen, Wyatt Clarke, Prabhat Reddy, Erik\n  Brynjolfsson, Martin Fleming", "title": "Learning Occupational Task-Shares Dynamics for the Future of Work", "comments": "9 pages, 5 figures, 6 tables, Proceedings of the AAAI/ACM Conference\n  on AI, Ethics, and Society (AIES), 2020", "journal-ref": null, "doi": "10.1145/3375627.3375826", "report-no": null, "categories": "cs.CY cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent wave of AI and automation has been argued to differ from previous\nGeneral Purpose Technologies (GPTs), in that it may lead to rapid change in\noccupations' underlying task requirements and persistent technological\nunemployment. In this paper, we apply a novel methodology of dynamic task\nshares to a large dataset of online job postings to explore how exactly\noccupational task demands have changed over the past decade of AI innovation,\nespecially across high, mid and low wage occupations. Notably, big data and AI\nhave risen significantly among high wage occupations since 2012 and 2016,\nrespectively. We built an ARIMA model to predict future occupational task\ndemands and showcase several relevant examples in Healthcare, Administration,\nand IT. Such task demands predictions across occupations will play a pivotal\nrole in retraining the workforce of the future.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 21:20:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Das", "Subhro", ""], ["Steffen", "Sebastian", ""], ["Clarke", "Wyatt", ""], ["Reddy", "Prabhat", ""], ["Brynjolfsson", "Erik", ""], ["Fleming", "Martin", ""]]}, {"id": "2002.05657", "submitter": "Tristan Braud", "authors": "Abhishek Kumar, Tristan Braud, Sasu Tarkoma, Pan Hui", "title": "Trustworthy AI in the Age of Pervasive Computing and Big Data", "comments": "To be published in Percrowd 2020 (PerCom Adjunct). Please cite as:\n  Abhishek Kumar, Tristan Braud, Sasu Tarkoma, Pan Hui. Trustworthy AI in the\n  Age of Pervasive Computing and Big Data. In Proceedings of the 3rd\n  International Workshop on Context-awareness for Multi-device Pervasive and\n  Mobile Computing (Percrowd), Austin USA, March 2020 (Percom 2020 Workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The era of pervasive computing has resulted in countless devices that\ncontinuously monitor users and their environment, generating an abundance of\nuser behavioural data. Such data may support improving the quality of service,\nbut may also lead to adverse usages such as surveillance and advertisement. In\nparallel, Artificial Intelligence (AI) systems are being applied to sensitive\nfields such as healthcare, justice, or human resources, raising multiple\nconcerns on the trustworthiness of such systems. Trust in AI systems is thus\nintrinsically linked to ethics, including the ethics of algorithms, the ethics\nof data, or the ethics of practice. In this paper, we formalise the\nrequirements of trustworthy AI systems through an ethics perspective. We\nspecifically focus on the aspects that can be integrated into the design and\ndevelopment of AI systems. After discussing the state of research and the\nremaining challenges, we show how a concrete use-case in smart cities can\nbenefit from these methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 08:09:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kumar", "Abhishek", ""], ["Braud", "Tristan", ""], ["Tarkoma", "Sasu", ""], ["Hui", "Pan", ""]]}, {"id": "2002.05658", "submitter": "Jeannette Wing", "authors": "Jeannette M. Wing", "title": "Ten Research Challenge Areas in Data Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although data science builds on knowledge from computer science, mathematics,\nstatistics, and other disciplines, data science is a unique field with many\nmysteries to unlock: challenging scientific questions and pressing questions of\nsocietal importance. This article starts with meta-questions about data science\nas a discipline and then elaborates on ten ideas for the basis of a research\nagenda for data science.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 21:39:57 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Wing", "Jeannette M.", ""]]}, {"id": "2002.05659", "submitter": "Mahdi Miraz", "authors": "Mahdi H. Miraz and Marie Haikel-Elsabeh", "title": "Analysis of Users' Behaviour and Adoption Trends of Social Media Payment\n  Platforms", "comments": null, "journal-ref": "2019 International Conference on Computing, Electronics &\n  Communications Engineering (iCCECE), London, United Kingdom, 2019, pp.\n  197-202", "doi": "10.1109/iCCECE46942.2019.8941991", "report-no": null, "categories": "cs.CY cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proliferation of Electronic Commerce (E-commerce) has been further\nescalated by multifaceted emerging payment solutions such as cryptocurrencies,\nmobile, peer-to-peer (P2P) and social media payment platforms. While these\ntechnological advancements are gaining tremendous popularity, mostly for their\nease of use, various impediments such as security and privacy concerns,\nsocietal and cultural norms etc. forbear the users' adoption trends to some\nextents. This article examines the current status of the social media payment\nplatforms as well as the projection of future adoption trends. Our research\nunderlines the motivations and obstacles to the adoption of social media\nplatforms.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 12:08:43 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Miraz", "Mahdi H.", ""], ["Haikel-Elsabeh", "Marie", ""]]}, {"id": "2002.05663", "submitter": "Manuel Mazzara", "authors": "Nikolay Buldakov, Timur Khalilev, Salvatore Distefano and Manuel\n  Mazzara", "title": "An Open Source Solution for Smart Contract-based Parking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an open source solution to smart-parking in highly\nurbanized areas. Interviews have been conducted with domain experts, user\nstories defined and a system architecture has been proposed with a case study.\nOur solution allows independent owners of parking space to be integrated into\none unified system, that facilitates the parking situation in a smart city. The\nutilization of such a system raises the issues of trust and transparency among\nseveral actors of the parking process. In order to tackle those, we propose a\nsmart contract-based solution, that brings in trust by encapsulating sensitive\nrelations and processes into transparent and distributed smart contracts.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 12:00:29 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Buldakov", "Nikolay", ""], ["Khalilev", "Timur", ""], ["Distefano", "Salvatore", ""], ["Mazzara", "Manuel", ""]]}, {"id": "2002.05664", "submitter": "Scott McLachlan Dr", "authors": "Scott McLachlan, Evangelia Kyrimi, and Norman Fenton", "title": "Public Authorities as Defendants: Using Bayesian Networks to determine\n  the Likelihood of Success for Negligence claims in the wake of Oakden", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Several countries are currently investigating issues of neglect, poor quality\ncare and abuse in the aged care sector. In most cases it is the State who\nlicense and monitor aged care providers, which frequently introduces a serious\nconflict of interest because the State also operate many of the facilities\nwhere our most vulnerable peoples are cared for. Where issues are raised with\nthe standard of care being provided, the State are seen by many as a\ndeep-pockets defendant and become the target of high-value lawsuits. This paper\ndraws on cases and circumstances from one jurisdiction based on the English\nlegal tradition, Australia, and proposes a Bayesian solution capable of\ndetermining probability for success for citizen plaintiffs who bring negligence\nclaims against a public authority defendant. Use of a Bayesian network trained\non case audit data shows that even when the plaintiff case meets all\nrequirements for a successful negligence litigation, success is not often\nassured. Only in around one-fifth of these cases does the plaintiff succeed\nagainst a public authority as defendant.\n", "versions": [{"version": "v1", "created": "Sat, 1 Feb 2020 14:24:53 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["McLachlan", "Scott", ""], ["Kyrimi", "Evangelia", ""], ["Fenton", "Norman", ""]]}, {"id": "2002.05665", "submitter": "Hatem Hajri", "authors": "Jeanine Harb, Nicolas R\\'eb\\'ena, Rapha\\\"el Chosidow, Gr\\'egoire\n  Roblin, Roman Potarusov and Hatem Hajri", "title": "FRSign: A Large-Scale Traffic Light Dataset for Autonomous Trains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the realm of autonomous transportation, there have been many initiatives\nfor open-sourcing self-driving cars datasets, but much less for alternative\nmethods of transportation such as trains. In this paper, we aim to bridge the\ngap by introducing FRSign, a large-scale and accurate dataset for vision-based\nrailway traffic light detection and recognition. Our recordings were made on\nselected running trains in France and benefited from carefully hand-labeled\nannotations. An illustrative dataset which corresponds to ten percent of the\nacquired data to date is published in open source with the paper. It contains\nmore than 100,000 images illustrating six types of French railway traffic\nlights and their possible color combinations, together with the relevant\ninformation regarding their acquisition such as date, time, sensor parameters,\nand bounding boxes. This dataset is published in open-source at the address\n\\url{https://frsign.irt-systemx.fr}. We compare, analyze various properties of\nthe dataset and provide metrics to express its variability. We also discuss\nspecific challenges and particularities related to autonomous trains in\ncomparison to autonomous cars.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2020 15:08:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Harb", "Jeanine", ""], ["R\u00e9b\u00e9na", "Nicolas", ""], ["Chosidow", "Rapha\u00ebl", ""], ["Roblin", "Gr\u00e9goire", ""], ["Potarusov", "Roman", ""], ["Hajri", "Hatem", ""]]}, {"id": "2002.05666", "submitter": "Behnam Pourghassemi", "authors": "Behnam Pourghassemi, Jordan Bonecutter, Zhou Li, Aparna\n  Chandramowlishwaran", "title": "adPerf: Characterizing the Performance of Third-party Ads", "comments": "13 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monetizing websites and web apps through online advertising is widespread in\nthe web ecosystem. The online advertising ecosystem nowadays forces publishers\nto integrate ads from these third-party domains. On the one hand, this raises\nseveral privacy and security concerns that are actively studied in recent\nyears. On the other hand, given the ability of today's browsers to load dynamic\nweb pages with complex animations and Javascript, online advertising has also\ntransformed and can have a significant impact on webpage performance. The\nperformance cost of online ads is critical since it eventually impacts user\nsatisfaction as well as their Internet bill and device energy consumption.\n  In this paper, we apply an in-depth and first-of-a-kind performance\nevaluation of web ads. Unlike prior efforts that rely primarily on adblockers,\nwe perform a fine-grained analysis on the web browser's page loading process to\ndemystify the performance cost of web ads. We aim to characterize the cost by\nevery component of an ad, so the publisher, ad syndicate, and advertiser can\nimprove the ad's performance with detailed guidance. For this purpose, we\ndevelop an infrastructure, adPerf, for the Chrome browser that classifies page\nloading workloads into ad-related and main-content at the granularity of\nbrowser activities (such as Javascript and Layout). Our evaluations show that\nonline advertising entails more than 15% of browser page loading workload and\napproximately 88% of that is spent on JavaScript. We also track the sources and\ndelivery chain of web ads and analyze performance considering the origin of the\nad contents. We observe that 2 of the well-known third-party ad domains\ncontribute to 35% of the ads performance cost and surprisingly, top news\nwebsites implicitly include unknown third-party ads which in some cases build\nup to more than 37% of the ads performance cost.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2020 02:09:05 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Pourghassemi", "Behnam", ""], ["Bonecutter", "Jordan", ""], ["Li", "Zhou", ""], ["Chandramowlishwaran", "Aparna", ""]]}, {"id": "2002.05671", "submitter": "Mislav Juri\\'c", "authors": "Mislav Juric, Agneza Sandic, Mario Brcic", "title": "AI safety: state of the field through quantitative lens", "comments": "2020 43rd International Convention on Information and Communication\n  Technology, Electronics and Microelectronics (MIPRO)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Last decade has seen major improvements in the performance of artificial\nintelligence which has driven wide-spread applications. Unforeseen effects of\nsuch mass-adoption has put the notion of AI safety into the public eye. AI\nsafety is a relatively new field of research focused on techniques for building\nAI beneficial for humans. While there exist survey papers for the field of AI\nsafety, there is a lack of a quantitative look at the research being conducted.\nThe quantitative aspect gives a data-driven insight about the emerging trends,\nknowledge gaps and potential areas for future research. In this paper,\nbibliometric analysis of the literature finds significant increase in research\nactivity since 2015. Also, the field is so new that most of the technical\nissues are open, including: explainability with its long-term utility, and\nvalue alignment which we have identified as the most important long-term\nresearch topic. Equally, there is a severe lack of research into concrete\npolicies regarding AI. As we expect AI to be the one of the main driving forces\nof changes in society, AI safety is the field under which we need to decide the\ndirection of humanity's future.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 11:26:44 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 11:32:14 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Juric", "Mislav", ""], ["Sandic", "Agneza", ""], ["Brcic", "Mario", ""]]}, {"id": "2002.05672", "submitter": "Osonde Osoba Ph.D.", "authors": "Osonde A. Osoba, Benjamin Boudreaux, Douglas Yeung", "title": "Steps Towards Value-Aligned Systems", "comments": "Original version appeared in Proceedings of the 2020 AAAI ACM\n  Conference on AI, Ethics, and Society (AIES '20), February 7-8, 2020, New\n  York, NY, USA. 5 pages, 2 figures. Corrected some typos in this version", "journal-ref": null, "doi": "10.1145/3375627.3375872", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic (including AI/ML) decision-making artifacts are an established\nand growing part of our decision-making ecosystem. They are indispensable tools\nfor managing the flood of information needed to make effective decisions in a\ncomplex world. The current literature is full of examples of how individual\nartifacts violate societal norms and expectations (e.g. violations of fairness,\nprivacy, or safety norms). Against this backdrop, this discussion highlights an\nunder-emphasized perspective in the literature on assessing value misalignment\nin AI-equipped sociotechnical systems. The research on value misalignment has a\nstrong focus on the behavior of individual tech artifacts. This discussion\nargues for a more structured systems-level approach for assessing\nvalue-alignment in sociotechnical systems. We rely primarily on the research on\nfairness to make our arguments more concrete. And we use the opportunity to\nhighlight how adopting a system perspective improves our ability to explain and\naddress value misalignments better. Our discussion ends with an exploration of\npriority questions that demand attention if we are to assure the value\nalignment of whole systems, not just individual artifacts.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2020 22:47:30 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 21:27:12 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Osoba", "Osonde A.", ""], ["Boudreaux", "Benjamin", ""], ["Yeung", "Douglas", ""]]}, {"id": "2002.05673", "submitter": "Ivan Vladimir Meza Ruiz", "authors": "Sof\\'ia Trejo and Ivan Meza and Fernanda L\\'opez-Escobedo", "title": "Hacia los Comit\\'es de \\'Etica en Inteligencia Artificial", "comments": "14 pages, in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Artificial Intelligence based systems is to take decisions that\nhave an effect in their environment and impact society. This points out to the\nnecessity of mechanism that regulate the impact of this type of system in\nsociety. For this reason, it is priority to create the rules and specialized\norganizations that can oversight the following of such rules, particularly that\nhuman rights precepts at local and international level. This work proposes the\ncreation, at the universities, of Ethical Committees or Commissions specialized\non Artificial Intelligence that would be in charge of define the principles and\nwill guarantee the following of good practices in the field Artificial\nIntelligence.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2020 23:48:31 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Trejo", "Sof\u00eda", ""], ["Meza", "Ivan", ""], ["L\u00f3pez-Escobedo", "Fernanda", ""]]}, {"id": "2002.05674", "submitter": "Micha{\\l} Ku\\'zba", "authors": "Micha{\\l} Ku\\'zba, Przemys{\\l}aw Biecek", "title": "What Would You Ask the Machine Learning Model? Identification of User\n  Needs for Model Explanations Based on Human-Model Conversations", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we see a rising number of methods in the field of eXplainable\nArtificial Intelligence. To our surprise, their development is driven by model\ndevelopers rather than a study of needs for human end users. The analysis of\nneeds, if done, takes the form of an A/B test rather than a study of open\nquestions. To answer the question \"What would a human operator like to ask the\nML model?\" we propose a conversational system explaining decisions of the\npredictive model. In this experiment, we developed a chatbot called dr_ant to\ntalk about machine learning model trained to predict survival odds on Titanic.\nPeople can talk with dr_ant about different aspects of the model to understand\nthe rationale behind its predictions. Having collected a corpus of 1000+\ndialogues, we analyse the most common types of questions that users would like\nto ask. To our knowledge, it is the first study which uses a conversational\nsystem to collect the needs of human operators from the interactive and\niterative dialogue explorations of a predictive model.\n", "versions": [{"version": "v1", "created": "Fri, 7 Feb 2020 15:59:49 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 17:14:08 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 13:49:43 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ku\u017aba", "Micha\u0142", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "2002.05679", "submitter": "Amro Najjar", "authors": "Daniel Karpati, Amro Najjar, Diego Agustin Ambrossio", "title": "Ethics of Food Recommender Applications", "comments": "6 pages, 1 Figure, AIES 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent unprecedented popularity of food recommender applications has\nraised several issues related to the ethical, societal and legal implications\nof relying on these applications. In this paper, in order to assess the\nrelevant ethical issues, we rely on the emerging principles across the\nAI\\&Ethics community and define them tailored context specifically. Considering\nthe popular Food Recommender Systems (henceforth F-RS) in the European market\ncannot be regarded as personalised F-RS, we show how merely this lack of\nfeature shifts the relevance of the focal ethical concerns. We identify the\nmajor challenges and propose a scheme for how explicit ethical agendas should\nbe explained. We also argue how a multi-stakeholder approach is indispensable\nto ensure producing long-term benefits for all stakeholders. After proposing\neight ethical desiderata points for F-RS, we present a case-study and assess it\nbased on our proposed desiderata points.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2020 00:53:02 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Karpati", "Daniel", ""], ["Najjar", "Amro", ""], ["Ambrossio", "Diego Agustin", ""]]}, {"id": "2002.05966", "submitter": "Hao Cheng", "authors": "Hao Cheng, Wentong Liao, Michael Ying Yang, Monika Sester, Bodo\n  Rosenhahn", "title": "MCENET: Multi-Context Encoder Network for Homogeneous Agent Trajectory\n  Prediction in Mixed Traffic", "comments": "8 pages, 5 figures, code is available on\n  https://github.com/haohao11/MCENET", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory prediction in urban mixed-traffic zones (a.k.a. shared spaces) is\ncritical for many intelligent transportation systems, such as intent detection\nfor autonomous driving. However, there are many challenges to predict the\ntrajectories of heterogeneous road agents (pedestrians, cyclists and vehicles)\nat a microscopical level. For example, an agent might be able to choose\nmultiple plausible paths in complex interactions with other agents in varying\nenvironments. To this end, we propose an approach named Multi-Context Encoder\nNetwork (MCENET) that is trained by encoding both past and future scene\ncontext, interaction context and motion information to capture the patterns and\nvariations of the future trajectories using a set of stochastic latent\nvariables. In inference time, we combine the past context and motion\ninformation of the target agent with samplings of the latent variables to\npredict multiple realistic trajectories in the future. Through experiments on\nseveral datasets of varying scenes, our method outperforms some of the recent\nstate-of-the-art methods for mixed traffic trajectory prediction by a large\nmargin and more robust in a very challenging environment. The impact of each\ncontext is justified via ablation studies.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:04:41 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 15:53:02 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 13:39:05 GMT"}, {"version": "v4", "created": "Sun, 5 Apr 2020 12:08:51 GMT"}, {"version": "v5", "created": "Tue, 23 Jun 2020 13:06:17 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Cheng", "Hao", ""], ["Liao", "Wentong", ""], ["Yang", "Michael Ying", ""], ["Sester", "Monika", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "2002.05971", "submitter": "Giacomo Livan", "authors": "Samuel Stern, Giacomo Livan, Robert E. Smith", "title": "A network perspective on intermedia agenda-setting", "comments": "21 pages, 9 figures", "journal-ref": "Applied Network Science 5, Article number: 31 (2020)", "doi": "10.1007/s41109-020-00272-4", "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Communication Theory, intermedia agenda-setting refers to the influence\nthat different news sources may have on each other, and how this subsequently\naffects the breadth of information that is presented to the public. Several\nstudies have attempted to quantify the impact of intermedia agenda-setting in\nspecific countries or contexts, but a large-scale, data-driven investigation is\nstill lacking. Here, we operationalise intermedia agenda-setting by putting\nforward a methodology to infer networks of influence between different news\nsources on a given topic, and apply it on a large dataset of news articles\npublished by globally and locally prominent news organisations in 2016. We find\ninfluence to be significantly topic-dependent, with the same news sources\nacting as agenda-setters (i.e., central nodes) with respect to certain topics\nand as followers (i.e., peripheral nodes) with respect to others. At the same\ntime, we find that the influence networks associated with most topics exhibit\nsmall world properties, which we find to play a significant role towards the\noverall diversity of sentiment expressed about the topic by the news sources in\nthe network. In particular, we find clustering and density of influence\nnetworks to act as competing forces in this respect, with the former increasing\nand the latter reducing diversity.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:27:16 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 08:43:32 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Stern", "Samuel", ""], ["Livan", "Giacomo", ""], ["Smith", "Robert E.", ""]]}, {"id": "2002.06086", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley", "title": "Artificial Intelligence, connected products, virtual reality: potential\n  impacts on consumer safety in terms of their physical and psychological\n  ability or well-being", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the progressive digitalisation of a majority of services to communities\nand individuals, humankind is facing new challenges. While energy sources are\nrapidly dwindling and rigorous choices have to be made to ensure the\nsustainability of our environment, there is increasing concern in science and\nsociety about the safety of connected products and technology for the\nindividual user. This essay provides a first basis for further inquiry into the\nrisks in terms of potentially negative, short and long-term, effects of\nconnected technologies and massive digitalisation on the psychological and/or\nphysical abilities and well-being of users or consumers.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 15:43:20 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Dresp-Langley", "Birgitta", ""]]}, {"id": "2002.06585", "submitter": "Vinicius Woloszyn", "authors": "Vinicius Woloszyn, Felipe Schaeffer, Beliza Boniatti, Eduardo Cortes,\n  Salar Mohtaj, Sebastian M\\\"oller", "title": "Untrue.News: A New Search Engine For Fake Stories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we demonstrate Untrue News, a new search engine for fake\nstories. Untrue News is easy to use and offers useful features such as: a) a\nmulti-language option combining fake stories from different countries and\nlanguages around the same subject or person; b) an user privacy protector,\navoiding the filter bubble by employing a bias-free ranking scheme; and c) a\ncollaborative platform that fosters the development of new tools for fighting\ndisinformation. Untrue News relies on Elasticsearch, a new scalable analytic\nsearch engine based on the Lucene library that provides near real-time results.\nWe demonstrate two key scenarios: the first related to a politician - looking\nhow the categories are shown for different types of fake stories - and a second\nrelated to a refugee - showing the multilingual tool. A prototype of Untrue\nNews is accessible via http://untrue.news\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 14:32:22 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Woloszyn", "Vinicius", ""], ["Schaeffer", "Felipe", ""], ["Boniatti", "Beliza", ""], ["Cortes", "Eduardo", ""], ["Mohtaj", "Salar", ""], ["M\u00f6ller", "Sebastian", ""]]}, {"id": "2002.06592", "submitter": "Juba Ziani", "authors": "Eshwar Ram Arunachaleswaran, Sampath Kannan, Aaron Roth, Juba Ziani", "title": "Pipeline Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \\emph{pipeline intervention} problem, defined by a layered\ndirected acyclic graph and a set of stochastic matrices governing transitions\nbetween successive layers. The graph is a stylized model for how people from\ndifferent populations are presented opportunities, eventually leading to some\nreward. In our model, individuals are born into an initial position (i.e. some\nnode in the first layer of the graph) according to a fixed probability\ndistribution, and then stochastically progress through the graph according to\nthe transition matrices, until they reach a node in the final layer of the\ngraph; each node in the final layer has a \\emph{reward} associated with it. The\npipeline intervention problem asks how to best make costly changes to the\ntransition matrices governing people's stochastic transitions through the\ngraph, subject to a budget constraint. We consider two objectives: social\nwelfare maximization, and a fairness-motivated maximin objective that seeks to\nmaximize the value to the population (starting node) with the \\emph{least}\nexpected value. We consider two variants of the maximin objective that turn out\nto be distinct, depending on whether we demand a deterministic solution or\nallow randomization. For each objective, we give an efficient approximation\nalgorithm (an additive FPTAS) for constant width networks. We also tightly\ncharacterize the \"price of fairness\" in our setting: the ratio between the\nhighest achievable social welfare and the highest social welfare consistent\nwith a maximin optimal solution. Finally we show that for polynomial width\nnetworks, even approximating the maximin objective to any constant factor is NP\nhard, even for networks with constant depth. This shows that the restriction on\nthe width in our positive results is essential.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 15:28:29 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 19:49:29 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Arunachaleswaran", "Eshwar Ram", ""], ["Kannan", "Sampath", ""], ["Roth", "Aaron", ""], ["Ziani", "Juba", ""]]}, {"id": "2002.06850", "submitter": "Donn Morrison", "authors": "J{\\o}rgen Svennevik Notland, Jakob Svennevik Notland, Donn Morrison", "title": "The Minimum Hybrid Contract (MHC): Combining legal and blockchain smart\n  contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corruption is a major global financial problem with billions of dollars\nrendered lost or unaccountable annually. Corruption through contract fraud is\noften conducted by withholding and/or altering financial information. When such\nscandals are investigated by authorities, financial and legal documents are\nusually altered to conceal the paper trail.\n  Smart contracts have emerged in recent years and appear promising for\napplications such as legal contracts where transparency is critical and of\npublic interest. Transparency and auditability are inherent because smart\ncontracts execute operations on the blockchain, a distributed public ledger.\n  In this paper, we propose the Minimum Hybrid Contract (MHC), with the aim of\nintroducing 1) auditability, 2) transparency, and 3) immutability to the\ncontract's financial transactions. The MHC comprises an online smart contract\nand an offline traditional legal contract. where the two are immutably linked.\n  Secure peer-to-peer financial transactions, transparency, and cost accounting\nare automated by the smart contract, and legal issues or disputes are carried\nout by civil courts. The reliance on established legal processes facilitates an\nappropriate adoption of smart contracts in traditional contracts.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:19:20 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Notland", "J\u00f8rgen Svennevik", ""], ["Notland", "Jakob Svennevik", ""], ["Morrison", "Donn", ""]]}, {"id": "2002.06852", "submitter": "Zhaohua Chen", "authors": "Hongyin Chen, Zhaohua Chen, Yukun Cheng, Xiaotie Deng, Wenhan Huang,\n  Jichen Li, Hongyi Ling, Mengqian Zhang", "title": "An Efficient Permissioned Blockchain with Provable Reputation Mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of permissioned blockchains places an access control requirement\nfor members to read, access, and write information over the blockchains. In\nthis paper, we study a hierarchical scenario to include three types of\nparticipants: providers, collectors, and governors. To be specific, providers\nforward transactions, collected from terminals, to collectors; collectors\nupload received transactions to governors after verifying and labeling them;\nand governors validate a part of received labeled transactions, pack valid ones\ninto a block, and append a new block on the ledger. Collectors in the\nhierarchical model play a crucial role in the design: they have connections\nwith both providers and governors, and are responsible for collecting,\nverifying, and uploading transactions. However, collectors are rational and\nsome of them may behave maliciously (not necessarily for their own benefits).\nIn this paper, we introduce a reputation protocol as a measure of the\nreliability of collectors in the permissioned blockchain environment. Its\nobjective is to encourage collectors to behave truthfully and, in addition, to\nreduce the verification cost. The verification cost on provider $p$ is defined\nas the total number of invalid transactions provided by $p$ and checked by\ngovernors. Through theoretical analysis, our protocol with the reputation\nmechanism has a significant improvement in efficiency. Specifically, the\nverification loss that governors suffer is proved to be asymptotically\n$O(\\sqrt{T_{total}})$ ($T_{total}$, representing the number of transactions\nverified by governors and provided by $p$), as long as there exists at least\none collector who behaves well. At last, two typical cases where our model can\nbe well applied are also demonstrated.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 09:25:59 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 08:42:17 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 12:28:02 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Chen", "Hongyin", ""], ["Chen", "Zhaohua", ""], ["Cheng", "Yukun", ""], ["Deng", "Xiaotie", ""], ["Huang", "Wenhan", ""], ["Li", "Jichen", ""], ["Ling", "Hongyi", ""], ["Zhang", "Mengqian", ""]]}, {"id": "2002.06885", "submitter": "Volodymyr Miz", "authors": "Volodymyr Miz, Jo\\\"elle Hanna, Nicolas Aspert, Benjamin Ricaud, and\n  Pierre Vandergheynst", "title": "What is Trending on Wikipedia? Capturing Trends and Language Biases\n  Across Wikipedia Editions", "comments": null, "journal-ref": null, "doi": "10.1145/3366424.3383567", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose an automatic evaluation and comparison of the\nbrowsing behavior of Wikipedia readers that can be applied to any language\neditions of Wikipedia. As an example, we focus on English, French, and Russian\nlanguages during the last four months of 2018. The proposed method has three\nsteps. Firstly, it extracts the most trending articles over a chosen period of\ntime. Secondly, it performs a semi-supervised topic extraction and thirdly, it\ncompares topics across languages. The automated processing works with the data\nthat combines Wikipedia's graph of hyperlinks, pageview statistics and\nsummaries of the pages.\n  The results show that people share a common interest and curiosity for\nentertainment, e.g. movies, music, sports independently of their language.\nDifferences appear in topics related to local events or about cultural\nparticularities. Interactive visualizations showing clusters of trending pages\nin each language edition are available online\nhttps://wiki-insights.epfl.ch/wikitrends\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 11:04:36 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Miz", "Volodymyr", ""], ["Hanna", "Jo\u00eblle", ""], ["Aspert", "Nicolas", ""], ["Ricaud", "Benjamin", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "2002.06938", "submitter": "Tom Mahler", "authors": "Tom Mahler, Yuval Elovici, Yuval Shahar", "title": "A New Methodology for Information Security Risk Assessment for Medical\n  Devices and Its Evaluation", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As technology advances towards more connected and digital environments,\nmedical devices are becoming increasingly connected to hospital networks and to\nthe Internet, which exposes them, and thus the patients using them, to new\ncybersecurity threats. Currently, there is a lack of a methodology dedicated to\ninformation security risk assessment for medical devices.\n  In this study, we present the Threat identification, ontology-based\nLikelihood, severity Decomposition, and Risk integration (TLDR) methodology for\ninformation security risk assessment for medical devices. The TLDR methodology\nuses the following steps: (1) identifying the potentially vulnerable components\nof medical devices, in this case, four different medical imaging devices\n(MIDs); (2) identifying the potential attacks, in this case, 23 potential\nattacks on MIDs; (3) mapping the discovered attacks into a known attack\nontology - in this case, the Common Attack Pattern Enumeration and\nClassifications (CAPECs); (4) estimating the likelihood of the mapped CAPECs in\nthe medical domain with the assistance of a panel of senior healthcare\nInformation Security Experts (ISEs); (5) computing the CAPEC-based likelihood\nestimates of each attack; (6) decomposing each attack into several severity\naspects and assigning them weights; (7) assessing the magnitude of the impact\nof each of the severity aspects for each attack with the assistance of a panel\nof senior Medical Experts (MEs); (8) computing the composite severity\nassessments for each attack; and finally, (9) integrating the likelihood and\nseverity of each attack into its risk, and thus prioritizing it. The details of\nsteps six to eight are beyond the scope of the current study; in the current\nstudy, we had replaced them by a single step that included asking the panel of\nMEs [in this case, radiologists], to assess the overall severity for each\nattack and use it as its severity...\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:10:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Mahler", "Tom", ""], ["Elovici", "Yuval", ""], ["Shahar", "Yuval", ""]]}, {"id": "2002.07033", "submitter": "Byungsoo Kim", "authors": "Youngduck Choi, Youngnam Lee, Junghyun Cho, Jineon Baek, Byungsoo Kim,\n  Yeongmin Cha, Dongmin Shin, Chan Bae, Jaewe Heo", "title": "Towards an Appropriate Query, Key, and Value Computation for Knowledge\n  Tracing", "comments": "L@S 2020", "journal-ref": null, "doi": "10.1145/3448139.3448188", "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing, the act of modeling a student's knowledge through learning\nactivities, is an extensively studied problem in the field of computer-aided\neducation. Although models with attention mechanism have outperformed\ntraditional approaches such as Bayesian knowledge tracing and collaborative\nfiltering, they share two limitations. Firstly, the models rely on shallow\nattention layers and fail to capture complex relations among exercises and\nresponses over time. Secondly, different combinations of queries, keys and\nvalues for the self-attention layer for knowledge tracing were not extensively\nexplored. Usual practice of using exercises and interactions (exercise-response\npairs) as queries and keys/values respectively lacks empirical support. In this\npaper, we propose a novel Transformer based model for knowledge tracing, SAINT:\nSeparated Self-AttentIve Neural Knowledge Tracing. SAINT has an encoder-decoder\nstructure where exercise and response embedding sequence separately enter the\nencoder and the decoder respectively, which allows to stack attention layers\nmultiple times. To the best of our knowledge, this is the first work to suggest\nan encoder-decoder model for knowledge tracing that applies deep self-attentive\nlayers to exercises and responses separately. The empirical evaluations on a\nlarge-scale knowledge tracing dataset show that SAINT achieves the\nstate-of-the-art performance in knowledge tracing with the improvement of AUC\nby 1.8% compared to the current state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:21:19 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 05:14:09 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 06:57:13 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 01:02:22 GMT"}, {"version": "v5", "created": "Mon, 1 Feb 2021 02:42:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Choi", "Youngduck", ""], ["Lee", "Youngnam", ""], ["Cho", "Junghyun", ""], ["Baek", "Jineon", ""], ["Kim", "Byungsoo", ""], ["Cha", "Yeongmin", ""], ["Shin", "Dongmin", ""], ["Bae", "Chan", ""], ["Heo", "Jaewe", ""]]}, {"id": "2002.07473", "submitter": "Olga Bondarenko", "authors": "Olga Bondarenko, Olena Pakhomova, Wlodzimierz Lewoniewski", "title": "The didactic potential of virtual information educational environment as\n  a tool of geography students training", "comments": "11 pages, 1 figure, 1 table", "journal-ref": "CEUR Workshop Proceedings 2547 (2019) 13-23", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article clarifies the concept of \"virtual information educational\nenvironment\" (VIEE) and examines the researchers' views on its meaning exposed\nin the scientific literature. The article determines the didactic potential of\nthe virtual information educational environment for the geography students\ntraining based on the analysis of the authors' experience of blended learning\nby means of the Google Classroom. It also specifies the features (immersion,\ninteractivity, and dynamism, sense of presence, continuity, and causality). The\nauthors highlighted the advantages of virtual information educational\nenvironment implementation, such as: increase of the efficiency of the\neducational process by intensifying the process of cognition and interpersonal\ninteractive communication; continuous access to multimedia content both in\nGoogle Classroom and beyond; saving student time due to the absence of\nnecessity to work out the training material \"manually\"; availability of virtual\npages of the virtual class; individualization of the educational process;\nformation of informational culture of the geography students ; and more\nproductive learning of the educational material at the expense of IT\neducational facilities. Among the disadvantages the article mentions low level\nof computerization, insignificant quantity and low quality of software\nproducts, underestimation of the role of VIEE in the professional training of\ngeography students, and the lack of economic stimuli, etc.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 10:25:05 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Bondarenko", "Olga", ""], ["Pakhomova", "Olena", ""], ["Lewoniewski", "Wlodzimierz", ""]]}, {"id": "2002.07734", "submitter": "Esteban Garc\\'ia-Cuesta PhD.", "authors": "Esteban Garc\\'ia-Cuesta", "title": "Artificial Intelligent Ethics in the Digital Era: an Engineering Ethical\n  Framework Proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays technology is being adopted on every aspect of our lives and it is\none of most important transformation driver in industry. Moreover, many of the\nsystems and digital services that we use daily rely on artificial intelligent\ntechnology capable of modeling social or individual behaviors that in turns\nalso modify personal decisions and actions. In this paper, we briefly discuss,\nfrom a technological perspective, a number of critical issues including the\npurpose of promoting trust and ensure social benefit by the proper use of\nArtificial Intelligent Systems. To achieve this goal we propose a generic\nethical technological framework as a first attempt to define a common context\ntowards developing real engineering ethical by design. We hope that this\ninitial proposal to be useful for early adopters and especially for\nstandardization teams.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 17:09:36 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Garc\u00eda-Cuesta", "Esteban", ""]]}, {"id": "2002.07768", "submitter": "Manuel Gra\\~na", "authors": "J. Estevez, JJ. Dominguez, M. Gra\\~na", "title": "Relationship between the visibility of political leaders during campaign\n  and the outcome in general elections. A case study for Spain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this article, the authors find the evidence that media coverage consisting\nof 13 online newspapers enhanced the electoral results of right wing party in\nSpain (Vox) during general elections in November 2019. We consider the\npolitical parties and leaders mentions in these media during the electoral\ncampaign from 1st to 10th November 2019, and only visibility or prominence\ndimension is necessary for the evidence.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 18:00:32 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Estevez", "J.", ""], ["Dominguez", "JJ.", ""], ["Gra\u00f1a", "M.", ""]]}, {"id": "2002.07880", "submitter": "Valerio Ficcadenti", "authors": "Matteo Cinelli, Valerio Ficcadenti, Jessica Riccioni", "title": "The interconnectedness of the economic content in the speeches of the US\n  Presidents", "comments": null, "journal-ref": "Ann Oper Res (2019)", "doi": "10.1007/s10479-019-03372-2", "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The speeches stated by influential politicians can have a decisive impact on\nthe future of a country. In particular, the economic content of such speeches\naffects the economy of countries and their financial markets. For this reason,\nwe examine a novel dataset containing the economic content of 951 speeches\nstated by 45 US Presidents from George Washington (April 1789) to Donald Trump\n(February 2017). In doing so, we use an economic glossary carried out by means\nof text mining techniques. The goal of our study is to examine the structure of\nsignificant interconnections within a network obtained from the economic\ncontent of presidential speeches. In such a network, nodes are represented by\ntalks and links by values of cosine similarity, the latter computed using the\noccurrences of the economic terms in the speeches. The resulting network\ndisplays a peculiar structure made up of a core (i.e. a set of highly central\nand densely connected nodes) and a periphery (i.e. a set of non-central and\nsparsely connected nodes). The presence of different economic dictionaries\nemployed by the Presidents characterize the core-periphery structure. The\nPresidents' talks belonging to the network's core share the usage of generic\n(non-technical) economic locutions like \"interest\" or \"trade\". While the use of\nmore technical and less frequent terms characterizes the periphery (e.g.\n\"yield\" ). Furthermore, the speeches close in time share a common economic\ndictionary. These results together with the economics glossary usages during\nthe US periods of boom and crisis provide unique insights on the economic\ncontent relationships among Presidents' speeches.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2020 21:10:55 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Cinelli", "Matteo", ""], ["Ficcadenti", "Valerio", ""], ["Riccioni", "Jessica", ""]]}, {"id": "2002.08035", "submitter": "Riccardo Fogliato", "authors": "Maria De-Arteaga, Riccardo Fogliato, Alexandra Chouldechova", "title": "A Case for Humans-in-the-Loop: Decisions in the Presence of Erroneous\n  Algorithmic Scores", "comments": "Accepted at ACM Conference on Human Factors in Computing Systems (ACM\n  CHI), 2020", "journal-ref": null, "doi": "10.1145/3313831.3376638", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased use of algorithmic predictions in sensitive domains has been\naccompanied by both enthusiasm and concern. To understand the opportunities and\nrisks of these technologies, it is key to study how experts alter their\ndecisions when using such tools. In this paper, we study the adoption of an\nalgorithmic tool used to assist child maltreatment hotline screening decisions.\nWe focus on the question: Are humans capable of identifying cases in which the\nmachine is wrong, and of overriding those recommendations? We first show that\nhumans do alter their behavior when the tool is deployed. Then, we show that\nhumans are less likely to adhere to the machine's recommendation when the score\ndisplayed is an incorrect estimate of risk, even when overriding the\nrecommendation requires supervisory approval. These results highlight the risks\nof full automation and the importance of designing decision pipelines that\nprovide humans with autonomy.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 07:27:32 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 06:13:16 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["De-Arteaga", "Maria", ""], ["Fogliato", "Riccardo", ""], ["Chouldechova", "Alexandra", ""]]}, {"id": "2002.08466", "submitter": "Jorge Barrera", "authors": "Jorge Barrera", "title": "Criptocurrencies, Fiat Money, Blockchains and Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two taxonomies of money that include cryptocurrencies are analyzed. A\ndefinition of the term cryptocurrency is given and a taxonomy of them is\npresented, based on how its price is fixed. The characteristics of the use of\ncurrent fiat money and the operation of two-level banking systems are\ndiscussed. Cryptocurrencies are compared with fiat money and the aspects in\nwhich the latter cannot be overcome are indicated. The characteristics of\nblockchains and databases are described. The possible cases of use of both\ntechnologies are compared, and it is noted that blockchains, in addition to\ncryptocurrencies and certain records, have not yet shown their usefulness,\nwhile databases constitute the foundation of most of the automated systems in\noperation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2020 18:04:10 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Barrera", "Jorge", ""]]}, {"id": "2002.08512", "submitter": "Rachel Thomas", "authors": "Rachel Thomas and David Uminsky", "title": "The Problem with Metrics is a Fundamental Problem for AI", "comments": "Accepted to EDSC (Ethics of Data Science Conference) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing a given metric is a central aspect of most current AI approaches,\nyet overemphasizing metrics leads to manipulation, gaming, a myopic focus on\nshort-term goals, and other unexpected negative consequences. This poses a\nfundamental contradiction for AI development. Through a series of real-world\ncase studies, we look at various aspects of where metrics go wrong in practice\nand aspects of how our online environment and current business practices are\nexacerbating these failures. Finally, we propose a framework towards mitigating\nthe harms caused by overemphasis of metrics within AI by: (1) using a slate of\nmetrics to get a fuller and more nuanced picture, (2) combining metrics with\nqualitative accounts, and (3) involving a range of stakeholders, including\nthose who will be most impacted.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 00:56:11 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Thomas", "Rachel", ""], ["Uminsky", "David", ""]]}, {"id": "2002.08608", "submitter": "Haewoon Kwak", "authors": "Haewoon Kwak and Jisun An and Elise Jing and Yong-Yeol Ahn", "title": "FrameAxis: Characterizing Microframe Bias and Intensity with Word\n  Embedding", "comments": "24 pages; published in PeerJ CS", "journal-ref": "PeerJ Computer Science 7:e644, 2021", "doi": "10.7717/peerj-cs.644", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Framing is a process of emphasizing a certain aspect of an issue over the\nothers, nudging readers or listeners towards different positions on the issue\neven without making a biased argument. {Here, we propose FrameAxis, a method\nfor characterizing documents by identifying the most relevant semantic axes\n(\"microframes\") that are overrepresented in the text using word embedding. Our\nunsupervised approach can be readily applied to large datasets because it does\nnot require manual annotations. It can also provide nuanced insights by\nconsidering a rich set of semantic axes. FrameAxis is designed to\nquantitatively tease out two important dimensions of how microframes are used\nin the text. \\textit{Microframe bias} captures how biased the text is on a\ncertain microframe, and \\textit{microframe intensity} shows how actively a\ncertain microframe is used. Together, they offer a detailed characterization of\nthe text. We demonstrate that microframes with the highest bias and intensity\nwell align with sentiment, topic, and partisan spectrum by applying FrameAxis\nto multiple datasets from restaurant reviews to political news.} The existing\ndomain knowledge can be incorporated into FrameAxis {by using custom\nmicroframes and by using FrameAxis as an iterative exploratory analysis\ninstrument.} Additionally, we propose methods for explaining the results of\nFrameAxis at the level of individual words and documents. Our method may\naccelerate scalable and sophisticated computational analyses of framing across\ndisciplines.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 08:01:28 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 02:21:21 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 06:47:08 GMT"}, {"version": "v4", "created": "Fri, 23 Jul 2021 01:45:20 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Kwak", "Haewoon", ""], ["An", "Jisun", ""], ["Jing", "Elise", ""], ["Ahn", "Yong-Yeol", ""]]}, {"id": "2002.08777", "submitter": "Jodie Lobana", "authors": "NIklas Kuhl, Jodie Lobana, and Christian Meske", "title": "Do you comply with AI? -- Personalized explanations of learning\n  algorithms and their impact on employees' compliance behavior", "comments": "Fortieth International Conference on Information Systems (ICIS) 2019,\n  Munich, Germany. All Authors contributed equally in shared first authorship", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning algorithms are technological key enablers for artificial\nintelligence (AI). Due to the inherent complexity, these learning algorithms\nrepresent black boxes and are difficult to comprehend, therefore influencing\ncompliance behavior. Hence, compliance with the recommendations of such\nartifacts, which can impact employees' task performance significantly, is still\nsubject to research - and personalization of AI explanations seems to be a\npromising concept in this regard. In our work, we hypothesize that, based on\nvarying backgrounds like training, domain knowledge and demographic\ncharacteristics, individuals have different understandings and hence mental\nmodels about the learning algorithm. Personalization of AI explanations,\nrelated to the individuals' mental models, may thus be an instrument to affect\ncompliance and therefore employee task performance. Our preliminary results\nalready indicate the importance of personalized explanations in industry\nsettings and emphasize the importance of this research endeavor.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:55:20 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Kuhl", "NIklas", ""], ["Lobana", "Jodie", ""], ["Meske", "Christian", ""]]}, {"id": "2002.09044", "submitter": "Philip Paquette", "authors": "Philip Paquette", "title": "A Road Map to Strong Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I wrote this paper because technology can really improve people's lives. With\nit, we can live longer in a healthy body, save time through increased\nefficiency and automation, and make better decisions. To get to the next level,\nwe need to start looking at intelligence from a much broader perspective, and\npromote international interdisciplinary collaborations. Section 1 of this paper\ndelves into sociology and social psychology to explain that the mechanisms\nunderlying intelligence are inherently social. Section 2 proposes a method to\nclassify intelligence, and describes the differences between weak and strong\nintelligence. Section 3 examines the Chinese Room argument from a different\nperspective. It demonstrates that a Turing-complete machine cannot have strong\nintelligence, and considers the modifications necessary for a computer to be\nintelligent and have understanding. Section 4 argues that the existential risk\ncaused by the technological explosion of a single agent should not be of\nserious concern. Section 5 looks at the AI control problem and argues that it\nis impossible to build a super-intelligent machine that will do what it\ncreators want. By using insights from biology, it also proposes a solution to\nthe control problem. Section 6 discusses some of the implications of strong\nintelligence. Section 7 lists the main challenges with deep learning, and\nasserts that radical changes will be required to reach strong intelligence.\nSection 8 examines a neuroscience framework that could help explain how a\ncortical column works. Section 9 lays out the broad strokes of a road map\ntowards strong intelligence. Finally, section 10 analyzes the impacts and the\nchallenges of greater intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:22:50 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Paquette", "Philip", ""]]}, {"id": "2002.09054", "submitter": "Lionel Robert", "authors": "Lionel P. Robert, Casey Pierce, Liz Morris, Sangmi Kim, Rasha Alahmad", "title": "Designing Fair AI for Managing Employees in Organizations: A Review,\n  Critique, and Design Agenda", "comments": "66 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations are rapidly deploying artificial intelligence (AI) systems to\nmanage their workers. However, AI has been found at times to be unfair to\nworkers. Unfairness toward workers has been associated with decreased worker\neffort and increased worker turnover. To avoid such problems, AI systems must\nbe designed to support fairness and redress instances of unfairness. Despite\nthe attention related to AI unfairness, there has not been a theoretical and\nsystematic approach to developing a design agenda. This paper addresses the\nissue in three ways. First, we introduce the organizational justice theory,\nthree different fairness types (distributive, procedural, interactional), and\nthe frameworks for redressing instances of unfairness (retributive justice,\nrestorative justice). Second, we review the design literature that specifically\nfocuses on issues of AI fairness in organizations. Third, we propose a design\nagenda for AI fairness in organizations that applies each of the fairness types\nto organizational scenarios. Then, the paper concludes with implications for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 22:52:43 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Robert", "Lionel P.", ""], ["Pierce", "Casey", ""], ["Morris", "Liz", ""], ["Kim", "Sangmi", ""], ["Alahmad", "Rasha", ""]]}, {"id": "2002.09449", "submitter": "Carlos Sarraute PhD", "authors": "Marcelo Mottalli, Alejo Sanchez, Gustavo Ajzenman, Carlos Sarraute", "title": "Snel: SQL Native Execution for LLVM", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Snel is a relational database engine featuring Just-In-Time (JIT) compilation\nof queries and columnar data representation. Snel is designed for fast on-line\nanalytics by leveraging the LLVM compiler infrastructure. It also has custom\nspecial methods like resolving histograms as extensions to the SQL language.\n\"Snel\" means \"SQL Native Execution for LLVM\".\n  Unlike traditional database engines, it does not provide a client-server\ninterface. Instead, it exposes its interface as an extension to SQLite, for a\nsimple interactive usage from command line and for embedding in applications.\nSince Snel tables are read-only, it does not provide features like transactions\nor updates. This allows queries to be very fast since they don't have the\noverhead of table locking or ensuring consistency.\n  At its core, Snel is simply a dynamic library that can be used by client\napplications. It has an SQLite extension for seamless integration with a\ntraditional SQL environment and simple interactive usage from command line.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 18:06:18 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 12:32:08 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Mottalli", "Marcelo", ""], ["Sanchez", "Alejo", ""], ["Ajzenman", "Gustavo", ""], ["Sarraute", "Carlos", ""]]}, {"id": "2002.09485", "submitter": "\\'Angel Panizo-LLedot", "authors": "David Camacho, \\`Angel Panizo-LLedot, Gema Bello-Orgaz, Antonio\n  Gonzalez-Pardo, Erik Cambria", "title": "The Four Dimensions of Social Network Analysis: An Overview of Research\n  Methods, Applications, and Software Tools", "comments": "This paper is currently under evaluation in Information Fusion\n  journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network based applications have experienced exponential growth in\nrecent years. One of the reasons for this rise is that this application domain\noffers a particularly fertile place to test and develop the most advanced\ncomputational techniques to extract valuable information from the Web. The main\ncontribution of this work is three-fold: (1) we provide an up-to-date\nliterature review of the state of the art on social network analysis (SNA);(2)\nwe propose a set of new metrics based on four essential features (or\ndimensions) in SNA; (3) finally, we provide a quantitative analysis of a set of\npopular SNA tools and frameworks. We have also performed a scientometric study\nto detect the most active research areas and application domains in this area.\nThis work proposes the definition of four different dimensions, namely Pattern\n& Knowledge discovery, Information Fusion & Integration, Scalability, and\nVisualization, which are used to define a set of new metrics (termed degrees)\nin order to evaluate the different software tools and frameworks of SNA (a set\nof 20 SNA-software tools are analyzed and ranked following previous metrics).\nThese dimensions, together with the defined degrees, allow evaluating and\nmeasure the maturity of social network technologies, looking for both a\nquantitative assessment of them, as to shed light to the challenges and future\ntrends in this active area.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 16:11:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Camacho", "David", ""], ["Panizo-LLedot", "\u00c0ngel", ""], ["Bello-Orgaz", "Gema", ""], ["Gonzalez-Pardo", "Antonio", ""], ["Cambria", "Erik", ""]]}, {"id": "2002.09546", "submitter": "Muhammad Ali Siddiqi", "authors": "Muhammad Ali Siddiqi, Christian Doerr, Christos Strydis", "title": "IMDfence: Architecting a Secure Protocol for Implantable Medical Devices", "comments": "17 pages, Accepted by IEEE Access", "journal-ref": "IEEE Access, 2020", "doi": "10.1109/ACCESS.2020.3015686", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past decade, focus on the security and privacy aspects of\nimplantable medical devices (IMDs) has intensified, driven by the multitude of\ncybersecurity vulnerabilities found in various existing devices. However, due\nto their strict computational, energy and physical constraints, conventional\nsecurity protocols are not directly applicable to IMDs. Custom-tailored schemes\nhave been proposed instead which, however, fail to cover the full spectrum of\nsecurity features that modern IMDs and their ecosystems so critically require.\nIn this paper we propose IMDfence, a security protocol for IMD ecosystems that\nprovides a comprehensive yet practical security portfolio, which includes\navailability, non-repudiation, access control, entity authentication, remote\nmonitoring and system scalability. The protocol also allows emergency access\nthat results in the graceful degradation of offered services without\ncompromising security and patient safety. The performance of the security\nprotocol as well as its feasibility and impact on modern IMDs are extensively\nanalyzed and evaluated. We find that IMDfence achieves the above security\nrequirements at a mere less than 7% increase in total IMD energy consumption,\nand less than 14 ms and 9 kB increase in system delay and memory footprint,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 20:46:05 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 11:27:51 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 22:11:03 GMT"}, {"version": "v4", "created": "Thu, 13 Aug 2020 09:34:22 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Siddiqi", "Muhammad Ali", ""], ["Doerr", "Christian", ""], ["Strydis", "Christos", ""]]}, {"id": "2002.09595", "submitter": "Andr\\'es P\\'aez", "authors": "Andr\\'es P\\'aez", "title": "The Pragmatic Turn in Explainable Artificial Intelligence (XAI)", "comments": null, "journal-ref": "Minds and Machines, 29(3), 441-459, 2019", "doi": "10.1007/s11023-019-09502-w", "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I argue that the search for explainable models and\ninterpretable decisions in AI must be reformulated in terms of the broader\nproject of offering a pragmatic and naturalistic account of understanding in\nAI. Intuitively, the purpose of providing an explanation of a model or a\ndecision is to make it understandable to its stakeholders. But without a\nprevious grasp of what it means to say that an agent understands a model or a\ndecision, the explanatory strategies will lack a well-defined goal. Aside from\nproviding a clearer objective for XAI, focusing on understanding also allows us\nto relax the factivity condition on explanation, which is impossible to fulfill\nin many machine learning models, and to focus instead on the pragmatic\nconditions that determine the best fit between a model and the methods and\ndevices deployed to understand it. After an examination of the different types\nof understanding discussed in the philosophical and psychological literature, I\nconclude that interpretative or approximation models not only provide the best\nway to achieve the objectual understanding of a machine learning model, but are\nalso a necessary condition to achieve post-hoc interpretability. This\nconclusion is partly based on the shortcomings of the purely functionalist\napproach to post-hoc interpretability that seems to be predominant in most\nrecent literature.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 01:40:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["P\u00e1ez", "Andr\u00e9s", ""]]}, {"id": "2002.09689", "submitter": "Carlos Sarraute PhD", "authors": "Ariel Futoransky, Carlos Sarraute, Daniel Fernandez, Matias Travizano,\n  Ariel Waissbein", "title": "Fair and Decentralized Exchange of Digital Goods", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We construct a privacy-preserving, distributed and decentralized marketplace\nwhere parties can exchange data for tokens. In this market, buyers and sellers\nmake transactions in a blockchain and interact with a third party, called\nnotary, who has the ability to vouch for the authenticity and integrity of the\ndata.\n  We introduce a protocol for the data-token exchange where neither party gains\nmore information than what it is paying for, and the exchange is fair: either\nboth parties gets the other's item or neither does. No third party involvement\nis required after setup, and no dispute resolution is needed.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2020 11:32:16 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Futoransky", "Ariel", ""], ["Sarraute", "Carlos", ""], ["Fernandez", "Daniel", ""], ["Travizano", "Matias", ""], ["Waissbein", "Ariel", ""]]}, {"id": "2002.09931", "submitter": "Carlos Sarraute PhD", "authors": "Mar\\'ia \\'Oskarsd\\'ottir, Cristi\\'an Bravo, Carlos Sarraute, Jan\n  Vanthienen, Bart Baesens", "title": "The Value of Big Data for Credit Scoring: Enhancing Financial Inclusion\n  using Mobile Phone Data and Social Network Analytics", "comments": null, "journal-ref": "Applied Soft Computing, Volume 74, January 2019, Pages 26-39", "doi": "10.1016/j.asoc.2018.10.004", "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Credit scoring is without a doubt one of the oldest applications of\nanalytics. In recent years, a multitude of sophisticated classification\ntechniques have been developed to improve the statistical performance of credit\nscoring models. Instead of focusing on the techniques themselves, this paper\nleverages alternative data sources to enhance both statistical and economic\nmodel performance. The study demonstrates how including call networks, in the\ncontext of positive credit information, as a new Big Data source has added\nvalue in terms of profit by applying a profit measure and profit-based feature\nselection. A unique combination of datasets, including call-detail records,\ncredit and debit account information of customers is used to create scorecards\nfor credit card applicants. Call-detail records are used to build call networks\nand advanced social network analytics techniques are applied to propagate\ninfluence from prior defaulters throughout the network to produce influence\nscores. The results show that combining call-detail records with traditional\ndata in credit scoring models significantly increases their performance when\nmeasured in AUC. In terms of profit, the best model is the one built with only\ncalling behavior features. In addition, the calling behavior features are the\nmost predictive in other models, both in terms of statistical and economic\nperformance. The results have an impact in terms of ethical use of call-detail\nrecords, regulatory implications, financial inclusion, as well as data sharing\nand privacy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 16:13:56 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["\u00d3skarsd\u00f3ttir", "Mar\u00eda", ""], ["Bravo", "Cristi\u00e1n", ""], ["Sarraute", "Carlos", ""], ["Vanthienen", "Jan", ""], ["Baesens", "Bart", ""]]}, {"id": "2002.09971", "submitter": "Sabina Tomkins", "authors": "Sabina Tomkins, Peng Liao, Predrag Klasnja, Serena Yeung, Susan Murphy", "title": "Rapidly Personalizing Mobile Health Treatment Policies with Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile health (mHealth), reinforcement learning algorithms that adapt to\none's context without learning personalized policies might fail to distinguish\nbetween the needs of individuals. Yet the high amount of noise due to the in\nsitu delivery of mHealth interventions can cripple the ability of an algorithm\nto learn when given access to only a single user's data, making personalization\nchallenging. We present IntelligentPooling, which learns personalized policies\nvia an adaptive, principled use of other users' data. We show that\nIntelligentPooling achieves an average of 26% lower regret than\nstate-of-the-art across all generative models. Additionally, we inspect the\nbehavior of this approach in a live clinical trial, demonstrating its ability\nto learn from even a small group of users.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 18:59:46 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Tomkins", "Sabina", ""], ["Liao", "Peng", ""], ["Klasnja", "Predrag", ""], ["Yeung", "Serena", ""], ["Murphy", "Susan", ""]]}, {"id": "2002.10010", "submitter": "Joshua Gardner", "authors": "Josh Gardner, Jawad Mroueh, Natalia Jenuwine, Noah Weaverdyck, Samuel\n  Krassenstein, Arya Farahi, Danai Koutra", "title": "Driving with Data in the Motor City: Mining and Modeling Vehicle Fleet\n  Maintenance Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The City of Detroit maintains an active fleet of over 2500 vehicles, spending\nan annual average of over \\$5 million on purchases and over \\$7.7 million on\nmaintenance. Modeling patterns and trends in this data is of particular\nimportance to a variety of stakeholders, particularly as Detroit emerges from\nChapter 9 bankruptcy, but the structure in such data is complex, and the city\nlacks dedicated resources for in-depth analysis. The City of Detroit's\nOperations and Infrastructure Group and the University of Michigan initiated a\ncollaboration which seeks to address this unmet need by analyzing data from the\nCity of Detroit's vehicle fleet. This work presents a case study and provides\nthe first data-driven benchmark, demonstrating a suite of methods to aid in\ndata understanding and prediction for large vehicle maintenance datasets. We\npresent analyses to address three key questions raised by the stakeholders,\nrelated to discovering multivariate maintenance patterns over time; predicting\nmaintenance; and predicting vehicle- and fleet-level costs. We present a novel\nalgorithm, PRISM, for automating multivariate sequential data analyses using\ntensor decomposition. This work is a first of its kind that presents both\nmethodologies and insights to guide future civic data research.\n", "versions": [{"version": "v1", "created": "Sun, 23 Feb 2020 23:06:54 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2020 21:34:21 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Gardner", "Josh", ""], ["Mroueh", "Jawad", ""], ["Jenuwine", "Natalia", ""], ["Weaverdyck", "Noah", ""], ["Krassenstein", "Samuel", ""], ["Farahi", "Arya", ""], ["Koutra", "Danai", ""]]}, {"id": "2002.10096", "submitter": "Marian D\\\"ork", "authors": "Philipp Geuder, Marie Claire Leidinger, Martin von Lupin, Marian\n  D\\\"ork, Tobias Schr\\\"oder", "title": "Emosaic: Visualizing Affective Content of Text at Varying Granularity", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Emosaic, a tool for visualizing the emotional tone of\ntext documents, considering multiple dimensions of emotion and varying levels\nof semantic granularity. Emosaic is grounded in psychological research on the\nrelationship between language, affect, and color perception. We capitalize on\nan established three-dimensional model of human emotion: valence (good, nice\nvs. bad, awful), arousal (calm, passive vs. exciting, active) and dominance\n(weak, controlled vs. strong, in control). Previously, multi-dimensional models\nof emotion have been used rarely in visualizations of textual data, due to the\nperceptual challenges involved. Furthermore, until recently most text\nvisualizations remained at a high level, precluding closer engagement with the\ndeep semantic content of the text. Informed by empirical studies, we introduce\na color mapping that translates any point in three-dimensional affective space\ninto a unique color. Emosaic uses affective dictionaries of words annotated\nwith the three emotional parameters of the valence-arousal-dominance model to\nextract emotional meanings from texts and then assigns to them corresponding\ncolor parameters of the hue-saturation-brightness color space. This approach of\nmapping emotion to color is aimed at helping readers to more easily grasp the\nemotional tone of the text. Several features of Emosaic allow readers to\ninteractively explore the affective content of the text in more detail; e.g.,\nin aggregated form as histograms, in sequential form following the order of\ntext, and in detail embedded into the text display itself. Interaction\ntechniques have been included to allow for filtering and navigating of text and\nvisualizations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 07:25:01 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Geuder", "Philipp", ""], ["Leidinger", "Marie Claire", ""], ["von Lupin", "Martin", ""], ["D\u00f6rk", "Marian", ""], ["Schr\u00f6der", "Tobias", ""]]}, {"id": "2002.10131", "submitter": "Chrysoula Terizi", "authors": "Chrysoula Terizi, Despoina Chatzakou, Evaggelia Pitoura, Panayiotis\n  Tsaparas and Nicolas Kourtellis", "title": "Modeling Aggression Propagation on Social Media", "comments": "13 pages, 5 figures, 3 tables", "journal-ref": "Online Social Networks and Media 24 (2021): 100137", "doi": "10.1016/j.osnem.2021.100137", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberaggression has been studied in various contexts and online social\nplatforms, and modeled on different data using state-of-the-art machine and\ndeep learning algorithms to enable automatic detection and blocking of this\nbehavior. Users can be influenced to act aggressively or even bully others\nbecause of elevated toxicity and aggression in their own (online) social\ncircle. In effect, this behavior can propagate from one user and neighborhood\nto another, and therefore, spread in the network. Interestingly, to our\nknowledge, no work has modeled the network dynamics of aggressive behavior. In\nthis paper, we take a first step towards this direction by studying propagation\nof aggression on social media using opinion dynamics. We propose ways to model\nhow aggression may propagate from one user to another, depending on how each\nuser is connected to other aggressive or regular users. Through extensive\nsimulations on Twitter data, we study how aggressive behavior could propagate\nin the network. We validate our models with crawled and annotated ground truth\ndata, reaching up to 80% AUC, and discuss the results and implications of our\nwork.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 09:50:49 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 21:13:00 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 09:13:40 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Terizi", "Chrysoula", ""], ["Chatzakou", "Despoina", ""], ["Pitoura", "Evaggelia", ""], ["Tsaparas", "Panayiotis", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2002.10394", "submitter": "Gr\\'egoire Jauvion", "authors": "Gr\\'egoire Jauvion, Thibaut Cassard, Boris Quennehen, David Lissmyr", "title": "DeepPlume: Very High Resolution Real-Time Air Quality Mapping", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an engine able to predict jointly the real-time\nconcentration of the main pollutants harming people's health: nitrogen dioxyde\n(NO2), ozone (O3) and particulate matter (PM2.5 and PM10, which are\nrespectively the particles whose size are below 2.5 um and 10 um).\n  The engine covers a large part of the world and is fed with real-time\nofficial stations measures, atmospheric models' forecasts, land cover data,\nroad networks and traffic estimates to produce predictions with a very high\nresolution in the range of a few dozens of meters. This resolution makes the\nengine adapted to very innovative applications like street-level air quality\nmapping or air quality adjusted routing.\n  Plume Labs has deployed a similar prediction engine to build several products\naiming at providing air quality data to individuals and businesses. For the\nsake of clarity and reproducibility, the engine presented here has been built\nspecifically for this paper and differs quite significantly from the one used\nin Plume Labs' products. A major difference is in the data sources feeding the\nengine: in particular, this prediction engine does not include mobile sensors\nmeasurements.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 14:05:45 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Jauvion", "Gr\u00e9goire", ""], ["Cassard", "Thibaut", ""], ["Quennehen", "Boris", ""], ["Lissmyr", "David", ""]]}, {"id": "2002.10616", "submitter": "Zhiming Fang", "authors": "Zhiming Fang, Zhongyi Huang, Xiaolian Li, Jun Zhang, Wei Lv, Lei\n  Zhuang, Xingpeng Xu, Nan Huang", "title": "How many infections of COVID-19 there will be in the \"Diamond\n  Princess\"-Predicted by a virus transmission model based on the simulation of\n  crowd flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Objectives: Simulate the transmission process of COVID-19 in a cruise ship,\nand then to judge how many infections there will be in the 3711 people in the\n\"Diamond Princess\" and analyze measures that could have prevented mass\ntransmission.\n  Methods: Based on the crowd flow model, the virus transmission rule between\npedestrians is established, to simulate the spread of the virus caused by the\nclose contact during pedestrians' daily activities on the cruise ship.\n  Measurements and main results: Three types of simulation scenarios are\ndesigned, the Basic scenario focus on the process of virus transmission caused\nby a virus carrier and the effect of the personal protective measure against\nthe virus. The condition that the original virus carriers had disembarked\nhalfway and more and more people strengthen self-protection are considered in\nthe Self-protection scenario, which would comparatively accord with the actual\nsituation of \"Diamond princess\" cruise. Control scenario are set to simulate\nthe effect of taking recommended or mandatory measures on virus transmission\n  Conclusions: There are 850~1009 persons (with large probability) who have\nbeen infected with COVID-19 during the voyage of \"Diamond Princess\". The crowd\ninfection percentage would be controlled effectively if the recommended or\nmandatory measures can be taken immediately during the alert phase of COVID-19\noutbreaks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 01:36:27 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Fang", "Zhiming", ""], ["Huang", "Zhongyi", ""], ["Li", "Xiaolian", ""], ["Zhang", "Jun", ""], ["Lv", "Wei", ""], ["Zhuang", "Lei", ""], ["Xu", "Xingpeng", ""], ["Huang", "Nan", ""]]}, {"id": "2002.10697", "submitter": "Faez Ahmed", "authors": "Faez Ahmed, John Dickerson, Mark Fuge", "title": "Forming Diverse Teams from Sequentially Arriving People", "comments": "Journal of Mechanical Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative work often benefits from having teams or organizations with\nheterogeneous members. In this paper, we present a method to form such diverse\nteams from people arriving sequentially over time. We define a monotone\nsubmodular objective function that combines the diversity and quality of a team\nand propose an algorithm to maximize the objective while satisfying multiple\nconstraints. This allows us to balance both how diverse the team is and how\nwell it can perform the task at hand. Using crowd experiments, we show that, in\npractice, the algorithm leads to large gains in team diversity. Using\nsimulations, we show how to quantify the additional cost of forming diverse\nteams and how to address the problem of simultaneously maximizing diversity for\nseveral attributes (e.g., country of origin, gender). Our method has\napplications in collaborative work ranging from team formation, the assignment\nof workers to teams in crowdsourcing, and reviewer allocation to journal papers\narriving sequentially. Our code is publicly accessible for further research.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 07:00:07 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Ahmed", "Faez", ""], ["Dickerson", "John", ""], ["Fuge", "Mark", ""]]}, {"id": "2002.11203", "submitter": "Kai Li", "authors": "Lili Yan and Kai Li", "title": "Interactive Summarizing -- Automatic Slide Localization Technology as\n  Generative Learning Tool", "comments": "Accepted by 19th IEEE International Conference on Advanced Learning\n  Technologies (ICALT 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making a summary is a common learning strategy in lecture learning. It is an\neffective way for learners to engage in both traditional and video lectures.\nVideo summarization is an effective technology applied to enhance learners'\nsummarizing experience in a video lecture. In this article, we propose to apply\ncutting-edge automatic slide localization technology to lecture video learning\nexperience. An interactive summarizing model is designed to explain how\nlearners are engaged in the video lecture learning process supported by\nconvolutional neural network and the possibility of related learning analytics.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 22:22:49 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Yan", "Lili", ""], ["Li", "Kai", ""]]}, {"id": "2002.11431", "submitter": "Robert Free", "authors": "Robert C. Free", "title": "Simpler handling of clinical concepts in R with clinconcept", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Routinely collected data in electronic healthcare records are often\nunderpinned by clinical concept dictionaries. Increasingly data sets from these\nsources are being made available and used for research purposes, but without\nadditional tooling it can be difficult to work effectively with these\ndictionaries due to their design, size and complex nature. In an effort to\nimprove this situation the clinconcept package was created to provide a\nstraightforward way for researchers to build, manage and interrogate databases\ncontaining commmonly used clinical concept dictionaries. This article describes\nthe rationale behind the package, how to install it and use it and how it can\nbe extended to support other data sources.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:20:55 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Free", "Robert C.", ""]]}, {"id": "2002.11618", "submitter": "Till Koebe", "authors": "Till Koebe", "title": "Better coverage, better outcomes? Mapping mobile network data to\n  official statistics using satellite imagery and radio propagation modelling", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0241981", "report-no": null, "categories": "cs.CY stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile sensing data has become a popular data source for geo-spatial\nanalysis, however, mapping it accurately to other sources of information such\nas statistical data remains a challenge. Popular mapping approaches such as\npoint allocation or voronoi tessellation provide only crude approximations of\nthe mobile network coverage as they do not consider holes, overlaps and\nwithin-cell heterogeneity. More elaborate mapping schemes often require\nadditional proprietary data operators are highly reluctant to share. In this\npaper, I use human settlement information extracted from publicly available\nsatellite imagery in combination with stochastic radio propagation modelling\ntechniques to account for that. I investigate in a simulation study and a\nreal-world application on unemployment estimates in Senegal whether better\ncoverage approximations lead to better outcome predictions. The good news is:\nit does not have to be complicated.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:19:19 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Koebe", "Till", ""]]}, {"id": "2002.11619", "submitter": "Subhankar Mishra", "authors": "Subhankar Mishra", "title": "Election in India: Polling in National Financial Switch", "comments": "8 pages, 4 figures, to be published CSI 2020 Conference Proceeding", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indian voters from Kashmir to Kanyakumari select their representatives to\nform their parliament by going to polls. India's election is one of the largest\ndemocratic exercise in the world history. About 850 million eligible voters\ndetermine which political party or alliance will form the government and in\nturn, will serve as prime minister. Given the electoral rules of placing a\npolling place within 2 kilometers of every habitation, it comes as no surprise\nthat is indeed a humongous task for the Election Commission of India (ECI). It\nsends around 11 million election workers through tough terrains to reach the\nlast mile. This exercise also comes as ever growing expenditure for the ECI.\nThis paper proposes the use of Automated Teller Machines (ATM) and Point Of\nSale (POS) machines to be used to cover as much as urban, rural and semi-urban\nplaces possible given the wide network of National Financial Switch (NFS) and\nincrease in connectivity through Digital India initiative. This would add to\nthe use of the existing infrastructure to accommodate a free, fair and\ntransparent election.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2020 15:39:50 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Mishra", "Subhankar", ""]]}, {"id": "2002.11621", "submitter": "Adriano Fazzone", "authors": "Giorgio Barnab\\`o and Adriano Fazzone and Stefano Leonardi and Chris\n  Schwiegelshohn", "title": "Algorithms for Fair Team Formation in Online Labour Marketplaces", "comments": "Accepted at \"FATES 2019 : 1st Workshop on Fairness, Accountability,\n  Transparency, Ethics, and Society on the Web\" (http://fates19.isti.cnr.it)", "journal-ref": "\"Companion Proceedings of The 2019 World Wide Web Conference\",\n  2019, pages 484-490", "doi": "10.1145/3308560.3317587", "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As freelancing work keeps on growing almost everywhere due to a sharp\ndecrease in communication costs and to the widespread of Internet-based labour\nmarketplaces (e.g., guru.com, feelancer.com, mturk.com, upwork.com), many\nresearchers and practitioners have started exploring the benefits of\noutsourcing and crowdsourcing. Since employers often use these platforms to\nfind a group of workers to complete a specific task, researchers have focused\ntheir efforts on the study of team formation and matching algorithms and on the\ndesign of effective incentive schemes. Nevertheless, just recently, several\nconcerns have been raised on possibly unfair biases introduced through the\nalgorithms used to carry out these selection and matching procedures. For this\nreason, researchers have started studying the fairness of algorithms related to\nthese online marketplaces, looking for intelligent ways to overcome the\nalgorithmic bias that frequently arises. Broadly speaking, the aim is to\nguarantee that, for example, the process of hiring workers through the use of\nmachine learning and algorithmic data analysis tools does not discriminate,\neven unintentionally, on grounds of nationality or gender. In this short paper,\nwe define the Fair Team Formation problem in the following way: given an online\nlabour marketplace where each worker possesses one or more skills, and where\nall workers are divided into two or more not overlapping classes (for examples,\nmen and women), we want to design an algorithm that is able to find a team with\nall the skills needed to complete a given task, and that has the same number of\npeople from all classes. We provide inapproximability results for the Fair Team\nFormation problem together with four algorithms for the problem itself. We also\ntested the effectiveness of our algorithmic solutions by performing experiments\nusing real data from an online labor marketplace.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 11:33:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Barnab\u00f2", "Giorgio", ""], ["Fazzone", "Adriano", ""], ["Leonardi", "Stefano", ""], ["Schwiegelshohn", "Chris", ""]]}, {"id": "2002.11623", "submitter": "Muhidin Mohamed", "authors": "Muhidin Mohamed, Philip Weber", "title": "Trends of digitalization and adoption of big data & analytics among UK\n  SMEs: Analysis and lessons drawn from a case study of 53 SMEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small and Medium Enterprises (SMEs) now generate digital data at an\nunprecedented rate from online transactions, social media marketing and\nassociated customer interactions, online product or service reviews and\nfeedback, clinical diagnosis, Internet of Things (IoT) sensors, and production\nprocesses. All these forms of data can be transformed into monetary value if\nput into a proper data value chain. This requires both skills and IT\ninvestments for the long-term benefit of businesses. However, such spending is\nbeyond the capacity of most SMEs due to their limited resources and restricted\naccess to finances. This paper presents lessons learned from a case study of 53\nUK SMEs, mostly from the West Midlands region of England, supported as part of\na 3-year ERDF project, Big Data Corridor, in the areas of big data management,\nanalytics and related IT issues. Based on our study's sample companies, several\nperspectives including the digital technology trends, challenges facing the UK\nSMEs, and the state of their adoption in data analytics and big data, are\npresented in the paper.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 09:51:24 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 10:10:25 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Mohamed", "Muhidin", ""], ["Weber", "Philip", ""]]}, {"id": "2002.11624", "submitter": "Byungsoo Kim", "authors": "Youngnam Lee, Dongmin Shin, HyunBin Loh, Jaemin Lee, Piljae Chae,\n  Junghyun Cho, Seoyon Park, Jinhwan Lee, Jineon Baek, Byungsoo Kim, Youngduck\n  Choi", "title": "Deep Attentive Study Session Dropout Prediction in Mobile Learning\n  Environment", "comments": "CSEDU 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student dropout prediction provides an opportunity to improve student\nengagement, which maximizes the overall effectiveness of learning experiences.\nHowever, researches on student dropout were mainly conducted on school dropout\nor course dropout, and study session dropout in a mobile learning environment\nhas not been considered thoroughly. In this paper, we investigate the study\nsession dropout prediction problem in a mobile learning environment. First, we\ndefine the concept of the study session, study session dropout and study\nsession dropout prediction task in a mobile learning environment. Based on the\ndefinitions, we propose a novel Transformer based model for predicting study\nsession dropout, DAS: Deep Attentive Study Session Dropout Prediction in Mobile\nLearning Environment. DAS has an encoder-decoder structure which is composed of\nstacked multi-head attention and point-wise feed-forward networks. The deep\nattentive computations in DAS are capable of capturing complex relations among\ndynamic student interactions. To the best of our knowledge, this is the first\nattempt to investigate study session dropout in a mobile learning environment.\nEmpirical evaluations on a large-scale dataset show that DAS achieves the best\nperformance with a significant improvement in area under the receiver operating\ncharacteristic curve compared to baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2020 06:05:42 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 04:35:20 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 06:54:26 GMT"}, {"version": "v4", "created": "Fri, 14 Aug 2020 01:27:49 GMT"}, {"version": "v5", "created": "Tue, 2 Feb 2021 04:59:06 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lee", "Youngnam", ""], ["Shin", "Dongmin", ""], ["Loh", "HyunBin", ""], ["Lee", "Jaemin", ""], ["Chae", "Piljae", ""], ["Cho", "Junghyun", ""], ["Park", "Seoyon", ""], ["Lee", "Jinhwan", ""], ["Baek", "Jineon", ""], ["Kim", "Byungsoo", ""], ["Choi", "Youngduck", ""]]}, {"id": "2002.11625", "submitter": "Gregory Falco", "authors": "Gregory Falco", "title": "Death by AI: Where Assured Autonomy in Smart Cities Meets the End-to-End\n  Argument", "comments": "PREPRINT, 6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A smart city involves critical infrastructure systems that have been\ndigitally enabled. Increasingly, many smart city cyber-physical systems are\nbecoming automated. The extent of automation ranges from basic logic gates to\nsophisticated, artificial intelligence (AI) that enables fully autonomous\nsystems. Because of modern society's reliance on autonomous systems in smart\ncities, it is crucial for them to operate in a safe manner; otherwise, it is\nfeasible for these systems to cause considerable physical harm or even death.\nBecause smart cities could involve thousands of autonomous systems operating in\nconcert in densely populated areas, safety assurances are required. Challenges\nabound to consistently manage the safety of such autonomous systems due to\ntheir disparate developers, manufacturers, operators and users. A novel network\nand a sample of associated network functions for autonomous systems is proposed\nthat aims to provide a baseline of safety for autonomous systems. This is\naccomplished by establishing a custom-designed network for autonomous systems\nthat is separate from the Internet, and can handle certain functions that\nenable safety through active networking. Such a network design sits at the\nmargins of the end-to-end principle, which is warranted considering the safety\nof autonomous systems is at stake as is argued in this paper. Without a\nscalable safety strategy for autonomous systems as proposed, assured autonomy\nin smart cities will remain elusive.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2020 20:14:25 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Falco", "Gregory", ""]]}, {"id": "2002.11631", "submitter": "Zhenyu Zhao", "authors": "Huigang Chen, Totte Harinen, Jeong-Yoon Lee, Mike Yung, Zhenyu Zhao", "title": "CausalML: Python Package for Causal Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CausalML is a Python implementation of algorithms related to causal inference\nand machine learning. Algorithms combining causal inference and machine\nlearning have been a trending topic in recent years. This package tries to\nbridge the gap between theoretical work on methodology and practical\napplications by making a collection of methods in this field available in\nPython. This paper introduces the key concepts, scope, and use cases of this\npackage.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 17:35:33 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 18:34:29 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Huigang", ""], ["Harinen", "Totte", ""], ["Lee", "Jeong-Yoon", ""], ["Yung", "Mike", ""], ["Zhao", "Zhenyu", ""]]}, {"id": "2002.11636", "submitter": "Eduardo Graells-Garrido", "authors": "Eduardo Graells-Garrido, Irene Meta, Feliu Serra-Burriel, Patricio\n  Reyes, Fernando M. Cucchietti", "title": "Measuring Spatial Subdivisions in Urban Mobility with Mobile Phone Data", "comments": "10 pages, 10 figures. To be presented at the Data Science for Social\n  Good workshop at The Web Conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban population grows constantly. By 2050 two thirds of the world population\nwill reside in urban areas. This growth is faster and more complex than the\nability of cities to measure and plan for their sustainability. To understand\nwhat makes a city inclusive for all, we define a methodology to identify and\ncharacterize spatial subdivisions: areas with over- and under-representation of\nspecific population groups, named hot and cold spots respectively. Using\naggregated mobile phone data, we apply this methodology to the city of\nBarcelona to assess the mobility of three groups of people: women, elders, and\ntourists. We find that, within the three groups, cold spots have a lower\ndiversity of amenities and services than hot spots. Also, cold spots of women\nand tourists tend to have lower population income. These insights apply to the\nfloating population of Barcelona, thus augmenting the scope of how\ninclusiveness can be analyzed in the city.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2020 14:37:46 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Graells-Garrido", "Eduardo", ""], ["Meta", "Irene", ""], ["Serra-Burriel", "Feliu", ""], ["Reyes", "Patricio", ""], ["Cucchietti", "Fernando M.", ""]]}, {"id": "2002.11645", "submitter": "Daniele Rama", "authors": "Daniele Rama, Yelena Mejova, Michele Tizzoni, Kyriaki Kalimeri, Ingmar\n  Weber", "title": "Facebook Ads as a Demographic Tool to Measure the Urban-Rural Divide", "comments": "To be published in the Proceedings of The Web Conference 2020 (WWW\n  '20)", "journal-ref": "Proceedings of The Web Conference 2020 (WWW '20) 327-338", "doi": "10.1145/3366423.3380118", "report-no": null, "categories": "cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the global move toward urbanization, making sure the people remaining in\nrural areas are not left behind in terms of development and policy\nconsiderations is a priority for governments worldwide. However, it is\nincreasingly challenging to track important statistics concerning this sparse,\ngeographically dispersed population, resulting in a lack of reliable,\nup-to-date data. In this study, we examine the usefulness of the Facebook\nAdvertising platform, which offers a digital \"census\" of over two billions of\nits users, in measuring potential rural-urban inequalities. We focus on Italy,\na country where about 30% of the population lives in rural areas. First, we\nshow that the population statistics that Facebook produces suffer from\ninstability across time and incomplete coverage of sparsely populated\nmunicipalities. To overcome such limitation, we propose an alternative\nmethodology for estimating Facebook Ads audiences that nearly triples the\ncoverage of the rural municipalities from 19% to 55% and makes feasible\nfine-grained sub-population analysis. Using official national census data, we\nevaluate our approach and confirm known significant urban-rural divides in\nterms of educational attainment and income. Extending the analysis to\nFacebook-specific user \"interests\" and behaviors, we provide further insights\non the divide, for instance, finding that rural areas show a higher interest in\ngambling. Notably, we find that the most predictive features of income in rural\nareas differ from those for urban centres, suggesting researchers need to\nconsider a broader range of attributes when examining rural wellbeing. The\nfindings of this study illustrate the necessity of improving existing tools and\nmethodologies to include under-represented populations in digital demographic\nstudies -- the failure to do so could result in misleading observations,\nconclusions, and most importantly, policies.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:19:24 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Rama", "Daniele", ""], ["Mejova", "Yelena", ""], ["Tizzoni", "Michele", ""], ["Kalimeri", "Kyriaki", ""], ["Weber", "Ingmar", ""]]}, {"id": "2002.11651", "submitter": "Hussein Mozannar", "authors": "Hussein Mozannar, Mesrob I. Ohannessian, Nathan Srebro", "title": "Fair Learning with Private Demographic Data", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensitive attributes such as race are rarely available to learners in real\nworld settings as their collection is often restricted by laws and regulations.\nWe give a scheme that allows individuals to release their sensitive information\nprivately while still allowing any downstream entity to learn\nnon-discriminatory predictors. We show how to adapt non-discriminatory learners\nto work with privatized protected attributes giving theoretical guarantees on\nperformance. Finally, we highlight how the methodology could apply to learning\nfair predictors in settings where protected attributes are only available for a\nsubset of the data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 17:26:19 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 04:48:58 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Mozannar", "Hussein", ""], ["Ohannessian", "Mesrob I.", ""], ["Srebro", "Nathan", ""]]}, {"id": "2002.11672", "submitter": "Jingwei Huang", "authors": "Jingwei Huang, Adrian Gheorghe, Holly Handley, Pilar Pazos, Ariel\n  Pinto, Samuel Kovacic, Andy Collins, Charles Keating, Andres Sousa-Poza,\n  Ghaith Rabadi, Resit Unal, Teddy Cotter, Rafael Landaeta, Charles Daniels", "title": "Towards Digital Engineering -- The Advent of Digital Systems Engineering", "comments": "23 pages, 6 figures International Journal of System of Systems\n  Engineering, (in press)", "journal-ref": "International Journal of System of Systems Engineering, 2020", "doi": "10.1504/IJSSE.2020.10031364", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digital Engineering, the digital transformation of engineering to leverage\ndigital technologies, is coming globally. This paper explores digital systems\nengineering, which aims at developing theory, methods, models, and tools to\nsupport the emerging digital engineering. A critical task is to digitalize\nengineering artifacts, thus enabling information sharing across platform,\nacross life cycle, and across domains. We identify significant challenges and\nenabling digital technologies; analyze the transition from traditional\nengineering to digital engineering; define core concepts, including\n\"digitalization\", \"unique identification\", \"digitalized artifacts\", \"digital\naugmentation\", and others; present a big picture of digital systems engineering\nin four levels: vision, strategy, action, and foundation; briefly discuss each\nof main areas of research issues. Digitalization enables fast infusing and\nleveraging novel digital technologies; unique identification enables\ninformation traceability and accountability in engineering lifecycle;\nprovenance enables tracing dependency relations among engineering artifacts;\nsupporting model reproducibility and replicability; helping with\ntrustworthiness evaluation of digital engineering artifacts.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2020 04:58:20 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 17:00:57 GMT"}, {"version": "v3", "created": "Sun, 30 Aug 2020 22:27:51 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Huang", "Jingwei", ""], ["Gheorghe", "Adrian", ""], ["Handley", "Holly", ""], ["Pazos", "Pilar", ""], ["Pinto", "Ariel", ""], ["Kovacic", "Samuel", ""], ["Collins", "Andy", ""], ["Keating", "Charles", ""], ["Sousa-Poza", "Andres", ""], ["Rabadi", "Ghaith", ""], ["Unal", "Resit", ""], ["Cotter", "Teddy", ""], ["Landaeta", "Rafael", ""], ["Daniels", "Charles", ""]]}, {"id": "2002.11836", "submitter": "Rumi Chunara", "authors": "Caitlin Kuhlman, Latifa Jackson, Rumi Chunara", "title": "No computation without representation: Avoiding data and algorithm\n  biases through diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence and growth of research on issues of ethics in AI, and in\nparticular algorithmic fairness, has roots in an essential observation that\nstructural inequalities in society are reflected in the data used to train\npredictive models and in the design of objective functions. While research\naiming to mitigate these issues is inherently interdisciplinary, the design of\nunbiased algorithms and fair socio-technical systems are key desired outcomes\nwhich depend on practitioners from the fields of data science and computing.\nHowever, these computing fields broadly also suffer from the same\nunder-representation issues that are found in the datasets we analyze. This\ndisconnect affects the design of both the desired outcomes and metrics by which\nwe measure success. If the ethical AI research community accepts this, we\ntacitly endorse the status quo and contradict the goals of non-discrimination\nand equity which work on algorithmic fairness, accountability, and transparency\nseeks to address. Therefore, we advocate in this work for diversifying\ncomputing as a core priority of the field and our efforts to achieve ethical AI\npractices. We draw connections between the lack of diversity within academic\nand professional computing fields and the type and breadth of the biases\nencountered in datasets, machine learning models, problem formulations, and\ninterpretation of results. Examining the current fairness/ethics in AI\nliterature, we highlight cases where this lack of diverse perspectives has been\nfoundational to the inequity in treatment of underrepresented and protected\ngroup data. We also look to other professional communities, such as in law and\nhealth, where disparities have been reduced both in the educational diversity\nof trainees and among professional practices. We use these lessons to develop\nrecommendations that provide concrete steps for the computing community to\nincrease diversity.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 23:07:39 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Kuhlman", "Caitlin", ""], ["Jackson", "Latifa", ""], ["Chunara", "Rumi", ""]]}, {"id": "2002.12387", "submitter": "Daniel J Liebling", "authors": "Daniel J. Liebling, Michal Lahav, Abigail Evans, Aaron Donsbach, Jess\n  Holbrook, Boris Smus, Lindsey Boran", "title": "Unmet Needs and Opportunities for Mobile Translation AI", "comments": "13 pages, 3 figures, to be published in Proceedings of the 2020 CHI\n  Conference on Human Factors in Computing Systems (CHI '20)", "journal-ref": null, "doi": "10.1145/3313831.3376260", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Translation apps and devices are often presented in the context of providing\nassistance while traveling abroad. However, the spectrum of needs for\ncross-language communication is much wider. To investigate these needs, we\nconducted three studies with populations spanning socioeconomic status and\ngeographic regions: (1) United States-based travelers, (2) migrant workers in\nIndia, and (3) immigrant populations in the United States. We compare frequent\ntravelers' perception and actual translation needs with those of the two\nmigrant communities. The latter two, with low language proficiency, have the\ngreatest translation needs to navigate their daily lives. However, current\nmobile translation apps do not meet these needs. Our findings provide new\ninsights on the usage practices and limitations of mobile translation tools.\nFinally, we propose design implications to help apps better serve these unmet\nneeds.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 19:01:08 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Liebling", "Daniel J.", ""], ["Lahav", "Michal", ""], ["Evans", "Abigail", ""], ["Donsbach", "Aaron", ""], ["Holbrook", "Jess", ""], ["Smus", "Boris", ""], ["Boran", "Lindsey", ""]]}, {"id": "2002.12457", "submitter": "Curtis Northcutt", "authors": "Curtis G. Northcutt, Kimberly A. Leon, Naichun Chen", "title": "Comment Ranking Diversification in Forum Discussions", "comments": "5 pages, 7 figures, published in Learning @ Scale, 2017", "journal-ref": "Proceedings of the Sixth {ACM} Conference on Learning @ Scale, L@S\n  2017", "doi": "10.1145/3051457.3054016", "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Viewing consumption of discussion forums with hundreds or more comments\ndepends on ranking because most users only view top-ranked comments. When\ncomments are ranked by an ordered score (e.g. number of replies or up-votes)\nwithout adjusting for semantic similarity of near-ranked comments, top-ranked\ncomments are more likely to emphasize the majority opinion and incur\nredundancy. In this paper, we propose a top K comment diversification\nre-ranking model using Maximal Marginal Relevance (MMR) and evaluate its impact\nin three categories: (1) semantic diversity, (2) inclusion of the semantics of\nlower-ranked comments, and (3) redundancy, within the context of a HarvardX\ncourse discussion forum. We conducted a double-blind, small-scale evaluation\nexperiment requiring subjects to select between the top 5 comments of a\ndiversified ranking and a baseline ranking ordered by score. For three\nsubjects, across 100 trials, subjects selected the diversified (75% score, 25%\ndiversification) ranking as significantly (1) more diverse, (2) more inclusive,\nand (3) less redundant. Within each category, inter-rater reliability showed\nmoderate consistency, with typical Cohen-Kappa scores near 0.2. Our findings\nsuggest that our model improves (1) diversification, (2) inclusion, and (3)\nredundancy, among top K ranked comments in online discussion forums.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 21:44:41 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Northcutt", "Curtis G.", ""], ["Leon", "Kimberly A.", ""], ["Chen", "Naichun", ""]]}, {"id": "2002.12616", "submitter": "Innar Liiv", "authors": "Henri Ots, Innar Liiv, and Diana Tur", "title": "Mobile Phone Usage Data for Credit Scoring", "comments": "14 pages, submitted to DB&IS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study is to demostrate that mobile phone usage data can be\nused to make predictions and find the best classification method for credit\nscoring even if the dataset is small (2,503 customers). We use different\nclassification algorithms to split customers into paying and non-paying ones\nusing mobile data, and then compare the predicted results with actual results.\nThere are several related works publicly accessible in which mobile data has\nbeen used for credit scoring, but they are all based on a large dataset. Small\ncompanies are unable to use datasets as large as those used by these related\npapers, therefore these studies are of little use for them. In this paper we\ntry to argue that there is value in mobile phone usage data for credit scoring\neven if the dataset is small. We found that with a dataset that consists of\nmobile data based only on 2,503 customers, we can predict credit risk. The best\nclassification method gave us the result 0.62 AUC (area under the curve).\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 09:32:11 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Ots", "Henri", ""], ["Liiv", "Innar", ""], ["Tur", "Diana", ""]]}, {"id": "2002.12632", "submitter": "Ilia Derevitskii", "authors": "Ilya V. Derevitskii, Daria A. Savitskaya, Alina Y. Babenko, Sergey V.\n  Kovalchuk", "title": "The Atrial Fibrillation Risk Score for Hyperthyroidism Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thyrotoxicosis (TT) is associated with an increase in both total and\ncardiovascu-lar mortality. One of the main thyrotoxicosis risks is Atrial\nFibrillation (AF). Right AF predicts help medical personal prescribe the\ncorrect medicaments and correct surgical or radioiodine therapy. The main goal\nof this study is creating a method for practical treatment and diagnostic AF.\nThis study proposes a new method for assessing the risk of occurrence atrial\nfibrillation for patients with TT. This method considers both the features of\nthe complication and the specifics of the chronic disease. A model is created\nbased on case histories of patients with thyrotoxicosis. We used Machine\nLearning methods for creating several models. Each model has advantages and\ndisadvantages depending on the diagnostic and medical purposes. The resulting\nmodels show high results in the different metrics of the prediction of AF.\nThese models interpreted and simple for use. Therefore, models can be used as\npart of the support and decision-making system (DSS) by medical specialists in\nthe treatment and diagnostic of AF.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 10:23:46 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Derevitskii", "Ilya V.", ""], ["Savitskaya", "Daria A.", ""], ["Babenko", "Alina Y.", ""], ["Kovalchuk", "Sergey V.", ""]]}, {"id": "2002.12899", "submitter": "Paul Fergus Dr", "authors": "P. Fergus, C. Chalmers", "title": "BMI: A Behavior Measurement Indicator for Fuel Poverty Using Aggregated\n  Load Readings from Smart Meters", "comments": "33 Pages, 12 Figures, Submitted as a book chapter to Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuel poverty affects between 50 and 125 million households in Europe and is a\nsignificant issue for both developed and developing countries globally. This\nmeans that fuel poor residents are unable to adequately warm their home and run\nthe necessary energy services needed for lighting, cooking, hot water, and\nelectrical appliances. The problem is complex but is typically caused by three\nfactors; low income, high energy costs, and energy inefficient homes. In the\nUnited Kingdom (UK), 4 million families are currently living in fuel poverty.\nThose in series financial difficulty are either forced to self-disconnect or\nhave their services terminated by energy providers. Fuel poverty contributed to\n10,000 reported deaths in England in the winter of 2016-2107 due to homes being\ncold. While it is recognized by governments as a social, public health and\nenvironmental policy issue, the European Union (EU) has failed to provide a\ncommon definition of fuel poverty or a conventional set of indicators to\nmeasure it. This chapter discusses current fuel poverty strategies across the\nEU and proposes a new and foundational behavior measurement indicator designed\nto directly assess and monitor fuel poverty risks in households using smart\nmeters, Consumer Access Device (CAD) data and machine learning. By detecting\nActivities of Daily Living (ADLS) through household appliance usage, it is\npossible to spot the early signs of financial difficulty and identify when\nsupport packages are required.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2020 16:03:11 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Fergus", "P.", ""], ["Chalmers", "C.", ""]]}, {"id": "2002.12926", "submitter": "Juste Raimbault", "authors": "Juste Raimbault", "title": "Cities as they could be: Artificial Life and Urban Systems", "comments": "8 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The metaphor of cities as organisms has a long history in urban planning, and\na few urban modeling approaches have explicitly been linked to Artificial Life.\nWe propose in that paper to explore the extent of Artificial Life and\nArtificial Intelligence application to urban issues, by constructing and\nexploring a citation network of around 225,000 papers. It shows that most of\nthe literature is indeed application of methodologies and a rather strong\nmodularity of approaches. We finally develop ALife concepts which have a strong\npotential for the development of new urban theories.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:54:37 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Raimbault", "Juste", ""]]}]