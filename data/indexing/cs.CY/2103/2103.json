[{"id": "2103.00068", "submitter": "Isaac Johnson", "authors": "Isaac Johnson, Martin Gerlach and Diego S\\'aez-Trumper", "title": "Language-agnostic Topic Classification for Wikipedia", "comments": "Accepted to WikiWorkshop at The Web Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A major challenge for many analyses of Wikipedia dynamics -- e.g., imbalances\nin content quality, geographic differences in what content is popular, what\ntypes of articles attract more editor discussion -- is grouping the very\ndiverse range of Wikipedia articles into coherent, consistent topics. This\nproblem has been addressed using various approaches based on Wikipedia's\ncategory network, WikiProjects, and external taxonomies. However, these\napproaches have always been limited in their coverage: typically, only a small\nsubset of articles can be classified, or the method cannot be applied across\n(the more than 300) languages on Wikipedia. In this paper, we propose a\nlanguage-agnostic approach based on the links in an article for classifying\narticles into a taxonomy of topics that can be easily applied to (almost) any\nlanguage and article on Wikipedia. We show that it matches the performance of a\nlanguage-dependent approach while being simpler and having much greater\ncoverage.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 22:17:50 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Johnson", "Isaac", ""], ["Gerlach", "Martin", ""], ["S\u00e1ez-Trumper", "Diego", ""]]}, {"id": "2103.00097", "submitter": "Parth Sane", "authors": "Parth Sane", "title": "A Brief Survey of Current Software Engineering Practices in Continuous\n  Integration and Automated Accessibility Testing", "comments": "IEEE Conference WiSPNET 2021 Accepted Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It's long been accepted that continuous integration (CI) in software\nengineering increases the code quality of enterprise projects when adhered to\nby it's practitioners. But is any of that effort to increase code quality and\nvelocity directed towards improving software accessibility accommodations? What\nare the potential benefits quoted in literature? Does it fit with the modern\nagile way that teams operate in most enterprises? This paper attempts to map\nthe current scene of the software engineering effort spent on improving\naccessibility via continuous integration and it's hurdles to adoption as quoted\nby researchers. We also try to explore steps that agile teams may take to train\nmembers on how to implement accessibility testing and introduce key diagrams to\nvisualize processes to implement CI based accessibility testing procedures in\nthe software development lifecycle.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 01:13:43 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Sane", "Parth", ""]]}, {"id": "2103.00163", "submitter": "Renzhe Yu", "authors": "Renzhe Yu, John Scott, Zachary A. Pardos", "title": "Unsupervised Representations Predict Popularity of Peer-Shared Artifacts\n  in an Online Learning Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In online collaborative learning environments, students create content and\nconstruct their own knowledge through complex interactions over time. To\nfacilitate effective social learning and inclusive participation in this\ncontext, insights are needed into the correspondence between\nstudent-contributed artifacts and their subsequent popularity among peers. In\nthis study, we represent student artifacts by their (a) contextual action logs\n(b) textual content, and (c) set of instructor-specified features, and use\nthese representations to predict artifact popularity measures. Through a\nmixture of predictive analysis and visual exploration, we find that the neural\nembedding representation, learned from contextual action logs, has the\nstrongest predictions of popularity, ahead of instructor's knowledge, which\nincludes academic value and creativity ratings. Because this representation can\nbe learnt without extensive human labeling effort, it opens up possibilities\nfor shaping more inclusive student interactions on the fly in collaboration\nwith instructors and students alike.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 09:13:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Yu", "Renzhe", ""], ["Scott", "John", ""], ["Pardos", "Zachary A.", ""]]}, {"id": "2103.00176", "submitter": "Mayank Gokarna", "authors": "Mayank Gokarna", "title": "Reasons behind growing adoption of Cloud after Covid-19 Pandemic and\n  Challenges ahead", "comments": "10 pages including 27 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  There are many sectors which have moved to Cloud and are planning\naggressively to move their workloads to Cloud since the world entered Covid-19\npandemic. There are various reasons why Cloud is an essential irresistible\ntechnology and serves as an ultimate solution to access IT software and\nsystems. It has become a new essential catalyst for Enterprise Organisations\nwhich are looking for Digital Transformation. Remote working is a common\nphenomenon now across all the IT companies making the services available all\nthe time. Covid-19 has made cloud adoption an immediate priority for\nOrganisation rather than a slowly approached future transformation. The\nbenefits of Cloud lies in the fact that employees rather engineers of an\nenterprise are no more dependent on the closed hardware-based IT infrastructure\nand hence eliminates the necessity of working from the networked office\npremises. This has raised a huge demand for skilled Cloud specialist who can\nmanage and support the systems running on cloud across different regions of the\nworld. In this research, the reasons for growing Cloud adoption after pandemic\nCovid-19 has been described and the challenges which Organization will face is\nalso explained. This study also details the most used cloud services during the\npandemic considering Amazon Web Services as the cloud provider.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 10:32:10 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Gokarna", "Mayank", ""]]}, {"id": "2103.00347", "submitter": "Kate Donahue", "authors": "Kate Donahue and Solon Barocas", "title": "Better Together? How Externalities of Size Complicate Notions of\n  Solidarity and Actuarial Fairness", "comments": "Presented at ACM Conference on Fairness, Accountability, and\n  Transparency (ACM FAccT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consider a cost-sharing game with players of different contribution to the\ntotal cost: an example might be an insurance company calculating premiums for a\npopulation of mixed-risk individuals. Two natural and competing notions of\nfairness might be to a) charge each individual the same price or b) charge each\nindividual according to the cost that they bring to the pool. In the insurance\nliterature, these general approaches are referred to as \"solidarity\" and\n\"actuarial fairness\" and are commonly viewed as opposites. However, in\ninsurance (and many other natural settings), the cost-sharing game also\nexhibits \"externalities of size\": all else being equal, larger groups have\nlower average cost. In the insurance case, we analyze a model with\nexternalities of size due to a reduction in the variability of losses. We\nexplore how this complicates traditional understandings of fairness, drawing on\nliterature in cooperative game theory.\n  First, we explore solidarity: we show that it is possible for both groups\n(high and low risk) to strictly benefit by joining an insurance pool where\ncosts are evenly split, as opposed to being in separate risk pools. We build on\nthis by producing a pricing scheme that maximally subsidizes the high risk\ngroup, while maintaining an incentive for lower risk people to stay in the\ninsurance pool. Next, we demonstrate that with this new model, the price\ncharged to each individual has to depend on the risk of other participants,\nmaking naive actuarial fairness inefficient. Furthermore, we prove that stable\npricing schemes must be ones where players have the anti-social incentive of\ndesiring riskier partners, contradicting motivations for using actuarial\nfairness. Finally, we describe how these results relate to debates about\nfairness in machine learning and potential avenues for future research.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 22:55:33 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Donahue", "Kate", ""], ["Barocas", "Solon", ""]]}, {"id": "2103.00352", "submitter": "Kaylea Champion", "authors": "Kaylea Champion and Benjamin Mako Hill", "title": "Underproduction: An Approach for Measuring Risk in Open Source Software", "comments": "Preprint of archival paper accepted for SANER 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The widespread adoption of Free/Libre and Open Source Software (FLOSS) means\nthat the ongoing maintenance of many widely used software components relies on\nthe collaborative effort of volunteers who set their own priorities and choose\ntheir own tasks. We argue that this has created a new form of risk that we call\n'underproduction' which occurs when the supply of software engineering labor\nbecomes out of alignment with the demand of people who rely on the software\nproduced. We present a conceptual framework for identifying relative\nunderproduction in software as well as a statistical method for applying our\nframework to a comprehensive dataset from the Debian GNU/Linux distribution\nthat includes 21,902 source packages and the full history of 461,656 bugs. We\ndraw on this application to present two experiments: (1) a demonstration of how\nour technique can be used to identify at-risk software packages in a large\nFLOSS repository and (2) a validation of these results using an alternate\nindicator of package risk. Our analysis demonstrates both the utility of our\napproach and reveals the existence of widespread underproduction in a range of\nwidely-installed software components in Debian.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 23:18:21 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Champion", "Kaylea", ""], ["Hill", "Benjamin Mako", ""]]}, {"id": "2103.00457", "submitter": "Lucia Cavallaro", "authors": "Annamaria Ficara, Lucia Cavallaro, Francesco Curreri, Giacomo Fiumara,\n  Pasquale De Meo, Ovidiu Bagdasar, Wei Song, Antonio Liotta", "title": "Criminal Networks Analysis in Missing Data scenarios through Graph\n  Distances", "comments": "18 pages, 4 figures, submitted to PLoS ONE Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Data collected in criminal investigations may suffer from: (i)\nincompleteness, due to the covert nature of criminal organisations; (ii)\nincorrectness, caused by either unintentional data collection errors and\nintentional deception by criminals; (iii) inconsistency, when the same\ninformation is collected into law enforcement databases multiple times, or in\ndifferent formats. In this paper we analyse nine real criminal networks of\ndifferent nature (i.e., Mafia networks, criminal street gangs and terrorist\norganizations) in order to quantify the impact of incomplete data and to\ndetermine which network type is most affected by it. The networks are firstly\npruned following two specific methods: (i) random edges removal, simulating the\nscenario in which the Law Enforcement Agencies (LEAs) fail to intercept some\ncalls, or to spot sporadic meetings among suspects; (ii) nodes removal, that\ncatches the hypothesis in which some suspects cannot be intercepted or\ninvestigated. Finally we compute spectral (i.e., Adjacency, Laplacian and\nNormalised Laplacian Spectral Distances) and matrix (i.e., Root Euclidean\nDistance) distances between the complete and pruned networks, which we compare\nusing statistical analysis. Our investigation identified two main features:\nfirst, the overall understanding of the criminal networks remains high even\nwith incomplete data on criminal interactions (i.e., 10% removed edges);\nsecond, removing even a small fraction of suspects not investigated (i.e., 2%\nremoved nodes) may lead to significant misinterpretation of the overall\nnetwork.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 11:12:05 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Ficara", "Annamaria", ""], ["Cavallaro", "Lucia", ""], ["Curreri", "Francesco", ""], ["Fiumara", "Giacomo", ""], ["De Meo", "Pasquale", ""], ["Bagdasar", "Ovidiu", ""], ["Song", "Wei", ""], ["Liotta", "Antonio", ""]]}, {"id": "2103.00473", "submitter": "Maria Papadopoulou Dr.", "authors": "Maria Papadopoulou, Zacharoula Smyrnaiou", "title": "Digital History and History Teaching in the Digital Age", "comments": "47 pages, in Greek, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Digital technologies, such as the Internet and Artificial Intelligence, are\npart of our daily lives, influencing broader aspects of our way of life, as\nwell as the way we interact with the past. Having dramatically changed the ways\nin which knowledge is produced and consumed, the algorithmic age has also\nradically changed the relationship that the general public has with History.\nFields of History such as Public and Oral History have particularly benefitted\nfrom the rise of digital culture. How does our digital culture affect the way\nwe think, study, research and teach the past, as historical evidence spreads\nrapidly in the public sphere? How do digital technologies promote the study,\nwriting and teaching of History? What should historians, students of history\nand pre-service history teachers be critically aware of, when swarmed with\ndigitized or born-digital content, constantly growing on the Internet? And\nwhile these changes are now visible globally, how is the discipline of History\nsituated within the digital transformation rapidly advancing in Greece?\nFinally, what are the consequences of these changes for History as a subject\ntaught at Greek secondary schools? These are some of the issues raised in the\ntext that follows, which is part of the course materials of the undergraduate\ncourse offered during winter semester 2020-2021 at the School University of\nAthens, School of Philosophy, Pedagogy, Psychology. Course Title: 'Pedagogics\nof History: Theory and Practice', Academic Institution: School of\nPhilosophy-Pedagogy-Psychology, University of Athens.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 11:51:45 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Papadopoulou", "Maria", ""], ["Smyrnaiou", "Zacharoula", ""]]}, {"id": "2103.00474", "submitter": "Jason R.C. Nurse Dr", "authors": "Jason R. C. Nurse", "title": "Cybersecurity Awareness", "comments": null, "journal-ref": "In: Jajodia S., Samarati P., Yung M. (eds) Encyclopedia of\n  Cryptography, Security and Privacy. Springer, Berlin, Heidelberg (2021)", "doi": "10.1007/978-3-642-27739-9_1596-1", "report-no": null, "categories": "cs.CR cs.CY cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybersecurity awareness can be viewed as the level of appreciation,\nunderstanding or knowledge of cybersecurity or information security aspects.\nSuch aspects include cognizance of cyber risks and threats, but also\nappropriate protection measures.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 11:54:58 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Nurse", "Jason R. C.", ""]]}, {"id": "2103.00508", "submitter": "Miguel Arana-Catania", "authors": "M. Arana-Catania, F.A. Van Lier, Rob Procter, Nataliya Tkachenko,\n  Yulan He, Arkaitz Zubiaga, Maria Liakata", "title": "Citizen Participation and Machine Learning for a Better Democracy", "comments": "19 pages, 5 figures, 4 tables, to appear in Digital Government:\n  Research and Practice (DGOV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of democratic systems is a crucial task as confirmed by its\nselection as one of the Millennium Sustainable Development Goals by the United\nNations. In this article, we report on the progress of a project that aims to\naddress barriers, one of which is information overload, to achieving effective\ndirect citizen participation in democratic decision-making processes. The main\nobjectives are to explore if the application of Natural Language Processing\n(NLP) and machine learning can improve citizens' experience of digital citizen\nparticipation platforms. Taking as a case study the \"Decide Madrid\" Consul\nplatform, which enables citizens to post proposals for policies they would like\nto see adopted by the city council, we used NLP and machine learning to provide\nnew ways to (a) suggest to citizens proposals they might wish to support; (b)\ngroup citizens by interests so that they can more easily interact with each\nother; (c) summarise comments posted in response to proposals; (d) assist\ncitizens in aggregating and developing proposals. Evaluation of the results\nconfirms that NLP and machine learning have a role to play in addressing some\nof the barriers users of platforms such as Consul currently experience.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 13:30:07 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Arana-Catania", "M.", ""], ["Van Lier", "F. A.", ""], ["Procter", "Rob", ""], ["Tkachenko", "Nataliya", ""], ["He", "Yulan", ""], ["Zubiaga", "Arkaitz", ""], ["Liakata", "Maria", ""]]}, {"id": "2103.00541", "submitter": "Glauco Carneiro", "authors": "Rafael Ant\\^onio Lima Cardoso, Glauco de Figueiredo Carneiro, Jos\\'e\n  Euclimar Xavier de Menezes", "title": "Dados Abertos Governamentais no contexto de Pol\\'iticas P\\'ublicas de\n  Sa\\'ude e Sistemas Prisionais: Realidade ou Utopia?", "comments": "in Portuguese", "journal-ref": "Dialogos Possiveis. v. 19, n. 2 (2020) 65-80", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are many initiatives of transparency reported in the access and use of\ngovernment open data for different purposes. This practice reveals an important\nrequirement to accomplish the participatory governance. The literature has\nreported a minimal set of criteria to categorize a specific data repository as\nopen. This paper discusses to which extent specific national and international\ndata repositories address these criteria. The analyzed repositories focus on\npublic health and prison systems. The results show different levels of\nalignment to the criteria and provide evidence that the adoption of government\nopen data practices are a reality. On the other hand, there is still a long way\nto achieve full alignment to the stated criteria.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 15:48:01 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Cardoso", "Rafael Ant\u00f4nio Lima", ""], ["Carneiro", "Glauco de Figueiredo", ""], ["de Menezes", "Jos\u00e9 Euclimar Xavier", ""]]}, {"id": "2103.00752", "submitter": "Atoosa Kasirzadeh", "authors": "Atoosa Kasirzadeh", "title": "Reasons, Values, Stakeholders: A Philosophical Framework for Explainable\n  Artificial Intelligence", "comments": "This paper is accepted for non-archival publication at the ACM\n  conference on Fairness, Accountability, and Transparency (FAccT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The societal and ethical implications of the use of opaque artificial\nintelligence systems for consequential decisions, such as welfare allocation\nand criminal justice, have generated a lively debate among multiple stakeholder\ngroups, including computer scientists, ethicists, social scientists, policy\nmakers, and end users. However, the lack of a common language or a\nmulti-dimensional framework to appropriately bridge the technical, epistemic,\nand normative aspects of this debate prevents the discussion from being as\nproductive as it could be. Drawing on the philosophical literature on the\nnature and value of explanations, this paper offers a multi-faceted framework\nthat brings more conceptual precision to the present debate by (1) identifying\nthe types of explanations that are most pertinent to artificial intelligence\npredictions, (2) recognizing the relevance and importance of social and ethical\nvalues for the evaluation of these explanations, and (3) demonstrating the\nimportance of these explanations for incorporating a diversified approach to\nimproving the design of truthful algorithmic ecosystems. The proposed\nphilosophical framework thus lays the groundwork for establishing a pertinent\nconnection between the technical and ethical aspects of artificial intelligence\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 04:50:31 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Kasirzadeh", "Atoosa", ""]]}, {"id": "2103.00822", "submitter": "Vera Sosnovik", "authors": "Vera Sosnovik and Oana Goga", "title": "Understanding the Complexity of Detecting Political Ads", "comments": "Proceedings of the Web Conference 2021 (WWW '21), April 19--23, 2021,\n  Ljubljana, Slovenia", "journal-ref": null, "doi": "10.1145/3442381.3450049", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online political advertising has grown significantly over the last few years.\nTo monitor online sponsored political discourse, companies such as Facebook,\nGoogle, and Twitter have created public Ad Libraries collecting the political\nads that run on their platforms. Currently, both policymakers and platforms are\ndebating further restrictions on political advertising to deter misuses.\n  This paper investigates whether we can reliably distinguish political ads\nfrom non-political ads. We take an empirical approach to analyze what kind of\nads are deemed political by ordinary people and what kind of ads lead to\ndisagreement. Our results show a significant disagreement between what ad\nplatforms, ordinary people, and advertisers consider political and suggest that\nthis disagreement mainly comes from diverging opinions on which ads address\nsocial issues. Overall our results imply that it is important to consider\nsocial issue ads as political, but they also complicate political advertising\nregulations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 07:44:08 GMT"}, {"version": "v2", "created": "Sun, 11 Apr 2021 19:23:09 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Sosnovik", "Vera", ""], ["Goga", "Oana", ""]]}, {"id": "2103.00847", "submitter": "Shahroz Tariq", "authors": "Shahroz Tariq, Sowon Jeon, Simon S. Woo", "title": "Am I a Real or Fake Celebrity? Measuring Commercial Face Recognition Web\n  APIs under Deepfake Impersonation Attack", "comments": "27 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, significant advancements have been made in face recognition\ntechnologies using Deep Neural Networks. As a result, companies such as\nMicrosoft, Amazon, and Naver offer highly accurate commercial face recognition\nweb services for diverse applications to meet the end-user needs. Naturally,\nhowever, such technologies are threatened persistently, as virtually any\nindividual can quickly implement impersonation attacks. In particular, these\nattacks can be a significant threat for authentication and identification\nservices, which heavily rely on their underlying face recognition technologies'\naccuracy and robustness. Despite its gravity, the issue regarding deepfake\nabuse using commercial web APIs and their robustness has not yet been\nthoroughly investigated. This work provides a measurement study on the\nrobustness of black-box commercial face recognition APIs against Deepfake\nImpersonation (DI) attacks using celebrity recognition APIs as an example case\nstudy. We use five deepfake datasets, two of which are created by us and\nplanned to be released. More specifically, we measure attack performance based\non two scenarios (targeted and non-targeted) and further analyze the differing\nsystem behaviors using fidelity, confidence, and similarity metrics.\nAccordingly, we demonstrate how vulnerable face recognition technologies from\npopular companies are to DI attack, achieving maximum success rates of 78.0%\nand 99.9% for targeted (i.e., precise match) and non-targeted (i.e., match with\nany celebrity) attacks, respectively. Moreover, we propose practical defense\nstrategies to mitigate DI attacks, reducing the attack success rates to as low\nas 0% and 0.02% for targeted and non-targeted attacks, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 08:40:10 GMT"}, {"version": "v2", "created": "Tue, 2 Mar 2021 07:56:46 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Tariq", "Shahroz", ""], ["Jeon", "Sowon", ""], ["Woo", "Simon S.", ""]]}, {"id": "2103.00923", "submitter": "Sarah Janboecke", "authors": "Sarah Janboecke and Susanne Zajitschek", "title": "Anticipation Next -- System-sensitive technology development and\n  integration in work contexts", "comments": null, "journal-ref": "Information 2021, 12, 269", "doi": "10.3390/info12070269", "report-no": null, "categories": "cs.HC cs.AI cs.CY cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When discussing future concerns within socio-technical systems in work\ncontexts, we often find descriptions of missed technology development and\nintegration. The experience of technology that fails whilst being integrated is\noften rooted in dysfunctional epistemological approaches within the research\nand development process. Thus, ultimately leading to sustainable\ntechnology-distrust in work contexts. This is true for organizations that\nintegrate new technologies and for organizations that invent them.\nOrganizations in which we find failed technology development and integrations\nare, in their very nature, social systems. Nowadays, those complex social\nsystems act within an even more complex environment. This urges the development\nof new anticipation methods for technology development and integration.\nGathering of and dealing with complex information in the described context is\nwhat we call Anticipation Next. This explorative work uses existing literature\nfrom the adjoining research fields of system theory, organizational theory, and\nsocio-technical research to combine various concepts. We deliberately aim at a\nnetworked way of thinking in scientific contexts and thus combine\nmultidisciplinary subject areas in one paper to present an innovative way to\ndeal with multi-faceted problems in a human-centred way. We end with suggesting\na conceptual framework that should be used in the very early stages of\ntechnology development and integration in work contexts.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 11:27:19 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 07:38:29 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Janboecke", "Sarah", ""], ["Zajitschek", "Susanne", ""]]}, {"id": "2103.01028", "submitter": "Chara Podimata", "authors": "Yahav Bechavod, Chara Podimata, Zhiwei Steven Wu, and Juba Ziani", "title": "Information Discrepancy in Strategic Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of information discrepancy across sub-populations on\ntheir ability to simultaneously improve their features in strategic learning\nsettings. Specifically, we consider a game where a principal deploys a decision\nrule in an attempt to optimize the whole population's welfare, and agents\nstrategically adapt to it to receive better scores. Inspired by real-life\nsettings, such as loan approvals and college admissions, we remove the typical\nassumption made in the strategic learning literature that the decision rule is\nfully known to the agents, and focus on settings where it is inaccessible. In\ntheir lack of knowledge, individuals try to infer this rule by learning from\ntheir peers (e.g., friends and acquaintances who previously applied for a\nloan), naturally forming groups in the population, each with possibly different\ntype and level of information about the decision rule. In our equilibrium\nanalysis, we show that the principal's decision rule optimizing the welfare\nacross subgroups may cause a surprising negative externality; the true quality\nof some of the subgroups can actually deteriorate. On the positive side, we\nshow that in many natural cases, optimal improvement is guaranteed\nsimultaneously for all subgroups in equilibrium. We also characterize the\ndisparity in improvements across subgroups via a measure of their informational\noverlap. Finally, we complement our theoretical analysis with experiments on\nreal-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 14:26:58 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 18:25:44 GMT"}, {"version": "v3", "created": "Mon, 7 Jun 2021 12:53:58 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bechavod", "Yahav", ""], ["Podimata", "Chara", ""], ["Wu", "Zhiwei Steven", ""], ["Ziani", "Juba", ""]]}, {"id": "2103.01041", "submitter": "Shoaib Sufi Mr", "authors": "Shoaib Sufi", "title": "The Rise of a New Digital Third Space Professional in Higher Education:\n  Recognising Research Software Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research Software Engineering is the application of professional software\nskills to research problems. Those who do this are called Research Software\nEngineers or RSEs for short. RSEs work closely with researchers in a\ncollaborative fashion rather than just offering a standalone function (c.f. the\ntraditional IT workforce or Librarians working to provide a general set of\nservices to the University community such as research, teaching or\nadministrative functions). It is this overlap with academic researchers that\nmake the RSE and the RSE management a new type of third space professional in\nthe higher education sector. We explore aspects of knowledge, relationships,\nlegitimacies and language in relation to the model constructed by Whitchurch in\nReconstructing Identities in Higher Education to explore how these relate to\nthe RSE role and go on to highlight open problems that need resolving to put\nRSEs on a firmer organisational footing.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 14:34:17 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Sufi", "Shoaib", ""]]}, {"id": "2103.01149", "submitter": "Jens Schneider", "authors": "Jens Schneider, Marco Agus", "title": "Reflections on the Clinical Acceptance of Artificial Intelligence", "comments": "This is the authors' preprint of a chapter accepted for publication\n  in \"Multiple Perspectives on Artificial Intelligence in Healthcare\", M.\n  Househ, E. Borycki, A. Kushniruk (Eds.), Springer, 2021, ISBN\n  978-3-030-67303-1, url: https://www.springer.com/gp/book/9783030673024, to\n  appear. For the final and definitive version, kindly refer to above reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we reflect on the use of Artificial Intelligence (AI) and\nits acceptance in clinical environments. We develop a general view of\nhindrances for clinical acceptance in the form of a pipeline model combining AI\nand clinical practise. We then link each challenge to the relevant stage in the\npipeline and discuss the necessary requirements in order to overcome each\nchallenge. We complement this discussion with an overview of opportunities for\nAI, which we currently see at the periphery of clinical workflows.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 17:34:09 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Schneider", "Jens", ""], ["Agus", "Marco", ""]]}, {"id": "2103.01168", "submitter": "Abeba Birhane", "authors": "Rediet Abebe, Kehinde Aruleba, Abeba Birhane, Sara Kingsley, George\n  Obaido, Sekou L. Remy, Swathi Sadagopan", "title": "Narratives and Counternarratives on Data Sharing in Africa", "comments": null, "journal-ref": null, "doi": "10.1145/3442188.3445897", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning and data science applications grow ever more prevalent,\nthere is an increased focus on data sharing and open data initiatives,\nparticularly in the context of the African continent. Many argue that data\nsharing can support research and policy design to alleviate poverty,\ninequality, and derivative effects in Africa. Despite the fact that the\ndatasets in question are often extracted from African communities,\nconversations around the challenges of accessing and sharing African data are\ntoo often driven by nonAfrican stakeholders. These perspectives frequently\nemploy a deficit narratives, often focusing on lack of education, training, and\ntechnological resources in the continent as the leading causes of friction in\nthe data ecosystem. We argue that these narratives obfuscate and distort the\nfull complexity of the African data sharing landscape. In particular, we use\nstorytelling via fictional personas built from a series of interviews with\nAfrican data experts to complicate dominant narratives and to provide\ncounternarratives. Coupling these personas with research on data practices\nwithin the continent, we identify recurring barriers to data sharing as well as\ninequities in the distribution of data sharing benefits. In particular, we\ndiscuss issues arising from power imbalances resulting from the legacies of\ncolonialism, ethno-centrism, and slavery, disinvestment in building trust, lack\nof acknowledgement of historical and present-day extractive practices, and\nWestern-centric policies that are ill-suited to the African context. After\noutlining these problems, we discuss avenues for addressing them when sharing\ndata generated in the continent.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 18:07:35 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Abebe", "Rediet", ""], ["Aruleba", "Kehinde", ""], ["Birhane", "Abeba", ""], ["Kingsley", "Sara", ""], ["Obaido", "George", ""], ["Remy", "Sekou L.", ""], ["Sadagopan", "Swathi", ""]]}, {"id": "2103.01169", "submitter": "Luca Maria Aiello", "authors": "Sanja Scepanovic, Luca Maria Aiello, Ke Zhou, Sagar Joglekar, Daniele\n  Quercia", "title": "The Healthy States of America: Creating a Health Taxonomy with Social\n  Media", "comments": "In proceedings of the International Conference on Web and Social\n  Media (ICWSM'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the uptake of social media, researchers have mined online discussions\nto track the outbreak and evolution of specific diseases or chronic conditions\nsuch as influenza or depression. To broaden the set of diseases under study, we\ndeveloped a Deep Learning tool for Natural Language Processing that extracts\nmentions of virtually any medical condition or disease from unstructured social\nmedia text. With that tool at hand, we processed Reddit and Twitter posts,\nanalyzed the clusters of the two resulting co-occurrence networks of\nconditions, and discovered that they correspond to well-defined categories of\nmedical conditions. This resulted in the creation of the first comprehensive\ntaxonomy of medical conditions automatically derived from online discussions.\nWe validated the structure of our taxonomy against the official International\nStatistical Classification of Diseases and Related Health Problems (ICD-11),\nfinding matches of our clusters with 20 official categories, out of 22. Based\non the mentions of our taxonomy's sub-categories on Reddit posts geo-referenced\nin the U.S., we were then able to compute disease-specific health scores. As\nopposed to counts of disease mentions or counts with no knowledge of our\ntaxonomy's structure, we found that our disease-specific health scores are\ncausally linked with the officially reported prevalence of 18 conditions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 18:07:47 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Scepanovic", "Sanja", ""], ["Aiello", "Luca Maria", ""], ["Zhou", "Ke", ""], ["Joglekar", "Sagar", ""], ["Quercia", "Daniele", ""]]}, {"id": "2103.01217", "submitter": "Burak Pak", "authors": "Gorsev Argin, Burak Pak, Handan Turkoglu", "title": "Between Post-Flaneur and Smartphone Zombie Smartphone Users Altering\n  Visual Attention and Walking Behavior in Public Space", "comments": null, "journal-ref": "2020 ISPRS International Journal of Geo-Information 9, 12, 700", "doi": "10.3390/ijgi9120700", "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The extensive use of smartphones in our everyday lives has created new modes\nof appropriation and behavior in public spaces. Recognition of these are\nessential for urban design and planning practices which help us to improve the\nrelationship between humans, technologies, and urban environment. This study\naims to research smartphone users in public space by observing their altering\nvisual attention and walking behavior, and, in this way, to reveal the emergent\nnew figures. For this purpose, Korenmarkt square in Ghent, Belgium, was\nobserved for seven days in 10-min time intervals. The gaze and walking behavior\nof smartphone users were encoded as geo-located and temporal data, analyzed and\nmapped using statistical and spatial analysis methods. Developing and\nimplementing new methods for identifying the characteristics of smartphone\nusers, this study resulted in a nuanced characterization of novel spatial\nappropriations. The findings led to a better understanding and knowledge of the\ndifferent behavior patterns of emergent figures such as post-flaneurs and\nsmartphone zombies while uncovering their altering visual interactions with and\nmovements in the public space. The results evoked questions on how researchers\nand designers can make use of spatial analysis methods and rethink the public\nspace of the future as a hybrid construct integrating the virtual and the\nphysical.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 14:53:45 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Argin", "Gorsev", ""], ["Pak", "Burak", ""], ["Turkoglu", "Handan", ""]]}, {"id": "2103.01309", "submitter": "Nelly Bencomo", "authors": "Alistair Sutcliffe, Pete Sawyer, Wei Liu, Nelly Bencomo", "title": "Investigating the potential impact of values on requirements and\n  software engineering", "comments": "ICSE SEIS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an investigation into value-based software engineering\nand proposes a comprehensive value taxonomy with an interpretation of design\nfeature implications. The value taxonomy is used to assess the design of\nCovid19 symptom tracker applications.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 21:05:06 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Sutcliffe", "Alistair", ""], ["Sawyer", "Pete", ""], ["Liu", "Wei", ""], ["Bencomo", "Nelly", ""]]}, {"id": "2103.01472", "submitter": "Kwan Hui Lim Dr", "authors": "Jolin Shaynn-Ly Kwan, Kwan Hui Lim", "title": "TweetCOVID: A System for Analyzing Public Sentiments and Discussions\n  about COVID-19 via Twitter Activities", "comments": "Accepted to the 26th International Conference on Intelligent User\n  Interfaces (IUI'21), Demo Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic has created widespread health and economical impacts,\naffecting millions around the world. To better understand these impacts, we\npresent the TweetCOVID system that offers the capability to understand the\npublic reactions to the COVID-19 pandemic in terms of their sentiments,\nemotions, topics of interest and controversial discussions, over a range of\ntime periods and locations, using public tweets. We also present three example\nuse cases that illustrates the usefulness of our proposed TweetCOVID system.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 05:00:41 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Kwan", "Jolin Shaynn-Ly", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "2103.01637", "submitter": "Alarith Uhde", "authors": "Alarith Uhde and Marc Hassenzahl", "title": "Towards a Better Understanding of Social Acceptability", "comments": "7 pages, 0 figures", "journal-ref": null, "doi": "10.1145/3411763.3451649", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social contexts play an important role in understanding acceptance and use of\ntechnology. However, current approaches used in HCI to describe contextual\ninfluence do not capture it appropriately. On the one hand, the often used\nTechnology Acceptance Model and related frameworks are too rigid to account for\nthe nuanced variations of social situations. On the other hand, Goffman's\ndramaturgical model of social interactions emphasizes interpersonal relations\nbut mostly overlooks the material (e.g., technology) that is central to HCI. As\nan alternative, we suggest an approach based on Social Practice Theory. We\nconceptualize social context as interactions between co-located social\npractices and acceptability as a matter of their (in)compatibilities. Finally,\nwe outline how this approach provides designers with a better understanding of\ndifferent types of social acceptability problems and helps finding appropriate\nsolutions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 10:59:17 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 17:22:11 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Uhde", "Alarith", ""], ["Hassenzahl", "Marc", ""]]}, {"id": "2103.01743", "submitter": "Pedro Huertas-Leyva", "authors": "Pedro Huertas-Leyva, Niccol\\`o Baldanzini, Giovanni Savino, Marco\n  Pierini", "title": "Human error in motorcycle crashes: a methodology based on in-depth data\n  to identify the skills needed and support training interventions for safe\n  riding", "comments": "Preprint submitted for publication in Taylor & Francis", "journal-ref": null, "doi": "10.1080/15389588.2021.1896714", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a methodology with in-depth data to identify the skills\nneeded by riders in the highest risk crash configurations to reduce casualty\nrates. We present a case study using in-depth data of 803 powered-two-wheeler\ncrashes. Seven high-risk crash configuration based on the pre-crash\ntrajectories of the road-users involved were considered to investigate the\nhuman errors as crash contributors. Primary crash contributing factor, evasive\nmanoeuvres performed, horizontal roadway alignment and speed-related factors\nwere identified, along with the most frequent configurations and those with the\ngreatest risk of severe injury. Straight Crossing Path/Lateral Direction was\nthe most frequent crash configuration and Turn Across Path/ Opposing Direction\nthat with the greatest risk of serious injury were identified. Multi-vehicle\ncrashes cannot be considered as a homogenous category of crashes to which the\nsame human failure is attributed, as different interactions between\nmotorcyclists and other road users are associated with both different types of\nhuman error and different rider reactions. Human error in multiple-vehicle\ncrashes related to crossing paths configurations were different from errors\nrelated to rear-end or head-on crashes. Multi-vehicle head-on crashes and\nsingle-vehicle collisions frequently occur along curves. The involved collision\navoidance manoeuvres of the riders differed significantly among the highest\nrisk crash configurations. The most relevant lack of skills are identified and\nlinked to their most representative context. In most cases a combination of\ndifferent skills was required simultaneously to avoid the crash. The findings\nunderline the need to group accident cases, beyond the usual single-vehicle\nversus multi-vehicle collision approach. Our methodology can also be applied to\nsupport preventive actions based on riders training and eventually ADAS design.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 21:30:37 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Huertas-Leyva", "Pedro", ""], ["Baldanzini", "Niccol\u00f2", ""], ["Savino", "Giovanni", ""], ["Pierini", "Marco", ""]]}, {"id": "2103.01752", "submitter": "Albina Zavgorodniaia", "authors": "Albina Zavgorodniaia, Raj Shrestha, Juho Leinonen, Arto Hellas and\n  John Edwards", "title": "Morning or Evening? An Examination of Circadian Rhythms of CS1 Students", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circadian rhythms are the cycles of our internal clock that play a key role\nin governing when we sleep and when we are active. A related concept is\nchronotype, which is a person's natural tendency toward activity at certain\ntimes of day and typically governs when the individual is most alert and\nproductive. In this work we investigate chronotypes in the setting of an\nIntroductory Computer Programming (CS1) course. Using keystroke data collected\nfrom students we investigate the existence of chronotypes through unsupervised\nlearning. The chronotypes we find align with those of typical populations\nreported in the literature and our results support correlations of certain\nchronotypes to academic achievement. We also find a lack of support for the\nstill-popular stereotype of a computer programmer as a night owl. The analyses\nare conducted on data from two universities, one in the US and one in Europe,\nthat use different teaching methods. In comparison of the two contexts, we look\ninto programming assignment design and administration that may promote better\nprogramming practices among students in terms of procrastination and effort.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 09:23:01 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Zavgorodniaia", "Albina", ""], ["Shrestha", "Raj", ""], ["Leinonen", "Juho", ""], ["Hellas", "Arto", ""], ["Edwards", "John", ""]]}, {"id": "2103.01756", "submitter": "Muhammad Mudassar Qureshi", "authors": "Muhammad Mudassar Qureshi, Amjad Farooq, Muhammad Mazhar Qureshi", "title": "Current eHealth Challenges and recent trends in eHealth applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  eHealth (Health Informatics/Medical Informatics) field is growing worldwide\ndue to acknowledge of reputable Organizations such as World Health\nOrganization, Institute of Medicine in USA and several others. This field is\nfacing number of challenges and there is need to classify these challenges\nmentioned by different researchers of this area. The purpose of this study is\nto classify different eHealth challenges in broader categories. We also\nanalyzed recent eHealth Applications to identify current trends of such\napplications. In this paper, we identify stakeholders who are responsible to\ncontribute in a particular eHealth challenge. Through eHealth application\nanalysis, we categories these applications based on different factors. We\nidentify different socio-economic benefits, which these applications can\nprovide. We also present ecosystem of an eHealth application. We gave\nrecommendations for eHealth challenges relevant to Information Technology\ndomain. We conclude our discussion by specifying areas for future research and\nrecommending researchers to work on identify which type of disease can control\nand manage by different eHealth applications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2021 15:00:31 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Qureshi", "Muhammad Mudassar", ""], ["Farooq", "Amjad", ""], ["Qureshi", "Muhammad Mazhar", ""]]}, {"id": "2103.01761", "submitter": "Martina Ferrando", "authors": "Martina Ferrando, Francesco Causone, Tianzhen Hong, Yixing Chen", "title": "Urban Building Energy Modeling (UBEM) Tools: A State-of-the-Art Review\n  of bottom-up physics-based approaches", "comments": "30 pages, 3 Figures, 4 tables", "journal-ref": "Sustainable Cities and Society, Volume 62, November 2020, 102408", "doi": "10.1016/j.scs.2020.102408", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Regulations corroborate the importance of retrofitting existing building\nstocks or constructing new energy efficient district. There is, thus, a need\nfor modeling tools to evaluate energy scenarios to better manage and design\ncities, and numerous methodologies and tools have been developed. Among them,\nUrban Building Energy Modeling (UBEM) tools allow the energy simulation of\nbuildings at large scales. Choosing an appropriate UBEM tool, balancing the\nlevel of complexity, accuracy, usability, and computing needs, remains a\nchallenge for users. The review focuses on the main bottom-up physics-based\nUBEM tools, comparing them from a user-oriented perspective. Five categories\nare used: (i) the required inputs, (ii) the reported outputs, (iii) the\nexploited workflow, (iv) the applicability of each tool, and (v) the potential\nusers. Moreover, a critical discussion is proposed focusing on interests and\ntrends in research and development. The results highlighted major differences\nbetween UBEM tools that must be considered to choose the proper one for an\napplication. Barriers of adoption of UBEM tools include the needs of a\nstandardized ontology, a common three dimensional city model, a standard\nprocedure to collect data, and a standard set of test cases. This feeds into\nfuture development of UBEM tools to support cities' sustainability goals.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 14:59:55 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Ferrando", "Martina", ""], ["Causone", "Francesco", ""], ["Hong", "Tianzhen", ""], ["Chen", "Yixing", ""]]}, {"id": "2103.01766", "submitter": "Muhammad Shahroz", "authors": "Muhammad Shahroz, Farooq Ahmad, Muhammad Shahzad Younis, Nadeem Ahmad,\n  Maged N. Kamel Boulos, Ricardo Vinuesa and Junaid Qadir", "title": "COVID-19 Digital Contact Tracing Applications and Techniques: A Review\n  Post Initial Deployments", "comments": "31 pages, 3 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The coronavirus disease 2019 (COVID-19) is a severe global pandemic that has\nclaimed millions of lives and continues to overwhelm public health systems in\nmany countries. The spread of COVID-19 pandemic has negatively impacted the\nhuman mobility patterns such as daily transportation-related behavior of the\npublic. There is a requirement to understand the disease spread patterns and\nits routes among neighboring individuals for the timely implementation of\ncorrective measures at the required placement. To increase the effectiveness of\ncontact tracing, countries across the globe are leveraging advancements in\nmobile technology and Internet of Things (IoT) to aid traditional manual\ncontact tracing to track individuals who have come in close contact with\nidentified COVID-19 patients. Even as the first administration of vaccines\nbegins in 2021, the COVID-19 management strategy will continue to be\nmulti-pronged for the foreseeable future with digital contact tracing being a\nvital component of the response along with the use of preventive measures such\nas social distancing and the use of face masks. After some months of deployment\nof digital contact tracing technology, deeper insights into the merits of\nvarious approaches and the usability, privacy, and ethical trade-offs involved\nare emerging. In this paper, we provide a comprehensive analysis of digital\ncontact tracing solutions in terms of their methodologies and technologies in\nthe light of the new data emerging about international experiences of\ndeployments of digital contact tracing technology. We also provide a discussion\non open challenges such as scalability, privacy, adaptability and highlight\npromising directions for future work.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 10:18:40 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Shahroz", "Muhammad", ""], ["Ahmad", "Farooq", ""], ["Younis", "Muhammad Shahzad", ""], ["Ahmad", "Nadeem", ""], ["Boulos", "Maged N. Kamel", ""], ["Vinuesa", "Ricardo", ""], ["Qadir", "Junaid", ""]]}, {"id": "2103.01768", "submitter": "Suchithra Rajendran", "authors": "Suchithra Rajendran and Sharan Srinivas", "title": "Air taxi service for urban mobility: A critical review of recent\n  developments, future challenges, and opportunities", "comments": "This is a pre-print version of the manuscript accepted in\n  Transportation Research Part E: Logistics and Transportation Review\n  (https://doi.org/10.1016/j.tre.2020.102090)", "journal-ref": "Transportation research part E: logistics and transportation\n  review, 143, 102090 (2020)", "doi": "10.1016/j.tre.2020.102090", "report-no": null, "categories": "cs.CY math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Expected to operate in the imminent future, air taxi service (ATS) is an\naerial on-demand transport for a single passenger or a small group of riders,\nwhich seeks to transform the method of everyday commute. This uncharted\nterritory in the emerging transportation world is anticipated to enable\nconsumers bypass traffic congestion in urban road networks. By adopting an\nelectric vertical takeoff and landing concept (eVTOL), air taxis could be\noperational from skyports retrofitted on building rooftops, thus gaining\nadvantage from an implementation standpoint. Motivated by the potential impact\nof ATS, this study provides a review of air taxi systems and associated\noperations. We first discuss the current developments in the ATS (demand\nprediction, air taxi network design, and vehicle configuration). Next, we\nanticipate potential future challenges of ATS from an operations management\nperspective, and review the existing literature that could be leveraged to\ntackle these problems (ride-matching, pricing strategies, vehicle maintenance\nscheduling, and pilot training and recruitment). Finally, we detail future\nresearch opportunities in the air taxi domain.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 22:48:03 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Rajendran", "Suchithra", ""], ["Srinivas", "Sharan", ""]]}, {"id": "2103.01769", "submitter": "Husein Osman Abdullahi Mr.", "authors": "Husein Osman Abdullahi, Abdikarim Abi Hassan, Murni Mahmud, Abdifatah\n  Farah Ali", "title": "Determinants of ICT Adoption Among Small Scale Agribusiness Enterprises\n  In Somalia", "comments": "9 pages, 2 figures", "journal-ref": "IJETT, 69(2), 68-76, 2021", "doi": "10.14445/22315381/IJETT-V69I2P210", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The use of Information and Communication Technology (ICT) can advance the\nAgricultural Business sector, particularly in a country seeking opportunities\nto explore the sector. There is evidence that ICT has made significant\ncontributions to agribusiness because it allows enterprises to manage their\noperations, and it has major impacts on the business. However, the critical\nfactors that motivate the adoption of new innovative technology by agribusiness\nenterprises are underexplored. The literature has indicated ICT adoption among\nsmall-scale agribusiness enterprises in Somalia is not fully understood.\nNevertheless, this study addresses this gap by investigating the adoption of\nICT among small-scale agribusiness enterprises in Somalia. The paper reports\nthe use of the Technology, Organization, Environment (TOE) framework. An online\nsurvey has been conducted with random sampling for data collection, with 107\nrespondents. The respondents are from agribusiness staff and farmers from\nvarious agricultural companies in Somalia. After quantitative data analysis,\nthe results indicated that relative advantage, complexity, top management\nsupport, and competitive pressure factors are significant contributors to ICT\nadoption in Somalian agribusiness enterprises, while ICT costs and vendor\nsupport are not significantly related to the adoption of ICT in agricultural\nbusiness. This study concludes that ICT adoption in Somalia is inspired by\ninsight and motivation rather than financial and external support.\nUnderstanding these factors leads to a better understanding of ICT adoption in\nSomalia. Additionally, it enriches the literature about the agriculture\nbusiness on the African continent\n  Keywords: Determinants, ICT Adoption, Agribusiness, Small Scale, TOE\nframework\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:25:15 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Abdullahi", "Husein Osman", ""], ["Hassan", "Abdikarim Abi", ""], ["Mahmud", "Murni", ""], ["Ali", "Abdifatah Farah", ""]]}, {"id": "2103.01773", "submitter": "Sabah Al-Fedaghi Dr.", "authors": "Sabah Al-Fedaghi", "title": "Conceptual Modeling for Computer Organization and Architecture", "comments": "11 pages, 12 figures", "journal-ref": "Journal of Computer Science 2021, 17 (2): 123.134", "doi": "10.3844/jcssp.2021.123.1324", "report-no": null, "categories": "cs.CY cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding computer system hardware, including how computers operate, is\nessential for undergraduate students in computer engineering and science.\nLiterature shows students learning computer organization and assembly language\noften find fundamental concepts difficult to comprehend within the topic\nmaterials. Tools have been introduced to improve students comprehension of the\ninteraction between computer architecture, assembly language, and the operating\nsystem. One such tool is the Little Man Computer (LMC) model that operates in a\nway similar to a computer but that is easier to understand. Even though LMC\ndoes not have modern CPUs with multiple cores nor executes multiple\ninstructions, it nevertheless shows the basic principles of the von Neumann\narchitecture. LMC aims to introduce students to such concepts as code and\ninstruction sets. In this paper, LMC is used for an additional purpose: a tool\nwith which to experiment using a new modeling language (i.e., a thinging\nmachine; TM) in the area of computer organization and architecture without\ninvolving complexity in the subject. That is, the simplicity of LMC facilitates\nthe application of TM without going deep into computer\norganization/architecture materials. Accordingly, the paper (a) provides a new\nway for using the LMC model for whatever purpose (e.g., education) and (b)\ndemonstrates that TM can be used to build an abstract level of description in\nthe organization/architect field. The resultant schematics from the TM model of\nLMC offer an initial case study that supports our thesis that TM is a viable\nmethod for hardware/software-independent descriptions in the computer\norganization and architect field of study.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 07:52:49 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Al-Fedaghi", "Sabah", ""]]}, {"id": "2103.01774", "submitter": "Henrietta Lyons", "authors": "Henrietta Lyons, Eduardo Velloso and Tim Miller", "title": "Conceptualising Contestability: Perspectives on Contesting Algorithmic\n  Decisions", "comments": null, "journal-ref": null, "doi": "10.1145/3449180", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of algorithmic systems in high-stakes decision-making increases,\nthe ability to contest algorithmic decisions is being recognised as an\nimportant safeguard for individuals. Yet, there is little guidance on what\n`contestability'--the ability to contest decisions--in relation to algorithmic\ndecision-making requires. Recent research presents different conceptualisations\nof contestability in algorithmic decision-making. We contribute to this growing\nbody of work by describing and analysing the perspectives of people and\norganisations who made submissions in response to Australia's proposed `AI\nEthics Framework', the first framework of its kind to include `contestability'\nas a core ethical principle. Our findings reveal that while the nature of\ncontestability is disputed, it is seen as a way to protect individuals, and it\nresembles contestability in relation to human decision-making. We reflect on\nand discuss the implications of these findings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:13:18 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Lyons", "Henrietta", ""], ["Velloso", "Eduardo", ""], ["Miller", "Tim", ""]]}, {"id": "2103.01776", "submitter": "Huansheng Ning Prof", "authors": "Sahraoui Dhelim, Huansheng Ning, Fadi Farha, Liming Chen, Luigi Atzori\n  and Mahmoud Daneshmand", "title": "IoT-Enabled Social Relationships Meet Artificial Social Intelligence", "comments": "IEEE Internet of Things Journal (2021)", "journal-ref": null, "doi": "10.1109/JIOT.2021.3081556", "report-no": null, "categories": "cs.CY cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advances of the Internet of Things, and the increasing\naccessibility of ubiquitous computing resources and mobile devices, the\nprevalence of rich media contents, and the ensuing social, economic, and\ncultural changes, computing technology and applications have evolved quickly\nover the past decade. They now go beyond personal computing, facilitating\ncollaboration and social interactions in general, causing a quick proliferation\nof social relationships among IoT entities. The increasing number of these\nrelationships and their heterogeneous social features have led to computing and\ncommunication bottlenecks that prevent the IoT network from taking advantage of\nthese relationships to improve the offered services and customize the delivered\ncontent, known as relationship explosion. On the other hand, the quick advances\nin artificial intelligence applications in social computing have led to the\nemerging of a promising research field known as Artificial Social Intelligence\n(ASI) that has the potential to tackle the social relationship explosion\nproblem. This paper discusses the role of IoT in social relationships detection\nand management, the problem of social relationships explosion in IoT and\nreviews the proposed solutions using ASI, including social-oriented\nmachine-learning and deep-learning techniques.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 09:07:32 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 19:43:27 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Dhelim", "Sahraoui", ""], ["Ning", "Huansheng", ""], ["Farha", "Fadi", ""], ["Chen", "Liming", ""], ["Atzori", "Luigi", ""], ["Daneshmand", "Mahmoud", ""]]}, {"id": "2103.01777", "submitter": "Pawe{\\l} Gora", "authors": "Paula Botella, Pawe{\\l} Gora, Martyna Sosnowska, Izabela Karsznia,\n  Sara Carvajal Querol", "title": "Modelling mobility and visualizing people's flow patterns in rural areas\n  for future infrastructure development as a good transnational land-governance\n  practice", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes a cross-border mobility study, origin-destination\nmobility modelling and visualization, conducted in support of the\ninfrastructure development efforts of local authorities and NGOs on the area\nover the Kayanga-Geba River, at the border between Senegal and Guinea Bissau.\nIt builds on the data collected through participatory mapping for the\nelaboration of the Cross-Border Land Management and Development Plans (Plans\nPAGET) aiming to harmonize the different national territorial management tools\ninto a unique transnational tool through the consideration of border areas as a\nterritorial unity. Despite a small amount of available mobility data, we were\nable to build a mobility model for the considered area, and implemented it in\nthe Traffic Simulation Framework, which was later used to calculate\norigin-destination matrices for the studied regions in two cases: with and\nwithout a cross-border mobility. We analyzed the differences in the mobility\npatterns and visualized the mobility flows, deliberating on what may be the\npotential impacts of building a bridge in the study area. Our methodology is\ngeneral and can be applied in similar studies on different areas. However, the\nquality of results may depend on the available data.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 09:52:29 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Botella", "Paula", ""], ["Gora", "Pawe\u0142", ""], ["Sosnowska", "Martyna", ""], ["Karsznia", "Izabela", ""], ["Querol", "Sara Carvajal", ""]]}, {"id": "2103.01778", "submitter": "Roee Shraga PhD", "authors": "Gregory Goren, Roee Shraga, Alexander Tuisov", "title": "OSOUM Framework for Trading Data Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decades, data have become a cornerstone component in many\nbusiness decisions, and copious resources are being poured into production and\nacquisition of the high-quality data. This emerging market possesses unique\nfeatures, and thus came under the spotlight for the stakeholders and\nresearchers alike. In this work, we aspire to provide the community with a set\nof tools for making business decisions, as well as analysis of markets behaving\naccording to certain rules. We supply, to the best of our knowledge, the first\nopen source simulation platform, termed Open SOUrce Market Simulator (OSOUM) to\nanalyze trading markets and specifically data markets. We also describe and\nimplement a specific data market model, consisting of two types of agents:\nsellers who own various datasets available for acquisition, and buyers\nsearching for relevant and beneficial datasets for purchase. The current\nsimulation treats data as an infinite supply product. Yet, other market\nsettings may be easily implemented using OSOUM. Although commercial frameworks,\nintended for handling data markets, already exist, we provide a free and\nextensive end-to-end research tool for simulating possible behavior for both\nbuyers and sellers participating in (data) markets.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 09:20:26 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Goren", "Gregory", ""], ["Shraga", "Roee", ""], ["Tuisov", "Alexander", ""]]}, {"id": "2103.01779", "submitter": "Omar Haggag", "authors": "Omar Haggag, Sherif Haggag, John Grundy, Mohamed Abdelrazek", "title": "COVID-19 vs Social Media Apps: Does Privacy Really Matter?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many people around the world are worried about using or even downloading\nCOVID-19 contact tracing mobile apps. The main reported concerns are centered\naround privacy and ethical issues. At the same time, people are voluntarily\nusing Social Media apps at a significantly higher rate during the pandemic\nwithout similar privacy concerns compared with COVID-19 apps. To better\nunderstand these seemingly anomalous behaviours, we analysed the privacy\npolicies, terms & conditions and data use agreements of the most commonly used\nCOVID-19, Social Media & Productivity apps. We also developed a tool to extract\nand analyse nearly 2 million user reviews for these apps. Our results show that\nSocial Media & Productivity apps actually have substantially higher privacy and\nethical issues compared with the majority of COVID-19 apps. Surprisingly, lots\nof people indicated in their user reviews that they feel more secure as their\nprivacy are better handled in COVID-19 apps than in Social Media apps. On the\nother hand, most of the COVID-19 apps are less accessible and stable compared\nto most Social Media apps, which negatively impacted their store ratings and\nled users to uninstall COVID-19 apps more frequently. Our findings suggest that\nin order to effectively fight this pandemic, health officials and technologists\nwill need to better raise awareness among people about COVID-19 app behaviour\nand trustworthiness. This will allow people to better understand COVID-19 apps\nand encourage them to download and use these apps. Moreover, COVID-19 apps need\nmany accessibility enhancements to allow a wider range of users from different\nsocieties and cultures to access to these apps.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 02:08:34 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Haggag", "Omar", ""], ["Haggag", "Sherif", ""], ["Grundy", "John", ""], ["Abdelrazek", "Mohamed", ""]]}, {"id": "2103.01858", "submitter": "Cristina Abad", "authors": "Cristina L. Abad and Alexandru Iosup and Edwin F. Boza and Eduardo\n  Ortiz-Holguin", "title": "An Analysis of Distributed Systems Syllabi With a Focus on\n  Performance-Related Topics", "comments": "Accepted for publication at WEPPE 2021, to be held in conjunction\n  with ACM/SPEC ICPE 2021: https://doi.org/10.1145/3447545.3451197 This article\n  is a follow-up of our prior ACM SIGCSE publication, arXiv:2012.00552", "journal-ref": null, "doi": "10.1145/3447545.3451197", "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a dataset of 51 current (2019-2020) Distributed Systems syllabi\nfrom top Computer Science programs, focusing on finding the prevalence and\ncontext in which topics related to performance are being taught in these\ncourses. We also study the scale of the infrastructure mentioned in DS courses,\nfrom small client-server systems to cloud-scale, peer-to-peer, global-scale\nsystems. We make eight main findings, covering goals such as performance, and\nscalability and its variant elasticity; activities such as performance\nbenchmarking and monitoring; eight selected performance-enhancing techniques\n(replication, caching, sharding, load balancing, scheduling, streaming,\nmigrating, and offloading); and control issues such as trade-offs that include\nperformance and performance variability.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 16:49:09 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Abad", "Cristina L.", ""], ["Iosup", "Alexandru", ""], ["Boza", "Edwin F.", ""], ["Ortiz-Holguin", "Eduardo", ""]]}, {"id": "2103.01924", "submitter": "Naser Damer", "authors": "Naser Damer, Fadi Boutros, Marius S\\\"u{\\ss}milch, Meiling Fang,\n  Florian Kirchbuchner, Arjan Kuijper", "title": "Masked Face Recognition: Human vs. Machine", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent COVID-19 pandemic has increased the focus on hygienic and\ncontactless identity verification methods. However, the pandemic led to the\nwide use of face masks, essential to keep the pandemic under control. The\neffect of wearing a mask on face recognition in a collaborative environment is\ncurrently sensitive yet understudied issue. Recent reports have tackled this by\nevaluating the masked probe effect on the performance of automatic face\nrecognition solutions. However, such solutions can fail in certain processes,\nleading to performing the verification task by a human expert. This work\nprovides a joint evaluation and in-depth analyses of the face verification\nperformance of human experts in comparison to state-of-the-art automatic face\nrecognition solutions. This involves an extensive evaluation with 12 human\nexperts and 4 automatic recognition solutions. The study concludes with a set\nof take-home messages on different aspects of the correlation between the\nverification behavior of human and machine.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 18:36:01 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 16:41:01 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Damer", "Naser", ""], ["Boutros", "Fadi", ""], ["S\u00fc\u00dfmilch", "Marius", ""], ["Fang", "Meiling", ""], ["Kirchbuchner", "Florian", ""], ["Kuijper", "Arjan", ""]]}, {"id": "2103.02052", "submitter": "Saurabh Mishra", "authors": "Saurabh Mishra and Kuansan Wang", "title": "Convergence and Inequality in Research Globalization", "comments": "19 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The catch-up effect and the Matthew effect offer opposing characterizations\nof globalization: the former predicts an eventual convergence as the poor can\ngrow faster than the rich due to free exchanges of complementary resources,\nwhile the latter, a deepening inequality between the rich and the poor. To\nunderstand these effects on the globalization of research, we conduct an\nin-depth study based on scholarly and patent publications covering STEM\nresearch from 218 countries/regions over the past four decades, covering more\nthan 55 million scholarly articles and 1.7 billion citations. Unique to this\ninvestigation is the simultaneous examination of both the research output and\nits impact in the same data set, using a novel machine learning based measure,\ncalled saliency, to mitigate the intrinsic biases in quantifying the research\nimpact. The results show that the two effects are in fact co-occurring: there\nare clear indications of convergence among the high income and upper middle\nincome countries across the STEM fields, but a widening gap is developing that\nsegregates the lower middle and low income regions from the higher income\nregions. Furthermore, the rate of convergence varies notably among the STEM\nsub-fields, with the highly strategic area of Artificial Intelligence (AI)\nsandwiched between fields such as Medicine and Materials Science that occupy\nthe opposite ends of the spectrum. The data support the argument that a leading\nexplanation of the Matthew effect, namely, the preferential attachment theory,\ncan actually foster the catch-up effect when organizations from lower income\ncountries forge substantial research collaborations with those already\ndominant. The data resoundingly show such collaborations benefit all parties\ninvolved, and a case of role reversal can be seen in the Materials Science\nfield where the most advanced signs of convergence are observed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 22:04:24 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Mishra", "Saurabh", ""], ["Wang", "Kuansan", ""]]}, {"id": "2103.02260", "submitter": "David Fischer", "authors": "Jiali Xing, David Fischer, Nitya Labh, Ryan Piersma, Benjamin C. Lee,\n  Yu Amy Xia, Tuhin Sahai, Vahid Tarokh", "title": "Talaria: A Framework for Simulation of Permissioned Blockchains for\n  Logistics and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Talaria, a novel permissioned blockchain simulator\nthat supports numerous protocols and use cases, most notably in supply chain\nmanagement. Talaria extends the capability of BlockSim, an existing blockchain\nsimulator, to include permissioned blockchains and serves as a foundation for\nfurther private blockchain assessment. Talaria is designed with both practical\nByzantine Fault Tolerance (pBFT) and simplified version of Proof-of-Authority\nconsensus protocols, but can be revised to include other permissioned protocols\nwithin its modular framework. Moreover, Talaria is able to simulate different\ntypes of malicious authorities and a variable daily transaction load at each\nnode. In using Talaria, business practitioners and policy planners have an\nopportunity to measure, evaluate, and adapt a range of blockchain solutions for\ncommercial operations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 08:43:30 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 00:22:10 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Xing", "Jiali", ""], ["Fischer", "David", ""], ["Labh", "Nitya", ""], ["Piersma", "Ryan", ""], ["Lee", "Benjamin C.", ""], ["Xia", "Yu Amy", ""], ["Sahai", "Tuhin", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2103.02524", "submitter": "Longqi Yang", "authors": "Jenna Butler, Mary Czerwinski, Shamsi Iqbal, Sonia Jaffe, Kate Nowak,\n  Emily Peloquin, Longqi Yang", "title": "Personal Productivity and Well-being -- Chapter 2 of the 2021 New Future\n  of Work Report", "comments": "In The New Future of Work: Research from Microsoft on the Impact of\n  the Pandemic on Work Practices, edited by Jaime Teevan, Brent Hecht, and\n  Sonia Jaffe, 1st ed. Microsoft, 2021. https://aka.ms/newfutureofwork", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.SE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We now turn to understanding the impact that COVID-19 had on the personal\nproductivity and well-being of information workers as their work practices were\nimpacted by remote work. This chapter overviews people's productivity,\nsatisfaction, and work patterns, and shows that the challenges and benefits of\nremote work are closely linked. Looking forward, the infrastructure surrounding\nwork will need to evolve to help people adapt to the challenges of remote and\nhybrid work.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 16:57:45 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Butler", "Jenna", ""], ["Czerwinski", "Mary", ""], ["Iqbal", "Shamsi", ""], ["Jaffe", "Sonia", ""], ["Nowak", "Kate", ""], ["Peloquin", "Emily", ""], ["Yang", "Longqi", ""]]}, {"id": "2103.02565", "submitter": "Somesh Mohapatra", "authors": "Somesh Mohapatra, Joyce An, Rafael G\\'omez-Bombarelli", "title": "Chemistry-informed Macromolecule Graph Representation for Similarity\n  Computation and Supervised Learning", "comments": "Main text: 6 pages, 3 figures, 1 table; Appendix: 21 pages, 26\n  figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY q-bio.BM q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Macromolecules are large, complex molecules composed of covalently bonded\nmonomer units, existing in different stereochemical configurations and\ntopologies. As a result of such chemical diversity, representing, comparing,\nand learning over macromolecules emerge as critical challenges. To address\nthis, we developed a macromolecule graph representation, with monomers and\nbonds as nodes and edges, respectively. We captured the inherent chemistry of\nthe macromolecule by using molecular fingerprints for node and edge attributes.\nFor the first time, we demonstrated computation of chemical similarity between\n2 macromolecules of varying chemistry and topology, using exact graph edit\ndistances and graph kernels. We trained interpretable graph neural networks for\na variety of glycan classification tasks, achieving state-of-the-art results.\nOur work has two-fold implications - it provides a general framework for\nrepresentation, comparison, and learning of macromolecules, and it enables\nquantitative chemistry-informed decision-making and iterative design in the\nmacromolecular chemical space.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 18:05:57 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 16:51:24 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Mohapatra", "Somesh", ""], ["An", "Joyce", ""], ["G\u00f3mez-Bombarelli", "Rafael", ""]]}, {"id": "2103.02699", "submitter": "Jeanne N. Clelland", "authors": "Jeanne N. Clelland, Nicholas Bossenbroek, Thomas Heckmaster, Adam\n  Nelson, Peter Rock, Jade VanAusdall", "title": "Compactness statistics for spanning tree recombination", "comments": "20 pages, 17 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ensemble analysis has become an important tool for quantifying\ngerrymandering; the main idea is to generate a large, random sample of\ndistricting plans (an \"ensemble\") to which any proposed plan may be compared.\nIf a proposed plan is an extreme outlier compared to the ensemble with regard\nto various redistricting criteria, this may indicate that the plan was\ndeliberately engineered to produce a specific outcome.\n  Many methods have been used to construct ensembles, and a fundamental\nquestion that arises is: Given a method for constructing plans, can we identify\na probability distribution on the space of plans that describes the probability\nof constructing any particular plan by that method?\n  Recently, MCMC methods have become a predominant tool for constructing\nensembles. Here we focus on the MCMC method known as \"ReCom,\" which was\nintroduced in 2018 by the MGGG Redistricting Lab. ReCom tends to produce plans\nwith more compact districts than some other methods, and we sought to better\nunderstand this phenomenon. We adopted a discrete analog of district perimeter\ncalled \"cut edges\" as a quantitative measure for district compactness; this\nmeasure was proposed by Duchin and Tenner, and it avoids some of the\ndifficulties associated with compactness measures based on geographic\nperimeter, such as the Polsby-Popper score.\n  To model the basic ReCom step, we constructed ensembles of 2-district plans\nfor two grid graphs and for the precinct graph of Boulder County, CO. We found\nthat the probability of sampling any particular plan -- which is roughly\nproportional to the product of the numbers of spanning trees for each of the\ntwo districts -- is also approximately proportional to an exponentially\ndecaying function of the number of cut edges in the plan. This is an important\nstep towards understanding compactness properties for districting plans\nproduced by the ReCom method.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 21:39:51 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 01:39:59 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Clelland", "Jeanne N.", ""], ["Bossenbroek", "Nicholas", ""], ["Heckmaster", "Thomas", ""], ["Nelson", "Adam", ""], ["Rock", "Peter", ""], ["VanAusdall", "Jade", ""]]}, {"id": "2103.02728", "submitter": "Cosmin Badea", "authors": "Cosmin Badea, Gregory Artus", "title": "Morality, Machines and the Interpretation Problem: A value-based,\n  Wittgensteinian approach to building Moral Agents", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the attempt to build morality into machines is subject to what\nwe call the Interpretation problem, whereby any rule we give the machine is\nopen to infinite interpretation in ways that we might morally disapprove of,\nand that the interpretation problem in Artificial Intelligence is an\nillustration of Wittgenstein's general claim that no rule can contain the\ncriteria for its own application. Using games as an example, we attempt to\ndefine the structure of normative spaces and argue that any rule-following\nwithin a normative space is guided by values that are external to that space\nand which cannot themselves be represented as rules. In light of this problem,\nwe analyse the types of mistakes an artificial moral agent could make and we\nmake suggestions about how to build morality into machines by getting them to\ninterpret the rules we give in accordance with these external values, through\nexplicit moral reasoning and the presence of structured values, the adjustment\nof causal power assigned to the agent and interaction with human agents, such\nthat the machine develops a virtuous character and the impact of the\ninterpretation problem is minimised.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 22:34:01 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Badea", "Cosmin", ""], ["Artus", "Gregory", ""]]}, {"id": "2103.02873", "submitter": "Bin Wang", "authors": "Bin Wang, Han Liu, Chao Liu, Zhiqiang Yang, Qian Ren, Huixuan Zheng,\n  Hong Lei", "title": "BLOCKEYE: Hunting For DeFi Attacks on Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decentralized finance, i.e., DeFi, has become the most popular type of\napplication on many public blockchains (e.g., Ethereum) in recent years.\nCompared to the traditional finance, DeFi allows customers to flexibly\nparticipate in diverse blockchain financial services (e.g., lending, borrowing,\ncollateralizing, exchanging etc.) via smart contracts at a relatively low cost\nof trust. However, the open nature of DeFi inevitably introduces a large attack\nsurface, which is a severe threat to the security of participants funds. In\nthis paper, we proposed BLOCKEYE, a real-time attack detection system for DeFi\nprojects on the Ethereum blockchain. Key capabilities provided by BLOCKEYE are\ntwofold: (1) Potentially vulnerable DeFi projects are identified based on an\nautomatic security analysis process, which performs symbolic reasoning on the\ndata flow of important service states, e.g., asset price, and checks whether\nthey can be externally manipulated. (2) Then, a transaction monitor is\ninstalled offchain for a vulnerable DeFi project. Transactions sent not only to\nthat project but other associated projects as well are collected for further\nsecurity analysis. A potential attack is flagged if a violation is detected on\na critical invariant configured in BLOCKEYE, e.g., Benefit is achieved within a\nvery short time and way much bigger than the cost. We applied BLOCKEYE in\nseveral popular DeFi projects and managed to discover potential security\nattacks that are unreported before. A video of BLOCKEYE is available at\nhttps://youtu.be/7DjsWBLdlQU.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 07:41:12 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Wang", "Bin", ""], ["Liu", "Han", ""], ["Liu", "Chao", ""], ["Yang", "Zhiqiang", ""], ["Ren", "Qian", ""], ["Zheng", "Huixuan", ""], ["Lei", "Hong", ""]]}, {"id": "2103.02917", "submitter": "Kalina Bontcheva", "authors": "Tracie Farrell, Mehmet Bakir, Kalina Bontcheva", "title": "MP Twitter Engagement and Abuse Post-first COVID-19 Lockdown in the UK:\n  White Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The UK has had a volatile political environment for some years now, with\nBrexit and leadership crises marking the past five years. With this work, we\nwanted to understand more about how the global health emergency, COVID-19,\ninfluences the amount, type or topics of abuse that UK politicians receive when\nengaging with the public. With this work, we wanted to understand more about\nhow the global health emergency, COVID-19, influences the amount, type or\ntopics of abuse that UK politicians receive when engaging with the public. This\nwork covers the period of June to December 2020 and analyses Twitter abuse in\nreplies to UK MPs. This work is a follow-up from our analysis of online abuse\nduring the first four months of the COVID-19 pandemic in the UK. The paper\nexamines overall abuse levels during this new seven month period, analyses\nreactions to members of different political parties and the UK government, and\nthe relationship between online abuse and topics such as Brexit, government's\nCOVID-19 response and policies, and social issues. In addition, we have also\nexamined the presence of conspiracy theories posted in abusive replies to MPs\nduring the period. We have found that abuse levels toward UK MPs were at an\nall-time high in December 2020 (5.4% of all reply tweets sent to MPs). This is\nalmost 1% higher that the two months preceding the General Election. In a\ndeparture from the trend seen in the first four months of the pandemic, MPs\nfrom the Tory party received the highest percentage of abusive replies from\nJuly 2020 onward, which stays above 5% starting from September 2020 onward, as\nthe COVID-19 crisis deepened and the Brexit negotiations with the EU started\nnearing completion.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 09:45:00 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 10:45:29 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Farrell", "Tracie", ""], ["Bakir", "Mehmet", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "2103.02982", "submitter": "Emad Grais", "authors": "Emad M. Grais, Xiaoya Wang, Jie Wang, Fei Zhao, Wen Jiang, Yuexin Cai,\n  Lifang Zhang, Qingwen Lin, Haidi Yang", "title": "Analysing Wideband Absorbance Immittance in Normal and Ears with Otitis\n  Media with Effusion Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wideband Absorbance Immittance (WAI) has been available for more than a\ndecade, however its clinical use still faces the challenges of limited\nunderstanding and poor interpretation of WAI results. This study aimed to\ndevelop Machine Learning (ML) tools to identify the WAI absorbance\ncharacteristics across different frequency-pressure regions in the normal\nmiddle ear and ears with otitis media with effusion (OME) to enable diagnosis\nof middle ear conditions automatically. Data analysis including pre-processing\nof the WAI data, statistical analysis and classification model development,\ntogether with key regions extraction from the 2D frequency-pressure WAI images\nare conducted in this study. Our experimental results show that ML tools appear\nto hold great potential for the automated diagnosis of middle ear diseases from\nWAI data. The identified key regions in the WAI provide guidance to\npractitioners to better understand and interpret WAI data and offer the\nprospect of quick and accurate diagnostic decisions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 12:07:36 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Grais", "Emad M.", ""], ["Wang", "Xiaoya", ""], ["Wang", "Jie", ""], ["Zhao", "Fei", ""], ["Jiang", "Wen", ""], ["Cai", "Yuexin", ""], ["Zhang", "Lifang", ""], ["Lin", "Qingwen", ""], ["Yang", "Haidi", ""]]}, {"id": "2103.03078", "submitter": "Philippe Burlina", "authors": "William Paul, Yinzhi Cao, Miaomiao Zhang, and Phil Burlina", "title": "Defending Medical Image Diagnostics against Privacy Attacks using\n  Generative Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models used in medical imaging diagnostics can be\nvulnerable to a variety of privacy attacks, including membership inference\nattacks, that lead to violations of regulations governing the use of medical\ndata and threaten to compromise their effective deployment in the clinic. In\ncontrast to most recent work in privacy-aware ML that has been focused on model\nalteration and post-processing steps, we propose here a novel and complementary\nscheme that enhances the security of medical data by controlling the data\nsharing process. We develop and evaluate a privacy defense protocol based on\nusing a generative adversarial network (GAN) that allows a medical data sourcer\n(e.g. a hospital) to provide an external agent (a modeler) a proxy dataset\nsynthesized from the original images, so that the resulting diagnostic systems\nmade available to model consumers is rendered resilient to privacy attackers.\nWe validate the proposed method on retinal diagnostics AI used for diabetic\nretinopathy that bears the risk of possibly leaking private information. To\nincorporate concerns of both privacy advocates and modelers, we introduce a\nmetric to evaluate privacy and utility performance in combination, and\ndemonstrate, using these novel and classical metrics, that our approach, by\nitself or in conjunction with other defenses, provides state of the art (SOTA)\nperformance for defending against privacy attacks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 15:02:57 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Paul", "William", ""], ["Cao", "Yinzhi", ""], ["Zhang", "Miaomiao", ""], ["Burlina", "Phil", ""]]}, {"id": "2103.03117", "submitter": "Andry Alamsyah", "authors": "Raden Johannes, Andry Alamsyah", "title": "Sales Prediction Model Using Classification Decision Tree Approach For\n  Small Medium Enterprise Based on Indonesian E-Commerce Data", "comments": null, "journal-ref": "The 6th Seminar & Conference on Business & Technology in ICT\n  Industry, 2015", "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growth of internet users in Indonesia gives an impact on many aspects of\ndaily life, including commerce. Indonesian small-medium enterprises took this\nadvantage of new media to derive their activity by the meaning of online\ncommerce. Until now, there is no known practical implementation of how to\npredict their sales and revenue using their historical transaction. In this\npaper, we build a sales prediction model on the Indonesian footwear industry\nusing real-life data crawled on Tokopedia, one of the biggest e-commerce\nproviders in Indonesia. Data mining is a discipline that can be used to gather\ninformation by processing the data. By using the method of classification in\ndata mining, this research will describe patterns of the market and predict the\npotential of the region in the national market commodities. Our approach is\nbased on the classification decision tree. We managed to determine predicted\nthe number of items sold by the viewers, price, and type of shoes.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 15:40:45 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Johannes", "Raden", ""], ["Alamsyah", "Andry", ""]]}, {"id": "2103.03120", "submitter": "Andry Alamsyah", "authors": "Andry Alamsyah, Dian Puteri Ramadhani, Farida Titik Kristanti", "title": "Event-Based Dynamic Banking Network Exploration for Economic Anomaly\n  Detection", "comments": "12 pages, 16 figures, 5 tables", "journal-ref": "Journal of Theoretical and Applied Information Technology, Issue\n  7, Vol. 98, page 1089-1100, 2020", "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The instability of financial system issues might trigger a bank failure,\nevoke spillovers, and generate contagion effects which negatively impacted the\nfinancial system, ultimately on the economy. This phenomenon is the result of\nthe highly interconnected banking transaction. The banking transactions network\nis considered as a financial architecture backbone. The strong\ninterconnectedness between banks escalates contagion disruption spreading over\nthe banking network and trigger the entire system collapse. This far, the\nfinancial instability is generally detected using macro approach mainly the\nuncontrolled transaction deficits amount and unpaid foreign debt. This research\nproposes financial instability detection in another point of view, through the\nmacro view where the banking network structure are explored globally and micro\nview where focuses on the detailed network patterns called motif. Network\ntriadic motif patterns used as a denomination to detect financial instability.\nThe most related network triadic motif changes related to the instability\nperiod are determined as a detector. We explore the banking network behavior\nunder financial instability phenomenon along with the major religious event in\nIndonesia, Eid al-Fitr. We discover one motif pattern as the financial\ninstability underlying detector. This research helps to support the financial\nsystem stability supervision.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 15:47:10 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Alamsyah", "Andry", ""], ["Ramadhani", "Dian Puteri", ""], ["Kristanti", "Farida Titik", ""]]}, {"id": "2103.03163", "submitter": "Wendy Ju", "authors": "Wendy Ju, Ilan Mandel, Kevin Weatherwax, Leila Takayama, Nikolas\n  Martelaro, Denis Willett", "title": "Remote Observation of Field Work on the Farm", "comments": "Presented at Microsoft Future of Work Symposium, August 3-5, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel restrictions and social distancing measures make it difficult to\nobserve, monitor or manage physical fieldwork. We describe research in progress\nthat applies technologies for real-time remote observation and conversation in\non-road vehicles to observe field work on a farm. We collaborated on a pilot\ndeployment of this project at Kreher Eggs in upstate New York. We instrumented\na tractor with equipment to remotely observe and interview farm workers\nperforming vehicle-related work. This work was initially undertaken to allow\nsustained observation of field work over longer periods of time from\ngeographically distant locales; given our current situation, this work provides\na case study in how to perform observational research when geographic and\nbodily distance have become the norm. We discuss our experiences and provide\nsome preliminary insights for others looking to conduct remote observational\nresearch in the field.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 17:10:09 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Ju", "Wendy", ""], ["Mandel", "Ilan", ""], ["Weatherwax", "Kevin", ""], ["Takayama", "Leila", ""], ["Martelaro", "Nikolas", ""], ["Willett", "Denis", ""]]}, {"id": "2103.03209", "submitter": "Kenji Saito", "authors": "Kenji Saito, Akimitsu Shiseki, Mitsuyasu Takada, Hiroki Yamamoto,\n  Masaaki Saitoh, Hiroaki Ohkawa, Hirofumi Andou, Naotake Miyamoto, Kazuaki\n  Yamakawa, Kiyoshi Kurakawa, Tomohiro Yabushita, Yuji Yamada, Go Masuda,\n  Kazuyuki Masuda", "title": "Requirement Analyses and Evaluations of Blockchain Platforms per\n  Possible Use Cases", "comments": "50 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is said that blockchain will contribute to the digital transformation of\nsociety in a wide range of ways, from the management of public and private\ndocuments to the traceability in various industries, as well as digital\ncurrencies. A number of so-called blockchain platforms have been developed, and\nexperiments and applications have been carried out on them. But are these\nplatforms really conducive to practical use of the blockchain concept?\n  To answer the question, we need to better understand what the technology\ncalled blockchain really is. We need to sort out the confusion we see in\nunderstanding what blockchain was invented for and what it means. We also need\nto clarify the structure of its applications.\n  This document provides a generic model of understanding blockchain and its\napplications. We introduce design patterns to classify the platforms. We\ncategorize possible use cases by identifying the structure among applications,\nand organize the functional, performance, operational and legal requirements\nfor each such case.\n  Based on the categorization and criteria, we evaluated and compared the\nfollowing platforms: Hyperledger Fabric, Hyperledger Iroha, Hyperledger Indy,\nEthereum, Quorum/Hyperledger Besu, Ethereum 2.0, Polkadot, Corda and BBc-1. We\nhave tried to be fair in our evaluations and comparisons, but we also expect to\nprovoke discussion.\n  The intended readers for this document is anyone involved in development of\napplication systems who wants to understand blockchain and their platforms,\nincluding non-engineers and non-technologists. The assessments in this document\nwill allow readers to understand the technological requirements for the\nblockchain platforms, to question existing technologies, and to choose the\nappropriate platforms for the applications they envision. The comparisons\nhopefully will also be useful as a guide for designing new technologies.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 18:27:57 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Saito", "Kenji", ""], ["Shiseki", "Akimitsu", ""], ["Takada", "Mitsuyasu", ""], ["Yamamoto", "Hiroki", ""], ["Saitoh", "Masaaki", ""], ["Ohkawa", "Hiroaki", ""], ["Andou", "Hirofumi", ""], ["Miyamoto", "Naotake", ""], ["Yamakawa", "Kazuaki", ""], ["Kurakawa", "Kiyoshi", ""], ["Yabushita", "Tomohiro", ""], ["Yamada", "Yuji", ""], ["Masuda", "Go", ""], ["Masuda", "Kazuyuki", ""]]}, {"id": "2103.03227", "submitter": "E K", "authors": "E.Kurshan, H. Shen", "title": "Graph Computing for Financial Crime and Fraud Detection: Trends,\n  Challenges and Outlook", "comments": "arXiv admin note: substantial text overlap with arXiv:2103.01854", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of digital payments has caused consequential changes in the\nfinancial crime landscape. As a result, traditional fraud detection approaches\nsuch as rule-based systems have largely become ineffective. AI and machine\nlearning solutions using graph computing principles have gained significant\ninterest in recent years. Graph-based techniques provide unique solution\nopportunities for financial crime detection. However, implementing such\nsolutions at industrial-scale in real-time financial transaction processing\nsystems has brought numerous application challenges to light. In this paper, we\ndiscuss the implementation difficulties current and next-generation graph\nsolutions face. Furthermore, financial crime and digital payments trends\nindicate emerging challenges in the continued effectiveness of the detection\ntechniques. We analyze the threat landscape and argue that it provides key\ninsights for developing graph-based solutions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 21:14:44 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Kurshan", "E.", ""], ["Shen", "H.", ""]]}, {"id": "2103.03332", "submitter": "Stefania Ionescu", "authors": "Stefania Ionescu, Aniko Hannak, Kenneth Joseph", "title": "An Agent-based Model to Evaluate Interventions on Online Dating\n  Platforms to Decrease Racial Homogamy", "comments": null, "journal-ref": null, "doi": "10.1145/3442188.3445904", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Perhaps the most controversial questions in the study of online platforms\ntoday surround the extent to which platforms can intervene to reduce the\nsocietal ills perpetrated on them. Up for debate is whether there exist any\neffective and lasting interventions a platform can adopt to address, e.g.,\nonline bullying, or if other, more far-reaching change is necessary to address\nsuch problems. Empirical work is critical to addressing such questions. But it\nis also challenging, because it is time-consuming, expensive, and sometimes\nlimited to the questions companies are willing to ask. To help focus and inform\nthis empirical work, we here propose an agent-based modeling (ABM) approach. As\nan application, we analyze the impact of a set of interventions on a simulated\nonline dating platform on the lack of long-term interracial relationships in an\nartificial society. In the real world, a lack of interracial relationships are\na critical vehicle through which inequality is maintained. Our work shows that\nmany previously hypothesized interventions online dating platforms could take\nto increase the number of interracial relationships from their website have\nlimited effects, and that the effectiveness of any intervention is subject to\nassumptions about sociocultural structure. Further, interventions that are\neffective in increasing diversity in long-term relationships are at odds with\nplatforms' profit-oriented goals. At a general level, the present work shows\nthe value of using an ABM approach to help understand the potential effects and\nside effects of different interventions that a platform could take.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 21:02:09 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Ionescu", "Stefania", ""], ["Hannak", "Aniko", ""], ["Joseph", "Kenneth", ""]]}, {"id": "2103.03351", "submitter": "Sanjay Rathee", "authors": "Sanjay Rathee and Sheah Lin Lee", "title": "So you want to be a Super Researcher?", "comments": "Available: https://researchmind.co.uk/super-researcher/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Publishing original scientific research is inherent to the work of a\nresearcher. However, the pressure to maintain productivity and scientific\nimpact can lead to research group publishing excessively, negatively affecting\nthe mental health of a researcher. Ph.D. students and early career researchers\nare particularly susceptible to this pressure due to the inherent vulnerability\nof their positions. At present, there are no resources that concisely summarise\nthe publication culture of a research group to help the researcher make an\ninformed decision before joining. In this article, we present the 'Super\nResearcher' app, an R Shiny application(app) with a user-friendly interface.\nUsing text-mining methodology to extract publicly available author data from\nScopus, this pilot app has four fundamental functions to provide snapshot\ninformation that will help researchers grasp the publication culture of a\nresearch group within minutes. The 'Super Researcher' app provides information\non: 1) institution data, 2) author's publication, 3) co-author network plots\nand 4) publication journals. The 'Super Researcher' app is built on R shiny\nwhich provides an interactive interface to users. This app utilizes the Big\nData framework Apache Spark to mine relevant information from a huge author\ninformation database. The author's information is stored and manipulated using\nboth SQL(SQLite) and NoSQL(HBase) databases. Hbase is used for local data\nstorage and manipulation while SQLite feeds data to the R Shiny interface. In\nthis paper, we introduce these functionalities and illustrate how this\ninformation can help guide a researcher to select a new Principle Investigator\n(PI) with better compatibility in terms of publication attitude using a case\nstudy.\n  Available: https://researchmind.co.uk/super-researcher/\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 02:11:57 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Rathee", "Sanjay", ""], ["Lee", "Sheah Lin", ""]]}, {"id": "2103.03409", "submitter": "Derek Weber", "authors": "Derek Weber and Frank Neumann", "title": "A General Method to Find Highly Coordinating Communities in Social Media\n  through Inferred Interaction Links", "comments": "58 pages, 25 figures, submitted to the International Journal of\n  Social Network Analysis and Mining (SNAM) as an expansion to an ASONAM'20\n  paper (arXiv:2010.08180)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Political misinformation, astroturfing and organised trolling are online\nmalicious behaviours with significant real-world effects. Many previous\napproaches examining these phenomena have focused on broad campaigns rather\nthan the small groups responsible for instigating or sustaining them. To reveal\nlatent (i.e., hidden) networks of cooperating accounts, we propose a novel\ntemporal window approach that relies on account interactions and metadata\nalone. It detects groups of accounts engaging in various behaviours that, in\nconcert, come to execute different goal-based strategies, a number of which we\ndescribe. The approach relies upon a pipeline that extracts relevant elements\nfrom social media posts, infers connections between accounts based on criteria\nmatching the coordination strategies to build an undirected weighted network of\naccounts, which is then mined for communities exhibiting high levels of\nevidence of coordination using a novel community extraction method. We address\nthe temporal aspect of the data by using a windowing mechanism, which may be\nsuitable for near real-time application. We further highlight consistent\ncoordination with a sliding frame across multiple windows and application of a\ndecay factor. Our approach is compared with other recent similar processing\napproaches and community detection methods and is validated against two\nrelevant datasets with ground truth data, using content, temporal, and network\nanalyses, as well as with the design, training and application of three\none-class classifiers built using the ground truth; its utility is furthermore\ndemonstrated in two case studies of contentious online discussions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 00:48:23 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Weber", "Derek", ""], ["Neumann", "Frank", ""]]}, {"id": "2103.03413", "submitter": "Yi-Lin Tsai", "authors": "Yi-Lin Tsai (1), Chetanya Rastogi (2), Peter K. Kitanidis (1, 3, and\n  4), Christopher B. Field (3, 5, and 6) ((1) Department of Civil and\n  Environmental Engineering, Stanford University, Stanford, CA, USA, (2)\n  Department of Computer Science, Stanford University, Stanford, CA, USA, (3)\n  Woods Institute for the Environment, Stanford University, Stanford, CA, USA,\n  (4) Institute for Computational and Mathematical Engineering, Stanford\n  University, Stanford, CA, USA, (5) Department of Biology, Stanford\n  University, Stanford, CA, USA, (6) Department of Earth System Science,\n  Stanford University, Stanford, CA, USA)", "title": "Routing algorithms as tools for integrating social distancing with\n  emergency evacuation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the implications of integrating social distancing with emergency\nevacuation, as would be expected when a hurricane approaches a city during the\nCOVID-19 pandemic. Specifically, we compare DNN (Deep Neural Network)-based and\nnon-DNN methods for generating evacuation strategies that minimize evacuation\ntime while allowing for social distancing in emergency vehicles. A central\nquestion is whether a DNN-based method provides sufficient extra routing\nefficiency to accommodate increased social distancing in a time-constrained\nevacuation operation. We describe the problem as a Capacitated Vehicle Routing\nProblem and solve it using a non-DNN solution (Sweep Algorithm) and a DNN-based\nsolution (Deep Reinforcement Learning). The DNN-based solution can provide\ndecision-makers with more efficient routing than the typical non-DNN routing\nsolution. However, it does not come close to compensating for the extra time\nrequired for social distancing, and its advantage disappears as the emergency\nvehicle capacity approaches the number of people per household.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 01:12:31 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 22:43:07 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 02:26:53 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Tsai", "Yi-Lin", "", "1, 3, and\n  4"], ["Rastogi", "Chetanya", "", "1, 3, and\n  4"], ["Kitanidis", "Peter K.", "", "1, 3, and\n  4"], ["Field", "Christopher B.", "", "3, 5, and 6"]]}, {"id": "2103.03482", "submitter": "William Wagner", "authors": "William Wagner, Anna \\'Zakowska, Clement Aladi, Joseph Santhosh", "title": "Pilot Investigation for a Comprehensive Taxonomy of Autonomous Entities", "comments": "15 pages, 4 figures, 7 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LO cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper documents an exploratory pilot study to define the term Autonomous\nEntity, and any characteristics that are required to identify or classify an\nAutonomous Entity. Our solution builds on previous work with regard to\nphilosophical and scientific classification methods but focuses on a novel\nDesign Science Research Methodology (DSRM) and model to help identify those\ncharacteristics which make any autonomous entity similar or different from\nothers. We have solved the problem of not having an existing term to define our\nlens by creating a new combinatorial term: \"Riskyishness\". We present a DSRM\nand instrument for initial investigation, as well as observational and\nstatistical descriptions of their use in the real world to solicit domain\nexpertise and statistical evidence. Further, we demonstrate a specific\napplication of the methodology by creating a second artifact - a tool to score\nexisting and future technologies based on Riskyishness. The first artifact also\nprovides a technique to disentangle miscellaneous existing technologies or add\ndimensions to the tools to capture future additions and paradigm shifts.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 05:51:40 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 07:33:26 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Wagner", "William", ""], ["\u0179akowska", "Anna", ""], ["Aladi", "Clement", ""], ["Santhosh", "Joseph", ""]]}, {"id": "2103.03544", "submitter": "Dejan Ni\\v{c}kovi\\'c", "authors": "Nadja Marko, Eike M\\\"ohlmann, Dejan Ni\\v{c}kovi\\'c, J\\\"urgen Niehaus,\n  Peter Priller, Martijn Rooker", "title": "Challenges of engineering safe and secure highly automated vehicles", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After more than a decade of intense focus on automated vehicles, we are still\nfacing huge challenges for the vision of fully autonomous driving to become a\nreality. The same \"disillusionment\" is true in many other domains, in which\nautonomous Cyber-Physical Systems (CPS) could considerably help to overcome\nsocietal challenges and be highly beneficial to society and individuals. Taking\nthe automotive domain, i.e. highly automated vehicles (HAV), as an example,\nthis paper sets out to summarize the major challenges that are still to\novercome for achieving safe, secure, reliable and trustworthy highly automated\nresp. autonomous CPS. We constrain ourselves to technical challenges,\nacknowledging the importance of (legal) regulations, certification,\nstandardization, ethics, and societal acceptance, to name but a few, without\ndelving deeper into them as this is beyond the scope of this paper. Four\nchallenges have been identified as being the main obstacles to realizing HAV:\nRealization of continuous, post-deployment systems improvement, handling of\nuncertainties and incomplete information, verification of HAV with machine\nlearning components, and prediction. Each of these challenges is described in\ndetail, including sub-challenges and, where appropriate, possible approaches to\novercome them. By working together in a common effort between industry and\nacademy and focusing on these challenges, the authors hope to contribute to\novercome the \"disillusionment\" for realizing HAV.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 08:52:31 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 21:27:51 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Marko", "Nadja", ""], ["M\u00f6hlmann", "Eike", ""], ["Ni\u010dkovi\u0107", "Dejan", ""], ["Niehaus", "J\u00fcrgen", ""], ["Priller", "Peter", ""], ["Rooker", "Martijn", ""]]}, {"id": "2103.03631", "submitter": "Emiliano De Cristofaro", "authors": "Yuping Wang, Savvas Zannettou, Jeremy Blackburn, Barry Bradlyn,\n  Emiliano De Cristofaro, and Gianluca Stringhini", "title": "A Multi-Platform Analysis of Political News Discussion and Sharing on\n  Web Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The news ecosystem has become increasingly complex, encompassing a wide range\nof sources with varying levels of trustworthiness, and with public commentary\ngiving different spins to the same stories. In this paper, we present a\nmulti-platform measurement of this ecosystem. We compile a list of 1,073 news\nwebsites and extract posts from four Web communities (Twitter, Reddit, 4chan,\nand Gab) that contain URLs from these sources. This yields a dataset of 38M\nposts containing 15M news URLs, spanning almost three years.\n  We study the data along several axes, assessing the trustworthiness of shared\nnews, designing a method to group news articles into stories, analyzing these\nstories are discussed and measuring the influence various Web communities have\nin that. Our analysis shows that different communities discuss different types\nof news, with polarized communities like Gab and /r/The_Donald subreddit\ndisproportionately referencing untrustworthy sources. We also find that fringe\ncommunities often have a disproportionate influence on other platforms w.r.t.\npushing narratives around certain news, for example about political elections,\nimmigration, or foreign policy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 12:27:28 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Wang", "Yuping", ""], ["Zannettou", "Savvas", ""], ["Blackburn", "Jeremy", ""], ["Bradlyn", "Barry", ""], ["De Cristofaro", "Emiliano", ""], ["Stringhini", "Gianluca", ""]]}, {"id": "2103.04118", "submitter": "Myounggyu Won", "authors": "Navid Mohammad Imran, Sabya Mishra, Myounggyu Won", "title": "Make Your Autonomous Vehicle Deliver And Earn Money for You", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The drone-based last-mile delivery is an emerging technology designed to\nautomate the delivery process by utilizing drones loaded on a truck to\ntransport parcels to customers. In this paper, we study the next level of\ndrone-based last-mile delivery where autonomous vehicles (AVs) without drivers\nare recruited to collaborate with drones to serve customers. We formulate the\nproblem of selecting AVs from a pool of available AVs and scheduling them to\nserve customers to minimize the total cost as an Integer Linear Programming\n(ILP). A novel greedy algorithm is proposed to solve the problem that\nincorporates the real-world operational cost of AVs, traveling distances\ncalculated based on Google Map API, and varying load capacities of AVs.\nExtensive simulations performed with numerous random delivery scenarios\ndemonstrate that both the optimal and greedy algorithms significantly increase\nprofits for the delivery company as well as the owners of AVs. Furthermore, the\nresults indicate that the greedy algorithm is highly effective with a\nperformance difference of only 2% compared with the optimal algorithm in terms\nof the total amount of profits.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 14:17:22 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Imran", "Navid Mohammad", ""], ["Mishra", "Sabya", ""], ["Won", "Myounggyu", ""]]}, {"id": "2103.04142", "submitter": "Ilias Politis Dr", "authors": "John C. Polley, Ilias Politis (Member, IEEE), Christos Xenakis\n  (Member, IEEE), Adarbad Master, and Micha{\\l} K\\k{e}pkowski", "title": "On an innovative architecture for digital immunity passports and\n  vaccination certificates", "comments": "This work has been funded in part with Federal funds from the\n  National Institutes of Health, Department of Health and Human Services, under\n  Contract No. 75N91020C00035 and in part by the European Union's Horizon 2020\n  Stimulating innovation by means of cross-fertilisation of knowledge program\n  under Grant 824015 (H2020-MSCA-RISE-2018-INCOGNITO) and the Grant 826404\n  (H2020-SC1-FA-DTS-2018-1-CUREX)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the COVID-19 pandemic entering a second phase and vaccination strategies\nbeing applied by countries and governments worldwide, there is an increasing\nexpectation by people to return to normal life. There is currently a debate\nabout immunity passports, privacy, and the enablement of individuals to safely\nenter everyday social life, workplace, and travel. Such digital immunity\npassports and vaccination certificates should meet people's expectations for\nprivacy while enabling them to present to 3rd party verifiers tamper-evident\ncredentials. This paper provides a comprehensive answer to the technological,\nethical and security challenges, by proposing an architecture that provides to\nindividuals, employers, and government agencies, a digital, decentralized,\nportable, immutable, and non-refutable health status cryptographic proof. It\ncan be used to evaluate the risk of allowing individuals to return to work,\ntravel, and public life activities.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 15:35:24 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 15:28:17 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 15:57:17 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 09:15:11 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Polley", "John C.", "", "Member, IEEE"], ["Politis", "Ilias", "", "Member, IEEE"], ["Xenakis", "Christos", "", "Member, IEEE"], ["Master", "Adarbad", ""], ["K\u0119pkowski", "Micha\u0142", ""]]}, {"id": "2103.04209", "submitter": "Jacob Sunshine", "authors": "Jacob Sunshine", "title": "Smart Speakers, the Next Frontier in Computational Health", "comments": "8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid dissemination and adoption of smart speakers has enabled\nsubstantial opportunities to improve human health. Just as the introduction of\nthe mobile phone led to considerable health innovation, smart speaker computing\nsystems carry several unique advantages that have the potential to catalyze new\nfields of health research, particularly in out-of-hospital environments. The\nrecent rise and ubiquity of these smart computing systems hold significant\npotential for enhancing chronic disease management, enabling passive\nidentification of unwitnessed medical emergencies, detecting subtle changes in\nhuman behavior and cognition, limiting isolation, and potentially allowing\nwidespread, passive, remote monitoring of respiratory diseases that impact the\npublic health. There are 3 broad mechanisms for how a smart speaker can\ninteract with a person to improve health. These include (i) as an intelligent\nconversational agent, (ii) a passive identifier of medically relevant\ndiagnostic sounds and (iii) active sensing using the device's internal hardware\nto measure physiologic parameters, such as with active sonar, radar or computer\nvision. Each of these different modalities have specific clinical use cases,\nall of which need to be balanced against potential privacy concerns, equity\nrelated to system access and regulatory frameworks which have not yet been\ndeveloped for this unique type of passive data collection.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 23:13:02 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Sunshine", "Jacob", ""]]}, {"id": "2103.04243", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Ziteng Cui, Yifan Wu, Lin Gu, Tatsuya Harada", "title": "Estimating and Improving Fairness with Adversarial Learning", "comments": "12 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fairness and accountability are two essential pillars for trustworthy\nArtificial Intelligence (AI) in healthcare. However, the existing AI model may\nbe biased in its decision marking. To tackle this issue, we propose an\nadversarial multi-task training strategy to simultaneously mitigate and detect\nbias in the deep learning-based medical image analysis system. Specifically, we\npropose to add a discrimination module against bias and a critical module that\npredicts unfairness within the base classification model. We further impose an\northogonality regularization to force the two modules to be independent during\ntraining. Hence, we can keep these deep learning tasks distinct from one\nanother, and avoid collapsing them into a singular point on the manifold.\nThrough this adversarial training method, the data from the underprivileged\ngroup, which is vulnerable to bias because of attributes such as sex and skin\ntone, are transferred into a domain that is neutral relative to these\nattributes. Furthermore, the critical module can predict fairness scores for\nthe data with unknown sensitive attributes. We evaluate our framework on a\nlarge-scale public-available skin lesion dataset under various fairness\nevaluation metrics. The experiments demonstrate the effectiveness of our\nproposed method for estimating and improving fairness in the deep\nlearning-based medical image analysis system.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 03:10:32 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 14:16:04 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Cui", "Ziteng", ""], ["Wu", "Yifan", ""], ["Gu", "Lin", ""], ["Harada", "Tatsuya", ""]]}, {"id": "2103.04442", "submitter": "Yash Vekaria", "authors": "Yash Vekaria, Vibhor Agarwal, Pushkal Agarwal, Sangeeta Mahapatra,\n  Sakthi Balan Muthiah, Nishanth Sastry, Nicolas Kourtellis", "title": "Differential Tracking Across Topical Webpages of Indian News Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Online user privacy and tracking have been extensively studied in recent\nyears, especially due to privacy and personal data-related legislations in the\nEU and the USA, such as the General Data Protection Regulation, ePrivacy\nRegulation, and California Consumer Privacy Act. Research has revealed novel\ntracking and personal identifiable information leakage methods that first- and\nthird-parties employ on websites around the world, as well as the intensity of\ntracking performed on such websites. However, for the sake of scaling to cover\na large portion of the Web, most past studies focused on homepages of websites,\nand did not look deeper into the tracking practices on their topical subpages.\nThe majority of studies focused on the Global North markets such as the EU and\nthe USA. Large markets such as India, which covers 20% of the world population\nand has no explicit privacy laws, have not been studied in this regard.\n  We aim to address these gaps and focus on the following research questions:\nIs tracking on topical subpages of Indian news websites different from their\nhomepage? Do third-party trackers prefer to track specific topics? How does\nthis preference compare to the similarity of content shown on these topical\nsubpages? To answer these questions, we propose a novel method for automatic\nextraction and categorization of Indian news topical subpages based on the\ndetails in their URLs. We study the identified topical subpages and compare\nthem with their homepages with respect to the intensity of cookie injection and\nthird-party embeddedness and type. We find differential user tracking among\nsubpages, and between subpages and homepages. We also find a preferential\nattachment of third-party trackers to specific topics. Also, embedded\nthird-parties tend to track specific subpages simultaneously, revealing\npossible user profiling in action.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 20:20:47 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Vekaria", "Yash", ""], ["Agarwal", "Vibhor", ""], ["Agarwal", "Pushkal", ""], ["Mahapatra", "Sangeeta", ""], ["Muthiah", "Sakthi Balan", ""], ["Sastry", "Nishanth", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2103.04448", "submitter": "Yang Shi", "authors": "Yang Shi, Krupal Shah, Wengran Wang, Samiha Marwan, Poorvaja Penmetsa\n  and Thomas W. Price", "title": "Toward Semi-Automatic Misconception Discovery Using Code Embeddings", "comments": "7 pages, 3 figures, Accepted in LAK'21", "journal-ref": null, "doi": "10.1145/3448139.3448205", "report-no": null, "categories": "cs.LG cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding students' misconceptions is important for effective teaching\nand assessment. However, discovering such misconceptions manually can be\ntime-consuming and laborious. Automated misconception discovery can address\nthese challenges by highlighting patterns in student data, which domain experts\ncan then inspect to identify misconceptions. In this work, we present a novel\nmethod for the semi-automated discovery of problem-specific misconceptions from\nstudents' program code in computing courses, using a state-of-the-art code\nclassification model. We trained the model on a block-based programming dataset\nand used the learned embedding to cluster incorrect student submissions. We\nfound these clusters correspond to specific misconceptions about the problem\nand would not have been easily discovered with existing approaches. We also\ndiscuss potential applications of our approach and how these misconceptions\ninform domain-specific insights into students' learning processes.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 20:32:41 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Shi", "Yang", ""], ["Shah", "Krupal", ""], ["Wang", "Wengran", ""], ["Marwan", "Samiha", ""], ["Penmetsa", "Poorvaja", ""], ["Price", "Thomas W.", ""]]}, {"id": "2103.04744", "submitter": "Anca Jurcut Dr.", "authors": "Guerrino Mazzarolo, Juan Carlos Fernandez Casas, Anca Delia Jurcut,\n  Nhien-AnLe-Khac", "title": "Protect Against Unintentional Insider Threats: The risk of an employee's\n  cyber misconduct on a Social Media Site", "comments": null, "journal-ref": "Crime and Justice in Digital soc. , Vol. I, Marleen Weulen\n  Kranenbarg and Rutger Leukfeldt (Eds): Cybercrime in Context,\n  978-3-030-60526-1, 498322_1_En, (Chapter 6), 2021", "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Social Media is a cyber-security risk for every business. What do people\nshare on the Internet? Almost everything about oneself is shared: friendship,\ndemographics, family, activities, and work-related information. This could\nbecome a potential risk in every business if the organization's policies,\ntraining and technology fail to properly address these issues. In many cases,\nit is the employees' behaviour that can put key company information at danger.\nSocial media has turned into a reconnaissance tool for malicious actors and\nusers accounts are now seen as a goldmine for cyber criminals. Investigation of\nSocial Media is in the embryonic stage and thus, is not yet well understood.\nThis research project aims to collect and analyse open-source data from\nLinkedIn, discover data leakage and analyse personality types through software\nas a service (SAAS). The final aim of the study is to understand if there are\nbehavioral factors that can predicting one's attitude toward disclosing\nsensitive data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 13:30:01 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Mazzarolo", "Guerrino", ""], ["Casas", "Juan Carlos Fernandez", ""], ["Jurcut", "Anca Delia", ""], ["Nhien-AnLe-Khac", "", ""]]}, {"id": "2103.04811", "submitter": "Suresh Kumar Mani", "authors": "Nataraj Kuntagod, Sanjay Podder, Satya Sai Srinivas Abbabathula,\n  Venkatesh Subramanian, Giju Mathew, Suresh Kumar Mani (Accenture)", "title": "A Framework for Enabling Safe and Resilient Food Factories for the\n  Public Feeding Programs", "comments": "4 pages, 3 figures. To appear ICSE Workshop on Software Engineering\n  for Healthcare, June 3, 2021, virtual", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public feeding programs continue to be a major source of nutrition to a large\npart of the population across the world. Any disruption to these activities,\nlike the one during the Covid-19 pandemic, can lead to adverse health outcomes,\nespecially among children. Policymakers and other stakeholders must balance the\nneed for continuing the feeding programs while ensuring the health and safety\nof workers engaged in the operations. This has led to several innovations that\nleverage advanced technologies like AI and IOT to monitor the health and safety\nof workers and ensure hygienic operations. However, there are practical\nchallenges in its implementation on a large scale. This paper presents an\nimplementation framework to build resilient public feeding programs using a\ncombination of intelligent technologies. The framework is a result of piloting\nthe technology solution at a facility run as part of a large mid-day meal\nfeeding program in India. Using existing resources like CCTV cameras and new\ntechnologies like AI and IOT, hygiene and safety compliance anomalies can be\ndetected and reported in a resource-efficient manner. It will guide\nstakeholders running public feeding programs as they seek to restart suspended\noperations and build systems that better adapt to future crises.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 15:12:44 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kuntagod", "Nataraj", "", "Accenture"], ["Podder", "Sanjay", "", "Accenture"], ["Abbabathula", "Satya Sai Srinivas", "", "Accenture"], ["Subramanian", "Venkatesh", "", "Accenture"], ["Mathew", "Giju", "", "Accenture"], ["Mani", "Suresh Kumar", "", "Accenture"]]}, {"id": "2103.04951", "submitter": "Jamie Duell MSc.", "authors": "Jamie Andrew Duell", "title": "A Comparative Approach to Explainable Artificial Intelligence Methods in\n  Application to High-Dimensional Electronic Health Records: Examining the\n  Usability of XAI", "comments": "18 Pages, 11 Figures, Supplementary work supporting a proposal - the\n  existing paper is open to future modification and further development post\n  arXiv submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explainable Artificial Intelligence (XAI) is a rising field in AI. It aims to\nproduce a demonstrative factor of trust, which for human subjects is achieved\nthrough communicative means, which Machine Learning (ML) algorithms cannot\nsolely produce, illustrating the necessity of an extra layer producing support\nto the model output. When approaching the medical field, we can see challenges\narise when dealing with the involvement of human-subjects, the ideology behind\ntrusting a machine to tend towards the livelihood of a human poses an ethical\nconundrum - leaving trust as the basis of the human-expert in acceptance to the\nmachines decision. The aim of this paper is to apply XAI methods to demonstrate\nthe usability of explainable architectures as a tertiary layer for the medical\ndomain supporting ML predictions and human-expert opinion, XAI methods produce\nvisualization of the feature contribution towards a given models output on both\na local and global level. The work in this paper uses XAI to determine feature\nimportance towards high-dimensional data-driven questions to inform\ndomain-experts of identifiable trends with a comparison of model-agnostic\nmethods in application to ML algorithms. The performance metrics for a\nglass-box method is also provided as a comparison against black-box capability\nfor tabular data. Future work will aim to produce a user-study using metrics to\nevaluate human-expert usability and opinion of the given models.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 18:15:52 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Duell", "Jamie Andrew", ""]]}, {"id": "2103.05154", "submitter": "Daniel Omeiza A", "authors": "Daniel Omeiza, Helena Webb, Marina Jirotka, Lars Kunze", "title": "Explanations in Autonomous Driving: A Survey", "comments": "18 pages, 5 Tables and 3 Figures. Submitted to the IEEE Transaction\n  on Intelligent Transportation Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The automotive industry is seen to have witnessed an increasing level of\ndevelopment in the past decades; from manufacturing manually operated vehicles\nto manufacturing vehicles with high level of automation. With the recent\ndevelopments in Artificial Intelligence (AI), automotive companies now employ\nhigh performance AI models to enable vehicles to perceive their environment and\nmake driving decisions with little or no influence from a human. With the hope\nto deploy autonomous vehicles (AV) on a commercial scale, the acceptance of AV\nby society becomes paramount and may largely depend on their degree of\ntransparency, trustworthiness, and compliance to regulations. The assessment of\nthese acceptance requirements can be facilitated through the provision of\nexplanations for AVs' behaviour. Explainability is therefore seen as an\nimportant requirement for AVs. AVs should be able to explain what they have\n'seen', done and might do in environments where they operate. In this paper, we\nprovide a comprehensive survey of the existing work in explainable autonomous\ndriving. First, we open by providing a motivation for explanations and\nexamining existing standards related to AVs. Second, we identify and categorise\nthe different stakeholders involved in the development, use, and regulation of\nAVs and show their perceived need for explanation. Third, we provide a taxonomy\nof explanations and reviewed previous work on explanation in the different AV\noperations. Finally, we draw a close by pointing out pertinent challenges and\nfuture research directions. This survey serves to provide fundamental knowledge\nrequired of researchers who are interested in explanation in autonomous\ndriving.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 00:31:30 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 15:51:59 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Omeiza", "Daniel", ""], ["Webb", "Helena", ""], ["Jirotka", "Marina", ""], ["Kunze", "Lars", ""]]}, {"id": "2103.05252", "submitter": "Julius Garcia", "authors": "Julius G. Garcia, Connie C. Aunario", "title": "Implementation of Departmental and Periodical Examination Analyzer\n  System", "comments": null, "journal-ref": "Science and Technology Conference 2015 - Electrical & Electronics,\n  Telecommunications, Information Technology, and Automation Symposium, 2015\n  pp. 212-218", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Administering examinations both in public and private academic institutions\ncan be tedious and unmanageable. The multiplicity of problems affecting the\nconduct of departmental and periodical examination can be greatly reduced by\nautomating the examination process. The purpose of this action research is to\nprovide an alternative technical solution in administering test through the use\nof Examination System. This software application can facilitate a plenitude of\nexaminees for different subjects that implements a random questioning technique\nand can generate item analysis and test results. The Departmental and\nPeriodical Examination System was developed using Visual Basic language. The\nsoftware modules were tested using the functional testing method. Using the\ncriteria and metrics of ISO 9126 software quality model, the system was\nevaluated by a group of students, teachers, school administrators and\ninformation technology professionals and has received an overall weighted mean\nof 4.56585 with an excellent descriptive rating. Therefore, the performance of\nthe application software provides solution that can surmount the gargantuan\nproblems of test administration and post-examination issues and performs all\nthe operations specified in the objectives.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 06:47:20 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Garcia", "Julius G.", ""], ["Aunario", "Connie C.", ""]]}, {"id": "2103.05309", "submitter": "Gianluca Schiavo", "authors": "Gianluca Schiavo, Ornella Mich, Michela Ferron, Nadia Mana", "title": "Trade-offs in the Design of Multimodal Interaction for Older Adults", "comments": null, "journal-ref": "Behaviour & Information Technology, 2020", "doi": "10.1080/0144929X.2020.1851768", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents key aspects and trade-offs that designers and\nHuman-Computer Interaction practitioners might encounter when designing\nmultimodal interaction for older adults. The paper gathers literature on\nmultimodal interaction and assistive technology, and describes a set of design\nchallenges specific for older users. Building on these main design challenges,\nfour trade-offs in the design of multimodal technology for this target group\nare presented and discussed. To highlight the relevance of the trade-offs in\nthe design process of multimodal technology for older adults, two of the four\nreported trade-offs are illustrated with two user studies that explored mid-air\nand speech-based interaction with a tablet device. The first study investigates\nthe design trade-offs related to redundant multimodal commands in older,\nmiddle-aged and younger adults, whereas the second one investigates the design\nchoices related to the definition of a set of mid-air one-hand gestures and\nvoice input commands. Further reflections highlight the design trade-offs that\nsuch considerations bring in the process, presenting an overview of the design\nchoices involved and of their potential consequences.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 09:12:16 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Schiavo", "Gianluca", ""], ["Mich", "Ornella", ""], ["Ferron", "Michela", ""], ["Mana", "Nadia", ""]]}, {"id": "2103.05434", "submitter": "Tae Wan Kim", "authors": "Tae Wan Kim, Tong (Joy) Lu, Kyusong Lee, Zhaoqi Cheng, Yanhan Tang,\n  and John Hooker", "title": "When is it permissible for artificial intelligence to lie? A trust-based\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Conversational Artificial Intelligence (AI) used in industry settings can be\ntrained to closely mimic human behaviors, including lying and deception.\nHowever, lying is often a necessary part of negotiation. To address this, we\ndevelop a normative framework for when it is ethical or unethical for a\nconversational AI to lie to humans, based on whether there is what we call\n\"invitation of trust\" in a particular scenario. Importantly, cultural norms\nplay an important role in determining whether there is invitation of trust\nacross negotiation settings, and thus an AI trained in one culture may not be\ngeneralizable to others. Moreover, individuals may have different expectations\nregarding the invitation of trust and propensity to lie for human vs. AI\nnegotiators, and these expectations may vary across cultures as well. Finally,\nwe outline how a conversational chatbot can be trained to negotiate ethically\nby applying autoregressive models to large dialog and negotiations datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 14:24:29 GMT"}, {"version": "v2", "created": "Sun, 14 Mar 2021 00:24:07 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Kim", "Tae Wan", "", "Joy"], ["Tong", "", "", "Joy"], ["Lu", "", ""], ["Lee", "Kyusong", ""], ["Cheng", "Zhaoqi", ""], ["Tang", "Yanhan", ""], ["Hooker", "John", ""]]}, {"id": "2103.05479", "submitter": "Satoshi Takahashi", "authors": "Satoshi Takahashi and Masaki Kitazawa and Ryoma Aoki and Atsushi\n  Yoshikawa", "title": "PEAK SHIFT ESTIMATION A novel method to estimate ranking of selectively\n  omitted examination data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we focus on examination results when examinees selectively\nskip examinations, to compare the difficulty levels of these examinations. We\ncall the resultant data 'selectively omitted examination data' Examples of this\ntype of examination are university entrance examinations, certification\nexaminations, and the outcome of students' job-hunting activities. We can learn\nthe number of students accepted for each examination and organization but not\nthe examinees' identity. No research has focused on this type of data. When we\nknow the difficulty level of these examinations, we can obtain a new index to\nassess organization ability, how many students pass, and the difficulty of the\nexaminations. This index would reflect the outcomes of their education\ncorresponding to perspectives on examinations. Therefore, we propose a novel\nmethod, Peak Shift Estimation, to estimate the difficulty level of an\nexamination based on selectively omitted examination data. First, we apply Peak\nShift Estimation to the simulation data and demonstrate that Peak Shift\nEstimation estimates the rank order of the difficulty level of university\nentrance examinations very robustly. Peak Shift Estimation is also suitable for\nestimating a multi-level scale for universities, that is, A, B, C, and D rank\nuniversity entrance examinations. We apply Peak Shift Estimation to real data\nof the Tokyo metropolitan area and demonstrate that the rank correlation\ncoefficient between difficulty level ranking and true ranking is 0.844 and that\nthe difference between 80 percent of universities is within 25 ranks. The\naccuracy of Peak Shift Estimation is thus low and must be improved; however,\nthis is the first study to focus on ranking selectively omitted examination\ndata, and therefore, one of our contributions is to shed light on this method.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 15:11:00 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Takahashi", "Satoshi", ""], ["Kitazawa", "Masaki", ""], ["Aoki", "Ryoma", ""], ["Yoshikawa", "Atsushi", ""]]}, {"id": "2103.05494", "submitter": "Pedro Almir Martins De Oliveira", "authors": "Pedro Almir Martins de Oliveira, Pedro de Alc\\^antara dos Santos Neto,\n  Gleison Silva, Irvayne Ibiapina, Werney Lira, Rossana Maria de Castro Andrade", "title": "Software Development During COVID-19 Pandemic: an Analysis of Stack\n  Overflow and GitHub", "comments": "8 pages, 8 figures, 3rd ICSE Workshop on Software Engineering for\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The new coronavirus became a severe health issue for the world. This\nsituation has motivated studies of different areas to combat this pandemic. In\nsoftware engineering, we point out data visualization projects to follow the\ndisease evolution, machine learning to estimate the pandemic behavior, and\ncomputer vision processing radiologic images. Most of these projects are stored\nin version control systems, and there are discussions about them in Question &\nAnswer websites. In this work, we conducted a Mining Software Repository on a\nlarge number of questions and projects aiming to find trends that could help\nresearchers and practitioners to fight against the coronavirus. We analyzed\n1,190 questions from Stack Overflow and Data Science Q\\&A and 60,352 GitHub\nprojects. We identified a correlation between the questions and projects\nthroughout the pandemic. The main questions about coronavirus are how-to,\nrelated to web scraping and data visualization, using Python, JavaScript, and\nR. The most recurrent GitHub projects are machine learning projects, using\nJavaScript, Python, and Java.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 15:28:34 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["de Oliveira", "Pedro Almir Martins", ""], ["Neto", "Pedro de Alc\u00e2ntara dos Santos", ""], ["Silva", "Gleison", ""], ["Ibiapina", "Irvayne", ""], ["Lira", "Werney", ""], ["Andrade", "Rossana Maria de Castro", ""]]}, {"id": "2103.05533", "submitter": "Daniel Lopes", "authors": "Daniel Lopes, J\\'essica Parente, Pedro Silva, Lic\\'inio Roque,\n  Penousal machado", "title": "Performing Creativity With Computational Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The introduction of new tools in people's workflow has always been promotive\nof new creative paths. This paper discusses the impact of using computational\ntools in the performance of creative tasks, especially focusing on graphic\ndesign. The study was driven by a grounded theory methodology, applied to a set\nof semi-structured interviews, made to twelve people working in the areas of\ngraphic design, data science, computer art, music and data visualisation. Among\nother questions, the results suggest some scenarios in which it is or it is not\nworth investing in the development of new intelligent creativity-aiding tools.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 16:24:43 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 10:38:26 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Lopes", "Daniel", ""], ["Parente", "J\u00e9ssica", ""], ["Silva", "Pedro", ""], ["Roque", "Lic\u00ednio", ""], ["machado", "Penousal", ""]]}, {"id": "2103.05544", "submitter": "Felix Engelmann", "authors": "Dominik Mei{\\ss}ner, Felix Engelmann, Frank Kargl, Benjamin Erb", "title": "PeQES: A Platform for Privacy-enhanced Quantitative Empirical Studies", "comments": "To be published in the 36th ACM/SIGAPP Symposium on Applied Computing\n  (SAC '21)", "journal-ref": null, "doi": "10.1145/3412841.3441997", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Empirical sciences and in particular psychology suffer a methodological\ncrisis due to the non-reproducibility of results, and in rare cases,\nquestionable research practices. Pre-registered studies and the publication of\nraw data sets have emerged as effective countermeasures. However, this approach\nrepresents only a conceptual procedure and may in some cases exacerbate privacy\nissues associated with data publications. We establish a novel,\nprivacy-enhanced workflow for pre-registered studies. We also introduce PeQES,\na corresponding platform that technically enforces the appropriate execution\nwhile at the same time protecting the participants' data from unauthorized use\nor data repurposing. Our PeQES prototype proves the overall feasibility of our\nprivacy-enhanced workflow while introducing only a negligible performance\noverhead for data acquisition and data analysis of an actual study. Using\ntrusted computing mechanisms, PeQES is the first platform to enable\nprivacy-enhanced studies, to ensure the integrity of study protocols, and to\nsafeguard the confidentiality of participants' data at the same time.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 16:46:25 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Mei\u00dfner", "Dominik", ""], ["Engelmann", "Felix", ""], ["Kargl", "Frank", ""], ["Erb", "Benjamin", ""]]}, {"id": "2103.05666", "submitter": "Christoph Gote", "authors": "Christoph Gote and Christian Zingg", "title": "gambit -- An Open Source Name Disambiguation Tool for Version Control\n  Systems", "comments": "MSR 2021, 10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Name disambiguation is a complex but highly relevant challenge whenever\nanalysing real-world user data, such as data from version control systems. We\npropose gambit, a rule-based disambiguation tool that only relies on name and\nemail information. We evaluate its performance against two commonly used\nalgorithms with similar characteristics on manually disambiguated ground-truth\ndata from the Gnome GTK project. Our results show that gambit significantly\noutperforms both algorithms, achieving an F1 score of 0.985.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 19:10:31 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Gote", "Christoph", ""], ["Zingg", "Christian", ""]]}, {"id": "2103.05827", "submitter": "Hoda Heidari", "authors": "Hoda Heidari, Solon Barocas, Jon Kleinberg, and Karen Levy", "title": "On Modeling Human Perceptions of Allocation Policies with Uncertain\n  Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many policies allocate harms or benefits that are uncertain in nature: they\nproduce distributions over the population in which individuals have different\nprobabilities of incurring harm or benefit. Comparing different policies thus\ninvolves a comparison of their corresponding probability distributions, and we\nobserve that in many instances the policies selected in practice are hard to\nexplain by preferences based only on the expected value of the total harm or\nbenefit they produce. In cases where the expected value analysis is not a\nsufficient explanatory framework, what would be a reasonable model for societal\npreferences over these distributions? Here we investigate explanations based on\nthe framework of probability weighting from the behavioral sciences, which over\nseveral decades has identified systematic biases in how people perceive\nprobabilities. We show that probability weighting can be used to make\npredictions about preferences over probabilistic distributions of harm and\nbenefit that function quite differently from expected-value analysis, and in a\nnumber of cases provide potential explanations for policy preferences that\nappear hard to motivate by other means. In particular, we identify optimal\npolicies for minimizing perceived total harm and maximizing perceived total\nbenefit that take the distorting effects of probability weighting into account,\nand we discuss a number of real-world policies that resemble such allocational\nstrategies. Our analysis does not provide specific recommendations for policy\nchoices, but is instead fundamentally interpretive in nature, seeking to\ndescribe observed phenomena in policy choices.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 02:22:08 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Heidari", "Hoda", ""], ["Barocas", "Solon", ""], ["Kleinberg", "Jon", ""], ["Levy", "Karen", ""]]}, {"id": "2103.05862", "submitter": "Katie Seaborn", "authors": "Katie Seaborn", "title": "Removing Gamification: A Research Agenda", "comments": "Accepted at CHI EA 2021", "journal-ref": null, "doi": "10.1145/3411763.3451695", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The effect of removing gamification elements from interactive systems has\nbeen a long-standing question in gamification research. Early work and\nfoundational theories raised concerns about the endurance of positive effects\nand the emergence of negative ones. Yet, nearly a decade later, no work to date\nhas sought consensus on these matters. Here, I offer a rapid review on the\nstate of the art and what is known about the impact of removing gamification. A\nsmall corpus of 8 papers published between 2012 and 2020 were found. Findings\nsuggest a mix of positive and negative effects related to removing\ngamification. Significantly, insufficient reporting, methodological weaknesses,\nlimited measures, and superficial interpretations of \"negative\" results prevent\nfirm conclusions. I offer a research agenda towards better understanding the\nnature of gamification removal. I end with a call for empirical and theoretical\nwork on illuminating the effects that may linger after systems are un-gamified.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 03:59:46 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 00:36:35 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Seaborn", "Katie", ""]]}, {"id": "2103.05927", "submitter": "James Lo", "authors": "Shi-Wei Lo, Jyh-Horng Wu, Jo-Yu Chang, Chien-Hao Tseng, Meng-Wei Lin,\n  Fang-Pang Lin", "title": "Deep Sensing of Urban Waterlogging", "comments": "19 pages, 14 figures, under submitting and patenting", "journal-ref": null, "doi": null, "report-no": "revise-2021-05-25", "categories": "cs.CV cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the monsoon season, sudden flood events occur frequently in urban areas,\nwhich hamper the social and economic activities and may threaten the\ninfrastructure and lives. The use of an efficient large-scale waterlogging\nsensing and information system can provide valuable real-time disaster\ninformation to facilitate disaster management and enhance awareness of the\ngeneral public to alleviate losses during and after flood disasters. Therefore,\nin this study, a visual sensing approach driven by deep neural networks and\ninformation and communication technology was developed to provide an end-to-end\nmechanism to realize waterlogging sensing and event-location mapping. The use\nof a deep sensing system in the monsoon season in Taiwan was demonstrated, and\nwaterlogging events were predicted on the island-wide scale. The system could\nsense approximately 2379 vision sources through an internet of video things\nframework and transmit the event-location information in 5 min. The proposed\napproach can sense waterlogging events at a national scale and provide an\nefficient and highly scalable alternative to conventional waterlogging sensing\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 08:34:37 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 03:43:52 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Lo", "Shi-Wei", ""], ["Wu", "Jyh-Horng", ""], ["Chang", "Jo-Yu", ""], ["Tseng", "Chien-Hao", ""], ["Lin", "Meng-Wei", ""], ["Lin", "Fang-Pang", ""]]}, {"id": "2103.05971", "submitter": "Bj\\\"orn Friedrich", "authors": "Bj\\\"orn Friedrich, Enno-Edzard Steen, Sebastian Fudickar, Andreas Hein", "title": "Analysing the Correlation of Geriatric Assessment Scores and Activity in\n  Smart Homes", "comments": "15 pages, 1 figure, 16 tables", "journal-ref": "International Journal of Ubiquitous Computing (IJU), Vol. 12, No.\n  1/2, April, 2021", "doi": "10.5121/iju.2021.12201", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A continuous monitoring of the physical strength and mobility of elderly\npeople is important for maintaining their health and treating diseases at an\nearly stage. However, frequent screenings by physicians are exceeding the\nlogistic capacities. An alternate approach is the automatic and unobtrusive\ncollection of functional measures by ambient sensors. In the current\npublication, we show the correlation among data of ambient motion sensors and\nthe well-established mobility assessments Short-Physical-Performance-Battery,\nTinetti and Timed Up & Go. We use the average number of motion sensor events as\nactivity measure for correlation with the assessment scores. The evaluation on\na real-world dataset shows a moderate to strong correlation with the scores of\nstandardised geriatrics physical assessments.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 10:04:47 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Friedrich", "Bj\u00f6rn", ""], ["Steen", "Enno-Edzard", ""], ["Fudickar", "Sebastian", ""], ["Hein", "Andreas", ""]]}, {"id": "2103.06051", "submitter": "Andry Alamsyah", "authors": "Andry Alamsyah, Yahya Peranginangin, Gabriel Nurhadi", "title": "Learning Organization using Conversational Social Network for Social\n  Customer Relationship Management Effort", "comments": "8 pages, 2 tables, 4 figures", "journal-ref": "The 2nd International Conference and Seminar on Learning\n  Organizations, 2014", "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The challenge of each organization is how they adapt to the shift of more\ncomplex technology such as mobile, big data, interconnected world, and the\nInternet of things. In order to achieve their objective, they must understand\nhow to take advantage of the interconnected individuals inside and outside the\norganization. Learning organization continues to transform by listening and\nmaintain the connection with their counterparts. Customer relationship\nmanagement is an important source for business organizations to grow and to\nassure their future. The complex social network, where interconnected peoples\nget information and get influenced very quickly, certainly a big challenge for\nbusiness organizations. The combination of these complex technologies provides\nintriguing insight such as the capabilities to listen to what the markets want,\nto understand their market competition, and to understand their market\nsegmentation. In this paper, as a part of organization transformation, we show\nhow a business organization mine online conversational in Twitter related to\ntheir brand issue and analyze them in the context of customer relationship\nmanagement to extract several insights regarding their market.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 13:49:53 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Alamsyah", "Andry", ""], ["Peranginangin", "Yahya", ""], ["Nurhadi", "Gabriel", ""]]}, {"id": "2103.06063", "submitter": "V\\'ictor Hugo Mas\\'ias H.", "authors": "V\\'ictor H. Mas\\'ias, Fernando Crespo, Pilar Navarro R., Razan Masood,\n  Nicole C. Kr\\\"amer, and H. Ulrich Hoppe", "title": "On spatial variation in the detectability and density of social media\n  user protest supporters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although much has been published regarding street protests on social media,\nfew works have attempted to characterize social media users' spatial behavior\nin such events. The research reported here uses spatial capture-recapture\nmethods to determine the influence of the built environment, physical proximity\nto protest location, and collective posting rhythm on variations in users'\nspatial detectability and density during a protest in Mexico City. The\nbest-obtained model, together with explaining the spatial density of users,\nshows that there is high variability in the detectability of social media user\nprotest supporters and that the collective posting rhythm and the day of\nobservation are significant explanatory factors. The implication is that\nstudies of collective spatial behavior would benefit by focussing on users'\nactivity centres and their urban environment, rather than their physical\nproximity to the protest location, the latter being unable to adequately\nexplain spatial variations in users' detectability and density during the\nprotest event.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 14:08:08 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Mas\u00edas", "V\u00edctor H.", ""], ["Crespo", "Fernando", ""], ["R.", "Pilar Navarro", ""], ["Masood", "Razan", ""], ["Kr\u00e4mer", "Nicole C.", ""], ["Hoppe", "H. Ulrich", ""]]}, {"id": "2103.06076", "submitter": "Hanna Wallach", "authors": "Solon Barocas, Anhong Guo, Ece Kamar, Jacquelyn Krones, Meredith\n  Ringel Morris, Jennifer Wortman Vaughan, Duncan Wadsworth, Hanna Wallach", "title": "Designing Disaggregated Evaluations of AI Systems: Choices,\n  Considerations, and Tradeoffs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several pieces of work have uncovered performance disparities by conducting\n\"disaggregated evaluations\" of AI systems. We build on these efforts by\nfocusing on the choices that must be made when designing a disaggregated\nevaluation, as well as some of the key considerations that underlie these\ndesign choices and the tradeoffs between these considerations. We argue that a\ndeeper understanding of the choices, considerations, and tradeoffs involved in\ndesigning disaggregated evaluations will better enable researchers,\npractitioners, and the public to understand the ways in which AI systems may be\nunderperforming for particular groups of people.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 14:26:14 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Barocas", "Solon", ""], ["Guo", "Anhong", ""], ["Kamar", "Ece", ""], ["Krones", "Jacquelyn", ""], ["Morris", "Meredith Ringel", ""], ["Vaughan", "Jennifer Wortman", ""], ["Wadsworth", "Duncan", ""], ["Wallach", "Hanna", ""]]}, {"id": "2103.06172", "submitter": "Sam Corbett-Davies", "authors": "Chlo\\'e Bakalar, Renata Barreto, Stevie Bergman, Miranda Bogen, Bobbie\n  Chern, Sam Corbett-Davies, Melissa Hall, Isabel Kloumann, Michelle Lam,\n  Joaquin Qui\\~nonero Candela, Manish Raghavan, Joshua Simons, Jonathan Tannen,\n  Edmund Tong, Kate Vredenburgh, Jiejing Zhao", "title": "Fairness On The Ground: Applying Algorithmic Fairness Approaches to\n  Production Systems", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many technical approaches have been proposed for ensuring that decisions made\nby machine learning systems are fair, but few of these proposals have been\nstress-tested in real-world systems. This paper presents an example of one\nteam's approach to the challenge of applying algorithmic fairness approaches to\ncomplex production systems within the context of a large technology company. We\ndiscuss how we disentangle normative questions of product and policy design\n(like, \"how should the system trade off between different stakeholders'\ninterests and needs?\") from empirical questions of system implementation (like,\n\"is the system achieving the desired tradeoff in practice?\"). We also present\nan approach for answering questions of the latter sort, which allows us to\nmeasure how machine learning systems and human labelers are making these\ntradeoffs across different relevant groups. We hope our experience integrating\nfairness tools and approaches into large-scale and complex production systems\nwill be useful to other practitioners facing similar challenges, and\nilluminating to academics and researchers looking to better address the needs\nof practitioners.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 16:42:20 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 17:15:40 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Bakalar", "Chlo\u00e9", ""], ["Barreto", "Renata", ""], ["Bergman", "Stevie", ""], ["Bogen", "Miranda", ""], ["Chern", "Bobbie", ""], ["Corbett-Davies", "Sam", ""], ["Hall", "Melissa", ""], ["Kloumann", "Isabel", ""], ["Lam", "Michelle", ""], ["Candela", "Joaquin Qui\u00f1onero", ""], ["Raghavan", "Manish", ""], ["Simons", "Joshua", ""], ["Tannen", "Jonathan", ""], ["Tong", "Edmund", ""], ["Vredenburgh", "Kate", ""], ["Zhao", "Jiejing", ""]]}, {"id": "2103.06412", "submitter": "Benzar Glen Grepon", "authors": "Benzar Glen Grepon", "title": "Designing and Implementing e-justice Systems: An Information Systems\n  Approach to Regional Trial Court Case Docket Management in Northern Mindanao,\n  Philippines", "comments": "11 pages", "journal-ref": "International Journal of Multidisciplinary Academic Research, 8\n  (2020) 44-54", "doi": "10.5281/zenodo.4459814", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer-based information systems for case management are still at an early\nstage of adoption in many trial courts in the Philippines. In most cases,\ninformation system implemented is the case docket using the official record\nbook on which cases are written and inventory of cases and reports are\ngenerated. This is a standalone system that often face data processing, data\nsecurity and case management challenges. However, there are examples of\nInformation systems in overcoming these pitfalls and producing innovative\nsolutions that surpass data management practices in in many trial courts in the\ncountry. One such case is the Regional Trial Court Branch 23 of Cagayan de Oro\nCity in Northern Mindanao, Philippines. A project named Web-based Case Docket\nInformation System (WCDIS) has been designed and developed for the court\nbranch. This system uses a framework known as System Development Life Cycle\n(SDLC) which is a guide for the design and development. This paper also\ndiscusses the key system functionalities and the implementation methodology,\nincluding both the benefits and shortcomings of this approach, with the goal of\napplying lessons learned for future installations. Foremost among the successes\nof this project is its ability to increase efficiency and reliability in\ncompleting court transactions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 01:59:58 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Grepon", "Benzar Glen", ""]]}, {"id": "2103.06446", "submitter": "Satoshi Takahashi", "authors": "Satoshi Takahashi and Hiroki Kuno and Atsushi Yoshikawa", "title": "Extracting candidate factors affecting long-term trends of student\n  abilities across subjects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Long-term student achievement data provide useful information to formulate\nthe research question of what types of student skills would impact future\ntrends across subjects. However, few studies have focused on long-term data.\nThis is because the criteria of examinations vary depending on their designers;\nadditionally, it is difficult for the same designer to maintain the coherence\nof the criteria of examinations beyond grades. To solve this inconsistency\nissue, we propose a novel approach to extract candidate factors affecting\nlong-term trends across subjects from long-term data. Our approach is composed\nof three steps: Data screening, time series clustering, and causal inference.\nThe first step extracts coherence data from long-term data. The second step\ngroups the long-term data by shape and value. The third step extracts factors\naffecting the long-term trends and validates the extracted variation factors\nusing two or more different data sets. We then conducted evaluation experiments\nwith student achievement data from five public elementary schools and four\npublic junior high schools in Japan. The results demonstrate that our approach\nextracts coherence data, clusters long-term data into interpretable groups, and\nextracts candidate factors affecting academic ability across subjects.\nSubsequently, our approach formulates a hypothesis and turns archived\nachievement data into useful information.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 04:13:58 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Takahashi", "Satoshi", ""], ["Kuno", "Hiroki", ""], ["Yoshikawa", "Atsushi", ""]]}, {"id": "2103.06503", "submitter": "Ching-Yao Chuang", "authors": "Ching-Yao Chuang, Youssef Mroueh", "title": "Fair Mixup: Fairness via Interpolation", "comments": null, "journal-ref": "ICLR 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training classifiers under fairness constraints such as group fairness,\nregularizes the disparities of predictions between the groups. Nevertheless,\neven though the constraints are satisfied during training, they might not\ngeneralize at evaluation time. To improve the generalizability of fair\nclassifiers, we propose fair mixup, a new data augmentation strategy for\nimposing the fairness constraint. In particular, we show that fairness can be\nachieved by regularizing the models on paths of interpolated samples between\nthe groups. We use mixup, a powerful data augmentation strategy to generate\nthese interpolates. We analyze fair mixup and empirically show that it ensures\na better generalization for both accuracy and fairness measurement in tabular,\nvision, and language benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 06:57:26 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Chuang", "Ching-Yao", ""], ["Mroueh", "Youssef", ""]]}, {"id": "2103.06515", "submitter": "Yuuki Nishiyama", "authors": "Yuuki Nishiyama, Yuui Kakino, Enishi Naka, Yuka Noda, Satsuki Hashiba,\n  Yusuke Yamada, Wataru Sasaki, Tadashi Okoshi, Jin Nakazawa, Masaki Mori,\n  Hisashi Mizutori, Kotomi Shiota, Tomohisa Nagano, Yuko Tokairin, Takaaki Kato", "title": "Physical Activity Analysis of College Students During the COVID-19\n  Pandemic Using Smartphones", "comments": "12 pages, in Japanese, 16 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the pandemic caused by the coronavirus disease of 2019 (COVID-19),\nseveral universities have closed their campuses for preventing the spread of\ninfection. Consequently, the university classes are being held over the\nInternet, and students attend these classes from their homes. While the\nCOVID-19 pandemic is expected to be prolonged, the online-centric lifestyle has\nraised concerns about secondary health issues caused by reduced physical\nactivity (PA). However, the actual status of PA among university students has\nnot yet been examined in Japan. Hence, in this study, we collected daily PA\ndata (including the data corresponding to the number of steps taken and the\ndata associated with six types of activities) by employing smartphones and\nthereby analyzed the changes in the PA of university students. The PA data were\ncollected over a period of ten weeks from 305 first-year university students\nwho were attending a mandatory class of physical education at the university.\nThe obtained results indicate that compared to the average number of steps\ntaken before the COVID-19 pandemic (6474.87 steps), the average number of steps\ntaken after the COVID-19 pandemic (3522.5 steps) has decreased by 45.6%.\nFurthermore, the decrease in commuting time (7 AM to 10 AM), classroom time,\nand extracurricular activity time (11 AM to 12 AM) has led to a decrease in PA\non weekdays owing to reduced unplanned exercise opportunities and has caused an\nincrease in the duration of being in the stationary state in the course of\ndaily life.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 08:02:37 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Nishiyama", "Yuuki", ""], ["Kakino", "Yuui", ""], ["Naka", "Enishi", ""], ["Noda", "Yuka", ""], ["Hashiba", "Satsuki", ""], ["Yamada", "Yusuke", ""], ["Sasaki", "Wataru", ""], ["Okoshi", "Tadashi", ""], ["Nakazawa", "Jin", ""], ["Mori", "Masaki", ""], ["Mizutori", "Hisashi", ""], ["Shiota", "Kotomi", ""], ["Nagano", "Tomohisa", ""], ["Tokairin", "Yuko", ""], ["Kato", "Takaaki", ""]]}, {"id": "2103.06621", "submitter": "Elochukwu Ukwandu Dr", "authors": "Celestine Ugwu, Casmir Ani, Modesta Ezema, Caroline Asogwa, Uchenna\n  Ome, Adaora Obayi, Deborah Ebem, Aminat Atanda and Elochukwu Ukwandu", "title": "Towards Determining the Effect of Age and Educational Level on\n  Cyber-Hygiene", "comments": "6 pages, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As internet related challenges increase such as cyber-attacks, the need for\nsafe practises among users to maintain computer system's health and online\nsecurity have become imperative, and this is known as cyber-hygiene. Poor\ncyber-hygiene among internet users is a very critical issue undermining the\ngeneral acceptance and adoption of internet technology. It has become a global\nissue and concern in this digital era when virtually all business transactions,\nlearning, communication and many other activities are performed online. Virus\nattack, poor authentication technique, improper file backups and the use of\ndifferent social engineering approaches by cyber-attackers to deceive internet\nusers into divulging their confidential information with the intention to\nattack them have serious negative implications on the industries and\norganisations, including educational institutions. Moreover, risks associated\nwith these ugly phenomena are likely to be more in developing countries such as\nNigeria. Thus, authors of this paper undertook an online pilot study among\nstudents and employees of University of Nigeria, Nsukka and a total of 145\nresponses were received and used for the study. The survey seeks to find out\nthe effect of age and level of education on the cyber hygiene knowledge and\nbehaviour of the respondents, and in addition, the type of devices used and\nactivities they engage in while on the internet. Our findings show wide\nadoption of internet in institution of higher learning, whereas, significant\nnumber of the internet users do not have good cyber hygiene knowledge and\nbehaviour. Hence, our findings can instigate an organised training for students\nand employees of higher institutions in Nigeria.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 11:42:23 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ugwu", "Celestine", ""], ["Ani", "Casmir", ""], ["Ezema", "Modesta", ""], ["Asogwa", "Caroline", ""], ["Ome", "Uchenna", ""], ["Obayi", "Adaora", ""], ["Ebem", "Deborah", ""], ["Atanda", "Aminat", ""], ["Ukwandu", "Elochukwu", ""]]}, {"id": "2103.06809", "submitter": "Tuomas Granlund", "authors": "Tuomas Granlund, Juha Vedenp\\\"a\\\"a, Vlad Stirbu and Tommi Mikkonen", "title": "On Medical Device Cybersecurity Compliance in EU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The medical device products at the European Union market must be safe and\neffective. To ensure this, medical device manufacturers must comply to the new\nregulatory requirements brought by the Medical Device Regulation (MDR) and the\nIn Vitro Diagnostic Medical Device Regulation (IVDR). In general, the new\nregulations increase regulatory requirements and oversight, especially for\nmedical software, and this is also true for requirements related to\ncybersecurity, which are now explicitly addressed in the legislation. The\nsignificant legislation changes currently underway, combined with increased\ncybersecurity requirements, create unique challenges for manufacturers to\ncomply with the regulatory framework. In this paper, we review the new\ncybersecurity requirements in the light of currently available guidance\ndocuments, and pinpoint four core concepts around which cybersecurity\ncompliance can be built. We argue that these core concepts form a foundations\nfor cybersecurity compliance in the European Union regulatory framework.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 17:26:06 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Granlund", "Tuomas", ""], ["Vedenp\u00e4\u00e4", "Juha", ""], ["Stirbu", "Vlad", ""], ["Mikkonen", "Tommi", ""]]}, {"id": "2103.06815", "submitter": "Tuomas Granlund", "authors": "Tuomas Granlund, Tommi Mikkonen and Vlad Stirbu", "title": "On Medical Device Software CE Compliance and Conformity Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manufacturing of medical devices is strictly controlled by authorities, and\nmanufacturers must conform to the regulatory requirements of the region in\nwhich a medical device is being marketed for use. In general, these\nrequirements make no difference between the physical device, embedded software\nrunning inside a physical device, or software that constitutes the device in\nitself. As a result, standalone software with intended medical use is\nconsidered to be a medical device. Consequently, its development must meet the\nsame requirements as the physical medical device manufacturing. This practice\ncreates a unique challenge for organizations developing medical software. In\nthis paper, we pinpoint a number of regulatory requirement mismatches between\nphysical medical devices and standalone medical device software. The view is\nbased on experiences from industry, from the development of all-software\nmedical devices as well as from defining the manufacturing process so that it\nmeets the regulatory requirements.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 17:35:40 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Granlund", "Tuomas", ""], ["Mikkonen", "Tommi", ""], ["Stirbu", "Vlad", ""]]}, {"id": "2103.06885", "submitter": "Philip Waggoner", "authors": "Philip D. Waggoner", "title": "Modern Dimension Reduction", "comments": "83 pages, 36 figures, to appear in the Cambridge University Press\n  Elements in Quantitative and Computational Methods for the Social Sciences\n  series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data are not only ubiquitous in society, but are increasingly complex both in\nsize and dimensionality. Dimension reduction offers researchers and scholars\nthe ability to make such complex, high dimensional data spaces simpler and more\nmanageable. This Element offers readers a suite of modern unsupervised\ndimension reduction techniques along with hundreds of lines of R code, to\nefficiently represent the original high dimensional data space in a simplified,\nlower dimensional subspace. Launching from the earliest dimension reduction\ntechnique principal components analysis and using real social science data, I\nintroduce and walk readers through application of the following techniques:\nlocally linear embedding, t-distributed stochastic neighbor embedding (t-SNE),\nuniform manifold approximation and projection, self-organizing maps, and deep\nautoencoders. The result is a well-stocked toolbox of unsupervised algorithms\nfor tackling the complexities of high dimensional data so common in modern\nsociety. All code is publicly accessible on Github.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 14:54:33 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Waggoner", "Philip D.", ""]]}, {"id": "2103.07205", "submitter": "Elochukwu Ukwandu Dr", "authors": "Comfort Olebara, Obianuju Ezugwu, Adaora Obayi, Deborah Ebem, Ujunwa\n  Mbgoh, Elochukwu Ukwandu", "title": "Determining the Impacts of Social Media on Mood, Time Management and\n  Academic Activities of Students and the Relationship with their Academic\n  Performance", "comments": "7 pages, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of social media sites have increased exponentially with new ones\ncashing in on the weaknesses of older ones and others going beyond community\nguidelines by offering uncensored content. The vendors of these platforms in\norder to have a wider reach do not place restrictions on viewing age, promises\nyoung people with fame, and other such attractive offers that make the youths\naddicted to the site. The possibility of hacking into accounts of users and\nusing same for fraud is another rave among Nigerian youths with desire for\nquick riches. The crash in prices of data, smart phones, and related digital\ndevices have increased availability and access thereby closing digital divide\nand widening its adverse effects on the youths morals and academic pursuits. It\nis important that the Nigerian government understand factors that contribute to\nthe dwindling performance level of students in government owned institutions to\nput in place policies and infrastructure that would help combat the challenges.\nThis study investigated the effects of social media on students academic\nactivities, mood and time management abilities. The result indicated that\nassociation between social media and academic activities is statistically\nsignificant. However, a negative association exists between them which implies\nthat the high the level of social media activity, the lower academic activities\nparticipation. Similar association was observed on the effects of social media\non students time management ability.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 10:58:46 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Olebara", "Comfort", ""], ["Ezugwu", "Obianuju", ""], ["Obayi", "Adaora", ""], ["Ebem", "Deborah", ""], ["Mbgoh", "Ujunwa", ""], ["Ukwandu", "Elochukwu", ""]]}, {"id": "2103.07215", "submitter": "Elochukwu Ukwandu Dr", "authors": "Modesta Ezema, Boniface Nworgu, Deborah Ebem, Stephenson Echezona,\n  Celestine Ugwu, Assumpta Ezugwu, Asogwa Chika, Ekene Ozioko, Elochukwu\n  Ukwandu", "title": "Development of An Assessment Benchmark for Synchronous Online Learning\n  for Nigerian Universities", "comments": "6 pages, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, as a result of COVID-19 pandemic, higher institutions in\nNigeria have been shutdown and the leadership of Academic Staff Union of\nUniversity (ASUU) said that Nigerian universities cannot afford to mount Online\nlearning platforms let alone conduct such learning system in Nigeria due to\nlack of infrastructure, capacity and skill sets in the face of COVID-19\npandemic. In the light of this, this research undertook an online survey using\nUniversity of Nigeria, Nsukka (UNN) as a case study to know which type of\nonline learning system ASUU leadership is talking about - Asynchronous or\nSynchronous? How did ASUU come about their facts? Did ASUU base their assertion\non facts, if YES, what are the benchmarks? Therefore, this research project is\nfocused on providing benchmarks to assess if a Nigerian University has what it\ntakes to run a synchronous Online Learning. It includes Infrastructure needed\n(Hardware, Software, Network connectivity), Skill sets from staff (Computer\nliteracy level). In a bid to do this, an online survey was administered to the\nstaff of Centre for Distance and E-learning of UNN and out of the 40 members of\nthat section of the University, we had 32 respondents. The survey seeks to find\nwhether UNN has the requisite infrastructure and the skill sets to mount\nsynchronous online learning. The available results of the study reveal that UNN\nis deficit in both the requisite infrastructure and Skills sets to mount\nsynchronous online learning.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 11:17:56 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Ezema", "Modesta", ""], ["Nworgu", "Boniface", ""], ["Ebem", "Deborah", ""], ["Echezona", "Stephenson", ""], ["Ugwu", "Celestine", ""], ["Ezugwu", "Assumpta", ""], ["Chika", "Asogwa", ""], ["Ozioko", "Ekene", ""], ["Ukwandu", "Elochukwu", ""]]}, {"id": "2103.07538", "submitter": "Sandeep Soni", "authors": "Sandeep Soni and Lauren Klein and Jacob Eisenstein", "title": "Abolitionist Networks: Modeling Language Change in Nineteenth-Century\n  Activist Newspapers", "comments": "23 pages, 6 figures, 2 tables", "journal-ref": "Journal of Cultural Analytics (2021)", "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.DL cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The abolitionist movement of the nineteenth-century United States remains\namong the most significant social and political movements in US history.\nAbolitionist newspapers played a crucial role in spreading information and\nshaping public opinion around a range of issues relating to the abolition of\nslavery. These newspapers also serve as a primary source of information about\nthe movement for scholars today, resulting in powerful new accounts of the\nmovement and its leaders. This paper supplements recent qualitative work on the\nrole of women in abolition's vanguard, as well as the role of the Black press,\nwith a quantitative text modeling approach. Using diachronic word embeddings,\nwe identify which newspapers tended to lead lexical semantic innovations -- the\nintroduction of new usages of specific words -- and which newspapers tended to\nfollow. We then aggregate the evidence across hundreds of changes into a\nweighted network with the newspapers as nodes; directed edge weights represent\nthe frequency with which each newspaper led the other in the adoption of a\nlexical semantic change. Analysis of this network reveals pathways of lexical\nsemantic influence, distinguishing leaders from followers, as well as others\nwho stood apart from the semantic changes that swept through this period. More\nspecifically, we find that two newspapers edited by women -- THE PROVINCIAL\nFREEMAN and THE LILY -- led a large number of semantic changes in our corpus,\nlending additional credence to the argument that a multiracial coalition of\nwomen led the abolitionist movement in terms of both thought and action. It\nalso contributes additional complexity to the scholarship that has sought to\ntease apart the relation of the abolitionist movement to the women's suffrage\nmovement, and the vexed racial politics that characterized their relation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 21:26:30 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Soni", "Sandeep", ""], ["Klein", "Lauren", ""], ["Eisenstein", "Jacob", ""]]}, {"id": "2103.07655", "submitter": "Kenji Saito", "authors": "Kenji Saito, Satoki Watanabe", "title": "Lightweight Selective Disclosure for Verifiable Documents on Blockchain", "comments": "8 pages, 3 figures, 1 table. Submitted to ICT Express", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve lightweight selective disclosure for protecting privacy of\ndocument holders, we propose an XML format for documents that can hide\narbitrary elements using a cryptographic hash function and salts, which allows\nto be partially digitally signed and efficiently verified, as well as a JSON\nformat that can be converted to such XML. The documents can be efficiently\nproven to exist by representing multiple such structures as a Merkle tree and\nstoring its root in blockchain.\n  We show that our proposal has advantages over known methods that represent\nthe document itself as a Merkle tree and partially hide it.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 08:32:45 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Saito", "Kenji", ""], ["Watanabe", "Satoki", ""]]}, {"id": "2103.07662", "submitter": "Jeremy Straub", "authors": "Jeremy Straub", "title": "Defining, Evaluating, Preparing for and Responding to a Cyber Pearl\n  Harbor", "comments": null, "journal-ref": "Technology in Society 65 (2021)", "doi": "10.1016/j.techsoc.2021.101599", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Despite not having a clear meaning, public perception and awareness makes the\nterm cyber Pearl Harbor an important part of the public discourse. This paper\nconsiders what the term has meant and proposes its decomposition based on three\ndifferent aspects of the historical Pearl Harbor attack, allowing the lessons\nfrom Pearl Harbor to be applied to threats and subjects that may not align with\nall aspects of the 1941 attack. Using these three definitions, prior attacks\nand current threats are assessed and preparation for and response to cyber\nPearl Harbor events is discussed.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 09:15:27 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Straub", "Jeremy", ""]]}, {"id": "2103.07669", "submitter": "Kenji Saito", "authors": "Kenji Saito, Mitsuru Iwamura", "title": "Privacy-Preserving Infection Exposure Notification without Trust in\n  Third Parties", "comments": "17 pages, 5 figures, 1 table. Submitted to Journal of Communications\n  and Networks (JCN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to the COVID-19 pandemic, Bluetooth-based contact tracing has\nbeen deployed in many countries with the help of the developers of smartphone\noperating systems that provide APIs for privacy-preserving exposure\nnotification. However, it has been assumed by the design that the OS\ndevelopers, smartphone vendors, or governments will not violate people's\nprivacy. We propose a privacy-preserving exposure notification under situations\nwhere none of the middle entities can be trusted. We believe that it can be\nachieved with small changes to the existing mechanism: random numbers are\ngenerated on the application side instead of the OS, and the positive test\nresults are reported to a public ledger (e.g. blockchain) rather than to a\ngovernment server, with endorsements from the medical institutes with blind\nsignatures. We also discuss how to incentivize the peer-to-peer maintenance of\nthe public ledger if it should be newly built. We show that the level of\nverifiability is much higher with our proposed design if a consumer group were\nto verify the privacy protections of the deployed systems. We believe that this\nwill allow for safer contact tracing, and contribute to healthier lifestyles\nfor citizens who may want to or have to go out under pandemic situations.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 09:47:45 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Saito", "Kenji", ""], ["Iwamura", "Mitsuru", ""]]}, {"id": "2103.07707", "submitter": "Semra Gunduc", "authors": "Semra Gunduc", "title": "Diffusion of Innovation In Competitive Markets-A Study on the Global\n  Smartphone Diffusion", "comments": null, "journal-ref": "ACTA POLONICA A Volume: 135 Issue: 3 Pages :485-494 Published :\n  Mar 2019", "doi": "10.12693/APhysPolA.135.485", "report-no": null, "categories": "physics.soc-ph cs.CY econ.GN q-fin.EC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work, the aim is to study the diffusion of innovation of two\ncompeting products. The main focus has been to understand the effects of the\ncompetitive dynamic market on the diffusion of innovation. The global\nsmartphone operating system sales are chosen as an example. The availability of\nthe sales and the number of users data, as well as the predictions for the\nfuture number of users, make the smartphone diffusion a new laboratory to test\nthe innovation of diffusion models for the competitive markets. In this work,\nthe Bass model and its extensions which incorporate the competition between the\nbrands are used. The diffusion of smartphones can be considered on two levels:\nthe product level and the brand level. The diffusion of the smartphone as a\ncategory is studied by using the Bass equation (category-level diffusion). The\ndiffusion of each competing operating system (iOS and Android) are considered\nas the competition of the brands, and it is studied in the context of\ncompetitive market models (product-level diffusion). It is shown that the\neffects of personal interactions play the dominant role in the diffusion\nprocess. Moreover, the volume of near future sales can be predicted by\nintroducing appropriate dynamic market potential which helps to extrapolate the\nmodel results for the future.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 12:26:32 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Gunduc", "Semra", ""]]}, {"id": "2103.07762", "submitter": "Bonaventure F. P. Dossou", "authors": "Bonaventure F. P. Dossou and Chris C. Emezue", "title": "OkwuGb\\'e: End-to-End Speech Recognition for Fon and Igbo", "comments": null, "journal-ref": "African NLP, EACL 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language is inherent and compulsory for human communication. Whether\nexpressed in a written or spoken way, it ensures understanding between people\nof the same and different regions. With the growing awareness and effort to\ninclude more low-resourced languages in NLP research, African languages have\nrecently been a major subject of research in machine translation, and other\ntext-based areas of NLP. However, there is still very little comparable\nresearch in speech recognition for African languages. Interestingly, some of\nthe unique properties of African languages affecting NLP, like their\ndiacritical and tonal complexities, have a major root in their speech,\nsuggesting that careful speech interpretation could provide more intuition on\nhow to deal with the linguistic complexities of African languages for\ntext-based NLP. OkwuGb\\'e is a step towards building speech recognition systems\nfor African low-resourced languages. Using Fon and Igbo as our case study, we\nconduct a comprehensive linguistic analysis of each language and describe the\ncreation of end-to-end, deep neural network-based speech recognition models for\nboth languages. We present a state-of-art ASR model for Fon, as well as\nbenchmark ASR model results for Igbo. Our linguistic analyses (for Fon and\nIgbo) provide valuable insights and guidance into the creation of speech\nrecognition models for other African low-resourced languages, as well as guide\nfuture NLP research for Fon and Igbo. The Fon and Igbo models source code have\nbeen made publicly available.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 18:02:44 GMT"}, {"version": "v2", "created": "Tue, 16 Mar 2021 04:35:06 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Dossou", "Bonaventure F. P.", ""], ["Emezue", "Chris C.", ""]]}, {"id": "2103.07942", "submitter": "Francesco Poggi", "authors": "Federica Bologna, Angelo Di Iorio, Silvio Peroni, Francesco Poggi", "title": "Do open citations inform the qualitative peer-review evaluation in\n  research assessments? An analysis of the Italian National Scientific\n  Qualification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past, several works have investigated ways for combining quantitative\nand qualitative methods in research assessment exercises. Indeed, the Italian\nNational Scientific Qualification (NSQ), i.e. the national assessment exercise\nwhich aims at deciding whether a scholar can apply to professorial academic\npositions as Associate Professor and Full Professor, adopts a quantitative and\nqualitative evaluation process: it makes use of bibliometrics followed by a\npeer-review process of candidates' CVs. The NSQ divides academic disciplines\ninto two categories, i.e. citation-based disciplines (CDs) and\nnon-citation-based disciplines (NDs), a division that affects the metrics used\nfor assessing the candidates of that discipline in the first part of the\nprocess, which is based on bibliometrics. In this work, we aim at exploring\nwhether citation-based metrics, calculated only considering open bibliographic\nand citation data, can support the human peer-review of NDs and yield insights\non how it is conducted. To understand if and what citation-based (and,\npossibly, other) metrics provide relevant information, we created a series of\nmachine learning models to replicate the decisions of the NSQ committees. As\none of the main outcomes of our study, we noticed that the strength of the\ncitational relationship between the candidate and the commission in charge of\nassessing his/her CV seems to play a role in the peer-review phase of the NSQ\nof NDs.\n", "versions": [{"version": "v1", "created": "Sun, 14 Mar 2021 14:44:45 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Bologna", "Federica", ""], ["Di Iorio", "Angelo", ""], ["Peroni", "Silvio", ""], ["Poggi", "Francesco", ""]]}, {"id": "2103.08538", "submitter": "Yao Yao", "authors": "Yao Yao, Linlong Li, Zhaotang Liang, Tao Cheng, Zhenhui Sun, Peng Luo,\n  Qingfeng Guan, Yaqian Zhai, Shihao Kou, Yuyang Cai, Lefei Li, Xinyue Ye", "title": "UrbanVCA: a vector-based cellular automata framework to simulate the\n  urban land-use change at the land-parcel level", "comments": "27 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vector-based cellular automata (CA) based on real land-parcel has become an\nimportant trend in current urban development simulation studies. Compared with\nraster-based and parcel-based CA models, vector CA models are difficult to be\nwidely used because of their complex data structures and technical\ndifficulties. The UrbanVCA, a brand-new vector CA-based urban development\nsimulation framework was proposed in this study, which supports multiple\nmachine-learning models. To measure the simulation accuracy better, this study\nalso first proposes a vector-based landscape index (VecLI) model based on the\nreal land-parcels. Using Shunde, Guangdong as the study area, the UrbanVCA\nsimulates multiple types of urban land-use changes at the land-parcel level\nhave achieved a high accuracy (FoM=0.243) and the landscape index similarity\nreaches 87.3%. The simulation results in 2030 show that the eco-protection\nscenario can promote urban agglomeration and reduce ecological aggression and\nloss of arable land by at least 60%. Besides, we have developed and released\nUrbanVCA software for urban planners and researchers.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 17:03:22 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Yao", "Yao", ""], ["Li", "Linlong", ""], ["Liang", "Zhaotang", ""], ["Cheng", "Tao", ""], ["Sun", "Zhenhui", ""], ["Luo", "Peng", ""], ["Guan", "Qingfeng", ""], ["Zhai", "Yaqian", ""], ["Kou", "Shihao", ""], ["Cai", "Yuyang", ""], ["Li", "Lefei", ""], ["Ye", "Xinyue", ""]]}, {"id": "2103.08763", "submitter": "Bianca Trinkenreich", "authors": "Bianca Trinkenreich", "title": "Please Don't Go -- A Comprehensive Approach to Increase Women's\n  Participation in Open Source Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Women represent less than 24% of employees in the software development\nindustry and experience various types of prejudice and bias. Despite various\nefforts to increase diversity and multi-gendered participation, women are even\nmore underrepresented in Open Source Software (OSS) projects. In my PhD, I\ninvestigate the following question: How can OSS communities increase women's\nparticipation in their projects? I will identify different OSS career pathways\nand develop a holistic view of women's motivations to join or leave OSS, as\nwell as their definitions of success. Based on this empirical investigation, I\nwill work together with the Linux Foundation to design attraction and retention\nstrategies focused on women. Before and after implementing the strategies, I\nwill conduct empirical studies to evaluate the state of the practice and\nunderstand the implications of the strategies.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2021 23:23:15 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Trinkenreich", "Bianca", ""]]}, {"id": "2103.08931", "submitter": "Jian Wang", "authors": "Jian Wang and Suzan Verberne", "title": "Two tales of science technology linkage: Patent in-text versus\n  front-page references", "comments": "45 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There is recurrent debate about how useful science is for technological\ndevelopment, but we know little about what kinds of science are more useful for\ntechnology. This paper fills this gap in the literature by exploring how the\nvalue of a patent (as measured by patent forward citations and the stock market\nresponse to the issuing of the patent) depends on the characteristics of the\nscientific papers that it builds on, specifically, basicness,\ninterdisciplinarity, novelty, and scientific citations. Using a dataset of\n33,337 USPTO biotech utility patents and their 860,879 in-text references to\nWeb of Science journal articles, we find (1) a positive effect of the number of\nreferenced scientific papers, (2) an inverted U-shaped effect of basicness, (3)\nan insignificant effect of interdisciplinarity, (4) a discontinuous and\nnonlinear effect of novelty, and (5) a positive effect of scientific citations\nfor patent market value but an insignificant effect on patent citations. In\naddition, in-text referenced papers have a higher chance of being listed on the\nfront-page of the same patent when they are moderately basic, less\ninterdisciplinary, less novel, and more highly cited. Accordingly, using\nfront-page reference yields substantially different results than using in-text\nreferences.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 09:28:28 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Wang", "Jian", ""], ["Verberne", "Suzan", ""]]}, {"id": "2103.09048", "submitter": "Anna Van Der Meulen", "authors": "Anna van der Meulen, Efthimia Aivaloglou", "title": "Who does what? Work division and allocation strategies of computer\n  science student teams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaboration skills are important for future software engineers. In computer\nscience education, these skills are often practiced through group assignments,\nwhere students develop software collaboratively. The approach that students\ntake in these assignments varies widely, but often involves a division of\nlabour. It can then be argued whether collaboration still takes place. The\ndiscipline of computing education is especially interesting in this context,\nbecause some of its specific features (such as the variation in entry skill\nlevel and the use of source code repositories as collaboration platforms) are\nlikely to influence the approach taken within groupwork. The aim of this\nresearch is to gain insight into the work division and allocation strategies\napplied by computer science students during group assignments. To this end, we\ninterviewed twenty students of four universities. The thematic analysis shows\nthat students tend to divide up the workload to enable working independently,\nwith pair programming and code reviews being often employed. Motivated\nprimarily by grade and efficiency factors, students choose and allocate tasks\nprimarily based on their prior expertise and preferences. Based on our\nfindings, we argue that the setup of group assignments can limit student\nmotivation for practicing new software engineering skills, and that\ninterventions are needed towards encouraging experimentation and learning.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 12:27:07 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["van der Meulen", "Anna", ""], ["Aivaloglou", "Efthimia", ""]]}, {"id": "2103.09049", "submitter": "Burcu G\\\"urb\\\"uz", "authors": "Dedi Saputra and Burcu G\\\"urb\\\"uz", "title": "Implementation of Technology Acceptance Model (TAM) and Importance\n  Performance Analysis (IPA) in Testing the Ease and Usability of E-wallet\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital payment innovation is currently increasingly needed by the community,\nespecially in making non-cash payment transactions. The purpose of this\nresearch is to know and measure the ease and usefulness of e-wallet digital\nwallet services, especially in the GoPay application. The population in this\nstudy are users of the Go-Pay service on the GO-JEK platform. The sample of\nthis study consisted of 124 respondents from distributing questionnaires in\nDepok, West Java using a modified Technology Acceptance Model (TAM) based on\nexisting references. The data processing in this research uses Importance\nPerformance Analysis (IPA) analysis. The results show that based on the gap\nanalysis, it is found that in general Go-Pay users are not satisfied with the\ncurrent service quality. Based on the IPA analysis, the priority scale of\nE-Wallet Go-Pay quality improvement can be mapped, where quadrant I is the\nhighest priority scale according to the user's perspective: [1], [4], [5], and\n[6]. These three items must be upgraded immediately by the manager to meet user\nexpectations. Areas that become the achievements or advantages of the GoPay\nE-Wallet that must be maintained are in quadrant II, namely: [2] and [3]. From\nthis explanation, it can be concluded that in general the E-Wallet GoPay\nService must be improved to improve its service performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Mar 2021 20:18:56 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Saputra", "Dedi", ""], ["G\u00fcrb\u00fcz", "Burcu", ""]]}, {"id": "2103.09050", "submitter": "Sultan Alshamrani", "authors": "Sultan Alshamrani, Ahmed Abusnaina, Mohammed Abuhamad, Daehun Nyang,\n  David Mohaisen", "title": "Hate, Obscenity, and Insults: Measuring the Exposure of Children to\n  Inappropriate Comments in YouTube", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media has become an essential part of the daily routines of children\nand adolescents. Moreover, enormous efforts have been made to ensure the\npsychological and emotional well-being of young users as well as their safety\nwhen interacting with various social media platforms. In this paper, we\ninvestigate the exposure of those users to inappropriate comments posted on\nYouTube videos targeting this demographic. We collected a large-scale dataset\nof approximately four million records and studied the presence of five\nage-inappropriate categories and the amount of exposure to each category. Using\nnatural language processing and machine learning techniques, we constructed\nensemble classifiers that achieved high accuracy in detecting inappropriate\ncomments. Our results show a large percentage of worrisome comments with\ninappropriate content: we found 11% of the comments on children's videos to be\ntoxic, highlighting the importance of monitoring comments, particularly on\nchildren's platforms.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2021 20:15:22 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Alshamrani", "Sultan", ""], ["Abusnaina", "Ahmed", ""], ["Abuhamad", "Mohammed", ""], ["Nyang", "Daehun", ""], ["Mohaisen", "David", ""]]}, {"id": "2103.09051", "submitter": "Markus Borg", "authors": "Markus Borg, Joshua Bronson, Linus Christensson, Fredrik Olsson, Olof\n  Lennartsson, Elias Sonnsj\\\"o, Hamid Ebabi, Martin Karsberg", "title": "Exploring the Assessment List for Trustworthy AI in the Context of\n  Advanced Driver-Assistance Systems", "comments": "Accepted for publication in the Proc. of the 2nd Workshop on Ethics\n  in Software Engineering Research and Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) is increasingly used in critical applications.\nThus, the need for dependable AI systems is rapidly growing. In 2018, the\nEuropean Commission appointed experts to a High-Level Expert Group on AI\n(AI-HLEG). AI-HLEG defined Trustworthy AI as 1) lawful, 2) ethical, and 3)\nrobust and specified seven corresponding key requirements. To help development\norganizations, AI-HLEG recently published the Assessment List for Trustworthy\nAI (ALTAI). We present an illustrative case study from applying ALTAI to an\nongoing development project of an Advanced Driver-Assistance System (ADAS) that\nrelies on Machine Learning (ML). Our experience shows that ALTAI is largely\napplicable to ADAS development, but specific parts related to human agency and\ntransparency can be disregarded. Moreover, bigger questions related to societal\nand environmental impact cannot be tackled by an ADAS supplier in isolation. We\npresent how we plan to develop the ADAS to ensure ALTAI-compliance. Finally, we\nprovide three recommendations for the next revision of ALTAI, i.e., life-cycle\nvariants, domain-specific adaptations, and removed redundancy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2021 21:48:11 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Borg", "Markus", ""], ["Bronson", "Joshua", ""], ["Christensson", "Linus", ""], ["Olsson", "Fredrik", ""], ["Lennartsson", "Olof", ""], ["Sonnsj\u00f6", "Elias", ""], ["Ebabi", "Hamid", ""], ["Karsberg", "Martin", ""]]}, {"id": "2103.09054", "submitter": "Mark Stamp", "authors": "Zidong Jiang and Fabio Di Troia and Mark Stamp", "title": "Sentiment Analysis for Troll Detection on Weibo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The impact of social media on the modern world is difficult to overstate.\nVirtually all companies and public figures have social media accounts on\npopular platforms such as Twitter and Facebook. In China, the micro-blogging\nservice provider, Sina Weibo, is the most popular such service. To influence\npublic opinion, Weibo trolls -- the so called Water Army -- can be hired to\npost deceptive comments. In this paper, we focus on troll detection via\nsentiment analysis and other user activity data on the Sina Weibo platform. We\nimplement techniques for Chinese sentence segmentation, word embedding, and\nsentiment score calculation. In recent years, troll detection and sentiment\nanalysis have been studied, but we are not aware of previous research that\nconsiders troll detection based on sentiment analysis. We employ the resulting\ntechniques to develop and test a sentiment analysis approach for troll\ndetection, based on a variety of machine learning strategies. Experimental\nresults are generated and analyzed. A Chrome extension is presented that\nimplements our proposed technique, which enables real-time troll detection when\na user browses Sina Weibo.\n", "versions": [{"version": "v1", "created": "Sun, 7 Mar 2021 14:59:12 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Jiang", "Zidong", ""], ["Di Troia", "Fabio", ""], ["Stamp", "Mark", ""]]}, {"id": "2103.09055", "submitter": "Hantian Zhang", "authors": "Hantian Zhang, Xu Chu, Abolfazl Asudeh, Shamkant B. Navathe", "title": "OmniFair: A Declarative System for Model-Agnostic Group Fairness in\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning (ML) is increasingly being used to make decisions in our\nsociety. ML models, however, can be unfair to certain demographic groups (e.g.,\nAfrican Americans or females) according to various fairness metrics. Existing\ntechniques for producing fair ML models either are limited to the type of\nfairness constraints they can handle (e.g., preprocessing) or require\nnontrivial modifications to downstream ML training algorithms (e.g.,\nin-processing).\n  We propose a declarative system OmniFair for supporting group fairness in ML.\nOmniFair features a declarative interface for users to specify desired group\nfairness constraints and supports all commonly used group fairness notions,\nincluding statistical parity, equalized odds, and predictive parity. OmniFair\nis also model-agnostic in the sense that it does not require modifications to a\nchosen ML algorithm. OmniFair also supports enforcing multiple user declared\nfairness constraints simultaneously while most previous techniques cannot. The\nalgorithms in OmniFair maximize model accuracy while meeting the specified\nfairness constraints, and their efficiency is optimized based on the\ntheoretically provable monotonicity property regarding the trade-off between\naccuracy and fairness that is unique to our system.\n  We conduct experiments on commonly used datasets that exhibit bias against\nminority groups in the fairness literature. We show that OmniFair is more\nversatile than existing algorithmic fairness approaches in terms of both\nsupported fairness constraints and downstream ML models. OmniFair reduces the\naccuracy loss by up to $94.8\\%$ compared with the second best method. OmniFair\nalso achieves similar running time to preprocessing methods, and is up to\n$270\\times$ faster than in-processing methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 02:44:10 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Zhang", "Hantian", ""], ["Chu", "Xu", ""], ["Asudeh", "Abolfazl", ""], ["Navathe", "Shamkant B.", ""]]}, {"id": "2103.09058", "submitter": "Joon Sung Park", "authors": "Joon Sung Park, Michael S. Bernstein, Robin N. Brewer, Ece Kamar,\n  Meredith Ringel Morris", "title": "Understanding the Representation and Representativeness of Age in AI\n  Data Sets", "comments": "9 pages", "journal-ref": "In Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\n  Society (AIES '21)", "doi": "10.1145/3461702.3462590", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A diverse representation of different demographic groups in AI training data\nsets is important in ensuring that the models will work for a large range of\nusers. To this end, recent efforts in AI fairness and inclusion have advocated\nfor creating AI data sets that are well-balanced across race, gender,\nsocioeconomic status, and disability status. In this paper, we contribute to\nthis line of work by focusing on the representation of age by asking whether\nolder adults are represented proportionally to the population at large in AI\ndata sets. We examine publicly-available information about 92 face data sets to\nunderstand how they codify age as a case study to investigate how the subjects'\nages are recorded and whether older generations are represented. We find that\nolder adults are very under-represented; five data sets in the study that\nexplicitly documented the closed age intervals of their subjects included older\nadults (defined as older than 65 years), while only one included oldest-old\nadults (defined as older than 85 years). Additionally, we find that only 24 of\nthe data sets include any age-related information in their documentation or\nmetadata, and that there is no consistent method followed across these data\nsets to collect and record the subjects' ages. We recognize the unique\ndifficulties in creating representative data sets in terms of age, but raise it\nas an important dimension that researchers and engineers interested in\ninclusive AI should consider.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2021 12:26:22 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 04:30:40 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Park", "Joon Sung", ""], ["Bernstein", "Michael S.", ""], ["Brewer", "Robin N.", ""], ["Kamar", "Ece", ""], ["Morris", "Meredith Ringel", ""]]}, {"id": "2103.09060", "submitter": "Xiaojian Zhang", "authors": "Xiang Yan, Wencui Yang, Xiaojian Zhang, Yiming Xu, Ilir Bejleri, Xilei\n  Zhao", "title": "Do e-scooters fill mobility gaps and promote equity before and during\n  COVID-19? A spatiotemporal analysis using open big data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing popularity of e-scooters and their rapid expansion across urban\nstreets has attracted widespread attention. A major policy question is whether\ne-scooters substitute existing mobility options or fill the service gaps left\nby them. This study addresses this question by analyzing the spatiotemporal\npatterns of e-scooter service availability and use in Washington DC, focusing\non their spatial relationships with public transit and bikesharing. Results\nfrom an analysis of three open big datasets suggest that e-scooters have both\ncompeting and complementary effects on transit and bikesharing services. The\nsupply of e-scooters significantly overlaps with the service areas of transit\nand bikesharing, and we classify a majority of e-scooter trips as substitutes\nto transit and bikesharing uses. A travel-time-based analysis further reveals\nthat when choosing e-scooters over transit, travelers pay a price premium and\nsave some travel time. The price premium is greater during the COVID-19\npandemic but the associated travel-time savings are smaller. This implies that\npublic health considerations rather than time-cost tradeoffs are the main\ndriver for many to choose e-scooters over transit during COVID. In addition, we\nfind that e-scooters complement bikesharing and transit by providing services\nto underserved neighborhoods. A sizeable proportion (about 10 percent) of\ne-scooter trips are taken to connect with the rail services. Future research\nmay combine the big-data-based analysis presented here with traditional methods\nto further shed light on the interactions between e-scooter services,\nbikesharing, and public transit.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 03:29:21 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Yan", "Xiang", ""], ["Yang", "Wencui", ""], ["Zhang", "Xiaojian", ""], ["Xu", "Yiming", ""], ["Bejleri", "Ilir", ""], ["Zhao", "Xilei", ""]]}, {"id": "2103.09062", "submitter": "Md Amiruzzaman", "authors": "Md Mashfiq Rizvee and Md Amiruzzaman and Md Rajibul Islam", "title": "Data Mining and Visualization to Understand Accident-prone Areas", "comments": "8 figures, 1 table", "journal-ref": "Proceedings of International Joint Conference on Advances in\n  Computational Intelligence 2020", "doi": "10.1007/978-981-16-0586-4_12", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we present both data mining and information visualization\ntechniques to identify accident-prone areas, most accident-prone time, day, and\nmonth. Also, we surveyed among volunteers to understand which visualization\ntechniques help non-expert users to understand the findings better. Findings of\nthis study suggest that most accidents occur in the dusk (i.e., between 6 to 7\npm), and on Fridays. Results also suggest that most accidents occurred in\nOctober, which is a popular month for tourism. These findings are consistent\nwith social information and can help policymakers, residents, tourists, and\nother law enforcement agencies. This study can be extended to draw broader\nimplications.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 18:11:23 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Rizvee", "Md Mashfiq", ""], ["Amiruzzaman", "Md", ""], ["Islam", "Md Rajibul", ""]]}, {"id": "2103.09224", "submitter": "Corrado Monti", "authors": "Arthur Capozzi, Gianmarco De Francisci Morales, Yelena Mejova, Corrado\n  Monti, Andr\\'e Panisson, Daniela Paolotti", "title": "Clandestino or Rifugiato? Anti-immigration Facebook Ad Targeting in\n  Italy", "comments": "Published at CHI21", "journal-ref": "CHI Conference on Human Factors in Computing Systems (CHI '21),\n  May 8-13, 2021, Yokohama, Japan. ACM", "doi": "10.1145/3411764.3445082", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring advertising around controversial issues is an important step in\nensuring accountability and transparency of political processes. To that end,\nwe use the Facebook Ads Library to collect 2312 migration-related advertising\ncampaigns in Italy over one year. Our pro- and anti-immigration classifier\n(F1=0.85) reveals a partisan divide among the major Italian political parties,\nwith anti-immigration ads accounting for nearly 15M impressions. Although\ncomposing 47.6% of all migration-related ads, anti-immigration ones receive\n65.2% of impressions. We estimate that about two thirds of all captured\ncampaigns use some kind of demographic targeting by location, gender, or age.\nWe find sharp divides by age and gender: for instance, anti-immigration ads\nfrom major parties are 17% more likely to be seen by a male user than a female.\nUnlike pro-migration parties, we find that anti-immigration ones reach a\nsimilar demographic to their own voters. However their audience change with\ntopic: an ad from anti-immigration parties is 24% more likely to be seen by a\nmale user when the ad speaks about migration, than if it does not. Furthermore,\nthe viewership of such campaigns tends to follow the volume of mainstream news\naround immigration, supporting the theory that political advertisers try to\n\"ride the wave\" of current news. We conclude with policy implications for\npolitical communication: since the Facebook Ads Library does not allow to\ndistinguish between advertisers intentions and algorithmic targeting, we argue\nthat more details should be shared by platforms regarding the targeting\nconfiguration of socio-political campaigns.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 17:52:35 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Capozzi", "Arthur", ""], ["Morales", "Gianmarco De Francisci", ""], ["Mejova", "Yelena", ""], ["Monti", "Corrado", ""], ["Panisson", "Andr\u00e9", ""], ["Paolotti", "Daniela", ""]]}, {"id": "2103.09287", "submitter": "Swati Gupta", "authors": "Jad Salem, Swati Gupta, Vijay Kamble", "title": "Taming Wild Price Fluctuations: Monotone Stochastic Convex Optimization\n  with Bandit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prices generated by automated price experimentation algorithms often display\nwild fluctuations, leading to unfavorable customer perceptions and violations\nof individual fairness: e.g., the price seen by a customer can be significantly\nhigher than what was seen by her predecessors, only to fall once again later.\nTo address this concern, we propose demand learning under a monotonicity\nconstraint on the sequence of prices, within the framework of stochastic convex\noptimization with bandit feedback.\n  Our main contribution is the design of the first sublinear-regret algorithms\nfor monotonic price experimentation for smooth and strongly concave revenue\nfunctions under noisy as well as noiseless bandit feedback. The monotonicity\nconstraint presents a unique challenge: since any increase (or decrease) in the\ndecision-levels is final, an algorithm needs to be cautious in its exploration\nto avoid over-shooting the optimum. At the same time, minimizing regret\nrequires that progress be made towards the optimum at a sufficient pace.\nBalancing these two goals is particularly challenging under noisy feedback,\nwhere obtaining sufficiently accurate gradient estimates is expensive. Our key\ninnovation is to utilize conservative gradient estimates to adaptively tailor\nthe degree of caution to local gradient information, being aggressive far from\nthe optimum and being increasingly cautious as the prices approach the optimum.\nImportantly, we show that our algorithms guarantee the same regret rates (up to\nlogarithmic factors) as the best achievable rates of regret without the\nmonotonicity requirement.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 19:06:28 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Salem", "Jad", ""], ["Gupta", "Swati", ""], ["Kamble", "Vijay", ""]]}, {"id": "2103.09593", "submitter": "Samson Tan", "authors": "Samson Tan, Shafiq Joty", "title": "Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots", "comments": "To be presented at NAACL-HLT 2021. Abstract also published in the\n  Rising Stars Track of the Workshop on Computational Approaches to Linguistic\n  Code-Switching (CALCS 2021)", "journal-ref": "2021.naacl-main.282", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilingual models have demonstrated impressive cross-lingual transfer\nperformance. However, test sets like XNLI are monolingual at the example level.\nIn multilingual communities, it is common for polyglots to code-mix when\nconversing with each other. Inspired by this phenomenon, we present two strong\nblack-box adversarial attacks (one word-level, one phrase-level) for\nmultilingual models that push their ability to handle code-mixed sentences to\nthe limit. The former uses bilingual dictionaries to propose perturbations and\ntranslations of the clean example for sense disambiguation. The latter directly\naligns the clean example with its translations before extracting phrases as\nperturbations. Our phrase-level attack has a success rate of 89.75% against\nXLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI.\nFinally, we propose an efficient adversarial training scheme that trains in the\nsame number of steps as the original model and show that it improves model\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 12:20:53 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 09:30:27 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 02:02:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tan", "Samson", ""], ["Joty", "Shafiq", ""]]}, {"id": "2103.10113", "submitter": "Andrew Tzer-Yeu Chen", "authors": "Andrew Tzer-Yeu Chen, Kimberly Thio", "title": "Exploring the Drivers and Barriers to Uptake for Digital Contact Tracing", "comments": "22 pages, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital contact tracing has been deployed as a public health intervention to\nhelp suppress the spread of COVID-19 in many jurisdictions. However, most\ngovernments have struggled with low uptake and participation rates, limiting\nthe effectiveness of the tool. This paper characterises a number of systems\ndeveloped around the world, comparing the uptake rates for systems with\ndifferent technology, data architectures, and mandates. The paper then\nintroduces the MAST framework (motivation, access, skills, and trust), adapted\nfrom the digital inclusion literature, to explore the drivers and barriers that\ninfluence people's decisions to participate or not in digital contact tracing\nsystems. Finally, the paper discusses some suggestions for policymakers on how\nto influence those drivers and barriers in order to improve uptake rates.\nExamples from existing digital contact tracing systems are presented\nthroughout, although more empirical experimentation is required to support more\nconcrete conclusions on what works.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 09:39:56 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 10:54:05 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 09:40:21 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chen", "Andrew Tzer-Yeu", ""], ["Thio", "Kimberly", ""]]}, {"id": "2103.10337", "submitter": "Anna Petrovskaia", "authors": "Anna Petrovskaia, Gleb Ryzhakov, Ivan Oseledets", "title": "Optimal soil sampling design based on the maxvol algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial soil sampling is an integral part of a soil survey aimed at creating\na soil map. We propose considering the soil sampling procedure as a task of\noptimal design. In practical terms, optimal experiments can reduce\nexperimentation costs, as they allow the researcher to obtain one optimal set\nof points. We present a sampling design, based on the fundamental idea of\nselecting sample locations by performing an optimal design method called the\nmaxvol algorithm. It is shown that the maxvol-base algorithm has a high\npotential for practical usage. Our method outperforms popular sampling methods\nin soil taxa prediction based on topographical features of the site and deals\nwith massive agricultural datasets in a reasonable time.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 15:54:06 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Petrovskaia", "Anna", ""], ["Ryzhakov", "Gleb", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2103.10489", "submitter": "Ivan Srba", "authors": "Ivan Srba, Gabriele Lenzini, Matus Pikuliak, Samuel Pecar", "title": "Addressing Hate Speech with Data Science: An Overview from Computer\n  Science Perspective", "comments": null, "journal-ref": "Wachs S., Koch-Priewe B., Zick A. (eds) Hate Speech -\n  Multidisziplinare Analysen und Handlungsoptionen. Springer VS, Wiesbaden.\n  2021", "doi": "10.1007/978-3-658-31793-5_14", "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  From a computer science perspective, addressing on-line hate speech is a\nchallenging task that is attracting the attention of both industry (mainly\nsocial media platform owners) and academia. In this chapter, we provide an\noverview of state-of-the-art data-science approaches - how they define hate\nspeech, which tasks they solve to mitigate the phenomenon, and how they address\nthese tasks. We limit our investigation mostly to (semi-)automatic detection of\nhate speech, which is the task that the majority of existing computer science\nworks focus on. Finally, we summarize the challenges and the open problems in\nthe current data-science research and the future directions in this field. Our\naim is to prepare an easily understandable report, capable to promote the\nmultidisciplinary character of hate speech research. Researchers from other\ndomains (e.g., psychology and sociology) can thus take advantage of the\nknowledge achieved in the computer science domain but also contribute back and\nhelp improve how computer science is addressing that urgent and socially\nrelevant issue which is the prevalence of hate speech in social media.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2021 19:19:44 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Srba", "Ivan", ""], ["Lenzini", "Gabriele", ""], ["Pikuliak", "Matus", ""], ["Pecar", "Samuel", ""]]}, {"id": "2103.10585", "submitter": "Benjamin Levy", "authors": "Benjamin Levy and Matthew Stewart", "title": "The evolving ecosystem of COVID-19 contact tracing applications", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the outbreak of the novel coronavirus, COVID-19, there has been\nincreased interest in the use of digital contact tracing as a means of stopping\nchains of viral transmission, provoking alarm from privacy advocates.\nConcerning the ethics of this technology, recent studies have predominantly\nfocused on (1) the formation of guidelines for ethical contact tracing, (2) the\nanalysis of specific implementations, or (3) the review of a select number of\ncontact tracing applications and their relevant privacy or ethical\nimplications. In this study, we provide a comprehensive survey of the evolving\necosystem of COVID-19 tracing applications, examining 152 contact tracing\napplications and assessing the extent to which they comply with existing\nguidelines for ethical contact tracing. The assessed criteria cover areas\nincluding data collection and storage, transparency and consent, and whether\nthe implementation is open source. We find that although many apps released\nearly in the pandemic fell short of best practices, apps released more\nrecently, following the publication of the Apple/Google exposure notification\nprotocol, have tended to be more closely aligned with ethical contact tracing\nprinciples. This dataset will be publicly available and may be updated as the\npandemic continues.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 01:38:19 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Levy", "Benjamin", ""], ["Stewart", "Matthew", ""]]}, {"id": "2103.10725", "submitter": "Thomas Mildner", "authors": "Thomas Mildner, Gian-Luca Savino", "title": "How Social Are Social Media The Dark Patterns In Facebook's Interface", "comments": "Position Paper at the Workshop \"What Can CHI Do About Dark Patterns?\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many researchers have been concerned with social media and possible negative\nimpacts on the well-being of their audience. With the popularity of social\nnetworking sites (SNS) steadily increasing, psychological and social sciences\nhave shown great interest in their effects and consequences on humans.\nUnfortunately, it appears to be difficult to find correlations between SNS and\nthe results of their works. We, therefore, investigate Facebook using the tools\nof HCI to find connections between interface features and the concerns raised\nby these domains. With a nod towards Dark Patterns, we use an empirical design\nanalysis to identify interface interferences that impact users' online privacy.\nWe further discuss how HCI can help to work towards more ethical user\ninterfaces in the future.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 10:40:29 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Mildner", "Thomas", ""], ["Savino", "Gian-Luca", ""]]}, {"id": "2103.10944", "submitter": "Buddhika Nettasinghe", "authors": "Buddhika Nettasinghe, Nazanin Alipourfard, Vikram Krishnamurthy,\n  Kristina Lerman", "title": "Emergence of Structural Inequalities in Scientific Citation Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.DL cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural inequalities persist in society, conferring systematic advantages\nto some people at the expense of others, for example, by giving them\nsubstantially more influence and opportunities. Using bibliometric data about\nauthors of scientific publications, we identify two types of structural\ninequalities in scientific citations. First, female authors, who represent a\nminority of researchers, receive less recognition for their work (through\ncitations) relative to male authors; second, authors affiliated with top-ranked\ninstitutions, who are also a minority, receive substantially more recognition\ncompared to other authors. We present a model for the growth of directed\ncitation networks and show that citations disparities arise from individual\npreferences to cite authors from the same group (homophily), highly cited or\nactive authors (preferential attachment), as well as the size of the group and\nhow frequently new authors join. We analyze the model and show that its\npredictions align well with real-world observations. Our theoretical and\nempirical analysis also suggests potential strategies to mitigate structural\ninequalities in science. In particular, we find that merely increasing the\nminority group size does little to narrow the disparities. Instead, reducing\nthe homophily of each group, frequently adding new authors to a research field\nwhile providing them an accessible platform among existing, established\nauthors, together with balanced group sizes can have the largest impact on\nreducing inequality. Our work highlights additional complexities of mitigating\nstructural disparities stemming from asymmetric relations (e.g., directed\ncitations) compared to symmetric relations (e.g., collaborations).\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 17:53:08 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 02:52:08 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Nettasinghe", "Buddhika", ""], ["Alipourfard", "Nazanin", ""], ["Krishnamurthy", "Vikram", ""], ["Lerman", "Kristina", ""]]}, {"id": "2103.11007", "submitter": "Jean-Gabriel Young", "authors": "Jean-Gabriel Young, Amanda Casari, Katie McLaughlin, Milo Z. Trujillo,\n  Laurent H\\'ebert-Dufresne, James P. Bagrow", "title": "Which contributions count? Analysis of attribution in open source", "comments": "Extended version of a paper accepted at MSR 2021", "journal-ref": "2021 IEEE/ACM 18th International Conference on Mining Software\n  Repositories (MSR), pp. 242-253 (2021)", "doi": "10.1109/MSR52588.2021.00036", "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open source software projects usually acknowledge contributions with text\nfiles, websites, and other idiosyncratic methods. These data sources are hard\nto mine, which is why contributorship is most frequently measured through\nchanges to repositories, such as commits, pushes, or patches. Recently, some\nopen source projects have taken to recording contributor actions with\nstandardized systems; this opens up a unique opportunity to understand how\ncommunity-generated notions of contributorship map onto codebases as the\nmeasure of contribution. Here, we characterize contributor acknowledgment\nmodels in open source by analyzing thousands of projects that use a model\ncalled All Contributors to acknowledge diverse contributions like outreach,\nfinance, infrastructure, and community management. We analyze the life cycle of\nprojects through this model's lens and contrast its representation of\ncontributorship with the picture given by other methods of acknowledgment,\nincluding GitHub's top committers indicator and contributions derived from\nactions taken on the platform. We find that community-generated systems of\ncontribution acknowledgment make work like idea generation or bug finding more\nvisible, which generates a more extensive picture of collaboration. Further, we\nfind that models requiring explicit attribution lead to more clearly defined\nboundaries around what is and what is not a contribution.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 20:14:40 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Young", "Jean-Gabriel", ""], ["Casari", "Amanda", ""], ["McLaughlin", "Katie", ""], ["Trujillo", "Milo Z.", ""], ["H\u00e9bert-Dufresne", "Laurent", ""], ["Bagrow", "James P.", ""]]}, {"id": "2103.11030", "submitter": "Luca Vigan\\`o", "authors": "Luca Vigan\\`o", "title": "Don't Tell Me The Cybersecurity Moon Is Shining... (Cybersecurity Show\n  And Tell)", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"Show, don't tell\" has become the literary commandment for any writer. It\napplies to all forms of fiction, and to non-fiction, including scientific\nwriting, where it lies at the heart of many scientific communication and\nstorytelling approaches. In this paper, I discuss how \"show \\emph{and} tell\" is\nactually often the best approach when one wants to present, teach or explain\ncomplicated ideas such as those underlying notions and results in mathematics\nand science, and in particular in cybersecurity. I discuss how different kinds\nof artworks can be used to explain cybersecurity and I illustrate how telling\n(i.e., explaining notions in a formal, technical way) can be paired with\nshowing through visual storytelling or other forms of storytelling. I also\ndiscuss four categories of artworks and the explanations they help provide.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 21:27:27 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 18:54:51 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 07:57:20 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Vigan\u00f2", "Luca", ""]]}, {"id": "2103.11042", "submitter": "Saurabh Mishra", "authors": "Saurabh Mishra, Robert Koopman, Giuditta De-Prato, Anand Rao, Israel\n  Osorio-Rodarte, Julie Kim, Nikola Spatafora, Keith Strier, and Andrea\n  Zaccaria", "title": "AI Specialization for Pathways of Economic Diversification", "comments": "27 pages, 20 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growth in AI is rapidly transforming the structure of economic\nproduction. However, very little is known about how within-AI specialization\nmay relate to broad-based economic diversification. This paper provides a\ndata-driven framework to integrate the interconnection between AI-based\nspecialization with goods and services export specialization to help design\nfuture comparative advantage based on the inherent capabilities of nations.\nUsing detailed data on private investment in AI and export specialization for\nmore than 80 countries, we propose a systematic framework to help identify the\nconnection from AI to goods and service sector specialization. The results are\ninstructive for nations that aim to harness AI specialization to help guide\nsources of future competitive advantage. The operational framework could help\ninform the public and private sector to uncover connections with nearby areas\nof specialization.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2021 22:05:20 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Mishra", "Saurabh", ""], ["Koopman", "Robert", ""], ["De-Prato", "Giuditta", ""], ["Rao", "Anand", ""], ["Osorio-Rodarte", "Israel", ""], ["Kim", "Julie", ""], ["Spatafora", "Nikola", ""], ["Strier", "Keith", ""], ["Zaccaria", "Andrea", ""]]}, {"id": "2103.11138", "submitter": "Teemu Lehtinen", "authors": "Teemu Lehtinen and Andr\\'e L. Santos and Juha Sorva", "title": "Let's Ask Students About Their Programs, Automatically", "comments": null, "journal-ref": "IEEE/ACM 29th International Conference on Program Comprehension\n  (2021) 467-475", "doi": "10.1109/ICPC52881.2021.00054", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Students sometimes produce code that works but that its author does not\ncomprehend. For example, a student may apply a poorly-understood code template,\nstumble upon a working solution through trial and error, or plagiarize.\nSimilarly, passing an automated functional assessment does not guarantee that\nthe student understands their code. One way to tackle these issues is to probe\nstudents' comprehension by asking them questions about their own programs. We\npropose an approach to automatically generate questions about student-written\nprogram code. We moreover propose a use case for such questions in the context\nof automatic assessment systems: after a student's program passes unit tests,\nthe system poses questions to the student about the code. We suggest that these\nquestions can enhance assessment systems, deepen student learning by acting as\nself-explanation prompts, and provide a window into students' program\ncomprehension. This discussion paper sets an agenda for future technical\ndevelopment and empirical research on the topic.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 09:15:37 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lehtinen", "Teemu", ""], ["Santos", "Andr\u00e9 L.", ""], ["Sorva", "Juha", ""]]}, {"id": "2103.11437", "submitter": "Kaoru Yamaoka", "authors": "Kaoru Yamaoka, Yusuke Kumakoshi, Yuji Yoshimura", "title": "Local Betweenness Centrality Analysis of 30 European Cities", "comments": "26 pages, 13 figures. To be appear in CUPUM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban morphology and socioeconomic aspects of cities have been explored by\nanalysing urban street network. To analyse the network, several variations of\nthe centrality indices are often used. However, its nature has not yet been\nwidely studied, thus leading to an absence of robust visualisation method of\nurban road network characteristics. To fill this gap, we propose to use a set\nof local betweenness centrality and a new simple and robust visualisation\nmethod. By analysing 30 European cities, we found that our method illustrates\ncommon structures of the cities: road segments important for long-distance\ntransportations are concentrated along larger streets while those for short\nrange transportations form clusters around CBD, historical, or residential\ndistricts. Quantitative analysis has corroborated these findings. Our findings\nare useful for urban planners and decision-makers to understand the current\nsituation of the city and make informed decisions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 17:08:04 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Yamaoka", "Kaoru", ""], ["Kumakoshi", "Yusuke", ""], ["Yoshimura", "Yuji", ""]]}, {"id": "2103.11469", "submitter": "Wes Gurnee", "authors": "Wes Gurnee and David B. Shmoys", "title": "Fairmandering: A column generation heuristic for fairness-optimized\n  political districting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DM cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The American winner-take-all congressional district system empowers\npoliticians to engineer electoral outcomes by manipulating district boundaries.\nExisting computational solutions mostly focus on drawing unbiased maps by\nignoring political and demographic input, and instead simply optimize for\ncompactness. We claim that this is a flawed approach because compactness and\nfairness are orthogonal qualities, and introduce a scalable two-stage method to\nexplicitly optimize for arbitrary piecewise-linear definitions of fairness. The\nfirst stage is a randomized divide-and-conquer column generation heuristic\nwhich produces an exponential number of distinct district plans by exploiting\nthe compositional structure of graph partitioning problems. This district\nensemble forms the input to a master selection problem to choose the districts\nto include in the final plan. Our decoupled design allows for unprecedented\nflexibility in defining fairness-aligned objective functions. The pipeline is\narbitrarily parallelizable, is flexible to support additional redistricting\nconstraints, and can be applied to a wide array of other regionalization\nproblems. In the largest ever ensemble study of congressional districts, we use\nour method to understand the range of possible expected outcomes and the\nimplications of this range on potential definitions of fairness.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 19:22:42 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 20:48:15 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gurnee", "Wes", ""], ["Shmoys", "David B.", ""]]}, {"id": "2103.11614", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en and Jessica McBroom and Bryn Jeffries and Irena\n  Koprinska and Kalina Yacef", "title": "ast2vec: Utilizing Recursive Neural Encodings of Python Programs", "comments": "Under consideration at the Journal of Educational Datamining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Educational datamining involves the application of datamining techniques to\nstudent activity. However, in the context of computer programming, many\ndatamining techniques can not be applied because they expect vector-shaped\ninput whereas computer programs have the form of syntax trees. In this paper,\nwe present ast2vec, a neural network that maps Python syntax trees to vectors\nand back, thereby facilitating datamining on computer programs as well as the\ninterpretation of datamining results. Ast2vec has been trained on almost half a\nmillion programs of novice programmers and is designed to be applied across\nlearning tasks without re-training, meaning that users can apply it without any\nneed for (additional) deep learning. We demonstrate the generality of ast2vec\nin three settings: First, we provide example analyses using ast2vec on a\nclassroom-sized dataset, involving visualization, student motion analysis,\nclustering, and outlier detection, including two novel analyses, namely a\nprogress-variance-projection and a dynamical systems analysis. Second, we\nconsider the ability of ast2vec to recover the original syntax tree from its\nvector representation on the training data and two further large-scale\nprogramming datasets. Finally, we evaluate the predictive capability of a\nsimple linear regression on top of ast2vec, obtaining similar results to\ntechniques that work directly on syntax trees. We hope ast2vec can augment the\neducational datamining toolbelt by making analyses of computer programs easier,\nricher, and more efficient.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 06:53:52 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""], ["McBroom", "Jessica", ""], ["Jeffries", "Bryn", ""], ["Koprinska", "Irena", ""], ["Yacef", "Kalina", ""]]}, {"id": "2103.11790", "submitter": "Patrick Schramowski", "authors": "Patrick Schramowski, Cigdem Turan, Nico Andersen, Constantin Rothkopf,\n  Kristian Kersting", "title": "Language Models have a Moral Dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial writing is permeating our lives due to recent advances in\nlarge-scale, transformer-based language models (LMs) such as BERT, its\nvariants, GPT-2/3, and others. Using them as pretrained models and fine-tuning\nthem for specific tasks, researchers have extended the state of the art for\nmany NLP tasks and shown that they not only capture linguistic knowledge but\nalso retain general knowledge implicitly present in the data. These and other\nsuccesses are exciting. Unfortunately, LMs trained on unfiltered text corpora\nsuffer from degenerate and biased behaviour. While this is well established, we\nshow that recent improvements of LMs also store ethical and moral values of the\nsociety and actually bring a ``moral dimension'' to surface: the values are\ncapture geometrically by a direction in the embedding space, reflecting well\nthe agreement of phrases to social norms implicitly expressed in the training\ntexts. This provides a path for attenuating or even preventing toxic\ndegeneration in LMs. Since one can now rate the (non-)normativity of arbitrary\nphrases without explicitly training the LM for this task, the moral dimension\ncan be used as ``moral compass'' guiding (even other) LMs towards producing\nnormative text, as we will show.\n", "versions": [{"version": "v1", "created": "Mon, 8 Mar 2021 16:59:52 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Schramowski", "Patrick", ""], ["Turan", "Cigdem", ""], ["Andersen", "Nico", ""], ["Rothkopf", "Constantin", ""], ["Kersting", "Kristian", ""]]}, {"id": "2103.11806", "submitter": "Scott A. Hale", "authors": "Zo Ahmed, Bertie Vidgen, and Scott A. Hale", "title": "Tackling Racial Bias in Automated Online Hate Detection: Towards Fair\n  and Accurate Classification of Hateful Online Users Using Geometric Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online hate is a growing concern on many social media platforms and other\nsites. To combat it, technology companies are increasingly identifying and\nsanctioning `hateful users' rather than simply moderating hateful content. Yet,\nmost research in online hate detection to date has focused on hateful content.\nThis paper examines how fairer and more accurate hateful user detection systems\ncan be developed by incorporating social network information through geometric\ndeep learning. Geometric deep learning dynamically learns information-rich\nnetwork representations and can generalise to unseen nodes. This is essential\nfor moving beyond manually engineered network features, which lack scalability\nand produce information-sparse network representations. This paper compares the\naccuracy of geometric deep learning with other techniques which either exclude\nnetwork information or incorporate it through manual feature engineering (e.g.,\nnode2vec). It also evaluates the fairness of these techniques using the\n`predictive equality' criteria, comparing the false positive rates on a subset\nof 136 African-American users with 4836 other users. Geometric deep learning\nproduces the most accurate and fairest classifier, with an AUC score of 90.8\\%\non the entire dataset and a false positive rate of zero among the\nAfrican-American subset for the best performing model. This highlights the\nbenefits of more effectively incorporating social network features in automated\nhateful user detection. Such an approach is also easily operationalized for\nreal-world content moderation as it has an efficient and scalable design.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 13:08:11 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Ahmed", "Zo", ""], ["Vidgen", "Bertie", ""], ["Hale", "Scott A.", ""]]}, {"id": "2103.11852", "submitter": "Jack Dunn", "authors": "Jack Dunn and Ying Daisy Zhuo", "title": "Detecting Racial Bias in Jury Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To support the 2019 U.S. Supreme Court case \"Flowers v. Mississippi\", APM\nReports collated historical court records to assess whether the State exhibited\na racial bias in striking potential jurors. This analysis used backward\nstepwise logistic regression to conclude that race was a significant factor,\nhowever this method for selecting relevant features is only a heuristic, and\nadditionally cannot consider interactions between features. We apply Optimal\nFeature Selection to identify the globally-optimal subset of features and\naffirm that there is significant evidence of racial bias in the strike\ndecisions. We also use Optimal Classification Trees to segment the juror\npopulation subgroups with similar characteristics and probability of being\nstruck, and find that three of these subgroups exhibit significant racial\ndisparity in strike rate, pinpointing specific areas of bias in the dataset.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 13:47:33 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Dunn", "Jack", ""], ["Zhuo", "Ying Daisy", ""]]}, {"id": "2103.11958", "submitter": "Wouter Lueks", "authors": "Theresa Stadler, Wouter Lueks, Katharina Kohls, Carmela Troncoso", "title": "Preliminary Analysis of Potential Harms in the Luca Tracing System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this document, we analyse the potential harms a large-scale deployment of\nthe Luca system might cause to individuals, venues, and communities. The Luca\nsystem is a digital presence tracing system designed to provide health\ndepartments with the contact information necessary to alert individuals who\nhave visited a location at the same time as a SARS-CoV-2-positive person.\nMultiple regional health departments in Germany have announced their plans to\ndeploy the Luca system for the purpose of presence tracing. The system's\ndevelopers suggest its use across various types of venues: from bars and\nrestaurants to public and private events, such religious or political\ngatherings, weddings, and birthday parties. Recently, an extension to include\nschools and other educational facilities was discussed in public. Our analysis\nof the potential harms of the system is based on the publicly available Luca\nSecurity Concept which describes the system's security architecture and its\nplanned protection mechanisms. The Security Concept furthermore provides a set\nof claims about the system's security and privacy properties. Besides an\nanalysis of harms, our analysis includes a validation of these claims.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 16:00:55 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Stadler", "Theresa", ""], ["Lueks", "Wouter", ""], ["Kohls", "Katharina", ""], ["Troncoso", "Carmela", ""]]}, {"id": "2103.12016", "submitter": "Christopher Starke", "authors": "Christopher Starke, Janine Baleis, Birte Keller, Frank Marcinkowski", "title": "Fairness Perceptions of Algorithmic Decision-Making: A Systematic Review\n  of the Empirical Literature", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithmic decision-making (ADM) increasingly shapes people's daily lives.\nGiven that such autonomous systems can cause severe harm to individuals and\nsocial groups, fairness concerns have arisen. A human-centric approach demanded\nby scholars and policymakers requires taking people's fairness perceptions into\naccount when designing and implementing ADM. We provide a comprehensive,\nsystematic literature review synthesizing the existing empirical insights on\nperceptions of algorithmic fairness from 39 empirical studies spanning multiple\ndomains and scientific disciplines. Through thorough coding, we systemize the\ncurrent empirical literature along four dimensions: (a) algorithmic predictors,\n(b) human predictors, (c) comparative effects (human decision-making vs.\nalgorithmic decision-making), and (d) consequences of ADM. While we identify\nmuch heterogeneity around the theoretical concepts and empirical measurements\nof algorithmic fairness, the insights come almost exclusively from\nWestern-democratic contexts. By advocating for more interdisciplinary research\nadopting a society-in-the-loop framework, we hope our work will contribute to\nfairer and more responsible ADM.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 17:12:45 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Starke", "Christopher", ""], ["Baleis", "Janine", ""], ["Keller", "Birte", ""], ["Marcinkowski", "Frank", ""]]}, {"id": "2103.12411", "submitter": "Xiaobing Sun", "authors": "Xiaobing Sun, Jiabao Zhang, Qiming Zhao, Shenghua Liu, Jinglei Chen,\n  Ruoyu Zhuang, Huawei Shen, Xueqi Cheng", "title": "CubeFlow: Money Laundering Detection with Coupled Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Money laundering (ML) is the behavior to conceal the source of money achieved\nby illegitimate activities, and always be a fast process involving frequent and\nchained transactions. How can we detect ML and fraudulent activity in large\nscale attributed transaction data (i.e.~tensors)? Most existing methods detect\ndense blocks in a graph or a tensor, which do not consider the fact that money\nare frequently transferred through middle accounts. CubeFlow proposed in this\npaper is a scalable, flow-based approach to spot fraud from a mass of\ntransactions by modeling them as two coupled tensors and applying a novel\nmulti-attribute metric which can reveal the transfer chains accurately.\nExtensive experiments show CubeFlow outperforms state-of-the-art baselines in\nML behavior detection in both synthetic and real data.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 09:24:31 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Sun", "Xiaobing", ""], ["Zhang", "Jiabao", ""], ["Zhao", "Qiming", ""], ["Liu", "Shenghua", ""], ["Chen", "Jinglei", ""], ["Zhuang", "Ruoyu", ""], ["Shen", "Huawei", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2103.12541", "submitter": "Preslav Nakov", "authors": "Firoj Alam, Stefano Cresci, Tanmoy Chakraborty, Fabrizio Silvestri,\n  Dimiter Dimitrov, Giovanni Da San Martino, Shaden Shaar, Hamed Firooz,\n  Preslav Nakov", "title": "A Survey on Multimodal Disinformation Detection", "comments": "disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images, videos, network structure,\n  temporality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI cs.CL cs.CR cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 18:04:17 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Alam", "Firoj", ""], ["Cresci", "Stefano", ""], ["Chakraborty", "Tanmoy", ""], ["Silvestri", "Fabrizio", ""], ["Dimitrov", "Dimiter", ""], ["Martino", "Giovanni Da San", ""], ["Shaar", "Shaden", ""], ["Firooz", "Hamed", ""], ["Nakov", "Preslav", ""]]}, {"id": "2103.12616", "submitter": "Majid Salimi", "authors": "Majid Salimi", "title": "Efficient Multilinear Map from Graded Encoding Scheme", "comments": "15 pagess", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Though the multilinear maps have many cryptographic applications, secure and\nefficient construction of such maps is an open problem. Many multilinear maps\nlike GGH, GGH15, CLT, and CLT15 have been and are being proposed, while none of\nthem is both secure and efficient. The construction of some multilinear maps is\nbased on the Graded Encoding Scheme (GES), where, the necessity of announcing\nzero-testing parameter and encoding of zero has destroyed the security of the\nmultilinear map.\n  Attempt is made to propose a new GES, where, instead of encoding an element,\nthe users can obtain the encoding of an associated but unknown random element.\nIn this new setting, there is no need to publish the encodings of zero and one.\nThis new GES provides the actual functionality of the usual GES and can be\napplied in constructing a secure and efficient multilinear map and a\nmulti-party non-interactive key exchange (MP-NIKE) scheme. We also improve the\nMP-NIKE scheme of \\cite{Access20} and turn it into an ID-based MP-NIKE scheme.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 15:15:23 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Salimi", "Majid", ""]]}, {"id": "2103.12842", "submitter": "Justin Lane", "authors": "Justin E. Lane, Kevin McCaffree, F. LeRon Shults", "title": "Is radicalization reinforced by social media censorship?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Radicalized beliefs, such as those tied to QAnon, Russiagate, and other\npolitical conspiracy theories, can lead some individuals and groups to engage\nin violent behavior, as evidenced in recent months. Understanding the\nmechanisms by which such beliefs are accepted, spread, and intensified is\ncritical for any attempt to mitigate radicalization and avoid increased\npolitical polarization. This article presents and agent-based model of a social\nmedia network that enables investigation of the effects of censorship on the\namount of dissenting information to which agents become exposed and the\ncertainty of their radicalized views. The model explores two forms of\ncensorship: 1) decentralized censorship-in which individuals can choose to\nbreak an online social network tie (unfriend or unfollow) with another\nindividual who transmits conflicting beliefs and 2) centralized censorship-in\nwhich a single authority can ban an individual from the social media network\nfor spreading a certain type of belief. This model suggests that both forms of\ncensorship increase certainty in radicalized views by decreasing the amount of\ndissent to which an agent is exposed, but centralized \"banning\" of individuals\nhas the strongest effect on radicalization.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 21:07:34 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Lane", "Justin E.", ""], ["McCaffree", "Kevin", ""], ["Shults", "F. LeRon", ""]]}, {"id": "2103.13287", "submitter": "Tobias Fiebig", "authors": "Mannat Kaur, Michel van Eeten, Marijn Janssen, Kevin Borgolte, and\n  Tobias Fiebig", "title": "Human Factors in Security Research: Lessons Learned from 2008-2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instead of only considering technology, computer security research now\nstrives to also take into account the human factor by studying regular users\nand, to a lesser extent, experts like operators and developers of systems. We\nfocus our analysis on the research on the crucial population of experts, whose\nhuman errors can impact many systems at once, and compare it to research on\nregular users. To understand how far we advanced in the area of human factors,\nhow the field can further mature, and to provide a point of reference for\nresearchers new to this field, we analyzed the past decade of human factors\nresearch in security and privacy, identifying 557 relevant publications. Of\nthese, we found 48 publications focused on expert users and analyzed all in\ndepth. For additional insights, we compare them to a stratified sample of 48\nend-user studies.\n  In this paper we investigate:\n  (i) The perspective on human factors, and how we can learn from safety\nscience (ii) How and who are the participants recruited, and how this -- as we\nfind -- creates a western-centric perspective (iii) Research objectives, and\nhow to align these with the chosen research methods (iv) How theories can be\nused to increase rigor in the communities scientific work, including\nlimitations to the use of Grounded Theory, which is often incompletely applied\n(v) How researchers handle ethical implications, and what we can do to account\nfor them more consistently\n  Although our literature review has limitations, new insights were revealed\nand avenues for further research identified.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 15:58:05 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Kaur", "Mannat", ""], ["van Eeten", "Michel", ""], ["Janssen", "Marijn", ""], ["Borgolte", "Kevin", ""], ["Fiebig", "Tobias", ""]]}, {"id": "2103.13391", "submitter": "Elochukwu Ukwandu Dr", "authors": "Chinyere A. Nwajiuba and Elochukwu Ukwandu", "title": "Female ICT participation in South-Eastern Nigerian Tertiary\n  Institutions: Inhibiting Factors", "comments": "16 pages, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study examined the participation of female students of South Eastern\nNigerian tertiary institutions in Information and Communication Technologies\n(ICTs). The study discussed the attendant gender divide in ICTs participation,\nreasons for low female participation in ICT, consequences of not bridging the\ndivide and ways of encouraging female participation in ICT. A structured\nquestionnaire was used to elicit information from respondents. A multi stage\nrandom sampling technique was used in the selection of respondents. One hundred\nand thirty six (136) undergraduate female students of tertiary institutions in\nSouth Eastern Nigeria constituted the study sample. Data collected was analysed\nusing descriptive statistics. Findings suggest that high cost of ICT and high\nlevel of male dominance, which made females think that ICT is for males were\nthe major reasons for low female participation in ICT. Reducing the cost of\nInformation Technology, and parental involvement in their children selection\nchoice of study were suggested to encourage female participation in Information\nand Communication Technologies.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2021 21:26:21 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Nwajiuba", "Chinyere A.", ""], ["Ukwandu", "Elochukwu", ""]]}, {"id": "2103.13570", "submitter": "Tao Zhou", "authors": "Jing-Yi Liao, Ying Kong, Tao Zhou", "title": "Quantifying the efficacy of childcare services on women employment", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Women are set back in the labor market after becoming mother. Intuitively,\nchildcare services are able to promote women employment as they may\nreconciliate the motherhood penalty. However, most known studies concentrated\non the effects of childcare services on fertility rate, instead of quantitative\nanalyses about the effects on women employment. Using worldwide panel data and\nChinese data at province level, this paper unfolds the quantitative\nrelationship between childcare services and women employment, that is, the\nattendance rate of childcare services is positively correlated with the\nrelative employment rate of women to men. Further analysis suggests that such a\npositive impact may largely resulted from breaking the vulnerable employment\ndilemma.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 02:42:05 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Liao", "Jing-Yi", ""], ["Kong", "Ying", ""], ["Zhou", "Tao", ""]]}, {"id": "2103.13924", "submitter": "David Benrimoh", "authors": "David Benrimoh, Ely Sibarium, Andrew Sheldon, Albert Powers", "title": "Computational Mechanism for the Effect of Psychosis Community Treatment:\n  A Conceptual Review from Neurobiology to Social Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The computational underpinnings of positive psychotic symptoms have recently\nreceived significant attention. Candidate mechanisms include some combination\nof maladaptive priors and reduced updating of these priors during perception. A\npotential benefit of models with such mechanisms is their ability to link\nmultiple levels of explanation. This is key to improving how we understand the\nexperience of psychosis. Moreover, it points us towards more comprehensive\navenues for therapeutic research by providing a putative mechanism that could\nallow for the generation of new treatments from first principles. In order to\ndemonstrate this, our conceptual paper will discuss the application of the\ninsights from previous computational models to an important and complex set of\nevidence-based clinical interventions with strong social elements, such as\ncoordinated specialty care clinics in early psychosis and assertive community\ntreatment. These interventions may include but also go beyond\npsychopharmacology, providing, we argue, structure and predictability for\npatients experiencing psychosis. We develop the argument that this structure\nand predictability directly counteract the relatively low precision afforded to\nsensory information in psychosis, while also providing the patient more access\nto external cognitive resources in the form of providers and the structure of\nthe programs themselves. We discuss how computational models explain the\nresulting reduction in symptoms, as well as the predictions these models make\nabout potential responses of patients to modifications or to different\nvariations of these interventions. We also link, via the framework of\ncomputational models, the experiences of patients and response to interventions\nto putative neurobiology.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 15:35:47 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Benrimoh", "David", ""], ["Sibarium", "Ely", ""], ["Sheldon", "Andrew", ""], ["Powers", "Albert", ""]]}, {"id": "2103.13954", "submitter": "Carsten Vogel", "authors": "Carsten Vogel, R\\\"udiger Pryss, Johannes Schobel, Winfried Schlee and\n  Felix Beierle", "title": "Developing Apps for Researching the COVID-19 Pandemic with the\n  TrackYourHealth Platform", "comments": "Accepted for publication in the proceedings of the 2021 IEEE/ACM 8th\n  International Conference on Mobile Software Engineering and Systems\n  (MobileSoft)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through lockdowns and other severe changes to daily life, almost everyone is\naffected by the COVID-19 pandemic. Scientists and medical doctors are - among\nothers - mainly interested in researching, monitoring, and improving physical\nand mental health of the general population. Mobile health apps (mHealth), and\napps conducting ecological momentary assessments (EMA) respectively, can help\nin this context. However, developing such mobile applications poses many\nchallenges like costly software development efforts, strict privacy rules,\ncompliance with ethical guidelines, local laws, and regulations. In this paper,\nwe present TrackYourHealth (TYH), a highly configurable, generic, and modular\nmobile data collection and EMA platform, which enabled us to develop and\nrelease two mobile multi-platform applications related to COVID-19 in just a\nfew weeks. We present TYH and highlight specific challenges researchers and\ndevelopers of similar apps may also face, especially when developing apps\nrelated to the medical field.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 16:22:51 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Vogel", "Carsten", ""], ["Pryss", "R\u00fcdiger", ""], ["Schobel", "Johannes", ""], ["Schlee", "Winfried", ""], ["Beierle", "Felix", ""]]}, {"id": "2103.14155", "submitter": "Sanchari Das", "authors": "Callie Monroe, Faiza Tazi, and Sanchari Das", "title": "Location Data and COVID-19 Contact Tracing: How Data Privacy Regulations\n  and Cell Service Providers Work In Tandem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Governments, Healthcare, and Private Organizations in the global scale have\nbeen using digital tracking to keep COVID-19 outbreaks under control. Although\nthis method could limit pandemic contagion, it raises significant concerns\nabout user privacy. Known as ~\"Contact Tracing Apps\", these mobile applications\nare facilitated by Cellphone Service Providers (CSPs), who enable the spatial\nand temporal real-time user tracking. Accordingly, it might be speculated that\nCSPs collect information violating the privacy policies such as GDPR, CCPA, and\nothers. To further clarify, we conducted an in-depth analysis comparing privacy\nlegislations with the real-world practices adapted by CSPs. We found that three\nof the regulations (GDPR, COPPA, and CCPA) analyzed defined mobile location\ndata as private information, and two (T-Mobile US, Boost Mobile) of the five\nCSPs that were analyzed did not comply with the COPPA regulation. Our results\nare crucial in view of the threat these violations represent, especially when\nit comes to children's data. As such proper security and privacy auditing is\nnecessary to curtail such violations. We conclude by providing actionable\nrecommendations to address concerns and provide privacy-preserving monitoring\nof the COVID-19 spread through the contact tracing applications.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 22:13:50 GMT"}, {"version": "v2", "created": "Wed, 7 Apr 2021 17:57:51 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Monroe", "Callie", ""], ["Tazi", "Faiza", ""], ["Das", "Sanchari", ""]]}, {"id": "2103.14587", "submitter": "Yang Han", "authors": "Yang Han, Qi Zhang, Victor O.K. Li, Jacqueline C.K. Lam", "title": "Deep-AIR: A Hybrid CNN-LSTM Framework for Air Quality Modeling in\n  Metropolitan Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Air pollution has long been a serious environmental health challenge,\nespecially in metropolitan cities, where air pollutant concentrations are\nexacerbated by the street canyon effect and high building density. Whilst\naccurately monitoring and forecasting air pollution are highly crucial,\nexisting data-driven models fail to fully address the complex interaction\nbetween air pollution and urban dynamics. Our Deep-AIR, a novel hybrid deep\nlearning framework that combines a convolutional neural network with a long\nshort-term memory network, aims to address this gap to provide fine-grained\ncity-wide air pollution estimation and station-wide forecast. Our proposed\nframework creates 1x1 convolution layers to strengthen the learning of\ncross-feature spatial interaction between air pollution and important urban\ndynamic features, particularly road density, building density/height, and\nstreet canyon effect. Using Hong Kong and Beijing as case studies, Deep-AIR\nachieves a higher accuracy than our baseline models. Our model attains an\naccuracy of 67.6%, 77.2%, and 66.1% in fine-grained hourly estimation, 1-hr,\nand 24-hr air pollution forecast for Hong Kong, and an accuracy of 65.0%,\n75.3%, and 63.5% for Beijing. Our saliency analysis has revealed that for Hong\nKong, street canyon and road density are the best estimators for NO2, while\nmeteorology is the best estimator for PM2.5.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2021 13:47:56 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Han", "Yang", ""], ["Zhang", "Qi", ""], ["Li", "Victor O. K.", ""], ["Lam", "Jacqueline C. K.", ""]]}, {"id": "2103.14601", "submitter": "Nicolas Kourtellis Ph.D.", "authors": "Yelena Mejova and Nicolas Kourtellis", "title": "YouTubing at Home: Media Sharing Behavior Change as Proxy for\n  MobilityAround COVID-19 Lockdowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compliance with public health measures, such as restrictions on movement and\nsocialization, is paramount in limiting the spread of diseases such as the\nsevere acute respiratory syndrome coronavirus 2 (also referred to as COVID-19).\nAlthough large population datasets, such as phone-based mobility data, may\nprovide some glimpse into such compliance, it is often proprietary, and may not\nbe available for all locales. In this work, we examine the usefulness of video\nsharing on social media as a proxy of the amount of time Internet users spend\nat home. In particular, we focus on the number of people sharing YouTube videos\non Twitter before and during COVID-19 lockdown measures were imposed by 109\ncountries. We find that the media sharing behavior differs widely between\ncountries, in some having immediate response to the lockdown decrees - mostly\nby increasing the sharing volume dramatically - while in others having a\nsubstantial lag. We confirm that these insights correlate strongly with\nmobility, as measured using phone data. Finally, we illustrate that both media\nsharing and mobility behaviors change more drastically around mandated\nlockdowns, and less so around more lax recommendations. We make the media\nsharing volume data available to the research community for continued\nmonitoring of behavior change around public health measures.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 17:08:31 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Mejova", "Yelena", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2103.14679", "submitter": "Tom Emery", "authors": "Michel Scheerman, Narges Zarrabi, Martijn Kruiten, Maxime Mog\\'e,\n  Lykle Voort, Annette Langedijk, Ruurd Schoonhoven, Tom Emery", "title": "Secure Platform for Processing Sensitive Data on Shared HPC Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High performance computing clusters operating in shared and batch mode pose\nchallenges for processing sensitive data. In the meantime, the need for secure\nprocessing of sensitive data on HPC system is growing. In this work we present\na novel method for creating secure computing environments on traditional\nmulti-tenant high-performance computing clusters. Our platform as a service\nprovides a customizable, virtualized solution using PCOCC and SLURM to meet\nstrict security requirements without modifying the exist-ing HPC\ninfrastructure. We show how this platform has been used in real-world research\napplications from different research domains. The solution is scalable by\ndesign with low performance overhead and can be generalized for processing\nsensitive data on shared HPC systems imposing high security criteria\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 18:30:33 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Scheerman", "Michel", ""], ["Zarrabi", "Narges", ""], ["Kruiten", "Martijn", ""], ["Mog\u00e9", "Maxime", ""], ["Voort", "Lykle", ""], ["Langedijk", "Annette", ""], ["Schoonhoven", "Ruurd", ""], ["Emery", "Tom", ""]]}, {"id": "2103.14712", "submitter": "Arijit Ray", "authors": "Arijit Ray, Michael Cogswell, Xiao Lin, Kamran Alipour, Ajay\n  Divakaran, Yi Yao, Giedrius Burachas", "title": "Knowing What VQA Does Not: Pointing to Error-Inducing Regions to Improve\n  Explanation Helpfulness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention maps, a popular heatmap-based explanation method for Visual\nQuestion Answering (VQA), are supposed to help users understand the model by\nhighlighting portions of the image/question used by the model to infer answers.\nHowever, we see that users are often misled by current attention map\nvisualizations that point to relevant regions despite the model producing an\nincorrect answer. Hence, we propose Error Maps that clarify the error by\nhighlighting image regions where the model is prone to err. Error maps can\nindicate when a correctly attended region may be processed incorrectly leading\nto an incorrect answer, and hence, improve users' understanding of those cases.\nTo evaluate our new explanations, we further introduce a metric that simulates\nusers' interpretation of explanations to evaluate their potential helpfulness\nto understand model correctness. We finally conduct user studies to see that\nour new explanations help users understand model correctness better than\nbaselines by an expected 30% and that our proxy helpfulness metrics correlate\nstrongly ($\\rho$>0.97) with how well users can predict model correctness.\n", "versions": [{"version": "v1", "created": "Fri, 26 Mar 2021 19:52:32 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 21:15:40 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Ray", "Arijit", ""], ["Cogswell", "Michael", ""], ["Lin", "Xiao", ""], ["Alipour", "Kamran", ""], ["Divakaran", "Ajay", ""], ["Yao", "Yi", ""], ["Burachas", "Giedrius", ""]]}, {"id": "2103.14853", "submitter": "Gavin Buckingham", "authors": "Gavin Buckingham", "title": "Hand tracking for immersive virtual reality: opportunities and\n  challenges", "comments": "8 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hand tracking has become an integral feature of recent generations of\nimmersive virtual reality head-mounted displays. With the widespread adoption\nof this feature, hardware engineers and software developers are faced with an\nexciting array of opportunities and a number of challenges, mostly in relation\nto the human user. In this article, I outline what I see as the main\npossibilities for hand tracking to add value to immersive virtual reality as\nwell as some of the potential challenges in the context of the psychology and\nneuroscience of the human user. It is hoped that this paper serves as a roadmap\nfor the development of best practices in the field for the development of\nsubsequent generations of hand tracking and virtual reality technologies.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2021 09:28:47 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Buckingham", "Gavin", ""]]}, {"id": "2103.15206", "submitter": "Sultan Mahmud", "authors": "Sultan Mahmud, Md. Mohsin, Ijaz Ahmed Khan, Ashraf Uddin Mian, Miah\n  Akib Zaman", "title": "Acceptance of COVID-19 Vaccine and Its Determinants in Bangladesh", "comments": "Original Research Paper, 18 pages, 3 Figures, 4 Tables, 49\n  references, 5 Sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Bangladesh govt. launched a nationwide vaccination drive against\nSARS-CoV-2 infection from early February 2021. The objectives of this study\nwere to evaluate the acceptance of the COVID-19 vaccines and examine the\nfactors associated with the acceptance in Bangladesh.\n  Method: In between January 30 to February 6, 2021, we conducted a web-based\nanonymous cross-sectional survey among the Bangladeshi general population. The\nmultivariate logistic regression was used to identify the factors that\ninfluence the acceptance of the COVID-19 vaccination.\n  Results: 61.16% (370/605) of the respondents were willing to accept/take the\nCOVID-19 vaccine. Among the accepted group, only 35.14% showed the willingness\nto take the COVID-19 vaccine immediately, while 64.86% would delay the\nvaccination until they are confirmed about the vaccine's efficacy and safety or\nCOVID-19 become deadlier in Bangladesh. The regression results showed age,\ngender, location (urban/rural), level of education, income, perceived risk of\nbeing infected with COVID-19 in the future, perceived severity of infection,\nhaving previous vaccination experience after age 18, having higher knowledge\nabout COVID-19 and vaccination were significantly associated with the\nacceptance of COVID-19 vaccines.\n  Conclusion: The research reported a high prevalence of COVID-19 vaccine\nrefusal and hesitancy in Bangladesh. To diminish the vaccine hesitancy and\nincrease the uptake, the policymakers need to design a well-researched\nimmunization strategy to remove the vaccination barriers. To improve vaccine\nacceptance among people, false rumors and misconceptions about the COVID-19\nvaccines must be dispelled (especially on the internet) and people must be\nexposed to the actual scientific facts.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 19:37:47 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Mahmud", "Sultan", ""], ["Mohsin", "Md.", ""], ["Khan", "Ijaz Ahmed", ""], ["Mian", "Ashraf Uddin", ""], ["Zaman", "Miah Akib", ""]]}, {"id": "2103.15237", "submitter": "Hansol Lee", "authors": "Renzhe Yu, Hansol Lee, Ren\\'e F. Kizilcec", "title": "Should College Dropout Prediction Models Include Protected Attributes?", "comments": "In Proceedings of the ACM Conference on Learning at Scale (L@S) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Early identification of college dropouts can provide tremendous value for\nimproving student success and institutional effectiveness, and predictive\nanalytics are increasingly used for this purpose. However, ethical concerns\nhave emerged about whether including protected attributes in the prediction\nmodels discriminates against underrepresented student groups and exacerbates\nexisting inequities. We examine this issue in the context of a large U.S.\nresearch university with both residential and fully online degree-seeking\nstudents. Based on comprehensive institutional records for this entire student\npopulation across multiple years, we build machine learning models to predict\nstudent dropout after one academic year of study, and compare the overall\nperformance and fairness of model predictions with or without four protected\nattributes (gender, URM, first-generation student, and high financial need). We\nfind that including protected attributes does not impact the overall prediction\nperformance and it only marginally improves algorithmic fairness of\npredictions. While these findings suggest that including protected attributes\nis preferred, our analysis also offers guidance on how to evaluate the impact\nin a local context, where institutional stakeholders seek to leverage\npredictive analytics to support student success.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 22:47:30 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 18:53:17 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Yu", "Renzhe", ""], ["Lee", "Hansol", ""], ["Kizilcec", "Ren\u00e9 F.", ""]]}, {"id": "2103.15458", "submitter": "Dimitris Tsakalidis", "authors": "George Domalis, Nikos Karacapilidis, Dimitris Tsakalidis, Anastasios\n  Giannaros", "title": "A trustable and interoperable decentralized solution for citizen-centric\n  and cross-border eGovernance: A conceptual approach", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Aiming to support a cross-sector and cross-border eGovernance paradigm for\nsharing common public services, this paper introduces an AI-enhanced solution\nthat enables beneficiaries to participate in a decenntralized network for\neffective big data exchange and service delivery that promotes the once-only\npriority and is by design digital, efficient, cost-effective, interoperable and\nsecure. The solution comprises (i) a reliable and efficient decentralized\nmechanism for data sharing, capable of addressing the complexity of the\nprocesses and their high demand of resources; (ii) an ecosystem for delivering\nmobile services tailored to the needs of stakeholders; (iii) a single sign-on\nWallet mechanism to manage the transactions with multiple services; and (iv) an\nintercommunication layer, responsible for the secure exchange of information\namong existing eGovernment systems with newly developed ones. An indicative\napplication scenario showcases the potential of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 09:44:52 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 13:25:10 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Domalis", "George", ""], ["Karacapilidis", "Nikos", ""], ["Tsakalidis", "Dimitris", ""], ["Giannaros", "Anastasios", ""]]}, {"id": "2103.15555", "submitter": "Cm Pintea", "authors": "Oliviu Matei, Erdei Rudolf, Camelia-M. Pintea", "title": "Selective Survey: Most Efficient Models and Solvers for Integrative\n  Multimodal Transport", "comments": "12 pages; Accepted: Informatica (ISSN 0868-4952)", "journal-ref": "Informatica, vol. 32, no. 2, pp. 371-396, 2021", "doi": "10.15388/21-INFOR449", "report-no": null, "categories": "cs.AI cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the family of Intelligent Transportation Systems (ITS), Multimodal\nTransport Systems (MMTS) have placed themselves as a mainstream transportation\nmean of our time as a feasible integrative transportation process. The Global\nEconomy progressed with the help of transportation. The volume of goods and\ndistances covered have doubled in the last ten years, so there is a high demand\nof an optimized transportation, fast but with low costs, saving resources but\nalso safe, with low or zero emissions. Thus, it is important to have an\noverview of existing research in this field, to know what was already done and\nwhat is to be studied next. The main objective is to explore a beneficent\nselection of the existing research, methods and information in the field of\nmultimodal transportation research, to identify industry needs and gaps in\nresearch and provide context for future research. The selective survey covers\nmultimodal transport design and optimization in terms of: cost, time, and\nnetwork topology. The multimodal transport theoretical aspects, context and\nresources are also covering various aspects. The survey's selection includes\nnowadays best methods and solvers for Intelligent Transportation Systems (ITS).\nThe gap between theory and real-world applications should be further solved in\norder to optimize the global multimodal transportation system.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2021 08:31:44 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Matei", "Oliviu", ""], ["Rudolf", "Erdei", ""], ["Pintea", "Camelia-M.", ""]]}, {"id": "2103.15753", "submitter": "Pavlos Papadopoulos", "authors": "Pavlos Papadopoulos, Will Abramson, Adam J. Hall, Nikolaos Pitropakis\n  and William J. Buchanan", "title": "Privacy and Trust Redefined in Federated Machine Learning", "comments": "MDPI Mach. Learn. Knowl. Extr. 2021, 3(2), 333-356;\n  https://doi.org/10.3390/make3020017", "journal-ref": "Mach. Learn. Knowl. Extr. 2021, 3(2), 333-356", "doi": "10.3390/make3020017", "report-no": null, "categories": "cs.CR cs.CY cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common privacy issue in traditional machine learning is that data needs to\nbe disclosed for the training procedures. In situations with highly sensitive\ndata such as healthcare records, accessing this information is challenging and\noften prohibited. Luckily, privacy-preserving technologies have been developed\nto overcome this hurdle by distributing the computation of the training and\nensuring the data privacy to their owners. The distribution of the computation\nto multiple participating entities introduces new privacy complications and\nrisks. In this paper, we present a privacy-preserving decentralised workflow\nthat facilitates trusted federated learning among participants. Our\nproof-of-concept defines a trust framework instantiated using decentralised\nidentity technologies being developed under Hyperledger projects\nAries/Indy/Ursa. Only entities in possession of Verifiable Credentials issued\nfrom the appropriate authorities are able to establish secure, authenticated\ncommunication channels authorised to participate in a federated learning\nworkflow related to mental health data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 16:47:01 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 15:07:01 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Papadopoulos", "Pavlos", ""], ["Abramson", "Will", ""], ["Hall", "Adam J.", ""], ["Pitropakis", "Nikolaos", ""], ["Buchanan", "William J.", ""]]}, {"id": "2103.15908", "submitter": "Ali el Hassouni", "authors": "Ali el Hassouni, Mark Hoogendoorn, Marketa Ciharova, Annet Kleiboer,\n  Khadicha Amarti, Vesa Muhonen, Heleen Riper, A. E. Eiben", "title": "pH-RL: A personalization architecture to bring reinforcement learning to\n  health practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While reinforcement learning (RL) has proven to be the approach of choice for\ntackling many complex problems, it remains challenging to develop and deploy RL\nagents in real-life scenarios successfully. This paper presents pH-RL\n(personalization in e-Health with RL) a general RL architecture for\npersonalization to bring RL to health practice. pH-RL allows for various levels\nof personalization in health applications and allows for online and batch\nlearning. Furthermore, we provide a general-purpose implementation framework\nthat can be integrated with various healthcare applications. We describe a\nstep-by-step guideline for the successful deployment of RL policies in a mobile\napplication. We implemented our open-source RL architecture and integrated it\nwith the MoodBuster mobile application for mental health to provide messages to\nincrease daily adherence to the online therapeutic modules. We then performed a\ncomprehensive study with human participants over a sustained period. Our\nexperimental results show that the developed policies learn to select\nappropriate actions consistently using only a few days' worth of data.\nFurthermore, we empirically demonstrate the stability of the learned policies\nduring the study.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 19:38:04 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 00:46:39 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Hassouni", "Ali el", ""], ["Hoogendoorn", "Mark", ""], ["Ciharova", "Marketa", ""], ["Kleiboer", "Annet", ""], ["Amarti", "Khadicha", ""], ["Muhonen", "Vesa", ""], ["Riper", "Heleen", ""], ["Eiben", "A. E.", ""]]}, {"id": "2103.15909", "submitter": "Massimo Stella", "authors": "Massimo Stella, Michael S. Vitevitch and Federico Botta", "title": "Cognitive networks identify the content of English and Italian popular\n  posts about COVID-19 vaccines: Anticipation, logistics, conspiracy and loss\n  of trust", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Monitoring social discourse about COVID-19 vaccines is key to understanding\nhow large populations perceive vaccination campaigns. We focus on 4765 unique\npopular tweets in English or Italian about COVID-19 vaccines between 12/2020\nand 03/2021. One popular English tweet was liked up to 495,000 times, stressing\nhow popular tweets affected cognitively massive populations. We investigate\nboth text and multimedia in tweets, building a knowledge graph of\nsyntactic/semantic associations in messages including visual features and\nindicating how online users framed social discourse mostly around the logistics\nof vaccine distribution. The English semantic frame of \"vaccine\" was highly\npolarised between trust/anticipation (towards the vaccine as a scientific asset\nsaving lives) and anger/sadness (mentioning critical issues with dose\nadministering). Semantic associations with \"vaccine,\" \"hoax\" and conspiratorial\njargon indicated the persistence of conspiracy theories and vaccines in\nmassively read English posts (absent in Italian messages). The image analysis\nfound that popular tweets with images of people wearing face masks used\nlanguage lacking the trust and joy found in tweets showing people with no\nmasks, indicating a negative affect attributed to face covering in social\ndiscourse. A behavioural analysis revealed a tendency for users to share\ncontent eliciting joy, sadness and disgust and to like less sad messages,\nhighlighting an interplay between emotions and content diffusion beyond\nsentiment. With the AstraZeneca vaccine being suspended in mid March 2021,\n\"Astrazeneca\" was associated with trustful language driven by experts, but\npopular Italian tweets framed \"vaccine\" by crucially replacing earlier levels\nof trust with deep sadness. Our results stress how cognitive networks and\ninnovative multimedia processing open new ways for reconstructing online\nperceptions about vaccines and trust.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 19:38:13 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Stella", "Massimo", ""], ["Vitevitch", "Michael S.", ""], ["Botta", "Federico", ""]]}, {"id": "2103.16085", "submitter": "Haftu Reda", "authors": "Haftu Tasew Reda, Adnan Anwar, Abdun Naser Mahmood, and Zahir Tari", "title": "A Taxonomy of Cyber Defence Strategies Against False Data Attacks in\n  Smart Grid", "comments": "35 pages, prepared using the 'acmsmall' document class. arXiv admin\n  note: substantial text overlap with arXiv:2103.10594", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Modern electric power grid, known as the Smart Grid, has fast transformed the\nisolated and centrally controlled power system to a fast and massively\nconnected cyber-physical system that benefits from the revolutions happening in\nthe communications and the fast adoption of Internet of Things devices. While\nthe synergy of a vast number of cyber-physical entities has allowed the Smart\nGrid to be much more effective and sustainable in meeting the growing global\nenergy challenges, it has also brought with it a large number of\nvulnerabilities resulting in breaches of data integrity, confidentiality and\navailability. False data injection (FDI) appears to be among the most critical\ncyberattacks and has been a focal point interest for both research and\nindustry. To this end, this paper presents a comprehensive review in the recent\nadvances of the defence countermeasures of the FDI attacks in the Smart Grid\ninfrastructure. Relevant existing literature are evaluated and compared in\nterms of their theoretical and practical significance to the Smart Grid\ncybersecurity. In conclusion, a range of technical limitations of existing\nfalse data attack detection researches are identified, and a number of future\nresearch directions are recommended.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 05:36:09 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Reda", "Haftu Tasew", ""], ["Anwar", "Adnan", ""], ["Mahmood", "Abdun Naser", ""], ["Tari", "Zahir", ""]]}, {"id": "2103.16387", "submitter": "Carlo Romano Marcello Alessandro Santagiustina", "authors": "Carlo Santagiustina and Massimo Warglien", "title": "The Unfolding Structure of Arguments in Online Debates: The case of a\n  No-Deal Brexit", "comments": "Main article (18 pages, 7 figures) & Supplementary material (25\n  pages, 7 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the last decade, political debates have progressively shifted to social\nmedia. Rhetorical devices employed by online actors and factions that operate\nin these debating arenas can be captured and analysed to conduct a statistical\nreading of societal controversies and their argumentation dynamics. In this\npaper, we propose a five-step methodology, to extract, categorize and explore\nthe latent argumentation structures of online debates. Using Twitter data about\na \"no-deal\" Brexit, we focus on the expected effects in case of materialisation\nof this event. First, we extract cause-effect claims contained in tweets using\nRegEx that exploit verbs related to Creation, Destruction and Causation.\nSecond, we categorise extracted \"no-deal\" effects using a Structural Topic\nModel estimated on unigrams and bigrams. Third, we select controversial effect\ntopics and explore within-topic argumentation differences between self-declared\npartisan user factions. We hence type topics using estimated covariate effects\non topic propensities, then, using the topics correlation network, we study the\ntopological structure of the debate to identify coherent topical\nconstellations. Finally, we analyse the debate time dynamics and infer\nlead/follow relations among factions. Results show that the proposed\nmethodology can be employed to perform a statistical rhetorics analysis of\ndebates, and map the architecture of controversies across time. In particular,\nthe \"no-deal\" Brexit debate is shown to have an assortative argumentation\nstructure heavily characterized by factional constellations of arguments, as\nwell as by polarized narrative frames invoked through verbs related to Creation\nand Destruction. Our findings highlight the benefits of implementing a systemic\napproach to the analysis of debates, which allows the unveiling of topical and\nfactional dependencies between arguments employed in online debates.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 12:29:43 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Santagiustina", "Carlo", ""], ["Warglien", "Massimo", ""]]}, {"id": "2103.16446", "submitter": "Richard Plant", "authors": "Richard Plant (for the Edinburgh Napier CSO Covidtracker project team)", "title": "COVID-19 UK Social Media Dataset for Public Health Research: Methodology\n  for Collection and Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a benchmark database of public social media postings from the\nUnited Kingdom related to the Covid-19 pandemic for academic research purposes,\nalong with some initial analysis, including a taxonomy of key themes organised\nby keyword. This release supports the findings of a research study funded by\nthe Scottish Government Chief Scientist Office that aims to investigate social\nsentiment in order to understand the response to public health measures\nimplemented during the pandemic.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 15:44:48 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Plant", "Richard", "", "for the Edinburgh Napier CSO Covidtracker project team"]]}, {"id": "2103.16455", "submitter": "Yasodara Cordova", "authors": "Yasodara Cordova", "title": "Privacidade digital como direito do cidadao: o caso dos grupos indigenas\n  do Brasil", "comments": "13 pages, 7 figures, in Portuguese-Brasil", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The article presents a brief review of the Brazilian legislation that impacts\nindigenous communities' digital privacy rights through governmental data\ncollection. Furthermore, the article aims to discuss the need to collect\nsensitive data from indigenous communities without the participation of the\nsame communities in developing the features for the data collection. The\narticle argues that the digitalization of indigenous communities' information\nfollows a colonial paradigm, harming entire indigenous communities and\nworsening their already precarious situation.\n  --\n  O artigo apresenta uma breve revis\\~ao da legisla\\c{c}\\~ao brasileira que\nimpacta os direitos de privacidade digital das comunidades ind\\'igenas por meio\nda coleta de dados governamentais. Al\\'em disso, o artigo visa discutir a\nnecessidade de coletar dados sens\\'iveis de comunidades ind\\'igenas sem a\nparticipa\\c{c}\\~ao das mesmas comunidades no desenvolvimento dos recursos para\na coleta de dados. O artigo argumenta que a digitaliza\\c{c}\\~ao das\ninforma\\c{c}\\~oes das comunidades ind\\'igenas segue um paradigma colonial,\nprejudicando comunidades ind\\'igenas inteiras e agravando sua situa\\c{c}\\~ao\nj\\'a prec\\'aria.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 16:00:39 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Cordova", "Yasodara", ""]]}, {"id": "2103.16476", "submitter": "Geri Dimas", "authors": "Geri L. Dimas, Renata A. Konrad, Kayse Lee Maass, Andrew C. Trapp", "title": "A Survey of Operations Research and Analytics Literature Related to\n  Anti-Human Trafficking", "comments": "28 pages, 6 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human trafficking is a compound social, economic, and human rights issue\noccurring in all regions of the world. Understanding and addressing such a\ncomplex crime requires effort from multiple domains and perspectives. As of\nthis writing, no systematic review exists of the Operations Research and\nAnalytics literature applied to the domain of human trafficking. The purpose of\nthis work is to fill this gap through a systematic literature review. Studies\nmatching our search criteria were found ranging from 2010 to March 2021. These\nstudies were gathered and analyzed to help answer the following three research\nquestions: (i) What aspects of human trafficking are being studied by\nOperations Research and Analytics researchers? (ii) What Operations Research\nand Analytics methods are being applied in the anti-human trafficking domain?\nand (iii) What are the existing research gaps associated with (i) and (ii)? By\nanswering these questions, we illuminate the extent to which these topics have\nbeen addressed in the literature, as well as inform future research\nopportunities in applying analytical methods to advance the fight against human\ntrafficking.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 16:32:57 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 13:08:57 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Dimas", "Geri L.", ""], ["Konrad", "Renata A.", ""], ["Maass", "Kayse Lee", ""], ["Trapp", "Andrew C.", ""]]}, {"id": "2103.16613", "submitter": "Diego Saez-Trumper", "authors": "Roldolfo Valentim, Giovanni Comarela, Souneil Park and Diego\n  Saez-Trumper", "title": "Tracking Knowledge Propagation Across Wikipedia Languages", "comments": null, "journal-ref": "15th International Conference on Web and Social Media (ICWSM-21),\n  2021", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a dataset of inter-language knowledge propagation\nin Wikipedia. Covering the entire 309 language editions and 33M articles, the\ndataset aims to track the full propagation history of Wikipedia concepts, and\nallow follow up research on building predictive models of them. For this\npurpose, we align all the Wikipedia articles in a language-agnostic manner\naccording to the concept they cover, which results in 13M propagation\ninstances. To the best of our knowledge, this dataset is the first to explore\nthe full inter-language propagation at a large scale. Together with the\ndataset, a holistic overview of the propagation and key insights about the\nunderlying structural factors are provided to aid future research. For example,\nwe find that although long cascades are unusual, the propagation tends to\ncontinue further once it reaches more than four language editions. We also find\nthat the size of language editions is associated with the speed of propagation.\nWe believe the dataset not only contributes to the prior literature on\nWikipedia growth but also enables new use cases such as edit recommendation for\naddressing knowledge gaps, detection of disinformation, and cultural\nrelationship analysis.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 18:36:13 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Valentim", "Roldolfo", ""], ["Comarela", "Giovanni", ""], ["Park", "Souneil", ""], ["Saez-Trumper", "Diego", ""]]}, {"id": "2103.16910", "submitter": "Philip Winter", "authors": "Philip Matthias Winter, Sebastian Eder, Johannes Weissenb\\\"ock,\n  Christoph Schwald, Thomas Doms, Tom Vogt, Sepp Hochreiter, Bernhard Nessler", "title": "Trusted Artificial Intelligence: Towards Certification of Machine\n  Learning Applications", "comments": "48 pages, 11 figures, soft-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence is one of the fastest growing technologies of the\n21st century and accompanies us in our daily lives when interacting with\ntechnical applications. However, reliance on such technical systems is crucial\nfor their widespread applicability and acceptance. The societal tools to\nexpress reliance are usually formalized by lawful regulations, i.e., standards,\nnorms, accreditations, and certificates. Therefore, the T\\\"UV AUSTRIA Group in\ncooperation with the Institute for Machine Learning at the Johannes Kepler\nUniversity Linz, proposes a certification process and an audit catalog for\nMachine Learning applications. We are convinced that our approach can serve as\nthe foundation for the certification of applications that use Machine Learning\nand Deep Learning, the techniques that drive the current revolution in\nArtificial Intelligence. While certain high-risk areas, such as fully\nautonomous robots in workspaces shared with humans, are still some time away\nfrom certification, we aim to cover low-risk applications with our\ncertification procedure. Our holistic approach attempts to analyze Machine\nLearning applications from multiple perspectives to evaluate and verify the\naspects of secure software development, functional requirements, data quality,\ndata protection, and ethics. Inspired by existing work, we introduce four\ncriticality levels to map the criticality of a Machine Learning application\nregarding the impact of its decisions on people, environment, and\norganizations. Currently, the audit catalog can be applied to low-risk\napplications within the scope of supervised learning as commonly encountered in\nindustry. Guided by field experience, scientific developments, and market\ndemands, the audit catalog will be extended and modified accordingly.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 08:59:55 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Winter", "Philip Matthias", ""], ["Eder", "Sebastian", ""], ["Weissenb\u00f6ck", "Johannes", ""], ["Schwald", "Christoph", ""], ["Doms", "Thomas", ""], ["Vogt", "Tom", ""], ["Hochreiter", "Sepp", ""], ["Nessler", "Bernhard", ""]]}, {"id": "2103.16953", "submitter": "Kalia Orphanou", "authors": "Kalia Orphanou, Jahna Otterbacher, Styliani Kleanthous, Khuyagbaatar\n  Batsuren, Fausto Giunchiglia, Veronika Bogina, Avital Shulner Tal,\n  AlanHartman and Tsvi Kuflik", "title": "Mitigating Bias in Algorithmic Systems: A Fish-Eye View of Problems and\n  Solutions Across Domains", "comments": "44 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mitigating bias in algorithmic systems is a critical issue drawing attention\nacross communities within the information and computer sciences. Given the\ncomplexity of the problem and the involvement of multiple stakeholders,\nincluding developers, end-users and third-parties, there is a need to\nunderstand the landscape of the sources of bias, and the solutions being\nproposed to address them. This survey provides a 'fish-eye view', examining\napproaches across four areas of research. The literature describes three steps\ntoward a comprehensive treatment: bias detection, fairness management and\nexplainability management, and underscores the need to work from within the\nsystem as well as from the perspective of stakeholders in the broader context.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 10:14:28 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Orphanou", "Kalia", ""], ["Otterbacher", "Jahna", ""], ["Kleanthous", "Styliani", ""], ["Batsuren", "Khuyagbaatar", ""], ["Giunchiglia", "Fausto", ""], ["Bogina", "Veronika", ""], ["Tal", "Avital Shulner", ""], ["AlanHartman", "", ""], ["Kuflik", "Tsvi", ""]]}, {"id": "2103.17109", "submitter": "Juan Luis Herrera", "authors": "Juan Luis Herrera, Javier Berrocal, Jose Garcia-Alonso, Juan Manuel\n  Murillo, Hsiao-Yuan Chen, Christine Julien, Niko M\\\"akitalo, Tommi Mikkonen", "title": "Personal Data Gentrification", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We live in an era in which the most valued services are not paid for in\nmoney, but in personal data. Every day, service providers collect the personal\ninformation of billions of individuals, information that sustain their\ninfrastructure by marketing profiles labeled with this information to personal\ndata consumers, such as advertisers. Not all uses of this personal data are for\nmarketing; data consumers can also include, for instance, public health\nauthorities tracking pandemics. In either case, individuals have undergone a\nprocess of Personal Data Gentrification, as data ownership has shifted from\nindividuals to service providers and data consumers, as if the data is worth\nnothing to the individuals; these new owners then harness the data to obtain\nlarge profits. Current privacy-enhancing technologies are beginning to allow\nindividuals to control and share less information. However, not sharing\nindividuals' personal information at all could lead to Personal Data Blight, in\nwhich the potential of personal data in applications that benefit all of\nsociety remains forever latent. In this paper, we propose Personal Data\nEnfranchisement as a middle ground, empowering individuals to control the\nsharing of their personal information to shift the business flows of personal\ninformation. Based on these insights, we propose a model to gradually and\nincrementally make a shift from our current situation towards one of Personal\nData Enfranchisement. Finally, we present a roadmap and some challenges towards\nachieving this bold vision.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 14:26:05 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Herrera", "Juan Luis", ""], ["Berrocal", "Javier", ""], ["Garcia-Alonso", "Jose", ""], ["Murillo", "Juan Manuel", ""], ["Chen", "Hsiao-Yuan", ""], ["Julien", "Christine", ""], ["M\u00e4kitalo", "Niko", ""], ["Mikkonen", "Tommi", ""]]}]