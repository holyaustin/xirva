[{"id": "1905.00140", "submitter": "Luca Maria Aiello", "authors": "Luca Maria Aiello, Rossano Schifanella, Daniele Quercia, Lucia Del\n  Prete", "title": "Large-scale and high-resolution analysis of food purchases and health\n  outcomes", "comments": "23 pages, 8 figures, 3 tables", "journal-ref": "EPJ Data Science 2019 8:14", "doi": "10.1140/epjds/s13688-019-0191-y", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To complement traditional dietary surveys, which are costly and of limited\nscale, researchers have resorted to digital data to infer the impact of eating\nhabits on people's health. However, online studies are limited in resolution:\nthey are carried out at regional level and do not capture precisely the\ncomposition of the food consumed. We study the association between food\nconsumption (derived from the loyalty cards of the main grocery retailer in\nLondon) and health outcomes (derived from publicly-available medical\nprescription records). The scale and granularity of our analysis is\nunprecedented: we analyze 1.6B food item purchases and 1.1B medical\nprescriptions for the entire city of London over the course of one year. By\nstudying food consumption down to the level of nutrients, we show that nutrient\ndiversity and amount of calories are the strongest predictors of the prevalence\nof three diseases related to what is called the \"metabolic syndrome\":\nhypertension, high cholesterol, and diabetes. This syndrome is a cluster of\nsymptoms generally associated with obesity, is common across the rich world,\nand affects one in four adults in the UK. Our linear regression models achieve\nan R2 of 0.6 when estimating the prevalence of diabetes in nearly 1000 census\nareas in London, and a classifier can identify (un)healthy areas with up to 91%\naccuracy. Interestingly, healthy areas are not necessarily well-off (income\nmatters less than what one would expect) and have distinctive features: they\ntend to systematically eat less carbohydrates and sugar, diversify nutrients,\nand avoid large quantities. More generally, our study shows that analytics of\ndigital records of grocery purchases can be used as a cheap and scalable tool\nfor health surveillance and, upon these records, different stakeholders from\ngovernments to insurance companies to food companies could implement effective\nprevention strategies.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 23:51:57 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Aiello", "Luca Maria", ""], ["Schifanella", "Rossano", ""], ["Quercia", "Daniele", ""], ["Del Prete", "Lucia", ""]]}, {"id": "1905.00288", "submitter": "Kieran Woodward Mr", "authors": "Kieran Woodward, Eiman Kanjo, David Brown, T.M. McGinnity, Becky\n  Inkster, Donald J Macintyre, Athanasios Tsanas", "title": "Beyond Mobile Apps: A Survey of Technologies for Mental Well-being", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mental health problems are on the rise globally and strain national health\nsystems worldwide. Mental disorders are closely associated with fear of stigma,\nstructural barriers such as financial burden, and lack of available services\nand resources which often prohibit the delivery of frequent clinical advice and\nmonitoring. Technologies for mental well-being exhibit a range of attractive\nproperties, which facilitate the delivery of state-of-the-art clinical\nmonitoring. This review article provides an overview of traditional techniques\nfollowed by their technological alternatives, sensing devices, behaviour\nchanging tools, and feedback interfaces. The challenges presented by these\ntechnologies are then discussed with data collection, privacy, and battery life\nbeing some of the key issues which need to be carefully considered for the\nsuccessful deployment of mental health toolkits. Finally, the opportunities\nthis growing research area presents are discussed including the use of portable\ntangible interfaces combining sensing and feedback technologies. Capitalising\non the data these ubiquitous devices can record, state of the art machine\nlearning algorithms can lead to the development of robust clinical decision\nsupport tools towards diagnosis and improvement of mental well-being delivery\nin real-time.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 12:50:26 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 13:57:27 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 18:16:09 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Woodward", "Kieran", ""], ["Kanjo", "Eiman", ""], ["Brown", "David", ""], ["McGinnity", "T. M.", ""], ["Inkster", "Becky", ""], ["Macintyre", "Donald J", ""], ["Tsanas", "Athanasios", ""]]}, {"id": "1905.00487", "submitter": "Amjad Rehman Dr", "authors": "Tanzila Saba", "title": "Online Decision Process based on Machine Learning Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyses role of internet in marketing and its influences on\nbusiness decision-making process. It explains how the decision maker collect\nvariety of information about customers through internet and analysis this data\nto better use it in enhancing the processes and the overall performance of the\norganization. In addition, how each department in an organization collaborates\nand use these information through data warehousing. Accordingly, a business\nintelligence model is proposed for web segmentation that divides potential\nmarkets or consumers into specific groups and analysis them for better decision\nmaking. The model further plans to push the significance of web opportunities\nin directing the web division and gathering client information. It is exhibited\nhow marketing information system include customers, equipment and procedures\nanalysis contribute to help decision makers make better decision.\n", "versions": [{"version": "v1", "created": "Sat, 23 Mar 2019 10:42:44 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 10:56:24 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Saba", "Tanzila", ""]]}, {"id": "1905.00490", "submitter": "Stephan Chalup", "authors": "Fayeem Aziz, Stephan K. Chalup and James Juniper", "title": "Big Data in IoT Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data in IoT is a large and fast-developing area where many different\nmethods and techniques can play a role. Due to rapid progress in Machine\nLearning and new hardware developments, a dynamic turnaround of methods and\ntechnologies can be observed. This overview therefore tries to be broad and\nhighlevel without claiming to be comprehensive. Its approach towards Big Data\nand IoT is predicated on a distinction between the digital economy and the\ncharacteristics of what Robin Milner has described as the Ubiquitous Computing\nSystem.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:46:03 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Aziz", "Fayeem", ""], ["Chalup", "Stephan K.", ""], ["Juniper", "James", ""]]}, {"id": "1905.00492", "submitter": "Fatemeh Afghah", "authors": "Fatemeh Afghah, Abolfazl Razi, Jacob Chakareski, Jonathan Ashdown", "title": "Wildfire Monitoring in Remote Areas using Autonomous Unmanned Aerial\n  Vehicles", "comments": "9 pages, 4 figures, accepted in IEEE INFOCOM workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a drone-based wildfire monitoring system for remote\nand hard-to-reach areas. This system utilizes autonomous unmanned aerial\nvehicles (UAVs) with the main advantage of providing on-demand monitoring\nservice faster than the current approaches of using satellite images, manned\naircraft and remotely controlled drones. Furthermore, using autonomous drones\nfacilitates minimizing human intervention in risky wildfire zones. In\nparticular, to develop a fully autonomous system, we propose a distributed\nleader-follower coalition formation model to cluster a set of drones into\nmultiple coalitions that collectively cover the designated monitoring field.\nThe coalition leader is a drone %with longer communication range that employs\nobserver drones potentially with different sensing and imaging %actuation\ncapabilities to hover in circular paths and collect imagery information from\nthe impacted areas. The objectives of the proposed system include i) to cover\nthe entire fire zone with a minimum number of drones, and ii) to minimize the\nenergy consumption and latency of the available drones to fly to the fire zone.\nSimulation results confirm that the performance of the proposed system --\nwithout the need for inter-coalition communications -- approaches that of a\ncentrally-optimized system.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 23:54:22 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Afghah", "Fatemeh", ""], ["Razi", "Abolfazl", ""], ["Chakareski", "Jacob", ""], ["Ashdown", "Jonathan", ""]]}, {"id": "1905.00493", "submitter": "Muhammad Usama", "authors": "Siddique Latif, Adnan Qayyum, Muhammad Usama, Junaid Qadir, Andrej\n  Zwitter, and Muhammad Shahzad", "title": "Caveat emptor: the risks of using big data for human development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data revolution promises to be instrumental in facilitating sustainable\ndevelopment in many sectors of life such as education, health, agriculture, and\nin combating humanitarian crises and violent conflicts. However, lurking\nbeneath the immense promises of big data are some significant risks such as (1)\nthe potential use of big data for unethical ends; (2) its ability to mislead\nthrough reliance on unrepresentative and biased data; and (3) the various\nprivacy and security challenges associated with data (including the danger of\nan adversary tampering with the data to harm people). These risks can have\nsevere consequences and a better understanding of these risks is the first step\ntowards mitigation of these risks. In this paper, we highlight the potential\ndangers associated with using big data, particularly for human development.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2019 15:58:20 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Latif", "Siddique", ""], ["Qayyum", "Adnan", ""], ["Usama", "Muhammad", ""], ["Qadir", "Junaid", ""], ["Zwitter", "Andrej", ""], ["Shahzad", "Muhammad", ""]]}, {"id": "1905.00501", "submitter": "Ricardo Vinuesa", "authors": "Ricardo Vinuesa, Hossein Azizpour, Iolanda Leite, Madeline Balaam,\n  Virginia Dignum, Sami Domisch, Anna Fell\\\"ander, Simone Langhans, Max Tegmark\n  and Francesco Fuso Nerini", "title": "The role of artificial intelligence in achieving the Sustainable\n  Development Goals", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-019-14108-y", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of artificial intelligence (AI) and its progressively wider\nimpact on many sectors across the society requires an assessment of its effect\non sustainable development. Here we analyze published evidence of positive or\nnegative impacts of AI on the achievement of each of the 17 goals and 169\ntargets of the 2030 Agenda for Sustainable Development. We find that AI can\nsupport the achievement of 128 targets across all SDGs, but it may also inhibit\n58 targets. Notably, AI enables new technologies that improve efficiency and\nproductivity, but it may also lead to increased inequalities among and within\ncountries, thus hindering the achievement of the 2030 Agenda. The fast\ndevelopment of AI needs to be supported by appropriate policy and regulation.\nOtherwise, it would lead to gaps in transparency, accountability, safety and\nethical standards of AI-based technology, which could be detrimental towards\nthe development and sustainable use of AI. Finally, there is a lack of research\nassessing the medium- and long-term impacts of AI. It is therefore essential to\nreinforce the global debate regarding the use of AI and to develop the\nnecessary regulatory insight and oversight for AI-based technologies.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 08:43:50 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Vinuesa", "Ricardo", ""], ["Azizpour", "Hossein", ""], ["Leite", "Iolanda", ""], ["Balaam", "Madeline", ""], ["Dignum", "Virginia", ""], ["Domisch", "Sami", ""], ["Fell\u00e4nder", "Anna", ""], ["Langhans", "Simone", ""], ["Tegmark", "Max", ""], ["Nerini", "Francesco Fuso", ""]]}, {"id": "1905.00614", "submitter": "Ross Gruetzemacher", "authors": "Ross Gruetzemacher, David Paradice", "title": "Alternative Techniques for Mapping Paths to HLAI", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The only systematic mapping of the HLAI technical landscape was conducted at\na workshop in 2009 [Adams et al., 2012]. However, the results from it were not\nwhat organizers had hoped for [Goertzel 2014, 2016], merely just a series of\nmilestones, up to 50% of which could be argued to have been completed already.\nWe consider two more recent articles outlining paths to human-like intelligence\n[Mikolov et al., 2016; Lake et al., 2017]. These offer technical and more\nrefined assessments of the requirements for HLAI rather than just milestones.\nWhile useful, they also have limitations. To address these limitations we\npropose the use of alternative techniques for an updated systematic mapping of\nthe paths to HLAI. The newly proposed alternative techniques can model complex\npaths of future technologies using intricate directed graphs. Specifically,\nthere are two classes of alternative techniques that we consider: scenario\nmapping methods and techniques for eliciting expert opinion through digital\nplatforms and crowdsourcing. We assess the viability and utility of both the\nprevious and alternative techniques, finding that the proposed alternative\ntechniques could be very beneficial in advancing the existing body of knowledge\non the plausible frameworks for creating HLAI. In conclusion, we encourage\ndiscussion and debate to initiate efforts to use these proposed techniques for\nmapping paths to HLAI.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 08:26:36 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Gruetzemacher", "Ross", ""], ["Paradice", "David", ""]]}, {"id": "1905.00687", "submitter": "Fares Zaidi", "authors": "Fares Zaidi (RI2C - LITIS), Laurent Amanton (RI2C - LITIS), Eric\n  Sanlaville (RI2C - LITIS)", "title": "Towards a Novel Cooperative Logistics Information System Framework", "comments": null, "journal-ref": "7th International Conference on Information Systems, Logistics and\n  Supply Chain (ILS2018), Jul 2018, Lyon, France", "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supply Chains and Logistics have a growing importance in global economy.\nSupply Chain Information Systems over the world are heterogeneous and each one\ncan both produce and receive massive amounts of structured and unstructured\ndata in real-time, which are usually generated by information systems,\nconnected objects or manually by humans. This heterogeneity is due to Logistics\nInformation Systems components and processes that are developed by different\nmodelling methods and running on many platforms; hence, decision making process\nis difficult in such multi-actor environment. In this paper we identify some\ncurrent challenges and integration issues between separately designed Logistics\nInformation Systems (LIS), and we propose a Distributed Cooperative Logistics\nPlatform (DCLP) framework based on NoSQL, which facilitates real-time\ncooperation between stakeholders and improves decision making process in a\nmulti-actor environment. We included also a case study of Hospital Supply Chain\n(HSC), and a brief discussion on perspectives and future scope of work.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 12:03:52 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Zaidi", "Fares", "", "RI2C - LITIS"], ["Amanton", "Laurent", "", "RI2C - LITIS"], ["Sanlaville", "Eric", "", "RI2C - LITIS"]]}, {"id": "1905.00752", "submitter": "Isaac Mativo", "authors": "Isaac Mativo, Yelena Yesha, Michael Grasso, Tim Oates, Qian Zhu", "title": "Hybrid Mortality Prediction using Multiple Source Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of artificial intelligence in clinical care to improve decision\nsupport systems is increasing. This is not surprising since, by its very\nnature, the practice of medicine consists of making decisions based on\nobservations from different systems both inside and outside the human body. In\nthis paper, we combine three general systems (ICU, diabetes, and comorbidities)\nand use them to make patient clinical predictions. We use an artificial\nintelligence approach to show that we can improve mortality prediction of\nhospitalized diabetic patients. We do this by utilizing a machine learning\napproach to select clinical input features that are more likely to predict\nmortality. We then use these features to create a hybrid mortality prediction\nmodel and compare our results to non-artificial intelligence models. For\nsimplicity, we limit our input features to patient comorbidities and features\nderived from a well-known mortality measure, the Sequential Organ Failure\nAssessment (SOFA).\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 03:32:57 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Mativo", "Isaac", ""], ["Yesha", "Yelena", ""], ["Grasso", "Michael", ""], ["Oates", "Tim", ""], ["Zhu", "Qian", ""]]}, {"id": "1905.00825", "submitter": "Josemar Caetano", "authors": "Josemar Alves Caetano, Gabriel Magno, Marcos Gon\\c{c}alves, Jussara\n  Almeida, Humberto T. Marques-Neto, Virg\\'ilio Almeida", "title": "Characterizing Attention Cascades in WhatsApp Groups", "comments": "Accepted as a full paper at the 11th International ACM Web Science\n  Conference (WebSci 2019). Please cite the WebSci version", "journal-ref": null, "doi": "10.1145/3292522.3326018", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important political and social phenomena discussed in several countries,\nlike India and Brazil, is the use of WhatsApp to spread false or misleading\ncontent. However, little is known about the information dissemination process\nin WhatsApp groups. Attention affects the dissemination of information in\nWhatsApp groups, determining what topics or subjects are more attractive to\nparticipants of a group. In this paper, we characterize and analyze how\nattention propagates among the participants of a WhatsApp group. An attention\ncascade begins when a user asserts a topic in a message to the group, which\ncould include written text, photos, or links to articles online. Others then\npropagate the information by responding to it. We analyzed attention cascades\nin more than 1.7 million messages posted in 120 groups over one year. Our\nanalysis focused on the structural and temporal evolution of attention cascades\nas well as on the behavior of users that participate in them. We found specific\ncharacteristics in cascades associated with groups that discuss political\nsubjects and false information. For instance, we observe that cascades with\nfalse information tend to be deeper, reach more users, and last longer in\npolitical groups than in non-political groups.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 16:00:52 GMT"}, {"version": "v2", "created": "Sat, 4 May 2019 00:42:13 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Caetano", "Josemar Alves", ""], ["Magno", "Gabriel", ""], ["Gon\u00e7alves", "Marcos", ""], ["Almeida", "Jussara", ""], ["Marques-Neto", "Humberto T.", ""], ["Almeida", "Virg\u00edlio", ""]]}, {"id": "1905.00829", "submitter": "Niels Dalum Hansen", "authors": "Niels Dalum Hansen", "title": "Web data mining for public health purposes", "comments": "PhD thesis (2017), Univ Copenhagen", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a long time, public health events, such as disease incidence or\nvaccination activity, have been monitored to keep track of the health status of\nthe population, allowing to evaluate the effect of public health initiatives\nand to decide where resources for improving public health are best spent. This\nthesis investigates the use of web data mining for public health monitoring,\nand makes contributions in the following two areas: New approaches for\npredicting public health events from web mined data, and novel applications of\nweb mined data for public health monitoring.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 16:04:21 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Hansen", "Niels Dalum", ""]]}, {"id": "1905.00928", "submitter": "Niki Gitinabard", "authors": "Niki Gitinabard, Sarah Heckman, Tiffany Barnes, Collin F. Lynch", "title": "What will you do next? A sequence analysis on the student transitions\n  between online platforms in blended courses", "comments": null, "journal-ref": "In International Conference on Educational Data Mining 2019", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Students' interactions with online tools can provide us with insights into\ntheir study and work habits. Prior research has shown that these habits, even\nas simple as the number of actions or the time spent on online platforms can\ndistinguish between the higher performing students and low-performers. These\nhabits are also often used to predict students' performance in classes. One key\nfeature of these actions that is often overlooked is how and when the students\ntransition between different online platforms. In this work, we study sequences\nof student transitions between online tools in blended courses and identify\nwhich habits make the most difference between the higher and lower performing\ngroups. While our results showed that most of the time students focus on a\nsingle tool, we were able to find patterns in their transitions to\ndifferentiate high and low performing groups. These findings can help\ninstructors to provide procedural guidance to the students, as well as to\nidentify harmful habits and make timely interventions.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 18:35:15 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Gitinabard", "Niki", ""], ["Heckman", "Sarah", ""], ["Barnes", "Tiffany", ""], ["Lynch", "Collin F.", ""]]}, {"id": "1905.01051", "submitter": "Pierre Laperdrix", "authors": "Pierre Laperdrix and Nataliia Bielova and Benoit Baudry and Gildas\n  Avoine", "title": "Browser Fingerprinting: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With this paper, we survey the research performed in the domain of browser\nfingerprinting, while providing an accessible entry point to newcomers in the\nfield. We explain how this technique works and where it stems from. We analyze\nthe related work in detail to understand the composition of modern fingerprints\nand see how this technique is currently used online. We systematize existing\ndefense solutions into different categories and detail the current challenges\nyet to overcome.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 07:24:32 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 12:46:06 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Laperdrix", "Pierre", ""], ["Bielova", "Nataliia", ""], ["Baudry", "Benoit", ""], ["Avoine", "Gildas", ""]]}, {"id": "1905.01347", "submitter": "Chris Dulhanty", "authors": "Chris Dulhanty, Alexander Wong", "title": "Auditing ImageNet: Towards a Model-driven Framework for Annotating\n  Demographic Attributes of Large-Scale Image Datasets", "comments": "To appear in the Workshop on Fairness Accountability Transparency and\n  Ethics in Computer Vision (FATE CV) at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ImageNet dataset ushered in a flood of academic and industry interest in\ndeep learning for computer vision applications. Despite its significant impact,\nthere has not been a comprehensive investigation into the demographic\nattributes of images contained within the dataset. Such a study could lead to\nnew insights on inherent biases within ImageNet, particularly important given\nit is frequently used to pretrain models for a wide variety of computer vision\ntasks. In this work, we introduce a model-driven framework for the automatic\nannotation of apparent age and gender attributes in large-scale image datasets.\nUsing this framework, we conduct the first demographic audit of the 2012\nImageNet Large Scale Visual Recognition Challenge (ILSVRC) subset of ImageNet\nand the \"person\" hierarchical category of ImageNet. We find that 41.62% of\nfaces in ILSVRC appear as female, 1.71% appear as individuals above the age of\n60, and males aged 15 to 29 account for the largest subgroup with 27.11%. We\nnote that the presented model-driven framework is not fair for all\nintersectional groups, so annotation are subject to bias. We present this work\nas the starting point for future development of unbiased annotation models and\nfor the study of downstream effects of imbalances in the demographics of\nImageNet. Code and annotations are available at:\nhttp://bit.ly/ImageNetDemoAudit\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 19:33:02 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 18:32:34 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Dulhanty", "Chris", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.01615", "submitter": "Reza Rawassizadeh", "authors": "Alireza Javaheri, Navid Moghadamnejad, Hamidreza Keshavarz, Ehsan\n  Javaheri, Chelsea Dobbins, Elaheh Momeni, Reza Rawassizadeh", "title": "Public vs Media Opinion on Robots", "comments": "15 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast proliferation of robots in people's everyday lives during recent years\ncalls for a profound examination of public consensus, which is the ultimate\ndeterminant of the future of this industry. This paper investigates text\ncorpora, consisting of posts in Twitter, Google News, Bing News, and\nKickstarter, over an 8 year period to quantify the public and media opinion\nabout this emerging technology. Results demonstrate that the news platforms and\nthe public take an overall positive position on robots. However, there is a\ndeviation between news coverage and people's attitude. Among various robot\ntypes, sex robots raise the fiercest debate. Besides, our evaluation reveals\nthat the public and news media conceptualization of robotics has altered over\nthe recent years. More specifically, a shift from the solely\nindustrial-purposed machines, towards more social, assistive, and multi-purpose\ngadgets is visible.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 05:53:51 GMT"}], "update_date": "2019-05-18", "authors_parsed": [["Javaheri", "Alireza", ""], ["Moghadamnejad", "Navid", ""], ["Keshavarz", "Hamidreza", ""], ["Javaheri", "Ehsan", ""], ["Dobbins", "Chelsea", ""], ["Momeni", "Elaheh", ""], ["Rawassizadeh", "Reza", ""]]}, {"id": "1905.01627", "submitter": "Burak Uzkent", "authors": "Evan Sheehan, Chenlin Meng, Matthew Tan, Burak Uzkent, Neal Jean,\n  David Lobell, Marshall Burke, Stefano Ermon", "title": "Predicting Economic Development using Geolocated Wikipedia Articles", "comments": "Accepted to KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress on the UN Sustainable Development Goals (SDGs) is hampered by a\npersistent lack of data regarding key social, environmental, and economic\nindicators, particularly in developing countries. For example, data on poverty\n--- the first of seventeen SDGs --- is both spatially sparse and infrequently\ncollected in Sub-Saharan Africa due to the high cost of surveys. Here we\npropose a novel method for estimating socioeconomic indicators using\nopen-source, geolocated textual information from Wikipedia articles. We\ndemonstrate that modern NLP techniques can be used to predict community-level\nasset wealth and education outcomes using nearby geolocated Wikipedia articles.\nWhen paired with nightlights satellite imagery, our method outperforms all\npreviously published benchmarks for this prediction task, indicating the\npotential of Wikipedia to inform both research in the social sciences and\nfuture policy decisions.\n", "versions": [{"version": "v1", "created": "Sun, 5 May 2019 07:38:10 GMT"}, {"version": "v2", "created": "Sat, 11 May 2019 08:09:52 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Sheehan", "Evan", ""], ["Meng", "Chenlin", ""], ["Tan", "Matthew", ""], ["Uzkent", "Burak", ""], ["Jean", "Neal", ""], ["Lobell", "David", ""], ["Burke", "Marshall", ""], ["Ermon", "Stefano", ""]]}, {"id": "1905.01777", "submitter": "Hamid Akin Unver", "authors": "H. Akin Unver", "title": "Internet, Social Media and Conflict Studies Can Greater\n  Interdisciplinarity Solve the Analytical Deadlocks in Cybersecurity Research?", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, computational research methods, digital trace data and\nonline human interactions have contributed to the emergence of new\ntechnology-oriented sub-fields within International Relations (IR). Although\nthe cybersecurity scholarship had an initial promise to be the primus inter\npares among these emerging fields, the main thrust of this new methodological\ninnovation came through the digital conflict studies sub-field. By integrating\nInternet and social media research tools and questions into its core topics of\nsub-national violence, terrorism and radical mobilization, digital conflict\nstudies has recently succeeded in addressing some of the data validity and\nmethodology problems faced by the cybersecurity scholarship. This article\nbegins by briefly reviewing some of the persistent data and method-oriented\nhurdles faced by the cybersecurity scholarship. Then, it moves onto a more\ndetailed account of how digital conflict studies have been addressing some of\nthese deadlocks by focusing individually on the literature on onset,\nmobilization, targeting, intensity/duration and termination phases of\nconflicts. Ultimately, the article concludes with the suggestion that the\ncybersecurity scholarship could move past its own deadlocks by building more\ngranular and dedicated research datasets and establishing mechanisms to share\nevent data with the scientific community.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 00:58:29 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Unver", "H. Akin", ""]]}, {"id": "1905.01805", "submitter": "Eric Bax", "authors": "Eric Bax", "title": "Computing a Data Dividend", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY econ.GN q-fin.EC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality data is a fundamental contributor to success in statistics and\nmachine learning. If a statistical assessment or machine learning leads to\ndecisions that create value, data contributors may want a share of that value.\nThis paper presents methods to assess the value of individual data samples, and\nof sets of samples, to apportion value among different data contributors. We\nuse Shapley values for individual samples and Owen values for combined samples,\nand show that these values can be computed in polynomial time in spite of their\ndefinitions having numbers of terms that are exponential in the number of\nsamples.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 02:51:29 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 16:38:34 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Bax", "Eric", ""]]}, {"id": "1905.02092", "submitter": "Neha Soni", "authors": "Neha Soni, Enakshi Khular Sharma, Narotam Singh, Amita Kapoor", "title": "Impact of Artificial Intelligence on Businesses: from Research,\n  Innovation, Market Deployment to Future Shifts in Business Models", "comments": "38 pages, 10 figures, 3 tables. A part of this work has been\n  presented in DIGITS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.AI cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fast pace of artificial intelligence (AI) and automation is propelling\nstrategists to reshape their business models. This is fostering the integration\nof AI in the business processes but the consequences of this adoption are\nunderexplored and need attention. This paper focuses on the overall impact of\nAI on businesses - from research, innovation, market deployment to future\nshifts in business models. To access this overall impact, we design a\nthree-dimensional research model, based upon the Neo-Schumpeterian economics\nand its three forces viz. innovation, knowledge, and entrepreneurship. The\nfirst dimension deals with research and innovation in AI. In the second\ndimension, we explore the influence of AI on the global market and the\nstrategic objectives of the businesses and finally, the third dimension\nexamines how AI is shaping business contexts. Additionally, the paper explores\nAI implications on actors and its dark sides.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 12:05:08 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Soni", "Neha", ""], ["Sharma", "Enakshi Khular", ""], ["Singh", "Narotam", ""], ["Kapoor", "Amita", ""]]}, {"id": "1905.02272", "submitter": "Taha Hassan", "authors": "Taha Hassan", "title": "On bias in social reviews of university courses", "comments": "WebSci'19 Companion Proceedings", "journal-ref": "Companion Proceedings of the 11th ACM International Conference on\n  Web Science, June 30th - July 3rd, Boston, MA, 2019", "doi": "10.1145/3328413.3328416", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  University course ranking forums are a popular means of disseminating\ninformation about satisfaction with the quality of course content and\ninstruction, especially with undergraduate students. A variety of policy\ndecisions by university administrators, instructional designers and teaching\nstaff affect how students perceive the efficacy of pedagogies employed in a\ngiven course, in class and online. While there is a large body of research on\nqualitative driving factors behind the use of academic rating sites, there is\nlittle investigation of the (potential) implicit student bias on said forums\ntowards desirable course outcomes at the institution level. To that end, we\nexamine the connection between course outcomes (student-reported GPA) and the\noverall ranking of the primary course instructor, as well as rating disparity\nby nature of course outcomes, for several hundred courses taught at Virginia\nTech based on data collected from a popular academic rating forum. We also\nreplicate our analysis for several public universities across the US. Our\nexperiments indicate that there is a discernible albeit complex bias towards\ncourse outcomes in the professor ratings registered by students.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 21:50:59 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Hassan", "Taha", ""]]}, {"id": "1905.02349", "submitter": "Leonardo Mu\\~noz", "authors": "Leonardo Munoz and Oscar Avila", "title": "Business and Information Technology Alignment Measurement -- a recent\n  Literature Review", "comments": "12 pages, Preprint version, BIS 2018 International Workshops, Berlin,\n  Germany, July 18 to 20, 2018, Revised Papers", "journal-ref": "Business Information Systems Workshops. BIS 2018. Lecture Notes in\n  Business Information Processing, vol 339, 2019, pp 112-123. Springer, Cham", "doi": "10.1007/978-3-030-04849-5_10", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since technology has been involved in the business context, Business and\nInformation Technology Alignment (BITA) has been one of the main concerns of IT\nand Business executives and directors due to its importance to overall company\nperformance, especially today in the age of digital transformation. Several\nmodels and frameworks have been developed for BITA implementation and for\nmeasuring their level of success, each one with a different approach to this\ndesired state. The BITA measurement is one of the main decision-making tools in\nthe strategic domain of companies. In general, the classical-internal alignment\nis the most measured domain and the external environment evolution alignment is\nthe least measured. This literature review aims to characterize and analyze\ncurrent research on BITA measurement with a comprehensive view of the works\npublished over the last 15 years to identify potential gaps and future areas of\nresearch in the field.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 04:37:21 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 21:21:09 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Munoz", "Leonardo", ""], ["Avila", "Oscar", ""]]}, {"id": "1905.02356", "submitter": "Leonardo Mu\\~noz", "authors": "Leonardo Munoz and Oscar Avila", "title": "A model to assess customer alignment through customer experience\n  concepts", "comments": "12 pages, Preprint version, BIS 2019 International Workshops,\n  Seville, Spain, June 26 to 28, 2019, Revised Papers", "journal-ref": "Business Information Systems Workshops. BIS 2019. Lecture Notes in\n  Business Information Processing, vol 373. Springer, Cham", "doi": "10.1007/978-3-030-36691-9_29", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business and Information Technology Alignment (BITA) has been one of the main\nconcerns of IT and Business executives and directors due to its importance to\noverall company performance, especially today in the age of digital\ntransformation. For BITA has been developed several models which in general has\nfocused in the implementation of alignment strategies for the internal\noperation of the organizations and in the measurement of this internal\nalignment, but, there is still a big gap in measurement models of the alignment\nwith the external environment of the organizations. In this paper is presented\nthe design and application of a maturity measurement model for BITA with the\ncustomers, where the customers are actors of the external environment of the\ncompanies. The proposed model involves evaluation criteria and business\npractices which the companies ideally do for improve the relationship with\ntheir customers.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 05:08:45 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 21:08:47 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 17:01:03 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Munoz", "Leonardo", ""], ["Avila", "Oscar", ""]]}, {"id": "1905.02530", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim", "title": "Deep Learning to Predict Student Outcomes", "comments": "Accepted as oral presentation to ICLR 2019, AI for Social Good\n  Workshop. arXiv admin note: substantial text overlap with arXiv:1809.06686,\n  arXiv:1804.07405", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasingly fast development cycle for online course contents, along\nwith the diverse student demographics in each online classroom, make real-time\nstudent outcomes prediction an interesting topic for both industrial research\nand practical needs. In this paper, we tackle the problem of real-time student\nperformance prediction in an on-going course using a domain adaptation\nframework. This framework is a system trained on labeled student outcome data\nfrom previous coursework but is meant to be deployed on another course. In\nparticular, we introduce a GritNet architecture, and develop an unsupervised\ndomain adaptation method to transfer a GritNet trained on a past course to a\nnew course without any student outcome label. Our results for real Udacity\nstudent graduation predictions show that the GritNet not only generalizes well\nfrom one course to another across different Nanodegree programs, but also\nenhances real-time predictions explicitly in the first few weeks when accurate\npredictions are most challenging.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 07:37:14 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Kim", "Byung-Hak", ""]]}, {"id": "1905.02840", "submitter": "Andrea Giovanni Nuzzolese", "authors": "Valentina Anita Carriero, Aldo Gangemi, Maria Letizia Mancinelli,\n  Ludovica Marinucci, Andrea Giovanni Nuzzolese, Valentina Presutti, Chiara\n  Veninata", "title": "ArCo: the Italian Cultural Heritage Knowledge Graph", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30796-7_3", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ArCo is the Italian Cultural Heritage knowledge graph, consisting of a\nnetwork of seven vocabularies and 169 million triples about 820 thousand\ncultural entities. It is distributed jointly with a SPARQL endpoint, a software\nfor converting catalogue records to RDF, and a rich suite of documentation\nmaterial (testing, evaluation, how-to, examples, etc.). ArCo is based on the\nofficial General Catalogue of the Italian Ministry of Cultural Heritage and\nActivities (MiBAC) - and its associated encoding regulations - which collects\nand validates the catalogue records of (ideally) all Italian Cultural Heritage\nproperties (excluding libraries and archives), contributed by CH administrators\nfrom all over Italy. We present its structure, design methods and tools, its\ngrowing community, and delineate its importance, quality, and impact.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 23:11:06 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Carriero", "Valentina Anita", ""], ["Gangemi", "Aldo", ""], ["Mancinelli", "Maria Letizia", ""], ["Marinucci", "Ludovica", ""], ["Nuzzolese", "Andrea Giovanni", ""], ["Presutti", "Valentina", ""], ["Veninata", "Chiara", ""]]}, {"id": "1905.02951", "submitter": "Mouhamed Abdulla Ph.D.", "authors": "Mouhamed Abdulla and Zohreh Motamedi and Amjed Majeed", "title": "Redesigning Telecommunication Engineering Courses with CDIO geared for\n  Polytechnic Education", "comments": "Proc. of the 10th Conference on Canadian Engineering Education\n  Association (CEEA'19)", "journal-ref": null, "doi": "10.24908/PCEEA.VI0.13855", "report-no": null, "categories": "cs.CY cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether in chemical, civil, mechanical, electrical, or their related\nengineering subdisciplines, remaining up-to-date in the subject matter is\ncrucial. However, due to the pace of technological evolution, information and\ncommunications technology (ICT) fields of study are impacted with much higher\nconsequences. Meanwhile, the curricula of higher educational institutes are\nstruggling to catch up to this reality. In order to remain competitive,\nengineering schools ought to offer ICT related courses that are at once modern,\nrelevant and ultimately beneficial for the employability of their graduates. In\nthis spirit, we were recently mandated by our engineering school to develop and\ndesign telecommunication courses with great emphasis on (i) technological\nmodernity, and (ii) experiential learning. To accomplish these objectives, we\nutilized the conceive, design, implement and operate (CDIO) framework, a modern\nengineering education initiative of which Sheridan is a member. In this\narticle, we chronicle the steps we took to streamline and modernize the\ncurriculum by outlining an effective methodology for course design and\ndevelopment with CDIO. We then provide examples of course update and design\nusing the proposed methodology and highlight the lessons learned from this\nsystematic curriculum development endeavor.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 08:24:15 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Abdulla", "Mouhamed", ""], ["Motamedi", "Zohreh", ""], ["Majeed", "Amjed", ""]]}, {"id": "1905.03108", "submitter": "Jeff Yan", "authors": "Jeff Yan", "title": "From Sicilian mafia to Chinese \"scam villages\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by Gambetta's theory on the origins of the mafia in Sicily, we\nreport a geo-concentrating phenomenon of scams in China, and propose a novel\neconomic explanation. Our analysis has some policy implications.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 10:23:15 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Yan", "Jeff", ""]]}, {"id": "1905.03314", "submitter": "Daniela Huppenkothen", "authors": "D. Huppenkothen, B. McFee, L. Nor\\'en", "title": "Entrofy Your Cohort: A Data Science Approach to Candidate Selection", "comments": "22 pages, 4 figures, submitted to PLOS One. The accompanying software\n  is available at https://github.com/dhuppenkothen/entrofy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY astro-ph.IM physics.ed-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Selecting a cohort from a set of candidates is a common task within and\nbeyond academia. Admitting students, awarding grants, choosing speakers for a\nconference are situations where human biases may affect the make-up of the\nfinal cohort. We propose a new algorithm, Entrofy, designed to be part of a\nlarger decision making strategy aimed at making cohort selection as just,\nquantitative, transparent, and accountable as possible. We suggest this\nalgorithm be embedded in a two-step selection procedure. First, all application\nmaterials are stripped of markers of identity that could induce conscious or\nsub-conscious bias. During blind review, the committee selects all applicants,\nsubmissions, or other entities that meet their merit-based criteria. This often\nyields a cohort larger than the admissible number. In the second stage, the\ntarget cohort can be chosen from this meritorious pool via a new algorithm and\nsoftware tool. Entrofy optimizes differences across an assignable set of\ncategories selected by the human committee. Criteria could include gender,\nacademic discipline, experience with certain technologies, or other\nquantifiable characteristics. The Entrofy algorithm yields the computational\nmaximization of diversity by solving the tie-breaking problem with provable\nperformance guarantees. We show how Entrofy selects cohorts according to\npre-determined characteristics in simulated sets of applications and\ndemonstrate its use in a case study. This cohort selection process allows human\njudgment to prevail when assessing merit, but assigns the assessment of\ndiversity to a computational process less likely to be beset by human bias.\nImportantly, the stage at which diversity assessments occur is fully\ntransparent and auditable with Entrofy. Splitting merit and diversity\nconsiderations into their own assessment stages makes it easier to explain why\na given candidate was selected or rejected.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 20:04:05 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Huppenkothen", "D.", ""], ["McFee", "B.", ""], ["Nor\u00e9n", "L.", ""]]}, {"id": "1905.03580", "submitter": "Andreas Kolb", "authors": "Cornelius Schubert, Andreas Kolb", "title": "Designing technology, developing theory. Towards a symmetrical approach", "comments": "36 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on collaborative activities that engage computer graphics designers\nand social scientists in systems design processes. Our conceptual symmetrical\naccount of technology design and theory development is elaborated as a mode of\nmutual engagement occurring in an interdisciplinary trading zone, where neither\ndiscipline is placed at the service of the other, and nor do disciplinary\nboundaries dissolve. To this end, we draw on analyses of mutual engagements\nbetween computer and social scientists stemming from the fields of\ncomputer-supported cooperative work (CSCW), human-computer interaction (HCI),\nand science and technology studies (STS). We especially build on theoretical\nwork in STS concerning information technology (IT) in health care and extend\nrecent contributions from STS with respect to the modes of engagement and\ntrading zones between computer and social sciences. We conceive participative\ndigital systems design as a form of inquiry for the analysis of cooperative\nwork settings, particularly when social science becomes part of design\nprocesses. We illustrate our conceptual approach using data from an\ninterdisciplinary project involving computer graphics designers, sociologists,\nand neurosurgeons with the aim of developing patient-centered visualizations\nfor clinical cooperation on a hospital ward.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 12:47:22 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 14:17:18 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Schubert", "Cornelius", ""], ["Kolb", "Andreas", ""]]}, {"id": "1905.03899", "submitter": "Aaron Massey", "authors": "Philip Feldman and Aaron Dant and Aaron Massey", "title": "Integrating Artificial Intelligence into Weapon Systems", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The integration of Artificial Intelligence (AI) into weapon systems is one of\nthe most consequential tactical and strategic decisions in the history of\nwarfare. Current AI development is a remarkable combination of accelerating\ncapability, hidden decision mechanisms, and decreasing costs. Implementation of\nthese systems is in its infancy and exists on a spectrum from resilient and\nflexible to simplistic and brittle. Resilient systems should be able to\neffectively handle the complexities of a high-dimensional battlespace.\nSimplistic AI implementations could be manipulated by an adversarial AI that\nidentifies and exploits their weaknesses.\n  In this paper, we present a framework for understanding the development of\ndynamic AI/ML systems that interactively and continuously adapt to their user's\nneeds. We explore the implications of increasingly capable AI in the kill chain\nand how this will lead inevitably to a fully automated, always on system,\nbarring regulation by treaty. We examine the potential of total integration of\ncyber and physical security and how this likelihood must inform the development\nof AI-enabled systems with respect to the \"fog of war\", human morals, and\nethics.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 00:38:35 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Feldman", "Philip", ""], ["Dant", "Aaron", ""], ["Massey", "Aaron", ""]]}, {"id": "1905.03919", "submitter": "Filippo Menczer", "authors": "Kazutoshi Sasahara, Wen Chen, Hao Peng, Giovanni Luca Ciampaglia,\n  Alessandro Flammini, Filippo Menczer", "title": "Social Influence and Unfollowing Accelerate the Emergence of Echo\n  Chambers", "comments": "28 pages, 11 figures. Forthcoming in Journal of Computational Social\n  Science", "journal-ref": "J Comput Soc Sc (2020)", "doi": "10.1007/s42001-020-00084-7", "report-no": null, "categories": "cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While social media make it easy to connect with and access information from\nanyone, they also facilitate basic influence and unfriending mechanisms that\nmay lead to segregated and polarized clusters known as \"echo chambers.\" Here we\nstudy the conditions in which such echo chambers emerge by introducing a simple\nmodel of information sharing in online social networks with the two ingredients\nof influence and unfriending. Users can change both their opinions and social\nconnections based on the information to which they are exposed through sharing.\nThe model dynamics show that even with minimal amounts of influence and\nunfriending, the social network rapidly devolves into segregated, homogeneous\ncommunities. These predictions are consistent with empirical data from Twitter.\nAlthough our findings suggest that echo chambers are somewhat inevitable given\nthe mechanisms at play in online social media, they also provide insights into\npossible mitigation strategies.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 03:08:23 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 16:40:50 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 02:27:40 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Sasahara", "Kazutoshi", ""], ["Chen", "Wen", ""], ["Peng", "Hao", ""], ["Ciampaglia", "Giovanni Luca", ""], ["Flammini", "Alessandro", ""], ["Menczer", "Filippo", ""]]}, {"id": "1905.04201", "submitter": "Edwin Wintermute V", "authors": "Edwin H. Wintermute, Matthieu Cisel, Ariel B. Lindner", "title": "A survival model for course-course interactions in a Massive Open Online\n  Course platform", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive Open Online Course (MOOC) platforms incorporate large course catalogs\nfrom which individual students may register multiple courses. We performed a\nnetwork-based analysis of student achievement, considering how course-course\ninteractions may positively or negatively affect student success. Our dataset\nincluded 378,000 users and 1,000,000 unique registration events in France\nUniversite Numerique (FUN), a national MOOC platform. We adapt reliability\ntheory to model certificate completion rates with a Weibull survival function,\nfollowing the intuition that students \"survive\" in a course for a certain time\nbefore stochastically dropping out. Course-course interactions are found to be\nwell described by a single parameter for user engagement that can be estimated\nfrom a user's registration profile. User engagement, in turn, correlates with\ncertificate rates in all courses regardless of specific content. The\nreliability approach is shown to capture several certificate rate patterns that\nare overlooked by conventional regression models. User engagement emerges as a\nnatural metric for tracking student progress across demographics and over time.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 14:53:31 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Wintermute", "Edwin H.", ""], ["Cisel", "Matthieu", ""], ["Lindner", "Ariel B.", ""]]}, {"id": "1905.04260", "submitter": "Demetris Paschalides", "authors": "Demetris Paschalides, Alexandros Kornilakis, Chrysovalantis\n  Christodoulou, Rafael Andreou, George Pallis, Marios D. Dikaiakos, Evangelos\n  Markatos", "title": "Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web", "comments": "8 pages, 6 figures,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 17:00:40 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Paschalides", "Demetris", ""], ["Kornilakis", "Alexandros", ""], ["Christodoulou", "Chrysovalantis", ""], ["Andreou", "Rafael", ""], ["Pallis", "George", ""], ["Dikaiakos", "Marios D.", ""], ["Markatos", "Evangelos", ""]]}, {"id": "1905.04288", "submitter": "Salvador Pueyo", "authors": "Salvador Pueyo", "title": "Growth, degrowth, and the challenge of artificial superintelligence", "comments": "Accepted manuscript (Journal of Cleaner Production, special issue on\n  Technology and Degrowth)", "journal-ref": "Journal of Cleaner Production 197, 1731-1736 (2018)", "doi": "10.1016/j.jclepro.2016.12.138", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implications of technological innovation for sustainability are becoming\nincreasingly complex with information technology moving machines from being\nmere tools for production or objects of consumption to playing a role in\neconomic decision making. This emerging role will acquire overwhelming\nimportance if, as a growing body of literature suggests, artificial\nintelligence is underway to outperform human intelligence in most of its\ndimensions, thus becoming \"superintelligence\". Hitherto, the risks posed by\nthis technology have been framed as a technical rather than a political\nchallenge. With the help of a thought experiment, this paper explores the\nenvironmental and social implications of superintelligence emerging in an\neconomy shaped by neoliberal policies. It is argued that such policies\nexacerbate the risk of extremely adverse impacts. The experiment also serves to\nhighlight some serious flaws in the pursuit of economic efficiency and growth\nper se, and suggests that the challenge of superintelligence cannot be\nseparated from the other major environmental and social challenges, demanding a\nfundamental transformation along the lines of degrowth. Crucially, with\nmachines outperforming them in their functions, there is little reason to\nexpect economic elites to be exempt from the threats that superintelligence\nwould pose in a neoliberal context, which opens a door to overcoming vested\ninterests that stand in the way of social change toward sustainability and\nequity.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 17:25:52 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Pueyo", "Salvador", ""]]}, {"id": "1905.04576", "submitter": "Sergio Pastrana", "authors": "Alice Hutchings and Sergio Pastrana", "title": "Understanding eWhoring", "comments": null, "journal-ref": "4th IEEE European Symposium on Security and Privacy 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a new type of online fraud, referred to as\n'eWhoring' by offenders. This crime script analysis provides an overview of the\n'eWhoring' business model, drawing on more than 6,500 posts crawled from an\nonline underground forum. This is an unusual fraud type, in that offenders\nreadily share information about how it is committed in a way that is almost\nprescriptive. There are economic factors at play here, as providing information\nabout how to make money from 'eWhoring' can increase the demand for the types\nof images that enable it to happen. We find that sexualised images are\ntypically stolen and shared online. While some images are shared for free,\nthese can quickly become 'saturated', leading to the demand for (and trade in)\nmore exclusive 'packs'. These images are then sold to unwitting customers who\nbelieve they have paid for a virtual sexual encounter. A variety of online\nservices are used for carrying out this fraud type, including email, video,\ndating sites, social media, classified advertisements, and payment platforms.\nThis analysis reveals potential interventions that could be applied to each\nstage of the crime commission process to prevent and disrupt this crime type.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 19:00:51 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Hutchings", "Alice", ""], ["Pastrana", "Sergio", ""]]}, {"id": "1905.04615", "submitter": "Jason R.C. Nurse Dr", "authors": "Oliver Buckley and Jason R. C. Nurse", "title": "The Language of Biometrics: Analysing Public Perceptions", "comments": null, "journal-ref": "Journal of Information Security and Applications, Volume 47,\n  August 2019, Pages 112-119", "doi": "10.1016/j.jisa.2019.05.001", "report-no": null, "categories": "cs.CR cs.CY cs.ET cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing shift in technology towards biometric solutions, but\none of the biggest barriers to widespread use is the acceptance by the users.\nIn this paper we investigate the understanding, awareness and acceptance of\nbiometrics by the general public. The primary research method was a survey,\nwhich had 282 respondents, designed to gauge public opinion around biometrics.\nAdditionally, qualitative data was captured in the form of the participants'\ndefinition of the term \\textit{biometrics}. We applied thematic analysis as\nwell as an automated Word Vector analysis to this data to provide a deeper\ninsight into the perceptions and understanding of the term. Our results\ndemonstrate that while there is generally a reasonable level of understanding\nof what biometrics are, this is typically limited to the techniques that are\nmost familiar to participants (e.g., fingerprints or facial recognition). Most\nnotably individuals' awareness overlooks emerging areas such as behavioural\nbiometrics (e.g., gait). This was also apparent when we compared participants'\nviews to definitions provided by official, published sources (e.g., ISO, NIST,\nOED, DHS). Overall, this article provides unique insight into the perceptions\nand understanding of biometrics as well as areas where users may lack knowledge\non biometric applications.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 00:45:52 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Buckley", "Oliver", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "1905.04933", "submitter": "Lihi Dery", "authors": "Lihi Dery, Svetlana Obraztsova, Zinovi Rabinovich and Meir Kalech", "title": "Lie on the Fly: Strategic Voting in an Iterative Preference Elicitation\n  Process", "comments": null, "journal-ref": null, "doi": "10.1007/s10726-019-09637-2", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A voting center is in charge of collecting and aggregating voter preferences.\nIn an iterative process, the center sends comparison queries to voters,\nrequesting them to submit their preference between two items. Voters might\ndiscuss the candidates among themselves, figuring out during the elicitation\nprocess which candidates stand a chance of winning and which do not.\nConsequently, strategic voters might attempt to manipulate by deviating from\ntheir true preferences and instead submit a different response in order to\nattempt to maximize their profit. We provide a practical algorithm for\nstrategic voters which computes the best manipulative vote and maximizes the\nvoter's selfish outcome when such a vote exists. We also provide a careful\nvoting center which is aware of the possible manipulations and avoids\nmanipulative queries when possible. In an empirical study on four real-world\ndomains, we show that in practice manipulation occurs in a low percentage of\nsettings and has a low impact on the final outcome. The careful voting center\nreduces manipulation even further, thus allowing for a non-distorted group\ndecision process to take place. We thus provide a core technology study of a\nvoting process that can be adopted in opinion or information aggregation\nsystems and in crowdsourcing applications, e.g., peer grading in Massive Open\nOnline Courses (MOOCs).\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 09:32:17 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Dery", "Lihi", ""], ["Obraztsova", "Svetlana", ""], ["Rabinovich", "Zinovi", ""], ["Kalech", "Meir", ""]]}, {"id": "1905.04985", "submitter": "Sushil Bhattacharjee", "authors": "Malinka Ivanova, Sushil Bhattacharjee, Sebastien Marcel, Anna Rozeva,\n  Mariana Durcheva", "title": "Enhancing Trust in eAssessment - the TeSLA System Solution", "comments": "Presented at the Conference on Technology Enhanced Assessment (TEA),\n  2018. 18 pages, 2 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust in eAssessment is an important factor for improving the quality of\nonline-education. A comprehensive model for trust based authentication for\neAssessment is being developed and tested within the score of the EU H2020\nproject TeSLA. The use of biometric verification technologies to authenticate\nthe identity and authorship claims of individual students in online-education\nscenarios is a significant component of TeSLA. Technical Univerity of Sofia\n(TUS) Bulgaria, a member of TeSLA consortium, participates in large-scale pilot\ntests of the TeSLA system. The results of questionnaires to students and\nteachers involved in the TUS pilot tests are analyzed and summarized in this\nwork. We also describe the TeSLA authentication and fraud-detection instruments\nand their role for enhancing trust in eAssessment.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 11:49:46 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ivanova", "Malinka", ""], ["Bhattacharjee", "Sushil", ""], ["Marcel", "Sebastien", ""], ["Rozeva", "Anna", ""], ["Durcheva", "Mariana", ""]]}, {"id": "1905.04994", "submitter": "Andrea Aler Tubella", "authors": "Andrea Aler Tubella, Andreas Theodorou, Virginia Dignum, Frank Dignum", "title": "Governance by Glass-Box: Implementing Transparent Moral Bounds for AI\n  Behaviour", "comments": "7 pages, 2 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) applications are being used to predict and\nassess behaviour in multiple domains, such as criminal justice and consumer\nfinance, which directly affect human well-being. However, if AI is to improve\npeople's lives, then people must be able to trust AI, which means being able to\nunderstand what the system is doing and why. Even though transparency is often\nseen as the requirement in this case, realistically it might not always be\npossible or desirable, whereas the need to ensure that the system operates\nwithin set moral bounds remains. In this paper, we present an approach to\nevaluate the moral bounds of an AI system based on the monitoring of its inputs\nand outputs. We place a \"glass box\" around the system by mapping moral values\ninto explicit verifiable norms that constrain inputs and outputs, in such a way\nthat if these remain within the box we can guarantee that the system adheres to\nthe value. The focus on inputs and outputs allows for the verification and\ncomparison of vastly different intelligent systems; from deep neural networks\nto agent-based systems. The explicit transformation of abstract moral values\ninto concrete norms brings great benefits in terms of explainability;\nstakeholders know exactly how the system is interpreting and employing relevant\nabstract moral human values and calibrate their trust accordingly. Moreover, by\noperating at a higher level we can check the compliance of the system with\ndifferent interpretations of the same value. These advantages will have an\nimpact on the well-being of AI systems users at large, building their trust and\nproviding them with concrete knowledge on how systems adhere to moral values.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 15:02:20 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 09:33:52 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Tubella", "Andrea Aler", ""], ["Theodorou", "Andreas", ""], ["Dignum", "Virginia", ""], ["Dignum", "Frank", ""]]}, {"id": "1905.05015", "submitter": "Federica Paganelli", "authors": "Giovanni Cuffaro, Federica Paganelli, Georgios Mylonas", "title": "A resource-based rule engine for energy savings recommendations in\n  educational buildings", "comments": null, "journal-ref": null, "doi": "10.1109/GIOTS.2017.8016275", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raising awareness among young people on the relevance of behaviour change for\nachieving energy savings is widely considered as a key approach towards\nlong-term and cost-effective energy efficiency policies. The GAIA Project aims\nto deliver a comprehensive solution for both increasing awareness on energy\nefficiency and achieving energy savings in school buildings. In this framework,\nwe present a novel rule engine that, leveraging a resource-based graph model\nencoding relevant application domain knowledge, accesses IoT data for producing\nenergy savings recommendations. The engine supports configurability,\nextensibility and ease-of-use requirements, to be easily applied and customized\nto different buildings. The paper introduces the main design and implementation\ndetails and presents a set of preliminary performance results.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 12:45:31 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Cuffaro", "Giovanni", ""], ["Paganelli", "Federica", ""], ["Mylonas", "Georgios", ""]]}, {"id": "1905.05025", "submitter": "Sean Quinn", "authors": "Se\\'an Quinn, Noel Murphy, Alan F. Smeaton", "title": "Tracking Human Behavioural Consistency by Analysing Periodicity of\n  Household Water Consumption", "comments": "2019 2nd International Conference on Sensors, Signal and Image\n  Processing", "journal-ref": null, "doi": "10.1145/3365245.3365246", "report-no": null, "categories": "eess.SP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People are living longer than ever due to advances in healthcare, and this\nhas prompted many healthcare providers to look towards remote patient care as a\nmeans to meet the needs of the future. It is now a priority to enable people to\nreside in their own homes rather than in overburdened facilities whenever\npossible. The increasing maturity of IoT technologies and the falling costs of\nconnected sensors has made the deployment of remote healthcare at scale an\nincreasingly attractive prospect. In this work we demonstrate that we can\nmeasure the consistency and regularity of the behaviour of a household using\nsensor readings generated from interaction with the home environment. We show\nthat we can track changes in this behaviour regularity longitudinally and\ndetect changes that may be related to significant life events or trends that\nmay be medically significant. We achieve this using periodicity analysis on\nwater usage readings sampled from the main household water meter every 15\nminutes for over 8 months. We utilise an IoT Application Enablement Platform in\nconjunction with low cost LoRa-enabled sensors and a Low Power Wide Area\nNetwork in order to validate a data collection methodology that could be\ndeployed at large scale in future. We envision the statistical methods\ndescribed here being applied to data streams from the homes of elderly and\nat-risk groups, both as a means of early illness detection and for monitoring\nthe well-being of those with known illnesses.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 13:15:53 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 23:10:24 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Quinn", "Se\u00e1n", ""], ["Murphy", "Noel", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "1905.05222", "submitter": "Jason R.C. Nurse Dr", "authors": "Meredydd Williams and Jason R. C. Nurse and Sadie Creese", "title": "Smartwatch games: Encouraging privacy-protective behaviour in a\n  longitudinal study", "comments": "21 pages, 2 figures", "journal-ref": "Computers in Human Behavior, 2019", "doi": "10.1016/j.chb.2019.04.026", "report-no": null, "categories": "cs.HC cs.CR cs.CY cs.ET cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the public claim concern for their privacy, they frequently appear to\noverlook it. This disparity between concern and behaviour is known as the\nPrivacy Paradox. Such issues are particularly prevalent on wearable devices.\nThese products can store personal data, such as text messages and contact\ndetails. However, owners rarely use protective features. Educational games can\nbe effective in encouraging changes in behaviour. Therefore, we developed the\nfirst privacy game for (Android) Wear OS watches. 10 participants used\nsmartwatches for two months, allowing their high-level settings to be\nmonitored. Five individuals were randomly assigned to our treatment group, and\nthey played a dynamically-customised privacy-themed game. To minimise\nconfounding variables, the other five received the same app but lacking the\nprivacy topic. The treatment group improved their protection, with their usage\nof screen locks significantly increasing (p = 0.043). In contrast, 80% of the\ncontrol group continued to never restrict their settings. After the posttest\nphase, we evaluated behavioural rationale through semi-structured interviews.\nPrivacy concerns became more nuanced in the treatment group, with opinions\naligning with behaviour. Actions appeared influenced primarily by three\nfactors: convenience, privacy salience and data sensitivity. This is the first\nsmartwatch game to encourage privacy-protective behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 18:14:40 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Williams", "Meredydd", ""], ["Nurse", "Jason R. C.", ""], ["Creese", "Sadie", ""]]}, {"id": "1905.05437", "submitter": "Shichang Ding", "authors": "Shichang Ding, Hong Huang, Tao Zhao, Xiaoming Fu", "title": "Estimating Socioeconomic Status via Temporal-Spatial Mobility Analysis\n  -- A Case Study of Smart Card Data", "comments": "9 pages, double column, IEEE ICCCN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of socioeconomic status (SES) of a person or family reflects the\ncorresponding entity's social and economic rank in society. Such information\nmay help applications like bank loaning decisions and provide measurable inputs\nfor related studies like social stratification, social welfare and business\nplanning. Traditionally, estimating SES for a large population is performed by\nnational statistical institutes through a large number of household interviews,\nwhich is highly expensive and time-consuming. Recently researchers try to\nestimate SES from data sources like mobile phone call records and online social\nnetwork platforms, which is much cheaper and faster. Instead of relying on\nthese data about users' cyberspace behaviors, various alternative data sources\non real-world users' behavior such as mobility may offer new insights for SES\nestimation. In this paper, we leverage Smart Card Data (SCD) for public\ntransport systems which records the temporal and spatial mobility behavior of a\nlarge population of users. More specifically, we develop S2S, a deep learning\nbased approach for estimating people's SES based on their SCD. Essentially, S2S\nmodels two types of SES-related features, namely the temporal-sequential\nfeature and general statistical feature, and leverages deep learning for SES\nestimation. We evaluate our approach in an actual dataset, Shanghai SCD, which\ninvolves millions of users. The proposed model clearly outperforms several\nstate-of-art methods in terms of various evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 08:06:44 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Ding", "Shichang", ""], ["Huang", "Hong", ""], ["Zhao", "Tao", ""], ["Fu", "Xiaoming", ""]]}, {"id": "1905.05518", "submitter": "Barbora Buhnova", "authors": "Barbora Buhnova and Dita Prikrylova", "title": "Women Want to Learn Tech: Lessons from the Czechitas Education Project", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it is understood by women that tech fluency might act as a powerful\ncareer accelerator or even a new career direction towards software engineering,\nthis awakening often comes after graduation from a different field, when it is\ndifficult for the women to make the shift towards tech and computing. In this\npaper, we report on our experience with running a successful education\nnon-profit called Czechitas, which shows that women in their 20s and 30s are\n(maybe surprisingly) highly interested in learning tech, they just need a\nhelping hand and tailored assistance, encouragement and guidance.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:02:55 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Buhnova", "Barbora", ""], ["Prikrylova", "Dita", ""]]}, {"id": "1905.05560", "submitter": "Gabriele D'Angelo", "authors": "Mirko Zichichi, Michele Contu, Stefano Ferretti, Gabriele D'Angelo", "title": "LikeStarter: a Smart-contract based Social DAO for Crowdfunding", "comments": "Proceedings of the 2st Workshop on Cryptocurrencies and Blockchains\n  for Distributed Systems (CryBlock'19). Paris, France, 29 April, 2019", "journal-ref": null, "doi": "10.1109/INFCOMW.2019.8845133", "report-no": null, "categories": "cs.CY cs.ET cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdfunding has become a popular form of collective funding, in which small\ndonations or investments, made by groups of people, support the development of\nnew projects in exchange of free products or different types of recognition.\nSocial network sites, on the other hand, promote user cooperation and currently\nare at the basis of any individuals cyber-interactions. In this paper, we\npresent LikeStarter, a blockchain-based decentralized platform that combines\nsocial interactions with crowdfunding mechanisms, allowing any user to raise\nfunds while becoming popular in the social network. Being built over the\nEthereum blockchain, LikeStarter is structured as a Decentralized Autonomous\nOrganization (DAO), that fosters crowdfunding without the intervention of any\ncentral authority, and recognizes the active role of donors, enabling them to\nsupport artists or projects, while making profits.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:43:58 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 19:25:10 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 15:36:51 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Zichichi", "Mirko", ""], ["Contu", "Michele", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "1905.05888", "submitter": "Christoph Salge", "authors": "Christoph Salge, Christian Guckelsberger, Michael Cerny Green, Rodrigo\n  Canaan and Julian Togelius", "title": "Generative Design in Minecraft: Chronicle Challenge", "comments": "5 pages, 1 Figure, accepted as late-breaking paper at ICCC 2019, 10th\n  International Conference on Computational Creativity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Chronicle Challenge as an optional addition to the\nSettlement Generation Challenge in Minecraft. One of the foci of the overall\ncompetition is adaptive procedural content generation (PCG), an arguably\nunder-explored problem in computational creativity. In the base challenge,\nparticipants must generate new settlements that respond to and ideally interact\nwith existing content in the world, such as the landscape or climate. The goal\nis to understand the underlying creative process, and to design better PCG\nsystems. The Chronicle Challenge in particular focuses on the generation of a\nnarrative based on the history of a generated settlement, expressed in natural\nlanguage. We discuss the unique features of the Chronicle Challenge in\ncomparison to other competitions, clarify the characteristics of a chronicle\neligible for submission and describe the evaluation criteria. We furthermore\ndraw on simulation-based approaches in computational storytelling as examples\nto how this challenge could be approached.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:53:57 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Salge", "Christoph", ""], ["Guckelsberger", "Christian", ""], ["Green", "Michael Cerny", ""], ["Canaan", "Rodrigo", ""], ["Togelius", "Julian", ""]]}, {"id": "1905.05961", "submitter": "Zijian Wang", "authors": "Zijian Wang, Scott A. Hale, David Adelani, Przemyslaw A. Grabowicz,\n  Timo Hartmann, Fabian Fl\\\"ock, David Jurgens", "title": "Demographic Inference and Representative Population Estimates from\n  Multilingual Social Media Data", "comments": "12 pages, 10 figures, Proceedings of the 2019 World Wide Web\n  Conference (WWW '19)", "journal-ref": "Proceedings of the 2019 World Wide Web Conference (WWW '19), May\n  13--17, 2019, San Francisco, CA, USA", "doi": "10.1145/3308558.3313684", "report-no": null, "categories": "cs.CY cs.CL cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media provide access to behavioural data at an unprecedented scale and\ngranularity. However, using these data to understand phenomena in a broader\npopulation is difficult due to their non-representativeness and the bias of\nstatistical inference tools towards dominant languages and groups. While\ndemographic attribute inference could be used to mitigate such bias, current\ntechniques are almost entirely monolingual and fail to work in a global\nenvironment. We address these challenges by combining multilingual demographic\ninference with post-stratification to create a more representative population\nsample. To learn demographic attributes, we create a new multimodal deep neural\narchitecture for joint classification of age, gender, and organization-status\nof social media users that operates in 32 languages. This method substantially\noutperforms current state of the art while also reducing algorithmic bias. To\ncorrect for sampling biases, we propose fully interpretable multilevel\nregression methods that estimate inclusion probabilities from inferred joint\npopulation counts and ground-truth population counts. In a large experiment\nover multilingual heterogeneous European regions, we show that our demographic\ninference and bias correction together allow for more accurate estimates of\npopulations and make a significant step towards representative social sensing\nin downstream applications with multilingual social media.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 06:15:16 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Wang", "Zijian", ""], ["Hale", "Scott A.", ""], ["Adelani", "David", ""], ["Grabowicz", "Przemyslaw A.", ""], ["Hartmann", "Timo", ""], ["Fl\u00f6ck", "Fabian", ""], ["Jurgens", "David", ""]]}, {"id": "1905.05985", "submitter": "Nicolas Jullien", "authors": "Nicolas Jullien (LEGO, MARSOUIN, IMT Atlantique - LUSSI), Klaas-Jan\n  Stol (UL), James Herbsleb", "title": "A Preliminary Theory for Open Source Ecosystem Micro-economics", "comments": "Brian Fitzgerald; Audris Mockus; Minghui Zhou. Towards Engineering\n  Free/Libre Open Source Software (FLOSS) Ecosystems for Impact and\n  Sustainability, Springer, In press, Communications of NII Shonan Meetings,\n  978-981-13-7098-4. https://www.springer.com/gp/book/9789811370984#aboutBook", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there has been substantial empirical work identifying factors that\ninfluence the contribution to, and use of open source software, we have as yet\nlittle theory that identifies the key constructs and relationships that would\nallow us to explain and predict how open source ecosystems function. What is\nneeded is a clearly articulated and empirically validated theory of open source\necosystems. Such a theory should: $\\bullet$ Explain why, how, and when key\nresources---primarily the work of developers---are attracted to or depart from\na project or an ecosystem. $\\bullet$ Explain why, how, and when projects and\necosystems move through a life cycle, from initiation, growth, maturity, and\ndecline and death. $\\bullet$ Explain how decisions about use are made, and how\nthe cumulatively influence the socio-technical position of a project within an\necosystem, and the relations of ecosystems to each other.The remainder of this\nchapter provides a sketch of such a theory in the form of a set of\npropositions, which may form the foundation for future empirical work\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:16:00 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Jullien", "Nicolas", "", "LEGO, MARSOUIN, IMT Atlantique - LUSSI"], ["Stol", "Klaas-Jan", "", "UL"], ["Herbsleb", "James", ""]]}, {"id": "1905.06203", "submitter": "Mohammad Mahdi Dehshibi Dr.", "authors": "Mohammad Mahdi Dehshibi, Gerard Pons, Bita Baiani, David Masip", "title": "VICSOM: VIsual Clues from SOcial Media for psychological assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sharing multimodal information (typically images, videos or text) in Social\nNetwork Sites (SNS) occupies a relevant part of our time. The particular way\nhow users expose themselves in SNS can provide useful information to infer\nhuman behaviors. This paper proposes to use multimodal data gathered from\nInstagram accounts to predict the perceived prototypical needs described in\nGlasser's choice theory. The contribution is two-fold: (i) we provide a large\nmultimodal database from Instagram public profiles (more than 30,000 images and\ntext captions) annotated by expert Psychologists on each perceived behavior\naccording to Glasser's theory, and (ii) we propose to automate the recognition\nof the (unconsciously) perceived needs by the users. Particularly, we propose a\nbaseline using three different feature sets: visual descriptors based on pixel\nimages (SURF and Visual Bag of Words), a high-level descriptor based on the\nautomated scene description using Convolutional Neural Networks, and a\ntext-based descriptor (Word2vec) obtained from processing the captions provided\nby the users. Finally, we propose a multimodal fusion of these descriptors\nobtaining promising results in the multi-label classification problem.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 14:18:01 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Dehshibi", "Mohammad Mahdi", ""], ["Pons", "Gerard", ""], ["Baiani", "Bita", ""], ["Masip", "David", ""]]}, {"id": "1905.06269", "submitter": "Weiqing Min", "authors": "Weiqing Min, Shuqiang Jiang, Ramesh Jain", "title": "Food Recommendation: Framework, Existing Solutions and Challenges", "comments": "Accepted by IEEE Transactions on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing proportion of the global population is becoming overweight or\nobese, leading to various diseases (e.g., diabetes, ischemic heart disease and\neven cancer) due to unhealthy eating patterns, such as increased intake of food\nwith high energy and high fat. Food recommendation is of paramount importance\nto alleviate this problem. Unfortunately, modern multimedia research has\nenhanced the performance and experience of multimedia recommendation in many\nfields such as movies and POI, yet largely lags in the food domain. This\narticle proposes a unified framework for food recommendation, and identifies\nmain issues affecting food recommendation including building the personal\nmodel, analyzing unique food characteristics, incorporating various context and\ndomain knowledge. We then review existing solutions for these issues, and\nfinally elaborate research challenges and future directions in this field. To\nour knowledge, this is the first survey that targets the study of food\nrecommendation in the multimedia field and offers a collection of research\nstudies and technologies to benefit researchers in this field.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:12:05 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 06:45:01 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Min", "Weiqing", ""], ["Jiang", "Shuqiang", ""], ["Jain", "Ramesh", ""]]}, {"id": "1905.06289", "submitter": "Kory W Mathewson", "authors": "Kory W. Mathewson", "title": "A Human-Centered Approach to Interactive Machine Learning", "comments": "4 pages, 4th Multidisciplinary Conference on Reinforcement Learning\n  and Decision Making", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interactive machine learning (IML) community aims to augment humans'\nability to learn and make decisions over time through the development of\nautomated decision-making systems. This interaction represents a collaboration\nbetween multiple intelligent systems---humans and machines. A lack of\nappropriate consideration for the humans involved can lead to problematic\nsystem behaviour, and issues of fairness, accountability, and transparency.\nThis work presents a human-centred thinking approach to applying IML methods.\nThis guide is intended to be used by AI practitioners who incorporate human\nfactors in their work. These practitioners are responsible for the health,\nsafety, and well-being of interacting humans. An obligation of responsibility\nfor public interaction means acting with integrity, honesty, fairness, and\nabiding by applicable legal statutes. With these values and principles in mind,\nwe as a research community can better achieve the collective goal of augmenting\nhuman ability. This practical guide aims to support many of the responsible\ndecisions necessary throughout iterative design, development, and dissemination\nof IML systems.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 16:46:55 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Mathewson", "Kory W.", ""]]}, {"id": "1905.06417", "submitter": "Ville Vakkuri", "authors": "Ville Vakkuri, Kai-Kristian Kemell, Pekka Abrahamsson", "title": "Ethically Aligned Design: An empirical evaluation of the\n  RESOLVEDD-strategy in Software and Systems development context", "comments": "This is the author's version of the work. The copyright holder's\n  version can be found at https://doi.org/10.1109/SEAA.2019.00015", "journal-ref": "2019 45th Euromicro Conference on Software Engineering and\n  Advanced Applications (SEAA)", "doi": "10.1109/SEAA.2019.00015", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of artificial intelligence (AI) in human contexts calls for ethical\nconsiderations for the design and development of AI-based systems. However,\nlittle knowledge currently exists on how to provide useful and tangible tools\nthat could help software developers and designers implement ethical\nconsiderations into practice. In this paper, we empirically evaluate a method\nthat enables ethically aligned design in a decision-making process. Though this\nmethod, titled the RESOLVEDD-strategy, originates from the field of business\nethics, it is being applied in other fields as well. We tested the\nRESOLVEDD-strategy in a multiple case study of five student projects where the\nuse of ethical tools was given as one of the design requirements. A key finding\nfrom the study indicates that simply the presence of an ethical tool has an\neffect on ethical consideration, creating more responsibility even in instances\nwhere the use of the tool is not intrinsically motivated.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 10:33:05 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 15:38:40 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 15:44:38 GMT"}, {"version": "v4", "created": "Wed, 22 Jan 2020 18:50:36 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Vakkuri", "Ville", ""], ["Kemell", "Kai-Kristian", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1905.06462", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Praneeth Vepakomma, Tristan Swedish, Aalekh Sharan", "title": "Data Markets to support AI for All: Pricing, Valuation and Governance", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a data market technique based on intrinsic (relevance and\nuniqueness) as well as extrinsic value (influenced by supply and demand) of\ndata. For intrinsic value, we explain how to perform valuation of data in\nabsolute terms (i.e just by itself), or relatively (i.e in comparison to\nmultiple datasets) or in conditional terms (i.e valuating new data given\ncurrently existing data).\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 04:41:11 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Raskar", "Ramesh", ""], ["Vepakomma", "Praneeth", ""], ["Swedish", "Tristan", ""], ["Sharan", "Aalekh", ""]]}, {"id": "1905.06463", "submitter": "Alimire Nabijiang", "authors": "Alimire Nabijiang, Supratik Mukhopadhyay, Yimin Zhu, Ravindra\n  Gudishala, Sanaz Saeidi, Qun Liu", "title": "Why do you take that route?", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to determine whether a particular context factor\namong the variables that a researcher is interested in causally affects the\nroute choice behavior of drivers. To our knowledge, there is limited literature\nthat consider the effects of various factors on route choice based on causal\ninference.Yet, collecting data sets that are sensitive to the aforementioned\nfactors are challenging and the existing approaches usually take into account\nonly the general factors motivating drivers route choice behavior. To fill\nthese gaps, we carried out a study using Immersive Virtual Environment (IVE)\ntools to elicit drivers' route choice behavioral data, covering drivers'\nnetwork familiarity, educationlevel, financial concern, etc, apart from\nconventional measurement variables. Having context-aware, high-fidelity\nproperties, IVE data affords the opportunity to incorporate the impacts of\nhuman related factors into the route choice causal analysis and advance a more\ncustomizable research tool for investigating causal factors on path selection\nin network routing. This causal analysis provides quantitative evidence to\nsupport drivers' diversion decision.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 22:57:51 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Nabijiang", "Alimire", ""], ["Mukhopadhyay", "Supratik", ""], ["Zhu", "Yimin", ""], ["Gudishala", "Ravindra", ""], ["Saeidi", "Sanaz", ""], ["Liu", "Qun", ""]]}, {"id": "1905.06464", "submitter": "Jasper Sebastiaan Wijnands", "authors": "Jasper S. Wijnands, Kerry A. Nice, Jason Thompson, Haifeng Zhao, Mark\n  Stevenson", "title": "Streetscape augmentation using generative adversarial networks: insights\n  related to health and wellbeing", "comments": "20 pages, 8 figures. Preprint accepted for publication in Sustainable\n  Cities and Society", "journal-ref": null, "doi": "10.1016/j.scs.2019.101602", "report-no": null, "categories": "cs.CY cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning using neural networks has provided advances in image style\ntransfer, merging the content of one image (e.g., a photo) with the style of\nanother (e.g., a painting). Our research shows this concept can be extended to\nanalyse the design of streetscapes in relation to health and wellbeing\noutcomes. An Australian population health survey (n=34,000) was used to\nidentify the spatial distribution of health and wellbeing outcomes, including\ngeneral health and social capital. For each outcome, the most and least\ndesirable locations formed two domains. Streetscape design was sampled using\naround 80,000 Google Street View images per domain. Generative adversarial\nnetworks translated these images from one domain to the other, preserving the\nmain structure of the input image, but transforming the `style' from locations\nwhere self-reported health was bad to locations where it was good. These\ntranslations indicate that areas in Melbourne with good general health are\ncharacterised by sufficient green space and compactness of the urban\nenvironment, whilst streetscape imagery related to high social capital\ncontained more and wider footpaths, fewer fences and more grass. Beyond\nidentifying relationships, the method is a first step towards\ncomputer-generated design interventions that have the potential to improve\npopulation health and wellbeing.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 03:13:15 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Wijnands", "Jasper S.", ""], ["Nice", "Kerry A.", ""], ["Thompson", "Jason", ""], ["Zhao", "Haifeng", ""], ["Stevenson", "Mark", ""]]}, {"id": "1905.06465", "submitter": "Kira Kempinska", "authors": "Kira Kempinska and Roberto Murcio", "title": "Modelling urban networks using Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing question for urban and regional planners pertains to the\nability to describe urban patterns quantitatively. Cities' transport\ninfrastructure, particularly street networks, provides an invaluable source of\ninformation about the urban patterns generated by peoples' movements and their\ninteractions. With the increasing availability of street network datasets and\nthe advancements in deep learning methods, we are presented with an\nunprecedented opportunity to push the frontiers of urban modelling towards more\ndata-driven and accurate models of urban forms. In this study, we present our\ninitial work on applying deep generative models to urban street network data to\ncreate spatially explicit urban models. We based our work on Variational\nAutoencoders (VAEs) which are deep generative models that have recently gained\ntheir popularity due to the ability to generate realistic images. Initial\nresults show that VAEs are capable of capturing key high-level urban network\nmetrics using low-dimensional vectors and generating new urban forms of\ncomplexity matching the cities captured in the street network data.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:36:40 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Kempinska", "Kira", ""], ["Murcio", "Roberto", ""]]}, {"id": "1905.06618", "submitter": "Junaid Ali", "authors": "Junaid Ali, Mahmoudreza Babaei, Abhijnan Chakraborty, Baharan\n  Mirzasoleiman, Krishna P. Gummadi, Adish Singla", "title": "On the Fairness of Time-Critical Influence Maximization in Social\n  Networks", "comments": "Human-Centeric Machine learning (HCML), Workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Influence maximization has found applications in a wide range of real-world\nproblems, for instance, viral marketing of products in an online social\nnetwork, and information propagation of valuable information such as job\nvacancy advertisements and health-related information. While existing\nalgorithmic techniques usually aim at maximizing the total number of people\ninfluenced, the population often comprises several socially salient groups,\ne.g., based on gender or race. As a result, these techniques could lead to\ndisparity across different groups in receiving important information.\nFurthermore, in many of these applications, the spread of influence is\ntime-critical, i.e., it is only beneficial to be influenced before a time\ndeadline. As we show in this paper, the time-criticality of the information\ncould further exacerbate the disparity of influence across groups. This\ndisparity, introduced by algorithms aimed at maximizing total influence, could\nhave far-reaching consequences, impacting people's prosperity and putting\nminority groups at a big disadvantage. In this work, we propose a notion of\ngroup fairness in time-critical influence maximization. We introduce surrogate\nobjective functions to solve the influence maximization problem under fairness\nconsiderations. By exploiting the submodularity structure of our objectives, we\nprovide computationally efficient algorithms with guarantees that are effective\nin enforcing fairness during the propagation process. We demonstrate the\neffectiveness of our approach through synthetic and real-world experiments.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 09:39:39 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 22:04:41 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 13:55:27 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Ali", "Junaid", ""], ["Babaei", "Mahmoudreza", ""], ["Chakraborty", "Abhijnan", ""], ["Mirzasoleiman", "Baharan", ""], ["Gummadi", "Krishna P.", ""], ["Singla", "Adish", ""]]}, {"id": "1905.06716", "submitter": "Julie Dugdale", "authors": "Antoine Flepp, Julie Dugdale, Fabrice Bourge, Tiphaine Marie-Cardot", "title": "A Method to Discover Digital Collaborative Conversations in Business\n  Collaborations", "comments": null, "journal-ref": "10th International Joint Conference on Knowledge Discovery,\n  Knowledge Engineering and Knowledge Management, May 2018, Seville, Spain", "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many companies have a suite of digital tools, such as Enterprise Social\nNetworks, conferencing and document sharing software, and email, to facilitate\ncollaboration among employees. During, or at the end of a collaboration,\ndocuments are often produced. People who were not involved in the initial\ncollaboration often have difficulties understanding parts of its content\nbecause they are lacking the overall context. We argue there is valuable\ncontextual and collaborative knowledge contained in these tools (content and\nuse) that can be used to understand the document. Our goal is to rebuild the\nconversations that took place over a messaging service and their links with a\ndigital conferencing tool during document production. The novelty in our\napproach is to combine several conversation-threading methods to identify\ninteresting links between distinct conversations. Specifically we combine\nheader-field information with social, temporal and semantic proximities. Our\nfindings suggest the messaging service and conferencing tool are used in a\ncomplementary way. The primary results confirm that combining different\nconversation threading approaches is efficient to detect and construct\nconversation threads from distinct digital conversations concerning the same\ndocument.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 12:21:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Flepp", "Antoine", ""], ["Dugdale", "Julie", ""], ["Bourge", "Fabrice", ""], ["Marie-Cardot", "Tiphaine", ""]]}, {"id": "1905.06871", "submitter": "Mario Coccia", "authors": "Mario Coccia", "title": "Artificial intelligence technology in oncology: a new technological\n  paradigm", "comments": "22 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) technology is based on theory and development of\ncomputer systems able to perform tasks that normally require human\nintelligence. In this context, deep learning is a family of computational\nmethods that allow an algorithm to program itself by learning from a large set\nof examples that demonstrate the desired behavior. Application of these methods\nto medical imaging can assist pathologists in the detection of cancer subtype,\ngene mutations and/or metastases for applying appropriate therapies. The\npurpose of this study is to show the emerging application of AI in medical\nimaging to detect lung and breast cancer. Moreover, this study shows the\ncomparative evolutionary pathways of this emerging technology for three\ncritical cancers: lung, breast and thyroid. A main finding of this study is the\nrecognition that, since the late 1990, the sharp increase of technological\ntrajectories of AI technology applied in cancer imaging seems to be driven by\nhigh rates of mortality of some types of cancer (e.g., lung and breast) in\norder to find new techniques for a more accurate detection, characterization\nand monitoring as well as to apply efficiently anticancer therapies that\nincrease the progression-free survival of patients: the so-called\nmortality-driven AI technological trajectories. Results also suggest that this\nnew technology can generate a technological paradigm shift for diagnostic\nassessment of any cancer type. However, application of these methods to medical\nimaging requires further assessment and validation to assist pathologists to\nincrease the efficiency of their workflow in both routine tasks and critical\ncases of diagnostics.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 07:59:47 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Coccia", "Mario", ""]]}, {"id": "1905.06873", "submitter": "Beno\\^it Choffin", "authors": "Beno\\^it Choffin, Fabrice Popineau, Yolaine Bourda and Jill-J\\^enn Vie", "title": "DAS3H: Modeling Student Learning and Forgetting for Optimally Scheduling\n  Distributed Practice of Skills", "comments": "10 pages, 1 figure, 6 tables, to appear at the 12th International\n  Conference on Educational Data Mining (EDM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spaced repetition is among the most studied learning strategies in the\ncognitive science literature. It consists in temporally distributing exposure\nto an information so as to improve long-term memorization. Providing students\nwith an adaptive and personalized distributed practice schedule would benefit\nmore than just a generic scheduler. However, the applicability of such adaptive\nschedulers seems to be limited to pure memorization, e.g. flashcards or foreign\nlanguage learning. In this article, we first frame the research problem of\noptimizing an adaptive and personalized spaced repetition scheduler when\nmemorization concerns the application of underlying multiple skills. To this\nend, we choose to rely on a student model for inferring knowledge state and\nmemory dynamics on any skill or combination of skills. We argue that no\nknowledge tracing model takes both memory decay and multiple skill tagging into\naccount for predicting student performance. As a consequence, we propose a new\nstudent learning and forgetting model suited to our research problem: DAS3H\nbuilds on the additive factor models and includes a representation of the\ntemporal distribution of past practice on the skills involved by an item. In\nparticular, DAS3H allows the learning and forgetting curves to differ from one\nskill to another. Finally, we provide empirical evidence on three real-world\neducational datasets that DAS3H outperforms other state-of-the-art EDM models.\nThese results suggest that incorporating both item-skill relationships and\nforgetting effect improves over student models that consider one or the other.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 16:41:03 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Choffin", "Beno\u00eet", ""], ["Popineau", "Fabrice", ""], ["Bourda", "Yolaine", ""], ["Vie", "Jill-J\u00eann", ""]]}, {"id": "1905.06875", "submitter": "Kit Rodolfa", "authors": "Kit T Rodolfa, Adolfo De Unanue, Matt Gee, Rayid Ghani", "title": "A Clinical Approach to Training Effective Data Scientists", "comments": "18 pages, 3 figures, 2 tables", "journal-ref": "Big Data 7:4, 249-261 (2019)", "doi": "10.1089/big.2019.0100", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Like medicine, psychology, or education, data science is fundamentally an\napplied discipline, with most students who receive advanced degrees in the\nfield going on to work on practical problems. Unlike these disciplines,\nhowever, data science education remains heavily focused on theory and methods,\nand practical coursework typically revolves around cleaned or simplified data\nsets that have little analog in professional applications. We believe that the\nenvironment in which new data scientists are trained should more accurately\nreflect that in which they will eventually practice and propose here a data\nscience master's degree program that takes inspiration from the residency model\nused in medicine. Students in the suggested program would spend three years\nworking on a practical problem with an industry, government, or nonprofit\npartner, supplemented with coursework in data science methods and theory. We\nalso discuss how this program can also be implemented in shorter formats to\naugment existing professional masters programs in different disciplines. This\napproach to learning by doing is designed to fill gaps in our current approach\nto data science education and ensure that students develop the skills they need\nto practice data science in a professional context and under the many\nconstraints imposed by that context.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 02:36:28 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Rodolfa", "Kit T", ""], ["De Unanue", "Adolfo", ""], ["Gee", "Matt", ""], ["Ghani", "Rayid", ""]]}, {"id": "1905.06876", "submitter": "Jessica Morley", "authors": "Jessica Morley, Luciano Floridi, Libby Kinsey and Anat Elhalal", "title": "From What to How: An Initial Review of Publicly Available AI Ethics\n  Tools, Methods and Research to Translate Principles into Practices", "comments": "15 pages, links to typology available on the web", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The debate about the ethical implications of Artificial Intelligence dates\nfrom the 1960s. However, in recent years symbolic AI has been complemented and\nsometimes replaced by Neural Networks and Machine Learning techniques. This has\nvastly increased its potential utility and impact on society, with the\nconsequence that the ethical debate has gone mainstream. Such debate has\nprimarily focused on principles - the what of AI ethics - rather than on\npractices, the how. Awareness of the potential issues is increasing at a fast\nrate, but the AI community's ability to take action to mitigate the associated\nrisks is still at its infancy. Therefore, our intention in presenting this\nresearch is to contribute to closing the gap between principles and practices\nby constructing a typology that may help practically-minded developers apply\nethics at each stage of the pipeline, and to signal to researchers where\nfurther work is needed. The focus is exclusively on Machine Learning, but it is\nhoped that the results of this research may be easily applicable to other\nbranches of AI. The article outlines the research method for creating this\ntypology, the initial findings, and provides a summary of future research\nneeds.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 07:38:44 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 12:10:32 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Morley", "Jessica", ""], ["Floridi", "Luciano", ""], ["Kinsey", "Libby", ""], ["Elhalal", "Anat", ""]]}, {"id": "1905.07054", "submitter": "Lionel Robert", "authors": "Lionel Peter Robert Jr", "title": "Are Automated Vehicles Safer than Manually Driven Cars?", "comments": "3 pages. AI & Society (2019)", "journal-ref": null, "doi": "10.1007/s00146-019-00894-y", "report-no": null, "categories": "cs.HC cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are automated vehicles really safer than manually driven vehicles? If so, how\nwould we know? Answering this question has spurred a contentious debate.\nUnfortunately, several issues make answering this question difficult for the\nforeseeable future. First, how do we measure safety? Second, how can we keep\ntrack of automated vehicle (AV) safety? Finally, how do we determine what is or\nwhat is not an AV? Until these questions are addressed, it will continue to be\ndifficult to determine whether or when AVs might really be safer than manually\ndriven vehicles.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 22:59:14 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Robert", "Lionel Peter", "Jr"]]}, {"id": "1905.07160", "submitter": "Juste Raimbault", "authors": "J. Raimbault, D. Pumain", "title": "Methods for Exploring Simulation Models", "comments": "16 pages", "journal-ref": "in Geographical Modeling: Cities and Territories, Pumain D. ed.,\n  pp. 125-150. Wiley Online Library (2019)", "doi": "10.1002/9781119687290.ch5", "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation models are an absolute necessity in the human and social sciences,\nwhich can only very exceptionally use experimental science methods to construct\ntheir knowledge. Models enable the simulation of social processes by replacing\nthe complex interplay of individual and collective actions and reactions with\nsimpler mathematical or computer mechanisms, making it easier to understand the\nrelationships between the causes and the consequences of these interactions and\nto make predictions. As the formalism of mathematical models offering\nanalytical solutions is often not suitable for representing social complexity,\nmore and more agent-based computer models are being used. For a long time, the\nlimited computing capacities of computers have hampered programming models that\nwould take into account the interactions between large numbers of\ngeographically located entities (persons or territories). In principle, these\nmodels should inform the conditions for the emergence of certain patterns\ndefined at a macro-geographic level from the interactions occurring at a\nmicro-geographic level, in systems whose behaviors are too complex to be\nunderstood directly by a human brain. Moreover, it is also necessary to analyze\nthe dynamic behavior of these models with nonlinear feedback effects and verify\nthat they produce plausible results at all stages of their simulation. This\nessential work of exploring the dynamics of modeled systems remained in its\ninfancy until the late 2010s. Since then, algorithms combining more\nsophisticated methods, including genetic algorithms and the use of distributed\nintensive computing, have made it possible to make a significant qualitative\nleap forward in the exploration and validation of models. The result is an\nepistemological turn for the human and social sciences, as indicated by the\nlatest applications realized with the help of the OpenMOLE platform presented\nhere.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 08:20:25 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2020 12:42:42 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Raimbault", "J.", ""], ["Pumain", "D.", ""]]}, {"id": "1905.07173", "submitter": "Lihi Dery", "authors": "Marina Bannikova, Lihi Dery, Svetlana Obraztsova, Zinovi Rabinovich\n  and Jeffrey S. Rosenschein", "title": "Reaching Consensus Under a Deadline", "comments": null, "journal-ref": "Autonomous Agents and Multi-Agent Systems, 35(1), 1-42 (2021)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Committee decisions are complicated by a deadline, e.g., the next start of a\nbudget, or the beginning of a semester. In committee hiring decisions, it may\nbe that if no candidate is supported by a strong majority, the default is to\nhire no one - an option that may cost dearly. As a result, committee members\nmight prefer to agree on a reasonable, if not necessarily the best, candidate,\nto avoid unfilled positions. In this paper, we propose a model for the above\nscenario - Consensus Under a Deadline (CUD)- based on a time-bounded iterative\nvoting process. We provide convergence guarantees and an analysis of the\nquality of the final decision. An extensive experimental study demonstrates\nmore subtle features of CUDs, e.g., the difference between two simple types of\ncommittee member behavior, lazy vs.~proactive voters. Finally, a user study\nexamines the differences between the behavior of rational voting bots and real\nvoters, concluding that it may often be best to have bots play on the voters'\nbehalf.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 09:06:07 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 09:31:12 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 11:55:40 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Bannikova", "Marina", ""], ["Dery", "Lihi", ""], ["Obraztsova", "Svetlana", ""], ["Rabinovich", "Zinovi", ""], ["Rosenschein", "Jeffrey S.", ""]]}, {"id": "1905.07697", "submitter": "Amit Sharma", "authors": "Ramaravind Kommiya Mothilal, Amit Sharma, Chenhao Tan", "title": "Explaining Machine Learning Classifiers through Diverse Counterfactual\n  Explanations", "comments": "13 pages", "journal-ref": "Conference on Fairness, Accountability, and Transparency (FAT*\n  2020)", "doi": "10.1145/3351095.3372850", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc explanations of machine learning models are crucial for people to\nunderstand and act on algorithmic predictions. An intriguing class of\nexplanations is through counterfactuals, hypothetical examples that show people\nhow to obtain a different prediction. We posit that effective counterfactual\nexplanations should satisfy two properties: feasibility of the counterfactual\nactions given user context and constraints, and diversity among the\ncounterfactuals presented. To this end, we propose a framework for generating\nand evaluating a diverse set of counterfactual explanations based on\ndeterminantal point processes. To evaluate the actionability of\ncounterfactuals, we provide metrics that enable comparison of\ncounterfactual-based methods to other local explanation methods. We further\naddress necessary tradeoffs and point to causal implications in optimizing for\ncounterfactuals. Our experiments on four real-world datasets show that our\nframework can generate a set of counterfactuals that are diverse and well\napproximate local decision boundaries, outperforming prior approaches to\ngenerating diverse counterfactuals. We provide an implementation of the\nframework at https://github.com/microsoft/DiCE.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:23:01 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 12:26:41 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Mothilal", "Ramaravind Kommiya", ""], ["Sharma", "Amit", ""], ["Tan", "Chenhao", ""]]}, {"id": "1905.07844", "submitter": "Alexander Wong", "authors": "Linda Wang and Alexander Wong", "title": "Implications of Computer Vision Driven Assistive Technologies Towards\n  Individuals with Visual Impairment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision based technology is becoming ubiquitous in society. One\napplication area that has seen an increase in computer vision is assistive\ntechnologies, specifically for those with visual impairment. Research has shown\nthe ability of computer vision models to achieve tasks such provide scene\ncaptions, detect objects and recognize faces. Although assisting individuals\nwith visual impairment with these tasks increases their independence and\nautonomy, concerns over bias, privacy and potential usefulness arise. This\npaper addresses the positive and negative implications computer vision based\nassistive technologies have on individuals with visual impairment, as well as\nconsiderations for computer vision researchers and developers in order to\nmitigate the amount of negative implications.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 02:00:56 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wang", "Linda", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.07964", "submitter": "Chico Q. Camargo", "authors": "Chico Q. Camargo, Jonathan Bright, Scott A. Hale", "title": "Diagnosing the performance of human mobility models at small spatial\n  scales using volunteered geographic information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate modelling of local population movement patterns is a core\ncontemporary concern for urban policymakers, affecting both the short term\ndeployment of public transport resources and the longer term planning of\ntransport infrastructure. Yet, while macro-level population movement models\n(such as the gravity and radiation models) are well developed, micro-level\nalternatives are in much shorter supply, with most macro-models known to\nperform badly in smaller geographic confines. In this paper we take a first\nstep to remedying this deficit, by leveraging two novel datasets to analyse\nwhere and why macro-level models of human mobility break down at small scales.\nIn particular, we use an anonymised aggregate dataset from a major mobility app\nand combine this with freely available data from OpenStreetMap concerning\nland-use composition of different areas around the county of Oxfordshire in the\nUnited Kingdom. We show where different models fail, and make the case for a\nnew modelling strategy which moves beyond rough heuristics such as distance and\npopulation size towards a detailed, granular understanding of the opportunities\npresented in different areas of the city.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 09:56:49 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Camargo", "Chico Q.", ""], ["Bright", "Jonathan", ""], ["Hale", "Scott A.", ""]]}, {"id": "1905.08067", "submitter": "Jason R.C. Nurse Dr", "authors": "Mariam Nouh and Jason R. C. Nurse and Michael Goldsmith", "title": "Understanding the Radical Mind: Identifying Signals to Detect Extremist\n  Content on Twitter", "comments": null, "journal-ref": "17th IEEE International Conference on Intelligence and Security\n  Informatics (ISI), 2019", "doi": "10.1109/ISI.2019.8823548", "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet and, in particular, Online Social Networks have changed the way\nthat terrorist and extremist groups can influence and radicalise individuals.\nRecent reports show that the mode of operation of these groups starts by\nexposing a wide audience to extremist material online, before migrating them to\nless open online platforms for further radicalization. Thus, identifying\nradical content online is crucial to limit the reach and spread of the\nextremist narrative. In this paper, our aim is to identify measures to\nautomatically detect radical content in social media. We identify several\nsignals, including textual, psychological and behavioural, that together allow\nfor the classification of radical messages. Our contribution is three-fold: (1)\nwe analyze propaganda material published by extremist groups and create a\ncontextual text-based model of radical content, (2) we build a model of\npsychological properties inferred from these material, and (3) we evaluate\nthese models on Twitter to determine the extent to which it is possible to\nautomatically identify online radical tweets. Our results show that radical\nusers do exhibit distinguishable textual, psychological, and behavioural\nproperties. We find that the psychological properties are among the most\ndistinguishing features. Additionally, our results show that textual models\nusing vector embedding features significantly improves the detection over\nTF-IDF features. We validate our approach on two experiments achieving high\naccuracy. Our findings can be utilized as signals for detecting online\nradicalization activities.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 17:14:34 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Nouh", "Mariam", ""], ["Nurse", "Jason R. C.", ""], ["Goldsmith", "Michael", ""]]}, {"id": "1905.08289", "submitter": "Roman Lukyanenko", "authors": "Roman Lukyanenko, Andrea Wiggins, Holly K. Rosser", "title": "Citizen Science: An Information Quality Research Frontier", "comments": null, "journal-ref": "2019, Information Systems Frontiers", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid proliferation of online content producing and sharing technologies\nresulted in an explosion of user-generated content (UGC), which now extends to\nscientific data. Citizen science, in which ordinary people contribute\ninformation for scientific research, epitomizes UGC. Citizen science projects\nare typically open to everyone, engage diverse audiences, and challenge\nordinary people to produce data of highest quality to be usable in science.\nThis also makes citizen science a very exciting area to study both traditional\nand innovative approaches to information quality management. With this paper we\nposition citizen science as a leading information quality research frontier. We\nalso show how citizen science opens a unique opportunity for the information\nsystems community to contribute to a broad range of disciplines in natural and\nsocial sciences and humanities.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 18:39:57 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Lukyanenko", "Roman", ""], ["Wiggins", "Andrea", ""], ["Rosser", "Holly K.", ""]]}, {"id": "1905.08355", "submitter": "Kashif Zia Dr.", "authors": "Kashif Zia, Alois Ferscha, Dari Trendafilov", "title": "Importance of Coordination and Cultural Diversity for an Efficient and\n  Flexible Manufacturing System", "comments": "4 pages, The Eleventh International Conference on Advanced Cognitive\n  Technologies and Applications, May 05, 2019 to May 09, 2019 - Venice, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manufacturing systems of the future need to have flexible resources and\nflexible routing to produce extremely personalized products, even of lot size\nequal to one. In this paper, we have proposed a framework, which is designed to\nachieve this goal. Towards this, we have integrated an established cultural\nevolution model to achieve desired flexibility of resources and acceptable\nrouting time. Promising results are evidenced through a simple proof-of-concept\nsimulation.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 21:28:36 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Zia", "Kashif", ""], ["Ferscha", "Alois", ""], ["Trendafilov", "Dari", ""]]}, {"id": "1905.08517", "submitter": "Anwitaman Datta", "authors": "Anwitaman Datta", "title": "Blockchain in the Government Technology Fabric", "comments": "13 pages, 1 Figure, Longer version of paper published in IIAS-Lien\n  2019 conference: Science, Technology and Innovation Policies track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuelled by the success (and hype) around cryptocurrencies, distributed ledger\ntechnologies (DLT), particularly blockchains, have gained a lot of attention\nfrom a wide spectrum of audience who perceive blockchains as a key to carry out\nbusiness processes that have hitherto been cumbersome in a cost and time\neffective manner. Governments across the globe have responded to this promising\nbut nascent technology differently - from being apathetic or adopting a\nwait-and-watch approach: letting the systems shape themselves, to creating\nregulatory sandboxes and sponsoring capacity building, or in some instances\n(arguably) over-regulating and attempting to put the blockchain genie back in\nthe bottle. Possible government role spans across a spectrum: regulating\ncrypto-currencies and initial coin offerings (ICO), formulating regulatory\nframeworks for managing the adoption of blockchains, particularly in critical\ninfrastructure industries, facilitating capacity building, and finally,\nembracing blockchain technology in conducting the activities of the government\nitself - be it internally, or in using them to deliver public services. In this\npaper we survey the last, namely, the use of blockchain and associated\ndistributed ledger technologies in the government technology (GovTech) stack,\nand discuss the merits and concerns associated with the existing initiatives\nand approaches.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 09:39:14 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Datta", "Anwitaman", ""]]}, {"id": "1905.08674", "submitter": "Daniel S. Katz", "authors": "Daniel S. Katz, Daina Bouquin, Neil P. Chue Hong, Jessica Hausman,\n  Catherine Jones, Daniel Chivvis, Tim Clark, Merc\\`e Crosas, Stephan Druskat,\n  Martin Fenner, Tom Gillespie, Alejandra Gonzalez-Beltran, Morane Gruenpeter,\n  Ted Habermann, Robert Haines, Melissa Harrison, Edwin Henneken, Lorraine\n  Hwang, Matthew B. Jones, Alastair A. Kelly, David N. Kennedy, Katrin\n  Leinweber, Fernando Rios, Carly B. Robinson, Ilian Todorov, Mingfang Wu, Qian\n  Zhang", "title": "Software Citation Implementation Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main output of the FORCE11 Software Citation working group\n(https://www.force11.org/group/software-citation-working-group) was a paper on\nsoftware citation principles (https://doi.org/10.7717/peerj-cs.86) published in\nSeptember 2016. This paper laid out a set of six high-level principles for\nsoftware citation (importance, credit and attribution, unique identification,\npersistence, accessibility, and specificity) and discussed how they could be\nused to implement software citation in the scholarly community. In a series of\ntalks and other activities, we have promoted software citation using these\nincreasingly accepted principles. At the time the initial paper was published,\nwe also provided guidance and examples on how to make software citable, though\nwe now realize there are unresolved problems with that guidance. The purpose of\nthis document is to provide an explanation of current issues impacting\nscholarly attribution of research software, organize updated implementation\nguidance, and identify where best practices and solutions are still needed.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 14:46:50 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Katz", "Daniel S.", ""], ["Bouquin", "Daina", ""], ["Hong", "Neil P. Chue", ""], ["Hausman", "Jessica", ""], ["Jones", "Catherine", ""], ["Chivvis", "Daniel", ""], ["Clark", "Tim", ""], ["Crosas", "Merc\u00e8", ""], ["Druskat", "Stephan", ""], ["Fenner", "Martin", ""], ["Gillespie", "Tom", ""], ["Gonzalez-Beltran", "Alejandra", ""], ["Gruenpeter", "Morane", ""], ["Habermann", "Ted", ""], ["Haines", "Robert", ""], ["Harrison", "Melissa", ""], ["Henneken", "Edwin", ""], ["Hwang", "Lorraine", ""], ["Jones", "Matthew B.", ""], ["Kelly", "Alastair A.", ""], ["Kennedy", "David N.", ""], ["Leinweber", "Katrin", ""], ["Rios", "Fernando", ""], ["Robinson", "Carly B.", ""], ["Todorov", "Ilian", ""], ["Wu", "Mingfang", ""], ["Zhang", "Qian", ""]]}, {"id": "1905.08772", "submitter": "Sergio Gast\\'on Burdisso", "authors": "Sergio G. Burdisso, Marcelo Errecalde, Manuel Montes-y-G\\'omez", "title": "A Text Classification Framework for Simple and Effective Early\n  Depression Detection Over Social Media Streams", "comments": "Highlights: (*) A novel text classifier having the ability to\n  visually explain its rationale; (*) Domain-independent classification that\n  does not require feature engineering; (*) Support for incremental learning\n  and text classification over streams; (*) Efficient framework for addressing\n  early risk detection problems; (*) State-of-the-art performance on early\n  depression detection task", "journal-ref": "18 May 2019, Volume 133, Expert Systems With Applications,\n  Elsevier", "doi": "10.1016/j.eswa.2019.05.023", "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of the Internet, there is a growing need to build intelligent\nsystems that are capable of efficiently dealing with early risk detection (ERD)\nproblems on social media, such as early depression detection, early rumor\ndetection or identification of sexual predators. These systems, nowadays mostly\nbased on machine learning techniques, must be able to deal with data streams\nsince users provide their data over time. In addition, these systems must be\nable to decide when the processed data is sufficient to actually classify\nusers. Moreover, since ERD tasks involve risky decisions by which people's\nlives could be affected, such systems must also be able to justify their\ndecisions. However, most standard and state-of-the-art supervised machine\nlearning models (such as SVM, MNB, Neural Networks, etc.) are not well suited\nto deal with this scenario. This is due to the fact that they either act as\nblack boxes or do not support incremental classification/learning. In this\npaper we introduce SS3, a novel supervised learning model for text\nclassification that naturally supports these aspects. SS3 was designed to be\nused as a general framework to deal with ERD problems. We evaluated our model\non the CLEF's eRisk2017 pilot task on early depression detection. Most of the\n30 contributions submitted to this competition used state-of-the-art methods.\nExperimental results show that our classifier was able to outperform these\nmodels and standard classifiers, despite being less computationally expensive\nand having the ability to explain its rationale.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 15:46:38 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Burdisso", "Sergio G.", ""], ["Errecalde", "Marcelo", ""], ["Montes-y-G\u00f3mez", "Manuel", ""]]}, {"id": "1905.08773", "submitter": "Issam Damaj", "authors": "Marwa Kandil (1), Reem AlBaghdadi (1), Fatemah AlAttar (1), Issam\n  Damaj (2) ((1) American University of Kuwait, (2) Rafik Hariri University)", "title": "AmIE: An Ambient Intelligent Environment for Assisted Living", "comments": "6 pages, 8 figures, 1 table", "journal-ref": "The 2nd Eng Innovations in Healthcare International Conference,\n  IEEE, Dubai, UAE, March 26-27, (2019) 1-6", "doi": "10.1109/ICASET.2019.8714499", "report-no": null, "categories": "cs.CY cs.HC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern world of technology Internet-of-things (IoT) systems strives to\nprovide an extensive interconnected and automated solutions for almost every\nlife aspect. This paper proposes an IoT context-aware system to present an\nAmbient Intelligence (AmI) environment; such as an apartment, house, or a\nbuilding; to assist blind, visually-impaired, and elderly people. The proposed\nsystem aims at providing an easy-to-utilize voice-controlled system to locate,\nnavigate and assist users indoors. The main purpose of the system is to provide\nindoor positioning, assisted navigation, outside weather information, room\ntemperature, people availability, phone calls and emergency evacuation when\nneeded. The system enhances the user's awareness of the surrounding environment\nby feeding them with relevant information through a wearable device to assist\nthem. In addition, the system is voice-controlled in both English and Arabic\nlanguages and the information are displayed as audio messages in both\nlanguages. The system design, implementation, and evaluation consider the\nconstraints in common types of premises in Kuwait and in challenges, such as\nthe training needed by the users. This paper presents cost-effective\nimplementation options by the adoption of a Raspberry Pi microcomputer,\nBluetooth Low Energy devices and an Android smart watch.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 13:57:31 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Kandil", "Marwa", "", "American University of Kuwait"], ["AlBaghdadi", "Reem", "", "American University of Kuwait"], ["AlAttar", "Fatemah", "", "American University of Kuwait"], ["Damaj", "Issam", "", "Rafik Hariri University"]]}, {"id": "1905.08775", "submitter": "Evangelos Pournaras", "authors": "David Castells-Graells, Christopher Salahub, Evangelos Pournaras", "title": "On Cycling Risk and Discomfort: Urban Safety Mapping and Bike Route\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bike usage in Smart Cities becomes paramount for sustainable urban\ndevelopment. Cycling provides tremendous opportunities for a more healthy\nlifestyle, lower energy consumption and carbon emissions as well as reduction\nof traffic jams. While the number of cyclists increase along with the expansion\nof bike sharing initiatives and infrastructures, the number of bike accidents\nrises drastically threatening to jeopardize the bike urban movement. This paper\nstudies cycling risk and discomfort using a diverse spectrum of data sources\nabout geolocated bike accidents and their severity. Empirical continuous\nspatial risk estimations are calculated via kernel density contours that map\nsafety in a case study of Zurich city. The role of weather, time, accident type\nand severity are illustrated. Given the predominance of self-caused accidents,\nan open-source software artifact for personalized route recommendations is\nintroduced. The software is also used to collect open baseline route data that\nare compared with alternative ones that minimize risk or discomfort. These\ncontributions can provide invaluable insights for urban planners to improve\ninfrastructure. They can also improve the risk awareness of existing cyclists'\nas well as support new cyclists, such as tourists, to safely explore a new\nurban environment by bike.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 20:50:31 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Castells-Graells", "David", ""], ["Salahub", "Christopher", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "1905.08819", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono and Alex Pentland", "title": "Data Cooperatives: Towards a Foundation for Decentralized Personal Data\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data cooperatives with fiduciary obligations to members provide a promising\ndirection for the empowerment of individuals through their own personal data. A\ndata cooperative can manage, curate and protect access to the personal data of\ncitizen members. Furthermore, the data cooperative can run internal analytics\nin order to obtain insights regarding the well-being of its members. Armed with\nthese insights, the data cooperative would be in a good position to negotiate\nbetter services and discounts for its members. Credit Unions and similar\ninstitutions can provide a suitable realization of data cooperatives.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 18:01:38 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Hardjono", "Thomas", ""], ["Pentland", "Alex", ""]]}, {"id": "1905.08833", "submitter": "Aron Laszka", "authors": "Afiya Ayman, Shanto Roy, Amin Alipour, Aron Laszka", "title": "Smart Contract Development from the Perspective of Developers: Topics\n  and Issues Discussed on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain-based platforms are emerging as a transformative technology that\ncan provide reliability, integrity, and auditability without trusted entities.\nOne of the key features of these platforms is the trustworthy decentralized\nexecution of general-purpose computation in the form of smart contracts, which\nare envisioned to have a wide range of applications. As a result, a rapidly\ngrowing and active community of smart-contract developers has emerged in recent\nyears. A number of research efforts have investigated the technological\nchallenges that these developers face, introducing a variety of tools,\nlanguages, and frameworks for smart-contract development, focusing on security.\nHowever, relatively little is known about the community itself, about the\ndevelopers, and about the issues that they face and discuss. To address this\ngap, we study smart-contract developers and their discussions on two social\nmedia sites, Stack Exchange and Medium. We provide insight into the trends and\nkey topics of these discussions, into the developers' interest in various\nsecurity issues and security tools, and into the developers' technological\nbackground.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 19:46:37 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 01:25:44 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Ayman", "Afiya", ""], ["Roy", "Shanto", ""], ["Alipour", "Amin", ""], ["Laszka", "Aron", ""]]}, {"id": "1905.08878", "submitter": "Lionel Robert", "authors": "Na Du, Jacob Haspiel, Qiaoning Zhang, Dawn Tilbury, Anuj K. Pradhan,\n  X. Jessie Yang, Lionel P. Robert Jr", "title": "Look Who's Talking Now: Implications of AV's Explanations on Driver's\n  Trust, AV Preference, Anxiety and Mental Workload", "comments": "42 pages, 5 figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations given by automation are often used to promote automation\nadoption. However, it remains unclear whether explanations promote acceptance\nof automated vehicles (AVs). In this study, we conducted a within-subject\nexperiment in a driving simulator with 32 participants, using four different\nconditions. The four conditions included: (1) no explanation, (2) explanation\ngiven before or (3) after the AV acted and (4) the option for the driver to\napprove or disapprove the AV's action after hearing the explanation. We\nexamined four AV outcomes: trust, preference for AV, anxiety and mental\nworkload. Results suggest that explanations provided before an AV acted were\nassociated with higher trust in and preference for the AV, but there was no\ndifference in anxiety and workload. These results have important implications\nfor the adoption of AVs.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 21:39:07 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Du", "Na", ""], ["Haspiel", "Jacob", ""], ["Zhang", "Qiaoning", ""], ["Tilbury", "Dawn", ""], ["Pradhan", "Anuj K.", ""], ["Yang", "X. Jessie", ""], ["Robert", "Lionel P.", "Jr"]]}, {"id": "1905.09116", "submitter": "Lihi Dery", "authors": "Lihi Dery, Dror Hermel, Artyom Jelnov", "title": "Cheating in Ranking Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an application sold on an on-line platform, with the app paying a\ncommission fee and, henceforth, offered for sale on the platform. The ability\nto sell the application depends on its customer ranking. Therefore, developers\nmay have an incentive to promote their applications ranking in a dishonest\nmanner. One way to do this is by faking positive customer reviews. However, the\nplatform is able to detect dishonest behavior (cheating) with some probability\nand then proceeds to decide whether to ban the application. We provide an\nanalysis and find the equilibrium behaviors of both the applications developers\n(cheat or not) and the platform (setting of the commission fee). We provide\ninitial insights into how the platforms detection accuracy affects the\nincentives of the app developers.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 13:10:24 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Dery", "Lihi", ""], ["Hermel", "Dror", ""], ["Jelnov", "Artyom", ""]]}, {"id": "1905.09146", "submitter": "Armando Toda", "authors": "Armando M. Toda, Wilk Oliveira, Lei Shi, Ig Ibert Bittencourt, Seiji\n  Isotani, Alexandra Cristea", "title": "Planning Gamification Strategies based on User Characteristics and DM: A\n  Gender-based Case Study", "comments": "https://drive.google.com/file/d/1UI28N2UtrOfL06k2mzHIUdPcgQtdfmy9/view?usp=sharing", "journal-ref": "Proceedings of the Educational Data Mining 2019 conference", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gamification frameworks can aid in gamification planning for education. Most\nframeworks, however, do not provide ways to select, relate or recommend how to\nuse game elements, to gamify a certain educational task. Instead, most provide\na \"one-size-fits-all\" approach covering all learners, without considering\ndifferent user characteristics, such as gender. Therefore, this work aims to\nadopt a data-driven approach to provide a set of game element recommendations,\nbased on user preferences, that could be used by teachers and instructors to\ngamify learning activities. We analysed data from a novel survey of 733 people\n(male=569 and female=164), collecting information about user preferences\nregarding game elements. Our results suggest that the most important rules were\nbased on four (out of nineteen) types of game elements: Objectives, Levels,\nProgress and Choice. From the perspective of user gender, for the female\nsample, the most interesting rule associated Objectives with Progress, Badges\nand Information (confidence=0.97), whilst the most interesting rule for the\nmale sample associated also Objectives with Progress, Renovation and Choice\n(confidence=0.94). These rules and our descriptive analysis provides\nrecommendations on how game elements can be used in educational scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 14:00:08 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 12:07:19 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Toda", "Armando M.", ""], ["Oliveira", "Wilk", ""], ["Shi", "Lei", ""], ["Bittencourt", "Ig Ibert", ""], ["Isotani", "Seiji", ""], ["Cristea", "Alexandra", ""]]}, {"id": "1905.09203", "submitter": "Krzysztof Cios", "authors": "Krzysztof J. Cios, Bartosz Krawczyk, Jacquelyne Cios, Kevin J. Staley", "title": "Uniqueness of Medical Data Mining: How the new technologies and data\n  they generate are transforming medicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes how the new technologies and data they generate are\ntransforming medicine. It stresses the uniqueness of heterogeneous medical data\nand the ways of dealing with them. It lists different sources that generate big\nmedical data, their security, legal and ethical issues, as well as machine\nlearning/AI methods of dealing with them. A unique feature of the paper is use\nof case studies to illustrate how the new technologies influence medical\npractice.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:52:08 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Cios", "Krzysztof J.", ""], ["Krawczyk", "Bartosz", ""], ["Cios", "Jacquelyne", ""], ["Staley", "Kevin J.", ""]]}, {"id": "1905.09239", "submitter": "Stratis Tsirtsis", "authors": "Stratis Tsirtsis, Behzad Tabibian, Moein Khajehnejad, Adish Singla,\n  Bernhard Sch\\\"olkopf, Manuel Gomez-Rodriguez", "title": "Optimal Decision Making Under Strategic Behavior", "comments": "New method of estimating the outcome probabilities and setting the\n  cost function values. New experiments on credit card data. Performance\n  optimization in the presence of non-actionable features", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are witnessing an increasing use of data-driven predictive models to\ninform decisions. As decisions have implications for individuals and society,\nthere is increasing pressure on decision makers to be transparent about their\ndecision policies. At the same time, individuals may use knowledge, gained by\ntransparency, to invest effort strategically in order to maximize their chances\nof receiving a beneficial decision. Our goal is to find decision policies that\nare optimal in terms of utility in such a strategic setting. To this end, we\nfirst characterize how strategic investment of effort by individuals leads to a\nchange in the feature distribution. Using this characterization, we first show\nthat, in general, we cannot expect to find optimal decision policies in\npolynomial time and there are cases in which deterministic policies are\nsuboptimal. Then, we demonstrate that, if the cost individuals pay to change\ntheir features satisfies a natural monotonicity assumption, we can narrow down\nthe search for the optimal policy to a particular family of decision policies\nwith a set of desirable properties, which allow for a highly effective\npolynomial time heuristic search algorithm using dynamic programming. Finally,\nunder no assumptions on the cost individuals pay to change their features, we\ndevelop an iterative search algorithm that is guaranteed to find locally\noptimal decision policies also in polynomial time. Experiments on synthetic and\nreal credit card data illustrate our theoretical findings and show that the\ndecision policies found by our algorithms achieve higher utility than those\nthat do not account for strategic behavior.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 16:55:24 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 08:08:52 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 08:38:35 GMT"}, {"version": "v4", "created": "Sun, 2 Feb 2020 22:11:06 GMT"}, {"version": "v5", "created": "Mon, 21 Sep 2020 10:53:42 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Tsirtsis", "Stratis", ""], ["Tabibian", "Behzad", ""], ["Khajehnejad", "Moein", ""], ["Singla", "Adish", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "1905.09350", "submitter": "Dan Calacci", "authors": "Dan Calacci, Alex Berke, Kent Larson, Alex (Sandy) Pentland", "title": "The tradeoff between the utility and risk of location data and\n  implications for public good", "comments": "22 pages, 3 figures, summary figure on page 16. Submitted to\n  Connected Life conference 2019 (non-archival)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-resolution individual geolocation data passively collected from mobile\nphones is increasingly sold in private markets and shared with researchers.\nThis data poses significant security, privacy, and ethical risks: it's been\nshown that users can be re-identified in such datasets, and its collection\nrarely involves their full consent or knowledge. This data is valuable to\nprivate firms (e.g. targeted marketing) but also presents clear value as a\npublic good. Recent public interest research has demonstrated that\nhigh-resolution location data can more accurately measure segregation in cities\nand provide inexpensive transit modeling. But as data is aggregated to mitigate\nits re-identifiability risk, its value as a good diminishes. How do we rectify\nthe clear security and safety risks of this data, its high market value, and\nits potential as a resource for public good? We extend the recently proposed\nconcept of a tradeoff curve that illustrates the relationship between dataset\nutility and privacy. We then hypothesize how this tradeoff differs between\nprivate market use and its potential use for public good. We further provide\nreal-world examples of how high resolution location data, aggregated to varying\ndegrees of privacy protection, can be used in the public sphere and how it is\ncurrently used by private firms.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 20:03:51 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 19:21:32 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Calacci", "Dan", "", "Sandy"], ["Berke", "Alex", "", "Sandy"], ["Larson", "Kent", "", "Sandy"], ["Alex", "", "", "Sandy"], ["Pentland", "", ""]]}, {"id": "1905.09735", "submitter": "Blaise Yvert", "authors": "\\'Eric Fourneret and Blaise Yvert", "title": "Digital Normativity: A challenge for human subjectivization and free\n  will", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past decade, artificial intelligence has demonstrated its efficiency\nin many different applications and a huge number of algorithms have become\ncentral and ubiquitous in our life. Their growing interest is essentially based\non their capability to synthesize and process large amounts of data, and to\nhelp humans making decisions in a world of increasing complexity. Yet, the\neffectiveness of algorithms in bringing more and more relevant recommendations\nto humans may start to compete with human-alone decisions based on values other\nthan pure efficacy. Here, we examine this tension in light of the emergence of\nseveral forms of digital normativity, and analyze how this normative role of AI\nmay influence the ability of humans to remain subject of their life. The advent\nof AI technology imposes a need to achieve a balance between concrete material\nprogress and progress of the mind to avoid any form of servitude. It has become\nessential that an ethical reflection accompany the current developments of\nintelligent algorithms beyond the sole question of their social acceptability.\nSuch reflection should be anchored where AI technologies are being developed as\nwell as in educational programs where their implications can be explained.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 15:53:21 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Fourneret", "\u00c9ric", ""], ["Yvert", "Blaise", ""]]}, {"id": "1905.09916", "submitter": "Ali Malik", "authors": "Ali Malik, Mike Wu, Vrinda Vasavada, Jinpeng Song, Madison Coots, John\n  Mitchell, Noah Goodman, Chris Piech", "title": "Generative Grading: Near Human-level Accuracy for Automated Feedback on\n  Richly Structured Problems", "comments": "10 pages of content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to high-quality education at scale is limited by the difficulty of\nproviding student feedback on open-ended assignments in structured domains like\ncomputer programming, graphics, and short response questions. This problem has\nproven to be exceptionally difficult: for humans, it requires large amounts of\nmanual work, and for computers, until recently, achieving anything near\nhuman-level accuracy has been unattainable. In this paper, we present\ngenerative grading: a novel computational approach for providing feedback at\nscale that is capable of accurately grading student work and providing nuanced,\ninterpretable feedback. Our approach uses generative descriptions of student\ncognition, written as probabilistic programs, to synthesise millions of\nlabelled example solutions to a problem; we then learn to infer feedback for\nreal student solutions based on this cognitive model.\n  We apply our methods to three settings. In block-based coding, we achieve a\n50% improvement upon the previous best results for feedback, achieving\nsuper-human accuracy. In two other widely different domains -- graphical tasks\nand short text answers -- we achieve major improvement over the previous state\nof the art by about 4x and 1.5x respectively, approaching human accuracy. In a\nreal classroom, we ran an experiment where we used our system to augment human\ngraders, yielding doubled grading accuracy while halving grading time.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 20:47:22 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 08:39:18 GMT"}, {"version": "v3", "created": "Fri, 25 Sep 2020 05:38:42 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 20:08:08 GMT"}, {"version": "v5", "created": "Tue, 23 Mar 2021 18:07:20 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Malik", "Ali", ""], ["Wu", "Mike", ""], ["Vasavada", "Vrinda", ""], ["Song", "Jinpeng", ""], ["Coots", "Madison", ""], ["Mitchell", "John", ""], ["Goodman", "Noah", ""], ["Piech", "Chris", ""]]}, {"id": "1905.09947", "submitter": "Giorgio Barnabo' Mr.", "authors": "Michael Mathioudakis, Carlos Castillo, Giorgio Barnabo, Sergio Celis", "title": "Affirmative Action Policies for Top-k Candidates Selection, With an\n  Application to the Design of Policies for University Admissions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing affirmative action policies for\nselecting the top-k candidates from a pool of applicants. We assume that for\neach candidate we have socio-demographic attributes and a series of variables\nthat serve as indicators of future performance (e.g., results on standardized\ntests). We further assume that we have access to historical data including the\nactual performance of previously selected candidates. Critically, performance\ninformation is only available for candidates who were selected under some\nprevious selection policy.\n  In this work we assume that due to legal requirements or voluntary\ncommitments, an organization wants to increase the presence of people from\ndisadvantaged socio-demographic groups among the selected candidates. Hence, we\nseek to design an affirmative action or positive action policy. This policy has\ntwo concurrent objectives: (i) to select candidates who, given what can be\nlearnt from historical data, are more likely to perform well, and (ii) to\nselect candidates in a way that increases the representation of disadvantaged\nsocio-demographic groups.\n  Our motivating application is the design of university admission policies to\nbachelor's degrees. We use a causal model as a framework to describe several\nfamilies of policies (changing component weights, giving bonuses, and enacting\nquotas), and compare them both theoretically and through extensive\nexperimentation on a large real-world dataset containing thousands of\nuniversity applicants. Our paper is the first to place the problem of\naffirmative-action policy design within the framework of algorithmic fairness.\nOur empirical results indicate that simple policies could favor the admission\nof disadvantaged groups without significantly compromising on the quality of\naccepted candidates.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:55:09 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 07:52:44 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Mathioudakis", "Michael", ""], ["Castillo", "Carlos", ""], ["Barnabo", "Giorgio", ""], ["Celis", "Sergio", ""]]}, {"id": "1905.10065", "submitter": "Bernadette Spieler", "authors": "Bernadette Spieler and Wolfgang Slany", "title": "A Customised App to Attract Female Teenagers to Coding", "comments": "10 pages, 6 figures, Proceedings of the 2nd International Conference\n  on Gender Research ICGR 2019 Rom, Italy, 11-12 April 2019 isbn:\n  978-1-912764-16-7,issn: 2516-2810, Academic Conferences and Publishing\n  International Limited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The number of women in IT-related disciplines is far below the number of men,\nespecially in developed countries. Middle-school girls appear to be engaged in\ncoding courses, but when they choose academic majors relevant to their future\ncareers, only few pursue computer science as a major. In order to show students\na new way of learning and to engage them with coding activities, we used the\nlearning app Pocket Code. In the \"No One Left Behind\" H2020 European project,\nthe app was evaluated in several school subjects. An evaluation of the\nattractiveness of the app shows that students were motivated by Pocket Code's\nease of use and its appealing design; however, girls rated the app less\nenthusiastically. To appeal to female teenagers in particular, a tailored\nversion of the app \"Luna&Cat\" has been developed. This customised version\nstands in contrast to the \"one size fits all\" solution Pocket Code, which may\ndiscourage certain user groups. For apps to have a higher chance to appeal to a\nspecific target group, it is, among many other points, necessary to optimise\ntheir store listing on app stores, especially as we found that app stores are\nthe most effective way to reach teenagers. Thus, this paper covers the\nfollowing research question. What customizations are necessary in Pocket Code\nto reinforce female teenagers in their coding activities? To answer this\nquestion, a focus group discussion was performed. This discussion first brought\ninsights about our target group and suggested names and designs for the new\napp; and second, allowed each student to make proposals for their desired\ngames. Later, these game ideas were analysed, graphically designed, and further\ndeveloped together with university design students. By showing female teenagers\ngames designed by other young women in their age group, we help them to get\nideas and inspiration to code their own programs.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 07:21:07 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Spieler", "Bernadette", ""], ["Slany", "Wolfgang", ""]]}, {"id": "1905.10361", "submitter": "Claudia Hilderbrand", "authors": "Claudia Hilderbrand, Christopher Perdriau, Lara Letaw, Jillian Emard,\n  Zoe Steine-Hanson, Margaret Burnett, Anita Sarma", "title": "Engineering Gender-Inclusivity into Software: Tales from the Trenches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the need for gender-inclusivity in software itself is gaining\nattention among both SE researchers and SE practitioners, and methods have been\npublished to help, little has been reported on how to make such methods work in\nreal-world settings. For example, how do busy software practitioners use such\nmethods in low-cost ways? How do they endeavor to maximize benefits from using\nthem? How do they avoid the controversies that can arise in talking about\ngender? To find out how teams were handling these and similar questions, we\nturned to 10 real-world software teams. We present these teams experiences \"in\nthe trenches,\" in the form of 12 practices and 3 potential pitfalls, so as to\nprovide their insights to other real-world software teams trying to engineer\ngender-inclusivity into their software products.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 16:13:53 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hilderbrand", "Claudia", ""], ["Perdriau", "Christopher", ""], ["Letaw", "Lara", ""], ["Emard", "Jillian", ""], ["Steine-Hanson", "Zoe", ""], ["Burnett", "Margaret", ""], ["Sarma", "Anita", ""]]}, {"id": "1905.10851", "submitter": "Muthu Kumar Chandrasekaran", "authors": "Muthu Kumar Chandrasekaran and Min-Yen Kan", "title": "When to reply? Context Sensitive Models to Predict Instructor\n  Interventions in MOOC Forums", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to time constraints, course instructors often need to selectively\nparticipate in student discussion threads, due to their limited bandwidth and\nlopsided student--instructor ratio on online forums. We propose the first deep\nlearning models for this binary prediction problem. We propose novel attention\nbased models to infer the amount of latent context necessary to predict\ninstructor intervention. Such models also allow themselves to be tuned to\ninstructor's preference to intervene early or late. Our three proposed\nattentive model variants to infer the latent context improve over the\nstate-of-the-art by a significant, large margin of 11% in F1 and 10% in recall,\non average. Further, introspection of attention help us better understand what\naspects of a discussion post propagate through the discussion thread that\nprompts instructor intervention.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 18:40:06 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Chandrasekaran", "Muthu Kumar", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1905.10868", "submitter": "Sundar Krishnan", "authors": "Sundar Krishnan, Lei Chen", "title": "Legal Concerns and Challenges in Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Legal issues have risen with the changing landscape of computing, especially\nwhen the service, data and infrastructure is not owned by the user. With the\nCloud, the question arises as to who is in the possession of the data. The\nCloud provider can be considered as a legal custodian, owner or possessor of\nthe data thereby causing complexities in legal matters around trademark\ninfringement, privacy of users and their data, abuse and security. By\nintroducing Cloud design focusing on privacy, legal as a service on a Cloud and\nservice provider accountability, users can expect the service providers to be\naccountable for privacy and data in addition to their regular SLAs.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 20:02:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Krishnan", "Sundar", ""], ["Chen", "Lei", ""]]}, {"id": "1905.10891", "submitter": "Bowei Chen", "authors": "Ji Ni and Bowei Chen and Nigel M. Allinson and Xujiong Ye", "title": "A hybrid model for predicting human physical activity status from\n  lifelogging data", "comments": null, "journal-ref": "European Journal of Operational Research, 281(3): 532-542, 2020", "doi": "10.1016/j.ejor.2019.05.035", "report-no": null, "categories": "cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One trend in the recent healthcare transformations is people are encouraged\nto monitor and manage their health based on their daily diets and physical\nactivity habits. However, much attention of the use of operational research and\nanalytical models in healthcare has been paid to the systematic level such as\ncountry or regional policy making or organisational issues. This paper proposes\na model concerned with healthcare analytics at the individual level, which can\npredict human physical activity status from sequential lifelogging data\ncollected from wearable sensors. The model has a two-stage hybrid structure (in\nshort, MOGP-HMM) -- a multi-objective genetic programming (MOGP) algorithm in\nthe first stage to reduce the dimensions of lifelogging data and a hidden\nMarkov model (HMM) in the second stage for activity status prediction over\ntime. It can be used as a decision support tool to provide real-time\nmonitoring, statistical analysis and personalized advice to individuals,\nencouraging positive attitudes towards healthy lifestyles. We validate the\nmodel with the real data collected from a group of participants in the UK, and\ncompare it with other popular two-stage hybrid models. Our experimental results\nshow that the MOGP-HMM can achieve comparable performance. To the best of our\nknowledge, this is the very first study that uses the MOGP in the hybrid\ntwo-stage structure for individuals' activity status prediction. It fits\nseamlessly with the current trend in the UK healthcare transformation of\npatient empowerment as well as contributing to a strategic development for more\nefficient and cost-effective provision of healthcare.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:49:40 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 15:08:24 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Ni", "Ji", ""], ["Chen", "Bowei", ""], ["Allinson", "Nigel M.", ""], ["Ye", "Xujiong", ""]]}, {"id": "1905.10975", "submitter": "Cole Freeman", "authors": "Cole Freeman, Mrinal Kanti Roy, Michele Fattoruso, Hamed Alhoori", "title": "Shared Feelings: Understanding Facebook Reactions to Scholarly Articles", "comments": "4 pages, 5 figures, JCDL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on social-media platforms has tended to rely on textual analysis to\nperform research tasks. While text-based approaches have significantly\nincreased our understanding of online behavior and social dynamics, they\noverlook features on these platforms that have grown in prominence in the past\nfew years: click-based responses to content. In this paper, we present a new\ndataset of Facebook Reactions to scholarly content. We give an overview of its\nstructure, analyze some of the statistical trends in the data, and use it to\ntrain and test two supervised learning algorithms. Our preliminary tests\nsuggest the presence of stratification in the number of users following pages,\ndivisions that seem to fall in line with distinctions in the subject matter of\nthose pages.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 05:00:59 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Freeman", "Cole", ""], ["Roy", "Mrinal Kanti", ""], ["Fattoruso", "Michele", ""], ["Alhoori", "Hamed", ""]]}, {"id": "1905.11082", "submitter": "Zhenan Feng", "authors": "Zhenan Feng, Vicente A. Gonz\\'alez, Robert Amor, Michael Spearpoint,\n  Jared Thomas, Rafael Sacks, Ruggiero Lovreglio, Guillermo Cabrera-Guerrero", "title": "An Immersive Virtual Reality Serious Game to Enhance Earthquake\n  Behavioral Responses and Post-earthquake Evacuation Preparedness in Buildings", "comments": null, "journal-ref": null, "doi": "10.1016/j.aei.2020.101118", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enhancing the earthquake behavioral responses and post-earthquake evacuation\npreparedness of building occupants is beneficial to increasing their chances of\nsurvival and reducing casualties after the main shock of an earthquake.\nTraditionally, training approaches such as seminars, posters, videos or drills\nare applied to enhance preparedness. However, they are not highly engaging and\nhave limited sensory capabilities to mimic life-threatening scenarios for the\npurpose of training potential participants. Immersive Virtual Reality (IVR) and\nSerious Games (SG) as innovative digital technologies can be used to create\ntraining tools to overcome these limitations. In this study, we propose an IVR\nSG-based training system to improve earthquake behavioral responses and\npost-earthquake evacuation preparedness. Auckland City Hospital was chosen as a\ncase study to test our IVR SG training system. A set of learning outcomes based\non best evacuation practice has been identified and embedded into several\ntraining scenarios of the IVR SG. Hospital staff (healthcare and administrative\nprofessionals) and visitors were recruited as participants to be exposed to\nthese training scenarios. Participants' preparedness has been measured along\ntwo dimensions: 1) Knowledge about best evacuation practice; 2) Self-efficacy\nin dealing with earthquake emergencies. Assessment results showed that there\nwas a significant knowledge and self-efficacy increase after the training. And\nparticipants acknowledged that it was easy and engaging to learn best\nevacuation practice knowledge through the IVR SG training system.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 09:44:44 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Feng", "Zhenan", ""], ["Gonz\u00e1lez", "Vicente A.", ""], ["Amor", "Robert", ""], ["Spearpoint", "Michael", ""], ["Thomas", "Jared", ""], ["Sacks", "Rafael", ""], ["Lovreglio", "Ruggiero", ""], ["Cabrera-Guerrero", "Guillermo", ""]]}, {"id": "1905.11110", "submitter": "Zhi-Xuan Tan", "authors": "Zhi-Xuan Tan and Desmond C. Ong", "title": "Bayesian Inference of Social Norms as Shared Constraints on Behavior", "comments": "7 pages, 5 figures, to appear in CogSci 2019, code available at\n  https://github.com/ztangent/norms-cogsci19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People act upon their desires, but often, also act in adherence to implicit\nsocial norms. How do people infer these unstated social norms from others'\nbehavior, especially in novel social contexts? We propose that laypeople have\nintuitive theories of social norms as behavioral constraints shared across\ndifferent agents in the same social context. We formalize inference of norms\nusing a Bayesian Theory of Mind approach, and show that this computational\napproach provides excellent predictions of how people infer norms in two\nscenarios. Our results suggest that people separate the influence of norms and\nindividual desires on others' actions, and have implications for modelling\ngeneralizations of hidden causes of behavior.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 10:33:28 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Tan", "Zhi-Xuan", ""], ["Ong", "Desmond C.", ""]]}, {"id": "1905.11361", "submitter": "Lee Cohen", "authors": "Lee Cohen, Zachary C. Lipton, Yishay Mansour", "title": "Efficient candidate screening under multiple tests and implications for\n  fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When recruiting job candidates, employers rarely observe their underlying\nskill level directly. Instead, they must administer a series of interviews\nand/or collate other noisy signals in order to estimate the worker's skill.\nTraditional economics papers address screening models where employers access\nworker skill via a single noisy signal. In this paper, we extend this\ntheoretical analysis to a multi-test setting, considering both Bernoulli and\nGaussian models. We analyze the optimal employer policy both when the employer\nsets a fixed number of tests per candidate and when the employer can set a\ndynamic policy, assigning further tests adaptively based on results from the\nprevious tests. To start, we characterize the optimal policy when employees\nconstitute a single group, demonstrating some interesting trade-offs.\nSubsequently, we address the multi-group setting, demonstrating that when the\nnoise levels vary across groups, a fundamental impossibility emerges whereby we\ncannot administer the same number of tests, subject candidates to the same\ndecision rule, and yet realize the same outcomes in both groups.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:45:50 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cohen", "Lee", ""], ["Lipton", "Zachary C.", ""], ["Mansour", "Yishay", ""]]}, {"id": "1905.11513", "submitter": "Maulik Kamdar", "authors": "Maulik R. Kamdar, Tymor Hamamsy, Shea Shelton, Ayin Vala, Tome\n  Eftimov, James Zou and Suzanne Tamang", "title": "A Knowledge Graph-based Approach for Exploring the U.S. Opioid Epidemic", "comments": "4 pages, 2 figures, ICLR AI for social good workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The United States is in the midst of an opioid epidemic with recent estimates\nindicating that more than 130 people die every day due to drug overdose. The\nover-prescription and addiction to opioid painkillers, heroin, and synthetic\nopioids, has led to a public health crisis and created a huge social and\neconomic burden. Statistical learning methods that use data from multiple\nclinical centers across the US to detect opioid over-prescribing trends and\npredict possible opioid misuse are required. However, the semantic\nheterogeneity in the representation of clinical data across different centers\nmakes the development and evaluation of such methods difficult and non-trivial.\nWe create the Opioid Drug Knowledge Graph (ODKG) -- a network of opioid-related\ndrugs, active ingredients, formulations, combinations, and brand names. We use\nthe ODKG to normalize drug strings in a clinical data warehouse consisting of\npatient data from over 400 healthcare facilities in 42 different states. We\nshowcase the use of ODKG to generate summary statistics of opioid prescription\ntrends across US regions. These methods and resources can aid the development\nof advanced and scalable models to monitor the opioid epidemic and to detect\nillicit opioid misuse behavior. Our work is relevant to policymakers and pain\nresearchers who wish to systematically assess factors that contribute to opioid\nover-prescribing and iatrogenic opioid addiction in the US.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 21:25:51 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kamdar", "Maulik R.", ""], ["Hamamsy", "Tymor", ""], ["Shelton", "Shea", ""], ["Vala", "Ayin", ""], ["Eftimov", "Tome", ""], ["Zou", "James", ""], ["Tamang", "Suzanne", ""]]}, {"id": "1905.11519", "submitter": "Kush Varshney", "authors": "Kush R. Varshney and Aleksandra Mojsilovic", "title": "Open Platforms for Artificial Intelligence for Social Good: Common\n  Patterns as a Pathway to True Impact", "comments": "appearing at the 2019 ICML AI for Social Good Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AI for social good movement has now reached a state in which a large\nnumber of one-off demonstrations have illustrated that partnerships of AI\npractitioners and social change organizations are possible and can address\nproblems faced in sustainable development. In this paper, we discuss how moving\nfrom demonstrations to true impact on humanity will require a different course\nof action, namely open platforms containing foundational AI capabilities to\nsupport common needs of multiple organizations working in similar topical\nareas. We lend credence to this proposal by describing three example patterns\nof social good problems and their AI-based solutions: natural language\nprocessing for making sense of international development reports, causal\ninference for providing guidance to vulnerable individuals, and\ndiscrimination-aware classification for supporting unbiased allocation\ndecisions. We argue that the development of such platforms will be possible\nthrough convenings of social change organizations, AI companies, and\ngrantmaking foundations.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 21:42:56 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Varshney", "Kush R.", ""], ["Mojsilovic", "Aleksandra", ""]]}, {"id": "1905.11652", "submitter": "Charith Perera", "authors": "Ahmed Hussein, Mahmoud Barhamgi, Massimo Vecchio, Charith Perera", "title": "Crowdsourced Peer Learning Activity for Internet of Things Education: A\n  Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing devices such as laptops, tablets and mobile phones have become part\nof our daily lives. End users increasingly know more and more information about\nthese devices. Further, more technically savvy end users know how such devices\nare being built and know how to choose one over the others. However, we cannot\nsay the same about the Internet of Things (IoT) products. Due to its infancy\nnature of the marketplace, end users have very little idea about IoT products.\nTo address this issue, we developed a method, a crowdsourced peer learning\nactivity, supported by an online platform (OLYMPUS) to enable a group of\nlearners to learn IoT products space better. We conducted two different user\nstudies to validate that our tool enables better IoT education. Our method\nguide learners to think more deeply about IoT products and their design\ndecisions. The learning platform we developed is open source and available for\nthe community.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 07:28:10 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Hussein", "Ahmed", ""], ["Barhamgi", "Mahmoud", ""], ["Vecchio", "Massimo", ""], ["Perera", "Charith", ""]]}, {"id": "1905.11838", "submitter": "Palash Dey", "authors": "Palash Dey, Neeldhara Misra, Swaprava Nath, and Garima Shakya", "title": "A Parameterized Perspective on Protecting Elections", "comments": "To appear in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.CY cs.DS cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the parameterized complexity of the optimal defense and optimal\nattack problems in voting. In both the problems, the input is a set of voter\ngroups (every voter group is a set of votes) and two integers $k_a$ and $k_d$\ncorresponding to respectively the number of voter groups the attacker can\nattack and the number of voter groups the defender can defend. A voter group\ngets removed from the election if it is attacked but not defended. In the\noptimal defense problem, we want to know if it is possible for the defender to\ncommit to a strategy of defending at most $k_d$ voter groups such that, no\nmatter which $k_a$ voter groups the attacker attacks, the outcome of the\nelection does not change. In the optimal attack problem, we want to know if it\nis possible for the attacker to commit to a strategy of attacking $k_a$ voter\ngroups such that, no matter which $k_d$ voter groups the defender defends, the\noutcome of the election is always different from the original (without any\nattack) one.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 14:20:33 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Dey", "Palash", ""], ["Misra", "Neeldhara", ""], ["Nath", "Swaprava", ""], ["Shakya", "Garima", ""]]}, {"id": "1905.11985", "submitter": "David Rozado", "authors": "David Rozado", "title": "Wide range screening of algorithmic bias in word embedding models using\n  large sentiment lexicons reveals underreported bias types", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0231189", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work describes a large-scale analysis of sentiment associations in\npopular word embedding models along the lines of gender and ethnicity but also\nalong the less frequently studied dimensions of socioeconomic status, age,\nsexual orientation, religious sentiment and political leanings. Consistent with\nprevious scholarly literature, this work has found systemic bias against given\nnames popular among African-Americans in most embedding models examined. Gender\nbias in embedding models however appears to be multifaceted and often reversed\nin polarity to what has been regularly reported. Interestingly, using the\ncommon operationalization of the term bias in the fairness literature, novel\ntypes of so far unreported bias types in word embedding models have also been\nidentified. Specifically, the popular embedding models analyzed here display\nnegative biases against middle and working-class socioeconomic status, male\nchildren, senior citizens, plain physical appearance, Islamic religious faith,\nnon-religiosity and conservative political orientation. Reasons for the\nparadoxical underreporting of these bias types in the relevant literature are\nprobably manifold but widely held blind spots when searching for algorithmic\nbias and a lack of widespread technical jargon to unambiguously describe a\nvariety of algorithmic associations could conceivably be playing a role. The\ncausal origins for the multiplicity of loaded associations attached to distinct\ndemographic groups within embedding models are often unclear but the\nheterogeneity of said associations and their potential multifactorial roots\nraises doubts about the validity of grouping them all under the umbrella term\nbias. Richer and more fine-grained terminology as well as a more comprehensive\nexploration of the bias landscape could help the fairness epistemic community\nto characterize and neutralize algorithmic discrimination more efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 06:59:48 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 02:27:11 GMT"}, {"version": "v3", "created": "Fri, 14 Jun 2019 04:29:02 GMT"}, {"version": "v4", "created": "Sun, 15 Dec 2019 09:02:17 GMT"}, {"version": "v5", "created": "Tue, 21 Jan 2020 10:31:00 GMT"}, {"version": "v6", "created": "Sun, 15 Mar 2020 05:42:42 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Rozado", "David", ""]]}, {"id": "1905.12267", "submitter": "Reza Vosooghi", "authors": "Reza Vosooghi (LGI, IRT SystemX), Joseph Kamel (IRT SystemX), Jakob\n  Puchinger (LGI, IRT SystemX), Vincent Leblond (IRT SystemX), Marija Jankovic\n  (LGI)", "title": "Robo-Taxi service fleet sizing: assessing the impact of user trust and\n  willingness-to-use", "comments": "Transportation, Springer Verlag, 2019", "journal-ref": null, "doi": "10.1007/s11116-019-10013-x", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first commercial fleets of Robo-Taxis will be on the road soon. Today\nimportant efforts are made to anticipate future Robo-Taxi services. Fleet size\nis one of the key parameters considered in the planning phase of service design\nand configuration. Based on multi-agent approaches, the fleet size can be\nexplored using dynamic demand response simulations. Time and cost are the most\ncommon variables considered in such simulation approaches. However, personal\ntaste variation can affect the demand and consequently the required fleet size.\nIn this paper, we explore the impact of user trust and willingness-to-use on\nthe Robo-Taxi fleet size. This research is based upon simulating the\ntransportation system of the Rouen-Normandie metropolitan area in France using\nMATSim, a multi-agent activity-based simulator. A local survey is made in order\nto explore the variation of user trust and their willingness-to-use future\nRobo-Taxis according to the sociodemographic attributes. Integrating survey\ndata in the model shows the significant importance of traveler trust and\nwillingness-to-use varying the Robo-Taxi use and the required fleet size.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 08:22:05 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Vosooghi", "Reza", "", "LGI, IRT SystemX"], ["Kamel", "Joseph", "", "IRT SystemX"], ["Puchinger", "Jakob", "", "LGI, IRT SystemX"], ["Leblond", "Vincent", "", "IRT SystemX"], ["Jankovic", "Marija", "", "LGI"]]}, {"id": "1905.12469", "submitter": "Yunpeng Zhao", "authors": "Francois Modave, Yunpeng Zhao, Janice Krieger, Zhe He, Yi Guo, Jinhai\n  Huo, Mattia Prosperi, Jiang Bian", "title": "Understanding Perceptions and Attitudes in Breast Cancer Discussions on\n  Twitter", "comments": "5 pages, 10 figures, The 17th World Congress of Medical and Health\n  Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among American women, the rate of breast cancer is only second to lung\ncancer. An estimated 12.4% women will develop breast cancer over the course of\ntheir lifetime. The widespread use of social media across the socio-economic\nspectrum offers unparalleled ways to facilitate information sharing, in\nparticular as it pertains to health. Social media is also used by many\nhealthcare stakeholders, ranging from government agencies to healthcare\nindustry, to disseminate health information and to engage patients. The purpose\nof this study is to investigate people's perceptions and attitudes relate to\nbreast cancer, especially those that are related to physical activities, on\nTwitter. To achieve this, we first identified and collected tweets related to\nbreast cancer; and then used topic modeling and sentiment analysis techniques\nto understanding discussion themes and quantify Twitter users' perceptions and\nemotions w.r.t breast cancer to answer 5 research questions.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 15:01:03 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Modave", "Francois", ""], ["Zhao", "Yunpeng", ""], ["Krieger", "Janice", ""], ["He", "Zhe", ""], ["Guo", "Yi", ""], ["Huo", "Jinhai", ""], ["Prosperi", "Mattia", ""], ["Bian", "Jiang", ""]]}, {"id": "1905.12470", "submitter": "Shiwei Tong", "authors": "Qi Liu, Shiwei Tong, Chuanren Liu, Hongke Zhao, Enhong Chen, Haiping\n  Ma, Shijin Wang", "title": "Exploiting Cognitive Structure for Adaptive Learning", "comments": "Accepted by KDD 2019 Research Track. In Proceedings of the 25th ACM\n  SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD'19)", "journal-ref": null, "doi": "10.1145/3292500.3330922", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive learning, also known as adaptive teaching, relies on learning path\nrecommendation, which sequentially recommends personalized learning items\n(e.g., lectures, exercises) to satisfy the unique needs of each learner.\nAlthough it is well known that modeling the cognitive structure including\nknowledge level of learners and knowledge structure (e.g., the prerequisite\nrelations) of learning items is important for learning path recommendation,\nexisting methods for adaptive learning often separately focus on either\nknowledge levels of learners or knowledge structure of learning items. To fully\nexploit the multifaceted cognitive structure for learning path recommendation,\nwe propose a Cognitive Structure Enhanced framework for Adaptive Learning,\nnamed CSEAL. By viewing path recommendation as a Markov Decision Process and\napplying an actor-critic algorithm, CSEAL can sequentially identify the right\nlearning items to different learners. Specifically, we first utilize a\nrecurrent neural network to trace the evolving knowledge levels of learners at\neach learning step. Then, we design a navigation algorithm on the knowledge\nstructure to ensure the logicality of learning paths, which reduces the search\nspace in the decision process. Finally, the actor-critic algorithm is used to\ndetermine what to learn next and whose parameters are dynamically updated along\nthe learning path. Extensive experiments on real-world data demonstrate the\neffectiveness and robustness of CSEAL.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 09:23:57 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Liu", "Qi", ""], ["Tong", "Shiwei", ""], ["Liu", "Chuanren", ""], ["Zhao", "Hongke", ""], ["Chen", "Enhong", ""], ["Ma", "Haiping", ""], ["Wang", "Shijin", ""]]}, {"id": "1905.12471", "submitter": "Soaad Hossain Mr", "authors": "Soaad Hossain", "title": "Complexity Analysis of Approaching Clinical Psychiatry with Predictive\n  Analytics and Neural Networks", "comments": "10 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the emerging field of predictive analytics in psychiatry generated and\ncontinues to generate massive interest overtime with its major promises to\npositively change and revolutionize clinical psychiatry, health care and\nmedical professionals are greatly looking forward to its integration and\napplication into psychiatry. However, by directly applying predictive analytics\nto the practice of psychiatry, this could cause detrimental damage to those\nthat use predictive analytics through creating or worsening existing medical\nissues. In both cases, medical ethics issues arise, and need to be addressed.\nThis paper will use literature to provide descriptions of selected stages in\nthe treatment of mental disorders and phases in a predictive analytics project,\napproach mental disorder diagnoses using predictive models that rely on neural\nnetworks, analyze the complexities in clinical psychiatry, neural networks and\npredictive analytics, and conclude with emphasizing and elaborating on\nlimitations and medical ethics issues of applying neural networks and\npredictive analytics to clinical psychiatry.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:03:15 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Hossain", "Soaad", ""]]}, {"id": "1905.12472", "submitter": "Samuel Cris Ayo", "authors": "Samuel Cris Ayo", "title": "Data Breach e-Crime, A Case Study and Legal Analysis", "comments": "for students and educational purposes only", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The Bonafede V. EE data breach is a reported data breach e-Crime in the\nmedia, also published by the BBC on 8th February 2019 in the United Kingdom\nwhich has not yet come to Court. Three laws and regulations of the United\nKingdom that have been breached and references to relevant case laws are\nhighlighted in this paper. Further, Facts of the Case; Issues observed;\nDecision made; Reasonings to the case; Opinions; and Analysis are discussed.\nThe discussions include legal points raised in the case, with the relevant laws\nto draw attention to the keywords or phrases that are in dispute. There are\nsufficient details of the organization for the reader to understand both the\nscale and its activity. Discussions refer to case law in support with the\nreasonings outlined, point by point in numbered paragraphs. At the analysis\nstage, the significance of the case, its relationship to other referenced\ncases, its place in history and the value of the current laws in place are\nevaluated while making references to current law. KEYWORDS: Data breach,\ne-Crime, Cyberlaw, Cybercrime, I.T and Internet law\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:53:47 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ayo", "Samuel Cris", ""]]}, {"id": "1905.12487", "submitter": "Kaylen Pfisterer", "authors": "Kaylen J. Pfisterer, Jennifer Boger, Alexander Wong", "title": "Food for thought: Ethical considerations of user trust in computer\n  vision", "comments": "Accepted to CVPR2019: Fairness Accountability Transparency and Ethics\n  in Computer Vision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision research, especially when novel applications of tools are\ndeveloped, ethical implications around user perceptions of trust in the\nunderlying technology should be considered and supported. Here, we describe an\nexample of the incorporation of such considerations within the long-term care\nsector for tracking resident food and fluid intake. We highlight our recent\nuser study conducted to develop a Goldilocks quality horizontal prototype\ndesigned to support trust cues in which perceived trust in our horizontal\nprototype was higher than the existing system in place. We discuss the\nimportance and need for user engagement as part of ongoing computer\nvision-driven technology development and describe several important factors\nrelated to trust that are relevant to developing decision-making tools.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:25:43 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Pfisterer", "Kaylen J.", ""], ["Boger", "Jennifer", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.12555", "submitter": "Marco Mobilio", "authors": "Anna Ferrari, Daniela Micucci, Marco Mobilio, Paolo Napoletano", "title": "A Platform to Collect, Unify, and Distribute Inertial Labeled Signals\n  for Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition (HAR) is a very active research field. Recently,\ndeep learning techniques are being exploited to recognize human activities from\ninertial signals. However, to compute accurate and reliable deep learning\nmodels, a huge amount of data is required. The goal of our work is the\ndefinition of a platform to support long-term data collection to be used in\ntraining of HAR algorithms. The platform aims to integrate datasets of inertial\nsignals in order to make available to the scientific community a large dataset\nof homogeneous data. The architecture of the platform has been defined and some\nof the main components have been developed in order to verify the soundness of\nthe approach.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 13:02:47 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Ferrari", "Anna", ""], ["Micucci", "Daniela", ""], ["Mobilio", "Marco", ""], ["Napoletano", "Paolo", ""]]}, {"id": "1905.12593", "submitter": "Guillermo Suarez-Tangil", "authors": "Guillermo Suarez-Tangil, Matthew Edwards, Claudia Peersman, Gianluca\n  Stringhini, Awais Rashid, Monica Whitty", "title": "Automatically Dismantling Online Dating Fraud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online romance scams are a prevalent form of mass-marketing fraud in the\nWest, and yet few studies have addressed the technical or data-driven responses\nto this problem. In this type of scam, fraudsters craft fake profiles and\nmanually interact with their victims. Because of the characteristics of this\ntype of fraud and of how dating sites operate, traditional detection methods\n(e.g., those used in spam filtering) are ineffective. In this paper, we present\nthe results of a multi-pronged investigation into the archetype of online\ndating profiles used in this form of fraud, including their use of\ndemographics, profile descriptions, and images, shedding light on both the\nstrategies deployed by scammers to appeal to victims and the traits of victims\nthemselves. Further, in response to the severe financial and psychological harm\ncaused by dating fraud, we develop a system to detect romance scammers on\nonline dating platforms. Our work presents the first system for automatically\ndetecting this fraud. Our aim is to provide an early detection system to stop\nromance scammers as they create fraudulent profiles or before they engage with\npotential victims. Previous research has indicated that the victims of romance\nscams score highly on scales for idealized romantic beliefs. We combine a range\nof structured, unstructured, and deep-learned features that capture these\nbeliefs. No prior work has fully analyzed whether these notions of romance\nintroduce traits that could be leveraged to build a detection system. Our\nensemble machine-learning approach is robust to the omission of profile details\nand performs at high accuracy (97\\%). The system enables development of\nautomated tools for dating site providers and individual users.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:12:44 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 12:26:03 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Suarez-Tangil", "Guillermo", ""], ["Edwards", "Matthew", ""], ["Peersman", "Claudia", ""], ["Stringhini", "Gianluca", ""], ["Rashid", "Awais", ""], ["Whitty", "Monica", ""]]}, {"id": "1905.12616", "submitter": "Rowan Zellers", "authors": "Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali\n  Farhadi, Franziska Roesner, Yejin Choi", "title": "Defending Against Neural Fake News", "comments": "NeurIPS 2019 camera ready version. Project page/code/demo at\n  https://rowanzellers.com/grover", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:58:52 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 21:37:14 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 16:17:17 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Zellers", "Rowan", ""], ["Holtzman", "Ari", ""], ["Rashkin", "Hannah", ""], ["Bisk", "Yonatan", ""], ["Farhadi", "Ali", ""], ["Roesner", "Franziska", ""], ["Choi", "Yejin", ""]]}, {"id": "1905.13005", "submitter": "Jennifer Cobbe Dr", "authors": "Jatinder Singh and Jennifer Cobbe", "title": "The Security Implications of Data Subject Rights", "comments": null, "journal-ref": null, "doi": "10.1109/MSEC.2019.2914614", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data protection regulations give individuals rights to obtain the information\nthat entities have on them. However, providing such information can also reveal\naspects of the underlying technical infrastructure and organisational\nprocesses. This article explores the security implications this raises, and\nhighlights the need to consider such in rights fulfillment processes.\n  To appear in IEEE Security & Privacy\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 12:48:44 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Singh", "Jatinder", ""], ["Cobbe", "Jennifer", ""]]}, {"id": "1905.13178", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Bret Greenstein, Babak Hodjat, Jerry Smith", "title": "Better Future through AI: Avoiding Pitfalls and Guiding AI Towards its\n  Full Potential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) technology is rapidly changing many areas of\nsociety. While there is tremendous potential in this transition, there are\nseveral pitfalls as well. Using the history of computing and the world-wide web\nas a guide, in this article we identify those pitfalls and actions that lead AI\ndevelopment to its full potential. If done right, AI will be instrumental in\nachieving the goals we set for economy, society, and the world in general.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:06:11 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Greenstein", "Bret", ""], ["Hodjat", "Babak", ""], ["Smith", "Jerry", ""]]}, {"id": "1905.13364", "submitter": "Bo Wang", "authors": "Bo Wang, Baixiang Xue, Anthony G. Greenwald", "title": "Can We Derive Explicit and Implicit Bias from Corpus?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language is a popular resource to mine speakers' attitude bias, supposing\nthat speakers' statements represent their bias on concepts. However, psychology\nstudies show that people's explicit bias in statements can be different from\ntheir implicit bias in mind. Although both explicit and implicit bias are\nuseful for different applications, current automatic techniques do not\ndistinguish them. Inspired by psychological measurements of explicit and\nimplicit bias, we develop an automatic language-based technique to reproduce\npsychological measurements on large population. By connecting each\npsychological measurement with the statements containing the certain\ncombination of special words, we derive explicit and implicit bias by\nunderstanding the sentiment of corresponding category of statements. Extensive\nexperiments on English and Chinese serious media (Wikipedia) and non-serious\nmedia (social media) show that our method successfully reproduce the\nsmall-scale psychological observations on large population and achieve new\nfindings.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 00:36:21 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Wang", "Bo", ""], ["Xue", "Baixiang", ""], ["Greenwald", "Anthony G.", ""]]}]