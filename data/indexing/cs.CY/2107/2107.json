[{"id": "2107.00349", "submitter": "Vjosa Preniqi", "authors": "Vjosa Preniqi, Kyriaki Kalimeri, Charalampos Saitis", "title": "Modelling Moral Traits with Music Listening Preferences and Demographics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music is an essential component in our everyday lives and experiences, as it\nis a way that we use to express our feelings, emotions and cultures. In this\nstudy, we explore the association between music genre preferences, demographics\nand moral values by exploring self-reported data from an online survey\nadministered in Canada. Participants filled in the moral foundations\nquestionnaire, while they also provided their basic demographic information,\nand music preferences. Here, we predict the moral values of the participants\ninferring on their musical preferences employing classification and regression\ntechniques. We also explored the predictive power of features estimated from\nfactor analysis on the music genres, as well as the generalist/specialist (GS)\nscore for revealing the diversity of musical choices for each user. Our results\nshow the importance of music in predicting a person's moral values (.55-.69\nAUROC); while knowledge of basic demographic features such as age and gender is\nenough to increase the performance (.58-.71 AUROC).\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:26:29 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Preniqi", "Vjosa", ""], ["Kalimeri", "Kyriaki", ""], ["Saitis", "Charalampos", ""]]}, {"id": "2107.00441", "submitter": "Liu Leqi", "authors": "Liu Leqi, Dylan Hadfield-Menell, Zachary C. Lipton", "title": "When Curation Becomes Creation: Algorithms, Microcontent, and the\n  Vanishing Distinction between Platforms and Creators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever since social activity on the Internet began migrating from the wilds of\nthe open web to the walled gardens erected by so-called platforms, debates have\nraged about the responsibilities that these platforms ought to bear. And yet,\ndespite intense scrutiny from the news media and grassroots movements of\noutraged users, platforms continue to operate, from a legal standpoint, on the\nfriendliest terms. Under the current regulatory framework, platforms\nsimultaneously benefit from: (1) broad discretion to organize (and censor)\ncontent however they choose; (2) powerful algorithms for curating a practically\nlimitless supply of user-posted microcontent according to whatever ends they\nwish; and (3) absolution from the sorts of liability born by creators of the\nunderlying content. In this paper, we contest the very validity of the\nplatform-creator distinction, arguing that it is ill-adapted to the modern\nsocial media landscape where, in a real sense, platforms are creating\nderivative media products. We argue that any coherent regulatory framework must\nadapt to this reality, recognizing the subtle continuum of activities that span\nthe curation-creation spectrum, providing a finer system of categorization and\nclearer guidance for precisely when platforms assume the responsibilities\nassociated with content creation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 13:37:05 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Leqi", "Liu", ""], ["Hadfield-Menell", "Dylan", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2107.00531", "submitter": "Chimdimma Noelyn Onah", "authors": "Chimdimma Noelyn Onah, Richard Allmendinger, Julia Handl, Ken W. Dunn", "title": "Towards a fairer reimbursement system for burn patients using\n  cost-sensitive classification", "comments": "Joint KDD 2021 Health Day and 2021 KDD Workshop on Applied Data\n  Science for Healthcare: State of XAI and trustworthiness in Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The adoption of the Prospective Payment System (PPS) in the UK National\nHealth Service (NHS) has led to the creation of patient groups called Health\nResource Groups (HRG). HRGs aim to identify groups of clinically similar\npatients that share similar resource usage for reimbursement purposes. These\ngroups are predominantly identified based on expert advice, with homogeneity\nchecked using the length of stay (LOS). However, for complex patients such as\nthose encountered in burn care, LOS is not a perfect proxy of resource usage,\nleading to incomplete homogeneity checks. To improve homogeneity in resource\nusage and severity, we propose a data-driven model and the inclusion of\npatient-level costing. We investigate whether a data-driven approach that\nconsiders additional measures of resource usage can lead to a more\ncomprehensive model. In particular, a cost-sensitive decision tree model is\nadopted to identify features of importance and rules that allow for a focused\nsegmentation on resource usage (LOS and patient-level cost) and clinical\nsimilarity (severity of burn). The proposed approach identified groups with\nincreased homogeneity compared to the current HRG groups, allowing for a more\nequitable reimbursement of hospital care costs if adopted.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 15:23:21 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Onah", "Chimdimma Noelyn", ""], ["Allmendinger", "Richard", ""], ["Handl", "Julia", ""], ["Dunn", "Ken W.", ""]]}, {"id": "2107.00593", "submitter": "Lucius Bynum", "authors": "Lucius E.J. Bynum, Joshua R. Loftus, Julia Stoyanovich", "title": "Impact Remediation: Optimal Interventions to Reduce Inequality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A significant body of research in the data sciences considers unfair\ndiscrimination against social categories such as race or gender that could\noccur or be amplified as a result of algorithmic decisions. Simultaneously,\nreal-world disparities continue to exist, even before algorithmic decisions are\nmade. In this work, we draw on insights from the social sciences and humanistic\nstudies brought into the realm of causal modeling and constrained optimization,\nand develop a novel algorithmic framework for tackling pre-existing real-world\ndisparities. The purpose of our framework, which we call the \"impact\nremediation framework,\" is to measure real-world disparities and discover the\noptimal intervention policies that could help improve equity or access to\nopportunity for those who are underserved with respect to an outcome of\ninterest. We develop a disaggregated approach to tackling pre-existing\ndisparities that relaxes the typical set of assumptions required for the use of\nsocial categories in structural causal models. Our approach flexibly\nincorporates counterfactuals and is compatible with various ontological\nassumptions about the nature of social categories. We demonstrate impact\nremediation with a real-world case study and compare our disaggregated approach\nto an existing state-of-the-art approach, comparing its structure and resulting\npolicy recommendations. In contrast to most work on optimal policy learning, we\nexplore disparity reduction itself as an objective, explicitly focusing the\npower of algorithms on reducing inequality.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:35:12 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Bynum", "Lucius E. J.", ""], ["Loftus", "Joshua R.", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "2107.00746", "submitter": "Amith Khandakar Mr.", "authors": "Amith Khandakar, Muhammad E. H. Chowdhury, Md. Saifuddin Khalid, Nizar\n  Zorba", "title": "Case study of Innovative Teaching Practices and their Impact for\n  Electrical Engineering Courses during COVID-19 Pandemic", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the COVID-19 pandemic, there was an urgent need to move to online\nteaching and develop innovations to guarantee the Student Learning Outcomes\n(SLOs) are being fulfilled. The contributions of this paper are two-fold: the\neffects of an experimented teaching strategy, i.e. multi-course project-based\nlearning (MPL) approach, are presented followed with online assessment\ntechniques investigation for senior level electrical engineering (EE) courses\nat Qatar University. The course project of the senior course was designed in\nsuch a way that it helps in simultaneously attaining the objectives of the\nsenior and capstone courses, that the students were taking at the same time. It\nis known that the MPL approach enhances the critical thinking capacity of\nstudents which is also a major outcome of Education for Sustainable Development\n(ESD). The developed project ensures the fulfillment of a series of SLOs, that\nare concentrated on soft engineering and project management skills. The\ndifficulties of adopting the MPL method for the senior level courses are in\naligning the project towards fulfilling the learning outcomes of every\nindividual course. The study also provides the students feedback on online\nassessment techniques incorporated with the MPL, due to online teaching during\nCOVID-19 pandemic. In order to provide a benchmark and to highlight the\nobtained results, the innovative teaching approaches were compared to\nconventional methods taught on the same senior course in a previous semester.\nBased on the feedback from teachers and students from previously conducted case\nstudy it was believed that the MPL approach would support the students. With\nthe statistical analysis (Chi-square, two-tailed T statistics and hypothesis\ntesting using z-test) it can be concluded that the MPL and online assessment\nactually help to achieve better attainment of the SLOs, even during a pandemic\nsituation.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:10:27 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Khandakar", "Amith", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Khalid", "Md. Saifuddin", ""], ["Zorba", "Nizar", ""]]}, {"id": "2107.00862", "submitter": "Yuanbang Li", "authors": "Yuanbang Li", "title": "User Role Discovery and Optimization Method based on K-means +\n  Reinforcement learning in Mobile Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the widespread use of mobile phones, users can share their location and\nactivity anytime, anywhere, as a form of check in data. These data reflect user\nfeatures. Long term stable, and a set of user shared features can be abstracted\nas user roles. The role is closely related to the user's social background,\noccupation, and living habits. This study provides four main contributions.\nFirstly, user feature models from different views for each user are constructed\nfrom the analysis of check in data. Secondly, K Means algorithm is used to\ndiscover user roles from user features. Thirdly, a reinforcement learning\nalgorithm is proposed to strengthen the clustering effect of user roles and\nimprove the stability of the clustering result. Finally, experiments are used\nto verify the validity of the method, the results of which show the\neffectiveness of the method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 06:40:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Li", "Yuanbang", ""]]}, {"id": "2107.00938", "submitter": "Mathias-Felipe De-Lima-Santos", "authors": "Mathias-Felipe de-Lima-Santos and Arwa Kooli", "title": "Instagrammable Data: Using Visuals to Showcase More Than Numbers on AJ\n  Labs Instagram Page", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB cs.GR cs.MM cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  News outlets are developing formats dedicated to social platforms that\ncapture audience attention, such as Instagram stories, Facebook Instant\narticles, and YouTube videos. In some cases, these formats are created in\ncollaboration with the tech companies themselves. At the same time, the use of\ndata-driven storytelling is becoming increasingly integrated into the\never-complex business models of news outlets, generating more impact and\nvisibility. Previous studies have focused on studying these two effects\nseparately. To address this gap in the literature, this paper identifies and\nanalyzes the use of data journalism on the Instagram content of AJ Labs, the\nteam dedicated to producing data-driven and interactive stories for the Al\nJazeera news network. Drawing upon a mixed-method approach, this study examines\nthe use and characteristics of data stories on social media platforms. Results\nsuggest that there is reliance on producing visual content that covers topics\nsuch as politics and violence. In general, AJ Labs relies on the use of\ninfographics and produces its own unique data. To conclude, this paper suggests\npotential ways to improve the use of Instagram to tell data stories.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 09:51:49 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["de-Lima-Santos", "Mathias-Felipe", ""], ["Kooli", "Arwa", ""]]}, {"id": "2107.00948", "submitter": "Haoyi Xiong", "authors": "Zhiyuan Wang, Haoyi Xiong, Jie Zhang, Sijia Yang, Mehdi Boukhechba,\n  Laura E. Barnes, Daqing Zhang", "title": "From Personalized Medicine to Population Health: A Survey of mHealth\n  Sensing Techniques", "comments": "Submitted to a journal for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile Sensing Apps have been widely used as a practical approach to collect\nbehavioral and health-related information from individuals and provide timely\nintervention to promote health and well-beings, such as mental health and\nchronic cares. As the objectives of mobile sensing could be either \\emph{(a)\npersonalized medicine for individuals} or \\emph{(b) public health for\npopulations}, in this work we review the design of these mobile sensing apps,\nand propose to categorize the design of these apps/systems in two paradigms --\n\\emph{(i) Personal Sensing} and \\emph{(ii) Crowd Sensing} paradigms. While both\nsensing paradigms might incorporate with common ubiquitous sensing\ntechnologies, such as wearable sensors, mobility monitoring, mobile data\noffloading, and/or cloud-based data analytics to collect and process sensing\ndata from individuals, we present a novel taxonomy system with two major\ncomponents that can specify and classify apps/systems from aspects of the\nlife-cycle of mHealth Sensing: \\emph{(1) Sensing Task Creation \\&\nParticipation}, \\emph{(2) Health Surveillance \\& Data Collection}, and\n\\emph{(3) Data Analysis \\& Knowledge Discovery}. With respect to different\ngoals of the two paradigms, this work systematically reviews this field, and\nsummarizes the design of typical apps/systems in the view of the configurations\nand interactions between these two components. In addition to summarization,\nthe proposed taxonomy system also helps figure out the potential directions of\nmobile sensing for health from both personalized medicines and population\nhealth perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 10:16:21 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Wang", "Zhiyuan", ""], ["Xiong", "Haoyi", ""], ["Zhang", "Jie", ""], ["Yang", "Sijia", ""], ["Boukhechba", "Mehdi", ""], ["Barnes", "Laura E.", ""], ["Zhang", "Daqing", ""]]}, {"id": "2107.01302", "submitter": "Stefan Andjelkovic", "authors": "Stefan Andjelkovic and Natasa Miskov-Zivanov", "title": "DiSH-trend: Intervention Modeling Simulator That Accounts for Trend\n  Influences", "comments": "12 pages, 5 figures, to be published in Proceedings of the 2021\n  Winter Simulation Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation on directed graphs is an important method for understanding the\ndynamics in the systems where connectivity graphs contain cycles. Discrete\nStochastic Heterogeneous Simulator (DiSH) is one of the simulation tools with\nwide application, which uses regulator values to calculate state updates of\nregulated elements. Here we present a new simulation approach DiSH-trend which\nalso takes into account the trends in regulating elements. We demonstrate the\nfeatures of trend-based regulation, as well as hybrid regulation, which is a\ncombination of the trend- and level-based approaches. The modeling capabilities\nare demonstrated on a small toy model, showcasing different functionalities.\nReal-world capabilities are demonstrated on a larger network model of food\ninsecurity in the Ethiopian region Oromia. Adding trend-based regulation to\nmodels results in increased modeling flexibility, and hybrid regulation\nimproves qualitative dynamic behavior prediction. With appropriate data,\nDiSH-trend becomes a powerful tool for exploring intervention strategies.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 23:34:41 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Andjelkovic", "Stefan", ""], ["Miskov-Zivanov", "Natasa", ""]]}, {"id": "2107.01325", "submitter": "Connor Lawless", "authors": "Connor Lawless, Oktay Gunluk", "title": "Fair Decision Rules for Binary Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning has begun automating decision making in\nfields as varied as college admissions, credit lending, and criminal\nsentencing. The socially sensitive nature of some of these applications\ntogether with increasing regulatory constraints has necessitated the need for\nalgorithms that are both fair and interpretable. In this paper we consider the\nproblem of building Boolean rule sets in disjunctive normal form (DNF), an\ninterpretable model for binary classification, subject to fairness constraints.\nWe formulate the problem as an integer program that maximizes classification\naccuracy with explicit constraints on two different measures of classification\nparity: equality of opportunity and equalized odds. Column generation\nframework, with a novel formulation, is used to efficiently search over\nexponentially many possible rules. When combined with faster heuristics, our\nmethod can deal with large data-sets. Compared to other fair and interpretable\nclassifiers, our method is able to find rule sets that meet stricter notions of\nfairness with a modest trade-off in accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:32:17 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Lawless", "Connor", ""], ["Gunluk", "Oktay", ""]]}, {"id": "2107.01385", "submitter": "Feng Li", "authors": "Feng Li, Jichao Zhao, Dongxiao Yu, Xiuzhen Cheng, Weifeng Lv", "title": "Harnessing Context for Budget-Limited Crowdsensing with Massive\n  Uncertain Workers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsensing is an emerging paradigm of ubiquitous sensing, through which a\ncrowd of workers are recruited to perform sensing tasks collaboratively.\nAlthough it has stimulated many applications, an open fundamental problem is\nhow to select among a massive number of workers to perform a given sensing task\nunder a limited budget. Nevertheless, due to the proliferation of smart devices\nequipped with various sensors, it is very difficult to profile the workers in\nterms of sensing ability. Although the uncertainties of the workers can be\naddressed by standard Combinatorial Multi-Armed Bandit (CMAB) framework through\na trade-off between exploration and exploitation, we do not have sufficient\nallowance to directly explore and exploit the workers under the limited budget.\nFurthermore, since the sensor devices usually have quite limited resources, the\nworkers may have bounded capabilities to perform the sensing task for only few\ntimes, which further restricts our opportunities to learn the uncertainty. To\naddress the above issues, we propose a Context-Aware Worker Selection (CAWS)\nalgorithm in this paper. By leveraging the correlation between the context\ninformation of the workers and their sensing abilities, CAWS aims at maximizing\nthe expected total sensing revenue efficiently with both budget constraint and\ncapacity constraints respected, even when the number of the uncertain workers\nare massive. The efficacy of CAWS can be verified by rigorous theoretical\nanalysis and extensive experiments.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:09:07 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Feng", ""], ["Zhao", "Jichao", ""], ["Yu", "Dongxiao", ""], ["Cheng", "Xiuzhen", ""], ["Lv", "Weifeng", ""]]}, {"id": "2107.01624", "submitter": "Andreas Schreiber", "authors": "Aur\\'elie Breidenbach and Caroline Mahlow and Andreas Schreiber", "title": "Implicit Gender Bias in Computer Science -- A Qualitative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gender diversity in the tech sector is - not yet? - sufficient to create a\nbalanced ratio of men and women. For many women, access to computer science is\nhampered by socialization-related, social, cultural and structural obstacles.\nThe so-called implicit gender bias has a great influence in this respect. The\nlack of contact in areas of computer science makes it difficult to develop or\nexpand potential interests. Female role models as well as more transparency of\nthe job description should help women to promote their - possible - interest in\nthe job description. However, gender diversity can also be promoted and\nfostered through adapted measures by leaders.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 13:30:26 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Breidenbach", "Aur\u00e9lie", ""], ["Mahlow", "Caroline", ""], ["Schreiber", "Andreas", ""]]}, {"id": "2107.01662", "submitter": "Matthias St\\\"urmer", "authors": "Matthias St\\\"urmer, Jasmin Nussbaumer, Pascal St\\\"ockli", "title": "Security implications of digitalization: The dangers of data colonialism\n  and the way towards sustainable and sovereign management of environmental\n  data", "comments": "This study was prepared under contract to the Federal Department of\n  Foreign Affairs (FDFA). The authors bear responsibility for the content", "journal-ref": null, "doi": "10.13140/RG.2.2.24791.80807", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digitalization opens up new opportunities in the collection, analysis, and\npresentation of data which can contribute to the achievement of the 2030 Agenda\nand its Sustainable Development Goals (SDGs). In particular, the access to and\ncontrol of environmental and geospatial data is fundamental to identify and\nunderstand global issues and trends. Also immediate crises such as the COVID-19\npandemic demonstrate the importance of accurate health data such as infection\nstatistics and the relevance of digital tools like video conferencing\nplatforms. However, today much of the data is collected and processed by\nprivate actors. Thus, governments and researchers depend on data platforms and\nproprietary systems of big tech companies such as Google or Microsoft. The\nmarket capitalization of the seven largest US and Chinese big tech companies\nhas grown to 8.7tn USD in recent years, about twice the size of Germany's gross\ndomestic product (GDP). Therefore, their market power is enormous, allowing\nthem to dictate many rules of the digital space and even interfere with\nlegislations. Based on a literature review and nine expert interviews this\nstudy presents a framework that identifies the risks and consequences along the\nworkflow of collecting, processing, storing, using of data. It also includes\nsolutions that governmental and multilateral actors can strive for to alleviate\nthe risks. Fundamental to this framework is the novel concept of \"data\ncolonialism\" which describes today's trend of private companies appropriating\nthe digital sphere. Historically, colonial nations used to grab indigenous land\nand exploit the cheap labor of slave workers. In a similar way, today's big\ntech corporations use cheap data of their users to produce valuable services\nand thus create enormous market power.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 15:31:42 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["St\u00fcrmer", "Matthias", ""], ["Nussbaumer", "Jasmin", ""], ["St\u00f6ckli", "Pascal", ""]]}, {"id": "2107.01674", "submitter": "Changjie Chen", "authors": "Changjie Chen, Jasmeet Judge, David Hulse", "title": "PyLUSAT: An open-source Python toolkit for GIS-based land use\n  suitability analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Desktop GIS applications, such as ArcGIS and QGIS, provide tools essential\nfor conducting suitability analysis, an activity that is central in formulating\na land-use plan. But, when it comes to building complicated land-use\nsuitability models, these applications have several limitations, including\noperating system-dependence, lack of dedicated modules, insufficient\nreproducibility, and difficult, if not impossible, deployment on a computing\ncluster. To address the challenges, this paper introduces PyLUSAT: Python for\nLand Use Suitability Analysis Tools. PyLUSAT is an open-source software package\nthat provides a series of tools (functions) to conduct various tasks in a\nsuitability modeling workflow. These tools were evaluated against comparable\ntools in ArcMap 10.4 with respect to both accuracy and computational\nefficiency. Results showed that PyLUSAT functions were two to ten times more\nefficient depending on the job's complexity, while generating outputs with\nsimilar accuracy compared to the ArcMap tools. PyLUSAT also features\nextensibility and cross-platform compatibility. It has been used to develop\nfourteen QGIS Processing Algorithms and implemented on a high-performance\ncomputational cluster (HiPerGator at the University of Florida) to expedite the\nprocess of suitability analysis. All these properties make PyLUSAT a\ncompetitive alternative solution for urban planners/researchers to customize\nand automate suitability analysis as well as integrate the technique into a\nlarger analytical framework.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 16:19:16 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chen", "Changjie", ""], ["Judge", "Jasmeet", ""], ["Hulse", "David", ""]]}, {"id": "2107.01984", "submitter": "Jeffrey Carver", "authors": "Sarah Heckman and Jeffrey C. Carver and Mark Sherriff and Ahmed\n  Al-Zubidy", "title": "A Systematic Literature Review of Empiricism and Norms of Reporting in\n  Computing Education Research Literature", "comments": "Paper to appear in ACM Transactions on Computing Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computing Education Research (CER) is critical for supporting the increasing\nnumber of students who need to learn computing skills. To systematically\nadvance knowledge, publications must be clear enough to support replications,\nmeta-analyses, and theory-building. The goal of this study is to characterize\nthe reporting of empiricism in CER literature by identifying whether\npublications include information to support replications, meta-analyses, and\ntheory building. The research questions are: RQ1) What percentage of papers in\nCER venues have empirical evaluation? RQ2) What are the characteristics of the\nempirical evaluation? RQ3) Do the papers with empirical evaluation follow\nreporting norms (both for inclusion and for labeling of key information)? We\nconducted an SLR of 427 papers published during 2014 and 2015 in five CER\nvenues: SIGCSE TS, ICER, ITiCSE, TOCE, and CSE. We developed and applied the\nCER Empiricism Assessment Rubric. Over 80% of papers had some form of empirical\nevaluation. Quantitative evaluation methods were the most frequent. Papers most\nfrequently reported results on interventions around pedagogical techniques,\ncurriculum, community, or tools. There was a split in papers that had some type\nof comparison between an intervention and some other data set or baseline. Many\npapers lacked properly reported research objectives, goals, research questions,\nor hypotheses, description of participants, study design, data collection, and\nthreats to validity. CER authors are contributing empirical results to the\nliterature; however, not all norms for reporting are met. We encourage authors\nto provide clear, labeled details about their work so readers can use the\nmethodologies and results for replications and meta-analyses. As our community\ngrows, our reporting of CER should mature to help establish computing education\ntheory to support the next generation of computing learners.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 16:37:29 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Heckman", "Sarah", ""], ["Carver", "Jeffrey C.", ""], ["Sherriff", "Mark", ""], ["Al-Zubidy", "Ahmed", ""]]}, {"id": "2107.02043", "submitter": "Hongping Zhang", "authors": "Hongping Zhang, Zhenfeng Shao, Jinqi Zhao, Xiao Huang, Jie Yang, Bin\n  Hu and Wenfu Wu", "title": "An extended watershed-based zonal statistical AHP model for flood risk\n  estimation: Constraining runoff converging related indicators by\n  sub-watersheds", "comments": "This paper is a research paper, it contains 40 pages and 8 figures.\n  This paper is a modest contribution to the ongoing discussions the accuracy\n  of flood risk estimation via AHP model improved by adopting pixels replaced\n  with sub-watersheds as basic unit", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Floods are highly uncertain events, occurring in different regions, with\nvarying prerequisites and intensities. A highly reliable flood disaster risk\nmap can help reduce the impact of floods for flood management, disaster\ndecreasing, and urbanization resilience. In flood risk estimation, the widely\nused analytic hierarchy process (AHP) usually adopts pixel as a basic unit, it\ncannot capture the similar threaten caused by neighborhood source flooding\ncells at sub-watershed scale. Thus, an extended watershed-based zonal\nstatistical AHP model constraining runoff converging related indicators by\nsub-watersheds (WZSAHP-Slope & Stream) is proposed to fill this gap. Taking the\nChaohu basin as test case, we validated the proposed method with a real-flood\narea extracted in July 2020. The results indicate that the WZSAHP-Slope &\nStream model using multiple flow direction division watersheds to calculate\nstatistics of distance from stream and slope by maximum statistic method\noutperformed other tested methods. Compering with pixel-based AHP method, the\nproposed method can improve the correct ratio by 16% (from 67% to 83%) and fit\nratio by 1% (from 13% to 14%) as in validation 1, and improve the correct ratio\nby 37% (from 23% to 60%) and fit ratio by 6% (from 12% to 18%) as in validation\n2.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 14:04:32 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhang", "Hongping", ""], ["Shao", "Zhenfeng", ""], ["Zhao", "Jinqi", ""], ["Huang", "Xiao", ""], ["Yang", "Jie", ""], ["Hu", "Bin", ""], ["Wu", "Wenfu", ""]]}, {"id": "2107.02185", "submitter": "Michael Szell", "authors": "Michael Szell, Sayat Mimar, Tyler Perlman, Gourab Ghoshal, Roberta\n  Sinatra", "title": "Growing Urban Bicycle Networks", "comments": "Main text: 12 pages, 7 figures, SI: 14 pages, 9 figures. Website:\n  http://growbike.net", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cycling is a promising solution to unsustainable car-centric urban transport\nsystems. However, prevailing bicycle network development follows a slow and\npiecewise process, without taking into account the structural complexity of\ntransportation networks. Here we explore systematically the topological\nlimitations of urban bicycle network development. For 62 cities we study\ndifferent variations of growing a synthetic bicycle network between an\narbitrary set of points routed on the urban street network. We find initially\ndecreasing returns on investment until a critical threshold, posing fundamental\nconsequences to sustainable urban planning: Cities must invest into bicycle\nnetworks with the right growth strategy, and persistently, to surpass a\ncritical mass. We also find pronounced overlaps of synthetically grown networks\nin cities with well-developed existing bicycle networks, showing that our model\nreflects reality. Growing networks from scratch makes our approach a generally\napplicable starting point for sustainable urban bicycle network planning with\nminimal data requirements.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:00:04 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 08:43:11 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Szell", "Michael", ""], ["Mimar", "Sayat", ""], ["Perlman", "Tyler", ""], ["Ghoshal", "Gourab", ""], ["Sinatra", "Roberta", ""]]}, {"id": "2107.02278", "submitter": "R.Stuart Geiger", "authors": "R. Stuart Geiger, Dominique Cope, Jamie Ip, Marsha Lotosh, Aayush\n  Shah, Jenny Weng, Rebekah Tang", "title": "\"Garbage In, Garbage Out\" Revisited: What Do Machine Learning\n  Application Papers Report About Human-Labeled Training Data?", "comments": null, "journal-ref": "Quantitative Science Studies 2:2 (2021)", "doi": "10.1162/qss_a_00144", "report-no": null, "categories": "cs.LG cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised machine learning, in which models are automatically derived from\nlabeled training data, is only as good as the quality of that data. This study\nbuilds on prior work that investigated to what extent 'best practices' around\nlabeling training data were followed in applied ML publications within a single\ndomain (social media platforms). In this paper, we expand by studying\npublications that apply supervised ML in a far broader spectrum of disciplines,\nfocusing on human-labeled data. We report to what extent a random sample of ML\napplication papers across disciplines give specific details about whether best\npractices were followed, while acknowledging that a greater range of\napplication fields necessarily produces greater diversity of labeling and\nannotation methods. Because much of machine learning research and education\nonly focuses on what is done once a \"ground truth\" or \"gold standard\" of\ntraining data is available, it is especially relevant to discuss issues around\nthe equally-important aspect of whether such data is reliable in the first\nplace. This determination becomes increasingly complex when applied to a\nvariety of specialized fields, as labeling can range from a task requiring\nlittle-to-no background knowledge to one that must be performed by someone with\ncareer expertise.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 21:24:02 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Geiger", "R. Stuart", ""], ["Cope", "Dominique", ""], ["Ip", "Jamie", ""], ["Lotosh", "Marsha", ""], ["Shah", "Aayush", ""], ["Weng", "Jenny", ""], ["Tang", "Rebekah", ""]]}, {"id": "2107.02472", "submitter": "Marco Guerini", "authors": "Yi-Ling Chung, Serra Sinem Tekiroglu, Sara Tonelli, Marco Guerini", "title": "Empowering NGOs in Countering Online Hate Messages", "comments": "Preprint of the paper published in Online Social Networks and Media\n  Journal (OSNEM)", "journal-ref": null, "doi": "10.1016/j.osnem.2021.100150", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on online hate speech have mostly focused on the automated detection\nof harmful messages. Little attention has been devoted so far to the\ndevelopment of effective strategies to fight hate speech, in particular through\nthe creation of counter-messages. While existing manual scrutiny and\nintervention strategies are time-consuming and not scalable, advances in\nnatural language processing have the potential to provide a systematic approach\nto hatred management. In this paper, we introduce a novel ICT platform that NGO\noperators can use to monitor and analyze social media data, along with a\ncounter-narrative suggestion tool. Our platform aims at increasing the\nefficiency and effectiveness of operators' activities against islamophobia. We\ntest the platform with more than one hundred NGO operators in three countries\nthrough qualitative and quantitative evaluation. Results show that NGOs favor\nthe platform solution with the suggestion tool, and that the time required to\nproduce counter-narratives significantly decreases.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:36:24 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Chung", "Yi-Ling", ""], ["Tekiroglu", "Serra Sinem", ""], ["Tonelli", "Sara", ""], ["Guerini", "Marco", ""]]}, {"id": "2107.02480", "submitter": "Anna Guitart Atienza", "authors": "Anna Guitart, Ana Fern\\'andez del R\\'io and \\'Africa Peri\\'a\\~nez", "title": "Midwifery Learning and Forecasting: Predicting Content Demand with\n  User-Generated Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Every day, 800 women and 6,700 newborns die from complications related to\npregnancy or childbirth. A well-trained midwife can prevent most of these\nmaternal and newborn deaths. Data science models together with logs generated\nby users of online learning applications for midwives can help to improve their\nlearning competencies. The goal is to use these rich behavioral data to push\ndigital learning towards personalized content and to provide an adaptive\nlearning journey. In this work, we evaluate various forecasting methods to\ndetermine the interest of future users on the different kind of contents\navailable in the app, broken down by profession and region.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 08:48:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Guitart", "Anna", ""], ["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "2107.02588", "submitter": "Derek Weber", "authors": "Derek Weber and Lucia Falzon", "title": "Temporal Nuances of Coordination Networks", "comments": "4 pages, 7 figures, 1 table, short paper submission to the 2021\n  IEEE/ACM International Conference on Advances in Social Networks Analysis and\n  Mining (ASONAM'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current network-based methods for detecting coordinated inauthentic behaviour\non social media focus primarily on inferring links between accounts based on\n\"behavioural traces\" [1], such as retweeting the same tweet or posting the same\nURL. Assuming the goal of coordination is amplification, i.e., boosting a\nmessage within a constrained period, most approaches use a temporal window to\nensure the co-activity occurs within a specific timeframe [1]-[4]. These\nmethods could all exploit temporal elements of coordinated activity. We\ndescribe preliminary research regarding coordination network semantics,\ncoordination network construction, relevant observations in three political\nTwitter datasets and the role of 'cheerleaders' to find social bots. See\nhttps://github.com/weberdc/find_hccs for code and data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:05:12 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Weber", "Derek", ""], ["Falzon", "Lucia", ""]]}, {"id": "2107.02765", "submitter": "Aaditeshwar Seth", "authors": "Mehak Gupta, Shayan Saifi, Konark Verma, Kumari Rekha, Aaditeshwar\n  Seth", "title": "Exploring the Scope of Using News Articles to Understand Development\n  Patterns of Districts in India", "comments": "11 pages of main text, 4 pages of supplementary material", "journal-ref": "The 3rd KDD Workshop on Data Science for Social Good, 2021", "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding what factors bring about socio-economic development may often\nsuffer from the streetlight effect, of analyzing the effect of only those\nvariables that have been measured and are therefore available for analysis. How\ndo we check whether all worthwhile variables have been instrumented and\nconsidered when building an econometric development model? We attempt to\naddress this question by building unsupervised learning methods to identify and\nrank news articles about diverse events occurring in different districts of\nIndia, that can provide insights about what may have transpired in the\ndistricts. This can help determine whether variables related to these events\nare indeed available or not to model the development of these districts. We\nalso describe several other applications that emerge from this approach, such\nas to use news articles to understand why pairs of districts that may have had\nsimilar socio-economic indicators approximately ten years back ended up at\ndifferent levels of development currently, and another application that\ngenerates a newsfeed of unusual news articles that do not conform to news\narticles about typical districts with a similar socio-economic profile. These\napplications outline the need for qualitative data to augment models based on\nquantitative data, and are meant to open up research on new ways to mine\ninformation from unstructured qualitative data to understand development.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 18:39:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gupta", "Mehak", ""], ["Saifi", "Shayan", ""], ["Verma", "Konark", ""], ["Rekha", "Kumari", ""], ["Seth", "Aaditeshwar", ""]]}, {"id": "2107.02776", "submitter": "Stratis Tsirtsis", "authors": "Stratis Tsirtsis, Abir De, Manuel Gomez-Rodriguez", "title": "Counterfactual Explanations in Sequential Decision Making Under\n  Uncertainty", "comments": "To appear at the ICML 2021 workshop on Interpretable Machine Learning\n  in Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Methods to find counterfactual explanations have predominantly focused on one\nstep decision making processes. In this work, we initiate the development of\nmethods to find counterfactual explanations for decision making processes in\nwhich multiple, dependent actions are taken sequentially over time. We start by\nformally characterizing a sequence of actions and states using finite horizon\nMarkov decision processes and the Gumbel-Max structural causal model. Building\nupon this characterization, we formally state the problem of finding\ncounterfactual explanations for sequential decision making processes. In our\nproblem formulation, the counterfactual explanation specifies an alternative\nsequence of actions differing in at most k actions from the observed sequence\nthat could have led the observed process realization to a better outcome. Then,\nwe introduce a polynomial time algorithm based on dynamic programming to build\na counterfactual policy that is guaranteed to always provide the optimal\ncounterfactual explanation on every possible realization of the counterfactual\nenvironment dynamics. We validate our algorithm using both synthetic and real\ndata from cognitive behavioral therapy and show that the counterfactual\nexplanations our algorithm finds can provide valuable insights to enhance\nsequential decision making under uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:38:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Tsirtsis", "Stratis", ""], ["De", "Abir", ""], ["Gomez-Rodriguez", "Manuel", ""]]}, {"id": "2107.02777", "submitter": "W. Damayantha Kularatne", "authors": "W. D. Kularatne, Lasanthika H. Dissawa, T.M.S.S.K. Ekanayake, Janaka\n  B. Ekanayake", "title": "Developing and delivering a remote experiment based on the experiential\n  learning framework during COVID-19 pandemic", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The students following Engineering disciplines should not only acquire the\nconceptual understanding of the concepts but also the processors and attitudes.\nThere are two recognizable learning environments for students, namely,\nclassroom environment and laboratory environment. With the COVID-19 pandemic,\nboth environments merged to online environments, impacting students'\ndevelopment of processes and characteristic attitudes. This paper introduces a\ntheoretical framework based on experiential learning to plan and deliver\nprocesses through an online environment. A case study based on the power factor\ncorrection experiment was presented. The traditional experiment that runs for 3\nhours was broken into smaller tasks such as a pre-lab activity, a simulation\nexercise, a PowerPoint presentation, a remote laboratory activity, and a final\nreport based on the experiential learning approach. A questionnaire that\ncarries close and open-ended questions were administered to obtain students'\nreflections about developing the processes through an online-friendly\nexperiential learning approach. The majority of the students like the approach\nfollowed and praise for providing them with an opportunity to perform the\nexperiment in a novel way during the COVID-19 situation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:39:48 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Kularatne", "W. D.", ""], ["Dissawa", "Lasanthika H.", ""], ["Ekanayake", "T. M. S. S. K.", ""], ["Ekanayake", "Janaka B.", ""]]}, {"id": "2107.02846", "submitter": "Shuchi Chawla", "authors": "Shuchi Chawla, Jelani Nelson, Chris Umans, and David Woodruff", "title": "Visions in Theoretical Computer Science: A Report on the TCS Visioning\n  Workshop 2020", "comments": "A Computing Community Consortium (CCC) workshop report, 36 pages", "journal-ref": null, "doi": null, "report-no": "ccc2021report_2", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Theoretical computer science (TCS) is a subdiscipline of computer science\nthat studies the mathematical foundations of computational and algorithmic\nprocesses and interactions. Work in this field is often recognized by its\nemphasis on mathematical technique and rigor. At the heart of the field are\nquestions surrounding the nature of computation: What does it mean to compute?\nWhat is computable? And how efficiently?\n  Every ten years or so the TCS community attends visioning workshops to\ndiscuss the challenges and recent accomplishments in the TCS field. The\nworkshops and the outputs they produce are meant both as a reflection for the\nTCS community and as guiding principles for interested investment partners.\nConcretely, the workshop output consists of a number of nuggets, each\nsummarizing a particular point, that are synthesized in the form of a white\npaper and illustrated with graphics/slides produced by a professional graphic\ndesigner. The second TCS Visioning Workshop was organized by the SIGACT\nCommittee for the Advancement of Theoretical Computer Science and took place\nduring the week of July 20, 2020. Despite the conference being virtual, there\nwere over 76 participants, mostly from the United States, but also a few from\nEurope and Asia who were able to attend due to the online format. Workshop\nparticipants were divided into categories as reflected in the sections of this\nreport: (1) models of computation; (2) foundations of data science; (3)\ncryptography; and (4) using theoretical computer science for other domains.\nEach group participated in a series of discussions that produced the nuggets\nbelow.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 19:12:03 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Chawla", "Shuchi", ""], ["Nelson", "Jelani", ""], ["Umans", "Chris", ""], ["Woodruff", "David", ""]]}, {"id": "2107.02941", "submitter": "Atif Ahmad", "authors": "Ritu Lakshmi, Humza Naseer, Sean Maynard, Atif Ahmad", "title": "Sensemaking in Cybersecurity Incident Response: The Interplay of\n  Organizations, Technology and Individuals", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sensemaking is a critical activity in organizations. It is a process through\nwhich individuals ascribe meanings to events which forms the basis to\nfacilitate collective action. However, the role of organizations, technology\nand individuals and their interaction in the process of sensemaking has not\nbeen sufficiently explored. This novel study seeks to address this gap by\nproposing a framework that explains how the interplay among organizations,\ntechnology and individuals enables sensemaking in the process of cybersecurity\nincident response. We propose that Organizations, Technology, and Individuals\nare the key components that interact in various ways to facilitate enactment,\nselection and retention activities (Sensemaking activities) in Incident\nResponse. We argue that sensemaking in Incident Response is the outcome of this\ninteraction. This interaction allows organizations to respond to cybersecurity\nincidents in a comprehensive manner.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 23:32:18 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Lakshmi", "Ritu", ""], ["Naseer", "Humza", ""], ["Maynard", "Sean", ""], ["Ahmad", "Atif", ""]]}, {"id": "2107.02959", "submitter": "David Kwan", "authors": "David Kwan, Luiz Marcio Cysneiros, Julio Cesar Sampaio do Prado Leite", "title": "Towards Achieving Trust Through Transparency and Ethics (Pre-Print)", "comments": "12 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquitous presence of software in the products we use, together with\nArtificial Intelligence in these products, has led to an increasing need for\nconsumer trust. Consumers often lose faith in products, and the lack of Trust\npropagates to the companies behind them. This is even more so in\nmission-critical systems such as autonomous vehicles and clinical support\nsystems. This paper follows grounded theory principles to elicit knowledge\nrelated to Trust, Ethics, and Transparency. We approach these qualities as\nNon-Functional Requirements (NFRs), aiming to build catalogs to subsidize the\nconstruction of Socially Responsible Software. The corpus we have used was\nbuilt on a selected collection of literature on Corporate Social\nResponsibility, with an emphasis on Business Ethics. Our challenge is how to\nencode the social perspective knowledge, mainly through the view of Corporate\nSocial Responsibility, on how organizations or institutions achieve\ntrustworthiness. Since our ground perspective is that of NFRs, results are\npresented by a catalogue of Trust as a Non-Functional Requirement, represented\nas a Softgoal Interdependency Graph (SIG). The SIG language helps software\nengineers in understanding alternatives they have to improve Trust in software\nproducts.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 00:44:12 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kwan", "David", ""], ["Cysneiros", "Luiz Marcio", ""], ["Leite", "Julio Cesar Sampaio do Prado", ""]]}, {"id": "2107.03200", "submitter": "Johannes Wachs", "authors": "Johannes Wachs, Mariusz Nitecki, William Schueller, Axel Polleres", "title": "The Geography of Open Source Software: Evidence from GitHub", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Open Source Software plays an important role in the digital economy. Yet\nalthough software production is amenable to remote collaboration and its end\nproducts are easily shared across distances, software development seems to\ncluster geographically in places such as Silicon Valley, London, or Berlin. And\nwhile recent work indicates that positive effects of open source software\nproduction accrue locally through knowledge spillovers and information effects,\nup-to-date data on the geographic distribution of active open source developers\nremains limited. Here we analyze the geographic distribution of more than half\na million active contributors to GitHub located in early 2021 at various\nspatial scales. Comparing our data with results from before 2010, we find a\nsignificant increase in the relative share of developers based in Asia, Latin\nAmerica and Eastern Europe, suggesting a more even spread of OSS developers\nglobally. Within countries, however, we find significant concentration in\nregions, exceeding by some margin the concentration of workers in high-tech\nfields. We relate OSS activity to a number of social and technological\nindicators at both scales using a multiple regression framework. Despite the\npotential of OSS as a distributed mode of collaborative work, the data suggest\nthat OSS activity remains highly localized.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:18:17 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wachs", "Johannes", ""], ["Nitecki", "Mariusz", ""], ["Schueller", "William", ""], ["Polleres", "Axel", ""]]}, {"id": "2107.03207", "submitter": "Yixuan Zhang", "authors": "Yixuan Zhang, Feng Zhou, Zhidong Li, Yang Wang, Fang Chen", "title": "Bias-Tolerant Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The label bias and selection bias are acknowledged as two reasons in data\nthat will hinder the fairness of machine-learning outcomes. The label bias\noccurs when the labeling decision is disturbed by sensitive features, while the\nselection bias occurs when subjective bias exists during the data sampling.\nEven worse, models trained on such data can inherit or even intensify the\ndiscrimination. Most algorithmic fairness approaches perform an empirical risk\nminimization with predefined fairness constraints, which tends to trade-off\naccuracy for fairness. However, such methods would achieve the desired fairness\nlevel with the sacrifice of the benefits (receive positive outcomes) for\nindividuals affected by the bias. Therefore, we propose a\nBias-TolerantFAirRegularizedLoss (B-FARL), which tries to regain the benefits\nusing data affected by label bias and selection bias. B-FARL takes the biased\ndata as input, calls a model that approximates the one trained with fair but\nlatent data, and thus prevents discrimination without constraints required. In\naddition, we show the effective components by decomposing B-FARL, and we\nutilize the meta-learning framework for the B-FARL optimization. The\nexperimental results on real-world datasets show that our method is empirically\neffective in improving fairness towards the direction of true but latent\nlabels.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:31:38 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhang", "Yixuan", ""], ["Zhou", "Feng", ""], ["Li", "Zhidong", ""], ["Wang", "Yang", ""], ["Chen", "Fang", ""]]}, {"id": "2107.03291", "submitter": "Jesse David Dinneen", "authors": "William Jones and Jesse David Dinneen and Robert Capra and Anne R.\n  Diekema and Manuel A. P\\'erez-Qui\\~nones", "title": "Personal Information Management", "comments": "Final version available at\n  https://www.routledgehandbooks.com/doi/10.1081/E-ELIS4-120053695", "journal-ref": "Chapter in Levine-Clark, M., & McDonald, J. (Eds.), Encyclopedia\n  of Library and Information Science, Fourth Edition, 2017, pp. 3584-3605. New\n  York, NY: Taylor & Francis", "doi": "10.1081/E-ELIS4-120053695", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Personal Information Management (PIM) refers to the practice and the study of\nthe activities a person performs in order to acquire or create, store,\norganize, maintain, retrieve, use, and distribute information in each of its\nmany forms (paper and digital, in e-mails, files, Web pages, text messages,\ntweets, posts, etc.) as needed to meet life's many goals (everyday and\nlong-term, work-related and not) and to fulfill life's many roles and\nresponsibilities (as parent, spouse, friend, employee, member of community,\netc.). PIM activities are an effort to establish, use, and maintain a mapping\nbetween information and need. Activities of finding (and re-finding) move from\na current need toward information while activities of keeping move from\nencountered information toward anticipated need. Meta-level activities such as\nmaintaining, organizing, and managing the flow of information focus on the\nmapping itself. Tools and techniques of PIM can promote information integration\nwith benefits for each kind of PIM activity and across the life cycle of\npersonal information. Understanding how best to accomplish this integration\nwithout inadvertently creating problems along the way is a key challenge of\nPIM.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:27:28 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jones", "William", ""], ["Dinneen", "Jesse David", ""], ["Capra", "Robert", ""], ["Diekema", "Anne R.", ""], ["P\u00e9rez-Qui\u00f1ones", "Manuel A.", ""]]}, {"id": "2107.03318", "submitter": "Aman Tyagi", "authors": "Aman Tyagi, Kathleen M. Carley", "title": "Climate Change Conspiracy Theories on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the critical emerging challenges in climate change communication is\nthe prevalence of conspiracy theories. This paper discusses some of the major\nconspiracy theories related to climate change found in a large Twitter corpus.\nWe use a state-of-the-art stance detection method to find whether conspiracy\ntheories are more popular among Disbelievers or Believers of climate change. We\nthen analyze which conspiracy theory is more popular than the others and how\npopularity changes with climate change belief. We find that Disbelievers of\nclimate change are overwhelmingly responsible for sharing messages with\nconspiracy theory-related keywords, and not all conspiracy theories are equally\nshared. Lastly, we discuss the implications of our findings for climate change\ncommunication.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:56:44 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Tyagi", "Aman", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "2107.03487", "submitter": "Devansh Saxena", "authors": "Devansh Saxena, Karla Badillo-Urquiola, Pamela Wisniewski, Shion Guha", "title": "A Framework of High-Stakes Algorithmic Decision-Making for the Public\n  Sector Developed through a Case Study of Child-Welfare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms have permeated throughout civil government and society, where they\nare being used to make high-stakes decisions about human lives. In this paper,\nwe first develop a cohesive framework of algorithmic decision-making adapted\nfor the public sector (ADMAPS) that reflects the complex socio-technical\ninteractions between \\textit{human discretion}, \\textit{bureaucratic\nprocesses}, and \\textit{algorithmic decision-making} by synthesizing disparate\nbodies of work in the fields of Human-Computer Interaction (HCI), Science and\nTechnology Studies (STS), and Public Administration (PA). We then applied the\nADMAPS framework to conduct a qualitative analysis of an in-depth, eight-month\nethnographic case study of the algorithms in daily use within a child-welfare\nagency that serves approximately 900 families and 1300 children in the\nmid-western United States. Overall, we found there is a need to focus on\nstrength-based algorithmic outcomes centered in social ecological frameworks.\nIn addition, algorithmic systems need to support existing bureaucratic\nprocesses and augment human discretion, rather than replace it. Finally,\ncollective buy-in in algorithmic systems requires trust in the target outcomes\nat both the practitioner and bureaucratic levels. As a result of our study, we\npropose guidelines for the design of high-stakes algorithmic decision-making\ntools in the child-welfare system, and more generally, in the public sector. We\nempirically validate the theoretically derived ADMAPS framework to demonstrate\nhow it can be useful for systematically making pragmatic decisions about the\ndesign of algorithms for the public sector.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 21:24:35 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Saxena", "Devansh", ""], ["Badillo-Urquiola", "Karla", ""], ["Wisniewski", "Pamela", ""], ["Guha", "Shion", ""]]}, {"id": "2107.03554", "submitter": "Byeongjoon Noh", "authors": "Byeongjoon Noh, Wonjun Noh, David Lee, Hwasoo Yeo", "title": "Automated Object Behavioral Feature Extraction for Potential Risk\n  Analysis based on Video Sensor", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pedestrians are exposed to risk of death or serious injuries on roads,\nespecially unsignalized crosswalks, for a variety of reasons. To date, an\nextensive variety of studies have reported on vision based traffic safety\nsystem. However, many studies required manual inspection of the volumes of\ntraffic video to reliably obtain traffic related objects behavioral factors. In\nthis paper, we propose an automated and simpler system for effectively\nextracting object behavioral features from video sensors deployed on the road.\nWe conduct basic statistical analysis on these features, and show how they can\nbe useful for monitoring the traffic behavior on the road. We confirm the\nfeasibility of the proposed system by applying our prototype to two\nunsignalized crosswalks in Osan city, South Korea. To conclude, we compare\nbehaviors of vehicles and pedestrians in those two areas by simple statistical\nanalysis. This study demonstrates the potential for a network of connected\nvideo sensors to provide actionable data for smart cities to improve pedestrian\nsafety in dangerous road environments.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 01:11:31 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Noh", "Byeongjoon", ""], ["Noh", "Wonjun", ""], ["Lee", "David", ""], ["Yeo", "Hwasoo", ""]]}, {"id": "2107.03721", "submitter": "Michael Veale", "authors": "Michael Veale and Frederik Zuiderveen Borgesius", "title": "Demystifying the Draft EU Artificial Intelligence Act", "comments": "16 pages, 1 table", "journal-ref": "Computer Law Review International (2021), 22(4)", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In April 2021, the European Commission proposed a Regulation on Artificial\nIntelligence, known as the AI Act. We present an overview of the Act and\nanalyse its implications, drawing on scholarship ranging from the study of\ncontemporary AI practices to the structure of EU product safety regimes over\nthe last four decades. Aspects of the AI Act, such as different rules for\ndifferent risk-levels of AI, make sense. But we also find that some provisions\nof the Draft AI Act have surprising legal implications, whilst others may be\nlargely ineffective at achieving their stated goals. Several overarching\naspects, including the enforcement regime and the risks of maximum\nharmonisation pre-empting legitimate national AI policy, engender significant\nconcern. These issues should be addressed as a priority in the legislative\nprocess.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 10:04:07 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 08:39:22 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Veale", "Michael", ""], ["Borgesius", "Frederik Zuiderveen", ""]]}, {"id": "2107.03895", "submitter": "Nalini Palaniswamy", "authors": "Dr. Nalini Palaniswamy", "title": "Social Media Marketing (SMM) A Strategic Tool for Developing Business\n  for Tourism Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Social media marketing is an emerging marketing technique worldwide. This\nresearch concentrates on how effectively social media can be used to promote a\nproduct in tourism industry. The efficient use of social media develops a\ntourism company in terms of sales, branding, reach and relationship management.\nThe study aims to find the best social media platform to promote and develop a\ntourism company and the customer opinion towards planning a trip through\nonline. It also concentrates on customer response for online offers and\ndiscounts in those social media platforms. The study attempts to understand and\ncreate suitable model for social media marketing for tourism companies with a\nsample size of 400. The sampling technique used in this study is purposive\nsampling method. The purposive sample can also be called as judgemental sample.\nNormally the sample will be selected based on the knowledge possessed by the\nrespondents on a particular phenomenon. Here, the study is been conducted among\nthe people who use social media. The sampling technique helped the researcher\nto identify the target sample i.e., the social media users.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 13:36:24 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Palaniswamy", "Dr. Nalini", ""]]}, {"id": "2107.03896", "submitter": "Adam Zielinski", "authors": "Adam Zielinski", "title": "AI and the future of pharmaceutical research", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper examines how pharmaceutical Artificial Intelligence advancements\nmay affect the development of new drugs in the coming years. The question was\nanswered by reviewing a rich body of source material, including industry\nliterature, research journals, AI studies, market reports, market projections,\ndiscussion papers, press releases, and organizations' websites. The paper\nargues that continued innovation in pharmaceutical AI will enable rapid\ndevelopment of safe and effective therapies for previously untreatable\ndiseases. A series of major points support this conclusion: The pharmaceutical\nindustry is in a significant productivity crisis today, and AI-enabled research\nmethods can be directly applied to reduce the time and cost of drug discovery\nprojects. The industry already reported results such as a 10-fold reduction in\ndrug molecule discovery times. Numerous AI alliances between industry,\ngovernments, and academia enabled utilizing proprietary data and led to\noutcomes such as the largest molecule toxicity database to date or more than\n200 drug safety predictive models. The momentum was recently increased by the\ninvolvement of tech giants combined with record rounds of funding. The\nlong-term effects will range from safer and more effective therapies, through\nthe diminished role of pharmaceutical patents, to large-scale collaboration and\nnew business strategies oriented around currently untreatable diseases. The\npaper notes that while many reviewed resources seem to have overly optimistic\nfuture expectations, even a fraction of these developments would alleviate the\nproductivity crisis. Finally, the paper concludes that the focus on\npharmaceutical AI put the industry on a trajectory towards another significant\ndisruption: open data sharing and collaboration.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 17:56:36 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Zielinski", "Adam", ""]]}, {"id": "2107.03897", "submitter": "Sandi Baressi \\v{S}egota", "authors": "Vedran Mrzljak, Nikola An{\\dj}eli\\'c, Ivan Lorencin and Sandi Baressi\n  \\v{S}egota", "title": "The influence of various optimization algorithms on nuclear power plant\n  steam turbine exergy efficiency and destruction", "comments": "25 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents an exergy analysis of the whole turbine, turbine\ncylinders and cylinder parts in four different operating regimes. Analyzed\nturbine operates in nuclear power plant while three of four operating regimes\nare obtained by using optimization algorithms - SA (Simplex Algorithm), GA\n(Genetic Algorithm) and IGSA (Improved Genetic-Simplex Algorithm). IGSA\noperating regime gives the highest developed mechanical power of the whole\nturbine equal to 1022.48 MW, followed by GA (1020.06 MW) and SA (1017.16 MW),\nwhile in Original operating regime whole turbine develop mechanical power equal\nto 996.29 MW. In addition, IGSA causes the highest increase in developed\nmechanical power of almost all cylinders and cylinder parts in comparison to\nthe Original operating regime. All observed optimization algorithms increases\nthe exergy destruction of the whole turbine in comparison to Original operating\nregime - the lowest increase causes IGSA, followed by GA and finally SA. The\nhighest exergy efficiency of the whole turbine, equal to 85.92% is obtained by\nIGSA, followed by GA (85.89%) and SA (85.82%), while the lowest exergy\nefficiency is obtained in Original operating regime (85.70%). Analyzed turbine,\nwhich operates by using wet steam is low influenced by the ambient temperature\nchange. IGSA, which shows dominant performance in exergy analysis parameters of\nthe analyzed turbine, in certain situations is overpowered by GA. Therefore, in\noptimization of steam turbine performance, IGSA and GA can be recommended.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 09:59:16 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mrzljak", "Vedran", ""], ["An\u0111eli\u0107", "Nikola", ""], ["Lorencin", "Ivan", ""], ["\u0160egota", "Sandi Baressi", ""]]}, {"id": "2107.03900", "submitter": "Hari Bandi", "authors": "Hari Bandi and Dimitris Bertsimas", "title": "The Price of Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systemic bias with respect to gender, race and ethnicity, often unconscious,\nis prevalent in datasets involving choices among individuals. Consequently,\nsociety has found it challenging to alleviate bias and achieve diversity in a\nway that maintains meritocracy in such settings. We propose (a) a novel\noptimization approach based on optimally flipping outcome labels and training\nclassification models simultaneously to discover changes to be made in the\nselection process so as to achieve diversity without significantly affecting\nmeritocracy, and (b) a novel implementation tool employing optimal\nclassification trees to provide insights on which attributes of individuals\nlead to flipping of their labels, and to help make changes in the current\nselection processes in a manner understandable by human decision makers. We\npresent case studies on three real-world datasets consisting of parole,\nadmissions to the bar and lending decisions, and demonstrate that the price of\ndiversity is low and sometimes negative, that is we can modify our selection\nprocesses in a way that enhances diversity without affecting meritocracy\nsignificantly, and sometimes improving it.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 02:23:27 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Bandi", "Hari", ""], ["Bertsimas", "Dimitris", ""]]}, {"id": "2107.03907", "submitter": "Jason R.C. Nurse Dr", "authors": "Jason R. C. Nurse and Nikki Williams and Emily Collins and Niki\n  Panteli and John Blythe and Ben Koppelman", "title": "Remote Working Pre- and Post-COVID-19: An Analysis of New Threats and\n  Risks to Security and Privacy", "comments": "HCI International 2021 (HCII 2021)", "journal-ref": null, "doi": "10.1007/978-3-030-78645-8_74", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 has radically changed society as we know it. To reduce the spread of\nthe virus, millions across the globe have been forced to work remotely, often\nin make-shift home offices, and using a plethora of new, unfamiliar digital\ntechnologies. In this article, we critically analyse cyber security and privacy\nconcerns arising due to remote working during the coronavirus pandemic. Through\nour work, we discover a series of security risks emerging because of the\nrealities of this period. For instance, lack of remote-working security\ntraining, heightened stress and anxiety, rushed technology deployment, and the\npresence of untrusted individuals in a remote-working environment (e.g., in\nflatshares), can result in new cyber-risk. Simultaneously, we find that as\norganisations look to manage these and other risks posed by their remote\nworkforces, employee's privacy (including personal information and activities)\nis often compromised. This is apparent in the significant adoption of remote\nworkplace monitoring, management and surveillance technologies. Such\ntechnologies raise several privacy and ethical questions, and further highlight\nthe tension between security and privacy going forward.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 15:39:56 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nurse", "Jason R. C.", ""], ["Williams", "Nikki", ""], ["Collins", "Emily", ""], ["Panteli", "Niki", ""], ["Blythe", "John", ""], ["Koppelman", "Ben", ""]]}, {"id": "2107.03912", "submitter": "Olga Fink", "authors": "Olga Fink, Torbj{\\o}rn Netland, Stefan Feuerriegel", "title": "Artificial intelligence across company borders", "comments": "Article accepted for publication in the Communications of the ACM on\n  June 8, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Artificial intelligence (AI) has become a valued technology in many\ncompanies. At the same time, a substantial potential for utilizing AI\n\\emph{across} company borders has remained largely untapped. An inhibiting\nfactor concerns disclosure of data to external parties, which raises legitimate\nconcerns about intellectual property rights, privacy issues, and cybersecurity\nrisks. Combining federated learning with domain adaptation can provide a\nsolution to this problem by enabling effective cross-company AI without data\ndisclosure. In this Viewpoint, we discuss the use, value, and implications of\nthis approach in a cross-company setting.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 11:56:41 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Fink", "Olga", ""], ["Netland", "Torbj\u00f8rn", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "2107.03913", "submitter": "Vladimir Kokh", "authors": "Pavel Blinov, Vladimir Kokh", "title": "Patient Embeddings in Healthcare and Insurance Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper researches the problem of concept and patient representations in\nthe medical domain. We present the patient histories from Electronic Health\nRecords (EHRs) as temporal sequences of ICD concepts for which embeddings are\nlearned in an unsupervised setup with a transformer-based neural network model.\nThe model training was performed on the collection of one million patients'\nhistories in 6 years. The predictive power of such a model is assessed in\ncomparison with several baseline methods. A series of experiments on the\nMIMIC-III data show the advantage of the presented model compared to a similar\nsystem. Further, we analyze the obtained embedding space with regards to\nconcept relations and show how knowledge from the medical domain can be\nsuccessfully transferred to the practical task of insurance scoring in the form\nof patient embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 13:30:43 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Blinov", "Pavel", ""], ["Kokh", "Vladimir", ""]]}, {"id": "2107.03924", "submitter": "Mahmoud Nasr Mr", "authors": "Mahmoud Nasr, MD. Milon Islam, Shady Shehata, Fakhri Karray and Yuri\n  Quintana", "title": "Smart Healthcare in the Age of AI: Recent Advances, Challenges, and\n  Future Prospects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significant increase in the number of individuals with chronic ailments\n(including the elderly and disabled) has dictated an urgent need for an\ninnovative model for healthcare systems. The evolved model will be more\npersonalized and less reliant on traditional brick-and-mortar healthcare\ninstitutions such as hospitals, nursing homes, and long-term healthcare\ncenters. The smart healthcare system is a topic of recently growing interest\nand has become increasingly required due to major developments in modern\ntechnologies, especially in artificial intelligence (AI) and machine learning\n(ML). This paper is aimed to discuss the current state-of-the-art smart\nhealthcare systems highlighting major areas like wearable and smartphone\ndevices for health monitoring, machine learning for disease diagnosis, and the\nassistive frameworks, including social robots developed for the ambient\nassisted living environment. Additionally, the paper demonstrates software\nintegration architectures that are very significant to create smart healthcare\nsystems, integrating seamlessly the benefit of data analytics and other tools\nof AI. The explained developed systems focus on several facets: the\ncontribution of each developed framework, the detailed working procedure, the\nperformance as outcomes, and the comparative merits and limitations. The\ncurrent research challenges with potential future directions are addressed to\nhighlight the drawbacks of existing systems and the possible methods to\nintroduce novel frameworks, respectively. This review aims at providing\ncomprehensive insights into the recent developments of smart healthcare systems\nto equip experts to contribute to the field.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2021 05:10:47 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Nasr", "Mahmoud", ""], ["Islam", "MD. Milon", ""], ["Shehata", "Shady", ""], ["Karray", "Fakhri", ""], ["Quintana", "Yuri", ""]]}, {"id": "2107.03925", "submitter": "Francesco Pirotti", "authors": "Francesco Pirotti, Alberto Guarnieri, Marco Piragnolo, Marco Boscaro,\n  Raffaele Cavalli", "title": "Analysis of geospatial behaviour of visitors of urban gardens: is\n  positioning via smartphones a valid solution?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Tracking locations is practical and speditive with smartphones, as they are\nomnipresent devices, relatively cheap, and have the necessary sensors for\npositioning and networking integrated in the same box. Nowadays recent models\nhave GNSS antennas capable of receiving multiple constellations. In the\nproposed work we test the hypothesis that GNSS positions directly recorded by\nsmartphones can be a valid solution for spatial analysis of people's behaviour\nin an urban garden. Particular behaviours can be linked to therapeutic spots\nthat promote health and well-being of visitors. Three parts are reported: (i)\nassessment of the accuracy of the positions relative to a reference track, (ii)\nimplementation of a framework for automating transmission and processing of the\nlocation information, (iii) analysis of preferred spots via spatial analytics.\nDifferent devices were used to survey at different times and with different\nmethods, i.e. in the pocket of the owner or on a rigid frame. Accuracy was\nestimated using distance of each located point to the reference track, and\nprecision was estimated with static multiple measures. A chat-bot through the\nTelegram application was implemented to allow users to send their data to a\ncentralized computing environment thus automating the spatial analysis. Results\nreport a horizontal accuracy below ~2.3 m at 95% confidence level, without\nsignificant difference between surveys, and very little differences between\ndevices. GNSS-only and assisted navigation with telephone cells also did not\nshow significant difference. Autocorrelation of the residuals over time and\nspace showed strong consistency of the residuals, thus proving a valid solution\nfor spatial analysis of walking behaviour.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 08:32:05 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Pirotti", "Francesco", ""], ["Guarnieri", "Alberto", ""], ["Piragnolo", "Marco", ""], ["Boscaro", "Marco", ""], ["Cavalli", "Raffaele", ""]]}, {"id": "2107.03959", "submitter": "Jason R.C. Nurse Dr", "authors": "Rahime Belen Saglam and Jason R.C. Nurse and Duncan Hodges", "title": "Privacy Concerns in Chatbot Interactions: When to Trust and When to\n  Worry", "comments": null, "journal-ref": "23rd International Conference on Human-Computer Interaction (HCII\n  2021)", "doi": "10.1007/978-3-030-78642-7_53", "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through advances in their conversational abilities, chatbots have started to\nrequest and process an increasing variety of sensitive personal information.\nThe accurate disclosure of sensitive information is essential where it is used\nto provide advice and support to users in the healthcare and finance sectors.\nIn this study, we explore users' concerns regarding factors associated with the\nuse of sensitive data by chatbot providers. We surveyed a representative sample\nof 491 British citizens. Our results show that the user concerns focus on\ndeleting personal information and concerns about their data's inappropriate\nuse. We also identified that individuals were concerned about losing control\nover their data after a conversation with conversational agents. We found no\neffect from a user's gender or education but did find an effect from the user's\nage, with those over 45 being more concerned than those under 45. We also\nconsidered the factors that engender trust in a chatbot. Our respondents'\nprimary focus was on the chatbot's technical elements, with factors such as the\nresponse quality being identified as the most critical factor. We again found\nno effect from the user's gender or education level; however, when we\nconsidered some social factors (e.g. avatars or perceived 'friendliness'), we\nfound those under 45 years old rated these as more important than those over\n45. The paper concludes with a discussion of these results within the context\nof designing inclusive, digital systems that support a wide range of users.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:31:58 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Saglam", "Rahime Belen", ""], ["Nurse", "Jason R. C.", ""], ["Hodges", "Duncan", ""]]}, {"id": "2107.04003", "submitter": "Robert Yawson PhD", "authors": "Robert M Yawson, Daniel Woldeab and Emmanuel Osafo", "title": "Human Resource Development and the Internet of Things", "comments": null, "journal-ref": "Proceedings of the 25th Annual Academy of Human Resource\n  Development International Research Conference in the Americas. Richmond VA,\n  USA. February 14 -17, 2018", "doi": "10.31124/advance.9638417.v1", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Internet of Things (IoT) is affecting national innovation ecosystems and\nthe approach of organizations to innovation and how they create and capture\nvalue in everyday business activities. The Internet of Things (IoT), is\ndisruptive, and it will change the manner in which human resources are\ndeveloped and managed, calling for a new and adaptive human resource\ndevelopment approach. The Classical Internet communication form is human-human.\nThe prospect of IoT is that every object will have a unique way of\nidentification and can be addressed so that every object can be connected. The\ncommunication forms will expand from human-human to human-human, human-thing,\nand thing-thing. This will bring a new challenge to how Human Resource\nDevelopment (HRD) is practiced. This paper provides an overview of the Internet\nof Things and conceptualizes the role of HRD in the age of the Internet of\nThings. Keywords:\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 01:11:29 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Yawson", "Robert M", ""], ["Woldeab", "Daniel", ""], ["Osafo", "Emmanuel", ""]]}, {"id": "2107.04009", "submitter": "Byungsoo Kim", "authors": "Byungsoo Kim, Hangyeol Yu, Dongmin Shin, Youngduck Choi", "title": "Knowledge Transfer by Discriminative Pre-training for Academic\n  Performance Prediction", "comments": "Nominated for the best short paper award of EDM 2021. This is an\n  extended version of the published one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The needs for precisely estimating a student's academic performance have been\nemphasized with an increasing amount of attention paid to Intelligent Tutoring\nSystem (ITS). However, since labels for academic performance, such as test\nscores, are collected from outside of ITS, obtaining the labels is costly,\nleading to label-scarcity problem which brings challenge in taking machine\nlearning approaches for academic performance prediction. To this end, inspired\nby the recent advancement of pre-training method in natural language processing\ncommunity, we propose DPA, a transfer learning framework with Discriminative\nPre-training tasks for Academic performance prediction. DPA pre-trains two\nmodels, a generator and a discriminator, and fine-tunes the discriminator on\nacademic performance prediction. In DPA's pre-training phase, a sequence of\ninteractions where some tokens are masked is provided to the generator which is\ntrained to reconstruct the original sequence. Then, the discriminator takes an\ninteraction sequence where the masked tokens are replaced by the generator's\noutputs, and is trained to predict the originalities of all tokens in the\nsequence. Compared to the previous state-of-the-art generative pre-training\nmethod, DPA is more sample efficient, leading to fast convergence to lower\nacademic performance prediction error. We conduct extensive experimental\nstudies on a real-world dataset obtained from a multi-platform ITS application\nand show that DPA outperforms the previous state-of-the-art generative\npre-training method with a reduction of 4.05% in mean absolute error and more\nrobust to increased label-scarcity.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 13:02:23 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 03:42:14 GMT"}, {"version": "v3", "created": "Mon, 12 Jul 2021 05:36:22 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kim", "Byungsoo", ""], ["Yu", "Hangyeol", ""], ["Shin", "Dongmin", ""], ["Choi", "Youngduck", ""]]}, {"id": "2107.04010", "submitter": "Alise Danielle Midtfjord", "authors": "Alise Danielle Midtfjord, Riccardo De Bin and Arne Bang Huseby", "title": "A Machine Learning Approach to Safer Airplane Landings: Predicting\n  Runway Conditions using Weather and Flight Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of snow and ice on runway surfaces reduces the available\ntire-pavement friction needed for retardation and directional control and\ncauses potential economic and safety threats for the aviation industry during\nthe winter seasons. To activate appropriate safety procedures, pilots need\naccurate and timely information on the actual runway surface conditions. In\nthis study, XGBoost is used to create a combined runway assessment system,\nwhich includes a classifcation model to predict slippery conditions and a\nregression model to predict the level of slipperiness. The models are trained\non weather data and data from runway reports. The runway surface conditions are\nrepresented by the tire-pavement friction coefficient, which is estimated from\nflight sensor data from landing aircrafts. To evaluate the performance of the\nmodels, they are compared to several state-of-the-art runway assessment\nmethods. The XGBoost models identify slippery runway conditions with a ROC AUC\nof 0.95, predict the friction coefficient with a MAE of 0.0254, and outperforms\nall the previous methods. The results show the strong abilities of machine\nlearning methods to model complex, physical phenomena with a good accuracy when\ndomain knowledge is used in the variable extraction. The XGBoost models are\ncombined with SHAP (SHapley Additive exPlanations) approximations to provide a\ncomprehensible decision support system for airport operators and pilots, which\ncan contribute to safer and more economic operations of airport runways.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:01:13 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Midtfjord", "Alise Danielle", ""], ["De Bin", "Riccardo", ""], ["Huseby", "Arne Bang", ""]]}, {"id": "2107.04011", "submitter": "Jawad Haqbeen", "authors": "J. Haqbeen, T. Ito, S. Sahab, R. Hadfi, T. Sato, S. Okuhara", "title": "Meeting the SDGs : Enabling the Goals by Cooperation with Crowd using a\n  Conversational AI Platform", "comments": "7 pages, 6 figures, 1 table, To appear as a conference paper at KICSS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we report about a large-scale online discussion with 1099\ncitizens on the Afghanistan Sustainable Development Goals.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 04:14:19 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Haqbeen", "J.", ""], ["Ito", "T.", ""], ["Sahab", "S.", ""], ["Hadfi", "R.", ""], ["Sato", "T.", ""], ["Okuhara", "S.", ""]]}, {"id": "2107.04014", "submitter": "Mitja Kulczynski", "authors": "Pamela Fleischmann and Mitja Kulczynski and Dirk Nowotka", "title": "The Show Must Go On -- Examination During a Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When unexpected incidents occur, new innovative and flexible solutions are\nrequired. If this event is something such radical and dramatic like the\nCOVID-19 pandemic, these solutions must aim to guarantee as much normality as\npossible while protecting lives. After a moment of shock our university decided\nthat the students have to be able to pursue their studies for guaranteeing a\ndegree in the expected time since most of them faced immediate financial\nproblems due to the loss of their student jobs. This implied, for us as\nteachers, that we had to reorganise not only the teaching methods from nearly\none day to the next, but we also had to come up with an adjusted way of\nexaminations which had to take place in person with pen and paper under strict\nhygiene rules. On the other hand the correction should avoid personal contacts.\nWe developed a framework which allowed us to correct the digitalised exams\nsafely at home while providing the high standards given by the general data\nprotection regulation of our country. Moreover, the time spent in the offices\ncould be reduced to a minimum thanks to automatically generated exam sheets,\nautomatically re-digitalised and sorted worked-on exams.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 09:22:52 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Fleischmann", "Pamela", ""], ["Kulczynski", "Mitja", ""], ["Nowotka", "Dirk", ""]]}, {"id": "2107.04022", "submitter": "Rajitha Ramanayake", "authors": "Rajitha Ramanayake, Philipp Wicke, Vivek Nallur", "title": "Immune Moral Models? Pro-Social Rule Breaking as a Moral Enhancement\n  Approach for Ethical AI", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The world is heading towards a state in which Artificial Intelligence (AI)\nbased agents make most decisions on behalf of humans. From healthcare decision\nmaking to social media censoring, these agents face problems and make decisions\nthat have ethical and societal implications. Hence, ethical behaviour is a\ncritical characteristic of a human-centric AI. A common observation in\nhuman-centric industries, like the service industry and healthcare, is that\ntheir professionals tend to break rules, if necessary, for pro-social reasons.\nTo make AI agents more human-centric, we argue that there is a need for a\nmechanism that helps AI agents to identify when and how to break rules set by\ntheir designers. In this paper, we examine the when, i.e., conditions under\nwhich humans break rules for pro-social reasons. In the presented study, we\nintroduce a 'vaccination strategy dilemma' where one needs to decide whether\nthey would distribute Covid-19 vaccines only to members of a high-risk group\n(follow the rule) or, in selected cases, administer the vaccine to a few social\ninfluencers (break the rule), which might yield an overall greater benefit to\nsociety. Results of the empirical study suggest a relationship between\nstakeholder utilities and pro-social rule breaking (PSRB), which either\ndeontological or utilitarian ethics cannot completely explain. Finally, the\npaper discusses the design characteristics of an ethical agent capable of PSRB\nand the future research directions on PSRB in the AI realm.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 18:44:55 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Ramanayake", "Rajitha", ""], ["Wicke", "Philipp", ""], ["Nallur", "Vivek", ""]]}, {"id": "2107.04023", "submitter": "Filip Biljecki", "authors": "Filip Biljecki, Lawrence Zheng Xiong Chew, Nikola Milojevic-Dupont,\n  Felix Creutzig", "title": "Open government geospatial data on buildings for planning sustainable\n  and resilient cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As buildings are central to the social and environmental sustainability of\nhuman settlements, high-quality geospatial data are necessary to support their\nmanagement and planning. Authorities around the world are increasingly\ncollecting and releasing such data openly, but these are mostly disconnected\ninitiatives, making it challenging for users to fully leverage their potential\nfor urban sustainability. We conduct a global study of 2D geospatial data on\nbuildings that are released by governments for free access, ranging from\nindividual cities to whole countries. We identify and benchmark more than 140\nreleases from 28 countries containing above 100 million buildings, based on\nfive dimensions: accessibility, richness, data quality, harmonisation, and\nrelationships with other actors. We find that much building data released by\ngovernments is valuable for spatial analyses, but there are large disparities\namong them and not all instances are of high quality, harmonised, and rich in\ndescriptive information. Our study also compares authoritative data to\nOpenStreetMap, a crowdsourced counterpart, suggesting a mutually beneficial and\ncomplementary relationship.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 17:13:04 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Biljecki", "Filip", ""], ["Chew", "Lawrence Zheng Xiong", ""], ["Milojevic-Dupont", "Nikola", ""], ["Creutzig", "Felix", ""]]}, {"id": "2107.04024", "submitter": "Patrick Glauner", "authors": "Patrick Glauner", "title": "Staying Ahead in the MOOC-Era by Teaching Innovative AI Courses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of the rapidly advancing digital transformation of teaching,\nuniversities have started to face major competition from Massive Open Online\nCourses (MOOCs). Universities thus have to set themselves apart from MOOCs in\norder to justify the added value of three to five-year degree programs to\nprospective students. In this paper, we show how we address this challenge at\nDeggendorf Institute of Technology in ML and AI. We first share our best\npractices and present two concrete courses: Computer Vision and Innovation\nManagement for AI. We then demonstrate how these courses contribute to\nDeggendorf Institute of Technology's ability to differentiate itself from MOOCs\n(and other universities).\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 11:31:47 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Glauner", "Patrick", ""]]}, {"id": "2107.04026", "submitter": "Ghalib Tahir", "authors": "Attiq ur Rehman, Asad Waqar Malik, Anis ur Rahman, Sohail Iqbal and\n  Ghalib Ahmed Tahir", "title": "CVEH: A Dynamic Framework To Profile Vehicle Movements To Mitigate Hit\n  And Run Cases Using Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In developed countries like the USA, Germany, and the UK, the security forces\nused highly sophisticated equipment, fast vehicles, drones, and helicopters to\ncatch offenders' vehicles. Whereas, in developing countries with limited\nresources such schemes cannot be utilized due to management cost and other\nconstraints. In this paper, we proposed a framework called CVEH that enables\ndeveloping countries to profile the offender vehicle movements through\ncrowdsourcing technique and act as an early warning system to the law forcing\nagencies. It also engages citizens to play their role in improving security\nconditions. The proposed CVEH framework allows Vehicle-to-Infrastructure (V2I)\ncommunication to monitor the movement of the offender's vehicle and shared its\ninformation with the Command and Control (CC) centre. The CC centre projects\nthe path and engages nearly located law enforcement agencies. CVEH is developed\nand evaluated on android smartphones. Simulations conducted for this study\nexhibit the effectiveness of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 15:52:28 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Rehman", "Attiq ur", ""], ["Malik", "Asad Waqar", ""], ["Rahman", "Anis ur", ""], ["Iqbal", "Sohail", ""], ["Tahir", "Ghalib Ahmed", ""]]}, {"id": "2107.04029", "submitter": "Florian Wirthm\\\"uller", "authors": "Florian Wirthm\\\"uller, Jochen Hipp, Christian Reichenb\\\"acher and\n  Manfred Reichert", "title": "The Atlas of Lane Changes: Investigating Location-dependent Lane Change\n  Behaviors Using Measurement Data from a Customer Fleet", "comments": "the article has been accepted for publication during the 24th IEEE\n  Intelligent Transportation Systems Conference (ITSC), 8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of surrounding traffic participants behavior is a crucial and\nchallenging task for driver assistance and autonomous driving systems. Today's\napproaches mainly focus on modeling dynamic aspects of the traffic situation\nand try to predict traffic participants behavior based on this. In this article\nwe take a first step towards extending this common practice by calculating\nlocation-specific a-priori lane change probabilities. The idea behind this is\nstraight forward: The driving behavior of humans may vary in exactly the same\ntraffic situation depending on the respective location. E.g. drivers may ask\nthemselves: Should I pass the truck in front of me immediately or should I wait\nuntil reaching the less curvy part of my route lying only a few kilometers\nahead? Although, such information is far away from allowing behavior prediction\non its own, it is obvious that today's approaches will greatly benefit when\nincorporating such location-specific a-priori probabilities into their\npredictions. For example, our investigations show that highway interchanges\ntend to enhance driver's motivation to perform lane changes, whereas curves\nseem to have lane change-dampening effects. Nevertheless, the investigation of\nall considered local conditions shows that superposition of various effects can\nlead to unexpected probabilities at some locations. We thus suggest dynamically\nconstructing and maintaining a lane change probability map based on customer\nfleet data in order to support onboard prediction systems with additional\ninformation. For deriving reliable lane change probabilities a broad customer\nfleet is the key to success.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 07:29:19 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 06:45:16 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Wirthm\u00fcller", "Florian", ""], ["Hipp", "Jochen", ""], ["Reichenb\u00e4cher", "Christian", ""], ["Reichert", "Manfred", ""]]}, {"id": "2107.04117", "submitter": "Evangelos Pournaras", "authors": "Evangelos Pournaras, Atif Nabi Ghulam, Renato Kunz, Regula H\\\"anggli", "title": "Crowd Sensing and Living Lab Outdoor Experimentation Made Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outdoor `living lab' experimentation using pervasive computing provides new\nopportunities: higher realism, external validity and large-scale\nsocio-spatio-temporal observations. However, experimentation `in the wild' is\nhighly complex and costly. Noise, biases, privacy concerns to comply with\nstandards of ethical review boards, remote moderation, control of experimental\nconditions and equipment perplex the collection of high-quality data for causal\ninference. This article introduces Smart Agora, a novel open-source software\nplatform for rigorous systematic outdoor experimentation. Without writing a\nsingle line of code, highly complex experimental scenarios are visually\ndesigned and automatically deployed to smart phones. Novel geolocated survey\nand sensor data are collected subject of participants verifying desired\nexperimental conditions, for instance. their presence at certain urban spots.\nThis new approach drastically improves the quality and purposefulness of crowd\nsensing, tailored to conditions that confirm/reject hypotheses. The features\nthat support this innovative functionality and the broad spectrum of its\napplicability are demonstrated.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 21:49:32 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Pournaras", "Evangelos", ""], ["Ghulam", "Atif Nabi", ""], ["Kunz", "Renato", ""], ["H\u00e4nggli", "Regula", ""]]}, {"id": "2107.04124", "submitter": "Jiaming Pei", "authors": "Jiaming Pei, Jinhai Li, Jiyuan Xu, Q.Dat Luong", "title": "PAC: Partial Area Cluster for adjusting the distribution of\n  transportation platforms in modern cities", "comments": "In the follow-up research, we found that our article has some serious\n  problems. The problem of our research has some flaws. In order not to affect\n  the research of other scholars, we hope you can help us delete this\n  submission. Once the research has made new discoveries, we will publish them\n  to arXiv immediately", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the modern city, the utilization rate of public transportation attached\nimportance to the efficiency of public traffic. However, the unreasonable\ndistribution of transportation platforms results in a low utilization rate. In\nthis paper, we researched and evaluated the distribution of platforms -- bus\nand subway -- and proposed a method, called \"partial area cluster\" (PAC), to\nimprove the utilization by changing and renewing the original distribution. The\nnovel method was based on the K-means algorithm in the field of machine\nlearning. PAC worked to search the suitable bus platforms as the center and\nmodified the original one to the subway. Experience has shown that the use of\npublic transport resources has increased by 20%. The study uses a similar\ncluster algorithm to solve transport networks' problems in a novel but\npractical term. As a result, the PAC is expected to be used extensively in the\ntransportation system construction process.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:04:18 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 14:47:39 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Pei", "Jiaming", ""], ["Li", "Jinhai", ""], ["Xu", "Jiyuan", ""], ["Luong", "Q. Dat", ""]]}, {"id": "2107.04427", "submitter": "Tom Vermeire", "authors": "Tom Vermeire and Thibault Laugel and Xavier Renard and David Martens\n  and Marcin Detyniecki", "title": "How to choose an Explainability Method? Towards a Methodical\n  Implementation of XAI in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability is becoming an important requirement for organizations that\nmake use of automated decision-making due to regulatory initiatives and a shift\nin public awareness. Various and significantly different algorithmic methods to\nprovide this explainability have been introduced in the field, but the existing\nliterature in the machine learning community has paid little attention to the\nstakeholder whose needs are rather studied in the human-computer interface\ncommunity. Therefore, organizations that want or need to provide this\nexplainability are confronted with the selection of an appropriate method for\ntheir use case. In this paper, we argue there is a need for a methodology to\nbridge the gap between stakeholder needs and explanation methods. We present\nour ongoing work on creating this methodology to help data scientists in the\nprocess of providing explainability to stakeholders. In particular, our\ncontributions include documents used to characterize XAI methods and user\nrequirements (shown in Appendix), which our methodology builds upon.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 13:22:58 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Vermeire", "Tom", ""], ["Laugel", "Thibault", ""], ["Renard", "Xavier", ""], ["Martens", "David", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2107.04506", "submitter": "Jason R.C. Nurse Dr", "authors": "Alice Jaffray and Conor Finn and Jason R.C. Nurse", "title": "SherLOCKED: A Detective-themed Serious Game for Cyber Security Education", "comments": null, "journal-ref": "15th IFIP International Symposium on Human Aspects of Information\n  Security & Assurance (HAISA 2021)", "doi": "10.1007/978-3-030-81111-2_4", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gamification and Serious Games are progressively being used over a host of\nfields, particularly to support education. Such games provide a new way to\nengage students with content and can complement more traditional approaches to\nlearning. This article proposes SherLOCKED, a new serious game created in the\nstyle of a 2D top-down puzzle adventure. The game is situated in the context of\nan undergraduate cyber security course, and is used to consolidate students'\nknowledge of foundational security concepts (e.g. the CIA triad, security\nthreats and attacks and risk management). SherLOCKED was built based on a\nreview of existing serious games and a study of common gamification principles.\nIt was subsequently implemented within an undergraduate course, and evaluated\nwith 112 students. We found the game to be an effective, attractive and fun\nsolution for allowing further engagement with content that students were\nintroduced to during lectures. This research lends additional evidence to the\nuse of serious games in supporting learning about cyber security.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 15:46:47 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Jaffray", "Alice", ""], ["Finn", "Conor", ""], ["Nurse", "Jason R. C.", ""]]}, {"id": "2107.04642", "submitter": "Ben Green", "authors": "Ben Green", "title": "Impossibility of What? Formal and Substantive Equality in Algorithmic\n  Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the face of compounding crises of social and economic inequality, many\nhave turned to algorithmic decision-making to achieve greater fairness in\nsociety. As these efforts intensify, reasoning within the burgeoning field of\n\"algorithmic fairness\" increasingly shapes how fairness manifests in practice.\nThis paper interrogates whether algorithmic fairness provides the appropriate\nconceptual and practical tools for enhancing social equality. I argue that the\ndominant, \"formal\" approach to algorithmic fairness is ill-equipped as a\nframework for pursuing equality, as its narrow frame of analysis generates\nrestrictive approaches to reform. In light of these shortcomings, I propose an\nalternative: a \"substantive\" approach to algorithmic fairness that centers\nopposition to social hierarchies and provides a more expansive analysis of how\nto address inequality. This substantive approach enables more fruitful\ntheorizing about the role of algorithms in combatting oppression. The\ndistinction between formal and substantive algorithmic fairness is exemplified\nby each approach's responses to the \"impossibility of fairness\" (an\nincompatibility between mathematical definitions of algorithmic fairness).\nWhile the formal approach requires us to accept the \"impossibility of fairness\"\nas a harsh limit on efforts to enhance equality, the substantive approach\nallows us to escape the \"impossibility of fairness\" by suggesting reforms that\nare not subject to this false dilemma and that are better equipped to\nameliorate conditions of social oppression.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:29:57 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Green", "Ben", ""]]}, {"id": "2107.04711", "submitter": "Jan Smeddinck", "authors": "Rosanna Bellini, Alexander Wilson, Jan David Smeddinck", "title": "Fragments of the Past: Curating Peer Support with Perpetrators of\n  Domestic Violence", "comments": null, "journal-ref": null, "doi": "10.1145/3411764.3445611", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing evidence that digital peer-support networks can have a\npositive influence on behaviour change and wellbeing outcomes for people who\nharm themselves and others. However, making and sustaining such networks are\nsubject to ethical and pragmatic challenges, particularly for perpetrators of\ndomestic violence whom pose unique risks when brought together. In this work we\nreport on a ten-month study where we worked with six support workers and\neighteen perpetrators in the design and deployment of Fragments of the Past; a\nsocio-material system that connects audio messages with tangible artefacts. We\nshare how crafting digitally-augmented artefacts - 'fragments' - of experiences\nof desisting from violence can translate messages for motivation and rapport\nbetween peers, without subjecting the process to risks inherent with direct\ninter-personal communication. These insights provide the basis for practical\nconsiderations for future network design with challenging populations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:57:43 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bellini", "Rosanna", ""], ["Wilson", "Alexander", ""], ["Smeddinck", "Jan David", ""]]}, {"id": "2107.04936", "submitter": "Martin Saveski", "authors": "Martin Saveski, Farshad Kooti, Sylvia Morelli Vitousek, Carlos Diuk,\n  Bryce Bartlett, Lada Adamic", "title": "Social Catalysts: Characterizing People Who Spark Conversations Among\n  Others", "comments": "To appear in CSCW (ACM Conference on Computer-Supported Cooperative\n  Work and Social Computing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  People assume different and important roles within social networks. Some\nroles have received extensive study: that of influencers who are\nwell-connected, and that of brokers who bridge unconnected parts of the\nnetwork. However, very little work has explored another potentially important\nrole, that of creating opportunities for people to interact and facilitating\nconversation between them. These individuals bring people together and act as\nsocial catalysts. In this paper, we test for the presence of social catalysts\non the online social network Facebook. We first identify posts that have\nspurred conversations between the poster's friends and summarize the\ncharacteristics of such posts. We then aggregate the number of catalyzed\ncomments at the poster level, as a measure of the individual's \"catalystness.\"\nThe top 1% of such individuals account for 31% of catalyzed interactions,\nalthough their network characteristics do not differ markedly from others who\npost as frequently and have a similar number of friends. By collecting survey\ndata, we also validate the behavioral measure of catalystness: a person is more\nlikely to be nominated as a social catalyst by their friends if their posts\nprompt discussions between other people more frequently. The measure, along\nwith other conversation-related features, is one of the most predictive of a\nperson being nominated as a catalyst. Although influencers and brokers may have\ngotten more attention for their network positions, our findings provide\nconverging evidence that another important role exists and is recognized in\nonline social networks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 01:06:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Saveski", "Martin", ""], ["Kooti", "Farshad", ""], ["Vitousek", "Sylvia Morelli", ""], ["Diuk", "Carlos", ""], ["Bartlett", "Bryce", ""], ["Adamic", "Lada", ""]]}, {"id": "2107.04953", "submitter": "Jonathan Stray", "authors": "Jonathan Stray", "title": "Designing Recommender Systems to Depolarize", "comments": "to appear in First Monday, September 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Polarization is implicated in the erosion of democracy and the progression to\nviolence, which makes the polarization properties of large algorithmic content\nselection systems (recommender systems) a matter of concern for peace and\nsecurity. While algorithm-driven social media does not seem to be a primary\ndriver of polarization at the country level, it could be a useful intervention\npoint in polarized societies. This paper examines algorithmic depolarization\ninterventions with the goal of conflict transformation: not suppressing or\neliminating conflict but moving towards more constructive conflict. Algorithmic\nintervention is considered at three stages: which content is available\n(moderation), how content is selected and personalized (ranking), and content\npresentation and controls (user interface). Empirical studies of online\nconflict suggest that the exposure diversity intervention proposed as an\nantidote to \"filter bubbles\" can be improved and can even worsen polarization\nunder some conditions. Using civility metrics in conjunction with diversity in\ncontent selection may be more effective. However, diversity-based interventions\nhave not been tested at scale and may not work in the diverse and dynamic\ncontexts of real platforms. Instead, intervening in platform polarization\ndynamics will likely require continuous monitoring of polarization metrics,\nsuch as the widely used \"feeling thermometer.\" These metrics can be used to\nevaluate product features, and potentially engineered as algorithmic\nobjectives. It may further prove necessary to include polarization measures in\nthe objective functions of recommender algorithms to prevent optimization\nprocesses from creating conflict as a side effect.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 03:23:42 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Stray", "Jonathan", ""]]}, {"id": "2107.05383", "submitter": "Jesse David Dinneen", "authors": "Jesse David Dinneen and Helen Bubinger", "title": "Not Quite 'Ask a Librarian': AI on the Nature, Value, and Future of LIS", "comments": "Final version to appear in ASIS&T '21: Proceedings of the 84th Annual\n  Meeting of the Association for Information Science & Technology, 58", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CY cs.HC cs.IT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  AI language models trained on Web data generate prose that reflects human\nknowledge and public sentiments, but can also contain novel insights and\npredictions. We asked the world's best language model, GPT-3, fifteen difficult\nquestions about the nature, value, and future of library and information\nscience (LIS), topics that receive perennial attention from LIS scholars. We\npresent highlights from its 45 different responses, which range from platitudes\nand caricatures to interesting perspectives and worrisome visions of the\nfuture, thus providing an LIS-tailored demonstration of the current performance\nof AI language models. We also reflect on the viability of using AI to forecast\nor generate research ideas in this way today. Finally, we have shared the full\nresponse log online for readers to consider and evaluate for themselves.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:20:17 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Dinneen", "Jesse David", ""], ["Bubinger", "Helen", ""]]}, {"id": "2107.05515", "submitter": "Annika King", "authors": "Annika King, Jacob Murri, Jake Callahan, Adrienne Russell, Tyler J.\n  Jarvis", "title": "Mathematical Analysis of Redistricting in Utah", "comments": "27 pages, 5. figures, submitted to \"Statistics and Public Policy\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the claim that the Utah congressional districts enacted in\n2011 represent an unfair Republican gerrymander, and we evaluate the most\ncommon measures of partisan fairness and gerrymandering in the context of\nUtah's congressional districts. We do this by generating large ensembles of\nalternative redistricting plans using Markov chain Monte Carlo methods. We also\npropose a new metric of partisan fairness in Utah, namely, the Republican vote\nshare in the least-Republican district. This metric only makes sense in\nsettings with at most one competitive district, but it is very effective for\nquantifying gerrymandering and for evaluating other metrics used in such\nsettings.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 15:38:34 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["King", "Annika", ""], ["Murri", "Jacob", ""], ["Callahan", "Jake", ""], ["Russell", "Adrienne", ""], ["Jarvis", "Tyler J.", ""]]}, {"id": "2107.05527", "submitter": "Andrea Baronchelli", "authors": "Andrea Baronchelli", "title": "Collective intelligence and the blockchain: Technology, communities and\n  social experiments", "comments": "Brief \"perspective\" commentary piece", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains are still perceived chiefly as a new technology. But each\nblockchain is also a community and a social experiment, built around social\nconsensus. Here I discuss three examples showing how collective intelligence\ncan help, threat or capitalize on blockchain-based ecosystems. They concern the\nimmutability of smart contracts, code transparency and new forms of property.\nThe examples show that more research, new norms and, eventually, laws are\nneeded to manage the interaction between collective behaviour and the\nblockchain technology. Insights from researchers in collective intelligence can\nhelp society rise up to the challenge.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 15:56:21 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Baronchelli", "Andrea", ""]]}, {"id": "2107.05558", "submitter": "Zixuan Kang", "authors": "Chen Weiya, Li Jiajia, Kang Zixuan", "title": "Research on Metro Service Quality Improvement Schemes Considering\n  Feasibility", "comments": "in Chinese language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is an important management task of metro agencies to formulate reasonable\nimprovement schemes based on the result of service quality surveys. Considering\nscores, weights, and improvement feasibility of service quality attributes in a\ncertain period, this paper integrates Decision Tree (DT) into\nImportance-Performance analysis (IPA) to build a DT-IPA model, which is used to\ndetermine the improvement priority of attributes, and to quantify the\nimprovement degree. If-then rules extracted from the optimal decision tree and\nthe improvement feasibility computed by analytic hierarchy process are two main\nitems derived from the DT-IPA model. They are used to optimize the initial\nimprovement priority of attributes determined by IPA and to quantify the degree\nof improvement of the adjusted attributes. Then, the overall service quality\ncan reach a high score, realizing the operation goal. The effectiveness of the\nDT-IPA model was verified through an empirical study which was taken place in\nChangsha Metro, China. The proposed method can be a decision-making tool for\nmetro agency managers to improve the quality of metro service.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 09:26:00 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Weiya", "Chen", ""], ["Jiajia", "Li", ""], ["Zixuan", "Kang", ""]]}, {"id": "2107.05704", "submitter": "Reuben Binns Dr", "authors": "Reuben Binns, Reuben Kirkham", "title": "How Could Equality and Data Protection Law Shape AI Fairness for People\n  with Disabilities?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article examines the concept of 'AI fairness' for people with\ndisabilities from the perspective of data protection and equality law. This\nexamination demonstrates that there is a need for a distinctive approach to AI\nfairness that is fundamentally different to that used for other protected\ncharacteristics, due to the different ways in which discrimination and data\nprotection law applies in respect of Disability. We articulate this new agenda\nfor AI fairness for people with disabilities, explaining how combining data\nprotection and equality law creates new opportunities for disabled people's\norganisations and assistive technology researchers alike to shape the use of\nAI, as well as to challenge potential harmful uses.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 19:41:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Binns", "Reuben", ""], ["Kirkham", "Reuben", ""]]}, {"id": "2107.05767", "submitter": "Lucka Gianvechio", "authors": "Carmen Melo Toledo, Guilherme Mendes Bassedon, Jonathan Batista\n  Ferreira, Lucka de Godoy Gianvechio, Carlos Guatimosim, Felipe Maia Polo,\n  Renato Vicente", "title": "Effects of personality traits in predicting grade retention of Brazilian\n  students", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Student's grade retention is a key issue faced by many education systems,\nespecially those in developing countries. In this paper, we seek to gauge the\nrelevance of students' personality traits in predicting grade retention in\nBrazil. For that, we used data collected in 2012 and 2017, in the city of\nSertaozinho, countryside of the state of Sao Paulo, Brazil. The surveys taken\nin Sertaozinho included several socioeconomic questions, standardized tests,\nand a personality test. Moreover, students were in grades 4, 5, and 6 in 2012.\nOur approach was based on training machine learning models on the surveys' data\nto predict grade retention between 2012 and 2017 using information from 2012 or\nbefore, and then using some strategies to quantify personality traits'\npredictive power. We concluded that, besides proving to be fairly better than a\nrandom classifier when isolated, personality traits contribute to prediction\neven when using socioeconomic variables and standardized tests results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:23:13 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Toledo", "Carmen Melo", ""], ["Bassedon", "Guilherme Mendes", ""], ["Ferreira", "Jonathan Batista", ""], ["Gianvechio", "Lucka de Godoy", ""], ["Guatimosim", "Carlos", ""], ["Polo", "Felipe Maia", ""], ["Vicente", "Renato", ""]]}, {"id": "2107.05978", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, Isabel Chien, Muhammad Bilal Zafar, Adrian Weller", "title": "DIVINE: Diverse Influential Training Points for Data Visualization and\n  Model Refinement", "comments": "30 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity of machine learning (ML) models increases, resulting in a\nlack of prediction explainability, several methods have been developed to\nexplain a model's behavior in terms of the training data points that most\ninfluence the model. However, these methods tend to mark outliers as highly\ninfluential points, limiting the insights that practitioners can draw from\npoints that are not representative of the training data. In this work, we take\na step towards finding influential training points that also represent the\ntraining data well. We first review methods for assigning importance scores to\ntraining points. Given importance scores, we propose a method to select a set\nof DIVerse INfluEntial (DIVINE) training points as a useful explanation of\nmodel behavior. As practitioners might not only be interested in finding data\npoints influential with respect to model accuracy, but also with respect to\nother important metrics, we show how to evaluate training data points on the\nbasis of group fairness. Our method can identify unfairness-inducing training\npoints, which can be removed to improve fairness outcomes. Our quantitative\nexperiments and user studies show that visualizing DIVINE points helps\npractitioners understand and explain model behavior better than earlier\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 10:50:58 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bhatt", "Umang", ""], ["Chien", "Isabel", ""], ["Zafar", "Muhammad Bilal", ""], ["Weller", "Adrian", ""]]}, {"id": "2107.06009", "submitter": "Artyom Lobanov", "authors": "Artyom Lobanov, Timofey Bryksin, Alexey Shpilman", "title": "Automatic Classification of Error Types in Solutions to Programming\n  Assignments at Online Learning Platform", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online programming courses are becoming more and more popular, but they still\nhave significant drawbacks when compared to the traditional education system,\ne.g., the lack of feedback. In this study, we apply machine learning methods to\nimprove the feedback of automated verification systems for programming\nassignments. We propose an approach that provides an insight on how to fix the\ncode for a given incorrect submission. To achieve this, we detect frequent\nerror types by clustering previously submitted incorrect solutions, label these\nclusters and use this labeled dataset to identify the type of an error in a new\nsubmission. We examine and compare several approaches to the detection of\nfrequent error types and to the assignment of clusters to new submissions. The\nproposed method is evaluated on a dataset provided by a popular online learning\nplatform.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:59:57 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Lobanov", "Artyom", ""], ["Bryksin", "Timofey", ""], ["Shpilman", "Alexey", ""]]}, {"id": "2107.06015", "submitter": "Steven Van Vaerenbergh", "authors": "Steven Van Vaerenbergh and Adri\\'an P\\'erez-Suay", "title": "A Classification of Artificial Intelligence Systems for Mathematics\n  Education", "comments": "Chapter in the upcoming book \"Mathematics Education in the Age of\n  Artificial Intelligence: How Artificial Intelligence can serve Mathematical\n  Human Learning\", Springer Nature, edited by P.R. Richard, P. V\\'elez, and S.\n  Van Vaerenbergh", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter provides an overview of the different Artificial Intelligence\n(AI) systems that are being used in contemporary digital tools for Mathematics\nEducation (ME). It is aimed at researchers in AI and Machine Learning (ML), for\nwhom we shed some light on the specific technologies that are being used in\neducational applications; and at researchers in ME, for whom we clarify: i)\nwhat the possibilities of the current AI technologies are, ii) what is still\nout of reach and iii) what is to be expected in the near future. We start our\nanalysis by establishing a high-level taxonomy of AI tools that are found as\ncomponents in digital ME applications. Then, we describe in detail how these AI\ntools, and in particular ML, are being used in two key applications,\nspecifically AI-based calculators and intelligent tutoring systems. We finish\nthe chapter with a discussion about student modeling systems and their\nrelationship to artificial general intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 12:09:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Van Vaerenbergh", "Steven", ""], ["P\u00e9rez-Suay", "Adri\u00e1n", ""]]}, {"id": "2107.06206", "submitter": "Sridhar Chimalakonda", "authors": "Shruti Priya, Shubhankar Bhadra and Sridhar Chimalakonda", "title": "ML-Quest: A Game for Introducing Machine Learning Concepts to K-12\n  Students", "comments": "13 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Today, Machine Learning (ML) is of a great importance to society due to the\navailability of huge data and high computational resources. This ultimately led\nto the introduction of ML concepts at multiple levels of education including\nK-12 students to promote computational thinking. However, teaching these\nconcepts to K-12 through traditional methodologies such as video lectures and\nbooks is challenging. Many studies in the literature have reported that using\ninteractive environments such as games to teach computational thinking and\nprogramming improves retention capacity and motivation among students.\nTherefore, introducing ML concepts using a game might enhance students'\nunderstanding of the subject and motivate them to learn further. However, we\nare not aware of any existing game which explicitly focuses on introducing ML\nconcepts to students using game play. Hence, in this paper, we propose\nML-Quest, a 3D video game to provide conceptual overview of three ML concepts:\nSupervised Learning, Gradient Descent and K-Nearest Neighbor (KNN)\nClassification. The crux of the game is to introduce the definition and working\nof these concepts, which we call conceptual overview, in a simulated scenario\nwithout overwhelming students with the intricacies of ML. The game has been\npredominantly evaluated for its usefulness and player experience using the\nTechnology Acceptance Model (TAM) model with the help of 23 higher-secondary\nschool students. The survey result shows that around 70% of the participants\neither agree or strongly agree that the ML-Quest is quite interactive and\nuseful in introducing them to ML concepts.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:05:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Priya", "Shruti", ""], ["Bhadra", "Shubhankar", ""], ["Chimalakonda", "Sridhar", ""]]}, {"id": "2107.06243", "submitter": "Moniba Keymanesh", "authors": "Moniba Keymanesh, Tanya Berger-Wolf, Micha Elsner, Srinivasan\n  Parthasarathy", "title": "Fairness-aware Summarization for Justified Decision-Making", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many applications such as recidivism prediction, facility inspection, and\nbenefit assignment, it's important for individuals to know the\ndecision-relevant information for the model's prediction. In addition, the\nmodel's predictions should be fairly justified. Essentially, decision-relevant\nfeatures should provide sufficient information for the predicted outcome and\nshould be independent of the membership of individuals in protected groups such\nas race and gender. In this work, we focus on the problem of (un)fairness in\nthe justification of the text-based neural models. We tie the explanatory power\nof the model to fairness in the outcome and propose a fairness-aware\nsummarization mechanism to detect and counteract the bias in such models. Given\na potentially biased natural language explanation for a decision, we use a\nmulti-task neural model and an attribution mechanism based on integrated\ngradients to extract the high-utility and discrimination-free justifications in\nthe form of a summary. The extracted summary is then used for training a model\nto make decisions for individuals. Results on several real-world datasets\nsuggests that our method: (i) assists users to understand what information is\nused for the model's decision and (ii) enhances the fairness in outcomes while\nsignificantly reducing the demographic leakage.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 17:04:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Keymanesh", "Moniba", ""], ["Berger-Wolf", "Tanya", ""], ["Elsner", "Micha", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "2107.06720", "submitter": "Ashudeep Singh", "authors": "Ashudeep Singh, David Kempe, Thorsten Joachims", "title": "Fairness in Ranking under Uncertainty", "comments": "Preprint under submission. 19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness has emerged as an important consideration in algorithmic\ndecision-making. Unfairness occurs when an agent with higher merit obtains a\nworse outcome than an agent with lower merit. Our central point is that a\nprimary cause of unfairness is uncertainty. A principal or algorithm making\ndecisions never has access to the agents' true merit, and instead uses proxy\nfeatures that only imperfectly predict merit (e.g., GPA, star ratings,\nrecommendation letters). None of these ever fully capture an agent's merit; yet\nexisting approaches have mostly been defining fairness notions directly based\non observed features and outcomes.\n  Our primary point is that it is more principled to acknowledge and model the\nuncertainty explicitly. The role of observed features is to give rise to a\nposterior distribution of the agents' merits. We use this viewpoint to define a\nnotion of approximate fairness in ranking. We call an algorithm $\\phi$-fair\n(for $\\phi \\in [0,1]$) if it has the following property for all agents $x$ and\nall $k$: if agent $x$ is among the top $k$ agents with respect to merit with\nprobability at least $\\rho$ (according to the posterior merit distribution),\nthen the algorithm places the agent among the top $k$ agents in its ranking\nwith probability at least $\\phi \\rho$.\n  We show how to compute rankings that optimally trade off approximate fairness\nagainst utility to the principal. In addition to the theoretical\ncharacterization, we present an empirical analysis of the potential impact of\nthe approach in simulation studies. For real-world validation, we applied the\napproach in the context of a paper recommendation system that we built and\nfielded at a large conference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:10:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Singh", "Ashudeep", ""], ["Kempe", "David", ""], ["Joachims", "Thorsten", ""]]}, {"id": "2107.06732", "submitter": "Andrea Pinna", "authors": "Fabio Caddeo and Andrea Pinna", "title": "Opportunities and challenges of Blockchain-Oriented systems in the\n  tourism industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tourism industry is increasingly influenced by the evolution of\ninformation and communication technologies (ICT), which are revolutionizing the\nway people travel. In this work we want to nvestigate the use of innovative IT\ntechnologies by DMOs (Destination Management Organizations), focusing on\nblockchain technology, both from the point of view of research in the field,\nand in the study of the most relevant software projects. In particular, we\nintend to verify the benefits offered by these IT tools in the management and\nmonitoring of a destination, without forgetting the implications for the other\nstakeholders involved. These technologies, in fact, can offer a wide range of\nservices that can be useful throughout the life cycle of the destination.\n", "versions": [{"version": "v1", "created": "Thu, 11 Mar 2021 23:22:03 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Caddeo", "Fabio", ""], ["Pinna", "Andrea", ""]]}, {"id": "2107.06751", "submitter": "Guillaume Cabanac", "authors": "Guillaume Cabanac and Cyril Labb\\'e and Alexander Magazinov", "title": "Tortured phrases: A dubious writing style emerging in science. Evidence\n  of critical issues affecting established journals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic text generators have been used to produce fake scientific\npapers for more than a decade. Such nonsensical papers are easily detected by\nboth human and machine. Now more complex AI-powered generation techniques\nproduce texts indistinguishable from that of humans and the generation of\nscientific texts from a few keywords has been documented. Our study introduces\nthe concept of tortured phrases: unexpected weird phrases in lieu of\nestablished ones, such as 'counterfeit consciousness' instead of 'artificial\nintelligence.' We combed the literature for tortured phrases and study one\nreputable journal where these concentrated en masse. Hypothesising the use of\nadvanced language models we ran a detector on the abstracts of recent articles\nof this journal and on several control sets. The pairwise comparisons reveal a\nconcentration of abstracts flagged as 'synthetic' in the journal. We also\nhighlight irregularities in its operation, such as abrupt changes in editorial\ntimelines. We substantiate our call for investigation by analysing several\nindividual dubious articles, stressing questionable features: tortured writing\nstyle, citation of non-existent literature, and unacknowledged image reuse.\nSurprisingly, some websites offer to rewrite texts for free, generating\ngobbledegook full of tortured phrases. We believe some authors used rewritten\ntexts to pad their manuscripts. We wish to raise the awareness on publications\ncontaining such questionable AI-generated or rewritten texts that passed (poor)\npeer review. Deception with synthetic texts threatens the integrity of the\nscientific literature.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:47:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Cabanac", "Guillaume", ""], ["Labb\u00e9", "Cyril", ""], ["Magazinov", "Alexander", ""]]}, {"id": "2107.06799", "submitter": "Akhila Sri Manasa Venigalla", "authors": "Kowndinya Boyalakuntla, Akhila Sri Manasa Venigalla and Sridhar\n  Chimalakonda", "title": "WAccess -- A Web Accessibility Tool based on the latest WCAG 2.2\n  guidelines", "comments": "11 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The vision of providing access to all web content equally for all users makes\nweb accessibility a fundamental goal of todays internet. Web accessibility is\nthe practice of removing barriers from websites that could hinder functionality\nfor users with various disabilities. Web accessibility is measured against the\naccessibility guidelines such as WCAG, GIGW and so on. WCAG 2.2 is the latest\nset of guidelines for web accessibility that helps in making websites\naccessible. The web accessibility tools available in the World Wide Web\nConsortium (W3C), only conform up to WCAG 2.1 guidelines. No tools exist for\nthe latest set of guidelines. Despite the availability of several tools to\ncheck conformity of websites with WCAG 2.1 guidelines, there is scarcity of\ntools that are both open source and scalable. To support automated\naccessibility evaluation of numerous websites against WCAG 2.2 and 2.1, we\npresent here a tool, WAccess. WAccess highlights violations of 9 guidelines\nfrom WCAG 2.1 and 7 guidelines from WCAG 2.2 of a specific web page on the web\nconsole and suggests the fix for violations while specifying violating code\nsnippet simultaneously. We evaluated WAccess against 2246 government websites\nof India, and observed a total of about 2 million violations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:56:38 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Boyalakuntla", "Kowndinya", ""], ["Venigalla", "Akhila Sri Manasa", ""], ["Chimalakonda", "Sridhar", ""]]}, {"id": "2107.07023", "submitter": "Denae Ford", "authors": "Souti Chattopadhyay, Thomas Zimmermann, Denae Ford", "title": "Reel Life vs. Real Life: How Software Developers Share Their Daily Life\n  through Vlogs", "comments": "12 pages, 2 figures, 3 tables", "journal-ref": null, "doi": "10.1145/3468264.3468599", "report-no": null, "categories": "cs.SE cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software developers are turning to vlogs (video blogs) to share what a day is\nlike to walk in their shoes. Through these vlogs developers share a rich\nperspective of their technical work as well their personal lives. However, does\nthe type of activities portrayed in vlogs differ from activities developers in\nthe industry perform? Would developers at a software company prefer to show\nactivities to different extents if they were asked to share about their day\nthrough vlogs? To answer these questions, we analyzed 130 vlogs by software\ndevelopers on YouTube and conducted a survey with 335 software developers at a\nlarge software company. We found that although vlogs present traditional\ndevelopment activities such as coding and code peripheral activities (11%),\nthey also prominently feature wellness and lifestyle related activities (47.3%)\nthat have not been reflected in previous software engineering literature. We\nalso found that developers at the software company were inclined to share more\nnon-coding tasks (e.g., personal projects, time spent with family and friends,\nand health) when asked to create a mock-up vlog to promote diversity. These\nfindings demonstrate a shift in our understanding of how software developers\nare spending their time and find valuable to share publicly. We discuss how\nvlogs provide a more complete perspective of software development work and\nserve as a valuable source of data for empirical research.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 22:16:53 GMT"}, {"version": "v2", "created": "Tue, 27 Jul 2021 16:56:46 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Chattopadhyay", "Souti", ""], ["Zimmermann", "Thomas", ""], ["Ford", "Denae", ""]]}, {"id": "2107.07155", "submitter": "Giacomo Livan", "authors": "Sonja Tilly, Giacomo Livan", "title": "Predicting market inflation expectations with news topics and sentiment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a novel approach to incorporating news topics and their\nassociated sentiment into predictions of breakeven inflation rate (BEIR)\nmovements for eight countries with mature bond markets. We calibrate five\nclasses of machine learning models including narrative-based features for each\ncountry, and find that they generally outperform corresponding benchmarks that\ndo not include such features. We find Logistic Regression and XGBoost\nclassifiers to deliver the best performance across countries. We complement\nthese results with a feature importance analysis, showing that economic and\nfinancial topics are the key performance drivers in our predictions, with\nadditional contributions from topics related to health and government. We\nexamine cross-country spillover effects of news narrative on BEIR via Graphical\nGranger Causality and confirm their existence for the US and Germany, while\nfive other countries considered in our study are only influenced by local\nnarrative.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 07:02:15 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Tilly", "Sonja", ""], ["Livan", "Giacomo", ""]]}, {"id": "2107.07249", "submitter": "Jan Gogoll", "authors": "Niina Zuber, Severin Kacianka, Jan Gogoll, Alexander Pretschner,\n  Julian Nida-R\\\"umelin", "title": "Empowered and Embedded: Ethics and Agile Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this article we focus on the structural aspects of the development of\nethical software, and argue that ethical considerations need to be embedded\ninto the (agile) software development process. In fact, we claim that agile\nprocesses of software development lend themselves specifically well for this\nendeavour. First, we contend that ethical evaluations need to go beyond the use\nof software products and include an evaluation of the software itself. This\nimplies that software engineers influence peoples' lives through the features\nof their designed products. Embedded values are thus approached best by\nsoftware engineers themselves. Therefore, we put emphasis on the possibility to\nimplement ethical deliberations in already existing and well established agile\nsoftware development processes. Our approach relies on software engineers\nmaking their own judgments throughout the entire development process to ensure\nthat technical features and ethical evaluation can be addressed adequately to\ntransport and foster desirable values and norms. We argue that agile software\ndevelopment processes may help the implementation of ethical deliberation for\nfive reasons: 1) agile methods are widely spread, 2) their emphasis on flat\nhierarchies promotes independent thinking, 3) their reliance on existing team\nstructures serve as an incubator for deliberation, 4) agile development\nenhances object-focused techno-ethical realism, and, finally, 5) agile\nstructures provide a salient endpoint to deliberation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 11:14:03 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Zuber", "Niina", ""], ["Kacianka", "Severin", ""], ["Gogoll", "Jan", ""], ["Pretschner", "Alexander", ""], ["Nida-R\u00fcmelin", "Julian", ""]]}, {"id": "2107.07334", "submitter": "L\\^e Nguy\\^en Hoang", "authors": "L\\^e-Nguy\\^en Hoang, Louis Faucon, Aidan Jungo, Sergei Volodin, Dalia\n  Papuc, Orfeas Liossatos, Ben Crulis, Mariame Tighanimine, Isabela Constantin,\n  Anastasiia Kucherenko, Alexandre Maurer, Felix Grimberg, Vlad Nitu, Chris\n  Vossen, S\\'ebastien Rouault and El-Mahdi El-Mhamdi", "title": "Tournesol: A quest for a large, secure and trustworthy database of\n  reliable human judgments", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Today's large-scale algorithms have become immensely influential, as they\nrecommend and moderate the content that billions of humans are exposed to on a\ndaily basis. They are the de-facto regulators of our societies' information\ndiet, from shaping opinions on public health to organizing groups for social\nmovements. This creates serious concerns, but also great opportunities to\npromote quality information. Addressing the concerns and seizing the\nopportunities is a challenging, enormous and fabulous endeavor, as intuitively\nappealing ideas often come with unwanted {\\it side effects}, and as it requires\nus to think about what we deeply prefer.\n  Understanding how today's large-scale algorithms are built is critical to\ndetermine what interventions will be most effective. Given that these\nalgorithms rely heavily on {\\it machine learning}, we make the following key\nobservation: \\emph{any algorithm trained on uncontrolled data must not be\ntrusted}. Indeed, a malicious entity could take control over the data, poison\nit with dangerously manipulative fabricated inputs, and thereby make the\ntrained algorithm extremely unsafe. We thus argue that the first step towards\nsafe and ethical large-scale algorithms must be the collection of a large,\nsecure and trustworthy dataset of reliable human judgments.\n  To achieve this, we introduce \\emph{Tournesol}, an open source platform\navailable at \\url{https://tournesol.app}. Tournesol aims to collect a large\ndatabase of human judgments on what algorithms ought to widely recommend (and\nwhat they ought to stop widely recommending). We outline the structure of the\nTournesol database, the key features of the Tournesol platform and the main\nhurdles that must be overcome to make it a successful project. Most\nimportantly, we argue that, if successful, Tournesol may then serve as the\nessential foundation for any safe and ethical large-scale algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:21:35 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Hoang", "L\u00ea-Nguy\u00ean", ""], ["Faucon", "Louis", ""], ["Jungo", "Aidan", ""], ["Volodin", "Sergei", ""], ["Papuc", "Dalia", ""], ["Liossatos", "Orfeas", ""], ["Crulis", "Ben", ""], ["Tighanimine", "Mariame", ""], ["Constantin", "Isabela", ""], ["Kucherenko", "Anastasiia", ""], ["Maurer", "Alexandre", ""], ["Grimberg", "Felix", ""], ["Nitu", "Vlad", ""], ["Vossen", "Chris", ""], ["Rouault", "S\u00e9bastien", ""], ["El-Mhamdi", "El-Mahdi", ""]]}, {"id": "2107.07356", "submitter": "Kunal Relia", "authors": "Kunal Relia", "title": "DiRe Committee : Diversity and Representation Constraints in Multiwinner\n  Elections", "comments": "30 pages, 8 figures, 2 tables, 4 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The study of fairness in multiwinner elections focuses on settings where\ncandidates have attributes. However, voters may also be divided into predefined\npopulations under one or more attributes (e.g., \"California\" and \"Illinois\"\npopulations under the \"state\" attribute), which may be same or different from\ncandidate attributes. The models that focus on candidate attributes alone may\nsystematically under-represent smaller voter populations. Hence, we develop a\nmodel, DiRe Committee Winner Determination (DRCWD), which delineates candidate\nand voter attributes to select a committee by specifying diversity and\nrepresentation constraints and a voting rule. We show the generalizability of\nour model, and analyze its computational complexity, inapproximability, and\nparameterized complexity. We develop a heuristic-based algorithm, which finds\nthe winning DiRe committee in under two minutes on 63% of the instances of\nsynthetic datasets and on 100% of instances of real-world datasets. We present\nan empirical analysis of the running time, feasibility, and utility traded-off.\n  Overall, DRCWD motivates that a study of multiwinner elections should\nconsider both its actors, namely candidates and voters, as candidate-specific\n\"fair\" models can unknowingly harm voter populations, and vice versa.\nAdditionally, even when the attributes of candidates and voters coincide, it is\nimportant to treat them separately as having a female candidate on the\ncommittee, for example, is different from having a candidate on the committee\nwho is preferred by the female voters, and who themselves may or may not be\nfemale.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:32:56 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Relia", "Kunal", ""]]}, {"id": "2107.07361", "submitter": "Lorenzo Lucchini", "authors": "Lorenzo Lucchini, Luca Maria Aiello, Laura Alessandretti, Gianmarco De\n  Francisci Morales, Michele Starnini, Andrea Baronchelli", "title": "From Reddit to Wall Street: The role of committed minorities in\n  financial collective action", "comments": "Main: 9 pages, 3 figures, 3 tables. Supplementary: 7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In January 2021, retail investors coordinated on Reddit to target short\nselling activity by hedge funds on GameStop shares, causing a surge in the\nshare price and triggering significant losses for the funds involved. Such an\neffective collective action was unprecedented in finance, and its dynamics\nremain unclear. Here, we analyse Reddit and financial data and rationalise the\nevents based on recent findings describing how a small fraction of committed\nindividuals may trigger behavioural cascades. First, we operationalise the\nconcept of individual commitment in financial discussions. Second, we show that\nthe increase of commitment within Reddit predated the initial surge in price.\nThird, we reveal that initial committed users occupied a central position in\nthe network of Reddit conversations. Finally, we show that the social identity\nof the broader Reddit community grew as the collective action unfolded. These\nfindings shed light on financial collective action, as several observers\nanticipate it will grow in importance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 14:39:07 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Lucchini", "Lorenzo", ""], ["Aiello", "Luca Maria", ""], ["Alessandretti", "Laura", ""], ["Morales", "Gianmarco De Francisci", ""], ["Starnini", "Michele", ""], ["Baronchelli", "Andrea", ""]]}, {"id": "2107.07393", "submitter": "Vijay Keswani", "authors": "Vijay Keswani and L. Elisa Celis", "title": "Auditing for Diversity using Representative Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing the diversity of a dataset of information associated with people is\ncrucial before using such data for downstream applications. For a given\ndataset, this often involves computing the imbalance or disparity in the\nempirical marginal distribution of a protected attribute (e.g. gender, dialect,\netc.). However, real-world datasets, such as images from Google Search or\ncollections of Twitter posts, often do not have protected attributes labeled.\nConsequently, to derive disparity measures for such datasets, the elements need\nto hand-labeled or crowd-annotated, which are expensive processes.\n  We propose a cost-effective approach to approximate the disparity of a given\nunlabeled dataset, with respect to a protected attribute, using a control set\nof labeled representative examples. Our proposed algorithm uses the pairwise\nsimilarity between elements in the dataset and elements in the control set to\neffectively bootstrap an approximation to the disparity of the dataset.\nImportantly, we show that using a control set whose size is much smaller than\nthe size of the dataset is sufficient to achieve a small approximation error.\nFurther, based on our theoretical framework, we also provide an algorithm to\nconstruct adaptive control sets that achieve smaller approximation errors than\nrandomly chosen control sets. Simulations on two image datasets and one Twitter\ndataset demonstrate the efficacy of our approach (using random and adaptive\ncontrol sets) in auditing the diversity of a wide variety of datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 15:21:17 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Keswani", "Vijay", ""], ["Celis", "L. Elisa", ""]]}, {"id": "2107.07552", "submitter": "Khahlil Louisy", "authors": "Maria Carnovale, Khahlil Louisy", "title": "Public Health, Technology, and Human Rights: Lessons from Digital\n  Contact Tracing", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To mitigate inefficiencies in manual contact tracing processes, Digital\nContact Tracing and Exposure Notifications Systems were developed for use as\npublic-interest technologies during the SARS-CoV-2 global pandemic. Effective\nimplementation of these tools requires alignment across several factors,\nincluding local regulations and policies and trust in government and public\nhealth officials. Careful consideration should also be made to minimize any\npotential conflicts with existing processes in public health which has\ndemonstrated effectiveness. Four unique cases-of Ireland, Guayaquil, Haiti, and\nthe Philippines-detailed in this paper will highlight the importance of\nupholding the principles of Scientific Validity, Necessity, Time Boundedness,\nand Proportionality.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 18:31:04 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Carnovale", "Maria", ""], ["Louisy", "Khahlil", ""]]}, {"id": "2107.07582", "submitter": "Venet Osmani", "authors": "Behrooz Mamandipoor, Wesley Yeung, Louis Agha-Mir-Salim, David J.\n  Stone, Venet Osmani, Leo Anthony Celi", "title": "Prediction of Blood Lactate Values in Critically Ill Patients: A\n  Retrospective Multi-center Cohort Study", "comments": "15 pages, 6 Appendices", "journal-ref": "J Clin Monit Comput. 2021 PMID: 34224051", "doi": "10.1007/s10877-021-00739-4", "report-no": null, "categories": "q-bio.QM cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose. Elevations in initially obtained serum lactate levels are strong\npredictors of mortality in critically ill patients. Identifying patients whose\nserum lactate levels are more likely to increase can alert physicians to\nintensify care and guide them in the frequency of tending the blood test. We\ninvestigate whether machine learning models can predict subsequent serum\nlactate changes.\n  Methods. We investigated serum lactate change prediction using the MIMIC-III\nand eICU-CRD datasets in internal as well as external validation of the eICU\ncohort on the MIMIC-III cohort. Three subgroups were defined based on the\ninitial lactate levels: i) normal group (<2 mmol/L), ii) mild group (2-4\nmmol/L), and iii) severe group (>4 mmol/L). Outcomes were defined based on\nincrease or decrease of serum lactate levels between the groups. We also\nperformed sensitivity analysis by defining the outcome as lactate change of\n>10% and furthermore investigated the influence of the time interval between\nsubsequent lactate measurements on predictive performance.\n  Results. The LSTM models were able to predict deterioration of serum lactate\nvalues of MIMIC-III patients with an AUC of 0.77 (95% CI 0.762-0.771) for the\nnormal group, 0.77 (95% CI 0.768-0.772) for the mild group, and 0.85 (95% CI\n0.840-0.851) for the severe group, with a slightly lower performance in the\nexternal validation.\n  Conclusion. The LSTM demonstrated good discrimination of patients who had\ndeterioration in serum lactate levels. Clinical studies are needed to evaluate\nwhether utilization of a clinical decision support tool based on these results\ncould positively impact decision-making and patient outcomes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 09:46:47 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Mamandipoor", "Behrooz", ""], ["Yeung", "Wesley", ""], ["Agha-Mir-Salim", "Louis", ""], ["Stone", "David J.", ""], ["Osmani", "Venet", ""], ["Celi", "Leo Anthony", ""]]}, {"id": "2107.07964", "submitter": "Bosubabu Sambana", "authors": "Bosubabu Sambana", "title": "Blockchain Technology: Bitcoins, Cryptocurrency and Applications", "comments": "7 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain is a decentralized ledger used to securely exchange digital\ncurrency, perform deals and transactions efficient manner, each user of the\nnetwork has access to the least copy of the encrypted ledger so that they can\nvalidate a new transaction. The blockchain ledger is a collection of all\nBitcoin transactions executed in the past. Basically, it's distributed database\nthat maintains continuously growing tamper-proof data structure blocks that\nholds batches of individual transactions. The completed blocks are added in a\nlinear and chronological order. Each block contains a timestamp and information\nlink which points to a previous block. Bitcoin is a peer-to-peer permissionless\nnetwork that allows every user to connect to the network and send new\ntransactions to verify and create new blocks. Satoshi Nakamoto described the\ndesign of Bitcoin digital currency in his research paper posted to a\ncryptography listserv 2008. Nakamoto's suggestion has solved the long-pending\nproblem of cryptography and laid the foundation stone for digital currency.\nThis paper explains the concept of bitcoin, its characteristics, the need for\nBlockchain, and how Bitcoin works. It attempts to highlight the role of\nBlockchain in shaping the future of banking , financial services, and the\nadoption of the Internet of Thinks and future Technologies.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:27:04 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Sambana", "Bosubabu", ""]]}, {"id": "2107.08027", "submitter": "Tanveer Khan", "authors": "Tanveer Khan, Antonis Michalas", "title": "Seeing and Believing: Evaluating the Trustworthiness of Twitter Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social networking and micro-blogging services, such as Twitter, play an\nimportant role in sharing digital information. Despite the popularity and\nusefulness of social media, there have been many instances where corrupted\nusers found ways to abuse it, as for instance, through raising or lowering\nuser's credibility. As a result, while social media facilitates an\nunprecedented ease of access to information, it also introduces a new challenge\n- that of ascertaining the credibility of shared information. Currently, there\nis no automated way of determining which news or users are credible and which\nare not. Hence, establishing a system that can measure the social media user's\ncredibility has become an issue of great importance. Assigning a credibility\nscore to a user has piqued the interest of not only the research community but\nalso most of the big players on both sides - such as Facebook, on the side of\nindustry, and political parties on the societal one. In this work, we created a\nmodel which, we hope, will ultimately facilitate and support the increase of\ntrust in the social network communities. Our model collected data and analysed\nthe behaviour of~50,000 politicians on Twitter. Influence score, based on\nseveral chosen features, was assigned to each evaluated user. Further, we\nclassified the political Twitter users as either trusted or untrusted using\nrandom forest, multilayer perceptron, and support vector machine. An active\nlearning model was used to classify any unlabelled ambiguous records from our\ndataset. Finally, to measure the performance of the proposed model, we used\nprecision, recall, F1 score, and accuracy as the main evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:39:32 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 08:35:15 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Khan", "Tanveer", ""], ["Michalas", "Antonis", ""]]}, {"id": "2107.08034", "submitter": "Tim Weninger PhD", "authors": "Pamela Bilo Thomas, Clark Hogan-Taylor, Michael Yankoski, Tim Weninger", "title": "Pilot Study Suggests Online Media Literacy Programming Reduces Belief in\n  False News in Indonesia", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Amidst the threat of digital misinformation, we offer a pilot study regarding\nthe efficacy of an online social media literacy campaign aimed at empowering\nindividuals in Indonesia with skills to help them identify misinformation. We\nfound that users who engaged with our online training materials and educational\nvideos were more likely to identify misinformation than those in our control\ngroup (total $N$=1000). Given the promising results of our preliminary study,\nwe plan to expand efforts in this area, and build upon lessons learned from\nthis pilot study.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:56:27 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Thomas", "Pamela Bilo", ""], ["Hogan-Taylor", "Clark", ""], ["Yankoski", "Michael", ""], ["Weninger", "Tim", ""]]}, {"id": "2107.08045", "submitter": "Carlos Mougan", "authors": "Carlos Mougan Navarro, Georgios Kanellos, Thomas Gottron", "title": "Desiderata for Explainable AI in statistical production systems of the\n  European Central Bank", "comments": "Submitted for review at European Congress of Machine Learning\n  (ECMLPKDD) - 2ND Worksho on bias and fairness in AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable AI constitutes a fundamental step towards establishing fairness\nand addressing bias in algorithmic decision-making. Despite the large body of\nwork on the topic, the benefit of solutions is mostly evaluated from a\nconceptual or theoretical point of view and the usefulness for real-world use\ncases remains uncertain. In this work, we aim to state clear user-centric\ndesiderata for explainable AI reflecting common explainability needs\nexperienced in statistical production systems of the European Central Bank. We\nlink the desiderata to archetypical user roles and give examples of techniques\nand methods which can be used to address the user's needs. To this end, we\nprovide two concrete use cases from the domain of statistical data production\nin central banks: the detection of outliers in the Centralised Securities\nDatabase and the data-driven identification of data quality checks for the\nSupervisory Banking data system.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 05:58:11 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Navarro", "Carlos Mougan", ""], ["Kanellos", "Georgios", ""], ["Gottron", "Thomas", ""]]}, {"id": "2107.08096", "submitter": "Divya Shanmugam", "authors": "Divya Shanmugam, Samira Shabanian, Fernando Diaz, Mich\\`ele Finck,\n  Asia Biega", "title": "Learning to Limit Data Collection via Scaling Laws: Data Minimization\n  Compliance in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data minimization is a legal obligation defined in the European Union's\nGeneral Data Protection Regulation (GDPR) as the responsibility to process an\nadequate, relevant, and limited amount of personal data in relation to a\nprocessing purpose. However, unlike fairness or transparency, the principle has\nnot seen wide adoption for machine learning systems due to a lack of\ncomputational interpretation. In this paper, we build on literature in machine\nlearning and law to propose the first learning framework for limiting data\ncollection based on an interpretation that ties the data collection purpose to\nsystem performance. We formalize a data minimization criterion based on\nperformance curve derivatives and provide an effective and interpretable\npiecewise power law technique that models distinct stages of an algorithm's\nperformance throughout data collection. Results from our empirical\ninvestigation offer deeper insights into the relevant considerations when\ndesigning a data minimization framework, including the choice of feature\nacquisition algorithm, initialization conditions, as well as impacts on\nindividuals that hint at tensions between data minimization and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 19:59:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Shanmugam", "Divya", ""], ["Shabanian", "Samira", ""], ["Diaz", "Fernando", ""], ["Finck", "Mich\u00e8le", ""], ["Biega", "Asia", ""]]}, {"id": "2107.08122", "submitter": "Gordana Dodig Crnkovic", "authors": "Gordana Dodig-Crnkovic, Tobias Holstein, Patrizio Pelliccione", "title": "Future Intelligent Autonomous Robots, Ethical by Design. Learning from\n  Autonomous Cars Ethics", "comments": "11 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of the intelligent autonomous robot technology presupposes its\nanticipated beneficial effect on the individuals and societies. In the case of\nsuch disruptive emergent technology, not only questions of how to build, but\nalso why to build and with what consequences are important. The field of ethics\nof intelligent autonomous robotic cars is a good example of research with\nactionable practical value, where a variety of stakeholders, including the\nlegal system and other societal and governmental actors, as well as companies\nand businesses, collaborate bringing about shared view of ethics and societal\naspects of technology. It could be used as a starting platform for the\napproaches to the development of intelligent autonomous robots in general,\nconsidering human-machine interfaces in different phases of the life cycle of\ntechnology - the development, implementation, testing, use and disposal.\nDrawing from our work on ethics of autonomous intelligent robocars, and the\nexisting literature on ethics of robotics, our contribution consists of a set\nof values and ethical principles with identified challenges and proposed\napproaches for meeting them. This may help stakeholders in the field of\nintelligent autonomous robotics to connect ethical principles with their\napplications. Our recommendations of ethical requirements for autonomous cars\ncan be used for other types of intelligent autonomous robots, with the caveat\nfor social robots that require more research regarding interactions with the\nusers. We emphasize that existing ethical frameworks need to be applied in a\ncontext-sensitive way, by assessments in interdisciplinary, multi-competent\nteams through multi-criteria analysis. Furthermore, we argue for the need of a\ncontinuous development of ethical principles, guidelines, and regulations,\ninformed by the progress of technologies and involving relevant stakeholders.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 21:10:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Dodig-Crnkovic", "Gordana", ""], ["Holstein", "Tobias", ""], ["Pelliccione", "Patrizio", ""]]}, {"id": "2107.08176", "submitter": "Peixin Zhang", "authors": "Peixin Zhang, Jingyi Wang, Jun Sun, Xinyu Wang, Guoliang Dong, Xingen\n  Wang, Ting Dai, Jin Song Dong", "title": "Automatic Fairness Testing of Neural Classifiers through Adversarial\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has demonstrated astonishing performance in many\napplications, there are still concerns about its dependability. One desirable\nproperty of deep learning applications with societal impact is fairness (i.e.,\nnon-discrimination). Unfortunately, discrimination might be intrinsically\nembedded into the models due to the discrimination in the training data. As a\ncountermeasure, fairness testing systemically identifies discriminatory\nsamples, which can be used to retrain the model and improve the model's\nfairness. Existing fairness testing approaches however have two major\nlimitations. Firstly, they only work well on traditional machine learning\nmodels and have poor performance (e.g., effectiveness and efficiency) on deep\nlearning models. Secondly, they only work on simple structured (e.g., tabular)\ndata and are not applicable for domains such as text. In this work, we bridge\nthe gap by proposing a scalable and effective approach for systematically\nsearching for discriminatory samples while extending existing fairness testing\napproaches to address a more challenging domain, i.e., text classification.\nCompared with state-of-the-art methods, our approach only employs lightweight\nprocedures like gradient computation and clustering, which is significantly\nmore scalable and effective. Experimental results show that on average, our\napproach explores the search space much more effectively (9.62 and 2.38 times\nmore than the state-of-the-art methods respectively on tabular and text\ndatasets) and generates much more discriminatory samples (24.95 and 2.68 times)\nwithin a same reasonable time. Moreover, the retrained models reduce\ndiscrimination by 57.2% and 60.2% respectively on average.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 03:47:08 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 05:09:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Zhang", "Peixin", ""], ["Wang", "Jingyi", ""], ["Sun", "Jun", ""], ["Wang", "Xinyu", ""], ["Dong", "Guoliang", ""], ["Wang", "Xingen", ""], ["Dai", "Ting", ""], ["Dong", "Jin Song", ""]]}, {"id": "2107.08189", "submitter": "Anand Avati", "authors": "Anand Avati, Martin Seneviratne, Emily Xue, Zhen Xu, Balaji\n  Lakshminarayanan and Andrew M. Dai", "title": "BEDS-Bench: Behavior of EHR-models under Distributional Shift--A\n  Benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has recently demonstrated impressive progress in predictive\naccuracy across a wide array of tasks. Most ML approaches focus on\ngeneralization performance on unseen data that are similar to the training data\n(In-Distribution, or IND). However, real world applications and deployments of\nML rarely enjoy the comfort of encountering examples that are always IND. In\nsuch situations, most ML models commonly display erratic behavior on\nOut-of-Distribution (OOD) examples, such as assigning high confidence to wrong\npredictions, or vice-versa. Implications of such unusual model behavior are\nfurther exacerbated in the healthcare setting, where patient health can\npotentially be put at risk. It is crucial to study the behavior and robustness\nproperties of models under distributional shift, understand common failure\nmodes, and take mitigation steps before the model is deployed. Having a\nbenchmark that shines light upon these aspects of a model is a first and\nnecessary step in addressing the issue. Recent work and interest in increasing\nmodel robustness in OOD settings have focused more on image modality, while the\nElectronic Health Record (EHR) modality is still largely under-explored. We aim\nto bridge this gap by releasing BEDS-Bench, a benchmark for quantifying the\nbehavior of ML models over EHR data under OOD settings. We use two open access,\nde-identified EHR datasets to construct several OOD data settings to run tests\non, and measure relevant metrics that characterize crucial aspects of a model's\nOOD behavior. We evaluate several learning algorithms under BEDS-Bench and find\nthat all of them show poor generalization performance under distributional\nshift in general. Our results highlight the need and the potential to improve\nrobustness of EHR models under distributional shift, and BEDS-Bench provides\none way to measure progress towards that goal.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 05:53:24 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Avati", "Anand", ""], ["Seneviratne", "Martin", ""], ["Xue", "Emily", ""], ["Xu", "Zhen", ""], ["Lakshminarayanan", "Balaji", ""], ["Dai", "Andrew M.", ""]]}, {"id": "2107.08217", "submitter": "Joseph Chow", "authors": "Qi Liu, Joseph Y. J. Chow", "title": "A congested schedule-based dynamic transit passenger flow estimator\n  using stop count data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A dynamic transit flow estimation model based on congested schedule-based\ntransit equilibrium assignment is proposed using observations from stop count\ndata. A solution algorithm is proposed for the mathematical program with\nschedule-based transit equilibrium constraints (MPEC) with computational\ncomplexity of O(N^2 L) where N and L represent the number of stops and transit\nlines respectively. The equilibrium constraints corresponding to the\nschedule-based hyperpath flow is adapted from the literature with some\nmodifications to fit it into an estimation problem. Computational experiments\nare conducted first to verify the methodology with two synthetic data sets (one\nof which is Sioux Falls), followed by a validation of the method using bus data\nfrom Qingpu District in Shanghai, China from July 1, 2016, with 4 bus lines,\n120 segments, 55 bus stops, and 120 one-minute intervals; this is one of the\nlargest implementation of the schedule-based assignment model with congestion\neffects in the literature and the first for passenger flow estimation based on\nit. The estimation model converged to 0.005 tolerance of relative change in 10\niterations. The estimated average of segment flows are only 2.5% off from the\naverage of the observed segment flows; relative errors among segments are\n42.5%, which compares well with OD estimation methods applied to real data in\nthe literature (e.g. Irvine network, Brescia motorway).\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 10:52:57 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Qi", ""], ["Chow", "Joseph Y. J.", ""]]}, {"id": "2107.08319", "submitter": "Karishma Sharma", "authors": "Karishma Sharma and Emilio Ferrara and Yan Liu", "title": "Characterizing Online Engagement with Disinformation and Conspiracies in\n  the 2020 U.S. Presidential Election", "comments": "Accepted at ICWSM'22", "journal-ref": "ICWSM 2022", "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying and characterizing disinformation in political discourse on\nsocial media is critical to ensure the integrity of elections and democratic\nprocesses around the world. Persistent manipulation of social media has\nresulted in increased concerns regarding the 2020 U.S. Presidential Election,\ndue to its potential to influence individual opinions and social dynamics. In\nthis work, we focus on the identification of distorted facts, in the form of\nunreliable and conspiratorial narratives in election-related tweets, to\ncharacterize discourse manipulation prior to the election. We apply a detection\nmodel to separate factual from unreliable (or conspiratorial) claims analyzing\na dataset of 242 million election-related tweets. The identified claims are\nused to investigate targeted topics of disinformation, and conspiracy groups,\nmost notably the far-right QAnon conspiracy group. Further, we characterize\naccount engagements with unreliable and conspiracy tweets, and with the QAnon\nconspiracy group, by political leaning and tweet types. Finally, using a\nregression discontinuity design, we investigate whether Twitter's actions to\ncurb QAnon activity on the platform were effective, and how QAnon accounts\nadapt to Twitter's restrictions.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 22:11:13 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sharma", "Karishma", ""], ["Ferrara", "Emilio", ""], ["Liu", "Yan", ""]]}, {"id": "2107.08348", "submitter": "Dipankar Chaki", "authors": "Dipankar Chaki and Athman Bouguettaya", "title": "Adaptive Priority-based Conflict Resolution of IoT Services", "comments": "6 pages, 7 figures. Accepted paper and to appear in the Proceedings\n  of the 2021 IEEE International Conference on Web Services (IEEE ICWS 2021)\n  affiliated with the 2021 IEEE World Congress on Services (IEEE SERVICES 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel conflict resolution framework for IoT services in\nmulti-resident smart homes. An adaptive priority model is developed considering\nthe residents' contextual factors (e.g., age, illness, impairment). The\nproposed priority model is designed using the concept of the analytic hierarchy\nprocess. A set of experiments on real-world datasets are conducted to show the\nefficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 02:41:26 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chaki", "Dipankar", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "2107.08362", "submitter": "Bing Sun", "authors": "Bing Sun, Jun Sun, Ting Dai, Lijun Zhang", "title": "Probabilistic Verification of Neural Networks Against Group Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is crucial for neural networks which are used in applications with\nimportant societal implication. Recently, there have been multiple attempts on\nimproving fairness of neural networks, with a focus on fairness testing (e.g.,\ngenerating individual discriminatory instances) and fairness training (e.g.,\nenhancing fairness through augmented training). In this work, we propose an\napproach to formally verify neural networks against fairness, with a focus on\nindependence-based fairness such as group fairness. Our method is built upon an\napproach for learning Markov Chains from a user-provided neural network (i.e.,\na feed-forward neural network or a recurrent neural network) which is\nguaranteed to facilitate sound analysis. The learned Markov Chain not only\nallows us to verify (with Probably Approximate Correctness guarantee) whether\nthe neural network is fair or not, but also facilities sensitivity analysis\nwhich helps to understand why fairness is violated. We demonstrate that with\nour analysis results, the neural weights can be optimized to improve fairness.\nOur approach has been evaluated with multiple models trained on benchmark\ndatasets and the experiment results show that our approach is effective and\nefficient.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 04:34:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sun", "Bing", ""], ["Sun", "Jun", ""], ["Dai", "Ting", ""], ["Zhang", "Lijun", ""]]}, {"id": "2107.08720", "submitter": "Marco Guerini", "authors": "Margherita Fanton, Helena Bonaldi, Serra Sinem Tekiroglu, Marco\n  Guerini", "title": "Human-in-the-Loop for Data Collection: a Multi-Target Counter Narrative\n  Dataset to Fight Online Hate Speech", "comments": "To appear at ACL 2021 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undermining the impact of hateful content with informed and non-aggressive\nresponses, called counter narratives, has emerged as a possible solution for\nhaving healthier online communities. Thus, some NLP studies have started\naddressing the task of counter narrative generation. Although such studies have\nmade an effort to build hate speech / counter narrative (HS/CN) datasets for\nneural generation, they fall short in reaching either high-quality and/or\nhigh-quantity. In this paper, we propose a novel human-in-the-loop data\ncollection methodology in which a generative language model is refined\niteratively by using its own data from the previous loops to generate new\ntraining samples that experts review and/or post-edit. Our experiments\ncomprised several loops including dynamic variations. Results show that the\nmethodology is scalable and facilitates diverse, novel, and cost-effective data\ncollection. To our knowledge, the resulting dataset is the only expert-based\nmulti-target HS/CN dataset available to the community.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 09:45:54 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Fanton", "Margherita", ""], ["Bonaldi", "Helena", ""], ["Tekiroglu", "Serra Sinem", ""], ["Guerini", "Marco", ""]]}, {"id": "2107.08821", "submitter": "Jie Ren", "authors": "Quanshi Zhang, Tian Han, Lixin Fan, Zhanxing Zhu, Hang Su, Ying Nian\n  Wu, Jie Ren, Hao Zhang", "title": "Proceedings of ICML 2021 Workshop on Theoretic Foundation, Criticism,\n  and Application Trend of Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the Proceedings of ICML 2021 Workshop on Theoretic Foundation,\nCriticism, and Application Trend of Explainable AI. Deep neural networks (DNNs)\nhave undoubtedly brought great success to a wide range of applications in\ncomputer vision, computational linguistics, and AI. However, foundational\nprinciples underlying the DNNs' success and their resilience to adversarial\nattacks are still largely missing. Interpreting and theorizing the internal\nmechanisms of DNNs becomes a compelling yet controversial topic. This workshop\npays a special interest in theoretic foundations, limitations, and new\napplication trends in the scope of XAI. These issues reflect new bottlenecks in\nthe future development of XAI.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:14:16 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 12:34:33 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Zhang", "Quanshi", ""], ["Han", "Tian", ""], ["Fan", "Lixin", ""], ["Zhu", "Zhanxing", ""], ["Su", "Hang", ""], ["Wu", "Ying Nian", ""], ["Ren", "Jie", ""], ["Zhang", "Hao", ""]]}, {"id": "2107.08946", "submitter": "Kimon Kieslich", "authors": "Marco L\\\"unich, Kimon Kieslich", "title": "Using automated decision-making (ADM) to allocate Covid-19 vaccinations?\n  Exploring the roles of trust and social group preference on the legitimacy of\n  ADM vs. human decision-making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In combating the ongoing global health threat of the Covid-19 pandemic,\ndecision-makers have to take actions based on a multitude of relevant health\ndata with severe potential consequences for the affected patients. Because of\ntheir presumed advantages in handling and analyzing vast amounts of data,\ncomputer systems of automated decision-making (ADM) are implemented and\nsubstitute humans in decision-making processes. In this study, we focus on a\nspecific application of ADM in contrast to human decision-making (HDM), namely\nthe allocation of Covid-19 vaccines to the public. In particular, we elaborate\non the role of trust and social group preference on the legitimacy of vaccine\nallocation. We conducted a survey with a 2x2 randomized factorial design among\nn=1602 German respondents, in which we utilized distinct decision-making agents\n(HDM vs. ADM) and prioritization of a specific social group (teachers vs.\nprisoners) as design factors. Our findings show that general trust in ADM\nsystems and preference for vaccination of a specific social group influence the\nlegitimacy of vaccine allocation. However, contrary to our expectations, trust\nin the agent making the decision did not moderate the link between social group\npreference and legitimacy. Moreover, the effect was also not moderated by the\ntype of decision-maker (human vs. algorithm). We conclude that trustworthy ADM\nsystems must not necessarily lead to the legitimacy of ADM systems.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:00:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["L\u00fcnich", "Marco", ""], ["Kieslich", "Kimon", ""]]}, {"id": "2107.08959", "submitter": "Matthew Sun", "authors": "Eli Lucherini, Matthew Sun, Amy Winecoff, Arvind Narayanan", "title": "T-RECS: A Simulation Tool to Study the Societal Impact of Recommender\n  Systems", "comments": "17 pages, 5 figures; updated Figure 2(b) after fixing small bug in\n  replication code (see Github for more details)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation has emerged as a popular method to study the long-term societal\nconsequences of recommender systems. This approach allows researchers to\nspecify their theoretical model explicitly and observe the evolution of\nsystem-level outcomes over time. However, performing simulation-based studies\noften requires researchers to build their own simulation environments from the\nground up, which creates a high barrier to entry, introduces room for\nimplementation error, and makes it difficult to disentangle whether observed\noutcomes are due to the model or the implementation.\n  We introduce T-RECS, an open-sourced Python package designed for researchers\nto simulate recommendation systems and other types of sociotechnical systems in\nwhich an algorithm mediates the interactions between multiple stakeholders,\nsuch as users and content creators. To demonstrate the flexibility of T-RECS,\nwe perform a replication of two prior simulation-based research on\nsociotechnical systems. We additionally show how T-RECS can be used to generate\nnovel insights with minimal overhead. Our tool promotes reproducibility in this\narea of research, provides a unified language for simulating sociotechnical\nsystems, and removes the friction of implementing simulations from scratch.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:16:44 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 00:52:04 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Lucherini", "Eli", ""], ["Sun", "Matthew", ""], ["Winecoff", "Amy", ""], ["Narayanan", "Arvind", ""]]}, {"id": "2107.09044", "submitter": "Evan Liu", "authors": "Evan Zheran Liu, Behzad Haghgoo, Annie S. Chen, Aditi Raghunathan,\n  Pang Wei Koh, Shiori Sagawa, Percy Liang, Chelsea Finn", "title": "Just Train Twice: Improving Group Robustness without Training Group\n  Information", "comments": "International Conference on Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard training via empirical risk minimization (ERM) can produce models\nthat achieve high accuracy on average but low accuracy on certain groups,\nespecially in the presence of spurious correlations between the input and\nlabel. Prior approaches that achieve high worst-group accuracy, like group\ndistributionally robust optimization (group DRO) require expensive group\nannotations for each training point, whereas approaches that do not use such\ngroup annotations typically achieve unsatisfactory worst-group accuracy. In\nthis paper, we propose a simple two-stage approach, JTT, that first trains a\nstandard ERM model for several epochs, and then trains a second model that\nupweights the training examples that the first model misclassified.\nIntuitively, this upweights examples from groups on which standard ERM models\nperform poorly, leading to improved worst-group performance. Averaged over four\nimage classification and natural language processing tasks with spurious\ncorrelations, JTT closes 75% of the gap in worst-group accuracy between\nstandard ERM and group DRO, while only requiring group annotations on a small\nvalidation set in order to tune hyperparameters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 17:52:32 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Liu", "Evan Zheran", ""], ["Haghgoo", "Behzad", ""], ["Chen", "Annie S.", ""], ["Raghunathan", "Aditi", ""], ["Koh", "Pang Wei", ""], ["Sagawa", "Shiori", ""], ["Liang", "Percy", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.09163", "submitter": "Maria De-Arteaga", "authors": "Sina Fazelpour, Maria De-Arteaga", "title": "Diversity in Sociotechnical Machine Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a surge of recent interest in sociocultural diversity in\nmachine learning (ML) research, with researchers (i) examining the benefits of\ndiversity as an organizational solution for alleviating problems with\nalgorithmic bias, and (ii) proposing measures and methods for implementing\ndiversity as a design desideratum in the construction of predictive algorithms.\nCurrently, however, there is a gap between discussions of measures and benefits\nof diversity in ML, on the one hand, and the broader research on the underlying\nconcepts of diversity and the precise mechanisms of its functional benefits, on\nthe other. This gap is problematic because diversity is not a monolithic\nconcept. Rather, different concepts of diversity are based on distinct\nrationales that should inform how we measure diversity in a given context.\nSimilarly, the lack of specificity about the precise mechanisms underpinning\ndiversity's potential benefits can result in uninformative generalities,\ninvalid experimental designs, and illicit interpretations of findings. In this\nwork, we draw on research in philosophy, psychology, and social and\norganizational sciences to make three contributions: First, we introduce a\ntaxonomy of different diversity concepts from philosophy of science, and\nexplicate the distinct epistemic and political rationales underlying these\nconcepts. Second, we provide an overview of mechanisms by which diversity can\nbenefit group performance. Third, we situate these taxonomies--of concepts and\nmechanisms--in the lifecycle of sociotechnical ML systems and make a case for\ntheir usefulness in fair and accountable ML. We do so by illustrating how they\nclarify the discourse around diversity in the context of ML systems, promote\nthe formulation of more precise research questions about diversity's impact,\nand provide conceptual tools to further advance research and practice.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 21:26:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Fazelpour", "Sina", ""], ["De-Arteaga", "Maria", ""]]}, {"id": "2107.09176", "submitter": "Qing Ke", "authors": "Chao Min, Qing Ke", "title": "Temporal search in the scientific space predicts breakthrough inventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of inventions is theorized as a process of searching and\nrecombining existing knowledge components. Previous studies under this theory\nhave examined myriad characteristics of recombined knowledge and their\nperformance implications. One feature that has received much attention is\ntechnological knowledge age. Yet, little is known about how the age of\nscientific knowledge influences the impact of inventions, despite the widely\nknown catalyzing role of science in the creation of new technologies. Here we\nuse a large corpus of patents and derive features characterizing how patents\ntemporally search in the scientific space. We find that patents that cite\nscientific papers have more citations and substantially more likely to become\nbreakthroughs. Conditional on searching in the scientific space, referencing\nmore recent papers increases the impact of patents and the likelihood of being\nbreakthroughs. However, this positive effect can be offset if patents cite\npapers whose ages exhibit a low variance. These effects are consistent across\ntechnological fields.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 22:08:33 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Min", "Chao", ""], ["Ke", "Qing", ""]]}, {"id": "2107.09183", "submitter": "Richard Kuzma", "authors": "Richard Kuzma, Iain J. Cruickshank, Kathleen M. Carley", "title": "Analysis of External Content in the Vaccination Discussion on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 22:47:17 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kuzma", "Richard", ""], ["Cruickshank", "Iain J.", ""], ["Carley", "Kathleen M.", ""]]}, {"id": "2107.09217", "submitter": "Shuting Jin", "authors": "Shuting Jin, Xiangxiang Zeng, Wei Huang, Feng Xia, Changzhi Jiang,\n  Xiangrong Liu and Shaoliang Peng", "title": "Heterogeneous network-based drug repurposing for COVID-19", "comments": "5 pages, 3 figures, ICLR 2021 MLPCP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Corona Virus Disease 2019 (COVID-19) belongs to human coronaviruses\n(HCoVs), which spreads rapidly around the world. Compared with new drug\ndevelopment, drug repurposing may be the best shortcut for treating COVID-19.\nTherefore, we constructed a comprehensive heterogeneous network based on the\nHCoVs-related target proteins and use the previously proposed deepDTnet, to\ndiscover potential drug candidates for COVID-19. We obtain high performance in\npredicting the possible drugs effective for COVID-19 related proteins. In\nsummary, this work utilizes a powerful heterogeneous network-based deep\nlearning method, which may be beneficial to quickly identify candidate\nrepurposable drugs toward future clinical trials for COVID-19. The code and\ndata are available at https://github.com/stjin-XMU/HnDR-COVID.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 01:24:40 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Jin", "Shuting", ""], ["Zeng", "Xiangxiang", ""], ["Huang", "Wei", ""], ["Xia", "Feng", ""], ["Jiang", "Changzhi", ""], ["Liu", "Xiangrong", ""], ["Peng", "Shaoliang", ""]]}, {"id": "2107.09283", "submitter": "Hyunji Chung", "authors": "Jungheum Park, Hyunji Chung", "title": "Toward Trustworthy Urban IT Systems: The Bright and Dark Sides of Smart\n  City Development", "comments": "1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In smart cities built on information and communication technology, citizens\nand various IT systems interoperate in harmony. Cloud computing and\nInternet-of-Things technologies that have been developed for a long time are\nmaking modern cities smarter. Smart cities can have a positive impact on\ncitizens, but they can also make cities dangerous. Today, with the emerging\nreality of smart cities, this paper looks at both the bright and dark sides and\nprovides a foundation for supporting work-related tasks of IT professionals as\nwell as non-IT experts involved in urban design and development.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 06:54:08 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Park", "Jungheum", ""], ["Chung", "Hyunji", ""]]}, {"id": "2107.09284", "submitter": "Hyunji Chung", "authors": "Jungheum Park, Hyunji Chung, Joanna F. DeFranco", "title": "Multi-Layered Diagnostics for Smart Cities", "comments": "1 figure, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Smart cities use technology to improve traffic patterns, energy distribution,\nair quality and more. The elements of a smart city can also increase the\nconvenience for its citizens, by integrating IT technology into many aspects of\ncitizen interaction such as simplifying access to many of the city services.\nThe fields of healthcare, education, culture, and shopping can all be\nintegrated into the core of a smart city to create an infrastructure that\nallows citizens to live more conveniently. Actual deployment cases exist in\nU.S., Europe, Singapore, and South Korea. With this environment, we need to\nthink ahead about cybersecurity and prepare countermeasures as the cyberattacks\nin a smart city can threaten the lives of its citizens. In this paper, we\nexamine smart city security threats from a multilayered perspective, targeting\nrepresentative elements that make up a smart city. A summary of attack\nscenarios and threat countermeasures are also described.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 06:58:11 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Park", "Jungheum", ""], ["Chung", "Hyunji", ""], ["DeFranco", "Joanna F.", ""]]}, {"id": "2107.09415", "submitter": "Rogier van de Wetering", "authors": "Rogier van de Wetering", "title": "IT ambidexterity driven patient agility and hospital patient service\n  performance: a variance approach", "comments": "12 pages, 2 figures, 1 Table. arXiv admin note: text overlap with\n  arXiv:2105.09013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Hospitals are currently exploring digital options to transform their clinical\nprocedures and their overall engagement with patients. This paper investigates\nhow hospital departments can leverage the ability of firms to simultaneously\nexplore new IT resources and practices (IT exploration) as well as exploit\ntheir current IT resources and practices (IT exploitation), i.e., IT\nambidexterity, to adequately sense and respond to patients' needs and demands,\ni.e., patient agility. This study embraces the dynamic capability view and\ndevelops a research model, and tests it accordingly using cross-sectional data\nfrom 90 clinical hospital departments from the Netherlands through an online\nsurvey. The model's hypothesized relationships are tested using Partial Least\nSquares (PLS) structural equation modeling (SEM). The outcomes demonstrate the\nsignificance of IT ambidexterity in developing patient agility, positively\ninfluencing patient service performance. The study outcomes support the\ntheorized model can the outcomes shed light on how to transform clinical\npractice and drive patient agility.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:23:22 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["van de Wetering", "Rogier", ""]]}, {"id": "2107.09419", "submitter": "Rogier van de Wetering", "authors": "Rogier van de Wetering and Johan Versendaal", "title": "The role of IT ambidexterity, digital dynamic capability and knowledge\n  processes as enablers of patient agility: an empirical study", "comments": "23 pages, 2 figures, 5 tables. arXiv admin note: text overlap with\n  arXiv:2105.09013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a limited understanding of IT's role as a crucial enabler of patient\nagility and the department's ability to respond to patient's needs and wishes\nadequately. This study's objective is to contribute to the insights of the\nvalidity of the hypothesized relationship between IT resources, practices and\ncapabilities, and hospital departments' knowledge processes and the\ndepartment's ability to adequately sense and respond to patient needs and\nwishes, i.e., patient agility. This study conveniently sampled data from 107\nclinical hospital departments in the Netherlands and uses structural equation\nmodeling for model assessment. IT ambidexterity positively enhances the\ndevelopment of a digital dynamic capability. Likewise, IT ambidexterity also\npositively impacts the hospital department's knowledge processes. Both digital\ndynamic capability and knowledge processes positively influence patient\nagility. IT ambidexterity promotes taking advantage of IT resources and\nexperiments to reshape patient services and enhance patient agility.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 11:30:56 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["van de Wetering", "Rogier", ""], ["Versendaal", "Johan", ""]]}, {"id": "2107.09509", "submitter": "Himanshu Thapliyal", "authors": "Rajdeep Kumar Nath and Himanshu Thapliyal", "title": "Wearable Health Monitoring System for Older Adults in a Smart Home\n  Environment", "comments": "6 Pages, 2021 IEEE Computer Society Annual Symposium on VLSI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of IoT has enabled the design of connected and integrated smart\nhealth monitoring systems. These smart health monitoring systems could be\nrealized in a smart home context to render long-term care to the elderly\npopulation. In this paper, we present the design of a wearable health\nmonitoring system suitable for older adults in a smart home context. The\nproposed system offers solutions to monitor the stress, blood pressure, and\nlocation of an individual within a smart home environment. The stress detection\nmodel proposed in this work uses Electrodermal Activity (EDA),\nPhotoplethysmogram (PPG), and Skin Temperature (ST) sensors embedded in a smart\nwristband for detecting physiological stress. The stress detection model is\ntrained and tested using stress labels obtained from salivary cortisol which is\na clinically established biomarker for physiological stress. A voice-based\nprototype is also implemented and the feasibility of the proposed system for\nintegration in a smart home environment is analyzed by simulating a data\nacquisition and streaming scenario. We have also proposed a blood pressure\nestimation model using PPG signal and advanced regression techniques for\nintegration with the stress detection model in the wearable health monitoring\nsystem. Finally, the design of a voice-assisted indoor location system is\nproposed for integration with the proposed system within a smart home\nenvironment. The proposed wearable health monitoring system is an important\ndirection to realize a smart home environment with extensive diagnostic\ncapabilities so that such a system could be useful for rendering long-term and\npersonalized care to the aging population in the comfort of their home.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 03:16:54 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Nath", "Rajdeep Kumar", ""], ["Thapliyal", "Himanshu", ""]]}, {"id": "2107.09533", "submitter": "Rayed AlGhamdi", "authors": "Rayed Alghamdi, Seyed M. Buhari, Madini O. Alassafi", "title": "From Teaching to Coaching: A Case Study of a Technical Communication\n  Course", "comments": "Conference Paper", "journal-ref": "13th annual International Conference of Education, Research and\n  Innovation, 2020", "doi": "10.21125/iceri.2020.0285", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the leading university goals is to provide the students with the\nnecessary skills for better functioning in their future studies. Gaining and\ndeveloping skills, both technical and soft skills, are the critical building\nblocks for a successful career. The traditional teaching process, which\nincludes delivering lectures and conducting exams, emphasizes the upliftment of\ntechnical knowledge rather than building self-esteem and enhancing skills\ndevelopment among students. Development of non-technical skills like\nself-esteem, life-long learning among students is vital for a successful\ncareer. This paper targets to achieve the objective of identifying ways to\nempower students with non-technical skills along with technical skills. The\napproach adopted in this research work is to transform the delivery of a\nfaculty-wide course from teaching to coaching. One salient difference between\nteaching and coaching is to move students motivation away from grades towards\nlife-long learning. Thus, university students maximize skills through coaching\nlike course structure, course delivery, course assessment, and student\ninvolvement. As a case study, the proposed approach was successfully tested and\nvalidated on a course taught in the Faculty of Computing and Information\nTechnology (FCIT) at King Abdulaziz University (KAU). The outcome of this case\nstudy reveals that there is substantial potential towards enhancement of\nself-responsibility. In the future, this approach can be extended for other\ncourses that aim to develop skills such as English language courses, computer,\nand communication skills courses in the preparatory/foundation year.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 14:44:38 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Alghamdi", "Rayed", ""], ["Buhari", "Seyed M.", ""], ["Alassafi", "Madini O.", ""]]}, {"id": "2107.09546", "submitter": "Eike Petersen", "authors": "Eike Petersen, Yannik Potdevin, Esfandiar Mohammadi, Stephan Zidowitz,\n  Sabrina Breyer, Dirk Nowotka, Sandra Henn, Ludwig Pechmann, Martin Leucker,\n  Philipp Rostalski and Christian Herzog", "title": "Responsible and Regulatory Conform Machine Learning for Medicine: A\n  Survey of Technical Challenges and Solutions", "comments": "Preprint submitted to Artificial Intelligence in Medicine", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning is expected to fuel significant improvements in medical\ncare. To ensure that fundamental principles such as beneficence, respect for\nhuman autonomy, prevention of harm, justice, privacy, and transparency are\nrespected, medical machine learning applications must be developed responsibly.\nIn this paper, we survey the technical challenges involved in creating medical\nmachine learning systems responsibly and in conformity with existing\nregulations, as well as possible solutions to address these challenges. We\nbegin by providing a brief overview of existing regulations affecting medical\nmachine learning, showing that properties such as safety, robustness,\nreliability, privacy, security, transparency, explainability, and\nnondiscrimination are all demanded already by existing law and regulations -\nalbeit, in many cases, to an uncertain degree. Next, we discuss the underlying\ntechnical challenges, possible ways for addressing them, and their respective\nmerits and drawbacks. We notice that distribution shift, spurious correlations,\nmodel underspecification, and data scarcity represent severe challenges in the\nmedical context (and others) that are very difficult to solve with classical\nblack-box deep neural networks. Important measures that may help to address\nthese challenges include the use of large and representative datasets and\nfederated learning as a means to that end, the careful exploitation of domain\nknowledge wherever feasible, the use of inherently transparent models,\ncomprehensive model testing and verification, as well as stakeholder inclusion.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:03:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Petersen", "Eike", ""], ["Potdevin", "Yannik", ""], ["Mohammadi", "Esfandiar", ""], ["Zidowitz", "Stephan", ""], ["Breyer", "Sabrina", ""], ["Nowotka", "Dirk", ""], ["Henn", "Sandra", ""], ["Pechmann", "Ludwig", ""], ["Leucker", "Martin", ""], ["Rostalski", "Philipp", ""], ["Herzog", "Christian", ""]]}, {"id": "2107.09554", "submitter": "Nicolas Tempelmeier", "authors": "Nicolas Tempelmeier, Udo Feuerhake, Oskar Wage, Elena Demidova", "title": "Mining Topological Dependencies of Recurrent Congestion in Road Networks", "comments": null, "journal-ref": "ISPRS International Journal of Geo-Information 2021, 10(4)", "doi": "10.3390/ijgi10040248", "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The discovery of spatio-temporal dependencies within urban road networks that\ncause Recurrent Congestion (RC) patterns is crucial for numerous real-world\napplications, including urban planning and scheduling of public transportation\nservices. While most existing studies investigate temporal patterns of RC\nphenomena, the influence of the road network topology on RC is often\noverlooked. This article proposes the ST-Discovery algorithm, a novel\nunsupervised spatio-temporal data mining algorithm that facilitates the\neffective data-driven discovery of RC dependencies induced by the road network\ntopology using real-world traffic data. We factor out regularly reoccurring\ntraffic phenomena, such as rush hours, mainly induced by the daytime, by\nmodelling and systematically exploiting temporal traffic load outliers. We\npresent an algorithm that first constructs connected subgraphs of the road\nnetwork based on the traffic speed outliers. Second, the algorithm identifies\npairs of subgraphs that indicate spatio-temporal correlations in their traffic\nload behaviour to identify topological dependencies within the road network.\nFinally, we rank the identified subgraph pairs based on the dependency score\ndetermined by our algorithm. Our experimental results demonstrate that\nST-Discovery can effectively reveal topological dependencies in urban road\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:14:10 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Tempelmeier", "Nicolas", ""], ["Feuerhake", "Udo", ""], ["Wage", "Oskar", ""], ["Demidova", "Elena", ""]]}, {"id": "2107.09615", "submitter": "Zoya Bylinskii", "authors": "Sofie Beier, Sam Berlow, Esat Boucaud, Zoya Bylinskii, Tianyuan Cai,\n  Jenae Cohn, Kathy Crowley, Stephanie L. Day, Tilman Dingler, Jonathan Dobres,\n  Jennifer Healey, Rajiv Jain, Marjorie Jordan, Bernard Kerr, Qisheng Li, Dave\n  B. Miller, Susanne Nobles, Alexandra Papoutsaki, Jing Qian, Tina Rezvanian,\n  Shelley Rodrigo, Ben D. Sawyer, Shannon M. Sheppard, Bram Stein, Rick\n  Treitman, Jen Vanek, Shaun Wallace, Benjamin Wolfe", "title": "Readability Research: An Interdisciplinary Approach", "comments": "This paper was generated collaboratively over the course of a series\n  of online workshops, the results of which were extensively edited by Dr. Zoya\n  Bylinskii, Dr. Ben D. Sawyer, and Dr. Benjamin Wolfe. Original illustrations\n  by Bernard Kerr. Corresponding Author: Dr. Ben D. Sawyer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Readability is on the cusp of a revolution. Fixed text is becoming fluid as a\nproliferation of digital reading devices rewrite what a document can do. As\npast constraints make way for more flexible opportunities, there is great need\nto understand how reading formats can be tuned to the situation and the\nindividual. We aim to provide a firm foundation for readability research, a\ncomprehensive framework for modern, multi-disciplinary readability research.\nReadability refers to aspects of visual information design which impact\ninformation flow from the page to the reader. Readability can be enhanced by\nchanges to the set of typographical characteristics of a text. These aspects\ncan be modified on-demand, instantly improving the ease with which a reader can\nprocess and derive meaning from text. We call on a multi-disciplinary research\ncommunity to take up these challenges to elevate reading outcomes and provide\nthe tools to do so effectively.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 16:52:17 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Beier", "Sofie", ""], ["Berlow", "Sam", ""], ["Boucaud", "Esat", ""], ["Bylinskii", "Zoya", ""], ["Cai", "Tianyuan", ""], ["Cohn", "Jenae", ""], ["Crowley", "Kathy", ""], ["Day", "Stephanie L.", ""], ["Dingler", "Tilman", ""], ["Dobres", "Jonathan", ""], ["Healey", "Jennifer", ""], ["Jain", "Rajiv", ""], ["Jordan", "Marjorie", ""], ["Kerr", "Bernard", ""], ["Li", "Qisheng", ""], ["Miller", "Dave B.", ""], ["Nobles", "Susanne", ""], ["Papoutsaki", "Alexandra", ""], ["Qian", "Jing", ""], ["Rezvanian", "Tina", ""], ["Rodrigo", "Shelley", ""], ["Sawyer", "Ben D.", ""], ["Sheppard", "Shannon M.", ""], ["Stein", "Bram", ""], ["Treitman", "Rick", ""], ["Vanek", "Jen", ""], ["Wallace", "Shaun", ""], ["Wolfe", "Benjamin", ""]]}, {"id": "2107.09803", "submitter": "Michela Meister", "authors": "Michela Meister and Jon Kleinberg", "title": "Optimizing the order of actions in contact tracing", "comments": "37 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is a key tool for managing epidemic diseases like HIV,\ntuberculosis, and COVID-19. Manual investigations by human contact tracers\nremain a dominant way in which this is carried out. This process is limited by\nthe number of contact tracers available, who are often overburdened during an\noutbreak or epidemic. As a result, a crucial decision in any contact tracing\nstrategy is, given a set of contacts, which person should a tracer trace next?\nIn this work, we develop a formal model that articulates these questions and\nprovides a framework for comparing contact tracing strategies. Through\nanalyzing our model, we give provably optimal prioritization policies via a\nclean connection to a tool from operations research called a \"branching\nbandit\". Examining these policies gives qualitative insight into trade-offs in\ncontact tracing applications.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:19:22 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Meister", "Michela", ""], ["Kleinberg", "Jon", ""]]}, {"id": "2107.09917", "submitter": "Hendrik Heuer", "authors": "Hendrik Heuer", "title": "Audit, Don't Explain -- Recommendations Based on a Socio-Technical\n  Understanding of ML-Based Systems", "comments": "This paper will be presented at the Workshop on User-Centered\n  Artificial Intelligence (UCAI '21) at Mensch und Computer 2021", "journal-ref": null, "doi": "10.18420/muc2021-mci-ws02-232", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this position paper, I provide a socio-technical perspective on machine\nlearning-based systems. I also explain why systematic audits may be preferable\nto explainable AI systems. I make concrete recommendations for how institutions\ngoverned by public law akin to the German T\\\"UV and Stiftung Warentest can\nensure that ML systems operate in the interest of the public.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 07:36:01 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Heuer", "Hendrik", ""]]}, {"id": "2107.09922", "submitter": "Hendrik Heuer", "authors": "Hendrik Heuer, Hendrik Hoch, Andreas Breiter, Yannis Theocharis", "title": "Auditing the Biases Enacted by YouTube for Political Topics in Germany", "comments": "To appear in Mensch und Computer '21, September 05-08, 2021,\n  Ingolstadt. Full Reference: Hendrik Heuer, Hendrik Hoch, Andreas Breiter, and\n  Yannis Theocharis. 2021. Auditing the Biases Enacted by YouTube for Political\n  Topics in Germany. In Mensch und Computer '21, September 05-08, 2021,\n  Ingolstadt. ACM, New York, NY, USA, 21 pages. https:\n  //doi.org/10.1145/1122445.1122456", "journal-ref": null, "doi": "10.1145/3473856.3473864", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With YouTube's growing importance as a news platform, its recommendation\nsystem came under increased scrutiny. Recognizing YouTube's recommendation\nsystem as a broadcaster of media, we explore the applicability of laws that\nrequire broadcasters to give important political, ideological, and social\ngroups adequate opportunity to express themselves in the broadcasted program of\nthe service. We present audits as an important tool to enforce such laws and to\nensure that a system operates in the public's interest. To examine whether\nYouTube is enacting certain biases, we collected video recommendations about\npolitical topics by following chains of ten recommendations per video. Our\nfindings suggest that YouTube's recommendation system is enacting important\nbiases. We find that YouTube is recommending increasingly popular but topically\nunrelated videos. The sadness evoked by the recommended videos decreases while\nthe happiness increases. We discuss the strong popularity bias we identified\nand analyze the link between the popularity of content and emotions. We also\ndiscuss how audits empower researchers and civic hackers to monitor complex\nmachine learning (ML)-based systems like YouTube's recommendation system.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 07:53:59 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Heuer", "Hendrik", ""], ["Hoch", "Hendrik", ""], ["Breiter", "Andreas", ""], ["Theocharis", "Yannis", ""]]}, {"id": "2107.10171", "submitter": "Emily Black", "authors": "Emily Black, Matt Fredrikson", "title": "Leave-one-out Unfairness", "comments": "FAccT '21", "journal-ref": "FAccT '21: Proceedings of the 2021 ACM Conference on Fairness,\n  Accountability, and Transparency 2021, Pages 285-295", "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce leave-one-out unfairness, which characterizes how likely a\nmodel's prediction for an individual will change due to the inclusion or\nremoval of a single other person in the model's training data. Leave-one-out\nunfairness appeals to the idea that fair decisions are not arbitrary: they\nshould not be based on the chance event of any one person's inclusion in the\ntraining data. Leave-one-out unfairness is closely related to algorithmic\nstability, but it focuses on the consistency of an individual point's\nprediction outcome over unit changes to the training data, rather than the\nerror of the model in aggregate. Beyond formalizing leave-one-out unfairness,\nwe characterize the extent to which deep models behave leave-one-out unfairly\non real data, including in cases where the generalization error is small.\nFurther, we demonstrate that adversarial training and randomized smoothing\ntechniques have opposite effects on leave-one-out fairness, which sheds light\non the relationships between robustness, memorization, individual fairness, and\nleave-one-out fairness in deep models. Finally, we discuss salient practical\napplications that may be negatively affected by leave-one-out unfairness.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:55:49 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Black", "Emily", ""], ["Fredrikson", "Matt", ""]]}, {"id": "2107.10204", "submitter": "Shruti Phadke", "authors": "Shruti Phadke, Mattia Samory, Tanushree Mitra", "title": "Characterizing Social Imaginaries and Self-Disclosures of Dissonance in\n  Online Conspiracy Discussion Communities", "comments": "Accepted at CSCW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Online discussion platforms offer a forum to strengthen and propagate belief\nin misinformed conspiracy theories. Yet, they also offer avenues for conspiracy\ntheorists to express their doubts and experiences of cognitive dissonance. Such\nexpressions of dissonance may shed light on who abandons misguided beliefs and\nunder which circumstances. This paper characterizes self-disclosures of\ndissonance about QAnon, a conspiracy theory initiated by a mysterious leader Q\nand popularized by their followers, anons in conspiracy theory subreddits. To\nunderstand what dissonance and disbelief mean within conspiracy communities, we\nfirst characterize their social imaginaries, a broad understanding of how\npeople collectively imagine their social existence. Focusing on 2K posts from\ntwo image boards, 4chan and 8chan, and 1.2 M comments and posts from 12\nsubreddits dedicated to QAnon, we adopt a mixed methods approach to uncover the\nsymbolic language representing the movement, expectations, practices, heroes\nand foes of the QAnon community. We use these social imaginaries to create a\ncomputational framework for distinguishing belief and dissonance from general\ndiscussion about QAnon. Further, analyzing user engagement with QAnon\nconspiracy subreddits, we find that self-disclosures of dissonance correlate\nwith a significant decrease in user contributions and ultimately with their\ndeparture from the community. We contribute a computational framework for\nidentifying dissonance self-disclosures and measuring the changes in user\nengagement surrounding dissonance. Our work can provide insights into designing\ndissonance-based interventions that can potentially dissuade conspiracists from\nonline conspiracy discussion communities.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:49:21 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Phadke", "Shruti", ""], ["Samory", "Mattia", ""], ["Mitra", "Tanushree", ""]]}, {"id": "2107.10302", "submitter": "Ram Shankar Siva Kumar", "authors": "Kendra Albert, Maggie Delano, Bogdan Kulynych, Ram Shankar Siva Kumar", "title": "Adversarial for Good? How the Adversarial ML Community's Values Impede\n  Socially Beneficial Uses of Attacks", "comments": "Author list is ordered alphabetically as there is equal contribution.\n  4 pages Accepted by the ICML 2021 workshop on \"A Blessing in Disguise:The\n  Prospects and Perils of Adversarial Machine Learning\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attacks from adversarial machine learning (ML) have the potential to be used\n\"for good\": they can be used to run counter to the existing power structures\nwithin ML, creating breathing space for those who would otherwise be the\ntargets of surveillance and control. But most research on adversarial ML has\nnot engaged in developing tools for resistance against ML systems. Why? In this\npaper, we review the broader impact statements that adversarial ML researchers\nwrote as part of their NeurIPS 2020 papers and assess the assumptions that\nauthors have about the goals of their work. We also collect information about\nhow authors view their work's impact more generally. We find that most\nadversarial ML researchers at NeurIPS hold two fundamental assumptions that\nwill make it difficult for them to consider socially beneficial uses of\nattacks: (1) it is desirable to make systems robust, independent of context,\nand (2) attackers of systems are normatively bad and defenders of systems are\nnormatively good. That is, despite their expressed and supposed neutrality,\nmost adversarial ML researchers believe that the goal of their work is to\nsecure systems, making it difficult to conceptualize and build tools for\ndisrupting the status quo.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 13:51:52 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Albert", "Kendra", ""], ["Delano", "Maggie", ""], ["Kulynych", "Bogdan", ""], ["Kumar", "Ram Shankar Siva", ""]]}, {"id": "2107.10328", "submitter": "Vladimir Vargas-Calder\\'on", "authors": "Vladimir Vargas-Calder\\'on, Andreina Moros Ochoa, Gilmer Yovani Castro\n  Nieto and Jorge E. Camargo", "title": "Machine learning for assessing quality of service in the hospitality\n  sector based on customer reviews", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": "10.1007/s40558-021-00207-4", "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The increasing use of online hospitality platforms provides firsthand\ninformation about clients preferences, which are essential to improve hotel\nservices and increase the quality of service perception. Customer reviews can\nbe used to automatically extract the most relevant aspects of the quality of\nservice for hospitality clientele. This paper proposes a framework for the\nassessment of the quality of service in the hospitality sector based on the\nexploitation of customer reviews through natural language processing and\nmachine learning methods. The proposed framework automatically discovers the\nquality of service aspects relevant to hotel customers. Hotel reviews from\nBogot\\'a and Madrid are automatically scrapped from Booking.com. Semantic\ninformation is inferred through Latent Dirichlet Allocation and FastText, which\nallow representing text reviews as vectors. A dimensionality reduction\ntechnique is applied to visualise and interpret large amounts of customer\nreviews. Visualisations of the most important quality of service aspects are\ngenerated, allowing to qualitatively and quantitatively assess the quality of\nservice. Results show that it is possible to automatically extract the main\nquality of service aspects perceived by customers from large customer review\ndatasets. These findings could be used by hospitality managers to understand\nclients better and to improve the quality of service.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 19:45:40 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Vargas-Calder\u00f3n", "Vladimir", ""], ["Ochoa", "Andreina Moros", ""], ["Nieto", "Gilmer Yovani Castro", ""], ["Camargo", "Jorge E.", ""]]}, {"id": "2107.10344", "submitter": "Simon Levin", "authors": "Edward Schrom, Ann Kinzig, Stephanie Forrest, Andrea L. Graham, Simon\n  A. Levin, Carl T. Bergstrom, Carlos Castillo-Chavez, James P. Collins, Rob J.\n  de Boer, Adam Doup\\'e, Roya Ensafi, Stuart Feldman, Bryan T. Grenfell. Alex\n  Halderman, Silvie Huijben, Carlo Maley, Melanie Mosesr, Alan S. Perelson,\n  Charles Perrings, Joshua Plotkin, Jennifer Rexford, Mohit Tiwari", "title": "Challenges in cybersecurity: Lessons from biological defense systems", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the commonalities between methods for assuring the security of\ncomputer systems (cybersecurity) and the mechanisms that have evolved through\nnatural selection to protect vertebrates against pathogens, and how insights\nderived from studying the evolution of natural defenses can inform the design\nof more effective cybersecurity systems. More generally, security challenges\nare crucial for the maintenance of a wide range of complex adaptive systems,\nincluding financial systems, and again lessons learned from the study of the\nevolution of natural defenses can provide guidance for the protection of such\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 20:18:35 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Schrom", "Edward", ""], ["Kinzig", "Ann", ""], ["Forrest", "Stephanie", ""], ["Graham", "Andrea L.", ""], ["Levin", "Simon A.", ""], ["Bergstrom", "Carl T.", ""], ["Castillo-Chavez", "Carlos", ""], ["Collins", "James P.", ""], ["de Boer", "Rob J.", ""], ["Doup\u00e9", "Adam", ""], ["Ensafi", "Roya", ""], ["Feldman", "Stuart", ""], ["Halderman", "Bryan T. Grenfell. Alex", ""], ["Huijben", "Silvie", ""], ["Maley", "Carlo", ""], ["Mosesr", "Melanie", ""], ["Perelson", "Alan S.", ""], ["Perrings", "Charles", ""], ["Plotkin", "Joshua", ""], ["Rexford", "Jennifer", ""], ["Tiwari", "Mohit", ""]]}, {"id": "2107.10356", "submitter": "Judy Gichoya", "authors": "Imon Banerjee, Ananth Reddy Bhimireddy, John L. Burns, Leo Anthony\n  Celi, Li-Ching Chen, Ramon Correa, Natalie Dullerud, Marzyeh Ghassemi,\n  Shih-Cheng Huang, Po-Chih Kuo, Matthew P Lungren, Lyle Palmer, Brandon J\n  Price, Saptarshi Purkayastha, Ayis Pyrros, Luke Oakden-Rayner, Chima\n  Okechukwu, Laleh Seyyed-Kalantari, Hari Trivedi, Ryan Wang, Zachary Zaiman,\n  Haoran Zhang, Judy W Gichoya", "title": "Reading Race: AI Recognises Patient's Racial Identity In Medical Images", "comments": "Submitted to the Lancet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: In medical imaging, prior studies have demonstrated disparate AI\nperformance by race, yet there is no known correlation for race on medical\nimaging that would be obvious to the human expert interpreting the images.\n  Methods: Using private and public datasets we evaluate: A) performance\nquantification of deep learning models to detect race from medical images,\nincluding the ability of these models to generalize to external environments\nand across multiple imaging modalities, B) assessment of possible confounding\nanatomic and phenotype population features, such as disease distribution and\nbody habitus as predictors of race, and C) investigation into the underlying\nmechanism by which AI models can recognize race.\n  Findings: Standard deep learning models can be trained to predict race from\nmedical images with high performance across multiple imaging modalities. Our\nfindings hold under external validation conditions, as well as when models are\noptimized to perform clinically motivated tasks. We demonstrate this detection\nis not due to trivial proxies or imaging-related surrogate covariates for race,\nsuch as underlying disease distribution. Finally, we show that performance\npersists over all anatomical regions and frequency spectrum of the images\nsuggesting that mitigation efforts will be challenging and demand further\nstudy.\n  Interpretation: We emphasize that model ability to predict self-reported race\nis itself not the issue of importance. However, our findings that AI can\ntrivially predict self-reported race -- even from corrupted, cropped, and\nnoised medical images -- in a setting where clinical experts cannot, creates an\nenormous risk for all model deployments in medical imaging: if an AI model\nsecretly used its knowledge of self-reported race to misclassify all Black\npatients, radiologists would not be able to tell using the same data the model\nhas access to.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 21:10:16 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Banerjee", "Imon", ""], ["Bhimireddy", "Ananth Reddy", ""], ["Burns", "John L.", ""], ["Celi", "Leo Anthony", ""], ["Chen", "Li-Ching", ""], ["Correa", "Ramon", ""], ["Dullerud", "Natalie", ""], ["Ghassemi", "Marzyeh", ""], ["Huang", "Shih-Cheng", ""], ["Kuo", "Po-Chih", ""], ["Lungren", "Matthew P", ""], ["Palmer", "Lyle", ""], ["Price", "Brandon J", ""], ["Purkayastha", "Saptarshi", ""], ["Pyrros", "Ayis", ""], ["Oakden-Rayner", "Luke", ""], ["Okechukwu", "Chima", ""], ["Seyyed-Kalantari", "Laleh", ""], ["Trivedi", "Hari", ""], ["Wang", "Ryan", ""], ["Zaiman", "Zachary", ""], ["Zhang", "Haoran", ""], ["Gichoya", "Judy W", ""]]}, {"id": "2107.10410", "submitter": "Kai-Hui Liang", "authors": "Kai-Hui Liang, Patrick Lange, Yoo Jung Oh, Jingwen Zhang, Yoshimi\n  Fukuoka, Zhou Yu", "title": "Evaluation of In-Person Counseling Strategies To Develop Physical\n  Activity Chatbot for Women", "comments": "Accepted by SIGDIAL 2021 as a long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence chatbots are the vanguard in technology-based\nintervention to change people's behavior. To develop intervention chatbots, the\nfirst step is to understand natural language conversation strategies in human\nconversation. This work introduces an intervention conversation dataset\ncollected from a real-world physical activity intervention program for women.\nWe designed comprehensive annotation schemes in four dimensions (domain,\nstrategy, social exchange, and task-focused exchange) and annotated a subset of\ndialogs. We built a strategy classifier with context information to detect\nstrategies from both trainers and participants based on the annotation. To\nunderstand how human intervention induces effective behavior changes, we\nanalyzed the relationships between the intervention strategies and the\nparticipants' changes in the barrier and social support for physical activity.\nWe also analyzed how participant's baseline weight correlates to the amount of\noccurrence of the corresponding strategy. This work lays the foundation for\ndeveloping a personalized physical activity intervention bot. The dataset and\ncode are available at\nhttps://github.com/KaihuiLiang/physical-activity-counseling\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 00:39:21 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Liang", "Kai-Hui", ""], ["Lange", "Patrick", ""], ["Oh", "Yoo Jung", ""], ["Zhang", "Jingwen", ""], ["Fukuoka", "Yoshimi", ""], ["Yu", "Zhou", ""]]}, {"id": "2107.10413", "submitter": "Alina Arseniev-Koehler", "authors": "Alina Arseniev-Koehler", "title": "Theoretical foundations and limits of word embeddings: what types of\n  meaning can they capture?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Measuring meaning is a central problem in cultural sociology and word\nembeddings may offer powerful new tools to do so. But like any tool, they build\non and exert theoretical assumptions. In this paper I theorize the ways in\nwhich word embeddings model three core premises of a structural linguistic\ntheory of meaning: that meaning is relational, coherent, and may be analyzed as\na static system. In certain ways, word embedding methods are vulnerable to the\nsame, enduring critiques of these premises. In other ways, they offer novel\nsolutions to these critiques. More broadly, formalizing the study of meaning\nwith word embeddings offers theoretical opportunities to clarify core concepts\nand debates in cultural sociology, such as the coherence of meaning. Just as\nnetwork analysis specified the once vague notion of social relations (Borgatti\net al. 2009), formalizing meaning with embedding methods can push us to specify\nand reimagine meaning itself.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 00:40:33 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Arseniev-Koehler", "Alina", ""]]}, {"id": "2107.10424", "submitter": "Chaoran Cui", "authors": "Chaoran Cui, Jian Zong, Yuling Ma, Xinhua Wang, Lei Guo, Meng Chen,\n  Yilong Yin", "title": "Tri-Branch Convolutional Neural Networks for Top-$k$ Focused Academic\n  Performance Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic performance prediction aims to leverage student-related information\nto predict their future academic outcomes, which is beneficial to numerous\neducational applications, such as personalized teaching and academic early\nwarning. In this paper, we address the problem by analyzing students' daily\nbehavior trajectories, which can be comprehensively tracked with campus\nsmartcard records. Different from previous studies, we propose a novel\nTri-Branch CNN architecture, which is equipped with row-wise, column-wise, and\ndepth-wise convolution and attention operations, to capture the characteristics\nof persistence, regularity, and temporal distribution of student behavior in an\nend-to-end manner, respectively. Also, we cast academic performance prediction\nas a top-$k$ ranking problem, and introduce a top-$k$ focused loss to ensure\nthe accuracy of identifying academically at-risk students. Extensive\nexperiments were carried out on a large-scale real-world dataset, and we show\nthat our approach substantially outperforms recently proposed methods for\nacademic performance prediction. For the sake of reproducibility, our codes\nhave been released at\nhttps://github.com/ZongJ1111/Academic-Performance-Prediction.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 02:35:36 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Cui", "Chaoran", ""], ["Zong", "Jian", ""], ["Ma", "Yuling", ""], ["Wang", "Xinhua", ""], ["Guo", "Lei", ""], ["Chen", "Meng", ""], ["Yin", "Yilong", ""]]}, {"id": "2107.10554", "submitter": "Keenan Jones", "authors": "Keenan Jones, Jason R. C. Nurse, Shujun Li", "title": "Out of the Shadows: Analyzing Anonymous' Twitter Resurgence during the\n  2020 Black Lives Matter Protests", "comments": "12 pages, 9 figures, 3 tables. Accepted for publication in the\n  proceedings of the sixteenth International AAAI Conference on Web and Social\n  Media", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, there had been little notable activity from the once prominent\nhacktivist group, Anonymous. The group, responsible for activist-based cyber\nattacks on major businesses and governments, appeared to have fragmented after\nkey members were arrested in 2013. In response to the major Black Lives Matter\n(BLM) protests that occurred after the killing of George Floyd, however,\nreports indicated that the group was back. To examine this apparent resurgence,\nwe conduct a large-scale study of Anonymous affiliates on Twitter. To this end,\nwe first use machine learning to identify a significant network of more than\n33,000 Anonymous accounts. Through topic modelling of tweets collected from\nthese accounts, we find evidence of sustained interest in topics related to\nBLM. We then use sentiment analysis on tweets focused on these topics, finding\nevidence of a united approach amongst the group, with positive tweets typically\nbeing used to express support towards BLM, and negative tweets typically being\nused to criticize police actions. Finally, we examine the presence of\nautomation in the network, identifying indications of bot-like behavior across\nthe majority of Anonymous accounts. These findings show that whilst the group\nhas seen a resurgence during the protests, bot activity may be responsible for\nexaggerating the extent of this resurgence.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:18:32 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Jones", "Keenan", ""], ["Nurse", "Jason R. C.", ""], ["Li", "Shujun", ""]]}, {"id": "2107.10556", "submitter": "Rajeshwari K", "authors": "Preetha S, Rajeshwari K, Anitha C, Kausthub Narayan", "title": "Codeathon Activity: A Design Prototype for Real World Problems", "comments": "6 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Activity-based learning helps students to learn through participation. A\nvirtual codeathon activity, as part of this learning scheme, was conducted for\n180 undergraduate students to focus on analysis and design of solutions to\ncrucial real-world problems in the existing Covid-19 pandemic situation. In\nthis paper, an analysis is made to know the problem solving skills of students\ngiven a single problem statement. Evaluators can further collate these multiple\nsolutions into one optimal solution. This Codeathon activity impacts their\npractical approach towards the analysis and design.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 10:19:43 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["S", "Preetha", ""], ["K", "Rajeshwari", ""], ["C", "Anitha", ""], ["Narayan", "Kausthub", ""]]}, {"id": "2107.10655", "submitter": "Mirela Silva", "authors": "Hanyu Shi, Mirela Silva, Daniel Capecci, Luiz Giovanini, Lauren Czech,\n  Juliana Fernandes, Daniela Oliveira", "title": "Lumen: A Machine Learning Framework to Expose Influence Cues in Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Phishing and disinformation are popular social engineering attacks with\nattackers invariably applying influence cues in texts to make them more\nappealing to users. We introduce Lumen, a learning-based framework that exposes\ninfluence cues in text: (i) persuasion, (ii) framing, (iii) emotion, (iv)\nobjectivity/subjectivity, (v) guilt/blame, and (vi) use of emphasis. Lumen was\ntrained with a newly developed dataset of 3K texts comprised of disinformation,\nphishing, hyperpartisan news, and mainstream news. Evaluation of Lumen in\ncomparison to other learning models showed that Lumen and LSTM presented the\nbest F1-micro score, but Lumen yielded better interpretability. Our results\nhighlight the promise of ML to expose influence cues in text, towards the goal\nof application in automatic labeling tools to improve the accuracy of\nhuman-based detection and reduce the likelihood of users falling for deceptive\nonline content.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 15:53:13 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shi", "Hanyu", ""], ["Silva", "Mirela", ""], ["Capecci", "Daniel", ""], ["Giovanini", "Luiz", ""], ["Czech", "Lauren", ""], ["Fernandes", "Juliana", ""], ["Oliveira", "Daniela", ""]]}, {"id": "2107.10724", "submitter": "Rohan Alexander", "authors": "Annie Collins, Rohan Alexander", "title": "Reproducibility of COVID-19 pre-prints", "comments": "14 pages, 6 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY cs.DL physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To examine the reproducibility of COVID-19 research, we create a dataset of\npre-prints posted to arXiv, bioRxiv, medRxiv, and SocArXiv between 28 January\n2020 and 30 June 2021 that are related to COVID-19. We extract the text from\nthese pre-prints and parse them looking for keyword markers signalling the\navailability of the data and code underpinning the pre-print. For the\npre-prints that are in our sample, we are unable to find markers of either open\ndata or open code for 75 per cent of those on arXiv, 67 per cent of those on\nbioRxiv, 79 per cent of those on medRxiv, and 85 per cent of those on SocArXiv.\nWe conclude that there may be value in having authors categorize the degree of\nopenness of their pre-print as part of the pre-print submissions process, and\nmore broadly, there is a need to better integrate open science training into a\nwide range of fields.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 15:02:06 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Collins", "Annie", ""], ["Alexander", "Rohan", ""]]}, {"id": "2107.10939", "submitter": "Ivan Vendrov", "authors": "Jonathan Stray, Ivan Vendrov, Jeremy Nixon, Steven Adler, Dylan\n  Hadfield-Menell", "title": "What are you optimizing for? Aligning Recommender Systems with Human\n  Values", "comments": "Originally presented at the ICML 2020 Participatory Approaches to\n  Machine Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe cases where real recommender systems were modified in the service\nof various human values such as diversity, fairness, well-being, time well\nspent, and factual accuracy. From this we identify the current practice of\nvalues engineering: the creation of classifiers from human-created data with\nvalue-based labels. This has worked in practice for a variety of issues, but\nproblems are addressed one at a time, and users and other stakeholders have\nseldom been involved. Instead, we look to AI alignment work for approaches that\ncould learn complex values directly from stakeholders, and identify four major\ndirections: useful measures of alignment, participatory design and operation,\ninteractive value learning, and informed deliberative judgments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 21:52:43 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Stray", "Jonathan", ""], ["Vendrov", "Ivan", ""], ["Nixon", "Jeremy", ""], ["Adler", "Steven", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "2107.10979", "submitter": "Nikolay Ivanov", "authors": "Nikolay Ivanov, Hanqing Guo, and Qiben Yan", "title": "Rectifying Administrated ERC20 Tokens", "comments": "23rd International Conference on Information and Communications\n  Security (ICICS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The developers of Ethereum smart contracts often implement administrating\npatterns, such as censoring certain users, creating or destroying balances on\ndemand, destroying smart contracts, or injecting arbitrary code. These routines\nturn an ERC20 token into an administrated token - the type of Ethereum smart\ncontract that we scrutinize in this research. We discover that many smart\ncontracts are administrated, and the owners of these tokens carry lesser social\nand legal responsibilities compared to the traditional centralized actors that\nthose tokens intend to disrupt. This entails two major problems: a) the owners\nof the tokens have the ability to quickly steal all the funds and disappear\nfrom the market; and b) if the private key of the owner's account is stolen,\nall the assets might immediately turn into the property of the attacker. We\ndevelop a pattern recognition framework based on 9 syntactic features\ncharacterizing administrated ERC20 tokens, which we use to analyze existing\nsmart contracts deployed on Ethereum Mainnet. Our analysis of 84,062 unique\nEthereum smart contracts reveals that nearly 58% of them are administrated\nERC20 tokens, which accounts for almost 90% of all ERC20 tokens deployed on\nEthereum. To protect users from the frivolousness of unregulated token owners\nwithout depriving the ability of these owners to properly manage their tokens,\nwe introduce SafelyAdministrated - a library that enforces a responsible\nownership and management of ERC20 tokens. The library introduces three\nmechanisms: deferred maintenance, board of trustees and safe pause. We\nimplement and test SafelyAdministrated in the form of Solidity abstract\ncontract, which is ready to be used by the next generation of safely\nadministrated ERC20 tokens.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 18:40:34 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Ivanov", "Nikolay", ""], ["Guo", "Hanqing", ""], ["Yan", "Qiben", ""]]}, {"id": "2107.11020", "submitter": "Junyi Jessy Li", "authors": "Alexander Tekle, Chau Pham, Cornelia Caragea, Junyi Jessy Li", "title": "When a crisis strikes: Emotion analysis and detection during COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crises such as natural disasters, global pandemics, and social unrest\ncontinuously threaten our world and emotionally affect millions of people\nworldwide in distinct ways. Understanding emotions that people express during\nlarge-scale crises helps inform policy makers and first responders about the\nemotional states of the population as well as provide emotional support to\nthose who need such support. We present CovidEmo, ~1K tweets labeled with\nemotions. We examine how well large pre-trained language models generalize\nacross domains and crises in the task of perceived emotion prediction in the\ncontext of COVID-19. Our results show that existing models do not directly\ntransfer from one disaster type to another but using labeled emotional corpora\nfor domain adaptation is beneficial.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 04:07:14 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Tekle", "Alexander", ""], ["Pham", "Chau", ""], ["Caragea", "Cornelia", ""], ["Li", "Junyi Jessy", ""]]}, {"id": "2107.11029", "submitter": "Pradipta Biswas", "authors": "Priyam Rajkhowa and Pradipta Biswas", "title": "User Perception of Privacy with Ubiquitous Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy is important for all individuals in everyday life. With emerging\ntechnologies, smartphones with AR, various social networking applications and\nartificial intelligence driven modes of surveillance, they tend to intrude\nprivacy. This study aimed to explore and discover various concerns related to\nperception of privacy in this era of ubiquitous technologies. It employed\nonline survey questionnaire to study user perspectives of privacy. Purposive\nsampling was used to collect data from 60 participants. Inductive thematic\nanalysis was used to analyze data. Our study discovered key themes like\nattitude towards privacy in public and private spaces, privacy awareness,\nconsent seeking, dilemmas/confusions related to various technologies, impact of\nattitude and beliefs on individuals actions regarding how to protect oneself\nfrom invasion of privacy in both public and private spaces. These themes\ninteracted amongst themselves and influenced formation of various actions. They\nwere like core principles that molded actions that prevented invasion of\nprivacy for both participant and bystander. Findings of this study would be\nhelpful to improve privacy and personalization of various emerging\ntechnologies. This study contributes to privacy by design and positive design\nby considering psychological needs of users. This is suggestive that the\nfindings can be applied in the areas of experience design, positive\ntechnologies, social computing and behavioral interventions.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 05:01:44 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Rajkhowa", "Priyam", ""], ["Biswas", "Pradipta", ""]]}, {"id": "2107.11903", "submitter": "Damjan Vukcevic", "authors": "Michelle Blom, Jurlind Budurushi, Ronald L. Rivest, Philip B. Stark,\n  Peter J. Stuckey, Vanessa Teague, Damjan Vukcevic", "title": "Assertion-based Approaches to Auditing Complex Elections, with\n  application to party-list proportional elections", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk-limiting audits (RLAs), an ingredient in evidence-based elections, are\nincreasingly common. They are a rigorous statistical means of ensuring that\nelectoral results are correct, usually without having to perform an expensive\nfull recount -- at the cost of some controlled probability of error. A recently\ndeveloped approach for conducting RLAs, SHANGRLA, provides a flexible framework\nthat can encompass a wide variety of social choice functions and audit\nstrategies. Its flexibility comes from reducing sufficient conditions for\noutcomes to be correct to canonical `assertions' that have a simple\nmathematical form.\n  Assertions have been developed for auditing various social choice functions\nincluding plurality, multi-winner plurality, super-majority, Hamiltonian\nmethods, and instant runoff voting. However, there is no systematic approach to\nbuilding assertions. Here, we show that assertions with linear dependence on\ntransformations of the votes can easily be transformed to canonical form for\nSHANGRLA. We illustrate the approach by constructing assertions for party-list\nelections such as Hamiltonian free list elections and elections using the\nD'Hondt method, expanding the set of social choice functions to which SHANGRLA\napplies directly.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 22:52:49 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Blom", "Michelle", ""], ["Budurushi", "Jurlind", ""], ["Rivest", "Ronald L.", ""], ["Stark", "Philip B.", ""], ["Stuckey", "Peter J.", ""], ["Teague", "Vanessa", ""], ["Vukcevic", "Damjan", ""]]}, {"id": "2107.11913", "submitter": "Luis Lamb", "authors": "Pedro H.C. Avelar and Rafael B. Audibert and Anderson R. Tavares and\n  Lu\\'is C. Lamb", "title": "Measuring Ethics in AI with AI: A Methodology and Dataset Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, the use of sound measures and metrics in Artificial Intelligence\nhas become the subject of interest of academia, government, and industry.\nEfforts towards measuring different phenomena have gained traction in the AI\ncommunity, as illustrated by the publication of several influential field\nreports and policy documents. These metrics are designed to help decision\ntakers to inform themselves about the fast-moving and impacting influences of\nkey advances in Artificial Intelligence in general and Machine Learning in\nparticular. In this paper we propose to use such newfound capabilities of AI\ntechnologies to augment our AI measuring capabilities. We do so by training a\nmodel to classify publications related to ethical issues and concerns. In our\nmethodology we use an expert, manually curated dataset as the training set and\nthen evaluate a large set of research papers. Finally, we highlight the\nimplications of AI metrics, in particular their contribution towards developing\ntrustful and fair AI-based tools and technologies. Keywords: AI Ethics; AI\nFairness; AI Measurement. Ethics in Computer Science.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 00:26:12 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Audibert", "Rafael B.", ""], ["Tavares", "Anderson R.", ""], ["Lamb", "Lu\u00eds C.", ""]]}, {"id": "2107.11929", "submitter": "Teruaki Hayashi", "authors": "Teruaki Hayashi, Takumi Shimizu, Yoshiaki Fukami", "title": "Collaborative Problem Solving on a Data Platform Kaggle", "comments": "This paper is the English-translated version of \"Collaborative\n  Problem Solving on a Data Platform Kaggle\" IEICE Tech. Rep., vol.120, no.362,\n  pp.37-40, 2021. (https://www.ieice.org/ken/paper/20210212XCc9/eng/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data exchange across different domains has gained much attention as a way of\ncreating new businesses and improving the value of existing services. Data\nexchange ecosystem is developed by platform services that facilitate data and\nknowledge exchange and offer co-creation environments for organizations to\npromote their problem-solving. In this study, we investigate Kaggle, a data\nanalysis competition platform, and discuss the characteristics of data and the\necosystem that contributes to collaborative problem-solving by analyzing the\ndatasets, users, and their relationships.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 02:28:01 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Hayashi", "Teruaki", ""], ["Shimizu", "Takumi", ""], ["Fukami", "Yoshiaki", ""]]}, {"id": "2107.12073", "submitter": "Jean-Philippe Cointet", "authors": "Jean-Philippe Cointet (M\\'edialab), Dominique Cardon (M\\'edialab),\n  Andre\\\"i Mogoutov (M\\'edialab), Benjamin Ooghe-Tabanou (M\\'edialab),\n  Guillaume Plique (M\\'edialab), Pedro Morales (M\\'edialab)", "title": "Uncovering the structure of the French media ecosystem", "comments": "IC2S2, Jul 2021, Zurich, Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:51:54 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Cointet", "Jean-Philippe", "", "M\u00e9dialab"], ["Cardon", "Dominique", "", "M\u00e9dialab"], ["Mogoutov", "Andre\u00ef", "", "M\u00e9dialab"], ["Ooghe-Tabanou", "Benjamin", "", "M\u00e9dialab"], ["Plique", "Guillaume", "", "M\u00e9dialab"], ["Morales", "Pedro", "", "M\u00e9dialab"]]}, {"id": "2107.12235", "submitter": "Marco De Nadai", "authors": "Lorenzo Lucchini, Simone Centellegher, Luca Pappalardo, Riccardo\n  Gallotti, Filippo Privitera, Bruno Lepri and Marco De Nadai", "title": "Living in a pandemic: adaptation of individual mobility and social\n  activity in the US", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-pharmaceutical interventions (NPIs), aimed at reducing the diffusion\nof the COVID-19 pandemic, has dramatically influenced our behaviour in everyday\nlife. In this work, we study how individuals adapted their daily movements and\nperson-to-person contact patterns over time in response to the COVID-19\npandemic and the NPIs. We leverage longitudinal GPS mobility data of hundreds\nof thousands of anonymous individuals in four US states and empirically show\nthe dramatic disruption in people's life. We find that local interventions did\nnot just impact the number of visits to different venues but also how people\nexperience them. Individuals spend less time in venues, preferring simpler and\nmore predictable routines and reducing person-to-person contact activities.\nMoreover, we show that the stringency of interventions alone does explain the\nnumber and duration of visits to venues: individual patterns of visits seem to\nbe influenced by the local severity of the pandemic and a risk adaptation\nfactor, which increases the people's mobility regardless of the stringency of\ninterventions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:27:22 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Lucchini", "Lorenzo", ""], ["Centellegher", "Simone", ""], ["Pappalardo", "Luca", ""], ["Gallotti", "Riccardo", ""], ["Privitera", "Filippo", ""], ["Lepri", "Bruno", ""], ["De Nadai", "Marco", ""]]}, {"id": "2107.12303", "submitter": "Iknoor Singh", "authors": "Iknoor Singh, Kalina Bontcheva, and Carolina Scarton", "title": "The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal\n  Analysis", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a\nglobal infodemic that has brought unprecedented challenges for society as a\nwhole. During this time, a number of manual fact-checking initiatives have\nemerged to alleviate the spread of dis/mis-information. This study is about\nCOVID-19 debunks published in multiple languages by different fact-checking\norganisations, sometimes as far as several months apart, despite the fact that\nthe claim has already been fact-checked before. The spatiotemporal analysis\nreveals that similar or nearly duplicate false COVID-19 narratives have been\nspreading in multifarious modalities on various social media platforms in\ndifferent countries. We also find that misinformation involving general medical\nadvice has spread across multiple countries and hence has the highest\nproportion of false COVID-19 narratives that keep being debunked. Furthermore,\nas manual fact-checking is an onerous task in itself, therefore debunking\nsimilar claims recurrently is leading to a waste of resources. To this end, we\npropound the idea of the inclusion of multilingual debunk search in the\nfact-checking pipeline.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:20:44 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Singh", "Iknoor", ""], ["Bontcheva", "Kalina", ""], ["Scarton", "Carolina", ""]]}, {"id": "2107.12312", "submitter": "Lizardo Vargas-Bianchi", "authors": "Andrea Pecho-Ninapaytan, Stefany Zambrano-Zuta, Lizardo Vargas-Bianchi", "title": "'No, auntie, that's false': Female baby boomers develop critical skills\n  to confront fake news with guidance from relatives", "comments": "14 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The spread of fake news has been increasing, which gives rise to a special\ninterest in the development of identification and coping skills among news\nconsumers so that they can filter out misleading information. Studies suggest\nthat older people share more fake news from social media. There is scarce\nliterature that analyse how baby boomers behave in the face of fake news. The\npurpose of this study is to examine how female baby boomers deal with fake news\non Facebook and their available resources to learn how to identify and handle\ndubious information. A qualitative study and thematic analysis were conducted\nusing information obtained from interviewing female baby boomers. Four themes\nemerge from the analysis, revealing that participants recognise that they can\nidentify fake news but may not always be able to do so due to limitations in\ntheir understanding of an issue or uncertainty about its source. Participants\nshow participants empirically develop critical identification and filtering\nskills with the assistance from close family members.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:33:47 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Pecho-Ninapaytan", "Andrea", ""], ["Zambrano-Zuta", "Stefany", ""], ["Vargas-Bianchi", "Lizardo", ""]]}, {"id": "2107.12507", "submitter": "Byeongjoon Noh", "authors": "Byeongjoon Noh, Hansaem Park, Hwasoo Yeo", "title": "Analyzing vehicle pedestrian interactions combining data cube structure\n  and predictive collision risk estimation model", "comments": "33 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traffic accidents are a threat to human lives, particularly pedestrians\ncausing premature deaths. Therefore, it is necessary to devise systems to\nprevent accidents in advance and respond proactively, using potential risky\nsituations as one of the surrogate safety measurements. This study introduces a\nnew concept of a pedestrian safety system that combines the field and the\ncentralized processes. The system can warn of upcoming risks immediately in the\nfield and improve the safety of risk frequent areas by assessing the safety\nlevels of roads without actual collisions. In particular, this study focuses on\nthe latter by introducing a new analytical framework for a crosswalk safety\nassessment with behaviors of vehicle/pedestrian and environmental features. We\nobtain these behavioral features from actual traffic video footage in the city\nwith complete automatic processing. The proposed framework mainly analyzes\nthese behaviors in multidimensional perspectives by constructing a data cube\nstructure, which combines the LSTM based predictive collision risk estimation\nmodel and the on line analytical processing operations. From the PCR estimation\nmodel, we categorize the severity of risks as four levels and apply the\nproposed framework to assess the crosswalk safety with behavioral features. Our\nanalytic experiments are based on two scenarios, and the various descriptive\nresults are harvested the movement patterns of vehicles and pedestrians by road\nenvironment and the relationships between risk levels and car speeds. Thus, the\nproposed framework can support decision makers by providing valuable\ninformation to improve pedestrian safety for future accidents, and it can help\nus better understand their behaviors near crosswalks proactively. In order to\nconfirm the feasibility and applicability of the proposed framework, we\nimplement and apply it to actual operating CCTVs in Osan City, Korea.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 23:00:56 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Noh", "Byeongjoon", ""], ["Park", "Hansaem", ""], ["Yeo", "Hwasoo", ""]]}, {"id": "2107.12711", "submitter": "Michiel Van Der Meer", "authors": "Ruth Shortall, Anatol Itten, Michiel van der Meer, Pradeep K.\n  Murukannaiah, Catholijn M. Jonker", "title": "Inclusion, equality and bias in designing online mass deliberative\n  platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designers of online deliberative platforms aim to counter the degrading\nquality of online debates and eliminate online discrimination based on class,\nrace or gender. Support technologies such as machine learning and natural\nlanguage processing open avenues for widening the circle of people involved in\ndeliberation, moving from small groups to ``crowd'' scale. Some design features\nof large-scale online discussion systems allow larger numbers of people to\ndiscuss shared problems, enhance critical thinking, and formulate solutions.\nHowever, scaling up deliberation is challenging. We review the\ntransdisciplinary literature on the design of digital mass-deliberation\nplatforms and examine the commonly featured design aspects (e.g., argumentation\nsupport, automated facilitation, and gamification). We find that the literature\nis heavily focused on developing technical fixes for scaling up deliberation,\nwith a heavy western influence on design and test users skew young and highly\neducated. Contrastingly, there is a distinct lack of discussion on the nature\nof the design process, the inclusion of stakeholders and issues relating to\ninclusion, which may unwittingly perpetuate bias. Another tendency of\ndeliberation platforms is to nudge participants to desired forms of\nargumentation, and simplifying definitions of good and bad arguments to fit\nalgorithmic purposes. Few studies bridge disciplines between deliberative\ntheory, design and engineering. As a result, scaling up deliberation will\nlikely advance in separate systemic siloes. We make design and process\nrecommendations to correct this course and suggest avenues for future research.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 10:13:57 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Shortall", "Ruth", ""], ["Itten", "Anatol", ""], ["van der Meer", "Michiel", ""], ["Murukannaiah", "Pradeep K.", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "2107.12831", "submitter": "Carolina Duarte", "authors": "Carolina Duarte, Valderi Leithardt", "title": "Estudo Abordando o Contexto de Not\\'icias Falsas em Pa\\'ises de L\\'ingua\n  Portuguesa (Fake News)", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work consists of a study that addresses the context of false news in the\nreality of today's world. False news is a widely used expression currently.\nDuring the study, it was possible to identify problems generalized about this\ntheme, such as the wide spread that these have and the impact they have on\nsociety. From these problems it was possible to identify more specific ones,\nsuch as the origin of the news, the news source, a person who shares and/or\ncreates news and the interpersonal relationship existing. With the\nidentification of the aforementioned sub-problems, it was possible develop a\ntaxonomic model with the aim of implementing a tool that helps in detecting\nfalse news, identifying if a news is true, false or whether the user must be\ncareful (when it is not possible identify whether the news is true or false).\nAfter implementation, it was possible get a tool that allows you to calculate a\nprobability of a news being false, selected as selected options in each\nparameter. It was also possible to verify that a probability was correct and\nthat the tool is reviewed in the study carried out.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:00:14 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Duarte", "Carolina", ""], ["Leithardt", "Valderi", ""]]}, {"id": "2107.12977", "submitter": "Inga Str\\\"umke", "authors": "Inga Str\\\"umke, Marija Slavkovik, Vince I. Madai", "title": "The social dilemma in AI development and why we have to solve it", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the demand for ethical artificial intelligence (AI) systems increases,\nthe number of unethical uses of AI accelerates, even though there is no\nshortage of ethical guidelines. We argue that a main underlying cause for this\nis that AI developers face a social dilemma in AI development ethics,\npreventing the widespread adaptation of ethical best practices. We define the\nsocial dilemma for AI development and describe why the current crisis in AI\ndevelopment ethics cannot be solved without relieving AI developers of their\nsocial dilemma. We argue that AI development must be professionalised to\novercome the social dilemma, and discuss how medicine can be used as a template\nin this process.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:43:48 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 15:44:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Str\u00fcmke", "Inga", ""], ["Slavkovik", "Marija", ""], ["Madai", "Vince I.", ""]]}, {"id": "2107.13115", "submitter": "Lu Wang", "authors": "Lu Wang, Munif Ishad Mujib, Jake Williams, George Demiris, Jina\n  Huh-Yoo", "title": "An Evaluation of Generative Pre-Training Model-based Therapy Chatbot for\n  Caregivers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of off-the-shelf intelligent home products and broader\ninternet adoption, researchers increasingly explore smart computing\napplications that provide easier access to health and wellness resources.\nAI-based systems like chatbots have the potential to provide services that\ncould provide mental health support. However, existing therapy chatbots are\noften retrieval-based, requiring users to respond with a constrained set of\nanswers, which may not be appropriate given that such pre-determined inquiries\nmay not reflect each patient's unique circumstances. Generative-based\napproaches, such as the OpenAI GPT models, could allow for more dynamic\nconversations in therapy chatbot contexts than previous approaches. To\ninvestigate the generative-based model's potential in therapy chatbot contexts,\nwe built a chatbot using the GPT-2 model. We fine-tuned it with 306 therapy\nsession transcripts between family caregivers of individuals with dementia and\ntherapists conducting Problem Solving Therapy. We then evaluated the model's\npre-trained and the fine-tuned model in terms of basic qualities using three\nmeta-information measurements: the proportion of non-word outputs, the length\nof response, and sentiment components. Results showed that: (1) the fine-tuned\nmodel created more non-word outputs than the pre-trained model; (2) the\nfine-tuned model generated outputs whose length was more similar to that of the\ntherapists compared to the pre-trained model; (3) both the pre-trained model\nand fine-tuned model were likely to generate more negative and fewer positive\noutputs than the therapists. We discuss potential reasons for the problem, the\nimplications, and solutions for developing therapy chatbots and call for\ninvestigations of the AI-based system application.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 01:01:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Lu", ""], ["Mujib", "Munif Ishad", ""], ["Williams", "Jake", ""], ["Demiris", "George", ""], ["Huh-Yoo", "Jina", ""]]}, {"id": "2107.13236", "submitter": "David Garcia", "authors": "David Garcia, Max Pellert, Jana Lasser, Hannah Metzler", "title": "Social media emotion macroscopes reflect emotional experiences in\n  society at large", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media generate data on human behaviour at large scales and over long\nperiods of time, posing a complementary approach to traditional methods in the\nsocial sciences. Millions of texts from social media can be processed with\ncomputational methods to study emotions over time and across regions. However,\nrecent research has shown weak correlations between social media emotions and\naffect questionnaires at the individual level and between static regional\naggregates of social media emotion and subjective well-being at the population\nlevel, questioning the validity of social media data to study emotions. Yet, to\ndate, no research has tested the validity of social media emotion macroscopes\nto track the temporal evolution of emotions at the level of a whole society.\nHere we present a pre-registered prediction study that shows how\ngender-rescaled time series of Twitter emotional expression at the national\nlevel substantially correlate with aggregates of self-reported emotions in a\nweekly representative survey in the United Kingdom. A follow-up exploratory\nanalysis shows a high prevalence of third-person references in\nemotionally-charged tweets, indicating that social media data provide a way of\nsocial sensing the emotions of others rather than just the emotional\nexperiences of users. These results show that, despite the issues that social\nmedia have in terms of representativeness and algorithmic confounding, the\ncombination of advanced text analysis methods with user demographic information\nin social media emotion macroscopes can provide measures that are informative\nof the general population beyond social media users.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 09:40:42 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Garcia", "David", ""], ["Pellert", "Max", ""], ["Lasser", "Jana", ""], ["Metzler", "Hannah", ""]]}, {"id": "2107.13368", "submitter": "Hongping Zhang", "authors": "Hongping Zhang, Zhenfeng Shao, Bin Hua, Xiao Huang, Jinqi Zhao, Wenfu\n  Wu, Yewen Fan", "title": "Evaluating the weight sensitivity in AHP-based flood risk estimation\n  models", "comments": "42pages, 12 figures, 7 tables. It is about sensitivity analyzing of\n  flood risk estimation using pixels or sub-watershed as basic unit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the analytic hierarchy process (AHP) based flood risk estimation models,\nit is widely acknowledged that different weighting criteria can lead to\ndifferent results. In this study, we evaluated and discussed the sensitivity of\nflood risk estimation brought by judgment matrix definition by investigating\nthe performance of pixel-based and sub-watershed-based AHP models. Taking a\nflood event that occurred in July 2020 in Chaohu basin, Anhui province, China,\nas a study case, we used the flood areas extracted from remote sensing images\nto construct ground truth for validation purposes. The results suggest that the\nperformance of the pixel-based AHP model fluctuates intensively given different\ndefinitions of judgment matrixes, while the performance of sub-watershed-based\nAHP models fluctuates considerably less than that of the pixel-based AHP model.\nSpecifically, sub-watershed delimitated via multiple flow direction (MFD)\nalways achieves increases in the correct ratio and the fit ratio by >35% and\n>5% with the pixel-based AHP model, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 13:56:43 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhang", "Hongping", ""], ["Shao", "Zhenfeng", ""], ["Hua", "Bin", ""], ["Huang", "Xiao", ""], ["Zhao", "Jinqi", ""], ["Wu", "Wenfu", ""], ["Fan", "Yewen", ""]]}, {"id": "2107.13509", "submitter": "Upol Ehsan", "authors": "Upol Ehsan, Samir Passi, Q. Vera Liao, Larry Chan, I-Hsiang Lee,\n  Michael Muller, Mark O. Riedl", "title": "The Who in Explainable AI: How AI Background Shapes Perceptions of AI\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainability of AI systems is critical for users to take informed actions\nand hold systems accountable. While \"opening the opaque box\" is important,\nunderstanding who opens the box can govern if the Human-AI interaction is\neffective. In this paper, we conduct a mixed-methods study of how two different\ngroups of whos--people with and without a background in AI--perceive different\ntypes of AI explanations. These groups were chosen to look at how disparities\nin AI backgrounds can exacerbate the creator-consumer gap. We quantitatively\nshare what the perceptions are along five dimensions: confidence, intelligence,\nunderstandability, second chance, and friendliness. Qualitatively, we highlight\nhow the AI background influences each group's interpretations and elucidate why\nthe differences might exist through the lenses of appropriation and cognitive\nheuristics. We find that (1) both groups had unwarranted faith in numbers, to\ndifferent extents and for different reasons, (2) each group found explanatory\nvalues in different explanations that went beyond the usage we designed them\nfor, and (3) each group had different requirements of what counts as humanlike\nexplanations. Using our findings, we discuss potential negative consequences\nsuch as harmful manipulation of user trust and propose design interventions to\nmitigate them. By bringing conscious awareness to how and why AI backgrounds\nshape perceptions of potential creators and consumers in XAI, our work takes a\nformative step in advancing a pluralistic Human-centered Explainable AI\ndiscourse.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:32:04 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ehsan", "Upol", ""], ["Passi", "Samir", ""], ["Liao", "Q. Vera", ""], ["Chan", "Larry", ""], ["Lee", "I-Hsiang", ""], ["Muller", "Michael", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2107.13625", "submitter": "William Paul", "authors": "William Paul, Philippe Burlina", "title": "Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive\n  Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When deploying artificial intelligence (AI) in the real world, being able to\ntrust the operation of the AI by characterizing how it performs is an\never-present and important topic. An important and still largely unexplored\ntask in this characterization is determining major factors within the real\nworld that affect the AI's behavior, such as weather conditions or lighting,\nand either a) being able to give justification for why it may have failed or b)\neliminating the influence the factor has. Determining these sensitive factors\nheavily relies on collected data that is diverse enough to cover numerous\ncombinations of these factors, which becomes more onerous when having many\npotential sensitive factors or operating in complex environments. This paper\ninvestigates methods that discover and separate out individual semantic\nsensitive factors from a given dataset to conduct this characterization as well\nas addressing mitigation of these factors' sensitivity. We also broaden\nremediation of fairness, which normally only addresses socially relevant\nfactors, and widen it to deal with the desensitization of AI with regard to all\npossible aspects of variation in the domain. The proposed methods which\ndiscover these major factors reduce the potentially onerous demands of\ncollecting a sufficiently diverse dataset. In experiments using the road sign\n(GTSRB) and facial imagery (CelebA) datasets, we show the promise of using this\nscheme to perform this characterization and remediation and demonstrate that\nour approach outperforms state of the art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:18:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Paul", "William", ""], ["Burlina", "Philippe", ""]]}, {"id": "2107.13671", "submitter": "Sebastian Raschka", "authors": "Sebastian Raschka", "title": "Deeper Learning By Doing: Integrating Hands-On Research Projects Into a\n  Machine Learning Course", "comments": "This paper was accepted to the Teaching Machine Learning Workshop at\n  ECML 2021 (https://teaching-ml.github.io/2021/). Reviews and comments are\n  available at https://openreview.net/forum?id=yFPqbprG2Qb&noteId=rSPC7tA6Pi_", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has seen a vast increase of interest in recent years, along\nwith an abundance of learning resources. While conventional lectures provide\nstudents with important information and knowledge, we also believe that\nadditional project-based learning components can motivate students to engage in\ntopics more deeply. In addition to incorporating project-based learning in our\ncourses, we aim to develop project-based learning components aligned with\nreal-world tasks, including experimental design and execution, report writing,\noral presentation, and peer-reviewing. This paper describes the organization of\nour project-based machine learning courses with a particular emphasis on the\nclass project components and shares our resources with instructors who would\nlike to include similar elements in their courses.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 23:41:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Raschka", "Sebastian", ""]]}, {"id": "2107.13734", "submitter": "Desmond Ong", "authors": "Desmond C. Ong", "title": "An Ethical Framework for Guiding the Development of Affectively-Aware\n  Artificial Intelligence", "comments": "Accepted at IEEE Affective Computing and Intelligent Interaction 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The recent rapid advancements in artificial intelligence research and\ndeployment have sparked more discussion about the potential ramifications of\nsocially- and emotionally-intelligent AI. The question is not if research can\nproduce such affectively-aware AI, but when it will. What will it mean for\nsociety when machines -- and the corporations and governments they serve -- can\n\"read\" people's minds and emotions? What should developers and operators of\nsuch AI do, and what should they not do? The goal of this article is to\npre-empt some of the potential implications of these developments, and propose\na set of guidelines for evaluating the (moral and) ethical consequences of\naffectively-aware AI, in order to guide researchers, industry professionals,\nand policy-makers. We propose a multi-stakeholder analysis framework that\nseparates the ethical responsibilities of AI Developers vis-\\`a-vis the\nentities that deploy such AI -- which we term Operators. Our analysis produces\ntwo pillars that clarify the responsibilities of each of these stakeholders:\nProvable Beneficence, which rests on proving the effectiveness of the AI, and\nResponsible Stewardship, which governs responsible collection, use, and storage\nof data and the decisions made from such data. We end with recommendations for\nresearchers, developers, operators, as well as regulators and law-makers.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 03:57:53 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ong", "Desmond C.", ""]]}, {"id": "2107.13964", "submitter": "Erkin Otles", "authors": "Erkin \\\"Otle\\c{s}, Jeeheh Oh, Benjamin Li, Michelle Bochinski, Hyeon\n  Joo, Justin Ortwine, Erica Shenoy, Laraine Washer, Vincent B. Young, Krishna\n  Rao, Jenna Wiens", "title": "Mind the Performance Gap: Examining Dataset Shift During Prospective\n  Validation", "comments": "Accepted by the 2021 Machine Learning for Healthcare Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Once integrated into clinical care, patient risk stratification models may\nperform worse compared to their retrospective performance. To date, it is\nwidely accepted that performance will degrade over time due to changes in care\nprocesses and patient populations. However, the extent to which this occurs is\npoorly understood, in part because few researchers report prospective\nvalidation performance. In this study, we compare the 2020-2021 ('20-'21)\nprospective performance of a patient risk stratification model for predicting\nhealthcare-associated infections to a 2019-2020 ('19-'20) retrospective\nvalidation of the same model. We define the difference in retrospective and\nprospective performance as the performance gap. We estimate how i) \"temporal\nshift\", i.e., changes in clinical workflows and patient populations, and ii)\n\"infrastructure shift\", i.e., changes in access, extraction and transformation\nof data, both contribute to the performance gap. Applied prospectively to\n26,864 hospital encounters during a twelve-month period from July 2020 to June\n2021, the model achieved an area under the receiver operating characteristic\ncurve (AUROC) of 0.767 (95% confidence interval (CI): 0.737, 0.801) and a Brier\nscore of 0.189 (95% CI: 0.186, 0.191). Prospective performance decreased\nslightly compared to '19-'20 retrospective performance, in which the model\nachieved an AUROC of 0.778 (95% CI: 0.744, 0.815) and a Brier score of 0.163\n(95% CI: 0.161, 0.165). The resulting performance gap was primarily due to\ninfrastructure shift and not temporal shift. So long as we continue to develop\nand validate models using data stored in large research data warehouses, we\nmust consider differences in how and when data are accessed, measure how these\ndifferences may affect prospective performance, and work to mitigate those\ndifferences.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:30:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["\u00d6tle\u015f", "Erkin", ""], ["Oh", "Jeeheh", ""], ["Li", "Benjamin", ""], ["Bochinski", "Michelle", ""], ["Joo", "Hyeon", ""], ["Ortwine", "Justin", ""], ["Shenoy", "Erica", ""], ["Washer", "Laraine", ""], ["Young", "Vincent B.", ""], ["Rao", "Krishna", ""], ["Wiens", "Jenna", ""]]}, {"id": "2107.13966", "submitter": "Hoe-Han Goh", "authors": "Hoe-Han Goh", "title": "Artificial Intelligence in Achieving Sustainable Development Goals", "comments": "10 pages, 1 figure, under evaluation as a Perspective in Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This perspective illustrates some of the AI applications that can accelerate\nthe achievement of SDGs and also highlights some of the considerations that\ncould hinder the efforts towards them. This emphasizes the importance of\nestablishing standard AI guidelines and regulations for the beneficial\napplications of AI.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 03:51:10 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Goh", "Hoe-Han", ""]]}, {"id": "2107.13969", "submitter": "Sri Harsha Dumpala Mr", "authors": "Sri Harsha Dumpala, Sebastian Rodriguez, Sheri Rempel, Rudolf Uher,\n  Sageev Oore", "title": "Significance of Speaker Embeddings and Temporal Context for Depression\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Depression detection from speech has attracted a lot of attention in recent\nyears. However, the significance of speaker-specific information in depression\ndetection has not yet been explored. In this work, we analyze the significance\nof speaker embeddings for the task of depression detection from speech.\nExperimental results show that the speaker embeddings provide important cues to\nachieve state-of-the-art performance in depression detection. We also show that\ncombining conventional OpenSMILE and COVAREP features, which carry\ncomplementary information, with speaker embeddings further improves the\ndepression detection performance. The significance of temporal context in the\ntraining of deep learning models for depression detection is also analyzed in\nthis paper.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jul 2021 05:14:48 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Dumpala", "Sri Harsha", ""], ["Rodriguez", "Sebastian", ""], ["Rempel", "Sheri", ""], ["Uher", "Rudolf", ""], ["Oore", "Sageev", ""]]}, {"id": "2107.13984", "submitter": "Leon Abdillah", "authors": "Leon A. Abdillah", "title": "Web-Based Learning", "comments": "25 pages, in Indonesian language, book section in Model Pembelajaran\n  Era Society 5.0, Cirebon, INSANIA, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Technology (IT) has had a number of positive impacts in various\nfields. In the world of education, IT provides its own style with various modes\nthat may be used. Modern education in the era of globalization and based on\nInformation Technology has transformed towards digital. IT has become the\nbackbone of the modern learning process. The educational process that was\npreviously carried out classically with a direct face-to-face mode has\nexperienced a shift towards distance learning mode. In distance learning mode,\nstudents can access lecture material via the internet. Web-based learning is\noften also called online learning or e-learning because it includes course\ncontent and includes all educational interventions that use the internet (or\nlocal intranet).\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:33:08 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Abdillah", "Leon A.", ""]]}, {"id": "2107.13986", "submitter": "Arlindo Flavio da Concei\\c{c}\\~ao", "authors": "Alexandre Siqueira and Arlindo Flavio da Concei\\c{c}\\~ao and Vladimir\n  Rocha", "title": "User-Centric Health Data Using Self-sovereign Identities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This article presents the potential use of the Self-Sovereign Identities\n(SSI), combining with Distributed Ledger Technologies (DLT), to improve the\nprivacy and control of health data. The paper presents the SSI technology,\nlists the prominent use cases of decentralized identities in the health area,\nand discusses an effective blockchain-based architecture. The main\ncontributions of the article are: (i) mapping SSI general and abstract\nconcepts, e.g., issuers and holders, to the health domain concepts, e.g.,\nphysicians and patients; (ii) creating a correspondence between the SSI\ninteractions, e.g., issue and verify a credential, and the US standardized set\nof health use cases; (iii) presenting and instantiating an architecture to deal\nwith the use cases mentioned, effectively organizing the data in a user-centric\nway, that uses well-known SSI and Blockchain technologies.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:09:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Siqueira", "Alexandre", ""], ["da Concei\u00e7\u00e3o", "Arlindo Flavio", ""], ["Rocha", "Vladimir", ""]]}, {"id": "2107.13998", "submitter": "Michael Lyons", "authors": "Michael J. Lyons", "title": "\"Excavating AI\" Re-excavated: Debunking a Fallacious Account of the\n  JAFFE Dataset", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twenty-five years ago, my colleagues Miyuki Kamachi and Jiro Gyoba and I\ndesigned and photographed JAFFE, a set of facial expression images intended for\nuse in a study of face perception. In 2019, without seeking permission or\ninforming us, Kate Crawford and Trevor Paglen exhibited JAFFE in two widely\npublicized art shows. In addition, they published a nonfactual account of the\nimages in the essay \"Excavating AI: The Politics of Images in Machine Learning\nTraining Sets.\" The present article recounts the creation of the JAFFE dataset\nand unravels each of Crawford and Paglen's fallacious statements. I also\ndiscuss JAFFE more broadly in connection with research on facial expression,\naffective computing, and human-computer interaction.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 01:31:59 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lyons", "Michael J.", ""]]}, {"id": "2107.14013", "submitter": "Jonathan Roberts PhD", "authors": "Jonathan C. Roberts, Peter Butcher, Ann Sherlock and Sarah Nason", "title": "Explanatory Journeys: Visualising to Understand and Explain\n  Administrative Justice Paths of Redress", "comments": "11 pages with 10 figures, accepted for publication in IEEE\n  Transactions on Visualization and Computer Graphics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Administrative justice concerns the relationships between individuals and the\nstate. It includes redress and complaints on decisions of a child's education,\nsocial care, licensing, planning, environment, housing and homelessness.\nHowever, if someone has a complaint or an issue, it is challenging for people\nto understand different possible redress paths and explore what path is\nsuitable for their situation. Explanatory visualisation has the potential to\ndisplay these paths of redress in a clear way, such that people can see,\nunderstand and explore their options. The visualisation challenge is further\ncomplicated because information is spread across many documents, laws, guidance\nand policies and requires judicial interpretation. Consequently, there is not a\nsingle database of paths of redress. In this work we present how we have\nco-designed a system to visualise administrative justice paths of redress.\nSimultaneously, we classify, collate and organise the underpinning data, from\nexpert workshops, heuristic evaluation and expert critical reflection. We make\nfour contributions: (i) an application design study of the explanatory\nvisualisation tool (Artemus), (ii) coordinated and co-design approach to\naggregating the data, (iii) two in-depth case studies in housing and education\ndemonstrating explanatory paths of redress in administrative law, and (iv)\nreflections on the expert co-design process and expert data gathering and\nexplanatory visualisation for administrative justice and law.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:25:58 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Roberts", "Jonathan C.", ""], ["Butcher", "Peter", ""], ["Sherlock", "Ann", ""], ["Nason", "Sarah", ""]]}, {"id": "2107.14034", "submitter": "Bo Lin", "authors": "Bo Lin, Bissan Ghaddar, Ada Hurst", "title": "Text Mining Undergraduate Engineering Programs' Applications: the Role\n  of Gender, Nationality, and Socio-economic Status", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Women, visible minorities, and other socially disadvantaged groups continue\nto be underrepresented in STEM education. Understanding students' motivations\nfor pursuing a STEM major, and the roles gender, ethnicity, parental education\nattainment, and socio-economic background play in shaping students' motivations\ncan support the design of more effective recruitment efforts towards these\ngroups. In this paper, we propose and develop a novel text mining approach\nincorporating the Latent Dirichlet Allocation and word embeddings to extract\nand analyze applicants' motivational factors to choosing an engineering\nprogram. We apply the proposed method to a data set of over 40,000 applications\nto the engineering school of a large North American university. We then\ninvestigate the relationship between applicants' gender, nationality, family\nincome, and educational attainment, and their stated motivations for applying\nto their engineering program of choice. We find that interest in technology and\nthe desire to make social impacts are the two most powerful motivators for\napplicants. Additionally, while we find significant motivational differences\nrelated to applicants' nationality and family socioeconomic status, gender\ndifferences are isolated from the effects of these factors.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:47:18 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lin", "Bo", ""], ["Ghaddar", "Bissan", ""], ["Hurst", "Ada", ""]]}, {"id": "2107.14035", "submitter": "Mike Wu", "authors": "Mike Wu, Noah Goodman, Chris Piech, Chelsea Finn", "title": "ProtoTransformer: A Meta-Learning Approach to Providing Student Feedback", "comments": "9 pages content; 6 pages supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  High-quality computer science education is limited by the difficulty of\nproviding instructor feedback to students at scale. While this feedback could\nin principle be automated, supervised approaches to predicting the correct\nfeedback are bottlenecked by the intractability of annotating large quantities\nof student code. In this paper, we instead frame the problem of providing\nfeedback as few-shot classification, where a meta-learner adapts to give\nfeedback to student code on a new programming question from just a few examples\nannotated by instructors. Because data for meta-training is limited, we propose\na number of amendments to the typical few-shot learning framework, including\ntask augmentation to create synthetic tasks, and additional side information to\nbuild stronger priors about each task. These additions are combined with a\ntransformer architecture to embed discrete sequences (e.g. code) to a\nprototypical representation of a feedback class label. On a suite of few-shot\nnatural language processing tasks, we match or outperform state-of-the-art\nperformance. Then, on a collection of student solutions to exam questions from\nan introductory university course, we show that our approach reaches an average\nprecision of 88% on unseen questions, surpassing the 82% precision of teaching\nassistants. Our approach was successfully deployed to deliver feedback to\n16,000 student exam-solutions in a programming course offered by a tier 1\nuniversity. This is, to the best of our knowledge, the first successful\ndeployment of a machine learning based feedback to open-ended student code.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 22:41:28 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Wu", "Mike", ""], ["Goodman", "Noah", ""], ["Piech", "Chris", ""], ["Finn", "Chelsea", ""]]}, {"id": "2107.14036", "submitter": "Abhaya Nayak", "authors": "Nguyen H Tran and Abhaya C Nayak", "title": "Self-Driving Cars and Driver Alertness", "comments": "12 pages. Planned to be submitted to the 34th Australasian Joint\n  Conference on Artificial Intelligence (AJCAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent years have seen growing interest in the development of self-driving\nvehicles that promise (or threaten) to replace human drivers with intelligent\nsoftware. However, current self-driving cars still require human supervision\nand prompt takeover of control when necessary. Poor alertness while controlling\nself-driving cars could hinder the drivers' ability to intervene during\nunpredictable situations, thus increasing the risk of avoidable accidents. In\nthis paper we examine the key factors that contribute to drivers' poor\nalertness, and the potential solutions that have been proposed to address them.\nBased on this examination we make some recommendations for various\nstakeholders, such as researchers, drivers, industry and policy makers.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 23:55:44 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Tran", "Nguyen H", ""], ["Nayak", "Abhaya C", ""]]}, {"id": "2107.14039", "submitter": "Joost Visser", "authors": "Olivier Koster and Ruud Kosman and Joost Visser", "title": "A Checklist for Explainable AI in the Insurance Domain", "comments": "Preprint of short paper for QUATIC 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) is a powerful tool to accomplish a great many\ntasks. This exciting branch of technology is being adopted increasingly across\nvarying sectors, including the insurance domain. With that power arise several\ncomplications. One of which is a lack of transparency and explainability of an\nalgorithm for experts and non-experts alike. This brings into question both the\nusefulness as well as the accuracy of the algorithm, coupled with an added\ndifficulty to assess potential biases within the data or the model. In this\npaper, we investigate the current usage of AI algorithms in the Dutch insurance\nindustry and the adoption of explainable artificial intelligence (XAI)\ntechniques. Armed with this knowledge we design a checklist for insurance\ncompanies that should help assure quality standards regarding XAI and a solid\nfoundation for cooperation between organisations. This checklist extends an\nexisting checklist of SIVI, the standardisation institute for digital\ncooperation and innovation in Dutch insurance.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 10:19:04 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Koster", "Olivier", ""], ["Kosman", "Ruud", ""], ["Visser", "Joost", ""]]}, {"id": "2107.14040", "submitter": "Dinh Nguyen", "authors": "Quoc-Viet Pham, Dinh C. Nguyen, Thien Huynh-The, Won-Joo Hwang, Pubudu\n  N Pathirana", "title": "Artificial Intelligence (AI) and Big Data for Coronavirus (COVID-19)\n  Pandemic: A Survey on the State-of-the-Arts", "comments": "Accepted at IEEE Access Journal, 19 pages", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3009328", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The very first infected novel coronavirus case (COVID-19) was found in Hubei,\nChina in Dec. 2019. The COVID-19 pandemic has spread over 214 countries and\nareas in the world, and has significantly affected every aspect of our daily\nlives. At the time of writing this article, the numbers of infected cases and\ndeaths still increase significantly and have no sign of a well-controlled\nsituation, e.g., as of 13 July 2020, from a total number of around 13.1 million\npositive cases, 571, 527 deaths were reported in the world. Motivated by recent\nadvances and applications of artificial intelligence (AI) and big data in\nvarious areas, this paper aims at emphasizing their importance in responding to\nthe COVID-19 outbreak and preventing the severe effects of the COVID-19\npandemic. We firstly present an overview of AI and big data, then identify the\napplications aimed at fighting against COVID-19, next highlight challenges and\nissues associated with state-of-the-art solutions, and finally come up with\nrecommendations for the communications to effectively control the COVID-19\nsituation. It is expected that this paper provides researchers and communities\nwith new insights into the ways AI and big data improve the COVID-19 situation,\nand drives further studies in stopping the COVID-19 outbreak.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 13:12:30 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Pham", "Quoc-Viet", ""], ["Nguyen", "Dinh C.", ""], ["Huynh-The", "Thien", ""], ["Hwang", "Won-Joo", ""], ["Pathirana", "Pubudu N", ""]]}, {"id": "2107.14041", "submitter": "Pankajeshwara Nand Sharma", "authors": "Fabrice Lartigou, Michael Govorov, Tofiga Aisake and Pankajeshwara N.\n  Sharma", "title": "Interactive GIS Web-Atlas for Twelve Pacific Islands Countries", "comments": "Project report article to Intergraph. (GeoMedia Research Laboratory\n  Initiative)", "journal-ref": null, "doi": "10.13140/RG.2.2.18883.73765", "report-no": null, "categories": "cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article deals with the development of an interactive up-to-date Pacific\nIslands Web GIS Atlas. It focuses on the compilation of spatial data from the\ntwelve member countries of the University of the South Pacific (Cook Islands,\nFiji Islands, Kiribati Islands, Marshall Islands, Nauru, Niue, Tonga, Tuvalu,\nTokelau, Solomon Islands, Vanuatu, and Western Samoa). A previous bitmap web\nAtlas was created in 1996, and was a pilot activity investigating the potential\nfor using Geographical Information Systems (GIS) in the South Pacific. The\nobjective of the new atlas is to provide sets of spatial and attributive data\nand maps for use of educators, students, researchers, policy makers and other\nrelevant user groups and the public. GIS is a highly flexible and dynamic\ntechnology that allows the construction and analysis of maps and data sets from\na variety of sources and formats. Nowadays, GIS application has moved from\nlocal and client-server applications to a three-tier architecture: Client (Web\nBrowser) -- Application Web Map Server -- Spatial Data Warehouses. The\nobjective of this project is to produce an Atlas that will include interactive\nmaps and data on an Application Web Map Server. Intergraph products such as\nGeoMedia Professional, Web Map and Web Publisher have been selected for the web\natlas production and design. In an interactive environment, an atlas will be\ncomposed from a series of maps and data profiles, which will be based on legend\nentries, queries, hot spots and cartographic tools. Only the first stage of\ndevelopment of the atlas and related technological solutions are outlined in\nthis article.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:41:01 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lartigou", "Fabrice", ""], ["Govorov", "Michael", ""], ["Aisake", "Tofiga", ""], ["Sharma", "Pankajeshwara N.", ""]]}, {"id": "2107.14042", "submitter": "Alexis Baria", "authors": "Alexis T. Baria (1) and Keith Cross (2) ((1) Society of Spoken Art,\n  New York, USA, (2) University of Hawai`i at Manoa, Honolulu, USA)", "title": "The brain is a computer is a brain: neuroscience's internal debate and\n  the social significance of the Computational Metaphor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Computational Metaphor, comparing the brain to the computer and vice\nversa, is the most prominent metaphor in neuroscience and artificial\nintelligence (AI). Its appropriateness is highly debated in both fields,\nparticularly with regards to whether it is useful for the advancement of\nscience and technology. Considerably less attention, however, has been devoted\nto how the Computational Metaphor is used outside of the lab, and particularly\nhow it may shape society's interactions with AI. As such, recently publicized\nconcerns over AI's role in perpetuating racism, genderism, and ableism suggest\nthat the term \"artificial intelligence\" is misplaced, and that a new lexicon is\nneeded to describe these computational systems. Thus, there is an essential\nquestion about the Computational Metaphor that is rarely asked by\nneuroscientists: whom does it help and whom does it harm? This essay invites\nthe neuroscience community to consider the social implications of the field's\nmost controversial metaphor.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 12:13:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Baria", "Alexis T.", ""], ["Cross", "Keith", ""]]}, {"id": "2107.14043", "submitter": "Endang Mulyati Ningsih", "authors": "Endang Mulyatiningsih, Sri Palupi, Prihastuti Ekawatiningsih, Ambar\n  Rizqi Firdausa", "title": "The Characteristics of Enjoyable Online Learning for Culinary Arts\n  Student", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Covid-19 pandemic outbreak has forced all courses to be carried out\nonline, but only a few truly fulfill student expectations. This study aims to\nexplain the characteristics of enjoyable online learning based on the platform,\nthe content, and the learning model. Data collected using closed and open\nquestionnaires which were responded to by 110 students in 2019/2020. The closed\nquestionnaire revealed the most preferred learning elements, and the open\nquestionnaire was to clarify their reasons. The data were arranged sequentially\nfrom the quantitative data to the qualitative data. The results of the study\nshowed that (1) the preferred online platforms were Moodle, Google Meet, and\nWhatsApp. They like Moodle because the content is well structured, Google Meet\nis easily accessible, and WhatsApp is their daily routine application; (2) The\nlearning content consists of 2 to 3 resources i.e.: 6-10 pages papers, 11-15\npages PowerPoint and 6-10 minute videos. Too much content causes a heavy\nlearning burden; (3) Most students preferred the blended learning strategy. The\nsynchronous lectures for 60-75 minutes can motivate them because they can\ninteract with lecturers and other students. Asynchronous lectures are more\nflexible that can be done anytime and anywhere so that the students become more\nindependent in their learning\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:34:57 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Mulyatiningsih", "Endang", ""], ["Palupi", "Sri", ""], ["Ekawatiningsih", "Prihastuti", ""], ["Firdausa", "Ambar Rizqi", ""]]}, {"id": "2107.14044", "submitter": "Ramya Akula", "authors": "Ramya Akula and Ivan Garibay", "title": "Ethical AI for Social Good", "comments": null, "journal-ref": "International Conference on Human-Computer Interaction, 2021", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of AI for Social Good(AI4SG) is gaining momentum in both\ninformation societies and the AI community. Through all the advancement of\nAI-based solutions, it can solve societal issues effectively. To date, however,\nthere is only a rudimentary grasp of what constitutes AI socially beneficial in\nprinciple, what constitutes AI4SG in reality, and what are the policies and\nregulations needed to ensure it. This paper fills the vacuum by addressing the\nethical aspects that are critical for future AI4SG efforts. Some of these\ncharacteristics are new to AI, while others have greater importance due to its\nusage.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:16:51 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Akula", "Ramya", ""], ["Garibay", "Ivan", ""]]}, {"id": "2107.14046", "submitter": "Ramya Akula", "authors": "Ramya Akula and Ivan Garibay", "title": "Audit and Assurance of AI Algorithms: A framework to ensure ethical\n  algorithmic practices in Artificial Intelligence", "comments": null, "journal-ref": "International Conference on Human-Computer Interaction 2021", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithms are becoming more widely used in business, and businesses are\nbecoming increasingly concerned that their algorithms will cause significant\nreputational or financial damage. We should emphasize that any of these damages\nstem from situations in which the United States lacks strict legislative\nprohibitions or specified protocols for measuring damages. As a result,\ngovernments are enacting legislation and enforcing prohibitions, regulators are\nfining businesses, and the judiciary is debating whether or not to make\nartificially intelligent computer models as the decision-makers in the eyes of\nthe law. From autonomous vehicles and banking to medical care, housing, and\nlegal decisions, there will soon be enormous amounts of algorithms that make\ndecisions with limited human interference. Governments, businesses, and society\nwould have an algorithm audit, which would have systematic verification that\nalgorithms are lawful, ethical, and secure, similar to financial audits. A\nmodern market, auditing, and assurance of algorithms developed to\nprofessionalize and industrialize AI, machine learning, and related algorithms.\nStakeholders of this emerging field include policymakers and regulators, along\nwith industry experts and entrepreneurs. In addition, we foresee audit\nthresholds and frameworks providing valuable information to all who are\nconcerned with governance and standardization. This paper aims to review the\ncritical areas required for auditing and assurance and spark discussion in this\nnovel field of study and practice.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 15:16:40 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Akula", "Ramya", ""], ["Garibay", "Ivan", ""]]}, {"id": "2107.14047", "submitter": "Sourav Ghosh", "authors": "Anupam Khan, Sourav Ghosh, Soumya K. Ghosh", "title": "Measuring Domain Knowledge for Early Prediction of Student Performance:\n  A Semantic Approach", "comments": "Published in 2020 IEEE International Conference on Teaching,\n  Assessment, and Learning for Engineering (TALE). 8 pages, 5 figures (includes\n  16 plots). Accessible at https://ieeexplore.ieee.org/document/9368439", "journal-ref": "2020 IEEE International Conference on Teaching, Assessment, and\n  Learning for Engineering (TALE), Takamatsu, Japan, 2020, pp. 444-451", "doi": "10.1109/TALE48869.2020.9368439", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The growing popularity of data mining catalyses the researchers to explore\nvarious exciting aspects of education. Early prediction of student performance\nis an emerging area among them. The researchers have used various predictors in\nperformance modelling studies. Although prior cognition can affect student\nperformance, establishing their relationship is still an open research\nchallenge. Quantifying the knowledge from readily available data is the major\nchallenge here. We have proposed a semantic approach for this purpose.\nAssociation mining on nearly 0.35 million observations establishes that prior\ncognition impacts the student performance. The proposed approach of measuring\ndomain knowledge can help the early performance modelling studies to use it as\na predictor.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 23:46:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Khan", "Anupam", ""], ["Ghosh", "Sourav", ""], ["Ghosh", "Soumya K.", ""]]}, {"id": "2107.14048", "submitter": "Laurent Kloeker", "authors": "Laurent Kloeker, Amarin Kloeker, Fabian Thomsen, Armin Erraji, Lutz\n  Eckstein, Serge Lamberty, Adrian Fazekas, Eszter Kall\\'o, Markus Oeser,\n  Charlotte Fl\\'echon, Jochen Lohmiller, Pascal Pfeiffer, Martin Sommer, Helen\n  Winter", "title": "Corridor for new mobility Aachen-D\\\"usseldorf: Methods and concepts of\n  the research project ACCorD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the Corridor for New Mobility Aachen - D\\\"usseldorf, an integrated\ndevelopment environment is created, incorporating existing test capabilities,\nto systematically test and validate automated vehicles in interaction with\nconnected Intelligent Transport Systems Stations (ITS-Ss). This is achieved\nthrough a time- and cost-efficient toolchain and methodology, in which\nsimulation, closed test sites as well as test fields in public transport are\nlinked in the best possible way. By implementing a digital twin, the recorded\ntraffic events can be visualized in real-time and driving functions can be\ntested in the simulation based on real data. In order to represent diverse\ntraffic scenarios, the corridor contains a highway section, a rural area, and\nurban areas. First, this paper outlines the project goals before describing the\nindividual project contents in more detail. These include the concepts of\ntraffic detection, driving function development, digital twin development, and\npublic involvement.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 07:09:51 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Kloeker", "Laurent", ""], ["Kloeker", "Amarin", ""], ["Thomsen", "Fabian", ""], ["Erraji", "Armin", ""], ["Eckstein", "Lutz", ""], ["Lamberty", "Serge", ""], ["Fazekas", "Adrian", ""], ["Kall\u00f3", "Eszter", ""], ["Oeser", "Markus", ""], ["Fl\u00e9chon", "Charlotte", ""], ["Lohmiller", "Jochen", ""], ["Pfeiffer", "Pascal", ""], ["Sommer", "Martin", ""], ["Winter", "Helen", ""]]}, {"id": "2107.14049", "submitter": "Taiwo Adetiloye Adetiloye", "authors": "Taiwo Adetiloye", "title": "Collaboration Planning of Stakeholders for Sustainable City Logistics\n  Operations", "comments": "https://spectrum.library.concordia.ca/973901/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  City logistics involves movements of goods in urban areas respecting the\nmunicipal and administrative guidelines. The importance of city logistics is\ngrowing over the years especially with its role in minimizing traffic\ncongestion and freeing up of public space for city residents. Collaboration is\nkey to managing city logistics operations efficiently. Collaboration can take\nplace in the form of goods consolidation, sharing of resources, information\nsharing, etc. We investigate the problems of collaboration planning of\nstakeholders to achieve sustainable city logistics operations. Two categories\nof models are proposed to evaluate the collaboration strategies. At the macro\nlevel, we have the simplified collaboration square model and advance\ncollaboration square model and at the micro level we have the operational level\nmodel. These collaboration decision making models, with their mathematical\nelaborations on business-to-business, business-to-customer,\ncustomer-to-business, and customer-to-customer provide roadmaps for evaluating\nthe collaboration strategies of stakeholders for achieving sustainable city\nlogistics operations attainable under non-chaotic situation and presumptions of\nhuman levity tendency. City logistics stakeholders can strive to achieve\neffective collaboration strategies for sustainable city logistics operations by\nmitigating the uncertainty effect and understanding the theories behind the\nmoving nature of the individual complexities of a city. To investigate system\ncomplexity, we propose axioms of uncertainty and use spider networks and system\ndynamics modeling to investigate system elements and their behavior over time.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:54:17 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Adetiloye", "Taiwo", ""]]}, {"id": "2107.14050", "submitter": "Ali Shahaab", "authors": "Ali Shahaab, Chaminda Hewage, Imtiaz Khan", "title": "Preventing Spoliation of Evidence with Blockchain: A Perspective from\n  South Asia", "comments": "ICBCT21, March 26-28, 2021, Shanghai, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evidence destruction and tempering is a time-tested tactic to protect the\npowerful perpetrators, criminals, and corrupt officials. Countries where law\nenforcing institutions and judicial system can be comprised, and evidence\ndestroyed or tampered, ordinary citizens feel disengaged with the investigation\nor prosecution process, and in some instances, intimidated due to the\nvulnerability to exposure and retribution. Using Distributed Ledger\nTechnologies (DLT), such as blockchain, as the underpinning technology, here we\npropose a conceptual model - 'EvidenceChain', through which citizens can\nanonymously upload digital evidence, having assurance that the integrity of the\nevidence will be preserved in an immutable and indestructible manner. Person\nuploading the evidence can anonymously share it with investigating authorities\nor openly with public, if coerced by the perpetrators or authorities.\nTransferring the ownership of evidence from authority to ordinary citizen, and\ncustodianship of evidence from susceptible centralized repository to an\nimmutable and indestructible distributed repository, can cause a paradigm shift\nof power that not only can minimize spoliation of evidence but human rights\nabuse too. Here the conceptual model was theoretically tested against some\nhigh-profile spoliation of evidence cases from four South Asian developing\ncountries that often rank high in global corruption index and low in human\nrights index.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 11:59:12 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Shahaab", "Ali", ""], ["Hewage", "Chaminda", ""], ["Khan", "Imtiaz", ""]]}, {"id": "2107.14052", "submitter": "Susan Von Struensee", "authors": "Susan von Struensee", "title": "The Role of Social Movements, Coalitions, and Workers in Resisting\n  Harmful Artificial Intelligence and Contributing to the Development of\n  Responsible AI", "comments": "184 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is mounting public concern over the influence that AI based systems has\nin our society. Coalitions in all sectors are acting worldwide to resist hamful\napplications of AI. From indigenous people addressing the lack of reliable\ndata, to smart city stakeholders, to students protesting the academic\nrelationships with sex trafficker and MIT donor Jeffery Epstein, the\nquestionable ethics and values of those heavily investing in and profiting from\nAI are under global scrutiny. There are biased, wrongful, and disturbing\nassumptions embedded in AI algorithms that could get locked in without\nintervention. Our best human judgment is needed to contain AI's harmful impact.\nPerhaps one of the greatest contributions of AI will be to make us ultimately\nunderstand how important human wisdom truly is in life on earth.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 18:51:29 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["von Struensee", "Susan", ""]]}, {"id": "2107.14065", "submitter": "Gregory Falco", "authors": "Gregory Falco, Paul Cornish, Sadie Creese, Madeline Carr, Myriam Dunn\n  Cavelty, Claudia Eckert, Herbert Lin, Gen Goto, Jamie Saunders, Andrew\n  Grotto, Howard Shrobe, Sean Kanuck, Lawrence Susskind, Arvind Parthasarathi", "title": "Cyber Crossroads: A Global Research Collaborative on Cyber Risk\n  Governance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spending on cybersecurity products and services is expected to top 123\nbillion U.S. dollars for 2020, more than double the 55 billion U.S. dollars\nspent in 2011.1 In that same period, cyber breaches quadrupled. Organizations\nglobally face increasing liabilities, while boards of directors grapple with a\nseemingly Sisyphean challenge. Cyber Crossroads was born out of these alarming\ntrends and a realization that the world cannot go on funneling finite resources\ninto an indefinite, intractable problem. Cyber Crossroads brings together\nexpertise from across the world, spanning aspects of the cyber problem\n(including technology, legal, risk, and economic) with the goal of creating a\nCyber Standard of Care built through a global, not-for-profit research\ncollaborative with no commercial interests. A Cyber Standard of Care should be\napplicable across industries and regardless of the organization size. It should\nbe practical and implementable, with no requirement to purchase any\nproduct/service. Cyber Standard of Care should be woven into the existing\ngovernance fabric of the organization and it should not be yet another\ntechnical checklist, but a process/governance framework that can stand over\ntime. To achieve this, we engaged with cyber risk experts and practitioners\nwith a variety of relevant expertise, secured the advice/guidance of regulators\nand legal experts across jurisdictions, and interviewed leaders from 56\norganizations globally to understand their challenges and identify best\npractices.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 11:58:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Falco", "Gregory", ""], ["Cornish", "Paul", ""], ["Creese", "Sadie", ""], ["Carr", "Madeline", ""], ["Cavelty", "Myriam Dunn", ""], ["Eckert", "Claudia", ""], ["Lin", "Herbert", ""], ["Goto", "Gen", ""], ["Saunders", "Jamie", ""], ["Grotto", "Andrew", ""], ["Shrobe", "Howard", ""], ["Kanuck", "Sean", ""], ["Susskind", "Lawrence", ""], ["Parthasarathi", "Arvind", ""]]}, {"id": "2107.14070", "submitter": "Aditya Jyoti Paul", "authors": "Aditya Jyoti Paul, Smaranjit Ghose, Kanishka Aggarwal, Niketha\n  Nethaji, Shivam Pal, Arnab Dutta Purkayastha", "title": "Machine Learning Advances aiding Recognition and Classification of\n  Indian Monuments and Landmarks", "comments": "Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tourism in India plays a quintessential role in the country's economy with an\nestimated 9.2% GDP share for the year 2018. With a yearly growth rate of 6.2%,\nthe industry holds a huge potential for being the primary driver of the economy\nas observed in the nations of the Middle East like the United Arab Emirates.\nThe historical and cultural diversity exhibited throughout the geography of the\nnation is a unique spectacle for people around the world and therefore serves\nto attract tourists in tens of millions in number every year. Traditionally,\ntour guides or academic professionals who study these heritage monuments were\nresponsible for providing information to the visitors regarding their\narchitectural and historical significance. However, unfortunately this system\nhas several caveats when considered on a large scale such as unavailability of\nsufficient trained people, lack of accurate information, failure to convey the\nrichness of details in an attractive format etc. Recently, machine learning\napproaches revolving around the usage of monument pictures have been shown to\nbe useful for rudimentary analysis of heritage sights. This paper serves as a\nsurvey of the research endeavors undertaken in this direction which would\neventually provide insights for building an automated decision system that\ncould be utilized to make the experience of tourism in India more modernized\nfor visitors.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 15:01:02 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Paul", "Aditya Jyoti", ""], ["Ghose", "Smaranjit", ""], ["Aggarwal", "Kanishka", ""], ["Nethaji", "Niketha", ""], ["Pal", "Shivam", ""], ["Purkayastha", "Arnab Dutta", ""]]}, {"id": "2107.14077", "submitter": "Soaad Hossain Mr", "authors": "Soraia Oueida, Soaad Hossain, Yehia Kotb, Syed Ishtiaque Ahmed", "title": "A Fair and Ethical Healthcare Artificial Intelligence System for\n  Monitoring Driver Behavior and Preventing Road Accidents", "comments": "12 pages, 2 figures, accepted to Future Technologies Conference (FTC\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to prevent transportation accidents and\nmonitor driver's behavior using a healthcare AI system that incorporates\nfairness and ethics. Dangerous medical cases and unusual behavior of the driver\nare detected. Fairness algorithm is approached in order to improve\ndecision-making and address ethical issues such as privacy issues, and to\nconsider challenges that appear in the wild within AI in healthcare and\ndriving. A healthcare professional will be alerted about any unusual activity,\nand the driver's location when necessary, is provided in order to enable the\nhealthcare professional to immediately help to the unstable driver. Therefore,\nusing the healthcare AI system allows for accidents to be predicted and thus\nprevented and lives may be saved based on the built-in AI system inside the\nvehicle which interacts with the ER system.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 20:23:42 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Oueida", "Soraia", ""], ["Hossain", "Soaad", ""], ["Kotb", "Yehia", ""], ["Ahmed", "Syed Ishtiaque", ""]]}, {"id": "2107.14082", "submitter": "Adib Syed Adib", "authors": "Adib Mohammed Syed", "title": "Social engineering: Concepts, Techniques and Security Countermeasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this report is to research the topic called Social Engineering\nin Cyber Security and present the explanation of the meaning, concepts,\ntechniques, and security countermeasures of Social Engineering based on factual\nacademic research.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:05:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Syed", "Adib Mohammed", ""]]}, {"id": "2107.14093", "submitter": "Elena Baninemeh", "authors": "Elena Baninemeh (1), Siamak Farshidi (2), Slinger Jansen (1) ((1)\n  Department of Information and Computer Science at Utrecht University,\n  Utrecht, the Netherlands, (2) Informatics Institute at University of\n  Amsterdam, Amsterdam, the Netherlands)", "title": "A Decision Model for Decentralized Autonomous Organization Platform\n  Selection: Three Industry Case Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized autonomous organizations as a new form of online governance\narecollections of smart contracts deployed on a blockchain platform that\nintercede groupsof people. A growing number of Decentralized Autonomous\nOrganization Platforms,such as Aragon and Colony, have been introduced in the\nmarket to facilitate thedevelopment process of such organizations. Selecting\nthe best fitting platform ischallenging for the organizations, as a significant\nnumber of decision criteria, such aspopularity, developer availability,\ngovernance issues, and consistent documentation ofsuch platforms, should be\nconsidered. Additionally, decision-makers at theorganizations are not experts\nin every domain, so they must continuously acquirevolatile knowledge regarding\nsuch platforms and keep themselves updated.Accordingly, a decision model is\nrequired to analyze the decision criteria usingsystematic identification and\nevaluation of potential alternative solutions for adevelopment project. We have\ndeveloped a theoretical framework to assist softwareengineers with a set of\nMulti-Criteria Decision-Making problems in software production.This study\npresents a decision model as a Multi-Criteria Decision-Making problem forthe\ndecentralized autonomous organization platform selection problem. Weconducted\nthree industry case studies in the context of three decentralizedautonomous\norganizations to evaluate the effectiveness and efficiency of the decisionmodel\nin assisting decision-makers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 10:05:56 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Baninemeh", "Elena", ""], ["Farshidi", "Siamak", ""], ["Jansen", "Slinger", ""]]}, {"id": "2107.14095", "submitter": "Md. Istiak Hossain Shihab", "authors": "Nazia Tasnim, Md. Istiak Hossain Shihab, Moqsadur Rahman, Sheikh\n  Rabiul Islam and Mohammad Ruhul Amin", "title": "Exploring the Scope and Potential of Local Newspaper-based Dengue\n  Surveillance in Bangladesh", "comments": "5 Pages, Joint KDD 2021 Health Day and 2021 KDD Workshop on Applied\n  Data Science for Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dengue fever has been considered to be one of the global public health\nproblems of the twenty-first century, especially in tropical and subtropical\ncountries of the global south. The high morbidity and mortality rates of Dengue\nfever impose a huge economic and health burden for middle and low-income\ncountries. It is so prevalent in such regions that enforcing a granular level\nof surveillance is quite impossible. Therefore, it is crucial to explore an\nalternative cost-effective solution that can provide updates of the ongoing\nsituation in a timely manner. In this paper, we explore the scope and potential\nof a local newspaper-based dengue surveillance system, using well-known\ndata-mining techniques, in Bangladesh from the analysis of the news contents\nwritten in the native language. In addition, we explain the working procedure\nof developing a novel database, using human-in-the-loop technique, for further\nanalysis, and classification of dengue and its intervention-related news. Our\nclassification method has an f-score of 91.45%, and matches the ground truth of\nreported cases quite closely. Based on the dengue and intervention-related\nnews, we identified the regions where more intervention efforts are needed to\nreduce the rate of dengue infection. A demo of this project can be accessed at:\nhttp://erdos.dsm.fordham.edu:3009/\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:48:15 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Tasnim", "Nazia", ""], ["Shihab", "Md. Istiak Hossain", ""], ["Rahman", "Moqsadur", ""], ["Islam", "Sheikh Rabiul", ""], ["Amin", "Mohammad Ruhul", ""]]}, {"id": "2107.14099", "submitter": "Charlotte Stix", "authors": "Charlotte Stix", "title": "The ghost of AI governance past, present and future: AI governance in\n  the European Union", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The received wisdom is that artificial intelligence (AI) is a competition\nbetween the US and China. In this chapter, the author will examine how the\nEuropean Union (EU) fits into that mix and what it can offer as a third way to\ngovern AI. The chapter presents this by exploring the past, present and future\nof AI governance in the EU. Section 1 serves to explore and evidence the EUs\ncoherent and comprehensive approach to AI governance. In short, the EU ensures\nand encourages ethical, trustworthy and reliable technological development.\nThis will cover a range of key documents and policy tools that lead to the most\ncrucial effort of the EU to date: to regulate AI. Section 2 maps the EUs drive\ntowards digital sovereignty through the lens of regulation and infrastructure.\nThis covers topics such as the trustworthiness of AI systems, cloud, compute\nand foreign direct investment. In Section 3, the chapter concludes by offering\nseveral considerations to achieve good AI governance in the EU.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 08:43:16 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Stix", "Charlotte", ""]]}, {"id": "2107.14100", "submitter": "Shivam Patel", "authors": "A. Jackulin Mahariba, Shivam Patel", "title": "Smart Band: An Integrated Device for Emergency Management", "comments": "3 pages, 6 figures", "journal-ref": "International Journal of Engineering and Advanced Technology,\n  Volume-8 Issue-4S2, April 2019", "doi": "10.35940/ijeat.D1010.0484S219", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the event of a kidnapping or a medical emergency, a person is often\nincapacitated to be able to call for help. And it's usually too late before the\nfirst responders arrive on-scene. Currently, a vast array of 'safety' devices\navailable in the market are often far too rudimentary such as double tapping\nthe power button that isn't very practical, or an app on a smart watch that is\na huge investment in the first place. The Smart Band aims to eliminate the need\nfor a physical trigger by the person who finds himself in dangerous situations\nlike kidnapping, front-facing some wild animal, heart attack, etc., and rather\nsenses the heartbeat. The Smart Band is designed as a personalized wearable\ndevice, wherein the user heart beat rate is collected and trained using machine\nlearning algorithm, which triggers the alert system automatically when the\nevent is identified. Hence the accuracy of assessing emergency situation will\nbe high and false rate will be reduced. As soon as the event is detected, the\nband relays GPS coordinates to first responders and emergency contacts, which\nwill be sent via the Network Carrier (SIM card module) directly from the band,\nnot relying on a mobile phone, which is usually out of reach during such\nemergency situations. In essence, the Smart Band consists of a GPS tracker, a\nheartbeat sensor, a Network module, and a Bluetooth module, all existing\ntechnologies which have been mass produced to an extent that the end product\ncan be made affordable, and in huge quantities as well. On further development\nthe smart band can be customized to a finely wearable jewel which can serve the\npurpose autonomously.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 06:40:06 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Mahariba", "A. Jackulin", ""], ["Patel", "Shivam", ""]]}, {"id": "2107.14101", "submitter": "Zoran \\v{S}koda", "authors": "Zoran \\v{S}koda", "title": "Why blockchain and smart contracts need semantic descriptions", "comments": "early draft, to be significantly expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We argue that there is a hierarchy of levels describing to that particular\nlevel relevant features of reality behind the content and behavior of\nblockchain and smart contracts in their realistic deployment.\n  Choice, design, audit and legal control of these systems could be more\ninformed, easier and raised to a higher level, if research on foundations of\nthese descriptions develops and sets the formalisms, tools and standards for\nsuch descriptions.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 17:48:06 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["\u0160koda", "Zoran", ""]]}, {"id": "2107.14107", "submitter": "Omer Aydin", "authors": "Omer Aydin", "title": "Analysis of the Visitor Data of a Higher Education Institution Website", "comments": "in Turkish language, Traffic analysis, Visitor analysis, Website\n  analysis, Corporate website, Trafik analizi, Ziyaretci analizi, Web sitesi\n  analizi, Kurumsal web sitesi", "journal-ref": "Yuksekogretim ve Bilim Dergisi, (2) , 299-309", "doi": "10.5961/jhes.2020.391", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In todays world, the internet affects every aspect of human life; it has\ncaused changes in corporate websites as well as in many other areas. Corporate\nwebsites should be more dynamic, more interactive, and more compatible with new\ntechnologies. The interaction of the website with users, search engines, and\nother devices has to be examined by experts, and improvements and changes\nshould be made for this interaction. In this study, a higher education\ninstitution website was examined. Visitor data collected between 2013 and 2019\nwere used for the analysis. In the study, which includes a wide range of\nexaminations and data, important findings from traffic analysis to development\nsuggestions were included. In particular, useful information has been obtained\nthrough the compatibility of the site with mobile devices, optimization of\npictures and videos, geographical features of users, language options, and\ndensity analysis of the content accessed over time.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 21:54:42 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Aydin", "Omer", ""]]}, {"id": "2107.14112", "submitter": "Petros Spachos", "authors": "Marc Jayson Baucas, Petros Spachos, and Stefano Gregori", "title": "Internet-of-Things Devices and Assistive Technologies for Healthcare:\n  Applications, Challenges, and Opportunities", "comments": null, "journal-ref": "IEEE Signal Processing Magazine, vol. 38, no. 4, pp. 65-77, July\n  2021", "doi": "10.1109/MSP.2021.3075929", "report-no": null, "categories": "physics.soc-ph cs.CY cs.LG cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical conditions and cases are growing at a rapid pace, where physical\nspace is starting to be constrained. Hospitals and clinics no longer have the\nability to accommodate large numbers of incoming patients. It is clear that the\ncurrent state of the health industry needs to improve its valuable and limited\nresources. The evolution of the Internet of Things (IoT) devices along with\nassistive technologies can alleviate the problem in healthcare, by being a\nconvenient and easy means of accessing healthcare services wirelessly. There is\na plethora of IoT devices and potential applications that can take advantage of\nthe unique characteristics that these technologies can offer. However, at the\nsame time, these services pose novel challenges that need to be properly\naddressed. In this article, we review some popular categories of IoT-based\napplications for healthcare along with their devices. Then, we describe the\nchallenges and discuss how research can properly address the open issues and\nimprove the already existing implementations in healthcare. Further possible\nsolutions are also discussed to show their potential in being viable solutions\nfor future healthcare applications\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 12:18:12 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Baucas", "Marc Jayson", ""], ["Spachos", "Petros", ""], ["Gregori", "Stefano", ""]]}]