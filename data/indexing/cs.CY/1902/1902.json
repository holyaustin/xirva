[{"id": "1902.00062", "submitter": "Justin Chan", "authors": "Justin Chan, Thomas Rea, Shyamnath Gollakota, Jacob E. Sunshine", "title": "Contactless Cardiac Arrest Detection Using Smart Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-hospital cardiac arrest (OHCA) is a leading cause of death worldwide.\nRapid diagnosis and initiation of cardiopulmonary resuscitation (CPR) is the\ncornerstone of therapy for victims of cardiac arrest. Yet a significant\nfraction of cardiac arrest victims have no chance of survival because they\nexperience an unwitnessed event, often in the privacy of their own homes. An\nunder-appreciated diagnostic element of cardiac arrest is the presence of\nagonal breathing, an audible biomarker and brainstem reflex that arises in the\nsetting of severe hypoxia. Here, we demonstrate that a support vector machine\n(SVM) can classify agonal breathing instances in real-time within a bedroom\nenvironment. Using real-world labeled 9-1-1 audio of cardiac arrests, we train\nthe SVM to accurately classify agonal breathing instances. We obtain an area\nunder the curve (AUC) of 0.998 and an operating point with an overall\nsensitivity and specificity of 97.03% (95% CI: 96.62 -- 97.41%) and 98.20% (95%\nCI: 97.87 -- 98.49%). We achieve a false positive rate between 0% -- 0.10% over\n82 hours (117,895 audio segments) of polysomnographic sleep lab data that\nincludes snoring, hypopnea, central and obstructive sleep apnea events. We\ndemonstrate the effectiveness of our contactless system in identifying\nreal-world cardiac arrest-associated agonal breathing instances and\nsuccessfully evaluate our classifier using commodity smart devices (Amazon Echo\nand Apple iPhone).\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 20:36:54 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 00:53:38 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Chan", "Justin", ""], ["Rea", "Thomas", ""], ["Gollakota", "Shyamnath", ""], ["Sunshine", "Jacob E.", ""]]}, {"id": "1902.00119", "submitter": "Rumi Chunara", "authors": "Kunal Relia, Zhengyi Li, Stephanie H. Cook, Rumi Chunara", "title": "Race, Ethnicity and National Origin-based Discrimination in Social Media\n  and Hate Crimes Across 100 U.S. Cities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study malicious online content via a specific type of hate speech: race,\nethnicity and national-origin based discrimination in social media, alongside\nhate crimes motivated by those characteristics, in 100 cities across the United\nStates. We develop a spatially-diverse training dataset and classification\npipeline to delineate targeted and self-narration of discrimination on social\nmedia, accounting for language across geographies. Controlling for census\nparameters, we find that the proportion of discrimination that is targeted is\nassociated with the number of hate crimes. Finally, we explore the linguistic\nfeatures of discrimination Tweets in relation to hate crimes by city, features\nused by users who Tweet different amounts of discrimination, and features of\ndiscrimination compared to non-discrimination Tweets. Findings from this\nspatial study can inform future studies of how discrimination in physical and\nvirtual worlds vary by place, or how physical and virtual world discrimination\nmay synergize.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 23:03:49 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Relia", "Kunal", ""], ["Li", "Zhengyi", ""], ["Cook", "Stephanie H.", ""], ["Chunara", "Rumi", ""]]}, {"id": "1902.00375", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en and Astrid Bunge and Carolin Hainke and Leon\n  Sindelar and Matthias Vogelsang", "title": "Dynamic fairness - Breaking vicious cycles in automatic decision making", "comments": "preprint of a paper accepted for oral presentation at the 27th\n  European Symposium on Artificial Neural Networks (ESANN 2019)", "journal-ref": "Proc. ESANN (2019), 477-482", "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning techniques have been increasingly applied\nin sensitive decision making processes, raising fairness concerns. Past\nresearch has shown that machine learning may reproduce and even exacerbate\nhuman bias due to biased training data or flawed model assumptions, and thus\nmay lead to discriminatory actions. To counteract such biased models,\nresearchers have proposed multiple mathematical definitions of fairness\naccording to which classifiers can be optimized. However, it has also been\nshown that the outcomes generated by some fairness notions may be\nunsatisfactory.\n  In this contribution, we add to this research by considering decision making\nprocesses in time. We establish a theoretic model in which even perfectly\naccurate classifiers which adhere to almost all common fairness definitions\nlead to stable long-term inequalities due to vicious cycles. Only demographic\nparity, which enforces equal rates of positive decisions across groups, avoids\nthese effects and establishes a virtuous cycle, which leads to perfectly\naccurate and fair classification in the long term.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 14:47:01 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 16:29:34 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""], ["Bunge", "Astrid", ""], ["Hainke", "Carolin", ""], ["Sindelar", "Leon", ""], ["Vogelsang", "Matthias", ""]]}, {"id": "1902.00705", "submitter": "Adil Rajput", "authors": "Adil E. Rajput, Samara M. Ahmed", "title": "Big Data and Social/Medical Sciences: State of the Art and Future Trends", "comments": "arXiv admin note: text overlap with arXiv:1902.00679", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of data on the internet is a direct corollary of the social\nmedia platform. With petabytes of data being generated by end users, the\nresearchers have access to unprecedented amount of data (Big Data). Such data\nprovides an insight into user mental state and hence can be utilized to produce\nclinical evidence. This lofty goal requires a thorough understanding of not\nonly the mental health issues but also the technology trends underlying the Big\nData and how they can be leveraged effectively. The paper looks at various such\nconcepts, provides an overview and enumerates the work that has been done in\nthis realm. Furthermore, we provide guidelines for future work that will help\nin streamlining the Big Data use in social/medical sciences.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 12:07:55 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Rajput", "Adil E.", ""], ["Ahmed", "Samara M.", ""]]}, {"id": "1902.00712", "submitter": "Flavio Moraes", "authors": "Flavio C. D. Moraes, Ana Lia Leonel, Pedro H. C. Torres, Pedro R.\n  Jacobi, Sandra Momm", "title": "Climate Change and Social Sciences: a bibliometric analysis", "comments": "13 pages 10 figures", "journal-ref": "V!rus, Sao Carlos, 20 (2020)", "doi": "10.4237/virus_journal", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of emergent wicked problems, such as climate change,\nculminates in a reformulation of how we think about society and mobilize\nscientists from various disciplines to seek solutions and perspectives on the\nproblem. From an epistemological point of view, it is essential to evaluate how\nsuch topics can be developed inside the academic arena but, to do that, it is\nnecessary to perform complex analysis of the great number of recent academic\npublications. In this work, we discuss how climate change has been addressed by\nsocial sciences in practice. Can we observe the development of a new\nepistemology by the emergence of the climate change debate? Are there\ncontributions in academic journals within the field of social sciences\naddressing climate change? Which journals are these? Who are the authors? To\nanswer these questions, we developed an innovative method combining different\ntools to search, filter, and analyze the impact of the academic production\nrelated to climate change in social sciences in the most relevant journals.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 13:00:26 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 05:53:51 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 18:18:11 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Moraes", "Flavio C. D.", ""], ["Leonel", "Ana Lia", ""], ["Torres", "Pedro H. C.", ""], ["Jacobi", "Pedro R.", ""], ["Momm", "Sandra", ""]]}, {"id": "1902.00757", "submitter": "Cass Dykeman", "authors": "Stephen Wong and Cass Dykeman", "title": "East Asians with Internet Addiction: Prevalence Rates and Support Use\n  Patterns", "comments": "26 pages, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The issue of Internet addiction has become a serious social and health issue\nin East Asian countries. There are only a few treatment programs for Internet\naddiction, and their effectiveness with people from East Asian remains unclear.\nAs support and treatment develop, it is necessary to understand cultural\npreferences for dealing with this concern. Using data from the East Asian\nSocial Survey (EASS), this study examined preferred sources of assistance for\nhelp with internet use problems in four countries - China, Japan, South Korea,\nand Taiwan. Preferences for kin versus non-kin support, use of alternative\nmedicine, and professional mental health assistance were examined, as were\nbetween-country differences in support preferences. The results indicate a\nstrong preference for seeking assistance from close relatives, followed by\nnon-kin support (i.e., close friends and co-participants in religious\ninstitutions), alternative medicine, and professional mental health services,\nrespectively. While there is a strong preference for family support, over 80%\nof survey respondents were open to seeking formal or informal mental health\nsupport outside the family. There were some significant differences between\ncountries, with South Koreans being more likely to seek non-kin support and\nprofessional support for internet addiction concerns compared to Chinese. These\ndifferences are discussed in the context of cultural and policy developments in\nEast Asian countries. Findings suggest the need for a more holistic approach to\ntreating low mental health concerns.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 17:34:54 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Wong", "Stephen", ""], ["Dykeman", "Cass", ""]]}, {"id": "1902.00775", "submitter": "Olga Bondarenko", "authors": "Olha Bondarenko, Svitlana Mantulenko, Andrey Pikilnyak", "title": "Google Classroom as a Tool of Support of Blended Learning for Geography\n  Students", "comments": null, "journal-ref": "CEUR Workshop Proceedings 2257 (2018) 182-191", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article reveals the experience of organizing blended learning for\ngeography students using Google Classroom, and discloses its potential uses in\nthe study of geography. For the last three years, the authors have tested such\ninclass and distance courses as \"Cartography and Basics of Topography\",\n\"Population Geography\", \"Information Systems and Technologies in Tourism\nIndustry\",\"Regional Economic and Social World Geography (Europe and the CIS)\",\n\"Regional Economic and Social World Geography (Africa, Latin America,\nAsia,Anglo-America, Australia and Oceania)\", \"Socio-Economic Cartography\". The\nadvantages of using the specified interactive tool during the study of\ngeographical disciplines are highlighted out in the article. As it has been\nestablished, the organization of the learning process using Google Classroom\nensures the unity of in-class and out-of-class learning; it is designed to\nrealize effective interaction of the subjects learning in real time; to monitor\nthe quality of training and control the students' learning achievements in\nclass as well as out of it, etc. The article outlines the disadvantages that\nshould be taken into account when organizing blended learning using Google\nClassroom, including the occasional predominance of students' external\nmotivation in education and their low level of readiness for work in the\nclassroom; insufficient level of material and technical support in some\nclassrooms; need for out-of-class pedagogical support; lack of guidance on the\ncontent aspect of Google Classroom pages, etc. Through the test series\nconducted during 2016-2017, an increase in the number of geography students\nwith a sufficient level of academic achievements and a decrease of those with a\nlow level of it was revealed.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 19:43:02 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Bondarenko", "Olha", ""], ["Mantulenko", "Svitlana", ""], ["Pikilnyak", "Andrey", ""]]}, {"id": "1902.00910", "submitter": "Maria Maleshkova", "authors": "Maria Maleshkova, Patrick Philipp, York Sure-Vetter and Rudi Studer", "title": "Smart Web Services (SmartWS) -- The Future of Services on the Web", "comments": null, "journal-ref": "The IPSI BgD Transactions on Advanced Research 2016", "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have been marked by an increased use of sensor\ntechnologies, abundant availability of mobile devices, and growing popularity\nof wearables, which enable the direct integration of their data as part of rich\nclient applications. Despite the potential and added value that such aggregate\napplications bring, the implementations are usually custom solutions for\nparticular use cases and do not support easy integration of further devices. To\nthis end, the vision of the Web of Things (WoT) is to leverage Web standards in\norder to interconnect all types of devices and real-world objects, and thus to\nmake them a part of the World Wide Web (WWW) and provide overall\ninteroperability. In this context we introduce Smart Web Services (SmartWS)\nthat not only provide remote access to resources and functionalities, by\nrelying on standard communication protocols, but also encapsulate\n`intelligence'. Smartness features can include, for instance, context-based\nadaptation, cognition, inference and rules that implement autonomous decision\nlogic in order to realize services that automatically perform tasks on behalf\nof the users, without requiring their explicit involvement. In this paper, we\npresent the key characteristics of SmartWS, and introduce a reference\nimplementation framework. Furthermore, we describe a specific use case for\nimplementing SmartWS in the medical domain and specify a maturity model for\ndetermining the quality and usability of SmartWS.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 15:36:09 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Maleshkova", "Maria", ""], ["Philipp", "Patrick", ""], ["Sure-Vetter", "York", ""], ["Studer", "Rudi", ""]]}, {"id": "1902.00953", "submitter": "Rayed AlGhamdi", "authors": "Rayed AlGhamdi and Adel Bahadad", "title": "Assessing the Usages of LMS at KAU and Proposing FORCE Strategy for the\n  Diffusion", "comments": "pp: 45-60", "journal-ref": "JKAU: Comp. IT. Sci, 2018", "doi": "10.4197/Comp.7-1.4", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the beginning of the Saudi Arabian academic year 1435 (Sept 2014), the\nweb-based learning management system Blackboard has been introduced and made\navailable to all instructors and students for all courses at King Abdulaziz\nUniversity (KAU). The current study takes place to assess the current usages of\nthe Blackboard usages at KAU. The data collected from the 923 students of the\nfoundation year which represent about one-third of the total number of the male\nstudents for the academic 2016-2017. Based on statistical evidence gained from\nthe students responses to the survey questions, 78% of the students are\ninactive users of the Blackboard. The study follows up with interviewing five\ninstructors who teach first-year students in order to seek explanations of the\nBlackboard low usages by the students. The outcomes point significant processes\nat an individual level and as well as an organizational level. The Diffusion of\nInnovation (DOI) was used to study the case because it is believed to be the\nbest explain such adoption of innovation at individual and organizational\nlevels. Based on the current outcomes and the author's experience in teaching a\ncomputer course using Blackboard, a strategy called 'FORCE' is proposed for the\ndiffusion process.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 18:45:43 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["AlGhamdi", "Rayed", ""], ["Bahadad", "Adel", ""]]}, {"id": "1902.01506", "submitter": "Jackson Killian", "authors": "Jackson A. Killian, Bryan Wilder, Amit Sharma, Daksha Shah, Vinod\n  Choudhary, Bistra Dilkina, Milind Tambe", "title": "Learning to Prescribe Interventions for Tuberculosis Patients Using\n  Digital Adherence Data", "comments": "10 pages, 6 figures", "journal-ref": "KDD 2019: The 25th ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining", "doi": "10.1145/3292500.3330777", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Adherence Technologies (DATs) are an increasingly popular method for\nverifying patient adherence to many medications. We analyze data from one city\nserved by 99DOTS, a phone-call-based DAT deployed for Tuberculosis (TB)\ntreatment in India where nearly 3 million people are afflicted with the disease\neach year. The data contains nearly 17,000 patients and 2.1M dose records. We\nlay the groundwork for learning from this real-world data, including a method\nfor avoiding the effects of unobserved interventions in training data used for\nmachine learning. We then construct a deep learning model, demonstrate its\ninterpretability, and show how it can be adapted and trained in different\nclinical scenarios to better target and improve patient care. In the real-time\nrisk prediction setting our model could be used to proactively intervene with\n21% more patients and before 76% more missed doses than current heuristic\nbaselines. For outcome prediction, our model performs 40% better than baseline\nmethods, allowing cities to target more resources to clinics with a heavier\nburden of patients at risk of failure. Finally, we present a case study\ndemonstrating how our model can be trained in an end-to-end decision focused\nlearning setting to achieve 15% better solution quality in an example decision\nproblem faced by health workers.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 00:59:44 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:05:38 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 07:19:55 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Killian", "Jackson A.", ""], ["Wilder", "Bryan", ""], ["Sharma", "Amit", ""], ["Shah", "Daksha", ""], ["Choudhary", "Vinod", ""], ["Dilkina", "Bistra", ""], ["Tambe", "Milind", ""]]}, {"id": "1902.01601", "submitter": "Antonio Luca Alfeo", "authors": "Antonio L. Alfeo, Mario G. C. A. Cimino, Bruno Lepri, Alex \"Sandy\"\n  Pentland, and Gigliola Vaglini", "title": "Detecting Permanent and Intermittent Purchase Hotspots via Computational\n  Stigmergy", "comments": null, "journal-ref": "in Proc. ICPRAM The 8th International Conference on Pattern\n  Recognition Applications and Methods (ICPRAM 2019)", "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The analysis of credit card transactions allows gaining new insights into the\nspending occurrences and mobility behavior of large numbers of individuals at\nan unprecedented scale. However, unfolding such spatiotemporal patterns at a\ncommunity level implies a non-trivial system modeling and parametrization, as\nwell as, a proper representation of the temporal dynamic. In this work we\naddress both those issues by means of a novel computational technique, i.e.\ncomputational stigmergy. By using computational stigmergy each sample position\nis associated with a digital pheromone deposit, which aggregates with other\ndeposits according to their spatiotemporal proximity. By processing\ntransactions data with computational stigmergy, it is possible to identify\nhigh-density areas (hotspots) occurring in different time and days, as well as,\nanalyze their consistency over time. Indeed, a hotspot can be permanent, i.e.\npresent throughout the period of observation, or intermittent, i.e. present\nonly in certain time and days due to community level occurrences (e.g.\nnightlife). Such difference is not only spatial (where the hotspot occurs) and\ntemporal (when the hotspot occurs) but affects also which people visit the\nhotspot. The proposed approach is tested on a real-world dataset containing the\ncredit card transaction of 60k users between 2014 and 2015.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 09:24:50 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Alfeo", "Antonio L.", ""], ["Cimino", "Mario G. C. A.", ""], ["Lepri", "Bruno", ""], ["Pentland", "Alex \"Sandy\"", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1902.01642", "submitter": "Peer-Olaf Siebers", "authors": "Daniel Stroud, Christian Wagner, Peer-Olaf Siebers", "title": "Agent-Based Simulation Modelling for Reflecting on Consequences of\n  Digital Mental Health", "comments": "16 pages, 18 figures, 3 tables, working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The premise of this working paper is based around agent-based simulation\nmodels and how to go about creating them from given incomplete information.\nAgent-based simulations are stochastic simulations that revolve around groups\nof agents that each have their own characteristics and can make decisions. Such\nsimulations can be used to emulate real life situations and to create\nhypothetical situations without the need for real-world testing prior. Here we\ndescribe the development of an agent-based simulation model for studying future\ndigital mental health scenarios. An incomplete conceptual model has been used\nas the basis for this development. To define differences in responses to\nstimuli we employed fuzzy decision making logic. The model has been implemented\nbut not been used for structured experimentation yet. This is planned as our\nnext step.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 11:15:55 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Stroud", "Daniel", ""], ["Wagner", "Christian", ""], ["Siebers", "Peer-Olaf", ""]]}, {"id": "1902.01752", "submitter": "Genevieve Gorrell", "authors": "Genevieve Gorrell, Mehmet E. Bakir, Ian Roberts, Mark A. Greenwood,\n  Benedetta Iavarone and Kalina Bontcheva", "title": "Partisanship, Propaganda and Post-Truth Politics: Quantifying Impact in\n  Online Debate", "comments": "This is now published in the Journal of Web Science. Please cite\n  accordingly. https://webscience-journal.net/webscience/article/view/84", "journal-ref": "Journal of Web Science 2019(7)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent past has highlighted the influential role of social networks and\nonline media in shaping public debate on current affairs and political issues.\nThis paper is focused on studying the role of politically-motivated actors and\ntheir strategies for influencing and manipulating public opinion online:\npartisan media, state-backed propaganda, and post-truth politics. In\nparticular, we present quantitative research on the presence and impact of\nthese three `Ps' in online Twitter debates in two contexts: (i) the run up to\nthe UK EU membership referendum (`Brexit'); and (ii) the information operations\nof Russia-backed online troll accounts. We first compare the impact of highly\npartisan versus mainstream media during the Brexit referendum, specifically\ncomparing tweets by half a million `leave' and `remain' supporters. Next,\nonline propaganda strategies are examined, specifically left- and right-wing\ntroll accounts. Lastly, we study the impact of misleading claims made by the\npolitical leaders of the leave and remain campaigns. This is then compared to\nthe impact of the Russia-backed partisan media and propaganda accounts during\nthe referendum. In particular, just two of the many misleading claims made by\npoliticians during the referendum were found to be cited in 4.6 times more\ntweets than the 7,103 tweets related to Russia Today and Sputnik and in 10.2\ntimes more tweets than the 3,200 Brexit-related tweets by the Russian troll\naccounts.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 15:51:36 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 11:09:09 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 14:30:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Gorrell", "Genevieve", ""], ["Bakir", "Mehmet E.", ""], ["Roberts", "Ian", ""], ["Greenwood", "Mark A.", ""], ["Iavarone", "Benedetta", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1902.01877", "submitter": "Jon Ha\\\"el Brenas", "authors": "Mohammad Sadnan Al Manir and Jon Ha\\\"el Brenas and Christopher JO\n  Baker and Arash Shaban-Nejad", "title": "A Surveillance Infrastructure for Malaria Analytics: Provisioning Data\n  Access and Preservation of Interoperability", "comments": null, "journal-ref": "JMIR Public Health Surveill 2018;4(2):e10218", "doi": "10.2196/10218", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose the Semantics, Interoperability, and Evolution for Malaria\nAnalytics (SIEMA) platform for use in malaria surveillance based on semantic\ndata federation. Using this approach, it is possible to access distributed\ndata, extend and preserve interoperability between multiple dynamic distributed\nmalaria sources, and facilitate detection of system changes that can interrupt\nmission-critical global surveillance activities. We used Semantic Automated\nDiscovery and Integration (SADI) Semantic Web Services to enable data access\nand improve interoperability, and the graphical user interface-enabled semantic\nquery engine HYDRA to implement the target queries typical of malaria programs.\nWe implemented a custom algorithm to detect changes to community-developed\nterminologies, data sources, and services that are core to SIEMA. This\nalgorithm reports to a dashboard. Valet SADI is used to mitigate the impact of\nchanges by rebuilding affected services. We developed a prototype surveillance\nand change management platform from a combination of third-party tools,\ncommunity-developed terminologies, and custom algorithms. We illustrated a\nmethodology and core infrastructure to facilitate interoperable access to\ndistributed data sources using SADI Semantic Web services. This degree of\naccess makes it possible to implement complex queries needed by our user\ncommunity with minimal technical skill. We implemented a dashboard that reports\non terminology changes that can render the services inactive, jeopardizing\nsystem interoperability. Using this information, end users can control and\nreactively rebuild services to preserve interoperability and minimize service\ndowntime.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 19:19:10 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Manir", "Mohammad Sadnan Al", ""], ["Brenas", "Jon Ha\u00ebl", ""], ["Baker", "Christopher JO", ""], ["Shaban-Nejad", "Arash", ""]]}, {"id": "1902.02236", "submitter": "Arinbj\\\"orn Kolbeinsson", "authors": "Naman Shukla, Arinbj\\\"orn Kolbeinsson, Ken Otwell, Lavanya Marla and\n  Kartik Yellepeddi", "title": "Dynamic Pricing for Airline Ancillaries with Customer Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancillaries have become a major source of revenue and profitability in the\ntravel industry. Yet, conventional pricing strategies are based on business\nrules that are poorly optimized and do not respond to changing market\nconditions. This paper describes the dynamic pricing model developed by Deepair\nsolutions, an AI technology provider for travel suppliers. We present a pricing\nmodel that provides dynamic pricing recommendations specific to each customer\ninteraction and optimizes expected revenue per customer. The unique nature of\npersonalized pricing provides the opportunity to search over the market space\nto find the optimal price-point of each ancillary for each customer, without\nviolating customer privacy. In this paper, we present and compare three\napproaches for dynamic pricing of ancillaries, with increasing levels of\nsophistication: (1) a two-stage forecasting and optimization model using a\nlogistic mapping function; (2) a two-stage model that uses a deep neural\nnetwork for forecasting, coupled with a revenue maximization technique using\ndiscrete exhaustive search; (3) a single-stage end-to-end deep neural network\nthat recommends the optimal price. We describe the performance of these models\nbased on both offline and online evaluations. We also measure the real-world\nbusiness impact of these approaches by deploying them in an A/B test on an\nairline's internet booking website. We show that traditional machine learning\ntechniques outperform human rule-based approaches in an online setting by\nimproving conversion by 36% and revenue per offer by 10%. We also provide\nresults for our offline experiments which show that deep learning algorithms\noutperform traditional machine learning techniques for this problem. Our\nend-to-end deep learning model is currently being deployed by the airline in\ntheir booking system.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 15:38:06 GMT"}], "update_date": "2019-02-07", "authors_parsed": [["Shukla", "Naman", ""], ["Kolbeinsson", "Arinbj\u00f6rn", ""], ["Otwell", "Ken", ""], ["Marla", "Lavanya", ""], ["Yellepeddi", "Kartik", ""]]}, {"id": "1902.02339", "submitter": "Kaicheng Yang", "authors": "Kai-Cheng Yang, Pik-Mai Hui, Filippo Menczer", "title": "Bot Electioneering Volume: Visualizing Social Bot Activity During\n  Elections", "comments": "3 pages, 3 figures. In submission", "journal-ref": "Companion Proceedings of The 2019 World Wide Web Conference", "doi": "10.1145/3308560.3316499", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been widely recognized that automated bots may have a significant\nimpact on the outcomes of national events. It is important to raise public\nawareness about the threat of bots on social media during these important\nevents, such as the 2018 US midterm election. To this end, we deployed a web\napplication to help the public explore the activities of likely bots on Twitter\non a daily basis. The application, called Bot Electioneering Volume (BEV),\nreports on the level of likely bot activities and visualizes the topics\ntargeted by them. With this paper we release our code base for the BEV\nframework, with the goal of facilitating future efforts to combat malicious\nbots on social media.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 18:56:45 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Yang", "Kai-Cheng", ""], ["Hui", "Pik-Mai", ""], ["Menczer", "Filippo", ""]]}, {"id": "1902.02580", "submitter": "Vicen\\c{c} G\\'omez Cerd\\`a", "authors": "Fabrizio Germano, Vicen\\c{c} G\\'omez, Ga\\\"el Le Mens", "title": "The few-get-richer: a surprising consequence of popularity-based\n  rankings", "comments": "7 pages, 3 figures, 1 table, Proceedings of The Web Conference (WWW\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Ranking algorithms play a crucial role in online platforms ranging from\nsearch engines to recommender systems. In this paper, we identify a surprising\nconsequence of popularity-based rankings: the fewer the items reporting a given\nsignal, the higher the share of the overall traffic they collectively attract.\nThis few-get-richer effect emerges in settings where there are few distinct\nclasses of items (e.g., left-leaning news sources versus right-leaning news\nsources), and items are ranked based on their popularity. We demonstrate\nanalytically that the few-get-richer effect emerges when people tend to click\non top-ranked items and have heterogeneous preferences for the classes of\nitems. Using simulations, we analyze how the strength of the effect changes\nwith assumptions about the setting and human behavior. We also test our\npredictions experimentally in an online experiment with human participants. Our\nfindings have important implications to understand the spread of\nmisinformation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 12:00:35 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 09:51:50 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Germano", "Fabrizio", ""], ["G\u00f3mez", "Vicen\u00e7", ""], ["Mens", "Ga\u00ebl Le", ""]]}, {"id": "1902.02635", "submitter": "Jun Zhao Dr", "authors": "Ge Wang, Jun Zhao and Nigel Shadbolt", "title": "Are Children Fully Aware of Online Privacy Risks and How Can We Improve\n  Their Coping Ability?", "comments": "9 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:1901.10245", "journal-ref": null, "doi": null, "report-no": "KOALA.03", "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The age of children adopting digital technologies, such as tablets or\nsmartphones, is increasingly young. However, children under 11 are often\nregarded as too young to comprehend the concept of online privacy. Limited\nresearch studies have focused on children of this age group. In the summer of\n2018, we conducted 12 focus group studies with 29 children aged 6-10 from\nOxfordshire primary schools. Our research has shown that children have a good\nunderstanding of certain privacy risks, such as information oversharing or\navoiding revealing real identities online. They could use a range of\ndescriptions to articulate the risks and describe their risk coping strategies.\nHowever, at the same time, we identified that children had less awareness\nconcerning other risks, such as online tracking or game promotions.\n  Inspired by Vygotsky's Zone of Proximal Development (ZPD), this study has\nidentified critical knowledge gaps in children's understanding of online\nprivacy, and several directions for future education and technology\ndevelopment. We call for attention to the needs of raising children's awareness\nand understanding of risks related to online recommendations and data tracking,\nwhich are becoming ever more prevalent in the games and content children\nencounter. We also call for attention to children's use of language to describe\nrisks, which may be appropriate but not necessarily indicate a full\nunderstanding of the threats.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 10:09:50 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Wang", "Ge", ""], ["Zhao", "Jun", ""], ["Shadbolt", "Nigel", ""]]}, {"id": "1902.02842", "submitter": "Jomara Sandbulte", "authors": "Jomara Sandbulte and Jessica Kropczynski and John M. Carroll", "title": "Community Animation: Exploring a design space that leverages geosocial\n  networking to increase community engagement", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores a design study of a smartphone enabled meet-up app meant\nto inspire engagement in community innovation. Community hubs such as\nco-working spaces, incubators, and maker spaces attract community members with\ndiverse interests. This paper presents these spaces as a design opportunity for\nan application that helps host community-centered meet-ups in smart and\nconnected communities. Our design study explores three scenarios of use,\ninspired by previous literature, for organizing meet-ups and compares them by\nsurveying potential users. Based on the results of our survey, we propose\nseveral design implications and implement them in the Community Animator\ngeosocial networking application, which identifies nearby individuals that are\nwilling to chat or perform community-centered activities. We present the\nresults of both our survey and our prototype, discuss our design goals, and\nprovide design implications for civic-minded, geosocial networking\napplications. Our contribution in this work is the development process,\nproposed design of a mobile application to support community-centered meet-ups,\nand insights for future work.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 20:57:03 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Sandbulte", "Jomara", ""], ["Kropczynski", "Jessica", ""], ["Carroll", "John M.", ""]]}, {"id": "1902.02960", "submitter": "Carrie Cai", "authors": "Carrie J. Cai, Emily Reif, Narayan Hegde, Jason Hipp, Been Kim, Daniel\n  Smilkov, Martin Wattenberg, Fernanda Viegas, Greg S. Corrado, Martin C.\n  Stumpe, Michael Terry", "title": "Human-Centered Tools for Coping with Imperfect Algorithms during Medical\n  Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) is increasingly being used in image retrieval systems\nfor medical decision making. One application of ML is to retrieve visually\nsimilar medical images from past patients (e.g. tissue from biopsies) to\nreference when making a medical decision with a new patient. However, no\nalgorithm can perfectly capture an expert's ideal notion of similarity for\nevery case: an image that is algorithmically determined to be similar may not\nbe medically relevant to a doctor's specific diagnostic needs. In this paper,\nwe identified the needs of pathologists when searching for similar images\nretrieved using a deep learning algorithm, and developed tools that empower\nusers to cope with the search algorithm on-the-fly, communicating what types of\nsimilarity are most important at different moments in time. In two evaluations\nwith pathologists, we found that these refinement tools increased the\ndiagnostic utility of images found and increased user trust in the algorithm.\nThe tools were preferred over a traditional interface, without a loss in\ndiagnostic accuracy. We also observed that users adopted new strategies when\nusing refinement tools, re-purposing them to test and understand the underlying\nalgorithm and to disambiguate ML errors from their own errors. Taken together,\nthese findings inform future human-ML collaborative systems for expert\ndecision-making.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 07:18:34 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Cai", "Carrie J.", ""], ["Reif", "Emily", ""], ["Hegde", "Narayan", ""], ["Hipp", "Jason", ""], ["Kim", "Been", ""], ["Smilkov", "Daniel", ""], ["Wattenberg", "Martin", ""], ["Viegas", "Fernanda", ""], ["Corrado", "Greg S.", ""], ["Stumpe", "Martin C.", ""], ["Terry", "Michael", ""]]}, {"id": "1902.02979", "submitter": "Niki Kilbertus", "authors": "Niki Kilbertus, Manuel Gomez-Rodriguez, Bernhard Sch\\\"olkopf, Krikamol\n  Muandet, Isabel Valera", "title": "Fair Decisions Despite Imperfect Predictions", "comments": "earlier version appeared at AISTATS 2020\n  http://proceedings.mlr.press/v108/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consequential decisions are increasingly informed by sophisticated\ndata-driven predictive models. However, to consistently learn accurate\npredictive models, one needs access to ground truth labels. Unfortunately, in\npractice, labels may only exist conditional on certain decisions---if a loan is\ndenied, there is not even an option for the individual to pay back the loan.\nHence, the observed data distribution depends on how decisions are being made.\nIn this paper, we show that in this selective labels setting, learning a\npredictor directly only from available labeled data is suboptimal in terms of\nboth fairness and utility. To avoid this undesirable behavior, we propose to\ndirectly learn decision policies that maximize utility under fairness\nconstraints and thereby take into account how decisions affect which data is\nobserved in the future. Our results suggest the need for a paradigm shift in\nthe context of fair machine learning from the currently prevalent idea of\nsimply building predictive models from a single static dataset via risk\nminimization, to a more interactive notion of \"learning to decide\". In\nparticular, such policies should not entirely neglect part of the input space,\ndrawing connections to explore/exploit tradeoffs in reinforcement learning,\ndata missingness, and potential outcomes in causal inference. Experiments on\nsynthetic and real-world data illustrate the favorable properties of learning\nto decide in terms of utility and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 08:50:31 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 08:15:45 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 01:22:11 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 08:09:32 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Kilbertus", "Niki", ""], ["Gomez-Rodriguez", "Manuel", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Muandet", "Krikamol", ""], ["Valera", "Isabel", ""]]}, {"id": "1902.03162", "submitter": "Uthman Baroudi Dr", "authors": "Uthman Baroudi, Abdulrahman Abu Elkhail, Hesham Alfares", "title": "Optimum Bi-level Hierarchical Clustering for Wireless Mobile Tracking\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel technique is proposed to optimize energy efficiency for wireless\nnetworks based on hierarchical mobile clustering. The new bi-level clustering\ntechnique minimizes mutual interference and energy consumption in large-scale\ntracking systems used in large public gatherings such as festivals and sports\nevents. This technique tracks random movements of a large number people in a\nbounded area by using a combination of smart-phone Bluetooth and Wi-Fi\nconnections. It can be effectively used for monitoring health conditions of\ncrowd members and providing their locations and movement directions. An integer\nlinear programming (ILP) model of the problem is formulated to optimize the\nformation of clusters in a two-level hierarchical structure. In order to\nevaluate the proposed technique, it is compared to the optimum solutions\nobtained from the ILP model for both single-level and two-level clustering.\nMoreover, a Matlab/Simulink simulation model is developed and used to test the\ntechnique performance under realistic operating conditions. The results\ndemonstrate a very good performance of the proposed technique.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 16:08:38 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Baroudi", "Uthman", ""], ["Elkhail", "Abdulrahman Abu", ""], ["Alfares", "Hesham", ""]]}, {"id": "1902.03237", "submitter": "Cristina Kadar", "authors": "Cristina Kadar, Rudolf Maculan, Stefan Feuerriegel", "title": "Public decision support for low population density areas: An\n  imbalance-aware hyper-ensemble for spatio-temporal crime prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crime events are known to reveal spatio-temporal patterns, which can be used\nfor predictive modeling and subsequent decision support. While the focus has\nhitherto been placed on areas with high population density, we address the\nchallenging undertaking of predicting crime hotspots in regions with low\npopulation densities and highly unequally-distributed crime.This results in a\nsevere sparsity (i.e., class imbalance) of the outcome variable, which impedes\npredictive modeling. To alleviate this, we develop machine learning models for\nspatio-temporal prediction that are specifically adjusted for an imbalanced\ndistribution of the class labels and test them in an actual setting with\nstate-of-the-art predictors (i.e., socio-economic, geographical, temporal,\nmeteorological, and crime variables in fine resolution). The proposed\nimbalance-aware hyper-ensemble increases the hit ratio considerably from 18.1%\nto 24.6% when aiming for the top 5% of hotspots, and from 53.1% to 60.4% when\naiming for the top 20% of hotspots.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 17:34:05 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kadar", "Cristina", ""], ["Maculan", "Rudolf", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1902.03245", "submitter": "Chenhao Tan", "authors": "Brian Lubars and Chenhao Tan", "title": "Ask Not What AI Can Do, But What AI Should Do: Towards a Framework of\n  Task Delegability", "comments": "19 pages, 3 figures, 5 tables, NeurIPS 2019, dataset available at\n  https://delegability.github.io", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While artificial intelligence (AI) holds promise for addressing societal\nchallenges, issues of exactly which tasks to automate and to what extent to do\nso remain understudied. We approach this problem of task delegability from a\nhuman-centered perspective by developing a framework on human perception of\ntask delegation to AI. We consider four high-level factors that can contribute\nto a delegation decision: motivation, difficulty, risk, and trust. To obtain an\nempirical understanding of human preferences in different tasks, we build a\ndataset of 100 tasks from academic papers, popular media portrayal of AI, and\neveryday life, and administer a survey based on our proposed framework. We find\nlittle preference for full AI control and a strong preference for\nmachine-in-the-loop designs, in which humans play the leading role. Among the\nfour factors, trust is the most correlated with human preferences of optimal\nhuman-machine delegation. This framework represents a first step towards\ncharacterizing human preferences of AI automation across tasks. We hope this\nwork encourages future efforts towards understanding such individual attitudes;\nour goal is to inform the public and the AI research community rather than\ndictating any direction in technology development.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2019 19:00:02 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 18:00:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Lubars", "Brian", ""], ["Tan", "Chenhao", ""]]}, {"id": "1902.03541", "submitter": "Matthias G\\\"orges", "authors": "Pu Liu, Sidney Fels, Nicholas West, Matthias G\\\"orges", "title": "Human Computer Interaction Design for Mobile Devices Based on a Smart\n  Healthcare Architecture", "comments": null, "journal-ref": "In: Yurish SY, ed. Advances in Computers and Software Engineering:\n  Reviews. 2019, Volume 2, p. 99-131", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart and IoT-enabled mobile devices have the potential to enhance healthcare\nservices for both patients and healthcare providers. Human computer interaction\ndesign is key to realizing a useful and usable connection between the users and\nthese smart healthcare technologies. Appropriate design of such devices\nenhances the usability, improves effective operation in an integrated\nhealthcare system, and facilitates the collaboration and information sharing\nbetween patients, healthcare providers, and institutions. In this paper, the\nconcept of smart healthcare is introduced, including its four-layer information\narchitecture of sensing, communication, data integration, and application.\nHuman Computer Interaction design principles for smart healthcare mobile\ndevices are outlined, based on user-centered design. These include: ensuring\nsafety, providing error-resistant displays and alarms, supporting the unique\nrelationship between patients and healthcare providers, distinguishing end-user\ngroups, accommodating legacy devices, guaranteeing low latency, allowing for\npersonalization, and ensuring patient privacy. Results are synthesized in\ndesign suggestions ranging from personas, scenarios, workflow, and information\narchitecture, to prototyping, testing and iterative development. Finally,\nfuture developments in smart healthcare and Human Computer Interaction design\nfor mobile health devices are outlined.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 05:49:53 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Liu", "Pu", ""], ["Fels", "Sidney", ""], ["West", "Nicholas", ""], ["G\u00f6rges", "Matthias", ""]]}, {"id": "1902.03558", "submitter": "Ramin Sahba", "authors": "Farshid Sahba, Amin Sahba, Ramin Sahba", "title": "Helping Blind People in Their Meeting Locations to Find Each Other Using\n  RFID Technology", "comments": "5 pages, 6 figures, Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "International Journal of Computer Science and Information Security\n  (IJCSIS), Vol. 16, No. 12, December 2018", "doi": null, "report-no": null, "categories": "eess.SP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new specific system based on RFID technology to help\nblind people find the other party in their meeting place. This system, uses a\ndevice called Smart Director or SD, equipped with Active Tag and RFID Reader.\nThe blind person, the visitor, adjusts the SD with the identification number of\nthe other party who has shared it previously for example on a telephone call,\nand takes the device to the meeting place. When the blind person arrives at the\nlocation, the reader of the device receives signals from the active tag of the\nother party's SD. It then identifies his/her position based on the intensity\nand direction of the received signals and tell it to the blind person. In this\nway, blind people can simply identify the position of the other party in\ncrowded places and find each other.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2019 08:21:41 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Sahba", "Farshid", ""], ["Sahba", "Amin", ""], ["Sahba", "Ramin", ""]]}, {"id": "1902.03689", "submitter": "Kristen Carlson", "authors": "Kristen W. Carlson", "title": "Safe Artificial General Intelligence via Distributed Ledger Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. Expert observers and artificial intelligence (AI) progression\nmetrics indicate AI will exceed human intelligence within a few decades.\nWhether general AI that exceeds human capabilities (AGI) will be the single\ngreatest boon in history or a disaster is unknown. No proofs exist that AGI\nwill benefit humans or that AGI will not harm or eliminate humans.\n  Objective. I propose a set of logically distinct conceptual components that\nare necessary and sufficient to 1) ensure that most known AGI scenarios will\nnot harm humanity and 2) robustly align AGI values and goals with human values.\n  Methods. By systematically addressing each pathway category to malevolent AI\nwe can induce the methods/axioms required to redress the category.\n  Results and Discussion. Distributed ledger technology (DLT, blockchain) is\nintegral to this proposal, e.g. to reduce the probability of hacking, provide\nan audit trail to detect and correct errors or identify components causing\nvulnerability or failure and replace them or shut them down remotely and/or\nautomatically, and to separate and balance key AGI components via decentralized\napps (dApps). Smart contracts based on DLT are necessary to address evolution\nof AI that will be too fast for human monitoring and intervention.\n  The proposed axioms. 1) Access to technology by market license. 2)\nTransparent ethics embodied in DLT. 3) Morality encrypted via DLT. 4) Behavior\ncontrol structure with values (ethics) at roots. 5) Individual bar-code\nidentification of all critical components. 6) Configuration Item (from business\ncontinuity/disaster recovery planning). 7) Identity verification secured via\nDLT. 8) Smart automated contracts based on DLT. 9) Decentralized applications -\nAI software code modules encrypted via DLT. 10) Audit trail of component usage\nstored via DLT. 11) Social ostracism (denial of societal resources) augmented\nby DLT petitions.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 00:10:47 GMT"}, {"version": "v2", "created": "Sat, 2 Mar 2019 14:27:57 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Carlson", "Kristen W.", ""]]}, {"id": "1902.03731", "submitter": "Jon Kleinberg", "authors": "Jon Kleinberg, Jens Ludwig, Sendhil Mullainathan, Cass R. Sunstein", "title": "Discrimination in the Age of Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The law forbids discrimination. But the ambiguity of human decision-making\noften makes it extraordinarily hard for the legal system to know whether anyone\nhas actually discriminated. To understand how algorithms affect discrimination,\nwe must therefore also understand how they affect the problem of detecting\ndiscrimination. By one measure, algorithms are fundamentally opaque, not just\ncognitively but even mathematically. Yet for the task of proving\ndiscrimination, processes involving algorithms can provide crucial forms of\ntransparency that are otherwise unavailable. These benefits do not happen\nautomatically. But with appropriate requirements in place, the use of\nalgorithms will make it possible to more easily examine and interrogate the\nentire decision process, thereby making it far easier to know whether\ndiscrimination has occurred. By forcing a new level of specificity, the use of\nalgorithms also highlights, and makes transparent, central tradeoffs among\ncompeting values. Algorithms are not only a threat to be regulated; with the\nright safeguards in place, they have the potential to be a positive force for\nequity.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 04:58:11 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kleinberg", "Jon", ""], ["Ludwig", "Jens", ""], ["Mullainathan", "Sendhil", ""], ["Sunstein", "Cass R.", ""]]}, {"id": "1902.03825", "submitter": "Vivek Kumar Mr.", "authors": "Vivek Kumar, Brojo Kishore Mishra, Manuel Mazzara, Dang N. H. Thanh,\n  Abhishek Verma", "title": "Prediction of Malignant & Benign Breast Cancer: A Data Mining Approach\n  in Healthcare Applications", "comments": "8 Pages, 2 Figures, 4 Tables. Conference- Advances in Data Science\n  and Management - Proceedings of ICDSM 2019 To be published with- Springer,\n  Lecture Notes on Data Engineering and Communications Technologies series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As much as data science is playing a pivotal role everywhere, healthcare also\nfinds it prominent application. Breast Cancer is the top rated type of cancer\namongst women; which took away 627,000 lives alone. This high mortality rate\ndue to breast cancer does need attention, for early detection so that\nprevention can be done in time. As a potential contributor to state-of-art\ntechnology development, data mining finds a multi-fold application in\npredicting Brest cancer. This work focuses on different classification\ntechniques implementation for data mining in predicting malignant and benign\nbreast cancer. Breast Cancer Wisconsin data set from the UCI repository has\nbeen used as experimental dataset while attribute clump thickness being used as\nan evaluation class. The performances of these twelve algorithms: Ada Boost M\n1, Decision Table, J Rip, Lazy IBK, Logistics Regression, Multiclass\nClassifier, Multilayer Perceptron, Naive Bayes, Random forest and Random Tree\nare analyzed on this data set. Keywords- Data Mining, Classification\nTechniques, UCI repository, Breast Cancer, Classification Algorithms\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 11:31:38 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 19:07:05 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 10:05:44 GMT"}, {"version": "v4", "created": "Sat, 23 Feb 2019 17:21:11 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Kumar", "Vivek", ""], ["Mishra", "Brojo Kishore", ""], ["Mazzara", "Manuel", ""], ["Thanh", "Dang N. H.", ""], ["Verma", "Abhishek", ""]]}, {"id": "1902.03857", "submitter": "Anton Kolonin Dr.", "authors": "Anton Kolonin, Ben Goertzel, Cassio Pennachin, Deborah Duong, Marco\n  Argentieri and Nejc Znidar", "title": "A Reputation System for Marketplaces - Viability Assessment", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the implementation of the reputation system for a\ngeneric marketplace, describe details of the algorithm and parameters driving\nits operation, justify an approach to simulation modeling, and explore how\nvarious kinds of reputation systems with different parameters impact the\neconomic security of the marketplace. Our emphasis here is on the protection of\nconsumers by means of an ability to distinguish between cheating participants\nand honest participants, as well as the ability to minimize losses of honest\nparticipants due to scam.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 13:16:35 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kolonin", "Anton", ""], ["Goertzel", "Ben", ""], ["Pennachin", "Cassio", ""], ["Duong", "Deborah", ""], ["Argentieri", "Marco", ""], ["Znidar", "Nejc", ""]]}, {"id": "1902.03975", "submitter": "Olivia Choudhury", "authors": "Olivia Choudhury, Noor Fairoza, Issa Sylla, Amar Das", "title": "A Blockchain Framework for Managing and Monitoring Data in Multi-Site\n  Clinical Trials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cost of conducting multi-site clinical trials has significantly increased\nover time, with site monitoring, data management, and amendments being key\ndrivers. Clinical trial data management approaches typically rely on a central\ndatabase, and require manual efforts to encode and maintain data capture and\nreporting requirements. To reduce the administrative burden, time, and effort\nof ensuring data integrity and privacy in multi-site trials, we propose a novel\ndata management framework based on permissioned blockchain technology. We\ndemonstrate how our framework, which uses smart contracts and private channels,\nenables confidential data communication, protocol enforcement, and and an\nautomated audit trail. We compare this framework with the traditional data\nmanagement approach and evaluate its effectiveness in satisfying the major\nrequirements of multi-site clinical trials. We show that our framework ensures\nenforcement of IRB-related regulatory requirements across multiple sites and\nstakeholders.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 16:34:44 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Choudhury", "Olivia", ""], ["Fairoza", "Noor", ""], ["Sylla", "Issa", ""], ["Das", "Amar", ""]]}, {"id": "1902.04056", "submitter": "Ashudeep Singh", "authors": "Ashudeep Singh, Thorsten Joachims", "title": "Policy Learning for Fairness in Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Learning-to-Rank (LTR) methods optimize the utility of the\nrankings to the users, but they are oblivious to their impact on the ranked\nitems. However, there has been a growing understanding that the latter is\nimportant to consider for a wide range of ranking applications (e.g. online\nmarketplaces, job placement, admissions). To address this need, we propose a\ngeneral LTR framework that can optimize a wide range of utility metrics (e.g.\nNDCG) while satisfying fairness of exposure constraints with respect to the\nitems. This framework expands the class of learnable ranking functions to\nstochastic ranking policies, which provides a language for rigorously\nexpressing fairness specifications. Furthermore, we provide a new LTR algorithm\ncalled Fair-PG-Rank for directly searching the space of fair ranking policies\nvia a policy-gradient approach. Beyond the theoretical evidence in deriving the\nframework and the algorithm, we provide empirical results on simulated and\nreal-world datasets verifying the effectiveness of the approach in individual\nand group-fairness settings.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 18:56:10 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 20:15:35 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Singh", "Ashudeep", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1902.04202", "submitter": "Siwei Lyu", "authors": "Yuezun Li and Siwei Lyu", "title": "De-identification without losing faces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of deep learning models for computer vision requires large image or\nvideo datasets from real world. Often, in collecting such datasets, we need to\nprotect the privacy of the people captured in the images or videos, while still\npreserve the useful attributes such as facial expressions. In this work, we\ndescribe a new face de-identification method that can preserve essential facial\nattributes in the faces while concealing the identities. Our method takes\nadvantage of the recent advances in face attribute transfer models, while\nmaintaining a high visual quality. Instead of changing factors of the original\nfaces or synthesizing faces completely, our method use a trained facial\nattribute transfer model to map non-identity related facial attributes to the\nface of donors, who are a small number (usually 2 to 3) of consented subjects.\nUsing the donors' faces ensures that the natural appearance of the synthesized\nfaces, while ensuring the identity of the synthesized faces are changed. On the\nother hand, the FATM blends the donors' facial attributes to those of the\noriginal faces to diversify the appearance of the synthesized faces.\nExperimental results on several sets of images and videos demonstrate the\neffectiveness of our face de-ID algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 01:15:15 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Li", "Yuezun", ""], ["Lyu", "Siwei", ""]]}, {"id": "1902.04506", "submitter": "Stefano Cresci", "authors": "Michele Mazza, Stefano Cresci, Marco Avvenuti, Walter Quattrociocchi,\n  Maurizio Tesconi", "title": "RTbust: Exploiting Temporal Patterns for Botnet Detection on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within OSNs, many of our supposedly online friends may instead be fake\naccounts called social bots, part of large groups that purposely re-share\ntargeted content. Here, we study retweeting behaviors on Twitter, with the\nultimate goal of detecting retweeting social bots. We collect a dataset of 10M\nretweets. We design a novel visualization that we leverage to highlight benign\nand malicious patterns of retweeting activity. In this way, we uncover a\n'normal' retweeting pattern that is peculiar of human-operated accounts, and 3\nsuspicious patterns related to bot activities. Then, we propose a bot detection\ntechnique that stems from the previous exploration of retweeting behaviors. Our\ntechnique, called Retweet-Buster (RTbust), leverages unsupervised feature\nextraction and clustering. An LSTM autoencoder converts the retweet time series\ninto compact and informative latent feature vectors, which are then clustered\nwith a hierarchical density-based algorithm. Accounts belonging to large\nclusters characterized by malicious retweeting patterns are labeled as bots.\nRTbust obtains excellent detection results, with F1 = 0.87, whereas competitors\nachieve F1 < 0.76. Finally, we apply RTbust to a large dataset of retweets,\nuncovering 2 previously unknown active botnets with hundreds of accounts.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 17:15:17 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Mazza", "Michele", ""], ["Cresci", "Stefano", ""], ["Avvenuti", "Marco", ""], ["Quattrociocchi", "Walter", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1902.04528", "submitter": "Luca Maria Aiello", "authors": "Sebastian Deri, Jeremie Rappaz, Luca Maria Aiello, Daniele Quercia", "title": "Coloring in the Links: Capturing Social Ties as They are Perceived", "comments": "18 pages, 5 figures", "journal-ref": "Proceedings of the ACM on Human-Computer Interaction, Vol. 2, No.\n  CSCW, Article 43. Publication date: November 2018", "doi": "10.1145/3274312", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The richness that characterizes relationships is often absent when they are\nmodeled using computational methods in network science. Typically,\nrelationships are represented simply as links, perhaps with weights. The lack\nof finer granularity is due in part to the fact that, aside from linkage and\nstrength, no fundamental or immediately obvious dimensions exist along which to\ncategorize relationships. Here we propose a set of dimensions that capture\nmajor components of many relationships -- derived both from relevant academic\nliterature and people's everyday descriptions of their relationships. We first\nreview prominent findings in sociology and social psychology, highlighting\ndimensions that have been widely used to categorize social relationships. Next,\nwe examine the validity of these dimensions empirically in two crowd-sourced\nexperiments. Ultimately, we arrive at a set of ten major dimensions that can be\nused to categorize relationships: similarity, trust, romance, social support,\nidentity, respect, knowledge exchange, power, fun, and conflict. These ten\ndimensions, while not dispositive, offer higher resolution than existing\nmodels. Indeed, we show that one can more accurately predict missing links in a\nsocial graph by using these dimensions than by using a state-of-the-art link\nembeddedness method. We also describe tinghy.org, an online platform we built\nto collect data about how social media users perceive their online\nrelationships, allowing us to examine these dimensions at scale. Overall, by\nproposing a new way of modeling social graphs, our work aims to contribute both\nto theory in network science and practice in the design of social-networking\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2019 18:09:53 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Deri", "Sebastian", ""], ["Rappaz", "Jeremie", ""], ["Aiello", "Luca Maria", ""], ["Quercia", "Daniele", ""]]}, {"id": "1902.04783", "submitter": "Hoda Heidari", "authors": "Megha Srivastava, Hoda Heidari, and Andreas Krause", "title": "Mathematical Notions vs. Human Perception of Fairness: A Descriptive\n  Approach to Fairness for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness for Machine Learning has received considerable attention, recently.\nVarious mathematical formulations of fairness have been proposed, and it has\nbeen shown that it is impossible to satisfy all of them simultaneously. The\nliterature so far has dealt with these impossibility results by quantifying the\ntradeoffs between different formulations of fairness. Our work takes a\ndifferent perspective on this issue. Rather than requiring all notions of\nfairness to (partially) hold at the same time, we ask which one of them is the\nmost appropriate given the societal domain in which the decision-making model\nis to be deployed. We take a descriptive approach and set out to identify the\nnotion of fairness that best captures \\emph{lay people's perception of\nfairness}. We run adaptive experiments designed to pinpoint the most compatible\nnotion of fairness with each participant's choices through a small number of\ntests. Perhaps surprisingly, we find that the most simplistic mathematical\ndefinition of fairness---namely, demographic parity---most closely matches\npeople's idea of fairness in two distinct application scenarios. This\nconclusion remains intact even when we explicitly tell the participants about\nthe alternative, more complicated definitions of fairness, and we reduce the\ncognitive burden of evaluating those notions for them. Our findings have\nimportant implications for the Fair ML literature and the discourse on\nformalizing algorithmic fairness.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 08:40:45 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 14:03:55 GMT"}, {"version": "v3", "created": "Mon, 19 Aug 2019 15:47:14 GMT"}, {"version": "v4", "created": "Sun, 8 Dec 2019 05:18:01 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Srivastava", "Megha", ""], ["Heidari", "Hoda", ""], ["Krause", "Andreas", ""]]}, {"id": "1902.05099", "submitter": "Mojtaba Noghabaee", "authors": "Mojtaba Noghabaei, Khashayar Asadi, and Kevin Han", "title": "Virtual Manipulation in an Immersive Virtual Environment: Simulation of\n  Virtual Assembly", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To fill the lack of research efforts in virtual assembly of modules and\ntraining, this paper presents a virtual manipulation of building objects in an\nImmersive Virtual Environment (IVE). A worker wearing a Virtual Reality (VR)\nhead-mounted device (HMD) virtually perform an assembly of multiple modules\nwhile identifying any issues. Hand motions of the worker are tracked by a\nmotion sensor mounted on the HMD. The worker can be graded based on his/her\noverall performance and speed during this VR simulation. The developed VR\nsimulation can ultimately enable workers to identify unforeseen issues (e.g.,\nnot enough clearance for an object to be installed). The presented method can\nsolve current deficiencies in discrepancy detection in 3D scanned models of\nelements. The developed VR platform can also be used for interactive training\nand simulation sessions that can potentially improve efficiency and help\nachieve better work performance for assemblies of complex systems.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 20:12:09 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Noghabaei", "Mojtaba", ""], ["Asadi", "Khashayar", ""], ["Han", "Kevin", ""]]}, {"id": "1902.05164", "submitter": "Shayan Eskandari", "authors": "Shayan Eskandari, Seyedehmahsa Moosavi, Jeremy Clark", "title": "SoK: Transparent Dishonesty: front-running attacks on Blockchain", "comments": null, "journal-ref": "FC: International Conference on Financial Cryptography 2019", "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider front-running to be a course of action where an entity benefits\nfrom prior access to privileged market information about upcoming transactions\nand trades. Front-running has been an issue in financial instrument markets\nsince the 1970s. With the advent of the blockchain technology, front-running\nhas resurfaced in new forms we explore here, instigated by blockchains\ndecentralized and transparent nature. In this paper, we draw from a scattered\nbody of knowledge and instances of front-running across the top 25 most active\ndecentral applications (DApps) deployed on Ethereum blockchain. Additionally,\nwe carry out a detailed analysis of Status.im initial coin offering (ICO) and\nshow evidence of abnormal miners behavior indicative of front-running token\npurchases. Finally, we map the proposed solutions to front-running into useful\ncategories.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 23:33:31 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 02:44:01 GMT"}, {"version": "v3", "created": "Tue, 9 Apr 2019 20:56:00 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Eskandari", "Shayan", ""], ["Moosavi", "Seyedehmahsa", ""], ["Clark", "Jeremy", ""]]}, {"id": "1902.05208", "submitter": "Zhengbo Zou", "authors": "Zhengbo Zou and Semiha Ergan", "title": "A Framework towards Quantifying Human Restorativeness in Virtual Built\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of built environment on the human restorativeness has long been\nargued; however, the interrelations between neuroscience and the built\nenvironment, and the degree to which the built environment contributes to\nincreased human restorativeness has not been completely understood yet.\nUnderstanding the interrelations between neuroscience and the built environment\nis critical as 90% of time in a typical day is spent indoors and architectural\nfeatures impact the productivity, health and comfort of occupants. The goal of\nthis study is to bring a structured understanding of architecture and\nneuroscience interactions in designed facilities and quantification of the\nimpact of design on human experience. The authors first built two virtual\nenvironments (i.e., restorative and non-restorative) using the architectural\ndesigns features related to human restorativeness identified by previous\nresearch efforts. Next, user experiments were conducted in the two built\nvirtual environments including 22 people. The subjects were asked to conduct\nnavigational tasks while their bodily responses recorded by body area sensors\n(e.g., EEG, GSR, and Eye-tracking). The result showed that human responses in\nrestorative and non-restorative environment had statistically significant\ndifference. This study serves as the first step of understanding human\nresponses in the virtual environment, and designing spaces that maximize human\nexperience.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 04:00:16 GMT"}], "update_date": "2019-02-15", "authors_parsed": [["Zou", "Zhengbo", ""], ["Ergan", "Semiha", ""]]}, {"id": "1902.05630", "submitter": "Jomara Sandbulte", "authors": "Jomara Sandbulte and Jessica Kropczynski and John M. Carroll", "title": "Using Key Player Analysis as a Method for Examining the Role of\n  Community Animators in Technology Adoption", "comments": "10 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper examines the role of community animators in technology adoption.\nCommunity animators are individuals that actively build social networks and\nbroker ties between nodes in those networks. The present study observes\ntechnology adoption patterns through data collected from a mobile application\nat a local arts festival. A social network was constructed through\nphoto-sharing and interaction within the app. Given this data, we propose the\nuse of key player analysis to identify community animators. In addition, we use\na graph invariant (i.e., fragmentation in the network) to describe the role and\nimpact of key players on the full network of interactions. Our results\ncontribute to literature on technology adoption in usability studies by\nproposing a method to quantify and identify the theoretical concept of\ncommunity animators. We further analyze the types of community animators to be\nfound in early adoption of technology: the early adopters themselves, and the\ninitiating developers.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 22:34:43 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Sandbulte", "Jomara", ""], ["Kropczynski", "Jessica", ""], ["Carroll", "John M.", ""]]}, {"id": "1902.05684", "submitter": "Sarwat Nizamani", "authors": "Sarwat Nizamani, Nasrullah Memon, Azhar Ali Shah, Sehrish Nizamani,\n  Saad Nizamani, Imdad Ali Ismaili", "title": "Crime Analysis using Open Source Information", "comments": null, "journal-ref": "Sindh University Research Journal (Science Series) Vol. 47 (4)\n  677- 682 (2015)", "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present a method of crime analysis from open source\ninformation. We employed un-supervised methods of data mining to explore the\nfacts regarding the crimes of an area of interest. The analysis is based on\nwell known clustering and association techniques. The results show that the\nproposed method of crime analysis is efficient and gives a broad picture of the\ncrimes of an area to analyst without much effort. The analysis is evaluated\nusing manual approach, which reveals that the results produced by the proposed\napproach are comparable to the manual analysis, while a great amount of time is\nsaved.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 05:12:45 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nizamani", "Sarwat", ""], ["Memon", "Nasrullah", ""], ["Shah", "Azhar Ali", ""], ["Nizamani", "Sehrish", ""], ["Nizamani", "Saad", ""], ["Ismaili", "Imdad Ali", ""]]}, {"id": "1902.05691", "submitter": "Sarwat Nizamani", "authors": "Sarwat Nizamani, Saad Nizamani, Sehrish Nizamani, Imdad Ali Ismaili", "title": "On the computational models for the analysis of illicit activities", "comments": null, "journal-ref": "Sindh University Research Journal (Science Series) Vol.46 (4):\n  561-566 (2014)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a study on the advancement of computational models for\nthe analysis of illicit activities. Computational models are being adapted to\naddress a number of social problems since the development of computers.\nComputational model are divided into three categories and discussed that how\ncomputational models can help in analyzing the illicit activities. The present\nstudy sheds a new light on the area of research that will aid to researchers in\nthe field as well as the law and enforcement agencies.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 05:30:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nizamani", "Sarwat", ""], ["Nizamani", "Saad", ""], ["Nizamani", "Sehrish", ""], ["Ismaili", "Imdad Ali", ""]]}, {"id": "1902.05796", "submitter": "Damilola Ibosiola", "authors": "Damilola Ibosiola, Ignacio Castro, Gianluca Stringhini, Steve Uhlig,\n  Gareth Tyson", "title": "Who Watches the Watchmen: Exploring Complaints on the Web", "comments": "The Web Conference 2019", "journal-ref": null, "doi": "10.1145/3308558.3313438", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Under increasing scrutiny, many web companies now offer bespoke mechanisms\nallowing any third party to file complaints (e.g., requesting the de-listing of\na URL from a search engine). While this self-regulation might be a valuable web\ngovernance tool, it places huge responsibility within the hands of these\norganisations that demands close examination. We present the first large-scale\nstudy of web complaints (over 1 billion URLs). We find a range of complainants,\nlargely focused on copyright enforcement. Whereas the majority of organisations\nare occasional users of the complaint system, we find a number of bulk senders\nspecialised in targeting specific types of domain. We identify a series of\ntrends and patterns amongst both the domains and complainants. By inspecting\nthe availability of the domains, we also observe that a sizeable portion go\noffline shortly after complaints are generated. This paper sheds critical light\non how complaints are issued, who they pertain to and which domains go offline\nafter complaints are issued.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 12:53:01 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 08:59:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Ibosiola", "Damilola", ""], ["Castro", "Ignacio", ""], ["Stringhini", "Gianluca", ""], ["Uhlig", "Steve", ""], ["Tyson", "Gareth", ""]]}, {"id": "1902.06019", "submitter": "Yao Xie", "authors": "Yao Xie, Ge Gao and Xiang 'Anthony' Chen", "title": "Outlining the Design Space of Explainable Intelligent Systems for\n  Medical Diagnosis", "comments": "6 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of intelligent systems creates opportunities as well as\nchallenges for medical work. On the positive side, intelligent systems have the\npotential to compute complex data from patients and generate automated\ndiagnosis recommendations for doctors. However, medical professionals often\nperceive such systems as black boxes and, therefore, feel concerned about\nrelying on system generated results to make decisions. In this paper, we\ncontribute to the ongoing discussion of explainable artificial intelligence\n(XAI) by exploring the concept of explanation from a human-centered\nperspective. We hypothesize that medical professionals would perceive a system\nas explainable if the system was designed to think and act like doctors. We\nreport a preliminary interview study that collected six medical professionals'\nreflection of how they interact with data for diagnosis and treatment purposes.\nOur data reveals when and how doctors prioritize among various types of data as\na central part of their diagnosis process. Based on these findings, we outline\nfuture directions regarding the design of XAI systems in the medical context.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 01:11:38 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Xie", "Yao", ""], ["Gao", "Ge", ""], ["Chen", "Xiang 'Anthony'", ""]]}, {"id": "1902.06284", "submitter": "Bilal Farooq", "authors": "Arash Kalatian and Bilal Farooq", "title": "A semi-supervised deep residual network for mode detection in Wi-Fi\n  signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their ubiquitous and pervasive nature, Wi-Fi networks have the\npotential to collect large-scale, low-cost, and disaggregate data on multimodal\ntransportation. In this study, we develop a semi-supervised deep residual\nnetwork (ResNet) framework to utilize Wi-Fi communications obtained from\nsmartphones for the purpose of transportation mode detection. This framework is\nevaluated on data collected by Wi-Fi sensors located in a congested urban area\nin downtown Toronto. To tackle the intrinsic difficulties and costs associated\nwith labelled data collection, we utilize ample amount of easily collected\nlow-cost unlabelled data by implementing the semi-supervised part of the\nframework. By incorporating a ResNet architecture as the core of the framework,\nwe take advantage of the high-level features not considered in the traditional\nmachine learning frameworks. The proposed framework shows a promising\nperformance on the collected data, with a prediction accuracy of 81.8% for\nwalking, 82.5% for biking and 86.0% for the driving mode.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2019 16:12:42 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kalatian", "Arash", ""], ["Farooq", "Bilal", ""]]}, {"id": "1902.06432", "submitter": "Ziqiang Cheng", "authors": "Ziqiang Cheng, Yang Yang, Chenhao Tan, Denny Cheng, Yueting Zhuang,\n  Alex Cheng", "title": "What Makes a Good Team? A Large-scale Study on the Effect of Team\n  Composition in Honor of Kings", "comments": "11 pages, 10 figures, WWW'19 short paper", "journal-ref": null, "doi": "10.1145/3308558.3313530", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Team composition is a central factor in determining the effectiveness of a\nteam. In this paper, we present a large-scale study on the effect of team\ncomposition on multiple measures of team effectiveness. We use a dataset from\nthe largest multiplayer online battle arena (MOBA) game, Honor of Kings, with\n96 million matches involving 100 million players. We measure team effectiveness\nbased on team performance (whether a team is going to win), team tenacity\n(whether a team is going to surrender), and team rapport (whether a team uses\nabusive language). Our results confirm the importance of team diversity and\nshow that diversity has varying effects on team effectiveness: although diverse\nteams perform well and show tenacity in adversity, they are more likely to\nabuse when losing than less diverse teams. Our study also contributes to the\nsituation vs. personality debate and show that abusive players tend to choose\nthe leading role and players do not become more abusive when taking such roles.\nWe further demonstrate the predictive power of features based on team\ncomposition in prediction experiments.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 07:41:39 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Cheng", "Ziqiang", ""], ["Yang", "Yang", ""], ["Tan", "Chenhao", ""], ["Cheng", "Denny", ""], ["Zhuang", "Yueting", ""], ["Cheng", "Alex", ""]]}, {"id": "1902.06462", "submitter": "Samara Ahmed", "authors": "Samara Ahmed", "title": "BYOD, Personal Area Networks (PANs) and IOT: Threats to Patients Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The passage of FISMA and HIPPA Acts have mandated various security controls\nthat ensure the privacy of patients data. Hospitals and health-care\norganizations are required by law to ensure that patients data is stored and\ndisseminated in a secure fashion. The advent of Bring Your Own Devices (BYOD),\nmobile devices, instant messaging (such as WhatsApp) and cloud technology\nhowever, have brought forth new challenges. The advent of Internet of Things\n(IOT) have complicated the matters further as organizations are not fully\ncognizant to the all facets of threats to data privacy. Physicians and health\ncare practitioners need to be made aware of various new avenues of data storage\nand transmission that need to be secured and controlled. In this paper we look\nat various threats and challenges that IOT, Bring Your Own Device (BYOD) and\nPersonal Area Networks (PANs) technologies pose to the patients privacy data.\nWe conclude the paper by providing the results of a survey that gauge the depth\nof understanding of healthcare professionals regarding the emerging threats to\npatients privacy\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 08:49:03 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Ahmed", "Samara", ""]]}, {"id": "1902.06521", "submitter": "Genevieve Gorrell", "authors": "Genevieve Gorrell, Mehmet E. Bakir, Luke Temple, Diana Maynard, Paolo\n  Cifariello, Jackie Harrison, J. Miguel Kanai, Kalina Bontcheva", "title": "Local Media and Geo-situated Responses to Brexit: A Quantitative\n  Analysis of Twitter, News and Survey Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Societal debates and political outcomes are subject to news and social media\ninfluences, which are in turn subject to commercial and other forces. Local\npress are in decline, creating a ``news gap''. Research shows a contrary\nrelationship between UK regions' economic dependence on EU membership and their\nvoting in the 2016 UK EU membership referendum, raising questions about local\nawareness. We draw on a corpus of Twitter data which has been annotated for\nuser location and Brexit vote intent, allowing us to investigate how location,\ntopics of concern and Brexit stance are related. We compare this with a large\ncorpus of articles from local and national news outlets, as well as survey\ndata, finding evidence of a distinctly different focus in local reporting.\nNational press focused more on terrorism and immigration than local press in\nmost areas. Some Twitter users focused on immigration. Local press focused on\ntrade, unemployment, local politics and agriculture. We find that remain voters\nshared interests more in keeping with local press on a per-region basis.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 11:25:09 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 09:16:05 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Gorrell", "Genevieve", ""], ["Bakir", "Mehmet E.", ""], ["Temple", "Luke", ""], ["Maynard", "Diana", ""], ["Cifariello", "Paolo", ""], ["Harrison", "Jackie", ""], ["Kanai", "J. Miguel", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1902.06532", "submitter": "Hossein Hassani", "authors": "Hossein Hassani and Emir Turajli\\'c and Kemal Taljanovi\\'c", "title": "Digital Humanities Readiness Assessment Framework: DHuRAF", "comments": "26 pages, 1 figure, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research suggests a framework, Digital Humanities Readiness Assessment\nFramework (DHuRAF), to assess the maturity level of the required infrastructure\nfor Digital Humanities studies (DH) in different communities. We use a similar\napproach to the Basic Language Resource Kit (BLARK) in developing the suggested\nframework. DH as a fairly new field, which has emerged at an intersection of\ndigital technologies and humanities, currently has no framework based on which\none could assess the status of the essential elements required for conducting\nresearch in a specific language or community. DH offers new research\nopportunities and challenges in the humanities, computer science and its\nrelevant technologies, hence such a framework could provide a starting point\nfor educational strategists, researchers, and software developers to understand\nthe prerequisites for their tasks and to have a statistical base for their\ndecisions and plans. The suggested framework has been applied in the context of\nKurdish DH, considering Kurdish as a less-resourced language. We have also\napplied the method to the Gaelic language in the Scottish community. Although\nthe research has focused on less-resourced and minority languages, it concludes\nthat DHuRAF has the potential to be generalized in a variety of different\ncontexts. Furthermore, despite significant reliance on Natural Language\nProcessing (NLP) and computational utilities, the research showed that DH could\nalso be used as an essential resource pool to leverage the NLP study of\nless-resourced and minority languages.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 11:54:04 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 08:20:11 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Hassani", "Hossein", ""], ["Turajli\u0107", "Emir", ""], ["Taljanovi\u0107", "Kemal", ""]]}, {"id": "1902.06548", "submitter": "Giovanni Stilo", "authors": "Andrea Lenzi, Marianna Maranghi, Giovanni Stilo, Paola Velardi", "title": "Quality of Life Assessment of Diabetic patients from health-related\n  blogs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivations: People are generating an enormous amount of social data to\ndescribe their health care experiences, and continuously search information\nabout diseases, symptoms, diagnoses, doctors, treatment options and medicines.\nThe increasing availability of these social traces presents an interesting\nopportunity to enhance timeliness and efficiency of care. By collecting,\nanalyzing and exploiting this information, it is possible to modify or in any\ncase significantly improve our knowledge on the manifestation of a pathology\nand obtain a more detailed and nuanced vision of patients' experience, that we\ncall the \"social phenotype\" of diseases. Materials and methods: In this paper\nwe present a data analytic framework to represent, extract and analyze the\nsocial phenotype of diseases. To show the effectiveness of our methodology we\npresents a detailed case study on diabetes. First, we create a high quality\ndata sample of diabetic patients' messages, extracted from popular medical\nforums during more than 10 years. Next, we use a topic extraction techniques\nbased on latent analysis and word embeddings, to identify the main\ncomplications, the frequently reported symptoms and the common concerns of\nthese patients. Results: We show that a freely manifested perception of a\ndisease can be noticeably different from what is inferred from questionnaires,\nsurveys and other common methodologies used to measure the impact of a disease\non the patients' quality of life. In our case study on diabetes, we found that\nissues reported to have a daily impact on diabetic patients are diet, glycemic\ncontrol, drugs and clinical tests. These problems are not commonly considered\nin Quality of Life assessments, since they are not perceived by doctors as\nrepresenting severe limitations.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 12:49:24 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Lenzi", "Andrea", ""], ["Maranghi", "Marianna", ""], ["Stilo", "Giovanni", ""], ["Velardi", "Paola", ""]]}, {"id": "1902.06660", "submitter": "Nirupam Bidikar", "authors": "Nirupam Bidikar, Kotoju Rajitha, P. Usha Supriya", "title": "A Novel Universal Solar Energy Predictor", "comments": "added additional results and discussion added new references\n  corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar energy is one of the most economical and clean sustainable energy\nsources on the planet. However, the solar energy throughput is highly\nunpredictable due to its dependency on a plethora of conditions including\nweather, seasons, and other ecological/environmental conditions. Thus, the\nsolar energy prediction is an inevitable necessity to optimize solar energy and\nalso to improve the efficiency of solar energy systems. Conventionally, the\noptimization of the solar energy is undertaken by subject matter experts using\ntheir domain knowledge; although it is impractical for even the experts to tune\nthe solar systems on a continuous basis. We strongly believe that the power of\nmachine learning can be harnessed to better optimize the solar energy\nproduction by learning the correlation between various conditions and solar\nenergy production from historical data which is typically readily available.\nFor this use, this paper predicts the daily total energy generation of an\ninstalled solar program using the Naive Bayes classifier. In the forecast\nprocedure, one year historical dataset including daily moderate temperatures,\ndaily total sunshine duration, daily total global solar radiation and daily\ntotal photovoltaic energy generation parameters are used as the categorical\nvalued features. By way of this Naive Bayes program the sensitivity and the\nprecision measures are improved for the photovoltaic energy prediction and also\nthe consequences of other solar characteristics on the solar energy production\nhave been assessed.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2019 03:30:59 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 17:20:03 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Bidikar", "Nirupam", ""], ["Rajitha", "Kotoju", ""], ["Supriya", "P. Usha", ""]]}, {"id": "1902.06661", "submitter": "Basit Qureshi", "authors": "Basit Qureshi, Kamal Kawlaq, Anis Koubaa, Basel Sultan, Mohammad\n  Younis", "title": "A Commodity SBC-Edge Cluster for Smart Cities", "comments": "6 pages. Submitted to 2nd International conference on Computer\n  Applications & Information Security, ICCAIS'2019. 19-21 March, 2019, Saudi\n  Computer Society, Riyadh, Saudi Arabia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The commodity Single Board Computers (SBCs) are increasingly becoming\npowerful and can execute standard operating systems and mainstream workloads.\nIn the context of cloud-based smart city applications, SBCs can be utilized as\nEdge computing devices reducing the network communication. In this paper, we\ninvestigate the design and implementation of a SBC based edge cluster (SBC-EC)\nframework for a smart parking application. Since SBCs are resource constrained\ndevices, we devise a container-based framework for a lighter foot-print.\nKubernetes was used as an orchestration tool to orchestrate various containers\nin the framework. To validate our approach, we implemented a proof-of-concept\nof the SBC based Edge cluster for a smart parking application, as a possible\nIoT use-case. Our implementation shows that, the use of SBC devices at the edge\nof a cloud based smart parking application is a cost effective and low energy,\ngreen computing solution. The proposed framework can be extended to similar\ncloud-based applications in the context of a smart city.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 08:33:17 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Qureshi", "Basit", ""], ["Kawlaq", "Kamal", ""], ["Koubaa", "Anis", ""], ["Sultan", "Basel", ""], ["Younis", "Mohammad", ""]]}, {"id": "1902.06662", "submitter": "Jinliang Xu", "authors": "Jinliang Xu and Shangguang Wang and Bharat K. Bhargava and Fangchun\n  Yang", "title": "A Blockchain-enabled Trustless Crowd-Intelligence Ecosystem on Mobile\n  Edge Computing", "comments": null, "journal-ref": null, "doi": "10.1109/TII.2019.2896965", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowd-intelligence tries to gather, process, infer and ascertain massive\nuseful information by utilizing the intelligence of crowds or distributed\ncomputers, which has great potential in Industrial Internet of Things (IIoT). A\ncrowd-intelligence ecosystem involves three stakeholders, namely the platform,\nworkers (e.g., individuals, sensors or processors), and task publisher. The\nstakeholders have no mutual trust but interest conflict, which means bad\ncooperation of them. Due to lack of trust, transferring raw data (e.g.,\npictures or video clips) between publisher and workers requires the remote\nplatform center to serve as a relay node, which implies network congestion.\nFirst we use a reward-penalty model to align the incentives of stakeholders.\nThen the predefined rules are implemented using blockchain smart contract on\nmany edge servers of the mobile edge computing network, which together function\nas a trustless hybrid human-machine crowd-intelligence platform. As edge\nservers are near to workers and publisher, network congestion can be\neffectively improved. Further, we proved the existence of the only one strong\nNash equilibrium, which can maximize the interests of involved edge servers and\nmake the ecosystem bigger. Theoretical analysis and experiments validate the\nproposed method respectively.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 05:57:01 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Xu", "Jinliang", ""], ["Wang", "Shangguang", ""], ["Bhargava", "Bharat K.", ""], ["Yang", "Fangchun", ""]]}, {"id": "1902.06670", "submitter": "Olivera Kotevska", "authors": "Olivera Kotevska", "title": "Increasing city safety awareness regarding disruptive traffic stream", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transportation systems serve the people in essence, in this study we focus in\ntraffic information related to violation events to respond to safety\nrequirements of the cities. Traffic violation events have an important role in\ncity safety awareness and secure travel. In this work, we describe the use of\nknowledge discovery from traffic violation reports in combination with\ndemographics approach using inductive logic programming to automatically\nextract knowledge about traffic violation behavior and their impact on the\nenvironment.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 15:36:44 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Kotevska", "Olivera", ""]]}, {"id": "1902.06672", "submitter": "Guy Lansley", "authors": "Guy Lansley, Michael de Smith, Michael Goodchild, Paul Longley", "title": "Big Data and Geospatial Analysis", "comments": "Geospatial Analysis: A comprehensive guide to principles, techniques\n  and software tools. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perhaps one of the mostly hotly debated topics in recent years has been the\nquestion of \"GIS and Big Data\". Much of the discussion has been about the data:\nhuge volumes of 2D and 3D spatial data and spatio-temporal data are now being\ncollected and stored; so how they can be accessed? and how can we map and\ninterpret massive datasets in an effective manner? Less attention has been paid\nto questions regarding the analysis of Big Data, although this has risen up the\nagenda in recent times. Examples include the use of density analysis to\nrepresent map request events, with Esri demonstrating that (given sufficient\nresources) they can process and analyze large numbers of data point events\nusing kernel density techniques within a very short timeframe (under a minute);\ndata filtering (to extract subsets of data that are of particular interest);\nand data mining (broader than simple filtering). For real-time data, sequential\nanalysis has also been successfully applied; in this case the data are received\nas a stream and are used to build up a dynamic map or to cumulatively generate\nstatistical values that may be mapped and/or used to trigger events or alarms.\nTo this extent the analysis is similar to that conducted on smaller datasets,\nbut with data and processing architectures that are specifically designed to\ncope with the data volumes involved and with a focus on data exploration as a\nkey mechanism for discovery. Miller and Goodchild (2014) have argued that\nconsiderable care is required when working with Big Data significant issues\narise from each of the \"four Vs of Big Data\": the sheer Volume of data; the\nVelocity of data arrival; the Variety of forms of data and their origins; and\nthe Veracity of such data. As such, geospatial research has had to adapt to\nharness new forms of data to validly represent real-world phenomena.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 11:26:52 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Lansley", "Guy", ""], ["de Smith", "Michael", ""], ["Goodchild", "Michael", ""], ["Longley", "Paul", ""]]}, {"id": "1902.06682", "submitter": "Alaa Mahdi Sahi", "authors": "Alaa Mahdi Sahi", "title": "Analysis of the Main Factors Affecting M-Commerce Adoption in Iraq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The telecommunications sector in Iraq is one of the most dynamic and active\nindustries. This sector has prime importance only next to oil & gas, as\nrevealed by recent reports. This industry has grown in leaps and bounds with\nthe rising demand for mobile services. Mobile services were inaccessible prior\nto 2003. As of 2016, there are 29 million mobile telephone subscribers, with\nonly 2.3 million fixed-line users. With the easy availability of telephone\nservices, the telecommunication sector has reported a rapid boom. Subsequent to\nthe fall of Saddam Hussein's regime on April 9, 2003, mobile commerce has\nreached new heights. This phenomenon is mainly attributed to the increasing\ninternet and smartphone usage. Telecommunication is now an imperative element\nin the social and economic growth of the country. This sector has also expanded\naccess to various prospects and has altered the manner of consumer interaction,\ncomparing prices, researching goods, and making purchases. Several studies have\nreviewed the penetration of mobile commerce to varied sectors. These studies\nhave also delved on the challenges, prospects, concerns, and impediments in\nthis sector. However, none of these studies has considered the situation in\nIraq. This paper examines the current literature to ascertain the parameters\naffecting m-commerce adoption in Iraq\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2019 03:32:03 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Sahi", "Alaa Mahdi", ""]]}, {"id": "1902.06685", "submitter": "Christian Truden", "authors": "Christian Wankm\\\"uller, Christian Truden, Christopher Korzen, Philipp\n  Hungerl\\\"ander, Ewald Kolesnik, Gerald Reiner", "title": "Optimal allocation of defibrillator drones in mountainous regions", "comments": null, "journal-ref": null, "doi": "10.1007/s00291-020-00575-z", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Responding to emergencies in Alpine terrain is quite challenging as air\nambulances and mountain rescue services are often confronted with logistics\nchallenges and adverse weather conditions that extend the response times\nrequired to provide life-saving support. Among other medical emergencies,\nsudden cardiac arrest (SCA) is the most time-sensitive event that requires the\nquick provision of medical treatment including cardiopulmonary resuscitation\nand electric shocks by automated external defibrillators (AED). An emerging\ntechnology called unmanned aerial vehicles (or drones) is regarded to support\nmountain rescuers in overcoming the time criticality of these emergencies by\nreducing the time span between SCA and early defibrillation. A drone that is\nequipped with a portable AED can fly from a base station to the patient's site\nwhere a bystander receives it and starts treatment. This paper considers such a\nresponse system and proposes an integer linear program to determine the optimal\nallocation of drone base stations in a given geographical region. In detail,\nthe developed model follows the objectives to minimize the number of used\ndrones and to minimize the average travel times of defibrillator drones\nresponding to SCA patients. In an example of application, under consideration\nof historical helicopter response times, the authors test the developed model\nand demonstrate the capability of drones to speed up the delivery of AEDs to\nSCA patients. Results indicate that time spans between SCA and early\ndefibrillation can be reduced by the optimal allocation of drone base stations\nin a given geographical region, thus increasing the survival rate of SCA\npatients.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 10:21:11 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 20:24:32 GMT"}, {"version": "v3", "created": "Fri, 29 Nov 2019 22:55:35 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Wankm\u00fcller", "Christian", ""], ["Truden", "Christian", ""], ["Korzen", "Christopher", ""], ["Hungerl\u00e4nder", "Philipp", ""], ["Kolesnik", "Ewald", ""], ["Reiner", "Gerald", ""]]}, {"id": "1902.06689", "submitter": "Cass Dykeman", "authors": "Mandy M. Greaves and Cass Dykeman", "title": "A Corpus Linguistic Analysis of Public Reddit Blog Posts on Non-Suicidal\n  Self-Injury", "comments": "21 pages, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While non-suicidal self-injury (NSSI) is not a new phenomenon, there is still\na limited yet little is still known about understanding of the behavior, the\nintent behind the behavior and what the individuals themselves say about their\nbehavior. This study collected pro-NSSI public blog posts from Reddit on\npro-NSSI and analyzed the content linguistically using LIWC software, in order\nto examine the use of NSSI specific words, linguistic properties and the\npsychological linguistic properties. were examined. The results inform current\ncounseling practices by dispelling myths and providing insight into the inner\nworld of people who engage in use NSSII to cope. The most frequently appearing\ncategory of For NSSI specific words categories, in the Reddit blogs was the\nreasons in which one engagesfor engaging in NSSI was the most frequently used\nin the Reddit blogs. The linguistic properties found in the analysis reflected\nthe predicted results; authors of pro-NSSI posts used demonstrated expected\nresults of first-person singular pronouns extensively, which indicatesing high\nlevels of mental health distress and isolation. The psychological linguistic\nproperties that could be observed of in these public Reddit posts were\ndominantly in a negative emotional tone which demonstrates youth and\nimpulsivity. The linguistic properties found when these posts were analyzed\nsupports the work of earlier studies that dispelled common myths about NSSI\nthat were circulating in the mental health community. These findings suggest\nthat the language of people who engage in NSSI supports research findings in\ndispelling common myths about NSSI.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 23:42:42 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Greaves", "Mandy M.", ""], ["Dykeman", "Cass", ""]]}, {"id": "1902.06691", "submitter": "Dennis Assenmacher", "authors": "Dennis Assenmacher, Lena Adam, Lena Frischlich, Heike Trautmann,\n  Christian Grimme", "title": "Openbots", "comments": "Fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bots have recently gained attention in the context of public opinion\nmanipulation on social media platforms. While a lot of research effort has been\nput into the classification and detection of such (semi-)automated programs, it\nis still unclear how sophisticated those bots actually are, which platforms\nthey target, and where they originate from. To answer these questions, we\ngathered repository data from open source collaboration platforms to identify\nthe status-quo as well as trends of publicly available bot code. Our findings\nindicate that most of the code on collaboration platforms is of supportive\nnature and provides modules of automation instead of fully fledged social bot\nprograms. Hence, the cost (in terms of additional programming effort) for\nbuilding social bots with the goal of topic-specific manipulation is higher\nthan assumed and that methods in context of machine- or deep-learning currently\nonly play a minor role. However, our approach can be applied as multifaceted\nknowledge discovery framework to monitor trends in public bot code evolution to\ndetect new developments and streams.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2019 15:40:37 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 09:37:48 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Assenmacher", "Dennis", ""], ["Adam", "Lena", ""], ["Frischlich", "Lena", ""], ["Trautmann", "Heike", ""], ["Grimme", "Christian", ""]]}, {"id": "1902.06693", "submitter": "Liudmyla Androshchuk", "authors": "L. V. Androshchuk and Aidan Rooney", "title": "Bayesian method for evaluation an airline profitability on the base\n  components of Airline Route Planning", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airline route planning takes into account the factors of commercial and\ncustomer preferences, safety, and should allow a flexibility given the\ntremendous uncertainty about market conditions. The mathematical model on the\nBayes formula allows optimizing the interaction of the base factors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2019 19:18:11 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Androshchuk", "L. V.", ""], ["Rooney", "Aidan", ""]]}, {"id": "1902.06739", "submitter": "Rohil Badkundri", "authors": "Rohil Badkundri, Victor Valbuena, Srikusmanjali Pinnamareddy, Brittney\n  Cantrell, Janet Standeven", "title": "Forecasting the 2017-2018 Yemen Cholera Outbreak with Machine Learning", "comments": "Originally completed as part of the iGEM competition (see\n  http://2018.igem.org/Team:Lambert_GA/Software); 3431 words, 1 table, 2\n  manuscript figures, 2 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing Yemen cholera outbreak has been deemed one of the worst cholera\noutbreaks in history, with over a million people impacted and thousands dead.\nTriggered by a civil war, the outbreak has been shaped by various political,\nenvironmental, and epidemiological factors and continues to worsen. While\ncholera has several effective treatments, the untimely and inefficient\ndistribution of existing medicines has been the primary cause of cholera\nmortality. With the hope of facilitating resource allocation, various\nmathematical models have been created to track the Yemeni outbreak and identify\nat-risk administrative divisions, called governorates. Existing models are not\npowerful enough to accurately and consistently forecast cholera cases per\ngovernorate over multiple timeframes. To address the need for a complex,\nreliable model, we offer the Cholera Artificial Learning Model (CALM); a system\nof 4 extreme-gradient-boosting (XGBoost) machine learning models that forecast\nthe number of new cholera cases a Yemeni governorate will experience from a\ntime range of 2 weeks to 2 months. CALM provides a novel machine learning\napproach that makes use of rainfall data, past cholera cases and deaths data,\ncivil war fatalities, and inter-governorate interactions represented across\nmultiple time frames. Additionally, the use of machine learning, along with\nextensive feature engineering, allows CALM to easily learn complex non-linear\nrelations apparent in an epidemiological phenomenon. CALM is able to forecast\ncholera incidence 2 weeks to 2 months in advance within a margin of just 5\ncholera cases per 10,000 people in real-world simulation.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 05:26:07 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Badkundri", "Rohil", ""], ["Valbuena", "Victor", ""], ["Pinnamareddy", "Srikusmanjali", ""], ["Cantrell", "Brittney", ""], ["Standeven", "Janet", ""]]}, {"id": "1902.06744", "submitter": "Mayank Agrawal", "authors": "Mayank Agrawal, Joshua C. Peterson, Thomas L. Griffiths", "title": "Using Machine Learning to Guide Cognitive Modeling: A Case Study in\n  Moral Reasoning", "comments": "Camera ready version for Cognitive Science Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale behavioral datasets enable researchers to use complex machine\nlearning algorithms to better predict human behavior, yet this increased\npredictive power does not always lead to a better understanding of the behavior\nin question. In this paper, we outline a data-driven, iterative procedure that\nallows cognitive scientists to use machine learning to generate models that are\nboth interpretable and accurate. We demonstrate this method in the domain of\nmoral decision-making, where standard experimental approaches often identify\nrelevant principles that influence human judgments, but fail to generalize\nthese findings to \"real world\" situations that place these principles in\nconflict. The recently released Moral Machine dataset allows us to build a\npowerful model that can predict the outcomes of these conflicts while remaining\nsimple enough to explain the basis behind human decisions.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 19:01:05 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 23:34:57 GMT"}, {"version": "v3", "created": "Fri, 10 May 2019 22:57:44 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Agrawal", "Mayank", ""], ["Peterson", "Joshua C.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "1902.06843", "submitter": "Amir Yazdavar", "authors": "Amir Hossein Yazdavar, Mohammad Saeid Mahdavinejad, Goonmeet Bajaj,\n  William Romine, Amirhassan Monadjemi, Krishnaprasad Thirunarayan, Amit Sheth,\n  Jyotishman Pathak", "title": "Fusing Visual, Textual and Connectivity Clues for Studying Mental Health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With ubiquity of social media platforms, millions of people are sharing their\nonline persona by expressing their thoughts, moods, emotions, feelings, and\neven their daily struggles with mental health issues voluntarily and publicly\non social media. Unlike the most existing efforts which study depression by\nanalyzing textual content, we examine and exploit multimodal big data to\ndiscern depressive behavior using a wide variety of features including\nindividual-level demographics. By developing a multimodal framework and\nemploying statistical techniques for fusing heterogeneous sets of features\nobtained by processing visual, textual and user interaction data, we\nsignificantly enhance the current state-of-the-art approaches for identifying\ndepressed individuals on Twitter (improving the average F1-Score by 5 percent)\nas well as facilitate demographic inference from social media for broader\napplications. Besides providing insights into the relationship between\ndemographics and mental health, our research assists in the design of a new\nbreed of demographic-aware health interventions.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 00:10:08 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Yazdavar", "Amir Hossein", ""], ["Mahdavinejad", "Mohammad Saeid", ""], ["Bajaj", "Goonmeet", ""], ["Romine", "William", ""], ["Monadjemi", "Amirhassan", ""], ["Thirunarayan", "Krishnaprasad", ""], ["Sheth", "Amit", ""], ["Pathak", "Jyotishman", ""]]}, {"id": "1902.06914", "submitter": "Adil Rajput", "authors": "Adil E. Rajput, Akila Sarirete and Tamer F. Desouky", "title": "Using Crowdsourcing to Identify a Proxy of Socio-Economic status", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social Media provides researchers with an unprecedented opportunity to gain\ninsight into various facets of human life. Health practitioners put a great\nemphasis on pinpointing socioeconomic status (SES) of individuals as they can\nuse to it to predict certain diseases. Crowdsourcing is a term coined that\nentails gathering intelligence from a user community online. In order to group\nthe users online into communities, researchers have made use of hashtags that\nwill cull the interest of a community of users. In this paper, we propose a\nmechanism to group a certain group of users based on their geographic\nbackground and build a corpus for such users. Specifically, we have looked at\ndiscussion forums for some vehi-cles where the site has established communities\nfor different areas to air their grievances or sing the praises of the vehicle.\nFrom such a discussion, it was pos-sible to glean the vocabulary that these\ngroup of users adheres to. We compared the corpus of different communities and\nnoted the difference in the choice of language. This provided us with the\ngroundwork for predicting the socio-eco-nomic status of such communities that\ncan be particularly helpful to health prac-titioners and in turn used in smart\ncities to provide better services to the commu-nity members. More work is\nunderway to take words and emojis out of vo-cablary(OOV) and assessing the\naverage score as special cases.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 06:25:23 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Rajput", "Adil E.", ""], ["Sarirete", "Akila", ""], ["Desouky", "Tamer F.", ""]]}, {"id": "1902.06961", "submitter": "Jason R.C. Nurse Dr", "authors": "Mariam Nouh and Jason R.C. Nurse and Helena Webb and Michael Goldsmith", "title": "Cybercrime Investigators are Users Too! Understanding the\n  Socio-Technical Challenges Faced by Law Enforcement", "comments": "11 pages, Proceedings of the 2019 Workshop on Usable Security (USEC)\n  at Network and Distributed System Security Symposium (NDSS)", "journal-ref": null, "doi": "10.14722/usec.2019.23032", "report-no": null, "categories": "cs.HC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cybercrime investigators face numerous challenges when policing online\ncrimes. Firstly, the methods and processes they use when dealing with\ntraditional crimes do not necessarily apply in the cyber-world. Additionally,\ncyber criminals are usually technologically-aware and constantly adapting and\ndeveloping new tools that allow them to stay ahead of law enforcement\ninvestigations. In order to provide adequate support for cybercrime\ninvestigators, there needs to be a better understanding of the challenges they\nface at both technical and socio-technical levels. In this paper, we\ninvestigate this problem through an analysis of current practices and workflows\nof investigators. We use interviews with experts from government and private\nsectors who investigate cybercrimes as our main data gathering process. From an\nanalysis of the collected data, we identify several outstanding challenges\nfaced by investigators. These pertain to practical, technical, and social\nissues such as systems availability, usability, and in computer-supported\ncollaborative work. Importantly, we use our findings to highlight research\nareas where user-centric workflows and tools are desirable. We also define a\nset of recommendations that can aid in providing a better foundation for future\nresearch in the field and allow more effective combating of cybercrimes.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 09:25:10 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Nouh", "Mariam", ""], ["Nurse", "Jason R. C.", ""], ["Webb", "Helena", ""], ["Goldsmith", "Michael", ""]]}, {"id": "1902.07102", "submitter": "Mohammad Kachuee Mr.", "authors": "Mohammad Kachuee, Kimmo Karkkainen, Orpaz Goldstein, Davina\n  Zamanzadeh, and Majid Sarrafzadeh", "title": "Cost-Sensitive Diagnosis and Learning Leveraging Public Health Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, machine learning algorithms rely on the assumption that all\nfeatures of a given dataset are available for free. However, there are many\nconcerns such as monetary data collection costs, patient discomfort in medical\nprocedures, and privacy impacts of data collection that require careful\nconsideration in any real-world health analytics system. An efficient solution\nwould only acquire a subset of features based on the value it provides while\nconsidering acquisition costs. Moreover, datasets that provide feature costs\nare very limited, especially in healthcare. In this paper, we provide a health\ndataset as well as a method for assigning feature costs based on the total\nlevel of inconvenience asking for each feature entails. Furthermore, based on\nthe suggested dataset, we provide a comparison of recent and state-of-the-art\napproaches to cost-sensitive feature acquisition and learning. Specifically, we\nanalyze the performance of major sensitivity-based and reinforcement learning\nbased methods in the literature on three different problems in the health\ndomain, including diabetes, heart disease, and hypertension classification.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 15:37:13 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 22:28:15 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kachuee", "Mohammad", ""], ["Karkkainen", "Kimmo", ""], ["Goldstein", "Orpaz", ""], ["Zamanzadeh", "Davina", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1902.07133", "submitter": "Craig Tutterow", "authors": "Craig Tutterow and Guillaume Saint-Jacques", "title": "Estimating Network Effects Using Naturally Occurring Peer Notification\n  Queue Counterfactuals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY econ.EM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized experiments, or A/B tests are used to estimate the causal impact\nof a feature on the behavior of users by creating two parallel universes in\nwhich members are simultaneously assigned to treatment and control. However, in\nsocial network settings, members interact, such that the impact of a feature is\nnot always contained within the treatment group. Researchers have developed a\nnumber of experimental designs to estimate network effects in social settings.\nAlternatively, naturally occurring exogenous variation, or 'natural\nexperiments,' allow researchers to recover causal estimates of peer effects\nfrom observational data in the absence of experimental manipulation. Natural\nexperiments trade off the engineering costs and some of the ethical concerns\nassociated with network randomization with the search costs of finding\nsituations with natural exogenous variation. To mitigate the search costs\nassociated with discovering natural counterfactuals, we identify a common\nengineering requirement used to scale massive online systems, in which natural\nexogenous variation is likely to exist: notification queueing. We identify two\nnatural experiments on the LinkedIn platform based on the order of notification\nqueues to estimate the causal impact of a received message on the engagement of\na recipient. We show that receiving a message from another member significantly\nincreases a member's engagement, but that some popular observational\nspecifications, such as fixed-effects estimators, overestimate this effect by\nas much as 2.7x. We then apply the estimated network effect coefficients to a\nlarge body of past experiments to quantify the extent to which it changes our\ninterpretation of experimental results. The study points to the benefits of\nusing messaging queues to discover naturally occurring counterfactuals for the\nestimation of causal effects without experimenter intervention.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 16:44:08 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Tutterow", "Craig", ""], ["Saint-Jacques", "Guillaume", ""]]}, {"id": "1902.07539", "submitter": "Francesco Pierri", "authors": "Francesco Pierri, Stefano Ceri", "title": "False News On Social Media: A Data-Driven Survey", "comments": null, "journal-ref": "ACM SIGMOD Record Vol. 48 Issue 2 June 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, the research community has dedicated growing interest\nto the issue of false news circulating on social networks. The widespread\nattention on detecting and characterizing false news has been motivated by\nconsiderable backlashes of this threat against the real world. As a matter of\nfact, social media platforms exhibit peculiar characteristics, with respect to\ntraditional news outlets, which have been particularly favorable to the\nproliferation of deceptive information. They also present unique challenges for\nall kind of potential interventions on the subject. As this issue becomes of\nglobal concern, it is also gaining more attention in academia. The aim of this\nsurvey is to offer a comprehensive study on the recent advances in terms of\ndetection, characterization and mitigation of false news that propagate on\nsocial media, as well as the challenges and the open questions that await\nfuture research on the field. We use a data-driven approach, focusing on a\nclassification of the features that are used in each study to characterize\nfalse information and on the datasets used for instructing classification\nmethods. At the end of the survey, we highlight emerging approaches that look\nmost promising for addressing false news.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 13:00:16 GMT"}, {"version": "v2", "created": "Sun, 23 Jun 2019 09:00:00 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2020 17:42:05 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Pierri", "Francesco", ""], ["Ceri", "Stefano", ""]]}, {"id": "1902.07588", "submitter": "Iqbal H. Sarker", "authors": "Iqbal H. Sarker", "title": "A Machine Learning based Robust Prediction Model for Real-life Mobile\n  Phone Data", "comments": "Journal: Internet of Things (IoT): Engineering Cyber-Physical Human\n  Systems (Elsevier). arXiv admin note: text overlap with arXiv:1710.04461", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-life mobile phone data may contain noisy instances, which is a\nfundamental issue for building a prediction model with many potential negative\nconsequences. The complexity of the inferred model may increase, may arise\noverfitting problem, and thereby the overall prediction accuracy of the model\nmay decrease. In this paper, we address these issues and present a robust\nprediction model for real-life mobile phone data of individual users, in order\nto improve the prediction accuracy of the model. In our robust model, we first\neffectively identify and eliminate the noisy instances from the training\ndataset by determining a dynamic noise threshold using naive Bayes classifier\nand laplace estimator, which may differ from user-to-user according to their\nunique behavioral patterns. After that, we employ the most popular rule-based\nmachine learning classification technique, i.e., decision tree, on the\nnoise-free quality dataset to build the prediction model. Experimental results\non the real-life mobile phone datasets (e.g., phone call log) of individual\nmobile phone users, show the effectiveness of our robust model in terms of\nprecision, recall and f-measure.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 15:29:25 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Sarker", "Iqbal H.", ""]]}, {"id": "1902.07823", "submitter": "Huang Lingxiao", "authors": "Lingxiao Huang and Nisheeth K. Vishnoi", "title": "Stable and Fair Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair classification has been a topic of intense study in machine learning,\nand several algorithms have been proposed towards this important task. However,\nin a recent study, Friedler et al. observed that fair classification algorithms\nmay not be stable with respect to variations in the training dataset -- a\ncrucial consideration in several real-world applications. Motivated by their\nwork, we study the problem of designing classification algorithms that are both\nfair and stable. We propose an extended framework based on fair classification\nalgorithms that are formulated as optimization problems, by introducing a\nstability-focused regularization term. Theoretically, we prove a stability\nguarantee, that was lacking in fair classification algorithms, and also provide\nan accuracy guarantee for our extended framework. Our accuracy guarantee can be\nused to inform the selection of the regularization parameter in our framework.\nTo the best of our knowledge, this is the first work that combines stability\nand fairness in automated decision-making tasks. We assess the benefits of our\napproach empirically by extending several fair classification algorithms that\nare shown to achieve the best balance between fairness and accuracy over the\nAdult dataset. Our empirical results show that our framework indeed improves\nthe stability at only a slight sacrifice in accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 00:56:14 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 14:15:32 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 16:22:18 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2020 12:32:22 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Huang", "Lingxiao", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1902.08008", "submitter": "Alexei Smirnov", "authors": "A.S. Smirnov, A.V. Tumialis, K.S. Golokhvast", "title": "Development of Internet of Things, Augmented Reality and 5G technologies\n  (review)", "comments": "in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Just as the emergence of personal computers and smartphones has changed the\nlife of modern society, the Internet of Things, augmented reality and\nultra-fast and reliable telecommunications networks of the new generation, by\ncombining the physical objects of the real world with the ever-increasing\ncomputing power and intelligence of cyberspace, will make the next big\nrevolution in all spheres of human activity. Keywords: Internet of Things, 5G,\naugmented reality.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 12:47:51 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Smirnov", "A. S.", ""], ["Tumialis", "A. V.", ""], ["Golokhvast", "K. S.", ""]]}, {"id": "1902.08121", "submitter": "Rui Chen", "authors": "Rui Chen, Christos G. Cassandras and Amin Tahmasbi-Sarvestani", "title": "Time and Energy-Optimal Lane Change Maneuvers for Cooperating Connected\n  Automated Vehicles", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive optimal control policies for a Connected and Automated Vehicle\n(CAV) cooperating with neighboring CAVs to implement a highway lane change\nmaneuver. We optimize the maneuver time and subsequently minimize the\nassociated energy consumption of all cooperating vehicles in this maneuver. We\nprove structural properties of the optimal policies which simplify the solution\nderivations and lead to analytical optimal control expressions. The solutions,\nwhen they exist, are guaranteed to satisfy safety constraints for all vehicles\ninvolved in the maneuver. Simulation results show the effectiveness of the\nproposed solution and significant performance improvements compared to\nmaneuvers performed by human-driven vehicles.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2019 16:21:27 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 16:00:45 GMT"}, {"version": "v3", "created": "Sat, 30 Nov 2019 17:01:11 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Chen", "Rui", ""], ["Cassandras", "Christos G.", ""], ["Tahmasbi-Sarvestani", "Amin", ""]]}, {"id": "1902.08448", "submitter": "Andreas Bunte", "authors": "Andreas Bunte, Andreas Fischbach, Jan Strohschein, Thomas\n  Bartz-Beielstein, Heide Faeskorn-Woyke and Oliver Niggemann", "title": "Evaluation of Cognitive Architectures for Cyber-Physical Production\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical production systems (CPPS) integrate physical and computational\nresources due to increasingly available sensors and processing power. This\nenables the usage of data, to create additional benefit, such as condition\nmonitoring or optimization. These capabilities can lead to cognition, such that\nthe system is able to adapt independently to changing circumstances by learning\nfrom additional sensors information. Developing a reference architecture for\nthe design of CPPS and standardization of machines and software interfaces is\ncrucial to enable compatibility of data usage between different machine models\nand vendors. This paper analysis existing reference architecture regarding\ntheir cognitive abilities, based on requirements that are derived from three\ndifferent use cases. The results from the evaluation of the reference\narchitectures, which include two instances that stem from the field of\ncognitive science, reveal a gap in the applicability of the architectures\nregarding the generalizability and the level of abstraction. While reference\narchitectures from the field of automation are suitable to address use case\nspecific requirements, and do not address the general requirements, especially\nw.r.t. adaptability, the examples from the field of cognitive science are well\nusable to reach a high level of adaption and cognition. It is desirable to\nmerge advantages of both classes of architectures to address challenges in the\nfield of CPPS in Industrie 4.0.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 11:47:29 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 13:38:47 GMT"}, {"version": "v3", "created": "Mon, 3 Jun 2019 12:26:15 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Bunte", "Andreas", ""], ["Fischbach", "Andreas", ""], ["Strohschein", "Jan", ""], ["Bartz-Beielstein", "Thomas", ""], ["Faeskorn-Woyke", "Heide", ""], ["Niggemann", "Oliver", ""]]}, {"id": "1902.08558", "submitter": "Jorge Louc\\~a", "authors": "Jorge Lou\\c{c}\\~a and Ant\\'onio Fonseca", "title": "Topology and dynamics of narratives on Brexit propagated by UK press\n  during 2016 and 2017", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article identifies and characterises political narratives regarding\nEurope and broadcasted in UK press during 2016 and 2017. A new theoretical and\noperational framework is proposed for typifying discourse narratives propagated\nin the public opinion space, based on the social constructivism and structural\nlinguistics approaches, and the mathematical theory of hypernetworks, where\nelementary units are aggregated into high-level entities. In this line of\nthought, a narrative is understood as a social construct where a related and\ncoherent aggregate of terms within public discourse is repeated and propagated\non media until it can be identified as a communication pattern, embodying\nmeaning in a way that provides individuals some interpretation of their world.\nAn inclusive methodology, with state-of-the-art technologies on natural\nlanguage processing and network theory, implements this concept of narrative. A\ncorpus from the Observatorium database, including articles from six UK\nnewspapers and incorporating far-right, right-wing, and left-wing narratives,\nis analysed. The research revealed clear distinctions between narratives along\nthe political spectrum. In 2016 far-right was particularly focused on\nemigration and refugees. Namely, during the referendum campaign, Europe was\nrelated to attacks on women and children, sexual offences, and terrorism.\nRight-wing was manly focused on internal politics, while left-wing was\nremarkably mentioning a diversity of non-political topics, such as sports, side\nby side with economics. During 2017, in general terrorism was less mentioned,\nand negotiations with EU, namely regarding economics, finance, and Ireland,\nbecame central.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 17:02:18 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Lou\u00e7\u00e3", "Jorge", ""], ["Fonseca", "Ant\u00f3nio", ""]]}, {"id": "1902.08628", "submitter": "Jonathan Chang", "authors": "Jonathan P. Chang and Cristian Danescu-Niculescu-Mizil", "title": "Trajectories of Blocked Community Members: Redemption, Recidivism and\n  Departure", "comments": "To appear in Proceedings of the 2019 World Wide Web Conference (WWW\n  '19), May 13-17, 2019, San Francisco, CA, USA. Code and data available as\n  part of ConvoKit: convokit.cornell.edu", "journal-ref": null, "doi": "10.1145/3308558.3313638", "report-no": null, "categories": "cs.CY cs.CL cs.SI physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Community norm violations can impair constructive communication and\ncollaboration online. As a defense mechanism, community moderators often\naddress such transgressions by temporarily blocking the perpetrator. Such\nactions, however, come with the cost of potentially alienating community\nmembers. Given this tradeoff, it is essential to understand to what extent, and\nin which situations, this common moderation practice is effective in\nreinforcing community rules.\n  In this work, we introduce a computational framework for studying the future\nbehavior of blocked users on Wikipedia. After their block expires, they can\ntake several distinct paths: they can reform and adhere to the rules, but they\ncan also recidivate, or straight-out abandon the community. We reveal that\nthese trajectories are tied to factors rooted both in the characteristics of\nthe blocked individual and in whether they perceived the block to be fair and\njustified. Based on these insights, we formulate a series of prediction tasks\naiming to determine which of these paths a user is likely to take after being\nblocked for their first offense, and demonstrate the feasibility of these new\ntasks. Overall, this work builds towards a more nuanced approach to moderation\nby highlighting the tradeoffs that are in play.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2019 19:00:10 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Chang", "Jonathan P.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""]]}, {"id": "1902.08769", "submitter": "Geoffrey Goodell", "authors": "Geoff Goodell, Tomaso Aste", "title": "A Decentralised Digital Identity Architecture", "comments": "30 pages, 10 figures, 3 tables", "journal-ref": null, "doi": "10.3389/fbloc.2019.00017", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current architectures to validate, certify, and manage identity are based on\ncentralised, top-down approaches that rely on trusted authorities and\nthird-party operators. We approach the problem of digital identity starting\nfrom a human rights perspective, with a primary focus on identity systems in\nthe developed world. We assert that individual persons must be allowed to\nmanage their personal information in a multitude of different ways in different\ncontexts and that to do so, each individual must be able to create multiple\nunrelated identities. Therefore, we first define a set of fundamental\nconstraints that digital identity systems must satisfy to preserve and promote\nprivacy as required for individual autonomy. With these constraints in mind, we\nthen propose a decentralised, standards-based approach, using a combination of\ndistributed ledger technology and thoughtful regulation, to facilitate\nmany-to-many relationships among providers of key services. Our proposal for\ndigital identity differs from others in its approach to trust in that we do not\nseek to bind credentials to each other or to a mutually trusted authority to\nachieve strong non-transferability. Because the system does not implicitly\nencourage its users to maintain a single aggregated identity that can\npotentially be constrained or reconstructed against their interests,\nindividuals and organisations are free to embrace the system and share in its\nbenefits.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2019 10:15:57 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 14:14:44 GMT"}, {"version": "v3", "created": "Thu, 1 Aug 2019 15:26:42 GMT"}, {"version": "v4", "created": "Mon, 12 Aug 2019 16:04:57 GMT"}, {"version": "v5", "created": "Mon, 14 Oct 2019 17:03:21 GMT"}, {"version": "v6", "created": "Sat, 26 Oct 2019 20:47:55 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Goodell", "Geoff", ""], ["Aste", "Tomaso", ""]]}, {"id": "1902.08882", "submitter": "Ryuichi Takanobu", "authors": "Ryuichi Takanobu, Tao Zhuang, Minlie Huang, Jun Feng, Haihong Tang, Bo\n  Zheng", "title": "Aggregating E-commerce Search Results from Heterogeneous Sources via\n  Hierarchical Reinforcement Learning", "comments": "WWW 19, 11 pages", "journal-ref": null, "doi": "10.1145/3308558.3313455", "report-no": null, "categories": "cs.IR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the task of aggregating search results from\nheterogeneous sources in an E-commerce environment. First, unlike traditional\naggregated web search that merely presents multi-sourced results in the first\npage, this new task may present aggregated results in all pages and has to\ndynamically decide which source should be presented in the current page.\nSecond, as pointed out by many existing studies, it is not trivial to rank\nitems from heterogeneous sources because the relevance scores from different\nsource systems are not directly comparable. To address these two issues, we\ndecompose the task into two subtasks in a hierarchical structure: a high-level\ntask for source selection where we model the sequential patterns of user\nbehaviors onto aggregated results in different pages so as to understand user\nintents and select the relevant sources properly; and a low-level task for item\npresentation where we formulate a slot filling process to sequentially present\nthe items instead of giving each item a relevance score when deciding the\npresentation order of heterogeneous items. Since both subtasks can be naturally\nformulated as sequential decision problems and learn from the future user\nfeedback on search results, we build our model with hierarchical reinforcement\nlearning. Extensive experiments demonstrate that our model obtains remarkable\nimprovements in search performance metrics, and achieves a higher user\nsatisfaction.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 03:18:43 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Takanobu", "Ryuichi", ""], ["Zhuang", "Tao", ""], ["Huang", "Minlie", ""], ["Feng", "Jun", ""], ["Tang", "Haihong", ""], ["Zheng", "Bo", ""]]}, {"id": "1902.08942", "submitter": "Daniel S. Katz", "authors": "Daniel S. Katz, Patrick Aerts, Neil P. Chue Hong, Anshu Dubey, Sandra\n  Gesing, Henry J. Neeman, David E. Pearah", "title": "Sustaining Research Software: an SC18 Panel", "comments": "The 2018 International Conference for High Performance Computing,\n  Networking, Storage, and Analysis (SC18), Dallas, Texas, USA, November 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many science advances have been possible thanks to the use of research\nsoftware, which has become essential to advancing virtually every Science,\nTechnology, Engineering and Mathematics (STEM) discipline and many non-STEM\ndisciplines including social sciences and humanities. And while much of it is\nmade available under open source licenses, work is needed to develop, support,\nand sustain it, as underlying systems and software as well as user needs\nevolve.\n  In addition, the changing landscape of high-performance computing (HPC)\nplatforms, where performance and scaling advances are ever more reliant on\nsoftware and algorithm improvements as we hit hardware scaling barriers, is\ncausing renewed tension between sustainability of software and its performance.\nWe must do more to highlight the trade-off between performance and\nsustainability, and to emphasize the need for sustainability given the fact\nthat complex software stacks don't survive without frequent maintenance; made\nmore difficult as a generation of developers of established and heavily-used\nresearch software retire. Several HPC forums are doing this, and it has become\nan active area of funding as well.\n  In response, the authors organized and ran a panel at the SC18 conference.\nThe objectives of the panel were to highlight the importance of sustainability,\nto illuminate the tension between pure performance and sustainability, and to\nsteer SC community discussion toward understanding and addressing this issue\nand this tension. The outcome of the discussions, as presented in this paper,\ncan inform choices of advance compute and data infrastructures to positively\nimpact future research software and future research.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 13:29:35 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Katz", "Daniel S.", ""], ["Aerts", "Patrick", ""], ["Hong", "Neil P. Chue", ""], ["Dubey", "Anshu", ""], ["Gesing", "Sandra", ""], ["Neeman", "Henry J.", ""], ["Pearah", "David E.", ""]]}, {"id": "1902.09022", "submitter": "Ahmed Fadhil Dr.", "authors": "Ahmed Fadhil, Gianluca Schiavo", "title": "Designing for Health Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building conversational agents have many technical, design and linguistic\nchallenges. Other more complex elements include using emotionally intelligent\nconversational agent to build trust with the individuals. In this chapter, we\nintroduce the nature of conversational user interfaces (CUIs) for health and\ndescribe UX design principles informed by a systematic literature review of\nrelevant research works. We analyze scientific literature in conversational\ninterfaces and chatterbots, providing a survey of major studies and describing\nUX design principles and interaction patterns.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 22:05:57 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Fadhil", "Ahmed", ""], ["Schiavo", "Gianluca", ""]]}, {"id": "1902.09453", "submitter": "Ian Stewart", "authors": "Ian Stewart, Ren\\'e Flores, Tim Riffe, Ingmar Weber, Emilio Zagheni", "title": "Rock, Rap, or Reggaeton?: Assessing Mexican Immigrants' Cultural\n  Assimilation Using Facebook Data", "comments": "WebConf 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The degree to which Mexican immigrants in the U.S. are assimilating\nculturally has been widely debated. To examine this question, we focus on\nmusical taste, a key symbolic resource that signals the social positions of\nindividuals. We adapt an assimilation metric from earlier work to analyze\nself-reported musical interests among immigrants in Facebook. We use the\nrelative levels of interest in musical genres, where a similarity to the host\npopulation in musical preferences is treated as evidence of cultural\nassimilation. Contrary to skeptics of Mexican assimilation, we find significant\ncultural convergence even among first-generation immigrants, which\nproblematizes their use as assimilative \"benchmarks\" in the literature.\nFurther, 2nd generation Mexican Americans show high cultural convergence\nvis-\\`a-vis both Anglos and African-Americans, with the exception of those who\nspeak Spanish. Rather than conforming to a single assimilation path, our\nfindings reveal how Mexican immigrants defy simple unilinear theoretical\nexpectations and illuminate their uniquely heterogeneous character.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 17:18:56 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Stewart", "Ian", ""], ["Flores", "Ren\u00e9", ""], ["Riffe", "Tim", ""], ["Weber", "Ingmar", ""], ["Zagheni", "Emilio", ""]]}, {"id": "1902.09464", "submitter": "Manuel Mazzara", "authors": "Manuel Mazzara, Ilya Afanasyev, Smruti R. Sarangi, Salvatore\n  Distefano, Vivek Kumar", "title": "A Reference Architecture for Smart and Software-defined Buildings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vision encompassing Smart and Software-defined Buildings (SSDB) is\nbecoming more and more popular and its implementation is now more accessible\ndue to the widespread adoption of the IoT infrastructure. Some of the most\nimportant applications sustaining this vision are energy management,\nenvironmental comfort, safety and surveillance. This paper surveys IoT and SSB\ntechnologies and their cooperation towards the realization of Smart Spaces. We\npropose a four-layer reference architecture and we organize related concepts\naround it. This conceptual frame is useful to identify the current literature\non the topic and to connect the dots into a coherent vision of the future of\nresidential and commercial buildings.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 17:29:09 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Mazzara", "Manuel", ""], ["Afanasyev", "Ilya", ""], ["Sarangi", "Smruti R.", ""], ["Distefano", "Salvatore", ""], ["Kumar", "Vivek", ""]]}, {"id": "1902.09604", "submitter": "Tiago Manuel Fern\\'andez-Caram\\'es", "authors": "Tiago M. Fern\\'andez-Caram\\'es, Paula Fraga-Lamas", "title": "A Review on the Application of Blockchain for the Next Generation of\n  Cybersecure Industry 4.0 Smart Factories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry 4.0 is a concept devised for improving the way modern factories\noperate through the use of some of the latest technologies, like the ones used\nfor creating Industrial Internet of Things (IIoT), robotics or Big Data\napplications. One of such technologies is blockchain, which is able to add\ntrust, security and decentralization to different industrial fields. This\narticle focuses on analyzing the benefits and challenges that arise when using\nblockchain and smart contracts to develop Industry 4.0 applications. In\naddition, this paper presents a thorough review on the most relevant\nblockchain-based applications for Industry 4.0 technologies. Thus, its aim is\nto provide a detailed guide for future Industry 4.0 developers that allows for\ndetermining how blockchain can enhance the next generation of cybersecure\nindustrial applications.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 20:45:22 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Fern\u00e1ndez-Caram\u00e9s", "Tiago M.", ""], ["Fraga-Lamas", "Paula", ""]]}, {"id": "1902.09749", "submitter": "Andr\\'es Monroy-Hern\\'andez", "authors": "Taryn Bipat, Maarten Willem Bos, Rajan Vaish, Andr\\'es\n  Monroy-Hern\\'andez", "title": "Analyzing the Use of Camera Glasses in the Wild", "comments": "In Proceedings of the 37th Annual ACM Conference on Human Factors in\n  Computing Systems (CHI 2019). ACM, New York, NY, USA", "journal-ref": null, "doi": "10.1145/3290605.3300651", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Camera glasses enable people to capture point-of-view videos using a common\naccessory, hands-free. In this paper, we investigate how, when, and why people\nused one such product: Spectacles. We conducted 39 semi-structured interviews\nand surveys with 191 owners of Spectacles. We found that the form factor\nelicits sustained usage behaviors, and opens opportunities for new use-cases\nand types of content captured. We provide a usage typology, and highlight\nsocietal and individual factors that influence the classification of behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 06:20:44 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Bipat", "Taryn", ""], ["Bos", "Maarten Willem", ""], ["Vaish", "Rajan", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""]]}, {"id": "1902.10008", "submitter": "Matheus Venturyne Xavier Ferreira", "authors": "Tithi Chattopadhyay and Nick Feamster and Matheus V. X. Ferreira and\n  Danny Yuxing Huang and S. Matthew Weinberg", "title": "Selling a Single Item with Negative Externalities", "comments": null, "journal-ref": "The World Wide Web Conference, 2019, 196-206", "doi": "10.1145/3308558.3313692", "report-no": null, "categories": "cs.GT cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of regulating products with negative externalities to\na third party that is neither the buyer nor the seller, but where both the\nbuyer and seller can take steps to mitigate the externality. The motivating\nexample to have in mind is the sale of Internet-of-Things (IoT) devices, many\nof which have historically been compromised for DDoS attacks that disrupted\nInternet-wide services such as Twitter. Neither the buyer (i.e., consumers) nor\nseller (i.e., IoT manufacturers) was known to suffer from the attack, but both\nhave the power to expend effort to secure their devices. We consider a\nregulator who regulates payments (via fines if the device is compromised, or\nmarket prices directly), or the product directly via mandatory security\nrequirements.\n  Both regulations come at a cost---implementing security requirements\nincreases production costs, and the existence of fines decreases consumers'\nvalues---thereby reducing the seller's profits. The focus of this paper is to\nunderstand the \\emph{efficiency} of various regulatory policies. That is,\npolicy A is more efficient than policy B if A more successfully minimizes\nnegatives externalities, while both A and B reduce seller's profits equally.\n  We develop a simple model to capture the impact of regulatory policies on a\nbuyer's behavior. {In this model, we show that for \\textit{homogeneous}\nmarkets---where the buyer's ability to follow security practices is always high\nor always low---the optimal (externality-minimizing for a given profit\nconstraint) regulatory policy need regulate \\emph{only} payments \\emph{or}\nproduction.} In arbitrary markets, by contrast, we show that while the optimal\npolicy may require regulating both aspects, there is always an approximately\noptimal policy which regulates just one.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 15:43:12 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Chattopadhyay", "Tithi", ""], ["Feamster", "Nick", ""], ["Ferreira", "Matheus V. X.", ""], ["Huang", "Danny Yuxing", ""], ["Weinberg", "S. Matthew", ""]]}, {"id": "1902.10086", "submitter": "Alexander Kott", "authors": "Alexander Kott, Ethan Stump", "title": "Intelligent Autonomous Things on the Battlefield", "comments": "This is a much expanded version of an earlier conference paper\n  available at arXiv:803.11256", "journal-ref": "In Artificial Intelligence for the Internet of Everything, pp.\n  47-65. Academic Press, 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous, artificially intelligent, networked things will populate the\nbattlefield of the future, operating in close collaboration with human\nwarfighters, and fighting as teams in highly adversarial environments. This\nchapter explores the characteristics, capabilities and intelli-gence required\nof such a network of intelligent things and humans - Internet of Battle Things\n(IOBT). The IOBT will experience unique challenges that are not yet well\naddressed by the current generation of AI and machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 17:59:55 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Kott", "Alexander", ""], ["Stump", "Ethan", ""]]}, {"id": "1902.10213", "submitter": "Qian Hu", "authors": "Qian Hu, Huzefa Rangwala", "title": "Reliable Deep Grade Prediction with Uncertainty Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, college-going students are taking longer to graduate than their\nparental generations. Further, in the United States, the six-year graduation\nrate has been 59% for decades. Improving the educational quality by training\nbetter-prepared students who can successfully graduate in a timely manner is\ncritical. Accurately predicting students' grades in future courses has\nattracted much attention as it can help identify at-risk students early so that\npersonalized feedback can be provided to them on time by advisors. Prior\nresearch on students' grade prediction include shallow linear models; however,\nstudents' learning is a highly complex process that involves the accumulation\nof knowledge across a sequence of courses that can not be sufficiently modeled\nby these linear models. In addition to that, prior approaches focus on\nprediction accuracy without considering prediction uncertainty, which is\nessential for advising and decision making. In this work, we present two types\nof Bayesian deep learning models for grade prediction. The MLP ignores the\ntemporal dynamics of students' knowledge evolution. Hence, we propose RNN for\nstudents' performance prediction. To evaluate the performance of the proposed\nmodels, we performed extensive experiments on data collected from a large\npublic university. The experimental results show that the proposed models\nachieve better performance than prior state-of-the-art approaches. Besides more\naccurate results, Bayesian deep learning models estimate uncertainty associated\nwith the predictions. We explore how uncertainty estimation can be applied\ntowards developing a reliable educational early warning system. In addition to\nuncertainty, we also develop an approach to explain the prediction results,\nwhich is useful for advisors to provide personalized feedback to students.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 20:47:51 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Hu", "Qian", ""], ["Rangwala", "Huzefa", ""]]}, {"id": "1902.10260", "submitter": "Anastasios Noulas", "authors": "Gergana Todorova, Anastasios Noulas", "title": "Exploiting Population Activity Dynamics to Predict Urban Epidemiological\n  Incidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambulance services worldwide are of vital importance to population health.\nTimely responding to incidents by dispatching an ambulance vehicle to the\nlocation a call came from can offer significant benefits to patient care across\na number of medical conditions. Moreover, identifying the reasons that drive\nambulance activity at an area not only can improve the operational capacity of\nemergency services, but can lead to better policy design in healthcare. In this\nwork, we analyse the temporal dynamics of 5.6 million ambulance calls across a\nregion of 7 million residents in the UK. We identify characteristic temporal\npatterns featuring diurnal and weekly cycles in ambulance call activity. These\npatterns are stable over time and across geographies. Using a dataset sourced\nfrom location intelligence platform Foursquare, we establish a link between the\nspatio-temporal dynamics of mobile users engaging with urban activities locally\nand emergency incidents. We use this information to build a novel metric that\nassesses the health risk of a geographic area in terms of its propensity to\nyield ambulance calls. Formulating then an online classification task where the\ngoal becomes to identify which regions will need an ambulance at a given time,\nwe demonstrate how semantic information about real world places crowdsourced\nthrough online platforms, can become a useful source of information in\nunderstanding and predicting regional epidemiological trends.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 23:02:40 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Todorova", "Gergana", ""], ["Noulas", "Anastasios", ""]]}, {"id": "1902.10419", "submitter": "Bruno Ordozgoiti", "authors": "Bruno Ordozgoiti and Aristides Gionis", "title": "Reconciliation k-median: Clustering with Non-Polarized Representatives", "comments": "The Web Conference 2019", "journal-ref": null, "doi": "10.1145/3308558.3313475", "report-no": null, "categories": "cs.DS cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new variant of the k-median problem, where the objective\nfunction models not only the cost of assigning data points to cluster\nrepresentatives, but also a penalty term for disagreement among the\nrepresentatives. We motivate this novel problem by applications where we are\ninterested in clustering data while avoiding selecting representatives that are\ntoo far from each other. For example, we may want to summarize a set of news\nsources, but avoid selecting ideologically-extreme articles in order to reduce\npolarization.\n  To solve the proposed k-median formulation we adopt the local-search\nalgorithm of Arya et al. We show that the algorithm provides a provable\napproximation guarantee, which becomes constant under an assumption on the\nminimum number of points for each cluster. We experimentally evaluate our\nproblem formulation and proposed algorithm on datasets inspired by the\nmotivating applications. In particular, we experiment with data extracted from\nTwitter, the US Congress voting records, and popular news sources. The results\nshow that our objective can lead to choosing less polarized groups of\nrepresentatives without significant loss in representation fidelity.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 09:57:51 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 08:59:19 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Ordozgoiti", "Bruno", ""], ["Gionis", "Aristides", ""]]}, {"id": "1902.10507", "submitter": "Maiia Popel", "authors": "Maiia Popel", "title": "Cloud service CoCalc as a means of forming the professional competencies\n  of the mathematics teacher", "comments": "241 pages, Monograph (Project Report)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The special issue contains a monograph by M. Popel, in which the methodical\nfoundations of the formation of professional competences of mathematics\nteachers in institutions of higher education of Ukraine are considered; the\nplace of cloud service CoCalc in the system of teaching mathematical\ndisciplines is specified; the features of CoCalc use in teaching mathematical\ndisciplines were discovered and the model of use of cloud service CoCalc as a\nmeans of formation of professional competences of mathematics teacher was\ndeveloped; The method of using CoCalc as a means of forming the professional\ncompetencies of the mathematics teacher is designed. For scientists,\npostgraduates, teachers of mathematical disciplines and students of pedagogical\neducational institutions, all who are interested in the application of\ncloud-oriented systems in education.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 04:08:40 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Popel", "Maiia", ""]]}, {"id": "1902.10514", "submitter": "Maria Maleshkova", "authors": "Frederik Buelthoff, Maria Maleshkova", "title": "RESTful or RESTless -- Current State of Today's Top Web APIs", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in the world of services on the Web show that both the\nnumber of available Web APIs as well as the applications built on top is\nconstantly increasing. This trend is commonly attributed to the wide adoption\nof the REST architectural principles. Still, the development of Web APIs is\nrather autonomous and it is up to the providers to decide how to implement,\nexpose and describe the Web APIs. The individual implementations are then\ncommonly documented in textual form as part of a webpage, showing a wide\nvariety in terms of content, structure and level of detail. As a result, client\napplication developers are forced to manually process and interpret the\ndocumentation. Before we can achieve a higher level of automation and can make\nany significant improvement to current practices and technologies, we need to\nreach a deeper understanding of their similarities and differences. Therefore,\nin this paper we present a thorough analysis of the most popular Web APIs\nthrough the examination of their documentation. We provide conclusions about\ncommon description forms, output types, usage of API parameters, invocation\nsupport, level of reusability, API granularity and authentication details. The\ncollected data builds a solid foundation for identifying deficiencies and can\nbe used as a basis for devising common standards and guidelines for Web API\ndevelopment.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2019 12:36:17 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Buelthoff", "Frederik", ""], ["Maleshkova", "Maria", ""]]}, {"id": "1902.10796", "submitter": "Ashwini Tonge", "authors": "Ashwini Tonge and Cornelia Caragea", "title": "Dynamic Deep Multi-modal Fusion for Image Privacy Prediction", "comments": "Accepted by The Web Conference (WWW) 2019", "journal-ref": null, "doi": "10.1145/3308558.3313691", "report-no": null, "categories": "cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With millions of images that are shared online on social networking sites,\neffective methods for image privacy prediction are highly needed. In this\npaper, we propose an approach for fusing object, scene context, and image tags\nmodalities derived from convolutional neural networks for accurately predicting\nthe privacy of images shared online. Specifically, our approach identifies the\nset of most competent modalities on the fly, according to each new target image\nwhose privacy has to be predicted. The approach considers three stages to\npredict the privacy of a target image, wherein we first identify the\nneighborhood images that are visually similar and/or have similar sensitive\ncontent as the target image. Then, we estimate the competence of the modalities\nbased on the neighborhood images. Finally, we fuse the decisions of the most\ncompetent modalities and predict the privacy label for the target image.\nExperimental results show that our approach predicts the sensitive (or private)\ncontent more accurately than the models trained on individual modalities\n(object, scene, and tags) and prior privacy prediction works. Also, our\napproach outperforms strong baselines, that train meta-classifiers to obtain an\noptimal combination of modalities.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 21:42:08 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 15:54:24 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Tonge", "Ashwini", ""], ["Caragea", "Cornelia", ""]]}, {"id": "1902.11091", "submitter": "Mansur Be\\c{s}ta\\c{s}", "authors": "Mansur Be\\c{s}ta\\c{s}", "title": "Massive Open Online Courses and Cloud Computing", "comments": "9 pages including the references, published at Academia E\\u{g}itim\n  Ara\\c{s}t{\\i}rmalar{\\i} Dergisi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important areas of todays computer technology is Cloud\nComputing. Benefits of Cloud Computing in various areas cannot be ignored. One\nfield affected by the opportunities provided by Cloud Computing is education.\nMOOC emerged as a result of opportunities in the field of learning provided by\ncloud computing. With the ever-increasing demand in recent years, MOOCs are\nconsidered to have a promising place in e-learning. Thus, the MOOC model will\nbe investigated as a business model. Customer types, services provided, the\nsources of income will be analyzed and tabulated. It will be aimed to reveal\nits relationship with platform and software service among the service models of\ncomputing. It was aimed with this study to present the relationship between\nCloud Computing and MOOC learning method.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 12:21:00 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Be\u015fta\u015f", "Mansur", ""]]}, {"id": "1902.11116", "submitter": "Miriam Redi", "authors": "Miriam Redi and Besnik Fetahu and Jonathan Morgan and Dario\n  Taraborelli", "title": "Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia's\n  Verifiability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikipedia is playing an increasingly central role on the web,and the policies\nits contributors follow when sourcing and fact-checking content affect million\nof readers. Among these core guiding principles, verifiability policies have a\nparticularly important role. Verifiability requires that information included\nin a Wikipedia article be corroborated against reliable secondary sources.\nBecause of the manual labor needed to curate and fact-check Wikipedia at scale,\nhowever, its contents do not always evenly comply with these policies.\nCitations (i.e. reference to external sources) may not conform to verifiability\nrequirements or may be missing altogether, potentially weakening the\nreliability of specific topic areas of the free encyclopedia. In this paper, we\naim to provide an empirical characterization of the reasons why and how\nWikipedia cites external sources to comply with its own verifiability\nguidelines. First, we construct a taxonomy of reasons why inline citations are\nrequired by collecting labeled data from editors of multiple Wikipedia language\neditions. We then collect a large-scale crowdsourced dataset of Wikipedia\nsentences annotated with categories derived from this taxonomy. Finally, we\ndesign and evaluate algorithmic models to determine if a statement requires a\ncitation, and to predict the citation reason based on our taxonomy. We evaluate\nthe robustness of such models across different classes of Wikipedia articles of\nvarying quality, as well as on an additional dataset of claims annotated for\nfact-checking purposes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 14:50:59 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Redi", "Miriam", ""], ["Fetahu", "Besnik", ""], ["Morgan", "Jonathan", ""], ["Taraborelli", "Dario", ""]]}]