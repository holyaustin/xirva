[{"id": "1911.00466", "submitter": "Wieslaw Kopec", "authors": "Wies{\\l}aw Kope\\'c, Marcin Wichrowski, Krzysztof Kalinowski, Anna\n  Jaskulska, Kinga Skorupska, Daniel Cnotkowski, Jakub Tyszka, Agata Popieluch,\n  Anna Voitenkova, Rafa{\\l} Mas{\\l}yk, Piotr Gago, Maciej Krzywicki, Monika\n  Kornacka, Cezary Biele, Pawe{\\l} Kobyli\\'nski, Jaros{\\l}aw Kowalski,\n  Katarzyna Abramczuk, Aldona Zdrodowska, Grzegorz Pochwatko, Jakub Mo\\.zaryn,\n  Krzysztof Marasek", "title": "VR with Older Adults: Participatory Design of a Virtual ATM Training\n  Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we report on a study conducted with a group of older adults in\nwhich they engaged in participatory design workshops to create a VR ATM\ntraining simulation. Based on observation, recordings and the developed VR\napplication we present the results of the workshops and offer considerations\nand recommendations for organizing opportunities for end users, in this case\nolder adults, to directly engage in co-creation of cutting-edge ICT solutions.\nThese include co-designing interfaces and interaction schemes for emerging\ntechnologies like VR and AR. We discuss such aspects as user engagement and\nhardware and software tools suitable for participatory prototyping of VR\napplications. Finally, we present ideas for further research in the area of VR\nparticipatory prototyping with users of various proficiency levels, taking\nsteps towards developing a unified framework for co-design in AR and VR.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 17:08:35 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Kope\u0107", "Wies\u0142aw", ""], ["Wichrowski", "Marcin", ""], ["Kalinowski", "Krzysztof", ""], ["Jaskulska", "Anna", ""], ["Skorupska", "Kinga", ""], ["Cnotkowski", "Daniel", ""], ["Tyszka", "Jakub", ""], ["Popieluch", "Agata", ""], ["Voitenkova", "Anna", ""], ["Mas\u0142yk", "Rafa\u0142", ""], ["Gago", "Piotr", ""], ["Krzywicki", "Maciej", ""], ["Kornacka", "Monika", ""], ["Biele", "Cezary", ""], ["Kobyli\u0144ski", "Pawe\u0142", ""], ["Kowalski", "Jaros\u0142aw", ""], ["Abramczuk", "Katarzyna", ""], ["Zdrodowska", "Aldona", ""], ["Pochwatko", "Grzegorz", ""], ["Mo\u017caryn", "Jakub", ""], ["Marasek", "Krzysztof", ""]]}, {"id": "1911.00498", "submitter": "Supreeth Shastri", "authors": "Supreeth Shastri, Melissa Wasserman, Vijay Chidambaram", "title": "GDPR Anti-Patterns: How Design and Operation of Modern Cloud-scale\n  Systems Conflict with GDPR", "comments": "arXiv admin note: substantial text overlap with arXiv:1903.09305", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, our society is being plagued by unprecedented levels of\nprivacy and security breaches. To rein in this trend, the European Union, in\n2018, introduced a comprehensive legislation called the General Data Protection\nRegulation (GDPR). In this article, we review GDPR from a systems perspective,\nand identify how the design and operation of modern cloud-scale systems\nconflict with this regulation. We illustrate these conflicts via six GDPR\nanti-patterns: storing data without a clear timeline for deletion; reusing data\nindiscriminately; creating walled gardens and black markets; risk-agnostic data\nprocessing; hiding data breaches; making unexplainable decisions. Our findings\nreveal deep-rooted tussle between GDPR requirements and how cloud-scale systems\nthat process personal data have evolved in the modern era. While it is\nimperative to avoid these anti-patterns, we believe that achieving compliance\nrequires comprehensive, grounds up solutions; anything short would amount to\nfixing a leaky faucet in a sinking ship.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:42:28 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shastri", "Supreeth", ""], ["Wasserman", "Melissa", ""], ["Chidambaram", "Vijay", ""]]}, {"id": "1911.00523", "submitter": "Chenhao Tan", "authors": "David Atkinson, Kumar Bhargav Srinivasan, Chenhao Tan", "title": "What Gets Echoed? Understanding the \"Pointers\" in Explanations of\n  Persuasive Arguments", "comments": "19 pages, 3 figures, EMNLP 2019, the code and dataset are available\n  at https://chenhaot.com/papers/explanation-pointers.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explanations are central to everyday life, and are a topic of growing\ninterest in the AI community. To investigate the process of providing natural\nlanguage explanations, we leverage the dynamics of the /r/ChangeMyView\nsubreddit to build a dataset with 36K naturally occurring explanations of why\nan argument is persuasive. We propose a novel word-level prediction task to\ninvestigate how explanations selectively reuse, or echo, information from what\nis being explained (henceforth, explanandum). We develop features to capture\nthe properties of a word in the explanandum, and show that our proposed\nfeatures not only have relatively strong predictive power on the echoing of a\nword in an explanation, but also enhance neural methods of generating\nexplanations. In particular, while the non-contextual properties of a word\nitself are more valuable for stopwords, the interaction between the constituent\nparts of an explanandum is crucial in predicting the echoing of content words.\nWe also find intriguing patterns of a word being echoed. For example, although\nnouns are generally less likely to be echoed, subjects and objects can,\ndepending on their source, be more likely to be echoed in the explanations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:00:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Atkinson", "David", ""], ["Srinivasan", "Kumar Bhargav", ""], ["Tan", "Chenhao", ""]]}, {"id": "1911.00677", "submitter": "Harvineet Singh", "authors": "Harvineet Singh, Rina Singh, Vishwali Mhasawade, Rumi Chunara", "title": "Fairness Violations and Mitigation under Covariate Shift", "comments": "11 pages main and 7 pages supplementary, To appear at ACM FAccT '21,\n  Previous arXiv version arXiv:1911.00677v1 was presented at Workshop on Fair\n  ML for Health '19", "journal-ref": null, "doi": "10.1145/3442188.3445865", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning fair prediction models for unseen test sets\ndistributed differently from the train set. Stability against changes in data\ndistribution is an important mandate for responsible deployment of models. The\ndomain adaptation literature addresses this concern, albeit with the notion of\nstability limited to that of prediction accuracy. We identify sufficient\nconditions under which stable models, both in terms of prediction accuracy and\nfairness, can be learned. Using the causal graph describing the data and the\nanticipated shifts, we specify an approach based on feature selection that\nexploits conditional independencies in the data to estimate accuracy and\nfairness metrics for the test set. We show that for specific fairness\ndefinitions, the resulting model satisfies a form of worst-case optimality. In\ncontext of a healthcare task, we illustrate the advantages of the approach in\nmaking more equitable decisions.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 08:10:58 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 20:03:54 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Singh", "Harvineet", ""], ["Singh", "Rina", ""], ["Mhasawade", "Vishwali", ""], ["Chunara", "Rumi", ""]]}, {"id": "1911.00715", "submitter": "Ren-Jie Han", "authors": "Ren-jie Han, Shi-yuan Liu, Qian Li", "title": "Do Chinese Internet Users Exist Heterogeneity in Search Behavior?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investor attention is an important concept in behavioral finance. Many\narticles have conducted cross-disciplinary research leading by this concept. In\nthis paper, we use data extraction technology to collect a large number of\nBaidu Index keyword search volume data. After analyzing the data, we draw a\nconclusion that has not been paid attention to in all the past research. We\nfind heterogeneity in searching by internet users in China. Firstly, in terms\nof search behavior, internet users are more inclined to use the PC end to\nobtain information when facing areas which need to be taken seriously by them.\nSecondly, attention is heterogeneous while searching. When Internet users\nsearch for information in mobile end, their attention is divergent, and search\nfor seemingly unrelated keywords at the same time which limits their attention\nto information.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 13:46:41 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Han", "Ren-jie", ""], ["Liu", "Shi-yuan", ""], ["Li", "Qian", ""]]}, {"id": "1911.00761", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Relations among different privacy notions", "comments": "Published in: IEEE 55th Annual Allerton Conference on Communication,\n  Control, and Computing (Allerton), UIUC, Illinois, US, October 2017", "journal-ref": null, "doi": "10.1109/ALLERTON.2017.8262821", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive view of the relations among several privacy\nnotions: differential privacy (DP) [1], Bayesian differential privacy (BDP)\n[2], semantic privacy (SP) [3], and membership privacy (MP) [4]. The results\nare organized into two parts. In part one, we extend the notion of semantic\nprivacy (SP) to Bayesian semantic privacy (BSP) and show its essential\nequivalence with Bayesian differential privacy (BDP) in the quantitative sense.\nWe prove the relations between BDP, BSP, and SP as follows: $\\epsilon$-BDP\n$\\Longleftarrow$ $\\big(\\frac{1}{2}-\\frac{1}{e^{\\epsilon}+1}\\big)$-BSP, and\n$\\epsilon$-BDP $\\Longrightarrow$ $(e^{2\\epsilon}-1)$-BSP $\\Longrightarrow$\n$(e^{2\\epsilon}-1)$-SP. In addition, we obtain a minor result $\\epsilon$-DP\n$\\Longleftarrow$ $\\big(\\frac{1}{2}-\\frac{1}{e^{\\epsilon}+1}\\big)$-SP, which\nimproves the result of Kasiviswanathan and Smith [3] stating $\\epsilon$-DP\n$\\Longleftarrow$ $\\epsilon/6$-SP for $\\epsilon \\leq 1.35$. In part two, we\nestablish the relations between BDP and MP. First, $\\epsilon$-BDP\n$\\Longrightarrow$ $\\epsilon$-MP. Second, for a family of distributions that are\ndownward scalable in the sense of Li et al. [4], it is shown that\n$\\epsilon$-BDP $\\Longleftarrow$ $\\epsilon$-MP.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:05:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00763", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Composition Properties of Bayesian Differential Privacy", "comments": "Published in: 2017 IEEE 28th Annual International Symposium on\n  Personal, Indoor, and Mobile Radio Communications (PIMRC)", "journal-ref": null, "doi": "10.1109/PIMRC.2017.8292647", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a rigorous privacy standard that has been applied to\na range of data analysis tasks. To broaden the application scenarios of\ndifferential privacy when data records have dependencies, the notion of\nBayesian differential privacy has been recently proposed. However, it is\nunknown whether Bayesian differential privacy preserves three nice properties\nof differential privacy: sequential composability, parallel composability, and\npost-processing. In this paper, we provide an affirmative answer to this\nquestion; i.e., Bayesian differential privacy still have these properties. The\nidea behind sequential composability is that if we have $m$ algorithms $Y_1,\nY_2, \\ldots, Y_m$, where $Y_{\\ell}$ is independently $\\epsilon_{\\ell}$-Bayesian\ndifferential private for ${\\ell}=1,2,\\ldots,m$, then by feeding the result of\n$Y_1$ into $Y_2$, the result of $Y_2$ into $Y_3$, and so on, we will finally\nhave an $\\sum_{\\ell=1}^m \\epsilon_{\\ell}$-Bayesian differential private\nalgorithm. For parallel composability, we consider the situation where a\ndatabase is partitioned into $m$ disjoint subsets. The $\\ell$-th subset is\ninput to a Bayesian differential private algorithm $Y_{\\ell}$, for\n${\\ell}=1,2,\\ldots,m$. Then the parallel composition of $Y_1$, $Y_2$, $\\ldots$,\n$Y_m$ will be $\\max_{\\ell=1}^m \\epsilon_{\\ell}$-Bayesian differential private.\nThe post-processing property means that a data analyst, without additional\nknowledge about the private database, cannot compute a function of the output\nof a Bayesian differential private algorithm and reduce its privacy guarantee.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:24:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00765", "submitter": "Jun Zhao", "authors": "Jun Zhao", "title": "Adaptive Statistical Learning with Bayesian Differential Privacy", "comments": "WPES '17 Proceedings of the 2017 on Workshop on Privacy in the\n  Electronic Society, held in conjunction with ACM SIGSAC 25th Annual\n  Conference on Computer and Communications Security (CCS), Dallas, Texas, US,\n  October 2017", "journal-ref": null, "doi": "10.1145/3139550.3139556", "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistical learning, a dataset is often partitioned into two parts: the\ntraining set and the holdout (i.e., testing) set. For instance, the training\nset is used to learn a predictor, and then the holdout set is used for\nestimating the accuracy of the predictor on the true distribution. However,\noften in practice, the holdout dataset is reused and the estimates tested on\nthe holdout dataset are chosen adaptively based on the results of prior\nestimates, leading to that the predictor may become dependent of the holdout\nset. Hence, overfitting may occur, and the learned models may not generalize\nwell to the unseen datasets. Prior studies have established connections between\nthe stability of a learning algorithm and its ability to generalize, but the\ntraditional generalization is not robust to adaptive composition. Recently,\nDwork et al. in NIPS, STOC, and Science 2015 show that the holdout dataset from\ni.i.d. data samples can be reused in adaptive statistical learning, if the\nestimates are perturbed and coordinated using techniques developed for\ndifferential privacy, which is a widely used notion to quantify privacy. Yet,\nthe results of Dwork et al. are applicable to only the case of i.i.d. samples.\nIn contrast, correlations between data samples exist because of various\nbehavioral, social, and genetic relationships between users. Our results in\nadaptive statistical learning generalize the results of Dwork et al. for i.i.d.\ndata samples to arbitrarily correlated data. Specifically, we show that the\nholdout dataset from correlated samples can be reused in adaptive statistical\nlearning, if the estimates are perturbed and coordinated using techniques\ndeveloped for Bayesian differential privacy, which is a privacy notion recently\nintroduced by Yang et al. in SIGMOD 2015 to broaden the application scenarios\nof differential privacy when data records are correlated.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2019 18:45:31 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhao", "Jun", ""]]}, {"id": "1911.00914", "submitter": "Saturnino Luz", "authors": "Bridget Kane, Jing Su, Saturnino Luz", "title": "Potential Applications of Machine Learning at Multidisciplinary Medical\n  Team Meetings", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning (ML) systems have produced great advances in several\ndomains, their use in support of complex cooperative work remains a research\nchallenge. A particularly challenging setting, and one that may benefit from ML\nsupport is the work of multidisciplinary medical teams (MDTs). This paper\nfocuses on the activities performed during the multidisciplinary medical team\nmeeting (MDTM), reviewing their main characteristics in light of a longitudinal\nanalysis of several MDTs in a large teaching hospital over a period of ten\nyears and of our development of ML methods to support MDTMs, and identifying\nopportunities and possible pitfalls for the use of ML to support MDTMs.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 15:51:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Kane", "Bridget", ""], ["Su", "Jing", ""], ["Luz", "Saturnino", ""]]}, {"id": "1911.01003", "submitter": "Saad Alqithami", "authors": "Saad Alqithami, Musaad Alzahrani, Abdulkareem Alzahrani, and Ahmed\n  Mostafa", "title": "Modeling an Augmented Reality Game Environment to Enhance Behavior of\n  ADHD Patients", "comments": "The 12th International Conference on Brain Informatics (BI 2019) ---\n  Brain Science meets Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper generically models an augmented reality game-based environment to\nproject the gamification of an online cognitive behavioral therapist that\nperforms instant measurements for patients with a predefined Attention Deficit\nHyperactivity Disorder (ADHD). ADHD is one of the most common\nneurodevelopmental disorders in which patients have difficulties related to\ninattention, hyperactivity, and impulsivity. Those patients are in need for a\npsychological therapy; the use of cognitive behavioral therapy as a\nfirmly-established treatment is to help in enhancing the way they think and\nbehave. A major limitation in traditional cognitive behavioral therapies is\nthat therapists may face difficulty to optimize patients' neuropsychological\nstimulus following a specified treatment plan, i.e., therapists struggle to\ndraw clear images when stimulating patients' mindset to a point where they\nshould be. Other limitations recognized here include availability,\naccessibility and level-of-experience of the therapists. Therefore, the paper\npresent a gamification model, we term as \"AR-Therapist,\" in order to take\nadvantages of augmented reality developments to engage patients in both real\nand virtual game-based environments. The model provides an on-time measurements\nof patients' progress throughout the treatment sessions which, in result,\novercomes limitations observed in traditional cognitive behavioral therapies.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 01:57:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Alqithami", "Saad", ""], ["Alzahrani", "Musaad", ""], ["Alzahrani", "Abdulkareem", ""], ["Mostafa", "Ahmed", ""]]}, {"id": "1911.01014", "submitter": "Muhammad Afzal", "authors": "Muhammad Afzal, S.M. Riazul Islam, Maqbool Hussain, and Sungyoung Lee", "title": "Precision Medicine Informatics: Principles, Prospects, and Challenges", "comments": "22 pages, 8 figures, 5 tables, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision Medicine (PM) is an emerging approach that appears with the\nimpression of changing the existing paradigm of medical practice. Recent\nadvances in technological innovations and genetics, and the growing\navailability of health data have set a new pace of the research and imposes a\nset of new requirements on different stakeholders. To date, some studies are\navailable that discuss about different aspects of PM. Nevertheless, a holistic\nrepresentation of those aspects deemed to confer the technological perspective,\nin relation to applications and challenges, is mostly ignored. In this context,\nthis paper surveys advances in PM from informatics viewpoint and reviews the\nenabling tools and techniques in a categorized manner. In addition, the study\ndiscusses how other technological paradigms including big data, artificial\nintelligence, and internet of things can be exploited to advance the potentials\nof PM. Furthermore, the paper provides some guidelines for future research for\nseamless implementation and wide-scale deployment of PM based on identified\nopen issues and associated challenges. To this end, the paper proposes an\nintegrated holistic framework for PM motivating informatics researchers to\ndesign their relevant research works in an appropriate context.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 02:40:00 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Afzal", "Muhammad", ""], ["Islam", "S. M. Riazul", ""], ["Hussain", "Maqbool", ""], ["Lee", "Sungyoung", ""]]}, {"id": "1911.01226", "submitter": "Ruibin Ma", "authors": "Ruibin Ma and Po-Hsuan Cameron Chen and Gang Li and Wei-Hung Weng and\n  Angela Lin and Krishna Gadepalli and Yuannan Cai", "title": "Human-centric Metric for Accelerating Pathology Reports Annotation", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathology reports contain useful information such as the main involved organ,\ndiagnosis, etc. These information can be identified from the free text reports\nand used for large-scale statistical analysis or serve as annotation for other\nmodalities such as pathology slides images. However, manual classification for\na huge number of reports on multiple tasks is labor-intensive. In this paper,\nwe have developed an automatic text classifier based on BERT and we propose a\nhuman-centric metric to evaluate the model. According to the model confidence,\nwe identify low-confidence cases that require further expert annotation and\nhigh-confidence cases that are automatically classified. We report the\npercentage of low-confidence cases and the performance of automatically\nclassified cases. On the high-confidence cases, the model achieves\nclassification accuracy comparable to pathologists. This leads a potential of\nreducing 80% to 98% of the manual annotation workload.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:09:19 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 15:12:45 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Ma", "Ruibin", ""], ["Chen", "Po-Hsuan Cameron", ""], ["Li", "Gang", ""], ["Weng", "Wei-Hung", ""], ["Lin", "Angela", ""], ["Gadepalli", "Krishna", ""], ["Cai", "Yuannan", ""]]}, {"id": "1911.01264", "submitter": "Tai-Quan Peng", "authors": "Jonathan J. H. Zhu, Tai-Quan Peng", "title": "Global Regularity and Individual Variability in Dynamic Behaviors of\n  Human Communication", "comments": "Paper presented at the Fifth Chinese Conference of Complex Networks\n  (CCCN09), Qindao, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A new model, called \"Human Dynamics\", has been recently proposed that\nindividuals execute activities based on a perceived priority of tasks, which\ncan be characterized by a power-law distribution of waiting time between\nconsecutive tasks (Barabasi, 2005). This power-law distribution has been found\nto exist in diverse human behaviors, such as mail correspondence, e-mail\ncommunication, webpage browsing, video-on-demand, and mobile phone calls.\nHowever, the pattern has been observed at the global (i.e., aggregated) level\nwithout considering individual differences. To guard against ecological\nfallacy, it is necessary to test the model at the individual level. The current\nstudy aims to address the following questions: Is the power-law uniform across\nindividuals? What distribution do individual behaviors follow? We examine these\nquestions with a client log file of nearly 4,000 Internet users' web browsing\nbehavior and a server log file of 2,300,000 users' file-sharing behaviors in a\nP2P system. The results confirm the human dynamic model at the aggregate-level\nboth in webpage browsing and P2P usage behavior. We have also found that there\nis detectable variability across the individuals in the decaying rate (i.e.,\nthe exponent gamma) of the power-law distribution, which follows well-known\ndistributions (i.e., Gaussian, Weibull, and log-normal).\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 15:00:26 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Zhu", "Jonathan J. H.", ""], ["Peng", "Tai-Quan", ""]]}, {"id": "1911.01273", "submitter": "Drimik Roy Chowdhury", "authors": "Namrata Chaudhary, Drimik Roy Chowdhury", "title": "Data Preprocessing for Evaluation of Recommendation Models in E-Commerce", "comments": null, "journal-ref": "Data. 2019; 4(1):23", "doi": "10.3390/data4010023", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  E-commerce businesses employ recommender models to assist in identifying a\npersonalized set of products for each visitor. To accurately assess the\nrecommendations' influence on customer clicks and buys, three target areas --\ncustomer behavior, data collection, user-interface -- will be explored for\npossible sources of erroneous data. Varied customer behavior misrepresents the\nrecommendations' true influence on a customer due to the presence of B2B\ninteractions and outlier customers. Non-parametric statistical procedures for\noutlier removal are delineated and other strategies are investigated to account\nfor the effect of a large percentage of new customers or high bounce rates.\nSubsequently, in data collection we identify probable misleading interactions\nin the raw data, propose a robust method of tracking unique visitors, and\naccurately attributing the buy influence for combo products. Lastly,\nuser-interface issues discuss the possible problems caused due to the\nrecommendation widget's positioning on the e-commerce website and the stringent\nconditions that should be imposed when utilizing data from the product listing\npage. This collective methodology results in an exact and valid estimation of\nthe customer's interactions influenced by the recommendation model in the\ncontext of standard industry metrics, such as Click-through rates, Buy-through\nrates, and Conversion revenue.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 16:52:57 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Chaudhary", "Namrata", ""], ["Chowdhury", "Drimik Roy", ""]]}, {"id": "1911.01274", "submitter": "Mostafa Mirzaie", "authors": "Mostafa Mirzaie, Behshid Behkamal, Samad Paydar", "title": "Contextualization of Big Data Quality: A framework for comparison", "comments": "18 pages, submitted to journal of data and information quality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of big data applications and the increasing amount of data\nbeing produced in these applications, the importance of efficient methods for\nbig data analysis has become highly evident. However, the success of any such\nmethod will be hindered should the data lacks the required quality. Big data\nquality assessment is therefore a major requirement for any organization or\nbusiness that use big data analytics for its decision making. On the other\nhand, using contextual information is advantageous in many analysis tasks in\nvarious domains, e.g. user behavior analysis in the social networks. However,\nthe big data quality assessment has benefited less from this potential. There\nis a vast variety of data sources in the big data domain that can be utilized\nto improve the quality evaluation of big data. Including contextual information\nprovided by these sources into the big data quality assessment process is an\nemerging trend towards more advanced techniques aimed at enhancing the\nperformance and accuracy of quality assessment. This paper presents a context\nclassification framework for big data quality, categorizing the context\nfeatures into four primary dimensions: 1) context category, 2) data source type\nthat contextual features come from, 3) discovery and extraction method of\ncontext, and 4) the quality factors affected by the contextual data. The\nproposed model introduces new context features and dimensions that need to be\ntaken into consideration in quality assessment of big data. The initial\nevaluation demonstrates that the model is more understandable, more\ncomprehensive, richer, and more useful compared to existing models.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 07:24:14 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mirzaie", "Mostafa", ""], ["Behkamal", "Behshid", ""], ["Paydar", "Samad", ""]]}, {"id": "1911.01275", "submitter": "Wesam Alruwaili", "authors": "Wesam Alruwaili, Bradley Protano, Tejasvi Sirigiriraju, Hamed Alhoori", "title": "Using Arabic Tweets to Understand Drug Selling Behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twitter is a popular platform for e-commerce in the Arab region including the\nsale of illegal goods and services. Social media platforms present multiple\nopportunities to mine information about behaviors pertaining to both illicit\nand pharmaceutical drugs and likewise to legal prescription drugs sold without\na prescription, i.e., illegally. Recognized as a public health risk, the sale\nand use of illegal drugs, counterfeit versions of legal drugs, and legal drugs\nsold without a prescription constitute a widespread problem that is reflected\nin and facilitated by social media. Twitter provides a crucial resource for\nmonitoring legal and illegal drug sales in order to support the larger goal of\nfinding ways to protect patient safety. We collected our dataset using Arabic\nkeywords. We then categorized the data using four machine learning classifiers.\nBased on a comparison of the respective results, we assessed the accuracy of\neach classifier in predicting two important considerations in analysing the\nextent to which drugs are available on social media: references to drugs for\nsale and the legality/illegality of the drugs thus advertised. For predicting\ntweets selling drugs, Support Vector Machine, yielded the highest accuracy rate\n(96%), whereas for predicting the legality of the advertised drugs, the Naive\nBayes, classifier yielded the highest accuracy rate (85%).\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 11:56:30 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Alruwaili", "Wesam", ""], ["Protano", "Bradley", ""], ["Sirigiriraju", "Tejasvi", ""], ["Alhoori", "Hamed", ""]]}, {"id": "1911.01276", "submitter": "Aidan Fuller", "authors": "Aidan Fuller, Zhong Fan, Charles Day and Chris Barlow", "title": "Digital Twin: Enabling Technologies, Challenges and Open Research", "comments": "This article has been accepted for publication in a future issue of\n  IEEE ACCESS, . Citation information: DOI 10.1109/ACCESS.2020.2998358, IEEE\n  Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2998358", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Twin technology is an emerging concept that has become the centre of\nattention for industry and, in more recent years, academia. The advancements in\nindustry 4.0 concepts have facilitated its growth, particularly in the\nmanufacturing industry. The Digital Twin is defined extensively but is best\ndescribed as the effortless integration of data between a physical and virtual\nmachine in either direction. The challenges, applications, and enabling\ntechnologies for Artificial Intelligence, Internet of Things (IoT) and Digital\nTwins are presented. A review of publications relating to Digital Twins is\nperformed, producing a categorical review of recent papers. The review has\ncategorised them by research areas: manufacturing, healthcare and smart cities,\ndiscussing a range of papers that reflect these areas and the current state of\nresearch. The paper provides an assessment of the enabling technologies,\nchallenges and open research for Digital Twins.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:16:21 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 13:01:28 GMT"}, {"version": "v3", "created": "Thu, 7 May 2020 16:45:01 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 11:56:59 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2020 15:58:27 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Fuller", "Aidan", ""], ["Fan", "Zhong", ""], ["Day", "Charles", ""], ["Barlow", "Chris", ""]]}, {"id": "1911.01277", "submitter": "Leon Abdillah", "authors": "Yandi Pranata, Leon Andretti Abdillah, Siti Sa'uda", "title": "Penerapan Knowledge Management System Sales and Customer Care pada PT\n  Satria Medikantara Palembang", "comments": "6 pages. Indonesian language. Penerapan Knowledge Management System\n  Sales and Customer Care pada PT Satria Medikantara Palembang. Paper presented\n  at the Bina Darma Conference on Computer Science (BDCCS2019), Palembang\n  (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PT Satria Medikantara Palembang has a great desire to apply knowledge\nmanagement system, therefore the documentation of knowledge and its utilization\nneeds to be well managed in the context of performance improvement. The\nimplementation of knowledge management in PT Satria Medikantara Palembang is\nconsidered very good and can have a positive impact for the quality of\nemployees. Where every employee can store and document and share knowledge\nowned, so that other employees can access, even learn and discuss with other\nemployees based on the knowledge posted. Then when needed a knowledge, it is\nvery easy to find in the database searching feature in the web based knowledge\nmanagement system at PT Satria Medikantara Palembang. The methodology used in\nthis study refers to the methodology of knowledge management system life cycle\ndeveloped by Awad and Ghaziri (2010), and this system will be based on web\nusing PHP programming language.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 05:45:56 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Pranata", "Yandi", ""], ["Abdillah", "Leon Andretti", ""], ["Sa'uda", "Siti", ""]]}, {"id": "1911.01278", "submitter": "Pietro Zambelli", "authors": "Chiara Scaramuzzino and Giulia Garegnani and Pietro Zambelli", "title": "Integrated approach for the identification of spatial patterns related\n  to renewable energy potential in European territories", "comments": "This study was conducted in the frame of the European Union (EU)\n  H2020 project HotMaps (grant number: 723677). HotMaps\n  (www.hotmaps-project.eu) aims at developing \"an open source heating/cooling\n  mapping and planning toolbox\" for EU28 policy makers at national and local\n  level. This work is licensed under a Creative Commons\n  Attribution-NonCommercial-NoDerivatives 4.0 International License", "journal-ref": "Scaramuzzino et al. 2019 Integrated approach for the\n  identification of spatial patterns related to renewable energy potential in\n  European territories. Renewable and Sustainable Energy Reviews, 101:1-13,\n  2019", "doi": "10.1016/j.rser.2018.10.024", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study presents an effort to classify the territories of a specific area,\naccording to similarities in the estimated potential of their renewable\nsources, considering also their economic and sociodemographic structure and\ntheir geographic features. Specifically, the paper focuses on the area of EU28\nand Switzerland and uses as basis for the analysis, data estimating the\npotential of renewable energy sources collected and elaborated in the framework\nof the project HotMaps (Horizon 2020). The method used to group the territorial\nunits is cluster analysis, and specifically the k-means algorithm. The data\npresent some interesting patterns and the territories of EU28 and Switzerland\nat NUTS3 level are classified into 17 clusters. The analysis shows the presence\nof heterogeneity within national borders and among territories comprised in the\nmacro regions target of specific EU programmes, specifically the\nAdriatic-Ionian region, the Alpine region, the Baltic Sea region and the Danube\nregion. The results of this research are meant to be used by European policy\nmakers in developing more focused transnational renewable energy policies and\nstrategies.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 11:43:45 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 10:39:21 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Scaramuzzino", "Chiara", ""], ["Garegnani", "Giulia", ""], ["Zambelli", "Pietro", ""]]}, {"id": "1911.01279", "submitter": "Lean Karlo Tolentino", "authors": "R. Jorda, Jr., C. Alcabasa, A. Buhay, E. C. Dela Cruz, J. P. Mendoza,\n  A. Tolentino, L. K. Tolentino, E. Fernandez, A. Thio-ac, J. Velasco, and N.\n  Arago", "title": "Automated Smart Wick System-Based Microfarm Using Internet of Things", "comments": null, "journal-ref": "Lecture Notes on Research and Innovation in Computer Engineering\n  and Computer Sciences, 2019", "doi": null, "report-no": null, "categories": "cs.CY eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a study conducted to allow urban farmers to remotely\nmonitor their farm through the design and development of an Internet of\nThings-based (IoT) microfarm prototype which utilized wick system as planting\nmethod. The system involves the detection of three environmental parameters\nnamely, light intensity, soil moisture and temperature through the use of\nrespective sensors which were connected to the Arduino microcontroller, the\nsensor node of the system. Irregularities in the aforementioned parameters were\nneutralized through the use of parameter regulators such as LED growlight\nstrips, water pump and air cooler. The data collected by these sensors were\ngathered by the Arduino microcontroller and were sent to the Web database\nthrough the IoT gateway which was the Raspberry Pi computer chip. These data\nwere also sent to an Android unit installed with the Microfarm Companion\napplication which was capable of monitoring and controlling the environmental\nparameters observed in the microfarm. The application allows the user to view\nthe current value of the parameter involved and to choose whether to control\nthe parameter regulators automatically or manually. The microfarm system runs\nautonomously which reduces the labor required to produce healthy plants and\ncrops. Mustard greens samples were used in testing the system. After a month of\nmonitoring the height of the samples, it was observed that the average height\nof the samples is about 0.23 cm taller than the standard height. The proponents\nhas also tested the system functionality by evaluating the sensor data log that\nprovides the values gathered by the sensors and the turn-on times of the\nparameter regulators. From these data, it can be observed that whenever the\nvalues obtained by the sensors fall outside the threshold range, the parameter\nregulators turns on, indicating that the system is working properly.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 22:35:03 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Jorda,", "R.", "Jr."], ["Alcabasa", "C.", ""], ["Buhay", "A.", ""], ["Cruz", "E. C. Dela", ""], ["Mendoza", "J. P.", ""], ["Tolentino", "A.", ""], ["Tolentino", "L. K.", ""], ["Fernandez", "E.", ""], ["Thio-ac", "A.", ""], ["Velasco", "J.", ""], ["Arago", "N.", ""]]}, {"id": "1911.01280", "submitter": "Juan C. Correa", "authors": "Henry Laverde-Rojas, Camilo A. Martinez, Oscar Camargo, Gustavo\n  Rojas-Matute, Marithza Sandoval-Escobar and Juan C. Correa", "title": "The Consistency of Trust-Sales Relationship in Latin-American E-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A taken-for-granted factor that facilitates the economic transactions in\nE-commerce platforms is the customer's trust in vendors' reputation. The\nempirical evaluation targeting the statistical consistency of the trust-sales\nrelationship, however, remains neglected in the literature. As an exploratory\nattempt of filling this gap, we provide a data-driven comprehensive framework\nthat allows us to develop a reproducible web scraping procedure that\nautomatically extracts the information of the interaction between customers and\nsellers in a Latin-American E-Commerce website with commercial operations in 18\ncountries. Among all nations analyzed, only Argentina, Brasil, Chile, Colombia,\nEcuador, Mexico, Uruguay, and Venezuela showed the highest indexes of trust.\nAlthough the trust-sales relationship was not statistically consistent across\nnations, trust proved to be the most important predictor of sales followed by\npurchase intention and price.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 12:37:36 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Laverde-Rojas", "Henry", ""], ["Martinez", "Camilo A.", ""], ["Camargo", "Oscar", ""], ["Rojas-Matute", "Gustavo", ""], ["Sandoval-Escobar", "Marithza", ""], ["Correa", "Juan C.", ""]]}, {"id": "1911.01281", "submitter": "Jie Hua", "authors": "Jie Hua, Chenguang Liu, Tomasz Kalbarczyk, Catherine Wright,\n  Gruia-Catalin Roman, Christine Julien", "title": "rIoT: Enabling Seamless Context-Aware Automation in the Internet of\n  Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in mobile computing capabilities and an increasing number of\nInternet of Things (IoT) devices have enriched the possibilities of the IoT but\nhave also increased the cognitive load required of IoT users. Existing\ncontext-aware systems provide various levels of automation in the IoT. Many of\nthese systems adaptively take decisions on how to provide services based on\nassumptions made a priori. The approaches are difficult to personalize to an\nindividual's dynamic environment, and thus today's smart IoT spaces often\ndemand complex and specialized interactions with the user in order to provide\ntailored services. We propose rIoT, a framework for seamless and personalized\nautomation of human-device interaction in the IoT. rIoT leverages existing\ntechnologies to operate across heterogeneous devices and networks to provide a\none-stop solution for device interaction in the IoT. We show how rIoT exploits\nsimilarities between contexts and employs a decision-tree like method to\nadaptively capture a user's preferences from a small number of interactions\nwith the IoT space. We measure the performance of rIoT on two real-world data\nsets and a real mobile device in terms of accuracy, learning speed, and latency\nin comparison to two state-of-the-art machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 00:07:04 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 16:53:09 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hua", "Jie", ""], ["Liu", "Chenguang", ""], ["Kalbarczyk", "Tomasz", ""], ["Wright", "Catherine", ""], ["Roman", "Gruia-Catalin", ""], ["Julien", "Christine", ""]]}, {"id": "1911.01282", "submitter": "Ziyuan Pu", "authors": "Ziyuan Pu, Meixin Zhu, Zhiyong Cui, Yinhai Wang", "title": "Mining Public Transit Ridership Flow and Origin-Destination Information\n  from Wi-Fi and Bluetooth Sensing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transit ridership flow and origin-destination (O-D) information is essential\nfor enhancing transit network design, optimizing transit route and improving\nservice. The effectiveness and preciseness of the traditional survey-based and\nsmart card data-driven method for O-D information inference have multiple\ndisadvantages due to the insufficient sample, the high time and energy cost,\nand the lack of inferring results validation. By considering the ubiquity of\nsmart mobile devices in the world, several methods were developed for\nestimating the transit ridership flow from Wi-Fi and Bluetooth sensing data by\nfiltering out the non-passenger MAC addresses based on the predefined\nthresholds. However, the accuracy of the filtering methods is still\nquestionable for the indeterminate threshold values and the lack of\nquantitative results validation. By combining the consideration of the assumed\noverlapped feature space of passenger and non-passenger with the above\nconcerns, a three steps data-driven method for estimating transit ridership\nflow and O-D information from Wi-Fi and Bluetooth sensing data is proposed in\nthis paper. The observed ridership flow is used as ground truth for calculating\nthe performance measurements. According to the results, the proposed approach\noutperformed all selected baseline models and existing filtering methods. The\nfindings of this study can help to provide real-time and precise transit\nridership flow and O-D information for supporting transit vehicle management\nand the quality of service enhancement.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 07:03:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Pu", "Ziyuan", ""], ["Zhu", "Meixin", ""], ["Cui", "Zhiyong", ""], ["Wang", "Yinhai", ""]]}, {"id": "1911.01468", "submitter": "Viktoriia Oliinyk", "authors": "Giulio Morina, Viktoriia Oliinyk, Julian Waton, Ines Marusic and\n  Konstantinos Georgatzis", "title": "Auditing and Achieving Intersectional Fairness in Classification\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms are extensively used to make increasingly more\nconsequential decisions about people, so achieving optimal predictive\nperformance can no longer be the only focus. A particularly important\nconsideration is fairness with respect to race, gender, or any other sensitive\nattribute. This paper studies intersectional fairness, where intersections of\nmultiple sensitive attributes are considered. Prior research has mainly focused\non fairness with respect to a single sensitive attribute, with intersectional\nfairness being comparatively less studied despite its critical importance for\nthe safety of modern machine learning systems. We present a comprehensive\nframework for auditing and achieving intersectional fairness in classification\nproblems: we define a suite of metrics to assess intersectional fairness in the\ndata or model outputs by extending known single-attribute fairness metrics, and\npropose methods for robustly estimating them even when some intersectional\nsubgroups are underrepresented. Furthermore, we develop post-processing\ntechniques to mitigate any detected intersectional bias in a classification\nmodel. Our techniques do not rely on any assumptions regarding the underlying\nmodel and preserve predictive performance at a guaranteed level of fairness.\nFinally, we give guidance on a practical implementation, showing how the\nproposed methods perform on a real-world dataset.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 19:55:23 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2020 16:41:23 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Morina", "Giulio", ""], ["Oliinyk", "Viktoriia", ""], ["Waton", "Julian", ""], ["Marusic", "Ines", ""], ["Georgatzis", "Konstantinos", ""]]}, {"id": "1911.01485", "submitter": "Yi Chern Tan", "authors": "Yi Chern Tan, L. Elisa Celis", "title": "Assessing Social and Intersectional Biases in Contextualized Word\n  Representations", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bias in machine learning has drawn significant attention, with work\nranging from demonstrations of bias in a multitude of applications, curating\ndefinitions of fairness for different contexts, to developing algorithms to\nmitigate bias. In natural language processing, gender bias has been shown to\nexist in context-free word embeddings. Recently, contextual word\nrepresentations have outperformed word embeddings in several downstream NLP\ntasks. These word representations are conditioned on their context within a\nsentence, and can also be used to encode the entire sentence. In this paper, we\nanalyze the extent to which state-of-the-art models for contextual word\nrepresentations, such as BERT and GPT-2, encode biases with respect to gender,\nrace, and intersectional identities. Towards this, we propose assessing bias at\nthe contextual word level. This novel approach captures the contextual effects\nof bias missing in context-free word embeddings, yet avoids confounding effects\nthat underestimate bias at the sentence encoding level. We demonstrate evidence\nof bias at the corpus level, find varying evidence of bias in embedding\nassociation tests, show in particular that racial bias is strongly encoded in\ncontextual word models, and observe that bias effects for intersectional\nminorities are exacerbated beyond their constituent minority identities.\nFurther, evaluating bias effects at the contextual word level captures biases\nthat are not captured at the sentence level, confirming the need for our novel\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 20:57:54 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tan", "Yi Chern", ""], ["Celis", "L. Elisa", ""]]}, {"id": "1911.01509", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Moninder Singh and Karthikeyan Natesan Ramamurthy", "title": "Understanding racial bias in health using the Medical Expenditure Panel\n  Survey data", "comments": "8 pages, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, several studies have demonstrated that there exist\nsignificant disparities in health indicators in the United States population\nacross various groups. Healthcare expense is used as a proxy for health in\nalgorithms that drive healthcare systems and this exacerbates the existing\nbias. In this work, we focus on the presence of racial bias in health\nindicators in the publicly available, and nationally representative Medical\nExpenditure Panel Survey (MEPS) data. We show that predictive models for care\nmanagement trained using this data inherit this bias. Finally, we demonstrate\nthat this inherited bias can be reduced significantly using simple mitigation\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 22:14:52 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Singh", "Moninder", ""], ["Ramamurthy", "Karthikeyan Natesan", ""]]}, {"id": "1911.01605", "submitter": "Wei Shao Dr", "authors": "Wei Shao, Arian Prabowo, Sichen Zhao, Siyu Tan, Piotr Konuiusz,\n  Jeffrey Chan, Xinhong Hei, Bradley Feest and Flora D. Salim", "title": "Flight Delay Prediction using Airport Situational Awareness Map", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prediction of flight delays plays a significantly important role for\nairlines and travelers because flight delays cause not only tremendous economic\nloss but also potential security risks. In this work, we aim to integrate\nmultiple data sources to predict the departure delay of a scheduled flight.\nDifferent from previous work, we are the first group, to our best knowledge, to\ntake advantage of airport situational awareness map, which is defined as\nairport traffic complexity (ATC), and combine the proposed ATC factors with\nweather conditions and flight information. Features engineering methods and\nmost state-of-the-art machine learning algorithms are applied to a large\nreal-world data sources. We reveal a couple of factors at the airport which has\na significant impact on flight departure delay time. The prediction results\nshow that the proposed factors are the main reasons behind the flight delays.\nUsing our proposed framework, an improvement in accuracy for flight departure\ndelay prediction is obtained.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 03:58:25 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Shao", "Wei", ""], ["Prabowo", "Arian", ""], ["Zhao", "Sichen", ""], ["Tan", "Siyu", ""], ["Konuiusz", "Piotr", ""], ["Chan", "Jeffrey", ""], ["Hei", "Xinhong", ""], ["Feest", "Bradley", ""], ["Salim", "Flora D.", ""]]}, {"id": "1911.01708", "submitter": "Olasupo Ajayi", "authors": "Olasupo O. Ajayi, Antoine B. Bagula and Kun Ma", "title": "Fourth Industrial Revolution for Development: The Relevance of Cloud\n  Federation in Healthcare Support", "comments": "25 pages, 24 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inefficient healthcare is a major concern among many African nations and can\nbe mitigated by building world-class infrastructure connecting different\nmedical facilities for collaboration and resource sharing. Such infrastructure\nshould support collection and exchange of medical data for the purpose of\naccessing expertise not available locally. It should be equipped with modern\ntechnologies of the fourth industrial revolution, providing decision support to\ndoctors thereby enabling African nations leapfrog from poorly equipped to\nmedically prepared. Sadly, world-class healthcare infrastructure are a missing\npiece in the African public health ecosystem. Medical facilities are either\nnon-existent or prohibitively expensive when they exist. Federated cloud\ncomputing can provide a solution to this challenge. Being a model that allows\ncollaboration between multiple Cloud service providers through resources\npooling; it allows for the execution of tasks on computing resources flexibly\nand cost efficiently. This paper aims to connect unconnected medical facilities\nin Africa by proposing a Cloud federation for healthcare using cooperative and\ncompetitive collaboration models. Simulations were carried out to test the\nefficacy of these models using five different workload allocation schemes:\nFirst-Fit-Descending (FFD), Best-Fit-Descending (BFD), Binary-Search-Best-Fit\n(BSBF); Genetic Algorithm meta-heuristic and Stable Roommate Allocation\neconomic model for both light and heavy workloads. Results of simulations\nrevealed that the cooperative model resulted in lower delays but higher\nresource utilisation; while the competitive provided faster service delivery\nand better quality of service. BSBF and BFD resulted in the best resources\nutilisation and energy conservation. Finally, deployment considerations and\npotential business models for federated Cloud for African healthcare were\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 10:59:18 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ajayi", "Olasupo O.", ""], ["Bagula", "Antoine B.", ""], ["Ma", "Kun", ""]]}, {"id": "1911.01968", "submitter": "Todd Hylton", "authors": "Tom Conte, Erik DeBenedictis, Natesh Ganesh, Todd Hylton, John Paul\n  Strachan, R. Stanley Williams, Alexander Alemi, Lee Altenberg, Gavin Crooks,\n  James Crutchfield, Lidia del Rio, Josh Deutsch, Michael DeWeese, Khari\n  Douglas, Massimiliano Esposito, Michael Frank, Robert Fry, Peter Harsha, Mark\n  Hill, Christopher Kello, Jeff Krichmar, Suhas Kumar, Shih-Chii Liu, Seth\n  Lloyd, Matteo Marsili, Ilya Nemenman, Alex Nugent, Norman Packard, Dana\n  Randall, Peter Sadowski, Narayana Santhanam, Robert Shaw, Adam Stieg, Elan\n  Stopnitzky, Christof Teuscher, Chris Watkins, David Wolpert, Joshua Yang, and\n  Yan Yufik", "title": "Thermodynamic Computing", "comments": "A Computing Community Consortium (CCC) workshop report, 36 pages", "journal-ref": null, "doi": null, "report-no": "ccc2019report_6", "categories": "cs.CY cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hardware and software foundations laid in the first half of the 20th\nCentury enabled the computing technologies that have transformed the world, but\nthese foundations are now under siege. The current computing paradigm, which is\nthe foundation of much of the current standards of living that we now enjoy,\nfaces fundamental limitations that are evident from several perspectives. In\nterms of hardware, devices have become so small that we are struggling to\neliminate the effects of thermodynamic fluctuations, which are unavoidable at\nthe nanometer scale. In terms of software, our ability to imagine and program\neffective computational abstractions and implementations are clearly challenged\nin complex domains. In terms of systems, currently five percent of the power\ngenerated in the US is used to run computing systems - this astonishing figure\nis neither ecologically sustainable nor economically scalable. Economically,\nthe cost of building next-generation semiconductor fabrication plants has\nsoared past $10 billion. All of these difficulties - device scaling, software\ncomplexity, adaptability, energy consumption, and fabrication economics -\nindicate that the current computing paradigm has matured and that continued\nimprovements along this path will be limited. If technological progress is to\ncontinue and corresponding social and economic benefits are to continue to\naccrue, computing must become much more capable, energy efficient, and\naffordable. We propose that progress in computing can continue under a united,\nphysically grounded, computational paradigm centered on thermodynamics. Herein\nwe propose a research agenda to extend these thermodynamic foundations into\ncomplex, non-equilibrium, self-organizing systems and apply them holistically\nto future computing systems that will harness nature's innate computational\ncapacity. We call this type of computing \"Thermodynamic Computing\" or TC.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 17:48:35 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 15:12:35 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Conte", "Tom", ""], ["DeBenedictis", "Erik", ""], ["Ganesh", "Natesh", ""], ["Hylton", "Todd", ""], ["Strachan", "John Paul", ""], ["Williams", "R. Stanley", ""], ["Alemi", "Alexander", ""], ["Altenberg", "Lee", ""], ["Crooks", "Gavin", ""], ["Crutchfield", "James", ""], ["del Rio", "Lidia", ""], ["Deutsch", "Josh", ""], ["DeWeese", "Michael", ""], ["Douglas", "Khari", ""], ["Esposito", "Massimiliano", ""], ["Frank", "Michael", ""], ["Fry", "Robert", ""], ["Harsha", "Peter", ""], ["Hill", "Mark", ""], ["Kello", "Christopher", ""], ["Krichmar", "Jeff", ""], ["Kumar", "Suhas", ""], ["Liu", "Shih-Chii", ""], ["Lloyd", "Seth", ""], ["Marsili", "Matteo", ""], ["Nemenman", "Ilya", ""], ["Nugent", "Alex", ""], ["Packard", "Norman", ""], ["Randall", "Dana", ""], ["Sadowski", "Peter", ""], ["Santhanam", "Narayana", ""], ["Shaw", "Robert", ""], ["Stieg", "Adam", ""], ["Stopnitzky", "Elan", ""], ["Teuscher", "Christof", ""], ["Watkins", "Chris", ""], ["Wolpert", "David", ""], ["Yang", "Joshua", ""], ["Yufik", "Yan", ""]]}, {"id": "1911.02013", "submitter": "Jun Zhao", "authors": "Wubing Chen, Zhiying Xu, Shuyu Shi, Yang Zhao, Jun Zhao", "title": "A Survey of Blockchain Applications in Different Domains", "comments": "Published in Proceedings of the 2018 International Conference on\n  Blockchain Technology and Application (ICBTA)", "journal-ref": null, "doi": "10.1145/3301403.3301407", "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains have received much attention recently since they provide\ndecentralized approaches to the creation and management of value. Many banks,\nInternet companies, car manufacturers, and even governments worldwide have\nincorporated or started considering blockchains to improve the security,\nscalability, and efficiency of their services. In this paper, we survey\nblockchain applications in different areas. These areas include cryptocurrency,\nhealthcare, advertising, insurance, copyright protection, energy, and societal\napplications. Our work provides a timely summary for individuals and\norganizations interested in blockchains. We envision our study to motivate more\nblockchain applications.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 03:27:27 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chen", "Wubing", ""], ["Xu", "Zhiying", ""], ["Shi", "Shuyu", ""], ["Zhao", "Yang", ""], ["Zhao", "Jun", ""]]}, {"id": "1911.02302", "submitter": "Nik Dawson", "authors": "Nik Dawson, Marian-Andrei Rizoiu, Benjamin Johnston and Mary-Anne\n  Williams", "title": "Adaptively selecting occupations to detect skill shortages from online\n  job ads", "comments": null, "journal-ref": "2019 IEEE International Conference on Big Data (Big Data)", "doi": "10.1109/BigData47090.2019.9005967", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Labour demand and skill shortages have historically been difficult to assess\ngiven the high costs of conducting representative surveys and the inherent\ndelays of these indicators. This is particularly consequential for fast\ndeveloping skills and occupations, such as those relating to Data Science and\nAnalytics (DSA). This paper develops a data-driven solution to detecting skill\nshortages from online job advertisements (ads) data. We first propose a method\nto generate sets of highly similar skills based on a set of seed skills from\njob ads. This provides researchers with a novel method to adaptively select\noccupations based on granular skills data. Next, we apply this adaptive skills\nsimilarity technique to a dataset of over 6.7 million Australian job ads in\norder to identify occupations with the highest proportions of DSA skills. This\nuncovers 306,577 DSA job ads across 23 occupational classes from 2012-2019.\nFinally, we propose five variables for detecting skill shortages from online\njob ads: (1) posting frequency; (2) salary levels; (3) education requirements;\n(4) experience demands; and (5) job ad posting predictability. This contributes\nfurther evidence to the goal of detecting skills shortages in real-time. In\nconducting this analysis, we also find strong evidence of skills shortages in\nAustralia for highly technical DSA skills and occupations. These results\nprovide insights to Data Science researchers, educators, and policy-makers from\nother advanced economies about the types of skills that should be cultivated to\nmeet growing DSA labour demands in the future.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 10:49:08 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 07:08:05 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 05:13:35 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Dawson", "Nik", ""], ["Rizoiu", "Marian-Andrei", ""], ["Johnston", "Benjamin", ""], ["Williams", "Mary-Anne", ""]]}, {"id": "1911.02376", "submitter": "Anamika Chhabra", "authors": "Anamika Chhabra, S. R. S. Iyengar", "title": "Investigating Ortega Hypothesis in Q&A portals: An Analysis of\n  StackOverflow", "comments": "11 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ortega Hypothesis considers masses, i.e., a large number of average people\nwho are not specially qualified as being instrumental in any system's progress.\nThis hypothesis has been reasonably examined in the scientific domain where it\nhas been supported by a few works while refuted by many others, resulting in no\nclear consensus. While the hypothesis has only been explored in the scientific\ndomain so far, it has hardly been examined in other fields. Given the\nlarge-scale collaboration facilitated by the modern Q&A portals where a crowd\nwith a diverse skill-set contributes, an investigation of this hypothesis\nbecomes necessary for informed policy-making. In this work, we investigate the\nresearch question inspired by Ortega Hypothesis in StackOverflow where we\nexamine the contribution made by masses and check whether the system may\ncontinue to function well even in their absence. The results point towards the\nimportance of masses in Q&A portals for the little but useful contribution that\nthey provide. The insights obtained from the study may help in devising\ninformed incentivization policies enabling better utilization of the potential\nof the users.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 13:34:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Chhabra", "Anamika", ""], ["Iyengar", "S. R. S.", ""]]}, {"id": "1911.02455", "submitter": "Agathe Balayn", "authors": "Agathe Balayn, Alessandro Bozzon, Zoltan Szlavik", "title": "Unfairness towards subjective opinions in Machine Learning", "comments": "Human-Centered Machine Learning Perspectives (HCML) workshop at the\n  CHI conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the high interest for Machine Learning (ML) in academia and industry,\nmany issues related to the application of ML to real-life problems are yet to\nbe addressed. Here we put forward one limitation which arises from a lack of\nadaptation of ML models and datasets to specific applications. We formalise a\nnew notion of unfairness as exclusion of opinions. We propose ways to quantify\nthis unfairness, and aid understanding its causes through visualisation. These\ninsights into the functioning of ML-based systems hint at methods to mitigate\nunfairness.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 16:11:41 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Balayn", "Agathe", ""], ["Bozzon", "Alessandro", ""], ["Szlavik", "Zoltan", ""]]}, {"id": "1911.02673", "submitter": "Emily Aiken", "authors": "Emily L. Aiken, Andre T. Nguyen, Mauricio Santillana", "title": "Towards the Use of Neural Networks for Influenza Prediction at Multiple\n  Spatial Resolutions", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract; Added Footer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of a Gated Recurrent Unit (GRU) for influenza prediction\nat the state- and city-level in the US, and experiment with the inclusion of\nreal-time flu-related Internet search data. We find that a GRU has lower\nprediction error than current state-of-the-art methods for data-driven\ninfluenza prediction at time horizons of over two weeks. In contrast with other\nmachine learning approaches, the inclusion of real-time Internet search data\ndoes not improve GRU predictions.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 23:14:53 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 05:10:27 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Aiken", "Emily L.", ""], ["Nguyen", "Andre T.", ""], ["Santillana", "Mauricio", ""]]}, {"id": "1911.02715", "submitter": "Johann Gaebler", "authors": "William Cai, Johann Gaebler, Nikhil Garg, Sharad Goel", "title": "Fair Allocation through Selective Information Acquisition", "comments": "To appear in Proceedings of the 2020 AAAI/ACM Conference on AI,\n  Ethics, and Society (AIES). Update: Fully specified the definition of\n  threshold policies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public and private institutions must often allocate scare resources under\nuncertainty. Banks, for example, extend credit to loan applicants based in part\non their estimated likelihood of repaying a loan. But when the quality of\ninformation differs across candidates (e.g., if some applicants lack\ntraditional credit histories), common lending strategies can lead to\ndisparities across groups. Here we consider a setting in which decision makers\n-- before allocating resources -- can choose to spend some of their limited\nbudget further screening select individuals. We present a computationally\nefficient algorithm for deciding whom to screen that maximizes a standard\nmeasure of social welfare. Intuitively, decision makers should screen\ncandidates on the margin, for whom the additional information could plausibly\nalter the allocation. We formalize this idea by showing the problem can be\nreduced to solving a series of linear programs. Both on synthetic and\nreal-world datasets, this strategy improves utility, illustrating the value of\ntargeted information acquisition in such decisions. Further, when there is\nsocial value for distributing resources to groups for whom we have a priori\npoor information -- like those without credit scores -- our approach can\nsubstantially improve the allocation of limited assets.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 02:09:06 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 17:18:39 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 03:05:05 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Cai", "William", ""], ["Gaebler", "Johann", ""], ["Garg", "Nikhil", ""], ["Goel", "Sharad", ""]]}, {"id": "1911.02771", "submitter": "Arnab Chatterjee", "authors": "Sachin Thukral, Arnab Chatterjee, Hardik Meisheri, Tushar Kataria,\n  Aman Agarwal, Ishan Verma, Lipika Dey", "title": "Characterizing behavioral trends in a community driven discussion\n  platform", "comments": "19 pages. Extended version of arxiv:1809.07087. Springer Lecture\n  Notes Format, to be published in Lecture Notes in Social Networks (Springer)", "journal-ref": null, "doi": "10.1007/978-3-030-33698-1_8", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a systematic analysis of the patterns of behavior of\nindividuals as well as groups observed in community-driven platforms for\ndiscussion like Reddit, where users usually exchange information and viewpoints\non their topics of interest. We perform a statistical analysis of the behavior\nof posts and model the users' interactions around them. A platform like Reddit\nwhich has grown exponentially, starting from a very small community to one of\nthe largest social networks, with its large user base and popularity harboring\na variety of behavior of users in terms of their activity. Our work provides\ninteresting insights about a huge number of inactive posts which fail to\nattract attention despite their authors exhibiting Cyborg-like behavior to\nattract attention. We also observe short-lived yet extremely active posts\nemulate a phenomenon like Mayfly Buzz. A method is presented, to study the\nactivity around posts which are highly active, to determine the presence of\nLimelight hogging activity. We also present a systematic analysis to study the\npresence of controversies in posts. We analyzed data from two periods of\none-year duration but separated by few years in time, to understand how social\nmedia has evolved through the years.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 06:29:19 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Thukral", "Sachin", ""], ["Chatterjee", "Arnab", ""], ["Meisheri", "Hardik", ""], ["Kataria", "Tushar", ""], ["Agarwal", "Aman", ""], ["Verma", "Ishan", ""], ["Dey", "Lipika", ""]]}, {"id": "1911.02854", "submitter": "Juste Raimbault", "authors": "Denise Pumain and Juste Raimbault", "title": "Perspectives on urban theories", "comments": "31 pages, 3 figures, 2 tables", "journal-ref": "In: Pumain D. (eds) Theories and Models of Urbanization (pp.\n  303-330). Lecture Notes in Morphogenesis. Springer, Cham (2020)", "doi": "10.1007/978-3-030-36656-8_16", "report-no": null, "categories": "cs.DL cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the end of the five years of work in our GeoDiverCity program, we brought\ntogether a diversity of authors from different disciplines. Each person was\ninvited to present an important question about the theories and models of\nurbanization. They are representative of a variety of currents in urban\nresearch. Rather than repeat here the contents of all chapters, we propose two\nways to synthesize the scientific contributions of this book. In a first part\nwe replace them in relation to a few principles that were experimented in our\nprogram, and in a second part we situate them with respect to a broader view of\ninternational literature on these topics.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2019 11:13:25 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 11:28:48 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Pumain", "Denise", ""], ["Raimbault", "Juste", ""]]}, {"id": "1911.03020", "submitter": "Mohammad Yaghini", "authors": "Mohammad Yaghini, Andreas Krause, and Hoda Heidari", "title": "A Human-in-the-loop Framework to Construct Context-aware Mathematical\n  Notions of Outcome Fairness", "comments": "In the forth AAAI/ACM Conference on Artificial Intelligence, Ethics,\n  and Society (AIES-2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing mathematical notions of fairness fail to account for the context of\ndecision-making. We argue that moral consideration of contextual factors is an\ninherently human task. So we present a framework to learn context-aware\nmathematical formulations of fairness by eliciting people's situated fairness\nassessments. Our family of fairness notions corresponds to a new interpretation\nof economic models of Equality of Opportunity (EOP), and it includes most\nexisting notions of fairness as special cases. Our human-in-the-loop approach\nis designed to learn the appropriate parameters of the EOP family by utilizing\nhuman responses to pair-wise questions about decision subjects' circumstance\nand deservingness, and the harm/benefit imposed on them. We illustrate our\nframework in a hypothetical criminal risk assessment scenario by conducting a\nseries of human-subject experiments on Amazon Mechanical Turk. Our work takes\nan important initial step toward empowering stakeholders to have a voice in the\nformulation of fairness for Machine Learning.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 03:41:03 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 12:41:14 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Yaghini", "Mohammad", ""], ["Krause", "Andreas", ""], ["Heidari", "Hoda", ""]]}, {"id": "1911.03064", "submitter": "Po-Sen Huang", "authors": "Po-Sen Huang, Huan Zhang, Ray Jiang, Robert Stanforth, Johannes Welbl,\n  Jack Rae, Vishal Maini, Dani Yogatama, Pushmeet Kohli", "title": "Reducing Sentiment Bias in Language Models via Counterfactual Evaluation", "comments": "Accepted in the Findings of EMNLP, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in language modeling architectures and the availability of large\ntext corpora have driven progress in automatic text generation. While this\nresults in models capable of generating coherent texts, it also prompts models\nto internalize social biases present in the training corpus. This paper aims to\nquantify and reduce a particular type of bias exhibited by language models:\nbias in the sentiment of generated text. Given a conditioning context (e.g., a\nwriting prompt) and a language model, we analyze if (and how) the sentiment of\nthe generated text is affected by changes in values of sensitive attributes\n(e.g., country names, occupations, genders) in the conditioning context using a\nform of counterfactual evaluation. We quantify sentiment bias by adopting\nindividual and group fairness metrics from the fair machine learning\nliterature, and demonstrate that large-scale models trained on two different\ncorpora (news articles, and Wikipedia) exhibit considerable levels of bias. We\nthen propose embedding and sentiment prediction-derived regularization on the\nlanguage model's latent representations. The regularizations improve fairness\nmetrics while retaining comparable levels of perplexity and semantic\nsimilarity.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 05:56:01 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 17:51:20 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 17:58:35 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Huang", "Po-Sen", ""], ["Zhang", "Huan", ""], ["Jiang", "Ray", ""], ["Stanforth", "Robert", ""], ["Welbl", "Johannes", ""], ["Rae", "Jack", ""], ["Maini", "Vishal", ""], ["Yogatama", "Dani", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1911.03216", "submitter": "Jevgenij Gamper", "authors": "Agnes Schim van der Loeff, Iggy Bassi, Sachin Kapila, Jevgenij Gamper", "title": "AI Ethics for Systemic Issues: A Structural Approach", "comments": null, "journal-ref": "NeurIPS AI for Social Good 2019", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The debate on AI ethics largely focuses on technical improvements and\nstronger regulation to prevent accidents or misuse of AI, with solutions\nrelying on holding individual actors accountable for responsible AI\ndevelopment. While useful and necessary, we argue that this \"agency\" approach\ndisregards more indirect and complex risks resulting from AI's interaction with\nthe socio-economic and political context. This paper calls for a \"structural\"\napproach to assessing AI's effects in order to understand and prevent such\nsystemic risks where no individual can be held accountable for the broader\nnegative impacts. This is particularly relevant for AI applied to systemic\nissues such as climate change and food security which require political\nsolutions and global cooperation. To properly address the wide range of AI\nrisks and ensure 'AI for social good', agency-focused policies must be\ncomplemented by policies informed by a structural approach.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 12:31:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["van der Loeff", "Agnes Schim", ""], ["Bassi", "Iggy", ""], ["Kapila", "Sachin", ""], ["Gamper", "Jevgenij", ""]]}, {"id": "1911.03563", "submitter": "Khaza Anuarul Hoque", "authors": "Samaikya Valluripally, Aniket Gulhane, Reshmi Mitra, Khaza Anuarul\n  Hoque, Prasad Calyam", "title": "Attack Trees for Security and Privacy in Social Virtual Reality Learning\n  Environments", "comments": "Accepted for publication in in the IEEE Consumer Communications &\n  Networking Conference (CCNC 2020)", "journal-ref": null, "doi": "10.1109/CCNC46108.2020.9045724", "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Virtual Reality Learning Environment (VRLE) is a novel edge computing\nplatform for collaboration amongst distributed users. Given that VRLEs are used\nfor critical applications (e.g., special education, public safety training), it\nis important to ensure security and privacy issues. In this paper, we present a\nnovel framework to obtain quantitative assessments of threats and\nvulnerabilities for VRLEs. Based on the use cases from an actual social VRLE\nviz., vSocial, we first model the security and privacy using the attack trees.\nSubsequently, these attack trees are converted into stochastic timed automata\nrepresentations that allow for rigorous statistical model checking. Such an\nanalysis helps us adopt pertinent design principles such as hardening,\ndiversity and principle of least privilege to enhance the resilience of social\nVRLEs. Through experiments in a vSocial case study, we demonstrate the\neffectiveness of our attack tree modeling with a reduction of 26% in\nprobability of loss of integrity (security) and 80% in privacy leakage\n(privacy) in before and after scenarios pertaining to the adoption of the\ndesign principles.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:25:21 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Valluripally", "Samaikya", ""], ["Gulhane", "Aniket", ""], ["Mitra", "Reshmi", ""], ["Hoque", "Khaza Anuarul", ""], ["Calyam", "Prasad", ""]]}, {"id": "1911.03730", "submitter": "Vikas Ramachandra", "authors": "Vikas Ramachandra", "title": "Forecasting the effect of heat stress index and climate change on cloud\n  data center energy consumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.SP stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we estimate the effect of heat stress index (a measure which\ntakes into account rising temperatures as well as humidity) on data center\nenergy consumption. We use forecasting models to predict future energy use by\ndata centers, taking into account rising temperature scenarios. We compare\nthose estimates with baseline forecasted energy consumption (without heat\nstress index or rising temperature correction) and present the result that\nthere is a sizeable and significant difference in the two forecasts. We show\nthat rising temperatures will cause a negative impact on data center energy\nconsumption, increasing it by about 8 percent, and conclude that data center\nenergy consumption analyses and forecasts must include the effects of heat\nstress index and rising temperatures and other climate change related effects.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 16:17:15 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ramachandra", "Vikas", ""]]}, {"id": "1911.03746", "submitter": "Manuel Mazzara", "authors": "Ziyad Elbanna, Ilya Afanasyev, Luiz J.P. Araujo, Rasheed Hussain,\n  Mansur Khazeev, Joseph Lamptey, Manuel Mazzara, Swati Megha, Diksha\n  Moolchandani, Dragos Strugar", "title": "A Machine to Machine framework for the charging of Electric Autonomous\n  Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric Autonomous Vehicles (EAVs) have gained increasing attention of\nindustry, governments and scientific communities concerned about issues related\nto classic transportation including accidents and casualties, gas emissions and\nair pollution, intensive traffic and city viability. One of the aspects,\nhowever, that prevent a broader adoption of this technology is the need for\nhuman interference to charge EAVs, which is still mostly manual and\ntime-consuming. This study approaches such a problem by introducing the\nInno-EAV, an open-source charging framework for EAVs that employs\nmachine-to-machine (M2M) distributed communication. The idea behind M2M is to\nhave networked devices that can interact, exchange information and perform\nactions without any manual assistance of humans. The advantages of the Inno-EAV\ninclude the automation of charging processes and the collection of relevant\ndata that can support better decision making in the spheres of energy\ndistribution. In this paper, we present the software design of the framework,\nthe development process, the emphasis on the distributed architecture and the\nnetworked communication, and we discuss the back-end database that is used to\nstore information about car owners, cars, and charging stations.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 18:09:32 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Elbanna", "Ziyad", ""], ["Afanasyev", "Ilya", ""], ["Araujo", "Luiz J. P.", ""], ["Hussain", "Rasheed", ""], ["Khazeev", "Mansur", ""], ["Lamptey", "Joseph", ""], ["Mazzara", "Manuel", ""], ["Megha", "Swati", ""], ["Moolchandani", "Diksha", ""], ["Strugar", "Dragos", ""]]}, {"id": "1911.03839", "submitter": "Dongrui Wu", "authors": "Bo Zhang and Yuqi Cui and Meng Wang and Jingjing Li and Lei Jin and\n  Dongrui Wu", "title": "In Vitro Fertilization (IVF) Cumulative Pregnancy Rate Prediction from\n  Basic Patient Characteristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tens of millions of women suffer from infertility worldwide each year. In\nvitro fertilization (IVF) is the best choice for many such patients. However,\nIVF is expensive, time-consuming, and both physically and emotionally\ndemanding. The first question that a patient usually asks before the IVF is how\nlikely she will conceive, given her basic medical examination information. This\npaper proposes three approaches to predict the cumulative pregnancy rate after\nmultiple oocyte pickup cycles. Experiments on 11,190 patients showed that first\nclustering the patients into different groups and then building a support\nvector machine model for each group can achieve the best overall performance.\nOur model could be a quick and economic approach for reliably estimating the\ncumulative pregnancy rate for a patient, given only her basic medical\nexamination information, well before starting the actual IVF procedure. The\npredictions can help the patient make optimal decisions on whether to use her\nown oocyte or donor oocyte, how many oocyte pickup cycles she may need, whether\nto use embryo frozen, etc. They will also reduce the patient's cost and time to\npregnancy, and improve her quality of life.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 03:00:07 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Zhang", "Bo", ""], ["Cui", "Yuqi", ""], ["Wang", "Meng", ""], ["Li", "Jingjing", ""], ["Jin", "Lei", ""], ["Wu", "Dongrui", ""]]}, {"id": "1911.03854", "submitter": "Kai Nakamura", "authors": "Kai Nakamura, Sharon Levy, William Yang Wang", "title": "r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake\n  News Detection", "comments": "Accepted LREC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news has altered society in negative ways in politics and culture. It\nhas adversely affected both online social network systems as well as offline\ncommunities and conversations. Using automatic machine learning classification\nmodels is an efficient way to combat the widespread dissemination of fake news.\nHowever, a lack of effective, comprehensive datasets has been a problem for\nfake news research and detection model development. Prior fake news datasets do\nnot provide multimodal text and image data, metadata, comment data, and\nfine-grained fake news categorization at the scale and breadth of our dataset.\nWe present Fakeddit, a novel multimodal dataset consisting of over 1 million\nsamples from multiple categories of fake news. After being processed through\nseveral stages of review, the samples are labeled according to 2-way, 3-way,\nand 6-way classification categories through distant supervision. We construct\nhybrid text+image models and perform extensive experiments for multiple\nvariations of classification, demonstrating the importance of the novel aspect\nof multimodality and fine-grained classification unique to Fakeddit.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 05:06:38 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 17:55:57 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Nakamura", "Kai", ""], ["Levy", "Sharon", ""], ["Wang", "William Yang", ""]]}, {"id": "1911.03855", "submitter": "Salvatore Giorgi", "authors": "Salvatore Giorgi, Veronica Lynn, Keshav Gupta, Farhan Ahmed, Sandra\n  Matz, Lyle Ungar and H. Andrew Schwartz", "title": "Correcting Sociodemographic Selection Biases for Population Prediction\n  from Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media is increasingly used for large-scale population predictions,\nsuch as estimating community health statistics. However, social media users are\nnot typically a representative sample of the intended population -- a\n\"selection bias\". Within the social sciences, such a bias is typically\naddressed with restratification techniques, where observations are reweighted\naccording to how under- or over-sampled their socio-demographic groups are.\nYet, restratifaction is rarely evaluated for improving prediction. Across four\ntasks of predicting U.S. county population health statistics from Twitter, we\nfind standard restratification techniques provide no improvement and often\ndegrade prediction accuracies. The core reasons for this seems to be both\nshrunken estimates (reduced variance of model predicted values) and sparse\nestimates of each population's socio-demographics. We thus develop and evaluate\nthree methods to address these problems: estimator redistribution to account\nfor shrinking, and adaptive binning and informed smoothing to handle sparse\nsocio-demographic estimates. We show that each of these methods significantly\noutperforms the standard restratification approaches. Combining approaches, we\nfind substantial improvements over non-restratified models, yielding a 53.0%\nincrease in predictive accuracy (R^2) in the case of surveyed life\nsatisfaction, and a 17.8% average increase across all tasks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 05:13:29 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 20:05:06 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 21:48:35 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Giorgi", "Salvatore", ""], ["Lynn", "Veronica", ""], ["Gupta", "Keshav", ""], ["Ahmed", "Farhan", ""], ["Matz", "Sandra", ""], ["Ungar", "Lyle", ""], ["Schwartz", "H. Andrew", ""]]}, {"id": "1911.04013", "submitter": "Vishal Anand", "authors": "Vishal Anand, Ravi Shukla, Ashwani Gupta and Abhishek Kumar", "title": "Customized video filtering on YouTube", "comments": "13 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inappropriate and profane content on social media is exponentially increasing\nand big corporations are becoming more aware of the type of content on which\nthey are advertising and how it may affect their brand reputation. But with a\nhuge surge in content being posted online it becomes seemingly difficult to\nfilter out related videos on which they can run their ads without compromising\nbrand name. Advertising on youtube videos generates a huge amount of revenue\nfor corporations. It becomes increasingly important for such corporations to\nadvertise on only the videos that don't hurt the feelings, community or harmony\nof the audience at large. In this paper, we propose a system to identify\ninappropriate content on YouTube and leverage it to perform a first of its\nkind, large scale, quantitative characterization that reveals some of the risks\nof YouTube ads consumption on inappropriate videos. Customization of the\narchitecture have also been included to serve different requirements of\ncorporations. Our analysis reveals that YouTube is still plagued by such\ndisturbing videos and its currently deployed countermeasures are ineffective in\nterms of detecting them in a timely manner. Our framework tries to fill this\ngap by providing a handy, add on solution to filter the videos and help\ncorporations and companies to push ads on the platform without worrying about\nthe content on which the ads are displayed.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 00:05:17 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 13:31:25 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Anand", "Vishal", ""], ["Shukla", "Ravi", ""], ["Gupta", "Ashwani", ""], ["Kumar", "Abhishek", ""]]}, {"id": "1911.04016", "submitter": "Hideaki Hata", "authors": "Raula Gaikovina Kula and Christoph Treude and Hideaki Hata and\n  Sebastian Baltes and Igor Steinmacher and Marco Aurelio Gerosa and Winifred\n  Kula Amini", "title": "Challenges for Inclusion in Software Engineering: The Case of the\n  Emerging Papua New Guinean Society", "comments": "IEEE Software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software plays a central role in modern societies, with its high economic\nvalue and potential for advancing societal change. In this paper, we\ncharacterise challenges and opportunities for a country progressing towards\nentering the global software industry, focusing on Papua New Guinea (PNG). By\nhosting a Software Engineering workshop, we conducted a qualitative study by\nrecording talks (n=3), employing a questionnaire (n=52), and administering an\nin-depth focus group session with local actors (n=5). Based on a thematic\nanalysis, we identified challenges as barriers and opportunities for the PNG\nsoftware engineering community. We also discuss the state of practices and how\nto make it inclusive for practitioners, researchers, and educators from both\nthe local and global software engineering community.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 22:20:22 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 09:27:04 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Kula", "Raula Gaikovina", ""], ["Treude", "Christoph", ""], ["Hata", "Hideaki", ""], ["Baltes", "Sebastian", ""], ["Steinmacher", "Igor", ""], ["Gerosa", "Marco Aurelio", ""], ["Amini", "Winifred Kula", ""]]}, {"id": "1911.04102", "submitter": "Anis Koubaa", "authors": "Anis Koubaa, Adel Ammar, Bilel Benjdira, Abdullatif Al-Hadid, Belal\n  Kawaf, Saleh Ali Al-Yahri, Abdelrahman Babiker, Koutaiba Assaf, Mohannad Ba\n  Ras", "title": "Activity Monitoring of Islamic Prayer (Salat) Postures using Deep\n  Learning", "comments": "Submitted to the 6th International Conference on Data Science and\n  Machine Learning Applications (CDMA 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the Muslim community, the prayer (i.e. Salat) is the second pillar of\nIslam, and it is the most essential and fundamental worshiping activity that\nbelievers have to perform five times a day. From a gestures' perspective, there\nare predefined human postures that must be performed in a precise manner.\nHowever, for several people, these postures are not correctly performed, due to\nbeing new to Salat or even having learned prayers in an incorrect manner.\nFurthermore, the time spent in each posture has to be balanced. To address\nthese issues, we propose to develop an artificial intelligence assistive\nframework that guides worshippers to evaluate the correctness of the postures\nof their prayers. This paper represents the first step to achieve this\nobjective and addresses the problem of the recognition of the basic gestures of\nIslamic prayer using Convolutional Neural Networks (CNN). The contribution of\nthis paper lies in building a dataset for the basic Salat positions, and train\na YOLOv3 neural network for the recognition of the gestures. Experimental\nresults demonstrate that the mean average precision attains 85% for a training\ndataset of 764 images of the different postures. To the best of our knowledge,\nthis is the first work that addresses human activity recognition of Salat using\ndeep learning.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 06:31:40 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Koubaa", "Anis", ""], ["Ammar", "Adel", ""], ["Benjdira", "Bilel", ""], ["Al-Hadid", "Abdullatif", ""], ["Kawaf", "Belal", ""], ["Al-Yahri", "Saleh Ali", ""], ["Babiker", "Abdelrahman", ""], ["Assaf", "Koutaiba", ""], ["Ras", "Mohannad Ba", ""]]}, {"id": "1911.04435", "submitter": "Joseph Chow", "authors": "Theodoros P. Pantelidis, Joseph Y. J. Chow, Saeid Rasulkhani", "title": "A many-to-many assignment game and stable outcome algorithm to evaluate\n  collaborative Mobility-as-a-Service platforms", "comments": null, "journal-ref": "Transportation Research Part B 104 (2020) 79-100", "doi": "10.1016/j.trb.2020.08.002", "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Mobility as a Service (MaaS) systems become increasingly popular, travel\nis changing from unimodal trips to personalized services offered by a platform\nof mobility operators. Evaluation of MaaS platforms depends on modeling both\nuser route decisions as well as operator service and pricing decisions. We\nadopt a new paradigm for traffic assignment in a MaaS network of multiple\noperators using the concept of stable matching to allocate costs and determine\nprices offered by operators corresponding to user route choices and operator\nservice choices without resorting to nonconvex bilevel programming\nformulations. Unlike our prior work, the proposed model allows travelers to\nmake multimodal, multi-operator trips, resulting in stable cost allocations\nbetween competing network operators to provide MaaS for users. An algorithm is\nproposed to efficiently generate stability conditions for the stable outcome\nmodel. Extensive computational experiments demonstrate the use of the model to\nhandling pricing responses of MaaS operators in technological and capacity\nchanges, government acquisition, consolidation, and firm entry, using the\nclassic Sioux Falls network. The proposed algorithm replicates the same\nstability conditions as explicit path enumeration while taking only 17 seconds\ncompared to explicit path enumeration timing out over 2 hours.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:20:25 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 16:34:36 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 00:37:52 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Pantelidis", "Theodoros P.", ""], ["Chow", "Joseph Y. J.", ""], ["Rasulkhani", "Saeid", ""]]}, {"id": "1911.04536", "submitter": "Fahad Ahmad", "authors": "Aysha Shabbir, Maryam Shabbir, Fahad Ahmad, Muhammad Rizwan", "title": "A New Approach: Cognitive Multi-Level Authentication (CMLA) in Nuclear\n  Command and Control", "comments": "We want to improve this version of research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear monitoring must considered as high precedence against national\nsecurity. Now with the increasing nuclear threats it is crucial to ensure that\nmalicious entity never procure nuclear warheads. Which comprises the prevention\nof illegal or terrorist access to nuclear weapons. The disastrous damage that\ncould be the consequence of unauthorized unapproved utilization of nuclear\nweapon and from the expansion of nuclear technologies to unacceptable states\nhas driven the nuclear forces to spend epic measures of securing nuclear\nwarheads as well as the supporting materials infrastructure and industries. The\nprocedure of ratifying users credentials is known as authentication. Cognitive\nbased authentication is a type of authentication that is actually the\namalgamation of neuron biological and psychological techniques. This research\nis intended to provide human inspired Cognitive Multi-level Authentication\nutilizing the extensive quantum processing capabilities. Simulation is being\ndone on online Q U V I S quantum simulator using quantum cryptography B B 8 4\nalgorithm where the intended person is successfully authenticated while\nconsidering different scenarios. So the proposed scheme will come up with self\nlearning intellect based secure speedy and reliable authentication systems\nagainst nuclear command and control.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 19:39:05 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 21:15:44 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Shabbir", "Aysha", ""], ["Shabbir", "Maryam", ""], ["Ahmad", "Fahad", ""], ["Rizwan", "Muhammad", ""]]}, {"id": "1911.04587", "submitter": "Xintao Wu", "authors": "Depeng Xu, Shuhan Yuan, Xintao Wu", "title": "Achieving Differential Privacy in Vertically Partitioned Multiparty\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preserving differential privacy has been well studied under centralized\nsetting. However, it's very challenging to preserve differential privacy under\nmultiparty setting, especially for the vertically partitioned case. In this\nwork, we propose a new framework for differential privacy preserving multiparty\nlearning in the vertically partitioned setting. Our core idea is based on the\nfunctional mechanism that achieves differential privacy of the released model\nby adding noise to the objective function. We show the server can simply\ndissect the objective function into single-party and cross-party sub-functions,\nand allocate computation and perturbation of their polynomial coefficients to\nlocal parties. Our method needs only one round of noise addition and secure\naggregation. The released model in our framework achieves the same utility as\napplying the functional mechanism in the centralized setting. Evaluation on\nreal-world and synthetic datasets for linear and logistic regressions shows the\neffectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 22:28:07 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Xu", "Depeng", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""]]}, {"id": "1911.04620", "submitter": "Xintao Wu", "authors": "Panpan Zheng, Shuhan Yuan, Xintao Wu, Yubao Wu", "title": "Identifying Hidden Buyers in Darknet Markets via Dirichlet Hawkes\n  Process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The darknet markets are notorious black markets in cyberspace, which involve\nselling or brokering drugs, weapons, stolen credit cards, and other illicit\ngoods. To combat illicit transactions in the cyberspace, it is important to\nanalyze the behaviors of participants in darknet markets. Currently, many\nstudies focus on studying the behavior of vendors. However, there is no much\nwork on analyzing buyers. The key challenge is that the buyers are anonymized\nin darknet markets. For most of the darknet markets, We only observe the first\nand last digits of a buyer's ID, such as ``a**b''. To tackle this challenge, we\npropose a hidden buyer identification model, called UNMIX, which can group the\ntransactions from one hidden buyer into one cluster given a transaction\nsequence from an anonymized ID. UNMIX is able to model the temporal dynamics\ninformation as well as the product, comment, and vendor information associated\nwith each transaction. As a result, the transactions with similar patterns in\nterms of time and content group together as the subsequence from one hidden\nbuyer. Experiments on the data collected from three real-world darknet markets\ndemonstrate the effectiveness of our approach measured by various clustering\nmetrics. Case studies on real transaction sequences explicitly show that our\napproach can group transactions with similar patterns into the same clusters.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 00:17:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Zheng", "Panpan", ""], ["Yuan", "Shuhan", ""], ["Wu", "Xintao", ""], ["Wu", "Yubao", ""]]}, {"id": "1911.04625", "submitter": "Mark A. Matienzo", "authors": "Emily Goodmann, Mark A. Matienzo, Shawn VanCour, William Vanden Dries", "title": "Building the National Radio Recordings Database: A Big Data Approach to\n  Documenting Audio Heritage", "comments": "7 pages; accepted by 4th Computational Archival Science (CAS)\n  workshop, IEEE Big Data 2019", "journal-ref": "2019 IEEE International Conference on Big Data (Big Data), Los\n  Angeles, CA, USA, 2019, pp. 3080-3086", "doi": "10.1109/BigData47090.2019.9006520", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper traces strategies used by the Radio Preservation Task Force of the\nLibrary of Congress's National Recording Preservation Board to develop a\npublicly searchable database documenting extant radio materials held by\ncollecting institutions throughout the country. Having aggregated metadata on\n2,500 unique collections to date, the project has encountered a series of\nlogistical challenges that are not only technical in nature but also\ninstitutional and social, raising critical issues involving organizational\nstructure, political representation, and the ethics of data access. As the\nproject continues to expand and evolve, lessons from its early development\noffer valuable reminders of the human judgment, hidden labor, and interpersonal\nrelations required for successful big data work.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 00:59:54 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Goodmann", "Emily", ""], ["Matienzo", "Mark A.", ""], ["VanCour", "Shawn", ""], ["Dries", "William Vanden", ""]]}, {"id": "1911.04643", "submitter": "Matthew Rueben", "authors": "Matthew Rueben, Frank J. Bernieri, Cindy M. Grimm, William D. Smart", "title": "Framing Effects on Privacy Concerns about a Home Telepresence Robot", "comments": "Revised version was later accepted to the 2017 ACM/IEEE International\n  Conference on Human-Robot Interaction (HRI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy-sensitive robotics is an emerging area of HRI research. Judgments\nabout privacy would seem to be context-dependent, but none of the promising\nwork on contextual \"frames\" has focused on privacy concerns. This work studies\nthe impact of contextual \"frames\" on local users' privacy judgments in a home\ntelepresence setting. Our methodology consists of using an online questionnaire\nto collect responses to animated videos of a telepresence robot after framing\npeople with an introductory paragraph.\n  The results of four studies indicate a large effect of manipulating the robot\noperator's identity between a stranger and a close confidante. It also appears\nthat this framing effect persists throughout several videos. These findings\nserve to caution HRI researchers that a change in frame could cause their\nresults to fail to replicate or generalize. We also recommend that robots be\ndesigned to encourage or discourage certain frames.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 02:56:47 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Rueben", "Matthew", ""], ["Bernieri", "Frank J.", ""], ["Grimm", "Cindy M.", ""], ["Smart", "William D.", ""]]}, {"id": "1911.04929", "submitter": "Boris Ruf", "authors": "Vincent Grari, Boris Ruf, Sylvain Lamprier, Marcin Detyniecki", "title": "Fairness-Aware Neural R\\'eyni Minimization for Continuous Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have seen a dramatic rise of academic and societal\ninterest in fair machine learning. While plenty of fair algorithms have been\nproposed recently to tackle this challenge for discrete variables, only a few\nideas exist for continuous ones. The objective in this paper is to ensure some\nindependence level between the outputs of regression models and any given\ncontinuous sensitive variables. For this purpose, we use the\nHirschfeld-Gebelein-R\\'enyi (HGR) maximal correlation coefficient as a fairness\nmetric. We propose two approaches to minimize the HGR coefficient. First, by\nreducing an upper bound of the HGR with a neural network estimation of the\n$\\chi^{2}$ divergence. Second, by minimizing the HGR directly with an\nadversarial neural network architecture. The idea is to predict the output Y\nwhile minimizing the ability of an adversarial neural network to find the\nestimated transformations which are required to predict the HGR coefficient. We\nempirically assess and compare our approaches and demonstrate significant\nimprovements on previously presented work in the field.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 15:20:29 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Grari", "Vincent", ""], ["Ruf", "Boris", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.05195", "submitter": "Vitaliy Tsyganok", "authors": "Vitaliy Tsyganok, Sergii Kadenko, Oleh Andriichuk", "title": "From Open Source Intelligence to Decision Making: a Hybrid Approach", "comments": "14 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an overview of tools enabling users to utilize data from open\nsources for decision-making support in weakly-structured subject domains.\nPresently, it is impossible to replace expert data with data from open sources\nin the process of decision-making. Although organization of expert sessions\nrequires much time and costs a lot, due to insufficient level of natural\nlanguage processing technology development, we still have to engage experts and\nknowledge engineers in decision-making process. Information, obtained from\nexperts and open sources, is processed, aggregated, and used as basis of\nrecommendations, provided to decision-maker. As an example of a\nweakly-structured domain, we consider information conflicts and operations. For\nthis domain we propose a hybrid decision support methodology, using data\nprovided by both experts and open sources. The methodology is based on\nhierarchic decomposition of the main goal of an information operation. Using\nthe data obtained from experts and open sources, we build the knowledge base of\nsubject domain in the form of a weighted graph. It represents a hierarchy of\nfactors influencing the main goal. Besides intensity, the impact of each factor\nis characterized by delay and duration. With these parameters taken into\naccount, main goal achievement degree is calculated, and changes of target\nparameters of information operation object are monitored. In order to\nillustrate the suggested hybrid approach, we consider a real-life example,\nwhere we detect, monitor, and analyze actions intended to discredit the\nNational academy of sciences of Ukraine. For this purpose, we use specialized\ndecision-making support and content monitoring software.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2019 20:08:11 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Tsyganok", "Vitaliy", ""], ["Kadenko", "Sergii", ""], ["Andriichuk", "Oleh", ""]]}, {"id": "1911.05332", "submitter": "Anqi Liu", "authors": "Anqi Liu, Maya Srikanth, Nicholas Adams-Cohen, R. Michael Alvarez,\n  Anima Anandkumar", "title": "Finding Social Media Trolls: Dynamic Keyword Selection Methods for\n  Rapidly-Evolving Online Debates", "comments": "AI for Social Good workshop at NeurIPS (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online harassment is a significant social problem. Prevention of online\nharassment requires rapid detection of harassing, offensive, and negative\nsocial media posts. In this paper, we propose the use of word embedding models\nto identify offensive and harassing social media messages in two aspects:\ndetecting fast-changing topics for more effective data collection and\nrepresenting word semantics in different domains. We demonstrate with\npreliminary results that using the GloVe (Global Vectors for Word\nRepresentation) model facilitates the discovery of new and relevant keywords to\nuse for data collection and trolling detection. Our paper concludes with a\ndiscussion of a research agenda to further develop and test word embedding\nmodels for identification of social media harassment and trolling.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 07:20:24 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 03:05:41 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Liu", "Anqi", ""], ["Srikanth", "Maya", ""], ["Adams-Cohen", "Nicholas", ""], ["Alvarez", "R. Michael", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1911.05369", "submitter": "Boris Ruf", "authors": "Vincent Grari, Boris Ruf, Sylvain Lamprier, Marcin Detyniecki", "title": "Fair Adversarial Gradient Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair classification has become an important topic in machine learning\nresearch. While most bias mitigation strategies focus on neural networks, we\nnoticed a lack of work on fair classifiers based on decision trees even though\nthey have proven very efficient. In an up-to-date comparison of\nstate-of-the-art classification algorithms in tabular data, tree boosting\noutperforms deep learning. For this reason, we have developed a novel approach\nof adversarial gradient tree boosting. The objective of the algorithm is to\npredict the output $Y$ with gradient tree boosting while minimizing the ability\nof an adversarial neural network to predict the sensitive attribute $S$. The\napproach incorporates at each iteration the gradient of the neural network\ndirectly in the gradient tree boosting. We empirically assess our approach on 4\npopular data sets and compare against state-of-the-art algorithms. The results\nshow that our algorithm achieves a higher accuracy while obtaining the same\nlevel of fairness, as measured using a set of different common fairness\ndefinitions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 09:43:55 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 10:28:37 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Grari", "Vincent", ""], ["Ruf", "Boris", ""], ["Lamprier", "Sylvain", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1911.05391", "submitter": "Jessica Velasco", "authors": "August Thio-ac, Erwin John Domingo, Ricca May Reyes, Nilo Arago, Romeo\n  Jr. Jorda and Jessica Velasco", "title": "Development of a Secure and Private Electronic Procurement System based\n  on Blockchain Implementation", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering (2019) 2626-2631", "doi": "10.30534/ijatcse/2019/115852019", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the development of an online procurement system and the\nintegration of blockchain technology. Various tools such as PHP, JavaScript,\nHTML, CSS, and jQuery were used in designing the graphical, programming logic,\nand blockchain aspect of the system. Every page and function will have their\nrespective construction and result. In addition, the proposed system's flow of\nprocess and the methods on the testing and hosting of the site as well as the\ndifferent web development languages used in every part of the development and\ndesign process were presented. The proposed system was successfully and\nfunctionally developed starting from the execution of procurement proper, to\nthe placement of procured items or goods, and up to the signing of contracts by\nthe winner and the procurer. Lastly, features were added such as user profiles\nof the bidder and procurer.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 10:47:29 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Thio-ac", "August", ""], ["Domingo", "Erwin John", ""], ["Reyes", "Ricca May", ""], ["Arago", "Nilo", ""], ["Jorda", "Romeo Jr.", ""], ["Velasco", "Jessica", ""]]}, {"id": "1911.05395", "submitter": "Christine Bauer", "authors": "Christine Bauer", "title": "Allowing for equal opportunities for artists in music recommendation", "comments": "3 pages, position paper, 1st Workshop on Designing Human-Centric MIR\n  Systems, Delft, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Promoting diversity in the music sector is widely discussed on the media.\nWhile the major problem may lie deep in our society, music information\nretrieval contributes to promoting diversity or may create unequal\nopportunities for artists. For example, considering the known problem of\npopularity bias in music recommendation, it is important to investigate whether\nthe short head of popular music artists and the long tail of less popular ones\nshow similar patterns of diversity---in terms of, for example, age, gender, or\nethnic origin---or the popularity bias amplifies a positive or negative effect.\nI advocate for reasonable opportunities for artists---for (currently) popular\nartists and artists in the long-tail alike---in music recommender systems. In\nthis work, I represent the position that we need to develop a deep\nunderstanding of the biases and inequalities because it is the essential basis\nto design approaches for music recommendation that provide reasonable\nopportunities. Thus, research needs to investigate the various reasons that\nhinder equal opportunity and diversity in music recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 10:58:30 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Bauer", "Christine", ""]]}, {"id": "1911.05399", "submitter": "Jessica Velasco", "authors": "August Thio-ac, Alfred Keanu Serut, Rayn Louise Torrejos, Keenan Dave\n  Rivo and Jessica Velasco", "title": "Blockchain-based System Evaluation: The Effectiveness of Blockchain on\n  E-Procurements", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering (2019) 2673-2676", "doi": "10.30534/ijatcse/2019/122852019", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electronic systems tend to simplify the tedious traditional scheme and\nbasically focuses on the platform design and process organization. The\nintegrity of the output of an automated system is not left behind but the\npossibility of internal manipulation is still high. This paper presents the\ncurrent issues in company procurements and the solution in the form of\nblockchain technology. Several individuals and professionals were asked to\nevaluate a blockchain-based procurement system in comparison to the current\nelectronic (e-procurement) system. A blockchain-based system has the capability\nto hold transactional data with complete decentralization and eliminate the\ngrowing number of fraud cases in companies and organizations. This paper mainly\nfocuses on the effectiveness of a blockchain-based system in company\nprocurements.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:08:42 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Thio-ac", "August", ""], ["Serut", "Alfred Keanu", ""], ["Torrejos", "Rayn Louise", ""], ["Rivo", "Keenan Dave", ""], ["Velasco", "Jessica", ""]]}, {"id": "1911.05464", "submitter": "Riccardo di Clemente", "authors": "Sharon Xu, Riccardo Di Clemente, Marta C. Gonz\\'alez", "title": "Mining urban lifestyles: urban computing, human behavior and recommender\n  systems", "comments": "8 pages, 4 figures", "journal-ref": "Big Data Recommender Systems - Volume 2: Application Paradigms,\n  Chapter 5 Mining urban lifestyles: urban computing, human behavior and\n  recommender systems, pp. 71-81, (Institution of Engineering and Technology\n  2019)", "doi": "10.1049/PBPC035G_ch5", "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, the digital age has sharply redefined the way we study\nhuman behavior. With the advancement of data storage and sensing technologies,\nelectronic records now encompass a diverse spectrum of human activity, ranging\nfrom location data, phone and email communication to Twitter activity and\nopen-source contributions on Wikipedia and OpenStreetMap. In particular, the\nstudy of the shopping and mobility patterns of individual consumers has the\npotential to give deeper insight into the lifestyles and infrastructure of the\nregion. Credit card records (CCRs) provide detailed insight into purchase\nbehavior and have been found to have inherent regularity in consumer shopping\npatterns; call detail records (CDRs) present new opportunities to understand\nhuman mobility, analyze wealth, and model social network dynamics. In this\nchapter, we jointly model the lifestyles of individuals, a more challenging\nproblem with higher variability when compared to the aggregated behavior of\ncity regions. Using collective matrix factorization, we propose a unified dual\nview of lifestyles. Understanding these lifestyles will not only inform\ncommercial opportunities, but also help policymakers and nonprofit\norganizations understand the characteristics and needs of the entire region, as\nwell as of the individuals within that region. The applications of this range\nfrom targeted advertisements and promotions to the diffusion of digital\nfinancial services among low-income groups.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 17:19:39 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Xu", "Sharon", ""], ["Di Clemente", "Riccardo", ""], ["Gonz\u00e1lez", "Marta C.", ""]]}, {"id": "1911.05494", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem, Aibek Musaev, Calton Pu", "title": "Concept Drift Adaptive Physical Event Detection for Social Media Streams", "comments": null, "journal-ref": "Services Congress 2019", "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection has long been the domain of physical sensors operating in a\nstatic dataset assumption. The prevalence of social media and web access has\nled to the emergence of social, or human sensors who report on events globally.\nThis warrants development of event detectors that can take advantage of the\ntruly dense and high spatial and temporal resolution data provided by more than\n3 billion social users. The phenomenon of concept drift, which causes terms and\nsignals associated with a topic to change over time, renders static machine\nlearning ineffective. Towards this end, we present an application for physical\nevent detection on social sensors that improves traditional physical event\ndetection with concept drift adaptation. Our approach continuously updates its\nmachine learning classifiers automatically, without the need for human\nintervention. It integrates data from heterogeneous sources and is designed to\nhandle weak-signal events (landslides, wildfires) with around ten posts per\nevent in addition to large-signal events (hurricanes, earthquakes) with\nhundreds of thousands of posts per event. We demonstrate a landslide detector\non our application that detects almost 350% more land-slides compared to static\napproaches. Our application has high performance: using classifiers trained in\n2014, achieving event detection accuracy of 0.988, compared to 0.762 for static\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 05:15:23 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Suprem", "Abhijit", ""], ["Musaev", "Aibek", ""], ["Pu", "Calton", ""]]}, {"id": "1911.05719", "submitter": "Flavio Cirillo", "authors": "Flavio Cirillo, Detlef Straeten, David Gomez, Jose Gato, Luis Diez,\n  Ignacio Elicegui Maestro, and Reza Akhavan", "title": "Atomic Services: sustainable ecosystem of smart city services through\n  pan-European collaboration", "comments": "2019 IEEE Global Internet-of-Things Summit (GIoTS)", "journal-ref": "2019 Global IoT Summit (GIoTS), Aarhus, Denmark, 2019, pp. 1-7", "doi": "10.1109/GIOTS.2019.8766431", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a world with an ever increasing urbanization, governance is investigating\ninnovative solutions to sustain the society evolution. Internet-of-Things\npromises huge benefits for cities and the proliferation of smart city\ndeployments demonstrates the common acceptance of IoT as basis for many\nsolutions. The city pilots developments occurred in parallel and with different\ndesigns thus creating fragmentation of IoT. The European project SynchroniCity\naims to synchronize 8 smart cities to establish a shared environment fostering\na self-sustained business growth. In this article we present the collaborative\nmethodology and shared efforts spent towards the creation of a common ecosystem\nfor the development of smart city services. Our design evolves around the\nconcept of \"atomic services\" that implements a single functional block to be\ncomposed for full-fledged smart city services. This creates opportunities for\ndiverse stakeholders to participate to a global smart cities market. The\nmethodology and outcome of our efforts will be followed by 10 new cities\nglobally, thus expanding the market range for IoT stakeholders\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 18:17:00 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Cirillo", "Flavio", ""], ["Straeten", "Detlef", ""], ["Gomez", "David", ""], ["Gato", "Jose", ""], ["Diez", "Luis", ""], ["Maestro", "Ignacio Elicegui", ""], ["Akhavan", "Reza", ""]]}, {"id": "1911.05725", "submitter": "Moon Duchin", "authors": "Daryl DeFord, Moon Duchin, Justin Solomon", "title": "Recombination: A family of Markov chains for redistricting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redistricting is the problem of partitioning a set of geographical units into\na fixed number of districts, subject to a list of often-vague rules and\npriorities. In recent years, the use of randomized methods to sample from the\nvast space of districting plans has been gaining traction in courts of law for\nidentifying partisan gerrymanders, and it is now emerging as a possible\nanalytical tool for legislatures and independent commissions. In this paper, we\nset up redistricting as a graph partition problem and introduce a new family of\nMarkov chains called Recombination (or ReCom) on the space of graph partitions.\nThe main point of comparison will be the commonly used Flip walk, which\nrandomly changes the assignment label of a single node at a time. We present\nevidence that ReCom mixes efficiently, especially in contrast to the\nslow-mixing Flip, and provide experiments that demonstrate its qualitative\nbehavior. We demonstrate the advantages of ReCom on real-world data and explain\nboth the challenges of the Markov chain approach and the analytical tools that\nit enables. We close with a short case study involving the Virginia House of\nDelegates.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 23:28:39 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["DeFord", "Daryl", ""], ["Duchin", "Moon", ""], ["Solomon", "Justin", ""]]}, {"id": "1911.05726", "submitter": "Petar Radanliev", "authors": "Petar Radanliev, David De Roure, Kevin Page, Jason Nurse, Rafael\n  Mantilla Montalvo, Omar Santos, La Treall Maddox, Peter Burnap", "title": "Cyber Risk at the Edge: Current and future trends on Cyber Risk\n  Analytics and Artificial Intelligence in the Industrial Internet of Things\n  and Industry 4.0 Supply Chains", "comments": null, "journal-ref": null, "doi": "10.1186/s42400-020-00052-8.", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital technologies have changed the way supply chain operations are\nstructured. In this article, we conduct systematic syntheses of literature on\nthe impact of new technologies on supply chains and the related cyber risks. A\ntaxonomic/cladistic approach is used for the evaluations of progress in the\narea of supply chain integration in the Industrial Internet of Things and\nIndustry 4.0, with a specific focus on the mitigation of cyber risks. An\nanalytical framework is presented, based on a critical assessment with respect\nto issues related to new types of cyber risk and the integration of supply\nchains with new technologies. This paper identifies a dynamic and self-adapting\nsupply chain system supported with Artificial Intelligence and Machine Learning\n(AI/ML) and real-time intelligence for predictive cyber risk analytics. The\nsystem is integrated into a cognition engine that enables predictive cyber risk\nanalytics with real-time intelligence from IoT networks at the edge. This\nenhances capacities and assist in the creation of a comprehensive understanding\nof the opportunities and threats that arise when edge computing nodes are\ndeployed, and when AI/ML technologies are migrated to the periphery of IoT\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 16:04:45 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 22:57:58 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Radanliev", "Petar", ""], ["De Roure", "David", ""], ["Page", "Kevin", ""], ["Nurse", "Jason", ""], ["Montalvo", "Rafael Mantilla", ""], ["Santos", "Omar", ""], ["Maddox", "La Treall", ""], ["Burnap", "Peter", ""]]}, {"id": "1911.05727", "submitter": "Erik Blasch", "authors": "Erik Blasch, James Sung, Tao Nguyen, Chandra P. Daniel, Alisa P. Mason", "title": "Artificial Intelligence Strategies for National Security and Safety\n  Standards", "comments": "Presented at AAAI FSS-19: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence (AI) have lead to an explosion of\nmultimedia applications (e.g., computer vision (CV) and natural language\nprocessing (NLP)) for different domains such as commercial, industrial, and\nintelligence. In particular, the use of AI applications in a national security\nenvironment is often problematic because the opaque nature of the systems leads\nto an inability for a human to understand how the results came about. A\nreliance on 'black boxes' to generate predictions and inform decisions is\npotentially disastrous. This paper explores how the application of standards\nduring each stage of the development of an AI system deployed and used in a\nnational security environment would help enable trust. Specifically, we focus\non the standards outlined in Intelligence Community Directive 203 (Analytic\nStandards) to subject machine outputs to the same rigorous standards as\nanalysis performed by humans.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 12:49:32 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Blasch", "Erik", ""], ["Sung", "James", ""], ["Nguyen", "Tao", ""], ["Daniel", "Chandra P.", ""], ["Mason", "Alisa P.", ""]]}, {"id": "1911.05731", "submitter": "Beno\\^it Otjacques", "authors": "Beno\\^it Otjacques", "title": "Reporting on Decision-Making Algorithms and some Related Ethical\n  Questions", "comments": "62 pages, Final paper presented to obtain the University Certificate\n  in Business Ethics and Compliance Management, Louvain School of Management,\n  Belgium, December 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Companies report on their financial performance for decades. More recently\nthey have also started to report on their environmental impact and their social\nresponsibility. The latest trend is now to deliver one single integrated report\nwhere all stakeholders of the company can easily connect all facets of the\nbusiness with their impact considered in a broad sense. The main purpose of\nthis integrated approach is to avoid delivering data related to disconnected\nsilos, which consequently makes it very difficult to globally assess the\noverall performance of an entity or a business line. In this paper, we focus on\nhow companies report on risks and ethical issues related to the increasing use\nof Artificial Intelligence (AI). We explain some of these risks and potential\nissues. Next, we identify some recent initiatives by various stakeholders to\ndefine a global ethical framework for AI. Finally, we illustrate with four\ncases that companies are very shy to report on these facets of AI.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 08:13:54 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Otjacques", "Beno\u00eet", ""]]}, {"id": "1911.05755", "submitter": "Nicholas Schmidt", "authors": "Nicholas Schmidt and Bryce Stephens", "title": "An Introduction to Artificial Intelligence and Solutions to the Problems\n  of Algorithmic Discrimination", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is substantial evidence that Artificial Intelligence (AI) and Machine\nLearning (ML) algorithms can generate bias against minorities, women, and other\nprotected classes. Federal and state laws have been enacted to protect\nconsumers from discrimination in credit, housing, and employment, where\nregulators and agencies are tasked with enforcing these laws. Additionally,\nthere are laws in place to ensure that consumers understand why they are denied\naccess to services and products, such as consumer loans. In this article, we\nprovide an overview of the potential benefits and risks associated with the use\nof algorithms and data, and focus specifically on fairness. While our\nobservations generalize to many contexts, we focus on the fairness concerns\nraised in consumer credit and the legal requirements of the Equal Credit and\nOpportunity Act. We propose a methodology for evaluating algorithmic fairness\nand minimizing algorithmic bias that aligns with the provisions of federal and\nstate anti-discrimination statutes that outlaw overt, disparate treatment, and,\nspecifically, disparate impact discrimination. We argue that while the use of\nAI and ML algorithms heighten potential discrimination risks, these risks can\nbe evaluated and mitigated, but doing so requires a deep understanding of these\nalgorithms and the contexts and domains in which they are being used.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 22:29:56 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Schmidt", "Nicholas", ""], ["Stephens", "Bryce", ""]]}, {"id": "1911.05798", "submitter": "Sruti Bhagavatula", "authors": "Matius Chairani, Mathieu Chevalley, Abderrahmane Lazraq, Sruti\n  Bhagavatula", "title": "By the user, for the user: A user-centric approach to quantifying the\n  privacy of websites", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-party tracking is common on almost all commercially operated websites.\nPrior work has studied in detail the extent of third-party tracking on the web,\ndetection of third-party trackers, and defending against third-party tracking.\nExisting research and tools have also attempted to inform web users of trackers\nand the extent of their privacy violations. However, existing tools do not take\ninto account users' perceptions of and understanding of the extent of trackers\non the web. Taking these factors into account is important for the usability of\nsuch tools so that users can be aware and protect themselves to a reasonable\nand necessary extent that aligns with their overall comfort with trackers. In\nthis paper, we elicit user perceptions and preferences about different trackers\non various websites through an online survey of 43 users. We use this data to\nbootstrap a privacy scoring system. This scoring system weights the usage of\ntrackers and the dispersion of user data within a page to third parties, with\nthe type of website being visited. Our work presents a proof-of-concept\nmethodology and tool to calculate a user-centric privacy score with preliminary\nbootstrap user data. We conclude with concrete future directions.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 20:17:36 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 15:54:27 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Chairani", "Matius", ""], ["Chevalley", "Mathieu", ""], ["Lazraq", "Abderrahmane", ""], ["Bhagavatula", "Sruti", ""]]}, {"id": "1911.05814", "submitter": "Paolo Magrassi", "authors": "Paolo Magrassi", "title": "Econophysics deserves a revamping", "comments": "arXiv admin note: text overlap with arXiv:1208.5316", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The paper argues that attracting more economists and adopting a more-precise\ndefinition of dynamic complexity might help econophysics acquire more attention\nin the economics community and bring new lymph to economic research. It may be\nnecessary to concentrate less on the applications than on the basics of\neconomic complexity, beginning with expansion and deepening of the study of\nsmall systems with few interacting components, while until thus far complexity\nhas been assumed to be a prerogative of complicated systems only. It is\npossible that without a thorough analysis at that level, the understanding of\nsystems that are at the same time complex and complicated will continue to\nelude economics and econophysics research altogether. To that purpose, the\npaper initiates and frames a definition of dynamic complexity grounded on the\nconcept of non-linear dynamical system.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 10:25:17 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 08:44:09 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Magrassi", "Paolo", ""]]}, {"id": "1911.05825", "submitter": "Benjamin Horne", "authors": "Benjamin D. Horne and Maur\\'icio Gruppi and Sibel Adal{\\i}", "title": "Trustworthy Misinformation Mitigation with Soft Information Nudging", "comments": "Published at IEEE TPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in combating misinformation reports many negative results: facts may\nnot change minds, especially if they come from sources that are not trusted.\nIndividuals can disregard and justify lies told by trusted sources. This\nproblem is made even worse by social recommendation algorithms which help\namplify conspiracy theories and information confirming one's own biases due to\ncompanies' efforts to optimize for clicks and watch time over individuals' own\nvalues and public good. As a result, more nuanced voices and facts are drowned\nout by a continuous erosion of trust in better information sources. Most\nmisinformation mitigation techniques assume that discrediting, filtering, or\ndemoting low veracity information will help news consumers make better\ninformation decisions. However, these negative results indicate that some news\nconsumers, particularly extreme or conspiracy news consumers will not be\nhelped.\n  We argue that, given this background, technology solutions to combating\nmisinformation should not simply seek facts or discredit bad news sources, but\ninstead use more subtle nudges towards better information consumption. Repeated\nexposure to such nudges can help promote trust in better information sources\nand also improve societal outcomes in the long run. In this article, we will\ntalk about technological solutions that can help us in developing such an\napproach, and introduce one such model called Trust Nudging.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 21:49:17 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Horne", "Benjamin D.", ""], ["Gruppi", "Maur\u00edcio", ""], ["Adal\u0131", "Sibel", ""]]}, {"id": "1911.06410", "submitter": "Andrew Dai", "authors": "Kun Zhang, Yuan Xue, Gerardo Flores, Alvin Rajkomar, Claire Cui,\n  Andrew M. Dai", "title": "Modelling EHR timeseries by restricting feature interaction", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data are prevalent in electronic health records, mostly in the\nform of physiological parameters such as vital signs and lab tests. The\npatterns of these values may be significant indicators of patients' clinical\nstates and there might be patterns that are unknown to clinicians but are\nhighly predictive of some outcomes. Many of these values are also missing which\nmakes it difficult to apply existing methods like decision trees. We propose a\nrecurrent neural network model that reduces overfitting to noisy observations\nby limiting interactions between features. We analyze its performance on\nmortality, ICD-9 and AKI prediction from observational values on the Medical\nInformation Mart for Intensive Care III (MIMIC-III) dataset. Our models result\nin an improvement of 1.1% [p<0.01] in AU-ROC for mortality prediction under the\nMetaVision subset and 1.0% and 2.2% [p<0.01] respectively for mortality and AKI\nunder the full MIMIC-III dataset compared to existing state-of-the-art\ninterpolation, embedding and decay-based recurrent models.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 23:06:11 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Zhang", "Kun", ""], ["Xue", "Yuan", ""], ["Flores", "Gerardo", ""], ["Rajkomar", "Alvin", ""], ["Cui", "Claire", ""], ["Dai", "Andrew M.", ""]]}, {"id": "1911.06411", "submitter": "Saloni Dash", "authors": "Saloni Dash, Ritik Dutta, Isabelle Guyon, Adrien Pavao, Andrew Yale,\n  Kristin P. Bennett", "title": "Synthetic Event Time Series Health Data Generation", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic medical data which preserves privacy while maintaining utility can\nbe used as an alternative to real medical data, which has privacy costs and\nresource constraints associated with it. At present, most models focus on\ngenerating cross-sectional health data which is not necessarily representative\nof real data. In reality, medical data is longitudinal in nature, with a single\npatient having multiple health events, non-uniformly distributed throughout\ntheir lifetime. These events are influenced by patient covariates such as\ncomorbidities, age group, gender etc. as well as external temporal effects\n(e.g. flu season). While there exist seminal methods to model time series data,\nit becomes increasingly challenging to extend these methods to medical event\ntime series data. Due to the complexity of the real data, in which each patient\nvisit is an event, we transform the data by using summary statistics to\ncharacterize the events for a fixed set of time intervals, to facilitate\nanalysis and interpretability. We then train a generative adversarial network\nto generate synthetic data. We demonstrate this approach by generating human\nsleep patterns, from a publicly available dataset. We empirically evaluate the\ngenerated data and show close univariate resemblance between synthetic and real\ndata. However, we also demonstrate how stratification by covariates is required\nto gain a deeper understanding of synthetic data quality.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2019 23:11:19 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 18:47:20 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Dash", "Saloni", ""], ["Dutta", "Ritik", ""], ["Guyon", "Isabelle", ""], ["Pavao", "Adrien", ""], ["Yale", "Andrew", ""], ["Bennett", "Kristin P.", ""]]}, {"id": "1911.06569", "submitter": "Eva-Maria Schomakers", "authors": "Eva-Maria Schomakers, Chantal Lidynia, Dirk M\\\"ullmann, Roman Matzutt,\n  Klaus Wehrle, Indra Spiecker gen. D\\\"ohmann, Martina Ziefle", "title": "Putting Privacy into Perspective -- Comparing Technical, Legal, and\n  Users' View of Data Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Web 2.0, social media, cloud computing, and IoT easily connect people around\nthe globe, overcoming time and space barriers, and offering manifold benefits.\nHowever, the technological advances and increased user participation generate\nnovel challenges for protecting users' privacy. From the user perspective, data\ndisclosure depends, in part, on the perceived sensitivity of that data, and\nthus on a risk assessment of data disclosure. But in light of the new\ntechnological opportunities to process and combine data, it is questionable\nwhether users are able to adequately evaluate the risks of data disclosures. As\nmediating authority, data protection laws try to protect user data, granting\nenhanced protection to 'special categories' of data. In this publication, the\nlegal, technological, and user perspectives on data sensitivity are presented\nand compared. From a technological perspective, all data can be referred to as\n'potentially sensitive.' The legal and user perspective on data sensitivity\ndeviate as some data types are granted special protection by the law but are\nnot perceived as very sensitive by the users, and vice versa. Merging the three\nperspectives, the implications for informational self-determination are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 11:25:33 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Schomakers", "Eva-Maria", ""], ["Lidynia", "Chantal", ""], ["M\u00fcllmann", "Dirk", ""], ["Matzutt", "Roman", ""], ["Wehrle", "Klaus", ""], ["D\u00f6hmann", "Indra Spiecker gen.", ""], ["Ziefle", "Martina", ""]]}, {"id": "1911.06606", "submitter": "Markus Schr\\\"oder", "authors": "Julian Klose, Markus Schr\\\"oder, Silke Becker, Ansgar Bernardi, and\n  Arno Ruckelshausen", "title": "Data Preparation in Agriculture Through Automated Semantic Annotation --\n  Basis for a Wide Range of Smart Services", "comments": "Translated version of submission for Gesellschaft f\\\"ur Informatik in\n  der Land-, Forst- und Ern\\\"ahrungswirtschaft (GIL) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern agricultural technology and the increasing digitalisation of such\nprocesses provide a wide range of data. However, their efficient and beneficial\nuse suffers from legitimate concerns about data sovereignty and control, format\ninconsistencies and different interpretations. As a proposed solution, we\npresent Wikinormia, a collaborative platform in which interested participants\ncan describe and discuss their own new data formats. Once a finalized\nvocabulary has been created, specific parsers can semantically process the raw\ndata into three basic representations: spatial information, time series and\nsemantic facts (agricultural knowledge graph). Thanks to publicly accessible\ndefinitions and descriptions, developers can easily gain an overview of the\nconcepts that are relevant to them. A variety of services will then (subject to\nindividual access rights) be able to query their data simply via a query\ninterface and retrieve results. We have already implemented this proposed\nsolution in a prototype in the SDSD (Smart Data - Smart Services) project and\ndemonstrate the benefits with a range of representative services. This provides\nan efficient system for the cooperative, flexible digitalisation of\nagricultural workflows.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 13:19:12 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Klose", "Julian", ""], ["Schr\u00f6der", "Markus", ""], ["Becker", "Silke", ""], ["Bernardi", "Ansgar", ""], ["Ruckelshausen", "Arno", ""]]}, {"id": "1911.06723", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej, Navaporn Surasvadi, Anon Plangprasopchok,\n  and Suttipong Thajchayapong", "title": "A nonparametric framework for inferring orders of categorical data from\n  category-real ordered pairs", "comments": "The R package can be found at https://github.com/DarkEyes/EDOIF", "journal-ref": "Heliyon, Volume 6, Issue 11, 2020, e05435", "doi": "10.1016/j.heliyon.2020.e05435", "report-no": null, "categories": "stat.ME cs.CY math.ST physics.data-an stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a dataset of careers and incomes, how large a difference of income\nbetween any pair of careers would be? Given a dataset of travel time records,\nhow long do we need to spend more when choosing a public transportation mode\n$A$ instead of $B$ to travel? In this paper, we propose a framework that is\nable to infer orders of categories as well as magnitudes of difference of real\nnumbers between each pair of categories using Estimation statistics framework.\nNot only reporting whether an order of categories exists, but our framework\nalso reports the magnitude of difference of each consecutive pairs of\ncategories in the order. In large dataset, our framework is scalable well\ncompared with the existing framework. The proposed framework has been applied\nto two real-world case studies: 1) ordering careers by incomes based on\ninformation of 350,000 households living in Khon Kaen province, Thailand, and\n2) ordering sectors by closing prices based on 1060 companies' closing prices\nof NASDAQ stock markets between years 2000 and 2016. The results of careers\nordering show income inequality among different careers. The stock market\nresults illustrate dynamics of sector domination that can change over time. Our\napproach is able to be applied in any research area that has category-real\nordered pairs. Our proposed \"Dominant-Distribution Network\" provides a novel\napproach to gain new insight of analyzing category orders. The software of this\nframework is available for researchers or practitioners within R package:\nEDOIF.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 16:10:27 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Surasvadi", "Navaporn", ""], ["Plangprasopchok", "Anon", ""], ["Thajchayapong", "Suttipong", ""]]}, {"id": "1911.06812", "submitter": "Ashraf Badawi", "authors": "Ghada El-Hadad, Doaa Shawky, Ashraf Badawi", "title": "Adaptive Learning Guidance System (ALGS)", "comments": "5 pages, Conference Paper, LAK'20 Learning Analytics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This poster presents the conceptual framework of the Adaptive Learning\nGuidance System ALGS. The system aims to propose a model for adaptive learning\nenvironments where two major concerns arising from past studies are being\naddressed; the marginal role of the teacher, and the need for a big data\napproach. Most past studies marginalized the teacher role in adaptive learning\nsystem, particularly the online ones. The most notable quality about ALGS is\nempowering the teacher with the capability of having input in all stages. This\nis where the hybrid recommendation system plays a crucial role in the 3-stage\nALGS architecture. The second issue addressed is the need for big data to\nenhance the system functionality. The more the data collected by the system,\nthe more efficient its adaptation functionality which makes it difficult for a\nfirst-time-run system and (or) a first-time user. Accordingly, collaborative\nfiltering is used at first until adequate data about the user interaction are\ncollected. ALGS architecture consists of a user, content, and 3-stage\nadaptation models.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 13:15:43 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["El-Hadad", "Ghada", ""], ["Shawky", "Doaa", ""], ["Badawi", "Ashraf", ""]]}, {"id": "1911.06893", "submitter": "Ravi Kashyap", "authors": "Ravi Kashyap", "title": "Imitation in the Imitation Game", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.04659,\n  arXiv:1703.08812", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.GT q-fin.GN q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the objectives of automation equipped with non-trivial decision\nmaking, or creating artificial intelligence, in the financial markets and\nprovide a possible alternative. Intelligence might be an unintended consequence\nof curiosity left to roam free, best exemplified by a frolicking infant. For\nthis unintentional yet welcome aftereffect to set in a foundational list of\nguiding principles needs to be present. A consideration of these requirements\nallows us to propose a test of intelligence for trading programs, on the lines\nof the Turing Test, long the benchmark for intelligent machines. We discuss the\napplication of this methodology to the dilemma in finance, which is whether,\nwhen and how much to Buy, Sell or Hold.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2019 05:07:47 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kashyap", "Ravi", ""]]}, {"id": "1911.07199", "submitter": "Quanzhi Li", "authors": "Quanzhi Li, Qiong Zhang, Luo Si, Yingchi Liu", "title": "Rumor Detection on Social Media: Datasets, Methods and Opportunities", "comments": "10 pages", "journal-ref": "EMNLP 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms have been used for information and news gathering, and\nthey are very valuable in many applications. However, they also lead to the\nspreading of rumors and fake news. Many efforts have been taken to detect and\ndebunk rumors on social media by analyzing their content and social context\nusing machine learning techniques. This paper gives an overview of the recent\nstudies in the rumor detection field. It provides a comprehensive list of\ndatasets used for rumor detection, and reviews the important studies based on\nwhat types of information they exploit and the approaches they take. And more\nimportantly, we also present several new directions for future research.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 09:40:24 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Li", "Quanzhi", ""], ["Zhang", "Qiong", ""], ["Si", "Luo", ""], ["Liu", "Yingchi", ""]]}, {"id": "1911.07223", "submitter": "Kiet Nguyen Van", "authors": "Phu X. V. Nguyen, Tham T. T. Hong, Kiet Van Nguyen, Ngan Luu-Thuy\n  Nguyen", "title": "Deep Learning versus Traditional Classifiers on Vietnamese Students'\n  Feedback Corpus", "comments": "In Proceeding of the 5th NAFOSTED Conference on Information and\n  Computer Science (NICS 2018)", "journal-ref": "5th NAFOSTED Conference on Information and Computer Science (NICS\n  2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student's feedback is an important source of collecting students' opinions to\nimprove the quality of training activities. Implementing sentiment analysis\ninto student feedback data, we can determine sentiments polarities which\nexpress all problems in the institution since changes necessary will be applied\nto improve the quality of teaching and learning. This study focused on machine\nlearning and natural language processing techniques (NaiveBayes, Maximum\nEntropy, Long Short-Term Memory, Bi-Directional Long Short-Term Memory) on the\nVietnameseStudents' Feedback Corpus collected from a university. The final\nresults were compared and evaluated to find the most effective model based on\ndifferent evaluation criteria. The experimental results show that the\nBi-Directional LongShort-Term Memory algorithm outperformed than three other\nalgorithms in terms of the F1-score measurement with 92.0% on the sentiment\nclassification task and 89.6% on the topic classification task. In addition, we\ndeveloped a sentiment analysis application analyzing student feedback. The\napplication will help the institution to recognize students' opinions about a\nproblem and identify shortcomings that still exist. With the use of this\napplication, the institution can propose an appropriate method to improve the\nquality of training activities in the future.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 12:32:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Nguyen", "Phu X. V.", ""], ["Hong", "Tham T. T.", ""], ["Van Nguyen", "Kiet", ""], ["Nguyen", "Ngan Luu-Thuy", ""]]}, {"id": "1911.07380", "submitter": "Elif Surer", "authors": "Elif Surer, Mustafa Erkayao\\u{g}lu, Zeynep Nur \\\"Ozt\\\"urk, Furkan\n  Y\\\"ucel, Emin Alp B{\\i}y{\\i}k, Burak Altan, B\\\"u\\c{s}ra \\c{S}enderin, Zeliha\n  O\\u{g}uz, Servet G\\\"urer, H. \\c{S}ebnem D\\\"uzg\\\"un", "title": "Developing a Scenario-Based Video Game Generation Framework: Preliminary\n  Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emergency training and planning provide structured curricula, rule-based\naction items, and interdisciplinary collaborative entities to imitate and teach\nreal-life tasks. This rule-based structure enables the curricula to be\ntransferred into other systematic learning platforms such as serious games\n---games that have additional purposes rather than only entertainment. Serious\ngames aim to educate, cure, and plan several real-life tasks and circumstances\nin an interactive, efficient, and user-friendly way. Although emergency\ntraining includes these highly structured and repetitive action responses, a\ngeneral framework to map the training scenarios' actions, roles, and\ncollaborative structures to game mechanics and game dialogues, is still not\navailable. To address this issue, in this study, a scenario-based game\ngenerator, which maps domain-oriented tasks to game rules and game mechanics,\nwas developed. Also, two serious games (i.e., Hospital game and BioGarden game)\naddressing the training mechanisms of Chemical, Biological, Radiological,\nNuclear, and Explosives (CBRNe) domain, were developed by both the game\ndevelopers and the scenario-based game generator for comparative analysis. The\nresults show that although the game generator uses higher CPU time, memory\nusage, and rendering time, it highly outperforms the game development pipeline\nperformance of the developers. Thus, this study is an initial attempt of a game\ngenerator which bridges the CBRNe practitioners and game developers to\ntransform real-life training scenarios into video games efficiently and\nquickly.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 00:43:06 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Surer", "Elif", ""], ["Erkayao\u011flu", "Mustafa", ""], ["\u00d6zt\u00fcrk", "Zeynep Nur", ""], ["Y\u00fccel", "Furkan", ""], ["B\u0131y\u0131k", "Emin Alp", ""], ["Altan", "Burak", ""], ["\u015eenderin", "B\u00fc\u015fra", ""], ["O\u011fuz", "Zeliha", ""], ["G\u00fcrer", "Servet", ""], ["D\u00fczg\u00fcn", "H. \u015eebnem", ""]]}, {"id": "1911.07585", "submitter": "Valentina Anita Carriero", "authors": "Valentina Anita Carriero and Aldo Gangemi and Maria Letizia Mancinelli\n  and Andrea Giovanni Nuzzolese and Valentina Presutti and Chiara Veninata", "title": "Pattern-based design applied to cultural heritage knowledge graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology Design Patterns (ODPs) have become an established and recognised\npractice for guaranteeing good quality ontology engineering. There are several\nODP repositories where ODPs are shared as well as ontology design methodologies\nrecommending their reuse. Performing rigorous testing is recommended as well\nfor supporting ontology maintenance and validating the resulting resource\nagainst its motivating requirements. Nevertheless, it is less than\nstraightforward to find guidelines on how to apply such methodologies for\ndeveloping domain-specific knowledge graphs. ArCo is the knowledge graph of\nItalian Cultural Heritage and has been developed by using eXtreme Design (XD),\nan ODP- and test-driven methodology. During its development, XD has been\nadapted to the need of the CH domain e.g. gathering requirements from an open,\ndiverse community of consumers, a new ODP has been defined and many have been\nspecialised to address specific CH requirements. This paper presents ArCo and\ndescribes how to apply XD to the development and validation of a CH knowledge\ngraph, also detailing the (intellectual) process implemented for matching the\nencountered modelling problems to ODPs. Relevant contributions also include a\nnovel web tool for supporting unit-testing of knowledge graphs, a rigorous\nevaluation of ArCo, and a discussion of methodological lessons learned during\nArCo development.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 12:33:33 GMT"}, {"version": "v2", "created": "Sat, 20 Jun 2020 08:51:59 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Carriero", "Valentina Anita", ""], ["Gangemi", "Aldo", ""], ["Mancinelli", "Maria Letizia", ""], ["Nuzzolese", "Andrea Giovanni", ""], ["Presutti", "Valentina", ""], ["Veninata", "Chiara", ""]]}, {"id": "1911.07633", "submitter": "Tajul Rosli Razak Mr", "authors": "Iman Hazwam Abd Halim, Nur Muhammad Irfan Abu Hassan, Tajul Rosli\n  Razak, Muhammad Nabil Fikri Jamaluddin, Mohammad Hafiz Ismail", "title": "Reducing Honeypot Log Storage Capacity Consumption -- Cron Job with\n  Perl-Script Approach", "comments": null, "journal-ref": "Journal of Computing Research & Innovation (JCRINN) Vol 4, No 1\n  (2019)", "doi": null, "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Honeypot is a decoy computer system that is used to attract and monitor\nhackers' activities in the network. The honeypot aims to collect information\nfrom the hackers in order to create a more secure system. However, the log file\ngenerated by honeypot can grow very large when heavy traffic occurred in the\nsystem, such as Distributed Denial of Services' (DDoS) attack. The DDoS\npossesses difficulty when it is being processed and analyzed by the network\nadministrator as it required a lot of time and resources. Therefore, in this\npaper, we propose an approach to decrease the log size that is by using a Cron\njob that will run with a Perl-script. This approach parses the collected data\ninto the database periodically to decrease the log size. Three DDoS attack\ncases were conducted in this study to show the increasing of the log size by\nsending a different amount of packet per second for 8 hours in each case. The\nresults have shown that by utilizing the Cron job with Perl-script, the log\nsize has been significantly reduced, the disk space used in the system has also\ndecreased. Consequently, this approach capable of speeding up the process of\nparsing the log file into the database and thus, improving the overall system\nperformance. This study contributes to providing a pathway in reducing honeypot\nlog storage using the Cron job with Perl-Script.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2019 01:58:10 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Halim", "Iman Hazwam Abd", ""], ["Hassan", "Nur Muhammad Irfan Abu", ""], ["Razak", "Tajul Rosli", ""], ["Jamaluddin", "Muhammad Nabil Fikri", ""], ["Ismail", "Mohammad Hafiz", ""]]}, {"id": "1911.07929", "submitter": "Jessica Velasco", "authors": "Jessica Velasco, Cherry Pascion, Jean Wilmar Alberio, Jonathan Apuang,\n  John Stephen Cruz, Mark Angelo Gomez, Benjamin Jr. Molina, Lyndon Tuala,\n  August Thio-ac and Romeo Jr. Jorda", "title": "A Smartphone-Based Skin Disease Classification Using MobileNet CNN", "comments": null, "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering (2019) 2632-2637", "doi": "10.30534/ijatcse/2019/116852019", "report-no": null, "categories": "cs.CV cs.CY cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The MobileNet model was used by applying transfer learning on the 7 skin\ndiseases to create a skin disease classification system on Android application.\nThe proponents gathered a total of 3,406 images and it is considered as\nimbalanced dataset because of the unequal number of images on its classes.\nUsing different sampling method and preprocessing of input data was explored to\nfurther improved the accuracy of the MobileNet. Using under-sampling method and\nthe default preprocessing of input data achieved an 84.28% accuracy. While,\nusing imbalanced dataset and default preprocessing of input data achieved a\n93.6% accuracy. Then, researchers explored oversampling the dataset and the\nmodel attained a 91.8% accuracy. Lastly, by using oversampling technique and\ndata augmentation on preprocessing the input data provide a 94.4% accuracy and\nthis model was deployed on the developed Android application.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2019 11:04:05 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Velasco", "Jessica", ""], ["Pascion", "Cherry", ""], ["Alberio", "Jean Wilmar", ""], ["Apuang", "Jonathan", ""], ["Cruz", "John Stephen", ""], ["Gomez", "Mark Angelo", ""], ["Molina", "Benjamin Jr.", ""], ["Tuala", "Lyndon", ""], ["Thio-ac", "August", ""], ["Jorda", "Romeo Jr.", ""]]}, {"id": "1911.08005", "submitter": "G\\'abor Erd\\'elyi", "authors": "Olivia J. Erd\\'elyi and G\\'abor Erd\\'elyi", "title": "The AI Liability Puzzle and A Fund-Based Work-Around", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certainty around the regulatory environment is crucial to enable responsible\nAI innovation and foster the social acceptance of these powerful new\ntechnologies. One notable source of uncertainty is, however, that the existing\nlegal liability system is inapt to assign responsibility where a potentially\nharmful conduct and/or the harm itself are unforeseeable, yet some\ninstantiations of AI and/or the harms they may trigger are not foreseeable in\nthe legal sense. The unpredictability of how courts would handle such cases\nmakes the risks involved in the investment and use of AI incalculable, creating\nan environment that is not conducive to innovation and may deprive society of\nsome of the benefits AI could provide. To tackle this problem, we propose to\ndraw insights from financial regulatory best-practices and establish a system\nof AI guarantee schemes. We envisage the system to form part of the broader\nmarket-structuring regulatory framework, with the primary function to provide a\nreadily available, clear, and transparent funding mechanism to compensate\nclaims that are either extremely hard or impossible to realize via conventional\nlitigation. We propose it to be at least partially industry-funded, with\nfunding arrangements depending on whether it would pursue other potential\npolicy goals. We aim to engage in a high-level, comparative conceptual debate\naround the suitability of the foreseeability concept to limit legal liability\nrather than confronting the intricacies of the case law of specific\njurisdictions. Recognizing the importance of the latter task, we leave this to\nfurther research in support of the legal system's incremental adaptation to the\nnovel challenges of present and future AI technologies.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 23:45:13 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 04:48:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Erd\u00e9lyi", "Olivia J.", ""], ["Erd\u00e9lyi", "G\u00e1bor", ""]]}, {"id": "1911.08054", "submitter": "Himank Yadav", "authors": "Himank Yadav, Zhengxiao Du, Thorsten Joachims", "title": "Policy-Gradient Training of Fair and Unbiased Ranking Functions", "comments": null, "journal-ref": null, "doi": "10.1145/3404835.3462953", "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While implicit feedback (e.g., clicks, dwell times, etc.) is an abundant and\nattractive source of data for learning to rank, it can produce unfair ranking\npolicies for both exogenous and endogenous reasons. Exogenous reasons typically\nmanifest themselves as biases in the training data, which then get reflected in\nthe learned ranking policy and often lead to rich-get-richer dynamics.\nMoreover, even after the correction of such biases, reasons endogenous to the\ndesign of the learning algorithm can still lead to ranking policies that do not\nallocate exposure among items in a fair way. To address both exogenous and\nendogenous sources of unfairness, we present the first learning-to-rank\napproach that addresses both presentation bias and merit-based fairness of\nexposure simultaneously. Specifically, we define a class of amortized\nfairness-of-exposure constraints that can be chosen based on the needs of an\napplication, and we show how these fairness criteria can be enforced despite\nthe selection biases in implicit feedback data. The key result is an efficient\nand flexible policy-gradient algorithm, called FULTR, which is the first to\nenable the use of counterfactual estimators for both utility estimation and\nfairness constraints. Beyond the theoretical justification of the framework, we\nshow empirically that the proposed algorithm can learn accurate and fair\nranking policies from biased and noisy feedback.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 02:45:42 GMT"}, {"version": "v2", "created": "Sun, 9 May 2021 11:15:39 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yadav", "Himank", ""], ["Du", "Zhengxiao", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1911.08089", "submitter": "Joseph Futoma", "authors": "Mark Sendak, Madeleine Elish, Michael Gao, Joseph Futoma, William\n  Ratliff, Marshall Nichols, Armando Bedoya, Suresh Balu, Cara O'Brien", "title": "\"The Human Body is a Black Box\": Supporting Clinical Decision-Making\n  with Deep Learning", "comments": "To appear at ACM FAT* 2020, Barcelona. Updated to camera-ready\n  version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning technologies are increasingly developed for use in\nhealthcare. While research communities have focused on creating\nstate-of-the-art models, there has been less focus on real world implementation\nand the associated challenges to accuracy, fairness, accountability, and\ntransparency that come from actual, situated use. Serious questions remain\nunder examined regarding how to ethically build models, interpret and explain\nmodel output, recognize and account for biases, and minimize disruptions to\nprofessional expertise and work cultures. We address this gap in the literature\nand provide a detailed case study covering the development, implementation, and\nevaluation of Sepsis Watch, a machine learning-driven tool that assists\nhospital clinicians in the early diagnosis and treatment of sepsis. We, the\nteam that developed and evaluated the tool, discuss our conceptualization of\nthe tool not as a model deployed in the world but instead as a socio-technical\nsystem requiring integration into existing social and professional contexts.\nRather than focusing on model interpretability to ensure a fair and accountable\nmachine learning, we point toward four key values and practices that should be\nconsidered when developing machine learning to support clinical\ndecision-making: rigorously define the problem in context, build relationships\nwith stakeholders, respect professional discretion, and create ongoing feedback\nloops with stakeholders. Our work has significant implications for future\nresearch regarding mechanisms of institutional accountability and\nconsiderations for designing machine learning systems. Our work underscores the\nlimits of model interpretability as a solution to ensure transparency,\naccuracy, and accountability in practice. Instead, our work demonstrates other\nmeans and goals to achieve FATML values in design and in practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 04:28:47 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 03:42:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sendak", "Mark", ""], ["Elish", "Madeleine", ""], ["Gao", "Michael", ""], ["Futoma", "Joseph", ""], ["Ratliff", "William", ""], ["Nichols", "Marshall", ""], ["Bedoya", "Armando", ""], ["Balu", "Suresh", ""], ["O'Brien", "Cara", ""]]}, {"id": "1911.08253", "submitter": "Sophie van der Zee", "authors": "Sophie Van Der Zee, Richard Clayton, and Ross Anderson", "title": "The gift of the gab: Are rental scammers skilled at the art of\n  persuasion?", "comments": "Working paper; correspondence address: Sophie van der Zee,\n  vanderzee@ese.eur.nl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rental scams are a type of advance fee fraud, in which the scammer tries to\nget a victim to pay a deposit to rent an apartment of which the scammer\npretends to be the landlord. We specifically focused on fraudulent long-term\nrentals advertised in the UK on Craigslist. After a victim responds to the\nscammer's advertisement, the scammer attempts to persuade them to transfer\nmoney without having seen the property. We were interested in which persuasion\ntechniques scammers use, and in assessing their skill at the art of persuasion.\nDuring a period of three weeks, we scraped 2112 letting advertisements,\nidentified the fraudulent advertisements and had 44 conversations of around 4\nor 5 emails each with the scammers. Our analysis indicates that Cialdini`s\nmarketing-based social persuasion strategies, such as liking, appeal to\nauthority, and the need for commitment and consistency are extensively\nimplemented by rental scammers. Of Stajano and Wilson's scam-based persuasion\nstrategies, an appeal to sympathy (i.e., kindness) and need for greed were\ncommonly used. We identified two further social persuasion strategies:\nestablishing credibility and removing objections. At a superficial level,\nrental scammers seem skilled at their job, because they mimic genuine landlords\nand use a range of effective persuasion techniques. However, when examining\ntheir emails more closely, we see they often use pre-scripted emails, their\nmimicry is often incompetent, and they have a lack of language skills and\ncultural knowledge that may tip people off. They appear to be the criminal\nequivalent of a boilerhouse sales operation, a modus operandi that has not\npreviously been studied by cybercrime researchers.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 13:27:58 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Van Der Zee", "Sophie", ""], ["Clayton", "Richard", ""], ["Anderson", "Ross", ""]]}, {"id": "1911.08271", "submitter": "Neeraj Bhanot Dr", "authors": "Neeraj Bhanot, Harwinder Singh, Divyansu Sharma, Harshit Jain,\n  Shreyansh Jain", "title": "Python vs. R: A Text Mining Approach for analyzing the Research Trends\n  in Scopus Database", "comments": "This study aims to help researchers by developing a Python based\n  algorithm to analyse research trends using Scopus Database considering large\n  amount of information in different domains as it will help the beginners to\n  get fair enough idea of research being carried out in their fields of\n  interest. A comparison with R has also been done to find as in which platform\n  provides more relevant results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the contemporary world, with the incubation of advanced technologies and\ntremendous outbursts of research works, analyzing big data to incorporate\nresearch strategies becomes more helpful using the tools and techniques\npresented in the current research scenario. This paper indeed tries to tackle\nthe most prominent challenges relating to big data analysis by utilizing a text\nmining approach to analyze research data published in the field of production\nmanagement as a case to begin with. The study has been conducted by considering\nresearch data of International Journal of Production Research (IJPR) indexed in\nScopus between 1961-2017 by dividing the analysis incurred into 3 fragments\nbeing 1961-1990, 1991-2010 and finally 2011-2017 as a case to highlight the\nfocus of journal. This has indeed provided multi-faceted benefits such as\nincreasing the effectiveness of the procured data with well-established\ncomparisons between R and Python Programming along with providing detailed\nresearch trends on the research work incubated. The results of the study\nhighlighted some most prominent topics in the existing IJPR literature such as\nsystem's optimization, supplier selection, process design, etc. providing\nwell-established details relating to ongoing research works. The study also\ncompared both languages suiting to a particular field of study for better\ncomprehension and vastness of the research topics. The current research work is\none of the part of a copyright work with registration number SW-10310/2018\ntitled Program for Analyzing Key Trends in Research Data-set. It has been\ndesigned in Python for carrying out detailed content analysis based on the\navailable research database in bib format as in the current context it has been\napplied for IJPR journal and can be replicated on articles of any domain found\nusing keyword search.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2019 13:53:20 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bhanot", "Neeraj", ""], ["Singh", "Harwinder", ""], ["Sharma", "Divyansu", ""], ["Jain", "Harshit", ""], ["Jain", "Shreyansh", ""]]}, {"id": "1911.08276", "submitter": "Ismet Addoui", "authors": "Ismet Addoui (IRT SystemX), Tarek Chouaki, Ambrogio Delli Colli", "title": "Generating relevant scenarios for intelligent transportation service", "comments": "MATEC Web of Conferences, EDP sciences, In press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses risk assessment issues while conceiving complex systems.\nIndeed, project stakeholders have to share the same problems understanding\nallowing to undertake rational and optimal decisions. We propose an approach\nbased on Natural Language Processing (NLP) techniques to improve systems\nquality requirements such as consistency and completeness. We assess the\nrelevancy of our approaches through experimentations and highlighted feedbacks\nfrom project stakeholders and players.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 13:04:27 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Addoui", "Ismet", "", "IRT SystemX"], ["Chouaki", "Tarek", ""], ["Colli", "Ambrogio Delli", ""]]}, {"id": "1911.08277", "submitter": "Bas R. J. Bolmer", "authors": "Bas R.J. Bolmer, Monique Taverne, Marco Scherer", "title": "Exploring the added value of blockchain technology for the healthcare\n  domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, the University Medical Center Groningen (UMCG) has written\ndown lessons learned on how blockchain technology can have an impact on the\nhealthcare domain. By looking at two use-cases, the hospital challenged several\nteams, participating in an open innovation program and blockchain hackathon, to\nfind a solution that showed the added value of the technology for patient care\nand scientific research. Besides this practical perspective, the report also\nconsiders literature discussing the current state of blockchain technology in\nregard to developments in the healthcare domain (touching on patient\nempowerment, data management, regulations, and interoperability between\nhealthcare systems).\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2019 17:00:00 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Bolmer", "Bas R. J.", ""], ["Taverne", "Monique", ""], ["Scherer", "Marco", ""]]}, {"id": "1911.08278", "submitter": "Thomas Hardjono", "authors": "Thomas Hardjono, George Howard, Eric Scace, Mizan Chowdury, Lucas\n  Novak, Meghan Gaudet, Justin Anderson, Nicole d'avis, Christopher Kulis,\n  Edward Sweeney, Chandler Vaughan", "title": "Towards an Open and Scalable Music Metadata Layer", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One of the significant issues in the music supply chain today is the lack of\nconsistent, complete and authoritative information or metadata regarding the\ncreation of a given musical work. In many cases multiple entities in the music\nsupply chain have each created their own version of the metadata for a musical\nwork, often by manually re-entering the same information or through scraping\ndata from other sites. In such cases, the effort to synchronize or to correct\nthe information becomes manually laborious and error-prone. Furthermore,\nconfidential information regarding the legal ownership of the musical work is\noften commingled in the same metadata, making the entire database proprietary\nand thus closed. In this paper we explore an alternative model for creation\nmetadata following the open access paradigm found in other industries, such as\nin book publishing, library systems and in the automotive parts supply chain.\nThe vision is to create a new music metadata layer for creation metadata that\nis open, scalable and provides an authoritative source of information that is\navailable to all entities in the music supply chain globally.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 02:23:07 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hardjono", "Thomas", ""], ["Howard", "George", ""], ["Scace", "Eric", ""], ["Chowdury", "Mizan", ""], ["Novak", "Lucas", ""], ["Gaudet", "Meghan", ""], ["Anderson", "Justin", ""], ["d'avis", "Nicole", ""], ["Kulis", "Christopher", ""], ["Sweeney", "Edward", ""], ["Vaughan", "Chandler", ""]]}, {"id": "1911.08288", "submitter": "Kyongsik Yun", "authors": "E. Natasha Stavros, Ali Agha, Allen Sirota, Marco Quadrelli, Kamak\n  Ebadi, Kyongsik Yun", "title": "Smoke Sky -- Exploring New Frontiers of Unmanned Aerial Systems for\n  Wildland Fire Science and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wildfire has had increasing impacts on society as the climate changes and the\nwildland urban interface grows. As such, there is a demand for innovative\nsolutions to help manage fire. Managing wildfire can include proactive fire\nmanagement such as prescribed burning within constrained areas or advancements\nfor reactive fire management (e.g., fire suppression). Because of the growing\nsocietal impact, the JPL BlueSky program sought to assess the current state of\nfire management and technology and determine areas with high return on\ninvestment. To accomplish this, we met with the national interagency Unmanned\nAerial System (UAS) Advisory Group (UASAG) and with leading technology transfer\nexperts for fire science and management applications. We provide an overview of\nthe current state as well as an analysis of the impact, maturity and\nfeasibility of integrating different technologies that can be developed by JPL.\nBased on the findings, the highest return on investment technologies for fire\nmanagement are first to develop single micro-aerial vehicle (MAV) autonomy,\nautonomous sensing over fire, and the associated data and information system\nfor active fire local environment mapping. Once this is completed for a single\nMAV, expanding the work to include many in a swarm would require further\ninvestment of distributed MAV autonomy and MAV swarm mechanics, but could\ngreatly expand the breadth of application over large fires. Important to\ninvesting in these technologies will be in developing collaborations with the\nkey influencers and champions for using UAS technology in fire management.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 20:37:19 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Stavros", "E. Natasha", ""], ["Agha", "Ali", ""], ["Sirota", "Allen", ""], ["Quadrelli", "Marco", ""], ["Ebadi", "Kamak", ""], ["Yun", "Kyongsik", ""]]}, {"id": "1911.08289", "submitter": "Waseem Sheikh", "authors": "Waseem Sheikh, Nadeem Sheikh", "title": "A Model-View-ViewModel (MVVM) Application Framework for Hearing\n  Impairment Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Around 466 million people worldwide (over 5% of the world's population) have\ndisabling hearing loss, and out of these 34 million are children. Estimates\nsuggest that by 2050, over 900 million people worldwide will have disabling\nhearing loss. The annual global cost of unaddressed hearing loss amounts to US$\n750 billion. Early detection of hearing loss can reduce its impact on an\nindividual's life in addition to saving a huge cost.\n  This paper presents the design, implementation, and evaluation of an\nopen-source application framework for hearing impairment diagnosis. The\nframework is built using the Model-View-ViewModel (MVVM) pattern which\nseparates the development of graphical user interface (GUI) from the\ndevelopment of business and back-end logic. Some of the benefits of the MVVM\npattern include reusable components, independent development of GUI and\nbusiness or back-end logic, flexibility to modify GUI without having to change\nbusiness or back-end logic, ease of unit testing, and reduced maintenance\noverhead. The proposed framework along with the open-source code makes it\npossible to easily extend the application functionality thus enabling other\nresearchers and practitioners to develop their own versions of hearing loss\ndiagnosis applications. The proposed software was evaluated by an\notolaryngologist and found to be very beneficial in assisting a clinician to\nreach a hearing impairment diagnosis conclusion more methodically, swiftly and\naccurately.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2019 22:20:42 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Sheikh", "Waseem", ""], ["Sheikh", "Nadeem", ""]]}, {"id": "1911.08292", "submitter": "Xintao Wu", "authors": "Wen Huang, Yongkai Wu, Lu Zhang, Xintao Wu", "title": "Fairness through Equality of Effort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fair machine learning is receiving an increasing attention in machine\nlearning fields. Researchers in fair learning have developed correlation or\nassociation-based measures such as demographic disparity, mistreatment\ndisparity, calibration, causal-based measures such as total effect, direct and\nindirect discrimination, and counterfactual fairness, and fairness notions such\nas equality of opportunity and equal odds that consider both decisions in the\ntraining data and decisions made by predictive models. In this paper, we\ndevelop a new causal-based fairness notation, called equality of effort.\nDifferent from existing fairness notions which mainly focus on discovering the\ndisparity of decisions between two groups of individuals, the proposed equality\nof effort notation helps answer questions like to what extend a legitimate\nvariable should change to make a particular individual achieve a certain\noutcome level and addresses the concerns whether the efforts made to achieve\nthe same outcome level for individuals from the protected group and that from\nthe unprotected group are different. We develop algorithms for determining\nwhether an individual or a group of individuals is discriminated in terms of\nequality of effort. We also develop an optimization-based method for removing\ndiscriminatory effects from the data if discrimination is detected. We conduct\nempirical evaluations to compare the equality of effort and existing fairness\nnotion and show the effectiveness of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 18:49:45 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Huang", "Wen", ""], ["Wu", "Yongkai", ""], ["Zhang", "Lu", ""], ["Wu", "Xintao", ""]]}, {"id": "1911.08293", "submitter": "Michael Hind", "authors": "Michael Hind, Stephanie Houde, Jacquelyn Martino, Aleksandra\n  Mojsilovic, David Piorkowski, John Richards, Kush R. Varshney", "title": "Experiences with Improving the Transparency of AI Models and Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI models and services are used in a growing number of highstakes areas,\nresulting in a need for increased transparency. Consistent with this, several\nproposals for higher quality and more consistent documentation of AI data,\nmodels, and systems have emerged. Little is known, however, about the needs of\nthose who would produce or consume these new forms of documentation. Through\nsemi-structured developer interviews, and two document creation exercises, we\nhave assembled a clearer picture of these needs and the various challenges\nfaced in creating accurate and useful AI documentation. Based on the\nobservations from this work, supplemented by feedback received during multiple\ndesign explorations and stakeholder conversations, we make recommendations for\neasing the collection and flexible presentation of AI facts to promote\ntransparency.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:30:58 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Hind", "Michael", ""], ["Houde", "Stephanie", ""], ["Martino", "Jacquelyn", ""], ["Mojsilovic", "Aleksandra", ""], ["Piorkowski", "David", ""], ["Richards", "John", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1911.08315", "submitter": "Christos Diou", "authors": "Christos Diou, Ioannis Sarafis, Vasileios Papapanagiotou, Ioannis\n  Ioakimidis and Anastasios Delopoulos", "title": "A Methodology for Obtaining Objective Measurements of Population\n  Obesogenic Behaviors in Relation to the Environment", "comments": "This paper has been accepted for publication at the Statistical\n  Journal of the International Association for Official Statistics,\n  https://content.iospress.com/journals/statistical-journal-of-the-iaos", "journal-ref": null, "doi": "10.3233/SJI-190537", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The way we eat and what we eat, the way we move and the way we sleep\nsignificantly impact the risk of becoming obese. These aspects of behavior\ndecompose into several personal behavioral elements including our food choices,\neating place preferences, transportation choices, sleeping periods and duration\netc. Most of these elements are highly correlated in a causal way with the\nconditions of our local urban, social, regulatory and economic environment. To\nthis end, the H2020 project \"BigO: Big Data Against Childhood Obesity\"\n(http://bigoprogram.eu) aims to create new sources of evidence together with\nexploration tools, assisting the Public Health Authorities in their effort to\ntackle childhood obesity. In this paper, we present the technology-based\nmethodology that has been developed in the context of BigO in order to: (a)\nobjectively monitor a matrix of a population's obesogenic behavioral elements\nusing commonly available wearable sensors (accelerometers, gyroscopes, GPS),\nembedded in smart phones and smart watches; (b) acquire information for the\nenvironment from open and online data sources; (c) provide aggregation\nmechanisms to correlate the population behaviors with the environmental\ncharacteristics; (d) ensure the privacy protection of the participating\nindividuals; and (e) quantify the quality of the collected big data.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2019 09:25:53 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Diou", "Christos", ""], ["Sarafis", "Ioannis", ""], ["Papapanagiotou", "Vasileios", ""], ["Ioakimidis", "Ioannis", ""], ["Delopoulos", "Anastasios", ""]]}, {"id": "1911.08354", "submitter": "Sorelle Friedler", "authors": "Kadan Lottick, Silvia Susai, Sorelle A. Friedler, and Jonathan P.\n  Wilson", "title": "Energy Usage Reports: Environmental awareness as part of algorithmic\n  accountability", "comments": "Workshop on Tackling Climate Change with Machine Learning at NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The carbon footprint of algorithms must be measured and transparently\nreported so computer scientists can take an honest and active role in\nenvironmental sustainability. In this paper, we take analyses usually applied\nat the industrial level and make them accessible for individual computer\nscience researchers with an easy-to-use Python package. Localizing to the\nenergy mixture of the electrical power grid, we make the conversion from energy\nusage to CO2 emissions, in addition to contextualizing these results with more\nhuman-understandable benchmarks such as automobile miles driven. We also\ninclude comparisons with energy mixtures employed in electrical grids around\nthe world. We propose including these automatically-generated Energy Usage\nReports as part of standard algorithmic accountability practices, and\ndemonstrate the use of these reports as part of model-choice in a machine\nlearning context.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 15:34:28 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 17:48:35 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Lottick", "Kadan", ""], ["Susai", "Silvia", ""], ["Friedler", "Sorelle A.", ""], ["Wilson", "Jonathan P.", ""]]}, {"id": "1911.08516", "submitter": "Shahid Alam", "authors": "Shahid Alam, Abdulaziz Ravshanbekov", "title": "Sieving Fake News From Genuine: A Synopsis", "comments": "Published in the Proceedings of the International Conference on All\n  Aspects of Cyber Security 2019, pp: 67-71", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the rise of social media, it has become easier to disseminate fake news\nfaster and cheaper, compared to traditional news media, such as television and\nnewspapers. Recently this phenomenon has attracted lot of public attention,\nbecause it is causing significant social and financial impacts on their lives\nand businesses. Fake news are responsible for creating false, deceptive,\nmisleading, and suspicious information that can greatly effect the outcome of\nan event. This paper presents a synopsis that explains what are fake news with\nexamples and also discusses some of the current machine learning techniques,\nspecifically natural language processing (NLP) and deep learning, for\nautomatically predicting and detecting fake news. Based on this synopsis, we\nrecommend that there is a potential of using NLP and deep learning to improve\nautomatic detection of fake news, but with the right set of data and features.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 19:24:07 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Alam", "Shahid", ""], ["Ravshanbekov", "Abdulaziz", ""]]}, {"id": "1911.08565", "submitter": "Simone Raponi", "authors": "Simone Raponi, Roberto Di Pietro", "title": "A Longitudinal Study on Web-sites Password Management (in)Security:\n  Evidence and Remedies", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.07016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-factor password-based authentication is generally the norm to access\non-line Web-sites. While single-factor authentication is well known to be a\nweak form of authentication, a further concern arises when considering the\npossibility for an attacker to recover the user passwords by leveraging the\nloopholes in the password recovery mechanisms. Indeed, the adoption by a\nWeb-site of a poor password management system makes useless even the most\nrobust password chosen by the registered users. In this paper, building on the\nresults of our previous work, we study the possible attacks to on-line password\nrecovery systems analyzing the mechanisms implemented by some of the most\npopular Web-sites. In detail, we provide several contributions: (i) we revise\nand detail the attacker model; (ii) we provide an updated analysis with respect\nto a preliminary study we carried out in December 2017; (iii) we perform a\nbrand new analysis of the current top 200 Alexa's Web-sites of five major EU\ncountries; and, (iv) we propose \\sol, a working open-source module that could\nbe adopted by any Web-site to provide registered users with a password recovery\nmechanism to prevent mail service provider-level attacks. Overall, it is\nstriking to notice how the analyzed Web-sites have made little (if any) effort\nto become compliant with the GDPR regulation, showing that the objective to\nhave basic user protection mechanisms in place---despite the fines threatened\nby GDPR---is still far, mainly because of sub-standard security management\npractices. Finally, it is worth noting that while this study has been focused\non EU registered Web-sites, the proposed solution has, instead, general\napplicability.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2019 13:54:03 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 07:36:36 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Raponi", "Simone", ""], ["Di Pietro", "Roberto", ""]]}, {"id": "1911.08603", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff", "title": "Forbidden knowledge in machine learning -- Reflections on the limits of\n  research and publication", "comments": null, "journal-ref": null, "doi": "10.1007/s00146-020-01045-4", "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain research strands can yield \"forbidden knowledge\". This term refers to\nknowledge that is considered too sensitive, dangerous or taboo to be produced\nor shared. Discourses about such publication restrictions are already\nentrenched in scientific fields like IT security, synthetic biology or nuclear\nphysics research. This paper makes the case for transferring this discourse to\nmachine learning research. Some machine learning applications can very easily\nbe misused and unfold harmful consequences, for instance with regard to\ngenerative video or text synthesis, personality analysis, behavior\nmanipulation, software vulnerability detection and the like. Up to now, the\nmachine learning research community embraces the idea of open access. However,\nthis is opposed to precautionary efforts to prevent the malicious use of\nmachine learning applications. Information about or from such applications may,\nif improperly disclosed, cause harm to people, organizations or whole\nsocieties. Hence, the goal of this work is to outline norms that can help to\ndecide whether and when the dissemination of such information should be\nprevented. It proposes review parameters for the machine learning community to\nestablish an ethical framework on how to deal with forbidden knowledge and\ndual-use applications.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 21:43:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Hagendorff", "Thilo", ""]]}, {"id": "1911.08842", "submitter": "Sanket Shah", "authors": "Sanket Shah, Meghna Lowalekar, Pradeep Varakantham", "title": "Neural Approximate Dynamic Programming for On-Demand Ride-Pooling", "comments": "Accepted for publication to the Thirty-Fourth AAAI Conference on\n  Artificial Intelligence (AAAI-20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-demand ride-pooling (e.g., UberPool) has recently become popular because\nof its ability to lower costs for passengers while simultaneously increasing\nrevenue for drivers and aggregation companies. Unlike in Taxi on Demand (ToD)\nservices -- where a vehicle is only assigned one passenger at a time -- in\non-demand ride-pooling, each (possibly partially filled) vehicle can be\nassigned a group of passenger requests with multiple different origin and\ndestination pairs. To ensure near real-time response, existing solutions to the\nreal-time ride-pooling problem are myopic in that they optimise the objective\n(e.g., maximise the number of passengers served) for the current time step\nwithout considering its effect on future assignments. This is because even a\nmyopic assignment in ride-pooling involves considering what combinations of\npassenger requests that can be assigned to vehicles, which adds a layer of\ncombinatorial complexity to the ToD problem.\n  A popular approach that addresses the limitations of myopic assignments in\nToD problems is Approximate Dynamic Programming (ADP). Existing ADP methods for\nToD can only handle Linear Program (LP) based assignments, however, while the\nassignment problem in ride-pooling requires an Integer Linear Program (ILP)\nwith bad LP relaxations. To this end, our key technical contribution is in\nproviding a general ADP method that can learn from ILP-based assignments.\nAdditionally, we handle the extra combinatorial complexity from combinations of\npassenger requests by using a Neural Network based approximate value function\nand show a connection to Deep Reinforcement Learning that allows us to learn\nthis value-function with increased stability and sample-efficiency. We show\nthat our approach outperforms past approaches on a real-world dataset by up to\n16%, a significant improvement in city-scale transportation problems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 11:52:00 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Shah", "Sanket", ""], ["Lowalekar", "Meghna", ""], ["Varakantham", "Pradeep", ""]]}, {"id": "1911.08940", "submitter": "Harun Siljak", "authors": "Mehrija Hasicic and Harun Siljak", "title": "Putting the SC in SCORE: Solar Car Optimized Route Estimation and Smart\n  Cities", "comments": "Book chapter accepted for publication in \"Modeling and Optimization\n  in Green Logistics\", Springer, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar exposure of streets and parking spaces in dense urban areas varies\nsignificantly due to the infrastructure: buildings, parks, tunnels, multistorey\ncar parks. This variability leaves space for both real-time and offline route\nand parking optimization for solar-powered vehicles. In this chapter we present\nSolar Car Optimized Route Estimation (SCORE), our optimization system based on\nhistoric and current solar radiance measurements. In addition to the\ncomprehensive review of SCORE, we offer a new perspective on it by embedding it\nin the bigger picture of smart cities (SC): we analyze SCORE's relationship\nwith the smart power generation and distribution systems (smart grid), novel\ntransportation paradigms and communication advancements. While the previous\nwork on SCORE was focused on technical challenges which are described in the\nfirst part of this chapter (optimization, communication, sensor data collection\nand fusion), here we proceed with a systemic approach and observe a\nSCORE-equipped unit in the near-future society, examine the sustainability of\nthe model and possible business models based on it. We consider the problem of\nvehicle routing and congestion avoidance using incentives for users on\nnon-critical journeys and co-existence of SCORE and non-SCORE using vehicles.\nRealistic pointers for SCORE-aware design of infrastructure are also given,\nboth for improved data collection and improved solar exposure while considering\ntrade-offs for non-SCORE users.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 14:46:20 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Hasicic", "Mehrija", ""], ["Siljak", "Harun", ""]]}, {"id": "1911.09005", "submitter": "Thomas Gilbert", "authors": "Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz", "title": "Hard Choices in Artificial Intelligence: Addressing Normative\n  Uncertainty through Sociotechnical Commitments", "comments": "To be presented at the AI for Social Good workshop at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI systems become prevalent in high stakes domains such as surveillance\nand healthcare, researchers now examine how to design and implement them in a\nsafe manner. However, the potential harms caused by systems to stakeholders in\ncomplex social contexts and how to address these remains unclear. In this\npaper, we explain the inherent normative uncertainty in debates about the\nsafety of AI systems. We then address this as a problem of vagueness by\nexamining its place in the design, training, and deployment stages of AI system\ndevelopment. We adopt Ruth Chang's theory of intuitive comparability to\nillustrate the dilemmas that manifest at each stage. We then discuss how\nstakeholders can navigate these dilemmas by incorporating distinct forms of\ndissent into the development pipeline, drawing on Elizabeth Anderson's work on\nthe epistemic powers of democratic institutions. We outline a framework of\nsociotechnical commitments to formal, substantive and discursive challenges\nthat address normative uncertainty across stakeholders, and propose the\ncultivation of related virtues by those responsible for development.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 16:21:12 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Dobbe", "Roel", ""], ["Gilbert", "Thomas Krendl", ""], ["Mintz", "Yonatan", ""]]}, {"id": "1911.09091", "submitter": "Oliver Karras", "authors": "Oliver Karras, Jil Kl\\\"under, Kurt Schneider", "title": "Tool-Supported Experiments for Continuously Collecting Data of\n  Subjective Video Quality Assessments During Video Playback", "comments": "2 pages, Fachgruppentreffen Requirements Engineering, GI\n  Softwaretechnik-Trends", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adequate use of documentation for communication is one challenge in\nrequirements engineering (RE). In recent years, several researchers addressed\nthis challenge by using videos as a communication mechanism. All of them\nconcluded that this way of using videos has the potential to facilitate\nrequirements communication. Nevertheless, software professionals are not\ndirectors and thus do not necessarily know what constitutes a good video. This\nlack of knowledge is one crucial reason why videos are still not an established\ncommunication mechanism in RE. When videos shall be established in the RE\nactivities, practices, and techniques, requirements engineers have to acquire\nthe necessary knowledge to produce and use good videos on their own at moderate\ncosts, yet sufficient quality. In our research project ViViReq (see\nAcknowledgment), we aspire to bridge this knowledge gap about what constitutes\na good video. Whether a video is good or not depends on its quality perceived\nby its viewers. However, video quality is a rather ill-defined concept due to\nnumerous unspecified technical and subjective characteristics. As part of our\nresearch plan, we develop a quality model for videos inspired by the idea of\nFemmer and Vogelsang to define and evaluate the quality of videos as RE\nartifacts. In addition to evaluating videos, this quality model can be used to\nidentify the relevant characteristics of videos for their specific purpose\nwhich can be further used to specify requirements, their criteria for\nsatisfaction, and corresponding measures. Therefore, software professionals may\nuse the quality model as guidance for producing and using videos.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 18:59:55 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 07:47:43 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Karras", "Oliver", ""], ["Kl\u00fcnder", "Jil", ""], ["Schneider", "Kurt", ""]]}, {"id": "1911.09156", "submitter": "Javier S\\'anchez-Monedero", "authors": "Javier S\\'anchez-Monedero and Lina Dencik", "title": "The politics of deceptive borders: 'biomarkers of deceit' and the case\n  of iBorderCtrl", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper critically examines a recently developed proposal for a border\ncontrol system called iBorderCtrl, designed to detect deception based on facial\nrecognition technology and the measurement of micro-expressions, termed\n'biomarkers of deceit'. Funded under the European Commission's Horizon 2020\nprogramme, we situate our analysis in the wider political economy of 'emotional\nAI' and the history of deception detection technologies. We then move on to\ninterrogate the design of iBorderCtrl using publicly available documents and\nassess the assumptions and scientific validation underpinning the project\ndesign. Finally, drawing on a Bayesian analysis we outline statistical\nfallacies in the foundational premise of mass screening and argue that it is\nvery unlikely that the model that iBorderCtrl provides for deception detection\nwould work in practice. By interrogating actual systems in this way, we argue\nthat we can begin to question the very premise of the development of\ndata-driven systems, and emotional AI and deception detection in particular,\npushing back on the assumption that these systems are fulfilling the tasks they\nclaim to be attending to and instead ask what function such projects carry out\nin the creation of subjects and management of populations. This function is not\nmerely technical but, rather, we argue, distinctly political and forms part of\na mode of governance increasingly shaping life opportunities and fundamental\nrights.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 20:17:11 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 20:22:23 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 12:48:18 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 12:18:36 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["S\u00e1nchez-Monedero", "Javier", ""], ["Dencik", "Lina", ""]]}, {"id": "1911.09179", "submitter": "Kaicheng Yang", "authors": "Kai-Cheng Yang, Onur Varol, Pik-Mai Hui, Filippo Menczer", "title": "Scalable and Generalizable Social Bot Detection through Data Selection", "comments": "AAAI 2020", "journal-ref": null, "doi": "10.1609/aaai.v34i01.5460", "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and reliable social bot classification is crucial for detecting\ninformation manipulation on social media. Despite rapid development,\nstate-of-the-art bot detection models still face generalization and scalability\nchallenges, which greatly limit their applications. In this paper we propose a\nframework that uses minimal account metadata, enabling efficient analysis that\nscales up to handle the full stream of public tweets of Twitter in real time.\nTo ensure model accuracy, we build a rich collection of labeled datasets for\ntraining and validation. We deploy a strict validation system so that model\nperformance on unseen datasets is also optimized, in addition to traditional\ncross-validation. We find that strategically selecting a subset of training\ndata yields better model accuracy and generalization than exhaustively training\non all available data. Thanks to the simplicity of the proposed model, its\nlogic can be interpreted to provide insights into social bot characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 21:31:36 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Yang", "Kai-Cheng", ""], ["Varol", "Onur", ""], ["Hui", "Pik-Mai", ""], ["Menczer", "Filippo", ""]]}, {"id": "1911.09242", "submitter": "Son Doan <", "authors": "Son Doan, Amanda Ritchart, Nicholas Perry, Juan D Chaparro, Mike\n  Conway", "title": "How Do You #relax When You're #stressed? A Content Analysis and\n  Infodemiology Study of Stress-Related Tweets", "comments": "38 pages,12 figures, 6 tables, 5 Appendix (full version) -- shorter\n  version published in JMIR Public Health Surveill 2017;3(2):e35", "journal-ref": "JMIR Public Health Surveill 2017;3(2):e35", "doi": "10.2196/publichealth.5939", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Stress is a contributing factor to many major health problems in\nthe United States, such as heart disease, depression, and autoimmune diseases.\nRelaxation is often recommended in mental health treatment as a frontline\nstrategy to reduce stress, thereby improving health conditions.\n  Objective: The objective of our study was to understand how people express\ntheir feelings of stress and relaxation through Twitter messages.\n  Methods: We first performed a qualitative content analysis of 1326 and 781\ntweets containing the keywords \"stress\" and \"relax\", respectively. We then\ninvestigated the use of machine learning algorithms to automatically classify\ntweets as stress versus non stress and relaxation versus non relaxation.\nFinally, we applied these classifiers to sample datasets drawn from 4 cities\nwith the goal of evaluating the extent of any correlation between our automatic\nclassification of tweets and results from public stress surveys.\n  Results: Content analysis showed that the most frequent topic of stress\ntweets was education, followed by work and social relationships. The most\nfrequent topic of relaxation tweets was rest and vacation, followed by nature\nand water. When we applied the classifiers to the cities dataset, the\nproportion of stress tweets in New York and San Diego was substantially higher\nthan that in Los Angeles and San Francisco.\n  Conclusions: This content analysis and infodemiology study revealed that\nTwitter, when used in conjunction with natural language processing techniques,\nis a useful data source for understanding stress and stress management\nstrategies, and can potentially supplement infrequently collected survey-based\nstress data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 02:08:14 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 19:06:20 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Doan", "Son", ""], ["Ritchart", "Amanda", ""], ["Perry", "Nicholas", ""], ["Chaparro", "Juan D", ""], ["Conway", "Mike", ""]]}, {"id": "1911.09386", "submitter": "Jana Korunovska", "authors": "Jana Korunovska, Bernadette Kamleitner and Sarah Spiekermann", "title": "The Power and Pitfalls of Transparent Privacy Policies in Social\n  Networking Service Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Users disclose ever-increasing amounts of personal data on Social Network\nService platforms (SNS). Unless SNSs' policies are privacy friendly, this\nleaves them vulnerable to privacy risks because they ignore the privacy\npolicies. Designers and regulators have pushed for shorter, simpler and more\nprominent privacy policies, however the evidence that transparent policies\nincrease informed consent is lacking. To answer this question, we conducted an\nonline experiment with 214 regular Facebook users asked to join a fictitious\nSNS. We experimentally manipulated the privacy-friendliness of SNS's policy and\nvaried threats of secondary data use and data visibility. Half of our\nparticipants incorrectly recalled even the most formally \"perfect\" and\neasy-to-read privacy policies. Mostly, users recalled policies as more privacy\nfriendly than they were. Moreover, participants self-censored their disclosures\nwhen aware that visibility threats were present, but were less sensitive to\nthreats of secondary data use. We present design recommendations to increase\ninformed consent.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 10:24:12 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 10:55:42 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Korunovska", "Jana", ""], ["Kamleitner", "Bernadette", ""], ["Spiekermann", "Sarah", ""]]}, {"id": "1911.09536", "submitter": "Abeer ElBahrawy", "authors": "Abeer ElBahrawy, Laura Alessandretti, Leonid Rusnac, Daniel Goldsmith,\n  Alexander Teytelboym, Andrea Baronchelli", "title": "Collective Dynamics of Dark Web Marketplaces", "comments": null, "journal-ref": "Sci Rep 10, 18827 (2020)", "doi": "10.1038/s41598-020-74416-y", "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dark markets are commercial websites that use Bitcoin to sell or broker\ntransactions involving drugs, weapons, and other illicit goods. Being illegal,\nthey do not offer any user protection, and several police raids and scams have\ncaused large losses to both customers and vendors over the past years. However,\nthis uncertainty has not prevented a steady growth of the dark market\nphenomenon and a proliferation of new markets. The origin of this resilience\nhave remained unclear so far, also due to the difficulty of identifying\nrelevant Bitcoin transaction data. Here, we investigate how the dark market\necosystem re-organises following the disappearance of a market, due to factors\nincluding raids and scams. To do so, we analyse 24 episodes of unexpected\nmarket closure through a novel datasets of 133 million Bitcoin transactions\ninvolving 31 dark markets and their users, totalling 4 billion USD. We show\nthat coordinated user migration from the closed market to coexisting markets\nguarantees overall systemic resilience beyond the intrinsic fragility of\nindividual markets. The migration is swift, efficient and common to all market\nclosures. We find that migrants are on average more active users in comparison\nto non-migrants and move preferentially towards the coexisting market with the\nhighest trading volume. Our findings shed light on the resilience of the dark\nmarket ecosystem and we anticipate that they may inform future research on the\nself-organisation of emerging online markets.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 15:21:54 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 18:27:12 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["ElBahrawy", "Abeer", ""], ["Alessandretti", "Laura", ""], ["Rusnac", "Leonid", ""], ["Goldsmith", "Daniel", ""], ["Teytelboym", "Alexander", ""], ["Baronchelli", "Andrea", ""]]}, {"id": "1911.09575", "submitter": "Anca Jurcut Dr.", "authors": "Guerrino Mazzarolo, Anca Delia Jurcut", "title": "Insider threats in Cyber Security: The enemy within the gates", "comments": null, "journal-ref": "EUROPEAN CYBERSECURITY JOURNAL, February 2020", "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insider threats have become reality for civilian firms such as Tesla, which\nexperienced sabotage and intellectual property theft, and Capital One, which\nsuffered from fraud. Even greater social impact was caused by the data breach\nat the US Department of Defense, perpetrated by well-known attackers Chelsea\nManning and Edward Snowden, whose espionage and hacktivist activities are\nwidely known. The dramatic increase of such incidents in recent years and the\nincalculable damage committed by insiders must serve as a warning for all\nmembers of the cyber security community. It is no longer acceptable to continue\nto underestimate the problem of insider threats. Firms, organizations,\ninstitutions and governments need to lead and embrace a cultural change in\ntheir security posture. Through the adoption of an Insider Threat Program that\nengages all the strategic branches (including HR, Legal, Information Assurance,\nCyber Security and Intelligence), coordinated by the chief information security\nofficer and supported by c-level executive, it is possible to implement a\nframework that can prevent, detect, and respond to disloyal and/or\nunintentional insider threats. Hence, defending your enterprise from insider\nthreats is a vital part of information security best practices. It is essential\nthat your company highly valuable classified data and assets are protected from\nits greatest threat: the enemy within the gates.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 16:09:21 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Mazzarolo", "Guerrino", ""], ["Jurcut", "Anca Delia", ""]]}, {"id": "1911.09735", "submitter": "Son Doan <", "authors": "Son Doan, Quoc-Hung Ngo, Ai Kawazoe, Nigel Collier", "title": "Global Health Monitor: A Web-based System for Detecting and Mapping\n  Infectious Diseases", "comments": "6 pages, 3 figures, Proc. of IJCNLP 2008", "journal-ref": "Proc. of the International Joint Conference on Natural Language\n  Processing (IJCNLP) 2008, pages 951-956", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Global Health Monitor, an online Web-based system for\ndetecting and mapping infectious disease outbreaks that appear in news stories.\nThe system analyzes English news stories from news feed providers, classifies\nthem for topical relevance and plots them onto a Google map using geo-coding\ninformation, helping public health workers to monitor the spread of diseases in\na geo-temporal context. The background knowledge for the system is contained in\nthe BioCaster ontology (BCO) (Collier et al., 2007a) which includes both\ninformation on infectious diseases as well as geographical locations with their\nlatitudes/longitudes. The system consists of four main stages: topic\nclassification, named entity recognition (NER), disease/location detection and\nvisualization. Evaluation of the system shows that it achieved high accuracy on\na gold standard corpus. The system is now in practical use. Running on a\nclustercomputer, it monitors more than 1500 news feeds 24/7, updating the map\nevery hour.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 20:26:29 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Doan", "Son", ""], ["Ngo", "Quoc-Hung", ""], ["Kawazoe", "Ai", ""], ["Collier", "Nigel", ""]]}, {"id": "1911.09763", "submitter": "Arash Shaban-Nejad", "authors": "Nii Antiaye Addy, Arash Shaban-Nejad, David L. Buckeridge, Laurette\n  Dub\\'e", "title": "An Innovative Approach to Addressing Childhood Obesity: A\n  Knowledge-Based Infrastructure for Supporting Multi-Stakeholder Partnership\n  Decision-Making in Quebec, Canada", "comments": null, "journal-ref": "Int J Environ Res Public Health. 2015 Jan 23;12(2):1314-33", "doi": "10.3390/ijerph120201314", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The purpose of this paper is to describe and analyze the development of a\nknowledge-based infrastructure to support MSP decision-making processes. The\npaper emerged from a study to define specifications for a knowledge-based\ninfrastructure to provide decision support for community-level MSPs in the\nCanadian province of Quebec. As part of the study, a process assessment was\nconducted to understand the needs of communities as they collect, organize, and\nanalyze data to make decisions about their priorities. The result of this\nprocess is a portrait, which is an epidemiological profile of health and\nnutrition in their community. Portraits inform strategic planning and\ndevelopment of interventions and are used to assess the impact of\ninterventions. Our key findings indicate ambiguities and disagreement among MSP\ndecision-makers regarding causal relationships between actions and outcomes,\nand the relevant data needed for making decisions. MSP decision-makers\nexpressed a desire for easy-to-use tools that facilitate the collection,\norganization, synthesis, and analysis of data, to enable decision-making in a\ntimely manner. Findings inform conceptual modeling and ontological analysis to\ncapture the domain knowledge and specify relationships between actions and\noutcomes. This modeling and analysis provide the foundation for an ontology,\nencoded using OWL 2 Web Ontology Language. The ontology is developed to provide\nsemantic support for the MSP process, defining objectives, strategies, actions,\nindicators, and data sources. In the future, software interacting with the\nontology can facilitate interactive browsing by decision-makers in the MSP in\nthe form of concepts, instances, relationships, and axioms. Our ontology also\nfacilitates the integration and interpretation of community data and can help\nin managing semantic interoperability between different knowledge sources.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 21:42:38 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Addy", "Nii Antiaye", ""], ["Shaban-Nejad", "Arash", ""], ["Buckeridge", "David L.", ""], ["Dub\u00e9", "Laurette", ""]]}, {"id": "1911.09769", "submitter": "Arash Shaban-Nejad", "authors": "Eun Kyong Shin, Youngsang Kwon, Arash Shaban-Nejad", "title": "Geo-clustered chronic affinity: pathways from socio-economic\n  disadvantages to health disparities", "comments": null, "journal-ref": "JAMIA Open, Volume 2, Issue 3, October 2019, Pages 317-322", "doi": "10.1093/jamiaopen/ooz029", "report-no": null, "categories": "cs.CY math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our objective was to develop and test a new concept (affinity) analogous to\nmultimorbidity of chronic conditions for individuals at census tract level in\nMemphis, TN. The use of affinity will improve the surveillance of multiple\nchronic conditions and facilitate the design of effective interventions. We\nused publicly available chronic condition data (Center for Disease Control and\nPrevention 500 Cities project), socio-demographic data (US Census Bureau), and\ndemographic data (Environmental Systems Research Institute). A geo-distinctive\npattern of clustered chronic affinity associated with socio-economic\ndeprivation wasobserved. Statistical results confirmed that neighborhoods with\nhigher rates of crime, poverty, and unemploy-ment were associated with an\nincreased likelihood of having a higher affinity among major chronic\nconditions.With the inclusion of smoking in the model, however, only the crime\nprevalence was statistically significantlyassociated with the chronic affinity.\nChronic affinity disadvantages were disproportionately accumulated in socially\ndisadvantagedareas. We showed links between commonly co-observed chronic\ndiseases at the population level and systemat-ically explored the complexity of\naffinity and socio-economic disparities. Our affinity score, based on\npubliclyavailable datasets, served as a surrogate for multimorbidity at the\npopulation level, which may assist policy-makers and public health planners to\nidentify urgent hot spots for chronic disease and allocate clinical, medicaland\nhealthcare resources efficiently.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 22:03:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Shin", "Eun Kyong", ""], ["Kwon", "Youngsang", ""], ["Shaban-Nejad", "Arash", ""]]}, {"id": "1911.09792", "submitter": "Jiahua Chen", "authors": "Jiahua Chen, Aneesha Manne, Rebecca Mendum, Poonam Sahoo, and Alicia\n  Yang", "title": "Minority Voter Distributions and Partisan Gerrymandering", "comments": "26 pages, 15 figures; mentored by Diana Davis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.MG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many people believe that it is disadvantageous for members aligning with a\nminority party to cluster in cities, as this makes it easier for the majority\nparty to gerrymander district boundaries to diminish the representation of the\nminority. We examine this effect by exhaustively computing the average\nrepresentation for every possible $5\\times 5$ grid of population placement and\ndistrict boundaries. We show that, in fact, it is advantageous for the minority\nto arrange themselves in clusters, as it is positively correlated with\nrepresentation. We extend this result to more general cases by considering the\ndual graph of districts, and we also propose and analyze metaheuristic\nalgorithms that allow us to find strong lower bounds for maximum expected\nrepresentation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 00:20:37 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Chen", "Jiahua", ""], ["Manne", "Aneesha", ""], ["Mendum", "Rebecca", ""], ["Sahoo", "Poonam", ""], ["Yang", "Alicia", ""]]}, {"id": "1911.09899", "submitter": "Mehmet Tekerek (PhD)", "authors": "Hilmi Bahad{\\i}r Temur, Ahmet Serdar Y{\\i}lmaz, Mehmet Tekerek", "title": "Knowledge Network and a Knowledge Network Example", "comments": "6 Pages, in Turkish language, 4 figures, Conference Proceeding", "journal-ref": "Proceedings of International Symposium on Advanced Engineering\n  Technologies 2019, 1, 1350-1355 (2019)", "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge networks can be defined as social networks that enable the transfer\nof the knowledge, which is defined as the intellectual product formed as a\nresult of the work of human intelligence, to be transferred to any other means\nof communication. A knowledge network represents a large number of people,\nresources and relationships between them, to create the highest value,\nprimarily to accumulate and use knowledge through the process of generating and\ntransmitting knowledge. General structure of knowledge networks; it consists of\nthree basic stages: gathering, organizing and disseminating knowledge. The\nfirst step, knowledge collection, institutions and organizations to enter the\nnetwork structure of the knowledge that is present. The organizing phase is the\nstructuring of irregular and unstructured knowledge in the network structure\naccording to certain standards and recording them regularly in the structure.\nKnowledge dissemination can be expressed as the transfer of organized knowledge\nin accordance with user knowledge and needs. The purpose of the training\nknowledge network is to ensure communication between the student, the teacher\nand the guide, and to store the knowledge that is formed in a course, to enable\nthe system to be recorded in a systematic way, to disseminate it according to\nthe needs of the users and to update the knowledge. A dynamic website and\ncontent management system have been developed for the training knowledge\nnetwork. The training knowledge network has a flexible structure to support web\ntechnologies. By making production, management and publication of knowledge\nwithin the framework of specific needs, it provides knowledge network for\ndifferent problems, producing different and tailored solutions. With the\nexample of education knowledge network, a knowledge network that can be\ndeveloped according to the innovative knowledge network structure is designed.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:33:43 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Temur", "Hilmi Bahad\u0131r", ""], ["Y\u0131lmaz", "Ahmet Serdar", ""], ["Tekerek", "Mehmet", ""]]}, {"id": "1911.09903", "submitter": "Alperen Kantarc{\\i}", "authors": "Rumeysa Bulut, Alperen Kantarc{\\i}, Safa Keskin, \\c{S}erif Bahtiyar", "title": "Blockchain-Based Electronic Voting System for Elections in Turkey", "comments": "4 pages, 4 figures, IEEE style", "journal-ref": "2019 4th International Conference on Computer Science and\n  Engineering (UBMK) (2019) 183-188", "doi": "10.1109/UBMK.2019.8907102", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional elections satisfy neither citizens nor political authorities in\nrecent years. They are not fully secure since it is easy to attack votes. It\nthreatens also privacy and transparency of voters. Additionally, it takes too\nmuch time to count the votes. This paper proposes a solution using Blockchain\nto eliminate all the disadvantages of conventional elections. Security and data\nintegrity of votes are absolutely provided theoretically. Voter privacy is\nanother requirement that is ensured in the system. Lastly, the waiting time for\nresults decreased significantly in the proposed Blockchain voting system.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 07:40:34 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bulut", "Rumeysa", ""], ["Kantarc\u0131", "Alperen", ""], ["Keskin", "Safa", ""], ["Bahtiyar", "\u015eerif", ""]]}, {"id": "1911.09923", "submitter": "Claudia Savina Bianchini", "authors": "Claudia S. Bianchini (FORELLIS), Fabrizio Borgia (UPS), Maria de\n  Marsico", "title": "SWift -- A SignWriting editor to bridge between deaf world and\n  e-learning", "comments": null, "journal-ref": "Proceedings of the International Conference on Advanced Learning\n  Technologies (ICALT), IEEE - Institute of Electrical and Electronics\n  Engineers, pp.526-530, 2012, 978-0-7695-4702-2", "doi": "10.1109/ICALT.2012.235", "report-no": "pubblicazione #010", "categories": "cs.HC cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SWift (SignWriting improved fast transcriber) is an advanced editor for\nSignWriting (SW). At present, SW is a promising alternative to provide\ndocuments in an easy-to-grasp written form of (any) Sign Language, the gestural\nway of communication which is widely adopted by the deaf community. SWift was\ndeveloped SW users, either deaf or not, to support collaboration and exchange\nof ideas. The application allows composing and saving desired signs using\nelementary components, called glyphs. The procedure that was devised guides and\nsimplifies the editing process. SWift aims at breaking the \"electronic\"\nbarriers that keep the deaf community away from ICT in general, and from\ne-learning in particular. The editor can be contained in a pluggable module;\ntherefore, it can be integrated everywhere the use of SW is an advisable\nalternative to written \"verbal\" language, which often hinders information\ngrasping by deaf users.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2019 08:44:23 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bianchini", "Claudia S.", "", "FORELLIS"], ["Borgia", "Fabrizio", "", "UPS"], ["de Marsico", "Maria", ""]]}, {"id": "1911.10395", "submitter": "Siddharth Biswal", "authors": "Siddharth Biswal, Cao Xiao, Lucas M. Glass, Elizabeth Milkovits,\n  Jimeng Sun", "title": "Doctor2Vec: Dynamic Doctor Representation Learning for Clinical Trial\n  Recruitment", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive electronic health records (EHRs) enable the success of learning\naccurate patient representations to support various predictive health\napplications. In contrast, doctor representation was not well studied despite\nthat doctors play pivotal roles in healthcare. How to construct the right\ndoctor representations? How to use doctor representation to solve important\nhealth analytic problems? In this work, we study the problem on {\\it clinical\ntrial recruitment}, which is about identifying the right doctors to help\nconduct the trials based on the trial description and patient EHR data of those\ndoctors. We propose doctor2vec which simultaneously learns 1) doctor\nrepresentations from EHR data and 2) trial representations from the description\nand categorical information about the trials. In particular, doctor2vec\nutilizes a dynamic memory network where the doctor's experience with patients\nare stored in the memory bank and the network will dynamically assign weights\nbased on the trial representation via an attention mechanism. Validated on\nlarge real-world trials and EHR data including 2,609 trials, 25K doctors and\n430K patients, doctor2vec demonstrated improved performance over the best\nbaseline by up to $8.7\\%$ in PR-AUC. We also demonstrated that the doctor2vec\nembedding can be transferred to benefit data insufficiency settings including\ntrial recruitment in less populated/newly explored country with $13.7\\%$\nimprovement or for rare diseases with $8.1\\%$ improvement in PR-AUC.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2019 17:59:12 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Biswal", "Siddharth", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas M.", ""], ["Milkovits", "Elizabeth", ""], ["Sun", "Jimeng", ""]]}, {"id": "1911.10509", "submitter": "Swati Megha", "authors": "Swati Megha, Joseph Lamptey, Hamza Salem, Manuel Mazzara", "title": "A survey of of blockchain-based solutions for Energy Industry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy industry needs to shift to a new paradigm from its classical model\nof energy generation, distribution, and management. This shift is necessary to\nhandle digitization, increased renewable energy generation, and to achieve\ngoals of environmental sustainability. This shift has several challenges on its\nway and has been seen through research and development that blockchain which is\none of the budding technology in this era could be suitable for addressing\nthose challenges. This paper is aimed at the survey of all the research and\ndevelopment related to blockchain in the energy industry and uses a software\nengineering approach to categories all the existing work in several clusters\nsuch as challenges addressed, quality attribute promoted, the maturity level of\nthe solutions, etc. This survey provides researchers in this field a\nwell-defined categorization and insight into the existing work in this field\nfrom 3 different perspectives (challenges, quality attributes, maturity).\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 11:38:05 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 09:16:06 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Megha", "Swati", ""], ["Lamptey", "Joseph", ""], ["Salem", "Hamza", ""], ["Mazzara", "Manuel", ""]]}, {"id": "1911.10517", "submitter": "Savvas Zannettou", "authors": "Savvas Zannettou", "title": "Towards Understanding the Information Ecosystem Through the Lens of\n  Multiple Web Communities", "comments": "PhD thesis. Overlaps with arXiv:1804.03461, arXiv:1705.06947,\n  arXiv:1805.12512, arXiv:1802.05287, arXiv:1801.10396, arXiv:1801.09288,\n  arXiv:1811.03130", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web consists of numerous Web communities, news sources, and services,\nwhich are often exploited by various entities for the dissemination of false\ninformation. Yet, we lack tools and techniques to effectively track the\npropagation of information across the multiple diverse communities, and to\nmodel the interplay and influence between them. Also, we lack an understanding\nof what the role and impact of emerging communities and services on the Web\nare, and how such communities are exploited by bad actors that spread false and\nweaponized information. In this thesis, we study the information ecosystem on\nthe Web by presenting a typology that includes the various types of false\ninformation, the involved actors and their possible motives. Then, we follow a\ndata-driven cross-platform quantitative approach to analyze billions of posts\nfrom Twitter, Reddit, 4chan's /pol/, and Gab, to shed light on: 1) how news and\nmemes travel from one Web community to another and how we can model and\nquantify the influence between Web communities; 2) characterizing the role of\nemerging Web communities and services on the Web, by studying Gab and two Web\narchiving services, namely the Wayback Machine and archive.is; and 3) how\npopular Web communities are exploited by state-sponsored actors for the purpose\nof spreading disinformation. Our analysis reveal that fringe Web communities\nlike 4chan's /pol/ and The_Donald subreddit have a disproportionate influence\non mainstream communities like Twitter with regard to the dissemination of news\nand memes. We find that Gab acts as the new hub for the alt-right community,\nwhile for Web archiving services we find that they can be misused to penalize\nad revenue from news sources with conflicting ideology. Finally, when studying\nstate-sponsored actors, we find that they were particularly influential in\nspreading news on popular communities like Twitter and Reddit.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 12:30:35 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Zannettou", "Savvas", ""]]}, {"id": "1911.10806", "submitter": "Fan Yang", "authors": "Jin Watanabe, Takatomi Kubo, Fan Yang and Kazushi Ikeda", "title": "Detecting Unknown Behaviors by Pre-defined Behaviours: An Bayesian\n  Non-parametric Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automatic mouse behavior recognition system can considerably reduce the\nworkload of experimenters and facilitate the analysis process. Typically,\nsupervised approaches, unsupervised approaches and semi-supervised approaches\nare applied for behavior recognition purpose under a setting which has all of\npredefined behaviors. In the real situation, however, as mouses can show\nvarious types of behaviors, besides the predefined behaviors that we want to\nanalyze, there are many undefined behaviors existing. Both supervised\napproaches and conventional semi-supervised approaches cannot identify these\nundefined behaviors. Though unsupervised approaches can detect these undefined\nbehaviors, a post-hoc labeling is needed. In this paper, we propose a\nsemi-supervised infinite Gaussian mixture model (SsIGMM), to incorporate both\nlabeled and unlabelled information in learning process while considering\nundefined behaviors. It also generates the distribution of the predefined and\nundefined behaviors by mixture Gaussians, which can be used for further\nanalysis. In our experiments, we confirmed the superiority of SsIGMM for\nsegmenting and labelling mouse-behavior videos.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 10:17:59 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 08:19:04 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Watanabe", "Jin", ""], ["Kubo", "Takatomi", ""], ["Yang", "Fan", ""], ["Ikeda", "Kazushi", ""]]}, {"id": "1911.11067", "submitter": "Bokun Kong", "authors": "Bokun Kong", "title": "Analysing Russian Trolls via NLP tools", "comments": "53 pages, 8 figures, 16 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The fifty-eighth American presidential election in 2016 still arouse fierce\ncontroversyat present. A portion of politicians as well as medium and voters\nbelieve that theRussian government interfered with the election of 2016 by\ncontrolling malicioussocial media accounts on twitter, such as trolls and bots\naccounts. Both of them willbroadcast fake news, derail the conversations about\nelection, and mislead people.Therefore, this paper will focus on analysing some\nof the twitter dataset about theelection of 2016 by using NLP methods and\nlooking for some interesting patterns ofwhether the Russian government\ninterfered with the election or not. We apply topicmodel on the given twitter\ndataset to extract some interesting topics and analysethe meaning, then we\nimplement supervised topic model to retrieve the relationshipbetween topics to\ncategory which is left troll or right troll, and analyse the\npattern.Additionally, we will do sentiment analysis to analyse the attitude of\nthe tweet. Afterextracting typical tweets from interesting topic, sentiment\nanalysis offers the ability toknow whether the tweet supports this topic or\nnot. Based on comprehensive analysisand evaluation, we find interesting\npatterns of the dataset as well as some meaningfultopics.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 08:30:54 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Kong", "Bokun", ""]]}, {"id": "1911.11085", "submitter": "Matthew England Dr", "authors": "David Croft and Matthew England", "title": "Computing with CodeRunner at Coventry University: Automated summative\n  assessment of Python and C++ code", "comments": "4 pages. Accepted for presentation at CEP20", "journal-ref": "Proc. 4th Conference on Computing Education Practice (CEP '20),\n  Article Num 1, ACM, 2020", "doi": "10.1145/3372356.3372357", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CodeRunner is a free open-source Moodle plugin for automatically marking\nstudent code. We describe our experience using CodeRunner for summative\nassessment in our first year undergraduate programming curriculum at Coventry\nUniversity. We use it to assess both Python3 and C++14 code (CodeRunner\nsupports other languages also). We give examples of our questions and report on\nhow key metrics have changed following its use at Coventry.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:44:18 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 11:11:47 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Croft", "David", ""], ["England", "Matthew", ""]]}, {"id": "1911.11088", "submitter": "Matthew England Dr", "authors": "Simon Billings and Matthew England", "title": "First Year Computer Science Projects at Coventry University:\n  Activity-led integrative team projects with continuous assessment", "comments": "4 pages. Accepted for presentation at CEP20", "journal-ref": "Proc. 4th Conference on Computing Education Practice (CEP '20),\n  Article Num 2, ACM, 2020", "doi": "10.1145/3372356.3372358", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the group projects undertaken by first year undergraduate\nComputer Science students at Coventry University. These are integrative course\nprojects: designed to bring together the topics from the various modules\nstudents take, to apply them as a coherent whole. They follow an activity-led\napproach, with students given a loose brief and a lot of freedom in how to\ndevelop their project.\n  We outline the new regulations at Coventry University which eases the use of\nsuch integrative projects. We then describe our continuous assessment approach:\nwhere students earn a weekly mark by demonstrating progress to a teacher as an\nopen presentation to the class. It involves a degree of self and peer\nassessment and allows for an assessment of group work that is both fair, and\nseen to be fair. It builds attendance, self-study / continuous engagement\nhabits, public speaking / presentation skills, and rewards group members for\nmaking meaningful individual contributions.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 17:45:08 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Billings", "Simon", ""], ["England", "Matthew", ""]]}, {"id": "1911.11214", "submitter": "Naeemul Hassan", "authors": "Sima Bhowmik, Md Main Uddin Rony, Md Mahfuzul Haque, Kristen Alley\n  Swain, Naeemul Hassan", "title": "Examining the Role of Clickbait Headlines to Engage Readers with\n  Reliable Health-related Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clickbait headlines are frequently used to attract readers to read articles.\nAlthough this headline type has turned out to be a technique to engage readers\nwith misleading items, it is still unknown whether the technique can be used to\nattract readers to reliable pieces. This study takes the opportunity to test\nits efficacy to engage readers with reliable health articles. A set of online\nsurveys would be conducted to test readers' engagement with and perception\nabout clickbait headlines with reliable articles. After that, we would design\nan automation system to generate clickabit headlines to maximize user\nengagement.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 20:29:01 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Bhowmik", "Sima", ""], ["Rony", "Md Main Uddin", ""], ["Haque", "Md Mahfuzul", ""], ["Swain", "Kristen Alley", ""], ["Hassan", "Naeemul", ""]]}, {"id": "1911.11265", "submitter": "Jessica Velasco", "authors": "Jessica Velasco, Leandro Alberto, Henrick Dave Ambatali, Marlon\n  Canilang, Vincent Daria, Jerome Bryan Liwanag, Gilfred Allen Madrigal", "title": "Internet of things-based (IoT) inventory monitoring refrigerator using\n  arduino sensor network", "comments": null, "journal-ref": "Indonesian Journal of Electrical Engineering and Computer Science\n  (2020) 508-515", "doi": "10.11591/ijeecs.v18.i1.pp508-515", "report-no": null, "categories": "eess.SY cs.CY cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents a system that combines a conventional refrigerator,\nmicrocontrollers and a smart phone to create an inventory monitoring that can\nmonitor the stocks inside the refrigerator wirelessly by accessing an Android\napplication. The developed refrigerator uses a sensor network system that is\ninstalled in a respective compartment inside the refrigerator. Each sensor will\ntransmit data to the microcontrollers, such as Arduino Yun and Arduino Uno,\nwhich are interconnected by the I2C communications. All data and images will be\nprocessed to provide the user an Internet of Things application through the\ncloud-based website Temboo. Temboo will have access to send data to the\nDropbox. A smartphone is connected to the Dropbox where all the data and images\nare stored. The user can monitor the stocks or contents of the refrigerator\nwirelessly using an Android Application.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 22:57:33 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Velasco", "Jessica", ""], ["Alberto", "Leandro", ""], ["Ambatali", "Henrick Dave", ""], ["Canilang", "Marlon", ""], ["Daria", "Vincent", ""], ["Liwanag", "Jerome Bryan", ""], ["Madrigal", "Gilfred Allen", ""]]}, {"id": "1911.11309", "submitter": "Xinyu Zhang", "authors": "Xinyu Zhang", "title": "Drivers affecting cloud ERP deployment decisions: an Australian study", "comments": "67 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud-based Enterprise Resources Planning (Cloud ERP) is hosting an ERP\nsystem through the cloud environment. Cloud ERP is responsible for\norganisational business processes such as purchasing, financial, and human\nresource by providing a real-time infrastructure for the enterprise. With the\ndevelopment of technology, cloud ERP is noticed by more and more enterprises.\nCurrently, limited researches have been conducted for cloud ERP systems in the\nAustralian context. Furthermore, no studies have indicated how different\nperspectives (client company & consultant company) bring insights into the\ndeployment decisions on cloud ERP. Hence, this research intends to understand\ndrivers affecting cloud ERP deployment decisions from both the client company\nand the consultant company perspective in an Australian context. This paper\nidentifies 31 relevant literature on cloud ERP adoption; 79 critical drivers\naffecting cloud ERP deployment decisions were identified from the selected\nliterature, and those drivers are then categorized using the\nTechnology-Organisation-Environment (TOE) framework to develop the initial\ntheoretical model. By conducting a Case Study Approach using a semi-structured\ninterview and secondary resources analysis, findings are then compared to the\ntheoretical model. As a result, an empirically validated model on drivers\naffecting cloud ERP deployment decisions from both client company and\nconsultant company perspectives has been developed; this model contains 15\ndrivers and 7 of them are new. The theoretical and practical contributions of\nthe findings are then outlined.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 02:13:12 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Zhang", "Xinyu", ""]]}, {"id": "1911.11356", "submitter": "Viet Trinh", "authors": "Viet Trinh, Roberto Manduchi", "title": "Semantic Interior Mapology: A Toolbox For Indoor Scene Description From\n  Architectural Floor Plans", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Semantic Interior Mapology (SIM) toolbox for the conversion\nof a floor plan and its room contents (such as furnitures) to a vectorized\nform. The toolbox is composed of the Map Conversion toolkit and the Map\nPopulation toolkit. The Map Conversion toolkit allows one to quickly trace the\nlayout of a floor plan, and to generate a GeoJSON file that can be rendered in\n3D using web applications such as Mapbox. The Map Population toolkit takes the\n3D scan of a room in the building (acquired from an RGB-D camera), and, through\na semi-automatic process, populates individual objects of interest with a\ncorrect dimension and position in the GeoJSON representation of the building.\nSIM is easy to use and produces accurate results even in the case of complex\nbuilding layouts.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 05:56:43 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Trinh", "Viet", ""], ["Manduchi", "Roberto", ""]]}, {"id": "1911.11377", "submitter": "Robert Podschwadt", "authors": "Daniel Takabi, Robert Podschwadt, Jeff Druce, Curt Wu, Kevin Procopio", "title": "Privacy preserving Neural Network Inference on Encrypted Data with GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning as a Service (MLaaS) has become a growing trend in recent\nyears and several such services are currently offered. MLaaS is essentially a\nset of services that provides machine learning tools and capabilities as part\nof cloud computing services. In these settings, the cloud has pre-trained\nmodels that are deployed and large computing capacity whereas the clients can\nuse these models to make predictions without having to worry about maintaining\nthe models and the service. However, the main concern with MLaaS is the privacy\nof the client's data.\n  Although there have been several proposed approaches in the literature to run\nmachine learning models on encrypted data, the performance is still far from\nbeing satisfactory for practical use. In this paper, we aim to accelerate the\nperformance of running machine learning on encrypted data using combination of\nFully Homomorphic Encryption (FHE), Convolutional Neural Networks (CNNs) and\nGraphics Processing Units (GPUs). We use a number of optimization techniques,\nand efficient GPU-based implementation to achieve high performance. We evaluate\na CNN whose architecture is similar to AlexNet to classify homomorphically\nencrypted samples from the Cars Overhead With Context (COWC) dataset. To the\nbest of our knowledge, it is the first time such a complex network and large\ndataset is evaluated on encrypted data. Our approach achieved reasonable\nclassification accuracy of 95% for the COWC dataset. In terms of performance,\nour results show that we could achieve several thousands times speed up when we\nimplement GPU-accelerated FHE operations on encrypted floating point numbers.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 07:36:38 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Takabi", "Daniel", ""], ["Podschwadt", "Robert", ""], ["Druce", "Jeff", ""], ["Wu", "Curt", ""], ["Procopio", "Kevin", ""]]}, {"id": "1911.11657", "submitter": "Gokul S Krishnan", "authors": "Gokul S Krishnan and Sowmya Kamath S", "title": "Hybrid Text Feature Modeling for Disease Group Prediction using\n  Unstructured Physician Notes", "comments": "Submitted to the International Conference on Computational Science\n  (ICCS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Clinical Decision Support Systems (CDSSs) largely depend on the\navailability of structured patient data and Electronic Health Records (EHRs) to\naid caregivers. However, in case of hospitals in developing countries,\nstructured patient data formats are not widely adopted, where medical\nprofessionals still rely on clinical notes in the form of unstructured text.\nSuch unstructured clinical notes recorded by medical personnel can also be a\npotential source of rich patient-specific information which can be leveraged to\nbuild CDSSs, even for hospitals in developing countries. If such unstructured\nclinical text can be used, the manual and time-consuming process of EHR\ngeneration will no longer be required, with huge person-hours and cost savings.\nIn this paper, we propose a generic ICD9 disease group prediction CDSS built on\nunstructured physician notes modeled using hybrid word embeddings. These word\nembeddings are used to train a deep neural network for effectively predicting\nICD9 disease groups. Experimental evaluation showed that the proposed approach\noutperformed the state-of-the-art disease group prediction model built on\nstructured EHRs by 15% in terms of AUROC and 40% in terms of AUPRC, thus\nproving our hypothesis and eliminating dependency on availability of structured\npatient data.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:55:39 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Krishnan", "Gokul S", ""], ["S", "Sowmya Kamath", ""]]}, {"id": "1911.11658", "submitter": "Victor Kristof", "authors": "Victor Kristof, Valentin Quelquejay-Lecl\\`ere, Robin Zbinden, Lucas\n  Maystre, Matthias Grossglauser, Patrick Thiran", "title": "A User Study of Perceived Carbon Footprint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical model to understand people's perception of their\ncarbon footprint. Driven by the observation that few people think of CO2 impact\nin absolute terms, we design a system to probe people's perception from simple\npairwise comparisons of the relative carbon footprint of their actions. The\nformulation of the model enables us to take an active-learning approach to\nselecting the pairs of actions that are maximally informative about the model\nparameters. We define a set of 18 actions and collect a dataset of 2183\ncomparisons from 176 users on a university campus. The early results reveal\npromising directions to improve climate communication and enhance climate\nmitigation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 15:56:46 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 14:56:02 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Kristof", "Victor", ""], ["Quelquejay-Lecl\u00e8re", "Valentin", ""], ["Zbinden", "Robin", ""], ["Maystre", "Lucas", ""], ["Grossglauser", "Matthias", ""], ["Thiran", "Patrick", ""]]}, {"id": "1911.11787", "submitter": "Goran Muric", "authors": "Goran Muric, Andres Abeliuk, Kristina Lerman, Emilio Ferrara", "title": "Collaboration Drives Individual Productivity", "comments": "Proc. ACM Hum.-Comput. Interact., Vol. 3, No. CSCW", "journal-ref": null, "doi": "10.1145/3359176", "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does the number of collaborators affect individual productivity? Results\nof prior research have been conflicting, with some studies reporting an\nincrease in individual productivity as the number of collaborators grows, while\nother studies showing that the {free-rider effect} skews the effort invested by\nindividuals, making larger groups less productive. The difference between these\nschools of thought is substantial: if a super-scaling effect exists, as\nsuggested by former studies, then as groups grow, their productivity will\nincrease even faster than their size, super-linearly improving their\nefficiency. We address this question by studying two planetary-scale\ncollaborative systems: GitHub and Wikipedia. By analyzing the activity of over\n2 million users on these platforms, we discover that the interplay between\ngroup size and productivity exhibits complex, previously-unobserved dynamics:\nthe productivity of smaller groups scales super-linearly with group size, but\nsaturates at larger sizes. This effect is not an artifact of the heterogeneity\nof productivity: the relation between group size and productivity holds at the\nindividual level. People tend to do more when collaborating with more people.\nWe propose a generative model of individual productivity that captures the\nnon-linearity in collaboration effort. The proposed model is able to explain\nand predict group work dynamics in GitHub and Wikipedia by capturing their\nmaximally informative behavioral features, and it paves the way for a\nprincipled, data-driven science of collaboration.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 19:00:06 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Muric", "Goran", ""], ["Abeliuk", "Andres", ""], ["Lerman", "Kristina", ""], ["Ferrara", "Emilio", ""]]}, {"id": "1911.11976", "submitter": "Faisal Hussain", "authors": "Faisal Hussain, Muhammad Basit Umair, Muhammad Ehatisham-ul-Haq, Ivan\n  Miguel Pires, T\\^ania Valente, Nuno M.Garcia and Nuno Pombo", "title": "An Efficient Machine Learning-based Elderly Fall Detection Algorithm", "comments": "6 pages, SENSORDEVICES 2018, the Ninth International Conference on\n  Sensor Device Technologies and Applications, Venice, Italy, 16-20 September\n  2018", "journal-ref": null, "doi": null, "report-no": "ISBN: 978-1-61208-660-6", "categories": "cs.LG cs.CY eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Falling is a commonly occurring mishap with elderly people, which may cause\nserious injuries. Thus, rapid fall detection is very important in order to\nmitigate the severe effects of fall among the elderly people. Many fall\nmonitoring systems based on the accelerometer have been proposed for the fall\ndetection. However, many of them mistakenly identify the daily life activities\nas fall or fall as daily life activity. To this aim, an efficient machine\nlearning-based fall detection algorithm has been proposed in this paper. The\nproposed algorithm detects fall with efficient sensitivity, specificity, and\naccuracy as compared to the state-of-the-art techniques. A publicly available\ndataset with a very simple and computationally efficient set of features is\nused to accurately detect the fall incident. The proposed algorithm reports and\naccuracy of 99.98% with the Support Vector Machine(SVM) classifier.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 06:26:10 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Hussain", "Faisal", ""], ["Umair", "Muhammad Basit", ""], ["Ehatisham-ul-Haq", "Muhammad", ""], ["Pires", "Ivan Miguel", ""], ["Valente", "T\u00e2nia", ""], ["Garcia", "Nuno M.", ""], ["Pombo", "Nuno", ""]]}, {"id": "1911.12039", "submitter": "Alessandro Galeazzi", "authors": "Matteo Cinelli, Stefano Cresci, Alessandro Galeazzi, Walter\n  Quattrociocchi, Maurizio Tesconi", "title": "The Limited Reach of Fake News on Twitter during 2019 European Elections", "comments": null, "journal-ref": "PLoS ONE 15(6): e0234689, 2020", "doi": "10.1371/journal.pone.0234689", "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 09:22:51 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Cinelli", "Matteo", ""], ["Cresci", "Stefano", ""], ["Galeazzi", "Alessandro", ""], ["Quattrociocchi", "Walter", ""], ["Tesconi", "Maurizio", ""]]}, {"id": "1911.12060", "submitter": "Jun Zhao", "authors": "Jun Zhao, Teng Wang, Tao Bai, Kwok-Yan Lam, Zhiying Xu, Shuyu Shi,\n  Xuebin Ren, Xinyu Yang, Yang Liu, Han Yu", "title": "Reviewing and Improving the Gaussian Mechanism for Differential Privacy", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy provides a rigorous framework to quantify data privacy,\nand has received considerable interest recently. A randomized mechanism\nsatisfying $(\\epsilon, \\delta)$-differential privacy (DP) roughly means that,\nexcept with a small probability $\\delta$, altering a record in a dataset cannot\nchange the probability that an output is seen by more than a multiplicative\nfactor $e^{\\epsilon} $. A well-known solution to $(\\epsilon, \\delta)$-DP is the\nGaussian mechanism initiated by Dwork et al. [1] in 2006 with an improvement by\nDwork and Roth [2] in 2014, where a Gaussian noise amount $\\sqrt{2\\ln\n\\frac{2}{\\delta}} \\times \\frac{\\Delta}{\\epsilon}$ of [1] or $\\sqrt{2\\ln\n\\frac{1.25}{\\delta}} \\times \\frac{\\Delta}{\\epsilon}$ of [2] is added\nindependently to each dimension of the query result, for a query with\n$\\ell_2$-sensitivity $\\Delta$. Although both classical Gaussian mechanisms\n[1,2] assume $0 < \\epsilon \\leq 1$, our review finds that many studies in the\nliterature have used the classical Gaussian mechanisms under values of\n$\\epsilon$ and $\\delta$ where the added noise amounts of [1,2] do not achieve\n$(\\epsilon,\\delta)$-DP. We obtain such result by analyzing the optimal noise\namount $\\sigma_{DP-OPT}$ for $(\\epsilon,\\delta)$-DP and identifying $\\epsilon$\nand $\\delta$ where the noise amounts of classical mechanisms are even less than\n$\\sigma_{DP-OPT}$.\n  Since $\\sigma_{DP-OPT}$ has no closed-form expression and needs to be\napproximated in an iterative manner, we propose Gaussian mechanisms by deriving\nclosed-form upper bounds for $\\sigma_{DP-OPT}$. Our mechanisms achieve\n$(\\epsilon,\\delta)$-DP for any $\\epsilon$, while the classical mechanisms [1,2]\ndo not achieve $(\\epsilon,\\delta)$-DP for large $\\epsilon$ given $\\delta$.\nMoreover, the utilities of our mechanisms improve those of [1,2] and are close\nto that of the optimal yet more computationally expensive Gaussian mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 10:26:50 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 04:13:50 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Zhao", "Jun", ""], ["Wang", "Teng", ""], ["Bai", "Tao", ""], ["Lam", "Kwok-Yan", ""], ["Xu", "Zhiying", ""], ["Shi", "Shuyu", ""], ["Ren", "Xuebin", ""], ["Yang", "Xinyu", ""], ["Liu", "Yang", ""], ["Yu", "Han", ""]]}, {"id": "1911.12139", "submitter": "Tobias Fiebig", "authors": "Tobias Fiebig", "title": "Moving Fast and Breaking Things: How to stop crashing more than twice", "comments": "Position Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Moving fast, and breaking things\", instead of \"being safe and secure\", is\nthe credo of the IT industry. In this paper, we take a look at how we keep\nfalling for the same security issues, and what we can learn from aviation\nsafety to learn building and operating IT systems securely. We find that\ncomputer security should adopt the idea of safety. This entails not only\nbuilding systems that are operating as desired in the presence of an active\nattacker, but also building them in a way that they remain secure and\noperational in the presence of any failure. Furthermore, we propose a 'clean\nslate policy design' to counter the current state of verbose, hardly followed\nbest practices, together with an incident handling and reporting structure\nsimilar to that found in aviation safety.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 12:38:23 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Fiebig", "Tobias", ""]]}, {"id": "1911.12143", "submitter": "Takahiro Yabe", "authors": "Takahiro Yabe, Kota Tsubouchi, Toru Shimizu, Yoshihide Sekimoto,\n  Satish V. Ukkusuri", "title": "City2City: Translating Place Representations across Cities", "comments": "A short 4-page version of this work was accepted in ACM SIGSPATIAL\n  Conference 2019. This is the full version with details. In Proceedings of the\n  27th ACM SIGSPATIAL International Conference on Advances in Geographic\n  Information Systems. ACM", "journal-ref": null, "doi": "10.1145/3347146.3359063", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large mobility datasets collected from various sources have allowed us to\nobserve, analyze, predict and solve a wide range of important urban challenges.\nIn particular, studies have generated place representations (or embeddings)\nfrom mobility patterns in a similar manner to word embeddings to better\nunderstand the functionality of different places within a city. However,\nstudies have been limited to generating such representations of cities in an\nindividual manner and has lacked an inter-city perspective, which has made it\ndifficult to transfer the insights gained from the place representations across\ndifferent cities. In this study, we attempt to bridge this research gap by\ntreating \\textit{cities} and \\textit{languages} analogously. We apply methods\ndeveloped for unsupervised machine language translation tasks to translate\nplace representations across different cities. Real world mobility data\ncollected from mobile phone users in 2 cities in Japan are used to test our\nplace representation translation methods. Translated place representations are\nvalidated using landuse data, and results show that our methods were able to\naccurately translate place representations from one city to another.\n", "versions": [{"version": "v1", "created": "Tue, 26 Nov 2019 18:57:43 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Yabe", "Takahiro", ""], ["Tsubouchi", "Kota", ""], ["Shimizu", "Toru", ""], ["Sekimoto", "Yoshihide", ""], ["Ukkusuri", "Satish V.", ""]]}, {"id": "1911.12275", "submitter": "Taha Yasseri", "authors": "Taha Yasseri and Jannie Reher", "title": "Fooling with facts: Quantifying anchoring bias through a large-scale\n  online experiment", "comments": "Under Review, 15 pages + Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Living in the 'Information Age' means that not only access to information has\nbecome easier but also that the distribution of information is more dynamic\nthan ever. Through a large-scale online field experiment, we provide new\nempirical evidence for the presence of the anchoring bias in people's judgment\ndue to irrational reliance on a piece of information that they are initially\ngiven. The comparison of the anchoring stimuli and respective responses across\ndifferent tasks reveals a positive, yet complex relationship between the\nanchors and the bias in participants' predictions of the outcomes of events in\nthe future. Participants in the treatment group were equally susceptible to the\nanchors regardless of their level of engagement, previous performance, or\ngender. Given the strong and ubiquitous influence of anchors quantified here,\nwe should take great care to closely monitor and regulate the distribution of\ninformation online to facilitate less biased decision making.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 16:41:20 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Yasseri", "Taha", ""], ["Reher", "Jannie", ""]]}, {"id": "1911.12482", "submitter": "Basit Ayantunde", "authors": "Basit Ayantunde, Jane Odum, Fadlullah Olawumi, and Joshua Olalekan", "title": "Designing the Next Generation of Intelligent Personal Robotic Assistants\n  for the Physically Impaired", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physically impaired commonly have difficulties performing simple routine\ntasks without relying on other individuals who are not always readily available\nand thus make them strive for independence. While their impaired abilities can\nin many cases be augmented (to certain degrees) with the use of assistive\ntechnologies, there has been little attention to their applications in embodied\nAI with assistive technologies. This paper presents the modular framework,\narchitecture, and design of the mid-fidelity prototype of MARVIN: an\nartificial-intelligence-powered robotic assistant designed to help the\nphysically impaired in performing simple day-to-day tasks. The prototype\nfeatures a trivial locomotion unit and also utilizes various state-of-the-art\nneural network architectures for specific modular components of the system.\nThese components perform specialized functions, such as automatic speech\nrecognition, object detection, natural language understanding, speech\nsynthesis, etc. We also discuss the constraints, challenges encountered,\npotential future applications and improvements towards succeeding prototypes.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 02:00:20 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ayantunde", "Basit", ""], ["Odum", "Jane", ""], ["Olawumi", "Fadlullah", ""], ["Olalekan", "Joshua", ""]]}, {"id": "1911.12587", "submitter": "Julia Stoyanovich", "authors": "Sebastian Schelter, Yuxuan He, Jatin Khilnani, Julia Stoyanovich", "title": "FairPrep: Promoting Data to a First-Class Citizen in Studies on\n  Fairness-Enhancing Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of incorporating ethics and legal compliance into\nmachine-assisted decision-making is broadly recognized. Further, several lines\nof recent work have argued that critical opportunities for improving data\nquality and representativeness, controlling for bias, and allowing humans to\noversee and impact computational processes are missed if we do not consider the\nlifecycle stages upstream from model training and deployment. Yet, very little\nhas been done to date to provide system-level support to data scientists who\nwish to develop and deploy responsible machine learning methods. We aim to fill\nthis gap and present FairPrep, a design and evaluation framework for\nfairness-enhancing interventions.\n  FairPrep is based on a developer-centered design, and helps data scientists\nfollow best practices in software engineering and machine learning. As part of\nour contribution, we identify shortcomings in existing empirical studies for\nanalyzing fairness-enhancing interventions. We then show how FairPrep can be\nused to measure the impact of sound best practices, such as hyperparameter\ntuning and feature scaling. In particular, our results suggest that the high\nvariability of the outcomes of fairness-enhancing interventions observed in\nprevious studies is often an artifact of a lack of hyperparameter tuning.\nFurther, we show that the choice of a data cleaning method can impact the\neffectiveness of fairness-enhancing interventions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:28:46 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Schelter", "Sebastian", ""], ["He", "Yuxuan", ""], ["Khilnani", "Jatin", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "1911.12593", "submitter": "Aziz Mohaisen", "authors": "David Mohaisen and Songqing Chen", "title": "Computer Systems Have 99 Problems, Let's Not Make Machine Learning\n  Another One", "comments": "5 pages; 0 figures; 0 tables. To appear in IEEE TPS 2019 (vision\n  track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques are finding many applications in computer\nsystems, including many tasks that require decision making: network\noptimization, quality of service assurance, and security. We believe machine\nlearning systems are here to stay, and to materialize on their potential we\nadvocate a fresh look at various key issues that need further attention,\nincluding security as a requirement and system complexity, and how machine\nlearning systems affect them. We also discuss reproducibility as a key\nrequirement for sustainable machine learning systems, and leads to pursuing it.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 08:43:01 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Mohaisen", "David", ""], ["Chen", "Songqing", ""]]}, {"id": "1911.12968", "submitter": "A.J. Santos", "authors": "A.J. Santos", "title": "Recognition of Blockchain-based Multisignature E-Awards", "comments": "Paper presented at Ankara Yildirim Beyazit University International\n  Arbitration Symposium on 25 April 2019. Applied computing Law", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With blockchain technology, information is recorded in a permanent\ndistributed ledger that is maintained by multiple computers in a peer-to-peer\nnetwork. There is no central authority that can alter records or change network\nconsensus rules. Such technology could be utilized for voting, title transfers,\nissuance of company shares, document notarization, but currently, the most\npopular use-case are virtual currencies. An interesting feature that some\nvirtual currencies have is a multisignature (multisig) protocol that requires\nthe electronic signatures from more than one private key to initiate a transfer\nof funds. Raw data of a multisig transaction may be recognized as an arbitral\naward under the New York Convention, where the law of England is the lex\narbitri and parties have opted-out of a reasoned award.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 06:41:07 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Santos", "A. J.", ""]]}, {"id": "1911.13155", "submitter": "Kevin Kells", "authors": "Kevin Kells", "title": "A Proposed Practical Problem-Solving Framework for Multi-Stakeholder\n  Initiatives in Socio-Ecological Systems Based on a Model of the Human\n  Cognitive Problem-Solving Process", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A practical problem-solving framework is proposed for multi-stakeholder\ninitiative (MSI) problem-solving processes involving socio-ecological systems\n(SES), so-called wicked problems, based on insights borrowed from a model of\nthe individual human, cognitive problem-solving process. The disciplined\nfacilitation of the multi-stakeholder process, adhering to the steps recognized\nin the individual process, is meant to reduce confusion and conflict. Obtaining\na one- to three-sentence human-language description of the desired system\nstate, as a first step, is proposed in multi-stakeholder initiatives for\nreasons of goal congruence and trust building. The systematic,\nstakeholder-driven subdivision of obstacles into larger numbers of simpler\nobstacles is proposed in order to obtain a list of \"what needs to be done,\"\ninviting a more rational and goal-driven conversation with resource providers.\nFinally, obtaining and maintaining stakeholder buy-in over the course of the\nproblem-solving effort is reinforced by reflecting back to all stakeholders, as\na communication device, a dynamic, visual problem-solving model, taking into\naccount the diversity of cognitive and individual capacities within the\nstakeholder group in its presentation. Mathematical parameters for gauging\napplicability of the proposed framework are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 15:40:27 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Kells", "Kevin", ""]]}]