[{"id": "2006.00046", "submitter": "Khuong An Nguyen", "authors": "Khuong An Nguyen, Zhiyuan Luo, Chris Watkins", "title": "Epidemic contact tracing with smartphone sensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is widely considered as an effective procedure in the fight\nagainst epidemic diseases. However, one of the challenges for technology based\ncontact tracing is the high number of false positives, questioning its\ntrust-worthiness and efficiency amongst the wider population for mass adoption.\nTo this end, this paper proposes a novel, yet practical smartphone-based\ncontact tracing approach, employing WiFi and acoustic sound for relative\ndistance estimate, in addition to the air pressure and the magnetic field for\nambient environment matching. We present a model combining 6 smartphone\nsensors, prioritising some of them when certain conditions are met. We\nempirically verified our approach in various realistic environments to\ndemonstrate an achievement of up to 95% fewer false positives, and 62% more\naccurate than Bluetooth-only system. To the best of our knowledge, this paper\nwas one of the first work to propose a combination of smartphone sensors for\ncontact tracing.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 19:29:46 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 13:50:29 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Nguyen", "Khuong An", ""], ["Luo", "Zhiyuan", ""], ["Watkins", "Chris", ""]]}, {"id": "2006.00048", "submitter": "Ralf Mikut", "authors": "Ivan Kovynyov and Axel Buerck and Ralf Mikut", "title": "Design of Transformation Initiatives Implementing Organisational Agility\n  -- An Empirical Study", "comments": null, "journal-ref": "SN Bus Econ 1, 79 (2021)", "doi": "10.1007/s43546-021-00073-6", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This study uses 125 responses from companies of all sizes headquartered in\nGermany, Switzerland, France and UK to reveal perceptions of the drivers of\norganisational agility. It further investigates current understanding of\nmanaging principles of multiple organisational dimensions such as culture,\nvalues, leadership, organisational structure, processes and others to achieve\ngreater organisational agility. The data set is disaggregated into four major\nprofiles of agile organisations: laggards, execution specialists,\nexperimenters, and leaders. The approach to agile transformation is analysed by\neach of those profiles. While the positive effect from a more holistic approach\nis confirmed, leaders tend to focus more on processes and products rather than\nproject work. Respondents perceive that IT, product development and research\nare most agile functions within their organisations, while human resources,\nfinance and administration are considered being not agile. Further,\norganisations with higher levels of organisational agility tend use more than\none agile scaling framework. Implications on theories of agile transformations\nand organisational design are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 19:30:55 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Kovynyov", "Ivan", ""], ["Buerck", "Axel", ""], ["Mikut", "Ralf", ""]]}, {"id": "2006.00140", "submitter": "Cristian Candia", "authors": "M. P. Raveau, J. P. Couyoumdjian, C. Fuentes-Bravo, C.\n  Rodriguez-Sickert, Cristian Candia", "title": "Citizens at the forefront of the constitutional debate: Participation\n  determinants and emergent content in Chile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few decades, constitution-making processes have shifted from\nclosed elite writing to incorporating democratic mechanisms. Yet, little is\nknown about democratic participation in deliberative constitution-making\nprocesses. Here, we study a deliberative constituent process held by the\nChilean government between 2015 and 2016. The Chilean process had the highest\nlevel of citizen participation in the world ($204,402$ people, i.e., $1.3\\%$ of\nthe population) for such a process and covered $98\\%$ of the national\nterritory. In its participatory phase, people gathered in self-convoked groups\nof 10 to 30 members, and they collectively selected, deliberated, and wrote\ndown an argument on why the new constitution should include those social\nrights. To understand the citizen participation drivers in this volunteer\nprocess, we first identify the determinants at the municipality level. We find\nthe educational level, engagement in politics, support for the (left-wing)\ngovernment, and Internet access increased participation. In contrast,\npopulation density and the share of evangelical Christians decreased\nparticipation. Moreover, we do not find evidence of political manipulation on\ncitizen participation. In light of those determinants, we analyze the\ncollective selection of social rights, and the content produced during the\ndeliberative phase. The findings suggest that the knowledge embedded in cities,\nproxied using education levels and main economic activity, facilitates\ndeliberation about themes, concepts, and ideas. These results can inform the\norganization of new deliberative processes that involve voluntary citizen\nparticipation, from citizen consultations to constitution-making processes.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 00:47:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Raveau", "M. P.", ""], ["Couyoumdjian", "J. P.", ""], ["Fuentes-Bravo", "C.", ""], ["Rodriguez-Sickert", "C.", ""], ["Candia", "Cristian", ""]]}, {"id": "2006.00245", "submitter": "Parvathy Panicker", "authors": "Parvathy Panicker", "title": "Critical pedagogy in the implementation of educational technologies", "comments": "6 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a critical review of the challenges to the implementation\nof learning technologies with particular focus on developing countries. A\ncomprehensive literature review on learning technologies was undertaken for the\npurpose of understanding the challenges in developing countries. The research\nquestion is: what extent does education empower learners to be full\nparticipants in a socially democratic society? The literature review identified\n25 papers relevant to this topic. Challenges are interrelated and to bring\nabout changes in developing countries, this paper proposes two educational\ntechnology frameworks based on: 1. cultural conceptual framework, and 2.\nproblem-based constructivist psychology simulation model. The framework and\nsimulation model are both useful to guide practice and research.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 12:00:03 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Panicker", "Parvathy", ""]]}, {"id": "2006.00268", "submitter": "Yujie Hu", "authors": "Yujie Hu, Joni Downs", "title": "Measuring and Visualizing Place-Based Space-Time Job Accessibility", "comments": null, "journal-ref": "Journal of Transport Geography, 74, 278-288 (2019)", "doi": "10.1016/j.jtrangeo.2018.12.002", "report-no": null, "categories": "cs.CY econ.GN q-fin.EC stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Place-based accessibility measures, such as the gravity-based model, are\nwidely applied to study the spatial accessibility of workers to job\nopportunities in cities. However, gravity-based measures often suffer from\nthree main limitations: (1) they are sensitive to the spatial configuration and\nscale of the units of analysis, which are not specifically designed for\ncapturing job accessibility patterns and are often too coarse; (2) they omit\nthe temporal dynamics of job opportunities and workers in the calculation,\ninstead assuming that they remain stable over time; and (3) they do not lend\nthemselves to dynamic geovisualization techniques. In this paper, a new\nmethodological framework for measuring and visualizing place-based job\naccessibility in space and time is presented that overcomes these three\nlimitations. First, discretization and dasymetric mapping approaches are used\nto disaggregate counts of jobs and workers over specific time intervals to a\nfine-scale grid. Second, Shen (1998) gravity-based accessibility measure is\nmodified to account for temporal fluctuations in the spatial distributions of\nthe supply of jobs and the demand of workers and is used to estimate hourly job\naccessibility at each cell. Third, a four-dimensional volumetric rendering\napproach is employed to integrate the hourly job access estimates into a\nspace-time cube environment, which enables the users to interactively visualize\nthe space-time job accessibility patterns. The integrated framework is\ndemonstrated in the context of a case study of the Tampa Bay region of Florida.\nThe findings demonstrate the value of the proposed methodology in job\naccessibility analysis and the policy-making process.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 13:39:07 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hu", "Yujie", ""], ["Downs", "Joni", ""]]}, {"id": "2006.00271", "submitter": "Yujie Hu", "authors": "Georgios P. Balomenos, Yujie Hu, Jamie E. Padgett, Kyle Shelton", "title": "Impact of Coastal Hazards on Residents Spatial Accessibility to Health\n  Services", "comments": null, "journal-ref": "Journal of Infrastructure Systems, 25(4), 04019028 (2019)", "doi": "10.1061/(ASCE)IS.1943-555X.0000509", "report-no": null, "categories": "cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The mobility of residents and their access to essential services can be\nhighly affected by transportation network closures that occur during and after\ncoastal hazard events. Few studies have used geographic information systems\ncoupled with infrastructure vulnerability models to explore how spatial\naccessibility to goods and services shifts after a hurricane. Models that\nexplore spatial accessibility to health services are particularly lacking. This\nstudy provides a framework to examine how the disruption of transportation\nnetworks during and after a hurricane can impact a residents ability to access\nhealth services over time. Two different bridge closure conditions, inundation\nand structural failure, along with roadway inundation are used to quantify\npost-hurricane accessibility at short- and long-term temporal scales.\nInundation may close a bridge for hours or days, but a structural failure may\nclose a route for weeks or months. Both forms of closure are incorporated using\nprobabilistic vulnerability models coupled with GIS-based models to assess\nspatial accessibility in the aftermath of a coastal hazard. Harris County, an\narea in Southeastern Texas prone to coastal hazards, is used as a case study.\nThe results indicate changes in the accessibility scores of specific areas\ndepending on the temporal scale of interest and intensity of the hazard\nscenario. Sociodemographic indicators are also examined for the study region,\nrevealing the populations most likely to suffer from lack of accessibility.\nOverall, the presented framework helps to understand how both short-term\nfunctionality loss and long-term damage affect access to critical services such\nas health care after a hazard. This information, in turn, can shape decisions\nabout future mitigation and planning efforts, while the presented framework can\nbe expanded to other hazard-prone areas.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 13:47:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Balomenos", "Georgios P.", ""], ["Hu", "Yujie", ""], ["Padgett", "Jamie E.", ""], ["Shelton", "Kyle", ""]]}, {"id": "2006.00272", "submitter": "Yujie Hu", "authors": "Yujie Hu, Fahui Wang, Cecile Guin, Haojie Zhu", "title": "A Spatio-Temporal Kernel Density Estimation Framework for Predictive\n  Crime Hotspot Mapping and Evaluation", "comments": null, "journal-ref": "Applied Geography, 99, 89-97 (2018)", "doi": "10.1016/j.apgeog.2018.08.001", "report-no": null, "categories": "stat.AP cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive hotspot mapping plays a critical role in hotspot policing.\nExisting methods such as the popular kernel density estimation (KDE) do not\nconsider the temporal dimension of crime. Building upon recent works in related\nfields, this article proposes a spatio-temporal framework for predictive\nhotspot mapping and evaluation. Comparing to existing work in this scope, the\nproposed framework has four major features: (1) a spatio-temporal kernel\ndensity estimation (STKDE) method is applied to include the temporal component\nin predictive hotspot mapping, (2) a data-driven optimization technique, the\nlikelihood cross-validation, is used to select the most appropriate bandwidths,\n(3) a statistical significance test is designed to filter out false positives\nin the density estimates, and (4) a new metric, the predictive accuracy index\n(PAI) curve, is proposed to evaluate predictive hotspots at multiple areal\nscales. The framework is illustrated in a case study of residential burglaries\nin Baton Rouge, Louisiana in 2011, and the results validate its utility.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 13:51:05 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hu", "Yujie", ""], ["Wang", "Fahui", ""], ["Guin", "Cecile", ""], ["Zhu", "Haojie", ""]]}, {"id": "2006.00275", "submitter": "Yujie Hu", "authors": "Yujie Hu, Fahui Wang, Imam Xierali", "title": "Automated Delineation of Hospital Service Areas and Hospital Referral\n  Regions by Modularity Optimization", "comments": null, "journal-ref": "Health Services Research, 53(1), 236-255 (2018)", "doi": "10.1111/1475-6773.12616", "report-no": null, "categories": "stat.AP cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective. To develop an automated, data-driven, and scale-flexible method to\ndelineate HSAs and HRRs that are up-to-date, representative of all patients,\nand have the optimal localization of hospital visits. Data Sources. The 2011\nState Inpatient Database (SID) in Florida from the Healthcare Cost and\nUtilization Project (HCUP). Study Design. A network optimization method was\nused to redefine HSAs and HRRs by maximizing patient-to-hospital flows within\neach HSA/HRR while minimizing flows between them. We first constructed as many\nHSAs/HRRs as existing Dartmouth units in Florida, and then compared the two by\nvarious metrics. Next, we sought to derive the optimal numbers and\nconfigurations of HSAs/HRRs that best reflect the modularity of hospitalization\npatterns in Florida. Principal Findings. The HSAs/HRRs by our method are\nfavored over the Dartmouth units in balance of region size and market\nstructure, shape, and most importantly, local hospitalization. Conclusions. The\nnew method is automated, scale-flexible, and effective in capturing the natural\nstructure of healthcare system. It has great potential for applications in\ndelineating other healthcare service areas or in larger geographic regions.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 13:58:29 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hu", "Yujie", ""], ["Wang", "Fahui", ""], ["Xierali", "Imam", ""]]}, {"id": "2006.00365", "submitter": "Mohammadreza Tavakoli", "authors": "Mohammadreza Tavakoli, Ali Faraji, Stefan T. Mol, G\\'abor Kismih\\'ok", "title": "OER Recommendations to Support Career Development", "comments": "This paper has been accepted to be published in the proceedings of\n  IEEE Frontiers In Education (FIE) 2020 by IEEE Xplore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This Work in Progress Research paper departs from the recent, turbulent\nchanges in global societies, forcing many citizens to re-skill themselves to\n(re)gain employment. Learners therefore need to be equipped with skills to be\nautonomous and strategic about their own skill development. Subsequently,\nhigh-quality, on-line, personalized educational content and services are also\nessential to serve this high demand for learning content. Open Educational\nResources (OERs) have high potential to contribute to the mitigation of these\nproblems, as they are available in a wide range of learning and occupational\ncontexts globally. However, their applicability has been limited, due to low\nmetadata quality and complex quality control. These issues resulted in a lack\nof personalised OER functions, like recommendation and search. Therefore, we\nsuggest a novel, personalised OER recommendation method to match skill\ndevelopment targets with open learning content. This is done by: 1) using an\nOER quality prediction model based on metadata, OER properties, and content; 2)\nsupporting learners to set individual skill targets based on actual labour\nmarket information, and 3) building a personalized OER recommender to help\nlearners to master their skill targets. Accordingly, we built a prototype\nfocusing on Data Science related jobs, and evaluated this prototype with 23\ndata scientists in different expertise levels. Pilot participants used our\nprototype for at least 30 minutes and commented on each of the recommended\nOERs. As a result, more than 400 recommendations were generated and 80.9% of\nthe recommendations were reported as useful.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 21:01:54 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Tavakoli", "Mohammadreza", ""], ["Faraji", "Ali", ""], ["Mol", "Stefan T.", ""], ["Kismih\u00f3k", "G\u00e1bor", ""]]}, {"id": "2006.00373", "submitter": "Yifei Huang", "authors": "Yifei Huang", "title": "Situation Awareness and Information Fusion in Sales and Customer\n  Engagement: A Paradigm Shift", "comments": "2020 IEEE Conference on Cognitive and Computational Aspects of\n  Situation Management (CogSIMA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With today's savvy and empowered customers, sales requires more judgment and\nbecomes more cognitively intense than ever before. We argue that Situation\nAwareness (SA) is at the center of effective sales and customer engagement in\nthis new era, and Information Fusion (IF) is the key for developing the next\ngeneration of decision support systems for digital and AI transformation,\nleveraging the ubiquitous virtual presence of sales and customer engagement\nwhich provides substantially richer capacity to access information. We propose\na vision and path for the paradigm shift from Customer Relationship Management\n(CRM) to the new paradigm of IF. We argue this new paradigm solves major\nproblems of the current CRM paradigm: (1) it reduces the burden of manual data\nentry and enables more reliable, comprehensive and up-to-date data and\nknowledge, (2) it enhances individual and team SA and alleviates information\nsilos with increased knowledge transferability, and (3) it enables a more\npowerful ecosystem of applications by providing common shared layer of\ncomputable knowledge assets.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 21:53:26 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 01:15:21 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2020 04:20:14 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Huang", "Yifei", ""]]}, {"id": "2006.00421", "submitter": "Nil-Jana Akpinar", "authors": "Nil-Jana Akpinar, Aaditya Ramdas, Umut Acar", "title": "Analyzing Student Strategies In Blended Courses Using Clickstream Data", "comments": null, "journal-ref": "International Conference on Educational Data Mining 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Educational software data promises unique insights into students' study\nbehaviors and drivers of success. While much work has been dedicated to\nperformance prediction in massive open online courses, it is unclear if the\nsame methods can be applied to blended courses and a deeper understanding of\nstudent strategies is often missing. We use pattern mining and models borrowed\nfrom Natural Language Processing (NLP) to understand student interactions and\nextract frequent strategies from a blended college course. Fine-grained\nclickstream data is collected through Diderot, a non-commercial educational\nsupport system that spans a wide range of functionalities. We find that\ninteraction patterns differ considerably based on the assessment type students\nare preparing for, and many of the extracted features can be used for reliable\nperformance prediction. Our results suggest that the proposed hybrid NLP\nmethods can provide valuable insights even in the low-data setting of blended\ncourses given enough data granularity.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 03:01:00 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Akpinar", "Nil-Jana", ""], ["Ramdas", "Aaditya", ""], ["Acar", "Umut", ""]]}, {"id": "2006.00432", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Tania De Gasperis (1 and 3) ((1) Montreal AI\n  Ethics Institute, (2) Microsoft, (3) OCAD University)", "title": "Participatory Design to build better contact- and proximity-tracing apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the push for contact- and proximity-tracing solutions as a means to\nmanage the spread of the pandemic, there is a distrust between the citizens and\nauthorities that are deploying these solutions. The efficacy of the solutions\nrelies on meeting a minimum uptake threshold which is hitting a barrier because\nof a lack of trust and transparency in how these solutions are being developed.\nWe propose participatory design as a mechanism to evoke trust and explore how\nit might be applied to co-create technological solutions that not only meet the\nneeds of the users better but also expand their reach to underserved and\nhigh-risk communities. We also highlight the role of the bazaar model of\ndevelopment and complement that with quantitative and qualitative metrics for\nevaluating the solutions and convincing policymakers and other stakeholders in\nthe value of this approach with empirical evidence.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 04:30:45 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["De Gasperis", "Tania", "", "1 and 3"]]}, {"id": "2006.00529", "submitter": "Georgios Magklaras", "authors": "Georgios Magklaras, Lucia Nikolaia Lopez Bojorquez", "title": "A review of information security aspects of the emerging COVID-19\n  contact tracing mobile phone applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses the aspects of data reliability and user privacy for the\nemerging practice of mobile phone based contact tracing for the COVID-19\npandemic. Various countries and large technology companies have already used or\nplan to design and use mobile phone based solutions, in an effort to urgently\nexpedite the process of identifying people who may have been exposed to the\ndisease and limit its spread to the general population. However, serious\nconcerns have been raised both in terms of the validity of the collected data\nas well as the extent to which implemented approaches can breach the privacy of\nthe mobile phone users. This review examines the weaknesses of existing\nimplementations and concludes with specific recommendations that can contribute\ntowards increasing the safety of infrastructures that collect and process this\nkind of information, as well as the adoption and acceptance of these solutions\nfrom the public.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 14:10:14 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Magklaras", "Georgios", ""], ["Bojorquez", "Lucia Nikolaia Lopez", ""]]}, {"id": "2006.00577", "submitter": "Alessandro Ecclesie Agazzi", "authors": "Alessandro Ecclesie Agazzi", "title": "Phishing and Spear Phishing: examples in Cyber Espionage and techniques\n  to protect against them", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing attacks have become the most used technique in the online scams,\ninitiating more than 91% of cyberattacks, from 2012 onwards. This study reviews\nhow Phishing and Spear Phishing attacks are carried out by the phishers,\nthrough 5 steps which magnify the outcome, increasing the chance of success.\nThe focus will be also given on four different layers of protection against\nthese social engineering attacks, showing their strengths and weaknesses; the\nfirst and second layers consist of automated tools and decision-aid tools. the\nthird one is users' knowledge and expertise to deal with potential threats. The\nlast layer, defined as \"external\", will underline the importance of having a\nMulti-factor authentication, an effective way to provide an enhanced security,\ncreating a further layer of protection against Phishing and Spear Phishing.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 18:10:09 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Agazzi", "Alessandro Ecclesie", ""]]}, {"id": "2006.00592", "submitter": "Sahan Bulathwela", "authors": "Sahan Bulathwela, Mar\\'ia P\\'erez-Ortiz, Aldo Lipani, Emine Yilmaz and\n  John Shawe-Taylor", "title": "Predicting Engagement in Video Lectures", "comments": "In Proceedings of International Conference on Educational Data Mining\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of Open Educational Resources (OERs) in the recent years\ncreates the demand for scalable, automatic approaches to process and evaluate\nOERs, with the end goal of identifying and recommending the most suitable\neducational materials for learners. We focus on building models to find the\ncharacteristics and features involved in context-agnostic engagement (i.e.\npopulation-based), a seldom researched topic compared to other contextualised\nand personalised approaches that focus more on individual learner engagement.\nLearner engagement, is arguably a more reliable measure than popularity/number\nof views, is more abundant than user ratings and has also been shown to be a\ncrucial component in achieving learning outcomes. In this work, we explore the\nidea of building a predictive model for population-based engagement in\neducation. We introduce a novel, large dataset of video lectures for predicting\ncontext-agnostic engagement and propose both cross-modal and modality-specific\nfeature sets to achieve this task. We further test different strategies for\nquantifying learner engagement signals. We demonstrate the use of our approach\nin the case of data scarcity. Additionally, we perform a sensitivity analysis\nof the best performing model, which shows promising performance and can be\neasily integrated into an educational recommender system for OERs.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 19:28:16 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 15:33:02 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Bulathwela", "Sahan", ""], ["P\u00e9rez-Ortiz", "Mar\u00eda", ""], ["Lipani", "Aldo", ""], ["Yilmaz", "Emine", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "2006.01307", "submitter": "Adnan Iftekhar", "authors": "Adnan Iftekhar, Xiaohui Cui, Mir Hassan, Wasif Afzal", "title": "Application of Blockchain and Internet of Things to Ensure Tamper-Proof\n  Data Availability for Food Safety", "comments": "Journal of Food Quality, 2020", "journal-ref": null, "doi": "10.1155/2020/5385207", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Food supply chain plays a vital role in human health and food prices. Food\nsupply chain inefficiencies in terms of unfair competition and lack of\nregulations directly affect the quality of human life and increase food safety\nrisks. This work merges Hyperledger Fabric, an enterprise-ready blockchain\nplatform with existing conventional infrastructure, to trace a food package\nfrom farm to fork using an identity unique for each food package while keeping\nit uncomplicated. It keeps the records of business transactions that are\nsecured and accessible to stakeholders according to the agreed set of policies\nand rules without involving any centralized authority. This paper focuses on\nexploring and building an uncomplicated, low-cost solution to quickly link the\nexisting food industry at different geographical locations in a chain to track\nand trace the food in the market.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 23:03:40 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Iftekhar", "Adnan", ""], ["Cui", "Xiaohui", ""], ["Hassan", "Mir", ""], ["Afzal", "Wasif", ""]]}, {"id": "2006.01322", "submitter": "Gregorio P\\'erez Bernal", "authors": "Gregorio Perez Bernal, Luisa Toro Villegas, Mauricio Toro", "title": "Saber Pro success prediction model using decision tree based learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary objective of this report is to determine what influences the\nsuccess rates of students who have studied in Colombia, analyzing the Saber 11,\nthe test done at the last school year, some socioeconomic aspects and comparing\nthe Saber Pro results with the national average. The problem this faces is to\nfind what influences success, but it also provides an insight in the countries\neducation dynamics and predicts one's opportunities to be prosperous. The\nopposite situation to the one presented in this paper could be the desertion\nlevels, in the sense that by detecting what makes someone outstanding, these\nfactors can say what makes one unsuccessful. The solution proposed to solve\nthis problem was to implement a CART decision tree algorithm that helps to\npredict the probability that a student has of scoring higher than the mean\nvalue, based on different socioeconomic and academic factors, such as the\nprofession of the parents of the subject parents and the results obtained on\nSaber 11. It was discovered that one of the most influential factors is the\nscore in the Saber 11, on the topic of Social Studies, and that the gender of\nthe subject is not as influential as it is usually portrayed as. The algorithm\ndesigned provided significant insight into which factors most affect the\nprobability of success of any given person and if further pursued could be used\nin many given situations such as deciding which subject in school should be\ngiven more intensity to and academic curriculum in general.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 00:19:02 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Bernal", "Gregorio Perez", ""], ["Villegas", "Luisa Toro", ""], ["Toro", "Mauricio", ""]]}, {"id": "2006.01381", "submitter": "Shalinda Adikari Dr.", "authors": "Shalinda Adikari and Kaushik Dutta", "title": "Identifying Fake Profiles in LinkedIn", "comments": "N/A", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As organizations increasingly rely on professionally oriented networks such\nas LinkedIn (the largest such social network) for building business\nconnections, there is increasing value in having one's profile noticed within\nthe network. As this value increases, so does the temptation to misuse the\nnetwork for unethical purposes. Fake profiles have an adverse effect on the\ntrustworthiness of the network as a whole, and can represent significant costs\nin time and effort in building a connection based on fake information.\nUnfortunately, fake profiles are difficult to identify. Approaches have been\nproposed for some social networks; however, these generally rely on data that\nare not publicly available for LinkedIn profiles. In this research, we identify\nthe minimal set of profile data necessary for identifying fake profiles in\nLinkedIn, and propose an appropriate data mining approach for fake profile\nidentification. We demonstrate that, even with limited profile data, our\napproach can identify fake profiles with 87% accuracy and 94% True Negative\nRate, which is comparable to the results obtained based on larger data sets and\nmore expansive profile information. Further, when compared to approaches using\nsimilar amounts and types of data, our method provides an improvement of\napproximately 14% accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 04:15:20 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Adikari", "Shalinda", ""], ["Dutta", "Kaushik", ""]]}, {"id": "2006.01411", "submitter": "Myounggyu Won", "authors": "Lokesh Das and Myounggyu Won", "title": "D-ACC: Dynamic Adaptive Cruise Control for Highways with Ramps Based on\n  Deep Q-Learning", "comments": "Accepted for Publication in IEEE International Conference on Robotics\n  and Automation (ICRA) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Adaptive Cruise Control (ACC) system allows vehicles to maintain a desired\nheadway distance to a preceding vehicle automatically. It is increasingly\nadopted by commercial vehicles. Recent research demonstrates that the effective\nuse of ACC can improve the traffic flow through the adaptation of the headway\ndistance in response to the current traffic conditions. In this paper, we\ndemonstrate that a state-of-the-art intelligent ACC system performs poorly on\nhighways with ramps due to the limitation of the model-based approaches that do\nnot take into account appropriately the traffic dynamics on ramps in\ndetermining the optimal headway distance. We then propose a dynamic adaptive\ncruise control system (D-ACC) based on deep reinforcement learning that adapts\nthe headway distance effectively according to dynamically changing traffic\nconditions for both the main road and ramp to optimize the traffic flow.\nExtensive simulations are performed with a combination of a traffic simulator\n(SUMO) and vehicle-to-everything communication (V2X) network simulator (Veins)\nunder numerous traffic scenarios. We demonstrate that D-ACC improves the\ntraffic flow by up to 70% compared with a state-of-the-art intelligent ACC\nsystem in a highway segment with a ramp.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:28:15 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 02:02:26 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 20:09:24 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 01:51:54 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Das", "Lokesh", ""], ["Won", "Myounggyu", ""]]}, {"id": "2006.01447", "submitter": "Kaicheng Yang", "authors": "Kai-Cheng Yang, Pik-Mai Hui, Filippo Menczer", "title": "How Twitter Data Sampling Biases U.S. Voter Behavior Characterizations", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social media are key platforms for the public to discuss political\nissues. As a result, researchers have used data from these platforms to analyze\npublic opinions and forecast election results. Recent studies reveal the\nexistence of inauthentic actors such as malicious social bots and trolls,\nsuggesting that not every message is a genuine expression from a legitimate\nuser. However, the prevalence of inauthentic activities in social data streams\nis still unclear, making it difficult to gauge biases of analyses based on such\ndata. In this paper, we aim to close this gap using Twitter data from the 2018\nU.S. midterm elections. Hyperactive accounts are over-represented in volume\nsamples. We compare their characteristics with those of randomly sampled\naccounts and self-identified voters using a fast and low-cost heuristic. We\nshow that hyperactive accounts are more likely to exhibit various suspicious\nbehaviors and share low-credibility information compared to likely voters.\nRandom accounts are more similar to likely voters, although they have slightly\nhigher chances to display suspicious behaviors. Our work provides insights into\nbiased voter characterizations when using online observations, underlining the\nimportance of accounting for inauthentic actors in studies of political issues\nbased on social media data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 08:33:30 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Yang", "Kai-Cheng", ""], ["Hui", "Pik-Mai", ""], ["Menczer", "Filippo", ""]]}, {"id": "2006.01523", "submitter": "Stefan Hochwarter", "authors": "Stefan Hochwarter, Pierre Tangermann, Martin Heinze, Julian Schwarz", "title": "Psychiatric Home Treatment for Inpatient Care -- Design, Implementation\n  and Participation", "comments": null, "journal-ref": "Vol. 27 No. 1 (2019): Proceedings from the annual NOKOBIT\n  conference held in Narvik 26-27 November 2019", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of information and communication technologies (ICT) to support\nlong-term care is gaining attention, also in the light of population ageing.\nKnown in Scandinavian countries under the term of welfare technology, it aims\nto increase the quality of life and independence of people with physical,\npsychological or social impairments. In Germany, a new form of psychiatric home\ntreatment, inpatient equivalent treatment (IET), is offered since 2018. It\nshould allow service users with severe mental health issues to stay in their\nfamiliar environment during crisis, while being treated in the same complexity\nand flexibility like in an inpatient unit. However, this change in delivering\nhealthcare services leads to sociotechnical challenges, such as coordination of\nwork, integration into existing healthcare workflows and ensuring continuity of\ncare. Hence, the objective of this exploratory study is to examine how\ninformation and communication technologies (ICT) interact in the new setting\nand how this process can be improved. Further, we also ask how service users\ncan participate in designing home treatment services. Methodologically, this\nstudy follows a qualitative research approach. Different methods including\nparticipant observation, interviews and focus groups were conducted to answer\nthe research questions. Data was collected during a field visit at the\npsychiatric department of a German clinic in summer 2019. Field notes and\ninterviews were analyzed using the R package for qualitative data analysis\nRQDA. A list of socio-technical challenges and opportunities related to IET\nwere identified. New forms of communication, gaps in documentation practices\nand continuity of care are seen to be highly relevant for designing and\nimplementing home treatment services in psychiatric care. We also discuss how\nservice users and health professionals can take pro-active part in designing\nthese services.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 11:17:42 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Hochwarter", "Stefan", ""], ["Tangermann", "Pierre", ""], ["Heinze", "Martin", ""], ["Schwarz", "Julian", ""]]}, {"id": "2006.01638", "submitter": "Yujie Hu", "authors": "Yujie Hu, Fahui Wang", "title": "Decomposing Excess Commuting: A Monte Carlo Simulation Approach", "comments": null, "journal-ref": "Journal of Transport Geography, 44, 43-52 (2015)", "doi": "10.1016/j.jtrangeo.2015.03.002", "report-no": null, "categories": "physics.soc-ph cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Excess or wasteful commuting is measured as the proportion of actual commute\nthat is over minimum (optimal) commute when assuming that people could freely\nswap their homes and jobs in a city. Studies usually rely on survey data to\ndefine actual commute, and measure the optimal commute at an aggregate zonal\nlevel by linear programming (LP). Travel time from a survey could include\nreporting errors and respondents might not be representative of the areas they\nreside; and the derived optimal commute at an aggregate areal level is also\nsubject to the zonal effect. Both may bias the estimate of excess commuting.\nBased on the 2006-2010 Census for Transportation Planning Package (CTPP) data\nin Baton Rouge, Louisiana, this research uses a Monte Carlo approach to\nsimulate individual resident workers and individual jobs within census tracts,\nestimate commute distance and time from journey-to-work trips, and define the\noptimal commute based on simulated individual locations. Findings indicate that\nboth reporting errors and the use of aggregate zonal data contribute to\nmiscalculation of excess commuting.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 14:09:06 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Hu", "Yujie", ""], ["Wang", "Fahui", ""]]}, {"id": "2006.01673", "submitter": "Corrado Monti", "authors": "Corrado Monti, Gianmarco De Francisci Morales, Francesco Bonchi", "title": "Learning Opinion Dynamics From Social Traces", "comments": "Published at KDD2020", "journal-ref": "Proceedings of the 26th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (KDD2020)", "doi": "10.1145/3394486.3403119", "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion dynamics - the research field dealing with how people's opinions form\nand evolve in a social context - traditionally uses agent-based models to\nvalidate the implications of sociological theories. These models encode the\ncausal mechanism that drives the opinion formation process, and have the\nadvantage of being easy to interpret. However, as they do not exploit the\navailability of data, their predictive power is limited. Moreover, parameter\ncalibration and model selection are manual and difficult tasks.\n  In this work we propose an inference mechanism for fitting a generative,\nagent-like model of opinion dynamics to real-world social traces. Given a set\nof observables (e.g., actions and interactions between agents), our model can\nrecover the most-likely latent opinion trajectories that are compatible with\nthe assumptions about the process dynamics. This type of model retains the\nbenefits of agent-based ones (i.e., causal interpretation), while adding the\nability to perform model selection and hypothesis testing on real data.\n  We showcase our proposal by translating a classical agent-based model of\nopinion dynamics into its generative counterpart. We then design an inference\nalgorithm based on online expectation maximization to learn the latent\nparameters of the model. Such algorithm can recover the latent opinion\ntrajectories from traces generated by the classical agent-based model. In\naddition, it can identify the most likely set of macro parameters used to\ngenerate a data trace, thus allowing testing of sociological hypotheses.\nFinally, we apply our model to real-world data from Reddit to explore the\nlong-standing question about the impact of backfire effect. Our results suggest\na low prominence of the effect in Reddit's political conversation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 14:48:17 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Monti", "Corrado", ""], ["Morales", "Gianmarco De Francisci", ""], ["Bonchi", "Francesco", ""]]}, {"id": "2006.01770", "submitter": "Lily Hu", "authors": "Lily Hu and Issa Kohler-Hausmann", "title": "What's Sex Got To Do With Fair Machine Learning?", "comments": "11 pages, 5 figures, ACM Conference on Fairness, Accountability, and\n  Transparency", "journal-ref": null, "doi": "10.1145/3351095.3375674", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debate about fairness in machine learning has largely centered around\ncompeting definitions of what fairness or nondiscrimination between groups\nrequires. However, little attention has been paid to what precisely a group is.\nMany recent approaches to \"fairness\" require one to specify a causal model of\nthe data generating process. These exercises make an implicit ontological\nassumption that a racial or sex group is simply a collection of individuals who\nshare a given trait. We show this by exploring the formal assumption of\nmodularity in causal models, which holds that the dependencies captured by one\ncausal pathway are invariant to interventions on any other pathways. Causal\nmodels of sex propose two substantive claims: 1) There exists a feature,\nsex-on-its-own, that is an inherent trait of an individual that causally brings\nabout social phenomena external to it in the world; and 2) the relations\nbetween sex and its effects can be modified in whichever ways and the former\nfeature would still retain the meaning that sex has in our world. We argue that\nthis ontological picture is false. Many of the \"effects\" that sex purportedly\n\"causes\" are in fact constitutive features of sex as a social status. They give\nthe social meaning of sex features, meanings that are precisely what make sex\ndiscrimination a distinctively morally problematic type of action. Correcting\nthis conceptual error has a number of implications for how models can be used\nto detect discrimination. Formal diagrams of constitutive relations present an\nentirely different path toward reasoning about discrimination. Whereas causal\ndiagrams guide the construction of sophisticated modular counterfactuals,\nconstitutive diagrams identify a different kind of counterfactual as central to\nan inquiry on discrimination: one that asks how the social meaning of a group\nwould be changed if its non-modular features were altered.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 16:51:39 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 22:54:18 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Hu", "Lily", ""], ["Kohler-Hausmann", "Issa", ""]]}, {"id": "2006.01855", "submitter": "Reid McIlroy-Young", "authors": "Reid McIlroy-Young and Siddhartha Sen and Jon Kleinberg and Ashton\n  Anderson", "title": "Aligning Superhuman AI with Human Behavior: Chess as a Model System", "comments": "11 pages, 11 figure, Proceedings of the 25th ACM SIGKDD international\n  conference on Knowledge discovery and data mining, Virtual 2020", "journal-ref": null, "doi": "10.1145/3394486.3403219", "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As artificial intelligence becomes increasingly intelligent---in some cases,\nachieving superhuman performance---there is growing potential for humans to\nlearn from and collaborate with algorithms. However, the ways in which AI\nsystems approach problems are often different from the ways people do, and thus\nmay be uninterpretable and hard to learn from. A crucial step in bridging this\ngap between human and artificial intelligence is modeling the granular actions\nthat constitute human behavior, rather than simply matching aggregate human\nperformance.\n  We pursue this goal in a model system with a long history in artificial\nintelligence: chess. The aggregate performance of a chess player unfolds as\nthey make decisions over the course of a game. The hundreds of millions of\ngames played online by players at every skill level form a rich source of data\nin which these decisions, and their exact context, are recorded in minute\ndetail. Applying existing chess engines to this data, including an open-source\nimplementation of AlphaZero, we find that they do not predict human moves well.\n  We develop and introduce Maia, a customized version of Alpha-Zero trained on\nhuman chess games, that predicts human moves at a much higher accuracy than\nexisting engines, and can achieve maximum accuracy when predicting decisions\nmade by players at a specific skill level in a tuneable way. For a dual task of\npredicting whether a human will make a large mistake on the next move, we\ndevelop a deep neural network that significantly outperforms competitive\nbaselines. Taken together, our results suggest that there is substantial\npromise in designing artificial intelligence systems with human collaboration\nin mind by first accurately modeling granular human decision-making.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 18:12:52 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 17:24:52 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2020 17:57:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["McIlroy-Young", "Reid", ""], ["Sen", "Siddhartha", ""], ["Kleinberg", "Jon", ""], ["Anderson", "Ashton", ""]]}, {"id": "2006.01908", "submitter": "Ashok Goel", "authors": "Ashok Goel", "title": "AI-Powered Learning: Making Education Accessible, Affordable, and\n  Achievable", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed an AI-powered socio-technical system for making online\nlearning in higher education more accessible, affordable and achievable. In\nparticular, we have developed four novel and intertwined AI technologies: (1)\nVERA, a virtual experimentation research assistant for supporting inquiry-based\nlearning of scientific knowledge, (2) Jill Watson Q&A, a virtual teaching\nassistant for answering questions based on educational documents including the\nVERA user reference guide, (3) Jill Watson SA, a virtual social agent that\npromotes online interactions, and (4) Agent Smith, that helps generate a Jill\nWatson Q&A agent for new documents such as class syllabi. The results are\npositive: (i) VERA enhances ecological knowledge and is freely available\nonline; (ii) Jill Watson Q&A has been used by >4,000 students in >12 online\nclasses and saved teachers >500 hours of work; (iii) Jill Q&A and Jill Watson\nSA promote learner engagement, interaction, and community; and (iv). Agent\nSmith helps generate Jill Watson Q&A for a new syllabus within ~25 hours. Put\ntogether, these innovative technologies help make online learning\nsimultaneously more accessible (by making materials available online),\naffordable (by saving teacher time), and achievable (by providing learning\nassistance and fostering student engagement).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 19:41:52 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Goel", "Ashok", ""]]}, {"id": "2006.01974", "submitter": "Joshua Garland", "authors": "Joshua Garland and Keyan Ghazi-Zahedi and Jean-Gabriel Young and\n  Laurent H\\'ebert-Dufresne and Mirta Galesic", "title": "Countering hate on social media: Large scale classification of hate and\n  counter speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hateful rhetoric is plaguing online discourse, fostering extreme societal\nmovements and possibly giving rise to real-world violence. A potential solution\nto this growing global problem is citizen-generated counter speech where\ncitizens actively engage in hate-filled conversations to attempt to restore\ncivil non-polarized discourse. However, its actual effectiveness in curbing the\nspread of hatred is unknown and hard to quantify. One major obstacle to\nresearching this question is a lack of large labeled data sets for training\nautomated classifiers to identify counter speech. Here we made use of a unique\nsituation in Germany where self-labeling groups engaged in organized online\nhate and counter speech. We used an ensemble learning algorithm which pairs a\nvariety of paragraph embeddings with regularized logistic regression functions\nto classify both hate and counter speech in a corpus of millions of relevant\ntweets from these two groups. Our pipeline achieved macro F1 scores on out of\nsample balanced test sets ranging from 0.76 to 0.97---accuracy in line and even\nexceeding the state of the art. On thousands of tweets, we used crowdsourcing\nto verify that the judgments made by the classifier are in close alignment with\nhuman judgment. We then used the classifier to discover hate and counter speech\nin more than 135,000 fully-resolved Twitter conversations occurring from 2013\nto 2018 and study their frequency and interaction. Altogether, our results\nhighlight the potential of automated methods to evaluate the impact of\ncoordinated counter speech in stabilizing conversations on social media.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 23:12:52 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 00:47:30 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 20:38:27 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Garland", "Joshua", ""], ["Ghazi-Zahedi", "Keyan", ""], ["Young", "Jean-Gabriel", ""], ["H\u00e9bert-Dufresne", "Laurent", ""], ["Galesic", "Mirta", ""]]}, {"id": "2006.02136", "submitter": "Noble Mathews", "authors": "Noble Saji Mathews, Sridhar Chimalakonda, Suresh Jain", "title": "AiR -- An Augmented Reality Application for Visualizing Air Pollution", "comments": "18 pages and 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Air quality is a term used to describe the concentration levels of various\npollutants in the air we breathe. The air quality, which is degrading rapidly\nacross the globe, has been a source of great concern. Across the globe,\ngovernments are taking various measures to reduce air pollution. Bringing\nawareness about environmental pollution among the public plays a major role in\ncontrolling air pollution, as the programs proposed by governments require the\nsupport of the public. Though information on air quality is present on multiple\nportals such as the Central Pollution Control Board (CPCB), which provides Air\nQuality Index that could be accessed by the public. However, such portals are\nscarcely visited by the general public. Visualizing air quality in the location\nwhere an individual resides could help in bringing awareness among the public.\nThis visualization could be rendered using Augmented Reality techniques.\nConsidering the widespread usage of Android based mobile devices in India, and\nthe importance of air quality visualization, we present AiR, as an Android\nbased mobile application. AiR considers the air quality measured by CPCB, in a\nlocality that is detected by the user's GPS or in a locality of user's choice,\nand visualizes various air pollutants present in the locality $(PM_1{}_0,\nPM_2{}_.{}_5, NO_2, SO_2, CO, O_3 \\& NH_3)$ and displays them in the user's\nsurroundings. AiR also creates awareness in an interactive manner about the\ndifferent pollutants, sources, and their impacts on health.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 10:03:47 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Mathews", "Noble Saji", ""], ["Chimalakonda", "Sridhar", ""], ["Jain", "Suresh", ""]]}, {"id": "2006.02181", "submitter": "Gabriele Etta", "authors": "Gabriele Etta, Alessandro Galeazzi, Matteo Cinelli, Mauro Conti,\n  Walter Quattrociocchi", "title": "Information Consumption and Social Response in a Segregated Environment:\n  the Case of Gab", "comments": "The paper is now replaced with an updated version: arXiv:2106.03924", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the information operations involve users who may foster polarization\nand distrust toward science and mainstream journalism, without these users\nbeing conscious of their role. Gab is well known to be an extremist-friendly\nplatform that performs little control on the posted content. Thus it represents\nan ideal benchmark for studying phenomena potentially related to polarization\nsuch as misinformation spreading. The combination of these factors may lead to\nhate as well as to episodes of harm in the real world. In this work we provide\na characterization of the interaction patterns within Gab around the COVID-19\ntopic. To assess the spreading of different content type, we analyze\nconsumption patterns based on both interaction type and source reliability.\nOverall we find that there are no strong statistical differences in the social\nresponse to questionable and reliable content, both following a power law\ndistribution. However, questionable and reliable sources display structural and\ntopical differences in the use of hashtags. The commenting behaviour of users\nin terms of both lifetime and sentiment reveals that questionable and reliable\nposts are perceived in the same manner. We can conclude that despite evident\ndifferences between questionable and reliable posts Gab users do not perform\nsuch a differentiation thus treating them as a whole. Our results provide\ninsights toward the understanding of coordinated inauthentic behavior and on\nthe early-warning of information operation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 11:34:25 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 16:33:20 GMT"}, {"version": "v3", "created": "Mon, 19 Jul 2021 15:14:39 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Etta", "Gabriele", ""], ["Galeazzi", "Alessandro", ""], ["Cinelli", "Matteo", ""], ["Conti", "Mauro", ""], ["Quattrociocchi", "Walter", ""]]}, {"id": "2006.02197", "submitter": "Essam Rashed", "authors": "Essam A. Rashed, Sachiko Kodera, Jose Gomez-Tames, Akimasa Hirata", "title": "Influence of Absolute Humidity, Temperature and Population Density on\n  COVID-19 Spread and Decay Durations: Multi-prefecture Study in Japan", "comments": "Submitted to: International Journal of Environmental Research and\n  Public Health", "journal-ref": "Int. J. Environ. Res. Public Health, 2020", "doi": "10.3390/ijerph17155354", "report-no": "vol. 17, number 15, pp. 5354", "categories": "q-bio.PE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study analyzed the spread and decay durations of the COVID-19 pandemic\nin different prefectures of Japan. During the pandemic, affordable healthcare\nwas widely available in Japan and the medical system did not suffer a collapse,\nmaking accurate comparisons between prefectures possible. For the 16\nprefectures included in this study that had daily maximum confirmed cases\nexceeding ten, the number of daily confirmed cases follow bell-shape or\nlog-normal distribution in most prefectures. A good correlation was observed\nbetween the spread and decay durations. However, some exceptions were observed\nin areas where travelers returned from foreign countries, which were defined as\nthe origins of infection clusters. Excluding these prefectures, the population\ndensity was shown to be a major factor affecting the spread and decay patterns,\nwith R2=0.39 (p<0.05) and 0.42 (p<0.05), respectively, approximately\ncorresponding to social distancing. The maximum absolute humidity was found to\naffect the decay duration normalized by the population density (R2>0.36, p\n<0.05). Our findings indicate that the estimated pandemic spread duration,\nbased on the multivariate analysis of maximum absolute humidity, ambient\ntemperature, and population density (adjusted R2=0.53, p-value<0.05), could\nprove useful for intervention planning during potential future pandemics,\nincluding a second COVID-19 outbreak.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 12:10:17 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 12:40:09 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Rashed", "Essam A.", ""], ["Kodera", "Sachiko", ""], ["Gomez-Tames", "Jose", ""], ["Hirata", "Akimasa", ""]]}, {"id": "2006.02254", "submitter": "Yujie Hu", "authors": "Yujie Hu, Fahui Wang", "title": "Temporal Trends of Intraurban Commuting in Baton Rouge 1990-2010", "comments": null, "journal-ref": "Annals of the American Association of Geographers, 106(2), 470-479\n  (2016)", "doi": "10.1080/00045608.2015.1113117", "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Based on the 1990-2010 CTPP data in Baton Rouge, this research analyzes the\ntemporal trends of commuting patterns in both time and distance. In comparison\nto previous work, commuting length is calibrated more accurately by Monte Carlo\nbased simulation of individual journey-to-work trips to mitigate the zonal\neffect. First, average commute distance kept climbing in 1990-2010 while\naverage commute time increased in 1990-2000 but then slightly dropped toward\n2010. Secondly, urban land use remained a good predictor of commuting pattern\nover time (e.g., explaining up to 90% of mean commute distance and about 30% of\nmean commute time). Finally, the percentage of excess commuting increased\nsignificantly in 1990-2000 and stabilized afterwards.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 14:07:38 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Hu", "Yujie", ""], ["Wang", "Fahui", ""]]}, {"id": "2006.02371", "submitter": "Johannes Wachs", "authors": "Lukas Moldon, Markus Strohmaier, Johannes Wachs", "title": "How Gamification Affects Software Developers: Cautionary Evidence from a\n  Natural Experiment on GitHub", "comments": "To appear in the proceedings of the 2021 IEEE/ACM 43rd International\n  Conference on Software Engineering (ICSE)", "journal-ref": null, "doi": "10.1109/ICSE43902.2021.00058", "report-no": null, "categories": "cs.SE cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We examine how the behavior of software developers changes in response to\nremoving gamification elements from GitHub, an online platform for\ncollaborative programming and software development. We find that the\nunannounced removal of daily activity streak counters from the user interface\n(from user profile pages) was followed by significant changes in behavior.\nLong-running streaks of activity were abandoned and became less common. Weekend\nactivity decreased and days in which developers made a single contribution\nbecame less common. Synchronization of streaking behavior in the platform's\nsocial network also decreased, suggesting that gamification is a powerful\nchannel for social influence. Focusing on a set of software developers that\nwere publicly pursuing a goal to make contributions for 100 days in a row, we\nfind that some of these developers abandon this quest following the removal of\nthe public streak counter. Our findings provide evidence for the significant\nimpact of gamification on the behavior of developers on large collaborative\nprogramming and software development platforms. They urge caution: gamification\ncan steer the behavior of software developers in unexpected and unwanted\ndirections.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 16:35:47 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 09:44:34 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 14:36:19 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Moldon", "Lukas", ""], ["Strohmaier", "Markus", ""], ["Wachs", "Johannes", ""]]}, {"id": "2006.02416", "submitter": "Anthony Luo", "authors": "Anthony Luo and Dianxiang Xu", "title": "Assessing Holistic Impacts of Major Events on the Bitcoin Blockchain\n  Network", "comments": "23 pages, 20 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the pioneer of blockchain technology, Bitcoin is the most popular\ncryptocurrency to date. Given its dramatic price spikes (and crashes) along\nwith the never-ending news from SEC regulations to security breaches, there\nseems to be a lack of understanding about the dynamics of cryptocurrencies.\nThese dynamics are believed to be affected by various political, security,\nfinancial, and regulatory events. In this paper, we present an efficient\nframework for holistic analysis of cryptocurrency fluctuations by introducing\nthe Impact-Score metric to distinguish event-induced changes from normal\nvariations. We have applied our framework to 16 major worldwide events and the\nBitcoin blockchain network (defined as Bitcoin transaction and users,\nblockchain data, and memory pool data) from 2016-2018. The results show that a\nmajority of the events are correlated with substantial network changes. We\nobserved roughly generalizable correlations between event types (e.g. financial\nevents) and sub-structures of the Bitcoin blockchain network. Subgroups of\nthese events have strongly consistent temporal impacts on specific facets (e.g.\nactivity or fees) of the Bitcoin ecosystem. Furthermore, we demonstrate the\nrobustness of our process by correlating a majority of spikes in\nnetwork/subnetwork change with major events.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 17:46:23 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Luo", "Anthony", ""], ["Xu", "Dianxiang", ""]]}, {"id": "2006.02456", "submitter": "Pavlos Papadopoulos", "authors": "Will Abramson, Adam James Hall, Pavlos Papadopoulos, Nikolaos\n  Pitropakis, William J Buchanan", "title": "A Distributed Trust Framework for Privacy-Preserving Machine Learning", "comments": "To be published in the proceedings of the 17th International\n  Conference on Trust, Privacy and Security in Digital Business - TrustBus2020", "journal-ref": "17th International Conference TrustBus 2020", "doi": "10.1007/978-3-030-58986-8_14", "report-no": "TrustBus 2020, LNCS 12395, pp. 205--220, 2020", "categories": "cs.CR cs.CY cs.DC cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training a machine learning model, it is standard procedure for the\nresearcher to have full knowledge of both the data and model. However, this\nengenders a lack of trust between data owners and data scientists. Data owners\nare justifiably reluctant to relinquish control of private information to third\nparties. Privacy-preserving techniques distribute computation in order to\nensure that data remains in the control of the owner while learning takes\nplace. However, architectures distributed amongst multiple agents introduce an\nentirely new set of security and trust complications. These include data\npoisoning and model theft. This paper outlines a distributed infrastructure\nwhich is used to facilitate peer-to-peer trust between distributed agents;\ncollaboratively performing a privacy-preserving workflow. Our outlined\nprototype sets industry gatekeepers and governance bodies as credential\nissuers. Before participating in the distributed learning workflow, malicious\nactors must first negotiate valid credentials. We detail a proof of concept\nusing Hyperledger Aries, Decentralised Identifiers (DIDs) and Verifiable\nCredentials (VCs) to establish a distributed trust architecture during a\nprivacy-preserving machine learning experiment. Specifically, we utilise secure\nand authenticated DID communication channels in order to facilitate a federated\nlearning workflow related to mental health care data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 18:06:13 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Abramson", "Will", ""], ["Hall", "Adam James", ""], ["Papadopoulos", "Pavlos", ""], ["Pitropakis", "Nikolaos", ""], ["Buchanan", "William J", ""]]}, {"id": "2006.02471", "submitter": "Julio C. S. Reis", "authors": "Julio C. S. Reis, Philipe de Freitas Melo, Kiran Garimella, Fabr\\'icio\n  Benevenuto", "title": "Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?", "comments": "This is a preprint version of an accepted manuscript on The Harvard\n  Kennedy School (HKS) Misinformation Review. Please, consider to cite it\n  instead of this one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WhatsApp was alleged to be widely used to spread misinformation and\npropaganda during elections in Brazil and India. Due to the private encrypted\nnature of the messages on WhatsApp, it is hard to track the dissemination of\nmisinformation at scale. In this work, using public WhatsApp data, we observe\nthat misinformation has been largely shared on WhatsApp public groups even\nafter they were already fact-checked by popular fact-checking agencies. This\nrepresents a significant portion of misinformation spread in both Brazil and\nIndia in the groups analyzed. We posit that such misinformation content could\nbe prevented if WhatsApp had a means to flag already fact-checked content. To\nthis end, we propose an architecture that could be implemented by WhatsApp to\ncounter such misinformation. Our proposal respects the current end-to-end\nencryption architecture on WhatsApp, thus protecting users' privacy while\nproviding an approach to detect the misinformation that benefits from\nfact-checking efforts.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 18:28:57 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 03:11:38 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Reis", "Julio C. S.", ""], ["Melo", "Philipe de Freitas", ""], ["Garimella", "Kiran", ""], ["Benevenuto", "Fabr\u00edcio", ""]]}, {"id": "2006.02472", "submitter": "Qing Ke", "authors": "Qing Ke", "title": "Technological impact of biomedical research: the role of basicness and\n  novelty", "comments": null, "journal-ref": "Research Policy 49, 104071 (2020)", "doi": "10.1016/j.respol.2020.104071", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ongoing interest in innovation studies is to understand how knowledge\ngenerated from scientific research can be used in the development of\ntechnologies. While previous inquiries have devoted to studying the scientific\ncapacity of technologies and institutional factors facilitating technology\ntransfer, little is known about the intrinsic characteristics of scientific\npublications that gain direct technological impact. Here we focus on two\nfeatures, namely basicness and novelty. Using a corpus of 3.8 million papers\npublished between 1980 and 1999, we find that basic science papers and novel\npapers are substantially more likely to achieve direct technological impact.\nFurther analysis that limits to papers with technological impact reveals that\nbasic science and novel science have more patent citations, experience shorter\ntime lag, and have impact in broader technological fields.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 18:31:05 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Ke", "Qing", ""]]}, {"id": "2006.02577", "submitter": "Mark Tygert", "authors": "Isabel Kloumann and Mark Tygert", "title": "An optimizable scalar objective value cannot be objective and should not\n  be the sole objective", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG cs.SY eess.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the ethics and morality of algorithms and computational\nsystems, and has been circulating internally at Facebook for the past couple\nyears. The paper reviews many Nobel laureates' work, as well as the work of\nother prominent scientists such as Richard Dawkins, Andrei Kolmogorov, Vilfredo\nPareto, and John von Neumann. The paper draws conclusions based on such works,\nas summarized in the title. The paper argues that the standard approach to\nmodern machine learning and artificial intelligence is bound to be biased and\nunfair, and that longstanding traditions in the professions of law, justice,\npolitics, and medicine should help.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 23:10:38 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Kloumann", "Isabel", ""], ["Tygert", "Mark", ""]]}, {"id": "2006.02709", "submitter": "Niels {\\O}rb{\\ae}k Chemnitz", "authors": "Niels {\\O}rb{\\ae}k Chemnitz, Philippe Bonnet, Irina Shklovski,\n  Sebastian B\\\"uttrich and Laura Watts", "title": "Unionized Data Governance in Virtual Power Plants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flexible electricity networks continuously coordinate and optimize operations\nthrough ICT systems. An overlay data grid conveys information about the state\nof the electricity grid, as well as the status of demand and production of\nelectricity in households and industry. Data is thus the basis for decisions\nthat affect electricity costs and availability of assets on the electricity\ngrid. It is crucial that these decisions are formed and monitored according to\na well-defined governance model. No such data governance model exists today. In\nthis paper, we focus on the central role of virtual power plants in flexible\nelectricity networks. We define the problem of data governance in a virtual\npower plant, insisting on the issues linked to the inherent asymmetry of this\nsystem. We propose unionization as a framing device to reason about this issue.\nThe central contribution of this paper is thus principles for a unionized data\ngovernance model for virtual power plants.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 09:03:26 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Chemnitz", "Niels \u00d8rb\u00e6k", ""], ["Bonnet", "Philippe", ""], ["Shklovski", "Irina", ""], ["B\u00fcttrich", "Sebastian", ""], ["Watts", "Laura", ""]]}, {"id": "2006.02825", "submitter": "Dirk Helbing", "authors": "Indushree Banerjee, Martijn Warnier, Frances M.T. Brazier, and Dirk\n  Helbing", "title": "SOS -- Self-Organization for Survival: Introducing fairness in emergency\n  communication to save lives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cond-mat.dis-nn nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is crucial when disasters isolate communities of people and\nrescue is delayed. Such delays force citizens to be first responders and form\nsmall rescue teams. Rescue teams require reliable communication, particularly\nin the first 72 hours, which is challenging due to damaged infrastructure and\nelectrical blackouts. We design a peer-to-peer communication network that meets\nthese challenges. We introduce the concept of participatory fairness: equal\ncommunication opportunities for all citizens regardless of initial inequality\nin phone battery charge. Our value-sensitive design approach achieves an even\nbattery charge distribution across phones over time and enables citizens to\ncommunicate over 72 hours. We apply the fairness principle to communication in\nan adapted standard Barabasi-Albert model of a scale-free network that\nautomatically (i) assigns high-battery phones as hubs, (ii) adapts the network\ntopology to the spatio-temporal battery charge distribution, and (iii)\nself-organizes to remain robust and reliable when links fail or phones leave\nthe network. While the Barabasi-Albert model has become a widespread\ndescriptive model, we demonstrate its use as a design principle to meet values\nsuch as fairness and systemic efficiency. Our results demonstrate that,\ncompared to a generic peer-to-peer mesh network, the new protocol achieves (i)\na longer network lifetime, (ii) an adaptive information flow, (iii) a fair\ndistribution of battery charge, and (iv) higher participation rates. Hence, our\nprotocol, Self-Organization for Survival ('SOS'), provides fair communication\nopportunities to all citizens during a disaster through self-organization. SOS\nenables participatory resilience and sustainability, empowering citizens to\ncommunicate when they need it most.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 12:55:52 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Banerjee", "Indushree", ""], ["Warnier", "Martijn", ""], ["Brazier", "Frances M. T.", ""], ["Helbing", "Dirk", ""]]}, {"id": "2006.03023", "submitter": "Geoffrey Goodell", "authors": "Geoffrey Goodell, Hazem Danny Al-Nakib, Paolo Tasca", "title": "Digital Currency and Economic Crises: Helping States Respond", "comments": "32 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current crisis, at the time of writing, has had a profound impact on the\nfinancial world, introducing the need for creative approaches to revitalising\nthe economy at the micro level as well as the macro level. In this informal\nanalysis and design proposal, we describe how infrastructure for digital assets\ncan serve as a useful monetary and fiscal policy tool and an enabler of\nexisting tools in the future, particularly during crises, while aligning the\ntrajectory of financial technology innovation toward a brighter future. We\npropose an approach to digital currency that would allow people without banking\nrelationships to transact electronically and privately, including both internet\npurchases and point-of-sale purchases that are required to be cashless. We also\npropose an approach to digital currency that would allow for more efficient and\ntransparent clearing and settlement, implementation of monetary and fiscal\npolicy, and management of systemic risk. The digital currency could be\nimplemented as central bank digital currency (CBDC), or it could be issued by\nthe government and collateralised by public funds or Treasury assets. Our\nproposed architecture allows both manifestations and would be operated by banks\nand other money services businesses, operating within a framework overseen by\ngovernment regulators. We argue that now is the time for action to undertake\ndevelopment of such a system, not only because of the current crisis but also\nin anticipation of future crises resulting from geopolitical risks, the\ncontinued globalisation of the digital economy, and the changing value and\nrisks that technology brings.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 17:17:49 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 10:32:00 GMT"}, {"version": "v3", "created": "Sun, 2 Aug 2020 05:55:42 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Goodell", "Geoffrey", ""], ["Al-Nakib", "Hazem Danny", ""], ["Tasca", "Paolo", ""]]}, {"id": "2006.03096", "submitter": "Svetlana Kiritchenko", "authors": "Svetlana Kiritchenko, Will E. Hipson, Robert J. Coplan, Saif M.\n  Mohammad", "title": "SOLO: A Corpus of Tweets for Examining the State of Being Alone", "comments": "In Proceedings of the 12th edition of the Language Resources and\n  Evaluation Conference (LREC), May 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of being alone can have a substantial impact on our lives, though\nexperiences with time alone diverge significantly among individuals.\nPsychologists distinguish between the concept of solitude, a positive state of\nvoluntary aloneness, and the concept of loneliness, a negative state of\ndissatisfaction with the quality of one's social interactions. Here, for the\nfirst time, we conduct a large-scale computational analysis to explore how the\nterms associated with the state of being alone are used in online language. We\npresent SOLO (State of Being Alone), a corpus of over 4 million tweets\ncollected with query terms 'solitude', 'lonely', and 'loneliness'. We use SOLO\nto analyze the language and emotions associated with the state of being alone.\nWe show that the term 'solitude' tends to co-occur with more positive,\nhigh-dominance words (e.g., enjoy, bliss) while the terms 'lonely' and\n'loneliness' frequently co-occur with negative, low-dominance words (e.g.,\nscared, depressed), which confirms the conceptual distinctions made in\npsychology. We also show that women are more likely to report on negative\nfeelings of being lonely as compared to men, and there are more teenagers among\nthe tweeters that use the word 'lonely' than among the tweeters that use the\nword 'solitude'.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 18:46:02 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kiritchenko", "Svetlana", ""], ["Hipson", "Will E.", ""], ["Coplan", "Robert J.", ""], ["Mohammad", "Saif M.", ""]]}, {"id": "2006.03119", "submitter": "Jeremy Foote", "authors": "Jeremy Foote, Nathan TeBlunthuis, Benjamin Mako Hill, Aaron Shaw", "title": "How individual behaviors drive inequality in online community sizes: an\n  agent-based simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why are online community sizes so extremely unequal? Most answers to this\nquestion have pointed to general mathematical processes drawn from physics like\ncumulative advantage. These explanations provide little insight into specific\nsocial dynamics or decisions that individuals make when joining and leaving\ncommunities. In addition, explanations in terms of cumulative advantage do not\ndraw from the enormous body of social computing research that studies\nindividual behavior. Our work bridges this divide by testing whether two\ninfluential social mechanisms used to explain community joining can also\nexplain the distribution of community sizes. Using agent-based simulations, we\nevaluate how well individual-level processes of social exposure and decisions\nbased on individual expected benefits reproduce empirical community size data\nfrom Reddit. Our simulations contribute to social computing theory by providing\nevidence that both processes together---but neither alone---generate realistic\ndistributions of community sizes. Our results also illustrate the potential\nvalue of agent-based simulation to online community researchers to both\nevaluate and bridge individual and group-level theories.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 20:20:43 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Foote", "Jeremy", ""], ["TeBlunthuis", "Nathan", ""], ["Hill", "Benjamin Mako", ""], ["Shaw", "Aaron", ""]]}, {"id": "2006.03121", "submitter": "Nathan TeBlunthuis", "authors": "Nathan TeBlunthuis, Benjamin Mako Hill, Aaron Halfaker", "title": "Effects of algorithmic flagging on fairness: quasi-experimental evidence\n  from Wikipedia", "comments": "27 pages, 11 figures, ACM CSCW", "journal-ref": "Proc. ACM Hum.-Comput. Interact. 5, CSCW1, Article 56 (April\n  2021), 27 pages", "doi": "10.1145/3449130", "report-no": null, "categories": "cs.CY cs.HC cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Online community moderators often rely on social signals such as whether or\nnot a user has an account or a profile page as clues that users may cause\nproblems. Reliance on these clues can lead to overprofiling bias when\nmoderators focus on these signals but overlook the misbehavior of others. We\npropose that algorithmic flagging systems deployed to improve the efficiency of\nmoderation work can also make moderation actions more fair to these users by\nreducing reliance on social signals and making norm violations by everyone else\nmore visible. We analyze moderator behavior in Wikipedia as mediated by\nRCFilters, a system which displays social signals and algorithmic flags, and\nestimate the causal effect of being flagged on moderator actions. We show that\nalgorithmically flagged edits are reverted more often, especially those by\nestablished editors with positive social signals, and that flagging decreases\nthe likelihood that moderation actions will be undone. Our results suggest that\nalgorithmic flagging systems can lead to increased fairness in some contexts\nbut that the relationship is complex and contingent.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 20:25:44 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 00:14:34 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["TeBlunthuis", "Nathan", ""], ["Hill", "Benjamin Mako", ""], ["Halfaker", "Aaron", ""]]}, {"id": "2006.03131", "submitter": "Yujie Hu", "authors": "Yujie Hu, Yu Zhang, Kyle Shelton", "title": "Where are the Dangerous Intersections for Pedestrians and Cyclists: A\n  Colocation-Based Approach", "comments": null, "journal-ref": "Transportation Research Part C: Emerging Technologies, 95, 431-441\n  (2018)", "doi": "10.1016/j.trc.2018.07.030", "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pedestrians and cyclists are vulnerable road users. They are at greater risk\nfor being killed in a crash than other road users. The percentage of fatal\ncrashes that involve a pedestrian or cyclist is higher than the overall\npercentage of total trips taken by both modes. Because of this risk, finding\nways to minimize problematic street environments is critical. Understanding\ntraffic safety spatial patterns and identifying dangerous locations with\nsignificantly high crash risks for pedestrians and cyclists is essential in\norder to design possible countermeasures to improve road safety. This research\ndevelops two indicators for examining spatial correlation patterns between\nelements of the built environment (intersections) and crashes (pedestrian- or\ncyclist-involved). The global colocation quotient detects the overall\nconnection in an area while the local colocation quotient identifies the\nlocations of high-risk intersections. To illustrate our approach, we applied\nthe methods to inspect the colocation patterns between pedestrian- or\ncyclist-vehicle crashes and intersections in Houston, Texas and we identified\namong many intersections the ones that significantly attract crashes. We also\nscrutinized those intersections, discussed possible attributes leading to high\ncolocation of crashes and proposed corresponding countermeasures.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 13:54:43 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Hu", "Yujie", ""], ["Zhang", "Yu", ""], ["Shelton", "Kyle", ""]]}, {"id": "2006.03150", "submitter": "Mouhamed Abdulla Ph.D.", "authors": "Mouhamed Abdulla, Meagan Troop, Amjed Majeed", "title": "Framework for an Integrated Learning Block with CDIO-led Engineering\n  Education", "comments": "Proc. of the 16th International CDIO Conference (CDIO'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a CDIO collaborating member, the School of Mechanical and Electrical\nEngineering of Sheridan maintains a curriculum that is deeply rooted in\nskills-based learning, experiential learning, and engineering design. To ensure\nour graduates are agile and ready for the workforce, we are taking proactive\nmeasures to further improve their learning experiences. An important challenge\nstill impeding our students knowledge acquisition is the perception that\nprogram courses have disjointed learning outcomes. The course map of programs\nis carefully designed in such a way that technical skills acquired in\nparticular courses gradually build on each other. Despite the traditional\nexistence of prerequisites and co-requisites, the inaccurate view that courses\nfunction independently persists among students and, occasionally, among faculty\nmembers. One feasible approach to tackle this pedagogical challenge is to\ncombine various courses into an integrated learning block (ILB) having a\nunified mission and objective. At Sheridan's School of MEET, we are applying an\nILB with three engineering courses offered within the same semester for all our\nB.Eng. degree programs. The ILB deliverables are based on the design of a\nchosen engineering system or subunit in a project-based learning (PBL)\nenvironment. The rationale of this paper is to share our framework for\nimplementing an ILB in engineering programs and to examine the opportunities\nand challenges related to this type of curriculum design. In particular, we\nwill discuss the methodology by which courses are selected to form an ILB while\ntaking into account their appropriateness for an industry-driven PBL. This will\nbe followed up with some of the strategies that are proposed to evaluate the\nperformance of students in an ILB through formative and summative assessments\nbased on CDIO competencies.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 22:00:58 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Abdulla", "Mouhamed", ""], ["Troop", "Meagan", ""], ["Majeed", "Amjed", ""]]}, {"id": "2006.03296", "submitter": "Bal\\'azs Bazsalya", "authors": "Balazs Bazsalya", "title": "Certain characteristics of financial management strategies of people\n  living in extreme poverty", "comments": "37 pages, 6 tables, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This study presents the structure of financial management of incomes,\nexpenses, and borrowing practices of households in extreme poverty, based on a\nsurvey conducted in two disadvantaged regions in Hungary. Additional to that, I\nshed light on financial management practices of households in extreme poverty\nbased on the analysis of in-depth interviews. I draw theoretical conclusions\nand explanations, building upon the experiences of empiric materials about the\nattitudes and behaviors of financial management of households in extreme\npoverty, and the reasons and consequences thereof.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 08:28:12 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Bazsalya", "Balazs", ""]]}, {"id": "2006.03363", "submitter": "Amjad Ibrahim", "authors": "Amjad Ibrahim and Alexander Pretschner", "title": "From Checking to Inference: Actual Causality Computations as\n  Optimization Problems", "comments": "ATVA 2020 The 18th International Symposium on Automated Technology\n  for Verification and Analysis", "journal-ref": null, "doi": "10.1007/978-3-030-59152-6_19", "report-no": null, "categories": "cs.AI cs.CY cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Actual causality is increasingly well understood. Recent formal approaches,\nproposed by Halpern and Pearl, have made this concept mature enough to be\namenable to automated reasoning. Actual causality is especially vital for\nbuilding accountable, explainable systems. Among other reasons, causality\nreasoning is computationally hard due to the requirements of counterfactuality\nand the minimality of causes. Previous approaches presented either inefficient\nor restricted, and domain-specific, solutions to the problem of automating\ncausality reasoning. In this paper, we present a novel approach to formulate\ndifferent notions of causal reasoning, over binary acyclic models, as\noptimization problems, based on quantifiable notions within counterfactual\ncomputations. We contribute and compare two compact, non-trivial, and sound\ninteger linear programming (ILP) and Maximum Satisfiability (MaxSAT) encodings\nto check causality. Given a candidate cause, both approaches identify what a\nminimal cause is. Also, we present an ILP encoding to infer causality without\nrequiring a candidate cause. We show that both notions are efficiently\nautomated. Using models with more than $8000$ variables, checking is computed\nin a matter of seconds, with MaxSAT outperforming ILP in many cases. In\ncontrast, inference is computed in a matter of minutes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 10:56:52 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 11:28:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Ibrahim", "Amjad", ""], ["Pretschner", "Alexander", ""]]}, {"id": "2006.03385", "submitter": "Dilusha Weeraddana Dr", "authors": "Dilusha Weeraddana, Bin Liang, Zhidong Li, Yang Wang, Fang Chen, Livia\n  Bonazzi, Dean Phillips, Nitin Saxena", "title": "Utilizing machine learning to prevent water main breaks by understanding\n  pipeline failure drivers", "comments": "8 pages, 18 figures. Ozwater 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data61 and Western Water worked collaboratively to apply engineering\nexpertise and Machine Learning tools to find a cost-effective solution to the\npipe failure problem in the region west of Melbourne, where on average 400\nwater main failures occur per year. To achieve this objective, we constructed a\ndetailed picture and understanding of the behaviour of the water pipe network\nby 1) discovering the underlying drivers of water main breaks, and 2)\ndeveloping a Machine Learning system to assess and predict the failure\nlikelihood of water main breaking using historical failure records, descriptors\nof pipes, and other environmental factors. The ensuing results open up an\navenue for Western Water to identify the priority of pipe renewals\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 11:44:02 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Weeraddana", "Dilusha", ""], ["Liang", "Bin", ""], ["Li", "Zhidong", ""], ["Wang", "Yang", ""], ["Chen", "Fang", ""], ["Bonazzi", "Livia", ""], ["Phillips", "Dean", ""], ["Saxena", "Nitin", ""]]}, {"id": "2006.03434", "submitter": "Mathias Unberath", "authors": "Mathias Unberath and Kimia Ghobadi and Scott Levin and Jeremiah Hinson\n  and Gregory D Hager", "title": "Artificial Intelligence-based Clinical Decision Support for COVID-19 --\n  Where Art Thou?", "comments": "Invited perspective piece on AI in the fight against COVID-19 to\n  appear in Advanced Intelligent Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 crisis has brought about new clinical questions, new workflows,\nand accelerated distributed healthcare needs. While artificial intelligence\n(AI)-based clinical decision support seemed to have matured, the application of\nAI-based tools for COVID-19 has been limited to date. In this perspective\npiece, we identify opportunities and requirements for AI-based clinical\ndecision support systems and highlight challenges that impact \"AI readiness\"\nfor rapidly emergent healthcare challenges.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 13:34:47 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Unberath", "Mathias", ""], ["Ghobadi", "Kimia", ""], ["Levin", "Scott", ""], ["Hinson", "Jeremiah", ""], ["Hager", "Gregory D", ""]]}, {"id": "2006.03498", "submitter": "Yujie Hu", "authors": "Yujie Hu, Fahui Wang, Chester Wilmot", "title": "Commuting Variability by Wage Groups in Baton Rouge 1990-2010", "comments": null, "journal-ref": "Papers in Applied Geography, 3(1), 14-29 (2017)", "doi": "10.1080/23754931.2016.1248577", "report-no": null, "categories": "stat.AP cs.CY econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Residential segregation recently has shifted to more class or income-based in\nthe United States, and neighborhoods are undergoing significant changes such as\ncommuting patterns over time. To better understand the commuting inequality\nacross neighborhoods of different income levels, this research analyzes\ncommuting variability (in both distance and time) across wage groups as well as\nstability over time using the CTPP data 1990-2010 in Baton Rouge. In comparison\nto previous work, commuting distance is estimated more accurately by Monte\nCarlo simulation of individual trips to mitigate aggregation error and scale\neffect. The results based on neighborhoods mean wage rate indicate that\ncommuting behaviors vary across areas of different wage rates and such\nvariability is captured by a convex shape. Affluent neighborhoods tended to\ncommute more but highest-wage neighborhoods retreated for less commuting. This\ntrend remains relatively stable over time despite an overall transportation\nimprovement in general. A complementary analysis based on the distribution of\nwage groups is conducted to gain more detailed insights and uncovers the\nlasting poor mobility (e.g., fewer location and transport options) of the\nlowest-wage workers in 1990-2010.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 14:03:42 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Hu", "Yujie", ""], ["Wang", "Fahui", ""], ["Wilmot", "Chester", ""]]}, {"id": "2006.03499", "submitter": "Yujie Hu", "authors": "Yujie Hu, Harvey J Miller, Xiang Li", "title": "Detecting and Analyzing Mobility Hotspots using Surface Networks", "comments": null, "journal-ref": "Transactions in GIS, 18(6), 911-935 (2014)", "doi": "10.1111/tgis.12076", "report-no": null, "categories": "stat.AP cs.CG cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Capabilities for collecting and storing data on mobile objects have increased\ndramatically over the past few decades. A persistent difficulty is summarizing\nlarge collections of mobile objects. This paper develops methods for extracting\nand analyzing hotspots or locations with relatively high levels of mobility\nactivity. We use kernel density estimation (KDE) to convert a large collection\nof mobile objects into a smooth, continuous surface. We then develop a\ntopological algorithm to extract critical geometric features of the surface;\nthese include critical points (peaks, pits and passes) and critical lines\n(ridgelines and course-lines). We connect the peaks and corresponding\nridgelines to produce a surface network that summarizes the topological\nstructure of the surface. We apply graph theoretic indices to analytically\ncharacterize the surface and its changes over time. To illustrate our approach,\nwe apply the techniques to taxi cab data collected in Shanghai, China. We find\nincreases in the complexity of the hotspot spatial distribution during normal\nactivity hours in the late morning, afternoon and evening and a spike in the\nconnectivity of the hotspot spatial distribution in the morning as taxis\nconcentrate on servicing travel to work. These results match with scientific\nand anecdotal knowledge about human activity patterns in the study area.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 14:11:26 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Hu", "Yujie", ""], ["Miller", "Harvey J", ""], ["Li", "Xiang", ""]]}, {"id": "2006.03716", "submitter": "Jun Zhao", "authors": "Jun Zhao, Minha Lee, Sepehr Ghader, Hannah Younes, Aref Darzi,\n  Chenfeng Xiong, Lei Zhang", "title": "Quarantine Fatigue: first-ever decrease in social distancing measures\n  after the COVID-19 outbreak before reopening United States", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By the emergence of the novel coronavirus disease (COVID-19) in Wuhan, China,\nand its rapid outbreak worldwide, the infectious illness has changed our\neveryday travel patterns. In this research, our team investigated the changes\nin the daily mobility pattern of people during the pandemic by utilizing an\nintegrated data panel. To incorporate various aspects of human mobility, the\nteam focused on the Social Distancing Index (SDI) which was calculated based on\nfive basic mobility measures. The SDI patterns showed a plateau stage in the\nbeginning of April that lasted for about two weeks. This phenomenon then\nfollowed by a universal decline of SDI, increased number of trips and reduction\nin percentage of people staying at home. We called the observation Quarantine\nFatigue. The Rate of Change (ROC) method was employed to trace back the start\ndate of quarantine fatigue which was indicated to be April 15th. Our analysis\nshowed that despite the existence of state-to-state variations, most states\nstarted experiencing a quarantine fatigue phenomenon during the same period.\nThis observation became more important by knowing that none of the states had\nofficially announced the reopening until late April showing that people decided\nto loosen up their social distancing practices before the official reopening\nannouncement. Moreover, our analysis indicated that official reopening led to a\nrapid decline in SDI, raising the concern of a second wave of outbreak. The\nsynchronized trend among states also emphasizes the importance of a more\nnationwide decision-making attitude for the future as the condition of each\nstate depends on the nationwide behavior.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 22:13:33 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 20:41:27 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Zhao", "Jun", ""], ["Lee", "Minha", ""], ["Ghader", "Sepehr", ""], ["Younes", "Hannah", ""], ["Darzi", "Aref", ""], ["Xiong", "Chenfeng", ""], ["Zhang", "Lei", ""]]}, {"id": "2006.03730", "submitter": "Richard Hill Prof", "authors": "Richard Hill", "title": "Blended Learning Content Generation: A Guide for Busy Academics", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": "01", "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A practical guide for university academics who need to create learning\nmaterials that support flexible delivery methods. Examples from the Computer\nScience domain are used to illustrate innovative approaches to engaging\nstudents with online and blended teaching resources.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 23:05:51 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Hill", "Richard", ""]]}, {"id": "2006.03835", "submitter": "Suyash Shandilya", "authors": "Suyash Shandilya", "title": "Compressive analysis and the Future of Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive analysis is the name given to the family of techniques that map\nraw data to their smaller representation. Largely, this includes data\ncompression, data encoding, data encryption, and hashing. In this paper, we\nanalyse the prospects of such technologies in realising customisable individual\nprivacy. We enlist the dire needs to establish privacy preserving frameworks\nand policies and how can individuals achieve a trade-off between the comfort of\nan intuitive digital service ensemble and their privacy. We examine the current\ntechnologies being implemented, and suggest the crucial advantages of\ncompressive analysis.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 10:33:35 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Shandilya", "Suyash", ""]]}, {"id": "2006.03857", "submitter": "Yu Yang", "authors": "Yu Yang, Zhiyuan Wen, Jiannong Cao, Jiaxing Shen, Hongzhi Yin and\n  Xiaofang Zhou", "title": "EPARS: Early Prediction of At-risk Students with Online and Offline\n  Learning Behaviors", "comments": "To be published in DASFAA 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early prediction of students at risk (STAR) is an effective and significant\nmeans to provide timely intervention for dropout and suicide. Existing works\nmostly rely on either online or offline learning behaviors which are not\ncomprehensive enough to capture the whole learning processes and lead to\nunsatisfying prediction performance. We propose a novel algorithm (EPARS) that\ncould early predict STAR in a semester by modeling online and offline learning\nbehaviors. The online behaviors come from the log of activities when students\nuse the online learning management system. The offline behaviors derive from\nthe check-in records of the library. Our main observations are two folds.\nSignificantly different from good students, STAR barely have regular and clear\nstudy routines. We devised a multi-scale bag-of-regularity method to extract\nthe regularity of learning behaviors that is robust to sparse data. Second,\nfriends of STAR are more likely to be at risk. We constructed a co-occurrence\nnetwork to approximate the underlying social network and encode the social\nhomophily as features through network embedding. To validate the proposed\nalgorithm, extensive experiments have been conducted among an Asian university\nwith 15,503 undergraduate students. The results indicate EPARS outperforms\nbaselines by 14.62% ~ 38.22% in predicting STAR.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 12:56:26 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Yang", "Yu", ""], ["Wen", "Zhiyuan", ""], ["Cao", "Jiannong", ""], ["Shen", "Jiaxing", ""], ["Yin", "Hongzhi", ""], ["Zhou", "Xiaofang", ""]]}, {"id": "2006.03895", "submitter": "Kevin Bowyer", "authors": "Kevin W. Bowyer, Michael King, Walter Scheirer and Kushal Vangara", "title": "The Criminality From Face Illusion", "comments": null, "journal-ref": "IEEE Transactions on Technology and Society, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic analysis of face images can generate predictions about a\nperson's gender, age, race, facial expression, body mass index, and various\nother indices and conditions. A few recent publications have claimed success in\nanalyzing an image of a person's face in order to predict the person's status\nas Criminal / Non-Criminal. Predicting criminality from face may initially seem\nsimilar to other facial analytics, but we argue that attempts to create a\ncriminality-from-face algorithm are necessarily doomed to fail, that apparently\npromising experimental results in recent publications are an illusion resulting\nfrom inadequate experimental design, and that there is potentially a large\nsocial cost to belief in the criminality from face illusion.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 15:45:05 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 16:13:49 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Bowyer", "Kevin W.", ""], ["King", "Michael", ""], ["Scheirer", "Walter", ""], ["Vangara", "Kushal", ""]]}, {"id": "2006.03907", "submitter": "Karen Levy", "authors": "Karen Levy, Bruce Schneier", "title": "Privacy threats in intimate relationships", "comments": null, "journal-ref": "Journal of Cybersecurity 6: 1-13 (2020)", "doi": "10.1093/cybsec/tyaa006", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article provides an overview of intimate threats: a class of privacy\nthreats that can arise within our families, romantic partnerships, close\nfriendships, and caregiving relationships. Many common assumptions about\nprivacy are upended in the context of these relationships, and many otherwise\neffective protective measures fail when applied to intimate threats. Those\nclosest to us know the answers to our secret questions, have access to our\ndevices, and can exercise coercive power over us. We survey a range of intimate\nrelationships and describe their common features. Based on these features, we\nexplore implications for both technical privacy design and policy, and offer\ndesign recommendations for ameliorating intimate privacy risks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 16:21:14 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Levy", "Karen", ""], ["Schneier", "Bruce", ""]]}, {"id": "2006.03931", "submitter": "Alessandro Ecclesie Agazzi", "authors": "Alessandro Ecclesie Agazzi", "title": "Study of the usability of LinkedIn: a social media platform meant to\n  connect employers and employees", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social network platforms have increased and become very popular in the last\ndecade; they allow people to create an online account to then interact with\nothers creating a complicated net of connections. LinkedIn is one of the most\nused social media platform, created and used for professional purposes. Here,\nindeed, the user can either apply for job positions or join professional\ncommunities to deepen his own knowledge and expertise and be always up to date\nin the interested field. The primary objectives of this paper are assessing\nLinkedIn's usability, by using both user and expert evaluation and giving\nrecommendations for the developer to improve this social network. This has been\nachieved through different steps; initially, feedbacks have been collected, via\nquestionnaire, from direct users. Later, the usability issues, which have been\nunderlined by users in the questionnaire, have been explored, by simulating\nuser's problem-solving process, through Walkthrough. Finally, the overall\nusability of LinkedIn application has been measured by using SUS (System\nUsability Scale).\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 18:19:45 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Agazzi", "Alessandro Ecclesie", ""]]}, {"id": "2006.03950", "submitter": "Aylin Caliskan", "authors": "Autumn Toney and Aylin Caliskan", "title": "ValNorm Quantifies Semantics to Reveal Consistent Valence Biases Across\n  Languages and Over Centuries", "comments": "15 pages, 3 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Word embeddings, which are numeric dictionaries for machines to process\nlanguage, learn implicit biases from linguistic regularities captured by word\nco-occurrence information. As a result, statistical methods can detect and\nquantify social biases along with widely shared associations present in the\ncorpus the word embeddings are trained on. By extending methods that quantify\nhuman-like biases in word embeddings, we introduce ValNorm, a novel word\nembedding intrinsic evaluation task and a method to measure the affective\nmeaning of valence (pleasantness/unpleasantness) in words, with high accuracy.\nThe correlation between human judgment scores of valence for 399 words\ncollected to establish pleasantness norms in English and ValNorm scores is\nr=0.88. These 399 words, obtained from the social psychology literature, are\nused to measure biases that are non-discriminatory among social groups. We\nhypothesize that the valence associations for this set of words (in various\ntranslations) are widely shared across languages and consistent over time. We\nestimate valence associations of these words using word embeddings from seven\nlanguages representing various language structures and from historical text\ncovering 200 years. Our method achieves consistently high accuracy, suggesting\nthat the valence associations for these words are widely shared. In contrast,\nwe measure gender stereotypes using the same set of word embeddings and find\nthat social biases vary across languages. Our results signal that valence\nassociations of this word set represent widely shared associations of the last\ntwo centuries. Consequently, ValNorm can be used to evaluate valence norms and\nthe accuracy of word embeddings especially when measuring biases.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 19:29:36 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 23:59:07 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 04:16:21 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Toney", "Autumn", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2006.03955", "submitter": "Aylin Caliskan", "authors": "Wei Guo and Aylin Caliskan", "title": "Detecting Emergent Intersectional Biases: Contextualized Word Embeddings\n  Contain a Distribution of Human-like Biases", "comments": "19 pages, 2 figures, 4 tables", "journal-ref": "AAAI/ACM Conference on Artificial Intelligence, Ethics, and\n  Society 2021", "doi": "10.1145/3461702.3462536", "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the starting point that implicit human biases are reflected in the\nstatistical regularities of language, it is possible to measure biases in\nEnglish static word embeddings. State-of-the-art neural language models\ngenerate dynamic word embeddings dependent on the context in which the word\nappears. Current methods measure pre-defined social and intersectional biases\nthat appear in particular contexts defined by sentence templates. Dispensing\nwith templates, we introduce the Contextualized Embedding Association Test\n(CEAT), that can summarize the magnitude of overall bias in neural language\nmodels by incorporating a random-effects model. Experiments on social and\nintersectional biases show that CEAT finds evidence of all tested biases and\nprovides comprehensive information on the variance of effect magnitudes of the\nsame bias in different contexts. All the models trained on English corpora that\nwe study contain biased representations.\n  Furthermore, we develop two methods, Intersectional Bias Detection (IBD) and\nEmergent Intersectional Bias Detection (EIBD), to automatically identify the\nintersectional biases and emergent intersectional biases from static word\nembeddings in addition to measuring them in contextualized word embeddings. We\npresent the first algorithmic bias detection findings on how intersectional\ngroup members are strongly associated with unique emergent biases that do not\noverlap with the biases of their constituent minority identities. IBD and EIBD\nachieve high accuracy when detecting the intersectional and emergent biases of\nAfrican American females and Mexican American females. Our results indicate\nthat biases at the intersection of race and gender associated with members of\nmultiple minority groups, such as African American females and Mexican American\nfemales, have the highest magnitude across all neural language models.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 19:49:50 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:08:41 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 18:43:34 GMT"}, {"version": "v4", "created": "Fri, 16 Apr 2021 01:45:35 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 15:06:28 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Guo", "Wei", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2006.03977", "submitter": "Daniela Ganelin", "authors": "Daniela Ganelin and Isaac Chuang", "title": "IP Geolocation Underestimates Regressive Economic Patterns in MOOC Usage", "comments": null, "journal-ref": "ICETC 2019: Proceedings of the 2019 11th International Conference\n  on Education Technology and Computers October 2019", "doi": "10.1145/3369255.3369301", "report-no": null, "categories": "cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive open online courses (MOOCs) promise to make rigorous higher education\naccessible to everyone, but prior research has shown that registrants tend to\ncome from backgrounds of higher socioeconomic status. We study geographically\ngranular economic patterns in about 76,000 U.S. registrations for about 600\nHarvardX and MITx courses between 2012 and 2018, identifying registrants'\nlocations using both IP geolocation and user-reported mailing addresses. By\neither metric, we find higher registration rates among postal codes with\ngreater prosperity or population density. However, we also find evidence of\nbias in IP geolocation: it makes greater errors, both geographically and\neconomically, for users from more economically distressed areas; it\ndisproportionately places users in prosperous areas; and it underestimates the\nregressive pattern in MOOC registration. Researchers should use IP geolocation\nin MOOC studies with care, and consider the possibility of similar economic\nbiases affecting its other academic, commercial, and legal uses.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 21:13:14 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ganelin", "Daniela", ""], ["Chuang", "Isaac", ""]]}, {"id": "2006.04013", "submitter": "Rubens Lacerda Queiroz", "authors": "Rubens Lacerda Queiroz, F\\'abio Ferrentini Sampaio, Cabral Lima and\n  Priscila Machado Vieira Lima", "title": "AI from concrete to abstract: demystifying artificial intelligence to\n  the general public", "comments": "23 pages; 2 tables; 47 figures; review comment: Included references\n  for the final published peer-reviewed version of this pre-print:\n  https://doi.org/10.1007/s00146-021-01151-x and https://rdcu.be/cihdO; typos\n  corrected", "journal-ref": "AI & SOCIETY, 1-17 (2021)", "doi": "10.1007/s00146-021-01151-x", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) has been adopted in a wide range of domains.\nThis shows the imperative need to develop means to endow common people with a\nminimum understanding of what AI means. Combining visual programming and WiSARD\nweightless artificial neural networks, this article presents a new methodology,\nAI from concrete to abstract (AIcon2abs), to enable general people (including\nchildren) to achieve this goal. The main strategy adopted by is to promote a\ndemystification of artificial intelligence via practical activities related to\nthe development of learning machines, as well as through the observation of\ntheir learning process. Thus, it is possible to provide subjects with skills\nthat contributes to making them insightful actors in debates and decisions\ninvolving the adoption of artificial intelligence mechanisms. Currently,\nexisting approaches to the teaching of basic AI concepts through programming\ntreat machine intelligence as an external element/module. After being trained,\nthat external module is coupled to the main application being developed by the\nlearners. In the methodology herein presented, both training and classification\ntasks are blocks that compose the main program, just as the other programming\nconstructs. As a beneficial side effect of AIcon2abs, the difference between a\nprogram capable of learning from data and a conventional computer program\nbecomes more evident. In addition, the simplicity of the WiSARD weightless\nartificial neural network model enables easy visualization and understanding of\ntraining and classification tasks internal realization.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 01:14:06 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 14:23:37 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 06:44:20 GMT"}, {"version": "v4", "created": "Tue, 1 Sep 2020 16:03:43 GMT"}, {"version": "v5", "created": "Thu, 15 Apr 2021 00:53:14 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Queiroz", "Rubens Lacerda", ""], ["Sampaio", "F\u00e1bio Ferrentini", ""], ["Lima", "Cabral", ""], ["Lima", "Priscila Machado Vieira", ""]]}, {"id": "2006.04029", "submitter": "Huthaifa I. Ashqar", "authors": "Davon Woodard, Huthaifa I. Ashqar, and Taoran Ji", "title": "Ethics, Data Science, and Health and Human Services: Embedded Bias in\n  Policy Approaches to Teen Pregnancy Prevention", "comments": "Submitted to the Health Policy Open journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: This study aims to evaluate the Chicago Teen Pregnancy Prevention\nInitiative delivery optimization outcomes given policy-neutral and\npolicy-focused approaches to deliver this program to at-risk teens across the\nCity of Chicago. Methods: We collect and compile several datasets from public\nsources including: Chicago Department of Public Health clinic locations, two\npublic health statistics datasets, census data of Chicago, list of Chicago\npublic high schools, and their Locations. Our policy-neutral approach will\nconsist of an equal distribution of funds and resources to schools and centers,\nregardless of past trends and outcomes. The policy-focused approaches will\nevaluate two models: first, a funding model based on prediction models from\nhistorical data; and second, a funding model based on economic and social\noutcomes for communities. Results: Results of this study confirms our initial\nhypothesis, that even though the models are optimized from a machine learning\nperspective, there is still possible that the models will produce wildly\ndifferent results in the real-world application. Conclusions: When ethics and\nethical considerations are extended beyond algorithmic optimization to\nencompass output and societal optimization, the foundation and philosophical\ngrounding of the decision-making process become even more critical in the\nknowledge discovery process.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 03:04:50 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Woodard", "Davon", ""], ["Ashqar", "Huthaifa I.", ""], ["Ji", "Taoran", ""]]}, {"id": "2006.04033", "submitter": "Huthaifa Ashqar", "authors": "Mohammed Hamad Almannaa, Huthaifa I. Ashqar, Mohammed Elhenawy,\n  Mahmoud Masoud, Andry Rakotonirainy, and Hesham Rakha", "title": "A Comparative Analysis of E-Scooter and E-Bike Usage Patterns: Findings\n  from the City of Austin, TX", "comments": "Submitted to the International Journal of Sustainable Transportation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-scooter-sharing and e-bike-sharing systems are accommodating and easing the\nincreased traffic in dense cities and are expanding considerably. However,\nthese new micro-mobility transportation modes raise numerous operational and\nsafety concerns. This study analyzes e-scooter and dockless e-bike sharing\nsystem user behavior. We investigate how average trip speed change depending on\nthe day of the week and the time of the day. We used a dataset from the city of\nAustin, TX from December 2018 to May 2019. Our results generally show that the\ntrip average speed for e-bikes ranges between 3.01 and 3.44 m/s, which is\nhigher than that for e-scooters (2.19 to 2.78 m/s). Results also show a similar\nusage pattern for the average speed of e-bikes and e-scooters throughout the\ndays of the week and a different usage pattern for the average speed of e-bikes\nand e-scooters over the hours of the day. We found that users tend to ride\ne-bikes and e-scooters with a slower average speed for recreational purposes\ncompared to when they are ridden for commuting purposes. This study is a\nbuilding block in this field, which serves as a first of its kind, and sheds\nthe light of significant new understanding of this emerging class of\nshared-road users.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 03:27:44 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Almannaa", "Mohammed Hamad", ""], ["Ashqar", "Huthaifa I.", ""], ["Elhenawy", "Mohammed", ""], ["Masoud", "Mahmoud", ""], ["Rakotonirainy", "Andry", ""], ["Rakha", "Hesham", ""]]}, {"id": "2006.04200", "submitter": "Abhishek Dubey", "authors": "Ayan Mukhopadhyay and Geoffrey Pettet and Sayyed Vazirizade and Di Lu\n  and Said El Said and Alex Jaimes and Hiba Baroud and Yevgeniy Vorobeychik and\n  Mykel Kochenderfer and Abhishek Dubey", "title": "A Review of Incident Prediction, Resource Allocation, and Dispatch\n  Models for Emergency Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last fifty years, researchers have developed statistical, data-driven,\nanalytical, and algorithmic approaches for designing and improving emergency\nresponse management (ERM) systems. The problem is inherently difficult and\nconstitutes spatio-temporal decision making under uncertainty, which has been\naddressed in the literature with varying assumptions and approaches. This\nsurvey provides a detailed review of these approaches, focusing on the key\nchallenges and issues regarding three subprocesses that are part of this\nproblem (a) incident prediction, (b) resource allocation, and (c)\ncomputer-aided dispatch to handle the emergency conditions. We highlight the\nstrengths and weaknesses of prior work in this domain and explore the\nsimilarities and differences between different modeling paradigms. We conclude\nby illustrating remain challenges and opportunities for future research in this\ncomplex domain.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 16:50:59 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 22:04:06 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 19:42:58 GMT"}, {"version": "v4", "created": "Fri, 3 Jul 2020 12:06:58 GMT"}, {"version": "v5", "created": "Tue, 1 Sep 2020 06:30:26 GMT"}, {"version": "v6", "created": "Mon, 1 Feb 2021 16:42:36 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mukhopadhyay", "Ayan", ""], ["Pettet", "Geoffrey", ""], ["Vazirizade", "Sayyed", ""], ["Lu", "Di", ""], ["Said", "Said El", ""], ["Jaimes", "Alex", ""], ["Baroud", "Hiba", ""], ["Vorobeychik", "Yevgeniy", ""], ["Kochenderfer", "Mykel", ""], ["Dubey", "Abhishek", ""]]}, {"id": "2006.04226", "submitter": "Andreea-Ina Radu", "authors": "Tom Goodman and Andreea-Ina Radu", "title": "Learn-Apply-Reinforce/Share Learning: Hackathons and CTFs as General\n  Pedagogic Tools in Higher Education, and Their Applicability to Distance\n  Learning", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper lays out two teaching/learning methods that are becoming\nincreasingly prevalent in computer science - hackathons, and Capture the Flag\n(CTF) competitions - and the pedagogic theory that underpins them. A case study\nof each is analysed, and the underpinning similarities extracted. The\nframeworks are then generalised to Learn-Apply-Reinforce/Share Learning - a\nsocial constructivistic method that can be used subject-independently. The\napplicability of this new method to distance learning is then investigated -\nwith a mind to potential necessity to work from home - both due to increasing\ndemand in the Higher Education sector, but also the devastating impact of\ncrises such as the ongoing COVID-19 pandemic. Finally, a few potential\nextensions and future applications are discussed - including the possibilities\nof pivoting the method to be more research-driven, or indeed, to drive\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 18:41:39 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Goodman", "Tom", ""], ["Radu", "Andreea-Ina", ""]]}, {"id": "2006.04244", "submitter": "Paul Hofmann", "authors": "Erik Brynjolfsson and Paul Hofmann and John Jordan", "title": "Economic and Business Dimensions Cloud Computing and Electricity: Beyond\n  the Utility Model", "comments": null, "journal-ref": "Communications of the ACM, May 2010, vol. 53, no. 5", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An overly simplistic reliance on the utility model risks blinding us to the\nreal opportunities and challenges of cloud computing.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 19:40:39 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Brynjolfsson", "Erik", ""], ["Hofmann", "Paul", ""], ["Jordan", "John", ""]]}, {"id": "2006.04300", "submitter": "Mu Mu", "authors": "Raghad Zenki and Mu Mu", "title": "Machine Learning Interpretability and Its Impact on Smart Campus\n  Projects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) has shown increasing abilities for predictive analytics\nover the last decades. It is becoming ubiquitous in different fields, such as\nhealthcare, criminal justice, finance and smart city. For instance, the\nUniversity of Northampton is building a smart system with multiple layers of\nIoT and software-defined networks (SDN) on its new Waterside Campus. The system\ncan be used to optimize smart buildings energy efficiency, improve the health\nand safety of its tenants and visitors, assist crowd management and\nway-finding, and improve the Internet connectivity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 00:48:53 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Zenki", "Raghad", ""], ["Mu", "Mu", ""]]}, {"id": "2006.04468", "submitter": "Dr John Stephen Kayode", "authors": "John Stephen Kayode, Asha Embrandiri, and Adijat Olubukola Olateju", "title": "The Covid-19 pandemic's effects on poor rural dwellers in sub-Saharan\n  Africa: A case study of access to basic clean water, sanitary systems and\n  hand-washing facilities", "comments": "The manuscript has 15 pages, 10 figures, 1 Table, 5705 Words, 628\n  Lines, 178 Paragraphs, 31274 Characters without space, 36926 Characters\n  including spaces", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fear of the invisible but prevalent Coronavirus (COVID-19), disease\ncannot be overemphasized since there is the potential possibility of it wiping\nout the entire world population within a few months if adequate and quick steps\nare not taken to curb this menace, and the sub-Saharan African (SSAn) region is\nno exception. It is evident that water, as an essential daily commodity, has\nlong been in a state of emergency in SSAn nations, which is largely attributed\nto decades of neglect by the successive governments, because it has not been\npossible to separate the existing bond between water, health, livelihood and\nthe economy. The laudable Millennium Development Goals (MDGs) proposed by the\nUnited Nations had yet to achieve the stated objective of improving the\nstandards of living and health conditions of the rural communities in the SSAn\nregion before the COVID-19 pandemic outbreak. This failure has been masked by a\nsort of delusion in which the people of this region are subjected to the\nhardship of searching for clean and healthy water in their own ponds, rivers,\nstreams and shallow hand-dug local wells on a continuous basis. Less than 17%\nof the rural population in all the SSAn communities can access basic\nhand-washing facilities and sanitation systems. The total water productivity,\nas measured by the Gross Domestic Product (GDP) per cubic meter of total\nfreshwater withdrawn, for the people was less than 5 GDP.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 10:46:39 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kayode", "John Stephen", ""], ["Embrandiri", "Asha", ""], ["Olateju", "Adijat Olubukola", ""]]}, {"id": "2006.04487", "submitter": "Ashish Kundu", "authors": "Ashish Kundu, Arun Ayachitula, Nagamani Sistla", "title": "Similarities and Learnings from Ancient Literature on Blockchain\n  Consensus and Integrity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have studied how the text of an ancient literature on how\ntheir integrity has been preserved for several centuries. Specifically, The\nVedas is an ancient literature, which has its text remained preserved without\nany corruption for thousands of years. As we studied the system that protects\nthe integrity of the text, pronunciation and semantics of the The Vedas, we\ndiscovered a number of similarities it has with the current concept of\nblockchain technology. It is surprising that the notion of de-centralized trust\nand mathematical encodings have existed since thousands of years in order to\nprotect this work of literature. We have presented our findings and analysis of\nthe similarities. There are also certain technical mechanisms that The Vedic\nintegrity system uses, which can be used to enhance the current digital\nblockchain platforms in terms of its security and robustness.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 11:32:47 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kundu", "Ashish", ""], ["Ayachitula", "Arun", ""], ["Sistla", "Nagamani", ""]]}, {"id": "2006.04497", "submitter": "Omer Ben-Porat", "authors": "Gal Bahar, Omer Ben-Porat, Kevin Leyton-Brown and Moshe Tennenholtz", "title": "Learning under Invariable Bayesian Safety", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent body of work addresses safety constraints in explore-and-exploit\nsystems. Such constraints arise where, for example, exploration is carried out\nby individuals whose welfare should be balanced with overall welfare. In this\npaper, we adopt a model inspired by recent work on a bandit-like setting for\nrecommendations. We contribute to this line of literature by introducing a\nsafety constraint that should be respected in every round and determines that\nthe expected value in each round is above a given threshold. Due to our\nmodeling, the safe explore-and-exploit policy deserves careful planning, or\notherwise, it will lead to sub-optimal welfare. We devise an asymptotically\noptimal algorithm for the setting and analyze its instance-dependent\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 12:07:59 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Bahar", "Gal", ""], ["Ben-Porat", "Omer", ""], ["Leyton-Brown", "Kevin", ""], ["Tennenholtz", "Moshe", ""]]}, {"id": "2006.04541", "submitter": "Thilo Hagendorff", "authors": "Thilo Hagendorff, Kristof Meding", "title": "Ethical Considerations and Statistical Analysis of Industry Involvement\n  in Machine Learning Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Industry involvement in the machine learning (ML) community seems to be\nincreasing. However, the quantitative scale and ethical implications of this\ninfluence are rather unknown. For this purpose, we have not only carried out an\ninformed ethical analysis of the field, but have inspected all papers of the\nmain ML conferences NeurIPS, CVPR, and ICML of the last 5 years - almost 11,000\npapers in total. Our statistical approach focuses on conflicts of interest,\ninnovation and gender equality. We have obtained four main findings: (1)\nAcademic-corporate collaborations are growing in numbers. At the same time, we\nfound that conflicts of interest are rarely disclosed. (2) Industry publishes\npapers about trending ML topics on average two years earlier than academia\ndoes. (3) Industry papers are not lagging behind academic papers in regard to\nsocial impact considerations. (4) Finally, we demonstrate that industrial\npapers fall short of their academic counterparts with respect to the ratio of\ngender diversity. We believe that this work is a starting point for an informed\ndebate within and outside of the ML community.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 12:51:38 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 13:01:51 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Hagendorff", "Thilo", ""], ["Meding", "Kristof", ""]]}, {"id": "2006.04579", "submitter": "Sarah Spiekermann", "authors": "Kathrin Bednar, Sarah Spiekermann and Marc Langheinrich", "title": "Engineering Privacy by Design: Are engineers ready to live up to the\n  challenge?", "comments": "System engineers; information privacy; motivation; attitude; Theory\n  of Planned Behaviour; responsibility", "journal-ref": null, "doi": "10.1080/01972243.2019.1583296", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organizations struggle to comply with legal requirements as well as customers\ncalls for better data protection. On the implementation level, incorporation of\nprivacy protections in products and services depends on the commitment of the\nengineers who design them. We interviewed six senior engineers, who work for\nglobally leading IT corporations and research institutions to investigate their\nmotivation and ability to comply with privacy regulations. Our findings point\nto a lack of perceived responsibility, control, autonomy, and frustrations with\ninteractions with the legal world. While we increasingly call on engineers to\ngo beyond functional requirements and be responsive to human values in our\nincreasingly technological society, we may be facing the dilemma of asking\nengineers to live up to a challenge they are currently not ready to embrace.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:28:01 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 13:40:33 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Bednar", "Kathrin", ""], ["Spiekermann", "Sarah", ""], ["Langheinrich", "Marc", ""]]}, {"id": "2006.04585", "submitter": "Sofiane Abbar", "authors": "Mohamed F Mokbel, Sofiane Abbar, Rade Stanojevic", "title": "Contact Tracing: Beyond the Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As pandemic wide spread results in locking down vital facilities, digital\ncontact tracing is deemed as a key for re-opening. However, current efforts in\ndigital contact tracing, running as mobile apps on users' smartphones, fall\nshort in being effective. This paper lays out the vision and guidelines for the\nnext era of digital contact tracing, where the contact tracing functionality is\nmoved from being personal responsibility to be the responsibility of facilities\nthat users visit daily. A privacy-preserving architecture is proposed, which\ncan be mandated as a prerequisite for any facility to re-open during or after\nthe pandemic.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:32:24 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Mokbel", "Mohamed F", ""], ["Abbar", "Sofiane", ""], ["Stanojevic", "Rade", ""]]}, {"id": "2006.04599", "submitter": "Aylin Caliskan", "authors": "Akshat Pandey and Aylin Caliskan", "title": "Disparate Impact of Artificial Intelligence Bias in Ridehailing\n  Economy's Price Discrimination Algorithms", "comments": "16 pages, 3 tables, 8 figures", "journal-ref": "AAAI/ACM Conference on Artificial Intelligence, Ethics, and\n  Society (AAAI/ACM AIES 2021)", "doi": "10.1145/3461702.3462561", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ridehailing applications that collect mobility data from individuals to\ninform smart city planning predict each trip's fare pricing with automated\nalgorithms that rely on artificial intelligence (AI). This type of AI\nalgorithm, namely a price discrimination algorithm, is widely used in the\nindustry's black box systems for dynamic individualized pricing. Lacking\ntransparency, studying such AI systems for fairness and disparate impact has\nnot been possible without access to data used in generating the outcomes of\nprice discrimination algorithms. Recently, in an effort to enhance transparency\nin city planning, the city of Chicago regulation mandated that transportation\nproviders publish anonymized data on ridehailing. As a result, we present the\nfirst large-scale measurement of the disparate impact of price discrimination\nalgorithms used by ridehailing applications.\n  The application of random effects models from the meta-analysis literature\ncombines the city-level effects of AI bias on fare pricing from census tract\nattributes, aggregated from the American Community Survey. An analysis of 100\nmillion ridehailing samples from the city of Chicago indicates a significant\ndisparate impact in fare pricing of neighborhoods due to AI bias learned from\nridehailing utilization patterns associated with demographic attributes.\nNeighborhoods with larger non-white populations, higher poverty levels, younger\nresidents, and high education levels are significantly associated with higher\nfare prices, with combined effect sizes, measured in Cohen's d, of -0.32,\n-0.28, 0.69, and 0.24 for each demographic, respectively. Further, our methods\nhold promise for identifying and addressing the sources of disparate impact in\nAI algorithms learning from datasets that contain U.S. geolocations.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:51:03 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 21:06:33 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2020 00:45:59 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 19:43:31 GMT"}, {"version": "v5", "created": "Thu, 8 Apr 2021 14:42:09 GMT"}, {"version": "v6", "created": "Mon, 3 May 2021 20:35:37 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Pandey", "Akshat", ""], ["Caliskan", "Aylin", ""]]}, {"id": "2006.04654", "submitter": "Subhashis Banerjee", "authors": "Prashant Agrawal, Anubhutie Singh, Malavika Raghavan, Subodh Sharma,\n  Subhashis Banerjee", "title": "An operational architecture for privacy-by-design in public service\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Governments around the world are trying to build large data registries for\neffective delivery of a variety of public services. However, these efforts are\noften undermined due to serious concerns over privacy risks associated with\ncollection and processing of personally identifiable information. While a rich\nset of special-purpose privacy-preserving techniques exist in computer science,\nthey are unable to provide end-to-end protection in alignment with legal\nprinciples in the absence of an overarching operational architecture to ensure\npurpose limitation and protection against insider attacks. This either leads to\nweak privacy protection in large designs, or adoption of overly defensive\nstrategies to protect privacy by compromising on utility.\n  In this paper, we present an operational architecture for privacy-by-design\nbased on independent regulatory oversight stipulated by most data protection\nregimes, regulated access control, purpose limitation and data minimisation. We\nbriefly discuss the feasibility of implementing our architecture based on\nexisting techniques. We also present some sample case studies of\nprivacy-preserving design sketches of challenging public service applications.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:57:29 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Agrawal", "Prashant", ""], ["Singh", "Anubhutie", ""], ["Raghavan", "Malavika", ""], ["Sharma", "Subodh", ""], ["Banerjee", "Subhashis", ""]]}, {"id": "2006.04707", "submitter": "Daniel Schiff", "authors": "Daniel Schiff and Bogdana Rakova and Aladdin Ayesh and Anat Fanti and\n  Michael Lennon", "title": "Principles to Practices for Responsible AI: Closing the Gap", "comments": "Preprint draft. A version has been submitted to the 2020 European\n  Conference on AI (ECAI) Workshop on \"ADVANCING TOWARDS THE SDGs: ARTIFICIAL\n  INTELLIGENCE FOR A FAIR, JUST AND EQUITABLE WORLD (AI4EQ)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Companies have considered adoption of various high-level artificial\nintelligence (AI) principles for responsible AI, but there is less clarity on\nhow to implement these principles as organizational practices. This paper\nreviews the principles-to-practices gap. We outline five explanations for this\ngap ranging from a disciplinary divide to an overabundance of tools. In turn,\nwe argue that an impact assessment framework which is broad, operationalizable,\nflexible, iterative, guided, and participatory is a promising approach to close\nthe principles-to-practices gap. Finally, to help practitioners with applying\nthese recommendations, we review a case study of AI's use in forest ecosystem\nrestoration, demonstrating how an impact assessment framework can translate\ninto effective and responsible AI practices.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 16:04:44 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Schiff", "Daniel", ""], ["Rakova", "Bogdana", ""], ["Ayesh", "Aladdin", ""], ["Fanti", "Anat", ""], ["Lennon", "Michael", ""]]}, {"id": "2006.04748", "submitter": "Bell Raj Eapen", "authors": "Bell Raj Eapen, Kamran Sartipi and Norm Archer", "title": "Serverless on FHIR: Deploying machine learning models for healthcare on\n  the cloud", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) plays a vital role in implementing digital health. The\nadvances in hardware and the democratization of software tools have\nrevolutionized machine learning. However, the deployment of ML models -- the\nmathematical representation of the task to be performed -- for effective and\nefficient clinical decision support at the point of care is still a challenge.\nML models undergo constant improvement of their accuracy and predictive power\nwith a high turnover rate. Updating models consumed by downstream health\ninformation systems is essential for patient safety. We introduce a functional\ntaxonomy and a four-tier architecture for cloud-based model deployment for\ndigital health. The four tiers are containerized microservices for\nmaintainability, serverless architecture for scalability, function as a service\nfor portability and FHIR schema for discoverability. We call this architecture\nServerless on FHIR and propose this as a standard to deploy digital health\napplications that can be consumed by downstream systems such as EMRs and\nvisualization tools.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 16:57:30 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Eapen", "Bell Raj", ""], ["Sartipi", "Kamran", ""], ["Archer", "Norm", ""]]}, {"id": "2006.04778", "submitter": "Vijay Keswani", "authors": "L. Elisa Celis and Lingxiao Huang and Vijay Keswani and Nisheeth K.\n  Vishnoi", "title": "Fair Classification with Noisy Protected Attributes: A Framework with\n  Provable Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimization framework for learning a fair classifier in the\npresence of noisy perturbations in the protected attributes. Compared to prior\nwork, our framework can be employed with a very general class of linear and\nlinear-fractional fairness constraints, can handle multiple, non-binary\nprotected attributes, and outputs a classifier that comes with provable\nguarantees on both accuracy and fairness. Empirically, we show that our\nframework can be used to attain either statistical rate or false positive rate\nfairness guarantees with a minimal loss in accuracy, even when the noise is\nlarge, in two real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:52:48 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 14:18:18 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 17:21:58 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Celis", "L. Elisa", ""], ["Huang", "Lingxiao", ""], ["Keswani", "Vijay", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "2006.04793", "submitter": "David Lyford-Smith", "authors": "David Lyford-Smith", "title": "Developing Excel Thought Leadership", "comments": "8 Pages", "journal-ref": "Proceedings of the EuSpRIG 2019 Conference \"Spreadsheet Risk\n  Management\", Browns, Covent Garden, London, pp39-46, ISBN: 978-1-905404-56-8", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over a period of five years, the Institute of Chartered Accountants in\nEngland and Wales (ICAEW) has developed a suite of three 'thought leadership'\npapers surrounding good practice in spreadsheet use and spreadsheet work\nenvironments. We will review the history of these three papers, the key lessons\nwhich each has to teach, and discuss how the process of making them has helped\nICAEW to develop its position in the field.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 20:19:29 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Lyford-Smith", "David", ""]]}, {"id": "2006.04803", "submitter": "Omar Abdul Wahab", "authors": "Omar Abdel Wahab, Jamal Bentahar, Robin Cohen, Hadi Otrok, Azzam\n  Mourad", "title": "A two-level solution to fight against dishonest opinions in\n  recommendation-based trust systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a mechanism to deal with dishonest opinions in\nrecommendation-based trust models, at both the collection and processing\nlevels. We consider a scenario in which an agent requests recommendations from\nmultiple parties to build trust toward another agent. At the collection level,\nwe propose to allow agents to self-assess the accuracy of their recommendations\nand autonomously decide on whether they would participate in the recommendation\nprocess or not. At the processing level, we propose a recommendations\naggregation technique that is resilient to collusion attacks, followed by a\ncredibility update mechanism for the participating agents. The originality of\nour work stems from its consideration of dishonest opinions at both the\ncollection and processing levels, which allows for better and more persistent\nprotection against dishonest recommenders. Experiments conducted on the\nEpinions dataset show that our solution yields better performance in protecting\nthe recommendation process against Sybil attacks, in comparison with a\ncompeting model that derives the optimal network of advisors based on the\nagents' trust values.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 00:34:11 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Wahab", "Omar Abdel", ""], ["Bentahar", "Jamal", ""], ["Cohen", "Robin", ""], ["Otrok", "Hadi", ""], ["Mourad", "Azzam", ""]]}, {"id": "2006.04816", "submitter": "Shuo Zhang", "authors": "Jason Shuo Zhang, Brian C. Keegan, Qin Lv, Chenhao Tan", "title": "Understanding the Diverging User Trajectories in Highly-related Online\n  Communities during the COVID-19 Pandemic", "comments": "12 pages, 10 figures, accepted to ICWSM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the COVID-19 pandemic is disrupting life worldwide, related online\ncommunities are popping up. In particular, two \"new\" communities, /r/China flu\nand /r/Coronavirus, emerged on Reddit and have been dedicated to COVID- related\ndiscussions from the very beginning of this pandemic. With /r/Coronavirus\npromoted as the official community on Reddit, it remains an open question how\nusers choose between these two highly-related communities.\n  In this paper, we characterize user trajectories in these two communities\nfrom the beginning of COVID-19 to the end of September 2020. We show that new\nusers of /r/China flu and /r/Coronavirus were similar from January to March.\nAfter that, their differences steadily increase, evidenced by both language\ndistance and membership prediction, as the pandemic continues to unfold.\nFurthermore, users who started at /r/China flu from January to March were more\nlikely to leave, while those who started in later months tend to remain highly\n\"loyal\". To understand this difference, we develop a movement analysis\nframework to understand membership changes in these two communities and\nidentify a significant proportion of /r/China flu members (around 50%) that\nmoved to /r/Coronavirus in February. This movement turns out to be highly\npredictable based on other subreddits that users were previously active in. Our\nwork demonstrates how two highly-related communities emerge and develop their\nown identity in a crisis, and highlights the important role of existing\ncommunities in understanding such an emergence.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 18:00:02 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 22:08:31 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Zhang", "Jason Shuo", ""], ["Keegan", "Brian C.", ""], ["Lv", "Qin", ""], ["Tan", "Chenhao", ""]]}, {"id": "2006.04864", "submitter": "John Noel Victorino", "authors": "John Noel Victorino, Naoto Fukunaga, and Tomohiro Shibata", "title": "Design and Development of an Automated Coimagination Support System", "comments": "6 pages, 9 figures, submitted to The 8th International Conference on\n  Human-Agent Interaction (HAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coimagination method is a novel approach to support interactive communication\nfor activating three (3) cognitive functions: episodic memory, division of\nattention, and planning. These cognitive functions are known to decline at an\nearly stage of mild cognitive impairment (MCI). In previous studies about the\ncoimagination method, experimenters tested different settings in different care\ninstitutions. Out of these experiments, various measures were introduced,\nanalyzed, and presented. However, ease of changing configuration based on\nparticipants, and a quick assessment of captured data remained challenging.\nAlso, several observers and measurers are needed to conduct the coimagination\nmethod. In this paper, we propose the initial design and development of an\nautomated coimagination support system that can handle such challenges. We aim\nto have an automated coimagination support system that can be used easily\neither by healthy participants or elderly participants via a natural voice\ninterface. In this paper, our focus is to measure how well our proposed\nfeatures work with elderly participants. Preliminary experiments were conducted\nwith healthy participants, and notably, with actual elder participants. Healthy\nparticipants experienced longer speaking round and question-and-answer round\nthan with elderly participants; while, the latter had preparation time before\nthe speaking round. In these preliminary experiments, our initial system showed\nthe capability to handle different configurations. Healthy participants have\noperated the system using voice, while elderly participants managed to use the\nsystem with minimal assistance.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 08:14:10 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 15:01:22 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Victorino", "John Noel", ""], ["Fukunaga", "Naoto", ""], ["Shibata", "Tomohiro", ""]]}, {"id": "2006.04943", "submitter": "Ermanno Lo Cascio", "authors": "Ermanno Lo Cascio, Zhenjun Ma and Fran\\c{c}ois Mar\\'echal", "title": "How Smart is the Grid?", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancient Romans called 'urbs' the set of buildings and infrastructures, and\n'civitas' the Roman citizens. Today instead, while the society is surfing the\ndigital tsunami, 'urbs' and 'civitas' tend to become much closer, almost\nmerging, that we might attempt to condensate these into a single concept:\n'smart grid'. Internet of things, artificial intelligence, blockchain, quantum\ncryptography is only a few of the paradigms that are likely to contribute to\ndetermining the final portrait of the future smart grid. However, to understand\nthe effective sustainability of complex grids, specific tools are required. To\nthis end, in this article, a systematic review of the emerging paradigms is\npresented, identifying intersectoral synergies and limitations with respect to\nthe `smart grid' concept. Further, a taxonomic framework for assessing the\nlevel of sustainability of the grid is proposed. Finally, from the scenario\nportrayed, a set of issues involving engineering, regulation, security, and\nsocial frameworks have been derived in a theoretical fashion. The findings are\nlikely to suggest the urgent need for multidisciplinary cooperation to wisely\naddress engineering and ontological challenges gravitating around the smart\ngrid concept.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 18:19:20 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 14:29:08 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Cascio", "Ermanno Lo", ""], ["Ma", "Zhenjun", ""], ["Mar\u00e9chal", "Fran\u00e7ois", ""]]}, {"id": "2006.04944", "submitter": "Avishek Kumar", "authors": "Avishek Kumar, Arthi Ramachandran, Adolfo De Unanue, Christina Sung,\n  Joe Walsh, John Schneider, Jessica Ridgway, Stephanie Masiello Schuette, Jeff\n  Lauritsen, Rayid Ghani", "title": "A Machine Learning System for Retaining Patients in HIV Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retaining persons living with HIV (PLWH) in medical care is paramount to\npreventing new transmissions of the virus and allowing PLWH to live normal and\nhealthy lifespans. Maintaining regular appointments with an HIV provider and\ntaking medication daily for a lifetime is exceedingly difficult. 51% of PLWH\nare non-adherent with their medications and eventually drop out of medical\ncare. Current methods of re-linking individuals to care are reactive (after a\npatient has dropped-out) and hence not very effective. We describe our system\nto predict who is most at risk to drop-out-of-care for use by the University of\nChicago HIV clinic and the Chicago Department of Public Health. Models were\nselected based on their predictive performance under resource constraints,\nstability over time, as well as fairness. Our system is applicable as a\npoint-of-care system in a clinical setting as well as a batch prediction system\nto support regular interventions at the city level. Our model performs 3x\nbetter than the baseline for the clinical model and 2.3x better than baseline\nfor the city-wide model. The code has been released on github and we hope this\nmethodology, particularly our focus on fairness, will be adopted by other\nclinics and public health agencies in order to curb the HIV epidemic.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 01:44:38 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kumar", "Avishek", ""], ["Ramachandran", "Arthi", ""], ["De Unanue", "Adolfo", ""], ["Sung", "Christina", ""], ["Walsh", "Joe", ""], ["Schneider", "John", ""], ["Ridgway", "Jessica", ""], ["Schuette", "Stephanie Masiello", ""], ["Lauritsen", "Jeff", ""], ["Ghani", "Rayid", ""]]}, {"id": "2006.04945", "submitter": "Joanna Henzel", "authors": "Joanna Henzel and Marek Sikora", "title": "Gradient Boosting Application in Forecasting of Performance Indicators\n  Values for Measuring the Efficiency of Promotions in FMCG Retail", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, a problem of forecasting promotion efficiency is raised. The\nauthors propose a new approach, using the gradient boosting method for this\ntask. Six performance indicators are introduced to capture the promotion\neffect. For each of them, within predefined groups of products, a model was\ntrained. A description of using these models for forecasting and optimising\npromotion efficiency is provided. Data preparation and hyperparameters tuning\nprocesses are also described. The experiments were performed for three groups\nof products from a large grocery company.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 20:08:01 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Henzel", "Joanna", ""], ["Sikora", "Marek", ""]]}, {"id": "2006.04946", "submitter": "Kyongsik Yun", "authors": "Kyongsik Yun, Thomas Lu, Alexander Huyen", "title": "Transforming unstructured voice and text data into insight for paramedic\n  emergency service using recurrent and convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paramedics often have to make lifesaving decisions within a limited time in\nan ambulance. They sometimes ask the doctor for additional medical\ninstructions, during which valuable time passes for the patient. This study\naims to automatically fuse voice and text data to provide tailored situational\nawareness information to paramedics. To train and test speech recognition\nmodels, we built a bidirectional deep recurrent neural network (long short-term\nmemory (LSTM)). Then we used convolutional neural networks on top of\ncustom-trained word vectors for sentence-level classification tasks. Each\nsentence is automatically categorized into four classes, including patient\nstatus, medical history, treatment plan, and medication reminder. Subsequently,\nincident reports were automatically generated to extract keywords and assist\nparamedics and physicians in making decisions. The proposed system found that\nit could provide timely medication notifications based on unstructured voice\nand text data, which was not possible in paramedic emergencies at present. In\naddition, the automatic incident report generation provided by the proposed\nsystem improves the routine but error-prone tasks of paramedics and doctors,\nhelping them focus on patient care.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 06:47:02 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Yun", "Kyongsik", ""], ["Lu", "Thomas", ""], ["Huyen", "Alexander", ""]]}, {"id": "2006.04947", "submitter": "Temiloluwa Prioleau", "authors": "Sudip Vhaduri and Temiloluwa Prioleau", "title": "Adherence to Personal Health Devices: A Case Study in Diabetes\n  Management", "comments": "11 pages, 8 figures, paper to appear in Pervasive Health 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal health devices can enable continuous monitoring of health\nparameters. However, the benefit of these devices is often directly related to\nthe frequency of use. Therefore, adherence to personal health devices is\ncritical. This paper takes a data mining approach to study continuous glucose\nmonitor use in diabetes management. We evaluate two independent datasets from a\ntotal of 44 subjects for 60 - 270 days. Our results show that: 1) missed target\ngoals (i.e. suboptimal outcomes) is a factor that is associated with wearing\nbehavior of personal health devices, and 2) longer duration of non-adherence,\nidentified through missing data or data gaps, is significantly associated with\npoorer outcomes. More specifically, we found that up to 33% of data gaps\noccurred when users were in abnormal blood glucose categories. The longest data\ngaps occurred in the most severe (i.e. very low / very high) glucose\ncategories. Additionally, subjects with poorly-controlled diabetes had longer\naverage data gap duration than subjects with well-controlled diabetes. This\nwork contributes to the literature on the design of context-aware systems that\ncan leverage data-driven approaches to understand factors that influence\nnon-wearing behavior. The results can also support targeted interventions to\nimprove health outcomes.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 02:47:21 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Vhaduri", "Sudip", ""], ["Prioleau", "Temiloluwa", ""]]}, {"id": "2006.04948", "submitter": "Andrew Critch PhD", "authors": "Andrew Critch, David Krueger", "title": "AI Research Considerations for Human Existential Safety (ARCHES)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Framed in positive terms, this report examines how technical AI research\nmight be steered in a manner that is more attentive to humanity's long-term\nprospects for survival as a species. In negative terms, we ask what existential\nrisks humanity might face from AI development in the next century, and by what\nprinciples contemporary technical research might be directed to address those\nrisks.\n  A key property of hypothetical AI technologies is introduced, called\n\\emph{prepotence}, which is useful for delineating a variety of potential\nexistential risks from artificial intelligence, even as AI paradigms might\nshift. A set of \\auxref{dirtot} contemporary research \\directions are then\nexamined for their potential benefit to existential safety. Each research\ndirection is explained with a scenario-driven motivation, and examples of\nexisting work from which to build. The research directions present their own\nrisks and benefits to society that could occur at various scales of impact, and\nin particular are not guaranteed to benefit existential safety if major\ndevelopments in them are deployed without adequate forethought and oversight.\nAs such, each direction is accompanied by a consideration of potentially\nnegative side effects.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 02:05:16 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Critch", "Andrew", ""], ["Krueger", "David", ""]]}, {"id": "2006.04950", "submitter": "Wiebke Toussaint", "authors": "Wiebke Toussaint and Aaron Yi Ding", "title": "Machine Learning Systems for Intelligent Services in the IoT: A Survey", "comments": "Requires rework", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) technologies are emerging in the Internet of Things\n(IoT) to provision intelligent services. This survey moves beyond existing ML\nalgorithms and cloud-driven design to investigate the less-explored systems,\nscaling and socio-technical aspects for consolidating ML and IoT. It covers the\nlatest developments (up to 2020) on scaling and distributing ML across cloud,\nedge, and IoT devices. With a multi-layered framework to classify and\nilluminate system design choices, this survey exposes fundamental concerns of\ndeveloping and deploying ML systems in the rising cloud-edge-device continuum\nin terms of functionality, stakeholder alignment and trustworthiness.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 18:26:48 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 09:24:41 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 11:14:40 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Toussaint", "Wiebke", ""], ["Ding", "Aaron Yi", ""]]}, {"id": "2006.04959", "submitter": "Rebekah Overdorf", "authors": "Rebekah Overdorf and Christopher Schwartz", "title": "Thinking Taxonomically about Fake Accounts: Classification, False\n  Dichotomies, and the Need for Nuance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often said that war creates a fog in which it becomes difficult to\ndiscern friend from foe on the battlefield. In the ongoing war on fake\naccounts, conscious development of taxonomies of the phenomenon has yet to\noccur, resulting in much confusion on the digital battlefield about what\nexactly a fake account is. This paper intends to address this problem, not by\nproposing a taxonomy of fake accounts, but by proposing a systematic way to\nthink taxonomically about the phenomenon. Specifically, we examine fake\naccounts through both a combined philosophical and computer science-based\nperspective. Through these lenses, we deconstruct narrow binary thinking about\nfake accounts, both in the form of general false dichotomies and specifically\nin relation to the Facebook's conceptual framework \"Coordinated Inauthentic\nBehavior\" (CIB). We then address the false dichotomies by constructing a more\ncomplex way of thinking taxonomically about fake accounts.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 21:40:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Overdorf", "Rebekah", ""], ["Schwartz", "Christopher", ""]]}, {"id": "2006.05031", "submitter": "MohammadNoor Injadat", "authors": "MohammadNoor Injadat, Abdallah Moubayed, Ali Bou Nassif, Abdallah\n  Shami", "title": "Multi-split Optimized Bagging Ensemble Model Selection for Multi-class\n  Educational Data Mining", "comments": "29 Pages, 13 Figures, 19 Tables, Accepted in Springer's Applied\n  Intelligence", "journal-ref": null, "doi": "10.1007/s10489-020-01776-3", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting students' academic performance has been a research area of\ninterest in recent years with many institutions focusing on improving the\nstudents' performance and the education quality. The analysis and prediction of\nstudents' performance can be achieved using various data mining techniques.\nMoreover, such techniques allow instructors to determine possible factors that\nmay affect the students' final marks. To that end, this work analyzes two\ndifferent undergraduate datasets at two different universities. Furthermore,\nthis work aims to predict the students' performance at two stages of course\ndelivery (20% and 50% respectively). This analysis allows for properly choosing\nthe appropriate machine learning algorithms to use as well as optimize the\nalgorithms' parameters. Furthermore, this work adopts a systematic multi-split\napproach based on Gini index and p-value. This is done by optimizing a suitable\nbagging ensemble learner that is built from any combination of six potential\nbase machine learning algorithms. It is shown through experimental results that\nthe posited bagging ensemble models achieve high accuracy for the target group\nfor both datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 03:22:33 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Injadat", "MohammadNoor", ""], ["Moubayed", "Abdallah", ""], ["Nassif", "Ali Bou", ""], ["Shami", "Abdallah", ""]]}, {"id": "2006.05089", "submitter": "Sachithra Lokuge", "authors": "Sachithra Lokuge, Darshana Sedera", "title": "Enterprise Systems Lifecycle-wide Innovation Readiness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Enterprise Systems have been touted as a key driver of delivering benefits\nthrough innovation in corporate Information Systems. The advent of such systems\nexpects to deliver best practices that improve organizational performance. Yet,\nmost Enterprise System installations struggle to see lifecycle-wide value of\nit. Considering that Enterprise Systems deliver lifecycle-wide innovation; we\nobserve organizational readiness for lifecycle-wide Enterprise Systems\ninnovation. The A VICTORY apriori model compares contributions of eight\nconstructs for organizational readiness for continuous Enterprise Systems\ninnovation. The model is tested responses of both client and implementation\npartner. Results indicate that six of the eight constructs of readiness make\nsignificant contributions to organizational readiness for Enterprise Systems\ninnovation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 07:35:11 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Lokuge", "Sachithra", ""], ["Sedera", "Darshana", ""]]}, {"id": "2006.05102", "submitter": "Wonse Jo", "authors": "Wonse Jo, Shyam Sundar Kannan, Go-Eum Cha, Ahreum Lee, and Byung-Cheol\n  Min", "title": "ROSbag-based Multimodal Affective Dataset for Emotional and Cognitive\n  States", "comments": "Accepted for publication in SMC2020, TORONTO, CANADA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new ROSbag-based multimodal affective dataset for\nemotional and cognitive states generated using Robot Operating System (ROS). We\nutilized images and sounds from the International Affective Pictures System\n(IAPS) and the International Affective Digitized Sounds (IADS) to stimulate\ntargeted emotions (happiness, sadness, anger, fear, surprise, disgust, and\nneutral), and a dual N-back game to stimulate different levels of cognitive\nworkload. 30 human subjects participated in the user study; their physiological\ndata was collected using the latest commercial wearable sensors, behavioral\ndata was collected using hardware devices such as cameras, and subjective\nassessments were carried out through questionnaires. All data was stored in\nsingle ROSbag files rather than in conventional Comma-separated values (CSV)\nfiles. This not only ensures synchronization of signals and videos in a data\nset, but also allows researchers to easily analyze and verify their algorithms\nby connecting directly to this dataset through ROS. The generated affective\ndataset consists of 1,602 ROSbag files, and size of the dataset is about 787GB.\nThe dataset is made publicly available. We expect that our dataset can be great\nresource for many researchers in the fields of affective computing, HCI, and\nHRI.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 08:09:42 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 15:47:48 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Jo", "Wonse", ""], ["Kannan", "Shyam Sundar", ""], ["Cha", "Go-Eum", ""], ["Lee", "Ahreum", ""], ["Min", "Byung-Cheol", ""]]}, {"id": "2006.05133", "submitter": "Andrea Aler Tubella", "authors": "Andrea Aler Tubella, Andreas Theodorou, Virginia Dignum, Loizos\n  Michael", "title": "Contestable Black Boxes", "comments": "Accepted at RuleML 2020 as a short paper", "journal-ref": null, "doi": "10.1007/978-3-030-57977-7_12", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The right to contest a decision with consequences on individuals or the\nsociety is a well-established democratic right. Despite this right also being\nexplicitly included in GDPR in reference to automated decision-making, its\nstudy seems to have received much less attention in the AI literature compared,\nfor example, to the right for explanation. This paper investigates the type of\nassurances that are needed in the contesting process when algorithmic\nblack-boxes are involved, opening new questions about the interplay of\ncontestability and explainability. We argue that specialised complementary\nmethodologies to evaluate automated decision-making in the case of a particular\ndecision being contested need to be developed. Further, we propose a\ncombination of well-established software engineering and rule-based approaches\nas a possible socio-technical solution to the issue of contestability, one of\nthe new democratic challenges posed by the automation of decision making.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 09:09:00 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 14:49:12 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Tubella", "Andrea Aler", ""], ["Theodorou", "Andreas", ""], ["Dignum", "Virginia", ""], ["Michael", "Loizos", ""]]}, {"id": "2006.05203", "submitter": "Travis LaCroix", "authors": "Travis LaCroix and Aydin Mohseni", "title": "The Tragedy of the AI Commons", "comments": "40 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy and guideline proposals for ethical artificial-intelligence research\nhave proliferated in recent years. These are supposed to guide the\nsocially-responsible development of AI for the common good. However, there\ntypically exist incentives for non-cooperation (i.e., non-adherence to such\npolicies and guidelines); and, these proposals often lack effective mechanisms\nto enforce their own normative claims. The situation just described constitutes\na social dilemma; namely, a situation where no one has an individual incentive\nto cooperate, though mutual cooperation would lead to the best outcome for all\ninvolved. In this paper, we use stochastic evolutionary game dynamics to model\nthis social dilemma in the context of the ethical development of artificial\nintelligence. This formalism allows us to isolate variables that may be\nintervened upon, thus providing actionable suggestions for increased\ncooperation amongst numerous stakeholders in AI. Our results show how\nstochastic effects can help make cooperation viable in such a scenario. They\nsuggest that coordination for a common good should be attempted in smaller\ngroups in which the cost for cooperation is low, and the perceived risk of\nfailure is high. This provides insight into the conditions under which we\nshould expect such ethics proposals to be successful with regard to their\nscope, scale, and content.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 12:01:01 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:07:13 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["LaCroix", "Travis", ""], ["Mohseni", "Aydin", ""]]}, {"id": "2006.05267", "submitter": "Paul Intrevado", "authors": "Ashwini Badgujar, Sheng Chen, Andrew Wang, Kai Yu, Paul Intrevado,\n  David Guy Brizan", "title": "Quantum Criticism: A Tagged News Corpus Analysed for Sentiment and Named\n  Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research, we continuously collect data from the RSS feeds of\ntraditional news sources. We apply several pre-trained implementations of named\nentity recognition (NER) tools, quantifying the success of each implementation.\nWe also perform sentiment analysis of each news article at the document,\nparagraph and sentence level, with the goal of creating a corpus of tagged news\narticles that is made available to the public through a web interface. Finally,\nwe show how the data in this corpus could be used to identify bias in news\nreporting.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 17:59:12 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Badgujar", "Ashwini", ""], ["Chen", "Sheng", ""], ["Wang", "Andrew", ""], ["Yu", "Kai", ""], ["Intrevado", "Paul", ""], ["Brizan", "David Guy", ""]]}, {"id": "2006.05372", "submitter": "Tobias Welz", "authors": "Tobias Welz, Matthias Stuermer", "title": "Sustainability of ICT hardware procurement in Switzerland -- A\n  status-quo analysis of the public procurement sector", "comments": "11 pages, 9 Figures. Accepted to be presented at the ICT4S 2020\n  Conference", "journal-ref": null, "doi": "10.1145/3401335.3401352", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sustainable procurement requires organizations to align their purchasing\nbehavior with regard to broader goals linked to resource efficiency, climate\nchange, social responsibility and other sustainability criteria. The level of\nsustainability in Information and Communication Technology (ICT) hardware\nprocurement is analyzed for two reasons: First, ICT hardware belongs to the six\nkey product groups in sustainable procurement. Second, ICT in general is\nexpected to be an important enabler for low-carbon economies, providing\nsolutions to reduce Green-House Gas (GHG) emissions. While the advantages of\nsustainable procurement are obvious, certain barriers hinder the adoption in\nday-to-day procurement. This case study on ICT hardware discusses the three\nimportant barriers \"lack of clear definitions per product group\", \"missing\nmarket intelligence about sustainable products\" and \"inflexible procedures and\nattitudes as barriers for innovative approaches\" based on an in-depth analysis\nof sustainable procurement of ICT hardware by the public sector in Switzerland.\nTo this end, tender data published on the national procurement platform\nsimap.ch is screened for sustainability criteria using the Common Procurement\nVocabulary (CPV) nomenclature to identify relevant ICT projects. The results\nreveal to which extent such criteria as well as their determinants are\ncurrently included in public tenders. Using two different approaches, only a\nsmall number of tenders were found containing sustainability criteria of a wide\nrange from basic to comprehensive. The overall performance of Swiss public\nprocurement is benchmarked by comparing the identified sustainability criteria\nwith available criteria from international key actors in sustainable\nprocurement. Thus, this analysis provides novel insights on how public agencies\ntoday take sustainability into account when procuring ICT hardware.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 16:04:36 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Welz", "Tobias", ""], ["Stuermer", "Matthias", ""]]}, {"id": "2006.05483", "submitter": "Artyom Kosmarski", "authors": "Artyom Kosmarski", "title": "Blockchain in the management of science: conceptual models, promises and\n  challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain has received much attention recently, due to its promises of\nverifiable, permanent, decentralized, and efficient data handling. In 2017-2019\nblockchain and associated technologies such as smart contracts has progressed\nbeyond cryptocurrencies, and has been adopted in banking, retail, healthcare,\nand other fields. This study critically examines recent applications of\nblockchain in science, touching upon different stages of research cycle, from\ndata management to publishing, peer review, research evaluation and funding.\nThe paper is based upon a review of blockchain projects, relevant literature, a\nset of interviews and focus groups with startup founders, scholars, librarians,\nIT experts from the EU, USA, Russia, and Belarus. Proponents of blockchain for\nscience present this technology as a tool to make science free from bias, red\ntape, data fraud, as well as provide innovative means to secure financial\nbacking for new ideas. However, these projects face a set of challenges. One\nissue concerns introducing crypto economy, with its financial incentives, into\nscience, a field that emphasizes disinterested and non-pecuniary pursuit of\ntruth. Another source of concern relates to the ongoing conflict between the\nprinciple of decentralization inherent to blockchain and the practice of\nforcing it from above, by the state and other centralized entities.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 19:49:32 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kosmarski", "Artyom", ""]]}, {"id": "2006.05493", "submitter": "Adewale Akinfaderin", "authors": "Oyinlola Babafemi and Adewale Akinfaderin", "title": "Predicting and Analyzing Law-Making in Kenya", "comments": "Accepted at 4th Widening NLP Workshop, Annual Meeting of the\n  Association for Computational Linguistics, ACL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modelling and analyzing parliamentary legislation, roll-call votes and order\nof proceedings in developed countries has received significant attention in\nrecent years. In this paper, we focused on understanding the bills introduced\nin a developing democracy, the Kenyan bicameral parliament. We developed and\ntrained machine learning models on a combination of features extracted from the\nbills to predict the outcome - if a bill will be enacted or not. We observed\nthat the texts in a bill are not as relevant as the year and month the bill was\nintroduced and the category the bill belongs to.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 20:21:50 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Babafemi", "Oyinlola", ""], ["Akinfaderin", "Adewale", ""]]}, {"id": "2006.05703", "submitter": "Borja Martinez", "authors": "Borja Martinez and Xavier Vilajosana", "title": "Exploiting the Solar Energy Surplus for Edge Computing", "comments": null, "journal-ref": null, "doi": "10.1109/TSUSC.2021.3058588", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the global energy ecosystem transformation, we introduce a\nnew approach to reduce the carbon emissions of the cloud-computing sector and,\nat the same time, foster the deployment of small-scale private photovoltaic\nplants. We consider the opportunity cost of moving some cloud services to\nprivate, distributed, solar-powered computing facilities. To this end, we\ncompare the potential revenue of leasing computing resources to a cloud pool\nwith the revenue obtained by selling the surplus energy to the grid. We first\nestimate the consumption of virtualized cloud computing instances, establishing\na metric of computational efficiency per nominal photovoltaic power installed.\nBased on this metric and characterizing the site's annual solar production, we\nestimate the total return and payback. The results show that the model is\neconomically viable and technically feasible. We finally depict the still many\nquestions open, such as security, and the fundamental barriers to address,\nmainly related with a cloud model ruled by a few big players.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 07:52:28 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Martinez", "Borja", ""], ["Vilajosana", "Xavier", ""]]}, {"id": "2006.05709", "submitter": "Giulia Cisotto", "authors": "Andrea Zanella, Federico Mason, Patrik Pluchino, Giulia Cisotto,\n  Valeria Orso, Luciano Gamberini", "title": "Internet of Things for Elderly and Fragile People", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the potential of the Internet of Things (IoT) paradigm\nin the context of assisted living for elderly and fragile people, in the light\nof the peculiar requirements of such users, both from a functional and a\ntechnological perspective. We stress some aspects that are often disregarded by\nthe technical community, such as technology acceptability and usability, and we\ndescribe the framework and the phases of the current co-design approaches that\nimply the active involvement of the final users in the system design process.\nThereby, we identify a series of design practices to merge technical and\nfragile people's requirements. The discussion is backed up by the description\nof DOMHO, a prototypal IoT-based AAL system that embodies most of the concepts\ndescribed in the paper, and that is being deployed and tested in a shelter\nhouse for elders, and in an apartment for the co-housing of individuals with\ndisabilities. Finally, we discuss the potential and limits of the current\napproaches and present some open challenges and future research directions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 07:56:59 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Zanella", "Andrea", ""], ["Mason", "Federico", ""], ["Pluchino", "Patrik", ""], ["Cisotto", "Giulia", ""], ["Orso", "Valeria", ""], ["Gamberini", "Luciano", ""]]}, {"id": "2006.05777", "submitter": "Clemens Schreiber", "authors": "Clemens Schreiber", "title": "Automated Sustainability Compliance Checking Using Process Mining and\n  Formal Logic", "comments": null, "journal-ref": null, "doi": "10.1145/3401335.3401355", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business processes need to have certain constraints such that they can lead\nto sustainable outcomes. These constraints can be manifold and their adherence\nhas to be monitored. In the past compliance checking has been applied in\nseveral business domains without considering certain sustainability aspects,\nsuch as multi-dimensionality and impact level. With my research I want to\ncontribute to the application of compliance checking techniques for the purpose\nof sustainability compliance. In order to achieve this, I want to analyse and\ndevelop data-driven approaches, which allow to automate the task of compliance\nchecking. The way in which this can be achieved, is be combining methods from\nprocess mining with formal languages that can express sustainability rules in a\nmachine-readable manner. The main goal is to develop a compliance engine that\ncan be adapted by ERP systems in order to evaluate sustainability conformance\nin business processes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 11:07:57 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 11:48:19 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Schreiber", "Clemens", ""]]}, {"id": "2006.05810", "submitter": "Maiia Marienko", "authors": "Maiia Marienko, Yulia Nosenko, Alisa Sukhikh, Viktor Tataurov, Mariya\n  Shyshkina", "title": "Personalization of learning through adaptive technologies in the context\n  of sustainable development of teachers education", "comments": "8 pages, 2 figures, E3S Web of Conferences (166). ISSN 2267-1242", "journal-ref": null, "doi": "10.1051/e3sconf/202016610015", "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The article highlights the issues of personalized learning as the global\ntrend of the modern ICTbased educational systems development. The notion, the\nmain stages of evolution, the main features and principles of adaptive learning\nsystems application for teachers training are outlined. It is emphasized that\nthe use and elaboration of the adaptive cloud-based learning systems are\nessential to provide sustainable development of teachers education. The current\ntrends and peculiarities of the cloud-based adaptive learning systems\ndevelopment and approach of their implementation for teachers training are\nconsidered. The general model of the adaptive cloud-based learning system\nstructure is proposed. The main components of the model are described; the\nissues of tools and services selection are outlined. The methods of the\ncloudbased learning components introduction within the adaptive systems of\nteacher training are considered. The current research developments of modeling\nand implementation of the adaptive cloud-based systems are outlined.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 09:44:52 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Marienko", "Maiia", ""], ["Nosenko", "Yulia", ""], ["Sukhikh", "Alisa", ""], ["Tataurov", "Viktor", ""], ["Shyshkina", "Mariya", ""]]}, {"id": "2006.05812", "submitter": "Praneeth Vepakomma", "authors": "Ramesh Raskar, Greg Nadeau, John Werner, Rachel Barbar, Ashley Mehra,\n  Gabriel Harp, Markus Leopoldseder, Bryan Wilson, Derrick Flakoll, Praneeth\n  Vepakomma, Deepti Pahwa, Robson Beaudry, Emelin Flores, Maciej Popielarz,\n  Akanksha Bhatia, Andrea Nuzzo, Matt Gee, Jay Summet, Rajeev Surati, Bikram\n  Khastgir, Francesco Maria Benedetti, Kristen Vilcans, Sienna Leis, Khahlil\n  Louisy", "title": "COVID-19 Contact-Tracing Mobile Apps: Evaluation and Assessment for\n  Decision Makers", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of groups, from governments to non-profits, have quickly acted to\ninnovate the contact-tracing process: they are designing, building, and\nlaunching contact-tracing apps in response to the COVID-19 crisis. A diverse\nrange of approaches exist, creating challenging choices for officials looking\nto implement contact-tracing technology in their community and raising concerns\nabout these choices among citizens asked to participate in contact tracing. We\nare frequently asked how to evaluate and differentiate between the options for\ncontact-tracing applications. Here, we share the questions we ask about app\nfeatures and plans when reviewing the many contact-tracing apps appearing on\nthe global stage.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 02:08:02 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Raskar", "Ramesh", ""], ["Nadeau", "Greg", ""], ["Werner", "John", ""], ["Barbar", "Rachel", ""], ["Mehra", "Ashley", ""], ["Harp", "Gabriel", ""], ["Leopoldseder", "Markus", ""], ["Wilson", "Bryan", ""], ["Flakoll", "Derrick", ""], ["Vepakomma", "Praneeth", ""], ["Pahwa", "Deepti", ""], ["Beaudry", "Robson", ""], ["Flores", "Emelin", ""], ["Popielarz", "Maciej", ""], ["Bhatia", "Akanksha", ""], ["Nuzzo", "Andrea", ""], ["Gee", "Matt", ""], ["Summet", "Jay", ""], ["Surati", "Rajeev", ""], ["Khastgir", "Bikram", ""], ["Benedetti", "Francesco Maria", ""], ["Vilcans", "Kristen", ""], ["Leis", "Sienna", ""], ["Louisy", "Khahlil", ""]]}, {"id": "2006.05873", "submitter": "Gary White", "authors": "Gary White, Christian Cabrera, Andrei Palade, Fan Li, Siobhan Clarke", "title": "WasteNet: Waste Classification at the Edge for Smart Bins", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart Bins have become popular in smart cities and campuses around the world.\nThese bins have a compaction mechanism that increases the bins' capacity as\nwell as automated real-time collection notifications. In this paper, we propose\nWasteNet, a waste classification model based on convolutional neural networks\nthat can be deployed on a low power device at the edge of the network, such as\na Jetson Nano. The problem of segregating waste is a big challenge for many\ncountries around the world. Automated waste classification at the edge allows\nfor fast intelligent decisions in smart bins without needing access to the\ncloud. Waste is classified into six categories: paper, cardboard, glass, metal,\nplastic and other. Our model achieves a 97\\% prediction accuracy on the test\ndataset. This level of classification accuracy will help to alleviate some\ncommon smart bin problems, such as recycling contamination, where different\ntypes of waste become mixed with recycling waste causing the bin to be\ncontaminated. It also makes the bins more user friendly as citizens do not have\nto worry about disposing their rubbish in the correct bin as the smart bin will\nbe able to make the decision for them.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 14:57:58 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["White", "Gary", ""], ["Cabrera", "Christian", ""], ["Palade", "Andrei", ""], ["Li", "Fan", ""], ["Clarke", "Siobhan", ""]]}, {"id": "2006.05892", "submitter": "Geoffrey Goodell", "authors": "Geoffrey Goodell", "title": "Privacy by Design in Value-Exchange Systems", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article addresses some of the most contentious issues related to privacy\nin electronic payment systems, particularly the current zeitgeist of proposed\nsolutions for central bank digital currency.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 15:25:43 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Goodell", "Geoffrey", ""]]}, {"id": "2006.05907", "submitter": "Shahinur Alam", "authors": "Shahinur Alam, Md Sultan Mahmud, Mohammed Yeasin", "title": "Toward Building Safer Smart Homes for the People with Disabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Situational awareness is a critical foundation for the protection of human\nlife/properties and is challenging to maintain for people with disabilities\n(i.e., visual impairments and limited mobility). In this paper, we present a\ndialog enabled end-to-end assistive solution called \"SafeAccess\" to build a\nsafer smart home by providing situational awareness. The key functions of\nSafeAccess are: - 1) monitoring homes and identifying incoming persons; 2)\nhelping users in assessing incoming threats (e.g., burglary, robbery, gun\nviolence); and, 3) allowing users to grant safe access to homes for\nfriends/families. In this work, we focus on building a robust model for\ndetecting and recognizing person, generating image descriptions, and designing\na prototype for the smart door. To interact with the system, we implemented a\ndialog enabled smartphone app, especially for creating a personalized profile\nfrom face images or videos of friends/families. A Raspberry pi connected to the\nhome monitoring cameras captures the video frames and performs change detection\nto identify frames with activities. Then, we detect human presence using Faster\nr-cnn and extract faces using Multi-task Cascaded Convolutional Networks\n(MTCNN). Subsequently, we match the detected faces using FaceNet/support vector\nmachine (SVM) classifiers. The system notifies users with an MMS containing the\nname of incoming persons or as \"unknown\", scene image, facial description, and\ncontextual information. The users can grant access or call emergency services\nusing the SafeAccess app based on the received notification. Our system\nidentifies persons with an F-score 0.97 and recognizes items to generate image\ndescription with an average F-score 0.97.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 15:50:32 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Alam", "Shahinur", ""], ["Mahmud", "Md Sultan", ""], ["Yeasin", "Mohammed", ""]]}, {"id": "2006.05914", "submitter": "Jonas H\\\"ochst", "authors": "Lars Baumg\\\"artner (1), Alexandra Dmitrienko (3), Bernd Freisleben\n  (2), Alexander Gruler (2), Jonas H\\\"ochst (1 and 2), Joshua K\\\"uhlberg (1),\n  Mira Mezini (1), Richard Mitev (1), Markus Miettinen (1), Anel Muhamedagic\n  (1), Thien Duc Nguyen (1), Alvar Penning (2), Dermot Frederik Pustelnik (1),\n  Filipp Roos (3), Ahmad-Reza Sadeghi (1), Michael Schwarz (2), Christian Uhl\n  (2) ((1) TU Darmstadt, (2) Philipps-Universit\\\"at Marburg, (3) JMU\n  W\\\"urzburg)", "title": "Mind the GAP: Security & Privacy Risks of Contact Tracing Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Google and Apple have jointly provided an API for exposure notification in\norder to implement decentralized contract tracing apps using Bluetooth Low\nEnergy, the so-called \"Google/Apple Proposal\", which we abbreviate by \"GAP\". We\ndemonstrate that in real-world scenarios the current GAP design is vulnerable\nto (i) profiling and possibly de-anonymizing infected persons, and (ii)\nrelay-based wormhole attacks that basically can generate fake contacts with the\npotential of affecting the accuracy of an app-based contact tracing system. For\nboth types of attack, we have built tools that can easily be used on mobile\nphones or Raspberry Pis (e.g., Bluetooth sniffers). The goal of our work is to\nperform a reality check towards possibly providing empirical real-world\nevidence for these two privacy and security risks. We hope that our findings\nprovide valuable input for developing secure and privacy-preserving digital\ncontact tracing systems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 16:05:05 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 13:27:07 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Baumg\u00e4rtner", "Lars", "", "1 and 2"], ["Dmitrienko", "Alexandra", "", "1 and 2"], ["Freisleben", "Bernd", "", "1 and 2"], ["Gruler", "Alexander", "", "1 and 2"], ["H\u00f6chst", "Jonas", "", "1 and 2"], ["K\u00fchlberg", "Joshua", ""], ["Mezini", "Mira", ""], ["Mitev", "Richard", ""], ["Miettinen", "Markus", ""], ["Muhamedagic", "Anel", ""], ["Nguyen", "Thien Duc", ""], ["Penning", "Alvar", ""], ["Pustelnik", "Dermot Frederik", ""], ["Roos", "Filipp", ""], ["Sadeghi", "Ahmad-Reza", ""], ["Schwarz", "Michael", ""], ["Uhl", "Christian", ""]]}, {"id": "2006.05983", "submitter": "Steven Krieg", "authors": "Steven J. Krieg, Jennifer J. Schnur, Jermaine D. Marshall, Matthew M.\n  Schoenbauer, Nitesh V. Chawla", "title": "Pandemic Pulse: Unraveling and Modeling Social Signals during the\n  COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and begin to explore a collection of social data that represents\npart of the COVID-19 pandemic's effects on the United States. This data is\ncollected from a range of sources and includes longitudinal trends of news\ntopics, social distancing behaviors, community mobility changes, web searches,\nand more. This multimodal effort enables new opportunities for analyzing the\nimpacts such a pandemic has on the pulse of society. Our preliminary results\nshow that the number of COVID-19-related news articles published immediately\nafter the World Health Organization declared the pandemic on March 11, and that\nsince that time have steadily decreased---regardless of changes in the number\nof cases or public policies. Additionally, we found that politically moderate\nand scientifically-grounded sources have, relative to baselines measured before\nthe beginning of the pandemic, published a lower proportion of COVID-19 news\nthan more politically extreme sources. We suggest that further analysis of\nthese multimodal signals could produce meaningful social insights and present\nan interactive dashboard to aid further exploration.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 17:55:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Krieg", "Steven J.", ""], ["Schnur", "Jennifer J.", ""], ["Marshall", "Jermaine D.", ""], ["Schoenbauer", "Matthew M.", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "2006.06021", "submitter": "Rajnikant Sharma", "authors": "Michael Rechtin, Vince Feldman, Sam Klare, Nathan Riddle, Rajnikant\n  Sharma", "title": "Modeling and Simulation of COVID-19 Pandemic for Cincinnati Tri-State\n  Area", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use SIR model to simulate the COVID-19 pandemic for\nCincinnati Tri-State Area. We have built a representative population of\nCincinnati that includes movements for traveling to stores, schools,\nworkplaces, and traveling to friends houses. Using this model, we simulate the\neffect of quarantine, return to work, and panic buying. We show that that there\nwill be a second wave of infections when people return to work and significant\nincrease in number of infections when there is panic buying at stores with the\nannouncement of the quarantine measures.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 18:13:21 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:33:10 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Rechtin", "Michael", ""], ["Feldman", "Vince", ""], ["Klare", "Sam", ""], ["Riddle", "Nathan", ""], ["Sharma", "Rajnikant", ""]]}, {"id": "2006.06053", "submitter": "Sainyam Galhotra Mr", "authors": "Sainyam Galhotra, Karthikeyan Shanmugam, Prasanna Sattigeri and Kush\n  R. Varshney", "title": "Fair Data Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DB stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of machine learning (ML) in high-stakes societal decisions has\nencouraged the consideration of fairness throughout the ML lifecycle. Although\ndata integration is one of the primary steps to generate high quality training\ndata, most of the fairness literature ignores this stage. In this work, we\nconsider fairness in the integration component of data management, aiming to\nidentify features that improve prediction without adding any bias to the\ndataset. We work under the causal interventional fairness paradigm. Without\nrequiring the underlying structural causal model a priori, we propose an\napproach to identify a sub-collection of features that ensure the fairness of\nthe dataset by performing conditional independence tests between different\nsubsets of features. We use group testing to improve the complexity of the\napproach. We theoretically prove the correctness of the proposed algorithm to\nidentify features that ensure interventional fairness and show that sub-linear\nconditional independence tests are sufficient to identify these variables. A\ndetailed empirical evaluation is performed on real-world datasets to\ndemonstrate the efficacy and efficiency of our technique.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 20:20:10 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Galhotra", "Sainyam", ""], ["Shanmugam", "Karthikeyan", ""], ["Sattigeri", "Prasanna", ""], ["Varshney", "Kush R.", ""]]}, {"id": "2006.06074", "submitter": "Eric Veith", "authors": "Eric MSP Veith, Stephan Balduin, Nils Wenninghoff, Martin Tr\\\"oschel,\n  Lars Fischer, Astrid Nie{\\ss}e, Thomas Wolgast, Richard Sethmann, Bastian\n  Fraune, Torben Woltjen", "title": "Analyzing Power Grid, ICT, and Market Without Domain Knowledge Using\n  Distributed Artificial Intelligence", "comments": "Submitted to DACH Energy Informatics 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern cyber-physical systems (CPS), such as our energy infrastructure, are\nbecoming increasingly complex: An ever-higher share of Artificial Intelligence\n(AI)-based technologies use the Information and Communication Technology (ICT)\nfacet of energy systems for operation optimization, cost efficiency, and to\nreach CO2 goals worldwide. At the same time, markets with increased flexibility\nand ever shorter trade horizons enable the multi-stakeholder situation that is\nemerging in this setting. These systems still form critical infrastructures\nthat need to perform with highest reliability. However, today's CPS are\nbecoming too complex to be analyzed in the traditional monolithic approach,\nwhere each domain, e.g., power grid and ICT as well as the energy market, are\nconsidered as separate entities while ignoring dependencies and side-effects.\nTo achieve an overall analysis, we introduce the concept for an application of\ndistributed artificial intelligence as a self-adaptive analysis tool that is\nable to analyze the dependencies between domains in CPS by attacking them. It\neschews pre-configured domain knowledge, instead exploring the CPS domains for\nemergent risk situations and exploitable loopholes in codices, with a focus on\nrational market actors that exploit the system while still following the market\nrules.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:32:39 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Veith", "Eric MSP", ""], ["Balduin", "Stephan", ""], ["Wenninghoff", "Nils", ""], ["Tr\u00f6schel", "Martin", ""], ["Fischer", "Lars", ""], ["Nie\u00dfe", "Astrid", ""], ["Wolgast", "Thomas", ""], ["Sethmann", "Richard", ""], ["Fraune", "Bastian", ""], ["Woltjen", "Torben", ""]]}, {"id": "2006.06082", "submitter": "Subhabrata Majumdar", "authors": "Emily Dodwell, Cheryl Flynn, Balachander Krishnamurthy, Subhabrata\n  Majumdar, Ritwik Mitra", "title": "Towards Integrating Fairness Transparently in Industrial Applications", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous Machine Learning (ML) bias-related failures in recent years have led\nto scrutiny of how companies incorporate aspects of transparency and\naccountability in their ML lifecycles. Companies have a responsibility to\nmonitor ML processes for bias and mitigate any bias detected, ensure business\nproduct integrity, preserve customer loyalty, and protect brand image.\nChallenges specific to industry ML projects can be broadly categorized into\nprincipled documentation, human oversight, and need for mechanisms that enable\ninformation reuse and improve cost efficiency. We highlight specific roadblocks\nand propose conceptual solutions on a per-category basis for ML practitioners\nand organizational subject matter experts. Our systematic approach tackles\nthese challenges by integrating mechanized and human-in-the-loop components in\nbias detection, mitigation, and documentation of projects at various stages of\nthe ML lifecycle. To motivate the implementation of our system -- SIFT (System\nto Integrate Fairness Transparently) -- we present its structural primitives\nwith an example real-world use case on how it can be used to identify potential\nbiases and determine appropriate mitigation strategies in a participatory\nmanner.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:54:27 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 22:35:50 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 23:23:08 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dodwell", "Emily", ""], ["Flynn", "Cheryl", ""], ["Krishnamurthy", "Balachander", ""], ["Majumdar", "Subhabrata", ""], ["Mitra", "Ritwik", ""]]}, {"id": "2006.06148", "submitter": "Jan Kallberg", "authors": "Jan Kallberg, Stephen S. Hamilton", "title": "Resiliency by Retrograded Communication- The Revival of Shortwave as a\n  Military Communication Channel", "comments": "3600 words, submitted to IEEE venue 06/10/20 (2020-06-10)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last three decades, the great powers have become increasingly\ndependent on satellite communication (SATCOM), very high frequency (VHF), and\nultra-high frequency (UHF) providing high bandwidth line of sight (LOS)\ncommunications. These military communication channels lack resilience because\nan EW campaign can affect both VHF and SATCOM simultaneously. The 1940s\npreferred spectrum, high frequency (HF), with its different propagation\npatterns, offers an opportunity for military communication resiliency in the\n21st century. The concept of retrograding could give an operational advantage\nand create the ability to sustain communication in electronic warfare (EW)\nsaturated environment.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 01:54:04 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Kallberg", "Jan", ""], ["Hamilton", "Stephen S.", ""]]}, {"id": "2006.06167", "submitter": "Quyu Kong", "authors": "Quyu Kong, Rohit Ram and Marian-Andrei Rizoiu", "title": "Evently: Modeling and Analyzing Reshare Cascades with Hawkes Processes", "comments": "WSDM 2021 Demo", "journal-ref": "Proceedings of the 14th ACM International Conference on Web Search\n  and Data Mining, 2021", "doi": "10.1145/3437963.3441708", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling online discourse dynamics is a core activity in understanding the\nspread of information, both offline and online, and emergent online behavior.\nThere is currently a disconnect between the practitioners of online social\nmedia analysis -- usually social, political and communication scientists -- and\nthe accessibility to tools capable of examining online discussions of users.\nHere we present evently, a tool for modeling online reshare cascades, and\nparticularly retweet cascades, using self-exciting processes. It provides a\ncomprehensive set of functionalities for processing raw data from Twitter\npublic APIs, modeling the temporal dynamics of processed retweet cascades and\ncharacterizing online users with a wide range of diffusion measures. This tool\nis designed for researchers with a wide range of computer expertise, and it\nincludes tutorials and detailed documentation. We illustrate the usage of\nevently with an end-to-end analysis of online user behavior on a topical\ndataset relating to COVID-19. We show that, by characterizing users solely\nbased on how their content spreads online, we can disentangle influential users\nand online bots.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 03:13:35 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 07:16:45 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2021 12:14:23 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Kong", "Quyu", ""], ["Ram", "Rohit", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "2006.06217", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3), and Sara\n  Kingsley (4) ((1) Montreal AI Ethics Institute, (2) Microsoft, (3) McGill\n  University, (4) Carnegie Mellon University)", "title": "SECure: A Social and Environmental Certificate for AI Systems", "comments": "Accepted for presentation at the Canadian Society for Ecological\n  Economics 2020 Research Symposium, Tracing the Veins 2020, ICML 2020\n  Deploying and Monitoring Machine Learning Systems workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a world increasingly dominated by AI applications, an understudied aspect\nis the carbon and social footprint of these power-hungry algorithms that\nrequire copious computation and a trove of data for training and prediction.\nWhile profitable in the short-term, these practices are unsustainable and\nsocially extractive from both a data-use and energy-use perspective. This work\nproposes an ESG-inspired framework combining socio-technical measures to build\neco-socially responsible AI systems. The framework has four pillars:\ncompute-efficient machine learning, federated learning, data sovereignty, and a\nLEEDesque certificate.\n  Compute-efficient machine learning is the use of compressed network\narchitectures that show marginal decreases in accuracy. Federated learning\naugments the first pillar's impact through the use of techniques that\ndistribute computational loads across idle capacity on devices. This is paired\nwith the third pillar of data sovereignty to ensure the privacy of user data\nvia techniques like use-based privacy and differential privacy. The final\npillar ties all these factors together and certifies products and services in a\nstandardized manner on their environmental and social impacts, allowing\nconsumers to align their purchase with their values.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 06:10:46 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 12:39:45 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"], ["Kingsley", "Sara", ""]]}, {"id": "2006.06292", "submitter": "Wiebke Toussaint", "authors": "Wiebke Toussaint, Dave Van Veen, Courtney Irwin, Yoni Nachmany, Manuel\n  Barreiro-Perez, Elena D\\'iaz-Pel\\'aez, Sara Guerreiro de Sousa, Liliana\n  Mill\\'an, Pedro L. S\\'anchez, Antonio S\\'anchez-Puente, Jes\\'us\n  Sampedro-G\\'omez, P. Ignacio Dorado-D\\'iaz, V\\'ictor Vicente-Palacios", "title": "Design Considerations for High Impact, Automated Echocardiogram Analysis", "comments": "2.5 pages, ICML 2020 Machine Learning for Global Health Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has the potential to automate echocardiogram analysis for early\ndetection of heart disease. Based on a qualitative analysis of design concerns,\nthis study suggests that predicting normal heart function instead of disease\naccounts for data quality bias and significantly increases efficiency in\ncardiologists' workflows.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 09:57:05 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 09:01:10 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Toussaint", "Wiebke", ""], ["Van Veen", "Dave", ""], ["Irwin", "Courtney", ""], ["Nachmany", "Yoni", ""], ["Barreiro-Perez", "Manuel", ""], ["D\u00edaz-Pel\u00e1ez", "Elena", ""], ["de Sousa", "Sara Guerreiro", ""], ["Mill\u00e1n", "Liliana", ""], ["S\u00e1nchez", "Pedro L.", ""], ["S\u00e1nchez-Puente", "Antonio", ""], ["Sampedro-G\u00f3mez", "Jes\u00fas", ""], ["Dorado-D\u00edaz", "P. Ignacio", ""], ["Vicente-Palacios", "V\u00edctor", ""]]}, {"id": "2006.06300", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (Montreal AI Ethics Institute and Microsoft)", "title": "Montreal AI Ethics Institute's Response to Scotland's AI Strategy", "comments": "Submitted to the Scottish Government based on analysis by the MAIEI\n  staff supplemented by contributions from participants of the workshop hosted\n  by MAIEI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In January and February 2020, the Scottish Government released two documents\nfor review by the public regarding their artificial intelligence (AI) strategy.\nThe Montreal AI Ethics Institute (MAIEI) reviewed these documents and published\na response on 4 June 2020. MAIEI's response examines several questions that\ntouch on the proposed definition of AI; the people-centered nature of the\nstrategy; considerations to ensure that everyone benefits from AI; the\nstrategy's overarching vision; Scotland's AI ecosystem; the proposed strategic\nthemes; and how to grow public confidence in AI by building responsible and\nethical systems.\n  In addition to examining the points above, MAIEI suggests that the strategy\nbe extended to include considerations on biometric data and how that will be\nprocessed and used in the context of AI. It also highlights the importance of\ntackling head-on the inherently stochastic nature of deep learning systems and\ndeveloping concrete guidelines to ensure that these systems are built\nresponsibly and ethically, particularly as machine learning becomes more\naccessible. Finally, it concludes that any national AI strategy must clearly\naddress the measurements of success in regards to the strategy's stated goals\nand vision to ensure that they are interpreted and applied consistently. To do\nthis, there must be inclusion and transparency between those building the\nsystems and those using them in their work.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 10:08:17 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Gupta", "Abhishek", "", "Montreal AI Ethics Institute and Microsoft"]]}, {"id": "2006.06336", "submitter": "Vukosi Marivate", "authors": "Vukosi Marivate, Avashlin Moodley, Athandiwe Saba", "title": "Extracting and categorising the reactions to COVID-19 by the South\n  African public -- A social media study", "comments": "Under review for EMNLP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Social Media can be used to extract discussion topics during a disaster. With\nthe COVID-19 pandemic impact on South Africa, we need to understand how the law\nand regulation promulgated by the government in response to the pandemic\ncontrasts with discussion topics social media users have been engaging in. In\nthis work, we expand on traditional media analysis by using Social Media\ndiscussions driven by or directed to South African government officials. We\nfind topics that are similar as well as different in some cases. The findings\ncan inform further study into social media during disaster settings in South\nAfrica and beyond.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:19:43 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Marivate", "Vukosi", ""], ["Moodley", "Avashlin", ""], ["Saba", "Athandiwe", ""]]}, {"id": "2006.06340", "submitter": "Karen Renaud", "authors": "Karen Renaud, Paul van Schaik, Alastair Irons, Sara Wilford", "title": "2020 UK Lockdown Cyber Narratives: the Secure, the Insecure and the\n  Worrying", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the 23rd March 2020, the UK entered a period of lockdown in the face of a\ndeadly pandemic. While some were unable to work from home, many organisations\nwere forced to move their activities online. Here, we discuss the technologies\nthey used, from a privacy and security perspective. We also mention the\ncommunication failures that have exacerbated uncertainty and anxiety during the\ncrisis. An organisation could be driven to move their activities online by a\nrange of disasters, of which a global pandemic is only one. We seek, in this\npaper, to highlight the need for organisations to have contingency plans in\nplace for this kind of eventuality. The insecure usages and poor communications\nwe highlight are a symptom of a lack of advance pre-pandemic planning. We hope\nthat this paper will help organisations to plan more effectively for the\nfuture.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 11:28:42 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 07:54:27 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Renaud", "Karen", ""], ["van Schaik", "Paul", ""], ["Irons", "Alastair", ""], ["Wilford", "Sara", ""]]}, {"id": "2006.06510", "submitter": "Wenying Ji", "authors": "Yitong Li and Wenying Ji", "title": "Understanding the Dynamics of Information Flow During Disaster Response\n  Using Absorbing Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to derive a quantitative model to evaluate the impact of\ninformation flow on the effectiveness of disaster response. At the core of the\nmodel is a specialized absorbing Markov chain that models the process of\ndelivering federal assistance to the community while considering stakeholder\ninteractions and information flow uncertainty. Using the proposed model, the\nprobability of community satisfaction is computed to reflect the effectiveness\nof disaster response. A hypothetical example is provided to demonstrate the\napplicability and interpretability of the derived quantitative model.\nPractically, the research provides governmental stakeholders interpretable\ninsights for evaluating the impact of information flow on their disaster\nresponse effectiveness so that critical stakeholders can be targeted proactive\nactions for enhanced disaster response.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 15:28:42 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 22:43:47 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Li", "Yitong", ""], ["Ji", "Wenying", ""]]}, {"id": "2006.06761", "submitter": "Gregory Heileman", "authors": "Gregory L. Heileman, Hayden W. Free, Johnny Flynn, Camden Mackowiak,\n  Jerzy W. Jaromczyk, Chaouki T. Abdallah", "title": "Curricular Complexity Versus Quality of Computer Science Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research paper we describe a study that involves measuring the\ncomplexities of undergraduate curricula offered by computer science\ndepartments, and then comparing them to the quality of these departments, where\nquality is determined by a metric-based ranking system. The study objective was\nto determine whether or not a relationship exists between the quality of\ncomputer science departments and the complexity of the curricula they offer.\nThe relationship between curricular complexity and program quality was\npreviously investigated for the case of undergraduate electrical engineering\nprograms, with surprising results. It was found that if the US News & World\nReport Best Undergraduate Programs ranking is used as a proxy for quality, then\na statistically significant difference in curricular complexities exists\nbetween higher and lower quality electrical engineering programs. Furthermore,\nit was found that higher quality electrical engineering programs tend to have\nlower complexity curricula, and vice versa. In the study reported in this\npaper, a sufficient amount of data was collected in order to determine that an\ninverse relationship between program quality and curricular complexity also\nexists in undergraduate computer science departments. This brings up an\ninteresting question regarding the extent to which this phenomenon exists\nacross the spectrum of STEM disciplines.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 19:34:20 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Heileman", "Gregory L.", ""], ["Free", "Hayden W.", ""], ["Flynn", "Johnny", ""], ["Mackowiak", "Camden", ""], ["Jaromczyk", "Jerzy W.", ""], ["Abdallah", "Chaouki T.", ""]]}, {"id": "2006.06815", "submitter": "Jayati Dev", "authors": "Jayati Dev", "title": "Discussing Privacy and Surveillance on Twitter: A Case Study of COVID-19", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.14162.38083", "report-no": null, "categories": "cs.CY cs.CR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology is uniquely positioned to help us analyze large amounts of\ninformation to provide valuable insight during widespread public health\nconcerns, like the ongoing COVID-19 pandemic. In fact, information technology\ncompanies like Apple and Google have recently launched tools for contact\ntracing-the ability to process location data to determine the people who have\nbeen in contact with a possible patient, in order to contain the spread of the\nvirus. While China and Singapore have successfully led the effort, more and\nmore countries are now implementing such surveillance systems, raising\npotential privacy concerns about this long term surveillance. For example, it\nis not clear what happens to the information post-pandemic because people are\nmore likely to share their information during a global crisis without\ngovernments having to elaborate on their data policies. Digital Ethnography on\nTwitter, which has over 330 million users worldwide, with a majority in the\nUnited States where the pandemic has the worst effects provides a unique\nopportunity to learn about real-time opinions of the general public about\ncurrent affairs in a rather naturalistic setting. Consequently, it might be\nuseful to highlight the privacy concerns of users, should they exist, through\nanalysis of Twitter data and information sharing policies during unprecedented\npublic health outbreaks. This will allow governments to protect their citizens\nboth during and after health emergencies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 20:56:55 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Dev", "Jayati", ""]]}, {"id": "2006.06819", "submitter": "Nuoa Lei", "authors": "Nuoa Lei", "title": "A robust modeling framework for energy analysis of data centers", "comments": null, "journal-ref": null, "doi": "10.1145/3401335.3401648", "report-no": null, "categories": "cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Global digitalization has given birth to the explosion of digital services in\napproximately every sector of contemporary life. Applications of artificial\nintelligence, blockchain technologies, and internet of things are promising to\naccelerate digitalization further. As a consequence, the number of data\ncenters, which provide the services of data processing, storage, and\ncommunication services, is also increasing rapidly. Because data centers are\nenergy-intensive with significant and growing electricity demand, an energy\nmodel of data centers with temporal, spatial, and predictive analysis\ncapability is critical for guiding industry and governmental authorities for\nmaking technology investment decisions. However, current models fail to provide\nconsistent and high dimensional energy analysis for data centers due to severe\ndata gaps. This can be further attributed to the lack of the modeling\ncapabilities for energy analysis of data center components including IT\nequipment and data center cooling and power provisioning infrastructure in\ncurrent energy models. In this research, a technology-based modeling framework,\nin hybrid with a data-driven approach, is proposed to address the knowledge\ngaps in current data center energy models. The research aims to provide policy\nmakers and data center energy analysts with comprehensive understanding of data\ncenter energy use and efficiency opportunities and a better understanding of\nmacro-level data center energy demand and energy saving potentials, in addition\nto the technological barriers for adopting energy efficiency measures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 21:05:20 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Lei", "Nuoa", ""]]}, {"id": "2006.06928", "submitter": "Rima Hazra", "authors": "Rima Hazra and Aryan and Hardik Aggarwal and Matteo Marsili and\n  Animesh Mukherjee", "title": "Characterising authors on the extent of their paper acceptance: A case\n  study of the Journal of High Energy Physics", "comments": "Accepted in JCDL'2020", "journal-ref": null, "doi": "10.1145/3383583.3398527", "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New researchers are usually very curious about the recipe that could\naccelerate the chances of their paper getting accepted in a reputed forum\n(journal/conference). In search of such a recipe, we investigate the profile\nand peer review text of authors whose papers almost always get accepted at a\nvenue (Journal of High Energy Physics in our current work). We find authors\nwith high acceptance rate are likely to have a high number of citations, high\n$h$-index, higher number of collaborators etc. We notice that they receive\nrelatively lengthy and positive reviews for their papers. In addition, we also\nconstruct three networks -- co-reviewer, co-citation and collaboration network\nand study the network-centric features and intra- and inter-category edge\ninteractions. We find that the authors with high acceptance rate are more\n`central' in these networks; the volume of intra- and inter-category\ninteractions are also drastically different for the authors with high\nacceptance rate compared to the other authors. Finally, using the above set of\nfeatures, we train standard machine learning models (random forest, XGBoost)\nand obtain very high class wise precision and recall. In a followup discussion\nwe also narrate how apart from the author characteristics, the peer-review\nsystem might itself have a role in propelling the distinction among the\ndifferent categories which could lead to potential discrimination and\nunfairness and calls for further investigation by the system admins.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 03:26:25 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Hazra", "Rima", ""], ["Aryan", "", ""], ["Aggarwal", "Hardik", ""], ["Marsili", "Matteo", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "2006.06941", "submitter": "Huthaifa I. Ashqar", "authors": "Huthaifa I. Ashqar, Mohammed Elhenawy, Mahmoud Masoud, Andry\n  Rakotonirainy, and Hesham A. Rakha", "title": "Vulnerable Road User Detection Using Smartphone Sensors and Recurrence\n  Quantification Analysis", "comments": "Published in: 2019 IEEE Intelligent Transportation Systems Conference\n  (ITSC)", "journal-ref": "2019 IEEE Intelligent Transportation Systems Conference (ITSC),\n  Auckland, New Zealand, 2019, pp. 1054-1059", "doi": "10.1109/ITSC.2019.8917520", "report-no": null, "categories": "cs.CY cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast advancements of the Autonomous Vehicle (AV) industry, detection\nof Vulnerable Road Users (VRUs) using smartphones is critical for safety\napplications of Cooperative Intelligent Transportation Systems (C-ITSs). This\nstudy explores the use of low-power smartphone sensors and the Recurrence\nQuantification Analysis (RQA) features for this task. These features are\ncomputed over a thresholded similarity matrix extracted from nine channels:\naccelerometer, gyroscope, and rotation vector in each direction (x, y, and z).\nGiven the high-power consumption of GPS, GPS data is excluded. RQA features are\nadded to traditional time domain features to investigate the classification\naccuracy when using binary, four-class, and five-class Random Forest\nclassifiers. Experimental results show a promising performance when only using\nRQA features with a resulted accuracy of 98. 34% and a 98. 79% by adding time\ndomain features. Results outperform previous reported accuracy, demonstrating\nthat RQA features have high classifying capability with respect to VRU\ndetection.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 04:42:10 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ashqar", "Huthaifa I.", ""], ["Elhenawy", "Mohammed", ""], ["Masoud", "Mahmoud", ""], ["Rakotonirainy", "Andry", ""], ["Rakha", "Hesham A.", ""]]}, {"id": "2006.06945", "submitter": "Huthaifa I. Ashqar", "authors": "Huthaifa I. Ashqar, Mohammed H. Almannaa, Mohammed Elhenawy, Hesham A.\n  Rakha, and Leanna House", "title": "Smartphone Transportation Mode Recognition Using a Hierarchical Machine\n  Learning Classifier and Pooled Features From Time and Frequency Domains", "comments": null, "journal-ref": "IEEE Transactions on Intelligent Transportation Systems Volume: 20\n  , Issue: 1 , pp. 244-252, Jan. 2019", "doi": "10.1109/TITS.2018.2817658", "report-no": null, "categories": "cs.LG cs.CY physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a novel two-layer hierarchical classifier that increases\nthe accuracy of traditional transportation mode classification algorithms. This\npaper also enhances classification accuracy by extracting new frequency domain\nfeatures. Many researchers have obtained these features from global positioning\nsystem data; however, this data was excluded in this paper, as the system use\nmight deplete the smartphone's battery and signals may be lost in some areas.\nOur proposed two-layer framework differs from previous classification attempts\nin three distinct ways: 1) the outputs of the two layers are combined using\nBayes' rule to choose the transportation mode with the largest posterior\nprobability; 2) the proposed framework combines the new extracted features with\ntraditionally used time domain features to create a pool of features; and 3) a\ndifferent subset of extracted features is used in each layer based on the\nclassified modes. Several machine learning techniques were used, including\nk-nearest neighbor, classification and regression tree, support vector machine,\nrandom forest, and a heterogeneous framework of random forest and support\nvector machine. Results show that the classification accuracy of the proposed\nframework outperforms traditional approaches. Transforming the time domain\nfeatures to the frequency domain also adds new features in a new space and\nprovides more control on the loss of information. Consequently, combining the\ntime domain and the frequency domain features in a large pool and then choosing\nthe best subset results in higher accuracy than using either domain alone. The\nproposed two-layer classifier obtained a maximum classification accuracy of\n97.02%.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 04:56:52 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ashqar", "Huthaifa I.", ""], ["Almannaa", "Mohammed H.", ""], ["Elhenawy", "Mohammed", ""], ["Rakha", "Hesham A.", ""], ["House", "Leanna", ""]]}, {"id": "2006.07025", "submitter": "Abhishek Gupta", "authors": "Mirka Snyder Caron (1) and Abhishek Gupta (1 and 2) ((1) Montreal AI\n  Ethics Institute, (2) Microsoft)", "title": "Response to Office of the Privacy Commissioner of Canada Consultation\n  Proposals pertaining to amendments to PIPEDA relative to Artificial\n  Intelligence", "comments": "Submitted to the Office of the Privacy Commissioner of Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In February 2020, the Montreal AI Ethics Institute (MAIEI) was invited by the\nOffice of the Privacy Commissioner of Canada (OPCC) to provide for comments\nboth at a closed roundtable and in writing on the OPCC consultation proposal\nfor amendments relative to Artificial Intelligence (AI), to the Canadian\nprivacy legislation, the Personal Information Protection and Electronic\nDocuments Act (PIPEDA). The present document includes MAIEI comments and\nrecommendations in writing. Per MAIEI's mission and mandate to act as a\ncatalyst for public feedback pertaining to AI Ethics and regulatory technology\ndevelopments, as well as to provide for public competence-building workshops on\ncritical topics in such domains, the reader will also find such public feedback\nand propositions by Montrealers who participated at MAIEI's workshops,\nsubmitted as Schedule 1 to the present report. For each of OPCC 12 proposals,\nand underlying questions, as described on its website, MAIEI provides a short\nreply, a summary list of recommendations, as well as comments relevant to the\nquestion at hand. We leave you with three general statements to keep in mind\nwhile going through the next pages:\n  1) AI systems should be used to augment human capacity for meaningful and\npurposeful connections and associations, not as a substitute for trust.\n  2) Humans have collectively accepted to uphold the rule of law, but for\nmachines, the code is rule. Where socio-technical systems are deployed to make\nimportant decisions, profiles or inferences about individuals, we will\nincreasingly have to attempt the difficult exercise of drafting and encoding\nour law in a manner learnable by machines.\n  3) Let us work collectively towards a world where Responsible AI becomes the\nrule, before our socio-technical systems become \"too connected to fail\".\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:20:04 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Caron", "Mirka Snyder", "", "1 and 2"], ["Gupta", "Abhishek", "", "1 and 2"]]}, {"id": "2006.07087", "submitter": "Salah Ghamizi", "authors": "Salah Ghamizi, Renaud Rwemalika, Lisa Veiber, Maxime Cordy, Tegawende\n  F. Bissyande, Mike Papadakis, Jacques Klein and Yves Le Traon", "title": "Data-driven Simulation and Optimization for Covid-19 Exit Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid spread of the Coronavirus SARS-2 is a major challenge that led\nalmost all governments worldwide to take drastic measures to respond to the\ntragedy. Chief among those measures is the massive lockdown of entire countries\nand cities, which beyond its global economic impact has created some deep\nsocial and psychological tensions within populations. While the adopted\nmitigation measures (including the lockdown) have generally proven useful,\npolicymakers are now facing a critical question: how and when to lift the\nmitigation measures? A carefully-planned exit strategy is indeed necessary to\nrecover from the pandemic without risking a new outbreak. Classically, exit\nstrategies rely on mathematical modeling to predict the effect of public health\ninterventions. Such models are unfortunately known to be sensitive to some key\nparameters, which are usually set based on rules-of-thumb.In this paper, we\npropose to augment epidemiological forecasting with actual data-driven models\nthat will learn to fine-tune predictions for different contexts (e.g., per\ncountry). We have therefore built a pandemic simulation and forecasting toolkit\nthat combines a deep learning estimation of the epidemiological parameters of\nthe disease in order to predict the cases and deaths, and a genetic algorithm\ncomponent searching for optimal trade-offs/policies between constraints and\nobjectives set by decision-makers. Replaying pandemic evolution in various\ncountries, we experimentally show that our approach yields predictions with\nmuch lower error rates than pure epidemiological models in 75% of the cases and\nachieves a 95% R2 score when the learning is transferred and tested on unseen\ncountries. When used for forecasting, this approach provides actionable\ninsights into the impact of individual measures and strategies.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 11:18:25 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Ghamizi", "Salah", ""], ["Rwemalika", "Renaud", ""], ["Veiber", "Lisa", ""], ["Cordy", "Maxime", ""], ["Bissyande", "Tegawende F.", ""], ["Papadakis", "Mike", ""], ["Klein", "Jacques", ""], ["Traon", "Yves Le", ""]]}, {"id": "2006.07140", "submitter": "Arosha Bandara", "authors": "Camilla Elphick, Richard Philpot, Min Zhang, Avelie Stuart, Zoe\n  Walkington, Lara Frumkin, Graham Pike, Kelly Gardner, Mark Lacey, Mark\n  Levine, Blaine Price, Arosha Bandara and Bashar Nuseibeh", "title": "Building trust in digital policing: A scoping review of community\n  policing apps", "comments": "Police Practice and Research (Taylor & Francis) 2020", "journal-ref": null, "doi": "10.1080/15614263.2020.1861449", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptions of police trustworthiness are linked to citizens' willingness to\ncooperate with police. Trust can be fostered by introducing accountability\nmechanisms, or by increasing a shared police/citizen identity, both which can\nbe achieved digitally. Digital mechanisms can also be designed to safeguard,\nengage, reassure, inform, and empower diverse communities. We systematically\nscoped 240 existing online citizen-police and relevant third-party\ncommunication apps, to examine whether they sought to meet community needs and\npolicing visions. We found that 82% required registration or login details, 55%\nof those with a reporting mechanism allowed for anonymous reporting, and 10%\nprovided an understandable privacy policy. Police apps were more likely to seek\nto reassure, safeguard and inform users, while third-party apps were more\nlikely to seek to empower users. As poorly designed apps risk amplifying\nmistrust and undermining policing efforts, we suggest 12 design considerations\nto help ensure the development of high quality/fit for purpose Police/Citizen\napps.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 12:52:42 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 19:38:19 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Elphick", "Camilla", ""], ["Philpot", "Richard", ""], ["Zhang", "Min", ""], ["Stuart", "Avelie", ""], ["Walkington", "Zoe", ""], ["Frumkin", "Lara", ""], ["Pike", "Graham", ""], ["Gardner", "Kelly", ""], ["Lacey", "Mark", ""], ["Levine", "Mark", ""], ["Price", "Blaine", ""], ["Bandara", "Arosha", ""], ["Nuseibeh", "Bashar", ""]]}, {"id": "2006.07153", "submitter": "Arosha Bandara", "authors": "Camilla Elphick, Avelie Stuart, Richard Philpot, Zoe Walkington, Lara\n  Frumkin, Min Zhang, Mark Levine, Blaine Price, Graham Pike, Bashar Nuseibeh,\n  Arosha Bandara", "title": "Altruism and anxiety: Engagement with online community support\n  initiatives (OCSIs) during Covid-19 lockdown in the UK and Ireland", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given concerns about mental health during periods of Covid-19 lockdown, it\nimportant to understand how engagement with online Covid-19 related material\ncan affect mood. In the UK and Ireland, online community support initiatives\n(OCSIs) have emerged to help people manage their lives. Yet, little is known\nabout how people engaged with these or whether they influenced subsequent mood.\nWe conducted surveys to explore how people in the UK and Ireland engaged with\nOCSIs, and found that 70% did so to offer support (e.g. to provide company).\nThose who did so reported feeling significantly calmer afterwards, those who\nengaged for general concerns (e.g. in response to anti-social behaviour)\nreported feeling significantly more anxious afterwards, but there was no\ndifference in reported mood for those who engaged for other reasons (e.g. to\nshare experiences or views). Thus, engaging with an OCSI for altruistic\npurposes might help to make people feel calmer.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 13:09:42 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Elphick", "Camilla", ""], ["Stuart", "Avelie", ""], ["Philpot", "Richard", ""], ["Walkington", "Zoe", ""], ["Frumkin", "Lara", ""], ["Zhang", "Min", ""], ["Levine", "Mark", ""], ["Price", "Blaine", ""], ["Pike", "Graham", ""], ["Nuseibeh", "Bashar", ""], ["Bandara", "Arosha", ""]]}, {"id": "2006.07204", "submitter": "Arun Sundararajan", "authors": "Manav Raj, Arun Sundararajan, Calum You", "title": "COVID-19 and Digital Resilience: Evidence from Uber Eats", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze how digital platforms can increase the survival rate of firms\nduring a crisis by providing continuity in access to customers. Using\norder-level data from Uber Technologies, we study how the COVID-19 pandemic and\nthe ensuing shutdown of businesses in the United States affected independent,\nsmall business restaurant supply and demand on the Uber Eats platform. We find\nevidence that small restaurants experience significant increases in total\nactivity, orders per day, and orders per hour following the closure of the\ndine-in channel, and that these increases may be due to both demand-side and\nsupply-side shocks. We document an increase in the intensity of competitive\neffects following the shock, showing that growth in the number of providers on\na platform induces both market expansion and heightened inter-provider\ncompetition. Our findings underscore the critical role that digital will play\nin creating business resilience in the post-COVID economy, and provide new\nmanagerial insight into how supply-side and demand-side factors shape business\nperformance on a platform.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:08:45 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Raj", "Manav", ""], ["Sundararajan", "Arun", ""], ["You", "Calum", ""]]}, {"id": "2006.07211", "submitter": "Kimon Kieslich", "authors": "Kimon Kieslich, Marco L\\\"unich, Frank Marcinkowski", "title": "The Threats of Artificial Intelligence Scale (TAI). Development,\n  Measurement and Test Over Three Application Domains", "comments": null, "journal-ref": null, "doi": "10.1007/s12369-020-00734-w", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years Artificial Intelligence (AI) has gained much popularity, with\nthe scientific community as well as with the public. AI is often ascribed many\npositive impacts for different social domains such as medicine and the economy.\nOn the other side, there is also growing concern about its precarious impact on\nsociety and individuals. Several opinion polls frequently query the public fear\nof autonomous robots and artificial intelligence (FARAI), a phenomenon coming\nalso into scholarly focus. As potential threat perceptions arguably vary with\nregard to the reach and consequences of AI functionalities and the domain of\napplication, research still lacks necessary precision of a respective\nmeasurement that allows for wide-spread research applicability. We propose a\nfine-grained scale to measure threat perceptions of AI that accounts for four\nfunctional classes of AI systems and is applicable to various domains of AI\napplications. Using a standardized questionnaire in a survey study (N=891), we\nevaluate the scale over three distinct AI domains (loan origination, job\nrecruitment and medical treatment). The data support the dimensional structure\nof the proposed Threats of AI (TAI) scale as well as the internal consistency\nand factoral validity of the indicators. Implications of the results and the\nempirical application of the scale are discussed in detail. Recommendations for\nfurther empirical use of the TAI scale are provided.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:15:02 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Kieslich", "Kimon", ""], ["L\u00fcnich", "Marco", ""], ["Marcinkowski", "Frank", ""]]}, {"id": "2006.07311", "submitter": "Edward Oughton", "authors": "Edward J. Oughton and Jatin Mathur", "title": "Predicting cell phone adoption metrics using satellite imagery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximately half of the global population does not have access to the\ninternet, even though digital connectivity can reduce poverty by\nrevolutionizing economic development opportunities. Due to a lack of data,\nMobile Network Operators and governments struggle to effectively determine if\ninfrastructure investments are viable, especially in greenfield areas where\ndemand is unknown. This leads to a lack of investment in network\ninfrastructure, resulting in a phenomenon commonly referred to as the `digital\ndivide`. In this paper we present a machine learning method that uses publicly\navailable satellite imagery to predict telecoms demand metrics, including cell\nphone adoption and spending on mobile services, and apply the method to Malawi\nand Ethiopia. Our predictive machine learning approach consistently outperforms\nbaseline models which use population density or nightlight luminosity, with an\nimprovement in data variance prediction of at least 40%. The method is a\nstarting point for developing more sophisticated predictive models of\ninfrastructure demand using machine learning and publicly available satellite\nimagery. The evidence produced can help to better inform infrastructure\ninvestment and policy decisions.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 16:47:45 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 08:48:52 GMT"}, {"version": "v3", "created": "Tue, 1 Dec 2020 09:36:19 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 18:00:14 GMT"}, {"version": "v5", "created": "Tue, 8 Jun 2021 20:52:14 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Oughton", "Edward J.", ""], ["Mathur", "Jatin", ""]]}, {"id": "2006.07488", "submitter": "Christopher Gorham", "authors": "Christopher Gorham", "title": "The 4th Industrial Revolution Effect on the Enterprise Cyber Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Fourth (4th) Industrial Revolution represents the profound advancement of\ntechnology that will likely transform the boundaries between the digital and\nphysical worlds in modern society. The impact of advance technology will\ndisrupt almost every aspect of business and government communities alike. In\nthe past few years, the advancement of information technologies has opened the\ndoor to artificial intelligence (AI), block chain technologies, robotics,\nvirtual reality and the possibility of quantum computing being released in the\ncommercial sector. The use of these innovative technologies will likely impact\nsociety by leveraging modern technological platforms such as cloud computing\nand AI. This also includes the release of 5G network technologies by Internet\nService Providers (ISP) beginning in 2019. Networks that rely upon 5G\ntechnologies in combination with cloud computing platforms will open the door\nallow greater innovations and change the nature of how work is performed in the\n4th Industrial Revolution.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 22:04:11 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Gorham", "Christopher", ""]]}, {"id": "2006.07516", "submitter": "Am\\'ilcar Soares", "authors": "Fateha Khanam Bappee, Lucas May Petry, Amilcar Soares, Stan Matwin", "title": "Analyzing the Impact of Foursquare and Streetlight Data with Human\n  Demographics on Future Crime Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding the factors contributing to criminal activities and their\nconsequences is essential to improve quantitative crime research. To respond to\nthis concern, we examine an extensive set of features from different\nperspectives and explanations. Our study aims to build data-driven models for\npredicting future crime occurrences. In this paper, we propose the use of\nstreetlight infrastructure and Foursquare data along with demographic\ncharacteristics for improving future crime incident prediction. We evaluate the\nclassification performance based on various feature combinations as well as\nwith the baseline model. Our proposed model was tested on each smallest\ngeographic region in Halifax, Canada. Our findings demonstrate the\neffectiveness of integrating diverse sources of data to gain satisfactory\nclassification performance.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 00:11:20 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Bappee", "Fateha Khanam", ""], ["Petry", "Lucas May", ""], ["Soares", "Amilcar", ""], ["Matwin", "Stan", ""]]}, {"id": "2006.07558", "submitter": "Kyle Dent", "authors": "Kyle Dent", "title": "Ethical Considerations for AI Researchers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of artificial intelligence is growing and expanding into applications\nthat impact people's lives. People trust their technology without really\nunderstanding it or its limitations. There is the potential for harm and we are\nalready seeing examples of that in the world. AI researchers have an obligation\nto consider the impact of intelligent applications they work on. While the\nethics of AI is not clear-cut, there are guidelines we can consider to minimize\nthe harm we might introduce.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 04:31:42 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Dent", "Kyle", ""]]}, {"id": "2006.07563", "submitter": "Huthaifa I. Ashqar", "authors": "Huthaifa I. Ashqar, Mohammed Elhenawy, and Hesham A.Rakha", "title": "Modeling bike counts in a bike-sharing system considering the effect of\n  weather conditions", "comments": "Published in Case Studies on Transport Policy (Volume 7, Issue 2,\n  June 2019, Pages 261-268)", "journal-ref": "Case studies on transport policy 7, no. 2 (2019): 261-268", "doi": "10.1016/j.cstp.2019.02.011", "report-no": null, "categories": "cs.CY cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops a method that quantifies the effect of weather conditions\non the prediction of bike station counts in the San Francisco Bay Area Bike\nShare System. The Random Forest technique was used to rank the predictors that\nwere then used to develop a regression model using a guided forward step-wise\nregression approach. The Bayesian Information Criterion was used in the\ndevelopment and comparison of the various prediction models. We demonstrated\nthat the proposed approach is promising to quantify the effect of various\nfeatures on a large BSS and on each station in cases of large networks with big\ndata. The results show that the time-of-the-day, temperature, and humidity\nlevel (which has not been studied before) are significant count predictors. It\nalso shows that as weather variables are geographic location dependent and thus\nshould be quantified before using them in modeling. Further, findings show that\nthe number of available bikes at station i at time t-1 and time-of-the-day were\nthe most significant variables in estimating the bike counts at station i.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 05:32:32 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ashqar", "Huthaifa I.", ""], ["Elhenawy", "Mohammed", ""], ["Rakha", "Hesham A.", ""]]}, {"id": "2006.07590", "submitter": "Harshavardhan Kamarthi", "authors": "Siddharth Nishtala, Harshavardhan Kamarthi, Divy Thakkar, Dhyanesh\n  Narayanan, Anirudh Grama, Aparna Hegde, Ramesh Padmanabhan, Neha Madhiwalla,\n  Suresh Chaudhary, Balaraman Ravindran, Milind Tambe", "title": "Missed calls, Automated Calls and Health Support: Using AI to improve\n  maternal health outcomes by increasing program engagement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  India accounts for 11% of maternal deaths globally where a woman dies in\nchildbirth every fifteen minutes. Lack of access to preventive care information\nis a significant problem contributing to high maternal morbidity and mortality\nnumbers, especially in low-income households. We work with ARMMAN, a non-profit\nbased in India, to further the use of call-based information programs by\nearly-on identifying women who might not engage on these programs that are\nproven to affect health parameters positively.We analyzed anonymized\ncall-records of over 300,000 women registered in an awareness program created\nby ARMMAN that uses cellphone calls to regularly disseminate health related\ninformation. We built robust deep learning based models to predict short term\nand long term dropout risk from call logs and beneficiaries' demographic\ninformation. Our model performs 13% better than competitive baselines for\nshort-term forecasting and 7% better for long term forecasting. We also discuss\nthe applicability of this method in the real world through a pilot validation\nthat uses our method to perform targeted interventions.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 08:32:41 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 13:23:33 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 23:17:36 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Nishtala", "Siddharth", ""], ["Kamarthi", "Harshavardhan", ""], ["Thakkar", "Divy", ""], ["Narayanan", "Dhyanesh", ""], ["Grama", "Anirudh", ""], ["Hegde", "Aparna", ""], ["Padmanabhan", "Ramesh", ""], ["Madhiwalla", "Neha", ""], ["Chaudhary", "Suresh", ""], ["Ravindran", "Balaraman", ""], ["Tambe", "Milind", ""]]}, {"id": "2006.07618", "submitter": "Ali AlSoufi Dr.", "authors": "Abdulkarim Katbi, Jaflah AlAmmari, Ali AlSoufi", "title": "The Demand Side of Open Government Data: A Case Study of Kingdom of\n  Bahrain", "comments": "18 pages, 6 figures, 7 tables, Journal", "journal-ref": "International Journal of Managing Information Technology (IJMIT),\n  VOlume 12, Number 2, May 2020", "doi": "10.5121/ijmit.2020.12203", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Governments around the world have realized the importance of Open Government\nData (OGD) as a new paradigm shift in government that focuses on making\ngovernments more service-oriented, transparent, and competent. However, as with\nmany countries, the situation of the OGD initiative in the Kingdom of Bahrain\nis not promising as reflected by a number of assessments that measure the\nimplementation and progress of OGD worldwide. The current research aims at\ninvesting in the local situation regarding consuming and reusing OGD in the\nKingdom of Bahrain. Specifically, this research assesses the level of citizen\nawareness towards OGD, determines citizens requirements of OGD, and identifies\nthe key challenges and obstacles in using/reusing OGD. A questionnaire was\ndeveloped to investigate the demand side of OGD. The findings show that serious\nand responsible efforts from the publishers of OGD, namely: Government\nOrganizations are believed to be a necessity in order to progress the\nimplementation process of the OGD initiative in the Kingdom of Bahrain.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 11:15:50 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Katbi", "Abdulkarim", ""], ["AlAmmari", "Jaflah", ""], ["AlSoufi", "Ali", ""]]}, {"id": "2006.07647", "submitter": "Ivan Smirnov", "authors": "Ivan Smirnov, Florian Lemmerich, Markus Strohmaier", "title": "Quota-based debiasing can decrease representation of already\n  underrepresented groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important decisions in societies such as school admissions, hiring, or\nelections are based on the selection of top-ranking individuals from a larger\npool of candidates. This process is often subject to biases, which typically\nmanifest as an under-representation of certain groups among the selected or\naccepted individuals. The most common approach to this issue is debiasing, for\nexample via the introduction of quotas that ensure proportional representation\nof groups with respect to a certain, often binary attribute. Cases include\nquotas for women on corporate boards or ethnic quotas in elections. This,\nhowever, has the potential to induce changes in representation with respect to\nother attributes. For the case of two correlated binary attributes we show that\nquota-based debiasing based on a single attribute can worsen the representation\nof already underrepresented groups and decrease overall fairness of selection.\nWe use several data sets from a broad range of domains from recidivism risk\nassessments to scientific citations to assess this effect in real-world\nsettings. Our results demonstrate the importance of including all relevant\nattributes in debiasing procedures and that more efforts need to be put into\neliminating the root causes of inequalities as purely numerical solutions such\nas quota-based debiasing might lead to unintended consequences.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 14:26:42 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Smirnov", "Ivan", ""], ["Lemmerich", "Florian", ""], ["Strohmaier", "Markus", ""]]}, {"id": "2006.07860", "submitter": "Mohammad Rahaman", "authors": "Farzana Afrin, Mohammad Saiedur Rahaman, Margaret Hamilton", "title": "Mining Student Responses to Infer Student Satisfaction Predictors", "comments": "Seventh International Conference on Learning and Teaching in\n  Computing and Engineering (LaTiCE'20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification and analysis of student satisfaction is a challenging\nissue. This is becoming increasingly important since a measure of student\nsatisfaction is taken as an indication of how well a course has been taught.\nHowever, it remains a challenging problem as student satisfaction has various\naspects. In this paper, we formulate the student satisfaction estimation as a\nprediction problem where we predict different levels of student satisfaction\nand infer the influential predictors related to course and instructor. We\npresent five different aspects of student satisfaction in terms of 1) course\ncontent, 2) class participation, 3) achievement of initial expectations about\nthe course, 4) relevancy towards professional development, and 5) if the course\nconnects them and helps to explore the real-world situations. We employ\nstate-of-the-art machine learning techniques to predict each of these aspects\nof student satisfaction levels. For our experiment, we utilize a large student\nevaluation dataset which includes student perception using different attributes\nrelated to courses and the instructors. Our experimental results and\ncomprehensive analysis reveal that student satisfaction is more influenced by\ncourse attributes in comparison to instructor related attributes.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 10:31:11 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Afrin", "Farzana", ""], ["Rahaman", "Mohammad Saiedur", ""], ["Hamilton", "Margaret", ""]]}, {"id": "2006.07967", "submitter": "Mozhdeh Sadighi", "authors": "Mozhdeh Sadighi, Mohammad Mahdi Ghobadi, Seyyed Hossein Hasanpour\n  Matikolaee", "title": "Identification of main factors affecting trust and determination of\n  their importance in electronic businesses in Iran", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, trust has become one of the main concerns of the electronic business\nin Iran. The role of trust especially in electronic businesses those directly\ndeal with selling physical goods through internet is a lot more evident.\nReviewing literature shows that several factors affect establishing of trust in\npotential customers. Since trust establishment needs to be noticed in each\ntriple stages of an electronic purchase (before, during and finally after\npurchase). In this study by using field research, the importance of influential\nfactors affecting the potential customers in three stages of an electronic\npurchase is determined. Based on the results from conducting the research, the\ncertainty of traceability of the purchase with importance factor of 85.97% in\npre-purchase stage, safety of transactions and the time of delivery of goods\nwith the importance factor of 85.67% in the middle stage of the purchase and\nreceiving a fault-free and undamaged good with the importance factor of 89.55%\nin the post purchase stage make up the top three most important factors.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 18:17:57 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Sadighi", "Mozhdeh", ""], ["Ghobadi", "Mohammad Mahdi", ""], ["Matikolaee", "Seyyed Hossein Hasanpour", ""]]}, {"id": "2006.07980", "submitter": "Germ\\'an Alf\\'erez", "authors": "Merari Gonz\\'alez, Germ\\'an H. Alf\\'erez", "title": "Application of Data Science to Discover Violence-Related Issues in Iraq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science has been satisfactorily used to discover social issues in\nseveral parts of the world. However, there is a lack of governmental open data\nto discover those issues in countries such as Iraq. This situation arises the\nfollowing questions: how to apply data science principles to discover social\nissues despite the lack of open data in Iraq? How to use the available data to\nmake predictions in places without data? Our contribution is the application of\ndata science to open non-governmental big data from the Global Database of\nEvents, Language, and Tone (GDELT) to discover particular violence-related\nsocial issues in Iraq. Specifically we applied the K-Nearest Neighbors, N\\\"aive\nBayes, Decision Trees, and Logistic Regression classification algorithms to\ndiscover the following issues: refugees, humanitarian aid, violent protests,\nfights with artillery and tanks, and mass killings. The best results were\nobtained with the Decision Trees algorithm to discover areas with refugee\ncrises and artillery fights. The accuracy for these two events is 0.7629. The\nprecision to discover the locations of refugee crises is 0.76, the recall is\n0.76, and the F1-score is 0.76. Also, our approach discovers the locations of\nartillery fights with a precision of 0.74, a recall of 0.75, and a F1-score of\n0.75.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 18:58:25 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Gonz\u00e1lez", "Merari", ""], ["Alf\u00e9rez", "Germ\u00e1n H.", ""]]}, {"id": "2006.07986", "submitter": "Sanghamitra Dutta", "authors": "Sanghamitra Dutta, Praveen Venkatesh, Piotr Mardziel, Anupam Datta,\n  Pulkit Grover", "title": "Fairness Under Feature Exemptions: Counterfactual and Observational\n  Measures", "comments": "Journal version (Shorter version was accepted at AAAI 2020 as an oral\n  presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.CY cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing use of AI in highly consequential domains, the\nquantification and removal of bias with respect to protected attributes, such\nas gender, race, etc., is becoming increasingly important. While quantifying\nbias is essential, sometimes the needs of a business (e.g., hiring) may require\nthe use of certain features that are critical in a way that any bias that can\nbe explained by them might need to be exempted. E.g., a standardized test-score\nmay be a critical feature that should be weighed strongly in hiring even if\nbiased, whereas other features, such as zip code may be used only to the extent\nthat they do not discriminate. In this work, we propose a novel\ninformation-theoretic decomposition of the total bias (in a counterfactual\nsense) into a non-exempt component that quantifies the part of the bias that\ncannot be accounted for by the critical features, and an exempt component which\nquantifies the remaining bias. This decomposition allows one to check if the\nbias arose purely due to the critical features (inspired from the business\nnecessity defense of disparate impact law) and also enables selective removal\nof the non-exempt component if desired. We arrive at this decomposition through\nexamples that lead to a set of desirable properties (axioms) that any measure\nof non-exempt bias should satisfy. We demonstrate that our proposed\ncounterfactual measure satisfies all of them. Our quantification bridges ideas\nof causality, Simpson's paradox, and a body of work from information theory\ncalled Partial Information Decomposition. We also obtain an impossibility\nresult showing that no observational measure of non-exempt bias can satisfy all\nof the desirable properties, which leads us to relax our goals and examine\nobservational measures that satisfy only some of these properties. We then\nperform case studies to show how one can train models while reducing non-exempt\nbias.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 19:14:00 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Venkatesh", "Praveen", ""], ["Mardziel", "Piotr", ""], ["Datta", "Anupam", ""], ["Grover", "Pulkit", ""]]}, {"id": "2006.08016", "submitter": "Aron Laszka", "authors": "Go Yamamoto, Aron Laszka, Fuhito Kojima", "title": "Equilibrium of Blockchain Miners with Dynamic Asset Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model and analyze blockchain miners who seek to maximize the compound\nreturn of their mining businesses. The analysis of the optimal strategies finds\na new equilibrium point among the miners and the mining pools, which predicts\nthe market share of each miner or mining pool. The cost of mining determines\nthe share of each miner or mining pool at equilibrium. We conclude that neither\nminers nor mining pools who seek to maximize their compound return will have a\nfinancial incentive to occupy more than 50% of the hash rate if the cost of\nmining is at the same level for all. However, if there is an outstandingly\ncost-efficient miner, then the market share of this miner may exceed 50% in the\nequilibrium, which can threaten the viability of the entire ecosystem.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 20:52:31 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 04:06:36 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Yamamoto", "Go", ""], ["Laszka", "Aron", ""], ["Kojima", "Fuhito", ""]]}, {"id": "2006.08140", "submitter": "Abhishek Gupta", "authors": "Mirka Snyder Caron (1), Abhishek Gupta (1 and 2) ((1) Montreal AI\n  Ethics Institute, (2) Microsoft)", "title": "The Social Contract for AI", "comments": "Accepted paper for presentation at the IJCAI 2019 AI for Social Good\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like any technology, AI systems come with inherent risks and potential\nbenefits. It comes with potential disruption of established norms and methods\nof work, societal impacts and externalities. One may think of the adoption of\ntechnology as a form of social contract, which may evolve or fluctuate in time,\nscale, and impact. It is important to keep in mind that for AI, meeting the\nexpectations of this social contract is critical, because recklessly driving\nthe adoption and implementation of unsafe, irresponsible, or unethical AI\nsystems may trigger serious backlash against industry and academia involved\nwhich could take decades to resolve, if not actually seriously harm society.\nFor the purpose of this paper, we consider that a social contract arises when\nthere is sufficient consensus within society to adopt and implement this new\ntechnology. As such, to enable a social contract to arise for the adoption and\nimplementation of AI, developing: 1) A socially accepted purpose, through 2) A\nsafe and responsible method, with 3) A socially aware level of risk involved,\nfor 4) A socially beneficial outcome, is key.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 05:30:48 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Caron", "Mirka Snyder", "", "1 and 2"], ["Gupta", "Abhishek", "", "1 and 2"]]}, {"id": "2006.08164", "submitter": "Gabriel Lima", "authors": "Gabriel Lima, Meeyoung Cha, Chiyoung Cha, Hyeyoung Hwang", "title": "COVID-19 Vaccine Acceptance in the US and UK in the Early Phase of the\n  Pandemic: AI-Generated Vaccines Hesitancy for Minors, and the Role of\n  Governments", "comments": "Published to the Journal of the Korean Data Analysis Society vol. 23\n  no. 3", "journal-ref": null, "doi": "10.37727/jkdas.2021.23.2.1045", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents survey results of the public's willingness to get\nvaccinated against COVID-19 during an early phase of the pandemic and examines\nfactors that could influence vaccine acceptance based on a between-subjects\ndesign. A representative quota sample of 572 adults in the US and UK\nparticipated in an online survey. First, the participants' medical use\ntendencies and initial vaccine acceptance were assessed; then, short vignettes\nwere provided to evaluate their changes in attitude towards COVID-19 vaccines.\nFor data analysis, ANOVA and post hoc pairwise comparisons were used. The\nparticipants were more reluctant to vaccinate their children than themselves\nand the elderly. The use of artificial intelligence (AI) in vaccine development\ndid not influence vaccine acceptance. Vignettes that explicitly stated the high\neffectiveness of vaccines led to an increase in vaccine acceptance. Our study\nsuggests public policies emphasizing the vaccine effectiveness against the\nvirus could lead to higher vaccination rates. We also discuss the public's\nexpectations of governments concerning vaccine safety and present a series of\nimplications based on our findings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:47:13 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 07:16:44 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 07:10:17 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lima", "Gabriel", ""], ["Cha", "Meeyoung", ""], ["Cha", "Chiyoung", ""], ["Hwang", "Hyeyoung", ""]]}, {"id": "2006.08220", "submitter": "Shailesh Arya", "authors": "Shailesh D. Arya, Dr. Samir Patel", "title": "Implementation of Google Assistant & Amazon Alexa on Raspberry Pi", "comments": "5 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the implementation of voice-enabled Google Assistant\nand Amazon Alexa on Raspberry Pi. Virtual Assistants are being a new trend in\nhow we interact or do computations with physical devices. A voice-enabled\nsystem essentially means a system that processes voice as an input, decodes, or\nunderstands the meaning of that input and generates an appropriate voice\noutput. In this paper, we are developing a smart speaker prototype that has the\nfunctionalities of both in the same Raspberry Pi. Users can invoke a virtual\nassistant by saying the hot words and can leverage the best services of both\neco-systems. This paper also explains the complex architecture of Google\nAssistant and Amazon Alexa and the working of both assistants as well. Later,\nthis system can be used to control the smart home IoT devices.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 08:46:48 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Arya", "Shailesh D.", ""], ["Patel", "Dr. Samir", ""]]}, {"id": "2006.08225", "submitter": "Bhavana Vaddadi", "authors": "Bhavana Vaddadi, Jan Bieser, Johanna Pohl, Anna Kramers", "title": "Towards a conceptual framework of direct and indirect environmental\n  effects of co-working", "comments": "Conference- ICT4S 2020, Bristol, UK 9 pages, 4 images, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through virtual presence, information and communication technology (ICT)\nallows employees to work from places other than their employers office and\nreduce commuting-related environmental effects (telecommuting). Working from a\nlocal coworking space, as a form of telecommuting, has the potential to\nsignificantly reduce commuting and is not associated with deficits of working\nfrom home (e.g. isolation, lack of focus). However, environmental burden might\nincrease through co-working due to the infrastructure required to set-up and\noperate the co-working space and potential rebound effects. In this paper, we\n(1) develop a framework of direct and indirect environmental effects of\ncoworking based on a well-known conceptual framework of environmental effects\nof ICT and, (2) apply the framework to investigate the case of a coworking\nliving lab established in Stockholm. Based on interviews and surveys conducted\nwith co-workers in the living lab and infrastructure data of the co-working\nspace, we roughly estimate associated energy impacts. Results show that energy\nrequirements associated with operating the coworking space can counterbalance\ncommute-related energy savings. Thus, in order to realize energy savings\nco-working should be accompanied with additional energy saving measures such as\na net reduction of (heated) floor space(at the co-working space, at the\nemployer's office and the co-workers home) and use of energy efficient\ntransport modes.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 08:54:22 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Vaddadi", "Bhavana", ""], ["Bieser", "Jan", ""], ["Pohl", "Johanna", ""], ["Kramers", "Anna", ""]]}, {"id": "2006.08352", "submitter": "Huthaifa I. Ashqar", "authors": "Huthaifa I. Ashqar, Mohammed Elhenawy, Mohammed H. Almannaa, Ahmed\n  Ghanem, Hesham A. Rakha, and Leanna House", "title": "Modeling bike availability in a bike-sharing system using machine\n  learning", "comments": "Published in: 2017 5th IEEE International Conference on Models and\n  Technologies for Intelligent Transportation Systems (MT-ITS)", "journal-ref": "2017 5th IEEE International Conference on Models and Technologies\n  for Intelligent Transportation Systems (MT-ITS), 2017, pp. 374-378", "doi": "10.1109/MTITS.2017.8005700", "report-no": null, "categories": "cs.CY cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper models the availability of bikes at San Francisco Bay Area Bike\nShare stations using machine learning algorithms. Random Forest (RF) and\nLeast-Squares Boosting (LSBoost) were used as univariate regression algorithms,\nand Partial Least-Squares Regression (PLSR) was applied as a multivariate\nregression algorithm. The univariate models were used to model the number of\navailable bikes at each station. PLSR was applied to reduce the number of\nrequired prediction models and reflect the spatial correlation between stations\nin the network. Results clearly show that univariate models have lower error\npredictions than the multivariate model. However, the multivariate model\nresults are reasonable for networks with a relatively large number of spatially\ncorrelated stations. Results also show that station neighbors and the\nprediction horizon time are significant predictors. The most effective\nprediction horizon time that produced the least prediction error was 15\nminutes.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 04:49:14 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ashqar", "Huthaifa I.", ""], ["Elhenawy", "Mohammed", ""], ["Almannaa", "Mohammed H.", ""], ["Ghanem", "Ahmed", ""], ["Rakha", "Hesham A.", ""], ["House", "Leanna", ""]]}, {"id": "2006.08361", "submitter": "Pegah Sagheb Haghighi", "authors": "Fadoua Khmaissia, Pegah Sagheb Haghighi, Aarthe Jayaprakash, Zhenwei\n  Wu, Sokratis Papadopoulos, Yuan Lai, Freddy T. Nguyen", "title": "An Unsupervised Machine Learning Approach to Assess the ZIP Code Level\n  Impact of COVID-19 in NYC", "comments": "Presented at ICML 2020 Workshop on the Healthcare Systems, Population\n  Health, and the Role of Health-Tech", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New York City has been recognized as the world's epicenter of the novel\nCoronavirus pandemic. To identify the key inherent factors that are highly\ncorrelated to the Increase Rate of COVID-19 new cases in NYC, we propose an\nunsupervised machine learning framework. Based on the assumption that ZIP code\nareas with similar demographic, socioeconomic, and mobility patterns are likely\nto experience similar outbreaks, we select the most relevant features to\nperform a clustering that can best reflect the spread, and map them down to 9\ninterpretable categories. We believe that our findings can guide policy makers\nto promptly anticipate and prevent the spread of the virus by taking the right\nmeasures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 03:21:56 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 17:34:00 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 15:05:16 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Khmaissia", "Fadoua", ""], ["Haghighi", "Pegah Sagheb", ""], ["Jayaprakash", "Aarthe", ""], ["Wu", "Zhenwei", ""], ["Papadopoulos", "Sokratis", ""], ["Lai", "Yuan", ""], ["Nguyen", "Freddy T.", ""]]}, {"id": "2006.08363", "submitter": "Genevieve Gorrell", "authors": "Genevieve Gorrell, Tracie Farrell and Kalina Bontcheva", "title": "MP Twitter Abuse in the Age of COVID-19: White Paper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As COVID-19 sweeps the globe, outcomes depend on effective relationships\nbetween the public and decision-makers. In the UK there were uncivil tweets to\nMPs about perceived UK tardiness to go into lockdown. The pandemic has led to\nincreased attention on ministers with a role in the crisis. However, generally\nthis surge has been civil. Prime minister Boris Johnson's severe illness with\nCOVID-19 resulted in an unusual peak of supportive responses on Twitter. Those\nwho receive more COVID-19 mentions in their replies tend to receive less abuse\n(significant negative correlation). Following Mr Johnson's recovery, with\nrising economic concerns and anger about lockdown violations by influential\nfigures, abuse levels began to rise in May. 1,902 replies to MPs within the\nstudy period were found containing hashtags or terms that refute the existence\nof the virus (e.g. #coronahoax, #coronabollocks, 0.04% of a total 4.7 million\nreplies, or 9% of the number of mentions of \"stay home save lives\" and\nvariants). These have tended to be more abusive. Evidence of some members of\nthe public believing in COVID-19 conspiracy theories was also found. Higher\nabuse levels were associated with hashtags blaming China for the pandemic.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 16:21:42 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Gorrell", "Genevieve", ""], ["Farrell", "Tracie", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "2006.08364", "submitter": "Pablo Robles-Granda", "authors": "Pablo Robles-Granda, Suwen Lin, Xian Wu, Sidney D'Mello, Gonzalo J.\n  Martinez, Koustuv Saha, Kari Nies, Gloria Mark, Andrew T. Campbell, Munmun De\n  Choudhury, Anind D. Dey, Julie Gregg, Ted Grover, Stephen M. Mattingly,\n  Shayan Mirjafari, Edward Moskal, Aaron Striegel, Nitesh V. Chawla", "title": "Jointly Predicting Job Performance, Personality, Cognitive Ability,\n  Affect, and Well-Being", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessment of job performance, personalized health and psychometric measures\nare domains where data-driven and ubiquitous computing exhibits the potential\nof a profound impact in the future. Existing techniques use data extracted from\nquestionnaires, sensors (wearable, computer, etc.), or other traits, to assess\nwell-being and cognitive attributes of individuals. However, these techniques\ncan neither predict individual's well-being and psychological traits in a\nglobal manner nor consider the challenges associated to processing the data\navailable, that is incomplete and noisy. In this paper, we create a benchmark\nfor predictive analysis of individuals from a perspective that integrates:\nphysical and physiological behavior, psychological states and traits, and job\nperformance. We design data mining techniques as benchmark and uses real noisy\nand incomplete data derived from wearable sensors to predict 19 constructs\nbased on 12 standardized well-validated tests. The study included 757\nparticipants who were knowledge workers in organizations across the USA with\nvaried work roles. We developed a data mining framework to extract the\nmeaningful predictors for each of the 19 variables under consideration. Our\nmodel is the first benchmark that combines these various instrument-derived\nvariables in a single framework to understand people's behavior by leveraging\nreal uncurated data from wearable, mobile, and social media sources. We verify\nour approach experimentally using the data obtained from our longitudinal\nstudy. The results show that our framework is consistently reliable and capable\nof predicting the variables under study better than the baselines when\nprediction is restricted to the noisy, incomplete data.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 14:30:29 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Robles-Granda", "Pablo", ""], ["Lin", "Suwen", ""], ["Wu", "Xian", ""], ["D'Mello", "Sidney", ""], ["Martinez", "Gonzalo J.", ""], ["Saha", "Koustuv", ""], ["Nies", "Kari", ""], ["Mark", "Gloria", ""], ["Campbell", "Andrew T.", ""], ["De Choudhury", "Munmun", ""], ["Dey", "Anind D.", ""], ["Gregg", "Julie", ""], ["Grover", "Ted", ""], ["Mattingly", "Stephen M.", ""], ["Mirjafari", "Shayan", ""], ["Moskal", "Edward", ""], ["Striegel", "Aaron", ""], ["Chawla", "Nitesh V.", ""]]}, {"id": "2006.08365", "submitter": "Soohwan Oh", "authors": "Jungwoo Cho, Soohwan Oh, Seyun Kim, Namwoo Kim, Yuyol Shin, Haechan\n  Cho, Yoonjin Yoon", "title": "COVID-19 Mobility Data Collection of Seoul, South Korea", "comments": null, "journal-ref": null, "doi": "10.6084/m9.figshare.12462515", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between pandemic and human mobility has received\nconsiderable attention from scholars, as it can provide an indication of how\nmobility patterns change in response to a public health crisis or whether\nreduced mobility contributes to preventing the spread of an infectious disease.\nWhile several studies attempted to unveil such relationship, no studies have\nfocused on changes in human mobility at a finer scale utilizing comprehensive,\nhigh-resolution data. To address the complex association between pandemic's\nspread and human mobility, this paper presents two categories of mobility\ndatasets - trip mode and trip purpose - that concern nearly 10 million\ncitizens' movements during COVID-19 in the capital city of South Korea, Seoul,\nwhere no lockdowns has been imposed. We curate hourly data of subway ridership,\ntraffic volume and population present count at selected points of interests.\nThe results to be derived from the presented datasets can be used as an\nimportant reference for public health decision making in the post COVID-19 era.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 07:04:31 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 09:33:53 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Cho", "Jungwoo", ""], ["Oh", "Soohwan", ""], ["Kim", "Seyun", ""], ["Kim", "Namwoo", ""], ["Shin", "Yuyol", ""], ["Cho", "Haechan", ""], ["Yoon", "Yoonjin", ""]]}, {"id": "2006.08368", "submitter": "Guillermo Gallego", "authors": "Anko B\\\"orner, Heinz-Wilhelm H\\\"ubers, Odej Kao, Florian Schmidt,\n  S\\\"oren Becker, Joachim Denzler, Daniel Matolin, David Haber, Sergio Lucia,\n  Wojciech Samek, Rudolph Triebel, Sascha Eichst\\\"adt, Felix Biessmann, Anna\n  Kruspe, Peter Jung, Manon Kok, Guillermo Gallego, Ralf Berger", "title": "Sensor Artificial Intelligence and its Application to Space Systems -- A\n  White Paper", "comments": "4 pages. 1st Workshop on Sensor Artificial Intelligence, Apr. 2020,\n  Berlin, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information and communication technologies have accompanied our everyday life\nfor years. A steadily increasing number of computers, cameras, mobile devices,\netc. generate more and more data, but at the same time we realize that the data\ncan only partially be analyzed with classical approaches. The research and\ndevelopment of methods based on artificial intelligence (AI) made enormous\nprogress in the area of interpretability of data in recent years. With growing\nexperience, both, the potential and limitations of these new technologies are\nincreasingly better understood. Typically, AI approaches start with the data\nfrom which information and directions for action are derived. However, the\ncircumstances under which such data are collected and how they change over time\nare rarely considered. A closer look at the sensors and their physical\nproperties within AI approaches will lead to more robust and widely applicable\nalgorithms. This holistic approach which considers entire signal chains from\nthe origin to a data product, \"Sensor AI\", is a highly relevant topic with\ngreat potential. It will play a decisive role in autonomous driving as well as\nin areas of automated production, predictive maintenance or space research. The\ngoal of this white paper is to establish \"Sensor AI\" as a dedicated research\ntopic. We want to exchange knowledge on the current state-of-the-art on Sensor\nAI, to identify synergies among research groups and thus boost the\ncollaboration in this key technology for science and industry.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 14:10:35 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["B\u00f6rner", "Anko", ""], ["H\u00fcbers", "Heinz-Wilhelm", ""], ["Kao", "Odej", ""], ["Schmidt", "Florian", ""], ["Becker", "S\u00f6ren", ""], ["Denzler", "Joachim", ""], ["Matolin", "Daniel", ""], ["Haber", "David", ""], ["Lucia", "Sergio", ""], ["Samek", "Wojciech", ""], ["Triebel", "Rudolph", ""], ["Eichst\u00e4dt", "Sascha", ""], ["Biessmann", "Felix", ""], ["Kruspe", "Anna", ""], ["Jung", "Peter", ""], ["Kok", "Manon", ""], ["Gallego", "Guillermo", ""], ["Berger", "Ralf", ""]]}, {"id": "2006.08369", "submitter": "Junhua Liu", "authors": "Junhua Liu, Trisha Singhal, Lucienne T.M. Blessing, Kristin L. Wood\n  and Kwan Hui Lim", "title": "EPIC30M: An Epidemics Corpus Of Over 30 Million Relevant Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the start of COVID-19, several relevant corpora from various sources\nare presented in the literature that contain millions of data points. While\nthese corpora are valuable in supporting many analyses on this specific\npandemic, researchers require additional benchmark corpora that contain other\nepidemics to facilitate cross-epidemic pattern recognition and trend analysis\ntasks. During our other efforts on COVID-19 related work, we discover very\nlittle disease related corpora in the literature that are sizable and rich\nenough to support such cross-epidemic analysis tasks. In this paper, we present\nEPIC30M, a large-scale epidemic corpus that contains 30 millions micro-blog\nposts, i.e., tweets crawled from Twitter, from year 2006 to 2020. EPIC30M\ncontains a subset of 26.2 millions tweets related to three general diseases,\nnamely Ebola, Cholera and Swine Flu, and another subset of 4.7 millions tweets\nof six global epidemic outbreaks, including 2009 H1N1 Swine Flu, 2010 Haiti\nCholera, 2012 Middle-East Respiratory Syndrome (MERS), 2013 West African Ebola,\n2016 Yemen Cholera and 2018 Kivu Ebola. Furthermore, we explore and discuss the\nproperties of the corpus with statistics of key terms and hashtags and trends\nanalysis for each subset. Finally, we demonstrate the value and impact that\nEPIC30M could create through a discussion of multiple use cases of\ncross-epidemic research topics that attract growing interest in recent years.\nThese use cases span multiple research areas, such as epidemiological modeling,\npattern recognition, natural language understanding and economical modeling.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:23:00 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 17:08:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Liu", "Junhua", ""], ["Singhal", "Trisha", ""], ["Blessing", "Lucienne T. M.", ""], ["Wood", "Kristin L.", ""], ["Lim", "Kwan Hui", ""]]}, {"id": "2006.08481", "submitter": "Ahmet-Serdar Karakaya", "authors": "Ahmet-Serdar Karakaya, Jonathan Hasenburg and David Bermbach", "title": "SimRa: Using Crowdsourcing to Identify Near Miss Hotspots in Bicycle\n  Traffic", "comments": "Accepted for publication in Elsevier Pervasive and Mobile Computing", "journal-ref": null, "doi": "10.1016/j.pmcj.2020.101197", "report-no": null, "categories": "cs.CY cs.DC cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An increased modal share of bicycle traffic is a key mechanism to reduce\nemissions and solve traffic-related problems. However, a lack of (perceived)\nsafety keeps people from using their bikes more frequently. To improve safety\nin bicycle traffic, city planners need an overview of accidents, near miss\nincidents, and bike routes. Such information, however, is currently not\navailable. In this paper, we describe SimRa, a platform for collecting data on\nbicycle routes and near miss incidents using smartphone-based crowdsourcing. We\nalso describe how we identify dangerous near miss hotspots based on the\ncollected data and propose a scoring model.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 15:29:52 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 07:46:40 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Karakaya", "Ahmet-Serdar", ""], ["Hasenburg", "Jonathan", ""], ["Bermbach", "David", ""]]}, {"id": "2006.08568", "submitter": "Ssu-Hsin Yu", "authors": "Ssu-Hsin Yu", "title": "PrivyTRAC: Privacy and Security Preserving Contact Tracing System", "comments": "11 pages, 5 figures; submitted to EmergencyComm 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphone location-based methods have been proposed and implemented as an\neffective alternative to traditional labor intensive contact tracing methods.\nHowever, there are serious privacy and security concerns that may impede\nwide-spread adoption in many societies. Furthermore, these methods rely solely\non proximity to patients, based on Bluetooth or GPS signal for example,\nignoring lingering effects of virus, including COVID-19, present in the\nenvironment. This results in inaccurate risk assessment and incomplete contact\ntracing. A new system concept, called PrivyTRAC, preserves user privacy,\nincreases security and improves accuracy of smartphone contact tracing.\nPrivyTRAC enhances users' and patients' privacy by letting users conduct\nself-evaluation based on the risk maps download to their smartphones. No user\ninformation is transmitted to external locations or devices, and no personally\nidentifiable patient information is embedded in the risk maps as they are\nprocessed anonymized and aggregated locations of confirmed patients. The risk\nmaps consider both spatial proximity and temporal effects to improve the\naccuracy of the infection risk estimation. Experiments conducted in the paper\nillustrate improvement of PrivyTRAC over proximity based methods in terms of\ntrue and false positives. An approach to further improve infection risk\nestimation by incorporating both positive and negative local test results from\ncontacts of confirmed cases is also described.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 17:32:38 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Yu", "Ssu-Hsin", ""]]}, {"id": "2006.08669", "submitter": "Reza Shokri", "authors": "Hongyan Chang, Ta Duy Nguyen, Sasi Kumar Murakonda, Ehsan Kazemi, Reza\n  Shokri", "title": "On Adversarial Bias and the Robustness of Fair Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing prediction accuracy can come at the expense of fairness. Towards\nminimizing discrimination against a group, fair machine learning algorithms\nstrive to equalize the behavior of a model across different groups, by imposing\na fairness constraint on models. However, we show that giving the same\nimportance to groups of different sizes and distributions, to counteract the\neffect of bias in training data, can be in conflict with robustness. We analyze\ndata poisoning attacks against group-based fair machine learning, with the\nfocus on equalized odds. An adversary who can control sampling or labeling for\na fraction of training data, can reduce the test accuracy significantly beyond\nwhat he can achieve on unconstrained models. Adversarial sampling and\nadversarial labeling attacks can also worsen the model's fairness gap on test\ndata, even though the model satisfies the fairness constraint on training data.\nWe analyze the robustness of fair machine learning through an empirical\nevaluation of attacks on multiple algorithms and benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 18:17:44 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Chang", "Hongyan", ""], ["Nguyen", "Ta Duy", ""], ["Murakonda", "Sasi Kumar", ""], ["Kazemi", "Ehsan", ""], ["Shokri", "Reza", ""]]}, {"id": "2006.08760", "submitter": "Ali Ahmad Malik", "authors": "Ali Ahmad Malik, Alexander Brem", "title": "Man, machine and work in a digital twin setup: a case study", "comments": null, "journal-ref": "Robotics and Computer-Integrated Manufacturing, 68, 2021, 102092,\n  ISSN 0736-5845", "doi": "10.1016/j.rcim.2020.102092", "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the opportunities of using a digital twin to address the\ncomplexities of collaborative production systems through an industrial case and\na demonstrator. A digital twin, as a virtual counterpart of a physical\nhuman-robot assembly system, is built as a front-runner for validation and\ncontrol through design, build, and operation. The forms of digital twins along\nthe system life cycle, the building blocks, and potential advantages are\npresented. Recommendations for future research and practice in the use of\ndigital twins in the field of collaborative robots are given.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:54:43 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 10:05:00 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Malik", "Ali Ahmad", ""], ["Brem", "Alexander", ""]]}, {"id": "2006.08773", "submitter": "DianChao Lin", "authors": "DianChao Lin and Saif Eddin Jabari", "title": "Comparative Analysis of Economic Instruments in Intersection Operation:\n  A User-Based Perspective", "comments": "6 pages, 8 figures, 6 tables, IEEE-ITSC2020", "journal-ref": "The 23rd IEEE International Conference on Intelligent\n  Transportation Systems, 2020", "doi": "10.1109/ITSC45102.2020.9294641", "report-no": "2020", "categories": "cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focusing on different economic instruments implemented in intersection\noperations under a connected environment, this paper analyzes their advantages\nand disadvantages from the travelers' perspective. Travelers' concerns revolve\naround whether a new instrument is easy to learn and operate, whether it can\nsave time or money, and whether it can reduce the rich-poor gap. After a\ncomparative analysis, we found that both credit and free-market schemes can\nbenefit users. Second-price auctions can only benefit high VOT vehicles. From\nthe perspective of technology deployment and adoption, a credit scheme is not\neasy to learn and operate for travelers.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 21:11:26 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lin", "DianChao", ""], ["Jabari", "Saif Eddin", ""]]}, {"id": "2006.08828", "submitter": "Ayman Moawad", "authors": "Ayman Moawad, Ehsan Islam, Namdoo Kim, Ram Vijayagopal, Aymeric\n  Rousseau, and Wei Biao Wu", "title": "Explainable AI for a No-Teardown Vehicle Component Cost Estimation: A\n  Top-Down Approach", "comments": "17 pages, 18 figures", "journal-ref": null, "doi": "10.1109/TAI.2021.3065011", "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broader ambition of this article is to popularize an approach for the\nfair distribution of the quantity of a system's output to its subsystems, while\nallowing for underlying complex subsystem level interactions. Particularly, we\npresent a data-driven approach to vehicle price modeling and its component\nprice estimation by leveraging a combination of concepts from machine learning\nand game theory. We show an alternative to common teardown methodologies and\nsurveying approaches for component and vehicle price estimation at the\nmanufacturer's suggested retail price (MSRP) level that has the advantage of\nbypassing the uncertainties involved in 1) the gathering of teardown data, 2)\nthe need to perform expensive and biased surveying, and 3) the need to perform\nretail price equivalent (RPE) or indirect cost multiplier (ICM) adjustments to\nmark up direct manufacturing costs to MSRP. This novel exercise not only\nprovides accurate pricing of the technologies at the customer level, but also\nshows the, a priori known, large gaps in pricing strategies between\nmanufacturers, vehicle sizes, classes, market segments, and other factors.\nThere is also clear synergism or interaction between the price of certain\ntechnologies and other specifications present in the same vehicle. Those\n(unsurprising) results are indication that old methods of manufacturer-level\ncomponent costing, aggregation, and the application of a flat and rigid RPE or\nICM adjustment factor should be carefully examined. The findings are based on\nan extensive database, developed by Argonne National Laboratory, that includes\nmore than 64,000 vehicles covering MY1990 to MY2020 over hundreds of vehicle\nspecs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:47:19 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Moawad", "Ayman", ""], ["Islam", "Ehsan", ""], ["Kim", "Namdoo", ""], ["Vijayagopal", "Ram", ""], ["Rousseau", "Aymeric", ""], ["Wu", "Wei Biao", ""]]}, {"id": "2006.08832", "submitter": "Kyle Brown", "authors": "Kyle Brown and Katherine Driggs-Campbell and Mykel J. Kochenderfer", "title": "A Taxonomy and Review of Algorithms for Modeling and Predicting Human\n  Driver Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a review and taxonomy of 200 models from the literature on driver\nbehavior modeling. We begin by introducing a mathematical framework for\ndescribing the dynamics of interactive multi-agent traffic. Based on the\npartially observable stochastic game, this framework provides a basis for\ndiscussing different driver modeling techniques. Our taxonomy is constructed\naround the core modeling tasks of state estimation, intention estimation, trait\nestimation, and motion prediction, and also discusses the auxiliary tasks of\nrisk estimation, anomaly detection, behavior imitation and microscopic traffic\nsimulation. Existing driver models are categorized based on the specific tasks\nthey address and key attributes of their approach.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:53:45 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 18:35:04 GMT"}, {"version": "v3", "created": "Sun, 29 Nov 2020 03:40:24 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Brown", "Kyle", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2006.08899", "submitter": "Brian Keegan", "authors": "Brian C. Keegan, Chenhao Tan", "title": "A Quantitative Portrait of Wikipedia's High-Tempo Collaborations during\n  the 2020 Coronavirus Pandemic", "comments": "25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The 2020 coronavirus pandemic was a historic social disruption with\nsignificant consequences felt around the globe. Wikipedia is a\nfreely-available, peer-produced encyclopedia with a remarkable ability to\ncreate and revise content following current events. Using 973,940 revisions\nfrom 134,337 editors to 4,238 articles, this study examines the dynamics of the\nEnglish Wikipedia's response to the coronavirus pandemic through the first five\nmonths of 2020 as a \"quantitative portrait\" describing the emergent\ncollaborative behavior at three levels of analysis: article revision, editor\ncontributions, and network dynamics. Across multiple data sources, quantitative\nmethods, and levels of analysis, we find four consistent themes characterizing\nWikipedia's unique large-scale, high-tempo, and temporary online\ncollaborations: external events as drivers of activity, spillovers of activity,\ncomplex patterns of editor engagement, and the shadows of the future. In light\nof increasing concerns about online social platforms' abilities to govern the\nconduct and content of their users, we identify implications from Wikipedia's\ncoronavirus collaborations for improving the resilience of socio-technical\nsystems during a crisis.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 03:28:04 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Keegan", "Brian C.", ""], ["Tan", "Chenhao", ""]]}, {"id": "2006.09428", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3) ((1) Montreal AI\n  Ethics Institute, (2) Microsoft, (3) McGill University)", "title": "Response by the Montreal AI Ethics Institute to the European\n  Commission's Whitepaper on AI", "comments": "Submitted to the European Commission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In February 2020, the European Commission (EC) published a white paper\nentitled, On Artificial Intelligence - A European approach to excellence and\ntrust. This paper outlines the EC's policy options for the promotion and\nadoption of artificial intelligence (AI) in the European Union. The Montreal AI\nEthics Institute (MAIEI) reviewed this paper and published a response\naddressing the EC's plans to build an \"ecosystem of excellence\" and an\n\"ecosystem of trust,\" as well as the safety and liability implications of AI,\nthe internet of things (IoT), and robotics.\n  MAIEI provides 15 recommendations in relation to the sections outlined above,\nincluding: 1) focus efforts on the research and innovation community, member\nstates, and the private sector; 2) create alignment between trading partners'\npolicies and EU policies; 3) analyze the gaps in the ecosystem between\ntheoretical frameworks and approaches to building trustworthy AI; 4) focus on\ncoordination and policy alignment; 5) focus on mechanisms that promote private\nand secure sharing of data; 6) create a network of AI research excellence\ncentres to strengthen the research and innovation community; 7) promote\nknowledge transfer and develop AI expertise through Digital Innovation Hubs; 8)\nadd nuance to the discussion regarding the opacity of AI systems; 9) create a\nprocess for individuals to appeal an AI system's decision or output; 10)\nimplement new rules and strengthen existing regulations; 11) ban the use of\nfacial recognition technology; 12) hold all AI systems to similar standards and\ncompulsory requirements; 13) ensure biometric identification systems fulfill\nthe purpose for which they are implemented; 14) implement a voluntary labelling\nsystem for systems that are not considered high-risk; 15) appoint individuals\nto the oversight process who understand AI systems well and are able to\ncommunicate potential risks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 18:16:51 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"]]}, {"id": "2006.09487", "submitter": "Zhibin Niu", "authors": "Junqi Wu, Zhibin Niu, Jing Wu, Xiufeng Liu, Jiawan Zhang", "title": "$E^3$: Visual Exploration of Spatiotemporal Energy Demand", "comments": "5 Pages, with 1 page reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding demand-side energy behaviour is critical for making efficiency\nresponses for energy demand management. We worked closely with energy experts\nand identified the key elements of the energy demand problem including temporal\nand spatial demand and shifts in spatiotemporal demand. To our knowledge, no\nprevious research has investigated the shifts in spatiotemporal demand. To fill\nthis research gap, we propose a unified visual analytics approach to support\nexploratory demand analysis; we developed E3, a highly interactive tool that\nsupport users in making and verifying hypotheses through human-client-server\ninteractions. A novel potential flow based approach was formalized to model\nshifts in energy demand and integrated into a server-side engine. Experts then\nevaluated and affirmed the usefulness of this approach through case studies of\nreal-world electricity data. In the future, we will improve the modelling\nalgorithm, enhance visualisation, and expand the process to support more forms\nof energy data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 19:59:28 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Wu", "Junqi", ""], ["Niu", "Zhibin", ""], ["Wu", "Jing", ""], ["Liu", "Xiufeng", ""], ["Zhang", "Jiawan", ""]]}, {"id": "2006.09501", "submitter": "Rajesh Kumar", "authors": "Vishaal Udandarao and Mohit Agrawal and Rajesh Kumar and Rajiv Ratn\n  Shah", "title": "On the Inference of Soft Biometrics from Typing Patterns Collected in a\n  Multi-device Environment", "comments": "The first two authors contributed equally. The code is available upon\n  request. Please contact the last author", "journal-ref": "The Sixth IEEE International Conference on Multimedia Big Data,\n  August 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the inference of gender, major/minor (computer\nscience, non-computer science), typing style, age, and height from the typing\npatterns collected from 117 individuals in a multi-device environment. The\ninference of the first three identifiers was considered as classification\ntasks, while the rest as regression tasks. For classification tasks, we\nbenchmark the performance of six classical machine learning (ML) and four deep\nlearning (DL) classifiers. On the other hand, for regression tasks, we\nevaluated three ML and four DL-based regressors. The overall experiment\nconsisted of two text-entry (free and fixed) and four device (Desktop, Tablet,\nPhone, and Combined) configurations. The best arrangements achieved accuracies\nof 96.15%, 93.02%, and 87.80% for typing style, gender, and major/minor,\nrespectively, and mean absolute errors of 1.77 years and 2.65 inches for age\nand height, respectively. The results are promising considering the variety of\napplication scenarios that we have listed in this work.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 20:25:58 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Udandarao", "Vishaal", ""], ["Agrawal", "Mohit", ""], ["Kumar", "Rajesh", ""], ["Shah", "Rajiv Ratn", ""]]}, {"id": "2006.09519", "submitter": "Rachel Freedman", "authors": "Rachel Freedman", "title": "Aligning with Heterogeneous Preferences for Kidney Exchange", "comments": "Presented at the IJCAI-PRICAI 2020 Workshop on Artificial\n  Intelligence Safety", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI algorithms increasingly make decisions that impact entire groups of\nhumans. Since humans tend to hold varying and even conflicting preferences, AI\nalgorithms responsible for making decisions on behalf of such groups encounter\nthe problem of preference aggregation: combining inconsistent and sometimes\ncontradictory individual preferences into a representative aggregate. In this\npaper, we address this problem in a real-world public health context: kidney\nexchange. The algorithms that allocate kidneys from living donors to patients\nneeding transplants in kidney exchange matching markets should prioritize\npatients in a way that aligns with the values of the community they serve, but\nallocation preferences vary widely across individuals. In this paper, we\npropose, implement and evaluate a methodology for prioritizing patients based\non such heterogeneous moral preferences. Instead of selecting a single static\nset of patient weights, we learn a distribution over preference functions based\non human subject responses to allocation dilemmas, then sample from this\ndistribution to dynamically determine patient weights during matching. We find\nthat this methodology increases the average rank of matched patients in the\nsampled preference ordering, indicating better satisfaction of group\npreferences. We hope that this work will suggest a roadmap for future automated\nmoral decision making on behalf of heterogeneous groups.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 21:16:53 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Freedman", "Rachel", ""]]}, {"id": "2006.09570", "submitter": "Clayton Miller", "authors": "Tapeesh Sood, Patrick Janssen, and Clayton Miller", "title": "Spacematch: Using environmental preferences to match occupants to\n  suitable activity-based workspaces", "comments": null, "journal-ref": "Front. Built Environ. 6:113 (2020)", "doi": "10.3389/fbuil.2020.00113", "report-no": null, "categories": "cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The activity-based workspace (ABW) paradigm is becoming more popular in\ncommercial office spaces. In this strategy, occupants are given a choice of\nspaces to do their work and personal activities on a day-to-day basis. This\npaper shows the implementation and testing of the Spacematch platform that was\ndesigned to improve the allocation and management of ABW. An experiment was\nimplemented to test the ability to characterize the preferences of occupants to\nmatch them with suitable environmentally-comfortable and spatially-efficient\nflexible workspaces. This approach connects occupants with a catalog of\navailable work desks using a web-based mobile application and enables them to\nprovide real-time environmental feedback. In this work, we tested the ability\nfor this feedback data to be merged with indoor environmental values from\nInternet-of-Things (IoT) sensors to optimize space and energy use by grouping\noccupants with similar preferences. This paper outlines a case study\nimplementation of this platform on two office buildings. This deployment\ncollected 1,182 responses from 25 field-based research participants over a\n30-day study. From this initial data set, the results show that the ABW\noccupants can be segmented into specific types of users based on their\naccumulated preference data, and matching preferences can be derived to build a\nrecommendation platform.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 00:00:21 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Sood", "Tapeesh", ""], ["Janssen", "Patrick", ""], ["Miller", "Clayton", ""]]}, {"id": "2006.09647", "submitter": "Sarah Cen", "authors": "Sarah H. Cen and Devavrat Shah", "title": "Regulating algorithmic filtering on social media", "comments": "58 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through the algorithmic filtering (AF) of content, social media platforms\n(SMPs) have the ability to influence users' perceptions and behaviors. Attempts\nto regulate externalities of AF are often difficult to pass or enforce due to\ncritical social, legal, financial, and user related considerations. In this\nwork, we explore this multifaceted problem by proposing a unifying framework\nthat considers the key stakeholders of AF regulation (or self-regulation). We\nmathematically formalize this framework, using it to construct a data-driven,\nstatistically sound regulatory procedure that satisfies several important\ncriteria. First, by design, it moderates the effect of AF on user learning and\ndecision-making. Second, it has desirable properties of online governance,\nincluding being normative and user-driven. Third, by illustrating the\nregulatory procedure in linear dynamical systems, we prove that it can align\nsocial and financial interests. Specifically, we identify conditions under\nwhich the regulation imposes a low cost on the SMP's reward (e.g., profits) and\nincentivizes the SMP to increase content diversity.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 04:14:20 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 11:57:32 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 23:51:03 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Cen", "Sarah H.", ""], ["Shah", "Devavrat", ""]]}, {"id": "2006.09663", "submitter": "Donald Martin Jr.", "authors": "Donald Martin Jr., Vinodkumar Prabhakaran, Jill Kuhlberg, Andrew\n  Smart, William S. Isaac", "title": "Extending the Machine Learning Abstraction Boundary: A Complex Systems\n  Approach to Incorporate Societal Context", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) fairness research tends to focus primarily on\nmathematically-based interventions on often opaque algorithms or models and/or\ntheir immediate inputs and outputs. Such oversimplified mathematical models\nabstract away the underlying societal context where ML models are conceived,\ndeveloped, and ultimately deployed. As fairness itself is a socially\nconstructed concept that originates from that societal context along with the\nmodel inputs and the models themselves, a lack of an in-depth understanding of\nsocietal context can easily undermine the pursuit of ML fairness. In this\npaper, we outline three new tools to improve the comprehension, identification\nand representation of societal context. First, we propose a complex adaptive\nsystems (CAS) based model and definition of societal context that will help\nresearchers and product developers to expand the abstraction boundary of ML\nfairness work to include societal context. Second, we introduce collaborative\ncausal theory formation (CCTF) as a key capability for establishing a\nsociotechnical frame that incorporates diverse mental models and associated\ncausal theories in modeling the problem and solution space for ML-based\nproducts. Finally, we identify community based system dynamics (CBSD) as a\npowerful, transparent and rigorous approach for practicing CCTF during all\nphases of the ML product development process. We conclude with a discussion of\nhow these systems theoretic approaches to understand the societal context\nwithin which sociotechnical systems are embedded can improve the development of\nfair and inclusive ML-based products.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 05:22:33 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Martin", "Donald", "Jr."], ["Prabhakaran", "Vinodkumar", ""], ["Kuhlberg", "Jill", ""], ["Smart", "Andrew", ""], ["Isaac", "William S.", ""]]}, {"id": "2006.09706", "submitter": "Manh Toan Ho Mr.", "authors": "Quan-Hoang Vuong, Manh-Toan Ho, Minh-Hoang Nguyen, Thanh-Hang Pham,\n  Hoang-Anh Ho, Thu-Trang Vuong, and Viet-Phuong La", "title": "On the environment-destructive probabilistic trends: a perceptual and\n  behavioral study on video game players", "comments": "6 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": "AISDL-2006-A", "categories": "cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, gaming is the world's favorite form of entertainment. Various\nstudies have shown how games impact players' perceptions and behaviors,\nprompting opportunities for purposes beyond entertainment. This study uses\nAnimal Crossing: New Horizons (ACNH), a real-time life-simulation game, as a\nunique case study of how video games can affect humans' environmental\nperceptions. A dataset of 584 observations from a survey of ACNH players and\nthe Hamiltonian MCMC technique has enabled us to explore the relationship\nbetween in-game behaviors and perceptions. The findings indicate a\nprobabilistic trend towards exploiting the in-game environment despite players'\nperceptions, suggesting that the simplification of commercial game design may\noverlook opportunities to engage players in pro-environmental activities.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 08:05:40 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Vuong", "Quan-Hoang", ""], ["Ho", "Manh-Toan", ""], ["Nguyen", "Minh-Hoang", ""], ["Pham", "Thanh-Hang", ""], ["Ho", "Hoang-Anh", ""], ["Vuong", "Thu-Trang", ""], ["La", "Viet-Phuong", ""]]}, {"id": "2006.09846", "submitter": "Muji Gunarto", "authors": "Muji Gunarto and Ratih Hurriyati", "title": "Creating Experience value to build student satisfaction in higher\n  education", "comments": "11 page. Dinasti International Journal of Education Management and\n  Social Science (February 2020)", "journal-ref": null, "doi": "10.31933/dijemss.v1i3.166", "report-no": null, "categories": "physics.ed-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher education products or services received by students are experiential\nvalues. The purpose of this study is how to create the values of student\nexperience so that student satisfaction arises. Higher education should now\nfocus on students by creating strong ties with students and alumni. This\nresearch was conducted with a survey confirmatory approach. The survey was\nconducted at 32 universities in South Sumatra Province, Indonesia with a total\nsample of 357 students. The sampling technique used was stratified random\nsampling and data analysis using structural equation modeling (SEM) analysis.\nThe results showed that the values of experience in HE were formed through\nincreased cocreation in HE, where students were directly involved in various\ncampus activities. High co-creation shows that there is a stronger attachment\nof students to HE and a higher value of student experience. Co-creation does\nnot directly affect student satisfaction, but it does indirectly affect\nexperience value. If the value of experience is higher, student satisfaction\nwill also be higher.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 15:29:41 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Gunarto", "Muji", ""], ["Hurriyati", "Ratih", ""]]}, {"id": "2006.10036", "submitter": "Mofeng Yang", "authors": "Mofeng Yang, Yixuan Pan, Aref Darzi, Sepehr Ghader, Chenfeng Xiong and\n  Lei Zhang", "title": "A Data-Driven Travel Mode Share Estimation Framework based on Mobile\n  Device Location Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile device location data (MDLD) contains abundant travel behavior\ninformation to support travel demand analysis. Compared to traditional travel\nsurveys, MDLD has larger spatiotemporal coverage of population and its\nmobility. However, ground truth information such as trip origins and\ndestinations, travel modes, and trip purposes are not included by default. Such\nimportant attributes must be imputed to maximize the usefulness of the data.\nThis paper tends to study the capability of MDLD on estimating travel mode\nshare at aggregated levels. A data-driven framework is proposed to extract\ntravel behavior information from the MDLD. The proposed framework first\nidentifies trip ends with a modified Spatiotemporal Density-based Spatial\nClustering of Applications with Noise (ST-DBSCAN) algorithm. Then three types\nof features are extracted for each trip to impute travel modes using machine\nlearning models. A labeled MDLD dataset with ground truth information is used\nto train the proposed models, resulting in 95% accuracy in identifying trip\nends and 93% accuracy in imputing five travel modes (drive, rail, bus, bike and\nwalk) with a Random Forest (RF) classifier. The proposed framework is then\napplied to two large-scale MDLD datasets, covering the Baltimore-Washington\nmetropolitan area and the United States, respectively. The estimated trip\ndistance, trip time, trip rate distribution, and travel mode share are compared\nagainst travel surveys at different geographies. The results suggest that the\nproposed framework can be readily applied in different states and metropolitan\nregions with low cost in order to study multimodal travel demand, understand\nmobility trends, and support decision making.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:57:31 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 20:13:43 GMT"}, {"version": "v3", "created": "Sun, 27 Dec 2020 19:55:42 GMT"}, {"version": "v4", "created": "Wed, 17 Feb 2021 16:04:48 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Yang", "Mofeng", ""], ["Pan", "Yixuan", ""], ["Darzi", "Aref", ""], ["Ghader", "Sepehr", ""], ["Xiong", "Chenfeng", ""], ["Zhang", "Lei", ""]]}, {"id": "2006.10148", "submitter": "Christopher Kenny", "authors": "Benjamin Fifield, Kosuke Imai, Jun Kawahara, Christopher T. Kenny", "title": "The Essential Role of Empirical Validation in Legislative Redistricting\n  Simulation", "comments": "32 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As granular data about elections and voters become available, redistricting\nsimulation methods are playing an increasingly important role when legislatures\nadopt redistricting plans and courts determine their legality. These simulation\nmethods are designed to yield a representative sample of all redistricting\nplans that satisfy statutory guidelines and requirements such as contiguity,\npopulation parity, and compactness. A proposed redistricting plan can be\nconsidered gerrymandered if it constitutes an outlier relative to this sample\naccording to partisan fairness metrics. Despite their growing use, an\ninsufficient effort has been made to empirically validate the accuracy of the\nsimulation methods. We apply a recently developed computational method that can\nefficiently enumerate all possible redistricting plans and yield an independent\nuniform sample from this population. We show that this algorithm scales to a\nstate with a couple of hundred geographical units. Finally, we empirically\nexamine how existing simulation methods perform on realistic validation data\nsets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 20:51:43 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Fifield", "Benjamin", ""], ["Imai", "Kosuke", ""], ["Kawahara", "Jun", ""], ["Kenny", "Christopher T.", ""]]}, {"id": "2006.10188", "submitter": "Jen Rexford", "authors": "Rachit Agarwal and Jen Rexford (workshop co-chairs) with contributions\n  from numerous workshop attendees", "title": "Wide-Area Data Analytics", "comments": "A Computing Community Consortium (CCC) workshop report, 16 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020report_2", "categories": "cs.CY cs.DB cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We increasingly live in a data-driven world, with diverse kinds of data\ndistributed across many locations. In some cases, the datasets are collected\nfrom multiple locations, such as sensors (e.g., mobile phones and street\ncameras) spread throughout a geographic region. The data may need to be\nanalyzed close to where they are produced, particularly when the applications\nrequire low latency, high, low cost, user privacy, and regulatory constraints.\nIn other cases, large datasets are distributed across public clouds, private\nclouds, or edge-cloud computing sites with more plentiful computation, storage,\nbandwidth, and energy resources. Often, some portion of the analysis may take\nplace on the end-host or edge cloud (to respect user privacy and reduce the\nvolume of data) while relying on remote clouds to complete the analysis (to\nleverage greater computation and storage resources).\n  Wide-area data analytics is any analysis of data that is generated by, or\nstored at, geographically dispersed entities. Over the past few years, several\nparts of the computer science research community have started to explore\neffective ways to analyze data spread over multiple locations. In particular,\nseveral areas of \"systems\" research - including databases, distributed systems,\ncomputer networking, and security and privacy - have delved into these topics.\nThese research subcommunities often focus on different aspects of the problem,\nconsider different motivating applications and use cases, and design and\nevaluate their solutions differently. To address these challenges the Computing\nCommunity Consortium (CCC) convened a 1.5-day workshop focused on wide-area\ndata analytics in October 2019. This report summarizes the challenges discussed\nand the conclusions generated at the workshop.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 22:44:33 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Agarwal", "Rachit", "", "workshop co-chairs"], ["Rexford", "Jen", "", "workshop co-chairs"], ["attendees", "with contributions from numerous workshop", ""]]}, {"id": "2006.10228", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Wen-Kai Kuan, Zong-Han Ciou, Yi-Lin\n  Tsai, Wei-Shan Chang, Lian-Chao Li, Naoyuki Kubota, Tzong-Xiang Huang, Eri\n  Sato-Shimokawara, and Toru Yamaguchi", "title": "A Study on AI-FML Robotic Agent for Student Learning Behavior Ontology\n  Construction", "comments": "This article has been accepted as a conference paper at CcS 2020 and\n  will be published in IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an AI-FML robotic agent for student learning\nbehavior ontology construction which can be applied in English speaking and\nlistening domain. The AI-FML robotic agent with the ontology contains the\nperception intelligence, computational intelligence, and cognition intelligence\nfor analyzing student learning behavior. In addition, there are three\nintelligent agents, including a perception agent, a computational agent, and a\ncognition agent in the AI-FML robotic agent. We deploy the perception agent and\nthe cognition agent on the robot Kebbi Air. Moreover, the computational agent\nwith the Deep Neural Network (DNN) model is performed in the cloud and can\ncommunicate with the perception agent and cognition agent via the Internet. The\nproposed AI-FML robotic agent is applied in Taiwan and tested in Japan. The\nexperimental results show that the agents can be utilized in the human and\nmachine co-learning model for the future education.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 01:45:30 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 11:56:54 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Kuan", "Wen-Kai", ""], ["Ciou", "Zong-Han", ""], ["Tsai", "Yi-Lin", ""], ["Chang", "Wei-Shan", ""], ["Li", "Lian-Chao", ""], ["Kubota", "Naoyuki", ""], ["Huang", "Tzong-Xiang", ""], ["Sato-Shimokawara", "Eri", ""], ["Yamaguchi", "Toru", ""]]}, {"id": "2006.10237", "submitter": "Sachithra Lokuge", "authors": "Sachithra Lokuge and Darshana Sedera", "title": "Enterprise System Lifecycle-wide Innovation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IT math.IT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Enterprise Systems purport to bring innovation to organizations. Yet, no past\nstudies, neither from innovation nor from ES disciplines have merged their\nknowledge to understand how ES could facilitate lifecycle-wide innovation.\nTherefore, this study forms conceptual bridge between the two disciplines. In\nthis research, we seek to understand how ES could facilitate innovation across\nits lifecycle phases. We associate classifications of innovation such as\nradical vs. incremental, administrative vs. technical innovation with the three\nphases of ES lifecycle. We introduce Continuous Restrained Innovation (CRI) as\na new type of innovation specific to ES, considering restraints of technology,\nbusiness processes and organization. Our empirical data collection at the\nimplementation phase, using data from both the client and implementation\npartner, shows preliminary evidence of CRI. In addition, we state that both\nparties consider the implementation of ES as a radical innovation yet, are less\ninterest in seeking further innovations through the system.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 02:16:10 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Lokuge", "Sachithra", ""], ["Sedera", "Darshana", ""]]}, {"id": "2006.10437", "submitter": "Vivek Nallur", "authors": "Elayne Ruane and Vivek Nallur", "title": "\"EHLO WORLD\" -- Checking If Your Conversational AI Knows Right from\n  Wrong", "comments": "8 pages, 2 figures, SoCAI 2020 : AISB Symposium on Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we discuss approaches to evaluating and validating the ethical\nclaims of a Conversational AI system. We outline considerations around both a\ntop-down regulatory approach and bottom-up processes. We describe the ethical\nbasis for each approach and propose a hybrid which we demonstrate by taking the\ncase of a customer service chatbot as an example. We speculate on the kinds of\ntop-down and bottom-up processes that would need to exist for a hybrid\nframework to successfully function as both an enabler as well as a shepherd\namong multiple use-cases and multiple competing AI solutions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 11:33:02 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Ruane", "Elayne", ""], ["Nallur", "Vivek", ""]]}, {"id": "2006.10528", "submitter": "Ian Brooks", "authors": "Ian Brooks", "title": "The United Nations Sustainable Development Goals in Systems Engineering:\n  Eliciting sustainability requirements", "comments": "7th International Conference on ICT for Sustainability (ICT4S2020),\n  June 21--26, 2020, Bristol, United Kingdom. ACM has non-exclusive licence to\n  publish", "journal-ref": null, "doi": "10.1145/3401335.3401359", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a PhD research project testing the hypothesis that using\nthe United Nations Sustainable Development Goals(SDG) as explicit inputs to\ndrive the Software Requirements Engineering process will result in requirements\nwith improved sustainability benefits. The research has adopted the Design\nScience Research Method (DSRM) [21] to test a process named SDG Assessment for\nRequirements Elicitation (SDGARE). Three DSRM cycles are being used to test the\nhypothesis in safety-critical, highprecision, software-intensive systems in\naerospace and healthcare. Initial results from the first two DSRM cycles\nsupport the hypothesis. However, these cycles are in a plan-driven (waterfall)\ndevelopment context and future research agenda would be a similar application\nin an Agile development context.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:14:05 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Brooks", "Ian", ""]]}, {"id": "2006.10719", "submitter": "Paul-Olivier Dehaye", "authors": "Paul-Olivier Dehaye, Joel Reardon", "title": "SwissCovid: a critical analysis of risk assessment by Swiss authorities", "comments": "v2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ahead of the rollout of the SwissCovid contact tracing app, an official\npublic security test was performed. During this audit, Prof. Serge Vaudenay and\nDr. Martin Vuagnoux described a large set of problems with the app, including a\nnew variation of a known false-positive attack, leveraging a cryptographic\nweakness in the Google and Apple Exposure Notification framework to tamper with\nthe emitted Bluetooth beacons. Separately, the first author described a\nre-identification attack leveraging rogue apps or SDKs. The response from the\nSwiss cybersecurity agency and the Swiss public health authority was to claim\nthese various attacks were unlikely as they required physical proximity of the\nattacker with the target (although it was admitted the attacker could be\nfurther than two meters). The physical presence of the attacker in Switzerland\nwas deemed significant as it would imply such attackers would fall under the\nSwiss Criminal Code. We show through one example that a much larger variety of\nadversaries must be considered in the scenarios originally described and that\nthese attacks can be done by adversaries without any physical presence in\nSwitzerland. This goes directly against official findings of Swiss public\nauthorities evaluating the risks associated with SwissCovid. To move the\ndiscussion further along, we briefly discuss the growth of the attack surface\nand harms with COVID-19 and SwissCovid prevalence in the population. While the\nfocus of this article is on Switzerland, we emphasize the core technical\nfindings and cybersecurity concerns are of relevance to many contact tracing\nefforts.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 17:50:28 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 07:15:02 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Dehaye", "Paul-Olivier", ""], ["Reardon", "Joel", ""]]}, {"id": "2006.10745", "submitter": "Michele Mancarella", "authors": "Aniello Lampo, Michele Mancarella and Angelo Piga", "title": "(Non)-neutrality of science and algorithms: Machine Learning between\n  fundamental physics and society", "comments": "Originally published in Italian on the journal The Lab's Quarterly", "journal-ref": "The Lab's Quarterly, XX, 4 (2018), 117-145", "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY physics.hist-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of Machine Learning (ML) algorithms in the age of big data and\nplatform capitalism has not spared scientific research in academia. In this\nwork, we will analyse the use of ML in fundamental physics and its relationship\nto other cases that directly affect society. We will deal with different\naspects of the issue, from a bibliometric analysis of the publications, to a\ndetailed discussion of the literature, to an overview on the productive and\nworking context inside and outside academia. The analysis will be conducted on\nthe basis of three key elements: the non-neutrality of science, understood as\nits intrinsic relationship with history and society; the non-neutrality of the\nalgorithms, in the sense of the presence of elements that depend on the choices\nof the programmer, which cannot be eliminated whatever the technological\nprogress is; the problematic nature of a paradigm shift in favour of a\ndata-driven science (and society). The deconstruction of the presumed\nuniversality of scientific thought from the inside becomes in this perspective\na necessary first step also for any social and political discussion. This is\nthe subject of this work in the case study of ML.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 09:43:28 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Lampo", "Aniello", ""], ["Mancarella", "Michele", ""], ["Piga", "Angelo", ""]]}, {"id": "2006.10805", "submitter": "Basit Qureshi", "authors": "Muhammad Ilyas and Basit Qureshi", "title": "Pervasive Communications Technologies For Managing Pandemics", "comments": "Paper submitted to SMARTTECH2020 for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Pandemics always have had serious consequences unless they were effectively\ncontained. Recent experiences with COVID-19 show that by using a smart and\nswift approach to deal with pandemics, avoids overwhelming of healthcare\nsystems, and reduces the loss of precious life. This paper is about using smart\ntechnologies such as Mobile Edge Clouds (MEC), Internet of Things (IoT), and\nArtificial Intelligence (AI), as an approach to effectively manage pandemics.\nIoT provides pervasive connectivity among various devices and can be used for\ncollecting information such as location and symptoms of potentially infected\nindividuals. MECs provide cloud services on the edge, integrating IoT\ninfrastructure and execution of sophisticated AI algorithms in the Cloud. In\nthis paper, we develop a prototype to demonstrate the convergence of pervasive\ntechnologies to support research in managing pandemics. Low-cost Single Board\nComputers (SBC) based clusters are integrated within MEC to support remote\nmedical teams in the field. The prototype implements a lightweight Docker\ncontainer orchestrated by Kubernetes eco-system which is deployed on the\nclusters. The prototype successfully demonstrates that mobile medical\nfacilities can utilize the proposed solution to collect information and execute\nAI algorithms while on the go. Finally, we present a discussion on the role of\nconverging pervasive technologies on managing pandemics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 18:46:33 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Ilyas", "Muhammad", ""], ["Qureshi", "Basit", ""]]}, {"id": "2006.10831", "submitter": "Vlad Coroama PhD", "authors": "Vlad C. Coroam\\u{a}, Pernilla Bergmark, Mattias H\\\"ojer, Jens Malmodin", "title": "A Methodology for Assessing the Environmental Effects Induced by ICT\n  Services. Part I: Single Services", "comments": "10 pages, 4 figures, The 7th International Conference on ICT for\n  Sustainability (ICT4S 2020)", "journal-ref": null, "doi": "10.1145/3401335.3401716", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information and communication technologies (ICT) are increasingly seen as key\nenablers for climate change mitigation measures. They can make existing\nproducts and activities more efficient or substitute them altogether.\nConsequently, different initiatives have started to estimate the environmental\neffects of ICT services. Such assessments, however, lack scientific rigor and\noften rely on crude assumptions and methods, leading to inaccurate or even\nmisleading results. The few methodological attempts that exist do not address\nseveral crucial aspects, and are thus insufficient to foster good as-sessment\npractice. Starting from such a high level standard from the European\nTelecommunication Standardisation Institute (ETSI) and the International\nTelecommunication Union (ITU), this article identifies the shortcomings of\nexisting methodologies and proposes solutions. It addresses several aspects for\nthe assessment of single ICT services: the goal and scope definition (analyzing\ndifferences between ICT substitution and optimization, the time perspective of\nthe assessment, the challenge of a hypothetical baseline for the situation\nwithout the ICT solution, and the differences between modelling and case\nstudies) as well as the often ignored influence of rebound effects and the\ndifficult extrapolation from case studies to larger populations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 19:55:23 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Coroam\u0103", "Vlad C.", ""], ["Bergmark", "Pernilla", ""], ["H\u00f6jer", "Mattias", ""], ["Malmodin", "Jens", ""]]}, {"id": "2006.10838", "submitter": "Vlad Coroam\\u{a}", "authors": "Pernilla Bergmark, Vlad C. Coroam\\u{a}, Mattias H\\\"ojer, Craig Donovan", "title": "A Methodology for Assessing the Environmental Effects Induced by ICT\n  Services. Part II: Multiple Services and Companies", "comments": "10 pages, 4 figures, The 7th International Conference on ICT for\n  Sustainability (ICT4S 2020)", "journal-ref": null, "doi": "10.1145/3401335.3401711", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information and communication technologies (ICT) can make existing products\nand activities more efficient or substitute them altogether and could thus\nbecome crucial for the mitigation of climate change. In this context,\nindividual ICT companies, industry organizations and international initiatives\nhave started to estimate the environmental effects of ICT services. Often such\nassessments rely on crude assumptions and methods, yielding inaccurate or even\nmisleading results. The few existing methodological attempts are too general to\nprovide guidance to practitioners. The starting points of this paper are i) a\nhigh level standard from the European Telecommunication Standardisation\nInstitute (ETSI) and the International Telecommunication Union (ITU), and ii)\nits suggested enhancements for single service assessment outlined in \"A\nMethodology for Assessing the Environmental Effects Induced by ICT Services\nPart I: Single services\" (Part I in short). Building on the assessment of\nsingle services, the current article identifies and addresses shortcomings of\nexisting methodologies and industry practices with regard to multiple services\nassessment. For a collection of services, it addresses the goal and scope\ndefinition, the so far ignored aggregation of effects among several services,\nand the allocation between several companies contributing to one or more\nservices. The article finally brings these considerations together with those\nof Part I into a workflow for performing such assessments in practice.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 20:12:26 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Bergmark", "Pernilla", ""], ["Coroam\u0103", "Vlad C.", ""], ["H\u00f6jer", "Mattias", ""], ["Donovan", "Craig", ""]]}, {"id": "2006.10843", "submitter": "Alaa Awad Abdellatif", "authors": "Alaa Awad Abdellatif, Abeer Z. Al-Marridi, Amr Mohamed, Aiman Erbad,\n  Carla Fabiana Chiasserini, and Ahmed Refaey", "title": "SSHealth: Toward Secure, Blockchain-Enabled Healthcare Systems", "comments": null, "journal-ref": "IEEE Network, 2020", "doi": "10.1109/MNET.011.1900553", "report-no": null, "categories": "cs.CY cs.CR cs.NI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The future of healthcare systems is being shaped by incorporating emerged\ntechnological innovations to drive new models for patient care. By acquiring,\nintegrating, analyzing, and exchanging medical data at different system levels,\nnew practices can be introduced, offering a radical improvement to healthcare\nservices. This paper presents a novel smart and secure Healthcare system\n(ssHealth), which, leveraging advances in edge computing and blockchain\ntechnologies, permits epidemics discovering, remote monitoring, and fast\nemergency response. The proposed system also allows for secure medical data\nexchange among local healthcare entities, thus realizing the integration of\nmultiple national and international entities and enabling the correlation of\ncritical medical events for, e.g., emerging epidemics management and control.\nIn particular, we develop a blockchain-based architecture and enable a flexible\nconfiguration thereof, which optimize medical data sharing between different\nhealth entities and fulfil the diverse levels of Quality of Service (QoS) that\nssHealth may require. Finally, we highlight the benefits of the proposed\nssHealth system and possible directions for future research.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 20:34:56 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Abdellatif", "Alaa Awad", ""], ["Al-Marridi", "Abeer Z.", ""], ["Mohamed", "Amr", ""], ["Erbad", "Aiman", ""], ["Chiasserini", "Carla Fabiana", ""], ["Refaey", "Ahmed", ""]]}, {"id": "2006.10884", "submitter": "Nitish Nag", "authors": "Dhruv Upadhyay, Vaibhav Pandey, Nitish Nag, Ramesh Jain", "title": "N=1 Modelling of Lifestyle Impact on SleepPerformance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep is critical to leading a healthy lifestyle. Each day, most people go to\nsleep without any idea about how their night's rest is going to be. For an\nactivity that humans spend around a third of their life doing, there is a\nsurprising amount of mystery around it. Despite current research, creating\npersonalized sleep models in real-world settings has been challenging. Existing\nliterature provides several connections between daily activities and sleep\nquality. Unfortunately, these insights do not generalize well in many\nindividuals. For these reasons, it is important to create a personalized sleep\nmodel. This research proposes a sleep model that can identify causal\nrelationships between daily activities and sleep quality and present the user\nwith specific feedback about how their lifestyle affects their sleep. Our\nmethod uses N-of-1 experiments on longitudinal user data and event mining to\ngenerate understanding between lifestyle choices (exercise, eating, circadian\nrhythm) and their impact on sleep quality. Our experimental results identified\nand quantified relationships while extracting confounding variables through a\ncausal framework. These insights can be used by the user or a personal health\nnavigator to provide guidance in improving sleep.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 22:43:35 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Upadhyay", "Dhruv", ""], ["Pandey", "Vaibhav", ""], ["Nag", "Nitish", ""], ["Jain", "Ramesh", ""]]}, {"id": "2006.10898", "submitter": "Suchithra Rajendran", "authors": "Suchithra Rajendran, Emily Pagel", "title": "Recommendations for Emerging Air Taxi Network Operations based on Online\n  Review Analysis of Helicopter Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effects of traffic congestion are adverse, primarily including air\npollution, commuter stress, and an increase in vehicle operating costs and\naccidents on the road. In efforts to alleviate these problems in metropolitan\ncities, logistics companies plan to introduce a new method of everyday commute\ncalled air taxis, an Urban Air Mobility (UAM) service. These are\nelectric-powered vehicles that are expected to operate in the forthcoming years\nby international transportation companies like Airbus, Uber, and Kitty Hawk.\nSince these flying taxis are emerging mode of transportation, it is necessary\nto provide recommendations for the initial design, implementation, and\noperation. This study proposes managerial insights for these upcoming services\nby analyzing online customer reviews and conducting an internal assessment of\nhelicopter operations. Helicopters are similar to air taxis in regards to their\noperations, and therefore, customer reviews pertaining to the former can enable\nus to obtain insights into the strengths and weaknesses of the short-distance\naviation service, in general. A four-stage sequential approach is used in this\nresearch, wherein the online reviews are mined in Stage 1, analyzed using the\nbigram and trigram models in Stage 2, 7S internal assessment is conducted for\nhelicopter services in Stage 3, and managerial recommendations for air taxis\nare proposed in Stage 4. The insights obtained in this paper could assist any\nair taxi companies in providing better customer service when they venture into\nthe market.\n  Keywords: Air taxi; Emerging technology; Urban Air Mobility (UAM); Helicopter\nservices; Online customer reviews; Text analytics;\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 23:44:49 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Rajendran", "Suchithra", ""], ["Pagel", "Emily", ""]]}, {"id": "2006.10904", "submitter": "Harshal Chaudhari", "authors": "Harshal A. Chaudhari, John W. Byers and Evimaria Terzi", "title": "Learn to Earn: Enabling Coordination within a Ride Hailing Fleet", "comments": "16 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of optimizing social welfare objectives on multi sided ride\nhailing platforms such as Uber, Lyft, etc., is challenging, due to misalignment\nof objectives between drivers, passengers, and the platform itself. An ideal\nsolution aims to minimize the response time for each hyper local passenger ride\nrequest, while simultaneously maintaining high demand satisfaction and supply\nutilization across the entire city. Economists tend to rely on dynamic pricing\nmechanisms that stifle price sensitive excess demand and resolve the supply\ndemand imbalances emerging in specific neighborhoods. In contrast, computer\nscientists primarily view it as a demand prediction problem with the goal of\npreemptively repositioning supply to such neighborhoods using black box\ncoordinated multi agent deep reinforcement learning based approaches. Here, we\nintroduce explainability in the existing supply repositioning approaches by\nestablishing the need for coordination between the drivers at specific\nlocations and times. Explicit need based coordination allows our framework to\nuse a simpler non deep reinforcement learning based approach, thereby enabling\nit to explain its recommendations ex post. Moreover, it provides envy free\nrecommendations i.e., drivers at the same location and time do not envy one\nanother's future earnings. Our experimental evaluation demonstrates the\neffectiveness, the robustness, and the generalizability of our framework.\nFinally, in contrast to previous works, we make available a reinforcement\nlearning environment for end to end reproducibility of our work and to\nencourage future comparative studies.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 00:20:15 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 17:07:58 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Chaudhari", "Harshal A.", ""], ["Byers", "John W.", ""], ["Terzi", "Evimaria", ""]]}, {"id": "2006.10955", "submitter": "Jasmine Bayrooti", "authors": "Nikka Mofid, Jasmine Bayrooti, Shreya Ravi", "title": "Keep Your AI-es on the Road: Tackling Distracted Driver Detection with\n  Convolutional Neural Networks and Targeted Data Augmentation", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the World Health Organization, distracted driving is one of the\nleading cause of motor accidents and deaths in the world. In our study, we\ntackle the problem of distracted driving by aiming to build a robust\nmulti-class classifier to detect and identify different forms of driver\ninattention using the State Farm Distracted Driving Dataset. We utilize\ncombinations of pretrained image classification models, classical data\naugmentation, OpenCV based image preprocessing and skin segmentation\naugmentation approaches. Our best performing model combines several\naugmentation techniques, including skin segmentation, facial blurring, and\nclassical augmentation techniques. This model achieves an approximately 15%\nincrease in F1 score over the baseline, thus showing the promise in these\ntechniques in enhancing the power of neural networks for the task of distracted\ndriver detection.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 04:56:08 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 01:05:55 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Mofid", "Nikka", ""], ["Bayrooti", "Jasmine", ""], ["Ravi", "Shreya", ""]]}, {"id": "2006.11002", "submitter": "Jordan Samhi", "authors": "Jordan Samhi, Kevin Allix, Tegawend\\'e F. Bissyand\\'e, Jacques Klein", "title": "A First Look at Android Applications in Google Play related to Covid-19", "comments": "Accepted in Empirical Software Engineering under reference:\n  EMSE-D-20-00211R1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the convenience of access-on-demand to information and business\nsolutions, mobile apps have become an important asset in the digital world. In\nthe context of the Covid-19 pandemic, app developers have joined the response\neffort in various ways by releasing apps that target different user bases\n(e.g., all citizens or journalists), offer different services (e.g., location\ntracking or diagnostic-aid), provide generic or specialized information, etc.\nWhile many apps have raised some concerns by spreading misinformation or even\nmalware, the literature does not yet provide a clear landscape of the different\napps that were developed. In this study, we focus on the Android ecosystem and\ninvestigate Covid-related Android apps. In a best-effort scenario, we attempt\nto systematically identify all relevant apps and study their characteristics\nwith the objective to provide a First taxonomy of Covid-related apps,\nbroadening the relevance beyond the implementation of contact tracing. Overall,\nour study yields a number of empirical insights that contribute to enlarge the\nknowledge on Covid-related apps: (1) Developer communities contributed rapidly\nto the Covid-19, with dedicated apps released as early as January 2020; (2)\nCovid-related apps deliver digital tools to users (e.g., health diaries), serve\nto broadcast information to users (e.g., spread statistics), and collect data\nfrom users (e.g., for tracing); (3) Covid-related apps are less complex than\nstandard apps; (4) they generally do not seem to leak sensitive data; (5) in\nthe majority of cases, Covid-related apps are released by entities with past\nexperience on the market, mostly official government entities or public health\norganizations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 08:02:31 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 10:04:56 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Samhi", "Jordan", ""], ["Allix", "Kevin", ""], ["Bissyand\u00e9", "Tegawend\u00e9 F.", ""], ["Klein", "Jacques", ""]]}, {"id": "2006.11043", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart and Jiahong Chen", "title": "On the Principle of Accountability: Challenges for Smart Homes &\n  Cybersecurity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter introduces the Accountability Principle and its role in data\nprotection governance. We focus on what accountability means in the context of\ncybersecurity management in smart homes, considering the EU General Data\nProtection Law requirements to secure personal data. This discussion sits\nagainst the backdrop of two key new developments in data protection law.\nFirstly, the law is moving into the home, due to narrowing of the so called\nhousehold exemption. Concurrently, household occupants may now have legal\nresponsibilities to comply with the GDPR, as they find themselves jointly\nresponsible for compliance, as they are possibly held to determine the means\nand purposes of data collection with IoT device vendors. As a complex\nsocio-technical space, we consider the interactions between accountability\nrequirements and the competencies of this new class of domestic data\ncontrollers (DDCs). Specifically, we consider the value and limitations of\nedge-based security analytics to manage smart home cybersecurity risks,\nreviewing a range of prototypes and studies of their use. We also reflect on\ninterpersonal power dynamics in the domestic setting e.g. device control;\nexisting social practices around privacy and security management in smart\nhomes; and usability issues that may hamper DDCs ability to rely on such\nsolutions. We conclude by reflecting on 1) the need for collective security\nmanagement in homes and 2) the increasingly complex divisions of responsibility\nin smart homes between device users, account holders, IoT\ndevice/software/firmware vendors, and third parties.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 09:50:21 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Urquhart", "Lachlan", ""], ["Chen", "Jiahong", ""]]}, {"id": "2006.11068", "submitter": "Kostas Magoutis", "authors": "Angelos Bilas, Dejan Kostic, Kostas Magoutis, Evangelos Markatos,\n  Dushyanth Narayanan, Peter Pietzuch and Margo Seltzer", "title": "The EuroSys 2020 Online Conference: Experience and lessons learned", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 15th European Conference on Computer Systems (EuroSys'20) was organized\nas a virtual (online) conference on April 27-30, 2020. The main EuroSys'20\ntrack took place April 28-30, 2020, preceded by five workshops (EdgeSys'20,\nEuroDW'20, EuroSec'20, PaPoC'20, SPMA'20) on April 27, 2020. The decision to\nhold a virtual (online) conference was taken in early April 2020, after\nconsultations with the EuroSys community and internal discussions about\npotential options, eventually allowing about three weeks for the organization.\nThis paper describes the choices we made to organize EuroSys'20 as a virtual\n(online) conference, the challenges we addressed, and the lessons learned.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 11:03:33 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Bilas", "Angelos", ""], ["Kostic", "Dejan", ""], ["Magoutis", "Kostas", ""], ["Markatos", "Evangelos", ""], ["Narayanan", "Dushyanth", ""], ["Pietzuch", "Peter", ""], ["Seltzer", "Margo", ""]]}, {"id": "2006.11109", "submitter": "Mohammadreza Tavakoli", "authors": "Mohammadreza Molavi, Mohammadreza Tavakoli, and G\\'abor Kismih\\'ok", "title": "Extracting Topics from Open Educational Resources", "comments": "Editted version of this paper has been accepted to be published in\n  the proceedings of The European Conference on Technology-Enhanced Learning\n  (EC-TEL) 2020 by Springer (Lecture Notes in Computer Science (LNCS) Series)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, Open Educational Resources (OERs) were earmarked as critical\nwhen mitigating the increasing need for education globally. Obviously, OERs\nhave high-potential to satisfy learners in many different circumstances, as\nthey are available in a wide range of contexts. However, the low-quality of OER\nmetadata, in general, is one of the main reasons behind the lack of\npersonalised services such as search and recommendation. As a result, the\napplicability of OERs remains limited. Nevertheless, OER metadata about covered\ntopics (subjects) is essentially required by learners to build effective\nlearning pathways towards their individual learning objectives. Therefore, in\nthis paper, we report on a work in progress project proposing an OER topic\nextraction approach, applying text mining techniques, to generate high-quality\nOER metadata about topic distribution. This is done by: 1) collecting 123\nlectures from Coursera and Khan Academy in the area of data science related\nskills, 2) applying Latent Dirichlet Allocation (LDA) on the collected\nresources in order to extract existing topics related to these skills, and 3)\ndefining topic distributions covered by a particular OER. To evaluate our\nmodel, we used the data-set of educational resources from Youtube, and compared\nour topic distribution results with their manually defined target topics with\nthe help of 3 experts in the area of data science. As a result, our model\nextracted topics with 79% of F1-score.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 12:50:55 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Molavi", "Mohammadreza", ""], ["Tavakoli", "Mohammadreza", ""], ["Kismih\u00f3k", "G\u00e1bor", ""]]}, {"id": "2006.11129", "submitter": "Paul Suski", "authors": "Paul Suski, Johanna Pohl and Vivian Frick", "title": "All you can stream: Investigating the role of user behavior for\n  greenhouse gas intensity of video streaming", "comments": "7th International Conference on ICT for Sustainability (ICT4S)", "journal-ref": null, "doi": "10.1145/3401335.3401709", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The information and communication technology sector reportedly has a relevant\nimpact on the environment. Within this sector, video streaming has been\nidentified as a major driver of CO2-emissions. To make streaming more\nsustainable, environmentally relevant factors must be identified on both the\nuser and the provider side. Hence, environmental assessments, like life cycle\nassessments (LCA), need to broaden their perspective from a mere technological\nto one that includes user decisions and behavior. However, quantitative data on\nuser behavior (e.g. streaming duration, choice of end device and resolution)\nare often lacking or difficult to integrate in LCA. Additionally, identifying\nrelevant determinants of user behavior, such as the design of streaming\nplatforms or user motivations, may help to design streaming services that keep\nenvironmental impact at a passable level. In order to carry out assessments in\nsuch a way, interdisciplinary collaboration is necessary. Therefore, this\nexploratory study combined LCA with an online survey (N= 91, 7 consecutive days\nof assessment). Based on this dataset the use phase of online video streaming\nwas modeled. Additionally, factors such as sociodemographic, motivational and\ncontextual determinants were measured. Results show that CO2-intensity of video\nstreaming depends on several factors. It is shown that for climate intensity\nthere is a factor 10 between choosing a smart TV and smartphone for video\nstreaming. Furthermore, results show that some factors can be tackled from\nprovider side to reduce overall energy demand at the user side; one of which is\nsetting a low resolution as default.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 13:38:58 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Suski", "Paul", ""], ["Pohl", "Johanna", ""], ["Frick", "Vivian", ""]]}, {"id": "2006.11158", "submitter": "Max Pellert", "authors": "Max Pellert, Jana Lasser, Hannah Metzler and David Garcia", "title": "Dashboard of sentiment in Austrian social media during COVID-19", "comments": "23 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To track online emotional expressions of the Austrian population close to\nreal-time during the COVID-19 pandemic, we build a self-updating monitor of\nemotion dynamics using digital traces from three different data sources. This\nenables decision makers and the interested public to assess issues such as the\nattitude towards counter-measures taken during the pandemic and the possible\nemergence of a (mental) health crisis early on. We use web scraping and API\naccess to retrieve data from the news platform derstandard.at, Twitter and a\nchat platform for students. We document the technical details of our workflow\nin order to provide materials for other researchers interested in building a\nsimilar tool for different contexts. Automated text analysis allows us to\nhighlight changes of language use during COVID-19 in comparison to a neutral\nbaseline. We use special word clouds to visualize that overall difference.\nLongitudinally, our time series show spikes in anxiety that can be linked to\nseveral events and media reporting. Additionally, we find a marked decrease in\nanger. The changes last for remarkably long periods of time (up to 12 weeks).\nWe discuss these and more patterns and connect them to the emergence of\ncollective emotions. The interactive dashboard showcasing our data is available\nonline under http://www.mpellert.at/covid19_monitor_austria/. Our work has\nattracted media attention and is part of an web archive of resources on\nCOVID-19 collected by the Austrian National Library.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:42:38 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Pellert", "Max", ""], ["Lasser", "Jana", ""], ["Metzler", "Hannah", ""], ["Garcia", "David", ""]]}, {"id": "2006.11244", "submitter": "Lucien Hardy", "authors": "Lucien Hardy", "title": "Counting Risk Increments to Make Decisions During an Epidemic", "comments": "51 pages, many diagrams", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I propose a smartphone app that will allow people to participate in the\nmanagement of their own safety during an epidemic or pandemic such as COVID-19\nby enabling them to view, in advance, the risks they would take if they visit\nsome given venue (a cafe, the gym, the workplace, the park,...) and,\nfurthermore, track the accumulation of such risks during the course of any\ngiven day or week. This idea can be presented to users of the app as counting\npoints. One point represents some constant probability, $p_\\text{point}$, of\ninfection. Then the app would work in a similar way to a calorie counting app\n(instead of counting calories we count probability increments of being\ninfected). Government could set a maximum recommended number of daily (or\nweekly) points available to each user in accord with its objectives (bringing\nthe disease under control, allowing essential workers to work, protecting\nvulnerable individuals, ...). It is posited that this, along with other\nproposed \"levers\" would allow government to manage a gradual transition to\nnormalcy. I discuss a circuit framework with wires running between boxes. In\nthis framework the wires represent possible sources of infection, namely\nindividuals and the venues themselves (through deposits of pathogens left at\nthe venue). The boxes represent interactions of these sources (when individuals\nvisit a venue). This circuit framework allows (i) calculation of points cost\nfor visiting venues and (ii) probabilistic contact tracing. The points systems\nproposed here could complement existing contact tracing apps by adding\nfunctionality to permit users to participate in decision making up front.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 17:35:03 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Hardy", "Lucien", ""]]}, {"id": "2006.11327", "submitter": "Nathalia da Cruz Alves", "authors": "Nathalia da Cruz Alves, Christiane Gresse von Wangenheim and Jean\n  Carlo Rossa Hauck", "title": "Teaching Programming to Novices: A Large-scale Analysis of App Inventor\n  Projects", "comments": "10 pages, 11 figures", "journal-ref": "2020 XV Conferencia Latinoamericana de Tecnologias de Aprendizaje\n  (LACLO), 2020, pp. 1-10", "doi": "10.1109/LACLO50806.2020.9381172", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching programming to K-12 students has become essential. In this context,\nApp Inventor is a popular block-based programming environment used by a wide\naudience, from K-12 to higher education, including end-users to create mobile\napplications to support their primary job or hobbies. Although learning\nprogramming with App Inventor has been investigated, a question that remains is\nwhich programming concepts are typically used and how this compares to other\nblock-based programming environments. Therefore, we explore the characteristics\nof App Inventor projects through a large-scale analysis of 88,606 apps from the\nApp Inventor Gallery. We discovered that the size of App Inventor projects\nvaries from projects with very few blocks to some surprisingly large projects\nwith more than 60,000 blocks. In general, much fewer design components are used\nthan programming blocks, as typically, to work properly, several programming\nblocks are necessary for each design component in an App Inventor project. In\naddition, we also compare our results with the analysis of 233,491 Scratch\nprojects reported by Aivaloglou and Hermans [4]. Several differences can be\nobserved, as in App Inventor projects events are more predominant, with lesser\nuse of conditionals and loops. These findings may guide the decision on the\nadoption of App Inventor for teaching computing depending on the specific\nlearning objectives or indicate the need for tailoring the curricula.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 19:02:02 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 03:19:02 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Alves", "Nathalia da Cruz", ""], ["von Wangenheim", "Christiane Gresse", ""], ["Hauck", "Jean Carlo Rossa", ""]]}, {"id": "2006.11343", "submitter": "Gautam Kishore Shahi", "authors": "Gautam Kishore Shahi, Durgesh Nandini", "title": "FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for\n  COVID-19", "comments": "CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020", "journal-ref": null, "doi": "10.36190/2020.14", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a first multilingual cross-domain dataset of 5182\nfact-checked news articles for COVID-19, collected from 04/01/2020 to\n15/05/2020. We have collected the fact-checked articles from 92 different\nfact-checking websites after obtaining references from Poynter and Snopes. We\nhave manually annotated articles into 11 different categories of the\nfact-checked news according to their content. The dataset is in 40 languages\nfrom 105 countries. We have built a classifier to detect fake news and present\nresults for the automatic fake news detection and its class. Our model achieves\nan F1 score of 0.76 to detect the false class and other fact check articles.\nThe FakeCovid dataset is available at Github.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 19:48:00 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Shahi", "Gautam Kishore", ""], ["Nandini", "Durgesh", ""]]}, {"id": "2006.11354", "submitter": "Karen Renaud", "authors": "James Conacher, Karen Renaud, Jacques Ophoff", "title": "Caveat Venditor, Used USB Drive Owner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  USB drives are a great way of transferring and backing up files. The problem\nis that they are easily lost, and users do not understand how to secure or\nproperly erase them. When used to store private and sensitive information, this\nconstitutes a risk that users may be unaware of. Consider that people sell used\nUSB drives online -- presumably either their own or drives others have lost.\nThis raises some interesting questions, such as whether sellers know how to\nensure that private data is erased before they relinquish the drive to an\nunknown buyer, and whether sellers use these drives in an attempt to compromise\nan unwary buyer's device. Governments do indeed issue advice about the risks of\nused mobile media, but we do not yet know whether this advice is reaching, and\nbeing heeded by, the general public. To assess the situation, a sample of used\nUSB drives were purchased from eBay sellers to determine, first hand, what was\non the drives. This acts as an indicator of actual security-related behaviours\nto answer the questions posed above. Using forensic analysis, it was found that\na great deal of private and sensitive information remained on many of the\ndrives, but there was no trace of malicious software. More effective ways of\nenlightening the public are needed, so that private data is not unwittingly\nleaked via sold used media.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 20:20:29 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Conacher", "James", ""], ["Renaud", "Karen", ""], ["Ophoff", "Jacques", ""]]}, {"id": "2006.11356", "submitter": "Stacy Hobson", "authors": "Stacy Hobson, Michael Hind, Aleksandra Mojsilovic, Kush R. Varshney", "title": "Trust and Transparency in Contact Tracing Applications", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global outbreak of COVID-19 has led to focus on efforts to manage and\nmitigate the continued spread of the disease. One of these efforts include the\nuse of contact tracing to identify people who are at-risk of developing the\ndisease through exposure to an infected person. Historically, contact tracing\nhas been primarily manual but given the exponential spread of the virus that\ncauses COVID-19, there has been significant interest in the development and use\nof digital contact tracing solutions to supplement the work of human contact\ntracers. The collection and use of sensitive personal details by these\napplications has led to a number of concerns by the stakeholder groups with a\nvested interest in these solutions. We explore digital contact tracing\nsolutions in detail and propose the use of a transparent reporting mechanism,\nFactSheets, to provide transparency of and support trust in these applications.\nWe also provide an example FactSheet template with questions that are specific\nto the contact tracing application domain.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 20:29:24 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Hobson", "Stacy", ""], ["Hind", "Michael", ""], ["Mojsilovic", "Aleksandra", ""], ["Varshney", "Kush R.", ""]]}, {"id": "2006.11373", "submitter": "Jimut Bahan Pal Mr.", "authors": "Jimut Bahan Pal", "title": "Deceiving computers in Reverse Turing Test through Deep Learning", "comments": "Masters thesis. All Text CAPTCHAs are broken with over 99% accuracy,\n  hence they are proved to be unreliable", "journal-ref": null, "doi": null, "report-no": "B1930050", "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is increasingly becoming difficult for human beings to work on their day\nto day life without going through the process of reverse Turing test, where the\nComputers tests the users to be humans or not. Almost every website and service\nproviders today have the process of checking whether their website is being\ncrawled or not by automated bots which could extract valuable information from\ntheir site. In the process the bots are getting more intelligent by the use of\nDeep Learning techniques to decipher those tests and gain unwanted automated\naccess to data while create nuisance by posting spam. Humans spend a\nconsiderable amount of time almost every day when trying to decipher CAPTCHAs.\nThe aim of this investigation is to check whether the use of a subset of\ncommonly used CAPTCHAs, known as the text CAPTCHA is a reliable process for\nverifying their human customers. We mainly focused on the preprocessing step\nfor every CAPTCHA which converts them in binary intensity and removes the\nconfusion as much as possible and developed various models to correctly label\nas many CAPTCHAs as possible. We also suggested some ways to improve the\nprocess of verifying the humans which makes it easy for humans to solve the\nexisting CAPTCHAs and difficult for bots to do the same.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 10:11:42 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Pal", "Jimut Bahan", ""]]}, {"id": "2006.11398", "submitter": "Mark Whiting", "authors": "Abdullah Almaatouq, Joshua Becker, James P. Houghton, Nicolas Paton,\n  Duncan J. Watts, Mark E. Whiting", "title": "Empirica: a virtual lab for high-throughput macro-level experiments", "comments": "36 pages, 6 figures. Accepted to Behavioral Research Methods. Behav\n  Res (2021)", "journal-ref": null, "doi": "10.3758/s13428-020-01535-9", "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual labs allow researchers to design high-throughput and macro-level\nexperiments that are not feasible in traditional in-person physical lab\nsettings. Despite the increasing popularity of online research, researchers\nstill face many technical and logistical barriers when designing and deploying\nvirtual lab experiments. While several platforms exist to facilitate the\ndevelopment of virtual lab experiments, they typically present researchers with\na stark trade-off between usability and functionality. We introduce Empirica: a\nmodular virtual lab that offers a solution to the usability-functionality\ntrade-off by employing a \"flexible defaults\" design strategy. This strategy\nenables us to maintain complete \"build anything\" flexibility while offering a\ndevelopment platform that is accessible to novice programmers. Empirica's\narchitecture is designed to allow for parameterizable experimental designs,\nreusable protocols, and rapid development. These features will increase the\naccessibility of virtual lab experiments, remove barriers to innovation in\nexperiment design, and enable rapid progress in the understanding of\ndistributed human computation.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 21:28:07 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 15:57:28 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Almaatouq", "Abdullah", ""], ["Becker", "Joshua", ""], ["Houghton", "James P.", ""], ["Paton", "Nicolas", ""], ["Watts", "Duncan J.", ""], ["Whiting", "Mark E.", ""]]}, {"id": "2006.11642", "submitter": "Yuhao Du", "authors": "Yuhao Du and Kenneth Joseph", "title": "MDR Cluster-Debias: A Nonlinear WordEmbedding Debiasing Pipeline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for debiasing word embeddings often do so only\nsuperficially, in that words that are stereotypically associated with, e.g., a\nparticular gender in the original embedding space can still be clustered\ntogether in the debiased space. However, there has yet to be a study that\nexplores why this residual clustering exists, and how it might be addressed.\nThe present work fills this gap. We identify two potential reasons for which\nresidual bias exists and develop a new pipeline, MDR Cluster-Debias, to\nmitigate this bias. We explore the strengths and weaknesses of our method,\nfinding that it significantly outperforms other existing debiasing approaches\non a variety of upstream bias tests but achieves limited improvement on\ndecreasing gender bias in a downstream task. This indicates that word\nembeddings encode gender bias in still other ways, not necessarily captured by\nupstream tests.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 20:03:07 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Du", "Yuhao", ""], ["Joseph", "Kenneth", ""]]}, {"id": "2006.11686", "submitter": "Chi Zhang", "authors": "Huitong Ding, Chi Zhang, Ning An, Lingling Zhang, Ning Xie, Gil\n  Alterovitz", "title": "Digital personal health libraries: a systematic literature review", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: This paper gives context on recent literature regarding the\ndevelopment of digital personal health libraries (PHL) and provides insights\ninto the potential application of consumer health informatics in diverse\nclinical specialties. Materials and Methods: A systematic literature review was\nconducted following the Preferred Reporting Items for Systematic Reviews and\nMeta-Analyses (PRISMA) statement. Here, 2,850 records were retrieved from\nPubMed and EMBASE in March 2020 using search terms: personal, health, and\nlibrary. Information related to the health topic, target population, study\npurpose, library function, data source, data science method, evaluation\nmeasure, and status were extracted from each eligible study. In addition,\nknowledge discovery methods, including co-occurrence analysis and multiple\ncorrespondence analysis, were used to explore research trends of PHL. Results:\nAfter screening, this systematic review focused on a dozen articles related to\nPHL. These encompassed health topics such as infectious diseases, congestive\nheart failure, electronic prescribing. Data science methods included relational\ndatabase, information retrieval technology, ontology construction technology.\nEvaluation measures were heterogeneous regarding PHL functions and settings. At\nthe time of writing, only one of the PHLs described in these articles is\navailable for the public while the others are either prototypes or in the pilot\nstage. Discussion: Although PHL researches have used different methods to\naddress problems in diverse health domains, there is a lack of an effective PHL\nto meet the needs of older adults. Conclusion: The development of PHLs may\ncreate an unprecedented opportunity for promoting the health of older consumers\nby providing diverse health information.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 01:11:38 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Ding", "Huitong", ""], ["Zhang", "Chi", ""], ["An", "Ning", ""], ["Zhang", "Lingling", ""], ["Xie", "Ning", ""], ["Alterovitz", "Gil", ""]]}, {"id": "2006.11929", "submitter": "Lynsay Shepherd", "authors": "Harjinder Singh Lallie, Lynsay A. Shepherd, Jason R. C. Nurse, Arnau\n  Erola, Gregory Epiphaniou, Carsten Maple, Xavier Bellekens", "title": "Cyber Security in the Age of COVID-19: A Timeline and Analysis of\n  Cyber-Crime and Cyber-Attacks during the Pandemic", "comments": "20 pages, 6 figures", "journal-ref": "Computers & Security 2021", "doi": "10.1016/j.cose.2021.102248", "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic was a remarkable unprecedented event which altered the\nlives of billions of citizens globally resulting in what became commonly\nreferred to as the new-normal in terms of societal norms and the way we live\nand work. Aside from the extraordinary impact on society and business as a\nwhole, the pandemic generated a set of unique cyber-crime related circumstances\nwhich also affected society and business. The increased anxiety caused by the\npandemic heightened the likelihood of cyber-attacks succeeding corresponding\nwith an increase in the number and range of cyber-attacks.\n  This paper analyses the COVID-19 pandemic from a cyber-crime perspective and\nhighlights the range of cyber-attacks experienced globally during the pandemic.\nCyber-attacks are analysed and considered within the context of key global\nevents to reveal the modus-operandi of cyber-attack campaigns. The analysis\nshows how following what appeared to be large gaps between the initial outbreak\nof the pandemic in China and the first COVID-19 related cyber-attack, attacks\nsteadily became much more prevalent to the point that on some days, 3 or 4\nunique cyber-attacks were being reported. The analysis proceeds to utilise the\nUK as a case study to demonstrate how cyber-criminals leveraged key events and\ngovernmental announcements to carefully craft and design cyber-crime campaigns.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 22:53:47 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Lallie", "Harjinder Singh", ""], ["Shepherd", "Lynsay A.", ""], ["Nurse", "Jason R. C.", ""], ["Erola", "Arnau", ""], ["Epiphaniou", "Gregory", ""], ["Maple", "Carsten", ""], ["Bellekens", "Xavier", ""]]}, {"id": "2006.12069", "submitter": "Leonardo Horn Iwaya", "authors": "Leonardo Horn Iwaya, Aakash Ahmad, M. Ali Babar", "title": "Security and Privacy for mHealth and uHealth Systems: a Systematic\n  Mapping Study", "comments": "29 pages, 10 figures, in IEEE Access, 2020", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3015962", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increased adoption of mobile health (mHealth) and ubiquitous health\n(uHealth) systems empower users with handheld devices and embedded sensors for\na broad range of healthcare services. However, m/uHealth systems face\nsignificant challenges related to data security and privacy that must be\naddressed to increase the pervasiveness of such systems. This study aims to\nsystematically identify, classify, compare, and evaluate state-of-the-art on\nsecurity and privacy of m/uHealth systems. We conducted a systematic mapping\nstudy (SMS) based on 365 qualitatively selected studies to (i) classify the\ntypes, frequency, and demography of published research and (ii) synthesize and\ncategorize research themes, (iii) recurring challenges, (iv) prominent\nsolutions (i.e., research outcomes) and their (v) reported evaluations (i.e.,\npractical validations). Results suggest that the existing research on security\nand privacy of m/uHealth systems primarily focuses on select group of control\nfamilies (compliant with NIST800-53), protection of systems and information,\naccess control, authentication, individual participation, and privacy\nauthorisation. In contrast, areas of data governance, security and privacy\npolicies, and program management are under-represented, although these are\ncritical to most of the organizations that employ m/uHealth systems. Most\nresearch proposes new solutions with limited validation, reflecting a lack of\nevaluation of security and privacy of m/uHealth in the real world. Empirical\nresearch, development, and validation of m/uHealth security and privacy is\nstill incipient, which may discourage practitioners from readily adopting\nsolutions from the literature. This SMS facilitates knowledge transfer,\nenabling researchers and practitioners to engineer security and privacy for\nemerging and next generation of m/uHealth systems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 08:44:49 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Iwaya", "Leonardo Horn", ""], ["Ahmad", "Aakash", ""], ["Babar", "M. Ali", ""]]}, {"id": "2006.12110", "submitter": "Sheeba Samuel", "authors": "Sheeba Samuel and Birgitta K\\\"onig-Ries", "title": "ReproduceMeGit: A Visualization Tool for Analyzing Reproducibility of\n  Jupyter Notebooks", "comments": "Accepted at ProvenanceWeek 2020\n  (https://iitdbgroup.github.io/ProvenanceWeek2020/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational notebooks have gained widespread adoption among researchers\nfrom academia and industry as they support reproducible science. These\nnotebooks allow users to combine code, text, and visualizations for easy\nsharing of experiments and results. They are widely shared in GitHub, which\ncurrently has more than 100 million repositories making it the largest host of\nsource code in the world. Recent reproducibility studies have indicated that\nthere exist good and bad practices in writing these notebooks which can affect\ntheir overall reproducibility. We present ReproduceMeGit, a visualization tool\nfor analyzing the reproducibility of Jupyter Notebooks. This will help\nrepository users and owners to reproduce and directly analyze and assess the\nreproducibility of any GitHub repository containing Jupyter Notebooks. The tool\nprovides information on the number of notebooks that were successfully\nreproducible, those that resulted in exceptions, those with different results\nfrom the original notebooks, etc. Each notebook in the repository along with\nthe provenance information of its execution can also be exported in RDF with\nthe integration of the ProvBook tool.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:05:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Samuel", "Sheeba", ""], ["K\u00f6nig-Ries", "Birgitta", ""]]}, {"id": "2006.12129", "submitter": "Mauro Vallati", "authors": "Daniel Harabor and Mauro Vallati", "title": "Organising a Successful AI Online Conference: Lessons from SoCS 2020", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 13th Symposium on Combinatorial Search (SoCS) was held May 26-28, 2020.\nOriginally scheduled to take place in Vienna, Austria, the symposium pivoted\ntoward a fully online technical program in early March. As an in-person event\nSoCS offers participants a diverse array of scholarly activities including\ntechnical talks (long and short), poster sessions, plenary sessions, a\ncommunity meeting and, new for 2020, a Master Class tutorial program.\n  This paper describes challenges, approaches and opportunities associated with\nadapting these many different activities to the online setting. We consider\nissues such as scheduling, dissemination, attendee interaction and community\nengagement before, during and after the event. We report on the approaches\ntaken by SoCS in each case, we give a post-hoc analysis of their their\neffectiveness and we discuss how these decisions continue to impact the SoCS\ncommunity in the days after SoCS 2020.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 10:34:06 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Harabor", "Daniel", ""], ["Vallati", "Mauro", ""]]}, {"id": "2006.12191", "submitter": "Duan Zhihua", "authors": "Duan Zhihua, Wang JiaLin", "title": "Potential customer mining application of smart home products based on\n  LightGBM PU learning and Spark ML algorithm practice", "comments": "7 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the case of big data-based intelligent product potential\ncustomer mining internal competition in China Telecom Shanghai Company. Huge\namounts of data based on big data table, the use of machine Learning and data\nanalysis technology, using the algorithm of LightGBM, PySpark machine Learning\nalgorithms, Positive Unlabeled Learning algorithm, and predict whether\ncustomers buy whole house product, precision marketing into artificial\nintelligence for the customer, large data capacity, promote the development of\nintelligent products of the company.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 12:42:53 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zhihua", "Duan", ""], ["JiaLin", "Wang", ""]]}, {"id": "2006.12358", "submitter": "Bogdana Rakova", "authors": "Bogdana Rakova, Jingying Yang, Henriette Cramer, Rumman Chowdhury", "title": "Where Responsible AI meets Reality: Practitioner Perspectives on\n  Enablers for shifting Organizational Practices", "comments": "In Proceedings of the 24th ACM Conference on Computer-Supported\n  Cooperative Work and Social Computing", "journal-ref": null, "doi": "10.1145/3449081", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large and ever-evolving technology companies continue to invest more time and\nresources to incorporate responsible Artificial Intelligence (AI) into\nproduction-ready systems to increase algorithmic accountability. This paper\nexamines and seeks to offer a framework for analyzing how organizational\nculture and structure impact the effectiveness of responsible AI initiatives in\npractice. We present the results of semi-structured qualitative interviews with\npractitioners working in industry, investigating common challenges, ethical\ntensions, and effective enablers for responsible AI initiatives. Focusing on\nmajor companies developing or utilizing AI, we have mapped what organizational\nstructures currently support or hinder responsible AI initiatives, what\naspirational future processes and structures would best enable effective\ninitiatives, and what key elements comprise the transition from current work\npractices to the aspirational future.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 15:57:30 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 18:29:12 GMT"}, {"version": "v3", "created": "Tue, 17 Nov 2020 16:57:58 GMT"}, {"version": "v4", "created": "Wed, 3 Mar 2021 01:59:43 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Rakova", "Bogdana", ""], ["Yang", "Jingying", ""], ["Cramer", "Henriette", ""], ["Chowdhury", "Rumman", ""]]}, {"id": "2006.12362", "submitter": "Cristiana Santos", "authors": "George Anthony Gal, Cristiana Santos, Lucien Rapp, R\\'eeka Markovich\n  and Leendert van der Torre", "title": "Artificial intelligence in space", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the next coming years, space activities are expected to undergo a radical\ntransformation with the emergence of new satellite systems or new services\nwhich will incorporate the contributions of artificial intelligence and machine\nlearning defined as covering a wide range of innovations from autonomous\nobjects with their own decision-making power to increasingly sophisticated\nservices exploiting very large volumes of information from space. This chapter\nidentifies some of the legal and ethical challenges linked to its use. These\nlegal and ethical challenges call for solutions which the international\ntreaties in force are not sufficient to determine and implement. For this\nreason, a legal methodology must be developed that makes it possible to link\nintelligent systems and services to a system of rules applicable thereto. It\ndiscusses existing legal AI-based tools amenable for making space law\nactionable, interoperable and machine readable for future compliance tools.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 16:00:44 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Gal", "George Anthony", ""], ["Santos", "Cristiana", ""], ["Rapp", "Lucien", ""], ["Markovich", "R\u00e9eka", ""], ["van der Torre", "Leendert", ""]]}, {"id": "2006.12387", "submitter": "Bogdana Rakova", "authors": "Bogdana Rakova and Alexander Winter", "title": "Leveraging traditional ecological knowledge in ecosystem restoration\n  projects utilizing machine learning", "comments": "In Proceedings of the ACM Knowledge Discovery and Data Mining (KDD)\n  2020 Conference Workshop on \"Fragile Earth: Data Science for a Sustainable\n  Planet\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ecosystem restoration has been recognized to be critical to achieving\naccelerating progress on all of the United Nations' Sustainable Development\nGoals. Decision makers, policymakers, data scientists, earth scientists, and\nother scholars working on these projects could positively benefit from the\nexplicit consideration and inclusion of diverse perspectives. Community\nengagement throughout the stages of ecosystem restoration projects could\ncontribute to improved community well-being, the conservation of biodiversity,\necosystem functions, and the resilience of socio-ecological systems. Conceptual\nframeworks are needed for the meaningful integration of traditional ecological\nknowledge of indigenous peoples and local communities with data science and\nmachine learning work practices. Adaptive frameworks would consider and address\nthe needs and challenges of local communities and geographic locations by\nimproving community and inter-agent communication around restoration and\nconservation projects and by making relevant real-time data accessible. In this\npaper, we provide a brief analysis of existing Machine Learning (ML)\napplications for forest ecosystem restoration projects. We go on to question if\ntheir inherent limitations may prevent them from being able to adequately\naddress socio-cultural aspects of the well-being of all involved stakeholders.\nBias and unintended consequences pose significant risks of downstream negative\nimplications of ML-based solutions. We suggest that adaptive and scalable\npractices could incentivize interdisciplinary collaboration during all stages\nof ecosystemic ML restoration projects and align incentives between human and\nalgorithmic actors. Furthermore, framing ML projects as open and reiterative\nprocesses can facilitate access on various levels and create incentives that\nlead to catalytic cooperation in the scaling of restoration efforts.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 16:17:48 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 17:00:15 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 15:05:24 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Rakova", "Bogdana", ""], ["Winter", "Alexander", ""]]}, {"id": "2006.12411", "submitter": "Lily Xu", "authors": "Lily Xu, Andrew Perrault, Andrew Plumptre, Margaret Driciru, Fred\n  Wanyama, Aggrey Rwetsiba, Milind Tambe", "title": "Game Theory on the Ground: The Effect of Increased Patrols on Deterring\n  Poachers", "comments": "5 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of artificial intelligence for wildlife protection have focused\non learning models of poacher behavior based on historical patterns. However,\npoachers' behaviors are described not only by their historical preferences, but\nalso their reaction to ranger patrols. Past work applying machine learning and\ngame theory to combat poaching have hypothesized that ranger patrols deter\npoachers, but have been unable to find evidence to identify how or even if\ndeterrence occurs. Here for the first time, we demonstrate a measurable\ndeterrence effect on real-world poaching data. We show that increased patrols\nin one region deter poaching in the next timestep, but poachers then move to\nneighboring regions. Our findings offer guidance on how adversaries should be\nmodeled in realistic game-theoretic settings.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 16:40:10 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Xu", "Lily", ""], ["Perrault", "Andrew", ""], ["Plumptre", "Andrew", ""], ["Driciru", "Margaret", ""], ["Wanyama", "Fred", ""], ["Rwetsiba", "Aggrey", ""], ["Tambe", "Milind", ""]]}, {"id": "2006.12557", "submitter": "Avi Schwarzschild", "authors": "Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P Dickerson, Tom\n  Goldstein", "title": "Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and\n  Data Poisoning Attacks", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning and backdoor attacks manipulate training data in order to\ncause models to fail during inference. A recent survey of industry\npractitioners found that data poisoning is the number one concern among threats\nranging from model stealing to adversarial attacks. However, it remains unclear\nexactly how dangerous poisoning methods are and which ones are more effective\nconsidering that these methods, even ones with identical objectives, have not\nbeen tested in consistent or realistic settings. We observe that data poisoning\nand backdoor attacks are highly sensitive to variations in the testing setup.\nMoreover, we find that existing methods may not generalize to realistic\nsettings. While these existing works serve as valuable prototypes for data\npoisoning, we apply rigorous tests to determine the extent to which we should\nfear them. In order to promote fair comparison in future work, we develop\nstandardized benchmarks for data poisoning and backdoor attacks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 18:34:08 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 21:59:59 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 14:10:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Schwarzschild", "Avi", ""], ["Goldblum", "Micah", ""], ["Gupta", "Arjun", ""], ["Dickerson", "John P", ""], ["Goldstein", "Tom", ""]]}, {"id": "2006.12559", "submitter": "Driss Benhaddou", "authors": "Ghezlane Halhoul Merabet, Mohamed Essaaidi, Mohamed Ben-Haddou,\n  Basheer Qolomany, Junaid Qadir, Muhammad Anan, Ala Al-Fuqaha, Riduan Mohamed\n  Abid and Driss Benhaddou", "title": "Artificial Intelligence-Assisted Energy and Thermal Comfort Control for\n  Sustainable Buildings: An Extended Representation of the Systematic Review", "comments": "1 table of 20 pages representing the latest research done in\n  application of AI in building", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different factors such as thermal comfort, humidity, air quality, and noise\nhave significant combined effects on the acceptability and quality of the\nactivities performed by the building occupants who spend most of their times\nindoors. Among the factors cited, thermal comfort, which contributes to the\nhuman well-being because of its connection with the thermoregulation of the\nhuman body. Therefore, the creation of thermally comfortable and energy\nefficient environments is of great importance in the design of the buildings\nand hence the heating, ventilation and air-conditioning systems. Recent works\nhave been directed towards more advanced control strategies, based mainly on\nartificial intelligence which has the ability to imitate human behavior. This\nsystematic literature review aims to provide an overview of the intelligent\ncontrol strategies inside building and to investigate their ability to balance\nthermal comfort and energy efficiency optimization in indoor environments.\nMethods. A systematic literature review examined the peer-reviewed research\nworks using ACM Digital Library, Scopus, Google Scholar, IEEE Xplore (IEOL),\nWeb of Science, and Science Direct (SDOL), besides other sources from manual\nsearch. With the following string terms: thermal comfort, comfort temperature,\npreferred temperature, intelligent control, advanced control, artificial\nintelligence, computational intelligence, building, indoors, and built\nenvironment. Inclusion criteria were: English, studies monitoring, mainly,\nhuman thermal comfort in buildings and energy efficiency simultaneously based\non control strategies using the intelligent approaches. Preferred Reporting\nItems for Systematic Reviews and Meta-Analysis guidelines were used. Initially,\n1,077 articles were yielded, and 120 ultimately met inclusion criteria and were\nreviewed.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 18:38:13 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 18:38:52 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Merabet", "Ghezlane Halhoul", ""], ["Essaaidi", "Mohamed", ""], ["Ben-Haddou", "Mohamed", ""], ["Qolomany", "Basheer", ""], ["Qadir", "Junaid", ""], ["Anan", "Muhammad", ""], ["Al-Fuqaha", "Ala", ""], ["Abid", "Riduan Mohamed", ""], ["Benhaddou", "Driss", ""]]}, {"id": "2006.12621", "submitter": "Vedant Nanda", "authors": "Vedant Nanda and Samuel Dooley and Sahil Singla and Soheil Feizi and\n  John P. Dickerson", "title": "Fairness Through Robustness: Investigating Robustness Disparity in Deep\n  Learning", "comments": "Accepted at ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are increasingly used in real-world applications\n(e.g. facial recognition). This has resulted in concerns about the fairness of\ndecisions made by these models. Various notions and measures of fairness have\nbeen proposed to ensure that a decision-making system does not\ndisproportionately harm (or benefit) particular subgroups of the population. In\nthis paper, we argue that traditional notions of fairness that are only based\non models' outputs are not sufficient when the model is vulnerable to\nadversarial attacks. We argue that in some cases, it may be easier for an\nattacker to target a particular subgroup, resulting in a form of\n\\textit{robustness bias}. We show that measuring robustness bias is a\nchallenging task for DNNs and propose two methods to measure this form of bias.\nWe then conduct an empirical study on state-of-the-art neural networks on\ncommonly used real-world datasets such as CIFAR-10, CIFAR-100, Adience, and\nUTKFace and show that in almost all cases there are subgroups (in some cases\nbased on sensitive attributes like race, gender, etc) which are less robust and\nare thus at a disadvantage. We argue that this kind of bias arises due to both\nthe data distribution and the highly complex nature of the learned decision\nboundary in the case of DNNs, thus making mitigation of such biases a\nnon-trivial task. Our results show that robustness bias is an important\ncriterion to consider while auditing real-world systems that rely on DNNs for\ndecision making. Code to reproduce all our results can be found here:\n\\url{https://github.com/nvedant07/Fairness-Through-Robustness}\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 22:22:24 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 07:42:59 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 00:56:26 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 13:18:04 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Nanda", "Vedant", ""], ["Dooley", "Samuel", ""], ["Singla", "Sahil", ""], ["Feizi", "Soheil", ""], ["Dickerson", "John P.", ""]]}, {"id": "2006.12624", "submitter": "Marie Alaghband", "authors": "Marie Alaghband, Ivan Garibay", "title": "Effects of Non-Cognitive Factors on Post-Secondary Persistence of Deaf\n  Students: An Agent-Based Modeling Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-secondary education persistence is the likelihood of a student remaining\nin post-secondary education. Although statistics show that post-secondary\npersistence for deaf students has increased recently, there are still many\nobstacles obstructing students from completing their post-secondary degree\ngoals. Therefore, increasing the persistence rate is crucial to increase\neducation and work goals for deaf students. In this work, we present an\nagent-based model using NetLogo software for the persistence phenomena of deaf\nstudents. We consider four non-cognitive factors: having clear goals, social\nintegration, social skills, and academic experience, which influence the\ndeparture decision of deaf students. Progress and results of this work suggest\nthat agent-based modeling approaches promise to give better understanding of\nwhat will increase persistence.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 21:11:56 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Alaghband", "Marie", ""], ["Garibay", "Ivan", ""]]}, {"id": "2006.12628", "submitter": "Amari Lewis", "authors": "Amari N. Lewis, Amelia C. Regan", "title": "Paratransit Agency Responses to the Adoption of Sub-contracted Services\n  Using Secure Technologies", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation agencies across the United States have the responsibility of\nproviding transportation services for all travelers. Paratransit services which\nare designed to meet the needs of disabled travelers have been available to a\ncertain extent for decades, but under the Americans with Disabilities Act\nmandate of 1990, uniform requirements were adopted across U.S. agencies. Most\nof these paratransit operators offer services which must be scheduled at least\na day in advance. And, provision of these services by accessible busses is\ngenerally very expensive. Therefore, many agencies are considering\nsub-contracting some services to approved ride-hailing or taxi services. The\npurpose of this work is to examine the opinions of various public agencies with\nrespect to the adoption of sub-contracted services through the use of secure\ntechnologies. Our research provides insight into the future of these\npartnerships. Agencies expressed interest in the use of privacy preserving\nsecure technologies as well as a strong desire for better software solutions\nfor paratransit passengers and operators. The on-line survey received thirty\nresponses for a completion rate of 19.1%. Our primary findings are that a major\nconcern of agencies for this sort of arrangement is the lack of Wheelchair\nAccessible Vehicles offered by taxis and TNCs and about 36% of the surveyed\nagencies have not considered such partnerships.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 21:25:43 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Lewis", "Amari N.", ""], ["Regan", "Amelia C.", ""]]}, {"id": "2006.12720", "submitter": "Konstantinos Pelechrinis", "authors": "Kristi Bushman, Konstantinos Pelechrinis, Alexandros Labrinidis", "title": "Effectiveness and Compliance to Social Distancing During COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the absence of pharmaceutical interventions to curb the spread of\nCOVID-19, countries relied on a number of nonpharmaceutical interventions to\nfight the first wave of the pandemic. The most prevalent one has been\nstay-at-home orders, whose the goal is to limit the physical contact between\npeople, which consequently will reduce the number of secondary infections\ngenerated. In this work, we use a detailed set of mobility data to evaluate the\nimpact that these interventions had on alleviating the spread of the virus in\nthe US as measured through the COVID-19-related deaths. To establish this\nimpact, we use the notion of Granger causality between two time-series. We show\nthat there is a unidirectional Granger causality, from the median percentage of\ntime spent daily at home to the daily number of COVID-19-related deaths with a\nlag of 2 weeks. We further analyze the mobility patterns at the census block\nlevel to identify which parts of the population might encounter difficulties in\nadhering and complying with social distancing measures. This information is\nimportant, since it can consequently drive interventions that aim at helping\nthese parts of the population.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 03:36:19 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 22:55:57 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Bushman", "Kristi", ""], ["Pelechrinis", "Konstantinos", ""], ["Labrinidis", "Alexandros", ""]]}, {"id": "2006.12759", "submitter": "Eduardo Ogasawara", "authors": "Balthazar Paix\\~ao, Lais Baroni, Rebecca Salles, Luciana Escobar,\n  Carlos de Sousa, Marcel Pedroso, Raphael Saldanha, Rafaelli Coutinho, Fabio\n  Porto, Eduardo Ogasawara", "title": "Estimation of COVID-19 under-reporting in Brazilian States through SARI", "comments": null, "journal-ref": null, "doi": "10.1007/s00354-021-00125-3", "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its impact, COVID-19 has been stressing the academy to search for\ncuring, mitigating, or controlling it. However, when it comes to controlling,\nthere are still few studies focused on under-reporting estimates. It is\nbelieved that under-reporting is a relevant factor in determining the actual\nmortality rate and, if not considered, can cause significant misinformation.\nTherefore, the objective of this work is to estimate the under-reporting of\ncases and deaths of COVID-19 in Brazilian states using data from the Infogripe\non notification of Severe Acute Respiratory Infection (SARI). The methodology\nis based on the concepts of inertia and the use of event detection techniques\nto study the time series of hospitalized SARI cases. The estimate of real cases\nof the disease, called novelty, is calculated by comparing the difference in\nSARI cases in 2020 (after COVID-19) with the total expected cases in recent\nyears (2016 to 2019) derived from a seasonal exponential moving average. The\nresults show that under-reporting rates vary significantly between states and\nthat there are no general patterns for states in the same region in Brazil.\n  The published version of this paper is made available at\nhttps://doi.org/10.1007/s00354-021-00125-3.\n  Please cite as: B. Paix\\~ao, L. Baroni, M. Pedroso, R. Salles, L. Escobar, C.\nde Sousa, R. de Freitas Saldanha, J. Soares, R. Coutinho, et al., 2021,\nEstimation of COVID-19 Under-Reporting in the Brazilian States Through SARI,\nNew Generation Computing\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 04:54:22 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 15:06:08 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Paix\u00e3o", "Balthazar", ""], ["Baroni", "Lais", ""], ["Salles", "Rebecca", ""], ["Escobar", "Luciana", ""], ["de Sousa", "Carlos", ""], ["Pedroso", "Marcel", ""], ["Saldanha", "Raphael", ""], ["Coutinho", "Rafaelli", ""], ["Porto", "Fabio", ""], ["Ogasawara", "Eduardo", ""]]}, {"id": "2006.12793", "submitter": "Ross Cutler", "authors": "Jamie Pool, Ebrahim Beyrami, Vishak Gopal, Ashkan Aazami, Jayant\n  Gupchup, Jeff Rowland, Binlong Li, Pritesh Kanani, Ross Cutler, and Johannes\n  Gehrke", "title": "Lumos: A Library for Diagnosing Metric Regressions in Web-Scale\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web-scale applications can ship code on a daily to weekly cadence. These\napplications rely on online metrics to monitor the health of new releases.\nRegressions in metric values need to be detected and diagnosed as early as\npossible to reduce the disruption to users and product owners. Regressions in\nmetrics can surface due to a variety of reasons: genuine product regressions,\nchanges in user population, and bias due to telemetry loss (or processing) are\namong the common causes. Diagnosing the cause of these metric regressions is\ncostly for engineering teams as they need to invest time in finding the root\ncause of the issue as soon as possible. We present Lumos, a Python library\nbuilt using the principles of AB testing to systematically diagnose metric\nregressions to automate such analysis. Lumos has been deployed across the\ncomponent teams in Microsoft's Real-Time Communication applications Skype and\nMicrosoft Teams. It has enabled engineering teams to detect 100s of real\nchanges in metrics and reject 1000s of false alarms detected by anomaly\ndetectors. The application of Lumos has resulted in freeing up as much as 95%\nof the time allocated to metric-based investigations. In this work, we open\nsource Lumos and present our results from applying it to two different\ncomponents within the RTC group over millions of sessions. This general library\ncan be coupled with any production system to manage the volume of alerting\nefficiently.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 07:02:07 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Pool", "Jamie", ""], ["Beyrami", "Ebrahim", ""], ["Gopal", "Vishak", ""], ["Aazami", "Ashkan", ""], ["Gupchup", "Jayant", ""], ["Rowland", "Jeff", ""], ["Li", "Binlong", ""], ["Kanani", "Pritesh", ""], ["Cutler", "Ross", ""], ["Gehrke", "Johannes", ""]]}, {"id": "2006.13062", "submitter": "Arthur Kramer", "authors": "Arthur Kramer and Clio Dosi and Manuel Iori and Matteo Vignoli", "title": "Successful implementation of discrete event simulation: the case of an\n  Italian emergency department", "comments": "24 pages, 8 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the study of a practical management problem faced by a\nhealthcare {\\it emergency department} (ED) located in the north of Italy. The\nobjective of our study was to propose organisational changes in the selected\nED, which admits approximately 7000 patients per month, aiming at improving key\nperformance indicators related to patient satisfaction, such as the waiting\ntime. Our study is based on a design thinking process that adopts a {\\it\ndiscrete event simulation} (DES) model as the main tool for proposing changes.\nWe used the DES model to propose and evaluate the impact of different improving\nscenarios. The model is based on historical data, on the observation of the\ncurrent ED situation, and information obtained from the ED staff. The results\nobtained by the DES model have been compared with those related to the existing\nED setting, and then validated by the ED managers. Based on the results we\nobtained, one of the tested scenarios was selected by the ED for\nimplementation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 14:38:05 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kramer", "Arthur", ""], ["Dosi", "Clio", ""], ["Iori", "Manuel", ""], ["Vignoli", "Matteo", ""]]}, {"id": "2006.13132", "submitter": "Martin Pawelczyk", "authors": "Martin Pawelczyk, Klaus Broelemann, Gjergji Kasneci", "title": "On Counterfactual Explanations under Predictive Multiplicity", "comments": null, "journal-ref": "Proceedings of the 36th Conference on Uncertainty in Artificial\n  Intelligence (UAI), PMLR volume 124, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual explanations are usually obtained by identifying the smallest\nchange made to an input to change a prediction made by a fixed model (hereafter\ncalled sparse methods). Recent work, however, has revitalized an old insight:\nthere often does not exist one superior solution to a prediction problem with\nrespect to commonly used measures of interest (e.g. error rate). In fact, often\nmultiple different classifiers give almost equal solutions. This phenomenon is\nknown as predictive multiplicity (Breiman, 2001; Marx et al., 2019). In this\nwork, we derive a general upper bound for the costs of counterfactual\nexplanations under predictive multiplicity. Most notably, it depends on a\ndiscrepancy notion between two classifiers, which describes how differently\nthey treat negatively predicted individuals. We then compare sparse and data\nsupport approaches empirically on real-world data. The results show that data\nsupport methods are more robust to multiplicity of different models. At the\nsame time, we show that those methods have provably higher cost of generating\ncounterfactual explanations under one fixed model. In summary, our theoretical\nand empiricaln results challenge the commonly held view that counterfactual\nrecommendations should be sparse in general.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 16:25:47 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Pawelczyk", "Martin", ""], ["Broelemann", "Klaus", ""], ["Kasneci", "Gjergji", ""]]}, {"id": "2006.13152", "submitter": "Giulia Carella", "authors": "Giulia Carella, Andy Eschbacher, Dongjie Fan, Miguel \\'Alvarez,\n  \\'Alvaro Arredondo, Alejandro Polvillo Hall, Javier P\\'erez Trufero, and\n  Javier de la Torre", "title": "Magnify Your Population: Statistical Downscaling to Augment the Spatial\n  Resolution of Socioeconomic Census Data", "comments": "14 pages, 5 figures, accepted at KDD Workshop on Humanitarian\n  Mapping, August 24, 2020 (https://kdd-humanitarian-mapping.herokuapp.com/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fine resolution estimates of demographic and socioeconomic attributes are\ncrucial for planning and policy development. While several efforts have been\nmade to produce fine-scale gridded population estimates, socioeconomic features\nare typically not available at scales finer than Census units, which may hide\nlocal heterogeneity and disparity. In this paper we present a new statistical\ndownscaling approach to derive fine-scale estimates of key socioeconomic\nattributes. The method leverages demographic and geographical extensive\ncovariates available at multiple scales and additional Census covariates only\navailable at coarse resolution, which are included in the model hierarchically\nwithin a \"forward learning\" approach. For each selected socioeconomic variable,\na Random Forest model is trained on the source Census units and then used to\ngenerate fine-scale gridded predictions, which are then adjusted to ensure the\nbest possible consistency with the coarser Census data. As a case study, we\napply this method to Census data in the United States, downscaling the selected\nsocioeconomic variables available at the block group level, to a grid of ~300\nspatial resolution. The accuracy of the method is assessed at both spatial\nscales, first computing a pseudo cross-validation coefficient of determination\nfor the predictions at the block group level and then, for extensive variables\nonly, also for the (unadjusted) predicted counts summed by block group. Based\non these scores and on the inspection of the downscaled maps, we conclude that\nour method is able to provide accurate, smoother, and more detailed\nsocioeconomic estimates than the available Census data.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 16:52:18 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Carella", "Giulia", ""], ["Eschbacher", "Andy", ""], ["Fan", "Dongjie", ""], ["\u00c1lvarez", "Miguel", ""], ["Arredondo", "\u00c1lvaro", ""], ["Hall", "Alejandro Polvillo", ""], ["Trufero", "Javier P\u00e9rez", ""], ["de la Torre", "Javier", ""]]}, {"id": "2006.13257", "submitter": "Shen Wang", "authors": "Shen Wang, Jibing Gong, Jinlong Wang, Wenzheng Feng, Hao Peng, Jie\n  Tang, Philip S. Yu", "title": "Attentional Graph Convolutional Networks for Knowledge Concept\n  Recommendation in MOOCs in a Heterogeneous View", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive open online courses are becoming a modish way for education, which\nprovides a large-scale and open-access learning opportunity for students to\ngrasp the knowledge. To attract students' interest, the recommendation system\nis applied by MOOCs providers to recommend courses to students. However, as a\ncourse usually consists of a number of video lectures, with each one covering\nsome specific knowledge concepts, directly recommending courses overlook\nstudents'interest to some specific knowledge concepts. To fill this gap, in\nthis paper, we study the problem of knowledge concept recommendation. We\npropose an end-to-end graph neural network-based approach\ncalledAttentionalHeterogeneous Graph Convolutional Deep Knowledge\nRecommender(ACKRec) for knowledge concept recommendation in MOOCs. Like other\nrecommendation problems, it suffers from sparsity issues. To address this\nissue, we leverage both content information and context information to learn\nthe representation of entities via graph convolution network. In addition to\nstudents and knowledge concepts, we consider other types of entities (e.g.,\ncourses, videos, teachers) and construct a heterogeneous information network to\ncapture the corresponding fruitful semantic relationships among different types\nof entities and incorporate them into the representation learning process.\nSpecifically, we use meta-path on the HIN to guide the propagation of students'\npreferences. With the help of these meta-paths, the students' preference\ndistribution with respect to a candidate knowledge concept can be captured.\nFurthermore, we propose an attention mechanism to adaptively fuse the context\ninformation from different meta-paths, in order to capture the different\ninterests of different students. The promising experiment results show that the\nproposedACKRecis able to effectively recommend knowledge concepts to students\npursuing online learning in MOOCs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 18:28:08 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Wang", "Shen", ""], ["Gong", "Jibing", ""], ["Wang", "Jinlong", ""], ["Feng", "Wenzheng", ""], ["Peng", "Hao", ""], ["Tang", "Jie", ""], ["Yu", "Philip S.", ""]]}, {"id": "2006.13259", "submitter": "Lana Yarosh", "authors": "Lana Yarosh, Suzanne Bakken, Alan Borning, Munmun De Choudhury, Cliff\n  Lampe, Elizabeth Mynatt, Stephen Schueller, and Tiffany Veinot", "title": "Computational Support for Substance Use Disorder Prevention, Detection,\n  Treatment, and Recovery", "comments": "A Computing Community Consortium (CCC) workshop report, 28 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020report_3", "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substance Use Disorders (SUDs) involve the misuse of any or several of a wide\narray of substances, such as alcohol, opioids, marijuana, and methamphetamine.\nSUDs are characterized by an inability to decrease use despite severe social,\neconomic, and health-related consequences to the individual. A 2017 national\nsurvey identified that 1 in 12 US adults have or have had a substance use\ndisorder. The National Institute on Drug Abuse estimates that SUDs relating to\nalcohol, prescription opioids, and illicit drug use cost the United States over\n$520 billion annually due to crime, lost work productivity, and health care\nexpenses. Most recently, the US Department of Health and Human Services has\ndeclared the national opioid crisis a public health emergency to address the\ngrowing number of opioid overdose deaths in the United States. In this\ninterdisciplinary workshop, we explored how computational support - digital\nsystems, algorithms, and sociotechnical approaches (which consider how\ntechnology and people interact as complex systems) - may enhance and enable\ninnovative interventions for prevention, detection, treatment, and long-term\nrecovery from SUDs.\n  The Computing Community Consortium (CCC) sponsored a two-day workshop titled\n\"Computational Support for Substance Use Disorder Prevention, Detection,\nTreatment, and Recovery\" on November 14-15, 2019 in Washington, DC. As outcomes\nfrom this visioning process, we identified three broad opportunity areas for\ncomputational support in the SUD context:\n  1. Detecting and mitigating risk of SUD relapse, 2. Establishing and\nempowering social support networks, and 3. Collecting and sharing data\nmeaningfully across ecologies of formal and informal care.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 18:30:20 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Yarosh", "Lana", ""], ["Bakken", "Suzanne", ""], ["Borning", "Alan", ""], ["De Choudhury", "Munmun", ""], ["Lampe", "Cliff", ""], ["Mynatt", "Elizabeth", ""], ["Schueller", "Stephen", ""], ["Veinot", "Tiffany", ""]]}, {"id": "2006.13277", "submitter": "Yujie Hu", "authors": "Fahui Wang, Yujie Hu, Shuai Wang, Xiaojuan Li", "title": "Local Indicator of Colocation Quotient with a Statistical Significance\n  Test: Examining Spatial Association of Crime and Facilities", "comments": null, "journal-ref": "The Professional Geographer, 69(1), 22-31 (2017)", "doi": "10.1080/00330124.2016.1157498", "report-no": null, "categories": "stat.AP cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most existing point-based colocation methods are global measures (e.g., join\ncount statistic, cross K function, and global colocation quotient). Most\nrecently, a local indicator such as the local colocation quotient is proposed\nto capture the variability of colocation across areas. Our research advances\nthis line of work by developing a simulation-based statistic test for the local\nindicator of colocation quotient (LCLQ). The study applies the indicator to\nexamine the association of land use facilities with crime patterns. Moreover,\nwe use the street network distance in addition to the traditional Euclidean\ndistance in defining neighbors since human activities (including facilities and\ncrimes) usually occur along a street network. The method is applied to analyze\nthe colocation of three types of crimes and three categories of facilities in a\ncity in Jiangsu Province, China. The findings demonstrate the value of the\nproposed method in colocation analysis of crime and facilities, and in general\ncolocation analysis of point data.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 14:05:41 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Wang", "Fahui", ""], ["Hu", "Yujie", ""], ["Wang", "Shuai", ""], ["Li", "Xiaojuan", ""]]}, {"id": "2006.13354", "submitter": "Muhammad Ajmal Azad Dr", "authors": "Muhammad Ajmal Azad, Junaid Arshad, Ali Akmal, Farhan Riaz, Sidrah\n  Abdullah, Muhammad Imran, and Farhan Ahmad", "title": "A First Look at Privacy Analysis of COVID-19 Contact Tracing Mobile\n  Applications", "comments": "submitted to IEEE IOT JOurnal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's smartphones are equipped with a large number of powerful value-added\nsensors and features such as a low power Bluetooth sensor, powerful embedded\nsensors such as the digital compass, accelerometer, GPS sensors, Wi-Fi\ncapabilities, microphone, humidity sensors, health tracking sensors, and a\ncamera, etc. These value-added sensors have revolutionized the lives of the\nhuman being in many ways such, as tracking the health of the patients and\nmovement of doctors, tracking employees movement in large manufacturing units,\nand monitoring the environment, etc. These embedded sensors could also be used\nfor large-scale personal, group, and community sensing applications especially\ntracing the spread of certain diseases. Governments and regulators are turning\nto use these features to trace the people thought to have symptoms of certain\ndiseases or virus e.g. COVID-19. The outbreak of COVID-19 in December 2019, has\nseen a surge of the mobile applications for tracing, tracking and isolating the\npersons showing COVID-19 symptoms to limit the spread of disease to the larger\ncommunity. The use of embedded sensors could disclose private information of\nthe users thus potentially bring threat to the privacy and security of users.\nIn this paper, we analyzed a large set of smartphone applications that have\nbeen designed to contain the spread of the COVID-19 virus and bring the people\nback to normal life. Specifically, we have analyzed what type of permission\nthese smartphone apps require, whether these permissions are necessary for the\ntrack and trace, how data from the user devices is transported to the analytic\ncenter, and analyzing the security measures these apps have deployed to ensure\nthe privacy and security of users.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 21:57:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 14:16:08 GMT"}, {"version": "v3", "created": "Sun, 16 Aug 2020 09:09:56 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Azad", "Muhammad Ajmal", ""], ["Arshad", "Junaid", ""], ["Akmal", "Ali", ""], ["Riaz", "Farhan", ""], ["Abdullah", "Sidrah", ""], ["Imran", "Muhammad", ""], ["Ahmad", "Farhan", ""]]}, {"id": "2006.13427", "submitter": "Lichin Chen", "authors": "Lichin Chen, Yu Tsao, Ji-Tian Sheu", "title": "Using Deep Learning and Explainable Artificial Intelligence in Patients'\n  Choices of Hospital Levels", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In countries that enabled patients to choose their own providers, a common\nproblem is that the patients did not make rational decisions, and hence, fail\nto use healthcare resources efficiently. This might cause problems such as\noverwhelming tertiary facilities with mild condition patients, thus limiting\ntheir capacity of treating acute and critical patients. To address such\nmaldistributed patient volume, it is essential to oversee patients choices\nbefore further evaluation of a policy or resource allocation. This study used\nnationwide insurance data, accumulated possible features discussed in existing\nliterature, and used a deep neural network to predict the patients choices of\nhospital levels. This study also used explainable artificial intelligence\nmethods to interpret the contribution of features for the general public and\nindividuals. In addition, we explored the effectiveness of changing data\nrepresentations. The results showed that the model was able to predict with\nhigh area under the receiver operating characteristics curve (AUC) (0.90),\naccuracy (0.90), sensitivity (0.94), and specificity (0.97) with highly\nimbalanced label. Generally, social approval of the provider by the general\npublic (positive or negative) and the number of practicing physicians serving\nper ten thousand people of the located area are listed as the top effecting\nfeatures. The changing data representation had a positive effect on the\nprediction improvement. Deep learning methods can process highly imbalanced\ndata and achieve high accuracy. The effecting features affect the general\npublic and individuals differently. Addressing the sparsity and discrete nature\nof insurance data leads to better prediction. Applications using deep learning\ntechnology are promising in health policy making. More work is required to\ninterpret models and practice implementation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 02:15:15 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chen", "Lichin", ""], ["Tsao", "Yu", ""], ["Sheu", "Ji-Tian", ""]]}, {"id": "2006.13438", "submitter": "Diego Chialva", "authors": "Diego Chialva, Alexis-Michel Mugabushaka", "title": "DINGO: an ontology for projects and grants linked data", "comments": "Accepted for the SKG2020 Workshop co-located with TPDL 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DINGO (Data INtegration for Grants Ontology), an ontology that\nprovides a machine readable extensible framework to model data for\nsemantically-enabled applications relative to projects, funding, actors, and,\nnotably, funding policies in the research landscape. DINGO is designed to yield\nhigh modeling power and elasticity to cope with the huge variety in funding,\nresearch and policy practices, which makes it applicable also to other areas\nbesides research where funding is an important aspect. We discuss its main\nfeatures, the principles followed for its development, its community uptake,\nits maintenance and evolution.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 02:47:40 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Chialva", "Diego", ""], ["Mugabushaka", "Alexis-Michel", ""]]}, {"id": "2006.13699", "submitter": "Vitalii Emelianov", "authors": "Vitalii Emelianov, Nicolas Gast, Krishna P. Gummadi and Patrick\n  Loiseau", "title": "On Fair Selection in the Presence of Implicit Variance", "comments": "27 pages, 10 figures, Economics and Computation (EC'20)", "journal-ref": null, "doi": "10.1145/3391403.3399482", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quota-based fairness mechanisms like the so-called Rooney rule or four-fifths\nrule are used in selection problems such as hiring or college admission to\nreduce inequalities based on sensitive demographic attributes. These mechanisms\nare often viewed as introducing a trade-off between selection fairness and\nutility. In recent work, however, Kleinberg and Raghavan showed that, in the\npresence of implicit bias in estimating candidates' quality, the Rooney rule\ncan increase the utility of the selection process.\n  We argue that even in the absence of implicit bias, the estimates of\ncandidates' quality from different groups may differ in another fundamental\nway, namely, in their variance. We term this phenomenon implicit variance and\nwe ask: can fairness mechanisms be beneficial to the utility of a selection\nprocess in the presence of implicit variance (even in the absence of implicit\nbias)? To answer this question, we propose a simple model in which candidates\nhave a true latent quality that is drawn from a group-independent normal\ndistribution. To make the selection, a decision maker receives an unbiased\nestimate of the quality of each candidate, with normal noise, but whose\nvariance depends on the candidate's group. We then compare the utility obtained\nby imposing a fairness mechanism that we term $\\gamma$-rule (it includes\ndemographic parity and the four-fifths rule as special cases), to that of a\ngroup-oblivious selection algorithm that picks the candidates with the highest\nestimated quality independently of their group. Our main result shows that the\ndemographic parity mechanism always increases the selection utility, while any\n$\\gamma$-rule weakly increases it. We extend our model to a two-stage selection\nprocess where the true quality is observed at the second stage. We discuss\nmultiple extensions of our results, in particular to different distributions of\nthe true latent quality.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 13:08:31 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Emelianov", "Vitalii", ""], ["Gast", "Nicolas", ""], ["Gummadi", "Krishna P.", ""], ["Loiseau", "Patrick", ""]]}, {"id": "2006.13721", "submitter": "Carsten Eickhoff", "authors": "Cindy Li, Elizabeth Chen, Guergana Savova, Hamish Fraser, Carsten\n  Eickhoff", "title": "Mining Misdiagnosis Patterns from Biomedical Literature", "comments": "AMIA Joint Summits in Translational Science, 2020", "journal-ref": "AMIA Jt Summits Transl Sci Proc. 2020;2020:360-366. Published 2020\n  May 30", "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnostic errors can pose a serious threat to patient safety, leading to\nserious harm and even death. Efforts are being made to develop interventions\nthat allow physicians to reassess for errors and improve diagnostic accuracy.\nOur study presents an exploration of misdiagnosis patterns mined from PubMed\nabstracts. Article titles containing certain phrases indicating misdiagnosis\nwere selected and frequencies of these misdiagnoses calculated. We present the\nresulting patterns in the form of a directed graph with frequency-weighted\nmisdiagnosis edges connecting diagnosis vertices. We find that the most\ncommonly misdiagnosed diseases were often misdiagnosed as many different\ndiseases, with each misdiagnosis having a relatively low frequency, rather than\nas a single disease with greater probability. Additionally, while a\nmisdiagnosis relationship may generally exist, the relationship was often found\nto be one-sided.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 13:34:43 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Li", "Cindy", ""], ["Chen", "Elizabeth", ""], ["Savova", "Guergana", ""], ["Fraser", "Hamish", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2006.13808", "submitter": "Viraj Kulkarni", "authors": "Amit Kharat, Vinay Duddalwar, Krishna Saoji, Ashrika Gaikwad, Viraj\n  Kulkarni, Gunjan Naik, Rohit Lokwani, Swaraj Kasliwal, Sudeep Kondal, Tanveer\n  Gupte, Aniruddha Pant", "title": "Role of Edge Device and Cloud Machine Learning in Point-of-Care\n  Solutions Using Imaging Diagnostics for Population Screening", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge devices are revolutionizing diagnostics. Edge devices can reside within\nor adjacent to imaging tools such as digital Xray, CT, MRI, or ultrasound\nequipment. These devices are either CPUs or GPUs with advanced processing deep\nand machine learning (artificial intelligence) algorithms that assist in\nclassification and triage solutions to flag studies as either normal or\nabnormal, TB or healthy (in case of TB screening), suspected COVID-19/other\npneumonia or unremarkable (in hospital or hotspot settings). These can be\ndeployed as screening point-of-care (PoC) solutions; this is particularly true\nfor digital and portable X-ray devices. Edge device learning can also be used\nfor mammography and CT studies where it can identify microcalcification and\nstroke, respectively. These solutions can be considered the first line of\npre-screening before the imaging specialist actually reviews scans and makes a\nfinal diagnosis. The key advantage of these tools is that they are instant, can\nbe deployed remotely where experts are not available to perform pre-screening\nbefore the experts actually review, and are not limited by internet bandwidth\nas the nano learning data centers are placed next to the device.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 08:58:14 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Kharat", "Amit", ""], ["Duddalwar", "Vinay", ""], ["Saoji", "Krishna", ""], ["Gaikwad", "Ashrika", ""], ["Kulkarni", "Viraj", ""], ["Naik", "Gunjan", ""], ["Lokwani", "Rohit", ""], ["Kasliwal", "Swaraj", ""], ["Kondal", "Sudeep", ""], ["Gupte", "Tanveer", ""], ["Pant", "Aniruddha", ""]]}, {"id": "2006.13831", "submitter": "Bedir Tekinerdogan", "authors": "Claudia Ayim, Ayalew Kassahun, Bedir Tekinerdogan, Chris Addison", "title": "Adoption of ICT innovations in the agriculture sector in Africa: A\n  Systematic Literature Review", "comments": "18 pages, 5 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the latest World Economic Forum report, about 70% of the African\npopulation depends on agriculture for their livelihood. This makes agriculture\na critical sector within the African continent. Nonetheless, agricultural\nproductivity is low and food insecurity is still a challenge. This has in\nrecent years led to several initiatives in using ICT (Information Communication\nTechnology) to improve agriculture productivity. This study aims to explore ICT\ninnovations in the agriculture sector of Africa. To achieve this, we conducted\na SLR (Systematic Literature Review) of the literature published since 2010.\nOur search yielded 779 papers, of which 23 papers were selected for a detailed\nanalysis following a detailed exclusion and quality assessment criteria. The\nanalysis of the selected papers shows that the main ICT technologies adopted\nare text and voice-based services targeting mobile phones. The analysis also\nshows that radios are still widely used in disseminating agriculture\ninformation to rural farmers, while computers are mainly used by researchers.\nThough the mobile-based services aimed at improving access to accurate and\ntimely agriculture information, the literature reviews indicate that the\nadoption of the services is constrained by poor technological infrastructure,\ninappropriate ICT policies and low capacity levels of users, especially\nfarmers, to using the technologies. The findings further indicate that\nliterature on an appropriate theoretical framework for guiding ICT innovations\nis lacking.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 16:03:27 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ayim", "Claudia", ""], ["Kassahun", "Ayalew", ""], ["Tekinerdogan", "Bedir", ""], ["Addison", "Chris", ""]]}, {"id": "2006.13893", "submitter": "Oluwasegun Adedugbe", "authors": "Oluwasegun Adedugbe, Elhadj Benkhelifa and Anoud Bani-Hani", "title": "A Cloud Computing Capability Model for Large-Scale Semantic Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic technologies are designed to facilitate context-awareness for web\ncontent, enabling machines to understand and process them. However, this has\nbeen faced with several challenges, such as disparate nature of existing\nsolutions and lack of scalability in proportion to web scale. With a holistic\nperspective to web content semantic annotation, this paper focuses on\nleveraging cloud computing for these challenges. To achieve this, a set of\nrequirements towards holistic semantic annotation on the web is defined and\nmapped with cloud computing mechanisms to facilitate them. Technical\nspecification for the requirements is critically reviewed and examined against\neach of the cloud computing mechanisms, in relation to their technical\nfunctionalities. Hence, a mapping is established if the cloud computing\nmechanism's functionalities proffer a solution for implementation of a\nrequirement's technical specification. The result is a cloud computing\ncapability model for holistic semantic annotation which presents an approach\ntowards delivering large scale semantic annotation on the web via a cloud\nplatform.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:23:06 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 14:02:05 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Adedugbe", "Oluwasegun", ""], ["Benkhelifa", "Elhadj", ""], ["Bani-Hani", "Anoud", ""]]}, {"id": "2006.13898", "submitter": "Yefim Shulman", "authors": "Yefim Shulman, Thao Ngo, Joachim Meyer", "title": "Order of Control and Perceived Control over Personal Information", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-42504-3_23", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focusing on personal information disclosure, we apply control theory and the\nnotion of the Order of Control to study people's understanding of the\nimplications of information disclosure and their tendency to consent to\ndisclosure. We analyzed the relevant literature and conducted a preliminary\nonline study (N = 220) to explore the relationship between the Order of Control\nand perceived control over personal information. Our analysis of existing\nresearch suggests that the notion of the Order of Control can help us\nunderstand people's decisions regarding the control over their personal\ninformation. We discuss limitations and future directions for research\nregarding the application of the idea of the Order of Control to online\nprivacy.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:34:12 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Shulman", "Yefim", ""], ["Ngo", "Thao", ""], ["Meyer", "Joachim", ""]]}, {"id": "2006.13920", "submitter": "Hsun Lee", "authors": "Hsun Lee, Hsu-Chun Hsiao", "title": "Practical and Verifiable Electronic Sortition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing verifiable e-sortition systems are impractical due to\ncomputationally expensive verification (linear to the duration of the\nregistration phase, T) or the ease of being denial of service. Based on the\nadvance in verifiable delay functions, we propose a verifiable e-sortition\nscheme whose result can be efficiently verified in constant time with respect\nto T. We present the preliminary design and implementation, and explore future\ndirections to further enhance practicability.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:49:21 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Lee", "Hsun", ""], ["Hsiao", "Hsu-Chun", ""]]}, {"id": "2006.13924", "submitter": "Amanda Stathopoulos", "authors": "J Soria, Y Chen, A Stathopoulos", "title": "K-Prototype Segmentation Analysis on Large-scale Ridesourcing Trip Data", "comments": null, "journal-ref": "Transportation Research Record, 2020", "doi": "10.1177/0361198120929338", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared mobility-on-demand services are expanding rapidly in cities around the\nworld. As a prominent example, app-based ridesourcing is becoming an integral\npart of many urban transportation ecosystems. Despite the centrality, limited\npublic availability of detailed temporal and spatial data on ridesourcing trips\nhas limited research on how new services interact with traditional mobility\noptions and how they impact travel in cities. Improving data-sharing agreements\nare opening unprecedented opportunities for research in this area. This study\nexamines emerging patterns of mobility using recently released City of Chicago\npublic ridesourcing data. The detailed spatio-temporal ridesourcing data are\nmatched with weather, transit, and taxi data to gain a deeper understanding of\nridesourcings role in Chicagos mobility system. The goal is to investigate the\nsystematic variations in patronage of ride-hailing. K-prototypes is utilized to\ndetect user segments owing to its ability to accept mixed variable data types.\nAn extension of the K-means algorithm, its output is a classification of the\ndata into several clusters called prototypes. Six ridesourcing prototypes are\nidentified and discussed based on significant differences in relation to\nadverse weather conditions, competition with alternative modes, location and\ntiming of use, and tendency for ridesplitting. The paper discusses implications\nof the identified clusters related to affordability, equity and competition\nwith transit.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:53:26 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Soria", "J", ""], ["Chen", "Y", ""], ["Stathopoulos", "A", ""]]}, {"id": "2006.14074", "submitter": "Abdul Ahad Abro", "authors": "Abdul Ahad Abro, Ufaque Shaikh", "title": "Design And Develop Network Storage Virtualization By Using GNS3", "comments": "Journal of Information & Communication Technology - JICT Vol. 13\n  Issue. 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CY cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization is an emerging and optimistic prospect in the IT industry. Its\nimpact has a footprint widely in digital infrastructure. Many innovativeness\nsectors utilized the concept of virtualization to reduce the cost of\nframeworks. In this paper, we have designed and developed storage\nvirtualization for physical functional solutions. It is an auspicious type of\nvirtualization that is accessible, secure, scalable, and manageable. In the\npaper, we have proposed the pool storage method used the RAID-Z file system\nwith the ZFS model which provides the duplication of site approach, compression\nblueprint, adequate backup methods, expansion in error-correcting techniques,\nand tested procedure on the real-time network location. Therefore, this study\nprovides useful guidelines to design and develop optimized storage\nvirtualization.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 22:15:11 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Abro", "Abdul Ahad", ""], ["Shaikh", "Ufaque", ""]]}, {"id": "2006.14109", "submitter": "Nikolay Laptev", "authors": "Paulo Tanaka, Sameet Sapra, Nikolay Laptev", "title": "Scalable Data Classification for Security and Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content based data classification is an open challenge. Traditional Data Loss\nPrevention (DLP)-like systems solve this problem by fingerprinting the data in\nquestion and monitoring endpoints for the fingerprinted data. With a large\nnumber of constantly changing data assets in Facebook, this approach is both\nnot scalable and ineffective in discovering what data is where. This paper is\nabout an end-to-end system built to detect sensitive semantic types within\nFacebook at scale and enforce data retention and access controls automatically.\n  The approach described here is our first end-to-end privacy system that\nattempts to solve this problem by incorporating data signals, machine learning,\nand traditional fingerprinting techniques to map out and classify all data\nwithin Facebook. The described system is in production achieving a 0.9+ average\nF2 scores across various privacy classes while handling a large number of data\nassets across dozens of data stores.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 00:19:34 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 22:44:47 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 16:28:04 GMT"}, {"version": "v4", "created": "Wed, 1 Jul 2020 19:40:55 GMT"}, {"version": "v5", "created": "Mon, 6 Jul 2020 20:03:21 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Tanaka", "Paulo", ""], ["Sapra", "Sameet", ""], ["Laptev", "Nikolay", ""]]}, {"id": "2006.14112", "submitter": "Eric Boria Ph.D.", "authors": "Eric Sergio Boria, Mohamed Badhrudeen, Guillemette Fonteix, Sybil\n  Derrible, Michael Siciliano", "title": "A Protocol to Convert Infrastructure Data from Computer-Aided Design\n  (CAD) to Geographic Information Systems (GIS)", "comments": "23 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  While many municipalities and organizations see value in converting\ninfrastructure data from Computer-Aided Design (CAD) to Geographic Information\nSystem (GIS) format, the process can be complex, expensive, and time-consuming.\nGiven that municipal employees often prefer to continue performing work in both\nCAD and GIS, depending on the type of work required, an improved conversion\nprocess would help municipalities more fully employ GIS-based analyses.\nMunicipalities facing budget and capacity challenges would especially benefit\nfrom an improved conversion process. With advances in GIS functionality and the\npromise of smart and connected cities, more emphasis is placed on the quality\nof data, and in this case, the potential loss of data quality from CAD to GIS\nformats. The goals of this article are twofold. First, to understand the common\npractices municipalities use to convert infrastructure CAD data to GIS and the\nspecific challenges they face. Second, based on knowledge of those practices\nand challenges, this article proposes a five-step process to reduce common\nconversion errors and reduce the time required to correct these errors. The\nprocess is illustrated through the conversion of CAD data from the University\nof Illinois at Chicago (UIC) campus. The findings were validated with\nqualitative, semi-structured interviews conducted with GIS Analysts and\nManagers working in eleven municipalities across the United States who directly\nmanage at least one of the following infrastructures: water, sanitary sewer, or\nstormwater sewer systems. The interviews confirmed the challenges\nmunicipalities faced with the conversion and identified solutions interviewees\nundertook to enable data-informed decision-making.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 00:25:02 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Boria", "Eric Sergio", ""], ["Badhrudeen", "Mohamed", ""], ["Fonteix", "Guillemette", ""], ["Derrible", "Sybil", ""], ["Siciliano", "Michael", ""]]}, {"id": "2006.14235", "submitter": "Aetienne Sardon", "authors": "David Sturzenegger, Aetienne Sardon, Stefan Deml, Thomas Hardjono", "title": "Confidential Computing for Privacy-Preserving Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is paramount to fighting the pandemic but it comes with\nlegitimate privacy concerns. This paper proposes a system enabling both,\ncontact tracing and data privacy.\n  We propose the use of the Intel SGX trusted execution environment to build a\nprivacy-preserving contact tracing backend. While the concept of a confidential\ncomputing backend proposed in this paper can be combined with any existing\ncontact tracing smartphone application, we describe a full contact tracing\nsystem for demonstration purposes.\n  A prototype of a privacy-preserving contact tracing system based on SGX has\nbeen implemented by the authors in a hackathon.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 08:06:23 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Sturzenegger", "David", ""], ["Sardon", "Aetienne", ""], ["Deml", "Stefan", ""], ["Hardjono", "Thomas", ""]]}, {"id": "2006.14245", "submitter": "Noe Elisa Nnko", "authors": "Noe Elisa", "title": "Usability, Accessibility and Web Security Assessment of E-government\n  Websites in Tanzania", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the fact that e-government agency (ega) in Tanzania emphasize on\nthe use of ICT within public institutions in Tanzania, accessibility, usability\nand web security vulnerabilities are still not considered by the majority of\nweb developers. The main objective of this study is to assess the usability,\naccessibility and web security vulnerabilities of selected Tanzania\ne-government websites. Using several automatic diagnostic (evaluation) tools\nsuch as pingdom, google speed insight, wave, w3c checker and acunetix, this\nstudy assess the usability, accessibility and web security vulnerabilities of\n79 selected e-government websites in Tanzania. The results reveal several\nissues on usability, accessibility and security of Tanzania e-government\nwebsites. There is high number of usability problems where 100% of websites\nwere found to have broken links and 52 out of 79 websites have loading time of\nmore than five (5) seconds for their main page. The accessibility results show\nthat all 79 selected websites have accessibility errors and violate w3c Web\nContent Accessibility Guidelines (WCAG) 1.0. The results on web security\nvulnerabilities indicate that 40 out of 79 (50.6%) assessed websites have one\nor more high-severity vulnerability (SQL injection or cross site scripting-XSS)\nwhile 51 out of 79 (64.5%) have one or more medium-severity vulnerabilities\n(Cross site request forgery or Denial of Service). Based on these results, this\nstudy provides some recommendations for improving the usability, accessibility\nand web security vulnerabilities of public institutions in Tanzania.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 08:23:45 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Elisa", "Noe", ""]]}, {"id": "2006.14329", "submitter": "David Butler", "authors": "David Butler, Chris Hicks, James Bell, Carsten Maple, Jon Crowcroft", "title": "Differentially Private Health Tokens for Estimating COVID-19 Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the fight against Covid-19, many governments and businesses are in the\nprocess of evaluating, trialling and even implementing so-called immunity\npassports. Also known as antibody or health certificates, there is a clear\ndemand for any technology that could allow people to return to work and other\ncrowded places without placing others at risk. One of the major criticisms of\nsuch systems is that they could be misused to unfairly discriminate against\nthose without immunity, allowing the formation of an `immuno-privileged' class\nof people. In this work we are motivated to explore an alternative technical\nsolution that is non-discriminatory by design. In particular we propose health\ntokens -- randomised health certificates which, using methods from differential\nprivacy, allow individual test results to be randomised whilst still allowing\nuseful aggregate risk estimates to be calculated. We show that health tokens\ncould mitigate immunity-based discrimination whilst still presenting a viable\nmechanism for estimating the collective transmission risk posed by small groups\nof users. We evaluate the viability of our approach in the context of\nidentity-free and identity-binding use cases and then consider a number of\npossible attacks. Our experimental results show that for groups of size 500 or\nmore, the error associated with our method can be as low as 0.03 on average and\nthus the aggregated results can be useful in a number of identity-free\ncontexts. Finally, we present the results of our open-source prototype which\ndemonstrates the practicality of our solution.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 12:02:16 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:09:01 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Butler", "David", ""], ["Hicks", "Chris", ""], ["Bell", "James", ""], ["Maple", "Carsten", ""], ["Crowcroft", "Jon", ""]]}, {"id": "2006.14407", "submitter": "Mansoor Ahmed-Rengers", "authors": "Mansoor Ahmed-Rengers, Ross Anderson, Darija Halatova, Ilia Shumailov", "title": "Snitches Get Stitches: On The Difficulty of Whistleblowing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.GT cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most critical security protocol problems for humans is when you\nare betraying a trust, perhaps for some higher purpose, and the world can turn\nagainst you if you're caught. In this short paper, we report on efforts to\nenable whistleblowers to leak sensitive documents to journalists more safely.\nFollowing a survey of cases where whistleblowers were discovered due to\noperational or technological issues, we propose a game-theoretic model\ncapturing the power dynamics involved in whistleblowing. We find that the\nwhistleblower is often at the mercy of motivations and abilities of others. We\nidentify specific areas where technology may be used to mitigate the\nwhistleblower's risk. However we warn against technical solutionism: the main\nconstraints are often institutional.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 13:46:04 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Ahmed-Rengers", "Mansoor", ""], ["Anderson", "Ross", ""], ["Halatova", "Darija", ""], ["Shumailov", "Ilia", ""]]}, {"id": "2006.14476", "submitter": "Alberto Sim\\~oes", "authors": "Alberto Sim\\~oes and Ricardo Queir\\'os", "title": "On the Nature of Programming Exercises", "comments": null, "journal-ref": null, "doi": "10.4230/OASIcs.ICPEC.2020.24", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There are countless reasons cited in scientific studies to explain the\ndifficulties in programming learning. The reasons range from the subject's\ncomplexity, the ineffective teaching and study methods, to psychological\naspects such as demotivation. Still, learning programming often boils down to\npractice on exercise solving. Hence, it is essential to understand that the\nnature of a programming exercise is an important factor for the success and\nconsistent learning.\n  This paper explores different approaches on the creation of a programming\nexercise, starting with realizing how it is currently formalized, presented and\nevaluated. From there, authors suggest variations that seek to broaden the way\nan exercise is solved and, with this diversity, increase student engagement and\nlearning outcome. The several types of exercises presented can use gamification\ntechniques fostering student motivation. To contextualize the student with his\npeers, we finish presenting metrics that can be obtained by existing automatic\nassessment tools.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 15:22:26 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Sim\u00f5es", "Alberto", ""], ["Queir\u00f3s", "Ricardo", ""]]}, {"id": "2006.14479", "submitter": "Martim Brand\\~ao", "authors": "Martim Brandao", "title": "Fair navigation planning: a humanitarian robot use case", "comments": "Appeared at the KDD 2020 Workshop on Humanitarian Mapping", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate potential issues of fairness related to the\nmotion of mobile robots. We focus on the particular use case of humanitarian\nmapping and disaster response. We start by showing that there is a fairness\ndimension to robot navigation, and use a walkthrough example to bring out\ndesign choices and issues that arise during the development of a fair system.\nWe discuss indirect discrimination, fairness-efficiency trade-offs, the\nexistence of counter-productive fairness definitions, privacy and other issues.\nFinally, we conclude with a discussion of the potential of our methodology as a\nconcrete responsible innovation tool for eliciting ethical issues in the design\nof autonomous systems.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 15:23:15 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Brandao", "Martim", ""]]}, {"id": "2006.14490", "submitter": "Dami\\'an Silvani", "authors": "Federico Bayle and Damian E. Silvani", "title": "Case study: Mapping potential informal settlements areas in Tegucigalpa\n  with machine learning to plan ground survey", "comments": "4 pages, 2 figures, submitted to ACM SIGKDD 2020 Conference on\n  Knowledge Discovery and Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Data collection through censuses is conducted every 10 years on average in\nLatin America, making it difficult to monitor the growth and support needed by\ncommunities living in these settlements. Conducting a field survey requires\nlogistical resources to be able to do it exhaustively. The increasing\navailability of open data, high-resolution satellite images, and free software\nto process them allow us to be able to do so in a scalable way based on the\nanalysis of these sources of information. This case study shows the\ncollaboration between Dymaxion Labs and the NGO Techo to employ machine\nlearning techniques to create the first informal settlements census of\nTegucigalpa, Honduras.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 15:38:04 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Bayle", "Federico", ""], ["Silvani", "Damian E.", ""]]}, {"id": "2006.14518", "submitter": "Joseph Chow", "authors": "Theodoros P. Pantelidis, Joseph Y. J. Chow, Oded Cats", "title": "Mobility operator fleet-sharing contract design to risk-pool against\n  network disruptions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a new mechanism to design risk-pooling contracts between operators\nto facilitate horizontal cooperation to mitigate those costs and improve\nservice resilience during disruptions. We formulate a novel two-stage\nstochastic multicommodity flow model to determine the cost savings of a\ncoalition under different disruption scenarios and solve it using L-shaped\nmethod along with sample average approximation. Computational tests of the\nL-shaped method against deterministic equivalent method with sample average\napproximation are conducted for network instances with up to 64 nodes, 13 OD\npairs, and 8192 scenarios, the largest tests of its kind in the recent\nstochastic multicommodity flow optimization literature. The results demonstrate\nthat the solution algorithm only becomes computationally effective for larger\nsize instances and that SAA with 500 sample size can maintain a close\napproximation. The proposed model is applied to a regional multimodal network\nin the Randstad area of the Netherlands, for four operators, 80\norigin-destination pairs, and over 1400 links where disruption data is\navailable. Using the proposed method, we identify stable cost allocations among\nfour operating agencies that could yield a 44% improvement in overall network\nperformance over not having any risk-pooling contract in place. Furthermore,\nthe model allows policymakers to evaluate the sensitivity of any one operator's\nbargaining power to different network structures and disruption scenario\ndistributions, as we illustrate for the HTM operator in Randstad.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 16:10:02 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 14:50:11 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Pantelidis", "Theodoros P.", ""], ["Chow", "Joseph Y. J.", ""], ["Cats", "Oded", ""]]}, {"id": "2006.14528", "submitter": "Ellis Solaiman", "authors": "B. Awaji, E. Solaiman, A. Albshri", "title": "Blockchain-Based Applications in Higher Education: A Systematic Mapping\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The utilisation of blockchain has moved beyond digital currency to other\nfields such as health, the Internet of Things, and education. In this paper, we\npresent a systematic mapping study to collect and analyse relevant research on\nblockchain technology related to the higher education field. The paper\nconcentrates on two main themes. First, it examines state of the art in\nblockchain-based applications that have been developed for educational\npurposes. Second, it summarises the challenges and research gaps that need to\nbe addressed in future studies.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 16:24:28 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Awaji", "B.", ""], ["Solaiman", "E.", ""], ["Albshri", "A.", ""]]}, {"id": "2006.14662", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta (1 and 2), Camylle Lanteigne (1 and 3), Victoria Heath\n  (1 and 4), Marianna Bergamaschi Ganapini (1 and 5), Erick Galinkin (1 and 6),\n  Allison Cohen (1 and 7), Tania De Gasperis (1 and 8), Mo Akif (1 and 3),\n  Renjie Butalid (1) ((1) Montreal AI Ethics Institute, (2) Microsoft, (3)\n  McGill University, (4) Creative Commons, (5) Union College, (6) Rapid7, (7)\n  AI Global, (8) OCAD University)", "title": "The State of AI Ethics Report (June 2020)", "comments": "128 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  These past few months have been especially challenging, and the deployment of\ntechnology in ways hitherto untested at an unrivalled pace has left the\ninternet and technology watchers aghast. Artificial intelligence has become the\nbyword for technological progress and is being used in everything from helping\nus combat the COVID-19 pandemic to nudging our attention in different\ndirections as we all spend increasingly larger amounts of time online. It has\nnever been more important that we keep a sharp eye out on the development of\nthis field and how it is shaping our society and interactions with each other.\nWith this inaugural edition of the State of AI Ethics we hope to bring forward\nthe most important developments that caught our attention at the Montreal AI\nEthics Institute this past quarter. Our goal is to help you navigate this\never-evolving field swiftly and allow you and your organization to make\ninformed decisions. This pulse-check for the state of discourse, research, and\ndevelopment is geared towards researchers and practitioners alike who are\nmaking decisions on behalf of their organizations in considering the societal\nimpacts of AI-enabled solutions. We cover a wide set of areas in this report\nspanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and\nLabor, the Future of AI Ethics, and more. Our staff has worked tirelessly over\nthe past quarter surfacing signal from the noise so that you are equipped with\nthe right tools and knowledge to confidently tread this complex yet\nconsequential domain.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 19:00:41 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Gupta", "Abhishek", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"], ["Heath", "Victoria", "", "1 and 4"], ["Ganapini", "Marianna Bergamaschi", "", "1 and 5"], ["Galinkin", "Erick", "", "1 and 6"], ["Cohen", "Allison", "", "1 and 7"], ["De Gasperis", "Tania", "", "1 and 8"], ["Akif", "Mo", "", "1 and 3"], ["Butalid", "Renjie", ""]]}, {"id": "2006.14666", "submitter": "Pranav Sharma", "authors": "Pranav Sharma", "title": "LPar -- A Distributed Multi Agent platform for building Polyglot, Omni\n  Channel and Industrial grade Natural Language Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of serving and delighting customers in a personal and near human\nlike manner is very high on automation agendas of most Enterprises. Last few\nyears, have seen huge progress in Natural Language Processing domain which has\nled to deployments of conversational agents in many enterprises. Most of the\ncurrent industrial deployments tend to use Monolithic Single Agent designs that\nmodel the entire knowledge and skill of the Domain. While this approach is one\nof the fastest to market, the monolithic design makes it very hard to scale\nbeyond a point. There are also challenges in seamlessly leveraging many tools\noffered by sub fields of Natural Language Processing and Information Retrieval\nin a single solution. The sub fields that can be leveraged to provide relevant\ninformation are, Question and Answer system, Abstractive Summarization,\nSemantic Search, Knowledge Graph etc. Current deployments also tend to be very\ndependent on the underlying Conversational AI platform (open source or\ncommercial) , which is a challenge as this is a fast evolving space and no one\nplatform can be considered future proof even in medium term of 3-4 years.\nLately,there is also work done to build multi agent solutions that tend to\nleverage a concept of master agent. While this has shown promise, this approach\nstill makes the master agent in itself difficult to scale. To address these\nchallenges, we introduce LPar, a distributed multi agent platform for large\nscale industrial deployment of polyglot, diverse and inter-operable agents. The\nasynchronous design of LPar supports dynamically expandable domain. We also\nintroduce multiple strategies available in the LPar system to elect the most\nsuitable agent to service a customer query.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 19:20:07 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Sharma", "Pranav", ""]]}, {"id": "2006.14679", "submitter": "Basavesh Ammanaghatta Shivakumar", "authors": "Paul M. Berges, Basavesh Ammanaghatta Shivakumar, Timothy Graziano,\n  Ryan Gerdes and Z. Berkay Celik", "title": "On the Feasibility of Exploiting Traffic Collision Avoidance System\n  Vulnerabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic Collision Avoidance Systems (TCAS) are safety-critical systems\nrequired on most commercial aircrafts in service today. However, TCAS was not\ndesigned to account for malicious actors. While in the past it may have been\ninfeasible for an attacker to craft radio signals to mimic TCAS signals,\nattackers today have access to open-source digital signal processing software,\nlike GNU Radio, and inexpensive software defined radios (SDR) that enable the\ntransmission of spurious TCAS messages. In this paper, methods, both\nqualitative and quantitative, for analyzing TCAS from an adversarial\nperspective are presented. To demonstrate the feasibility of inducing near\nmid-air collisions between current day TCAS-equipped aircraft, an experimental\nPhantom Aircraft generator is developed using GNU Radio and an SDR against a\nrealistic threat model.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 20:03:17 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Berges", "Paul M.", ""], ["Shivakumar", "Basavesh Ammanaghatta", ""], ["Graziano", "Timothy", ""], ["Gerdes", "Ryan", ""], ["Celik", "Z. Berkay", ""]]}, {"id": "2006.14711", "submitter": "Gabriel Leit\\~ao", "authors": "Gabriel Leit\\~ao, Juan Colonna, Edwin Monteiro, Elaine Oliveira,\n  Raimundo Barreto", "title": "New Metrics for Learning Evaluation in Digital Education Platforms", "comments": "12 pages, 6 figures, 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology applied in education can provide great benefits and overcome\nchallenges by facilitating access to learning objects anywhere and anytime.\nHowever, technology alone is not enough, since it requires suitable planning\nand learning methodologies. Using technology can be problematic, especially in\ndetermining whether learning has occurred or not. Futhermore, if learning has\nnot occured, technology can make it difficult to determine how to mitigate this\nlack of learning. This paper presents a set of new metrics for measuring\nstudent's acquired understanding of a content in technology-based education\nplatforms. Some metrics were taken from the literature \"as is\", some were\nmodified slighty, while others were added. The hypothesis is that we should not\nonly focus on traditional scoring, because it only counts the number of\nhits/errors and does not consider any other aspect of learning. We applied all\nmetrics to an assessment conducted in a high school class in which we show\nspecific cases, along with metrics, where very useful information can be\nobtained from by combining several metrics. We conclude that the proposed\nmetrics are promising for measuring student's acquired understanding of a\ncontent, as well as for teachers to measure student's weaknesses.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 21:25:44 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Leit\u00e3o", "Gabriel", ""], ["Colonna", "Juan", ""], ["Monteiro", "Edwin", ""], ["Oliveira", "Elaine", ""], ["Barreto", "Raimundo", ""]]}, {"id": "2006.14746", "submitter": "Sergio R. Coria", "authors": "Sergio R. Coria, Leonardo Marcos-Santiago, Christian A. Cruz-Melendez,\n  Juan M. Jimenez-Canseco", "title": "Towards an automated repository for indexing, analysis and\n  characterization of municipal e-government websites in Mexico", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article addresses a problem in the electronic government discipline with\nspecial interest in Mexico: the need for a concentrated and updated information\nsource about municipal e-government websites. One reason for this is the lack\nof a complete and updated database containing the electronic addresses (web\ndomain names) of the municipal governments having a website. Due to diverse\ncauses, not all the Mexican municipalities have one, and a number of those\nhaving it do not present information corresponding to the current governments\nbut, instead, to other previous ones. The scarce official lists of municipal\nwebsites are not updated with the sufficient frequency, and manually\ndetermining which municipalities have an operating and valid website in a given\nmoment is a time-consuming process. Besides, website contents do not always\ncomply with legal requirements and are considerably heterogeneous. In turn, the\nevolution development level of municipal websites is valuable information that\ncan be harnessed for diverse theoretical and practical purposes in the public\nadministration field. Obtaining all these pieces of information requires\nwebsite content analysis. Therefore, this article investigates the need for and\nthe feasibility to automate implementation and updating of a digital repository\nto perform diverse analyses of these websites. Its technological feasibility is\naddressed by means of a literature review about web scraping and by proposing a\npreliminary manual methodology. This takes into account known, proven,\ntechniques and software tools for web crawling and scraping. No new techniques\nfor crawling or scraping are proposed because the existing ones satisfy the\ncurrent needs. Finally, software requirements are specified in order to\nautomate the creation, updating, indexing, and analyses of the repository.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 01:20:20 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Coria", "Sergio R.", ""], ["Marcos-Santiago", "Leonardo", ""], ["Cruz-Melendez", "Christian A.", ""], ["Jimenez-Canseco", "Juan M.", ""]]}, {"id": "2006.14750", "submitter": "Andrew Hines", "authors": "Labhaoise Ni Fhaolain and Andrew Hines", "title": "Could regulating the creators deliver trustworthy AI?", "comments": "To be published in The Second Workshop on Implementing Machine\n  Ethics, Dublin, Ireland, 30 June 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is a new regulated profession, such as Artificial Intelligence (AI) Architect\nwho is responsible and accountable for AI outputs necessary to ensure\ntrustworthy AI? AI is becoming all pervasive and is often deployed in everyday\ntechnologies, devices and services without our knowledge. There is heightened\nawareness of AI in recent years which has brought with it fear. This fear is\ncompounded by the inability to point to a trustworthy source of AI, however\neven the term \"trustworthy AI\" itself is troublesome. Some consider trustworthy\nAI to be that which complies with relevant laws, while others point to the\nrequirement to comply with ethics and standards (whether in addition to or in\nisolation of the law). This immediately raises questions of whose ethics and\nwhich standards should be applied and whether these are sufficient to produce\ntrustworthy AI in any event.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 01:32:53 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Fhaolain", "Labhaoise Ni", ""], ["Hines", "Andrew", ""]]}, {"id": "2006.14864", "submitter": "William Buchanan Prof", "authors": "Will Abramson, Nicole E. van Deursen, William J Buchanan", "title": "Trust-by-Design: Evaluating Issues and Perceptions within Clinical\n  Passporting", "comments": null, "journal-ref": "Blockchain in Healthcare Today, 3 (2020)", "doi": "10.30953/bhty.v3.140", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A substantial administrative burden is placed on healthcare professionals as\nthey manage and progress through their careers. Identity verification,\npre-employment screening and appraisals: the bureaucracy associated with each\nof these processes takes precious time out of a healthcare professional's day.\nTime that could have been spent focused on patient care. In the midst of the\nCOVID-19 crisis, it is more important than ever to optimize these\nprofessionals' time. This paper presents the synthesis of a design workshop\nheld at the Royal College of Physicians of Edinburgh (RCPE) and subsequent\ninterviews with healthcare professionals. The main research question posed is\nwhether these processes can be re-imagined using digital technologies,\nspecifically Self-Sovereign Identity? A key contribution in the paper is the\ndevelopment of a set of user-led requirements and design principles for\nidentity systems used within healthcare. These are then contrasted with the\ndesign principles found in the literature. The results of this study confirm\nthe need and potential of professionalising identity and credential management\nthroughout a healthcare professional's career.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 08:49:44 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Abramson", "Will", ""], ["van Deursen", "Nicole E.", ""], ["Buchanan", "William J", ""]]}, {"id": "2006.14882", "submitter": "Fan Zuo", "authors": "Fan Zuo, Jingxing Wang, Jingqin Gao, Kaan Ozbay, Xuegang Jeff Ban,\n  Yubin Shen, Hong Yang, Shri Iyer", "title": "An Interactive Data Visualization and Analytics Tool to Evaluate\n  Mobility and Sociability Trends During COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 outbreak has dramatically changed travel behavior in affected\ncities. The C2SMART research team has been investigating the impact of COVID-19\non mobility and sociability. New York City (NYC) and Seattle, two of the cities\nmost affected by COVID-19 in the U.S. were included in our initial study. An\nall-in-one dashboard with data mining and cloud computing capabilities was\ndeveloped for interactive data analytics and visualization to facilitate the\nunderstanding of the impact of the outbreak and corresponding policies such as\nsocial distancing on transportation systems. This platform is updated regularly\nand continues to evolve with the addition of new data, impact metrics, and\nvisualizations to assist public and decision-makers to make informed decisions.\nThis paper presents the architecture of the COVID related mobility data\ndashboard and preliminary mobility and sociability metrics for NYC and Seattle.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 09:27:53 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Zuo", "Fan", ""], ["Wang", "Jingxing", ""], ["Gao", "Jingqin", ""], ["Ozbay", "Kaan", ""], ["Ban", "Xuegang Jeff", ""], ["Shen", "Yubin", ""], ["Yang", "Hong", ""], ["Iyer", "Shri", ""]]}, {"id": "2006.14890", "submitter": "Dr Gregory Epiphaniou", "authors": "Carsten Maple and Peter Davies and Kerstin Eder and Chris Hankin and\n  Greg Chance and Gregory Epiphaniou", "title": "CyRes -- Avoiding Catastrophic Failure in Connected and Autonomous\n  Vehicles (Extended Abstract)", "comments": "7 pages, extended abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to cyber security and regulation in the automotive sector\ncannot achieve the quality of outcome necessary to ensure the safe mass\ndeployment of advanced vehicle technologies and smart mobility systems. Without\nsustainable resilience hard-fought public trust will evaporate, derailing\nemerging global initiatives to improve the efficiency, safety and environmental\nimpact of future transport. This paper introduces an operational cyber\nresilience methodology, CyRes, that is suitable for standardisation. The CyRes\nmethodology itself is capable of being tested in court or by publicly appointed\nregulators. It is designed so that operators understand what evidence should be\nproduced by it and are able to measure the quality of that evidence. The\nevidence produced is capable of being tested in court or by publicly appointed\nregulators. Thus, the real-world system to which the CyRes methodology has been\napplied is capable of operating at all times and in all places with a legally\nand socially acceptable value of negative consequence.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 09:59:52 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:12:59 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 10:54:33 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Maple", "Carsten", ""], ["Davies", "Peter", ""], ["Eder", "Kerstin", ""], ["Hankin", "Chris", ""], ["Chance", "Greg", ""], ["Epiphaniou", "Gregory", ""]]}, {"id": "2006.15069", "submitter": "Victor E. Staartjes", "authors": "Julius M. Kernbach, Victor E. Staartjes", "title": "Machine learning-based clinical prediction modeling -- A practical guide\n  for clinicians", "comments": "57 pages, 21 figures. Supplementary material (R Codes and the\n  Glioblastoma dataset) can be downloaded from: https://micnlab.com/files/ .\n  Julius M. Kernbach and Victor E. Staartjes contributed equally to this work\n  and share first authorship", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the emerging era of big data, larger available clinical datasets and\ncomputational advances have sparked a massive interest in machine\nlearning-based approaches. The number of manuscripts related to machine\nlearning or artificial intelligence has exponentially increased over the past\nyears. As analytical machine learning tools become readily available for\nclinicians to use, the understanding of key concepts and the awareness of\nanalytical pitfalls are increasingly required for clinicians, investigators,\nreviewers and editors, who even as experts in their clinical field, sometimes\nfind themselves insufficiently equipped to evaluate machine learning\nmethodologies. In the first section, we provide explanations on the general\nprinciples of machine learning, as well as analytical steps required for\nsuccessful machine learning-based predictive modelling - which is the focus of\nthis series. In further sections, we review the importance of resampling,\noverfitting and model generalizability as well as feature reduction and\nselection (Part II), strategies for model evaluation, reporting and discussion\nof common caveats and other points of significance (Part III), as well as offer\na practical guide to classification (Part IV) and regression modelling (Part\nV), with a complete coding pipeline. Methodological rigor and clarity as well\nas understanding of the underlying reasoning of the internal workings of a\nmachine learning approach are required, otherwise predictive applications\ndespite being strong analytical tools are not well accepted into the clinical\nroutine. Going forward, machine learning and artificial intelligence shape and\ninfluence modern medicine across disciplines including the field of\nneurosurgery.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 20:11:37 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Kernbach", "Julius M.", ""], ["Staartjes", "Victor E.", ""]]}, {"id": "2006.15179", "submitter": "Nils Clausen", "authors": "Nils Clausen", "title": "An Analysis of Academic Performance of University Students in Namibia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on observations it seems that a considerable proportion of university\nstudents in Namibia need to enhance their academic performance in regard to be\nfully competitive in a globalised working environment. This specifically\nincludes thorough understanding of mathematics, as it forms an integral part of\nmodern knowledge disciplines such as information technology and the management\nsciences. Yet students struggle or fail to engage in relevant coursework,\neither because of an absence of adequate material, capable educators, their own\nwill power, or a combination thereof. This study aims to investigate the\ncritical factors that are related to academic performance of university\nstudents in Namibia.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 19:11:08 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Clausen", "Nils", ""]]}, {"id": "2006.15195", "submitter": "Lorenzo Lucchini", "authors": "Samuel P. Fraiberger, Pablo Astudillo, Lorenzo Candeago, Alex Chunet,\n  Nicholas K. W. Jones, Maham Faisal Khan, Bruno Lepri, Nancy Lozano Gracia,\n  Lorenzo Lucchini, Emanuele Massaro, Aleister Montfort", "title": "Uncovering socioeconomic gaps in mobility reduction during the COVID-19\n  pandemic using location data", "comments": "to appear in KDD 2020, Workshop on Humanitarian Mapping", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Using smartphone location data from Colombia, Mexico, and Indonesia, we\ninvestigate how non-pharmaceutical policy interventions intended to mitigate\nthe spread of the COVID-19 pandemic impact human mobility. In all three\ncountries, we find that following the implementation of mobility restriction\nmeasures, human movement decreased substantially. Importantly, we also uncover\nlarge and persistent differences in mobility reduction between wealth groups:\non average, users in the top decile of wealth reduced their mobility up to\ntwice as much as users in the bottom decile. For decision-makers seeking to\nefficiently allocate resources to response efforts, these findings highlight\nthat smartphone location data can be leveraged to tailor policies to the needs\nof specific socioeconomic groups, especially the most vulnerable.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 19:58:34 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 14:16:56 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Fraiberger", "Samuel P.", ""], ["Astudillo", "Pablo", ""], ["Candeago", "Lorenzo", ""], ["Chunet", "Alex", ""], ["Jones", "Nicholas K. W.", ""], ["Khan", "Maham Faisal", ""], ["Lepri", "Bruno", ""], ["Gracia", "Nancy Lozano", ""], ["Lucchini", "Lorenzo", ""], ["Massaro", "Emanuele", ""], ["Montfort", "Aleister", ""]]}, {"id": "2006.15216", "submitter": "Vukosi Marivate", "authors": "Nompumelelo Mtsweni, Herkulaas MvE Combrink, Vukosi Marivate", "title": "Mapping the South African health landscape in response to COVID-19", "comments": "Accepted for KDD 2020 Workshop on Humanitarian Mapping", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  When the COVID-19 disease pandemic infiltrated the world, there was an\nimmediate need for accurate information. As with any outbreak, the outbreak\nfollows a clear trajectory, and subsequently, the supporting information for\nthat outbreak needs to address the needs associated with that stage of the\noutbreak. At first, there was a need to inform the public of the information\nrelated to the initial situation related to the \"who\" of the COVID-19 disease.\nHowever, as time continued, the \"where\", \"when\" and \"how to\" related questions\nstarted to emerge in relation to the public healthcare system themselves.\nQuestions surrounding the health facilities including COVID-19 hospital bed\ncapacity, locations of designated COVID-19 facilities, and general information\nrelated to these facilities were not easily accessible to the general public.\nFurthermore, the available information was found to be outdated, fragmented\nacross several platforms, and still had gaps in the data related to these\nfacilities. To rectify this problem, a group of volunteers working on the\ncovid19za project stepped in to assist. Each member leading a part of the\nproject chose to focus on one of four problems related to the challenges\nassociated with the Hospital information including: data quality, data\ncompleteness, data source validation and data visualisation capacity. As the\nproject developed, so did the sophistication of the data, visualisation and\ncore function of the project. The future prospects of this project relate to a\nProgressive Web Application that will avail this information for the public as\nwell as healthcare workers through comprehensive mapping and data quality.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 21:14:06 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Mtsweni", "Nompumelelo", ""], ["Combrink", "Herkulaas MvE", ""], ["Marivate", "Vukosi", ""]]}, {"id": "2006.15383", "submitter": "Qing Ke", "authors": "Qing Ke", "title": "Interdisciplinary research and technological impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interdisciplinary research has been considered as a solution to today's\ncomplex societal challenges. While its relationship with scientific impact has\nbeen extensively studied, the technological impact of interdisciplinary\nresearch remains unexplored. Here, we examine how interdisciplinarity is\nassociated with technological impact at the paper level. We measure the degree\nof interdisciplinarity of a paper using three popular indicators, namely\nvariety, balance, and disparity, and track how it gets cited by patented\ntechnologies over time. Drawing on a large sample of biomedical papers\npublished in 18 years, we find that papers that cites more fields (variety) and\nwhose distributions over those cited fields are more even (balance) are more\nlikely to receive patent citations, but both effects can be offset if papers\ndraw upon more distant fields (disparity). Those associations are consistent\nacross different citation-window lengths. Additional analysis that focuses on\nthe subset of papers with at least one patent citation reveals that the\nintensity of their technological impact, as measured as the number of patent\ncitations, increases with balance and disparity. Our work may have policy\nimplications for interdisciplinary research and scientific and technology\nimpact.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 15:21:40 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ke", "Qing", ""]]}, {"id": "2006.15428", "submitter": "Muhammad E. H. Chowdhury", "authors": "Amith Khandakar, Annaufal Rizqullah, Anas Ashraf Abdou Berbar,\n  Mohammad Rafi Ahmed, Atif Iqbal, Muhammad E. H. Chowdhury, S. M. Ashfaq Uz\n  Zaman", "title": "A Case Study to Identify the Hindrances to Widespread Adoption of\n  Electric Vehicles in Qatar", "comments": "22 pages, 5 Figures, 5 tables", "journal-ref": "Energies 2020, 13(15), 3994", "doi": "10.3390/en13153994", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of electric vehicles (EVs) have proven to be a crucial factor to\ndecreasing the emission of greenhouse gases (GHG) into the atmosphere. However,\nthere are various hurdles that impede people from purchasing EVs. For example,\nlong charging time, short driving range, cost and insufficient charging\ninfrastructures available, etc. This article reports the public perception of\nEV-adoption using statistical analyses and proposes some recommendations for\nimproving EV-adoption in Qatar. User perspectives on EV-adoption barriers in\nQatar were investigated based on survey questionnaires. The survey\nquestionnaires were based on similar studies done in other regions of the\nworld. The study attempted to look at different perspectives of the adoption of\nEV, when asked to a person who is aware of EVs or a person who may or may not\nbe aware of EVs. Cumulative survey responses from the two groups were compared\nand analyzed using a two sample t-test statistical analysis. Detailed analyses\nshowed that among various major hindrances raising of public awareness of such\ngreener modes of transportation, the availability of charging options in more\nplaces and policy incentives towards EVs would play a major role in\nEV-adoption. The authors provide recommendations that along with government\nincentives could help make a gradual shift to a greater number of EVs\nconvenient for people of Qatar. The proposed systematic approach for such a\nstudy and analysis may help in streamlining research on policies,\ninfrastructures and technologies for efficient penetration of EVs in Qatar.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 18:56:46 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Khandakar", "Amith", ""], ["Rizqullah", "Annaufal", ""], ["Berbar", "Anas Ashraf Abdou", ""], ["Ahmed", "Mohammad Rafi", ""], ["Iqbal", "Atif", ""], ["Chowdhury", "Muhammad E. H.", ""], ["Zaman", "S. M. Ashfaq Uz", ""]]}, {"id": "2006.15433", "submitter": "Fang Liu", "authors": "Dong Wang and Fang Liu", "title": "Privacy Risk and Preservation For COVID-19 Contact Tracing Apps", "comments": "To appear in CHANCE 33(2): special issue on COVID-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing in the COVID-19 pandemic is key to prevent the further spread\nof COVID-19. Countries and regions around the world have developed and deployed\nor are considering adopting contact-tracing software or mobile apps. While\ncontact tracing apps and software play an important role in the pandemic, red\nflags have been raised regarding the privacy risk associated with contact\ntracing. In this short paper, we provide an overview on the GPS and Bluetooth\nbased contact-tracing apps in the framework of both centralized and\ndecentralized models, examine the associated privacy risk and the effectiveness\nof the privacy-preserving measures adopted in different apps.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 19:42:30 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Wang", "Dong", ""], ["Liu", "Fang", ""]]}, {"id": "2006.15648", "submitter": "Taha Yasseri", "authors": "Alicia Mergenthaler and Taha Yasseri", "title": "Selling sex: what determines rates and popularity? An analysis of 11,500\n  online profiles", "comments": "Main manuscript and Supplementary Information", "journal-ref": "Published in Culture, Health & Sexuality (2021)", "doi": "10.1080/13691058.2021.1901145", "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sex work, or the exchange of sexual services for money or goods, is\nubiquitous across eras and cultures. However, the practice of selling sex is\noften hidden due to stigma and the varying legal status of sex work. Online\nplatforms that sex workers use to advertise services have become an\nincreasingly important means of studying a market that is largely hidden.\nAlthough prior literature has primarily shed light on sex work from a public\nhealth or policy perspective (focusing largely on female sex workers), there\nare few studies that empirically research patterns of service provision in\nonline sex work. This study investigated the determinants of pricing and\npopularity in the market for commercial sexual services online by using data\nfrom the largest UK network of online sexual services, a platform that is the\nindustry-standard for sex workers. While the size of these influences varies\nacross genders, nationality, age and the services provided are shown to be\nprimary drivers of rates and popularity in sex work.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 16:46:22 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 10:51:58 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 17:04:07 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Mergenthaler", "Alicia", ""], ["Yasseri", "Taha", ""]]}, {"id": "2006.15717", "submitter": "IA Grant Wilson", "authors": "IA Grant Wilson, Shivangi Sharma, Joseph Day, Noah Godfrey", "title": "Calculating Great Britains half-hourly electrical demand from publicly\n  available data", "comments": "33 pages, 3 Figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Here we present a method to combine half-hourly publicly available electrical\ngeneration and interconnector data to create a timeseries that approximates\nGreat Britains electrical demand. Publishing the method and the data provides a\nresource to the wider community that can be further enhanced or adapted and\nallows the method itself to be considered and critiqued. The method adds value\nby combining transmission and distribution generation data into a single\ndataset and adding ISO 8601 compatible datetimes to increase interoperability\nwith other data. The published data is therefore more useable by a wider group\nof researchers and stakeholders interested in an example of the rapid\ndecarbonisation of a countries electrical system.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 21:16:22 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 16:39:22 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 16:33:18 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Wilson", "IA Grant", ""], ["Sharma", "Shivangi", ""], ["Day", "Joseph", ""], ["Godfrey", "Noah", ""]]}, {"id": "2006.15794", "submitter": "Shehroze Farooqi", "authors": "Shehroze Farooqi and Maaz Musa and Zubair Shafiq and Fareed Zaffar", "title": "CanaryTrap: Detecting Data Misuse by Third-Party Apps on Online Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social networks support a vibrant ecosystem of third-party apps that\nget access to personal information of a large number of users. Despite several\nrecent high-profile incidents, methods to systematically detect data misuse by\nthird-party apps on online social networks are lacking. We propose CanaryTrap\nto detect misuse of data shared with third-party apps. CanaryTrap associates a\nhoneytoken to a user account and then monitors its unrecognized use via\ndifferent channels after sharing it with the third-party app. We design and\nimplement CanaryTrap to investigate misuse of data shared with third-party apps\non Facebook. Specifically, we share the email address associated with a\nFacebook account as a honeytoken by installing a third-party app. We then\nmonitor the received emails and use Facebook's ad transparency tool to detect\nany unrecognized use of the shared honeytoken. Our deployment of CanaryTrap to\nmonitor 1,024 Facebook apps has uncovered multiple cases of misuse of data\nshared with third-party apps on Facebook including ransomware, spam, and\ntargeted advertising.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 03:32:03 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Farooqi", "Shehroze", ""], ["Musa", "Maaz", ""], ["Shafiq", "Zubair", ""], ["Zaffar", "Fareed", ""]]}, {"id": "2006.16083", "submitter": "Miguel Ribeiro", "authors": "Miguel Ribeiro, Bernardo Galv\\~ao, Catia Prandi, Nuno Nunes", "title": "Passive Wi-Fi Monitoring in Public Transport: A case study in the\n  Madeira Island", "comments": null, "journal-ref": "Proceedings of TRA2020, the 8th Transport Research Arena:\n  Rethinking transport towards clean and inclusive mobility", "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transportation has become of evermore importance in the last years, affecting\npeople's satisfaction and significantly impacting their quality of life. In\nthis paper we present a low-cost infrastructure to collect passive Wi-Fi probes\nwith the aim of monitoring, optimizing and personalizing public transport,\ntowards a more sustainable mobility. We developed an embedded system deployed\nin 19 public transportation vehicles using passive Wi-Fi data. This data is\nanalyzed on a per-vehicle and per-stop basis and compared against ground truth\ndata (ticketing), while also using a method of estimating passenger exits,\ndetecting peak loads on vehicles, and origin destination habits. As such, we\nargue that this data enables route optimization and provides local authorities\nand tourism boards with a tool to monitor and optimize the management of routes\nand transportation, identify and prevent accessibility issues, with the aim of\nimproving the services offered to citizens and tourists, towards a more\nsustainable mobility.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 14:35:58 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ribeiro", "Miguel", ""], ["Galv\u00e3o", "Bernardo", ""], ["Prandi", "Catia", ""], ["Nunes", "Nuno", ""]]}, {"id": "2006.16140", "submitter": "Laurent H\\'ebert-Dufresne", "authors": "Juniper Lovato, Antoine Allard, Randall Harp and Laurent\n  H\\'ebert-Dufresne", "title": "Limits of individual consent and models of distributed consent in online\n  social networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal data is not discrete in socially-networked digital environments. A\nuser who consents to allow access to their profile can expose the personal data\nof their network connections to non-consented access. Therefore, the\ntraditional consent model (informed and individual) is not appropriate in\nsocial networks where informed consent may not be possible for all users\naffected by data processing and where information is distributed across users.\nHere, we outline the adequacy of consent for data transactions. Informed by the\nshortcomings of individual consent, we introduce both a platform-specific model\nof \"distributed consent\" and a cross-platform model of a \"consent passport.\" In\nboth models, individuals and groups can coordinate by giving consent\nconditional on that of their network connections. We simulate the impact of\nthese distributed consent models on the observability of social networks and\nfind that low adoption would allow macroscopic subsets of networks to preserve\ntheir connectivity and privacy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:00:11 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 00:39:35 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Lovato", "Juniper", ""], ["Allard", "Antoine", ""], ["Harp", "Randall", ""], ["H\u00e9bert-Dufresne", "Laurent", ""]]}, {"id": "2006.16179", "submitter": "Ram Shankar Siva Kumar", "authors": "Ram Shankar Siva Kumar, Jonathon Penney, Bruce Schneier, Kendra Albert", "title": "Legal Risks of Adversarial Machine Learning Research", "comments": "Accepted at ICML 2020 Workshop on Law & Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Machine Learning is booming with ML researchers increasingly\ntargeting commercial ML systems such as those used in Facebook, Tesla,\nMicrosoft, IBM, Google to demonstrate vulnerabilities. In this paper, we ask,\n\"What are the potential legal risks to adversarial ML researchers when they\nattack ML systems?\" Studying or testing the security of any operational system\npotentially runs afoul the Computer Fraud and Abuse Act (CFAA), the primary\nUnited States federal statute that creates liability for hacking. We claim that\nAdversarial ML research is likely no different. Our analysis show that because\nthere is a split in how CFAA is interpreted, aspects of adversarial ML attacks,\nsuch as model inversion, membership inference, model stealing, reprogramming\nthe ML system and poisoning attacks, may be sanctioned in some jurisdictions\nand not penalized in others. We conclude with an analysis predicting how the US\nSupreme Court may resolve some present inconsistencies in the CFAA's\napplication in Van Buren v. United States, an appeal expected to be decided in\n2021. We argue that the court is likely to adopt a narrow construction of the\nCFAA, and that this will actually lead to better adversarial ML security\noutcomes in the long term.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 16:45:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Kumar", "Ram Shankar Siva", ""], ["Penney", "Jonathon", ""], ["Schneier", "Bruce", ""], ["Albert", "Kendra", ""]]}, {"id": "2006.16380", "submitter": "Sanchari Das", "authors": "Ploy Unchit, Sanchari Das, Andrew Kim, L. Jean Camp", "title": "Quantifying Susceptibility to Spear Phishing in a High School\n  Environment Using Signal Detection Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spear phishing is a deceptive attack that uses social engineering to obtain\nconfidential information through targeted victimization. It is distinguished by\nits use of social cues and personalized information to target specific victims.\nPrevious work on resilience to spear phishing has focused on convenience\nsamples, with a disproportionate focus on students. In contrast, here, we\nreport on an evaluation of a high school community. We engaged 57 high school\nstudents and faculty members (12 high school students, 45 staff members) as\nparticipants in research utilizing signal detection theory (SDT). Through\nscenario-based analysis, participants tasked with distinguishing phishing\nemails from authentic emails. The results revealed an overconfidence bias in\nself-detection from the participants, regardless of their technical background.\nThese findings are critical for evaluating the decision-making of\nunderrepresented populations and protecting people from potential spear\nphishing attacks by examining human susceptibility.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:59:54 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:02:05 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Unchit", "Ploy", ""], ["Das", "Sanchari", ""], ["Kim", "Andrew", ""], ["Camp", "L. Jean", ""]]}, {"id": "2006.16402", "submitter": "Jasmine Bayrooti", "authors": "Elizabeth Reichert, Helen Qiu, Jasmine Bayrooti", "title": "Reading Between the Demographic Lines: Resolving Sources of Bias in\n  Toxicity Classifiers", "comments": "8 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The censorship of toxic comments is often left to the judgment of imperfect\nmodels. Perspective API, a creation of Google technology incubator Jigsaw, is\nperhaps the most widely used toxicity classifier in industry; the model is\nemployed by several online communities including The New York Times to identify\nand filter out toxic comments with the goal of preserving online safety.\nUnfortunately, Google's model tends to unfairly assign higher toxicity scores\nto comments containing words referring to the identities of commonly targeted\ngroups (e.g., \"woman,'' \"gay,'' etc.) because these identities are frequently\nreferenced in a disrespectful manner in the training data. As a result,\ncomments generated by marginalized groups referencing their identities are\noften mistakenly censored. It is important to be cognizant of this unintended\nbias and strive to mitigate its effects. To address this issue, we have\nconstructed several toxicity classifiers with the intention of reducing\nunintended bias while maintaining strong classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 21:40:55 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Reichert", "Elizabeth", ""], ["Qiu", "Helen", ""], ["Bayrooti", "Jasmine", ""]]}, {"id": "2006.16445", "submitter": "Renata Konrad", "authors": "Renata Konrad, Kayse Lee Maass and Andrew C. Trapp", "title": "A perspective on how to conduct responsible anti-human trafficking\n  research in operations and analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human trafficking, the commercial exploitation of individuals, is a gross\nviolation of human rights and harms societies, economies, health and\ndevelopment. The related disciplines of Operations Management (OM), Analytics,\nand Operations Research (OR) are uniquely positioned to support trafficking\nprevention and intervention efforts by efficiently evaluating a plethora of\ndecision alternatives, and providing quantitative, actionable insights. As\noperations and analytical efforts in the counter-trafficking field emerge, it\nis imperative to grasp subtle yet distinctive nuances associated with human\ntrafficking. This note is intended to inform those practitioners working in the\nfield by highlighting key features of human trafficking activity. We grouped\nnine themes around three broad categories: (1) representation of human\ntrafficking, (2) consideration of survivors and communities, and (3) analytics\nrelated. These insights are derived from our collective experience in working\nin this area and substantiated by domain expertise.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 00:47:05 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Konrad", "Renata", ""], ["Maass", "Kayse Lee", ""], ["Trapp", "Andrew C.", ""]]}, {"id": "2006.16504", "submitter": "Prabir Barooah", "authors": "Duzgun Agdas and Prabir Barooah", "title": "The COVID-19 pandemic's impact on U.S. electricity demand and supply: an\n  early view from the data", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2020.3016912", "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the onset of the recent COVID-19 pandemic, a number of studies reported\non possible changes in electricity consumption trends. The overall theme of\nthese reports was that ``electricity use has decreased during the pandemic, but\nthe power grid is still reliable''---mostly due to reduced economic activity.\nIn this paper we analyze electricity data upto end of May 2020, examining both\nelectricity demand and variables that can indicate stress on the power grid,\nsuch as peak demand and demand ramp-rate. We limit this study to three states\nin the USA: New York, California, and Florida. The results indicate that the\neffect of the pandemic on electricity demand is not a simple reduction from\ncomparable time frames, and there are noticeable differences among regions. The\nvariables that can indicate stress on the grid also conveyed mixed messages:\nsome indicate an increase in stress, some indicate a decrease, and some do not\nindicate any clear difference. A positive message is that some of the changes\nthat were observed around the time stay-at-home orders were issued appeared to\nrevert back by May 2020. A key challenge in ascribing any observed change to\nthe pandemic is correcting for weather. We provide a weather-correction method,\napply it to a small city-wide area, and discuss the implications of the\nestimated changes in demand. The weather correction exercise underscored that\nweather-correction is as challenging as it is important.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 03:25:23 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Agdas", "Duzgun", ""], ["Barooah", "Prabir", ""]]}, {"id": "2006.16745", "submitter": "Sami Zhioua", "authors": "Karima Makhlouf, Sami Zhioua, Catuscia Palamidessi", "title": "On the Applicability of ML Fairness Notions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ML-based predictive systems are increasingly used to support decisions with a\ncritical impact on individuals' lives such as college admission, job hiring,\nchild custody, criminal risk assessment, etc. As a result, fairness emerged as\nan important requirement to guarantee that predictive systems do not\ndiscriminate against specific individuals or entire sub-populations, in\nparticular, minorities. Given the inherent subjectivity of viewing the concept\nof fairness, several notions of fairness have been introduced in the\nliterature. This paper is a survey of fairness notions that, unlike other\nsurveys in the literature, addresses the question of \"which notion of fairness\nis most suited to a given real-world scenario and why?\". Our attempt to answer\nthis question consists in (1) identifying the set of fairness-related\ncharacteristics of the real-world scenario at hand, (2) analyzing the behavior\nof each fairness notion, and then (3) fitting these two elements to recommend\nthe most suitable fairness notion in every specific setup. The results are\nsummarized in a decision diagram that can be used by practitioners and policy\nmakers to navigate the relatively large catalogue of fairness notions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 13:01:06 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 07:50:19 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Makhlouf", "Karima", ""], ["Zhioua", "Sami", ""], ["Palamidessi", "Catuscia", ""]]}, {"id": "2006.16849", "submitter": "Beatrice Perez", "authors": "Beatrice Perez, Sara R. Machado, Jerone T. A. Andrews, Nicolas\n  Kourtellis", "title": "I call BS: Fraud Detection in Crowdfunding Campaigns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Donations to charity-based crowdfunding environments have been on the rise in\nthe last few years. Unsurprisingly, deception and fraud in such platforms have\nalso increased, but have not been thoroughly studied to understand what\ncharacteristics can expose such behavior and allow its automatic detection and\nblocking. Indeed, crowdfunding platforms are the only ones typically performing\noversight for the campaigns launched in each service. However, they are not\nproperly incentivized to combat fraud among users and the campaigns they\nlaunch: on the one hand, a platform's revenue is directly proportional to the\nnumber of transactions performed (since the platform charges a fixed amount per\ndonation); on the other hand, if a platform is transparent with respect to how\nmuch fraud it has, it may discourage potential donors from participating.\n  In this paper, we take the first step in studying fraud in crowdfunding\ncampaigns. We analyze data collected from different crowdfunding platforms, and\nannotate 700 campaigns as fraud or not. We compute various textual and\nimage-based features and study their distributions and how they associate with\ncampaign fraud. Using these attributes, we build machine learning classifiers,\nand show that it is possible to automatically classify such fraudulent behavior\nwith up to 90.14% accuracy and 96.01% AUC, only using features available from\nthe campaign's description at the moment of publication (i.e., with no user or\nmoney activity), making our method applicable for real-time operation on a user\nbrowser.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:38:21 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Perez", "Beatrice", ""], ["Machado", "Sara R.", ""], ["Andrews", "Jerone T. A.", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "2006.16858", "submitter": "Mark Christopher Ballandies", "authors": "Mark Christopher Ballandies, Evangelos Pournaras", "title": "Mobile Link Prediction: Automated Creation and Crowd-sourced Validation\n  of Knowledge Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building trustworthy knowledge graphs for cyber-physical social systems\n(CPSS) is a challenge. In particular, current approaches relying on human\nexperts have limited scalability, while automated approaches are often not\naccountable to users resulting in knowledge graphs of questionable quality.\nThis paper introduces a novel pervasive knowledge graph builder that brings\ntogether automation, experts' and crowd-sourced citizens' knowledge. The\nknowledge graph grows via automated link predictions using genetic programming\nthat are validated by humans for improving transparency and calibrating\naccuracy. The knowledge graph builder is designed for pervasive devices such as\nsmartphones and preserves privacy by localizing all computations. The accuracy,\npracticality, and usability of the knowledge graph builder is evaluated in a\nreal-world social experiment that involves a smartphone implementation and a\nSmart City application scenario. The proposed knowledge graph building\nmethodology outperforms the baseline method in terms of accuracy while\ndemonstrating its efficient calculations on smartphones and the feasibility of\nthe pervasive human supervision process in terms of high interactions\nthroughput. These findings promise new opportunities to crowd-source and\noperate pervasive reasoning systems for cyber-physical social systems in Smart\nCities.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:50:34 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ballandies", "Mark Christopher", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "2006.16879", "submitter": "Devin Guillory", "authors": "Devin Guillory", "title": "Combating Anti-Blackness in the AI Community", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to a national and international awakening on the issues of\nanti-Blackness and systemic discrimination, we have penned this piece to serve\nas a resource for allies in the AI community who are wondering how they can\nmore effectively engage with dismantling racist systems. This work aims to help\nelucidate areas where the AI community actively and passively contributes to\nanti-Blackness and offers actionable items on ways to reduce harm.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 19:14:00 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Guillory", "Devin", ""]]}, {"id": "2006.16882", "submitter": "Muhammad Nazrul Islam", "authors": "Muhammad Nazrul Islam and A.K.M. Najmul Islam", "title": "A Systematic Review of the Digital Interventions for Fighting COVID-19:\n  The Bangladesh Perspective", "comments": "10 pages, 4 figures, 1 table", "journal-ref": "IEEE Access, Vol. 8, page: 114078 - 114087, 2020", "doi": "10.1109/ACCESS.2020.3002445", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The objective of this paper is to synthesize the digital interventions\ninitiatives to fight against COVID-19 in Bangladesh and compare with other\ncountries. In order to obtain our research objective, we conducted a systematic\nreview of the online content. We first reviewed the digital interventions that\nhave been used to fight against COVID-19 across the globe. We then reviewed the\ninitiatives that have been taken place in Bangladesh. Thereafter, we present a\ncomparative analysis between the initiatives taken in Bangladesh and the other\ncountries. Our findings show that while Bangladesh is capable to take benefits\nof the digital intervention approaches, tighter cooperation between government\nand private organizations as well as universities would be needed to get the\nmost benefits. Furthermore, the government needs to make sure that the privacy\nof its citizens are protected.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 08:03:25 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Islam", "Muhammad Nazrul", ""], ["Islam", "A. K. M. Najmul", ""]]}, {"id": "2006.16900", "submitter": "Anita Graser", "authors": "Anita Graser, Esteban Zim\\'anyi, Krishna Chaitanya Bommakanti", "title": "From Simple Features to Moving Features and Beyond?", "comments": "6 pages, 4 figures, originally prepared for GIScience2020 (which was\n  postponed to 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobility data science lacks common data structures and analytical functions.\nThis position paper assesses the current status and open issues towards a\nuniversal API for mobility data science. In particular, we look at\nstandardization efforts revolving around the OGC Moving Features standard\nwhich, so far, has not attracted much attention within the mobility data\nscience community. We discuss the hurdles any universal API for movement data\nhas to overcome and propose key steps of a roadmap that would provide the\nfoundation for the development of this API.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 08:02:41 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Graser", "Anita", ""], ["Zim\u00e1nyi", "Esteban", ""], ["Bommakanti", "Krishna Chaitanya", ""]]}, {"id": "2006.16910", "submitter": "Jean-Baptiste Lamy", "authors": "Jean-Baptiste Lamy", "title": "A data science approach to drug safety: Semantic and visual mining of\n  adverse drug events from clinical trials of pain treatments", "comments": "13 pages, 15 figures", "journal-ref": "Artificial Intelligence in Medicine 2021;115:102074", "doi": "10.1016/j.artmed.2021.102074", "report-no": null, "categories": "cs.CY cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Clinical trials are the basis of Evidence-Based Medicine. Trial results are\nreviewed by experts and consensus panels for producing meta-analyses and\nclinical practice guidelines. However, reviewing these results is a long and\ntedious task, hence the meta-analyses and guidelines are not updated each time\na new trial is published. Moreover, the independence of experts may be\ndifficult to appraise. On the contrary, in many other domains, including\nmedical risk analysis, the advent of data science, big data and visual\nanalytics allowed moving from expert-based to fact-based knowledge. Since 12\nyears, many trial results are publicly available online in trial registries.\nNevertheless, data science methods have not yet been applied widely to trial\ndata. In this paper, we present a platform for analyzing the safety events\nreported during clinical trials and published in trial registries. This\nplatform is based on an ontological model including 582 trials on pain\ntreatments, and uses semantic web technologies for querying this dataset at\nvarious levels of granularity. It also relies on a 26-dimensional flower glyph\nfor the visualization of the Adverse Drug Events (ADE) rates in 13 categories\nand 2 levels of seriousness. We illustrate the interest of this platform\nthrough several use cases and we were able to find back conclusions that were\ninitially found during meta-analyses. The platform was presented to four\nexperts in drug safety, and is publicly available online, with the ontology of\npain treatment ADE.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:37:36 GMT"}, {"version": "v2", "created": "Sat, 17 Apr 2021 12:25:33 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Lamy", "Jean-Baptiste", ""]]}, {"id": "2006.16911", "submitter": "Kwadwo Osei Bonsu", "authors": "Kwadwo Osei Bonsu, Jie Song", "title": "Turbulence on the Global Economy influenced by Artificial Intelligence\n  and Foreign Policy Inefficiencies", "comments": "This is the pre-print version", "journal-ref": null, "doi": "10.47305/JLIA2020113ob", "report-no": null, "categories": "cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is said that Data and Information are the new oil. One, who handles the\ndata, handles the emerging future of the global economy. Complex algorithms and\nintelligence-based filter programs are utilized to manage, store, handle and\nmaneuver vast amounts of data for the fulfillment of specific purposes. This\npaper seeks to find the bridge between artificial intelligence and its impact\non the international policy implementation in the light of geopolitical\ninfluence, global economy and the future of labor markets. We hypothesize that\nthe distortion in the labor markets caused by artificial intelligence can be\nmitigated by a collaborative international foreign policy on the deployment of\nAI in the industrial circles. We, in this paper, then proceed to propose a\ndisposition for the essentials of AI-based foreign policy and implementation,\nwhile asking questions such as 'could AI become the real Invisible Hand\ndiscussed by economists?'.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 10:59:32 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Bonsu", "Kwadwo Osei", ""], ["Song", "Jie", ""]]}, {"id": "2006.16913", "submitter": "Adish Singla", "authors": "Umair Z. Ahmed, Maria Christakis, Aleksandr Efremov, Nigel Fernandez,\n  Ahana Ghosh, Abhik Roychoudhury, Adish Singla", "title": "Synthesizing Tasks for Block-based Programming", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block-based visual programming environments play a critical role in\nintroducing computing concepts to K-12 students. One of the key pedagogical\nchallenges in these environments is in designing new practice tasks for a\nstudent that match a desired level of difficulty and exercise specific\nprogramming concepts. In this paper, we formalize the problem of synthesizing\nvisual programming tasks. In particular, given a reference visual task $\\rm\nT^{in}$ and its solution code $\\rm C^{in}$, we propose a novel methodology to\nautomatically generate a set $\\{(\\rm T^{out}, \\rm C^{out})\\}$ of new tasks\nalong with solution codes such that tasks $\\rm T^{in}$ and $\\rm T^{out}$ are\nconceptually similar but visually dissimilar. Our methodology is based on the\nrealization that the mapping from the space of visual tasks to their solution\ncodes is highly discontinuous; hence, directly mutating reference task $\\rm\nT^{in}$ to generate new tasks is futile. Our task synthesis algorithm operates\nby first mutating code $\\rm C^{in}$ to obtain a set of codes $\\{\\rm C^{out}\\}$.\nThen, the algorithm performs symbolic execution over a code $\\rm C^{out}$ to\nobtain a visual task $\\rm T^{out}$; this step uses the Monte Carlo Tree Search\n(MCTS) procedure to guide the search in the symbolic tree. We demonstrate the\neffectiveness of our algorithm through an extensive empirical evaluation and\nuser study on reference tasks taken from the \\emph{Hour of Code: Classic Maze}\nchallenge by \\emph{Code.org} and the \\emph{Intro to Programming with Karel}\ncourse by \\emph{CodeHS.com}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 15:04:37 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 22:37:26 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 00:00:55 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Ahmed", "Umair Z.", ""], ["Christakis", "Maria", ""], ["Efremov", "Aleksandr", ""], ["Fernandez", "Nigel", ""], ["Ghosh", "Ahana", ""], ["Roychoudhury", "Abhik", ""], ["Singla", "Adish", ""]]}, {"id": "2006.16915", "submitter": "Hanshuang Tong", "authors": "Hanshuang Tong, Zhen Wang, Qi Liu, Yun Zhou and Wenyuan Han", "title": "HGKT: Introducing Hierarchical Exercise Graph for Knowledge Tracing", "comments": "10 pages, 11 figures, submitted to SIGIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing (KT) which aims at predicting learner's knowledge mastery\nplays an important role in the computer-aided educational system. In recent\nyears, many deep learning models have been applied to tackle the KT task, which\nhave shown promising results. However, limitations still exist. Most existing\nmethods simplify the exercising records as knowledge sequences, which fail to\nexplore rich information that existed in exercises. Besides, the existing\ndiagnosis results of knowledge tracing are not convincing enough since they\nneglect prior relations between exercises. To solve the above problems, we\npropose a hierarchical graph knowledge tracing model called HGKT to explore the\nlatent hierarchical relations between exercises. Specifically, we introduce the\nconcept of problem schema to construct a hierarchical exercise graph that could\nmodel the exercise learning dependencies. Moreover, we employ two attention\nmechanisms to highlight the important historical states of learners. In the\ntesting stage, we present a K\\&S diagnosis matrix that could trace the\ntransition of mastery of knowledge and problem schema, which can be more easily\napplied to different applications. Extensive experiments show the effectiveness\nand interpretability of our proposed models.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 07:09:52 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 02:43:10 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:49:28 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 12:24:39 GMT"}, {"version": "v5", "created": "Wed, 21 Apr 2021 12:22:56 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tong", "Hanshuang", ""], ["Wang", "Zhen", ""], ["Liu", "Qi", ""], ["Zhou", "Yun", ""], ["Han", "Wenyuan", ""]]}, {"id": "2006.16920", "submitter": "Amanda Stathopoulos", "authors": "M Said, A Biehl, A Stathopoulos", "title": "Interdependence in active mobility adoption: Joint modelling and\n  motivational spill-over in walking, cycling and bike-sharing", "comments": "Transportation Research Board 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active mobility offers an array of physical, emotional, and social wellbeing\nbenefits. However, with the proliferation of the sharing economy, new\nnonmotorized means of transport are entering the fold, complementing some\nexisting mobility options while competing with others. The purpose of this\nresearch study is to investigate the adoption of three active travel modes;\nnamely walking, cycling and bikesharing, in a joint modeling framework. The\nanalysis is based on an adaptation of the stages of change framework, which\noriginates from the health behavior sciences. Multivariate ordered probit\nmodeling drawing on U.S. survey data provides well-needed insights into\nindividuals preparedness to adopt multiple active modes as a function of\npersonal, neighborhood and psychosocial factors. The research suggests three\nimportant findings. 1) The joint model structure confirms interdependence among\ndifferent active mobility choices. The strongest complementarity is found for\nwalking and cycling adoption. 2) Each mode has a distinctive adoption path with\neither three or four separate stages. We discuss the implications of derived\nstage-thresholds and plot adoption contours for selected scenarios. 3)\nPsychological and neighborhood variables generate more coupling among active\nmodes than individual and household factors. Specifically, identifying strongly\nwith active mobility aspirations, experiences with multimodal travel,\npossessing better navigational skills, along with supportive local community\nnorms are the factors that appear to drive the joint adoption decisions. This\nstudy contributes to the understanding of how decisions within the same\nfunctional domain are related and help to design policies that promote active\nmobility by identifying positive spillovers and joint determinants.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:37:45 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 19:14:12 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Said", "M", ""], ["Biehl", "A", ""], ["Stathopoulos", "A", ""]]}, {"id": "2006.16922", "submitter": "Natalie Kiesler", "authors": "Natalie Kiesler", "title": "Zur Modellierung und Klassifizierung von Kompetenzen in der\n  grundlegenden Programmierausbildung anhand der Anderson Krathwohl Taxonomie", "comments": "12 pages, 4 tables, in German", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This research paper focusses on the competences expected from computer\nscience novices in the domain of basic programming and how they can be\nclassified. By means of a qualitative content analysis of current learning\nobjectives at German universities and the perspective of university teachers,\nbasic programming competencies are identified. Since the competency model\nproposed by the German Society of Computer Science (GI) reveals several\ndeficits, competencies are classified along the Anderson Krathwohl Taxonomy\n(AKT) of learning, teaching and assessing. As a result, dimensions and subtypes\nof the AKT are revised towards a model specific to computer science aiming at\nthe classification of programming competencies according to their cognitive\ncomplexity and knowledge dimension. The adaptation of the educational model can\nthereby help standardize curricula, and develop assessments and corresponding\nitems in the future.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:07:12 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kiesler", "Natalie", ""]]}, {"id": "2006.16923", "submitter": "Vinay Prabhu", "authors": "Vinay Uday Prabhu, Abeba Birhane", "title": "Large image datasets: A pyrrhic win for computer vision?", "comments": "Github: https://github.com/vinayprabhu/Dataset_audits. Update on July\n  23rd: (1) Added in the supplementary section (2) The curators of the Tiny\n  Images dataset decided to withdraw the dataset in response to the previous\n  version of this paper, a change that has duly been reflected in this version.\n  Their statement: https://groups.csail.mit.edu/vision/TinyImages/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate problematic practices and consequences of large\nscale vision datasets. We examine broad issues such as the question of consent\nand justice as well as specific concerns such as the inclusion of verifiably\npornographic images in datasets. Taking the ImageNet-ILSVRC-2012 dataset as an\nexample, we perform a cross-sectional model-based quantitative census covering\nfactors such as age, gender, NSFW content scoring, class-wise accuracy,\nhuman-cardinality-analysis, and the semanticity of the image class information\nin order to statistically investigate the extent and subtleties of ethical\ntransgressions. We then use the census to help hand-curate a look-up-table of\nimages in the ImageNet-ILSVRC-2012 dataset that fall into the categories of\nverifiably pornographic: shot in a non-consensual setting (up-skirt), beach\nvoyeuristic, and exposed private parts. We survey the landscape of harm and\nthreats both society broadly and individuals face due to uncritical and\nill-considered dataset curation practices. We then propose possible courses of\ncorrection and critique the pros and cons of these. We have duly open-sourced\nall of the code and the census meta-datasets generated in this endeavor for the\ncomputer vision community to build on. By unveiling the severity of the\nthreats, our hope is to motivate the constitution of mandatory Institutional\nReview Boards (IRB) for large scale dataset curation processes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 06:41:32 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 02:55:13 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Prabhu", "Vinay Uday", ""], ["Birhane", "Abeba", ""]]}, {"id": "2006.16925", "submitter": "Soaad Hossain Mr", "authors": "Soaad Hossain, Syed Ishtiaque Ahmed", "title": "Ethical Analysis on the Application of Neurotechnology for Human\n  Augmentation in Physicians and Surgeons", "comments": "24 pages, 2 figures, accepted to Future Technologies Conference (FTC)\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the shortage of physicians and surgeons and increase in demand worldwide\ndue to situations such as the COVID-19 pandemic, there is a growing interest in\nfinding solutions to help address the problem. A solution to this problem would\nbe to use neurotechnology to provide them augmented cognition, senses and\naction for optimal diagnosis and treatment. Consequently, doing so can\nnegatively impact them and others. We argue that applying neurotechnology for\nhuman enhancement in physicians and surgeons can cause injustices, and harm to\nthem and patients. In this paper, we will first describe the augmentations and\nneurotechnologies that can be used to achieve the relevant augmentations for\nphysicians and surgeons. We will then review selected ethical concerns\ndiscussed within literature, discuss the neuroengineering behind using\nneurotechnology for augmentation purposes, then conclude with an analysis on\noutcomes and ethical issues of implementing human augmentation via\nneurotechnology in medical and surgical practice.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 07:46:22 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 16:58:58 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Hossain", "Soaad", ""], ["Ahmed", "Syed Ishtiaque", ""]]}, {"id": "2006.16926", "submitter": "Yash Raj Shrestha", "authors": "Leopold Franz, Yash Raj Shrestha, Bibek Paudel", "title": "A Deep Learning Pipeline for Patient Diagnosis Prediction Using\n  Electronic Health Records", "comments": null, "journal-ref": "BIOKDD 2020 at the ACM SIGKDD Conference on Knowledge Discovery\n  and Data Mining (KDD) 2020", "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Augmentation of disease diagnosis and decision-making in healthcare with\nmachine learning algorithms is gaining much impetus in recent years. In\nparticular, in the current epidemiological situation caused by COVID-19\npandemic, swift and accurate prediction of disease diagnosis with machine\nlearning algorithms could facilitate identification and care of vulnerable\nclusters of population, such as those having multi-morbidity conditions. In\norder to build a useful disease diagnosis prediction system, advancement in\nboth data representation and development of machine learning architectures are\nimperative. First, with respect to data collection and representation, we face\nsevere problems due to multitude of formats and lack of coherency prevalent in\nElectronic Health Records (EHRs). This causes hindrance in extraction of\nvaluable information contained in EHRs. Currently, no universal global data\nstandard has been established. As a useful solution, we develop and publish a\nPython package to transform public health dataset into an easy to access\nuniversal format. This data transformation to an international health data\nformat facilitates researchers to easily combine EHR datasets with clinical\ndatasets of diverse formats. Second, machine learning algorithms that predict\nmultiple disease diagnosis categories simultaneously remain underdeveloped. We\npropose two novel model architectures in this regard. First, DeepObserver,\nwhich uses structured numerical data to predict the diagnosis categories and\nsecond, ClinicalBERT_Multi, that incorporates rich information available in\nclinical notes via natural language processing methods and also provides\ninterpretable visualizations to medical practitioners. We show that both models\ncan predict multiple diagnoses simultaneously with high accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 14:58:58 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Franz", "Leopold", ""], ["Shrestha", "Yash Raj", ""], ["Paudel", "Bibek", ""]]}, {"id": "2006.16944", "submitter": "Carlos Denner Dos Santos Jr.", "authors": "Carlos Denner dos Santos, Isadora Castro, George Kuk, Silvia Onoyama,\n  Marina Moreira", "title": "Bucking the Trend: An Agentive Perspective of Managerial Influence on\n  Blogs Attractiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blog management is central to the digitalization of work. However, existing\ntheories tend to focus on environmental influence rather than managerial\ncontrol of a blogs attractiveness at a microlevel. This study provides an\nagentive account of the adaptive behaviours exerted by the bloggers through the\nways they use contents of their blogs to locate and harness their structural\nnetwork positions of a blogosphere. We collated individual characteristics of\n165 bloggers who blogged about economics, and then analysed the ways they\nmaintained the contents of their blogs. We used network analysis and monomial\nlogistic regression to test our model predictions. Our findings show that in\ncontrast to less attractive blogs, bloggers who are mindful of their peers\ncontents as a means of maintaining network positions attract a significantly\nhigher level of traffic to their blogs. This agentive perspective offers\npractical insights into how nodal preferences can be reversed in blog\nmanagement. We conclude the paper by discussing contributions to theory and\nfuture research.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 16:33:06 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Santos", "Carlos Denner dos", ""], ["Castro", "Isadora", ""], ["Kuk", "George", ""], ["Onoyama", "Silvia", ""], ["Moreira", "Marina", ""]]}, {"id": "2006.16960", "submitter": "Martina Karl", "authors": "Kilian Holzapfel, Martina Karl, Linus Lotz, Georg Carle, Christian\n  Djeffal, Christian Fruck, Christian Haack, Dirk Heckmann, Philipp H. Kindt,\n  Michael K\\\"oppl, Patrick Krause, Lolian Shtembari, Lorenz Marx, Stephan\n  Meighen-Berger, Birgit Neumair, Matthias Neumair, Julia Pollmann, Tina\n  Pollmann, Elisa Resconi, Stefan Sch\\\"onert, Andrea Turcati, Christoph\n  Wiesinger, Giovanni Zattera, Christopher Allan, Esteban Barco, Kai\n  Bitterschulte, J\\\"orn Buchwald, Clara Fischer, Judith Gampe, Martin H\\\"acker,\n  Jasin Islami, Anatol Pomplun, Sebastian Preisner, Nele Quast, Christian\n  Romberg, Christoph Steinlehner, Tjark Ziehm", "title": "Digital Contact Tracing Service: An improved decentralized design for\n  privacy and effectiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a decentralized digital contact tracing service that preserves the\nusers' privacy by design while complying to the highest security standards. Our\napproach is based on Bluetooth and measures actual encounters of people, the\ncontact time period, and estimates the proximity of the contact. We trace the\nusers' contacts and the possible spread of infectious diseases while preventing\nlocation tracking of users, protecting their data and identity. We verify and\nimprove the impact of tracking based on epidemiological models. We compare a\ncentralized and decentralized approach on a legal perspective and find a\ndecentralized approach preferable considering proportionality and data\nminimization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 13:12:07 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Holzapfel", "Kilian", ""], ["Karl", "Martina", ""], ["Lotz", "Linus", ""], ["Carle", "Georg", ""], ["Djeffal", "Christian", ""], ["Fruck", "Christian", ""], ["Haack", "Christian", ""], ["Heckmann", "Dirk", ""], ["Kindt", "Philipp H.", ""], ["K\u00f6ppl", "Michael", ""], ["Krause", "Patrick", ""], ["Shtembari", "Lolian", ""], ["Marx", "Lorenz", ""], ["Meighen-Berger", "Stephan", ""], ["Neumair", "Birgit", ""], ["Neumair", "Matthias", ""], ["Pollmann", "Julia", ""], ["Pollmann", "Tina", ""], ["Resconi", "Elisa", ""], ["Sch\u00f6nert", "Stefan", ""], ["Turcati", "Andrea", ""], ["Wiesinger", "Christoph", ""], ["Zattera", "Giovanni", ""], ["Allan", "Christopher", ""], ["Barco", "Esteban", ""], ["Bitterschulte", "Kai", ""], ["Buchwald", "J\u00f6rn", ""], ["Fischer", "Clara", ""], ["Gampe", "Judith", ""], ["H\u00e4cker", "Martin", ""], ["Islami", "Jasin", ""], ["Pomplun", "Anatol", ""], ["Preisner", "Sebastian", ""], ["Quast", "Nele", ""], ["Romberg", "Christian", ""], ["Steinlehner", "Christoph", ""], ["Ziehm", "Tjark", ""]]}, {"id": "2006.16964", "submitter": "Longbing Cao", "authors": "Longbing Cao", "title": "Data Science: Nature and Pitfalls", "comments": null, "journal-ref": "IEEE Intelligent Systems, Volume: 31, Issue: 5, 66-75, 2016", "doi": "10.1109/MIS.2016.86", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data science is creating very exciting trends as well as significant\ncontroversy. A critical matter for the healthy development of data science in\nits early stages is to deeply understand the nature of data and data science,\nand to discuss the various pitfalls. These important issues motivate the\ndiscussions in this article.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 02:06:54 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Cao", "Longbing", ""]]}, {"id": "2006.16965", "submitter": "Myeong Lee", "authors": "Myeong Lee, Seongkyu Lee, Seonghoon Kim and Noseong Park", "title": "Human Mobility during COVID-19 in the Context of Mild Social Distancing:\n  Implications for Technological Interventions", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The COVID-19 pandemic has brought both tangible and intangible damage to our\nsociety. Many researchers studied about its societal impacts in the countries\nthat had implemented strong social distancing measures such as stay-at-home\norders. Among them, human mobility has been studied extensively due to its\nimportance in flattening the curve. However, mobility has not been actively\nstudied in the context of mild social distancing. Insufficient understanding of\nhuman mobility in diverse contexts might provide limited implications for any\ntechnological interventions to alleviate the situation. To this end, we\ncollected a dataset consisting of more than 1M daily smart device users in the\nthird-largest city of South Korea, which has implemented mild social distancing\npolicies. We analyze how COVID-19 shaped human mobility in the city from\ngeographical, socio-economic, and socio-political perspectives. We also examine\nmobility changes for points of interest and special occasions such as\ntransportation stations and the case of legislative elections. We identify a\ntypology of populations through these analyses as a means to provide design\nimplications for technological interventions. This paper contributes to social\nsciences through in-depth analyses of human mobility and to the CSCW community\nwith new design challenges and potential implications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 20:50:15 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 03:36:51 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Lee", "Myeong", ""], ["Lee", "Seongkyu", ""], ["Kim", "Seonghoon", ""], ["Park", "Noseong", ""]]}, {"id": "2006.16966", "submitter": "Longbing Cao", "authors": "Longbing Cao", "title": "Data Science: Challenges and Directions", "comments": null, "journal-ref": "Communications of the ACM, Vol. 60 No. 8, Pages 59-68, 2017", "doi": "10.1145/3015456", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While data science has emerged as a contentious new scientific field,\nenormous debates and discussions have been made on it why we need data science\nand what makes it as a science. In reviewing hundreds of pieces of literature\nwhich include data science in their titles, we find that the majority of the\ndiscussions essentially concern statistics, data mining, machine learning, big\ndata, or broadly data analytics, and only a limited number of new data-driven\nchallenges and directions have been explored. In this paper, we explore the\nintrinsic challenges and directions inspired by comprehensively exploring the\ncomplexities and intelligence embedded in data science problems. We focus on\nthe research and innovation challenges inspired by the nature of data science\nproblems as complex systems, and the methodologies for handling such systems.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 01:49:00 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Cao", "Longbing", ""]]}]