[{"id": "2007.00088", "submitter": "Hansol Lee", "authors": "Hansol Lee and Ren\\'e F. Kizilcec", "title": "Evaluation of Fairness Trade-offs in Predicting Student Success", "comments": "FATED (Fairness, Accountability, and Transparency in Educational\n  Data) Workshop at EDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Predictive models for identifying at-risk students early can help teaching\nstaff direct resources to better support them, but there is a growing concern\nabout the fairness of algorithmic systems in education. Predictive models may\ninadvertently introduce bias in who receives support and thereby exacerbate\nexisting inequities. We examine this issue by building a predictive model of\nstudent success based on university administrative records. We find that the\nmodel exhibits gender and racial bias in two out of three fairness measures\nconsidered. We then apply post-hoc adjustments to improve model fairness to\nhighlight trade-offs between the three fairness measures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 20:03:18 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Lee", "Hansol", ""], ["Kizilcec", "Ren\u00e9 F.", ""]]}, {"id": "2007.00177", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Dylan Turpin, Animesh Garg, Ashton Anderson", "title": "De-anonymization of authors through arXiv submissions during\n  double-blind review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the effects of releasing arXiv preprints of\npapers that are undergoing a double-blind review process. In particular, we ask\nthe following research question: What is the relation between de-anonymization\nof authors through arXiv preprints and acceptance of a research paper at a\n(nominally) double-blind venue? Under two conditions: papers that are released\non arXiv before the review phase and papers that are not, we examine the\ncorrelation between the reputation of their authors with the review scores and\nacceptance decisions. By analyzing a dataset of ICLR 2020 and ICLR 2019\nsubmissions (n=5050), we find statistically significant evidence of positive\ncorrelation between percentage acceptance and papers with high reputation\nreleased on arXiv. In order to understand this observed association better, we\nperform additional analyses based on self-specified confidence scores of\nreviewers and observe that less confident reviewers are more likely to assign\nhigh review scores to papers with well known authors and low review scores to\npapers with less known authors, where reputation is quantified in terms of\nnumber of Google Scholar citations. We emphasize upfront that our results are\npurely correlational and we neither can nor intend to make any causal claims. A\nblog post accompanying the paper and our scraping code will be linked in the\nproject website https://sites.google.com/view/deanon-arxiv/home\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 01:40:06 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Turpin", "Dylan", ""], ["Garg", "Animesh", ""], ["Anderson", "Ashton", ""]]}, {"id": "2007.00251", "submitter": "Vedant Nanda", "authors": "Vedant Nanda, Till Speicher, John P. Dickerson, Krishna P. Gummadi,\n  Muhammad Bilal Zafar", "title": "Unifying Model Explainability and Robustness via Machine-Checkable\n  Concepts", "comments": "22 pages, 12 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks (DNNs) get adopted in an ever-increasing number of\napplications, explainability has emerged as a crucial desideratum for these\nmodels. In many real-world tasks, one of the principal reasons for requiring\nexplainability is to in turn assess prediction robustness, where predictions\n(i.e., class labels) that do not conform to their respective explanations\n(e.g., presence or absence of a concept in the input) are deemed to be\nunreliable. However, most, if not all, prior methods for checking\nexplanation-conformity (e.g., LIME, TCAV, saliency maps) require significant\nmanual intervention, which hinders their large-scale deployability. In this\npaper, we propose a robustness-assessment framework, at the core of which is\nthe idea of using machine-checkable concepts. Our framework defines a large\nnumber of concepts that the DNN explanations could be based on and performs the\nexplanation-conformity check at test time to assess prediction robustness. Both\nsteps are executed in an automated manner without requiring any human\nintervention and are easily scaled to datasets with a very large number of\nclasses. Experiments on real-world datasets and human surveys show that our\nframework is able to enhance prediction robustness significantly: the\npredictions marked to be robust by our framework have significantly higher\naccuracy and are more robust to adversarial perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 05:21:16 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 07:33:15 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Nanda", "Vedant", ""], ["Speicher", "Till", ""], ["Dickerson", "John P.", ""], ["Gummadi", "Krishna P.", ""], ["Zafar", "Muhammad Bilal", ""]]}, {"id": "2007.00480", "submitter": "Piyush Yadav", "authors": "Piyush Yadav, Shamsuddin Ladha, Shailesh Deshpande, Edward Curry", "title": "Computational Model for Urban Growth Using Socioeconomic Latent\n  Parameters", "comments": "12 pages", "journal-ref": "ECML PKDD 2018 Lecture Notes in Computer Science vol 11329\n  Springer Cham", "doi": "10.1007/978-3-030-13453-2_6", "report-no": null, "categories": "stat.AP cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land use land cover changes (LULCC) are generally modeled using multi-scale\nspatio-temporal variables. Recently, Markov Chain (MC) has been used to model\nLULCC. However, the model is derived from the proportion of LULCC observed over\na given period and it does not account for temporal factors such as\nmacro-economic, socio-economic, etc. In this paper, we present a richer model\nbased on Hidden Markov Model (HMM), grounded in the common knowledge that\neconomic, social and LULCC processes are tightly coupled. We propose a HMM\nwhere LULCC classes represent hidden states and temporal fac-tors represent\nemissions that are conditioned on the hidden states. To our knowledge, HMM has\nnot been used in LULCC models in the past. We further demonstrate its\nintegration with other spatio-temporal models such as Logistic Regression. The\nintegrated model is applied on the LULCC data of Pune district in the state of\nMaharashtra (India) to predict and visualize urban LULCC over the past 14\nyears. We observe that the HMM integrated model has improved prediction\naccuracy as compared to the corresponding MC integrated model\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 13:38:17 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Yadav", "Piyush", ""], ["Ladha", "Shamsuddin", ""], ["Deshpande", "Shailesh", ""], ["Curry", "Edward", ""]]}, {"id": "2007.00492", "submitter": "Shaoqing Yuan", "authors": "Shaoqing Yuan, Parminder Bhatia, Busra Celikkaya, Haiyang Liu,\n  Kyunghwan Choi", "title": "Towards User Friendly Medication Mapping Using Entity-Boosted Two-Tower\n  Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in medical entity linking have been applied in the area\nof scientific literature and social media data. However, with the adoption of\ntelemedicine and conversational agents such as Alexa in healthcare settings,\nmedical name inference has become an important task. Medication name inference\nis the task of mapping user friendly medication names from a free-form text to\na concept in a normalized medication list. This is challenging due to the\ndifferences in the use of medical terminology from health care professionals\nand user conversations coming from the lay public. We begin with mapping\ndescriptive medication phrases (DMP) to standard medication names (SMN). Given\nthe prescriptions of each patient, we want to provide them with the flexibility\nof referring to the medication in their preferred ways. We approach this as a\nranking problem which maps SMN to DMP by ordering the list of medications in\nthe patient's prescription list obtained from pharmacies. Furthermore, we\nleveraged the output of intermediate layers and performed medication\nclustering. We present the Medication Inference Model (MIM) achieving\nstate-of-the-art results. By incorporating medical entities based attention, we\nhave obtained further improvement for ranking models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 18:56:44 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2020 18:44:40 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Yuan", "Shaoqing", ""], ["Bhatia", "Parminder", ""], ["Celikkaya", "Busra", ""], ["Liu", "Haiyang", ""], ["Choi", "Kyunghwan", ""]]}, {"id": "2007.00700", "submitter": "Abhishek Gupta", "authors": "Marianna Bergamaschi Ganapini (1 and 2), Camylle Lanteigne (1 and 3),\n  Abhishek Gupta (1 and 4) ((1) Montreal AI Ethics Institute, (2) Union\n  College, (3) McGill University, (4) Microsoft)", "title": "Response by the Montreal AI Ethics Institute to the Santa Clara\n  Principles on Transparency and Accountability in Online Content Moderation", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In April 2020, the Electronic Frontier Foundation (EFF) publicly called for\ncomments on expanding and improving the Santa Clara Principles on Transparency\nand Accountability (SCP), originally published in May 2018. The Montreal AI\nEthics Institute (MAIEI) responded to this call by drafting a set of\nrecommendations based on insights and analysis by the MAIEI staff and\nsupplemented by workshop contributions from the AI Ethics community convened\nduring two online public consultation workshops.\n  In its submission, MAIEI provides 12 overarching recommendations for the SCP,\nthese include: 1) ensure there is more diversity in the content moderation\nprocess; 2) increase transparency into how platforms guide content-ranking; 3)\ndisclose anonymized data on the training and/or cultural background of the\ncontent moderators for a platform; 4) tailor content moderation tools for\nspecific issues; 5) draft specific guidelines for messaging applications with\nregards to data protection in content moderation; 6) take into account cultural\ndifferences relevant to what constitutes acceptable behavior online; 7) ensure\nplatforms are transparent in regards to political advertising; 8) ensure\ngreater transparency into the user-generated flagging/reporting systems\ndeployed by a platform; 9) clarify if user content is flagged or reported\nthrough an automated system; 10) provide more data on the types of content\nremoved from platforms; 11) provide clear guidelines on the appeal process, as\nwell as data on prior appeals; 12) create a system for periodically revisiting\nthe SCP so it reflects various technological advancements, modifications in law\nand policy, as well as changing trends or movements in content moderation.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 18:46:08 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Ganapini", "Marianna Bergamaschi", "", "1 and 2"], ["Lanteigne", "Camylle", "", "1 and 3"], ["Gupta", "Abhishek", "", "1 and 4"]]}, {"id": "2007.00740", "submitter": "Mahmoud AbdelRahman", "authors": "Mahmoud Abdelrahman, Adrian Chong, and Clayton Miller", "title": "Build2Vec: Building Representation in Vector Space", "comments": "4 pages, 9 figures, 24 referencess", "journal-ref": "http://simaud.org/2020/proceedings/102.pdf", "doi": null, "report-no": null, "categories": "cs.CY cs.DM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we represent a methodology of a graph embeddings algorithm\nthat is used to transform labeled property graphs obtained from a Building\nInformation Model (BIM). Industrial Foundation Classes (IFC) is a standard\nschema for BIM, which is utilized to convert the building data into a graph\nrepresentation. We used node2Vec with biased random walks to extract semantic\nsimilarities between different building components and represent them in a\nmulti-dimensional vector space. A case study implementation is conducted on a\nnet-zero-energy building located at the National University of Singapore\n(SDE4). This approach shows promising machine learning applications in\ncapturing the semantic relations and similarities of different building\nobjects, more specifically, spatial and spatio-temporal data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 20:39:39 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Abdelrahman", "Mahmoud", ""], ["Chong", "Adrian", ""], ["Miller", "Clayton", ""]]}, {"id": "2007.00750", "submitter": "Caitrin Armstrong", "authors": "Caitrin Armstrong and Derek Ruths", "title": "Legends: Folklore on Reddit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Reddit legends, a collection of venerated old\nposts that have become famous on Reddit. To establish the utility of Reddit\nlegends for both computational science/HCI and folkloristics, we investigate\ntwo main questions: (1) whether they can be considered folklore, i.e. if they\nhave consistent form, cultural significance, and undergo spontaneous\ntransmission, and (2) whether they can be studied in a systematic manner.\nThrough several subtasks, including the creation of a typology, an analysis of\nreferences to Reddit legends, and an examination of some of the textual\ncharacteristics of referencing behaviour, we show that Reddit legends can\nindeed be considered as folklore and that they are amendable to systematic\ntext-based approaches. We discuss how these results will enable future analyses\nof folklore on Reddit, including tracking subreddit-wide and individual-user\nbehaviour, and the relationship of this behaviour to other cultural markers.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 20:55:41 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Armstrong", "Caitrin", ""], ["Ruths", "Derek", ""]]}, {"id": "2007.00854", "submitter": "Vanessa Teague", "authors": "Michelle Blom, Andrew Conway, Peter J. Stuckey, Vanessa Teague, Damjan\n  Vukcevic", "title": "Random errors are not necessarily politically neutral", "comments": null, "journal-ref": "Electronic Voting, E-Vote-ID 2020, Lecture Notes in Computer\n  Science 12455 (2020) 19-35", "doi": "10.1007/978-3-030-60347-2_2", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Errors are inevitable in the implementation of any complex process. Here we\nexamine the effect of random errors on Single Transferable Vote (STV)\nelections, a common approach to deciding multi-seat elections. It is usually\nexpected that random errors should have nearly equal effects on all candidates,\nand thus be fair. We find to the contrary that random errors can introduce\nsystematic bias into election results. This is because, even if the errors are\nrandom, votes for different candidates occur in different patterns that are\naffected differently by random errors. In the STV context, the most important\neffect of random errors is to invalidate the ballot. This removes far more\nvotes for those candidates whose supporters tend to list a lot of preferences,\nbecause their ballots are much more likely to be invalidated by random error.\nDifferent validity rules for different voting styles mean that errors are much\nmore likely to penalise some types of votes than others. For close elections\nthis systematic bias can change the result of the election.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 03:37:48 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 22:52:29 GMT"}, {"version": "v3", "created": "Mon, 28 Sep 2020 07:10:38 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Blom", "Michelle", ""], ["Conway", "Andrew", ""], ["Stuckey", "Peter J.", ""], ["Teague", "Vanessa", ""], ["Vukcevic", "Damjan", ""]]}, {"id": "2007.01059", "submitter": "Dima Kagan", "authors": "Dima Kagan, Galit Fuhrmann Alpert, Michael Fire", "title": "Zooming Into Video Conferencing Privacy and Security Threats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic outbreak, with its related social distancing and\nshelter-in-place measures, has dramatically affected ways in which people\ncommunicate with each other, forcing people to find new ways to collaborate,\nstudy, celebrate special occasions, and meet with family and friends. One of\nthe most popular solutions that have emerged is the use of video conferencing\napplications to replace face-to-face meetings with virtual meetings. This\nresulted in unprecedented growth in the number of video conferencing users. In\nthis study, we explored privacy issues that may be at risk by attending virtual\nmeetings. We extracted private information from collage images of meeting\nparticipants that are publicly posted on the Web. We used image processing,\ntext recognition tools, as well as social network analysis to explore our web\ncrawling curated dataset of over 15,700 collage images, and over 142,000 face\nimages of meeting participants. We demonstrate that video conference users are\nfacing prevalent security and privacy threats. Our results indicate that it is\nrelatively easy to collect thousands of publicly available images of video\nconference meetings and extract personal information about the participants,\nincluding their face images, age, gender, usernames, and sometimes even full\nnames. This type of extracted data can vastly and easily jeopardize people's\nsecurity and privacy both in the online and real-world, affecting not only\nadults but also more vulnerable segments of society, such as young children and\nolder adults. Finally, we show that cross-referencing facial image data with\nsocial network data may put participants at additional privacy risks they may\nnot be aware of and that it is possible to identify users that appear in\nseveral video conference meetings, thus providing a potential to maliciously\naggregate different sources of information about a target individual.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 12:31:54 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Kagan", "Dima", ""], ["Alpert", "Galit Fuhrmann", ""], ["Fire", "Michael", ""]]}, {"id": "2007.01074", "submitter": "Hugo Court\\'e", "authors": "Hugo Court\\'e, Titouan-Joseph Revol, Cl\\'ement Lagneau-Donzelle,\n  Albert Nicol\\'as L\\'opez", "title": "The use of personal data in French public services: e-mails, websites,\n  apps", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The study we carried out enabled us to extract some conclusions, which are\ncontrasted with the results obtained. First, in the field of mobile\napplications, permissions and tracers are almost always present. Android, as\nfar as PlayStore permissions are concerned, is the main entity concerning this\ndomain. Under the pretext of guaranteeing an optimal functioning of the\napplications, these permissions can sometimes hide some very dangerous tracing\nmeans for the users. Google, a major player in tracing and a major power in the\nstorage of information of net users, is behind most tracers. Trackers have two\nmain missions. On the one hand, they allow the application to work, like\nFacebook's trackers that are used to log into the application or Google's\ntrackers that allow either to trace crashes or to analyze how the application\nis used. On the other hand, they allow you to manage the advertising that\nappears in the application, which can be targeted or not. Regarding tracking in\nemails, we find stakeholders quite present: Google, Xiti and Iroquois. Even if\nthey are most often used in the context of hearing measurements, they are\npresent in public service emails. Finally with websites, Google is very present\nin government websites. We find common actors for applications and emails such\nas GAFAM or Xiti. Most of the cookies present are for audience measurement and\nadvertising display which is often targeted.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 13:04:53 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 07:57:29 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Court\u00e9", "Hugo", ""], ["Revol", "Titouan-Joseph", ""], ["Lagneau-Donzelle", "Cl\u00e9ment", ""], ["L\u00f3pez", "Albert Nicol\u00e1s", ""]]}, {"id": "2007.01100", "submitter": "Xiao Huang", "authors": "Xiao Huang, Zhenlong Li, Yuqin Jiang, Xiaoming Li, Dwayne Porter", "title": "Twitter, human mobility, and COVID-19", "comments": "27 pages, 9 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The outbreak of COVID-19 highlights the need for a more harmonized, less\nprivacy-concerning, easily accessible approach to monitoring the human mobility\nthat has been proved to be associated with the viral transmission. In this\nstudy, we analyzed 587 million tweets worldwide to see how global collaborative\nefforts in reducing human mobility are reflected from the user-generated\ninformation at the global, country, and the U.S. state scale. Considering the\nmultifaceted nature of mobility, we propose two types of distance: the\nsingle-day distance and the cross-day distance. To quantify the responsiveness\nin certain geographical regions, we further propose a mobility-based responsive\nindex (MRI) that captures the overall degree of mobility changes within a time\nwindow. The results suggest that mobility patterns obtained from Twitter data\nare amendable to quantitatively reflect the mobility dynamics. Globally, the\nproposed two distances had greatly deviated from their baselines after March\n11, 2020, when WHO declared COVID-19 as a pandemic. The considerably less\nperiodicity after the declaration suggests that the protection measures have\nobviously affected people's travel routines. The country scale comparisons\nreveal the discrepancies in responsiveness, evidenced by the contrasting\nmobility patterns in different epidemic phases. We find that the triggers of\nmobility changes correspond well with the national announcements of mitigation\nmeasures. In the U.S., the influence of the COVID-19 pandemic on mobility is\ndistinct. However, the impacts varied substantially among states. The strong\nmobility recovering momentum is further fueled by the Black Lives Matter\nprotests, potentially fostering the second wave of infections in the U.S.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 23:21:03 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Huang", "Xiao", ""], ["Li", "Zhenlong", ""], ["Jiang", "Yuqin", ""], ["Li", "Xiaoming", ""], ["Porter", "Dwayne", ""]]}, {"id": "2007.01202", "submitter": "Corinna Hertweck", "authors": "Corinna Hertweck, Carlos Castillo, Michael Mathioudakis", "title": "Towards Data-Driven Affirmative Action Policies under Uncertainty", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study university admissions under a centralized system that\nuses grades and standardized test scores to match applicants to university\nprograms. We consider affirmative action policies that seek to increase the\nnumber of admitted applicants from underrepresented groups. Since such a policy\nhas to be announced before the start of the application period, there is\nuncertainty about the score distribution of the students applying to each\nprogram. This poses a difficult challenge for policy-makers. We explore the\npossibility of using a predictive model trained on historical data to help\noptimize the parameters of such policies.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 15:37:16 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Hertweck", "Corinna", ""], ["Castillo", "Carlos", ""], ["Mathioudakis", "Michael", ""]]}, {"id": "2007.01242", "submitter": "Benjamin Zorn", "authors": "Benjamin Zorn, Tom Conte, Keith Marzullo, and Suresh\n  Venkatasubramanian", "title": "Evolving Methods for Evaluating and Disseminating Computing Research", "comments": "A Computing Community Consortium (CCC) white paper, 12 pages", "journal-ref": null, "doi": null, "report-no": "ccc2020whitepaper_2", "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social and technical trends have significantly changed methods for evaluating\nand disseminating computing research. Traditional venues for reviewing and\npublishing, such as conferences and journals, worked effectively in the past.\nRecently, trends have created new opportunities but also put new pressures on\nthe process of review and dissemination. For example, many conferences have\nseen large increases in the number of submissions. Likewise, dissemination of\nresearch ideas has become dramatically through publication venues such as\narXiv.org and social media networks. While these trends predate COVID-19, the\npandemic could accelerate longer term changes. Based on interviews with leading\nacademics in computing research, our findings include: (1) Trends impacting\ncomputing research are largely positive and have increased the participation,\nscope, accessibility, and speed of the research process. (2) Challenges remain\nin securing the integrity of the process, including addressing ways to scale\nthe review process, avoiding attempts to misinform or confuse the dissemination\nof results, and ensuring fairness and broad participation in the process\nitself. Based on these findings, we recommend: (1) Regularly polling members of\nthe computing research community, including program and general conference\nchairs, journal editors, authors, reviewers, etc., to identify specific\nchallenges they face to better understand these issues. (2) An influential\nbody, such as the Computing Research Association regularly issues a \"State of\nthe Computing Research Enterprise\" report to update the community on trends,\nboth positive and negative, impacting the computing research enterprise. (3) A\ndeeper investigation, specifically to better understand the influence that\nsocial media and preprint archives have on computing research, is conducted.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 16:50:28 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zorn", "Benjamin", ""], ["Conte", "Tom", ""], ["Marzullo", "Keith", ""], ["Venkatasubramanian", "Suresh", ""]]}, {"id": "2007.01382", "submitter": "Srinivasan Iyengar", "authors": "Srinivasan Iyengar, Stephen Lee, David Irwin, Prashant Shenoy,\n  Benjamin Weil", "title": "WattScale: A Data-driven Approach for Energy Efficiency Analytics of\n  Buildings at Scale", "comments": "This paper appeared in the Journal ACM Transactions on Data Science", "journal-ref": null, "doi": "10.1145/3406961", "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buildings consume over 40% of the total energy in modern societies, and\nimproving their energy efficiency can significantly reduce our energy\nfootprint. In this paper, we present \\texttt{WattScale}, a data-driven approach\nto identify the least energy-efficient buildings from a large population of\nbuildings in a city or a region. Unlike previous methods such as least-squares\nthat use point estimates, \\texttt{WattScale} uses Bayesian inference to capture\nthe stochasticity in the daily energy usage by estimating the distribution of\nparameters that affect a building. Further, it compares them with similar homes\nin a given population. \\texttt{WattScale} also incorporates a fault detection\nalgorithm to identify the underlying causes of energy inefficiency. We validate\nour approach using ground truth data from different geographical locations,\nwhich showcases its applicability in various settings. \\texttt{WattScale} has\ntwo execution modes -- (i) individual, and (ii) region-based, which we\nhighlight using two case studies. For the individual execution mode, we present\nresults from a city containing >10,000 buildings and show that more than half\nof the buildings are inefficient in one way or another indicating a significant\npotential from energy improvement measures. Additionally, we provide probable\ncause of inefficiency and find that 41\\%, 23.73\\%, and 0.51\\% homes have poor\nbuilding envelope, heating, and cooling system faults, respectively. For the\nregion-based execution mode, we show that \\texttt{WattScale} can be extended to\nmillions of homes in the US due to the recent availability of representative\nenergy datasets.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 20:45:33 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Iyengar", "Srinivasan", ""], ["Lee", "Stephen", ""], ["Irwin", "David", ""], ["Shenoy", "Prashant", ""], ["Weil", "Benjamin", ""]]}, {"id": "2007.01404", "submitter": "Chaoyang Song", "authors": "Chaoyang Song, Jianxi Luo, Katja H\\\"oltt\\\"a-Otto, Warren Seering,\n  Kevin Otto", "title": "Crowdfunding for Design Innovation: Prediction Model with Critical\n  Factors", "comments": "12 pages, 3 figures, 7 tables, accepted by IEEE TEM", "journal-ref": null, "doi": "10.1109/TEM.2020.3001764", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reward-based crowdfunding campaigns have emerged as an innovative\napproach for validating demands, discovering early adopters, and seeking\nlearning and feedback in the design processes of innovative products. However,\ncrowdfunding campaigns for innovative products are faced with a high degree of\nuncertainty and suffer meager rates of success to fulfill their values for\ndesign. To guide designers and innovators for crowdfunding campaigns, this\npaper presents a data-driven methodology to build a prediction model with\ncritical factors for crowdfunding success, based on public online crowdfunding\ncampaign data. Specifically, the methodology filters 26 candidate factors in\nthe Real-Win-Worth framework and identifies the critical ones via step-wise\nregression to predict the amount of crowdfunding. We demonstrate the\nmethodology via deriving prediction models and identifying essential factors\nfrom 3D printer and smartwatch campaign data on Kickstarter and Indiegogo. The\ncritical factors can guide campaign developments, and the prediction model may\nevaluate crowdfunding potential of innovations in contexts, to increase the\nchance of crowdfunding success of innovative products.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 21:44:40 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Song", "Chaoyang", ""], ["Luo", "Jianxi", ""], ["H\u00f6ltt\u00e4-Otto", "Katja", ""], ["Seering", "Warren", ""], ["Otto", "Kevin", ""]]}, {"id": "2007.01413", "submitter": "Ridwan Alam", "authors": "Ridwan Alam, David B. Peden, and John C. Lach", "title": "Wearable Respiration Monitoring: Interpretable Inference with Context\n  and Sensor Biomarkers", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": "10.1109/JBHI.2020.3035776", "report-no": null, "categories": "eess.SP cs.AI cs.CY cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Breathing rate (BR), minute ventilation (VE), and other respiratory\nparameters are essential for real-time patient monitoring in many acute health\nconditions, such as asthma. The clinical standard for measuring respiration,\nnamely Spirometry, is hardly suitable for continuous use. Wearables can track\nmany physiological signals, like ECG and motion, yet not respiration. Deriving\nrespiration from other modalities has become an area of active research. In\nthis work, we infer respiratory parameters from wearable ECG and wrist motion\nsignals. We propose a modular and generalizable classification-regression\npipeline to utilize available context information, such as physical activity,\nin learning context-conditioned inference models. Morphological and power\ndomain novel features from the wearable ECG are extracted to use with these\nmodels. Exploratory feature selection methods are incorporated in this pipeline\nto discover application-specific interpretable biomarkers. Using data from 15\nsubjects, we evaluate two implementations of the proposed pipeline: for\ninferring BR and VE. Each implementation compares generalized linear model,\nrandom forest, support vector machine, Gaussian process regression, and\nneighborhood component analysis as contextual regression models. Permutation,\nregularization, and relevance determination methods are used to rank the ECG\nfeatures to identify robust ECG biomarkers across models and activities. This\nwork demonstrates the potential of wearable sensors not only in continuous\nmonitoring, but also in designing biomarker-driven preventive measures.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 22:12:49 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Alam", "Ridwan", ""], ["Peden", "David B.", ""], ["Lach", "John C.", ""]]}, {"id": "2007.01561", "submitter": "Alberto Giaretta", "authors": "Matthias Forstmann, Alberto Giaretta, and Jennifer Renoux", "title": "Users' Concern for Privacy in Context-Aware Reasoning Systems", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-aware reasoning systems allow drawing sophisticated inferences about\nusers' behaviour and physiological condition, by aggregating data from\nseemingly unrelated sources. We conducted a general population online survey to\nevaluate users' concern about the privacy of data gathered by these systems. We\nfound that people are more concerned about third parties accessing data\ngathered by environmental sensors as compared to physiological sensors.\nParticipants also indicated greater concern about unfamiliar third parties\n(e.g., private companies) as opposed to familiar third parties (e.g.,\nrelatives). We further found that these concerns are predicted and (to a lesser\ndegree) causally affected by people's beliefs about how much can be inferred\nfrom these types of data, as well as by their background in computer science.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 09:13:57 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Forstmann", "Matthias", ""], ["Giaretta", "Alberto", ""], ["Renoux", "Jennifer", ""]]}, {"id": "2007.01605", "submitter": "Ricky Lamberty", "authors": "Ricky Lamberty, Alexander Poddey", "title": "Regulation conform DLT-operable payment adapter based on trustless -\n  justified trust combined generalized state channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open technologies, decentralized computation and intelligent applications\nenable the third-generation web, Web 3.0, thereby digitizing whole industries.\nThe emerging Economy of Things (EoT) will be based on software agents running\non peer-to-peer trustless networks that require a programmable, regulation\nconform means of payment. We give an overview of current solutions that differ\nin their fundamental values and technological possibilities, like e.g.\nprivate-issued stablecoins, DLT-issued electronic money and genuine\ncryptocurrencies. Based on this analysis, we present the concept of justified\ntrust and propose to combine the strengths of the crypto based, decentralized\ntrustless elements with established and well regulated means of payment, based\non this concept, via a secure external re-balancing interface.\n  Combining the advantages, e.g. lightweight, trustless, efficient high\nfrequency micro state transfers on the one hand, and ease of use, widely\nspread, accepted alignment to a multitude of regulative requirements, on the\nother hand, while neither leading into a lock-in in any of the proposed\nsolutions, nor undermining the basic principles of the crypto-movement or\nunnecessarily reinforcing the banking system provides a synergy and the\nnecessary flexibility for further evolution alongside the regulative framework.\nThis offers a regulation conform transitional solution that can be implemented\nin the short term, which enables companies to place their decentralized\nbusiness operations in a regulated environment.\n  The contribution of our work is twofold: First, we illustrate and discuss\ndifferent DLT-operable means of payment. Second, our research proposes a novel\nhybrid payment solution by interfacing trustless with justified trust combined\ngeneralized state channels.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 10:45:55 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Lamberty", "Ricky", ""], ["Poddey", "Alexander", ""]]}, {"id": "2007.01688", "submitter": "Louis Beziaud", "authors": "Tristan Allard (DRUID), Louis B\\'eziaud (LATECE Laboratory - UQAM\n  Montreal, DRUID), S\\'ebastien Gambs (LATECE Laboratory - UQAM Montreal)", "title": "Online publication of court records: circumventing the\n  privacy-transparency trade-off", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The open data movement is leading to the massive publishing of court records\nonline, increasing transparency and accessibility of justice, and to the design\nof legal technologies building on the wealth of legal data available. However,\nthe sensitive nature of legal decisions also raises important privacy issues.\nCurrent practices solve the resulting privacy versus transparency trade-off by\ncombining access control with (manual or semi-manual) text redaction. In this\nwork, we claim that current practices are insufficient for coping with massive\naccess to legal data (restrictive access control policies is detrimental to\nopenness and to utility while text redaction is unable to provide sound privacy\nprotection) and advocate for a in-tegrative approach that could benefit from\nthe latest developments of the privacy-preserving data publishing domain. We\npresent a thorough analysis of the problem and of the current approaches, and\npropose a straw man multimodal architecture paving the way to a full-fledged\nprivacy-preserving legal data publishing system.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 13:58:01 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Allard", "Tristan", "", "DRUID"], ["B\u00e9ziaud", "Louis", "", "LATECE Laboratory - UQAM\n  Montreal, DRUID"], ["Gambs", "S\u00e9bastien", "", "LATECE Laboratory - UQAM Montreal"]]}, {"id": "2007.01823", "submitter": "Michael Soltys", "authors": "Michael Soltys and Katharine Soltys", "title": "WordPress on AWS: a Communication Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every organization needs to communicate with its audience, and social media\nis an attractive and inexpensive way to maintain dialogic communication. About\n1/3 of the Internet web pages are powered by WordPress, and about a million\ncompanies have moved their IT infrastructure to the AWS cloud. Together, AWS\nand WordPress offer an attractive, effective and inexpensive way for companies,\nboth large and small, to maintain their presence on the web.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 17:20:45 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Soltys", "Michael", ""], ["Soltys", "Katharine", ""]]}, {"id": "2007.02083", "submitter": "Gabriela Purri Rosas Gomes", "authors": "Gabriela Purri R. Gomes, Sydney Rubin, Leah I. Stein Duker, Donna\n  Benton, Andreas Kratky, Sze Yu A Chen, Maryalice Jordan-Marsh, and Marientina\n  Gotsis", "title": "Healing Spaces: Feasibility of a Multisensory Experience for Older\n  Adults with Advanced Dementia and their Caregivers", "comments": "PETRA 20: Proceedings of the 13th ACM International Conference on\n  PErvasive Technologies Related to Assistive Environments. June 2020. Article\n  No 24. Pages 1 to 9", "journal-ref": "2020. In Proceedings of the 13th ACM International Conference on\n  PErvasive Technologies Related to Assistive Environments (PETRA 20).\n  Association for Computing Machinery, New York, NY, USA, Article 24, 1 to 9", "doi": "10.1145/3389189.3392607", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healing Spaces proposes a new approach to multisensory interventions that\nshow potential in ameliorating the behavioral and psychological symptoms of\nadvanced dementia in older adults. Using smart technology, the project combines\nboth digital and physical components to transform spaces and create unified,\ncurated sensory experiences that provide meaningful context for interaction,\nand are easy for caregivers to deliver. A usability study was conducted for the\nHealing Spaces app followed by a feasibility evaluation of the full experience\nin a memory care facility recruiting caregivers, and residents in advanced\nstages of dementia. The feasibility evaluation successfully illuminated\nstrengths as well as areas for improvement for the Healing Spaces experience in\na memory care setting with older adults with advanced dementia. Caregivers and\nfacility managers expressed interest in continuing to use Healing Spaces with\nthe residents of the facility. Lessons learned about the technical and\nlogistical implementation of Healing Spaces are discussed, as well as future\ndirections for study design and potential therapeutic value of the experience.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 12:27:19 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Gomes", "Gabriela Purri R.", ""], ["Rubin", "Sydney", ""], ["Duker", "Leah I. Stein", ""], ["Benton", "Donna", ""], ["Kratky", "Andreas", ""], ["Chen", "Sze Yu A", ""], ["Jordan-Marsh", "Maryalice", ""], ["Gotsis", "Marientina", ""]]}, {"id": "2007.02124", "submitter": "Judy Gichoya", "authors": "Ningcheng Li, Guy Maresh, Maxwell Cretcher, Khashayar Farsad, Ramsey\n  Al-Hakim, John Kaufman, Judy Gichoya", "title": "A Modern Non-SQL Approach to Radiology-Centric Search Engine Design with\n  Clinical Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Healthcare data is increasing in size at an unprecedented speed with much\nattention on big data analysis and Artificial Intelligence application for\nquality assurance, clinical training, severity triaging, and decision support.\nRadiology is well-suited for innovation given its intrinsically paired\nlinguistic and visual data. Previous attempts to unlock this information\ngoldmine were encumbered by heterogeneity of human language, proprietary search\nalgorithms, and lack of medicine-specific search performance matrices. We\npresent a de novo process of developing a document-based, secure, efficient,\nand accurate search engine in the context of Radiology. We assess our\nimplementation of the search engine with comparison to pre-existing manually\ncollected clinical databases used previously for clinical research projects in\naddition to computational performance benchmarks and survey feedback. By\nleveraging efficient database architecture, search capability, and clinical\nthinking, radiologists are at the forefront of harnessing the power of\nhealthcare data.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 15:21:49 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Li", "Ningcheng", ""], ["Maresh", "Guy", ""], ["Cretcher", "Maxwell", ""], ["Farsad", "Khashayar", ""], ["Al-Hakim", "Ramsey", ""], ["Kaufman", "John", ""], ["Gichoya", "Judy", ""]]}, {"id": "2007.02149", "submitter": "Piyush Yadav", "authors": "Piyush Yadav, Dipto Sarkar, Shailesh Deshpande, Edward Curry", "title": "Human Assisted Artificial Intelligence Based Technique to Create Natural\n  Features for OpenStreetMap", "comments": "3 pages, 2 Figures, Submitted to FOSS4G Europe 2020 Academic Track\n  (Postponed to 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an AI-based technique using freely available\nsatellite images like Landsat and Sentinel to create natural features over OSM\nin congruence with human editors acting as initiators and validators. The\nmethod is based on Interactive Machine Learning technique where human inputs\nare coupled with the machine to solve complex problems efficiently as compare\nto pure autonomous process. We use a bottom-up approach where a machine\nlearning (ML) pipeline in loop with editors is used to extract classes using\nspectral signatures of images and later convert them to editable features to\ncreate natural features.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 17:26:46 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 18:33:35 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Yadav", "Piyush", ""], ["Sarkar", "Dipto", ""], ["Deshpande", "Shailesh", ""], ["Curry", "Edward", ""]]}, {"id": "2007.02161", "submitter": "Ellis Solaiman", "authors": "Bakri Awaji, Ellis Solaiman, Lindsay Marshall", "title": "Blockchain-Based Trusted Achievement Record System Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary purpose of this paper is to provide a design of a\nblockchain-based system, which produces a verifiable record of achievements.\nSuch a system has a wide range of potential benefits for students, employers\nand higher education institutions. A verifiable record of achievements enables\nstudents to present academic accomplishments to employers, within a trusted\nframework. Furthermore, the availability of such a record system would enable\nstudents to review their learning throughout their career, giving them a\nplatform on which to plan for their future accomplishments, both individually\nand with support from other parties (for example, academic advisors,\nsupervisors, or potential employers). The proposed system will help students in\nuniversities to increase their extra-curricular activities and improve\nnon-academic skills. Moreover, the system will facilitate communication between\nindustry, students, and universities for employment purposes and simplify the\nsearch for the most appropriate potential employees for the job.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 18:43:47 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Awaji", "Bakri", ""], ["Solaiman", "Ellis", ""], ["Marshall", "Lindsay", ""]]}, {"id": "2007.02162", "submitter": "Ellis Solaiman", "authors": "Bakri Awaji, Ellis Solaiman, Lindsay Marshall", "title": "Investigating the Requirements for Building a Blockchain- Based\n  Achievement Record System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A trusted achievement record is a secure system that aims to record and\nauthenticate certificates as well as key learning activities and achievements.\nThis paper intends to gather important information on the thoughts and outlooks\nof stakeholders on an achievement record system that uses blockchain and smart\ncontract technology. The system would allow stakeholders (for example\nemployers) to validate learning records. Two main aims are investigated. The\nfirst is to evaluate the suitability of the idea of building a trusted\nachievement record for learners in higher education, and to evaluate potential\nuser knowledge of blockchain technology. This is to ensure that a designed\nsystem is usable. The second aim includes an interview conducted with a small\ngroup of participants to gather information about the challenges individuals\nhave when creating, and reviewing CVs. Overall, 90% of participants agreed that\nthere was a strong need for a trusted achievement record. In addition, 93.64%\nof respondents stated that they felt it was invaluable to have a system that is\nusable by all stakeholders. When tackling the second aim it was found that a\nprimary challenge is lack of knowledge of blockchain and its complexity. From\nthe employers' perspective, there is a lack of trust due to inaccuracies when\nstudents describe skills and qualifications in their resumes.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 18:44:14 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Awaji", "Bakri", ""], ["Solaiman", "Ellis", ""], ["Marshall", "Lindsay", ""]]}, {"id": "2007.02163", "submitter": "Mohsin Ur Rahman", "authors": "Mohsin Ur Rahman", "title": "Scalable Role-based Access Control Using The EOS Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Role-based access control (RBAC) policies represent the rights of subjects in\nterms of roles to access resources. This research proposes a scalable, flexible\nand auditable RBAC system using the EOS blockchain platform to meet the\nsecurity requirements of organizations. The EOS blockchain platform for\ndeveloping smart contract and decentralized applications (DAPPs) aims to\naddress the scalability problem found in existing blockchain platforms. This\nsmart contract platform aims to eliminate transaction fees while conducting\nmillions of transactions per second. In our proposed approach, the EOS\nblockchain transparently stores RBAC policies. Administrative roles control\naccess to resources at a higher level according to the way organisations\nperform operations. An organisation creates roles, role hierarchies and\nconstraints to regulate user actions. Therefore, once an RBAC framework is\nestablished, the administrative user (issuer) only needs to grant and revoke\nroles to support changes in the organisational structure. Our proposed\nblockchain-based RBAC supports delegation capabilities using gaseless\ntransactions which makes it adoptable and appealing in a large number of\napplication scenarios. Our proposed solution is application-agnostic and\nwell-suited for diverse use cases. Existing state-of-the art security\nframeworks are not suitable due to the difficulty of scale, higher cost and\nsingle point of failure. Consequently, organisations demand a scalable,\ncost-effective and lightweight access control solution which can better protect\ntheir privacy as well. A proof of concept implementation is developed based on\nthe EOS blockchain. Our experimental results and analysis clearly show that our\nEOS blockchain-based RBAC outperforms existing blockchain platforms in terms of\ncost, latency, block generation time, contract execution time and throughput.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 18:45:14 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Rahman", "Mohsin Ur", ""]]}, {"id": "2007.02199", "submitter": "Kaylea Champion", "authors": "Kaylea Champion", "title": "Characterizing Online Vandalism: A Rational Choice Perspective", "comments": null, "journal-ref": null, "doi": "10.1145/3400806.3400813", "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  What factors influence the decision to vandalize? Although the harm is clear,\nthe benefit to the vandal is less clear. In many cases, the thing being damaged\nmay itself be something the vandal uses or enjoys. Vandalism holds\ncommunicative value: perhaps to the vandal themselves, to some audience at whom\nthe vandalism is aimed, and to the general public. Viewing vandals as rational\ncommunity participants despite their antinormative behavior offers the\npossibility of engaging with or countering their choices in novel ways.\nRational choice theory (RCT) as applied in value expectancy theory (VET) offers\na strategy for characterizing behaviors in a framework of rational choices, and\nbegins with the supposition that subject to some weighting of personal\npreferences and constraints, individuals maximize their own utility by\ncommitting acts of vandalism. This study applies the framework of RCT and VET\nto gain insight into vandals' preferences and constraints. Using a\nmixed-methods analysis of Wikipedia, I combine social computing and\ncriminological perspectives on vandalism to propose an ontology of vandalism\nfor online content communities. I use this ontology to categorize 141 instances\nof vandalism and find that the character of vandalistic acts varies by vandals'\nrelative identifiability, policy history with Wikipedia, and the effort\nrequired to vandalize.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 22:29:22 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Champion", "Kaylea", ""]]}, {"id": "2007.02203", "submitter": "A. Feder Cooper", "authors": "A. Feder Cooper, Karen Levy, Christopher De Sa", "title": "Understanding Accuracy-Efficiency Trade-Offs as a Means for Holding\n  Distributed ML Systems Accountable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Trade-offs between accuracy and efficiency are found in multiple\nnon-computing domains, such as law and public health, which have developed\nrules and heuristics to guide how to balance the two in conditions of\nuncertainty. While accuracy-efficiency trade-offs are also commonly\nacknowledged in some areas of computer science, their policy implications\nremain poorly examined. Drawing on risk assessment practices in the US, we\nargue that, since examining accuracy-efficiency trade-offs has been useful for\nguiding governance in other domains, explicitly framing such trade-offs in\ncomputing is similarly useful for the governance of computer systems. Our\ndiscussion focuses on real-time distributed ML systems; understanding the\npolicy implications in this area is particularly urgent because such systems,\nwhich include autonomous vehicles, tend to be high-stakes and safety-critical.\nWe describe how the trade-off takes shape for these systems, highlight gaps\nbetween existing US risk assessment standards and what these systems require in\norder to be properly assessed, and make specific calls to action to facilitate\naccountability when hypothetical risks become realized as accidents in the real\nworld. We close by discussing how such accountability mechanisms encourage more\njust, transparent governance aligned with public values.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 23:00:52 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 08:44:59 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 19:39:32 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 21:42:55 GMT"}, {"version": "v5", "created": "Mon, 14 Jun 2021 20:21:55 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Cooper", "A. Feder", ""], ["Levy", "Karen", ""], ["De Sa", "Christopher", ""]]}, {"id": "2007.02285", "submitter": "Xiaoyuan Liu", "authors": "Xiaoyuan Liu, Ni Trieu, Evgenios M. Kornaropoulos, Dawn Song", "title": "BeeTrace: A Unified Platform for Secure Contact Tracing that Breaks Data\n  Silos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing is an important method to control the spread of an infectious\ndisease such as COVID-19. However, existing contact tracing methods alone\ncannot provide sufficient coverage and do not successfully address privacy\nconcerns of the participating entities. Current solutions do not utilize the\nhuge volume of data stored in business databases and individual digital\ndevices. This information is typically stored in data silos and cannot be used\ndue to regulations in place. To successfully unlock the potential of contact\ntracing, we need to consider both data utilization from multiple sources and\nthe privacy of the participating parties. To this end, we propose BeeTrace, a\nunified platform that breaks data silos and deploys state-of-the-art\ncryptographic protocols to guarantee privacy goals.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 10:33:45 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Liu", "Xiaoyuan", ""], ["Trieu", "Ni", ""], ["Kornaropoulos", "Evgenios M.", ""], ["Song", "Dawn", ""]]}, {"id": "2007.02304", "submitter": "Shuiqiao Yang", "authors": "Hui Yin, Shuiqiao Yang, Jianxin Li", "title": "Detecting Topic and Sentiment Dynamics Due to COVID-19 Pandemic Using\n  Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outbreak of the novel Coronavirus Disease (COVID-19) has greatly\ninfluenced people's daily lives across the globe. Emergent measures and\npolicies (e.g., lockdown, social distancing) have been taken by governments to\ncombat this highly infectious disease. However, people's mental health is also\nat risk due to the long-time strict social isolation rules. Hence, monitoring\npeople's mental health across various events and topics will be extremely\nnecessary for policy makers to make the appropriate decisions. On the other\nhand, social media have been widely used as an outlet for people to publish and\nshare their personal opinions and feelings. The large scale social media posts\n(e.g., tweets) provide an ideal data source to infer the mental health for\npeople during this pandemic period. In this work, we propose a novel framework\nto analyze the topic and sentiment dynamics due to COVID-19 from the massive\nsocial media posts. Based on a collection of 13 million tweets related to\nCOVID-19 over two weeks, we found that the positive sentiment shows higher\nratio than the negative sentiment during the study period. When zooming into\nthe topic-level analysis, we find that different aspects of COVID-19 have been\nconstantly discussed and show comparable sentiment polarities. Some topics like\n``stay safe home\" are dominated with positive sentiment. The others such as\n``people death\" are consistently showing negative sentiment. Overall, the\nproposed framework shows insightful findings based on the analysis of the\ntopic-level sentiment dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 12:05:30 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Yin", "Hui", ""], ["Yang", "Shuiqiao", ""], ["Li", "Jianxin", ""]]}, {"id": "2007.02317", "submitter": "Abhishek Singh", "authors": "Ramesh Raskar, Abhishek Singh, Sam Zimmerman, Shrikant Kanaparti", "title": "Adding Location and Global Context to the Google/Apple Exposure\n  Notification Bluetooth API", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contact tracing requires a strong understanding of the context of a user, and\nlocation with other sensory data could provide a context for any infection\nencounter. Although Bluetooth technology gives a good insight into the\nproximity aspect of an encounter, it does not provide any location context\nrelated to it which helps to make better decisions. Using the ideas presented\nin this paper, one shall be able to obtain this valuable information that could\naddress the problem of false-positive and false-negative to a certain extent.\nAll of this within the purview of Google/Apple Exposure Notification (GAEN)\nspecification, while preserving complete user privacy. There are four ways of\npropagating context between any two users. Two such methods allow private\nlocation logging, without revealing the location history within an app. The\nother two are encryption-based methods. The first encryption method is a\nvariant of Apple's FindMy protocol, that allows nearby Apple devices to capture\nthe GPS location of a lost Apple device. The second encryption is a minor\nmodification of the existing GAEN protocol so that global context is available\nto a healthy phone only when it is exposed - this is a better option\ncomparatively. It will still be the role of Public Health smartphone app to\ndecide, on how to use the location-time context, to build a full-fledged\ncontact tracing and public health solution. Lastly, we highlight the benefits\nand potential privacy issues with each of these context propagation methods\nproposed here.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 08:03:21 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 04:54:47 GMT"}, {"version": "v3", "created": "Sat, 25 Jul 2020 18:04:51 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Raskar", "Ramesh", ""], ["Singh", "Abhishek", ""], ["Zimmerman", "Sam", ""], ["Kanaparti", "Shrikant", ""]]}, {"id": "2007.02325", "submitter": "Shuiqiao Yang", "authors": "Jianlong Zhou, Hamad Zogan, Shuiqiao Yang, Shoaib Jameel, Guandong Xu,\n  Fang Chen", "title": "Detecting Community Depression Dynamics Due to COVID-19 Pandemic in\n  Australia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent COVID-19 pandemic has caused unprecedented impact across the\nglobe. We have also witnessed millions of people with increased mental health\nissues, such as depression, stress, worry, fear, disgust, sadness, and anxiety,\nwhich have become one of the major public health concerns during this severe\nhealth crisis. For instance, depression is one of the most common mental health\nissues according to the findings made by the World Health Organisation (WHO).\nDepression can cause serious emotional, behavioural and physical health\nproblems with significant consequences, both personal and social costs\nincluded. This paper studies community depression dynamics due to COVID-19\npandemic through user-generated content on Twitter. A new approach based on\nmulti-modal features from tweets and Term Frequency-Inverse Document Frequency\n(TF-IDF) is proposed to build depression classification models. Multi-modal\nfeatures capture depression cues from emotion, topic and domain-specific\nperspectives. We study the problem using recently scraped tweets from Twitter\nusers emanating from the state of New South Wales in Australia. Our novel\nclassification model is capable of extracting depression polarities which may\nbe affected by COVID-19 and related events during the COVID-19 period. The\nresults found that people became more depressed after the outbreak of COVID-19.\nThe measures implemented by the government such as the state lockdown also\nincreased depression levels. Further analysis in the Local Government Area\n(LGA) level found that the community depression level was different across\ndifferent LGAs. Such granular level analysis of depression dynamics not only\ncan help authorities such as governmental departments to take corresponding\nactions more objectively in specific regions if necessary but also allows users\nto perceive the dynamics of depression over the time.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 12:55:34 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhou", "Jianlong", ""], ["Zogan", "Hamad", ""], ["Yang", "Shuiqiao", ""], ["Jameel", "Shoaib", ""], ["Xu", "Guandong", ""], ["Chen", "Fang", ""]]}, {"id": "2007.02333", "submitter": "Xing He", "authors": "Xing He, Rui Zhang, Jordan Alpert, Sicheng Zhou, Terrence J Adam,\n  Aantaki Raisa, Yifan Peng, Hansi Zhang, Yi Guo, Jiang Bian", "title": "When Text Simplification Is Not Enough: Could a Graph-Based\n  Visualization Facilitate Consumers' Comprehension of Dietary Supplement\n  Information?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dietary supplements are widely used but not always safe. With the rapid\ndevelopment of the Internet, consumers usually seek health information\nincluding dietary supplement information online. To help consumers access\nquality online dietary supplement information, we have identified trustworthy\ndietary supplement information sources and built an evidence-based knowledge\nbase of dietary supplement information-the integrated DIetary Supplement\nKnowledge base (iDISK) that integrates and standardizes dietary supplement\nrelated information across these different sources. However, as information in\niDISK was collected from scientific sources, the complex medical jargon is a\nbarrier for consumers' comprehension. To assess how different approaches to\nsimplify and represent dietary supplement information from iDISK will affect\nlay consumers' comprehension, using a crowdsourcing platform, we recruited\nparticipants to read dietary supplement information in four different\nrepresentations from iDISK: original text, syntactic and lexical text\nsimplification, manual text simplification, and a graph-based visualization. We\nthen assessed how the different simplification and representation strategies\naffected consumers' comprehension of dietary supplement information in terms of\naccuracy and response time to a set of comprehension questions. With responses\nfrom 690 qualified participants, our experiments confirmed that the manual\napproach had the best performance for both accuracy and response time to the\ncomprehension questions, while the graph-based approach ranked the second\noutperforming other representations. In some cases, the graph-based\nrepresentation outperformed the manual approach in terms of response time. A\nhybrid approach that combines text and graph-based representations might be\nneeded to accommodate consumers' different information needs and information\nseeking behavior.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 13:27:16 GMT"}, {"version": "v2", "created": "Sat, 3 Apr 2021 16:02:19 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["He", "Xing", ""], ["Zhang", "Rui", ""], ["Alpert", "Jordan", ""], ["Zhou", "Sicheng", ""], ["Adam", "Terrence J", ""], ["Raisa", "Aantaki", ""], ["Peng", "Yifan", ""], ["Zhang", "Hansi", ""], ["Guo", "Yi", ""], ["Bian", "Jiang", ""]]}, {"id": "2007.02423", "submitter": "Emanuel Moss", "authors": "Mona Sloane, Emanuel Moss, Olaitan Awomolo, Laura Forlano", "title": "Participation is not a Design Fix for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper critically examines existing modes of participation in design\npractice and machine learning. Cautioning against 'participation-washing', it\nsuggests that the ML community must become attuned to possibly exploitative and\nextractive forms of community involvement and shift away from the prerogatives\nof context-independent scalability.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 18:59:37 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 15:05:09 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 15:39:46 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Sloane", "Mona", ""], ["Moss", "Emanuel", ""], ["Awomolo", "Olaitan", ""], ["Forlano", "Laura", ""]]}, {"id": "2007.02426", "submitter": "Carlos Denner Dos Santos Jr.", "authors": "Daniel Esashika, Carlos Denner dos Santos", "title": "The influence of sponsors on organizational structure of free software\n  communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Initially, free software communities are characterized by selfmanagement,\nhowever, they were also influenced by public and private organizations that\nidentified potential gains in the use of the geographically distributed\nproduction model. In this context, this research aims to answer the following\nquestions: Do sponsors influence the organizational structures of free software\ncommunities by promoting differences between sponsored and non-sponsored\ncommunities? What strategies are adopted by the sponsor to influence the\norganizational structure of free software communities? Two constructs are\ncentral to the study: organizational structure and sponsorship. For this\nresearch, we adopted case study methodology and three free software communities\nwere studied. In the analysis of the results it was evidenced that sponsors\ninfluence decision making, definition of community key roles, and a\nformalization of norms. In turn, nonsponsored communities were characterized by\nthe centralization and informality of the norms. We conclude that differences\nwere identified in the organizational structure of sponsored and nonsponsored\nfree software communities, and this differentiation was influenced by sponsors.\nIn addition, it was possible to describe strategies and mechanisms used by\nsponsors to influence the community organizational structure.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 19:06:09 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Esashika", "Daniel", ""], ["Santos", "Carlos Denner dos", ""]]}, {"id": "2007.02452", "submitter": "Hyeju Jang", "authors": "Hyeju Jang, Emily Rempel, Giuseppe Carenini, Naveed Janjua", "title": "Exploratory Analysis of COVID-19 Related Tweets in North America to\n  Inform Public Health Institutes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social media is a rich source where we can learn about people's reactions to\nsocial issues. As COVID-19 has significantly impacted on people's lives, it is\nessential to capture how people react to public health interventions and\nunderstand their concerns. In this paper, we aim to investigate people's\nreactions and concerns about COVID-19 in North America, especially focusing on\nCanada. We analyze COVID-19 related tweets using topic modeling and\naspect-based sentiment analysis, and interpret the results with public health\nexperts. We compare timeline of topics discussed with timing of implementation\nof public health interventions for COVID-19. We also examine people's sentiment\nabout COVID-19 related issues. We discuss how the results can be helpful for\npublic health agencies when designing a policy for new interventions. Our work\nshows how Natural Language Processing (NLP) techniques could be applied to\npublic health questions with domain expert involvement.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 21:38:28 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Jang", "Hyeju", ""], ["Rempel", "Emily", ""], ["Carenini", "Giuseppe", ""], ["Janjua", "Naveed", ""]]}, {"id": "2007.02603", "submitter": "Rachel McKendry", "authors": "Isabel Bennett, Jobie Budd, Erin M. Manning, Ed Manley, Mengdie\n  Zhuang, Ingemar J. Cox, Michael Short, Anne M. Johnson, Deenan Pillay, Rachel\n  A. McKendry", "title": "Go local: The key to controlling the COVID-19 pandemic in the post\n  lockdown era", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The UK government announced its first wave of lockdown easing on 10 May 2020,\ntwo months after the non-pharmaceutical measures to reduce the spread of\nCOVID-19 were first introduced on 23 March 2020. Analysis of reported case rate\ndata from Public Health England and aggregated and anonymised crowd level\nmobility data shows variability across local authorities in the UK. A\nlocality-based approach to lockdown easing is needed, enabling local public\nhealth and associated health and social care services to rapidly respond to\nemerging hotspots of infection. National level data will hide an increasing\nheterogeneity of COVID-19 infections and mobility, and new ways of real-time\ndata presentation to the public are required. Data sources (including mobile)\nallow for faster visualisation than more traditional data sources, and are part\nof a wider trend towards near real-time analysis of outbreaks needed for\ntimely, targeted local public health interventions. Real time data\nvisualisation may give early warnings of unusual levels of activity which\nwarrant further investigation by local public health authorities.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 09:23:16 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Bennett", "Isabel", ""], ["Budd", "Jobie", ""], ["Manning", "Erin M.", ""], ["Manley", "Ed", ""], ["Zhuang", "Mengdie", ""], ["Cox", "Ingemar J.", ""], ["Short", "Michael", ""], ["Johnson", "Anne M.", ""], ["Pillay", "Deenan", ""], ["McKendry", "Rachel A.", ""]]}, {"id": "2007.02628", "submitter": "Alessandro Ecclesie Agazzi", "authors": "Alessandro Ecclesie Agazzi", "title": "Smart Home, security concerns of IoT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IoT (Internet of Things) has become widely popular in the domestic\nenvironments. People are renewing their homes into smart homes; however, the\nprivacy concerns of owning many Internet connected devices with always-on\nenvironmental sensors remain insufficiently addressed. Default and weak\npasswords, cheap materials and hardware, and unencrypted communication are\nidentified as the principal threats and vulnerabilities of IoT devices.\nSolutions and countermeasures are also provided: choosing a strong password,\nstrong authentication mechanisms, check online databases of exposed or default\ncredentials to mitigate the first threat; a selection of smart home devices\nfrom reputable companies and the implementation of the SDN for the Dos/DDoS\nthreat; and finally IDS, HTTPS protocol and VPN for eavesdropping. The paper\nconcludes dealing with a further challenge, \"the lack of technical support\", by\nwhich an auto-configuration approach should be analysed; this could both ease\nthe installation/maintenance and enhance the security in the self configuration\nstep of Smart Home devices.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 10:36:11 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Agazzi", "Alessandro Ecclesie", ""]]}, {"id": "2007.02642", "submitter": "Sang-Woo Lee", "authors": "Sang-Woo Lee, Hyunhoon Jung, SukHyun Ko, Sunyoung Kim, Hyewon Kim,\n  Kyoungtae Doh, Hyunjung Park, Joseph Yeo, Sang-Houn Ok, Joonhaeng Lee,\n  Sungsoon Lim, Minyoung Jeong, Seongjae Choi, SeungTae Hwang, Eun-Young Park,\n  Gwang-Ja Ma, Seok-Joo Han, Kwang-Seung Cha, Nako Sung, Jung-Woo Ha", "title": "CareCall: a Call-Based Active Monitoring Dialog Agent for Managing\n  COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking suspected cases of COVID-19 is crucial to suppressing the spread of\nCOVID-19 pandemic. Active monitoring and proactive inspection are indispensable\nto mitigate COVID-19 spread, though these require considerable social and\neconomic expense. To address this issue, we introduce CareCall, a call-based\ndialog agent which is deployed for active monitoring in Korea and Japan. We\ndescribe our system with a case study with statistics to show how the system\nworks. Finally, we discuss a simple idea which uses CareCall to support\nproactive inspection.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 11:05:22 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2020 09:21:08 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Lee", "Sang-Woo", ""], ["Jung", "Hyunhoon", ""], ["Ko", "SukHyun", ""], ["Kim", "Sunyoung", ""], ["Kim", "Hyewon", ""], ["Doh", "Kyoungtae", ""], ["Park", "Hyunjung", ""], ["Yeo", "Joseph", ""], ["Ok", "Sang-Houn", ""], ["Lee", "Joonhaeng", ""], ["Lim", "Sungsoon", ""], ["Jeong", "Minyoung", ""], ["Choi", "Seongjae", ""], ["Hwang", "SeungTae", ""], ["Park", "Eun-Young", ""], ["Ma", "Gwang-Ja", ""], ["Han", "Seok-Joo", ""], ["Cha", "Kwang-Seung", ""], ["Sung", "Nako", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "2007.02661", "submitter": "Muhammad R. A. Khandaker PhD", "authors": "Md. Tanvir Rahman, Risala T. Khan, Muhammad R. A. Khandaker, and Md.\n  Sifat Ar Salan", "title": "An Automated Contact Tracing Approach for Controlling Covid-19 Spread\n  Based on Geolocation Data from Mobile Cellular Networks", "comments": "Submitted to IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coronavirus (COVID-19) has appeared as the greatest challenge due to its\ncontinuous structural evolution as well as the absence of proper antidotes for\nthis particular virus. The virus mainly spreads and replicates itself among\nmass people through close contact which unfortunately can happen in many\nunpredictable ways. Therefore, to slow down the spread of this novel virus, the\nonly relevant initiatives are to maintain social distance, perform contact\ntracing, use proper safety gears, and impose quarantine measures. But despite\nbeing theoretically possible, these approaches are very difficult to uphold in\ndensely populated countries and areas. Therefore, to control the virus spread,\nresearchers and authorities are considering the use of smartphone based mobile\napplications (apps) to identify the likely infected persons as well as the\nhighly risky zones to maintain isolation and lockdown measures. However, these\nmethods heavily depend on advanced technological features and expose\nsignificant privacy loopholes. In this paper, we propose a new method for\nCOVID-19 contact tracing based on mobile phone users' geolocation data. The\nproposed method will help the authorities to identify the number of probable\ninfected persons without using smartphone based mobile applications. In\naddition, the proposed method can help people take the vital decision of when\nto seek medical assistance by letting them know whether they are already in the\nlist of exposed persons. Numerical examples demonstrate that the proposed\nmethod can significantly outperform the smartphone app-based solutions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 11:40:23 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Rahman", "Md. Tanvir", ""], ["Khan", "Risala T.", ""], ["Khandaker", "Muhammad R. A.", ""], ["Salan", "Md. Sifat Ar", ""]]}, {"id": "2007.02684", "submitter": "Ramachandra Raghavendra Prof.", "authors": "Sushma Venkatesh, Kiran Raja, Raghavendra Ramachandra, Christoph Busch", "title": "On the Influence of Ageing on Face Morph Attacks: Vulnerability and\n  Detection", "comments": "Accepted in IJCB 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face morphing attacks have raised critical concerns as they demonstrate a new\nvulnerability of Face Recognition Systems (FRS), which are widely deployed in\nborder control applications. The face morphing process uses the images from\nmultiple data subjects and performs an image blending operation to generate a\nmorphed image of high quality. The generated morphed image exhibits similar\nvisual characteristics corresponding to the biometric characteristics of the\ndata subjects that contributed to the composite image and thus making it\ndifficult for both humans and FRS, to detect such attacks. In this paper, we\nreport a systematic investigation on the vulnerability of the\nCommercial-Off-The-Shelf (COTS) FRS when morphed images under the influence of\nageing are presented. To this extent, we have introduced a new morphed face\ndataset with ageing derived from the publicly available MORPH II face dataset,\nwhich we refer to as MorphAge dataset. The dataset has two bins based on age\nintervals, the first bin - MorphAge-I dataset has 1002 unique data subjects\nwith the age variation of 1 year to 2 years while the MorphAge-II dataset\nconsists of 516 data subjects whose age intervals are from 2 years to 5 years.\nTo effectively evaluate the vulnerability for morphing attacks, we also\nintroduce a new evaluation metric, namely the Fully Mated Morphed Presentation\nMatch Rate (FMMPMR), to quantify the vulnerability effectively in a realistic\nscenario. Extensive experiments are carried out by using two different COTS FRS\n(COTS I - Cognitec and COTS II - Neurotechnology) to quantify the vulnerability\nwith ageing. Further, we also evaluate five different Morph Attack Detection\n(MAD) techniques to benchmark their detection performance with ageing.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 12:32:41 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2020 16:56:29 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Venkatesh", "Sushma", ""], ["Raja", "Kiran", ""], ["Ramachandra", "Raghavendra", ""], ["Busch", "Christoph", ""]]}, {"id": "2007.02806", "submitter": "Alain Mermoud", "authors": "Franck Legendre, Mathias Humbert, Alain Mermoud, Vincent Lenders", "title": "Contact Tracing: An Overview of Technologies and Cyber Risks", "comments": "26 pages, Technology Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 2020 COVID-19 pandemic has led to a global lockdown with severe health\nand economical consequences. As a result, authorities around the globe have\nexpressed their needs for better tools to monitor the spread of the virus and\nto support human labor. Researchers and technology companies such as Google and\nApple have offered to develop such tools in the form of contact tracing\napplications. The goal of these applications is to continuously track people's\nproximity and to make the smartphone users aware if they have ever been in\ncontact with positively diagnosed people, so that they could self-quarantine\nand possibly have an infection test. A fundamental challenge with these\nsmartphone-based contact tracing technologies is to ensure the security and\nprivacy of their users. Moving from manual to smartphone-based contact tracing\ncreates new cyber risks that could suddenly affect the entire population. Major\nrisks include for example the abuse of the people's private data by companies\nand/or authorities, or the spreading of wrong alerts by malicious users in\norder to force individuals to go into quarantine. In April 2020, the\nPan-European Privacy-Preserving Proximity Tracing (PEPP-PT) was announced with\nthe goal to develop and evaluate secure solutions for European countries.\nHowever, after a while, several team members left this consortium and created\nDP-3T which has led to an international debate among the experts. At this time,\nit is confusing for the non-expert to follow this debate; this report aims to\nshed light on the various proposed technologies by providing an objective\nassessment of the cybersecurity and privacy risks. We first review the\nstate-of-the-art in digital contact tracing technologies and then explore the\nrisk-utility trade-offs of the techniques proposed for COVID-19. We focus\nspecifically on the technologies that are already adopted by certain countries.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 15:10:20 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Legendre", "Franck", ""], ["Humbert", "Mathias", ""], ["Mermoud", "Alain", ""], ["Lenders", "Vincent", ""]]}, {"id": "2007.02890", "submitter": "Robert Long", "authors": "Robert Long", "title": "Fairness in machine learning: against false positive rate equality as a\n  measure of fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning informs increasingly consequential decisions, different\nmetrics have been proposed for measuring algorithmic bias or unfairness. Two\npopular fairness measures are calibration and equality of false positive rate.\nEach measure seems intuitively important, but notably, it is usually impossible\nto satisfy both measures. For this reason, a large literature in machine\nlearning speaks of a fairness tradeoff between these two measures. This framing\nassumes that both measures are, in fact, capturing something important. To\ndate, philosophers have not examined this crucial assumption, and examined to\nwhat extent each measure actually tracks a normatively important property. This\nmakes this inevitable statistical conflict, between calibration and false\npositive rate equality, an important topic for ethics. In this paper, I give an\nethical framework for thinking about these measures and argue that, contrary to\ninitial appearances, false positive rate equality does not track anything about\nfairness, and thus sets an incoherent standard for evaluating the fairness of\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 17:03:58 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Long", "Robert", ""]]}, {"id": "2007.03019", "submitter": "Abdulkareem Alsudais", "authors": "Abdulkareem Alsudais", "title": "Incorrect Data in the Widely Used Inside Airbnb Dataset", "comments": null, "journal-ref": null, "doi": "10.1016/j.dss.2020.113453", "report-no": null, "categories": "cs.CY cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recently published papers in Decision Support Systems discussed\nissues related to data quality in Information Systems research. In this short\nresearch note, I build on the work introduced in these papers and document two\ndata quality issues discovered in a large open dataset commonly used in\nresearch. Inside Airbnb (IA) collects data from places and reviews as posted by\nusers of Airbnb.com. Visitors can effortlessly download data collected by IA\nfor several locations around the globe. While the dataset is widely used in\nacademic research, no thorough investigation of the dataset and its validity\nhas been conducted. This note examines the dataset and explains an issue of\nincorrect data added to the dataset. Findings suggest that this issue can be\nattributed to systemic errors in the data collection process. The results\nsuggest that the use of unverified open datasets can be problematic, although\nthe discoveries presented in this work may not be significant enough to\nchallenge all published research that used the IA dataset. Additionally,\nfindings indicate that the incorrect data happens because of a new feature\nimplemented by Airbnb. Thus, unless changes are made, it is likely that the\nconsequences of this issue will only become more severe. Finally, this note\nexplores why reproducibility is a problem when two different releases of the\ndataset are compared.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 19:06:28 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 06:20:00 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Alsudais", "Abdulkareem", ""]]}, {"id": "2007.03051", "submitter": "Raghavendra Selvan", "authors": "Lasse F. Wolff Anthony, Benjamin Kanding, Raghavendra Selvan", "title": "Carbontracker: Tracking and Predicting the Carbon Footprint of Training\n  Deep Learning Models", "comments": "Accepted to be presented at the ICML Workshop on \"Challenges in\n  Deploying and monitoring Machine Learning Systems\", 2020. Source code at this\n  link https://github.com/lfwa/carbontracker/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) can achieve impressive results across a wide variety of\ntasks, but this often comes at the cost of training models for extensive\nperiods on specialized hardware accelerators. This energy-intensive workload\nhas seen immense growth in recent years. Machine learning (ML) may become a\nsignificant contributor to climate change if this exponential trend continues.\nIf practitioners are aware of their energy and carbon footprint, then they may\nactively take steps to reduce it whenever possible. In this work, we present\nCarbontracker, a tool for tracking and predicting the energy and carbon\nfootprint of training DL models. We propose that energy and carbon footprint of\nmodel development and training is reported alongside performance metrics using\ntools like Carbontracker. We hope this will promote responsible computing in ML\nand encourage research into energy-efficient deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 20:24:31 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Anthony", "Lasse F. Wolff", ""], ["Kanding", "Benjamin", ""], ["Selvan", "Raghavendra", ""]]}, {"id": "2007.03215", "submitter": "Arisa Ema", "authors": "Takashi Matsumoto, Arisa Ema", "title": "RCModel, a Risk Chain Model for Risk Reduction in AI Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing use of artificial intelligence (AI) services and products\nin recent years, issues related to their trustworthiness have emerged and AI\nservice providers need to be prepared for various risks. In this policy\nrecommendation, we propose a risk chain model (RCModel) that supports AI\nservice providers in proper risk assessment and control. We hope that RCModel\nwill contribute to the realization of trustworthy AI services.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 05:53:54 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Matsumoto", "Takashi", ""], ["Ema", "Arisa", ""]]}, {"id": "2007.03225", "submitter": "Paheli Bhattacharya", "authors": "Paheli Bhattacharya, Kripabandhu Ghosh, Arindam Pal, Saptarshi Ghosh", "title": "Hier-SPCNet: A Legal Statute Hierarchy-based Heterogeneous Network for\n  Computing Legal Case Document Similarity", "comments": "Accepted at the 43rd International ACM SIGIR Conference on Research\n  and Development in Information Retrieval, 2020 (Short Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing similarity between two legal case documents is an important and\nchallenging task in Legal IR, for which text-based and network-based measures\nhave been proposed in literature. All prior network-based similarity methods\nconsidered a precedent citation network among case documents only (PCNet).\nHowever, this approach misses an important source of legal knowledge -- the\nhierarchy of legal statutes that are applicable in a given legal jurisdiction\n(e.g., country). We propose to augment the PCNet with the hierarchy of legal\nstatutes, to form a heterogeneous network Hier-SPCNet, having citation links\nbetween case documents and statutes, as well as citation and hierarchy links\namong the statutes. Experiments over a set of Indian Supreme Court case\ndocuments show that our proposed heterogeneous network enables significantly\nbetter document similarity estimation, as compared to existing approaches using\nPCNet. We also show that the proposed network-based method can complement\ntext-based measures for better estimation of legal document similarity.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 06:30:46 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Bhattacharya", "Paheli", ""], ["Ghosh", "Kripabandhu", ""], ["Pal", "Arindam", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "2007.03447", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley", "title": "Children's health in the digital age", "comments": null, "journal-ref": "International Journal of Environmental Research and Public Health,\n  2020, 17(9), 3240", "doi": "10.3390/ijerph17093240", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental studies, metabolic research, and state of the art in\nneurobiology point towards the reduced amount of natural day and sunlight\nexposure of the developing childs organism, as a consequence of increasingly\nlong hours spent indoors online, as the single unifying source of a whole set\nof health risks identified worldwide, as is made clear in this review of the\ncurrent literature. Over exposure to digital environments, from abuse to\naddiction, now concerns even the youngest (ages zero to 2), and triggers, as\nargued on the basis of clear examples herein, a chain of interdependent\nnegative and potentially long-term metabolic changes. This leads to a\nderegulation of the serotonin and dopamine neurotransmitter pathways in the\ndeveloping brain, currently associated with online activity abuse or internet\naddiction, and akin to that found in severe substance abuse syndromes. A\ngeneral functional working model is proposed under the light of evidence\nbrought to the forefront in this review.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 13:54:42 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Dresp-Langley", "Birgitta", ""]]}, {"id": "2007.03520", "submitter": "Huawei Huang", "authors": "Huawei Huang, Wei Kong, Sicong Zhou, Zibin Zheng, Song Guo", "title": "A Survey of State-of-the-Art on Blockchains: Theories, Modelings, and\n  Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To draw a roadmap of current research activities of the blockchain community,\nwe first conduct a brief overview of state-of-the-art blockchain surveys\npublished in the recent 5 years. We found that those surveys are basically\nstudying the blockchain-based applications, such as blockchain-assisted\nInternet of Things (IoT), business applications, security-enabled solutions,\nand many other applications in diverse fields. However, we think that a\ncomprehensive survey towards the essentials of blockchains by exploiting the\nstate-of-the-art theoretical modelings, analytic models, and useful experiment\ntools is still missing. To fill this gap, we perform a thorough survey by\nidentifying and classifying the most recent high-quality research outputs that\nare closely related to the theoretical findings and essential mechanisms of\nblockchain systems and networks. Several promising open issues are also\nsummarized finally for future research directions. We wish this survey can\nserve as a useful guideline for researchers, engineers, and educators about the\ncutting-edge development of blockchains in the perspectives of theories,\nmodelings, and tools.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:50:32 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 02:47:55 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Huang", "Huawei", ""], ["Kong", "Wei", ""], ["Zhou", "Sicong", ""], ["Zheng", "Zibin", ""], ["Guo", "Song", ""]]}, {"id": "2007.03573", "submitter": "Zhibin Niu", "authors": "Zhibin Niu, Runlin Li, Junqi Wu, Yaqi Xue, Jiawan Zhang", "title": "regvis.net -- A Visual Bibliography of Regulatory Visualization", "comments": "2 pages. Refer to http://regvis.net", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information visualization and visual analytics technology has attracted\nsignificant attention from the financial regulation community. In this\nresearch, we present regvis.net, a visual survey of regulatory visualization\nthat allows researchers from both the computing and financial communities to\nreview their literature of interest. We have collected and manually tagged more\nthan 80 regulation visualization related publications. To the best of our\nknowledge, this is the first publication set tailored for regulatory\nvisualization. We have provided a webpage (http://regvis.net) for interactive\nsearches and filtering. Each publication is represented by a thumbnail of the\nrepresentative system interface or key visualization chart, and users can\nconduct multi-condition screening explorations and fixed text searches.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:49:35 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Niu", "Zhibin", ""], ["Li", "Runlin", ""], ["Wu", "Junqi", ""], ["Xue", "Yaqi", ""], ["Zhang", "Jiawan", ""]]}, {"id": "2007.03596", "submitter": "Han Wang", "authors": "Wang Han, Wesley Yeung, Angeline Tung, Joey Tay Ai Meng, Davin\n  Ryanputera, Feng Mengling, Shalini Arulanadam", "title": "An Emergency Medical Services Clinical Audit System driven by Named\n  Entity Recognition from Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinical performance audits are routinely performed in Emergency Medical\nServices (EMS) to ensure adherence to treatment protocols, to identify\nindividual areas of weakness for remediation, and to discover systemic\ndeficiencies to guide the development of the training syllabus. At present,\nthese audits are performed by manual chart review which is time-consuming and\nlaborious. In this paper, we present an automatic audit system based on both\nthe structured and unstructured ambulance case records and clinical notes with\na deep neural network-based named entities recognition model. The dataset used\nin this study contained 58,898 unlabelled ambulance incidents encountered by\nthe Singapore Civil Defence Force from 1st April 2019 to 30th June 2019. A\nweakly-supervised training approach was adopted to label the sentences. Later\non, we trained three different models to perform the NER task. All three models\nachieve F1 scores of around 0.981 under entity type matching evaluation and\naround 0.976 under strict evaluation, while the BiLSTM-CRF model is 1~2 orders\nof magnitude lighter and faster than our BERT-based models. Overall, our\napproach yielded a named entity recognition model that could reliably identify\nclinical entities from unstructured paramedic free-text reports. Our proposed\nsystem may improve the efficiency of clinical performance audits and can also\nhelp with EMS database research.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 16:32:44 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Han", "Wang", ""], ["Yeung", "Wesley", ""], ["Tung", "Angeline", ""], ["Meng", "Joey Tay Ai", ""], ["Ryanputera", "Davin", ""], ["Mengling", "Feng", ""], ["Arulanadam", "Shalini", ""]]}, {"id": "2007.03603", "submitter": "Christian Wischnewski", "authors": "Christian Wischnewski", "title": "The Disruptive Potential of FinTechs in the German Consumer Finance\n  Sector -- A Blue Ocean Scenario?", "comments": "Master's Dissertation. 100 pages, 11 Figures, 24 Tables", "journal-ref": null, "doi": "10.13140/RG.2.2.12797.59367", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the Blue Ocean strategy as an underlying strategic element, this\ndissertation analyses whether this statement holds true for the rather more\nconservative banking sector in Germany and the overall risk-averse mindset of\nthe German population by using both quantitative and qualitative elements to\nassess the current market share of FinTech companies in the Federal Republic,\nas well as grasp a potential outlook on the future development. A literature\nreview of the strategic framework, the banking sector in Germany and the\nFinTech sector is carried out accordingly. Subsequently, a formal verification\nas to whether the banking sector is a \"Red Ocean\" and if the FinTech industry\nis a \"Blue Ocean\" is carried out using case studies from both sectors. A\nquantitative analysis of banking customers in Germany and their use of FinTech\ncompanies is conducted by way of an online survey, with selected participants\nbeing interviewed thereafter to gain additional insights. Data evaluation is\nmade using pivotal analysis and cross tabulation of survey results and\ninterview findings, along with extrapolating indicators to reflect the full\nsize of the German banking sector and transactional volumes per segment are\nprovided and examined for signs of elevated FinTech use in the market. Despite\nseveral limitations from where ideas for future research are derived, the\noutcomes provide an overview of existing trends for the use of FinTechs in\nGermany. The main finding is that with the notable exception of payment\nsolutions, Germans do not have a high affinity towards FinTechs, rendering them\na byproduct of the financial service industry, with limited market share and\nlow potential.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 01:30:49 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Wischnewski", "Christian", ""]]}, {"id": "2007.03604", "submitter": "Stefano Cresci", "authors": "Stefano Cresci", "title": "A Decade of Social Bot Detection", "comments": "Forthcoming in Communications of the ACM", "journal-ref": "Communications of the ACM 63.10 (2020):72-83", "doi": "10.1145/3409116", "report-no": null, "categories": "cs.CY cs.HC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the morning of November 9th 2016, the world woke up to the shocking\noutcome of the US Presidential elections: Donald Trump was the 45th President\nof the United States of America. An unexpected event that still has tremendous\nconsequences all over the world. Today, we know that a minority of social bots,\nautomated social media accounts mimicking humans, played a central role in\nspreading divisive messages and disinformation, possibly contributing to\nTrump's victory. In the aftermath of the 2016 US elections, the world started\nto realize the gravity of widespread deception in social media. Following\nTrump's exploit, we witnessed to the emergence of a strident dissonance between\nthe multitude of efforts for detecting and removing bots, and the increasing\neffects that these malicious actors seem to have on our societies. This paradox\nopens a burning question: What strategies should we enforce in order to stop\nthis social bot pandemic? In these times, during the run-up to the 2020 US\nelections, the question appears as more crucial than ever. What stroke social,\npolitical and economic analysts after 2016, deception and automation, has been\nhowever a matter of study for computer scientists since at least 2010. In this\nwork, we briefly survey the first decade of research in social bot detection.\nVia a longitudinal analysis, we discuss the main trends of research in the\nfight against bots, the major results that were achieved, and the factors that\nmake this never-ending battle so challenging. Capitalizing on lessons learned\nfrom our extensive analysis, we suggest possible innovations that could give us\nthe upper hand against deception and manipulation. Studying a decade of\nendeavours at social bot detection can also inform strategies for detecting and\nmitigating the effects of other, more recent, forms of online deception, such\nas strategic information operations and political trolls.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 13:46:38 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 07:55:22 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Cresci", "Stefano", ""]]}, {"id": "2007.03606", "submitter": "Longbing Cao", "authors": "Longbing Cao", "title": "Data Science: A Comprehensive Overview", "comments": null, "journal-ref": "ACM Computing Surveys, 50(3), 43:1-42, 2017", "doi": "10.1145/3076253", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The twenty-first century has ushered in the age of big data and data economy,\nin which data DNA, which carries important knowledge, insights and potential,\nhas become an intrinsic constituent of all data-based organisms. An appropriate\nunderstanding of data DNA and its organisms relies on the new field of data\nscience and its keystone, analytics. Although it is widely debated whether big\ndata is only hype and buzz, and data science is still in a very early phase,\nsignificant challenges and opportunities are emerging or have been inspired by\nthe research, innovation, business, profession, and education of data science.\nThis paper provides a comprehensive survey and tutorial of the fundamental\naspects of data science: the evolution from data analysis to data science, the\ndata science concepts, a big picture of the era of data science, the major\nchallenges and directions in data innovation, the nature of data analytics, new\nindustrialization and service opportunities in the data economy, the profession\nand competency of data education, and the future of data science. This article\nis the first in the field to draw a comprehensive big picture, in addition to\noffering rich observations, lessons and thinking about data science and\nanalytics.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 02:33:58 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Cao", "Longbing", ""]]}, {"id": "2007.03613", "submitter": "Amitash Ojha Dr", "authors": "Pan IIT Group", "title": "PAN IIT Survey on Online Education: A Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the COVID-19 pandemic that set in in the middle of the semester, most\nof the IITs (and other institutions from across India and the world) switched\nto an online mode for completing the semester. Since then, many different\ninstitutions from across the world have been discussing ways and means to make\nonline education effective, via various means, such as webinars, talks and\nshort workshops. However, a general observation has been that there is a lack\nof data on online education, particularly in the Indian context. Anticipating\nthis, we decided to conduct a pan-IIT survey on online education and compiled\ntwo sets of questionnaires (one each for faculty members and students) in\ndiscussion with the members of the pan-IIT group on Online Pedagogy\n(https://www.paniit-onlinepedagogy-researchgroup.net/), that has been formed\nfor conducting research on the broad area of online education. The current\nsurvey has been steered by IIT Dharwad and IIT Jammu along with the members of\nthe pan-IIT group on online pedagogy. The survey data was collected from 5th\nMay 2020 to 25th May 2020. We received about 11,890 and 840 responses from\nstudents and faculty members, respectively. About 82% and 86% of the\nrespondents were males among the students and faculty surveys, respectively. In\nthe following, we present and discuss the survey responses pertaining to\nvarious aspects of online education. An infographic representation of the\nsurvey responses may be found in Appendix. We note that the survey conducted\nwas a broad survey, covering various broad aspects of online education.\nHowever, a fine-grained survey may be required to obtain an in-depth\nunderstanding of specific aspects, such as on how to handle lab courses and\ncarry out assessments.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 06:08:18 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Pan IIT Group", "", ""]]}, {"id": "2007.03615", "submitter": "Weisong Yang", "authors": "Rafael Poyiadzi and Weisong Yang and Yoav Ben-Shlomo and Ian Craddock\n  and Liz Coulthard and Raul Santos-Rodriguez and James Selwood and Niall\n  Twomey", "title": "Detecting Signatures of Early-stage Dementia with Behavioural Models\n  Derived from Sensor Data", "comments": "Accepted by the 1st edition of HELPLINE: Artificial Intelligence for\n  Health, Personalized Medicine and Wellbeing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a pressing need to automatically understand the state and\nprogression of chronic neurological diseases such as dementia. The emergence of\nstate-of-the-art sensing platforms offers unprecedented opportunities for\nindirect and automatic evaluation of disease state through the lens of\nbehavioural monitoring. This paper specifically seeks to characterise\nbehavioural signatures of mild cognitive impairment (MCI) and Alzheimer's\ndisease (AD) in the \\textit{early} stages of the disease. We introduce bespoke\nbehavioural models and analyses of key symptoms and deploy these on a novel\ndataset of longitudinal sensor data from persons with MCI and AD. We present\npreliminary findings that show the relationship between levels of sleep quality\nand wandering can be subtly different between patients in the early stages of\ndementia and healthy cohabiting controls.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 18:46:49 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Poyiadzi", "Rafael", ""], ["Yang", "Weisong", ""], ["Ben-Shlomo", "Yoav", ""], ["Craddock", "Ian", ""], ["Coulthard", "Liz", ""], ["Santos-Rodriguez", "Raul", ""], ["Selwood", "James", ""], ["Twomey", "Niall", ""]]}, {"id": "2007.03616", "submitter": "Michael Falk", "authors": "Michael Falk", "title": "Artificial Stupidity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Public debate about AI is dominated by Frankenstein Syndrome, the fear that\nAI will become superhuman and escape human control. Although superintelligence\nis certainly a possibility, the interest it excites can distract the public\nfrom a more imminent concern: the rise of Artificial Stupidity (AS). This\narticle discusses the roots of Frankenstein Syndrome in Mary Shelley's famous\nnovel of 1818. It then provides a philosophical framework for analysing the\nstupidity of artificial agents, demonstrating that modern intelligent systems\ncan be seen to suffer from 'stupidity of judgement'. Finally it identifies an\nalternative literary tradition that exposes the perils and benefits of AS. In\nthe writings of Edmund Spenser, Jonathan Swift and E.T.A. Hoffmann, ASs\nreplace, oppress or seduce their human users. More optimistically, Joseph\nFurphy and Laurence Sterne imagine ASs that can serve human intellect as maps\nor as pipes. These writers provide a strong counternarrative to the myths that\ncurrently drive the AI debate. They identify ways in which even stupid\nartificial agents can evade human control, for instance by appealing to\nstereotypes or distancing us from reality. And they underscore the continuing\nimportance of the literary imagination in an increasingly automated society.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 00:37:23 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Falk", "Michael", ""]]}, {"id": "2007.03617", "submitter": "Petros Spachos", "authors": "Katherine McLeod, Petros Spachos, Konstantinos Plataniotis", "title": "Smartphone-based Wellness Assessment Using Mobile Environmental Sensor", "comments": null, "journal-ref": null, "doi": "10.1109/JSYST.2020.3004558", "report-no": null, "categories": "cs.CY cs.HC cs.MM cs.SI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental health and general wellness are becoming a growing concern in our\nsociety. Environmental factors contribute to mental illness and have the power\nto affect a person's wellness. This work presents a smartphone-based wellness\nassessment system and examines if there is any correlation with one's\nenvironment and their wellness. The introduced system was initiated in response\nto a growing need for individualized and independent mental health care and\nevaluated through experimentation. The participants were given an Android\nsmartphone and a mobile sensor board and they were asked to complete a brief\npsychological survey three times per day. During the survey completion, the\nboard in their possession is reading environmental data. The five environmental\nvariables collected are temperature, humidity, air pressure, luminosity, and\nnoise level. Upon submission of the survey, the results of the survey and the\nenvironmental data are sent to a server for further processing. Three\nexperiments with 62 participants in total have been completed. The correlation\nmost regularly deemed statistically significant was that of light and audio and\nstress.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 20:23:32 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["McLeod", "Katherine", ""], ["Spachos", "Petros", ""], ["Plataniotis", "Konstantinos", ""]]}, {"id": "2007.03659", "submitter": "Shaun Kane", "authors": "Shaun Kane, Richard Ladner, and Clayton Lewis", "title": "Promoting Strategic Research on Inclusive Access to Rich Online Content\n  and Services", "comments": "A Computing Community Consortium (CCC) workshop report, 16 pages", "journal-ref": null, "doi": null, "report-no": "ccc2014report_5", "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to content and services online is increasingly important for everyone,\nincluding people with disabilities. National commitments, including the\nAmericans with Disabilities Act, and international resolutions, including the\nUnited Nations Declaration of the Rights of Persons with Disabilities, call for\nwork to ensure that people with disabilities can participate fully in the\nonline world. Gains in education, employment and health, as well as in civic\nengagement, social participation, and personal independence will follow from\nenhanced inclusion online. Research in many areas of computer science,\nincluding recognition technology, natural language processing, personalization,\nsoftware architecture, and others, is needed to secure these benefits.\nOrganizing this research calls for partnerships among academic researchers,\nfederal agencies, and commercial organizations, as well as effective division\nof labor and cooperation between computer scientists, behavioral scientists,\nadvocacy groups, and consumers.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 17:50:03 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kane", "Shaun", ""], ["Ladner", "Richard", ""], ["Lewis", "Clayton", ""]]}, {"id": "2007.03661", "submitter": "Yiling Chen", "authors": "Yiling Chen, Arpita Ghosh, Michael Kearns, Tim Roughgarden, and\n  Jennifer Wortman Vaughan", "title": "Mathematical Foundations for Social Computing", "comments": "A Computing Community Consortium (CCC) workshop report, 15 pages", "journal-ref": null, "doi": null, "report-no": "ccc2014report_5", "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social computing encompasses the mechanisms through which people interact\nwith computational systems: crowdsourcing systems, ranking and recommendation\nsystems, online prediction markets, citizen science projects, and\ncollaboratively edited wikis, to name a few. These systems share the common\nfeature that humans are active participants, making choices that determine the\ninput to, and therefore the output of, the system. The output of these systems\ncan be viewed as a joint computation between machine and human, and can be\nricher than what either could produce alone. The term social computing is often\nused as a synonym for several related areas, such as \"human computation\" and\nsubsets of \"collective intelligence\"; we use it in its broadest sense to\nencompass all of these things.\n  Social computing is blossoming into a rich research area of its own, with\ncontributions from diverse disciplines including computer science, economics,\nand other social sciences. Yet a broad mathematical foundation for social\ncomputing is yet to be established, with a plethora of under-explored\nopportunities for mathematical research to impact social computing.\n  As in other fields, there is great potential for mathematical work to\ninfluence and shape the future of social computing. However, we are far from\nhaving the systematic and principled understanding of the advantages,\nlimitations, and potentials of social computing required to match the impact on\napplications that has occurred in other fields. In June 2015, we brought\ntogether roughly 25 experts in related fields to discuss the promise and\nchallenges of establishing mathematical foundations for social computing. This\ndocument captures several of the key ideas discussed.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 17:50:27 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Chen", "Yiling", ""], ["Ghosh", "Arpita", ""], ["Kearns", "Michael", ""], ["Roughgarden", "Tim", ""], ["Vaughan", "Jennifer Wortman", ""]]}, {"id": "2007.03704", "submitter": "Rajeev Alur", "authors": "Rajeev Alur, Richard Baraniuk, Rastislav Bodik, Ann Drobnis, Sumit\n  Gulwani, Bjoern Hartmann, Yasmin Kafai, Jeff Karpicke, Ran Libeskind-Hadas,\n  Debra Richardson, Armando Solar-Lezama, Candace Thille, and Moshe Vardi", "title": "Computer-Aided Personalized Education", "comments": "A Computing Community Consortium (CCC) workshop report, 12 pages", "journal-ref": null, "doi": null, "report-no": "ccc2016report_6", "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shortage of people trained in STEM fields is becoming acute, and\nuniversities and colleges are straining to satisfy this demand. In the case of\ncomputer science, for instance, the number of US students taking introductory\ncourses has grown three-fold in the past decade. Recently, massive open online\ncourses (MOOCs) have been promoted as a way to ease this strain. This at best\nprovides access to education. The bigger challenge though is coping with\nheterogeneous backgrounds of different students, retention, providing feedback,\nand assessment. Personalized education relying on computational tools can\naddress this challenge.\n  While automated tutoring has been studied at different times in different\ncommunities, recent advances in computing and education technology offer\nexciting opportunities to transform the manner in which students learn. In\nparticular, at least three trends are significant. First, progress in logical\nreasoning, data analytics, and natural language processing has led to tutoring\ntools for automatic assessment, personalized instruction including targeted\nfeedback, and adaptive content generation for a variety of subjects. Second,\nresearch in the science of learning and human-computer interaction is leading\nto a better understanding of how different students learn, when and what types\nof interventions are effective for different instructional goals, and how to\nmeasure the success of educational tools. Finally, the recent emergence of\nonline education platforms, both in academia and industry, is leading to new\nopportunities for the development of a shared infrastructure. This CCC workshop\nbrought together researchers developing educational tools based on technologies\nsuch as logical reasoning and machine learning with researchers in education,\nhuman-computer interaction, and cognitive psychology.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 18:00:04 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Alur", "Rajeev", ""], ["Baraniuk", "Richard", ""], ["Bodik", "Rastislav", ""], ["Drobnis", "Ann", ""], ["Gulwani", "Sumit", ""], ["Hartmann", "Bjoern", ""], ["Kafai", "Yasmin", ""], ["Karpicke", "Jeff", ""], ["Libeskind-Hadas", "Ran", ""], ["Richardson", "Debra", ""], ["Solar-Lezama", "Armando", ""], ["Thille", "Candace", ""], ["Vardi", "Moshe", ""]]}, {"id": "2007.03741", "submitter": "Peter Coveney", "authors": "Peter V. Coveney and Roger R. Highfield", "title": "When we can trust computers (and when we can't)", "comments": "15 pages", "journal-ref": null, "doi": "10.1098/rsta.2020.0067", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the relentless rise of computer power, there is a widespread expectation\nthat computers can solve the most pressing problems of science, and even more\nbesides. We explore the limits of computational modelling and conclude that, in\nthe domains of science and engineering that are relatively simple and firmly\ngrounded in theory, these methods are indeed powerful. Even so, the\navailability of code, data and documentation, along with a range of techniques\nfor validation, verification and uncertainty quantification, are essential for\nbuilding trust in computer generated findings. When it comes to complex systems\nin domains of science that are less firmly grounded in theory, notably biology\nand medicine, to say nothing of the social sciences and humanities, computers\ncan create the illusion of objectivity, not least because the rise of big data\nand machine learning pose new challenges to reproducibility, while lacking true\nexplanatory power. We also discuss important aspects of the natural world which\ncannot be solved by digital means. In the long-term, renewed emphasis on\nanalogue methods will be necessary to temper the excessive faith currently\nplaced in digital computation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 08:55:53 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Coveney", "Peter V.", ""], ["Highfield", "Roger R.", ""]]}, {"id": "2007.03745", "submitter": "Sivapriya Mothilal Bhagavathy", "authors": "Sivapriya Mothilal Bhagavathy and Malcolm McCulloch", "title": "Electric Vehicle transition in the UK", "comments": "To be published in journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an overview of the electric vehicle transition in the UK.\nThe spatial disparity in the uptake of BEVs across the different regions is\nanalysed using historic BEV sales. A forecast for future growth in BEVs\n(ignoring the impact of Covid-19) is performed using an s-curve model.\nCurrently, South East England and Greater London have the highest BEV sales as\na percentage of new vehicle sales. The spatial distribution of EV chargers\nacross the different regions is also analysed. The spatial analysis clearly\nshows the regional disparity in the uptake of EV. South East England has the\nhighest number of public chargers excluding Greater London. However, if we\nconsider the number of EVs in that region, it has the second-lowest ratio of\napprox. 1 charger per 10 BEV. The lowest ratio being 0.8 in the West Midlands.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 13:03:20 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Bhagavathy", "Sivapriya Mothilal", ""], ["McCulloch", "Malcolm", ""]]}, {"id": "2007.03787", "submitter": "Anya Vostinar", "authors": "Anya E. Vostinar, Barbara Z. Johnson, and Kevin Connors", "title": "Artificial Life in Game Mods for Intuitive Evolution Education", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding and acceptance of evolution by natural selection has become\na difficult issue in many parts of the world, particularly the United States of\nAmerica. The use of games to improve intuition about evolution via natural\nselection is promising but can be challenging. We propose the use of\nmodifications to commercial games using artificial life techniques to 'stealth\nteach' about evolution via natural selection, provide a proof-of-concept mod of\nthe game Stardew Valley, and report on its initial reception.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 21:04:10 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Vostinar", "Anya E.", ""], ["Johnson", "Barbara Z.", ""], ["Connors", "Kevin", ""]]}, {"id": "2007.03819", "submitter": "Charlie Welch", "authors": "Charles Welch, Allison Lahnala, Ver\\'onica P\\'erez-Rosas, Siqi Shen,\n  Sarah Seraj, Larry An, Kenneth Resnicow, James Pennebaker, Rada Mihalcea", "title": "Expressive Interviewing: A Conversational System for Coping with\n  COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing COVID-19 pandemic has raised concerns for many regarding personal\nand public health implications, financial security and economic stability.\nAlongside many other unprecedented challenges, there are increasing concerns\nover social isolation and mental health. We introduce \\textit{Expressive\nInterviewing}--an interview-style conversational system that draws on ideas\nfrom motivational interviewing and expressive writing. Expressive Interviewing\nseeks to encourage users to express their thoughts and feelings through writing\nby asking them questions about how COVID-19 has impacted their lives. We\npresent relevant aspects of the system's design and implementation as well as\nquantitative and qualitative analyses of user interactions with the system. In\naddition, we conduct a comparative evaluation with a general purpose dialogue\nsystem for mental health that shows our system potential in helping users to\ncope with COVID-19 issues.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 22:52:14 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Welch", "Charles", ""], ["Lahnala", "Allison", ""], ["P\u00e9rez-Rosas", "Ver\u00f3nica", ""], ["Shen", "Siqi", ""], ["Seraj", "Sarah", ""], ["An", "Larry", ""], ["Resnicow", "Kenneth", ""], ["Pennebaker", "James", ""], ["Mihalcea", "Rada", ""]]}, {"id": "2007.03879", "submitter": "Sanchu Han", "authors": "Sanchu Han, Yong He, Yin Ding", "title": "Enable an Open Software Defined Mobility Ecosystem through VEC-OF", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OEMs and new entrants can take the Mobility as a Service market (MaaS) as the\nentry point, upgrade its E/E (Electric and Electronic) architecture to be C/C\n(Computing and Communication) architecture, build one open software defined and\ndata driven software platform for its production and service model, use\nefficient and collaborative ways of vehicles, roads, cloud and network to\ncontinuously improve core technologies such as autonomous driving, provide MaaS\noperators with an affordable and agile platform. In this paper we present one\nnew framework, VEC-OF (Vehicle-Edge-Cloud Open Framework), which is a new data\nand AI centric vehicle software framework enabling a much safer, more\nefficient, connected and trusted MaaS through cooperative vehicle,\ninfrastructure and cloud capabilities and intelligence\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 03:38:38 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Han", "Sanchu", ""], ["He", "Yong", ""], ["Ding", "Yin", ""]]}, {"id": "2007.03941", "submitter": "Laura Aymerich-Franch", "authors": "Laura Aymerich-Franch, Iliana Ferrer", "title": "The implementation of social robots during the COVID-19 pandemic", "comments": "10 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study examines the implementation of social robots in real\nsettings during the COVID-19 pandemic. In particular, we analyze the areas in\nwhich social robots are being adopted, the roles and tasks being fulfilled, and\nthe robot models being implemented. For that, we traced back and analyzed 195\nexperiences with 66 different social robots worldwide that have been adopted\nduring the coronavirus outbreak. We identified a clear resurgence and expansion\nof social robots during the crisis. The social robots' capacity to perform the\nroles of liaison in tasks that require human-human interaction, to act as a\nsafeguard to ensure contagion risk-free environments, and to act as well-being\ncoaches by providing therapeutic and entertaining functions for quarantined\npatients, which are directly associated with the needs of facilitating physical\ndistance and palliate the effects of isolation, have been key to the\nrenaissance of these robots during the pandemic.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 07:52:30 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 08:30:10 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 11:43:09 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Aymerich-Franch", "Laura", ""], ["Ferrer", "Iliana", ""]]}, {"id": "2007.04060", "submitter": "Andik Asmara", "authors": "Andik Asmara", "title": "Study on Computational Thinking as Problem-solving Skill: Comparison\n  Based on Students Mindset in Engineering and Social Science", "comments": "If you have suggestions on questions, please feel free email me.\n  Thank You", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the capabilities which 21st-century skill compulsory a person is\ncritical thinking and problem-solving skill that becomes top positions rank.\nFocus on problem-solving skills can be taught to a child, especially begun in\nelementary school refer to prior research focus on K-12. Computational thinking\nwas one problem-solving skill that popular to implemented and studied in the\ncurrent decade. This study was conducted to explore students' capability to be\nable solving of the problem based on the possibility use the computational\nthinking way. Participants in this study came from six international students\nthat study in Taiwan and from two deferent sciences disciplines, engineering,\nand social science. A qualitative method was used to analyze data interviews,\ntook example cases from the global issue that is Climate Change. The result\nfounded that survive in a new environment was become evidence of their\nimplementation of problem-solving skills. Problem-solving mindset both students\nof engineering and social science had discrepancy, those are how to use precise\nstructure in the algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 12:19:04 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Asmara", "Andik", ""]]}, {"id": "2007.04068", "submitter": "Shakir Mohamed", "authors": "Shakir Mohamed, Marie-Therese Png, William Isaac", "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in\n  Artificial Intelligence", "comments": "28 Pages. Accepted, to appear in: Philosophy and Technology (405),\n  Springer. Submitted 16 January, Accepted 26 May 2020", "journal-ref": null, "doi": "10.1007/s13347-020-00405-8", "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the important role of critical science, and in particular\nof post-colonial and decolonial theories, in understanding and shaping the\nongoing advances in artificial intelligence. Artificial Intelligence (AI) is\nviewed as amongst the technological advances that will reshape modern societies\nand their relations. Whilst the design and deployment of systems that\ncontinually adapt holds the promise of far-reaching positive change, they\nsimultaneously pose significant risks, especially to already vulnerable\npeoples. Values and power are central to this discussion. Decolonial theories\nuse historical hindsight to explain patterns of power that shape our\nintellectual, political, economic, and social world. By embedding a decolonial\ncritical approach within its technical practice, AI communities can develop\nforesight and tactics that can better align research and technology development\nwith established ethical principles, centring vulnerable peoples who continue\nto bear the brunt of negative impacts of innovation and scientific progress. We\nhighlight problematic applications that are instances of coloniality, and using\na decolonial lens, submit three tactics that can form a decolonial field of\nartificial intelligence: creating a critical technical practice of AI, seeking\nreverse tutelage and reverse pedagogies, and the renewal of affective and\npolitical communities. The years ahead will usher in a wave of new scientific\nbreakthroughs and technologies driven by AI research, making it incumbent upon\nAI communities to strengthen the social contract through ethical foresight and\nthe multiplicity of intellectual perspectives available to us; ultimately\nsupporting future technologies that enable greater well-being, with the goal of\nbeneficence and justice for all.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 12:36:21 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Mohamed", "Shakir", ""], ["Png", "Marie-Therese", ""], ["Isaac", "William", ""]]}, {"id": "2007.04109", "submitter": "Sajedul Talukder", "authors": "Sajedul Talukder and Md. Iftekharul Islam Sakib and Zahidur Talukder", "title": "Giving Up Privacy For Security: A Survey On Privacy Trade-off During\n  Pandemic Emergency", "comments": "20 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the COVID-19 pandemic continues to be as complex as ever, the\ncollection and exchange of data in the light of fighting coronavirus poses a\nmajor challenge for privacy systems around the globe. The disease's size and\nmagnitude is not uncommon but it appears to be at the point of hysteria\nsurrounding it. Consequently, in a very short time, extreme measures for\ndealing with the situation appear to have become the norm. Any such actions\naffect the privacy of individuals in particular. For some cases, there is\nintensive monitoring of the whole population while the medical data of those\ndiagnosed with the virus is commonly circulated through institutions and\nnations. This may well be in the interest of saving the world from a deadly\ndisease, but is it really appropriate and right? Although creative solutions\nhave been implemented in many countries to address the issue, proponents of\nprivacy are concerned that technologies will eventually erode privacy, while\nregulators and privacy supporters are worried about what kind of impact this\ncould bring. While that tension has always been present, privacy has been\nthrown into sharp relief by the sheer urgency of containing an exponentially\nspreading virus. The essence of this dilemma indicates that establishing the\nright equilibrium will be the best solution. The jurisprudence concerning cases\nregarding the willingness of public officials to interfere with the\nconstitutional right to privacy in the interests of national security or public\nhealth has repeatedly proven that a reasonable balance can be reached.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 09:14:27 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Talukder", "Sajedul", ""], ["Sakib", "Md. Iftekharul Islam", ""], ["Talukder", "Zahidur", ""]]}, {"id": "2007.04125", "submitter": "Peter Hillmann", "authors": "Matthias Schopp, Peter Hillmann", "title": "Agile Approach for IT Forensics Management", "comments": "Journal of Internet Technology and Secured Transactions (JITST) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.IR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The forensic investigation of cyber attacks and IT incidents is becoming\nincreasingly difficult due to increasing complexity and intensify networking.\nEspecially with Advanced Attacks (AT) like the increasing Advanced Persistent\nThreats an agile approach is indispensable. Several systems are involved in an\nattack (multi-host attacks). Current forensic models and procedures show\nconsiderable deficits in the process of analyzing such attacks. For this\npurpose, this paper presents the novel flower model, which uses agile methods\nand forms a new forensic management approach. In this way, the growing\nchallenges of ATs are met. In the forensic investigation of such attacks, big\ndata problems have to be solved due to the amount of data that needs to be\nanalyzed. The proposed model meets this requirement by precisely defining the\nquestions that need to be answered in an early state and collecting only the\nevidence usable in court proceedings that is needed to answer these questions.\nAdditionally, the novel flower model for AT is presented that meets the\ndifferent phases of an investigation process.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 13:48:50 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Schopp", "Matthias", ""], ["Hillmann", "Peter", ""]]}, {"id": "2007.04181", "submitter": "Dylan Grosz", "authors": "Dylan Grosz, Patricia Conde-Cespedes", "title": "Automatic Detection of Sexist Statements Commonly Used at the Workplace", "comments": "Published at the PAKDD 2020 Workshop on Learning Data Representation\n  for Clustering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting hate speech in the workplace is a unique classification task, as\nthe underlying social context implies a subtler version of conventional hate\nspeech. Applications regarding a state-of the-art workplace sexism detection\nmodel include aids for Human Resources departments, AI chatbots and sentiment\nanalysis. Most existing hate speech detection methods, although robust and\naccurate, focus on hate speech found on social media, specifically Twitter. The\ncontext of social media is much more anonymous than the workplace, therefore it\ntends to lend itself to more aggressive and \"hostile\" versions of sexism.\nTherefore, datasets with large amounts of \"hostile\" sexism have a slightly\neasier detection task since \"hostile\" sexist statements can hinge on a couple\nwords that, regardless of context, tip the model off that a statement is\nsexist. In this paper we present a dataset of sexist statements that are more\nlikely to be said in the workplace as well as a deep learning model that can\nachieve state-of-the art results. Previous research has created\nstate-of-the-art models to distinguish \"hostile\" and \"benevolent\" sexism based\nsimply on aggregated Twitter data. Our deep learning methods, initialized with\nGloVe or random word embeddings, use LSTMs with attention mechanisms to\noutperform those models on a more diverse, filtered dataset that is more\ntargeted towards workplace sexism, leading to an F1 score of 0.88.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:14:29 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Grosz", "Dylan", ""], ["Conde-Cespedes", "Patricia", ""]]}, {"id": "2007.04183", "submitter": "Alan Smeaton", "authors": "Alan Smeaton and Hyowon Lee and Niamh Morris and David Hanley", "title": "Using Online Implicit Association Tests in Opinion Polling", "comments": "17 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinion polls have now become a very important component of society because\nthey are now a defacto component of our daily news cycle and because their\nresults influence governments and business in ways which are not always obvious\nto us. However, polling is not always accurate and there have been some really\ninaccurate polling results which have had major influences on the world going\nback to the 1930s but also as recently as just the last 3 or 4 years. In this\npaper we analyse the phenomenon of socially desirable responding (shy voters)\nwhich has emerged as one of the reasons for modern day inaccurate polling. We\ndescribe how it can be exposed through implicit association tests (IATs) and we\ndemonstrate the shy voter effect in a small survey on opinions in Ireland\ntowards the United Kingdom. We argue for inclusion of IATs in traditional\npolling and point to the fact that these can be conducted accurately online,\nwhich also allows polling to reach a larger and more diverse sample of\nrespondents in the days of Covid-19 restrictions which restricts the\nopportunities for poll sampling from the general public.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 15:16:15 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Smeaton", "Alan", ""], ["Lee", "Hyowon", ""], ["Morris", "Niamh", ""], ["Hanley", "David", ""]]}, {"id": "2007.04456", "submitter": "Faisal Hussain", "authors": "Ivan Miguel Pires, Faisal Hussain, Nuno M. Garcia, Eftim Zdravevski", "title": "An Efficient Data Imputation Technique for Human Activity Recognition", "comments": "8 Pages, 8 Figures, 1 Table. Accepted in 14th Multi Conference on\n  Computer Science and Information Systems 2020 (MCCSIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous applications of human activity recognition are surging its\nspan from health monitoring systems to virtual reality applications. Thus, the\nautomatic recognition of daily life activities has become significant for\nnumerous applications. In recent years, many datasets have been proposed to\ntrain the machine learning models for efficient monitoring and recognition of\nhuman daily living activities. However, the performance of machine learning\nmodels in activity recognition is crucially affected when there are incomplete\nactivities in a dataset, i.e., having missing samples in dataset captures.\nTherefore, in this work, we propose a methodology for extrapolating the missing\nsamples of a dataset to better recognize the human daily living activities. The\nproposed method efficiently pre-processes the data captures and utilizes the\nk-Nearest Neighbors (KNN) imputation technique to extrapolate the missing\nsamples in dataset captures. The proposed methodology elegantly extrapolated a\nsimilar pattern of activities as they were in the real dataset.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 22:05:38 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Pires", "Ivan Miguel", ""], ["Hussain", "Faisal", ""], ["Garcia", "Nuno M.", ""], ["Zdravevski", "Eftim", ""]]}, {"id": "2007.04484", "submitter": "Aria Shahverdi", "authors": "Mingliang Chen, Aria Shahverdi, Sarah Anderson, Se Yong Park, Justin\n  Zhang, Dana Dachman-Soled, Kristin Lauter, Min Wu", "title": "Transparency Tools for Fairness in AI (Luskin)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new tools for policy-makers to use when assessing and correcting\nfairness and bias in AI algorithms. The three tools are:\n  - A new definition of fairness called \"controlled fairness\" with respect to\nchoices of protected features and filters. The definition provides a simple\ntest of fairness of an algorithm with respect to a dataset. This notion of\nfairness is suitable in cases where fairness is prioritized over accuracy, such\nas in cases where there is no \"ground truth\" data, only data labeled with past\ndecisions (which may have been biased).\n  - Algorithms for retraining a given classifier to achieve \"controlled\nfairness\" with respect to a choice of features and filters. Two algorithms are\npresented, implemented and tested. These algorithms require training two\ndifferent models in two stages. We experiment with combinations of various\ntypes of models for the first and second stage and report on which combinations\nperform best in terms of fairness and accuracy.\n  - Algorithms for adjusting model parameters to achieve a notion of fairness\ncalled \"classification parity\". This notion of fairness is suitable in cases\nwhere accuracy is prioritized. Two algorithms are presented, one which assumes\nthat protected features are accessible to the model during testing, and one\nwhich assumes protected features are not accessible during testing.\n  We evaluate our tools on three different publicly available datasets. We find\nthat the tools are useful for understanding various dimensions of bias, and\nthat in practice the algorithms are effective in starkly reducing a given\nobserved bias when tested on new data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 00:21:54 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Chen", "Mingliang", ""], ["Shahverdi", "Aria", ""], ["Anderson", "Sarah", ""], ["Park", "Se Yong", ""], ["Zhang", "Justin", ""], ["Dachman-Soled", "Dana", ""], ["Lauter", "Kristin", ""], ["Wu", "Min", ""]]}, {"id": "2007.04508", "submitter": "Dustin Stoltz", "authors": "Dustin S. Stoltz and Marshall A. Taylor", "title": "Cultural Cartography with Word Embeddings", "comments": null, "journal-ref": null, "doi": "10.1016/j.poetic.2021.101567", "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Using the frequency of keywords is a classic approach in the formal analysis\nof text, but has the drawback of glossing over the relationality of word\nmeanings. Word embedding models overcome this problem by constructing a\nstandardized and continuous \"meaning space\" where words are assigned a location\nbased on relations of similarity to other words based on how they are used in\nnatural language samples. We show how word embeddings are commensurate with\nprevailing theories of meaning in sociology and can be put to the task of\ninterpretation via two kinds of navigation. First, one can hold terms constant\nand measure how the embedding space moves around them--much like astronomers\nmeasured the changing of celestial bodies with the seasons. Second, one can\nalso hold the embedding space constant and see how documents or authors move\nrelative to it--just as ships use the stars on a given night to determine their\nlocation. Using the empirical case of immigration discourse in the United\nStates, we demonstrate the merits of these two broad strategies for advancing\nimportant topics in cultural theory, including social marking, media fields,\necho chambers, and cultural diffusion and change more broadly.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 01:58:28 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 20:58:20 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 15:48:56 GMT"}, {"version": "v4", "created": "Mon, 3 May 2021 21:13:27 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Stoltz", "Dustin S.", ""], ["Taylor", "Marshall A.", ""]]}, {"id": "2007.04583", "submitter": "Xin Liu Dr.", "authors": "Hibiki Taguchi, Xin Liu, Tsuyoshi Murata", "title": "Graph Convolutional Networks for Graphs Containing Missing Features", "comments": null, "journal-ref": "Future Generation Computer Systems, Volume 117, Pages 155-168,\n  2021", "doi": "10.1016/j.future.2020.11.016", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Network (GCN) has experienced great success in graph\nanalysis tasks. It works by smoothing the node features across the graph. The\ncurrent GCN models overwhelmingly assume that the node feature information is\ncomplete. However, real-world graph data are often incomplete and containing\nmissing features. Traditionally, people have to estimate and fill in the\nunknown features based on imputation techniques and then apply GCN. However,\nthe process of feature filling and graph learning are separated, resulting in\ndegraded and unstable performance. This problem becomes more serious when a\nlarge number of features are missing. We propose an approach that adapts GCN to\ngraphs containing missing features. In contrast to traditional strategy, our\napproach integrates the processing of missing features and graph learning\nwithin the same neural network architecture. Our idea is to represent the\nmissing data by Gaussian Mixture Model (GMM) and calculate the expected\nactivation of neurons in the first hidden layer of GCN, while keeping the other\nlayers of the network unchanged. This enables us to learn the GMM parameters\nand network weight parameters in an end-to-end manner. Notably, our approach\ndoes not increase the computational complexity of GCN and it is consistent with\nGCN when the features are complete. We demonstrate through extensive\nexperiments that our approach significantly outperforms the imputation-based\nmethods in node classification and link prediction tasks. We show that the\nperformance of our approach for the case with a low level of missing features\nis even superior to GCN for the case with complete features.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 06:47:21 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 13:07:35 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Taguchi", "Hibiki", ""], ["Liu", "Xin", ""], ["Murata", "Tsuyoshi", ""]]}, {"id": "2007.04608", "submitter": "Geoffrey Goodell", "authors": "Geoffrey Goodell", "title": "Serverless Electronic Mail", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a simple approach to peer-to-peer electronic mail that would\nallow users of ordinary workstations and mobile devices to exchange messages\nwithout relying upon third-party mail server operators. Crucially, the system\nallows participants to establish and use multiple unlinked identities for\ncommunication with each other. The architecture leverages ordinary SMTP for\nmessage delivery and Tor for peer-to-peer communication. The design offers a\nrobust, unintrusive method to use self-certifying Tor onion service names to\nbootstrap a web of trust based on public keys for end-to-end authentication and\nencryption, which in turn can be used to facilitate message delivery when the\nsender and recipient are not online simultaneously. We show how the system can\ninteroperate with existing email systems and paradigms, allowing users to hold\nmessages that others can retrieve via IMAP or to operate as a relay between\nsystem participants and external email users. Finally, we show how it is\npossible to use a broadcast protocol to implement mailing lists and how\ndistributed ledger technology might be used to bootstrap consensus about shared\nknowledge among list members.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 07:35:29 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 17:32:53 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Goodell", "Geoffrey", ""]]}, {"id": "2007.04611", "submitter": "Gregory Palmer", "authors": "Gregory Palmer, Mark Green, Emma Boyland, Yales Stefano Rios\n  Vasconcelos, Rahul Savani, Alex Singleton", "title": "A deep learning approach to identify unhealthy advertisements in street\n  view images", "comments": "13 pages, 5 figures, 3 table. To appear in Nature Scientific Reports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While outdoor advertisements are common features within towns and cities,\nthey may reinforce social inequalities in health. Vulnerable populations in\ndeprived areas may have greater exposure to fast food, gambling and alcohol\nadvertisements encouraging their consumption. Understanding who is exposed and\nevaluating potential policy restrictions requires a substantial manual data\ncollection effort. To address this problem we develop a deep learning workflow\nto automatically extract and classify unhealthy advertisements from\nstreet-level images. We introduce the Liverpool 360 Street View (LIV360SV)\ndataset for evaluating our workflow. The dataset contains 25,349, 360 degree,\nstreet-level images collected via cycling with a GoPro Fusion camera, recorded\nJan 14th - 18th 2020. 10,106 advertisements were identified and classified as\nfood (1335), alcohol (217), gambling (149) and other (8405) (e.g., cars and\nbroadband). We find evidence of social inequalities with a larger proportion of\nfood advertisements located within deprived areas and those frequented by\nstudents. Our project presents a novel implementation for the incidental\nclassification of street view images for identifying unhealthy advertisements,\nproviding a means through which to identify areas that can benefit from tougher\nadvertisement restriction policies for tackling social inequalities.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 07:44:43 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 19:58:40 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Palmer", "Gregory", ""], ["Green", "Mark", ""], ["Boyland", "Emma", ""], ["Vasconcelos", "Yales Stefano Rios", ""], ["Savani", "Rahul", ""], ["Singleton", "Alex", ""]]}, {"id": "2007.04693", "submitter": "Erick Galinkin", "authors": "Abhishek Gupta, Erick Galinkin", "title": "Green Lighting ML: Confidentiality, Integrity, and Availability of\n  Machine Learning Systems in Deployment", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Security and ethics are both core to ensuring that a machine learning system\ncan be trusted. In production machine learning, there is generally a hand-off\nfrom those who build a model to those who deploy a model. In this hand-off, the\nengineers responsible for model deployment are often not privy to the details\nof the model and thus, the potential vulnerabilities associated with its usage,\nexposure, or compromise. Techniques such as model theft, model inversion, or\nmodel misuse may not be considered in model deployment, and so it is incumbent\nupon data scientists and machine learning engineers to understand these\npotential risks so they can communicate them to the engineers deploying and\nhosting their models. This is an open problem in the machine learning community\nand in order to help alleviate this issue, automated systems for validating\nprivacy and security of models need to be developed, which will help to lower\nthe burden of implementing these hand-offs and increasing the ubiquity of their\nadoption.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 10:38:59 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Gupta", "Abhishek", ""], ["Galinkin", "Erick", ""]]}, {"id": "2007.04696", "submitter": "Anastasija Nikiforova", "authors": "Anastasija Nikiforova, Zane Bicevska", "title": "Application of LEAN Principles to Improve Business Processes: a Case\n  Study in Latvian IT Company", "comments": "24 pages, 7 figure, 4 tables, Baltic J. Modern Computing", "journal-ref": "Baltic J. Modern Computing, Vol. 6 (2018), No. 3, 247-270", "doi": "10.22364/bjmc.2018.6.3.03", "report-no": null, "categories": "cs.SE cs.CY cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research deals with application of the LEAN principles to business\nprocesses of a typical IT company. The paper discusses LEAN principles\namplifying advantages and shortcomings of their application. The authors\nsuggest use of the LEAN principles as a tool to identify improvement potential\nfor IT company's business processes and work-flow efficiency. During a case\nstudy the implementation of LEAN principles has been exemplified in business\nprocesses of a particular Latvian IT company. The obtained results and\nconclusions can be used for meaningful and successful application of LEAN\nprinciples and methods in projects of other IT companies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 10:42:58 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nikiforova", "Anastasija", ""], ["Bicevska", "Zane", ""]]}, {"id": "2007.04697", "submitter": "Anastasija Nikiforova", "authors": "Anastasija Nikiforova", "title": "Open Data Quality Evaluation: A Comparative Analysis of Open Data in\n  Latvia", "comments": "24 pages, 2 tables, 3 figures, Baltic J. Modern Computing", "journal-ref": "Baltic J. Modern Computing, Vol. 6(2018), No. 4, 363-386", "doi": "10.22364/bjmc.2018.6.4.04", "report-no": null, "categories": "cs.DB cs.CY cs.IR stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays open data is entering the mainstream - it is free available for\nevery stakeholder and is often used in business decision-making. It is\nimportant to be sure data is trustable and error-free as its quality problems\ncan lead to huge losses. The research discusses how (open) data quality could\nbe assessed. It also covers main points which should be considered developing a\ndata quality management solution. One specific approach is applied to several\nLatvian open data sets. The research provides a step-by-step open data sets\nanalysis guide and summarizes its results. It is also shown there could exist\ndifferences in data quality depending on data supplier (centralized and\ndecentralized data releases) and, unfortunately, trustable data supplier cannot\nguarantee data quality problems absence. There are also underlined common data\nquality problems detected not only in Latvian open data but also in open data\nof 3 European countries.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 10:43:28 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nikiforova", "Anastasija", ""]]}, {"id": "2007.04912", "submitter": "Mokhtar Ben Henda", "authors": "Mokhtar Ben Henda", "title": "GUIDE for a blended learning system", "comments": "104 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This guide is proposed as an operational instrument for CONFRASIE member\nuniversities (Regional Rectors' Conference of AUF member institutions in\nPacific-Asia) in their projects to set up a blended learning system for\nbachelor's, Master's and Doctorate degrees. It is structured in sections\ncorresponding to a complete process of operationalizing a blended learning\nsystem, from the definition of an implementation strategy to the assessment of\nresults. This guide covers also conceptual and theoretical fundamentals of\ndistance learning as well as methodological and procedural tips and\nrecommendations on how to implement blended learning in an existing\nface-to-face curriculum. It can serve for leaders of educational ICT-based\nprojects as a guidance document to take pedagogical, technological and\nmethodological decisions for the development, monitoring and assessment of a\nblended learning curricula. This guide can be augmented by other standards,\ntool and software manuals offering further training materials and guidelines on\neducational skills ans=d services.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 16:21:14 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Henda", "Mokhtar Ben", ""]]}, {"id": "2007.05039", "submitter": "Timothy Hazen", "authors": "Timothy J. Hazen and Alexandra Olteanu and Gabriella Kazai and\n  Fernando Diaz and Michael Golebiewski", "title": "On the Social and Technical Challenges of Web Search Autosuggestion\n  Moderation", "comments": "17 Pages, 4 images displayed within 3 latex figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Past research shows that users benefit from systems that support them in\ntheir writing and exploration tasks. The autosuggestion feature of Web search\nengines is an example of such a system: It helps users in formulating their\nqueries by offering a list of suggestions as they type. Autosuggestions are\ntypically generated by machine learning (ML) systems trained on a corpus of\nsearch logs and document representations. Such automated methods can become\nprone to issues that result in problematic suggestions that are biased, racist,\nsexist or in other ways inappropriate. While current search engines have become\nincreasingly proficient at suppressing such problematic suggestions, there are\nstill persistent issues that remain. In this paper, we reflect on past efforts\nand on why certain issues still linger by covering explored solutions along a\nprototypical pipeline for identifying, detecting, and addressing problematic\nautosuggestions. To showcase their complexity, we discuss several dimensions of\nproblematic suggestions, difficult issues along the pipeline, and why our\ndiscussion applies to the increasing number of applications beyond web search\nthat implement similar textual suggestion features. By outlining persistent\nsocial and technical challenges in moderating web search suggestions, we\nprovide a renewed call for action.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 19:22:00 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Hazen", "Timothy J.", ""], ["Olteanu", "Alexandra", ""], ["Kazai", "Gabriella", ""], ["Diaz", "Fernando", ""], ["Golebiewski", "Michael", ""]]}, {"id": "2007.05057", "submitter": "Tom Lovett", "authors": "Tom Lovett, Mark Briers, Marcos Charalambides, Radka Jersakova, James\n  Lomax and Chris Holmes", "title": "Inferring proximity from Bluetooth Low Energy RSSI with Unscented Kalman\n  Smoothers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Covid-19 pandemic has resulted in a variety of approaches for managing\ninfection outbreaks in international populations. One example is mobile phone\napplications, which attempt to alert infected individuals and their contacts by\nautomatically inferring two key components of infection risk: the proximity to\nan individual who may be infected, and the duration of proximity. The former\ncomponent, proximity, relies on Bluetooth Low Energy (BLE) Received Signal\nStrength Indicator(RSSI) as a distance sensor, and this has been shown to be\nproblematic; not least because of unpredictable variations caused by different\ndevice types, device location on-body, device orientation, the local\nenvironment and the general noise associated with radio frequency propagation.\nIn this paper, we present an approach that infers posterior probabilities over\ndistance given sequences of RSSI values. Using a single-dimensional Unscented\nKalman Smoother (UKS) for non-linear state space modelling, we outline several\nGaussian process observation transforms, including: a generative model that\ndirectly captures sources of variation; and a discriminative model that learns\na suitable observation function from training data using both distance and\ninfection risk as optimisation objective functions. Our results show that good\nrisk prediction can be achieved in $\\mathcal{O}(n)$ time on real-world data\nsets, with the UKS outperforming more traditional classification methods\nlearned from the same training data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 20:47:02 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Lovett", "Tom", ""], ["Briers", "Mark", ""], ["Charalambides", "Marcos", ""], ["Jersakova", "Radka", ""], ["Lomax", "James", ""], ["Holmes", "Chris", ""]]}, {"id": "2007.05075", "submitter": "R. Pito Salas", "authors": "R. Pito Salas", "title": "Reusable Learning Objects: An Agile Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses Reusable Learning Objects (RLOs) and to what extent they\nhave lived up to the promise, particularly of reusability. Reusable Learning\nObjects have actually been discussed in the literature for the last 20 years\nand yet true large scale sharing of learning and teaching materials remains\nrelatively rare and challenging. This paper argues that part of the reason is\nthat the granularity of the learning objects that are in use today is not\nconducive to true reuse. Certainly whole PowerPoint slide decks and word\ndocuments are kept in individual files and folders. It is not an ideal\nsituation. As a result, educators, teachers, course designers, are constantly\nreinventing the wheel, or searching for where that one excellent assignment,\nexplanation, definition was last seen so it can be copied forward. This paper\nargues that to achieve effective reuse of Learning Objects, the following are\nrequired: smaller, more granular (micro) learning objects; means to combine\nthem into larger presentation products; and modern revision and version\ncontrol. The paper proposes applying approaches originating in the software\nengineering community, such as agile methodology, version control and\nmanagement, markup languages, and agile publishing, which together form the\nAgile Approach of the title of the paper. With that foundation laid, the paper\nexamines CourseGen, an open source software platform designed for creating,\nsharing, reusing and publishing reusable course content. CourseGen uses a\nmodified markdown format augmented by CourseGen specific directives, such as\n$link to and $include topic. The CourseGen compiler converts a collection of\nCourseGen files into the final format such as a web site or a PowerPoint.\nCourseGen was designed, used and refined over the last three years in several\nComputer Science Courses at Brandeis University.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 21:27:47 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Salas", "R. Pito", ""]]}, {"id": "2007.05129", "submitter": "Ashutosh Saxena", "authors": "Ashutosh Saxena and David R Cheriton", "title": "Senior Living Communities: Made Safer by AI", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is a historically unprecedented shift in demographics towards seniors,\nwhich will result in significant housing development over the coming decade.\nThis is an enormous opportunity for real-estate operators to innovate and\naddress the demand in this growing market. However, investments in this area\nare fraught with risk. Seniors often have more health issues, and Covid-19 has\nexposed just how vulnerable they are -- especially those living in close\nproximity. Conventionally, most services for seniors are \"high-touch\",\nrequiring close physical contact with trained caregivers. Not only are trained\ncaregivers short in supply, but the pandemic has made it evident that\nconventional high-touch approaches to senior care are high-cost and greater\nrisk. There are not enough caregivers to meet the needs of this emerging\ndemographic, and even fewer who want to undertake the additional training and\nrisk of working in a senior facility, especially given the current pandemic. In\nthis article, we rethink the design of senior living facilities to mitigate the\nrisks and costs using automation. With AI-enabled pervasive automation, we\nclaim there is an opportunity, if not an urgency, to go from high-touch to\nalmost \"no touch\" while dramatically reducing risk and cost. Although our\nvision goes beyond the current reality, we cite measurements from Caspar\nAI-enabled senior properties that show the potential benefit of this approach.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 01:13:54 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 02:52:45 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 03:00:45 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Saxena", "Ashutosh", ""], ["Cheriton", "David R", ""]]}, {"id": "2007.05259", "submitter": "Oksana Kulyk", "authors": "Camilla Nadja Fleron, Jonas Kofod J{\\o}rgensen, Oksana Kulyk, and Elda\n  Paja", "title": "\"It's Not Something We Have Talked to Our Team About\": Results From a\n  Preliminary Investigation of Cybersecurity Challenges in Denmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although Denmark is reportedly one of the most digitised countries in Europe,\nIT security in Danish companies has not followed along. To shed light into the\nchallenges that companies experience with implementing IT security, we\nconducted a preliminary study running semi-structured interviews with four\nemployees from four different companies, asking about their IT security and\nwhat they need to reduce risks of cyber threats. Our results show that\ncompanies are lacking fundamental security protection and are in need of\nguidance and tools to help them implementing basic security practices, while\nraising awareness of cyber threats. Based on our findings and with the\ninspiration of the latest reports and international security standards, we\ndiscuss steps towards further investigation towards developing a framework\ntargeting SMEs that want to adopt straightforward and actionable IT security\nguidance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 09:07:39 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Fleron", "Camilla Nadja", ""], ["J\u00f8rgensen", "Jonas Kofod", ""], ["Kulyk", "Oksana", ""], ["Paja", "Elda", ""]]}, {"id": "2007.05373", "submitter": "Joris Dugueperoux", "authors": "Joris Dugu\\'ep\\'eroux (DRUID), Tristan Allard (DRUID)", "title": "From Task Tuning to Task Assignment in Privacy-Preserving Crowdsourcing\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DB cs.DC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Specialized worker profiles of crowdsourcing platforms may contain a large\namount of identifying and possibly sensitive personal information (e.g.,\npersonal preferences, skills, available slots, available devices) raising\nstrong privacy concerns. This led to the design of privacy-preserving\ncrowdsourcing platforms, that aim at enabling efficient crowd-sourcing\nprocesses while providing strong privacy guarantees even when the platform is\nnot fully trusted. In this paper, we propose two contributions. First, we\npropose the PKD algorithm with the goal of supporting a large variety of\naggregate usages of worker profiles within a privacy-preserving crowdsourcing\nplatform. The PKD algorithm combines together homomorphic encryption and\ndifferential privacy for computing (perturbed) partitions of the\nmulti-dimensional space of skills of the actual population of workers and a\n(perturbed) COUNT of workers per partition. Second, we propose to benefit from\nrecent progresses in Private Information Retrieval techniques in order to\ndesign a solution to task assignment that is both private and affordable. We\nperform an in-depth study of the problem of using PIR techniques for proposing\ntasks to workers, show that it is NP-Hard, and come up with the PKD PIR Packing\nheuristic that groups tasks together according to the partitioning output by\nthe PKD algorithm. In a nutshell, we design the PKD algorithm and the PKD PIR\nPacking heuristic, we prove formally their security against honest-but-curious\nworkers and/or platform, we analyze their complexities, and we demonstrate\ntheir quality and affordability in real-life scenarios through an extensive\nexperimental evaluation performed over both synthetic and realistic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 13:21:18 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Dugu\u00e9p\u00e9roux", "Joris", "", "DRUID"], ["Allard", "Tristan", "", "DRUID"]]}, {"id": "2007.05394", "submitter": "Sao Mai Nguyen", "authors": "Linda Nanan Vall\\'ee (ESATIC), Sao Mai Nguyen (IMT Atlantique, IMT\n  Atlantique - INFO, Lab-STICC, Flowers), Christophe Lohr (Lab-STICC, IMT\n  Atlantique - INFO, IMT Atlantique), Ioannis Kanellos (Lab-STICC, IMT\n  Atlantique - INFO, IMT Atlantique), Olivier Asseu (ESATIC)", "title": "How An Automated Gesture Imitation Game Can Improve Social Interactions\n  With Teenagers With ASD", "comments": null, "journal-ref": "IEEE ICRA Workshop on Social Robotics for Neurodevelopmental\n  Disorders, Jun 2020, Paris, France", "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the outlook of improving communication and social abilities of people\nwith ASD, we propose to extend the paradigm of robot-based imitation games to\nASD teenagers. In this paper, we present an interaction scenario adapted to ASD\nteenagers, propose a computational architecture using the latest machine\nlearning algorithm Openpose for human pose detection, and present the results\nof our basic testing of the scenario with human caregivers. These results are\npreliminary due to the number of session (1) and participants (4). They include\na technical assessment of the performance of Openpose, as well as a preliminary\nuser study to confirm our game scenario could elicit the expected response from\nsubjects.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 14:01:24 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Vall\u00e9e", "Linda Nanan", "", "ESATIC"], ["Nguyen", "Sao Mai", "", "IMT Atlantique, IMT\n  Atlantique - INFO, Lab-STICC, Flowers"], ["Lohr", "Christophe", "", "Lab-STICC, IMT\n  Atlantique - INFO, IMT Atlantique"], ["Kanellos", "Ioannis", "", "Lab-STICC, IMT\n  Atlantique - INFO, IMT Atlantique"], ["Asseu", "Olivier", "", "ESATIC"]]}, {"id": "2007.05408", "submitter": "Umang Bhatt", "authors": "Umang Bhatt, McKane Andrus, Adrian Weller, Alice Xiang", "title": "Machine Learning Explainability for External Stakeholders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning is increasingly deployed in high-stakes contexts\naffecting people's livelihoods, there have been growing calls to open the black\nbox and to make machine learning algorithms more explainable. Providing useful\nexplanations requires careful consideration of the needs of stakeholders,\nincluding end-users, regulators, and domain experts. Despite this need, little\nwork has been done to facilitate inter-stakeholder conversation around\nexplainable machine learning. To help address this gap, we conducted a\nclosed-door, day-long workshop between academics, industry experts, legal\nscholars, and policymakers to develop a shared language around explainability\nand to understand the current shortcomings of and potential solutions for\ndeploying explainable machine learning in service of transparency goals. We\nalso asked participants to share case studies in deploying explainable machine\nlearning at scale. In this paper, we provide a short summary of various case\nstudies of explainable machine learning, lessons from those studies, and\ndiscuss open challenges.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 14:27:06 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bhatt", "Umang", ""], ["Andrus", "McKane", ""], ["Weller", "Adrian", ""], ["Xiang", "Alice", ""]]}, {"id": "2007.05443", "submitter": "Hansol Lee", "authors": "Ren\\'e F. Kizilcec and Hansol Lee", "title": "Algorithmic Fairness in Education", "comments": "Forthcoming in W. Holmes & K. Porayska-Pomsta (Eds.), Ethics in\n  Artificial Intelligence in Education, Taylor & Francis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven predictive models are increasingly used in education to support\nstudents, instructors, and administrators. However, there are concerns about\nthe fairness of the predictions and uses of these algorithmic systems. In this\nintroduction to algorithmic fairness in education, we draw parallels to prior\nliterature on educational access, bias, and discrimination, and we examine core\ncomponents of algorithmic systems (measurement, model learning, and action) to\nidentify sources of bias and discrimination in the process of developing and\ndeploying these systems. Statistical, similarity-based, and causal notions of\nfairness are reviewed and contrasted in the way they apply in educational\ncontexts. Recommendations for policy makers and developers of educational\ntechnology offer guidance for how to promote algorithmic fairness in education.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 15:35:10 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 01:25:59 GMT"}, {"version": "v3", "created": "Sun, 11 Apr 2021 15:22:14 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Kizilcec", "Ren\u00e9 F.", ""], ["Lee", "Hansol", ""]]}, {"id": "2007.05479", "submitter": "Adrien Bibal", "authors": "Adrien Bibal, Michael Lognoul, Alexandre de Streel and Beno\\^it\n  Fr\\'enay", "title": "Impact of Legal Requirements on Explainability in Machine Learning", "comments": "ICML Workshop on Law and Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The requirements on explainability imposed by European laws and their\nimplications for machine learning (ML) models are not always clear. In that\nperspective, our research analyzes explanation obligations imposed for private\nand public decision-making, and how they can be implemented by machine learning\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 16:57:18 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bibal", "Adrien", ""], ["Lognoul", "Michael", ""], ["de Streel", "Alexandre", ""], ["Fr\u00e9nay", "Beno\u00eet", ""]]}, {"id": "2007.05516", "submitter": "Pavan Ravishankar", "authors": "Pavan Ravishankar, Pranshu Malviya, Balaraman Ravindran", "title": "A Causal Linear Model to Quantify Edge Flow and Edge Unfairness for\n  UnfairEdge Prioritization and Discrimination Removal", "comments": "Accepted in the Workshop on Law and Machine Learning, ICML 2020;\n  First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Law enforcement must prioritize sources of unfairness before mitigating their\nunderlying unfairness, considering that they have limited resources. Unlike\nprevious works that only make cautionary claims of discrimination and de-biases\ndata after its generation, this paper attempts to prioritize unfair sources\nbefore mitigating their unfairness in the real-world. We assume that a causal\nbayesian network, representative of the data generation procedure, along with\nthe sensitive nodes, that result in unfairness, are given. We quantify Edge\nFlow, which is the belief flowing along an edge by attenuating the indirect\npath influences, and use it to quantify Edge Unfairness. We prove that\ncumulative unfairness is non-existent in any decision, like judicial bail,\ntowards any sensitive groups, like race, when the edge unfairness is absent,\ngiven an error-free linear model of conditional probability. We then measure\nthe potential to mitigate the cumulative unfairness when edge unfairness is\ndecreased. Based on these measures, we propose an unfair edge prioritization\nalgorithm that prioritizes the unfair edges and a discrimination removal\nprocedure that de-biases the generated data distribution. The experimental\nsection validates the specifications used for quantifying the above measures.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 17:50:41 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 17:02:58 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 17:50:23 GMT"}, {"version": "v4", "created": "Thu, 11 Mar 2021 05:35:15 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Ravishankar", "Pavan", ""], ["Malviya", "Pranshu", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "2007.05522", "submitter": "Bernardo Huberman", "authors": "Bernardo Huberman, Bob Lund and Jing Wang", "title": "Quantum Secured Internet Transport", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.NI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing represents an emerging threat to the public key\ninfrastructure underlying transport layer security (TLS) widely used in the\nInternet. This paper describes how QKD symmetric keys can be used with TLS to\nprovide quantum computing resistant security for existing Internet\napplications. We also implement and test a general hybrid key delivery\narchitecture with QKD over long distance fibers between secure sites, and\nwireless key distribution over short distance within each site Finally we show\nhow this same capability can be extended to a TLS cipher scheme with perfect\nsecurity.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 17:57:06 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Huberman", "Bernardo", ""], ["Lund", "Bob", ""], ["Wang", "Jing", ""]]}, {"id": "2007.05552", "submitter": "Ebenezer Agbozo", "authors": "Maija K\\=ale and Ebenezer Agbozo", "title": "Tracing Complexity in Food Blogging Entries", "comments": "12 pages, 5 figures, conference, published\n  http://ceur-ws.org/Vol-2612/paper4.pdf", "journal-ref": "Proceedings of the Digital Humanities in the Nordic Countries 5th\n  Conference, Riga, Latvia, October 21-23, 2020[online only]. CEUR Workshop\n  Proceedings 2612 (2020) 51-62", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within this paper, we focus on the concept of complexity and how it is\nrepresented in food blogging entries on Twitter. We turn specific attention to\ncomplexity capture when looking at healthy foods, focusing on food blogging\nentries that entail the notions of health/healthiness/healthy. We do so because\nwe consider that complexity manifests hedonism - that is the irrational\ndeterminant of food choice above rational considerations of nutrition and\nhealthiness. Using text as a platform for our analysis, we derive bigrams and\ntopic models that illustrate the frequencies of words and bi-grams, thus,\npointing our attention to current discourse in food blogging entries on\nTwitter. The results show that, contrary to complexity, that the dominating\ncharacteristics in healthy food domain are easiness and speed of preparation,\nhowever, rational and health related considerations may not always take\nprecedence when the choice is determined. Food blogging entries show\nsurprisingly little account of healthy food as being tasty and enjoyable. With\nthis we aim to contribute to the knowledge of how to shape more healthy\nconsumer behaviors. Having discovered the scarcity of hedonic connotations,\nthis work invites for further research in text-based information about food.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 18:13:48 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["K\u0101le", "Maija", ""], ["Agbozo", "Ebenezer", ""]]}, {"id": "2007.05801", "submitter": "Ravi Tejwani", "authors": "Ravi Tejwani, Felipe Moreno, Sooyeon Jeong, Hae Won Park, Cynthia\n  Breazeal", "title": "Migratable AI: Effect of identity and information migration on users\n  perception of conversational AI agents", "comments": "Accepted to RO-MAN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational AI agents are proliferating, embodying a range of devices such\nas smart speakers, smart displays, robots, cars, and more. We can envision a\nfuture where a personal conversational agent could migrate across different\nform factors and environments to always accompany and assist its user to\nsupport a far more continuous, personalized, and collaborative experience. This\nopens the question of what properties of a conversational AI agent migrates\nacross forms, and how it would impact user perception. To explore this, we\ndeveloped a Migratable AI system where a user's information and/or the agent's\nidentity can be preserved as it migrates across form factors to help its user\nwith a task. We designed a 2x2 between-subjects study to explore the effects of\ninformation migration and identity migration on user perceptions of trust,\ncompetence, likeability, and social presence. Our results suggest that identity\nmigration had a positive effect on trust, competence, and social presence,\nwhile information migration had a positive effect on trust, competence, and\nlikeability. Overall, users report the highest trust, competence, likeability,\nand social presence towards the conversational agent when both identity and\ninformation were migrated across embodiments.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 15:46:37 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 22:36:36 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Tejwani", "Ravi", ""], ["Moreno", "Felipe", ""], ["Jeong", "Sooyeon", ""], ["Park", "Hae Won", ""], ["Breazeal", "Cynthia", ""]]}, {"id": "2007.05831", "submitter": "Md Abu Sayeed Mondol", "authors": "Md Abu Sayeed Mondol, Brooke Bell, Meiyi Ma, Ridwan Alam, Ifat Emi,\n  Sarah Masud Preum, Kayla de la Haye, Donna Spruijt-Metz, John C. Lach, and\n  John A. Stankovic", "title": "MFED: A System for Monitoring Family Eating Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obesity is a risk factor for many health issues, including heart disease,\ndiabetes, osteoarthritis, and certain cancers. One of the primary behavioral\ncauses, dietary intake, has proven particularly challenging to measure and\ntrack. Current behavioral science suggests that family eating dynamics (FED)\nhave high potential to impact child and parent dietary intake, and ultimately\nthe risk of obesity. Monitoring FED requires information about when and where\neating events are occurring, the presence or absence of family members during\neating events, and some person-level states such as stress, mood, and hunger.\nTo date, there exists no system for real-time monitoring of FED. This paper\npresents MFED, the first of its kind of system for monitoring FED in the wild\nin real-time. Smart wearables and Bluetooth beacons are used to monitor and\ndetect eating activities and the location of the users at home. A smartphone is\nused for the Ecological Momentary Assessment (EMA) of a number of behaviors,\nstates, and situations. While the system itself is novel, we also present a\nnovel and efficient algorithm for detecting eating events from wrist-worn\naccelerometer data. The algorithm improves eating gesture detection F1-score by\n19% with less than 20% computation compared to the state-of-the-art methods. To\ndate, the MFED system has been deployed in 20 homes with a total of 74\nparticipants, and responses from 4750 EMA surveys have been collected. This\npaper describes the system components, reports on the eating detection results\nfrom the deployments, proposes two techniques for improving ground truth\ncollection after the system is deployed, and provides an overview of the FED\ndata, generated from the multi-component system, that can be used to model and\nmore comprehensively understand insights into the monitoring of family eating\ndynamics.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 19:00:53 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Mondol", "Md Abu Sayeed", ""], ["Bell", "Brooke", ""], ["Ma", "Meiyi", ""], ["Alam", "Ridwan", ""], ["Emi", "Ifat", ""], ["Preum", "Sarah Masud", ""], ["de la Haye", "Kayla", ""], ["Spruijt-Metz", "Donna", ""], ["Lach", "John C.", ""], ["Stankovic", "John A.", ""]]}, {"id": "2007.05843", "submitter": "Julian Posada", "authors": "Julian Posada", "title": "The Future of Work Is Here: Toward a Comprehensive Approach to\n  Artificial Intelligence and Labour", "comments": null, "journal-ref": "Ethics of AI in Context (2020)", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This commentary traces contemporary discourses on the relationship between\nartificial intelligence and labour and explains why these principles must be\ncomprehensive in their approach to labour and AI. First, the commentary asserts\nthat ethical frameworks in AI alone are not enough to guarantee workers' rights\nsince they lack enforcement mechanisms and the representation of different\nstakeholders. Secondly, it argues that current discussions on AI and labour\nfocus on the deployment of these technologies in the workplace but ignore the\nessential role of human labour in their development, particularly in the\ndifferent cases of outsourced labour around the world. Finally, it recommends\nusing existing human rights frameworks for working conditions to provide more\ncomprehensive ethical principles and regulations. The commentary concludes by\narguing that the central question regarding the future of work should not be\nwhether intelligent machines will replace humans, but who will own these\nsystems and have a say in their development and operation.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 19:50:36 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 19:23:52 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Posada", "Julian", ""]]}, {"id": "2007.06116", "submitter": "Lisa Singh", "authors": "Lisa Singh, Katharine Donato, Ali Arab, Tomas Alvarez Belon, Abraham\n  Fraifeld, Sean Fulmer, Douglas Post, Yanchen Wang", "title": "Identifying Meaningful Indirect Indicators of Migration for Different\n  Conflicts", "comments": "3 pages ACM Humanitarian Workshop - KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended abstract describes an ongoing project that attempts to blend\npublicly available organic, real time behavioral data, event data, and\ntraditional migration data to determine when and where people will move during\ntimes of instability. We present a methodology that was successful for a case\nstudy predicting mass movement in Iraq from 2015 - 2017, and discuss how we are\nextending it to capture indirect indicators of movement in Venezuela.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2020 22:32:16 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Singh", "Lisa", ""], ["Donato", "Katharine", ""], ["Arab", "Ali", ""], ["Belon", "Tomas Alvarez", ""], ["Fraifeld", "Abraham", ""], ["Fulmer", "Sean", ""], ["Post", "Douglas", ""], ["Wang", "Yanchen", ""]]}, {"id": "2007.06229", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim, Seshadri Sridharan, Andy Atwal and Varun Ganapathi", "title": "Deep Claim: Payer Response Prediction from Claims Data with Deep\n  Learning", "comments": "To be presented at the Healthcare Systems, Population Health, and the\n  Role of Health-Tech (HSYS) Workshop at the 37th International Conference on\n  Machine Learning, Vienna, Austria, July 13-18, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each year, almost 10% of claims are denied by payers (i.e., health insurance\nplans). With the cost to recover these denials and underpayments, predicting\npayer response (likelihood of payment) from claims data with a high degree of\naccuracy and precision is anticipated to improve healthcare staffs' performance\nproductivity and drive better patient financial experience and satisfaction in\nthe revenue cycle (Barkholz, 2017). However, constructing advanced predictive\nanalytics models has been considered challenging in the last twenty years. That\nsaid, we propose a (low-level) context-dependent compact representation of\npatients' historical claim records by effectively learning complicated\ndependencies in the (high-level) claim inputs. Built on this new latent\nrepresentation, we demonstrate that a deep learning-based framework, Deep\nClaim, can accurately predict various responses from multiple payers using\n2,905,026 de-identified claims data from two US health systems. Deep Claim's\nimprovements over carefully chosen baselines in predicting claim denials are\nmost pronounced as 22.21% relative recall gain (at 95% precision) on Health\nSystem A, which implies Deep Claim can find 22.21% more denials than the best\nbaseline system.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 08:05:17 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Kim", "Byung-Hak", ""], ["Sridharan", "Seshadri", ""], ["Atwal", "Andy", ""], ["Ganapathi", "Varun", ""]]}, {"id": "2007.06290", "submitter": "Ivan P Yamshchikov", "authors": "Yana Agafonova, Alexey Tikhonov, Ivan P. Yamshchikov", "title": "Paranoid Transformer: Reading Narrative of Madness as Computational\n  Approach to Creativity", "comments": null, "journal-ref": null, "doi": "10.3390/fi12110182", "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This papers revisits the receptive theory in context of computational\ncreativity. It presents a case study of a Paranoid Transformer - a fully\nautonomous text generation engine with raw output that could be read as the\nnarrative of a mad digital persona without any additional human post-filtering.\nWe describe technical details of the generative system, provide examples of\noutput and discuss the impact of receptive theory, chance discovery and\nsimulation of fringe mental state on the understanding of computational\ncreativity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:18:24 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Agafonova", "Yana", ""], ["Tikhonov", "Alexey", ""], ["Yamshchikov", "Ivan P.", ""]]}, {"id": "2007.06308", "submitter": "Alireza Shojaifar", "authors": "Alireza Shojaifar and Samuel A. Fricker", "title": "SMEs' Confidentiality Concerns for Security Information Sharing", "comments": "10 pages, 2 figures, 14th International Symposium on Human Aspects of\n  Information Security & Assurance (HAISA 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-57404-8_22", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Small and medium-sized enterprises are considered an essential part of the EU\neconomy, however, highly vulnerable to cyberattacks. SMEs have specific\ncharacteristics which separate them from large companies and influence their\nadoption of good cybersecurity practices. To mitigate the SMEs' cybersecurity\nadoption issues and raise their awareness of cyber threats, we have designed a\nself-paced security assessment and capability improvement method, CYSEC. CYSEC\nis a security awareness and training method that utilises self-reporting\nquestionnaires to collect companies' information about cybersecurity awareness,\npractices, and vulnerabilities to generate automated recommendations for\ncounselling. However, confidentiality concerns about cybersecurity information\nhave an impact on companies' willingness to share their information. Security\ninformation sharing decreases the risk of incidents and increases users'\nself-efficacy in security awareness programs. This paper presents the results\nof semi-structured interviews with seven chief information security officers of\nSMEs to evaluate the impact of online consent communication on motivation for\ninformation sharing. The results were analysed in respect of the Self\nDetermination Theory. The findings demonstrate that online consent with\nmultiple options for indicating a suitable level of agreement improved\nmotivation for information sharing. This allows many SMEs to participate in\nsecurity information sharing activities and supports security experts to have a\nbetter overview of common vulnerabilities. The final publication is available\nat Springer via https://doi.org/10.1007/978-3-030-57404-8_22\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:59:40 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 16:19:50 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Shojaifar", "Alireza", ""], ["Fricker", "Samuel A.", ""]]}, {"id": "2007.06374", "submitter": "Maria Ovchinnikova", "authors": "Arian Garshi and Malin Wist Jakobsen and J{\\o}rgen Nyborg-Christensen\n  and Daniel Ostnes and Maria Ovchinnikova", "title": "Smart technology in the classroom: a systematic review.Prospects for\n  algorithmic accountability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence (AI) algorithms have emerged in the educational\ndomain as a tool to make learning more efficient. Different applications for\nmastering particular skills, learning new languages, and tracking their\nprogress are used by children. What is the impact on children from using this\nsmart technology? We conducted a systematic review to understand the state of\nthe art. We explored the literature in several sub-disciplines: wearables,\nchild psychology, AI and education, school surveillance, and accountability.\nOur review identified the need for more research for each established topic. We\nmanaged to find both positive and negative effects of using wearables, but\ncannot conclude if smart technology use leads to lowering the young children's\nperformance. Based on our insights we propose a framework to effectively\nidentify accountability for smart technology in education.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 13:34:49 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Garshi", "Arian", ""], ["Jakobsen", "Malin Wist", ""], ["Nyborg-Christensen", "J\u00f8rgen", ""], ["Ostnes", "Daniel", ""], ["Ovchinnikova", "Maria", ""]]}, {"id": "2007.06507", "submitter": "Lee Braine", "authors": "Aishwarya Nair, Lee Braine", "title": "Industry Adoption Scenarios for Authoritative Data Stores using the ISDA\n  Common Domain Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we explore opportunities for the post-trade industry to\nstandardise and simplify in order to significantly increase efficiency and\nreduce costs. We start by summarising relevant industry problems (inconsistent\nprocesses, inconsistent data, and duplicated data) and the corresponding\npotential industry solutions (process standardisation, data standardisation,\nand authoritative data stores). This includes transitioning to the\nInternational Swaps and Derivatives Association (ISDA) Common Domain Model\n(CDM) as a standard set of digital representations for the events and processes\nthroughout the lifecycle of a trade. We then explore how financial market\ninfrastructures could operate authoritative data stores that make CDM business\nevents available to broker-dealers, considering both traditional centralised\nmodels and potential decentralised models. For both models, there are many\npossible adoption scenarios (depending on each broker-dealer's degree of\nintegration with the authoritative data store and usage of the CDM) and we\nidentify some of the key scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:59:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Nair", "Aishwarya", ""], ["Braine", "Lee", ""]]}, {"id": "2007.06540", "submitter": "Anastasija Nikiforova", "authors": "Anastasija Nikiforova", "title": "Open Data Quality", "comments": "10 pages, 3 figures, 13th International Baltic Conference on\n  Databases and Information Systems & The Baltic DB&IS 2018 Doctoral Consortium\n  (Baltic DB&IS 2018) At: Lithuania, Trakai, Volume: 2158. arXiv admin note:\n  substantial text overlap with arXiv:2007.04697", "journal-ref": "Baltic DB&IS 2018 Joint Proceedings of the Conference Forum and\n  Doctoral Consortium", "doi": null, "report-no": null, "categories": "cs.DB cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The research discusses how (open) data quality could be described, what\nshould be considered developing a data quality management solution and how it\ncould be applied to open data to check its quality. The proposed approach\nfocuses on development of data quality specification which can be executed to\nget data quality evaluation results, find errors in data and possible problems\nwhich must be solved. The proposed approach is applied to several open data\nsets to evaluate their quality. Open data is very popular, free available for\nevery stakeholder - it is often used to make business decisions. It is\nimportant to be sure that this data is trustable and error-free as its quality\nproblems can lead to huge losses.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 11:10:22 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Nikiforova", "Anastasija", ""]]}, {"id": "2007.06570", "submitter": "Guha Balakrishnan", "authors": "Guha Balakrishnan, Yuanjun Xiong, Wei Xia, Pietro Perona", "title": "Towards causal benchmarking of bias in face analysis algorithms", "comments": "Long-form version of ECCV 2020 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring algorithmic bias is crucial both to assess algorithmic fairness,\nand to guide the improvement of algorithms. Current methods to measure\nalgorithmic bias in computer vision, which are based on observational datasets,\nare inadequate for this task because they conflate algorithmic bias with\ndataset bias.\n  To address this problem we develop an experimental method for measuring\nalgorithmic bias of face analysis algorithms, which manipulates directly the\nattributes of interest, e.g., gender and skin tone, in order to reveal causal\nlinks between attribute variation and performance change. Our proposed method\nis based on generating synthetic ``transects'' of matched sample images that\nare designed to differ along specific attributes while leaving other attributes\nconstant. A crucial aspect of our approach is relying on the perception of\nhuman observers, both to guide manipulations, and to measure algorithmic bias.\n  Besides allowing the measurement of algorithmic bias, synthetic transects\nhave other advantages with respect to observational datasets: they sample\nattributes more evenly allowing for more straightforward bias analysis on\nminority and intersectional groups, they enable prediction of bias in new\nscenarios, they greatly reduce ethical and legal challenges, and they are\neconomical and fast to obtain, helping make bias testing affordable and widely\navailable.\n  We validate our method by comparing it to a study that employs the\ntraditional observational method for analyzing bias in gender classification\nalgorithms. The two methods reach different conclusions. While the\nobservational method reports gender and skin color biases, the experimental\nmethod reveals biases due to gender, hair length, age, and facial hair.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 17:10:34 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Balakrishnan", "Guha", ""], ["Xiong", "Yuanjun", ""], ["Xia", "Wei", ""], ["Perona", "Pietro", ""]]}, {"id": "2007.06653", "submitter": "Alex Berke", "authors": "Alex Berke, Jason Nawyn, Thomas Sanchez Lengeling, Kent Larson", "title": "Urban Mobility Swarms: A Scalable Implementation", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-52246-9_1", "report-no": null, "categories": "cs.MA cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system to coordinate 'urban mobility swarms' in order to promote\nthe use and safety of lightweight, sustainable transit, while enhancing the\nvibrancy and community fabric of cities. This work draws from behavior\nexhibited by swarms of nocturnal insects, such as crickets and fireflies,\nwhereby synchrony unifies individuals in a decentralized network. Coordination\nnaturally emerges in these cases and provides a compelling demonstration of\n'strength in numbers'. Our work is applied to coordinating lightweight\nvehicles, such as bicycles, which are automatically inducted into ad-hoc\n'swarms', united by the synchronous pulsation of light. We model individual\nriders as nodes in a decentralized network and synchronize their behavior via a\npeer-to-peer message protocol and algorithm, which preserves individual\nprivacy. Nodes broadcast over radio with a transmission range tuned to localize\nswarm membership. Nodes then join or disconnect from others based on proximity,\naccommodating the dynamically changing topology of urban mobility networks.\nThis paper provides a technical description of our system, including the\nprotocol and algorithm to coordinate the swarming behavior that emerges from\nit. We also demonstrate its implementation in code, circuity, and hardware,\nwith a system prototype tested on a city bike-share. In doing so, we evince the\nscalability of our system. Our prototype uses low-cost components, and\nbike-share programs, which manage bicycle fleets distributed across cities,\ncould deploy the system at city-scale. Our flexible, decentralized design\nallows additional bikes to then connect with the network, enhancing its scale\nand impact.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 19:44:16 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Berke", "Alex", ""], ["Nawyn", "Jason", ""], ["Lengeling", "Thomas Sanchez", ""], ["Larson", "Kent", ""]]}, {"id": "2007.06718", "submitter": "Samantha Robertson", "authors": "Samantha Robertson and Niloufar Salehi", "title": "What If I Don't Like Any Of The Choices? The Limits of Preference\n  Elicitation for Participatory Algorithm Design", "comments": "Presented at the workshop on Participatory Approaches to Machine\n  Learning at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging methods for participatory algorithm design have proposed collecting\nand aggregating individual stakeholder preferences to create algorithmic\nsystems that account for those stakeholders' values. Using algorithmic student\nassignment as a case study, we argue that optimizing for individual preference\nsatisfaction in the distribution of limited resources may actually inhibit\nprogress towards social and distributive justice. Individual preferences can be\na useful signal but should be expanded to support more expressive and inclusive\nforms of democratic participation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 21:58:30 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Robertson", "Samantha", ""], ["Salehi", "Niloufar", ""]]}, {"id": "2007.06767", "submitter": "Silvano Herculano da Luz Junior", "authors": "Silvano Herculano da Luz J\\'unior, Francisco \\'Icaro Cipriano Silva,\n  Gustavo Sousa Galisa Albuquerque, Francisco Petr\\^onio Alencar de Medeiros\n  and Heremita Brasileiro Lira", "title": "Enterprise Architecture in Healthcare Systems: A systematic literature\n  review", "comments": "22 pages", "journal-ref": null, "doi": "10.17632/44bygxg8w3.1", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enterprise architecture (EA) has been present in scientific literature since\nthe 1980s and has branched out into several research fields. EA delivers value\nby presenting business and ICT leaders with recommendations for adjusting\npolicies and projects to achieve business goals. Although there are many works\non the EA application in healthcare systems, the literature lacks studies that\nprovide a systematic approach to this topic specifically. This work presents a\ndeep and broad Systematic Literature Review (SLR) to select studies\ndemonstrating current EA practices in healthcare systems. The researchers\nestablished an SLR protocol returning 280 primary studies after the first step\nof the Data Selection and a consolidated inclusion of 46 articles after the\nsecond step. They assessed the level of disagreement during the team's\nevaluations using Cohen's Kappa. This SLR revealed essential aspects of\nstate-of-the-art EA application in healthcare systems, such as the most used\nmethodologies and tools, best practices, and criteria considered for their\nchoice. It also analyzed the main positive impacts, challenges, and critical\nsuccess factors described by the studies' authors based on empirical\napproaches. Besides, this work brings the main publication channels and the\nmost influential authors on the topic of EA in Healthcare systems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 02:01:25 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 11:18:38 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["J\u00fanior", "Silvano Herculano da Luz", ""], ["Silva", "Francisco \u00cdcaro Cipriano", ""], ["Albuquerque", "Gustavo Sousa Galisa", ""], ["de Medeiros", "Francisco Petr\u00f4nio Alencar", ""], ["Lira", "Heremita Brasileiro", ""]]}, {"id": "2007.06908", "submitter": "Davide Chiarella", "authors": "P. Cutugno, D. Chiarella, R. Lucentini, L. Marconi and G. Morgavi", "title": "Language, communication and society: a gender based linguistics analysis", "comments": "7 pages, Mladenov et al., Recent Advances in Communications -\n  Proceedings of the 19th International Conference on Communications (part of\n  19th International Conference on Circuits, Systems, Communications and\n  Computers 2015)", "journal-ref": "Recent Advances in Electrical Engineering Series Volume 50, pag.\n  154-160, 2015, WSEAS Press. Athens ISBN: 9781618043184 ISSN: 1790-5117", "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to find evidence for supporting the hypothesis\nthat language is the mirror of our thinking, our prejudices and cultural\nstereotypes. In this analysis, a questionnaire was administered to 537 people.\nThe answers have been analysed to see if gender stereotypes were present such\nas the attribution of psychological and behavioural characteristics. In\nparticular, the aim was to identify, if any, what are the stereotyped images,\nwhich emerge in defining the roles of men and women in modern society.\nMoreover, the results given can be a good starting point to understand if\ngender stereotypes, and the expectations they produce, can result in\npenalization or inequality. If so, the language and its use would create\ninherently a gender bias, which influences evaluations both in work settings\nboth in everyday life.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:38:37 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Cutugno", "P.", ""], ["Chiarella", "D.", ""], ["Lucentini", "R.", ""], ["Marconi", "L.", ""], ["Morgavi", "G.", ""]]}, {"id": "2007.06915", "submitter": "Davide Chiarella", "authors": "Andrea Cerniglia, Davide Chiarella, Paola Cutugno, Lucia Marconi, Anna\n  Magrini, Gelsomina Di Feo, Melissa Ferretti", "title": "Questionnaire analysis to define the most suitable survey for port-noise\n  investigation", "comments": "8 pages, Proceedings of the 26th International Congress on Sound and\n  Vibration. ISBN 978-1-9991810-0-0 ISSN 2329-3675", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high level of noise pollution affecting the areas between ports and\nlogistic platforms represents a problem that can be faced from different points\nof view. Acoustic monitoring, mapping, short-term measurements, port and road\ntraffic flows analyses can give useful indications on the strategies to be\nproposed for a better management of the problem. A survey campaign through the\npreparation of questionnaires to be submitted to the population exposed to\nnoise in the back-port areas will help to better understand the subjective\npoint of view. The paper analyses a sample of questions suitable for the\nspecific research, chosen as part of the wide database of questionnaires\ninternationally proposed for subjective investigations. The preliminary results\nof a first data collection campaign are considered to verify the adequacy of\nthe number, the type of questions, and the type of sample noise used for the\nsurvey. The questionnaire will be optimized to be distributed in the TRIPLO\nproject (TRansports and Innovative sustainable connections between Ports and\nLOgistic platforms). The results of this survey will be the starting point for\nthe linguistic investigation carried out in combination with the acoustic\nmonitoring, to improve understanding the connections between personal feeling\nand technical aspects.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:52:55 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Cerniglia", "Andrea", ""], ["Chiarella", "Davide", ""], ["Cutugno", "Paola", ""], ["Marconi", "Lucia", ""], ["Magrini", "Anna", ""], ["Di Feo", "Gelsomina", ""], ["Ferretti", "Melissa", ""]]}, {"id": "2007.06933", "submitter": "Clayton Miller", "authors": "Clayton Miller, Pandarasamy Arjunan, Anjukan Kathirgamanathan, Chun\n  Fu, Jonathan Roth, June Young Park, Chris Balbach, Krishnan Gowri, Zoltan\n  Nagy, Anthony Fontanini, Jeff Haberl", "title": "The ASHRAE Great Energy Predictor III competition: Overview and results", "comments": null, "journal-ref": "Science and Technology for the Built Environment, 26:10,\n  1427-1447, (2020)", "doi": "10.1080/23744731.2020.1795514", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In late 2019, ASHRAE hosted the Great Energy Predictor III (GEPIII) machine\nlearning competition on the Kaggle platform. This launch marked the third\nenergy prediction competition from ASHRAE and the first since the mid-1990s. In\nthis updated version, the competitors were provided with over 20 million points\nof training data from 2,380 energy meters collected for 1,448 buildings from 16\nsources. This competition's overall objective was to find the most accurate\nmodeling solutions for the prediction of over 41 million private and public\ntest data points. The competition had 4,370 participants, split across 3,614\nteams from 94 countries who submitted 39,403 predictions. In addition to the\ntop five winning workflows, the competitors publicly shared 415 reproducible\nonline machine learning workflow examples (notebooks), including over 40\nadditional, full solutions. This paper gives a high-level overview of the\ncompetition preparation and dataset, competitors and their discussions, machine\nlearning workflows and models generated, winners and their submissions,\ndiscussion of lessons learned, and competition outputs and next steps. The most\npopular and accurate machine learning workflows used large ensembles of mostly\ngradient boosting tree models, such as LightGBM. Similar to the first predictor\ncompetition, preprocessing of the data sets emerged as a key differentiator.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 09:41:36 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Miller", "Clayton", ""], ["Arjunan", "Pandarasamy", ""], ["Kathirgamanathan", "Anjukan", ""], ["Fu", "Chun", ""], ["Roth", "Jonathan", ""], ["Park", "June Young", ""], ["Balbach", "Chris", ""], ["Gowri", "Krishnan", ""], ["Nagy", "Zoltan", ""], ["Fontanini", "Anthony", ""], ["Haberl", "Jeff", ""]]}, {"id": "2007.07003", "submitter": "Robert Peach", "authors": "Robert L. Peach and Sam F. Greenbury and Iain G. Johnston and Sophia\n  N. Yaliraki and David Lefevre and Mauricio Barahona", "title": "Data-driven modelling and characterisation of task completion sequences\n  in online courses", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The intrinsic temporality of learning demands the adoption of methodologies\ncapable of exploiting time-series information. In this study we leverage the\nsequence data framework and show how data-driven analysis of temporal sequences\nof task completion in online courses can be used to characterise personal and\ngroup learners' behaviors, and to identify critical tasks and course sessions\nin a given course design. We also introduce a recently developed probabilistic\nBayesian model to learn sequence trajectories of students and predict student\nperformance. The application of our data-driven sequence-based analyses to data\nfrom learners undertaking an on-line Business Management course reveals\ndistinct behaviors within the cohort of learners, identifying learners or\ngroups of learners that deviate from the nominal order expected in the course.\nUsing course grades a posteriori, we explore differences in behavior between\nhigh and low performing learners. We find that high performing learners follow\nthe progression between weekly sessions more regularly than low performing\nlearners, yet within each weekly session high performing learners are less tied\nto the nominal task order. We then model the sequences of high and low\nperformance students using the probablistic Bayesian model and show that we can\nlearn engagement behaviors associated with performance. We also show that the\ndata sequence framework can be used for task centric analysis; we identify\ncritical junctures and differences among types of tasks within the course\ndesign. We find that non-rote learning tasks, such as interactive tasks or\ndiscussion posts, are correlated with higher performance. We discuss the\napplication of such analytical techniques as an aid to course design,\nintervention, and student supervision.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 12:39:03 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Peach", "Robert L.", ""], ["Greenbury", "Sam F.", ""], ["Johnston", "Iain G.", ""], ["Yaliraki", "Sophia N.", ""], ["Lefevre", "David", ""], ["Barahona", "Mauricio", ""]]}, {"id": "2007.07016", "submitter": "Andrew Buzzell", "authors": "Andrew Buzzell", "title": "Public Goods From Private Data -- An Efficacy and Justification Paradox\n  for Digital Contact Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debate about the adoption of digital contact tracing (DCT) apps to control\nthe spread of COVID-19 has focussed on risks to individual privacy (Sharma &\nBashir 2020, Tang 2020). This emphasis reveals significant challenges to\nethical deployment of DCT, but generates constraints which undermine\njustification to implement DCT. It would be a mistake to view this result\nsolely as the successful operation of ethical foresight analysis (Floridi &\nStrait 2020), preventing deployment of potentially harmful technology.\nPrivacy-centric analysis treats data as private property, frames the\nrelationship between individuals and governments as adversarial, entrenches\ntechnology platforms as gatekeepers, and supports a conception of emergency\npublic health authority as limited by individual consent and considerable\ncorporate influence that is in some tension with the more communitarian values\nthat typically inform public health ethics. To overcome the barriers to ethical\nand effective DCT, and develop infrastructure and policy that supports the\nrealization of potential public benefits of digital technology, a public\nresource conception of aggregate data should be developed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 13:08:29 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Buzzell", "Andrew", ""]]}, {"id": "2007.07092", "submitter": "Xavier Ferrer Aran", "authors": "Natalia Criado, Xavier Ferrer, Jose M. Such", "title": "A Normative approach to Attest Digital Discrimination", "comments": "Author's copy of the manuscript accepted in the Advancing Towards the\n  SDGS Artificial Intelligence for a Fair, Just and Equitable World Workshop of\n  the 24th European Conference on Artificial Intelligence (ECAI'20)", "journal-ref": "Advancing Towards the SDGS Artificial Intelligence for a Fair,\n  Just and Equitable World Workshop of the 24th European Conference on\n  Artificial Intelligence 2020 (ECAI'20)", "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digital discrimination is a form of discrimination whereby users are\nautomatically treated unfairly, unethically or just differently based on their\npersonal data by a machine learning (ML) system. Examples of digital\ndiscrimination include low-income neighbourhood's targeted with high-interest\nloans or low credit scores, and women being undervalued by 21% in online\nmarketing. Recently, different techniques and tools have been proposed to\ndetect biases that may lead to digital discrimination. These tools often\nrequire technical expertise to be executed and for their results to be\ninterpreted. To allow non-technical users to benefit from ML, simpler notions\nand concepts to represent and reason about digital discrimination are needed.\nIn this paper, we use norms as an abstraction to represent different situations\nthat may lead to digital discrimination. In particular, we formalise\nnon-discrimination norms in the context of ML systems and propose an algorithm\nto check whether ML systems violate these norms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 15:14:52 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 11:39:18 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Criado", "Natalia", ""], ["Ferrer", "Xavier", ""], ["Such", "Jose M.", ""]]}, {"id": "2007.07096", "submitter": "Jacques Bou Abdo", "authors": "Jacques Bou Abdo and Sherali Zeadally", "title": "Multi-Utility Market: Framework for a Blockchain Exchange Platform for\n  Sustainable Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Water and other resources are becoming scarcer every day, and developing\ncountries are the neediest for an immediate intervention. Water, as a national\nneed, is considered to be one of the main causes for conflicts in the 21st\ncentury. Peer-to-peer trading is one of the most convenient, scalable and\nsustainable solutions but faces organization challenges such as: the absence of\nsuitable business models motivating normal users to sell their generated\nresources, currency and financial settlement complexities, and single utility\nmarkets. We propose a multi-utility trading platform, based on blockchain\ntechnology which can address the challenges faced by peer-to-peer trading. This\nplatform meets the needs of developing countries in particular as well as rural\nareas of developed countries. The open nature of our proposed design makes it\nsuitable for adoption and use by various stakeholders.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 15:15:55 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Abdo", "Jacques Bou", ""], ["Zeadally", "Sherali", ""]]}, {"id": "2007.07333", "submitter": "Carlos Denner dos Santos Jr.", "authors": "Luiz F. Pinto, Carlos Denner dos Santos, Silvia Onoyama", "title": "Individual Factors that Influence Effort and Contributions on Wikipedia", "comments": "Presented at AoM 2019 in Boston", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we aim to analyze how attitude, self-efficacy, and altruism\ninfluence effort and active contributions on Wikipedia. We propose a new\nconceptual model based on the theory of planned behavior and findings from the\nliterature on online communities. This model differs from other models that\nhave been previously proposed by considering altruism in its various facets\n(identification, reciprocity, and reputation), and by treating effort as a\nfactor prior to performance results, which is measured in terms of active\ncontributions, according to the organizational literature. To fulfill the study\nspecific objectives, Wikipedia surveyed community members and collected\nsecondary data. After excluding outliers, we obtained a final sample with 212\nparticipants. We applied exploratory factor analysis and structural equation\nmodeling, which resulted in a model with satisfactory fit indices. The results\nindicate that effort influences active contributions, and attitude, altruism by\nreputation, and altruism by identification influence effort. None of the\nproposed factors are directly related to active contributions. Experience\ndirectly influences self-efficacy while it positively moderates the relation\nbetween effort and active contributions. Finally, we present the conclusions\nvia several implications for the literature as well as suggestions for future\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 19:57:51 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Pinto", "Luiz F.", ""], ["Santos", "Carlos Denner dos", ""], ["Onoyama", "Silvia", ""]]}, {"id": "2007.07377", "submitter": "Saraju Mohanty", "authors": "Laavanya Rachakonda and Anand K. Bapatla and Saraju P. Mohanty and\n  Elias Kougianos", "title": "SaYoPillow: A Blockchain-Enabled, Privacy-Assured Framework for Stress\n  Detection, Prediction and Control Considering Sleeping Habits in the IoMT", "comments": "38 pages, 22 figures and 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering today's lifestyle, people just sleep forgetting the benefits it\nprovides to the human body. The reasons for not having a productive sleep could\nbe many. Smart-Yoga Pillow (SaYoPillow) is envisioned as a device that may help\nin recognizing the importance of a good quality sleep to alleviate stress while\nestablishing a measurable relationship between stress and sleeping habits. A\nsystem that analyzes the sleeping habits by continuously monitoring the\nphysiological changes that occur during rapid eye movement (REM) and non-rapid\neye movement (NREM) stages of sleep is proposed in the current work. In\naddition to the physiological parameter changes, factors such as sleep\nduration, snoring range, eye movement, and limb movements are also monitored.\nThe SaYoPillow system is processed at the edge level with the storage being at\nthe cloud. Not having to compromise the user's privacy, SaYoPillow proposes\nsecure data transmission for both uploading and retrieving, and secure storage\nand communications as an attempt to reduce malicious attacks on healthcare. A\nuser interface is provided for the user to control data accessibility and\nvisibility. SaYoPillow has 96% accuracy which is close to other existing\nresearch works. However, SaYoPillow is the only work with security features as\nwell as only work that considers sleeping habits for stress.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 22:09:33 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Rachakonda", "Laavanya", ""], ["Bapatla", "Anand K.", ""], ["Mohanty", "Saraju P.", ""], ["Kougianos", "Elias", ""]]}, {"id": "2007.07399", "submitter": "Emily Denton", "authors": "Emily Denton, Alex Hanna, Razvan Amironesei, Andrew Smart, Hilary\n  Nicole, Morgan Klaus Scheuerman", "title": "Bringing the People Back In: Contesting Benchmark Machine Learning\n  Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to algorithmic unfairness embedded in sociotechnical systems,\nsignificant attention has been focused on the contents of machine learning\ndatasets which have revealed biases towards white, cisgender, male, and Western\ndata subjects. In contrast, comparatively less attention has been paid to the\nhistories, values, and norms embedded in such datasets. In this work, we\noutline a research program - a genealogy of machine learning data - for\ninvestigating how and why these datasets have been created, what and whose\nvalues influence the choices of data to collect, the contextual and contingent\nconditions of their creation. We describe the ways in which benchmark datasets\nin machine learning operate as infrastructure and pose four research questions\nfor these datasets. This interrogation forces us to \"bring the people back in\"\nby aiding us in understanding the labor embedded in dataset construction, and\nthereby presenting new avenues of contestation for other researchers\nencountering the data.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 23:22:13 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Denton", "Emily", ""], ["Hanna", "Alex", ""], ["Amironesei", "Razvan", ""], ["Smart", "Andrew", ""], ["Nicole", "Hilary", ""], ["Scheuerman", "Morgan Klaus", ""]]}, {"id": "2007.07514", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart and Peter Craigon", "title": "The Moral-IT Deck: A Tool for Ethics by Design", "comments": "Governance and Regulation; Design Tools; Responsible Research and\n  Innovation; Ethics by Design; Games; Human Computer Interaction, Card Based\n  Tools", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the design process and empirical evaluation of a new tool\nfor enabling ethics by design: The Moral-IT Cards. Better tools are needed to\nsupport the role of technologists in addressing ethical issues during system\ndesign. These physical cards support reflection by technologists on normative\naspects of technology development, specifically on emerging risks, appropriate\nsafeguards and challenges of implementing these in the system. We discuss how\nthe cards were developed and tested within 5 workshops with 20 participants\nfrom both research and commercial settings. We consider the role of\ntechnologists in ethics from different EU/UK policymaking initiatives and\ndisciplinary perspectives (i.e. Science and Technology Studies (STS), IT Law,\nHuman Computer Interaction (HCI), Computer/Engineering Ethics). We then examine\nexisting ethics by design tools, and other cards based tools before arguing why\ncards can be a useful medium for addressing complex ethical issues. We present\nthe development process for the Moral-IT cards, document key features of our\ncard design, background on the content, the impact assessment board process for\nusing them and how this was formulated. We discuss our study design and\nmethodology before examining key findings which are clustered around three\noverarching themes. These are: the value of our cards as a tool, their impact\non the technology design process and how they structure ethical reflection\npractices. We conclude with key lessons and concepts such as how they level the\nplaying field for debate; enable ethical clustering, sorting and comparison;\nprovide appropriate anchors for discussion and highlighted the intertwined\nnature of ethics.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 07:26:45 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Urquhart", "Lachlan", ""], ["Craigon", "Peter", ""]]}, {"id": "2007.07587", "submitter": "Natalia Lara Nieto-Marquez", "authors": "Natalia Lara Nieto-M\\'arquez (1 y 2), Alejandro Baldominos (3 y 4),\n  Almudena Gonz\\'alez Petronila (2) ((1) Universidad Camilo Jos\\'e Cela, (2)\n  Educational Department Smile and Learn Digital Creations, (3) Computer\n  Science Department Universidad Carlos III de Madrid, (4) Data Science\n  Department Smile and Learn Digital Creations)", "title": "SARS-CoV-2 Impact on Online Teaching Methodologies and the Ed-Tech\n  Sector: Smile and Learn Platform Case Study", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, the use of new technologies and digital, educational\nmaterial has been increasing. Owing to the situation brought about in Spain by\nthe SARS-CoV-2 (COVID-19) pandemic, schools have closed and families were asked\nto confine at home since March 2020. During this period there has been a need\nof resources to be made available to the families and teachers so that they\nwould be able to continue their teaching practice. Consequently, this study\nanalyzes the importance of online methodologies and usage tendency of an\neducational resource example: The Smile and Learn platform. Thereby, the study\npresents the different models implemented to support education and its impact\nin the use of the platform. The analyzed outcomes and their effect on education\nare discussed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 10:06:51 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Nieto-M\u00e1rquez", "Natalia Lara", "", "1 y 2"], ["Baldominos", "Alejandro", "", "3 y 4"], ["Petronila", "Almudena Gonz\u00e1lez", ""]]}, {"id": "2007.07602", "submitter": "Alireza Shojaifar", "authors": "Alireza Shojaifar, Samuel A. Fricker, Martin Gwerder", "title": "Automating the Communication of Cybersecurity Knowledge: Multi-Case\n  Study", "comments": "14 pages, 1 figure, 13th World Conference on Information Security\n  Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cybersecurity is essential for the protection of companies against cyber\nthreats. Traditionally, cybersecurity experts assess and improve a company's\ncapabilities. However, many small and medium-sized businesses (SMBs) consider\nsuch services not to be affordable. We explore an alternative do-it-yourself\n(DIY) approach to bringing cybersecurity to SMBs. Our method and tool, CYSEC,\nimplements the Self-Determination Theory (SDT) to guide and motivate SMBs to\nadopt good cybersecurity practices. CYSEC uses assessment questions and\nrecommendations to communicate cybersecurity knowledge to the end user SMBs and\nencourage self-motivated change. In this paper, the operationalisation of SDT\nin CYSEC is presented and the results of a multi-case study shown that offer\ninsight into how SMBs adopted cybersecurity practices with CYSEC. Effective\nautomated cybersecurity communication depended on the SMB's hands-on skills,\ntools adaptedness, and the users' willingness to documenting confidential\ninformation. The SMBs wanted to learn in simple, incremental steps, allowing\nthem to understand what they do. An SMB's motivation to improve security\ndepended on the fitness of assessment questions and recommendations with the\nSMB's business model and IT infrastructure. The results of this study indicate\nthat automated counselling can help many SMBs in security adoption.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 10:30:20 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Shojaifar", "Alireza", ""], ["Fricker", "Samuel A.", ""], ["Gwerder", "Martin", ""]]}, {"id": "2007.07610", "submitter": "Lo\\\"ic Lannelongue", "authors": "Lo\\\"ic Lannelongue, Jason Grealey and Michael Inouye", "title": "Green Algorithms: Quantifying the carbon footprint of computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Climate change is profoundly affecting nearly all aspects of life on earth,\nincluding human societies, economies and health. Various human activities are\nresponsible for significant greenhouse gas emissions, including data centres\nand other sources of large-scale computation. Although many important\nscientific milestones have been achieved thanks to the development of\nhigh-performance computing, the resultant environmental impact has been\nunderappreciated. In this paper, we present a methodological framework to\nestimate the carbon footprint of any computational task in a standardised and\nreliable way, based on the processing time, type of computing cores, memory\navailable and the efficiency and location of the computing facility. Metrics to\ninterpret and contextualise greenhouse gas emissions are defined, including the\nequivalent distance travelled by car or plane as well as the number of\ntree-months necessary for carbon sequestration. We develop a freely available\nonline tool, Green Algorithms (www.green-algorithms.org), which enables a user\nto estimate and report the carbon footprint of their computation. The Green\nAlgorithms tool easily integrates with computational processes as it requires\nminimal information and does not interfere with existing code, while also\naccounting for a broad range of CPUs, GPUs, cloud computing, local servers and\ndesktop computers. Finally, by applying Green Algorithms, we quantify the\ngreenhouse gas emissions of algorithms used for particle physics simulations,\nweather forecasts and natural language processing. Taken together, this study\ndevelops a simple generalisable framework and freely available tool to quantify\nthe carbon footprint of nearly any computation. Combined with a series of\nrecommendations to minimise unnecessary CO2 emissions, we hope to raise\nawareness and facilitate greener computation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 11:05:33 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 07:59:58 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 11:24:24 GMT"}, {"version": "v4", "created": "Wed, 14 Oct 2020 10:08:52 GMT"}, {"version": "v5", "created": "Thu, 17 Dec 2020 14:30:09 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Lannelongue", "Lo\u00efc", ""], ["Grealey", "Jason", ""], ["Inouye", "Michael", ""]]}, {"id": "2007.07710", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "Human $\\neq$ AGI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terms Artificial General Intelligence (AGI) and Human-Level Artificial\nIntelligence (HLAI) have been used interchangeably to refer to the Holy Grail\nof Artificial Intelligence (AI) research, creation of a machine capable of\nachieving goals in a wide range of environments. However, widespread implicit\nassumption of equivalence between capabilities of AGI and HLAI appears to be\nunjustified, as humans are not general intelligences. In this paper, we will\nprove this distinction.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 14:06:13 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "2007.07747", "submitter": "Bryan Wilder", "authors": "Eric Rice, Laura Onasch-Vera, Graham T. DiGuiseppi, Bryan Wilder,\n  Robin Petering, Chyna Hill, Amulya Yadav, Milind Tambe", "title": "Preliminary Results from a Peer-Led, Social Network Intervention,\n  Augmented by Artificial Intelligence to Prevent HIV among Youth Experiencing\n  Homelessness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each year, there are nearly 4 million youth experiencing homelessness (YEH)\nin the United States with HIV prevalence ranging from 3 to 11.5%. Peer change\nagent (PCA) models for HIV prevention have been used successfully in many\npopulations, but there have been notable failures. In recent years, network\ninterventionists have suggested that these failures could be attributed to PCA\nselection procedures. The change agents themselves who are selected to do the\nPCA work can often be as important as the messages they convey. To address this\nconcern, we tested a new PCA intervention for YEH, with three arms: (1) an arm\nusing an artificial intelligence (AI) planning algorithm to select PCA, (2) a\npopularity arm--the standard PCA approach--operationalized as highest degree\ncentrality (DC), and (3) an observation only comparison group (OBS). PCA models\nthat promote HIV testing, HIV knowledge, and condom use are efficacious for\nYEH. Both the AI and DC arms showed improvements over time. AI-based PCA\nselection led to better outcomes and increased the speed of intervention\neffects. Specifically, the changes in behavior observed in the AI arm occurred\nby 1 month, but not until 3 months in the DC arm. Given the transient nature of\nYEH and the high risk for HIV infection, more rapid intervention effects are\ndesirable.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 02:17:53 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Rice", "Eric", ""], ["Onasch-Vera", "Laura", ""], ["DiGuiseppi", "Graham T.", ""], ["Wilder", "Bryan", ""], ["Petering", "Robin", ""], ["Hill", "Chyna", ""], ["Yadav", "Amulya", ""], ["Tambe", "Milind", ""]]}, {"id": "2007.07751", "submitter": "Bianca Minetto Napole\\~ao", "authors": "Katia Romero Felizardo, \\'Erica Ferreira de Souza, Bianca Minetto\n  Napole\\~ao, Nandamudi Lankalapalli Vijaykumar, Maria Teresa Baldassarre", "title": "Secondary Studies in the Academic Context: A Systematic Mapping and\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context: Several researchers have reported their experiences in applying\nsecondary studies (Systematic Literature Reviews - SLRs and Systematic Mappings\n- SMs) in Software Engineering (SE). However, there is still a lack of studies\ndiscussing the value of performing secondary studies in an academic context.\nGoal: The main goal of this study is to provide an overview on the use of\nsecondary studies in an academic context. Method: Two empirical research\nmethods were used. Initially, we conducted an SM to identify the available and\nrelevant studies on the use of secondary studies as a research methodology for\nconducting SE research projects. Secondly, a survey was performed with 64 SE\nresearchers to identify their perception related to the value of performing\nsecondary studies to support their research projects. Results: Our results show\nbenefits of using secondary studies in the academic context, such as, providing\nan overview of the literature as well as identifying relevant research\nliterature on a research area enabling to find reasons to explain why a\nresearch project should be approved for a grant and/or supporting decisions\nmade in a research project. Difficulties faced by SE graduate students with\nsecondary studies are that they tend to be conducted by a team and it demands\nmore effort than a traditional review. Conclusions: Secondary studies are\nvaluable to graduate students. They should consider conducting a secondary\nstudy for their research project due to the benefits and contributions provided\nto develop the overall project. However, the advice of an experienced\nsupervisor is essential to avoid bias. In addition, the acquisition of skills\ncan increase student's motivation to pursue their research projects and prepare\nthem for both academic or industrial careers.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 20:01:26 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Felizardo", "Katia Romero", ""], ["de Souza", "\u00c9rica Ferreira", ""], ["Napole\u00e3o", "Bianca Minetto", ""], ["Vijaykumar", "Nandamudi Lankalapalli", ""], ["Baldassarre", "Maria Teresa", ""]]}, {"id": "2007.07753", "submitter": "Peter Hillmann", "authors": "Sandro Passarelli, Cem G\\\"undogan, Lars Stiemert, Matthias Schopp,\n  Peter Hillmann", "title": "NERD: Neural Network for Edict of Risky Data Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.DC cs.IR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber incidents can have a wide range of cause from a simple connection loss\nto an insistent attack. Once a potential cyber security incidents and system\nfailures have been identified, deciding how to proceed is often complex.\nEspecially, if the real cause is not directly in detail determinable.\nTherefore, we developed the concept of a Cyber Incident Handling Support\nSystem. The developed system is enriched with information by multiple sources\nsuch as intrusion detection systems and monitoring tools. It uses over twenty\nkey attributes like sync-package ratio to identify potential security incidents\nand to classify the data into different priority categories. Afterwards, the\nsystem uses artificial intelligence to support the further decision-making\nprocess and to generate corresponding reports to brief the Board of Directors.\nOriginating from this information, appropriate and detailed suggestions are\nmade regarding the causes and troubleshooting measures. Feedback from users\nregarding the problem solutions are included into future decision-making by\nusing labelled flow data as input for the learning process. The prototype shows\nthat the decision making can be sustainably improved and the Cyber Incident\nHandling process becomes much more effective.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 14:24:48 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Passarelli", "Sandro", ""], ["G\u00fcndogan", "Cem", ""], ["Stiemert", "Lars", ""], ["Schopp", "Matthias", ""], ["Hillmann", "Peter", ""]]}, {"id": "2007.07768", "submitter": "Helge Spieker", "authors": "Mohit Kumar Ahuja, Mohamed-Bachir Belaid, Pierre Bernab\\'e, Mathieu\n  Collet, Arnaud Gotlieb, Chhagan Lal, Dusica Marijan, Sagar Sen, Aizaz Sharif,\n  Helge Spieker", "title": "Opening the Software Engineering Toolbox for the Assessment of\n  Trustworthy AI", "comments": "1st International Workshop on New Foundations for Human-Centered AI @\n  ECAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trustworthiness is a central requirement for the acceptance and success of\nhuman-centered artificial intelligence (AI). To deem an AI system as\ntrustworthy, it is crucial to assess its behaviour and characteristics against\na gold standard of Trustworthy AI, consisting of guidelines, requirements, or\nonly expectations. While AI systems are highly complex, their implementations\nare still based on software. The software engineering community has a\nlong-established toolbox for the assessment of software systems, especially in\nthe context of software testing. In this paper, we argue for the application of\nsoftware engineering and testing practices for the assessment of trustworthy\nAI. We make the connection between the seven key requirements as defined by the\nEuropean Commission's AI high-level expert group and established procedures\nfrom software engineering and raise questions for future work.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 08:16:15 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 14:16:31 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Ahuja", "Mohit Kumar", ""], ["Belaid", "Mohamed-Bachir", ""], ["Bernab\u00e9", "Pierre", ""], ["Collet", "Mathieu", ""], ["Gotlieb", "Arnaud", ""], ["Lal", "Chhagan", ""], ["Marijan", "Dusica", ""], ["Sen", "Sagar", ""], ["Sharif", "Aizaz", ""], ["Spieker", "Helge", ""]]}, {"id": "2007.07838", "submitter": "Deepak P", "authors": "Deepak P", "title": "Whither Fair Clustering?", "comments": "Accepted at the AI for Social Good Workshop, Harvard, July 20-21,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the relatively busy area of fair machine learning that has been\ndominated by classification fairness research, fairness in clustering has\nstarted to see some recent attention. In this position paper, we assess the\nexisting work in fair clustering and observe that there are several directions\nthat are yet to be explored, and postulate that the state-of-the-art in fair\nclustering has been quite parochial in outlook. We posit that widening the\nnormative principles to target for, characterizing shortfalls where the target\ncannot be achieved fully, and making use of knowledge of downstream processes\ncan significantly widen the scope of research in fair clustering research. At a\ntime when clustering and unsupervised learning are being increasingly used to\nmake and influence decisions that matter significantly to human lives, we\nbelieve that widening the ambit of fair clustering is of immense significance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 19:41:25 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["P", "Deepak", ""]]}, {"id": "2007.07860", "submitter": "Vijay Keswani", "authors": "Vijay Keswani and L. Elisa Celis", "title": "Dialect Diversity in Text Summarization on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussions on Twitter involve participation from different communities with\ndifferent dialects and it is often necessary to summarize a large number of\nposts into a representative sample to provide a synopsis. Yet, any such\nrepresentative sample should sufficiently portray the underlying dialect\ndiversity to present the voices of different participating communities\nrepresenting the dialects. Extractive summarization algorithms perform the task\nof constructing subsets that succinctly capture the topic of any given set of\nposts. However, we observe that there is dialect bias in the summaries\ngenerated by common summarization approaches, i.e., they often return summaries\nthat under-represent certain dialects.\n  The vast majority of existing \"fair\" summarization approaches require\nsocially salient attribute labels (in this case, dialect) to ensure that the\ngenerated summary is fair with respect to the socially salient attribute.\nNevertheless, in many applications, these labels do not exist. Furthermore, due\nto the ever-evolving nature of dialects in social media, it is unreasonable to\nlabel or accurately infer the dialect of every social media post. To correct\nfor the dialect bias, we employ a framework that takes an existing text\nsummarization algorithm as a blackbox and, using a small set of dialect-diverse\nsentences, returns a summary that is relatively more dialect-diverse.\nCrucially, this approach does not need the posts being summarized to have\ndialect labels, ensuring that the diversification process is independent of\ndialect classification/identification models. We show the efficacy of our\napproach on Twitter datasets containing posts written in dialects used by\ndifferent social groups defined by race or gender; in all cases, our approach\nleads to improved dialect diversity compared to standard text summarization\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 17:24:41 GMT"}, {"version": "v2", "created": "Sun, 4 Apr 2021 22:49:10 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Keswani", "Vijay", ""], ["Celis", "L. Elisa", ""]]}, {"id": "2007.08003", "submitter": "Mansi Khamkar", "authors": "Gresha Bhatia, Binoy Saha, Mansi Khamkar, Ashish Chandwani, Reshma\n  Khot", "title": "Stutter Diagnosis and Therapy System Based on Deep Learning", "comments": "About stutter classification, severity diagnosis and therapy\n  recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stuttering, also called stammering, is a communication disorder that breaks\nthe continuity of the speech. This program of work is an attempt to develop\nautomatic recognition procedures to assess stuttered dysfluencies and use these\nassessments to filter out speech therapies for an individual. Stuttering may be\nin the form of repetitions, prolongations or abnormal stoppages of sounds and\nsyllables. Our system aims to help stutterers by diagnosing the severity and\ntype of stutter and also by suggesting appropriate therapies for practice by\nlearning the correlation between stutter descriptors and the effectiveness of\nspeech therapies on them. This paper focuses on the implementation of a stutter\ndiagnosis agent using Gated Recurrent CNN on MFCC audio features and therapy\nrecommendation agent using SVM. It also presents the results obtained and\nvarious key findings of the system developed.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:24:02 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Bhatia", "Gresha", ""], ["Saha", "Binoy", ""], ["Khamkar", "Mansi", ""], ["Chandwani", "Ashish", ""], ["Khot", "Reshma", ""]]}, {"id": "2007.08006", "submitter": "Matt Luckcuck", "authors": "Matt Luckcuck and Marie Farrell", "title": "Regulating Safety and Security in Autonomous Robotic Systems", "comments": "Experience Report, reported in BCS FACS Facts", "journal-ref": null, "doi": "10.5281/zenodo.3937545", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Robotics Systems are inherently safety-critical and have complex\nsafety issues to consider (for example, a safety failure can lead to a safety\nfailure). Before they are deployed, these systems of have to show evidence that\nthey adhere to a set of regulator-defined rules for safety and security. Formal\nmethods provide robust approaches to proving a system obeys given rules, but\nformalising (usually natural language) rules can prove difficult. Regulations\nspecifically for autonomous systems are still being developed, but the safety\nrules for a human operator are a good starting point when trying to show that\nan autonomous system is safe. For applications of autonomous systems like\ndriverless cars and pilotless aircraft, there are clear rules for human\noperators, which have been formalised and used to prove that an autonomous\nsystem obeys some or all of these rules. However, in the space and nuclear\nsectors applications are more likely to differ, so a set of general safety\nprinciples has developed. This allows novel applications to be assessed for\ntheir safety, but are difficult to formalise. To improve this situation, we are\ncollaborating with regulators and the community in the space and nuclear\nsectors to develop guidelines for autonomous and robotic systems that are\namenable to robust (formal) verification. These activities also have the\nbenefit of bridging the gaps in knowledge within both the space or nuclear\ncommunities and academia.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 16:33:14 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Luckcuck", "Matt", ""], ["Farrell", "Marie", ""]]}, {"id": "2007.08078", "submitter": "Giovanni Luca Ciampaglia", "authors": "Saumya Bhadani, Shun Yamaya, Alessandro Flammini, Filippo Menczer,\n  Giovanni Luca Ciampaglia, and Brendan Nyhan", "title": "Political audience diversity and news reliability in algorithmic ranking", "comments": "47 pages, 23 figures, 5 tables (including supplementary materials)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Newsfeed algorithms frequently amplify misinformation and other low-quality\ncontent. How can social media platforms more effectively promote reliable\ninformation? Existing approaches are difficult to scale and vulnerable to\nmanipulation. In this paper, we propose using the political diversity of a\nwebsite's audience as a quality signal. Using news source reliability ratings\nfrom domain experts and web browsing data from a diverse sample of 6,890 U.S.\ncitizens, we first show that websites with more extreme and less politically\ndiverse audiences have lower journalistic standards. We then incorporate\naudience diversity into a standard collaborative filtering framework and show\nthat our improved algorithm increases the trustworthiness of websites suggested\nto users -- especially those who most frequently consume misinformation --\nwhile keeping recommendations relevant. These findings suggest that partisan\naudience diversity is a valuable signal of higher journalistic standards that\nshould be incorporated into algorithmic ranking decisions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 02:13:55 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 15:11:31 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Bhadani", "Saumya", ""], ["Yamaya", "Shun", ""], ["Flammini", "Alessandro", ""], ["Menczer", "Filippo", ""], ["Ciampaglia", "Giovanni Luca", ""], ["Nyhan", "Brendan", ""]]}, {"id": "2007.08087", "submitter": "Yingjie Hu", "authors": "Yingjie Hu", "title": "Starting with data: advancing spatial data science by building and\n  sharing high-quality datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial data science has emerged in recent years as an interdisciplinary\nfield. This position paper discusses the importance of building and sharing\nhigh-quality datasets for spatial data science.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 03:15:56 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Hu", "Yingjie", ""]]}, {"id": "2007.08177", "submitter": "Alireza Shojaifar", "authors": "Alireza Shojaifar, Samuel A. Fricker, Martin Gwerder", "title": "Elicitation of SME Requirements for Cybersecurity Solutions by Studying\n  Adherence to Recommendations", "comments": "7 pages, REFSQ 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Small and medium-sized enterprises (SME) have become the weak spot of our\neconomy for cyber attacks. These companies are large in number and often do not\nhave the controls in place to prevent successful attacks, respectively are not\nprepared to systematically manage their cybersecurity capabilities. One of the\nreasons for why many SME do not adopt cybersecurity is that developers of\ncybersecurity solutions understand little the SME context and the requirements\nfor successful use of these solutions. We elicit requirements by studying how\ncybersecurity experts provide advice to SME. The experts recommendations offer\ninsights into what important capabilities of the solution are and how these\ncapabilities ought to be used for mitigating cybersecurity threats. The\nadoption of a recommendation hints at a correct match of the solution, hence\nsuccessful consideration of requirements. Abandoned recommendations point to a\nmisalignment that can be used as a source to inquire missed requirements.\nRe-occurrence of adoption or abandonment decisions corroborate the presence of\nrequirements. This poster describes the challenges of SME regarding\ncybersecurity and introduces our proposed approach to elicit requirements for\ncybersecurity solutions. The poster describes CYSEC, our tool used to capture\ncybersecurity advice and help to scale cybersecurity requirements elicitation\nto a large number of participating SME. We conclude by outlining the planned\nresearch to develop and validate CYSEC.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 08:36:40 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Shojaifar", "Alireza", ""], ["Fricker", "Samuel A.", ""], ["Gwerder", "Martin", ""]]}, {"id": "2007.08197", "submitter": "Cristina Menghini", "authors": "Cristina Menghini and Aris Anagnostopoulos and Eli Upfal", "title": "Auditing Wikipedia's Hyperlinks Network on Polarizing Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  People eager to learn about a topic can access Wikipedia to form a\npreliminary opinion. Despite the solid revision process behind the\nencyclopedia's articles, the users' exploration process is still influenced by\nthe hyperlinks' network. In this paper, we shed light on this overlooked\nphenomenon by investigating how articles describing complementary subjects of a\ntopic interconnect, and thus may shape readers' exposure to diverging content.\nTo quantify this, we introduce the exposure to diverse information, a metric\nthat captures how users' exposure to multiple subjects of a topic varies\nclick-after-click by leveraging navigation models.\n  For the experiments, we collected six topic-induced networks about polarizing\ntopics and analyzed the extent to which their topologies induce readers to\nexamine diverse content. More specifically, we take two sets of articles about\nopposing stances (e.g., guns control and guns right) and measure the\nprobability that users move within or across the sets, by simulating their\nbehavior via a Wikipedia-tailored model. Our findings show that the networks\nhinder users to symmetrically explore diverse content. Moreover, on average,\nthe probability that the networks nudge users to remain in a knowledge bubble\nis up to an order of magnitude higher than that of exploring pages of\ncontrasting subjects. Taken together, those findings return a new and\nintriguing picture of Wikipedia's network structural influence on polarizing\nissues' exploration.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 09:19:57 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 14:32:19 GMT"}, {"version": "v3", "created": "Fri, 5 Mar 2021 17:15:16 GMT"}, {"version": "v4", "created": "Mon, 8 Mar 2021 05:51:08 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Menghini", "Cristina", ""], ["Anagnostopoulos", "Aris", ""], ["Upfal", "Eli", ""]]}, {"id": "2007.08201", "submitter": "Alireza Shojaifar", "authors": "Alireza Shojaifar", "title": "SMEs Confidentiality Issues and Adoption of Good Cybersecurity Practices", "comments": "9 pages, 1 figure, ifip summer school 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Small and medium-sized enterprises (SME) are considered more vulnerable to\ncyber-attacks. However, and based on SMEs characteristics, they do not adopt\ngood cybersecurity practices. To address the SMEs security adoption problem, we\nare designing a do-it-yourself (DIY) security assessment and capability\nimprovement method, CYSEC. In the first validation of CYSEC, we conducted a\nmulti-case study in four SMEs. We observed that confidentiality concerns could\ninfluence users decisions to provide CYSEC with relevant and accurate security\ninformation. The lack of precise information may impact our DIY assessment\nmethod to provide accurate recommendations. In this paper, we explore the\nimportance of dynamic consent and its effect on SMEs trust perception and\nsharing information. We discuss the lack of trust perception may be addressed\nby applying dynamic consent. Finally, we describe the results of three\ninterviews with SMEs and present how the new way of communication in CYSEC can\nhelp us to understand better SMEs attitudes towards sharing information.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 09:24:51 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Shojaifar", "Alireza", ""]]}, {"id": "2007.08331", "submitter": "Wayes Tushar", "authors": "Wayes Tushar, Tapan K. Saha, Chau Yuen, Peta Ashworth, H. Vincent Poor\n  and Subarna Basnet", "title": "Challenges and Prospects of Negawatt Trading in Light of Recent\n  Technological Developments", "comments": "Accepted in Nature Energy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of the smart grid, the current energy system is moving\ntowards a future where people can buy what they need, sell when they have\nexcess, and can trade the right of buying to other prosumers. While the first\ntwo schemes already exist in the market, selling the right of buying, also\nknown as negawatt trading, is something that is yet to be implemented. Here, we\nreview the challenges and prospects of negawatt trading in light of recent\ntechnological advancements. Through reviewing a number of emerging\ntechnologies, we show that the necessary methodologies that are needed to\nestablish negawatt trading as a feasible energy management scheme in the smart\ngrid are already available. Grid interactive buildings and distributed ledger\ntechnologies for instance can ensure active participation and fair pricing.\nHowever, some additional challenges need to address for fully functional\nnegawatt trading mechanisms in today's energy market.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 13:41:14 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Tushar", "Wayes", ""], ["Saha", "Tapan K.", ""], ["Yuen", "Chau", ""], ["Ashworth", "Peta", ""], ["Poor", "H. Vincent", ""], ["Basnet", "Subarna", ""]]}, {"id": "2007.08375", "submitter": "Luiz Capretz Dr.", "authors": "Yadira Lizama, Daniel Varona, Pradeep Waychal, Luiz Fernando Capretz", "title": "The Unpopularity of the Software Tester Role among Software\n  Practitioners: A Case Study", "comments": "pp. 183-194", "journal-ref": "Book: Advances in Reliability, Availability, Maintainability and\n  Safety (RAMS) Engineering, 2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As software systems are becoming more pervasive, they are also becoming more\nsusceptible to failures, resulting in potentially lethal combinations. Software\ntest-ing is critical to preventing software failures but is, arguably, the\nleast understood part of the software life cycle and the toughest to perform\ncorrectly. Adequate re-search has been carried out in both the process and\ntechnology dimensions of testing, but not in the human dimensions. This work\nattempts to fill in the gap by exploring the human dimension, i.e., trying to\nunderstand the motivation/de-motivation of software practitioners to take up\nand sustain testing careers. One hundred and forty four software practitioners\nfrom several Cuban software insti-tutes were surveyed. Individuals were asked\nthe PROs (advantages or motiva-tors) and CONs (disadvantages or de-motivators)\nof taking up a career in soft-ware testing and their chances of doing so. The\nresults of this investigation identi-fied 9 main PROs and 8 main CONs for\ntaking up a testing career showing that the role of tester is perceived as a\nsocial role.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 14:52:36 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Lizama", "Yadira", ""], ["Varona", "Daniel", ""], ["Waychal", "Pradeep", ""], ["Capretz", "Luiz Fernando", ""]]}, {"id": "2007.08457", "submitter": "Ning Yu", "authors": "Ning Yu, Vladislav Skripniuk, Sahar Abdelnabi, Mario Fritz", "title": "Artificial Fingerprinting for Generative Models: Rooting Deepfake\n  Attribution in Training Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.CY cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photorealistic image generation has reached a new level of quality due to the\nbreakthroughs of generative adversarial networks (GANs). Yet, the dark side of\nsuch deepfakes, the malicious use of generated media, raises concerns about\nvisual misinformation. While existing research work on deepfake detection\ndemonstrates high accuracy, it is subject to advances in generation techniques\nand adversarial iterations on detection countermeasure techniques. Thus, we\nseek a proactive and sustainable solution on deepfake detection, that is\nagnostic to the evolution of generative models, by introducing artificial\nfingerprints into the models.\n  Our approach is simple and effective. We first embed artificial fingerprints\ninto training data, then validate a surprising discovery on the transferability\nof such fingerprints from training data to generative models, which in turn\nappears in the generated deepfakes. Experiments show that our fingerprinting\nsolution (1) holds for a variety of cutting-edge generative models, (2) leads\nto a negligible side effect on generation quality, (3) stays robust against\nimage-level and model-level perturbations, (4) stays hard to be detected by\nadversaries, and (5) converts deepfake detection and attribution into trivial\ntasks and outperforms the recent state-of-the-art baselines. Our solution\ncloses the responsibility loop between publishing pre-trained generative model\ninventions and their possible misuses, which makes it independent of the\ncurrent arms race.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:49:55 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 21:46:54 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 04:17:39 GMT"}, {"version": "v4", "created": "Wed, 16 Dec 2020 00:32:00 GMT"}, {"version": "v5", "created": "Wed, 31 Mar 2021 00:49:28 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Yu", "Ning", ""], ["Skripniuk", "Vladislav", ""], ["Abdelnabi", "Sahar", ""], ["Fritz", "Mario", ""]]}, {"id": "2007.08626", "submitter": "Jan Kallberg", "authors": "Jan Kallberg", "title": "Revisiting Strategic Cyberwar Theory Reaching Decisive Strategic Outcome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each strategy has a foundation, an overarching way of explaining why things\nare the way we see them and how to successfully reach our goals. Therefore,\nstrategy is theory based because theory provides an intellectual framework for\npredicting outcomes leading to the end goal the strategy pursues. This article\nwill present a theory, strategic cyberwar theory, that states that the utility\nof strategic cyberwar is tied to the likelihood of institutional instability in\nthe targeted nation. In an ideal scenario, the cyber attacks are systematically\nattacking the targeted adversary institutions triggering the dormant entropy\nembedded in a nation with weak institutions. This will lead to submission to\nforeign policy and intent. The current alternative to strategic cyberwar theory\nis to unsystematically attack the adversary with cyber attacks where\nexploitation opportunities occur, which is likely to degrade parts of the\ninformation infrastructure, but it will not reach any strategic goals. If an\nadversarial society is unaffected by a cyber conflict, the conflict itself has\nnot reached a decisive outcome, and results only in tit for tat game or\nstalemate. In strategic cyberwar theory1, the concept is to cyber attack the\ncore of the institutional framework of the adversarial nation in pursuit of\ndestabilization.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 20:44:43 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Kallberg", "Jan", ""]]}, {"id": "2007.08630", "submitter": "Doron Laadan", "authors": "Doron Laadan, Eyal Arviv, and Michael Fire", "title": "Using Data Mining for Infrastructure and Safety Violations Discovery in\n  Cities", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In city planning and maintenance, the abilty to quickly identify\ninfrastructure violations - such as missing or misplaced fire hydrants - can be\ncrucial for maintaining a safe city; it can even save lives. In this work, we\naim to provide an analysis of such violations, and to demonstrate the potential\nof data-driven approaches for quickly locating and addressing them. We conduct\nan analytical study based upon data from the city of Beer-Sheva's public\nrecords of fire hydrants, bomb shelters, and other public facilities. The\nresult of our analysis are presented along with an interactive exploration\ntool, which allows for easy exploration and identification of different\nfacilities around the city that viloate regulations.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 20:50:44 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Laadan", "Doron", ""], ["Arviv", "Eyal", ""], ["Fire", "Michael", ""]]}, {"id": "2007.08666", "submitter": "Mike Zajko", "authors": "Mike Zajko", "title": "Conservative AI and social inequality: Conceptualizing alternatives to\n  bias through social theory", "comments": "AI & Soc (2021)", "journal-ref": null, "doi": "10.1007/s00146-021-01153-9", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to calls for greater interdisciplinary involvement from the\nsocial sciences and humanities in the development, governance, and study of\nartificial intelligence systems, this paper presents one sociologist's view on\nthe problem of algorithmic bias and the reproduction of societal bias.\nDiscussions of bias in AI cover much of the same conceptual terrain that\nsociologists studying inequality have long understood using more specific terms\nand theories. Concerns over reproducing societal bias should be informed by an\nunderstanding of the ways that inequality is continually reproduced in society\n-- processes that AI systems are either complicit in, or can be designed to\ndisrupt and counter. The contrast presented here is between conservative and\nradical approaches to AI, with conservatism referring to dominant tendencies\nthat reproduce and strengthen the status quo, while radical approaches work to\ndisrupt systemic forms of inequality. The limitations of conservative\napproaches to class, gender, and racial bias are discussed as specific\nexamples, along with the social structures and processes that biases in these\nareas are linked to. Societal issues can no longer be out of scope for AI and\nmachine learning, given the impact of these systems on human lives. This\nrequires engagement with a growing body of critical AI scholarship that goes\nbeyond biased data to analyze structured ways of perpetuating inequality,\nopening up the possibility for radical alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 21:52:13 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Zajko", "Mike", ""]]}, {"id": "2007.08670", "submitter": "Tom Williams", "authors": "Ryan Blake Jackson and Tom Williams", "title": "Enabling Morally Sensitive Robotic Clarification Requests", "comments": "Accepted for nonarchival presentation at Advances in Cognitive\n  Systems (ACS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of current natural language oriented robot architectures enables\ncertain architectural components to circumvent moral reasoning capabilities.\nOne example of this is reflexive generation of clarification requests as soon\nas referential ambiguity is detected in a human utterance. As shown in previous\nresearch, this can lead robots to (1) miscommunicate their moral dispositions\nand (2) weaken human perception or application of moral norms within their\ncurrent context. We present a solution to these problems by performing moral\nreasoning on each potential disambiguation of an ambiguous human utterance and\nresponding accordingly, rather than immediately and naively requesting\nclarification. We implement our solution in the DIARC robot architecture,\nwhich, to our knowledge, is the only current robot architecture with both moral\nreasoning and clarification request generation capabilities. We then evaluate\nour method with a human subjects experiment, the results of which indicate that\nour approach successfully ameliorates the two identified concerns.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 22:12:35 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Jackson", "Ryan Blake", ""], ["Williams", "Tom", ""]]}, {"id": "2007.08708", "submitter": "Ciera Martinez", "authors": "Sara Stoudt, Valeri N. Vasquez, Ciera C. Martinez", "title": "Principles for data analysis workflows", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1008770", "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional data science education often omits training on research\nworkflows: the process that moves a scientific investigation from raw data to\ncoherent research question to insightful contribution. In this paper, we\nelaborate basic principles of a reproducible data analysis workflow by defining\nthree phases: the Exploratory, Refinement, and Polishing Phases. Each workflow\nphase is roughly centered around the audience to whom research decisions,\nmethodologies, and results are being immediately communicated. Importantly,\neach phase can also give rise to a number of research products beyond\ntraditional academic publications. Where relevant, we draw analogies between\nprinciples for data-intensive research workflows and established practice in\nsoftware development. The guidance provided here is not intended to be a strict\nrulebook; rather, the suggestions for practices and tools to advance\nreproducible, sound data-intensive analysis may furnish support for both\nstudents and current professionals.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 01:17:37 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Stoudt", "Sara", ""], ["Vasquez", "Valeri N.", ""], ["Martinez", "Ciera C.", ""]]}, {"id": "2007.08886", "submitter": "Simone Parisotto Dr", "authors": "Ninetta Leone, Simone Parisotto, Kasia Targonska-Hadzibabic, Spike\n  Bucklow, Alessandro Launaro, Suzanne Reynolds, Carola-Bibiane Sch\\\"onlieb", "title": "Art Speaks Maths, Maths Speaks Art", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our interdisciplinary team Mathematics for Applications in Cultural Heritage\n(MACH) aims to use mathematical research for the benefit of the arts and\nhumanities. Our ultimate goal is to create user-friendly software toolkits for\nartists, art conservators and archaeologists. In order for their underlying\nmathematical engines and functionality to be optimised for the needs of the end\nusers, we pursue an iterative approach based on a continuous communication\nbetween the mathematicians and the cultural-heritage members of our team. Our\npaper illustrates how maths can speak art, but only if first art speaks maths.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 10:24:23 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Leone", "Ninetta", ""], ["Parisotto", "Simone", ""], ["Targonska-Hadzibabic", "Kasia", ""], ["Bucklow", "Spike", ""], ["Launaro", "Alessandro", ""], ["Reynolds", "Suzanne", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "2007.08911", "submitter": "Ehsan Toreini", "authors": "Ehsan Toreini, Mhairi Aitken, Kovila P. L. Coopamootoo, Karen Elliott,\n  Vladimiro Gonzalez Zelaya, Paolo Missier, Magdalene Ng, Aad van Moorsel", "title": "Technologies for Trustworthy Machine Learning: A Survey in a\n  Socio-Technical Context", "comments": "We are updating some sections to include more recent advances", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concerns about the societal impact of AI-based services and systems has\nencouraged governments and other organisations around the world to propose AI\npolicy frameworks to address fairness, accountability, transparency and related\ntopics. To achieve the objectives of these frameworks, the data and software\nengineers who build machine-learning systems require knowledge about a variety\nof relevant supporting tools and techniques. In this paper we provide an\noverview of technologies that support building trustworthy machine learning\nsystems, i.e., systems whose properties justify that people place trust in\nthem. We argue that four categories of system properties are instrumental in\nachieving the policy objectives, namely fairness, explainability, auditability\nand safety & security (FEAS). We discuss how these properties need to be\nconsidered across all stages of the machine learning life cycle, from data\ncollection through run-time model inference. As a consequence, we survey in\nthis paper the main technologies with respect to all four of the FEAS\nproperties, for data-centric as well as model-centric stages of the machine\nlearning system life cycle. We conclude with an identification of open research\nproblems, with a particular focus on the connection between trustworthy machine\nlearning technologies and their implications for individuals and society.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 11:39:20 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 09:40:31 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Toreini", "Ehsan", ""], ["Aitken", "Mhairi", ""], ["Coopamootoo", "Kovila P. L.", ""], ["Elliott", "Karen", ""], ["Zelaya", "Vladimiro Gonzalez", ""], ["Missier", "Paolo", ""], ["Ng", "Magdalene", ""], ["van Moorsel", "Aad", ""]]}, {"id": "2007.09134", "submitter": "Ganga Prasad Basyal", "authors": "Ganga Prasad Basyal, Bhaskar P. Rimal, and David Zeng", "title": "A Systematic Review of Natural Language Processing for Knowledge\n  Management in Healthcare", "comments": null, "journal-ref": null, "doi": "10.5121/csit.2020.100921", "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the visions of Data Science, recent years have seen a paradigm\nshift in Natural Language Processing (NLP). NLP has set the milestone in text\nprocessing and proved to be the preferred choice for researchers in the\nhealthcare domain. The objective of this paper is to identify the potential of\nNLP, especially, how NLP is used to support the knowledge management process in\nthe healthcare domain, making data a critical and trusted component in\nimproving the health outcomes. This paper provides a comprehensive survey of\nthe state-of-the-art NLP research with a particular focus on how knowledge is\ncreated, captured, shared, and applied in the healthcare domain. Our findings\nsuggest, first, the techniques of NLP those supporting knowledge management\nextraction and knowledge capture processes in healthcare. Second, we propose a\nconceptual model for the knowledge extraction process through NLP. Finally, we\ndiscuss a set of issues, challenges, and proposed future research areas.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 17:50:50 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Basyal", "Ganga Prasad", ""], ["Rimal", "Bhaskar P.", ""], ["Zeng", "David", ""]]}, {"id": "2007.09181", "submitter": "Siddharth Dixit Mr.", "authors": "Siddharth Dixit, Meghna Chaudhary, Niteesh Sahni", "title": "Network Learning Approaches to study World Happiness", "comments": "13 Pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The United Nations in its 2011 resolution declared the pursuit of happiness a\nfundamental human goal and proposed public and economic policies centered\naround happiness. In this paper we used 2 types of computational strategies\nviz. Predictive Modelling and Bayesian Networks (BNs) to model the processed\nhistorical happiness index data of 156 nations published by UN since 2012. We\nattacked the problem of prediction using General Regression Neural Networks\n(GRNNs) and show that it out performs other state of the art predictive models.\nTo understand causal links amongst key features that have been proven to have a\nsignificant impact on world happiness, we first used a manual discretization\nscheme to discretize continuous variables into 3 levels viz. Low, Medium and\nHigh. A consensus World Happiness BN structure was then fixed after\namalgamating information by learning 10000 different BNs using bootstrapping.\nLastly, exact inference through conditional probability queries was used on\nthis BN to unravel interesting relationships among the important features\naffecting happiness which would be useful in policy making.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 18:29:49 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Dixit", "Siddharth", ""], ["Chaudhary", "Meghna", ""], ["Sahni", "Niteesh", ""]]}, {"id": "2007.09230", "submitter": "Daniel Mendoza", "authors": "Daniel L. Mendoza (1 and 2), Cheryl S. Pirozzi (1), Erik T. Crosman\n  (3), Theodore G. Liou (1 and 4), Yue Zhang (5), Jessica J. Cleeves (6),\n  Stephen C. Bannister (7), William R.L. Anderegg (8), Robert Paine III (1)\n  ((1) Division of Respiratory, Critical Care and Occupational Pulmonary\n  Medicine, School of Medicine, University of Utah, (2) Department of\n  Atmospheric Sciences, University of Utah, (3) Department of Life, Earth, and\n  Environmental Sciences, West Texas A&M University, (4) Center for\n  Quantitative Biology, University of Utah, (5) Division of Epidemiology,\n  Department of Internal Medicine, University of Utah School of Medicine, (6)\n  Center for Science and Mathematics Education, University of Utah, (7)\n  Department of Economics, University of Utah, (8) School of Biological\n  Sciences, University of Utah)", "title": "Absentee and Economic Impact of Low-Level Fine Particulate Matter and\n  Ozone Exposure in K-12 Students", "comments": "31 pages, 11 figures, 2 tables", "journal-ref": null, "doi": "10.13140/RG.2.2.12720.17925", "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High air pollution levels are associated with school absences. However, low\nlevel pollution impact on individual school absences are under-studied. We\nmodelled PM2.5 and ozone concentrations at 36 schools from July 2015 to June\n2018 using data from a dense, research grade regulatory sensor network. We\ndetermined exposures and daily absences at each school. We used generalized\nestimating equations model to retrospectively estimate rate ratios for\nassociation between outdoor pollutant concentrations and school absences. We\nestimated lost school revenue, productivity, and family economic burden. PM2.5\nand ozone concentrations and absence rates vary across the School District.\nPollution exposure were associated with as high a rate ratio of 1.02 absences\nper ug/m$^3$ and 1.01 per ppb increase for PM2.5 and ozone, respectively.\nSignificantly, even PM2.5 and ozone exposure below regulatory standards (<12.1\nug/m$^3$ and <55 ppb) was associated with positive rate ratios of absences:\n1.04 per ug/m$^3$ and 1.01 per ppb increase, respectively. Granular local\nmeasurements enabled demonstration of air pollution impacts that varied between\nschools undetectable with averaged pollution levels. Reducing pollution by 50%\nwould save $452,000 per year districtwide. Pollution reduction benefits would\nbe greatest in schools located in socioeconomically disadvantaged areas.\nExposures to air pollution, even at low levels, are associated with increased\nschool absences. Heterogeneity in exposure, disproportionately affecting\nsocioeconomically disadvantaged schools, points to the need for fine resolution\nexposure estimation. The economic cost of absences associated with air\npollution is substantial even excluding indirect costs such as hospital visits\nand medication. These findings may help inform decisions about recess during\nsevere pollution events and regulatory considerations for localized pollution\nsources.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 01:27:27 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Mendoza", "Daniel L.", "", "1 and 2"], ["Pirozzi", "Cheryl S.", "", "1 and 4"], ["Crosman", "Erik T.", "", "1 and 4"], ["Liou", "Theodore G.", "", "1 and 4"], ["Zhang", "Yue", ""], ["Cleeves", "Jessica J.", ""], ["Bannister", "Stephen C.", ""], ["Anderegg", "William R. L.", ""], ["Paine", "Robert", "III"]]}, {"id": "2007.09402", "submitter": "Massimo Stella", "authors": "Massimo Stella, Anastasiya Kapuza, Catherine Cramer and Stephen Uzzo", "title": "Mapping computational thinking mindsets between educational levels with\n  cognitive network science", "comments": "18 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI physics.ed-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computational thinking is a way of reasoning about the world in terms of\ndata. This mindset channels number crunching toward an ambition to discover\nknowledge through logic, models and simulations. Here we show how computational\ncognitive science can be used to reconstruct and analyse the structure of\ncomputational thinking mindsets (forma mentis in Latin) through complex\nnetworks. As a case study, we investigate cognitive networks tied to key\nconcepts of computational thinking provided by: (i) 159 high school students\nenrolled in a science curriculum and (ii) 59 researchers in complex systems and\nsimulations. Researchers' reconstructed forma mentis highlighted a positive\nmindset about scientific modelling, semantically framing data and simulations\nas ways of discovering nature. Students correctly identified different aspects\nof logic reasoning but perceived \"computation\" as a distressing,\nanxiety-eliciting task, framed with math jargon and lacking links to real-world\ndiscovery. Students' mindsets around \"data\", \"model\" and \"simulations\"\ncritically revealed no awareness of numerical modelling as a way for\nunderstanding the world. Our findings provide evidence of a crippled\ncomputational thinking mindset in students, who acquire mathematical skills\nthat are not channelled toward real-world discovery through coding. This\nunlinked knowledge ends up being perceived as distressing number-crunching\nexpertise with no relevant outcome. The virtuous mindset of researchers\nreported here indicates that computational thinking can be restored by training\nstudents specifically in coding, modelling and simulations in relation to\ndiscovering nature. Our approach opens innovative ways for quantifying\ncomputational thinking and enhancing its development through mindset\nreconstruction.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 10:51:21 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Stella", "Massimo", ""], ["Kapuza", "Anastasiya", ""], ["Cramer", "Catherine", ""], ["Uzzo", "Stephen", ""]]}, {"id": "2007.09416", "submitter": "Anna Jobin", "authors": "James Scheibner, Anna Jobin, Effy Vayena", "title": "Ethical issues with using Internet of Things devices in citizen science\n  research: A scoping review", "comments": "Authors' version; 17 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our chapter presents a scoping review of published scientific studies or case\nstudies of scientific studies that utilise both citizen scientists and Internet\nof Things devices. Specifically, we selected studies where the authors had\nincluded at least a short discussion of the ethical issues encountered during\nthe research process. Having conducted a search of five databases (IEEE Xplore,\nScopus, Web of Science, ProQuest, and PubMed), we identified 631 potential\nresults. Following abstract and title screening, and then full text eligibility\nassessment, we identified 34 published articles that matched our criteria. We\nthen analysed the full text for these articles inductively and deductively,\ncoding ethical issues into three main categories. These categories were\nautonomy and data privacy, data quality, and intellectual property. We also\nanalysed the full text of these articles to see what strategies researchers\ntook to resolve these ethical issues, as well as any legal implications raised.\nFollowing this analysis, our discussion provides recommendations for\nresearchers who wish to integrate citizen scientists and Internet of Things\ndevices into their research. First, all citizen science projects should\nintegrate a data privacy protocol to protect the confidentiality of\nparticipants. Secondly, scientific researchers should consider any potential\nissues of data quality, including whether compromises might be required, before\nestablishing a project. Finally, all intellectual property issues should be\nclarified both at the start of the project and during its lifecycle.\nResearchers should also consider any ethical issues that might flow from the\nuse of commercially available Internet of Things devices for research.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 12:22:05 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 13:48:26 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Scheibner", "James", ""], ["Jobin", "Anna", ""], ["Vayena", "Effy", ""]]}, {"id": "2007.09815", "submitter": "Liang Zhao", "authors": "Liang Zhao", "title": "Event Prediction in the Big Data Era: A Systematic Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events are occurrences in specific locations, time, and semantics that\nnontrivially impact either our society or the nature, such as civil unrest,\nsystem failures, and epidemics. It is highly desirable to be able to anticipate\nthe occurrence of such events in advance in order to reduce the potential\nsocial upheaval and damage caused. Event prediction, which has traditionally\nbeen prohibitively challenging, is now becoming a viable option in the big data\nera and is thus experiencing rapid growth. There is a large amount of existing\nwork that focuses on addressing the challenges involved, including\nheterogeneous multi-faceted outputs, complex dependencies, and streaming data\nfeeds. Most existing event prediction methods were initially designed to deal\nwith specific application domains, though the techniques and evaluation\nprocedures utilized are usually generalizable across different domains.\nHowever, it is imperative yet difficult to cross-reference the techniques\nacross different domains, given the absence of a comprehensive literature\nsurvey for event prediction. This paper aims to provide a systematic and\ncomprehensive survey of the technologies, applications, and evaluations of\nevent prediction in the big data era. First, systematic categorization and\nsummary of existing techniques are presented, which facilitate domain experts'\nsearches for suitable techniques and help model developers consolidate their\nresearch at the frontiers. Then, comprehensive categorization and summary of\nmajor application domains are provided. Evaluation metrics and procedures are\nsummarized and standardized to unify the understanding of model performance\namong stakeholders, model developers, and domain experts in various application\ndomains. Finally, open problems and future directions for this promising and\nimportant domain are elucidated and discussed.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 23:24:52 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 01:39:17 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2020 23:59:11 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Zhao", "Liang", ""]]}, {"id": "2007.09834", "submitter": "Ioannis Korkontzelos", "authors": "Isa Inuwa-Dutse, Mark Liptrott and Ioannis Korkontzelos", "title": "Migration and Refugee Crisis: a Critical Analysis of Online Public\n  Perception", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The migration rate and the level of resentments towards migrants are an\nimportant issue in modern civilisation. The infamous EU refugee crisis caught\nmany countries unprepared, leading to sporadic and rudimentary containment\nmeasures that, in turn, led to significant public discourse. Decades of offline\ndata collected via traditional survey methods have been utilised earlier to\nunderstand public opinion to foster peaceful coexistence. Capturing and\nunderstanding online public opinion via social media is crucial towards a joint\nstrategic regulation spanning safety, rights of migrants and cordial\nintegration for economic prosperity. We present a analysis of opinions on\nmigrants and refugees expressed by the users of a very popular social platform,\nTwitter. We analyse sentiment and the associated context of expressions in a\nvast collection of tweets related to the EU refugee crisis. Our study reveals a\nmarginally higher proportion of negative sentiments vis-a-vis migrants and a\nlarge proportion of the negative sentiments is more reflected among the\nordinary users. Users with many followers and non-governmental organisations\n(NGO) tend to tweet favourably about the topic, offsetting the distribution of\nnegative sentiment. We opine that they can be encouraged to be more proactive\nin neutralising negative attitudes that may arise concerning similar\nincidences.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 02:04:01 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Inuwa-Dutse", "Isa", ""], ["Liptrott", "Mark", ""], ["Korkontzelos", "Ioannis", ""]]}, {"id": "2007.10083", "submitter": "Huimin Xu", "authors": "Huimin Xu, Zhicong Chen, Ruiqi Li, Cheng-Jun Wang", "title": "The Geometry of Information Cocoon: Analyzing the Cultural Space with\n  Word Embedding Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accompanied by the development of digital media, the threat of information\ncocoon has become a significant issue. However, little is known about the\nmeasure of information cocoon as a cultural space and its relationship with\nsocial class. This study addresses this problem by constructing the cultural\nspace with word embedding models and random shuffling methods among three\nlarge-scale digital media use datasets. In the light of field theory of\ncultural production, we investigate the information cocoon effect on different\nsocial classes among 979 computer users, 100,000 smartphone users, and 159,373\nmobile reading application users. Our analysis reveals that information cocoons\nwidely exist in the daily use of digital media. Moreover, people of lower\nsocial class have a higher probability of getting stuck in the information\ncocoon filled with the entertainment content. In contrast, the people of higher\nsocial class have more capability to stride over the constraints of the\ninformation cocoon. The results suggest that the disadvantages for vulnerable\ngroups in acquiring knowledge may further widen social inequality.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 13:30:25 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 03:04:33 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 10:04:38 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Xu", "Huimin", ""], ["Chen", "Zhicong", ""], ["Li", "Ruiqi", ""], ["Wang", "Cheng-Jun", ""]]}, {"id": "2007.10159", "submitter": "Sagar Joglekar", "authors": "Sagar Joglekar, Sumithra Velupillai, Rina Dutta, Nishanth Sastry", "title": "Analysing Meso and Macro conversation structures in an online suicide\n  support forum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Platforms like Reddit and Twitter offer internet users an opportunity to talk\nabout diverse issues, including those pertaining to physical and mental health.\nSome of these forums also function as a safe space for severely distressed\nmental health patients to get social support from peers. The online community\nplatform Reddit's SuicideWatch is one example of an online forum dedicated\nspecifically to people who suffer from suicidal thoughts, or who are concerned\nabout people who might be at risk. It remains to be seen if these forums can be\nused to understand and model the nature of online social support, not least\nbecause of the noisy and informal nature of conversations. Moreover,\nunderstanding how a community of volunteering peers react to calls for help in\ncases of suicidal posts, would help to devise better tools for online\nmitigation of such episodes. In this paper, we propose an approach to\ncharacterise conversations in online forums. Using data from the SuicideWatch\nsubreddit as a case study, we propose metrics at a macroscopic level --\nmeasuring the structure of the entire conversation as a whole. We also develop\na framework to measure structures in supportive conversations at a mesoscopic\nlevel -- measuring interactions with the immediate neighbours of the person in\ndistress. We statistically show through comparison with baseline conversations\nfrom random Reddit threads that certain macro and meso-scale structures in an\nonline conversation exhibit signatures of social support, and are particularly\nover-expressed in SuicideWatch conversations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 14:33:53 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Joglekar", "Sagar", ""], ["Velupillai", "Sumithra", ""], ["Dutta", "Rina", ""], ["Sastry", "Nishanth", ""]]}, {"id": "2007.10235", "submitter": "Diane Hosfelt", "authors": "Diane Hosfelt and Nicole Shadowen", "title": "Privacy Implications of Eye Tracking in Mixed Reality", "comments": "Presented at CHI Workshop on Exploring Potentially Abusive Ethical\n  Social and Political Implications of Mixed Reality Research in HCI\n  (https://chi2020.acm.org/accepted-workshops/#W37)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed Reality (MR) devices require a world with always-on sensors and\nreal-time processing applied to their outputs. We have grappled with some of\nthe ethical concerns presented by this scenario, such as bystander privacy\nissues with smartphones and cameras. However, MR technologies demand that we\ndefine and defend privacy in this new paradigm. This paper focuses on the\nchallenges presented by eye tracking and gaze tracking, techniques that have\ncommonly been deployed in the HCI community for years but are now being\nintegrated into MR devices by default.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 16:25:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hosfelt", "Diane", ""], ["Shadowen", "Nicole", ""]]}, {"id": "2007.10246", "submitter": "Diane Hosfelt", "authors": "Nicole Shadowen and Diane Hosfelt", "title": "Addressing the Privacy Implications of Mixed Reality: A Regulatory\n  Approach", "comments": "Presented at the CHI 2020 Workshop on Exploring Potentially Abusive\n  Ethical, Social and Political Implications of Mixed Reality Research in HCI\n  (https://chi2020.acm.org/accepted-workshops/#W37)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed reality (MR) technologies are emerging into the mainstream with\naffordable devices like the Oculus Quest. These devices blend the physical and\nvirtual in novel ways that blur the lines that exist in legal precedent, like\nthose between speech and conduct. In this paper, we discuss the challenges of\nregulating immersive technologies, focusing on the potential for extensive data\ncollection, and examine the trade-offs of three potential approaches to\nprotecting data privacy in the context of mixed reality environments.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 16:35:17 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Shadowen", "Nicole", ""], ["Hosfelt", "Diane", ""]]}, {"id": "2007.10306", "submitter": "Stephen Pfohl", "authors": "Stephen R. Pfohl, Agata Foryciarz, Nigam H. Shah", "title": "An Empirical Characterization of Fair Machine Learning For Clinical Risk\n  Prediction", "comments": "Published in the Journal of Biomedical Informatics\n  (https://doi.org/10.1016/j.jbi.2020.103621). Version 3 updates\n  acknowledgements and fixes typos", "journal-ref": "Journal of Biomedical Informatics, Volume 113, January 2021,\n  103621", "doi": "10.1016/j.jbi.2020.103621", "report-no": null, "categories": "stat.ML cs.CY cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning to guide clinical decision making has the\npotential to worsen existing health disparities. Several recent works frame the\nproblem as that of algorithmic fairness, a framework that has attracted\nconsiderable attention and criticism. However, the appropriateness of this\nframework is unclear due to both ethical as well as technical considerations,\nthe latter of which include trade-offs between measures of fairness and model\nperformance that are not well-understood for predictive models of clinical\noutcomes. To inform the ongoing debate, we conduct an empirical study to\ncharacterize the impact of penalizing group fairness violations on an array of\nmeasures of model performance and group fairness. We repeat the analyses across\nmultiple observational healthcare databases, clinical outcomes, and sensitive\nattributes. We find that procedures that penalize differences between the\ndistributions of predictions across groups induce nearly-universal degradation\nof multiple performance metrics within groups. On examining the secondary\nimpact of these procedures, we observe heterogeneity of the effect of these\nprocedures on measures of fairness in calibration and ranking across\nexperimental conditions. Beyond the reported trade-offs, we emphasize that\nanalyses of algorithmic fairness in healthcare lack the contextual grounding\nand causal awareness necessary to reason about the mechanisms that lead to\nhealth disparities, as well as about the potential of algorithmic fairness\nmethods to counteract those mechanisms. In light of these limitations, we\nencourage researchers building predictive models for clinical use to step\noutside the algorithmic fairness frame and engage critically with the broader\nsociotechnical context surrounding the use of machine learning in healthcare.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 17:46:31 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 19:25:57 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 15:28:53 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Pfohl", "Stephen R.", ""], ["Foryciarz", "Agata", ""], ["Shah", "Nigam H.", ""]]}, {"id": "2007.10403", "submitter": "Isaac Johnson", "authors": "Isaac Johnson, Florian Lemmerich, Diego S\\'aez-Trumper, Robert West,\n  Markus Strohmaier, and Leila Zia", "title": "Global gender differences in Wikipedia readership", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikipedia represents the largest and most popular source of encyclopedic\nknowledge in the world today, aiming to provide equal access to information\nworldwide. From a global online survey of 65,031 readers of Wikipedia and their\ncorresponding reading logs, we present novel evidence of gender differences in\nWikipedia readership and how they manifest in records of user behavior. More\nspecifically we report that (1) women are underrepresented among readers of\nWikipedia, (2) women view fewer pages per reading session than men do, (3) men\nand women visit Wikipedia for similar reasons, and (4) men and women exhibit\nspecific topical preferences. Our findings lay the foundation for identifying\npathways toward knowledge equity in the usage of online encyclopedic knowledge.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 18:40:32 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Johnson", "Isaac", ""], ["Lemmerich", "Florian", ""], ["S\u00e1ez-Trumper", "Diego", ""], ["West", "Robert", ""], ["Strohmaier", "Markus", ""], ["Zia", "Leila", ""]]}, {"id": "2007.10436", "submitter": "Aliakbar Kabiri", "authors": "Aliakbar Kabiri, Aref Darzi, Weiyi Zhou, Qianqian Sun, Lei Zhang", "title": "How different age groups responded to the COVID-19 pandemic in terms of\n  mobility behaviors: a case study of the United States", "comments": "13 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid spread of COVID-19 has affected thousands of people from different\nsocio-demographic groups all over the country. A decisive step in preventing or\nslowing the outbreak is the use of mobility interventions, such as government\nstay-at-home orders. However, different socio-demographic groups might have\ndifferent responses to these orders and regulations. In this paper, we attempt\nto fill the current gap in the literature by examining how different\ncommunities with different age groups performed social distancing by following\norders such as the national emergency declaration on March 13, as well as how\nfast they started changing their behavior after the regulations were imposed.\nFor this purpose, we calculated the behavior changes of people in different\nmobility metrics, such as percentage of people staying home during the study\nperiod (March, April, and May 2020), in different age groups in comparison to\nthe days before the pandemic (January and February 2020), by utilizing\nanonymized and privacy-protected mobile device data. Our study indicates that\nsenior communities outperformed younger communities in terms of their behavior\nchange. Senior communities not only had a faster response to the outbreak in\ncomparison to young communities, they also had better performance consistency\nduring the pandemic.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 19:49:33 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 03:44:29 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Kabiri", "Aliakbar", ""], ["Darzi", "Aref", ""], ["Zhou", "Weiyi", ""], ["Sun", "Qianqian", ""], ["Zhang", "Lei", ""]]}, {"id": "2007.10477", "submitter": "Deepti Gupta", "authors": "Deepti Gupta, Smriti Bhatt, Maanak Gupta, and Ali Saman Tosun", "title": "Future Smart Connected Communities to Fight COVID-19 Outbreak", "comments": "Accepted", "journal-ref": "Elsevier, Internet of Things, 2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) has grown rapidly in the last decade and continue to\ndevelop in terms of dimension and complexity offering wide range of devices to\nsupport diverse set of applications. With ubiquitous Internet, connected\nsensors and actuators, networking and communication technology, and artificial\nintelligence (AI), smart cyber-physical systems (CPS) provide services\nrendering assistance to humans in their daily lives. However, the recent\noutbreak of COVID-19 (also known as coronavirus) pandemic has exposed and\nhighlighted the limitations of current technological deployments to curtail\nthis disease. IoT and smart connected technologies together with data-driven\napplications can play a crucial role not only in prevention, continuous\nmonitoring, and mitigation of the disease, but also enable prompt enforcement\nof guidelines, rules and government orders to contain such future outbreaks. In\nthis paper, we envision an IoT-enabled ecosystem for intelligent monitoring,\npro-active prevention and control, and mitigation of COVID-19. We propose\ndifferent architectures, applications and technology systems for various smart\ninfrastructures including E-health, smart home, smart supply chain management,\nsmart locality, and smart city, to develop future connected communities to\nmanage and mitigate similar outbreaks. Furthermore, we present research\nchallenges together with future directions to enable and develop these smart\ncommunities and infrastructures to fight and prepare against such outbreaks.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 21:07:53 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 04:12:52 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Gupta", "Deepti", ""], ["Bhatt", "Smriti", ""], ["Gupta", "Maanak", ""], ["Tosun", "Ali Saman", ""]]}, {"id": "2007.10502", "submitter": "Gari Clifford", "authors": "Gari D. Clifford", "title": "The Future AI in Healthcare: A Tsunami of False Alarms or a Product of\n  Experts?", "comments": "46 pages, 4 figures, invited editorial to accompany keynote talk at\n  Society for Critical Care Medicine, 16 February 2020, available at:\n  https://youtu.be/Tv9ADevax8M", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent significant increases in affordable and accessible computational power\nand data storage have enabled machine learning to provide almost unbelievable\nclassification and prediction performances compared to well-trained humans.\nThere have been some promising (but limited) results in the complex healthcare\nlandscape, particularly in imaging. This promise has led some individuals to\nleap to the conclusion that we will solve an ever-increasing number of problems\nin human health and medicine by applying `artificial intelligence' to `big\n(medical) data'. The scientific literature has been inundated with algorithms,\noutstripping our ability to review them effectively. Unfortunately, I argue\nthat most, if not all of these publications or commercial algorithms make\nseveral fundamental errors. I argue that because everyone (and therefore every\nalgorithm) has blind spots, there are multiple `best' algorithms, each of which\nexcels on different types of patients or in different contexts. Consequently,\nwe should vote many algorithms together, weighted by their overall performance,\ntheir independence from each other, and a set of features that define the\ncontext (i.e., the features that maximally discriminate between the situations\nwhen one algorithm outperforms another). This approach not only provides a\nbetter performing classifier or predictor but provides confidence intervals so\nthat a clinician can judge how to respond to an alert. Moreover, I argue that a\nsufficient number of (mostly) independent algorithms that address the same\nproblem can be generated through a large international competition/challenge,\nlasting many months and define the conditions for a successful event. Finally,\nI propose introducing the requirement for major grantees to run challenges in\nthe final year of funding to maximize the value of research and select a new\ngeneration of grantees.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 21:56:36 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 03:26:46 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Clifford", "Gari D.", ""]]}, {"id": "2007.10546", "submitter": "Mayoore Jaiswal", "authors": "Shagun Sodhani, Mayoore S. Jaiswal, Lauren Baker, Koustuv Sinha, Carl\n  Shneider, Peter Henderson, Joel Lehman, Ryan Lowe", "title": "Ideas for Improving the Field of Machine Learning: Summarizing\n  Discussion from the NeurIPS 2019 Retrospectives Workshop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report documents ideas for improving the field of machine learning,\nwhich arose from discussions at the ML Retrospectives workshop at NeurIPS 2019.\nThe goal of the report is to disseminate these ideas more broadly, and in turn\nencourage continuing discussion about how the field could improve along these\naxes. We focus on topics that were most discussed at the workshop: incentives\nfor encouraging alternate forms of scholarship, re-structuring the review\nprocess, participation from academia and industry, and how we might better\ntrain computer scientists as scientists. Videos from the workshop can be\naccessed at\nhttps://slideslive.com/neurips/west-114-115-retrospectives-a-venue-for-selfreflection-in-ml-research\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 01:17:29 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Sodhani", "Shagun", ""], ["Jaiswal", "Mayoore S.", ""], ["Baker", "Lauren", ""], ["Sinha", "Koustuv", ""], ["Shneider", "Carl", ""], ["Henderson", "Peter", ""], ["Lehman", "Joel", ""], ["Lowe", "Ryan", ""]]}, {"id": "2007.10604", "submitter": "Mohd Zeeshan Ansari", "authors": "Mohd Zeeshan Ansari, Areesha Fatima Siddiqui and Mohammad Anas", "title": "Inferring Political Preferences from Twitter", "comments": "International Conference on Emerging Technologies in Data Mining and\n  Information Security IEMIS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis is the task of automatic analysis of opinions and emotions\nof users towards an entity or some aspect of that entity. Political Sentiment\nAnalysis of social media helps the political strategists to scrutinize the\nperformance of a party or candidate and improvise their weaknesses far before\nthe actual elections. During the time of elections, the social networks get\nflooded with blogs, chats, debates and discussions about the prospects of\npolitical parties and politicians. The amount of data generated is much large\nto study, analyze and draw inferences using the latest techniques. Twitter is\none of the most popular social media platforms enables us to perform\ndomain-specific data preparation. In this work, we chose to identify the\ninclination of political opinions present in Tweets by modelling it as a text\nclassification problem using classical machine learning. The tweets related to\nthe Delhi Elections in 2020 are extracted and employed for the task. Among the\nseveral algorithms, we observe that Support Vector Machines portrays the best\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 05:20:43 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Ansari", "Mohd Zeeshan", ""], ["Siddiqui", "Areesha Fatima", ""], ["Anas", "Mohammad", ""]]}, {"id": "2007.10774", "submitter": "Olga Bondarenko", "authors": "Ihor Kholoshyn, Olga Bondarenko, Olena Hanchuk, Iryna Varfolomyeyeva", "title": "Cloud technologies as a tool of creating Earth Remote Sensing\n  educational resources", "comments": "13 pages, 6 figure, 1 table", "journal-ref": "CEUR Workshop Proceedings 2643 (2020) 474-486", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is dedicated to the Earth Remote Sensing (ERS), which the\nauthors believe is a great way to teach geography and allows forming an idea of\nthe actual geographic features and phenomena. One of the major problems that\nnow constrains the active introduction of remote sensing data in the\neducational process is the low availability of training aerospace pictures,\nwhich meet didactic requirements. The article analyzes the main sources of ERS\nas a basis for educational resources formation with aerospace images: paper,\nvarious individual sources (personal stations receiving satellite information,\ndrones, balloons, kites and balls) and Internet sources (mainstream sites,\nsites of scientific-technical organizations and distributors, interactive\nInternet geoservices, cloud platforms of geospatial analysis). The authors\npoint out that their geospatial analysis platforms (Google Earth Engine, Land\nViewer, EOS Platform, etc.), due to their unique features, are the basis for\nthe creation of information thematic databases of ERS. The article presents an\nexample of such a database, covering more than 800 aerospace images and dynamic\nmodels, which are combined according to such didactic principles as high\ninformation load and clarity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 13:16:44 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Kholoshyn", "Ihor", ""], ["Bondarenko", "Olga", ""], ["Hanchuk", "Olena", ""], ["Varfolomyeyeva", "Iryna", ""]]}, {"id": "2007.10797", "submitter": "Anshu Ankolekar", "authors": "Anshu Ankolekar (1), Ben G.L. Vanneste (1), Esther Bloemen-van Gurp (2\n  and 6), Joep van Roermund (3), Adriana Berlanga (4), Cheryl Roumen (1), Evert\n  van Limbergen (1), Ludy Lutgens (1), Tom Marcelissen (3), Philippe Lambin\n  (5), Andre Dekker (1), Rianne Fijten (1) ((1) Department of Radiation\n  Oncology (MAASTRO), GROW School for Oncology, Maastricht University Medical\n  Centre+, Maastricht, The Netherlands, (2) Fontys University of Applied\n  Sciences, Eindhoven, The Netherlands, (3) Department of Urology, Maastricht\n  University Medical Centre+, Maastricht, The Netherlands, (4) Maastricht\n  University, Maastricht, The Netherlands, (5) The D-Lab, Department of\n  Precision Medicine, GROW - School for Oncology, Maastricht University Medical\n  Centre+, Maastricht University, Maastricht, The Netherlands, (6) Zuyd\n  University of Applied Sciences, Heerlen, The Netherlands)", "title": "Nine Recommendations for Decision Aid Implementation from the Clinician\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Shared decision-making (SDM) aims to empower patients to take an\nactive role in their treatment choices, supported by clinicians and patient\ndecision aids (PDAs). The purpose of this study is to explore barriers and\npossible facilitators to SDM and a PDA in the prostate cancer trajectory. In\nthe process we identify possible actions that organizations and individuals can\ntake to support implementation in practice.\n  Methods: We use the Ottawa Model of Research Use as a framework to determine\nthe barriers and facilitators to SDM and PDAs from the perspective of\nclinicians. Semi-structured interviews were conducted with urologists (n=4),\nradiation oncologists (n=3), and oncology nurses (n=2), focusing on the current\ndecision-making process experienced by these stakeholders. Questions included\ntheir attitudes towards SDM and PDAs, barriers to implementation and possible\nstrategies to overcome them.\n  Results: Time pressure and patient characteristics were cited as major\nbarriers by 55% of the clinicians we interviewed. Structural factors such as\nexternal quotas for certain treatment procedures were also considered as\nbarriers by 44% of the clinicians. Facilitating factors involved organizational\nchanges to em-bed PDAs in the treatment trajectory, training in using PDAs as a\ntool for SDM, and clinician motivation by disseminating positive clinical\noutcomes. Our findings also suggest a role for external stakeholders such as\nhealthcare insurers in creating economic incentives to facilitate\nimplementation.\n  Conclusion: Our findings highlight the importance of a multi-faceted\nimplementation strategy to support SDM. While clinician motivation and patient\nactivation are essential, structural/economic barriers may hamper\nimplementation. Action must also be taken at the administrative and policy\nlevels to foster a collaborative environment for SDM and, in the process, for\nPDAs.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 13:40:23 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Ankolekar", "Anshu", "", "2\n  and 6"], ["Vanneste", "Ben G. L.", "", "2\n  and 6"], ["Gurp", "Esther Bloemen-van", "", "2\n  and 6"], ["van Roermund", "Joep", ""], ["Berlanga", "Adriana", ""], ["Roumen", "Cheryl", ""], ["van Limbergen", "Evert", ""], ["Lutgens", "Ludy", ""], ["Marcelissen", "Tom", ""], ["Lambin", "Philippe", ""], ["Dekker", "Andre", ""], ["Fijten", "Rianne", ""]]}, {"id": "2007.10882", "submitter": "Renato Luiz de Freitas Cunha", "authors": "Renato Luiz de Freitas Cunha, Bruno Silva", "title": "Estimating crop yields with remote sensing and deep learning", "comments": "6 pages, 2 figures. Accepted for publication at 2020 Latin American\n  GRSS & ISPRS Remote Sensing Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the accuracy of crop yield estimates may allow improvements in the\nwhole crop production chain, allowing farmers to better plan for harvest, and\nfor insurers to better understand risks of production, to name a few\nadvantages. To perform their predictions, most current machine learning models\nuse NDVI data, which can be hard to use, due to the presence of clouds and\ntheir shadows in acquired images, and due to the absence of reliable crop masks\nfor large areas, especially in developing countries. In this paper, we present\na deep learning model able to perform pre-season and in-season predictions for\nfive different crops. Our model uses crop calendars, easy-to-obtain remote\nsensing data and weather forecast information to provide accurate yield\nestimates.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 15:09:11 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Cunha", "Renato Luiz de Freitas", ""], ["Silva", "Bruno", ""]]}, {"id": "2007.10970", "submitter": "Laura Prichard", "authors": "Inclusive Astronomy 2 Local Organizing Committee: Brian Brooks, Keira\n  Brooks, Lea Hagen, Nimish Hathi, Samantha Hoffman, James Paranilam, Laura\n  Prichard", "title": "Recommendations for Planning Inclusive Astronomy Conferences", "comments": "41 pages. An editable version of the document and contact information\n  available here: https://outerspace.stsci.edu/display/IA2/LOC+Recommendations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Inclusive Astronomy (IA) conference series aims to create a safe space\nwhere community members can listen to the experiences of marginalized\nindividuals in astronomy, discuss actions being taken to address inequities,\nand give recommendations to the community for how to improve diversity, equity,\nand inclusion in astronomy. The first IA was held in Nashville, TN, USA, 17-19\nJune, 2015. The Inclusive Astronomy 2 (IA2) conference was held in Baltimore,\nMD, USA, 14-15 October, 2019. The Inclusive Astronomy 2 (IA2) Local Organizing\nCommittee (LOC) has put together a comprehensive document of recommendations\nfor planning future Inclusive Astronomy conferences based on feedback received\nand lessons learned. While these are specific to the IA series, many parts will\nbe applicable to other conferences as well. Please find the recommendations and\naccompanying letter to the community here:\nhttps://outerspace.stsci.edu/display/IA2/LOC+Recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 17:38:52 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Committee", "Inclusive Astronomy 2 Local Organizing", ""], [":", "", ""], ["Brooks", "Brian", ""], ["Brooks", "Keira", ""], ["Hagen", "Lea", ""], ["Hathi", "Nimish", ""], ["Hoffman", "Samantha", ""], ["Paranilam", "James", ""], ["Prichard", "Laura", ""]]}, {"id": "2007.11070", "submitter": "EPTCS", "authors": "Pedro Figueir\\^edo (E\\\"otv\\\"os Lor\\'and University), Yuri Kim\n  (E\\\"otv\\\"os Lor\\'and University), Nghia Le Minh (E\\\"otv\\\"os Lor\\'and\n  University), Evan Sitt (E\\\"otv\\\"os Lor\\'and University), Xue Ying (E\\\"otv\\\"os\n  Lor\\'and University), Vikt\\'oria Zs\\'ok (E\\\"otv\\\"os Lor\\'and University)", "title": "How to Increase Interest in Studying Functional Programming via\n  Interdisciplinary Application", "comments": "In Proceedings TFPIE 2019 and 2020, arXiv:2008.08923", "journal-ref": "EPTCS 321, 2020, pp. 37-54", "doi": "10.4204/EPTCS.321.3", "report-no": null, "categories": "cs.CY cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional programming represents a modern tool for applying and implementing\nsoftware. The state of the art in functional programming reports an increasing\nnumber of methodologies in this paradigm. However, extensive interdisciplinary\napplications are missing. Our goal is to increase student interest in pursuing\nfurther studies in functional programming with the use of an application: the\nray tracer. We conducted a teaching experience, with positive results and\nstudent feedback, described here in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 20:08:54 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 09:19:09 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Figueir\u00eado", "Pedro", "", "E\u00f6tv\u00f6s Lor\u00e1nd University"], ["Kim", "Yuri", "", "E\u00f6tv\u00f6s Lor\u00e1nd University"], ["Minh", "Nghia Le", "", "E\u00f6tv\u00f6s Lor\u00e1nd\n  University"], ["Sitt", "Evan", "", "E\u00f6tv\u00f6s Lor\u00e1nd University"], ["Ying", "Xue", "", "E\u00f6tv\u00f6s\n  Lor\u00e1nd University"], ["Zs\u00f3k", "Vikt\u00f3ria", "", "E\u00f6tv\u00f6s Lor\u00e1nd University"]]}, {"id": "2007.11134", "submitter": "Seung Ah Choi", "authors": "Seung Ah Choi", "title": "Designing a Novel Method for Personalizing Recommendations to Decrease\n  Plastic Pollution", "comments": "9 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third world countries tend to have a higher share of plastic waste that is\ninadequately managed while the First world countries have higher plastic waste\ngeneration per person. A difference in the characteristics of plastic pollution\ndepending on the country's standing results in varying optimal recommendations\nfor users. Through Big Text and OSOME meme analysis, I constructed a list with\noptimal recommendations for First World and Third World countries. Based on the\nlist, I designed a User Interface wit Google Apps Scripts that provide\npersonalized recommendations based on the country's standing and user's\npreferred difficulty and reassessed the code based on the six qualities of\ncode. The purpose of the User Interface is to aid people who wish to help solve\nplastic pollution by offering a set of personalized tasks for each user and\nkeeping their progress accountable through a point tracking system. With a\nsignificant number of users, the application could eventually contribute to\nsolving the problem of plastic pollution.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 23:37:02 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Choi", "Seung Ah", ""]]}, {"id": "2007.11147", "submitter": "Seyedamin Pouriyeh", "authors": "Mohammad Nasajpour, Seyedamin Pouriyeh, Reza M. Parizi, Mohsen\n  Dorodchi, Maria Valero, Hamid R. Arabnia", "title": "Internet of Things for Current COVID-19 and Future Pandemics: An\n  Exploratory Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the Internet of Things (IoT) has drawn convincing research\nground as a new research topic in a wide variety of academic and industrial\ndisciplines, especially in healthcare. The IoT revolution is reshaping modern\nhealthcare systems by incorporating technological, economic, and social\nprospects. It is evolving healthcare systems from conventional to more\npersonalized healthcare systems through which patients can be diagnosed,\ntreated, and monitored more easily. The current global challenge of the\npandemic caused by the novel severe contagious respiratory syndrome coronavirus\n2 presents the greatest global public health crisis since the pandemic\ninfluenza outbreak of 1918. At the time this paper was written, the number of\ndiagnosed COVID-19 cases around the world had reached more than 31 million.\nSince the pandemic started, there has been a rapid effort in different research\ncommunities to exploit a wide variety of technologies to combat this worldwide\nthreat, and IoT technology is one of the pioneers in this area. In the context\nof COVID-19, IoT enabled /linked devices/applications are utilized to lower the\npossible spread of COVID-19 to others by early diagnosis, monitoring patients,\nand practicing defined protocols after patient recovery. This paper surveys the\nrole of IoT-based technologies in COVID-19 and reviews the state-of-the-art\narchitectures, platforms, applications, and industrial IoT-based solutions\ncombating COVID-19 in three main phases, including early diagnosis, quarantine\ntime, and after recovery.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 00:37:24 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 14:47:25 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Nasajpour", "Mohammad", ""], ["Pouriyeh", "Seyedamin", ""], ["Parizi", "Reza M.", ""], ["Dorodchi", "Mohsen", ""], ["Valero", "Maria", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "2007.11218", "submitter": "Araz Taeihagh", "authors": "Mikolaj firlej, Araz Taeihagh", "title": "Regulating human control over autonomous systems", "comments": null, "journal-ref": "Regulation and Governance (2020)", "doi": "10.1111/rego.12344", "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many sectors have experienced significant progress in\nautomation, associated with the growing advances in artificial intelligence and\nmachine learning. There are already automated robotic weapons, which are able\nto evaluate and engage with targets on their own, and there are already\nautonomous vehicles that do not need a human driver. It is argued that the use\nof increasingly autonomous systems (AS) should be guided by the policy of human\ncontrol, according to which humans should execute a certain significant level\nof judgment over AS. While in the military sector there is a fear that AS could\nmean that humans lose control over life and death decisions, in the\ntransportation domain, on the contrary, there is a strongly held view that\nautonomy could bring significant operational benefits by removing the need for\na human driver. This article explores the notion of human control in the United\nStates in the two domains of defense and transportation. The operationalization\nof emerging policies of human control results in the typology of direct and\nindirect human controls exercised over the use of AS. The typology helps to\nsteer the debate away from the linguistic complexities of the term autonomy. It\nidentifies instead where human factors are undergoing important changes and\nultimately informs about more detailed rules and standards formulation, which\ndiffer across domains, applications, and sectors.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 06:05:41 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["firlej", "Mikolaj", ""], ["Taeihagh", "Araz", ""]]}, {"id": "2007.11281", "submitter": "Alexis Comber", "authors": "Chris Brunsdon and Alexis Comber", "title": "Big Issues for Big Data: challenges for critical spatial data analytics", "comments": "0 figures. 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we consider some of the issues of working with big data and big\nspatial data and highlight the need for an open and critical framework. We\nfocus on a set of challenges underlying the collection and analysis of big\ndata. In particular, we consider 1) the issues related to inference when\nworking with usually biased big data, challenging the assumed inferential\nsuperiority of data with observations, n, approaching N, the population (n->N),\nand the need for data science analysis that answer questions of practical\nsignificance or with greater emphasis n the size of the effect, rather than the\ntruth or falsehood of a statistical statement; 2) the need to accept messiness\nin your data and to document all operations undertaken on the data because of\nthis support of openness and reproducibility paradigms; and 3) the need to\nexplicitly seek to understand the causes of bias, messiness etc in the data and\nthe inferential consequences of using such data in analyses, by adopting\ncritical approaches to spatial data science. In particular we consider the need\nto place individual data science studies in a wider social and economic\ncontexts, along the the role of inferential theory in the presence of big data,\nand issues relating to messiness and complexity in big data.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 09:11:56 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 12:56:18 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Brunsdon", "Chris", ""], ["Comber", "Alexis", ""]]}, {"id": "2007.11506", "submitter": "Joss Wright", "authors": "Joss Wright, Robert Lennox, Diogo Ver\\'issimo", "title": "Online Monitoring of Global Attitudes Towards Wildlife", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human factors are increasingly recognised as central to conservation of\nbiodiversity. Despite this, there are no existing systematic efforts to monitor\nglobal trends in perceptions of wildlife. With traditional news reporting now\nlargely online, the internet presents a powerful means to monitor global\nattitudes towards species. In this work we develop a method using the Global\nDatabase of Events, Language, and Tone (GDELT) to scan global news media,\nallowing us to identify and download conservation-related articles. Applying\nsupervised machine learning techniques, we filter irrelevant articles to create\na continually updated global dataset of news coverage for seven target taxa:\nlion, tiger, saiga, rhinoceros, pangolins, elephants, and orchids, and observe\nthat over two-thirds of articles matching a simple keyword search were\nirrelevant. We examine coverage of each taxa in different regions, and find\nthat elephants, rhinos, tigers, and lions receive the most coverage, with daily\npeaks of around 200 articles. Mean sentiment was positive for all taxa, except\nsaiga for which it was neutral. Coverage was broadly distributed, with articles\nfrom 73 countries across all continents. Elephants and tigers received coverage\nin the most countries overall, whilst orchids and saiga were mentioned in the\nsmallest number of countries. We further find that sentiment towards\ncharismatic megafauna is most positive in non-range countries, with the\nopposite being true for pangolins and orchids. Despite promising results, there\nremain substantial obstacles to achieving globally representative results.\nDisparities in internet access between low and high income countries and users\nis a major source of bias, with the need to focus on a diversity of data\nsources and languages, presenting sizable technical challenges...\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 15:59:41 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Wright", "Joss", ""], ["Lennox", "Robert", ""], ["Ver\u00edssimo", "Diogo", ""]]}, {"id": "2007.11615", "submitter": "Jeremy Auerbach", "authors": "Jeremy D. Auerbach, Eugene C. Fitzhugh, Ellen Zavisca", "title": "The impact of small changes in thoroughfare connectivity on the\n  potential for student walking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student active commuting to school is an important component to student\nachievement and student health, yet this form of physical activity has\nsignificantly declined in the U.S. Distance between the school and student\nresidence is often reported as a barrier for student walking, thereby\nincreasing street and trail connectivity between and within residential\ndevelopments and schools could foster student walking. The purpose of this\nstudy is to evaluate the potential benefits of increased thoroughfare\nconnectivity on student walking within school walking zones. This study\nconducts a cost-benefit analysis of increased thoroughfare connectivity around\nelementary and middle schools in a U.S. school system that serves sixty\nthousand students. Benefits, which include the increased time of physical\nactivity from student walking and the potential cost-savings to a school system\nif they had fewer students to bus to school, are compared to the financial\ncosts of the new connections. Advanced network optimization techniques were\napplied to several suburban and rural schools from a representative the school\nsystem to locate the optimal new thoroughfare connections that maximize student\nwalking to a school and minimize the length of the new thoroughfare. Results\nfrom this case study showed that short and inexpensive new thoroughfares could\nincrease the potential number of student active commuters and provide a\nsignificant increase of physical activity for those potential student walkers.\nThis work can foster the integration of student walking and student health in\nresidential planning decisions around schools.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 18:24:41 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Auerbach", "Jeremy D.", ""], ["Fitzhugh", "Eugene C.", ""], ["Zavisca", "Ellen", ""]]}, {"id": "2007.11663", "submitter": "Sanchari Das", "authors": "Reyhan Duezguen, Peter Mayer, Sanchari Das, Melanie Volkamer", "title": "Towards Secure and Usable Authentication for Augmented and Virtual\n  Reality Head-Mounted Displays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Immersive technologies, including augmented and virtual reality (AR & VR)\ndevices, have enhanced digital communication along with a considerable increase\nin digital threats. Thus, authentication becomes critical in AR & VR\ntechnology, particularly in shared spaces. In this paper, we propose applying\nthe ZeTA protocol that allows secure authentication even in shared spaces for\nthe AR & VR context. We explain how it can be used with the available\ninteraction methods provided by Head-Mounted Displays. In future work, our\nresearch goal is to evaluate different designs of ZeTA (e.g., interaction\nmodes) concerning their usability and users' risk perception regarding their\nsecurity - while using a cross-cultural approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 20:34:14 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 01:14:27 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Duezguen", "Reyhan", ""], ["Mayer", "Peter", ""], ["Das", "Sanchari", ""], ["Volkamer", "Melanie", ""]]}, {"id": "2007.11821", "submitter": "Elad Yom-Tov", "authors": "Elad Yom-Tov, Vasileios Lampos, Ingemar J. Cox, Michael Edelstein", "title": "Providing early indication of regional anomalies in COVID19 case counts\n  in England using search engine queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID19 was first reported in England at the end of January 2020, and by\nmid-June over 150,000 cases were reported. We assume that, similarly to\ninfluenza-like illnesses, people who suffer from COVID19 may query for their\nsymptoms prior to accessing the medical system (or in lieu of it). Therefore,\nwe analyzed searches to Bing from users in England, identifying cases where\nunexpected rises in relevant symptom searches occurred at specific areas of the\ncountry. Our analysis shows that searches for \"fever\" and \"cough\" were the most\ncorrelated with future case counts, with searches preceding case counts by\n16-17 days. Unexpected rises in search patterns were predictive of future case\ncounts multiplying by 2.5 or more within a week, reaching an Area Under Curve\n(AUC) of 0.64. Similar rises in mortality were predicted with an AUC of\napproximately 0.61 at a lead time of 3 weeks. Thus, our metric provided Public\nHealth England with an indication which could be used to plan the response to\nCOVID19 and could possibly be utilized to detect regional anomalies of other\npathogens.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 06:47:17 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Yom-Tov", "Elad", ""], ["Lampos", "Vasileios", ""], ["Cox", "Ingemar J.", ""], ["Edelstein", "Michael", ""]]}, {"id": "2007.11845", "submitter": "Hamit Basgol", "authors": "Hamit Basgol, Inci Ayhan, Emre Ugur", "title": "Time Perception: A Review on Psychological, Computational and Robotic\n  Models", "comments": "15 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals exploit time to survive in the world. Temporal information is\nrequired for higher-level cognitive abilities such as planning, decision\nmaking, communication, and effective cooperation. Since time is an inseparable\npart of cognition, there is a growing interest in the artificial intelligence\napproach to subjective time, which has a possibility of advancing the field.\nThe current survey study aims to provide researchers with an interdisciplinary\nperspective on time perception. Firstly, we introduce a brief background from\nthe psychology and neuroscience literature, covering the characteristics and\nmodels of time perception and related abilities. Secondly, we summarize the\nemergent computational and robotic models of time perception. A general\noverview to the literature reveals that a substantial amount of timing models\nare based on a dedicated time processing like the emergence of a clock-like\nmechanism from the neural network dynamics and reveal a relationship between\nthe embodiment and time perception. We also notice that most models of timing\nare developed for either sensory timing (i.e. ability to assess an interval) or\nmotor timing (i.e. ability to reproduce an interval). The number of timing\nmodels capable of retrospective timing, which is the ability to track time\nwithout paying attention, is insufficient. In this light, we discuss the\npossible research directions to promote interdisciplinary collaboration in the\nfield of time perception.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:16:47 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 23:30:12 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 08:23:33 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Basgol", "Hamit", ""], ["Ayhan", "Inci", ""], ["Ugur", "Emre", ""]]}, {"id": "2007.11932", "submitter": "Wilfried Elmenreich", "authors": "Haider Tarish Haider, Ong Hang See, W. Elmenreich", "title": "Dynamic residential load scheduling based on an adaptive consumption\n  level pricing scheme", "comments": null, "journal-ref": "Electric Power Systems Research, 133:27-35, 2016", "doi": "10.1016/j.epsr.2015.12.007", "report-no": null, "categories": "eess.SY cs.CY cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand response (DR) for smart grids, which intends to balance the required\npower demand with the available supply resources, has been gaining widespread\nattention. The growing demand for electricity has presented new opportunities\nfor residential load scheduling systems to improve energy consumption by\nshifting or curtailing the demand required with respect to price change or\nemergency cases. In this paper, a dynamic residential load scheduling system\n(DRLS) is proposed for optimal scheduling of household appliances on the basis\nof an adaptive consumption level (CL) pricing scheme (ACLPS). The proposed load\nscheduling system encourages customers to manage their energy consumption\nwithin the allowable consumption allowance (CA) of the proposed DR pricing\nscheme to achieve lower energy bills. Simulation results show that employing\nthe proposed DRLS system benefits the customers by reducing their energy bill\nand the utility companies by decreasing the peak load of the aggregated load\ndemand. For a given case study, the proposed residential load scheduling system\nbased on ACLPS allows customers to reduce their energy bills by up to 53% and\nto decrease the peak load by up to 35%.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 11:14:39 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Haider", "Haider Tarish", ""], ["See", "Ong Hang", ""], ["Elmenreich", "W.", ""]]}, {"id": "2007.11934", "submitter": "Marcel Neunhoeffer", "authors": "Marcel Neunhoeffer, Zhiwei Steven Wu, Cynthia Dwork", "title": "Private Post-GAN Boosting", "comments": null, "journal-ref": "International Conference on Learning Representations, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differentially private GANs have proven to be a promising approach for\ngenerating realistic synthetic data without compromising the privacy of\nindividuals. Due to the privacy-protective noise introduced in the training,\nthe convergence of GANs becomes even more elusive, which often leads to poor\nutility in the output generator at the end of training. We propose Private\npost-GAN boosting (Private PGB), a differentially private method that combines\nsamples produced by the sequence of generators obtained during GAN training to\ncreate a high-quality synthetic dataset. To that end, our method leverages the\nPrivate Multiplicative Weights method (Hardt and Rothblum, 2010) to reweight\ngenerated samples. We evaluate Private PGB on two dimensional toy data, MNIST\nimages, US Census data and a standard machine learning prediction task. Our\nexperiments show that Private PGB improves upon a standard private GAN approach\nacross a collection of quality measures. We also provide a non-private variant\nof PGB that improves the data quality of standard GAN training.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 11:20:14 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 16:53:34 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Neunhoeffer", "Marcel", ""], ["Wu", "Zhiwei Steven", ""], ["Dwork", "Cynthia", ""]]}, {"id": "2007.12061", "submitter": "Angus Lamb", "authors": "Zichao Wang, Angus Lamb, Evgeny Saveliev, Pashmina Cameron, Yordan\n  Zaykov, Jos\\'e Miguel Hern\\'andez-Lobato, Richard E. Turner, Richard G.\n  Baraniuk, Craig Barton, Simon Peyton Jones, Simon Woodhead, Cheng Zhang", "title": "Instructions and Guide for Diagnostic Questions: The NeurIPS 2020\n  Education Challenge", "comments": "28 pages, 6 figures, NeurIPS 2020 Competition Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital technologies are becoming increasingly prevalent in education,\nenabling personalized, high quality education resources to be accessible by\nstudents across the world. Importantly, among these resources are diagnostic\nquestions: the answers that the students give to these questions reveal key\ninformation about the specific nature of misconceptions that the students may\nhold. Analyzing the massive quantities of data stemming from students'\ninteractions with these diagnostic questions can help us more accurately\nunderstand the students' learning status and thus allow us to automate learning\ncurriculum recommendations. In this competition, participants will focus on the\nstudents' answer records to these multiple-choice diagnostic questions, with\nthe aim of 1) accurately predicting which answers the students provide; 2)\naccurately predicting which questions have high quality; and 3) determining a\npersonalized sequence of questions for each student that best predicts the\nstudent's answers. These tasks closely mimic the goals of a real-world\neducational platform and are highly representative of the educational\nchallenges faced today. We provide over 20 million examples of students'\nanswers to mathematics questions from Eedi, a leading educational platform\nwhich thousands of students interact with daily around the globe. Participants\nto this competition have a chance to make a lasting, real-world impact on the\nquality of personalized education for millions of students across the world.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:17:36 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 07:22:32 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2021 22:45:06 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Wang", "Zichao", ""], ["Lamb", "Angus", ""], ["Saveliev", "Evgeny", ""], ["Cameron", "Pashmina", ""], ["Zaykov", "Yordan", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Turner", "Richard E.", ""], ["Baraniuk", "Richard G.", ""], ["Barton", "Craig", ""], ["Jones", "Simon Peyton", ""], ["Woodhead", "Simon", ""], ["Zhang", "Cheng", ""]]}, {"id": "2007.12087", "submitter": "James Jordon", "authors": "James Jordon, Daniel Jarrett, Jinsung Yoon, Tavian Barnes, Paul\n  Elbers, Patrick Thoral, Ari Ercole, Cheng Zhang, Danielle Belgrave and\n  Mihaela van der Schaar", "title": "Hide-and-Seek Privacy Challenge", "comments": "19 pages, 5 figures. Part of the NeurIPS 2020 competition track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clinical time-series setting poses a unique combination of challenges to\ndata modeling and sharing. Due to the high dimensionality of clinical time\nseries, adequate de-identification to preserve privacy while retaining data\nutility is difficult to achieve using common de-identification techniques. An\ninnovative approach to this problem is synthetic data generation. From a\ntechnical perspective, a good generative model for time-series data should\npreserve temporal dynamics, in the sense that new sequences respect the\noriginal relationships between high-dimensional variables across time. From the\nprivacy perspective, the model should prevent patient re-identification by\nlimiting vulnerability to membership inference attacks. The NeurIPS 2020\nHide-and-Seek Privacy Challenge is a novel two-tracked competition to\nsimultaneously accelerate progress in tackling both problems. In our\nhead-to-head format, participants in the synthetic data generation track (i.e.\n\"hiders\") and the patient re-identification track (i.e. \"seekers\") are directly\npitted against each other by way of a new, high-quality intensive care\ntime-series dataset: the AmsterdamUMCdb dataset. Ultimately, we seek to advance\ngenerative techniques for dense and high-dimensional temporal data streams that\nare (1) clinically meaningful in terms of fidelity and predictivity, as well as\n(2) capable of minimizing membership privacy risks in terms of the concrete\nnotion of patient re-identification.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:50:59 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 17:10:18 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Jordon", "James", ""], ["Jarrett", "Daniel", ""], ["Yoon", "Jinsung", ""], ["Barnes", "Tavian", ""], ["Elbers", "Paul", ""], ["Thoral", "Patrick", ""], ["Ercole", "Ari", ""], ["Zhang", "Cheng", ""], ["Belgrave", "Danielle", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2007.12312", "submitter": "Ashlesha Nesarikar", "authors": "Ashlesha Nesarikar (University of Texas at Dallas and Plano\n  Intelligence), Waqas Haque (UT Southwestern), Suchith Vuppala (UT\n  Southwestern), Abhijit Nesarikar (Plano Intelligence)", "title": "COVID-19 Remote Patient Monitoring: Social Impact of AI", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary indicator of success in the fight against COVID-19 is avoiding\nstress on critical care infrastructure and services (CCIS). However, CCIS will\nlikely remain stressed until sustained herd immunity is built. There are also\nsecondary considerations for success: mitigating economic damage; curbing the\nspread of misinformation, improving morale, and preserving a sense of control;\nbuilding global trust for diplomacy, trade and travel; and restoring\nreliability and normalcy to day-to-day life, among others. We envision\ntechnology plays a pivotal role. Here, we focus on the effective use of readily\navailable technology to improve the primary and secondary success criteria for\nthe fight against SARS-CoV-2. In a multifaceted technology approach, we start\nwith effective technology use for remote patient monitoring (RPM) of COVID-19\nwith the following objectives:\n  1. Deploy readily available technology for continuous real-time remote\nmonitoring of patient vitals with the help of biosensors on a large scale.\n  2. Effective and safe remote large-scale communitywide care of low-severity\ncases as a buffer against surges in COVID-19 hospitalizations to reduce strain\non critical care services and emergency hospitals.\n  3. Improve the patient, their family, and their community's sense of control\nand morale.\n  4. Propose a clear technology and medical definition of remote patient\nmonitoring for COVID-19 to address an urgent technology need; address\nobfuscated, narrow, and erroneous information and provide examples; and urge\npublishers to be clear and complete in their disclosures.\n  5. Leverage the cloud-based distributed cognitive RPM platform for community\nleaders and decision makers to enable planning and resource management,\npandemic research, damage prevention and containment, and receiving feedback on\nstrategies and executions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 01:09:56 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Nesarikar", "Ashlesha", "", "University of Texas at Dallas and Plano\n  Intelligence"], ["Haque", "Waqas", "", "UT Southwestern"], ["Vuppala", "Suchith", "", "UT\n  Southwestern"], ["Nesarikar", "Abhijit", "", "Plano Intelligence"]]}, {"id": "2007.12353", "submitter": "Flora D. Salim", "authors": "Sam Nolan, Shakila Khan Rumi, Christoph Anderson, Klaus David, Flora\n  D. Salim", "title": "Exploring the Impact of COVID-19 Lockdown on Social Roles and Emotions\n  while Working from Home", "comments": "9 pages, Accepted at The New Future of Work Symposium, Microsoft,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the opening months of 2020, COVID-19 changed the way for which people\nwork, forcing more people to work from home. This research investigates the\nimpact of COVID-19 on five researchers' work and private roles, happiness, and\nmobile and desktop activity patterns. Desktop and smartphone application usage\nwere gathered before and during COVID-19. Individuals' roles and happiness were\ncaptured through experience sampling. Our analysis show that researchers tend\nto work more during COVID-19 resulting an imbalance of work and private roles.\nWe also found that as working styles and patterns as well as individual\nbehaviour changed, reported valence distribution was less varied in the later\nweeks of the pandemic when compared to the start. This shows a resilient\nadaptation to the disruption caused by the pandemic.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 05:17:01 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Nolan", "Sam", ""], ["Rumi", "Shakila Khan", ""], ["Anderson", "Christoph", ""], ["David", "Klaus", ""], ["Salim", "Flora D.", ""]]}, {"id": "2007.12487", "submitter": "Dipankar Chaki", "authors": "Dipankar Chaki, Athman Bouguettaya", "title": "Fine-grained Conflict Detection of IoT Services", "comments": "9 pages, 6 figures, 4 tables. This is an accepted paper and it is\n  going to appear in the Proceedings of the 2020 IEEE International Conference\n  on Services Computing (IEEE SCC 2020) affiliated with the 2020 IEEE World\n  Congress on Services (IEEE SERVICES 2020), Beijing, China. arXiv admin note:\n  text overlap with arXiv:2004.12702", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework to detect conflicts among IoT services in a\nmulti-resident smart home. A fine-grained conflict model is proposed\nconsidering the functional and non-functional properties of IoT services. The\nproposed conflict model is designed using the concept of entropy and\ninformation gain from information theory. We use a novel algorithm based on\ntemporal proximity to detect conflicts. Experimental results on real-world\ndatasets show the efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 11:15:57 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Chaki", "Dipankar", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "2007.12488", "submitter": "Ioana Manolescu", "authors": "Oana Balalau (CEDAR), Catarina Concei\\c{c}{\\~a}o (INESC-ID, IST),\n  Helena Galhardas (INESC-ID, IST), Ioana Manolescu (CEDAR), Tayeb Merabti\n  (CEDAR), Jingmao You (CEDAR, IP Paris), Youssr Youssef (CEDAR, ENSAE, IP\n  Paris)", "title": "Graph integration of structured, semistructured and unstructured data\n  for data journalism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, journalism is facilitated by the existence of large amounts of\ndigital data sources, including many Open Data ones. Such data sources are\nextremely heterogeneous, ranging from highly struc-tured (relational\ndatabases), semi-structured (JSON, XML, HTML), graphs (e.g., RDF), and text.\nJournalists (and other classes of users lacking advanced IT expertise, such as\nmost non-governmental-organizations, or small public administrations) need to\nbe able to make sense of such heterogeneous corpora, even if they lack the\nability to de ne and deploy custom extract-transform-load work ows. These are\ndi cult to set up not only for arbitrary heterogeneous inputs , but also given\nthat users may want to add (or remove) datasets to (from) the corpus. We\ndescribe a complete approach for integrating dynamic sets of heterogeneous data\nsources along the lines described above: the challenges we faced to make such\ngraphs useful, allow their integration to scale, and the solutions we proposed\nfor these problems. Our approach is implemented within the ConnectionLens\nsystem; we validate it through a set of experiments.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:55:09 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 08:07:09 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Balalau", "Oana", "", "CEDAR"], ["Concei\u00e7{\u00e3}o", "Catarina", "", "INESC-ID, IST"], ["Galhardas", "Helena", "", "INESC-ID, IST"], ["Manolescu", "Ioana", "", "CEDAR"], ["Merabti", "Tayeb", "", "CEDAR"], ["You", "Jingmao", "", "CEDAR, IP Paris"], ["Youssef", "Youssr", "", "CEDAR, ENSAE, IP\n  Paris"]]}, {"id": "2007.12580", "submitter": "Daniel Russo", "authors": "Daniel Russo, Paul H. P. Hanel, Seraphina Altnickel, Niels van Berkel", "title": "Predictors of Well-being and Productivity among Software Professionals\n  during the COVID-19 Pandemic -- A Longitudinal Study", "comments": null, "journal-ref": "Empirical Software Engineering, 2021", "doi": "10.1007/s10664-021-09945-9", "report-no": null, "categories": "cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has forced governments worldwide to impose movement\nrestrictions on their citizens. Although critical to reducing the virus'\nreproduction rate, these restrictions come with far-reaching social and\neconomic consequences. In this paper, we investigate the impact of these\nrestrictions on an individual level among software engineers who were working\nfrom home. Although software professionals are accustomed to working with\ndigital tools, but not all of them remotely, in their day-to-day work, the\nabrupt and enforced work-from-home context has resulted in an unprecedented\nscenario for the software engineering community. In a two-wave longitudinal\nstudy (N=192), we covered over 50 psychological, social, situational, and\nphysiological factors that have previously been associated with well-being or\nproductivity. Examples include anxiety, distractions, coping strategies,\npsychological and physical needs, office set-up, stress, and work motivation.\nThis design allowed us to identify the variables that explained unique variance\nin well-being and productivity. Results include (1) the quality of social\ncontacts predicted positively, and stress predicted an individual's well-being\nnegatively when controlling for other variables consistently across both waves;\n(2) boredom and distractions predicted productivity negatively; (3)\nproductivity was less strongly associated with all predictor variables at time\ntwo compared to time one, suggesting that software engineers adapted to the\nlockdown situation over time; and (4) longitudinal analyses did not provide\nevidence that any predictor variable causal explained variance in well-being\nand productivity. Overall, we conclude that working from home was per se not a\nsignificant challenge for software engineers.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 15:32:44 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 17:43:37 GMT"}, {"version": "v3", "created": "Tue, 19 Jan 2021 10:59:16 GMT"}, {"version": "v4", "created": "Sun, 24 Jan 2021 10:50:12 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Russo", "Daniel", ""], ["Hanel", "Paul H. P.", ""], ["Altnickel", "Seraphina", ""], ["van Berkel", "Niels", ""]]}, {"id": "2007.12761", "submitter": "Temiloluwa Prioleau", "authors": "Temiloluwa Prioleau, Ashutosh Sabharwal, Madhuri M. Vasudevan", "title": "Understanding Reflection Needs for Personal Health Data in Diabetes", "comments": "11 pages, 6 figures, paper to appear in Pervasive Health 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To empower users of wearable medical devices, it is important to enable\nmethods that facilitate reflection on previous care to improve future outcomes.\nIn this work, we conducted a two-phase user-study involving patients,\ncaregivers, and clinicians to understand gaps in current approaches that\nsupport reflection and user needs for new solutions. Our results show that\nusers desire to have specific summarization metrics, solutions that minimize\ncognitive effort, and solutions that enable data integration to support\nmeaningful reflection on diabetes management. In addition, we developed and\nevaluated a visualization called PixelGrid that presents key metrics in a\nmatrix-based plot. Majority of users (84%) found the matrix-based approach to\nbe useful for identifying salient patterns related to certain times and days in\nblood glucose data. Through our evaluation we identified that users desire data\nvisualization solutions with complementary textual descriptors, concise and\nflexible presentation, contextually-fitting content, and informative and\nactionable insights. Directions for future research on tools that automate\npattern discovery, detect abnormalities, and provide recommendations to improve\ncare were also identified.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 20:29:33 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Prioleau", "Temiloluwa", ""], ["Sabharwal", "Ashutosh", ""], ["Vasudevan", "Madhuri M.", ""]]}, {"id": "2007.12780", "submitter": "Prithwish Chakraborty", "authors": "Parthasarathy Suryanarayanan, Bhavani Iyer, Prithwish Chakraborty,\n  Bibo Hao, Italo Buleje, Piyush Madan, James Codella, Antonio Foncubierta,\n  Divya Pathak, Sarah Miller, Amol Rajmane, Shannon Harrer, Gigi Yuan-Reed,\n  Daby Sow", "title": "A Canonical Architecture For Predictive Analytics on Longitudinal\n  Patient Records", "comments": "Presented at DSHealth 2020 KDD Workshop on Applied Data Science for\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many institutions within the healthcare ecosystem are making significant\ninvestments in AI technologies to optimize their business operations at lower\ncost with improved patient outcomes. Despite the hype with AI, the full\nrealization of this potential is seriously hindered by several systemic\nproblems, including data privacy, security, bias, fairness, and explainability.\nIn this paper, we propose a novel canonical architecture for the development of\nAI models in healthcare that addresses these challenges. This system enables\nthe creation and management of AI predictive models throughout all the phases\nof their life cycle, including data ingestion, model building, and model\npromotion in production environments. This paper describes this architecture in\ndetail, along with a qualitative evaluation of our experience of using it on\nreal world problems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 21:51:41 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 19:46:04 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Suryanarayanan", "Parthasarathy", ""], ["Iyer", "Bhavani", ""], ["Chakraborty", "Prithwish", ""], ["Hao", "Bibo", ""], ["Buleje", "Italo", ""], ["Madan", "Piyush", ""], ["Codella", "James", ""], ["Foncubierta", "Antonio", ""], ["Pathak", "Divya", ""], ["Miller", "Sarah", ""], ["Rajmane", "Amol", ""], ["Harrer", "Shannon", ""], ["Yuan-Reed", "Gigi", ""], ["Sow", "Daby", ""]]}, {"id": "2007.12796", "submitter": "Andrew Sonta", "authors": "Andrew Sonta, Thomas R. Dougherty, Rishee K. Jain", "title": "Data-driven optimization of building layouts for energy efficiency", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.enbuild.2021.110815", "report-no": null, "categories": "cs.CE cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  One of the primary driving factors in building energy performance is occupant\nbehavioral dynamics. As a result, the layout of building occupant workstations\nis likely to influence energy consumption. In this paper, we introduce methods\nfor relating lighting zone energy to zone-level occupant dynamics, simulating\nenergy consumption of a lighting system based on this relationship, and\noptimizing the layout of buildings through the use of both a clustering-based\napproach and a genetic algorithm in order to reduce energy consumption. We find\nin a case study that nonhomogeneous behavior (i.e., high diversity) among\noccupant schedules positively correlates with the energy consumption of a\nhighly controllable lighting system. We additionally find through data-driven\nsimulation that the na\\\"ive clustering-based optimization and the genetic\nalgorithm (which makes use of the energy simulation engine) produce layouts\nthat reduce energy consumption by roughly 5% compared to the existing layout of\na real office space comprised of 165 occupants. Overall, this study\ndemonstrates the merits of utilizing low-cost dynamic design of existing\nbuilding layouts as a means to reduce energy usage. Our work provides an\nadditional path to reach our sustainable energy goals in the built environment\nthrough new non-capital-intensive interventions.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 22:58:16 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sonta", "Andrew", ""], ["Dougherty", "Thomas R.", ""], ["Jain", "Rishee K.", ""]]}, {"id": "2007.12841", "submitter": "Naeemul Hassan", "authors": "Md Mahfuzul Haque, Mohammad Yousuf, Ahmed Shatil Alam, Pratyasha Saha,\n  Syed Ishtiaque Ahmed, Naeemul Hassan", "title": "Combating Misinformation in Bangladesh: Roles and Responsibilities as\n  Perceived by Journalists, Fact-checkers, and Users", "comments": null, "journal-ref": null, "doi": "10.1145/3415201", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a growing interest within CSCW community in understanding the\ncharacteristics of misinformation propagated through computational media, and\nthe devising techniques to address the associated challenges. However, most\nwork in this area has been concentrated on the cases in the western world\nleaving a major portion of this problem unaddressed that is situated in the\nGlobal South. This paper aims to broaden the scope of this discourse by\nfocusing on this problem in the context of Bangladesh, a country in the Global\nSouth. The spread of misinformation on Facebook in Bangladesh, a country with a\npopulation over 163 million, has resulted in chaos, hate attacks, and killings.\nBy interviewing journalists, fact-checkers, in addition to surveying the\ngeneral public, we analyzed the current state of verifying misinformation in\nBangladesh. Our findings show that most people in the `news audience' want the\nnews media to verify the authenticity of online information that they see\nonline. However, the newspaper journalists say that fact-checking online\ninformation is not a part of their job, and it is also beyond their capacity\ngiven the amount of information being published online everyday. We further\nfind that the voluntary fact-checkers in Bangladesh are not equipped with\nsufficient infrastructural support to fill in this gap. We show how our\nfindings are connected to some of the core concerns of CSCW community around\nsocial media, collaboration, infrastructural politics, and information\ninequality. From our analysis, we also suggest several pathways to increase the\nimpact of fact-checking efforts through collaboration, technology design, and\ninfrastructure development.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 03:03:20 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 13:12:05 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 04:01:13 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Haque", "Md Mahfuzul", ""], ["Yousuf", "Mohammad", ""], ["Alam", "Ahmed Shatil", ""], ["Saha", "Pratyasha", ""], ["Ahmed", "Syed Ishtiaque", ""], ["Hassan", "Naeemul", ""]]}, {"id": "2007.12870", "submitter": "Georgy Kopanitsa", "authors": "Sergey V. Kovalchuk, Georgy D. Kopanitsa, Ilia V. Derevitskii, Daria\n  A. Savitskaya", "title": "Three-stage intelligent support of clinical decision making for higher\n  trust, validity, and explainability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents an approach for building consistent and applicable\nclinical decision support systems (CDSSs) using a data-driven predictive model\naimed at resolving the problem of low applicability and scalability of CDSSs in\nreal-world applications. The approach is based on a threestage application of\ndomain-specific and data-driven supportive procedures that are to be integrated\ninto clinical business processes with higher trust and explainability of the\nprediction results and recommendations. Within the considered three stages, the\nregulatory policy, data-driven modes, and interpretation procedures are\nintegrated to enable natural domain-specific interaction with decisionmakers\nwith sequential narrowing of the intelligent decision support focus. The\nproposed methodology enables a higher level of automation, scalability, and\nsemantic interpretability of CDSSs. The approach was implemented in software\nsolutions and tested within a case study in T2DM prediction, enabling us to\nimprove known clinical scales (such as FINDRISK) while keeping the\nproblem-specific reasoning interface similar to existing applications. Such\ninheritance, together with the three-staged approach, provide higher\ncompatibility of the solution and leads to trust, valid, and explainable\napplication of data-driven solutions in real-world cases.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 07:12:21 GMT"}, {"version": "v2", "created": "Sat, 6 Mar 2021 17:16:41 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Kovalchuk", "Sergey V.", ""], ["Kopanitsa", "Georgy D.", ""], ["Derevitskii", "Ilia V.", ""], ["Savitskaya", "Daria A.", ""]]}, {"id": "2007.12969", "submitter": "Ahmed Abbasi", "authors": "Ahmed Abbasi, David G. Dobolyi, Richard G. Netemeyer", "title": "Constructing a Testbed for Psychometric Natural Language Processing", "comments": "7 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychometric measures of ability, attitudes, perceptions, and beliefs are\ncrucial for understanding user behaviors in various contexts including health,\nsecurity, e-commerce, and finance. Traditionally, psychometric dimensions have\nbeen measured and collected using survey-based methods. Inferring such\nconstructs from user-generated text could afford opportunities for timely,\nunobtrusive, collection and analysis. In this paper, we describe our efforts to\nconstruct a corpus for psychometric natural language processing (NLP). We\ndiscuss our multi-step process to align user text with their survey-based\nresponse items and provide an overview of the resulting testbed which\nencompasses survey-based psychometric measures and accompanying user-generated\ntext from over 8,500 respondents. We report preliminary results on the use of\nthe text to categorize/predict users' survey response labels. We also discuss\nthe important implications of our work and resulting testbed for future\npsychometric NLP research.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 16:29:24 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Abbasi", "Ahmed", ""], ["Dobolyi", "David G.", ""], ["Netemeyer", "Richard G.", ""]]}, {"id": "2007.13127", "submitter": "Rustam Tagiew", "authors": "Rustam Tagiew", "title": "What Government by Algorithm Might Look Like", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algocracy is the rule by algorithms. This paper summarises technologies\nuseful to create algocratic social machines and presents idealistic examples of\ntheir application. In particular, it describes smart contracts and their\nimplementations, challenges of behaviour mining and prediction, as well as\ngame-theoretic and AI approaches to mechanism design. The presented idealistic\nexamples of new algocratic solutions are picked from the reality of a modern\nstate. The examples are science funding, trade by organisations, regulation of\nrental agreements, ranking of significance and sortition. Artificial General\nIntelligence is not in the scope of this feasibility study.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 13:27:05 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Tagiew", "Rustam", ""]]}, {"id": "2007.13169", "submitter": "Luca Maria Aiello", "authors": "Luca Maria Aiello, Daniele Quercia, Ke Zhou, Marios Constantinides,\n  Sanja \\v{S}\\'cepanovi\\'c, Sagar Joglekar", "title": "How Epidemic Psychology Works on Twitter: Evolution of responses to the\n  COVID-19 pandemic in the U.S", "comments": "Humanities and Social Sciences Communications. 24 pages, 7 figures, 4\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disruptions resulting from an epidemic might often appear to amount to chaos\nbut, in reality, can be understood in a systematic way through the lens of\n\"epidemic psychology\". According to Philip Strong, the founder of the\nsociological study of epidemic infectious diseases, not only is an epidemic\nbiological; there is also the potential for three psycho-social epidemics: of\nfear, moralization, and action. This work empirically tests Strong's model at\nscale by studying the use of language of 122M tweets related to the COVID-19\npandemic posted in the U.S. during the whole year of 2020. On Twitter, we\nidentified three distinct phases. Each of them is characterized by different\nregimes of the three psycho-social epidemics. In the refusal phase, users\nrefused to accept reality despite the increasing number of deaths in other\ncountries. In the anger phase (started after the announcement of the first\ndeath in the country), users' fear translated into anger about the looming\nfeeling that things were about to change. Finally, in the acceptance phase,\nwhich began after the authorities imposed physical-distancing measures, users\nsettled into a \"new normal\" for their daily activities. Overall, refusal of\naccepting reality gradually died off as the year went on, while acceptance\nincreasingly took hold. During 2020, as cases surged in waves, so did anger,\nre-emerging cyclically at each wave. Our real-time operationalization of\nStrong's model is designed in a way that makes it possible to embed epidemic\npsychology into real-time models (e.g., epidemiological and mobility models).\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 16:22:23 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 13:43:30 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 16:43:49 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Aiello", "Luca Maria", ""], ["Quercia", "Daniele", ""], ["Zhou", "Ke", ""], ["Constantinides", "Marios", ""], ["\u0160\u0107epanovi\u0107", "Sanja", ""], ["Joglekar", "Sagar", ""]]}, {"id": "2007.13182", "submitter": "Molla Rashied Hussein", "authors": "Molla Rashied Hussein, Abdullah Bin Shams, Ehsanul Hoque Apu,\n  Khondaker Abdullah Al Mamun and Mohammad Shahriar Rahman", "title": "Digital Surveillance Systems for Tracing COVID-19: Privacy and Security\n  Challenges with Recommendations", "comments": "Submitted to ICAICT 2020 (2nd International Conference on Advanced\n  Information and Communication Technology) on June 30, 2020 and is under\n  review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coronavirus disease 2019, i.e. COVID-19 has imposed the public health measure\nof keeping social distancing for preventing mass transmission of COVID-19. For\nmonitoring the social distancing and keeping the trace of transmission, we are\nobligated to develop various types of digital surveillance systems, which\ninclude contact tracing systems and drone-based monitoring systems. Due to the\ninconvenience of manual labor, traditional contact tracing systems are\ngradually replaced by the efficient automated contact tracing applications that\nare developed for smartphones. However, the commencement of automated contact\ntracing applications introduces the inevitable privacy and security challenges.\nNevertheless, unawareness and/or lack of smartphone usage among mass people\nlead to drone-based monitoring systems. These systems also invite unwelcomed\nprivacy and security challenges. This paper discusses the recently designed and\ndeveloped digital surveillance system applications with their protocols\ndeployed in several countries around the world. Their privacy and security\nchallenges are discussed as well as analyzed from the viewpoint of privacy\nacts. Several recommendations are suggested separately for automated contact\ntracing systems and drone-based monitoring systems, which could further be\nexplored and implemented afterwards to prevent any possible privacy violation\nand protect an unsuspecting person from any potential cyber attack.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 17:09:58 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Hussein", "Molla Rashied", ""], ["Shams", "Abdullah Bin", ""], ["Apu", "Ehsanul Hoque", ""], ["Mamun", "Khondaker Abdullah Al", ""], ["Rahman", "Mohammad Shahriar", ""]]}, {"id": "2007.13188", "submitter": "Sanchari Das", "authors": "Swapna Joshi, Kostas Stavrianakis, Sanchari Das", "title": "Substituting Restorative Benefits of Being Outdoors through Interactive\n  Augmented Spatial Soundscapes", "comments": null, "journal-ref": "ASSET '20: The 22nd International ACM SIGACCESS Conference on\n  Computers and Accessibility, October 26--28, 2020, Athens, Greece (Virtual\n  Conference: Poster)", "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geriatric depression is a common mental health condition affecting majority\nof older adults in the US. As per Attention Restoration Theory (ART),\nparticipation in outdoor activities is known to reduce depression and provide\nrestorative benefits. However, many older adults, who suffer from depression,\nespecially those who receive care in organizational settings, have less access\nto sensory experiences of the outdoor natural environment. This is often due to\ntheir physical or cognitive limitations and from lack of organizational\nresources to support outdoor activities. To address this, we plan to study how\ntechnology can bring the restorative benefits of outdoors to the indoor\nenvironments through augmented spatial natural soundscapes. Thus, we propose an\ninterview and observation-based study at an assisted living facility to\nevaluate how augmented soundscapes substitute for outdoor restorative, social,\nand experiential benefits. We aim to integrate these findings into a minimally\nintrusive and intuitive design of an interactive augmented soundscape, for\nindoor organizational care settings.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 18:00:04 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 20:28:10 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Joshi", "Swapna", ""], ["Stavrianakis", "Kostas", ""], ["Das", "Sanchari", ""]]}, {"id": "2007.13261", "submitter": "Christopher Baker", "authors": "Christopher M. Baker, Patricia T. Campbell, Iadine Chades, Angela J.\n  Dean, Susan M. Hester, Matthew H. Holden, James M. McCaw, Jodie McVernon,\n  Robert Moss, Freya M. Shearer and Hugh P. Possingham", "title": "From climate change to pandemics: decision science can help scientists\n  have impact", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Scientific knowledge and advances are a cornerstone of modern society. They\nimprove our understanding of the world we live in and help us navigate global\nchallenges including emerging infectious diseases, climate change and the\nbiodiversity crisis. For any scientist, whether they work primarily in\nfundamental knowledge generation or in the applied sciences, it is important to\nunderstand how science fits into a decision-making framework. Decision science\nis a field that aims to pinpoint evidence-based management strategies. It\nprovides a framework for scientists to directly impact decisions or to\nunderstand how their work will fit into a decision process. Decision science is\nmore than undertaking targeted and relevant scientific research or providing\ntools to assist policy makers; it is an approach to problem formulation,\nbringing together mathematical modelling, stakeholder values and logistical\nconstraints to support decision making. In this paper we describe decision\nscience, its use in different contexts, and highlight current gaps in\nmethodology and application. The COVID-19 pandemic has thrust mathematical\nmodels into the public spotlight, but it is one of innumerable examples in\nwhich modelling informs decision making. Other examples include models of storm\nsystems (eg. cyclones, hurricanes) and climate change. Although the decision\ntimescale in these examples differs enormously (from hours to decades), the\nunderlying decision science approach is common across all problems. Bridging\ncommunication gaps between different groups is one of the greatest challenges\nfor scientists. However, by better understanding and engaging with the\ndecision-making processes, scientists will have greater impact and make\nstronger contributions to important societal problems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 00:51:31 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Baker", "Christopher M.", ""], ["Campbell", "Patricia T.", ""], ["Chades", "Iadine", ""], ["Dean", "Angela J.", ""], ["Hester", "Susan M.", ""], ["Holden", "Matthew H.", ""], ["McCaw", "James M.", ""], ["McVernon", "Jodie", ""], ["Moss", "Robert", ""], ["Shearer", "Freya M.", ""], ["Possingham", "Hugh P.", ""]]}, {"id": "2007.13281", "submitter": "Ke Wang", "authors": "Ke Wang, Gang Li, Junlan Chen, Yan Long, Tao Chen, Long Chen and Qin\n  Xia", "title": "The Adaptability and Challenges of Autonomous Vehicles to Pedestrians in\n  Urban China", "comments": "24 pages, 9 figures", "journal-ref": "Accident Analysis and Prevention. 145(2020), 105692", "doi": "10.1016/j.aap.2020.105692", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  China is the world's largest automotive market and is ambitious for\nautonomous vehicles (AVs) development. As one of the key goals of AVs,\npedestrian safety is an important issue in China. Despite the rapid development\nof driverless technologies in recent years, there is a lack of researches on\nthe adaptability of AVs to pedestrians. To fill the gap, this study would\ndiscuss the adaptability of current driverless technologies to China urban\npedestrians by reviewing the latest researches. The paper firstly analyzed\ntypical Chinese pedestrian behaviors and summarized the safety demands of\npedestrians for AVs through articles and open database data, which are worked\nas the evaluation criteria. Then, corresponding driverless technologies are\ncarefully reviewed. Finally, the adaptability would be given combining the\nabove analyses. Our review found that autonomous vehicles have trouble in the\noccluded pedestrian environment and Chinese pedestrians do not accept AVs well.\nAnd more explorations should be conducted on standard human-machine\ninteraction, interaction information overload avoidance, occluded pedestrians\ndetection and nation-based receptivity research. The conclusions are very\nuseful for motor corporations and driverless car researchers to place more\nattention on the complexity of the Chinese pedestrian environment, for\ntransportation experts to protect pedestrian safety in the context of AVs, and\nfor governors to think about making new pedestrians policies to welcome the\nupcoming driverless cars.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 02:40:18 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Wang", "Ke", ""], ["Li", "Gang", ""], ["Chen", "Junlan", ""], ["Long", "Yan", ""], ["Chen", "Tao", ""], ["Chen", "Long", ""], ["Xia", "Qin", ""]]}, {"id": "2007.13305", "submitter": "Md. Shirajum Munir", "authors": "Anupam Kumar Bairagi, Mehedi Masud, Do Hyeon Kim, Md. Shirajum Munir,\n  Abdullah Al Nahid, Sarder Fakhrul Abedin, Kazi Masudul Alam, Sujit Biswas,\n  Sultan S Alshamrani, Zhu Han, and Choong Seon Hong", "title": "Controlling the Outbreak of COVID-19: A Noncooperative Game Perspective", "comments": "Accepted article by IEEE Access. DOI: 10.1109/ACCESS.2020.3040821", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3040821", "report-no": null, "categories": "cs.CY cs.CE cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 is a global epidemic. Till now, there is no remedy for this\nepidemic. However, isolation and social distancing are seemed to be effective\npreventive measures to control this pandemic. Therefore, in this paper, an\noptimization problem is formulated that accommodates both isolation and social\ndistancing features of the individuals. To promote social distancing, we solve\nthe formulated problem by applying a noncooperative game that can provide an\nincentive for maintaining social distancing to prevent the spread of COVID-19.\nFurthermore, the sustainability of the lockdown policy is interpreted with the\nhelp of our proposed game-theoretic incentive model for maintaining social\ndistancing where there exists a Nash equilibrium. Finally, we perform an\nextensive numerical analysis that shows the effectiveness of the proposed\napproach in terms of achieving the desired social-distancing to prevent the\noutbreak of the COVID-19 in a noncooperative environment. Numerical results\nshow that the individual incentive increases more than 85% with an increasing\npercentage of home isolation from 25% to 100% for all considered scenarios. The\nnumerical results also demonstrate that in a particular percentage of home\nisolation, the individual incentive decreases with an increasing number of\nindividuals.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 04:28:32 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 08:29:02 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Bairagi", "Anupam Kumar", ""], ["Masud", "Mehedi", ""], ["Kim", "Do Hyeon", ""], ["Munir", "Md. Shirajum", ""], ["Nahid", "Abdullah Al", ""], ["Abedin", "Sarder Fakhrul", ""], ["Alam", "Kazi Masudul", ""], ["Biswas", "Sujit", ""], ["Alshamrani", "Sultan S", ""], ["Han", "Zhu", ""], ["Hong", "Choong Seon", ""]]}, {"id": "2007.13306", "submitter": "Serena Kim", "authors": "Serena Y. Kim, Koushik Ganesan, Princess Dickens, and Soumya Panda", "title": "Public Sentiment Toward Solar Energy: Opinion Mining of Twitter Using a\n  Transformer-Based Language Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public acceptance and support for renewable energy are important determinants\nof renewable energy policies and market conditions. This paper examines public\nsentiment toward solar energy in the United States using data from Twitter, a\nmicro-blogging platform in which people post messages, known as tweets. We\nfiltered tweets specific to solar energy and performed a classification task\nusing Robustly optimized Bidirectional Encoder Representations from\nTransformers (RoBERTa). Analyzing 71,262 tweets during the period of late\nJanuary to early July 2020, we find public sentiment varies significantly\nacross states. Within the study period, the Northeastern U.S. region shows more\npositive sentiment toward solar energy than did the Southern U.S. region. Solar\nradiation does not correlate to variation in solar sentiment across states. We\nalso find that public sentiment toward solar correlates to renewable energy\npolicy and market conditions, specifically, Renewable Portfolio Standards (RPS)\ntargets, customer-friendly net metering policies, and a mature solar market.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 04:31:18 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kim", "Serena Y.", ""], ["Ganesan", "Koushik", ""], ["Dickens", "Princess", ""], ["Panda", "Soumya", ""]]}, {"id": "2007.13346", "submitter": "Murdoch Gabbay", "authors": "Devraj Basu and Murdoch Gabbay", "title": "Karl Marx and the Blockchain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is often presented as a technological development; however,\nclearly it is not only that: the `Blockchain buzz' exists in the context of\ncurrent social and political developments. In this essay, we analyse blockchain\ntechnology and its social and political context from a perspective of Marxist\neconomic theory.\n  Since arguably the last great inflection point in society and technology was\nanalysed by Marx in terms of labour and capital and since we seem to be\nexperiencing a shift in the balance between these forces today, it makes sense\nto revisit the Marxist ideas and apply them to the current situation, to see\nhow well they still apply and if necessary to update them for current events.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 08:03:40 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 13:16:07 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 13:28:27 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Basu", "Devraj", ""], ["Gabbay", "Murdoch", ""]]}, {"id": "2007.13372", "submitter": "Dinislam Abdulgalimov", "authors": "Dinislam Abdulgalimov, Timur Osadchiy", "title": "Our House is Our Glassy Castle: Challenges of Pervasive Computing in\n  Private Spaces", "comments": "5 pages, CHI 2017 conference, \"Making Home: Asserting Agency in the\n  Age of IoT\" workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Modern society is going through the transformation under the influence of\nInformation Technologies. Internet of Things as one of the latest facet of it\nbecoming more visible and widely spread. We wish to reflect and discuss the\ncurrent concerns regarding its expansion. Our particular interests lie in the\nincreasing of usability and comfortability through the unification of the IoT\nprotocols and security measures. As well as addressing the privacy concerns and\ndiscussing the possible changings in the perception of privacy and personal\nspace concepts.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 08:42:48 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Abdulgalimov", "Dinislam", ""], ["Osadchiy", "Timur", ""]]}, {"id": "2007.13410", "submitter": "Sean McKeown", "authors": "Christopher Kelly, Nikolaos Pitropakis, Sean McKeown, Costas\n  Lambrinoudakis", "title": "Testing And Hardening IoT Devices Against the Mirai Botnet", "comments": "8 pages, conference paper", "journal-ref": null, "doi": "10.1109/CyberSecurity49315.2020.9138887", "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large majority of cheap Internet of Things (IoT) devices that arrive brand\nnew, and are configured with out-of-the-box settings, are not being properly\nsecured by the manufactures, and are vulnerable to existing malware lurking on\nthe Internet. Among them is the Mirai botnet which has had its source code\nleaked to the world, allowing any malicious actor to configure and unleash it.\nA combination of software assets not being utilised safely and effectively are\nexposing consumers to a full compromise. We configured and attacked 4 different\nIoT devices using the Mirai libraries. Our experiments concluded that three out\nof the four devices were vulnerable to the Mirai malware and became infected\nwhen deployed using their default configuration. This demonstrates that the\noriginal security configurations are not sufficient to provide acceptable\nlevels of protection for consumers, leaving their devices exposed and\nvulnerable. By analysing the Mirai libraries and its attack vectors, we were\nable to determine appropriate device configuration countermeasures to harden\nthe devices against this botnet, which were successfully validated through\nexperimentation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 10:15:37 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Kelly", "Christopher", ""], ["Pitropakis", "Nikolaos", ""], ["McKeown", "Sean", ""], ["Lambrinoudakis", "Costas", ""]]}, {"id": "2007.13525", "submitter": "Lelin Zhang", "authors": "Lelin Zhang (1), Xi Nan (2), Eva Huang (2), Sidong Liu (3) ((1)\n  University of Technology Sydney, (2) The University of Sydney Business\n  School, (3) Macquarie University)", "title": "Detecting Transaction-based Tax Evasion Activities on Social Media\n  Platforms Using Multi-modal Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms now serve billions of users by providing convenient\nmeans of communication, content sharing and even payment between different\nusers. Due to such convenient and anarchic nature, they have also been used\nrampantly to promote and conduct business activities between unregistered\nmarket participants without paying taxes. Tax authorities worldwide face\ndifficulties in regulating these hidden economy activities by traditional\nregulatory means. This paper presents a machine learning based Regtech tool for\ninternational tax authorities to detect transaction-based tax evasion\nactivities on social media platforms. To build such a tool, we collected a\ndataset of 58,660 Instagram posts and manually labelled 2,081 sampled posts\nwith multiple properties related to transaction-based tax evasion activities.\nBased on the dataset, we developed a multi-modal deep neural network to\nautomatically detect suspicious posts. The proposed model combines comments,\nhashtags and image modalities to produce the final output. As shown by our\nexperiments, the combined model achieved an AUC of 0.808 and F1 score of 0.762,\noutperforming any single modality models. This tool could help tax authorities\nto identify audit targets in an efficient and effective manner, and combat\nsocial e-commerce tax evasion in scale.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 13:05:39 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zhang", "Lelin", ""], ["Nan", "Xi", ""], ["Huang", "Eva", ""], ["Liu", "Sidong", ""]]}, {"id": "2007.13633", "submitter": "Molla Rashied Hussein", "authors": "Molla Rashied Hussein, Ehsanul Hoque Apu, Shahriar Shahabuddin,\n  Abdullah Bin Shams and Russell Kabir", "title": "Overview of digital health surveillance system during COVID-19 pandemic:\n  public health issues and misapprehensions", "comments": "Submitted to the Elsevier Journal of Health Policy and Technology on\n  June 16,2020 and is under review (last update: July 15, 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Without proper medication and vaccination for the COVID-19, many governments\nare using automated digital healthcare surveillance system to prevent and\ncontrol the spread. There is not enough literature explaining the concerns and\nprivacy issues; hence, we have briefly explained the topics in this paper. We\nfocused on digital healthcare surveillance system's privacy concerns and\ndifferent segments. Further research studies should be conducted in different\nsectors. This paper provides an overview based on the published articles, which\nare not focusing on the privacy issues that much. Artificial intelligence and\n5G networks combine the advanced digital healthcare surveillance system;\nwhereas Bluetooth-based contact tracing systems have fewer privacy concerns.\nMore studies are required to find the appropriate digital healthcare\nsurveillance system, which would be ideal for monitoring, controlling, and\npredicting the COVID-19 trajectory.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 15:18:31 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Hussein", "Molla Rashied", ""], ["Apu", "Ehsanul Hoque", ""], ["Shahabuddin", "Shahriar", ""], ["Shams", "Abdullah Bin", ""], ["Kabir", "Russell", ""]]}, {"id": "2007.13705", "submitter": "Cm Pintea", "authors": "Anca Avram, Oliviu Matei, Camelia Pintea, Carmen Anton", "title": "Innovative Platform for Designing Hybrid Collaborative & Context-Aware\n  Data Mining Scenarios", "comments": "15 figures", "journal-ref": "Mathematics 8(5):1-19, 684 (2020) (ISSN 2227-7390)", "doi": "10.3390/math8050684", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of knowledge discovery involves nowadays a major number of\ntechniques. Context-Aware Data Mining (CADM) and Collaborative Data Mining\n(CDM) are some of the recent ones. the current research proposes a new hybrid\nand efficient tool to design prediction models called Scenarios\nPlatform-Collaborative & Context-Aware Data Mining (SP-CCADM). Both CADM and\nCDM approaches are included in the new platform in a flexible manner; SP-CCADM\nallows the setting and testing of multiple configurable scenarios related to\ndata mining at once. The introduced platform was successfully tested and\nvalidated on real life scenarios, providing better results than each standalone\ntechnique-CADM and CDM. Nevertheless, SP-CCADM was validated with various\nmachine learning algorithms-k-Nearest Neighbour (k-NN), Deep Learning (DL),\nGradient Boosted Trees (GBT) and Decision Trees (DT). SP-CCADM makes a step\nforward when confronting complex data, properly approaching data contexts and\ncollaboration between data. Numerical experiments and statistics illustrate in\ndetail the potential of the proposed platform.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 17:36:02 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Avram", "Anca", ""], ["Matei", "Oliviu", ""], ["Pintea", "Camelia", ""], ["Anton", "Carmen", ""]]}, {"id": "2007.13714", "submitter": "Bharat Bohara", "authors": "Bharat Bohara, Sunil Maharjan, Bibek Raj Shrestha", "title": "IoT Based Smart Home using Blynk Framework", "comments": "5 pages, 6 figures, presented in 13th National Technological\n  Festival, Locus-2016, Tribhuvan University, Nepal", "journal-ref": "ZERONE SCHOLAR, VOL. 1, (2016) 26-30", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The project discussed in this paper is targeted at solving sundry problems\nfaced by Nepalese people in their daily life. It is designed to control and\nmonitor appliances via smartphone using Wi-Fi as communication protocol and\nraspberry pi as private server. All the appliances and sensors are connected to\nthe internet via NodeMcu microcontroller, which serves as the gateway to the\ninternet. Even if the user goes offline, the system is designed to switch to\nautomated state controlling the appliances automatically as per the sensors\nreadings. Also, the data are logged on to the server for future data mining.\nThe core system of this project is adopted from the Blynk framework.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 17:46:39 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Bohara", "Bharat", ""], ["Maharjan", "Sunil", ""], ["Shrestha", "Bibek Raj", ""]]}, {"id": "2007.13833", "submitter": "Stefan Dreisiebner", "authors": "Stefan Dreisiebner, Sophie M\\\"arz, Thomas Mandl", "title": "Information Behavior During the Covid-19 Crisis in German-Speaking\n  Countries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the impact of the Covid-19 crisis at the level of\nindividual information behavior, based on an online survey among 308\nparticipants from the German-speaking countries Austria, Germany and\nSwitzerland in April and May 2020. The results show first that the Covid-19\ncrisis has led to an increased demand for reliable information. This goes\nalongside a significant increased use of public broadcasting, newspapers and\ninformation provided by public organizations. Second, the majority (84%) of the\nparticipants reported being satisfied with the information supply during the\nCovid-19 crisis. Participants who were less satisfied with the information\nsupply during the Covid-19 crisis used reliable sources significantly less\nfrequently, specifically public television, national newspapers and information\nprovided by public organizations. Third, the amount of Covid-19-related\ninformation during the peak of the crisis led some participants to a feeling of\ninformation overload, which resulted in a reduction of information seeking and\nmedia use.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 19:52:45 GMT"}, {"version": "v2", "created": "Mon, 2 Nov 2020 15:28:48 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Dreisiebner", "Stefan", ""], ["M\u00e4rz", "Sophie", ""], ["Mandl", "Thomas", ""]]}, {"id": "2007.13850", "submitter": "Pankaj Khatiwada", "authors": "Pankaj Khatiwada, Hari Bhusal, Ayan Chatterjee, Martin W. Gerdess", "title": "A Proposed Access Control-Based Privacy Preservation Model to Share\n  Healthcare Data in Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare data in cloud computing facilitates the treatment of patients\nefficiently by sharing information about personal health data between the\nhealthcare providers for medical consultation. Furthermore, retaining the\nconfidentiality of data and patients' identity is a another challenging task.\nThis paper presents the concept of an access control-based (AC) privacy\npreservation model for the mutual authentication of users and data owners in\nthe proposed digital system. The proposed model offers a high-security\nguarantee and high efficiency. The proposed digital system consists of four\ndifferent entities, user, data owner, cloud server, and key generation center\n(KGC). This approach makes the system more robust and highly secure, which has\nbeen verified with multiple scenarios. Besides, the proposed model consisted of\nthe setup phase, key generation phase, encryption phase, validation phase,\naccess control phase, and data sharing phase. The setup phases are run by the\ndata owner, which takes input as a security parameter and generates the system\nmaster key and security parameter. Then, in the key generation phase, the\nprivate key is generated by KGC and is stored in the cloud server. After that,\nthe generated private key is encrypted. Then, the session key is generated by\nKGC and granted to the user and cloud server for storing, and then, the results\nare verified in the validation phase using validation messages. Finally, the\ndata is shared with the user and decrypted at the user-end. The proposed model\noutperforms other methods with a maximal genuine data rate of 0.91.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 20:32:51 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Khatiwada", "Pankaj", ""], ["Bhusal", "Hari", ""], ["Chatterjee", "Ayan", ""], ["Gerdess", "Martin W.", ""]]}, {"id": "2007.13902", "submitter": "Kirk Bansak", "authors": "Jeremy Ferwerda, Nicholas Adams-Cohen, Kirk Bansak, Jennifer Fei,\n  Duncan Lawrence, Jeremy M. Weinstein, Jens Hainmueller", "title": "Leveraging the Power of Place: A Data-Driven Decision Helper to Improve\n  the Location Decisions of Economic Immigrants", "comments": "51 pages (including appendix), 13 figures. Immigration Policy Lab\n  (IPL) Working Paper Series, Working Paper No. 20-06", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG econ.GN q-fin.EC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of countries have established programs to attract immigrants\nwho can contribute to their economy. Research suggests that an immigrant's\ninitial arrival location plays a key role in shaping their economic success.\nYet immigrants currently lack access to personalized information that would\nhelp them identify optimal destinations. Instead, they often rely on\navailability heuristics, which can lead to the selection of sub-optimal landing\nlocations, lower earnings, elevated outmigration rates, and concentration in\nthe most well-known locations. To address this issue and counteract the effects\nof cognitive biases and limited information, we propose a data-driven decision\nhelper that draws on behavioral insights, administrative data, and machine\nlearning methods to inform immigrants' location decisions. The decision helper\nprovides personalized location recommendations that reflect immigrants'\npreferences as well as data-driven predictions of the locations where they\nmaximize their expected earnings given their profile. We illustrate the\npotential impact of our approach using backtests conducted with administrative\ndata that links landing data of recent economic immigrants from Canada's\nExpress Entry system with their earnings retrieved from tax records.\nSimulations across various scenarios suggest that providing location\nrecommendations to incoming economic immigrants can increase their initial\nearnings and lead to a mild shift away from the most populous landing\ndestinations. Our approach can be implemented within existing institutional\nstructures at minimal cost, and offers governments an opportunity to harness\ntheir administrative data to improve outcomes for economic immigrants.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 23:02:11 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Ferwerda", "Jeremy", ""], ["Adams-Cohen", "Nicholas", ""], ["Bansak", "Kirk", ""], ["Fei", "Jennifer", ""], ["Lawrence", "Duncan", ""], ["Weinstein", "Jeremy M.", ""], ["Hainmueller", "Jens", ""]]}, {"id": "2007.14013", "submitter": "Taichi Murayama", "authors": "Taichi Murayama, Shoko Wakamiya and Eiji Aramaki", "title": "Fake News Detection using Temporal Features Extracted via Point Process", "comments": "CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020", "journal-ref": null, "doi": "10.36190/2020.13", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many people use social networking services (SNSs) to easily access various\nnews. There are numerous ways to obtain and share ``fake news,'' which are news\ncarrying false information. To address fake news, several studies have been\nconducted for detecting fake news by using SNS-extracted features. In this\nstudy, we attempt to use temporal features generated from SNS posts by using a\npoint process algorithm to identify fake news from real news. Temporal features\nin fake news detection have the advantage of robustness over existing features\nbecause it has minimal dependence on fake news propagators. Further, we propose\na novel multi-modal attention-based method, which includes linguistic and user\nfeatures alongside temporal features, for detecting fake news from SNS posts.\nResults obtained from three public datasets indicate that the proposed model\nachieves better performance compared to existing methods and demonstrate the\neffectiveness of temporal features for fake news detection.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 06:34:54 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Murayama", "Taichi", ""], ["Wakamiya", "Shoko", ""], ["Aramaki", "Eiji", ""]]}, {"id": "2007.14059", "submitter": "Taichi Murayama", "authors": "Taichi Murayama, Shoko Wakamiya, Eiji Aramaki and Ryota Kobayashi", "title": "Modeling the spread of fake news on Twitter", "comments": "Published at PLOS ONE in 2021", "journal-ref": "Plos one 16.4: e0250419 (2021)", "doi": "10.1371/journal.pone.0250419", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news can have a significant negative impact on society because of the\ngrowing use of mobile devices and the worldwide increase in Internet access. It\nis therefore essential to develop a simple mathematical model to understand the\nonline dissemination of fake news. In this study, we propose a point process\nmodel of the spread of fake news on Twitter. The proposed model describes the\nspread of a fake news item as a two-stage process: initially, fake news spreads\nas a piece of ordinary news; then, when most users start recognizing the\nfalsity of the news item, that itself spreads as another news story. We\nvalidate this model using two datasets of fake news items spread on Twitter. We\nshow that the proposed model is superior to the current state-of-the-art\nmethods in accurately predicting the evolution of the spread of a fake news\nitem. Moreover, a text analysis suggests that our model appropriately infers\nthe correction time, i.e., the moment when Twitter users start realizing the\nfalsity of the news item. The proposed model contributes to understanding the\ndynamics of the spread of fake news on social media. Its ability to extract a\ncompact representation of the spreading pattern could be useful in the\ndetection and mitigation of fake news.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 08:28:16 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 05:15:52 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Murayama", "Taichi", ""], ["Wakamiya", "Shoko", ""], ["Aramaki", "Eiji", ""], ["Kobayashi", "Ryota", ""]]}, {"id": "2007.14065", "submitter": "Essam Rashed", "authors": "Sachiko Kodera, Essam A. Rashed, Akimasa Hirata", "title": "Correlation between COVID-19 morbidity and mortality rates in Japan and\n  local population density, temperature and absolute humidity", "comments": "International Journal of Environmental Research and Public Health,\n  2020", "journal-ref": null, "doi": "10.3390/ijerph17155477", "report-no": null, "categories": "q-bio.PE cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study analyzed the morbidity and mortality rates of the COVID-19\npandemic in different prefectures of Japan. Under the constraint that daily\nmaximum confirmed deaths and daily maximum cases should exceed 4 and 10,\nrespectively, 14 prefectures were included, and cofactors affecting the\nmorbidity and mortality rates were evaluated. In particular, the number of\nconfirmed deaths was assessed excluding the cases of nosocomial infections and\nnursing home patients. A mild correlation was observed between morbidity rate\nand population density (R2=0.394). In addition, the percentage of the elderly\nper population was also found to be non-negligible. Among weather parameters,\nthe maximum temperature and absolute humidity averaged over the duration were\nfound to be in modest correlation with the morbidity and mortality rates,\nexcluding the cases of nosocomial infections. The lower morbidity and mortality\nare observed for higher temperature and absolute humidity. Multivariate\nanalysis considering these factors showed that determination coefficients for\nthe spread, decay, and combined stages were 0.708, 0.785, and 0.615,\nrespectively. These findings could be useful for intervention planning during\nfuture pandemics, including a potential second COVID-19 outbreak.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 08:41:43 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 01:27:32 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kodera", "Sachiko", ""], ["Rashed", "Essam A.", ""], ["Hirata", "Akimasa", ""]]}, {"id": "2007.14083", "submitter": "Taichi Murayama", "authors": "Taichi Murayama and Shoko Wakamiya and Eiji Aramaki", "title": "Universal Fake News Collection System using Debunking Tweets", "comments": "5pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large numbers of people use Social Networking Services (SNS) for easy access\nto various news, but they have more opportunities to obtain and share ``fake\nnews'' carrying false information. Partially to combat fake news, several\nfact-checking sites such as Snopes and PolitiFact have been founded.\nNevertheless, these sites rely on time-consuming and labor-intensive tasks.\nMoreover, their available languages are not extensive. To address these\ndifficulties, we propose a new fake news collection system based on rule-based\n(unsupervised) frameworks that can be extended easily for various languages.\nThe system collects news with high probability of being fake by debunking\ntweets by users and presents event clusters gathering higher attention. Our\nsystem currently functions in two languages: English and Japanese. It shows\nevent clusters, 65\\% of which are actually fake. In future studies, it will be\napplied to other languages and will be published with a large fake news\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 09:32:41 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Murayama", "Taichi", ""], ["Wakamiya", "Shoko", ""], ["Aramaki", "Eiji", ""]]}, {"id": "2007.14181", "submitter": "Kevin Wallis", "authors": "Kevin Wallis, Jan Stodt, Eugen Jastremskoj and Christoph Reich", "title": "Agreements between Enterprises digitized by Smart Contracts in the\n  Domain of Industry 4.0", "comments": "CCSEA, BIoT, DKMP, CLOUD, NLCAI, SIPRO - 2020 pp. 23-32, 2020. CS &\n  IT - CSCP 2020", "journal-ref": null, "doi": "10.5121/csit.2020.101003", "report-no": null, "categories": "cs.CR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The digital transformation of companies is expected to increase the digital\ninterconnection between different companies to develop optimized, customized,\nhybrid business models. These cross-company business models require secure,\nreliable, and traceable logging and monitoring of contractually agreed\ninformation sharing between machine tools, operators, and service providers.\nThis paper discusses how the major requirements for building hybrid business\nmodels can be tackled by the blockchain for building a chain of trust and smart\ncontracts for digitized contracts. A machine maintenance use case is used to\ndiscuss the readiness of smart contracts for the automation of workflows\ndefined in contracts. Furthermore, it is shown that the number of failures is\nsignificantly improved by using these contracts and a blockchain.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:08:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Wallis", "Kevin", ""], ["Stodt", "Jan", ""], ["Jastremskoj", "Eugen", ""], ["Reich", "Christoph", ""]]}, {"id": "2007.14273", "submitter": "Liz Dowthwaite", "authors": "Liz Dowthwaite, Elvira Perez Vallejos, Helen Creswick, Virginia\n  Portillo, Menisha Patel, Jun Zhao", "title": "Developing a measure of online wellbeing and user trust", "comments": "Full paper, 8 pages", "journal-ref": "In Societal Challenges in the Smart Society pp21-33. Ethicomp Book\n  Series, Universidad de La Rioja (2020)", "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the first stage of the ongoing development of two scales\nto measure online wellbeing and trust, based on the results of a series of\nworkshops with younger and older adults. The first, the Online Wellbeing Scale\nincludes subscales covering both psychological, or eudaimonic, wellbeing and\nsubjective, or hedonic, wellbeing, as well as digital literacy and online\nactivity; the overall aim is to understand how a user's online experiences\naffect their wellbeing. The second scale, the Trust Index includes three\nsubscales covering the importance of trust to the user, trusting beliefs, and\ncontextual factors; the aim for this scale is to examine trust in online\nalgorithm-driven systems. The scales will be used together to aid researchers\nin understanding how trust (or lack of trust) relates to overall wellbeing\nonline. They will also contribute to the development of a suite of tools for\nempowering users to negotiate issues of trust online, as well as in designing\nguidelines for the inclusion of trust considerations in the development of\nonline algorithm-driven systems. The next step is to release the prototype\nscales developed as a result of this pilot in a large online study in to\nvalidate the measures.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 14:40:13 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Dowthwaite", "Liz", ""], ["Vallejos", "Elvira Perez", ""], ["Creswick", "Helen", ""], ["Portillo", "Virginia", ""], ["Patel", "Menisha", ""], ["Zhao", "Jun", ""]]}, {"id": "2007.14302", "submitter": "Raeid Saqur", "authors": "Frank Rudzicz and Raeid Saqur", "title": "Ethics of Artificial Intelligence in Surgery", "comments": null, "journal-ref": "In Hashimoto D.A. (Ed.) Artificial Intelligence in Surgery: A\n  Primer for Surgical Practice. New York: McGraw Hill. ISBN: 978-1260452730\n  (2020)", "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we discuss the four key principles of bio-medical ethics from surgical\ncontext. We elaborate on the definition of 'fairness' and its implications in\nAI system design, with taxonomy of algorithmic biases in AI. We discuss the\nshifts in ethical paradigms as the degree of autonomy in AI systems continue to\nevolve. We also emphasize the need for continuous revisions of ethics in AI due\nto evolution and dynamic nature of AI systems and technologies.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 15:16:45 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Rudzicz", "Frank", ""], ["Saqur", "Raeid", ""]]}, {"id": "2007.14308", "submitter": "Andres Ospina-Alvarez Dr.", "authors": "Silvia de Juan and Andres Ospina-Alvarez and Sebasti\\'an Villasante\n  and Ana Ruiz-Frau", "title": "A Graph Theory approach to assess nature's contribution to people at a\n  global scale", "comments": "25 pages, 5 figures, 2 tables, 3 appendices, submitted manuscript to\n  Scientific Reports at November 30 2020", "journal-ref": "Sci. Rep. 11, 9118 (2021)", "doi": "10.1038/s41598-021-88745-z", "report-no": null, "categories": "cs.SI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cultural Ecosystem Services (CES) assessment at large scales is crucial in\nmarine ecosystems as they reflect key physical and cognitive interactions\nbetween humans and nature. The analysis of social media data with graph theory\nis a promising approach to provide global information on users' perceptions for\ndifferent marine ecosystems. Fourteen areas were selected to illustrate the use\nof graph theory on social media data. The selected areas, known to protect key\nrecreational, educational and heritage attributes of marine ecosystems, were\ninvestigated to identify variability in users' preferences. Instagram data\n(i.e., hashtags associated to photos) was extracted for each area allowing an\nin-depth assessment of the CES most appreciated by the users. Hashtags were\nanalysed using network centrality measures to identify clusters of words,\naspects not normally captured by traditional photo content analysis. The\nemergent properties of networks of hashtags were explored to characterise\nvisitors' preferences (e.g., cultural heritage or nature appreciation),\nactivities (e.g., diving or hiking), preferred habitats and species (e.g.\nforest, beach, penguins), and feelings (e.g., happiness or place identity).\nNetwork analysis on Instagram hashtags allowed delineating the users' discourse\naround a natural area, which provides crucial information for effective\nmanagement of popular natural spaces for people.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 09:58:56 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 09:22:47 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["de Juan", "Silvia", ""], ["Ospina-Alvarez", "Andres", ""], ["Villasante", "Sebasti\u00e1n", ""], ["Ruiz-Frau", "Ana", ""]]}, {"id": "2007.14361", "submitter": "Kenneth Lai", "authors": "Kenneth Lai, Helder C. R. Oliveira, Ming Hou, Svetlana N.\n  Yanushkevich, and Vlad Shmerko", "title": "Assessing Risks of Biases in Cognitive Decision Support Systems", "comments": "submitted to 28th European Signal Processing Conference (EUSIPCO\n  2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing, assessing, countering, and mitigating the biases of different\nnature from heterogeneous sources is a critical problem in designing a\ncognitive Decision Support System (DSS). An example of such a system is a\ncognitive biometric-enabled security checkpoint. Biased algorithms affect the\ndecision-making process in an unpredictable way, e.g. face recognition for\ndifferent demographic groups may severely impact the risk assessment at a\ncheckpoint. This paper addresses a challenging research question on how to\nmanage an ensemble of biases? We provide performance projections of the DSS\noperational landscape in terms of biases. A probabilistic reasoning technique\nis used for assessment of the risk of such biases. We also provide a\nmotivational experiment using face biometric component of the checkpoint system\nwhich highlights the discovery of an ensemble of biases and the techniques to\nassess their risks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 16:53:45 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Lai", "Kenneth", ""], ["Oliveira", "Helder C. R.", ""], ["Hou", "Ming", ""], ["Yanushkevich", "Svetlana N.", ""], ["Shmerko", "Vlad", ""]]}, {"id": "2007.14443", "submitter": "Ha-Kyung Kwon", "authors": "Ha-Kyung Kwon, Chirranjeevi Balaji Gopal, Jared Kirschner, Santiago\n  Caicedo, and Brian D. Storey", "title": "A user-centered approach to designing an experimental laboratory data\n  platform", "comments": "15 pages, 3 figures (38 pages in Supplementary Materials)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While automated experiments and high-throughput methods are becoming more\nmainstream in the age of data, empowering individual researchers to capture,\ncollate, and contextualize their data faster and more reproducibly still\nremains a challenge in science. Despite the abundance of software products to\nhelp digitize and organize scientific information, their broader adoption in\nthe scientific community has been hindered by the lack of a holistic\nunderstanding of the diverse needs of researchers and their experimental\nprocesses. In this work, we take a user-centered approach to understand what\nessential elements of design and functionality researchers (in chemical and\nmaterials science) want in an experimental data platform to address the problem\nof data capture in their experimental processes. We found that having the\ncapability to contextualize rich, complex experimental datasets is the primary\nuser requirement. We synthesize this and other key findings into design\ncriteria for a potential solution.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 19:26:28 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Kwon", "Ha-Kyung", ""], ["Gopal", "Chirranjeevi Balaji", ""], ["Kirschner", "Jared", ""], ["Caicedo", "Santiago", ""], ["Storey", "Brian D.", ""]]}, {"id": "2007.14570", "submitter": "Long Cheng", "authors": "Song Liao, Christin Wilson, Long Cheng, Hongxin Hu, Huixing Deng", "title": "Measuring the Effectiveness of Privacy Policies for Voice Assistant\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice Assistants (VA) such as Amazon Alexa and Google Assistant are quickly\nand seamlessly integrating into people's daily lives. The increased reliance on\nVA services raises privacy concerns such as the leakage of private\nconversations and sensitive information. Privacy policies play an important\nrole in addressing users' privacy concerns and informing them about the data\ncollection, storage, and sharing practices. VA platforms (both Amazon Alexa and\nGoogle Assistant) allow third-party developers to build new voice-apps and\npublish them to the app store. Voice-app developers are required to provide\nprivacy policies to disclose their apps' data practices. However, little is\nknown whether these privacy policies are informative and trustworthy or not on\nemerging VA platforms. On the other hand, many users invoke voice-apps through\nvoice and thus there exists a usability challenge for users to access these\nprivacy policies. In this paper, we conduct the first large-scale data\nanalytics to systematically measure the effectiveness of privacy policies\nprovided by voice-app developers on two mainstream VA platforms. We seek to\nunderstand the quality and usability issues of privacy policies provided by\ndevelopers in the current app stores. We analyzed 64,720 Amazon Alexa skills\nand 2,201 Google Assistant actions. Our work also includes a user study to\nunderstand users' perspectives on VA's privacy policies. Our findings reveal a\nworrisome reality of privacy policies in two mainstream voice-app stores, where\nthere exists a substantial number of problematic privacy policies.\nSurprisingly, Google and Amazon even have official voice-apps violating their\nown requirements regarding the privacy policy.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 03:17:51 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Liao", "Song", ""], ["Wilson", "Christin", ""], ["Cheng", "Long", ""], ["Hu", "Hongxin", ""], ["Deng", "Huixing", ""]]}, {"id": "2007.14574", "submitter": "Parinaz Naghizadeh", "authors": "Parinaz Naghizadeh, Carlee Joe-Wong, Mung Chiang", "title": "Paid Prioritization with Content Competition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of allowing paid prioritization arrangements in a market\nwith content provider (CP) competition. We consider competing CPs who pay\nprioritization fees to a monopolistic ISP so as to offset the ISP's cost for\ninvesting in infrastructure to support fast lanes. Unlike prior works, our\nproposed model of users' content consumption accounts for multi-purchasing\n(i.e., users simultaneously subscribing to more than one CP). This model allows\nus to account for the \"attention\" received by each CP, and consequently to draw\na contrast between how subscription-revenues and ad-revenues are impacted by\npaid prioritization. We show that there exist incentives for the ISP to build\nadditional fast lanes subsidized by CPs with sufficiently high revenue (from\neither subscription fees or advertisements). We show that non-prioritized\ncontent providers need not lose users, yet may lose revenue from advertisements\ndue to decreased attention from users. We further show that users will consume\na wider variety of content in a prioritized regime, and that they can attain\nhigher welfare provided that non-prioritized traffic is not throttled. We\ndiscuss some policy and practical implications of these findings and\nnumerically validate them.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 03:39:41 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Naghizadeh", "Parinaz", ""], ["Joe-Wong", "Carlee", ""], ["Chiang", "Mung", ""]]}, {"id": "2007.14732", "submitter": "Yushan Pan", "authors": "Yushan Pan, Arnfinn Oksavik and Hans Petter Hildre", "title": "Simulator as a Tool for the Future Maritime Education and Research: A\n  Discussion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A few studies in the maritime domain utilize co-design in ship design\nworkshops, however, none of them addresses a full picture of how co-design can\nmake changes in simulation-based maritime education. In this paper, we reflect\nhow co-design can help to foresight future skills in the maritime domain,\nespecially on how to use simulators to support increasing competence of\nseafarers and in turn to redesign simulators to support maritime education.\nThus, we address collaborative and innovative research activities, to enable\nall participants (seafarers, trainers, technicians, authorities etc.) to share\ntheir experiences so a joint recognition of needed future skills can be\nreached. Along with the ex-change of experiences, we assert that the supported\nsimulations and simulator techniques could be designed to achieve sustainable\ngrowth for all participants.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 10:41:44 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Pan", "Yushan", ""], ["Oksavik", "Arnfinn", ""], ["Hildre", "Hans Petter", ""]]}, {"id": "2007.14775", "submitter": "Giorgio Barnabo' Mr.", "authors": "Giorgio Barnabo', Carlos Castillo, Michael Mathioudakis, Sergio Celis", "title": "Intersectional Affirmative Action Policies for Top-k Candidates\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of selecting the top-k candidates from a pool of\napplicants, where each candidate is associated with a score indicating his/her\naptitude. Depending on the specific scenario, such as job search or college\nadmissions, these scores may be the results of standardized tests or other\npredictors of future performance and utility. We consider a situation in which\nsome groups of candidates experience historical and present disadvantage that\nmakes their chances of being accepted much lower than other groups. In these\ncircumstances, we wish to apply an affirmative action policy to reduce\nacceptance rate disparities, while avoiding any large decrease in the aptitude\nof the candidates that are eventually selected. Our algorithmic design is\nmotivated by the frequently observed phenomenon that discrimination\ndisproportionately affects individuals who simultaneously belong to multiple\ndisadvantaged groups, defined along intersecting dimensions such as gender,\nrace, sexual orientation, socio-economic status, and disability. In short, our\nalgorithm's objective is to simultaneously: select candidates with high\nutility, and level up the representation of disadvantaged intersectional\nclasses. This naturally involves trade-offs and is computationally challenging\ndue to the the combinatorial explosion of potential subgroups as more\nattributes are considered. We propose two algorithms to solve this problem,\nanalyze them, and evaluate them experimentally using a dataset of university\napplication scores and admissions to bachelor degrees in an OECD country. Our\nconclusion is that it is possible to significantly reduce disparities in\nadmission rates affecting intersectional classes with a small loss in terms of\nselected candidate aptitude. To the best of our knowledge, we are the first to\nstudy fairness constraints with regards to intersectional classes in the\ncontext of top-k selection.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 12:27:18 GMT"}, {"version": "v2", "created": "Fri, 5 Mar 2021 16:21:37 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Barnabo'", "Giorgio", ""], ["Castillo", "Carlos", ""], ["Mathioudakis", "Michael", ""], ["Celis", "Sergio", ""]]}, {"id": "2007.14806", "submitter": "Ashad Kabir", "authors": "Fariha Afsana, Muhammad Ashad Kabir, Naeemul Hassan, Manoranjan Paul", "title": "Towards Domain-Specific Characterization of Misinformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid dissemination of health misinformation poses an increasing risk to\npublic health. To best understand the way of combating health misinformation,\nit is important to acknowledge how the fundamental characteristics of\nmisinformation differ from domain to domain. This paper presents a pathway\ntowards domain-specific characterization of misinformation so that we can\naddress the concealed behavior of health misinformation compared to others and\ntake proper initiative accordingly for combating it. With this aim, we have\nmentioned several possible approaches to identify discriminating features of\nmedical misinformation from other types of misinformation. Thereafter, we\nbriefly propose a research plan followed by possible challenges to meet up. The\nfindings of the proposed research idea will provide new directions to the\nmisinformation research community.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 12:46:45 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Afsana", "Fariha", ""], ["Kabir", "Muhammad Ashad", ""], ["Hassan", "Naeemul", ""], ["Paul", "Manoranjan", ""]]}, {"id": "2007.14826", "submitter": "Bogdana Rakova", "authors": "Marek Havrda and Bogdana Rakova", "title": "Enhanced well-being assessment as basis for the practical implementation\n  of ethical and rights-based normative principles for AI", "comments": "8 pages, In the Proceedings of 2020 IEEE International Conference on\n  Systems, Man and Cybernetics (SMC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence (AI) has an increasing impact on all areas of\npeople's livelihoods. A detailed look at existing interdisciplinary and\ntransdisciplinary metrics frameworks could bring new insights and enable\npractitioners to navigate the challenge of understanding and assessing the\nimpact of Autonomous and Intelligent Systems (A/IS). There has been emerging\nconsensus on fundamental ethical and rights-based AI principles proposed by\nscholars, governments, civil rights organizations, and technology companies. In\norder to move from principles to real-world implementation, we adopt a lens\nmotivated by regulatory impact assessments and the well-being movement in\npublic policy. Similar to public policy interventions, outcomes of AI systems\nimplementation may have far-reaching complex impacts. In public policy,\nindicators are only part of a broader toolbox, as metrics inherently lead to\ngaming and dissolution of incentives and objectives. Similarly, in the case of\nA/IS, there's a need for a larger toolbox that allows for the iterative\nassessment of identified impacts, inclusion of new impacts in the analysis, and\nidentification of emerging trade-offs. In this paper, we propose the practical\napplication of an enhanced well-being impact assessment framework for A/IS that\ncould be employed to address ethical and rights-based normative principles in\nAI. This process could enable a human-centered algorithmically-supported\napproach to the understanding of the impacts of AI systems. Finally, we propose\na new testing infrastructure which would allow for governments, civil rights\norganizations, and others, to engage in cooperating with A/IS developers\ntowards implementation of enhanced well-being impact assessments.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 13:26:05 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 15:15:16 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Havrda", "Marek", ""], ["Rakova", "Bogdana", ""]]}, {"id": "2007.14910", "submitter": "Soham Poddar", "authors": "Soham Poddar, Mainack Mondal and Saptarshi Ghosh", "title": "A Survey on Disaster: Understanding the After-effects of Super-cyclone\n  Amphan and Helping Hand of Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The super-cyclonic storm \"Amphan\" hit Eastern India, specifically the state\nof West Bengal, Odisha and parts of Bangladesh in May 2020, and caused severe\ndamage to the regions. In this study, we aim to understand the self-reported\neffects of this natural disaster on residents of the state of West Bengal. To\nthat end, we conducted an online survey to understand the effects of the\ncyclone. In total, 201 participants (spanning five districts) from the\nworst-affected state of West Bengal participated in the survey. This report\ndescribes our findings from the survey, with respect to the damages caused by\nthe cyclone, how it affected the population in various districts of West\nBengal, and how prepared the authorities were in responding to the disaster. We\nfound that the participants were most adversely affected in this disaster due\nto disruption of services like electricity, phone and internet (as opposed to\nuprooting of trees and water-logging). Furthermore, we found that receiving\nresponses to Amphan-related queries is highly positively correlated with the\nfavorable perception of people about preparedness of authorities. Additionally,\nwe study the usage of online social media by the affected population in the\ndays immediately after the disaster. Our results strongly suggest how social\nmedia platforms can help authorities to better prepare for future disasters. In\nsummary, our study analyzes self-reported data collected from grassroots, and\nbrings out several key insights that can help authorities deal better with\ndisaster events in future.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 15:30:26 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Poddar", "Soham", ""], ["Mondal", "Mainack", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "2007.15351", "submitter": "Harold Steven Ruiz Rondan Dr.", "authors": "H. S. Ruiz, A. Sunarso, K. Ibrahim-bathis, S. A. Murti, and I.\n  Budiarto", "title": "GIS-AHP Multi-Decision-Criteria-Analysis for the Optimal Location of\n  Solar Energy Plants at Indonesia", "comments": "This work was supported by the Institutional Links grant, ID\n  413871894, under the Newton Fund Indonesia partnership. The grant is funded\n  by the UK Department for Business, Energy and Industrial Strategy and the\n  Indonesian Ministry of Research, Technology, Higher Education and delivered\n  by the British Council. For further information, please visit\n  www.newtonfund.ac.uk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reliable tool for site-suitability assessment of solar power plants capable\nto account for the sustainable development and protection of cultural and\nbiodiversity conservation areas is proposed. We present a novel Analytic\nHierarchy Process (AHP) based approach for the Multi-Decision Criteria Analysis\n(MDCA) of SSI satellite retrieved data and local information sources, it within\na GIS platform tailored to fit the needs of energy stakeholders at Indonesia,\nsimultaneously ensuring the conservation of legally protected areas. This\nimposes significant challenges due to the wide diversification of cultural,\nnatural, and ecological protected areas that need to be considered, in\nlandmarks that demand for high resolution imaging of surface solar irradiance\n(SSI) within $\\pm 4^{\\circ}$ of the equator. To overcome these challenges, a\nGIS spatial weighted overlay analysis for criteria layers such as climatology,\ntopography, electrical grid, and road infrastructure has been performed, it\nbased on the technical and economic feasibility for solar plants deployment\nwithin three approximation schemes focused on their proximity to the existing\n(i) power network, (ii) road infrastructure, and (iii) community settlements.\nHere, we focused on the West Kalimantan Province of Borneo Island (WKP), it\nmainly due to its possibility of onshore inter-connectivity and energy share\nwith Malaysia and Brunei, and the high national and international importance\nthat brings forward the protection of the biodiversity of Borneo. It has been\nfound that the optimal location of PV plants can be reduced to just $0.03\\%$\n($46.60~km^{2}$) and $0.07\\%$ ($108.58~{km}^{2}$) of WKP, in what we report as\nthe best-suitable conditions out of the $33.05\\%$ exploitable area found after\nthe exclusion of conservation areas. This corresponds to ...\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 09:58:47 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Ruiz", "H. S.", ""], ["Sunarso", "A.", ""], ["Ibrahim-bathis", "K.", ""], ["Murti", "S. A.", ""], ["Budiarto", "I.", ""]]}, {"id": "2007.15550", "submitter": "Adel Daoud", "authors": "Adel Daoud, Anders Herlitz, and SV Subramanian", "title": "Combining distributive ethics and causal Inference to make trade-offs\n  between austerity and population health", "comments": "Working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The International Monetary Fund (IMF) provides financial assistance to its\nmember-countries in economic turmoil, but requires at the same time that these\ncountries reform their public policies. In several contexts, these reforms are\nat odds with population health. While researchers have empirically analyzed the\nconsequences of these reforms on health, no analysis exist on identifying fair\ntradeoffs between consequences on population health and economic outcomes. Our\narticle analyzes and identifies the principles governing these tradeoffs.\nFirst, this article reviews existing policy-evaluation studies, which show, on\nbalance, that IMF policies frequently cause adverse effects on child health and\nmaterial standards in the pursuit of macroeconmic improvement. Second, this\narticle discusses four theories in distributive ethics (maximization,\negalitarianianism, prioritarianiasm, and sufficientarianism) to identify which\nis the most compatible with the core mission of the IMF, that is, improved\nmacroeconomics (Articles of Agreement) while at the same time balancing\nconsequences on health. Using a distributive-ethics analyses of IMF polices, we\nargue that sufficientarianism is the most compatible theory. Third, this\narticle offer a qualitative rearticulation of the Articles of Agreement, and\nformalize sufficientarian principles in the language of causal inference. We\nalso offer a framework on how to empirically measure, from observational data,\nthe extent that IMF policies trade off fairly between population health and\neconomic outcomes. We conclude with policy recommendations and suggestions for\nfuture research.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 15:54:40 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 09:56:33 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Daoud", "Adel", ""], ["Herlitz", "Anders", ""], ["Subramanian", "SV", ""]]}, {"id": "2007.15584", "submitter": "Longqi Yang", "authors": "Longqi Yang, Sonia Jaffe, David Holtz, Siddharth Suri, Shilpi Sinha,\n  Jeffrey Weston, Connor Joyce, Neha Shah, Kevin Sherman, CJ Lee, Brent Hecht,\n  Jaime Teevan", "title": "How Work From Home Affects Collaboration: A Large-Scale Study of\n  Information Workers in a Natural Experiment During COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has had a wide-ranging impact on information workers\nsuch as higher stress levels, increased workloads, new workstreams, and more\ncaregiving responsibilities during lockdown. COVID-19 also caused the\noverwhelming majority of information workers to rapidly shift to working from\nhome (WFH). The central question this work addresses is: can we isolate the\neffects of WFH on information workers' collaboration activities from all other\nfactors, especially the other effects of COVID-19? This is important because in\nthe future, WFH will likely to be more common than it was prior to the\npandemic.\n  We use difference-in-differences (DiD), a causal identification strategy\ncommonly used in the social sciences, to control for unobserved confounding\nfactors and estimate the causal effect of WFH. Our analysis relies on measuring\nthe difference in changes between those who WFH prior to COVID-19 and those who\ndid not. Our preliminary results suggest that on average, people spent more\ntime on collaboration in April (Post WFH mandate) than in February (Pre WFH\nmandate), but this is primarily due to factors other than WFH, such as\nlockdowns during the pandemic. The change attributable to WFH specifically is\nin the opposite direction: less time on collaboration and more focus time. This\nreversal shows the importance of using causal inference: a simple analysis\nwould have resulted in the wrong conclusion. We further find that the effect of\nWFH is moderated by individual remote collaboration experience prior to WFH.\nMeanwhile, the medium for collaboration has also shifted due to WFH: instant\nmessages were used more, whereas scheduled meetings were used less. We discuss\ndesign implications -- how future WFH may affect focused work, collaborative\nwork, and creative work.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 16:43:26 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Yang", "Longqi", ""], ["Jaffe", "Sonia", ""], ["Holtz", "David", ""], ["Suri", "Siddharth", ""], ["Sinha", "Shilpi", ""], ["Weston", "Jeffrey", ""], ["Joyce", "Connor", ""], ["Shah", "Neha", ""], ["Sherman", "Kevin", ""], ["Lee", "CJ", ""], ["Hecht", "Brent", ""], ["Teevan", "Jaime", ""]]}, {"id": "2007.15585", "submitter": "Huthaifa I. Ashqar", "authors": "Mohammed Elhenawy, MD Mostafizur Rahman Komol, Huthaifa I. Ashqar,\n  Mohammed Hamad Almannaa, Mahmoud Masoud, Hesham A. Rakha, and Andry\n  Rakotonirainy", "title": "Developing a Novel Crowdsourcing Business Model for Micro-Mobility\n  Ride-Sharing Systems: Methodology and Preliminary Results", "comments": "Submitted to TRB 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro-mobility ride-sharing is an emerging technology that provides access to\nthe transit system with minimum environmental impacts. Significant research is\nrequired to ensure that micro-mobility ride-sharing provides a better\nfulfilment of user needs. In this study, we propose a novel business model for\nthe micro-mobility ride-sharing system where light vehicles such as electric\nscooters and electric bikes are crowdsourced. This new model consists of three\nentities, the suppliers, the customers, and a management party, which is\nresponsible for receiving, renting, booking, and demand matching with offered\nresources. The proposed model has the potential to allow the suppliers to\ndefine the location of their private e-scooter/e-bike and the period of time\nthey are available for rent, match it with a particular demand, and then offer\nsuppliers the opportunity to get their e-scooters/e-bikes rented and returned\nat the end of the renting period to the same (nearby) location. The management\nparty will need to match the e-scooter/e-bike to a series of renting demands\nwith the last demand as a destination very close to the initial location of the\ne-scooter/e-bike at the start of the renting period. One potential advantage of\nthe proposed model is that it shifts the charging and maintenance efforts to a\ncrowd of suppliers.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 16:44:19 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Elhenawy", "Mohammed", ""], ["Komol", "MD Mostafizur Rahman", ""], ["Ashqar", "Huthaifa I.", ""], ["Almannaa", "Mohammed Hamad", ""], ["Masoud", "Mahmoud", ""], ["Rakha", "Hesham A.", ""], ["Rakotonirainy", "Andry", ""]]}, {"id": "2007.15619", "submitter": "Raunak Shah", "authors": "Tushar Goswamy, Naishadh Parmar, Ayush Gupta, Vatsalya Tandon, Raunak\n  Shah, Varun Goyal, Sanyog Gupta, Karishma Laud, Shivam Gupta, Sudhanshu\n  Mishra, Ashutosh Modi", "title": "AI-based Monitoring and Response System for Hospital Preparedness\n  towards COVID-19 in Southeast Asia", "comments": "5 pages, 5 figures. Accepted to the ICML 2020 Workshop on Healthcare\n  Systems, Population Health, and the Role of Health-Tech", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research paper proposes a COVID-19 monitoring and response system to\nidentify the surge in the volume of patients at hospitals and shortage of\ncritical equipment like ventilators in South-east Asian countries, to\nunderstand the burden on health facilities. This can help authorities in these\nregions with resource planning measures to redirect resources to the regions\nidentified by the model. Due to the lack of publicly available data on the\ninflux of patients in hospitals, or the shortage of equipment, ICU units or\nhospital beds that regions in these countries might be facing, we leverage\nTwitter data for gleaning this information. The approach has yielded accurate\nresults for states in India, and we are working on validating the model for the\nremaining countries so that it can serve as a reliable tool for authorities to\nmonitor the burden on hospitals.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 17:39:13 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Goswamy", "Tushar", ""], ["Parmar", "Naishadh", ""], ["Gupta", "Ayush", ""], ["Tandon", "Vatsalya", ""], ["Shah", "Raunak", ""], ["Goyal", "Varun", ""], ["Gupta", "Sanyog", ""], ["Laud", "Karishma", ""], ["Gupta", "Shivam", ""], ["Mishra", "Sudhanshu", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2007.15628", "submitter": "Raunak Shah", "authors": "Tushar Goswamy, Vatsalya Tandon, Naishadh Parmar, Raunak Shah, Ayush\n  Gupta", "title": "IIT Kanpur Consulting Group: Using Machine Learning and Management\n  Consulting for Social Good", "comments": "4 pages. Accepted to the ICML 2020 Workshop on Healthcare Systems,\n  Population Health, and the Role of Health-Tech", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IIT Kanpur Consulting Group is one of the pioneering research groups in\nIndia which focuses on the applications of Machine Learning and Strategy\nConsulting for social good. The group has been working since 2018 to help\nsocial organizations, nonprofits, and government entities in India leverage\nbetter insights from their data, with a special emphasis on the healthcare,\nenvironmental, and agriculture sectors. The group has worked on critical social\nproblems which India is facing including Polio recurrence, COVID-19, air\npollution and agricultural crop damage. This position paper summarises the\nfocus areas and relevant projects which the group has worked on since its\nestablishment, and also highlights the group's plans for using machine learning\nto address social problems during the COVID-19 crisis.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 17:52:15 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Goswamy", "Tushar", ""], ["Tandon", "Vatsalya", ""], ["Parmar", "Naishadh", ""], ["Shah", "Raunak", ""], ["Gupta", "Ayush", ""]]}, {"id": "2007.15807", "submitter": "Mohammad Rahaman", "authors": "Mohammad Saiedur Rahaman, Shaw Kudo, Tim Rawling, Yongli Ren, and\n  Flora D. Salim", "title": "Seating preference analysis for hybrid workplaces", "comments": "4 pages, 3 figures", "journal-ref": "NFW '20: Symposium on New Future of Work, August 03--05, 2020", "doi": null, "report-no": null, "categories": "cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing nature of flexible work and the recent requirements\nfrom COVID-19 restrictions, workplaces are becoming more hybrid (i.e. allowing\nworkers to work between traditional office spaces and elsewhere including from\nhome). Since workplaces are different in design, layout and available\nfacilities, many workers find it difficult to adjust accordingly. Eventually,\nthis impacts negatively towards work productivity and other related parameters\nincluding concentration, stress, and mood while at work. One of the key factors\nthat causes this negative work experience is directly linked to the available\nseating arrangements. In this paper, we conduct an analysis to understand\nvarious seating preferences of 37 workers with varying demographics, using the\ndata collected pre-COVID-19, and analyse the findings in the context of hybrid\nworkplace settings. We also discuss a list of implications illustrating how our\nfindings can be adapted across wider hybrid work settings.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 02:17:20 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Rahaman", "Mohammad Saiedur", ""], ["Kudo", "Shaw", ""], ["Rawling", "Tim", ""], ["Ren", "Yongli", ""], ["Salim", "Flora D.", ""]]}, {"id": "2007.15864", "submitter": "Alan Winfield", "authors": "Alan F.T. Winfield, Katie Winkle", "title": "RoboTed: a case study in Ethical Risk Assessment", "comments": "Revised version following review, presented at ICRES 2020, 28\n  September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk Assessment is a well known and powerful method for discovering and\nmitigating risks, and hence improving safety. Ethical Risk Assessment uses the\nsame approach but extends the envelope of risk to cover ethical risks in\naddition to safety risks. In this paper we outline Ethical Risk Assessment\n(ERA) and set ERA within the broader framework of Responsible Robotics. We then\nillustrate ERA with a case study of a hypothetical smart robot toy teddy bear:\nRoboTed. The case study shows the value of ERA and how consideration of ethical\nrisks can prompt design changes, resulting in a more ethical and sustainable\nrobot.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 06:35:18 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2020 13:15:39 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Winfield", "Alan F. T.", ""], ["Winkle", "Katie", ""]]}, {"id": "2007.16063", "submitter": "William Taylor", "authors": "William Taylor, Qammer H. Abbasi, Kia Dashtipour, Shuja Ansari, Aziz\n  Shah, Arslan Khan and Muhammad Ali Imran", "title": "A Review on the State of the Art in Non Contact Sensing for COVID-19", "comments": "10 pages, 6 figures. Submitted as journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY eess.IV physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19 disease, caused by SARS-CoV-2, has resulted in a global pandemic\nrecently. With no approved vaccination or treatment, governments around the\nworld have issued guidance to their citizens to remain at home in efforts to\ncontrol the spread of the disease. The goal of controlling the spread of the\nvirus is to prevent strain on hospital. In this paper, we have focus on how\nnon-invasive methods are being used to detect the COVID-19 and assist\nhealthcare workers in caring for COVID-19 patients. Early detection of the\nCOVID-19 virus can allow for early isolation to prevent further spread. This\nstudy outlines the advantages and disadvantages and a breakdown of the methods\napplied in the current state-of-the-art approaches. In addition, the paper\nhighlights some future research directions, which are required to be explored\nfurther to come up with innovative technologies to control this pandemic.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 11:18:38 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Taylor", "William", ""], ["Abbasi", "Qammer H.", ""], ["Dashtipour", "Kia", ""], ["Ansari", "Shuja", ""], ["Shah", "Aziz", ""], ["Khan", "Arslan", ""], ["Imran", "Muhammad Ali", ""]]}, {"id": "2007.16172", "submitter": "Zachary Levonian", "authors": "Zachary Levonian, Marco Dow, Drew Erikson, Sourojit Ghosh, Hannah\n  Miller Hillberg, Saumik Narayanan, Loren Terveen, Svetlana Yarosh", "title": "Patterns of Patient and Caregiver Mutual Support Connections in an\n  Online Health Community", "comments": "Pre-print of paper conditionally accepted to CSCW 2020. 31\n  main-article pages; 46 pages with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online health communities offer the promise of support benefits to users, in\nparticular because these communities enable users to find peers with similar\nexperiences. Building mutually supportive connections between peers is a key\nmotivation for using online health communities. However, a user's role in a\ncommunity may influence the formation of peer connections. In this work, we\nstudy patterns of peer connections between two structural health roles: patient\nand non-professional caregiver. We examine user behavior in an online health\ncommunity where finding peers is not explicitly supported. This context lets us\nuse social network analysis methods to explore the growth of such connections\nin the wild and identify users' peer communication preferences. We investigated\nhow connections between peers were initiated, finding that initiations are more\nlikely between two authors who have the same role and who are close within the\nbroader communication network. Relationships are also more likely to form and\nbe more interactive when authors have the same role. Our results have\nimplications for the design of systems supporting peer communication, e.g.\npeer-to-peer recommendation systems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:51:41 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 15:31:57 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 19:24:03 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Levonian", "Zachary", ""], ["Dow", "Marco", ""], ["Erikson", "Drew", ""], ["Ghosh", "Sourojit", ""], ["Hillberg", "Hannah Miller", ""], ["Narayanan", "Saumik", ""], ["Terveen", "Loren", ""], ["Yarosh", "Svetlana", ""]]}]