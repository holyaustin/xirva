[{"id": "1405.0174", "submitter": "Karim Mahmoud", "authors": "Karim M. Mohamed, Mohamed A. Ismail, Nagia M. Ghanem", "title": "VSCAN: An Enhanced Video Summarization using Density-based Spatial\n  Clustering", "comments": "arXiv admin note: substantial text overlap with arXiv:1401.3590 by\n  other authors without attribution", "journal-ref": null, "doi": "10.1007/978-3-642-41181-6_74", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present VSCAN, a novel approach for generating static video\nsummaries. This approach is based on a modified DBSCAN clustering algorithm to\nsummarize the video content utilizing both color and texture features of the\nvideo frames. The paper also introduces an enhanced evaluation method that\ndepends on color and texture features. Video Summaries generated by VSCAN are\ncompared with summaries generated by other approaches found in the literature\nand those created by users. Experimental results indicate that the video\nsummaries generated by VSCAN have a higher quality than those generated by\nother approaches.\n", "versions": [{"version": "v1", "created": "Thu, 1 May 2014 14:36:35 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["Mohamed", "Karim M.", ""], ["Ismail", "Mohamed A.", ""], ["Ghanem", "Nagia M.", ""]]}, {"id": "1405.0413", "submitter": "Renato J Cintra", "authors": "F. M. Bayer, R. J. Cintra, A. Madanayake, U. S. Potluri", "title": "Multiplierless Approximate 4-point DCT VLSI Architectures for Transform\n  Block Coding", "comments": "5 pages, 1 figure, corrected Figure 1 (published paper in EL is\n  incorrect)", "journal-ref": "Electronics Letters, vol. 49, no. 24, pp. 1532-1534, 2013", "doi": "10.1049/el.2013.1352", "report-no": null, "categories": "cs.AR cs.MM cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two multiplierless algorithms are proposed for 4x4 approximate-DCT for\ntransform coding in digital video. Computational architectures for 1-D/2-D\nrealisations are implemented using Xilinx FPGA devices. CMOS synthesis at the\n45 nm node indicate real-time operation at 1 GHz yielding 4x4 block rates of\n125 MHz at less than 120 mW of dynamic power consumption.\n", "versions": [{"version": "v1", "created": "Fri, 2 May 2014 14:29:02 GMT"}], "update_date": "2014-05-05", "authors_parsed": [["Bayer", "F. M.", ""], ["Cintra", "R. J.", ""], ["Madanayake", "A.", ""], ["Potluri", "U. S.", ""]]}, {"id": "1405.3173", "submitter": "Jian Zhang", "authors": "Jian Zhang, Debin Zhao, Ruiqin Xiong, Siwei Ma, Wen Gao", "title": "Image Restoration Using Joint Statistical Modeling in Space-Transform\n  Domain", "comments": "14 pages, 18 figures, 7 Tables, to be published in IEEE Transactions\n  on Circuits System and Video Technology (TCSVT). High resolution pdf version\n  and Code can be found at: http://idm.pku.edu.cn/staff/zhangjian/IRJSM/", "journal-ref": null, "doi": "10.1109/TCSVT.2014.2302380", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel strategy for high-fidelity image restoration by\ncharacterizing both local smoothness and nonlocal self-similarity of natural\nimages in a unified statistical manner. The main contributions are three-folds.\nFirst, from the perspective of image statistics, a joint statistical modeling\n(JSM) in an adaptive hybrid space-transform domain is established, which offers\na powerful mechanism of combining local smoothness and nonlocal self-similarity\nsimultaneously to ensure a more reliable and robust estimation. Second, a new\nform of minimization functional for solving image inverse problem is formulated\nusing JSM under regularization-based framework. Finally, in order to make JSM\ntractable and robust, a new Split-Bregman based algorithm is developed to\nefficiently solve the above severely underdetermined inverse problem associated\nwith theoretical proof of convergence. Extensive experiments on image\ninpainting, image deblurring and mixed Gaussian plus salt-and-pepper noise\nremoval applications verify the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 May 2014 08:45:07 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Zhang", "Jian", ""], ["Zhao", "Debin", ""], ["Xiong", "Ruiqin", ""], ["Ma", "Siwei", ""], ["Gao", "Wen", ""]]}, {"id": "1405.3207", "submitter": "Parvathavarthini Sivagnanam", "authors": "Parvathavarthini S. and Shanthakumari R", "title": "An Adaptive Watermarking Process in Hadamard Transform", "comments": "7 Pages, 10 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adaptive visible/invisible watermarking scheme is done to prevent the\nprivacy and preserving copyright protection of digital data using Hadamard\ntransform based on the scaling factor of the image. The value of scaling factor\ndepends on the control parameter. The scaling factor is calculated to embedded\nthe watermark. Depend upon the control parameter the visible and invisible\nwatermarking is determined. The proposed Hadamard transform domain method is\nmore robust again image/signal processing attacks. Furthermore, it also shows\nthat the proposed method confirm the efficiency through various performance\nanalysis and experimental results.\n", "versions": [{"version": "v1", "created": "Mon, 12 May 2014 16:45:21 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["S.", "Parvathavarthini", ""], ["R", "Shanthakumari", ""]]}, {"id": "1405.3622", "submitter": "Anh Le", "authors": "Anh Le, Lorenzo Keller, Hulya Seferoglu, Blerim Cici, Christina\n  Fragouli, Athina Markopoulou", "title": "MicroCast: Cooperative Video Streaming using Cellular and D2D\n  Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a group of mobile users, within proximity of each other, who are\ninterested in watching the same online video at roughly the same time. The\ncommon practice today is that each user downloads the video independently on\nher mobile device using her own cellular connection, which wastes access\nbandwidth and may also lead to poor video quality. We propose a novel\ncooperative system where each mobile device uses simultaneously two network\ninterfaces: (i) the cellular to connect to the video server and download parts\nof the video and (ii) WiFi to connect locally to all other devices in the group\nand exchange those parts. Devices cooperate to efficiently utilize all network\nresources and are able to adapt to varying wireless network conditions. In the\nlocal WiFi network, we exploit overhearing, and we further combine it with\nnetwork coding. The end result is savings in cellular bandwidth and improved\nuser experience (faster download) by a factor on the order up to the group\nsize.\n  We follow a complete approach, from theory to practice. First, we formulate\nthe problem using a network utility maximization (NUM) framework, decompose the\nproblem, and provide a distributed solution. Then, based on the structure of\nthe NUM solution, we design a modular system called MicroCast and we implement\nit as an Android application. We provide both simulation results of the NUM\nsolution and experimental evaluation of MicroCast on a testbed consisting of\nAndroid phones. We demonstrate that the proposed approach brings significant\nperformance benefits without battery penalty.\n", "versions": [{"version": "v1", "created": "Wed, 14 May 2014 18:55:26 GMT"}], "update_date": "2014-05-16", "authors_parsed": [["Le", "Anh", ""], ["Keller", "Lorenzo", ""], ["Seferoglu", "Hulya", ""], ["Cici", "Blerim", ""], ["Fragouli", "Christina", ""], ["Markopoulou", "Athina", ""]]}, {"id": "1405.4709", "submitter": "Gerardo Gomez", "authors": "Gerardo Gomez, Lorenzo Hortiguela, Quiliano Perez, Javier Lorca,\n  Raquel Garcia, Mari Carmen Aguayo-Torres", "title": "YouTube QoE Evaluation Tool for Android Wireless Terminals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an Android application which is able to evaluate\nand analyze the perceived Quality of Experience (QoE) for YouTube service in\nwireless terminals. To achieve this goal, the application carries out\nmeasurements of objective Quality of Service (QoS) parameters, which are then\nmapped onto subjective QoE (in terms of Mean Opinion Score, MOS) by means of a\nutility function. Our application also informs the user about potential causes\nthat lead to a low MOS as well as provides some hints to improve it. After each\nYouTube session, the users may optionally qualify the session through an online\nopinion survey. This information has been used in a pilot experience to\ncorrelate the theoretical QoE model with real user feedback. Results from such\nan experience have shown that the theoretical model (taken from the literature)\nprovides slightly more pessimistic results compared to user feedback. Users\nseem to be more indulgent with wireless connections, increasing the MOS from\nthe opinion survey in about 20% compared to the theoretical model, which was\nobtained from wired scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 13:10:09 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Gomez", "Gerardo", ""], ["Hortiguela", "Lorenzo", ""], ["Perez", "Quiliano", ""], ["Lorca", "Javier", ""], ["Garcia", "Raquel", ""], ["Aguayo-Torres", "Mari Carmen", ""]]}, {"id": "1405.4721", "submitter": "Erik Cuevas E", "authors": "Erik Cuevas, Daniel Zaldivar, Marco Perez-Cisneros and Diego Oliva", "title": "Block matching algorithm based on Differential Evolution for motion\n  estimation", "comments": "19 pages", "journal-ref": "Engineering Applications of Artificial Intelligence, 26 (1) ,\n  (2013), pp. 488-498", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion estimation is one of the major problems in developing video coding\napplications. Among all motion estimation approaches, Block matching (BM)\nalgorithms are the most popular methods due to their effectiveness and\nsimplicity for both software and hardware implementations. A BM approach\nassumes that the movement of pixels within a defined region of the current\nframe (Macro-Block, MB) can be modeled as a translation of pixels contained in\nthe previous frame. In this procedure, the motion vector is obtained by\nminimizing the sum of absolute differences (SAD) produced by the MB of the\ncurrent frame over a determined search window from the previous frame. The SAD\nevaluation is computationally expensive and represents the most consuming\noperation in the BM process. The most straightforward BM method is the full\nsearch algorithm (FSA) which finds the most accurate motion vector, calculating\nexhaustively the SAD values for all elements of the search window. Over this\ndecade, several fast BM algorithms have been proposed to reduce the number of\nSAD operations by calculating only a fixed subset of search locations at the\nprice of a poor accuracy. In this paper, a new algorithm based on Differential\nEvolution (DE) is proposed to reduce the number of search locations in the BM\nprocess. In order to avoid computing several search locations, the algorithm\nestimates the SAD values (fitness) for some locations using the SAD values of\npreviously calculated neighboring positions. Since the proposed algorithm does\nnot consider any fixed search pattern or other different assumption, a high\nprobability for finding the true minimum (accurate motion vector) is expected.\nIn comparison to other fast BM algorithms, the proposed method deploys more\naccurate motion vectors yet delivering competitive time rates.\n", "versions": [{"version": "v1", "created": "Fri, 16 May 2014 19:41:14 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Cuevas", "Erik", ""], ["Zaldivar", "Daniel", ""], ["Perez-Cisneros", "Marco", ""], ["Oliva", "Diego", ""]]}, {"id": "1405.4843", "submitter": "Daniele Giacobello", "authors": "Joshua Atkins and Daniele Giacobello", "title": "Trends and Perspectives for Signal Processing in Consumer Audio", "comments": "IEEE Audio and Acoustic Signal Processing Technical Committee\n  Newsletter, May 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The trend in media consumption towards streaming and portability offers new\nchallenges and opportunities for signal processing in audio and acoustics. The\nmost significant embodiment of this trend is that most music consumption now\nhappens on-the-go which has recently led to an explosion in headphone sales and\nsmall portable speakers. In particular, premium headphones offer a gateway for\na younger generation to experience high quality sound. Additionally, through\ntechnologies incorporating head-related transfer functions headphones can also\noffer unique new experiences in gaming, augmented reality, and surround sound\nlistening. Home audio has also seen a transition to smaller sound systems in\nthe form of sound bars. This speaker configuration offers many exciting\nchallenges for surround sound reproduction which has traditionally used five\nspeakers surrounding the listener. Furthermore, modern home entertainment\nsystems offer more than just content delivery; users now expect wireless and\nconnected smart devices with video conferencing, gaming, and other interactive\ncapabilities. With this comes challenges for voice interaction at a distance\nand in demanding conditions, e.g., during content playback, and opportunities\nfor new smart interactive experiences based on awareness of environment and\nuser biometrics.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 19:10:15 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Atkins", "Joshua", ""], ["Giacobello", "Daniele", ""]]}, {"id": "1405.5119", "submitter": "Sugata Sanyal", "authors": "Tanmoy Sarkar, Sugata Sanyal", "title": "Steganalysis: Detecting LSB Steganographic Techniques", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganalysis means analysis of stego images. Like cryptanalysis, steganalysis\nis used to detect messages often encrypted using secret key from stego images\nproduced by steganography techniques. Recently lots of new and improved\nsteganography techniques are developed and proposed by researchers which\nrequire robust steganalysis techniques to detect the stego images having\nminimum false alarm rate. This paper discusses about the different Steganalysis\ntechniques and help to understand how, where and when this techniques can be\nused based on different situations.\n", "versions": [{"version": "v1", "created": "Tue, 20 May 2014 15:21:52 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Sarkar", "Tanmoy", ""], ["Sanyal", "Sugata", ""]]}, {"id": "1405.5203", "submitter": "Ta Minh Thanh", "authors": "Ta Minh Thanh, Munetoshi Iwakiri", "title": "An Incomplete Cryptography based Digital Rights Management with DCFF", "comments": null, "journal-ref": "Journal of Soft Computing and Software Engineering [JSCSE], Vol.\n  3, No. 3, pp. 507-513, 2013", "doi": "10.7321/jscse.v3.n3.77", "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, DRM (Digital Rights Management) system is responsible for the\nsafe distribution of digital content, however, DRM system is achieved with\nindividual function modules of cryptography, watermarking and so on. In this\ntypical system flow, it has a problem that all original digital contents are\ntemporarily disclosed with perfect condition via decryption process. In this\npaper, we propose the combination of the differential codes and fragile\nfingerprinting (DCFF) method based on incomplete cryptography that holds\npromise for a better compromise between practicality and security for emerging\ndigital rights management applications. Experimental results with simulation\nconfirmed that DCFF keeps compatibility with standard JPEG codec, and revealed\nthat the proposed method is suitable for DRM in the network distribution\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 03:45:22 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Thanh", "Ta Minh", ""], ["Iwakiri", "Munetoshi", ""]]}, {"id": "1405.5340", "submitter": "Manish Kumar Thakur", "authors": "Manish K Thakur, Vikas Saxena and J P Gupta", "title": "A hybrid video quality metric for analyzing quality degradation due to\n  frame drop", "comments": "7 pages, 9 figures", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 6, No 1, November 2012", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In last decade, ever growing internet technologies provided platform to share\nthe multimedia data among different communities. As the ultimate users are\nhuman subjects who are concerned about quality of visual information, it is\noften desired to have good resumed perceptual quality of videos, thus arises\nthe need of quality assessment. This paper presents a full reference hybrid\nvideo quality metric which is capable to analyse the video quality for\nspatially or temporally (frame drop) or spatio-temporally distorted video\nsequences. Simulated results show that the metric efficiently analyses the\nquality degradation and more closer to the developed human visual system\n", "versions": [{"version": "v1", "created": "Wed, 21 May 2014 09:01:32 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Thakur", "Manish K", ""], ["Saxena", "Vikas", ""], ["Gupta", "J P", ""]]}, {"id": "1405.5948", "submitter": "Jing Liu", "authors": "Jing Liu, Fei Qiao, Zhijian Ou, Huazhong Yang", "title": "Low-complexity video encoder for smart eyes based on underdetermined\n  blind signal separation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a low complexity video coding method based on\nUnderdetermined Blind Signal Separation (UBSS). The detailed coding framework\nis designed. Three key techniques are proposed to enhance the compression ratio\nand the quality of the decoded frames. The experiments validate that the\nproposed method costs 30ms encoding time less than DISCOVER. The simulation\nshows that this new method can save 50% energy compared with H.264.\n", "versions": [{"version": "v1", "created": "Fri, 23 May 2014 02:24:11 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Liu", "Jing", ""], ["Qiao", "Fei", ""], ["Ou", "Zhijian", ""], ["Yang", "Huazhong", ""]]}, {"id": "1405.6147", "submitter": "Wesam Ahmed abdalsamea", "authors": "A.M. Raid, W.M. Khedr, M. A. El-dosuky, Wesam Ahmed", "title": "Jpeg Image Compression Using Discrete Cosine Transform - A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing requirements for transmission of images in computer,\nmobile environments, the research in the field of image compression has\nincreased significantly. Image compression plays a crucial role in digital\nimage processing, it is also very important for efficient transmission and\nstorage of images. When we compute the number of bits per image resulting from\ntypical sampling rates and quantization methods, we find that Image compression\nis needed. Therefore development of efficient techniques for image compression\nhas become necessary .This paper is a survey for lossy image compression using\nDiscrete Cosine Transform, it covers JPEG compression algorithm which is used\nfor full-colour still image applications and describes all the components of\nit.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 08:04:21 GMT"}], "update_date": "2014-05-26", "authors_parsed": [["Raid", "A. M.", ""], ["Khedr", "W. M.", ""], ["El-dosuky", "M. A.", ""], ["Ahmed", "Wesam", ""]]}, {"id": "1405.6434", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Lingbo Wang, Yanwen Guo", "title": "Multi-view Metric Learning for Multi-view Video Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods on video summarization are designed to generate summaries\nfor single-view video records; and thus they cannot fully exploit the\nredundancy in multi-view video records. In this paper, we present a multi-view\nmetric learning framework for multi-view video summarization that combines the\nadvantages of maximum margin clustering with the disagreement minimization\ncriterion. The learning framework thus has the ability to find a metric that\nbest separates the data, and meanwhile to force the learned metric to maintain\noriginal intrinsic information between data points, for example geometric\ninformation. Facilitated by such a framework, a systematic solution to the\nmulti-view video summarization problem is developed. To the best of our\nknowledge, it is the first time to address multi-view video summarization from\nthe viewpoint of metric learning. The effectiveness of the proposed method is\ndemonstrated by experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 May 2014 22:35:19 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 22:56:21 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Fu", "Yanwei", ""], ["Wang", "Lingbo", ""], ["Guo", "Yanwen", ""]]}, {"id": "1405.6661", "submitter": "Divyajyothi M G Ms", "authors": "Divyajyothi M G, Rachappa and D H Rao", "title": "A scenario based approach for dealing with challenges in a pervasive\n  computing environment", "comments": "8 pages, IJCSA, Vol 4, No.2,April 2014", "journal-ref": null, "doi": "10.5121/ijcsa.2014.4204", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the surge in modern research focus towards Pervasive Computing, lot of\ntechniques and challenges needs to be addressed so as to effectively create\nsmart spaces and achieve miniaturization. In the process of scaling down to\ncompact devices, the real things to ponder upon are the Information Retrieval\nchallenges. In this work, we discuss the aspects of multimedia which makes\ninformation access challenging. An Example Pattern Recognition scenario is\npresented and the mathematical techniques that can be used to model uncertainty\nare also presented for developing a system that can sense, compute and\ncommunicate in a way that can make human life easy with smart objects assisting\nfrom around his surroundings.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 07:16:46 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["G", "Divyajyothi M", ""], ["Rachappa", "", ""], ["Rao", "D H", ""]]}, {"id": "1405.7102", "submitter": "Tim Althoff", "authors": "Tim Althoff, Hyun Oh Song, Trevor Darrell", "title": "Detection Bank: An Object Detection Based Video Representation for\n  Multimedia Event Recognition", "comments": "ACM Multimedia 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While low-level image features have proven to be effective representations\nfor visual recognition tasks such as object recognition and scene\nclassification, they are inadequate to capture complex semantic meaning\nrequired to solve high-level visual tasks such as multimedia event detection\nand recognition. Recognition or retrieval of events and activities can be\nimproved if specific discriminative objects are detected in a video sequence.\nIn this paper, we propose an image representation, called Detection Bank, based\non the detection images from a large number of windowed object detectors where\nan image is represented by different statistics derived from these detections.\nThis representation is extended to video by aggregating the key frame level\nimage representations through mean and max pooling. We empirically show that it\ncaptures complementary information to state-of-the-art representations such as\nSpatial Pyramid Matching and Object Bank. These descriptors combined with our\nDetection Bank representation significantly outperforms any of the\nrepresentations alone on TRECVID MED 2011 data.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 02:07:29 GMT"}, {"version": "v2", "created": "Sat, 14 Jun 2014 20:17:48 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Althoff", "Tim", ""], ["Song", "Hyun Oh", ""], ["Darrell", "Trevor", ""]]}, {"id": "1405.7452", "submitter": "Tim Althoff", "authors": "Tim Althoff, Damian Borth, J\\\"orn Hees, Andreas Dengel", "title": "Analysis and Forecasting of Trending Topics in Online Media Streams", "comments": "ACM Multimedia 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the vast information available on the web, social media streams capture\nwhat people currently pay attention to and how they feel about certain topics.\nAwareness of such trending topics plays a crucial role in multimedia systems\nsuch as trend aware recommendation and automatic vocabulary selection for video\nconcept detection systems.\n  Correctly utilizing trending topics requires a better understanding of their\nvarious characteristics in different social media streams. To this end, we\npresent the first comprehensive study across three major online and social\nmedia streams, Twitter, Google, and Wikipedia, covering thousands of trending\ntopics during an observation period of an entire year. Our results indicate\nthat depending on one's requirements one does not necessarily have to turn to\nTwitter for information about current events and that some media streams\nstrongly emphasize content of specific categories. As our second key\ncontribution, we further present a novel approach for the challenging task of\nforecasting the life cycle of trending topics in the very moment they emerge.\nOur fully automated approach is based on a nearest neighbor forecasting\ntechnique exploiting our assumption that semantically similar topics exhibit\nsimilar behavior.\n  We demonstrate on a large-scale dataset of Wikipedia page view statistics\nthat forecasts by the proposed approach are about 9-48k views closer to the\nactual viewing statistics compared to baseline methods and achieve a mean\naverage percentage error of 45-19% for time periods of up to 14 days.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 03:43:41 GMT"}, {"version": "v2", "created": "Sat, 14 Jun 2014 20:14:07 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Althoff", "Tim", ""], ["Borth", "Damian", ""], ["Hees", "J\u00f6rn", ""], ["Dengel", "Andreas", ""]]}, {"id": "1405.7571", "submitter": "Bin Li", "authors": "Bin Li, Tian-Tsong Ng, Xiaolong Li, Shunquan Tan, and Jiwu Huang", "title": "JPEG Noises beyond the First Compression Cycle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the JPEG noises, which include the quantization noise\nand the rounding noise, during a JPEG compression cycle. The JPEG noises in the\nfirst compression cycle have been well studied; however, so far less attention\nhas been paid on the JPEG noises in higher compression cycles. In this work, we\npresent a statistical analysis on JPEG noises beyond the first compression\ncycle. To our knowledge, this is the first work on this topic. We find that the\nnoise distributions in higher compression cycles are different from those in\nthe first compression cycle, and they are dependent on the quantization\nparameters used between two successive cycles. To demonstrate the benefits from\nthe statistical analysis, we provide two applications that can employ the\nderived noise distributions to uncover JPEG compression history with\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 14:43:55 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Li", "Bin", ""], ["Ng", "Tian-Tsong", ""], ["Li", "Xiaolong", ""], ["Tan", "Shunquan", ""], ["Huang", "Jiwu", ""]]}, {"id": "1405.7629", "submitter": "Abbas Bradai", "authors": "Abbas Bradai (LaBRI), Toufik Ahmed (LaBRI), Samir Medjiah (LaBRI)", "title": "QoE assessment for SVC streaming in ENVISION", "comments": "IEEE 20th International Conference on Electronics, Circuits, and\n  Systems (IEEE ICECS 2013), Abu Dhabi : United Arab Emirates (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable video coding has drawn great interest in content delivery in many\nmultimedia services thanks to its capability to handle terminal heterogeneity\nand network conditions variation. In our previous work, and under the umbrella\nof ENVISION, we have proposed a playout smoothing mechanism to ensure the\nuniform delivery of the layered stream, by reducing the quality changes that\nthe stream undergoes when adapting to changing network conditions. In this\npaper we study the resulting video quality, from the final user perception\nunder different network conditions of loss and delays. For that we have adopted\nthe Double Stimulus Impairment Scale (DSIS) method. The results show that the\nMean Opinion Score for the smoothed video clips was higher under different\nnetwork configuration. This confirms the effectiveness of the proposed\nsmoothing mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 28 May 2014 17:15:51 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Bradai", "Abbas", "", "LaBRI"], ["Ahmed", "Toufik", "", "LaBRI"], ["Medjiah", "Samir", "", "LaBRI"]]}]