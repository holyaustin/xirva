[{"id": "1112.2027", "submitter": "JaeDeok Lim", "authors": "JaeDeok Lim, ByeongCheol Choi, SeungWan Han, ChoelHoon Lee", "title": "Automatic Classification of X-rated Videos using Obscene Sound Analysis\n  based on a Repeated Curve-like Spectrum Feature", "comments": "18 pages, 5 figures, 11 tables, IJMA(The International Journal of\n  Multimedia & Its Applications)", "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.3, No.4, November 2011, pp.1-17", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the automatic classification of X-rated videos by\nanalyzing its obscene sounds. In this paper, obscene sounds refer to audio\nsignals generated from sexual moans and screams during sexual scenes. By\nanalyzing various sound samples, we determined the distinguishable\ncharacteristics of obscene sounds and propose a repeated curve-like spectrum\nfeature that represents the characteristics of such sounds. We constructed\n6,269 audio clips to evaluate the proposed feature, and separately constructed\n1,200 X-rated and general videos for classification. The proposed feature has\nan F1-score, precision, and recall rate of 96.6%, 98.2%, and 95.2%,\nrespectively, for the original dataset, and 92.6%, 97.6%, and 88.0% for a noisy\ndataset of 5dB SNR. And, in classifying videos, the feature has more than a 90%\nF1-score, 97% precision, and an 84% recall rate. From the measured performance,\nX-rated videos can be classified with only the audio features and the repeated\ncurve-like spectrum feature is suitable to detect obscene sounds.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 07:05:49 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Lim", "JaeDeok", ""], ["Choi", "ByeongCheol", ""], ["Han", "SeungWan", ""], ["Lee", "ChoelHoon", ""]]}, {"id": "1112.2040", "submitter": "V. Vijayakumar", "authors": "Vijayakumar V and Nedunchezhian R", "title": "Recent Trends and Research Issues in Video Association Mining", "comments": "13 pages; 1 Figure; 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-growing digital libraries and video databases, it is\nincreasingly important to understand and mine the knowledge from video database\nautomatically. Discovering association rules between items in a large video\ndatabase plays a considerable role in the video data mining research areas.\nBased on the research and development in the past years, application of\nassociation rule mining is growing in different domains such as surveillance,\nmeetings, broadcast news, sports, archives, movies, medical data, as well as\npersonal and online media collections. The purpose of this paper is to provide\ngeneral framework of mining the association rules from video database. This\narticle is also represents the research issues in video association mining\nfollowed by the recent trends.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 08:16:03 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["V", "Vijayakumar", ""], ["R", "Nedunchezhian", ""]]}, {"id": "1112.2042", "submitter": "Saleh Omari", "authors": "Saleh Ali Alomari, Putra Sumari", "title": "Statistical Information of the Increased Demand for Watch the VOD with\n  the Increased Sophistication in the Mobile Devices,Communications and\n  Internet Penetration in Asia", "comments": "17 pages, 17 figures, 4 tables; The International Journal of\n  Multimedia & Its Applications (IJMA) Vol.3, No.4, November 2011", "journal-ref": null, "doi": "10.5121/ijma.2011.3415", "report-no": null, "categories": "cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  As the rapid progress of the media streaming applications such as video\nstreaming can be classified into two types of streaming, Live video streaming,\nVideo on Demand (VoD). Live video streaming is a service which allows the\nclients to watch many TV channels over the internet and the clients able to use\none operation to perform is to switch the channels. Video on Demand (VoD) is\none of the most important applications for the internet of the future and has\nbecome an interactive multimedia service which allows the users to start\nwatching the video of their choice at anytime and anywhere, especially after\nthe rapid deployment of the wireless networks and mobile devices. In this paper\nprovide statistical information about the Internet, communications and mobile\ndevices etc. This has led to an increased demand for the development,\ncommunication and computational powers of many of the mobile wireless\nsubscribers/mobile devices such as laptops, PDAs, smart phones and notebook.\nThese techniques are utilized to obtain a video on demand service with higher\nresolution and quality. Another objective in this paper is to see Malaysia\nranked as a fully developed country by the year 2020.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 08:26:23 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Alomari", "Saleh Ali", ""], ["Sumari", "Putra", ""]]}, {"id": "1112.2044", "submitter": "Surekha Mariam Varghese Dr.", "authors": "Kurien Zacharia, Eldo P. Elias, Surekha Mariam Varghese", "title": "Modelling Gesture Based Ubiquitous Applications", "comments": "10 pages; The International Journal of Multimedia & Its Applications\n  (IJMA) Vol.3, No.4, November 2011", "journal-ref": null, "doi": "10.5121/ijma.2011.3403", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A cost effective, gesture based modelling technique called Virtual\nInteractive Prototyping (VIP) is described in this paper. Prototyping is\nimplemented by projecting a virtual model of the equipment to be prototyped.\nUsers can interact with the virtual model like the original working equipment.\nFor capturing and tracking the user interactions with the model image and sound\nprocessing techniques are used. VIP is a flexible and interactive prototyping\nmethod that has much application in ubiquitous computing environments.\nDifferent commercial as well as socio-economic applications and extension to\ninteractive advertising of VIP are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 08:35:14 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Zacharia", "Kurien", ""], ["Elias", "Eldo P.", ""], ["Varghese", "Surekha Mariam", ""]]}, {"id": "1112.2261", "submitter": "Sm Thamarai", "authors": "Dr. T.Meyyappan, SM.Thamarai and N.M.Jeya Nachiaban", "title": "Lossless Digital Image Compression Method for Bitmap Images", "comments": "10 pages, 7 figures, presented in First International Conference on\n  Digital Image Processing and Pattern Recognition (DPPR-2011)In conjunction\n  with (CCSEIT-2011), Manonmaniam Sundharanar University, September 23~25,\n  2011, Tirunelveli, Tamil Nadu, India", "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.3, No.4, November 2011", "doi": "10.5121/ijma.2011.3407", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research paper, the authors propose a new approach to digital image\ncompression using crack coding This method starts with the original image and\ndevelop crack codes in a recursive manner, marking the pixels visited earlier\nand expanding the entropy in four directions. The proposed method is\nexperimented with sample bitmap images and results are tabulated. The method is\nimplemented in uni-processor machine using C language source code.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2011 08:34:51 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Meyyappan", "Dr. T.", ""], ["Thamarai", "SM.", ""], ["Nachiaban", "N. M. Jeya", ""]]}, {"id": "1112.2809", "submitter": "Rosziati Ibrahim Dr.", "authors": "Rosziati Ibrahim and Teoh Suk Kuan", "title": "Steganography Algorithm to Hide Secret Message inside an Image", "comments": "7 pages, 7 figures", "journal-ref": "Computer Technology and Application 2 (2011) 102-108", "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the authors propose a new algorithm to hide data inside image\nusing steganography technique. The proposed algorithm uses binary codes and\npixels inside an image. The zipped file is used before it is converted to\nbinary codes to maximize the storage of data inside the image. By applying the\nproposed algorithm, a system called Steganography Imaging System (SIS) is\ndeveloped. The system is then tested to see the viability of the proposed\nalgorithm. Various sizes of data are stored inside the images and the PSNR\n(Peak signal-to-noise ratio) is also captured for each of the images tested.\nBased on the PSNR value of each images, the stego image has a higher PSNR\nvalue. Hence this new steganography algorithm is very efficient to hide the\ndata inside the image.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 06:56:25 GMT"}], "update_date": "2011-12-14", "authors_parsed": [["Ibrahim", "Rosziati", ""], ["Kuan", "Teoh Suk", ""]]}, {"id": "1112.3873", "submitter": "Nicolas Friot", "authors": "Nicolas Friot, Christophe Guyeux, and Jacques M. Bahi", "title": "Chaotic iterations for steganography: Stego-security and\n  topological-security", "comments": "15 pages; 3 figures; SECRYPT 2011: International Conference on\n  Security and Cryptography, Seville, Spain, 18-21 July", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM math.DS math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper is proposed a novel steganographic scheme based on chaotic\niterations. This research work takes place into the information hiding security\nfields. We show that the proposed scheme is stego-secure, which is the highest\nlevel of security in a well defined and studied category of attack called\n\"watermark-only attack\". Additionally, we prove that this scheme presents\ntopological properties so that it is one of the firsts able to face, at least\npartially, an adversary when considering the others categories of attacks\ndefined in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 16:12:07 GMT"}], "update_date": "2011-12-19", "authors_parsed": [["Friot", "Nicolas", ""], ["Guyeux", "Christophe", ""], ["Bahi", "Jacques M.", ""]]}, {"id": "1112.3874", "submitter": "Nicolas Friot", "authors": "Christophe Guyeux, Nicolas Friot, and Jacques M. Bahi", "title": "Chaotic iterations versus Spread-spectrum: topological-security and\n  stego-security", "comments": "2 figures; 10 pages; IIH-MSP 2010: The Sixth International Conference\n  on Intelligent Information Hiding and Multimedia Signal Processing, October\n  15-17, 2010 Darmstadt, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM math.DS math.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new framework for information hiding security, called topological-security,\nhas been proposed in a previous study. It is based on the evaluation of\nunpredictability of the scheme, whereas existing notions of security, as\nstego-security, are more linked to information leaks. It has been proven that\nspread-spectrum techniques, a well-known stego-secure scheme, are\ntopologically-secure too. In this paper, the links between the two notions of\nsecurity is deepened and the usability of topological-security is clarified, by\npresenting a novel data hiding scheme that is twice stego and\ntopological-secure. This last scheme has better scores than spread-spectrum\nwhen evaluating qualitative and quantitative topological-security properties.\nIncidentally, this result shows that the new framework for security tends to\nimprove the ability to compare data hiding scheme.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 16:12:49 GMT"}], "update_date": "2011-12-19", "authors_parsed": [["Guyeux", "Christophe", ""], ["Friot", "Nicolas", ""], ["Bahi", "Jacques M.", ""]]}, {"id": "1112.4084", "submitter": "Nicholas Mastronarde", "authors": "Nicholas Mastronarde, Karim Kanoun, David Atienza, Pascal Frossard,\n  Mihaela van der Schaar", "title": "Markov Decision Process Based Energy-Efficient On-Line Scheduling for\n  Slice-Parallel Video Decoders on Multicore Systems", "comments": null, "journal-ref": "IEEE Trans. on Multimedia, vol. 15, no. 2, pp. 268-278, Feb. 2013", "doi": "10.1109/TMM.2012.2231668", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of energy-efficient on-line scheduling for\nslice-parallel video decoders on multicore systems. We assume that each of the\nprocessors are Dynamic Voltage Frequency Scaling (DVFS) enabled such that they\ncan independently trade off performance for power, while taking the video\ndecoding workload into account. In the past, scheduling and DVFS policies in\nmulti-core systems have been formulated heuristically due to the inherent\ncomplexity of the on-line multicore scheduling problem. The key contribution of\nthis report is that we rigorously formulate the problem as a Markov decision\nprocess (MDP), which simultaneously takes into account the on-line scheduling\nand per-core DVFS capabilities; the power consumption of the processor cores\nand caches; and the loss tolerant and dynamic nature of the video decoder's\ntraffic. In particular, we model the video traffic using a Direct Acyclic Graph\n(DAG) to capture the precedence constraints among frames in a Group of Pictures\n(GOP) structure, while also accounting for the fact that frames have different\ndisplay/decoding deadlines and non-deterministic decoding complexities. The\nobjective of the MDP is to minimize long-term power consumption subject to a\nminimum Quality of Service (QoS) constraint related to the decoder's\nthroughput. Although MDPs notoriously suffer from the curse of dimensionality,\nwe show that, with appropriate simplifications and approximations, the\ncomplexity of the MDP can be mitigated. We implement a slice-parallel version\nof H.264 on a multiprocessor ARM (MPARM) virtual platform simulator, which\nprovides cycle-accurate and bus signal-accurate simulation for different\nprocessors. We use this platform to generate realistic video decoding traces\nwith which we evaluate the proposed on-line scheduling algorithm in Matlab.\n", "versions": [{"version": "v1", "created": "Sat, 17 Dec 2011 20:22:27 GMT"}, {"version": "v2", "created": "Fri, 25 May 2012 00:21:25 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Mastronarde", "Nicholas", ""], ["Kanoun", "Karim", ""], ["Atienza", "David", ""], ["Frossard", "Pascal", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1112.4243", "submitter": "Ziqiang Shi", "authors": "Ziqiang Shi and Jiqing Han and Tieran Zheng and Shiwen Deng", "title": "Online Learning for Classification of Low-rank Representation Features\n  and Its Applications in Audio Segment Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel framework based on trace norm minimization for audio\nsegment is proposed. In this framework, both the feature extraction and\nclassification are obtained by solving corresponding convex optimization\nproblem with trace norm regularization. For feature extraction, robust\nprinciple component analysis (robust PCA) via minimization a combination of the\nnuclear norm and the $\\ell_1$-norm is used to extract low-rank features which\nare robust to white noise and gross corruption for audio segments. These\nlow-rank features are fed to a linear classifier where the weight and bias are\nlearned by solving similar trace norm constrained problems. For this\nclassifier, most methods find the weight and bias in batch-mode learning, which\nmakes them inefficient for large-scale problems. In this paper, we propose an\nonline framework using accelerated proximal gradient method. This framework has\na main advantage in memory cost. In addition, as a result of the regularization\nformulation of matrix classification, the Lipschitz constant was given\nexplicitly, and hence the step size estimation of general proximal gradient\nmethod was omitted in our approach. Experiments on real data sets for\nlaugh/non-laugh and applause/non-applause classification indicate that this\nnovel framework is effective and noise robust.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 05:29:18 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Shi", "Ziqiang", ""], ["Han", "Jiqing", ""], ["Zheng", "Tieran", ""], ["Deng", "Shiwen", ""]]}, {"id": "1112.5493", "submitter": "John Scoville", "authors": "John Scoville", "title": "Critical Data Compression", "comments": "99 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach to data compression is developed and applied to multimedia\ncontent. This method separates messages into components suitable for both\nlossless coding and 'lossy' or statistical coding techniques, compressing\ncomplex objects by separately encoding signals and noise. This is demonstrated\nby compressing the most significant bits of data exactly, since they are\ntypically redundant and compressible, and either fitting a maximally likely\nnoise function to the residual bits or compressing them using lossy methods.\nUpon decompression, the significant bits are decoded and added to a noise\nfunction, whether sampled from a noise model or decompressed from a lossy code.\nThis results in compressed data similar to the original. For many test images,\na two-part image code using JPEG2000 for lossy coding and PAQ8l for lossless\ncoding produces less mean-squared error than an equal length of JPEG2000.\nComputer-generated images typically compress better using this method than\nthrough direct lossy coding, as do many black and white photographs and most\ncolor photographs at sufficiently high quality levels. Examples applying the\nmethod to audio and video coding are also demonstrated. Since two-part codes\nare efficient for both periodic and chaotic data, concatenations of roughly\nsimilar objects may be encoded efficiently, which leads to improved inference.\nApplications to artificial intelligence are demonstrated, showing that signals\nusing an economical lossless code have a critical level of redundancy which\nleads to better description-based inference than signals which encode either\ninsufficient data or too much detail.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 00:17:46 GMT"}], "update_date": "2011-12-26", "authors_parsed": [["Scoville", "John", ""]]}]