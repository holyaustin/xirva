[{"id": "1008.0502", "submitter": "Akisato Kimura", "authors": "Akamine Kazuma, Ken Fukuchi, Akisato Kimura and Shigeru Takagi", "title": "Fully automatic extraction of salient objects from videos in near\n  real-time", "comments": "submitted to Special Issue on High Performance Computation on\n  Hardware Accelerators, the Computer Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic video segmentation plays an important role in a wide range of\ncomputer vision and image processing applications. Recently, various methods\nhave been proposed for this purpose. The problem is that most of these methods\nare far from real-time processing even for low-resolution videos due to the\ncomplex procedures. To this end, we propose a new and quite fast method for\nautomatic video segmentation with the help of 1) efficient optimization of\nMarkov random fields with polynomial time of number of pixels by introducing\ngraph cuts, 2) automatic, computationally efficient but stable derivation of\nsegmentation priors using visual saliency and sequential update mechanism, and\n3) an implementation strategy in the principle of stream processing with\ngraphics processor units (GPUs). Test results indicates that our method\nextracts appropriate regions from videos as precisely as and much faster than\nprevious semi-automatic methods even though any supervisions have not been\nincorporated.\n", "versions": [{"version": "v1", "created": "Tue, 3 Aug 2010 10:00:07 GMT"}, {"version": "v2", "created": "Fri, 13 Aug 2010 02:27:15 GMT"}], "update_date": "2010-08-16", "authors_parsed": [["Kazuma", "Akamine", ""], ["Fukuchi", "Ken", ""], ["Kimura", "Akisato", ""], ["Takagi", "Shigeru", ""]]}, {"id": "1008.0757", "submitter": "Zhineng Chen", "authors": "Zhineng Chen, Juan Cao, Yicheng Song, Yongdong Zhang, Jintao Li", "title": "Web Video Categorization based on Wikipedia Categories and\n  Content-Duplicated Open Resources", "comments": "4 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for web video categorization by\nleveraging Wikipedia categories (WikiCs) and open resources describing the same\ncontent as the video, i.e., content-duplicated open resources (CDORs). Note\nthat current approaches only col-lect CDORs within one or a few media forms and\nignore CDORs of other forms. We explore all these resources by utilizing WikiCs\nand commercial search engines. Given a web video, its discrimin-ative Wikipedia\nconcepts are first identified and classified. Then a textual query is\nconstructed and from which CDORs are collected. Based on these CDORs, we\npropose to categorize web videos in the space spanned by WikiCs rather than\nthat spanned by raw tags. Experimental results demonstrate the effectiveness of\nboth the proposed CDOR collection method and the WikiC voting catego-rization\nalgorithm. In addition, the categorization model built based on both WikiCs and\nCDORs achieves better performance compared with the models built based on only\none of them as well as state-of-the-art approach.\n", "versions": [{"version": "v1", "created": "Wed, 4 Aug 2010 12:01:39 GMT"}], "update_date": "2010-08-05", "authors_parsed": [["Chen", "Zhineng", ""], ["Cao", "Juan", ""], ["Song", "Yicheng", ""], ["Zhang", "Yongdong", ""], ["Li", "Jintao", ""]]}, {"id": "1008.2824", "submitter": "S Geetha", "authors": "S. Geetha and N. Kamaraj", "title": "Optimized Image Steganalysis through Feature Selection using MBEGA", "comments": "15 pages, IEEE NetCom 2009 Conference, IJCNC Journal", "journal-ref": "International Journal of Computer Networks & Communications 2.4\n  (2010) 161-175", "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature based steganalysis, an emerging branch in information forensics, aims\nat identifying the presence of a covert communication by employing the\nstatistical features of the cover and stego image as clues/evidences. Due to\nthe large volumes of security audit data as well as complex and dynamic\nproperties of steganogram behaviours, optimizing the performance of\nsteganalysers becomes an important open problem. This paper is focussed at fine\ntuning the performance of six promising steganalysers in this field, through\nfeature selection. We propose to employ Markov Blanket-Embedded Genetic\nAlgorithm (MBEGA) for stego sensitive feature selection process. In particular,\nthe embedded Markov blanket based memetic operators add or delete features (or\ngenes) from a genetic algorithm (GA) solution so as to quickly improve the\nsolution and fine-tune the search. Empirical results suggest that MBEGA is\neffective and efficient in eliminating irrelevant and redundant features based\non both Markov blanket and predictive power in classifier model. Observations\nshow that the proposed method is superior in terms of number of selected\nfeatures, classification accuracy and computational cost than their existing\ncounterparts.\n", "versions": [{"version": "v1", "created": "Tue, 17 Aug 2010 05:57:36 GMT"}], "update_date": "2010-08-18", "authors_parsed": [["Geetha", "S.", ""], ["Kamaraj", "N.", ""]]}, {"id": "1008.3741", "submitter": "Wei Yang", "authors": "Wei Yang, Wanlu Sun, Lihua Li", "title": "Reliable Multicasting for Device-to-Device Radio Underlaying Cellular\n  Networks", "comments": "This paper has been withdrawn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Leader in Charge (LiC), a reliable multicast architecture\nfor device-to-device (D2D) radio underlaying cellular networks. The\nmulticast-requesting user equipments (UEs) in close proximity form a D2D\ncluster to receive the multicast packets through cooperation. In addition to\nreceiving the multicast packets from the eNB, UEs share what they received from\nthe multicast on short-range links among UEs, namely the D2D links, to exploit\nthe wireless resources a more efficient way. Consequently, we show that\nutilizing the D2D links in cellular networks increases the throughput of a\nmulticast session by means of simulation. We also discuss some practical issues\nfacing the integration of LiC into the current cellular networks. In\nparticular, we propose efficient delay control mechanism to reduce the average\nand maximum delay experienced by LiC users, which is further confirmed by the\nsimulation results.\n", "versions": [{"version": "v1", "created": "Mon, 23 Aug 2010 03:06:22 GMT"}, {"version": "v2", "created": "Sun, 4 Mar 2012 22:07:22 GMT"}], "update_date": "2012-03-06", "authors_parsed": [["Yang", "Wei", ""], ["Sun", "Wanlu", ""], ["Li", "Lihua", ""]]}, {"id": "1008.4406", "submitter": "Fangwen Fu", "authors": "Fangwen Fu, and Mihaela van der Schaar", "title": "Structural Solutions to Dynamic Scheduling for Multimedia Transmission\n  in Unknown Wireless Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a systematic solution to the problem of scheduling\ndelay-sensitive media data for transmission over time-varying wireless\nchannels. We first formulate the dynamic scheduling problem as a Markov\ndecision process (MDP) that explicitly considers the users' heterogeneous\nmultimedia data characteristics (e.g. delay deadlines, distortion impacts and\ndependencies etc.) and time-varying channel conditions, which are not\nsimultaneously considered in state-of-the-art packet scheduling algorithms.\nThis formulation allows us to perform foresighted decisions to schedule\nmultiple data units for transmission at each time in order to optimize the\nlong-term utilities of the multimedia applications. The heterogeneity of the\nmedia data enables us to express the transmission priorities between the\ndifferent data units as a priority graph, which is a directed acyclic graph\n(DAG). This priority graph provides us with an elegant structure to decompose\nthe multi-data unit foresighted decision at each time into multiple single-data\nunit foresighted decisions which can be performed sequentially, from the high\npriority data units to the low priority data units, thereby significantly\nreducing the computation complexity. When the statistical knowledge of the\nmultimedia data characteristics and channel conditions is unknown a priori, we\ndevelop a low-complexity online learning algorithm to update the value\nfunctions which capture the impact of the current decision on the future\nutility. The simulation results show that the proposed solution significantly\noutperforms existing state-of-the-art scheduling solutions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Aug 2010 23:06:39 GMT"}], "update_date": "2010-08-27", "authors_parsed": [["Fu", "Fangwen", ""], ["van der Schaar", "Mihaela", ""]]}]