[{"id": "1209.0410", "submitter": "George Teodoro", "authors": "George Teodoro, Eduardo Valle, Nathan Mariano, Ricardo Torres, Wagner\n  Meira Jr, Joel H. Saltz", "title": "Approximate Similarity Search for Online Multimedia Services on\n  Distributed CPU-GPU Platforms", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.DB cs.DC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Similarity search in high-dimentional spaces is a pivotal operation found a\nvariety of database applications. Recently, there has been an increase interest\nin similarity search for online content-based multimedia services. Those\nservices, however, introduce new challenges with respect to the very large\nvolumes of data that have to be indexed/searched, and the need to minimize\nresponse times observed by the end-users. Additionally, those users dynamically\ninteract with the systems creating fluctuating query request rates, requiring\nthe search algorithm to adapt in order to better utilize the underline hardware\nto reduce response times. In order to address these challenges, we introduce\nhypercurves, a flexible framework for answering approximate k-nearest neighbor\n(kNN) queries for very large multimedia databases, aiming at online\ncontent-based multimedia services. Hypercurves executes on hybrid CPU--GPU\nenvironments, and is able to employ those devices cooperatively to support\nmassive query request rates. In order to keep the response times optimal as the\nrequest rates vary, it employs a novel dynamic scheduler to partition the work\nbetween CPU and GPU. Hypercurves was throughly evaluated using a large database\nof multimedia descriptors. Its cooperative CPU--GPU execution achieved\nperformance improvements of up to 30x when compared to the single CPU-core\nversion. The dynamic work partition mechanism reduces the observed query\nresponse times in about 50% when compared to the best static CPU--GPU task\npartition configuration. In addition, Hypercurves achieves superlinear\nscalability in distributed (multi-node) executions, while keeping a high\nguarantee of equivalence with its sequential version --- thanks to the proof of\nprobabilistic equivalence, which supported its aggressive parallelization\ndesign.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2012 17:12:59 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["Teodoro", "George", ""], ["Valle", "Eduardo", ""], ["Mariano", "Nathan", ""], ["Torres", "Ricardo", ""], ["Meira", "Wagner", "Jr"], ["Saltz", "Joel H.", ""]]}, {"id": "1209.0442", "submitter": "Nectaria Gizani Dr", "authors": "Eleni E. Varsaki, Nectaria A. B. Gizani, Vassilis Fotopoulos and\n  Athanassios N. Skodras", "title": "Alternative Astronomical FITS imaging", "comments": "2 pages, conference, The 11th Asian-Pacific Regional IAU Meeting\n  2011, NARIT Conference Series, Vol. 1, S. Komonjinda, Y. Kovalev, and D.\n  Ruffolo, eds", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.MM physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astronomical radio maps are presented mainly in FITS format. Astronomical\nImage Processing Software (AIPS) uses a set of tables attached to the output\nmap to include all sorts of information concerning the production of the image.\nHowever this information together with information on the flux and noise of the\nmap is lost as soon as the image of the radio source in fits or other format is\nextracted from AIPS. This information would have been valuable to another\nastronomer who just uses NED, for example, to download the map. In the current\nwork, we show a method of data hiding inside the radio map, which can be\npreserved under transformations, even for example while the format of the map\nis changed from fits to other lossless available image formats.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2012 19:25:23 GMT"}], "update_date": "2012-09-04", "authors_parsed": [["Varsaki", "Eleni E.", ""], ["Gizani", "Nectaria A. B.", ""], ["Fotopoulos", "Vassilis", ""], ["Skodras", "Athanassios N.", ""]]}, {"id": "1209.0841", "submitter": "Xi Peng", "authors": "Xi Peng, Zhiding Yu, Huajin Tang, Zhang Yi", "title": "Constructing the L2-Graph for Robust Subspace Learning and Subspace\n  Clustering", "comments": null, "journal-ref": "IEEE Trans. on Cybernetics, vol. 47, no. 4, pp. 1053-1066, Apr.\n  2017", "doi": "10.1109/TCYB.2016.2536752", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the framework of graph-based learning, the key to robust subspace\nclustering and subspace learning is to obtain a good similarity graph that\neliminates the effects of errors and retains only connections between the data\npoints from the same subspace (i.e., intra-subspace data points). Recent works\nachieve good performance by modeling errors into their objective functions to\nremove the errors from the inputs. However, these approaches face the\nlimitations that the structure of errors should be known prior and a complex\nconvex problem must be solved. In this paper, we present a novel method to\neliminate the effects of the errors from the projection space (representation)\nrather than from the input space. We first prove that $\\ell_1$-, $\\ell_2$-,\n$\\ell_{\\infty}$-, and nuclear-norm based linear projection spaces share the\nproperty of Intra-subspace Projection Dominance (IPD), i.e., the coefficients\nover intra-subspace data points are larger than those over inter-subspace data\npoints. Based on this property, we introduce a method to construct a sparse\nsimilarity graph, called L2-Graph. The subspace clustering and subspace\nlearning algorithms are developed upon L2-Graph. Experiments show that L2-Graph\nalgorithms outperform the state-of-the-art methods for feature extraction,\nimage clustering, and motion segmentation in terms of accuracy, robustness, and\ntime efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 01:36:11 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 01:52:37 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2012 09:41:24 GMT"}, {"version": "v4", "created": "Sun, 11 Nov 2012 06:17:34 GMT"}, {"version": "v5", "created": "Tue, 5 Mar 2013 06:58:31 GMT"}, {"version": "v6", "created": "Tue, 17 Sep 2013 02:42:04 GMT"}, {"version": "v7", "created": "Sat, 17 Jan 2015 12:00:47 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Peng", "Xi", ""], ["Yu", "Zhiding", ""], ["Tang", "Huajin", ""], ["Yi", "Zhang", ""]]}, {"id": "1209.1125", "submitter": "Jamel Slimi", "authors": "Jamel Slimi, Anis Ben Ammar and Adel M. Alimi", "title": "Video Data Visualization System: Semantic Classification And\n  Personalization", "comments": "graphics", "journal-ref": null, "doi": "10.5121/ijcga.2012.2201", "report-no": null, "categories": "cs.IR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper an intelligent video data visualization tool, based\non semantic classification, for retrieving and exploring a large scale corpus\nof videos. Our work is based on semantic classification resulting from semantic\nanalysis of video. The obtained classes will be projected in the visualization\nspace. The graph is represented by nodes and edges, the nodes are the keyframes\nof video documents and the edges are the relation between documents and the\nclasses of documents. Finally, we construct the user's profile, based on the\ninteraction with the system, to render the system more adequate to its\nreferences.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 21:28:32 GMT"}], "update_date": "2012-09-07", "authors_parsed": [["Slimi", "Jamel", ""], ["Ammar", "Anis Ben", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1209.1399", "submitter": "John MacCormick", "authors": "John MacCormick", "title": "Video Chat with Multiple Cameras", "comments": "49 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant paradigm for video chat employs a single camera at each end of\nthe conversation, but some conversations can be greatly enhanced by using\nmultiple cameras at one or both ends. This paper provides the first rigorous\ninvestigation of multi-camera video chat, concentrating especially on the\nability of users to switch between views at either end of the conversation. A\nuser study of 23 individuals analyzes the advantages and disadvantages of\npermitting a user to switch between views at a remote location. Benchmark\nexperiments employing up to four webcams simultaneously demonstrate that\nmulti-camera video chat is feasible on consumer hardware. The paper also\npresents the design of MultiCam, a software package permitting multi-camera\nvideo chat. Some important trade-offs in the design of MultiCam are discussed,\nand typical usage scenarios are analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2012 20:10:02 GMT"}], "update_date": "2012-09-10", "authors_parsed": [["MacCormick", "John", ""]]}, {"id": "1209.1673", "submitter": "Shujun Li Dr.", "authors": "Shujun Li and Andreas Karrenbauer and Dietmar Saupe and C.-C. Jay Kuo", "title": "Recovering Missing Coefficients in DCT-Transformed Images", "comments": "4 pages, 4 figures", "journal-ref": "Proceedings of 2011 18th IEEE International Conference on Image\n  Processing (ICIP 2011), pages 1537-1540, IEEE, 2011", "doi": "10.1109/ICIP.2011.6115738", "report-no": null, "categories": "cs.MM cs.CR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general method for recovering missing DCT coefficients in DCT-transformed\nimages is presented in this work. We model the DCT coefficients recovery\nproblem as an optimization problem and recover all missing DCT coefficients via\nlinear programming. The visual quality of the recovered image gradually\ndecreases as the number of missing DCT coefficients increases. For some images,\nthe quality is surprisingly good even when more than 10 most significant DCT\ncoefficients are missing. When only the DC coefficient is missing, the proposed\nalgorithm outperforms existing methods according to experimental results\nconducted on 200 test images. The proposed recovery method can be used for\ncryptanalysis of DCT based selective encryption schemes and other applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2012 23:59:01 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Li", "Shujun", ""], ["Karrenbauer", "Andreas", ""], ["Saupe", "Dietmar", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1209.1949", "submitter": "Mehdi Khalili", "authors": "Atefeh Elahian, Mehdi Khalili, Shahriar Baradaran Shokouhi", "title": "Improved Robust DWT-Watermarking in YCbCr Color Space", "comments": "5 Pages, 4 Figures, 3 Tables", "journal-ref": "Global journal of Computer Application and Technology (GJCAT),\n  Vol.1, No.3, 2011, Pages 300-304", "doi": null, "report-no": null, "categories": "cs.CR cs.MM cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital watermarking is an effective way to protect copyright. In this paper,\na robust watermarking algorithm based on wavelet transformation is proposed\nwhich can confirm the copyright without original image. The wavelet\ntransformation technique is effective in image analyzing and processing. Thus\nthe color-image watermark algorithm based on discrete wavelet transformation\n(DWT) begins to draw an increasing attention. In the proposed approach, the\nwatermark Encrypt by Arnold transform and the host image is converted into the\nYCbCr color space. Then its Y channel decomposed into wavelet coefficients and\nthe selected approximation coefficients are quantized and then their least\nsignificant bit of the quantized coefficients is replaced by the Encrypted\nwatermark using LSB insertion technique. The experimental results show that\nwatermark embedded by this algorithm is of better robustness and extra\nimperceptibility and robustness against wavelet compression compared to the\ntraditional embedding methods in RGB color space.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 11:35:39 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Elahian", "Atefeh", ""], ["Khalili", "Mehdi", ""], ["Shokouhi", "Shahriar Baradaran", ""]]}, {"id": "1209.2067", "submitter": "Chao Chen", "authors": "Chao Chen and Robert W. Heath Jr and Alan C. Bovik and Gustavo de\n  Veciana", "title": "A Markov Decision Model for Adaptive Scheduling of Stored Scalable\n  Videos", "comments": "14 pages", "journal-ref": "IEEE Transactions on Circuits and Systems for Video Technology,\n  vol.23, no.6, pp.1081-1095, June 2013", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two scheduling algorithms that seek to optimize the quality of\nscalably coded videos that have been stored at a video server before\ntransmission.} The first scheduling algorithm is derived from a Markov Decision\nProcess (MDP) formulation developed here. We model the dynamics of the channel\nas a Markov chain and reduce the problem of dynamic video scheduling to a\ntractable Markov decision problem over a finite state space. Based on the MDP\nformulation, a near-optimal scheduling policy is computed that minimize the\nmean square error. Using insights taken from the development of the optimal\nMDP-based scheduling policy, the second proposed scheduling algorithm is an\nonline scheduling method that only requires easily measurable knowledge of the\nchannel dynamics, and is thus viable in practice. Simulation results show that\nthe performance of both scheduling algorithms is close to a performance upper\nbound also derived in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2012 17:19:45 GMT"}, {"version": "v2", "created": "Sat, 23 Nov 2013 23:41:20 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Chen", "Chao", ""], ["Heath", "Robert W.", "Jr"], ["Bovik", "Alan C.", ""], ["de Veciana", "Gustavo", ""]]}, {"id": "1209.2070", "submitter": "Yi Wang", "authors": "Yi Wang", "title": "Content-based Multi-media Retrieval Technology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a summary of the content-based Image Retrieval and\nContent-based Audio Retrieval, which are two parts of the Content-based\nRetrieval. Content-based Retrieval is the retrieval based on the features of\nthe content. Generally, it is a way to extract features of the media data and\nfind other data with the similar features from the database automatically.\nContent-based Retrieval can not only work on discrete media like texts, but\nalso can be used on continuous media, such as video and audio.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2012 16:00:06 GMT"}], "update_date": "2012-09-11", "authors_parsed": [["Wang", "Yi", ""]]}, {"id": "1209.2855", "submitter": "Mohammad Ashraful Hoque Mohammad Ashraful Hoque", "authors": "Mohammad Ashraful Hoque, Matti Siekkinen, Jukka K. Nurminen, Mika\n  Aalto", "title": "Investigating Streaming Techniques and Energy Efficiency of Mobile Video\n  Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We report results from a measurement study of three video streaming services,\nYouTube, Dailymotion and Vimeo on six different smartphones. We measure and\nanalyze the traffic and energy consumption when streaming different quality\nvideos over Wi-Fi and 3G. We identify five different techniques to deliver the\nvideo and show that the use of a particular technique depends on the device,\nplayer, quality, and service. The energy consumption varies dramatically\nbetween devices, services, and video qualities depending on the streaming\ntechnique used. As a consequence, we come up with suggestions on how to improve\nthe energy efficiency of mobile video streaming services.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2012 11:25:19 GMT"}], "update_date": "2012-09-14", "authors_parsed": [["Hoque", "Mohammad Ashraful", ""], ["Siekkinen", "Matti", ""], ["Nurminen", "Jukka K.", ""], ["Aalto", "Mika", ""]]}, {"id": "1209.2905", "submitter": "Marie-Jose Montpetit", "authors": "Marie-Jose Montpetit, Pablo Cesar, Maja Matijasevic, Zhu Liu, John\n  Crowcroft and Oscar Martinez-Bonastre", "title": "Surveying the Social, Smart and Converged TV Landscape: Where is\n  Television Research Headed?", "comments": "18 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TV is dead motto of just a few years ago has been replaced by the\nprospect of Internet Protocol (IP) television experiences over converged\nnetworks to become one of the great technology opportunities in the next few\nyears. As an introduction to the Special Issue on Smart, Social and Converged\nTelevision, this extended editorial intends to review the current IP television\nlandscape in its many realizations: operator-based, over-the-top, and user\ngenerated. We will address new services like social TV and recommendation\nengines, dissemination including new paradigms built on peer to peer and\ncontent centric networks, as well as the all important quality of experience\nthat challenges services and networks alike. But we intend to go further than\njust review the existing work by proposing areas for the future of television\nresearch. These include strategies to provide services that are more efficient\nin network and energy usage while being socially engaging, novel services that\nwill provide consumers with a broader choice of content and devices, and\nmetrics that will enable operators and users alike to define the level of\nservice they require or that they are ready to provide. These topics are\naddressed in this survey paper that attempts to create a unifying framework to\nlink them all together. Not only is television not dead, it is well alive,\nthriving and fostering innovation and this paper will hopefully prove it.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2012 14:24:45 GMT"}], "update_date": "2012-09-14", "authors_parsed": [["Montpetit", "Marie-Jose", ""], ["Cesar", "Pablo", ""], ["Matijasevic", "Maja", ""], ["Liu", "Zhu", ""], ["Crowcroft", "John", ""], ["Martinez-Bonastre", "Oscar", ""]]}, {"id": "1209.3052", "submitter": "Samuel King Opoku", "authors": "Samuel King Opoku (Kumasi Polytechnic)", "title": "A Simultaneous-Movement Mobile Multiplayer Game Design based on Adaptive\n  Background Partitioning Technique", "comments": "8 pages", "journal-ref": "Cyber Journals: Multidisciplinary Journals in Science and\n  Technology, JSAT, Vol. 3, No. 4, pg 1-8, 2012", "doi": null, "report-no": null, "categories": "cs.GT cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementations of mobile games have become prevalent industrial technology\ndue to the ubiquitous nature of mobile devices. However, simultaneous-movement\nmultiplayer games, games that a player competes simultaneously with other\nplayers, are usually affected by such parameters as latency, type of game\narchitecture and type of communication technology. This paper makes a review of\nthe above parameters, considering the pros and cons of the various techniques\nused in addressing each parameter. It then goes ahead to propose an enhanced\nmechanism for dealing with packet delays based on partitioning the game\nbackground into grids. The proposed design is implemented and tested using\nBluetooth and Wi-Fi communication technologies. The efficiency and\neffectiveness of the design are also analyzed.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2012 22:12:16 GMT"}], "update_date": "2012-09-17", "authors_parsed": [["Opoku", "Samuel King", "", "Kumasi Polytechnic"]]}, {"id": "1209.4275", "submitter": "Prabhu Natarajan", "authors": "Prabhu Natarajan, Trong Nghia Hoang, Kian Hsiang Low, Mohan\n  Kankanhalli", "title": "Decision-Theoretic Coordination and Control for Active Multi-Camera\n  Surveillance in Uncertain, Partially Observable Environments", "comments": "6th ACM/IEEE International Conference on Distributed Smart Cameras\n  (ICDSC 2012), Extended version with proofs, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem of surveillance is to monitor multiple targets moving in a\nlarge-scale, obstacle-ridden environment with occlusions. This paper presents a\nnovel principled Partially Observable Markov Decision Process-based approach to\ncoordinating and controlling a network of active cameras for tracking and\nobserving multiple mobile targets at high resolution in such surveillance\nenvironments. Our proposed approach is capable of (a) maintaining a belief over\nthe targets' states (i.e., locations, directions, and velocities) to track\nthem, even when they may not be observed directly by the cameras at all times,\n(b) coordinating the cameras' actions to simultaneously improve the belief over\nthe targets' states and maximize the expected number of targets observed with a\nguaranteed resolution, and (c) exploiting the inherent structure of our\nsurveillance problem to improve its scalability (i.e., linear time) in the\nnumber of targets to be observed. Quantitative comparisons with\nstate-of-the-art multi-camera coordination and control techniques show that our\napproach can achieve higher surveillance quality in real time. The practical\nfeasibility of our approach is also demonstrated using real AXIS 214 PTZ\ncameras\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2012 15:15:08 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2012 12:19:53 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2012 08:44:59 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Natarajan", "Prabhu", ""], ["Hoang", "Trong Nghia", ""], ["Low", "Kian Hsiang", ""], ["Kankanhalli", "Mohan", ""]]}]