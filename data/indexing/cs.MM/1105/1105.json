[{"id": "1105.0011", "submitter": "Ali Ayremlou", "authors": "Ramtin Madani, Ali Ayremlou, Arash Amini, Farrokh Marvasti", "title": "Optimized Spline Interpolation", "comments": "IEEE Transactions on Signal Processing, Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the problem of designing compact support\ninterpolation kernels for a given class of signals. By using calculus of\nvariations, we simplify the optimization problem from an infinite nonlinear\nproblem to a finite dimensional linear case, and then find the optimum compact\nsupport function that best approximates a given filter in the least square\nsense (l2 norm). The benefit of compact support interpolants is the low\ncomputational complexity in the interpolation process while the optimum compact\nsupport interpolant gaurantees the highest achivable Signal to Noise Ratio\n(SNR). Our simulation results confirm the superior performance of the proposed\nsplines compared to other conventional compact support interpolants such as\ncubic spline.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 20:05:52 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Madani", "Ramtin", ""], ["Ayremlou", "Ali", ""], ["Amini", "Arash", ""], ["Marvasti", "Farrokh", ""]]}, {"id": "1105.0023", "submitter": "Lu Lu", "authors": "Lu Lu", "title": "Survey of Cognitive Radio Techniques in Wireless Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, I surveyed the cognitive radio technique in wireless\nnetworks. Researched several kinds of cognitive techniques about their\nadvantages and disadvantages.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 21:34:21 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Lu", "Lu", ""]]}, {"id": "1105.0699", "submitter": "Andreas Baldi", "authors": "Morteza Zahedi, Ali Reza Manashty", "title": "Robust Sign Language Recognition System Using ToF Depth Cameras", "comments": "6 Pages", "journal-ref": "World of Computer Science and Information Technology Journal\n  (WCSIT), Vol. 1, No. 3, 50-55, 2011", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sign language recognition is a difficult task, yet required for many\napplications in real-time speed. Using RGB cameras for recognition of sign\nlanguages is not very successful in practical situations and accurate 3D\nimaging requires expensive and complex instruments. With introduction of\nTime-of-Flight (ToF) depth cameras in recent years, it has become easier to\nscan the environment for accurate, yet fast depth images of the objects without\nthe need of any extra calibrating object. In this paper, a robust system for\nsign language recognition using ToF depth cameras is presented for converting\nthe recorded signs to a standard and portable XML sign language named SiGML for\neasy transferring and converting to real-time 3D virtual characters animations.\nFeature extraction using moments and classification using nearest neighbor\nclassifier are used to track hand gestures and significant result of 100% is\nachieved for the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 21:57:18 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Zahedi", "Morteza", ""], ["Manashty", "Ali Reza", ""]]}, {"id": "1105.0755", "submitter": "Hyokun Yun", "authors": "Hyokun Yun", "title": "Using Logistic Regression to Analyze the Balance of a Game: The Case of\n  StarCraft II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the market size of online game has been increasing astonishingly\nfast, and so does the importance of good game design. In online games, usually\na human user competes with others, so the fairness of the game system to all\nusers is of great importance not to lose interests of users on the game.\nFurthermore, the emergence and success of electronic sports (e-sports) and\nprofessional gaming which specially talented gamers compete with others draws\nmore attention on whether they are competing in the fair environment. No matter\nhow fierce the debates are in the game-design community, it is rarely the case\nthat one employs statistical analysis to answer this question seriously. But\nconsidering the fact that we can easily gather large amount of user behavior\ndata on games, it seems potentially beneficial to make use of this data to aid\nmaking decisions on design problems of games. Actually, modern games do not aim\nto perfectly design the game at once: rather, they first release the game, and\nthen monitor users' behavior to better balance the game. In such a scenario,\nstatistical analysis can be particularly helpful. Specifically, we chose to\nanalyze the balance of StarCraft II, which is a very successful\nrecently-released real-time strategy (RTS) game. It is a central icon in\ncurrent e-Sports and professional gaming community: from April 1st to 15th,\nthere were 18 tournaments of StarCraft II. However, there is endless debate on\nwhether the winner of the tournament is actually superior to others, or it is\nlargely due to certain design flaws of the game. In this paper, we aim to\nanswer such a question using traditional statistical tool, logistic regression.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2011 08:15:20 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Yun", "Hyokun", ""]]}, {"id": "1105.0826", "submitter": "Radu Arsinte", "authors": "Radu Arsinte, Eugen Lupu", "title": "Streaming Multimedia Information Using the Features of the DVB-S Card", "comments": "4 pages, 5 figures", "journal-ref": "Scientific Bulletin of the \"Politehnica\" University Timi\\c{s}oara,\n  Transaction on Electronics and Telecomunications, Tom 51(65), Fascicola 1-2,\n  pag. 181-184, 2006", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of audio-video streaming using the additional\npossibilities of a DVB-S card. The board used for experiments (Technisat\nSkyStar 2) is one of the most frequently used cards for this purpose. Using the\nmain blocks of the board's software support it is possible the implement a\nreally useful and full functional system for audio-video streaming. The\nstreaming is possible to be implemented either for decoded MPEG stream or for\ntransport stream. In this last case it is possible to view not only a program,\nbut any program from the same multiplex. This allows us to implement\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2011 13:46:31 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Arsinte", "Radu", ""], ["Lupu", "Eugen", ""]]}, {"id": "1105.1561", "submitter": "Jing (Tiffany) Li", "authors": "Yang Liu, Jing (Tiffany) Li, Kai Xie", "title": "Efficient Image Transmission Through Analog Error Correction", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new paradigm for image transmission through analog\nerror correction codes. Conventional schemes rely on digitizing images through\nquantization (which inevitably causes significant bandwidth expansion) and\ntransmitting binary bit-streams through digital error correction codes (which\ndo not automatically differentiate the different levels of significance among\nthe bits). To strike a better overall performance in terms of transmission\nefficiency and quality, we propose to use a single analog error correction code\nin lieu of digital quantization, digital code and digital modulation. The key\nis to get analog coding right. We show that this can be achieved by cleverly\nexploiting an elegant \"butterfly\" property of chaotic systems. Specifically, we\ndemonstrate a tail-biting triple-branch baker's map code and its\nmaximum-likelihood decoding algorithm. Simulations show that the proposed\nanalog code can actually outperform digital turbo code, one of the best codes\nknown to date. The results and findings discussed in this paper speak volume\nfor the promising potential of analog codes, in spite of their rather short\nhistory.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2011 00:07:56 GMT"}, {"version": "v2", "created": "Wed, 3 Aug 2011 18:57:17 GMT"}], "update_date": "2011-08-04", "authors_parsed": [["Liu", "Yang", "", "Tiffany"], ["Jing", "", "", "Tiffany"], ["Li", "", ""], ["Xie", "Kai", ""]]}, {"id": "1105.1948", "submitter": "Reza Keyvan", "authors": "Mohammadreza keyvanpour (1) and Najva Izadpanah (2) ((1) Department of\n  Computer Engineering, Alzahra University, Tehran, Iran, (2) Department of\n  Computer Engineering, Islamic Azad University, Qazvin Branch, Qazvin, Iran)", "title": "Analytical Classification of Multimedia Index Structures by Using a\n  Partitioning Method-Based Framework", "comments": null, "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.3, No.1, February 2011", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the advances in hardware technology and increase in production of\nmultimedia data in many applications, during the last decades, multimedia\ndatabases have become increasingly important. Contentbased multimedia retrieval\nis one of an important research area in the field of multimedia databases. Lots\nof research on this field has led to proposition of different kinds of index\nstructures to support fast and efficient similarity search to retrieve\nmultimedia data from these databases. Due to variety and plenty of proposed\nindex structures, we suggest a systematic framework based on partitioning\nmethod used in these structures to classify multimedia index structures, and\nthen we evaluated these structures based on important functional measures. We\nhope this proposed framework will lead to empirical and technical comparison of\nmultimedia index structures and development of more efficient structures at\nfuture.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 13:55:31 GMT"}], "update_date": "2011-05-11", "authors_parsed": [["keyvanpour", "Mohammadreza", ""], ["Izadpanah", "Najva", ""]]}, {"id": "1105.2344", "submitter": "Brian McFee", "authors": "Brian McFee, Luke Barrington and Gert Lanckriet", "title": "Learning content similarity for music recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in music information retrieval, such as recommendation, and\nplaylist generation for online radio, fall naturally into the query-by-example\nsetting, wherein a user queries the system by providing a song, and the system\nresponds with a list of relevant or similar song recommendations. Such\napplications ultimately depend on the notion of similarity between items to\nproduce high-quality results. Current state-of-the-art systems employ\ncollaborative filter methods to represent musical items, effectively comparing\nitems in terms of their constituent users. While collaborative filter\ntechniques perform well when historical data is available for each item, their\nreliance on historical data impedes performance on novel or unpopular items. To\ncombat this problem, practitioners rely on content-based similarity, which\nnaturally extends to novel items, but is typically out-performed by\ncollaborative filter methods.\n  In this article, we propose a method for optimizing contentbased similarity\nby learning from a sample of collaborative filter data. The optimized\ncontent-based similarity metric can then be applied to answer queries on novel\nand unpopular items, while still maintaining high recommendation accuracy. The\nproposed system yields accurate and efficient representations of audio content,\nand experimental results show significant improvements in accuracy over\ncompeting content-based recommendation techniques.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 00:43:46 GMT"}], "update_date": "2011-05-13", "authors_parsed": [["McFee", "Brian", ""], ["Barrington", "Luke", ""], ["Lanckriet", "Gert", ""]]}, {"id": "1105.2770", "submitter": "Md Sahidullah", "authors": "Md. Sahidullah and Sandipan Chakroborty and Goutam Saha", "title": "Improving Performance of Speaker Identification System Using\n  Complementary Information Fusion", "comments": "6 Pages, 3 figures", "journal-ref": "Proceedings of 17th International Conference on Advanced Computing\n  and Communications (ADCOM 2009) pp. 182-187 (2009)", "doi": null, "report-no": null, "categories": "cs.SD cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature extraction plays an important role as a front-end processing block in\nspeaker identification (SI) process. Most of the SI systems utilize like\nMel-Frequency Cepstral Coefficients (MFCC), Perceptual Linear Prediction (PLP),\nLinear Predictive Cepstral Coefficients (LPCC), as a feature for representing\nspeech signal. Their derivations are based on short term processing of speech\nsignal and they try to capture the vocal tract information ignoring the\ncontribution from the vocal cord. Vocal cord cues are equally important in SI\ncontext, as the information like pitch frequency, phase in the residual signal,\netc could convey important speaker specific attributes and are complementary to\nthe information contained in spectral feature sets. In this paper we propose a\nnovel feature set extracted from the residual signal of LP modeling.\nHigher-order statistical moments are used here to find the nonlinear\nrelationship in residual signal. To get the advantages of complementarity vocal\ncord based decision score is fused with the vocal tract based score. The\nexperimental results on two public databases show that fused mode system\noutperforms single spectral features.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 16:32:44 GMT"}, {"version": "v2", "created": "Mon, 16 May 2011 19:29:53 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Sahidullah", "Md.", ""], ["Chakroborty", "Sandipan", ""], ["Saha", "Goutam", ""]]}, {"id": "1105.2795", "submitter": "Afzal  Godil", "authors": "Helin Dutagaci, Afzal Godil, Bulent Sankur, Y\\\"ucel Yemez", "title": "View subspaces for indexing and retrieval of 3D models", "comments": "Three-Dimensional Image Processing (3DIP) and Applications\n  (Proceedings Volume) Proceedings of SPIE Volume: 7526 Editor(s): Atilla M.\n  Baskurt ISBN: 9780819479198 Date: 2 February 2010", "journal-ref": null, "doi": "10.1117/12.839186", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  View-based indexing schemes for 3D object retrieval are gaining popularity\nsince they provide good retrieval results. These schemes are coherent with the\ntheory that humans recognize objects based on their 2D appearances. The\nviewbased techniques also allow users to search with various queries such as\nbinary images, range images and even 2D sketches. The previous view-based\ntechniques use classical 2D shape descriptors such as Fourier invariants,\nZernike moments, Scale Invariant Feature Transform-based local features and 2D\nDigital Fourier Transform coefficients. These methods describe each object\nindependent of others. In this work, we explore data driven subspace models,\nsuch as Principal Component Analysis, Independent Component Analysis and\nNonnegative Matrix Factorization to describe the shape information of the\nviews. We treat the depth images obtained from various points of the view\nsphere as 2D intensity images and train a subspace to extract the inherent\nstructure of the views within a database. We also show the benefit of\ncategorizing shapes according to their eigenvalue spread. Both the shape\ncategorization and data-driven feature set conjectures are tested on the PSB\ndatabase and compared with the competitor view-based 3D shape retrieval\nalgorithms\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 18:24:10 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Dutagaci", "Helin", ""], ["Godil", "Afzal", ""], ["Sankur", "Bulent", ""], ["Yemez", "Y\u00fccel", ""]]}, {"id": "1105.2796", "submitter": "Afzal  Godil", "authors": "Afzal Godil, Asim Imdad Wagan", "title": "Salient Local 3D Features for 3D Shape Retrieval", "comments": "Three-Dimensional Imaging, Interaction, and Measurement. Edited by\n  Beraldin, J. Angelo; Cheok, Geraldine S.; McCarthy, Michael B.;\n  Neuschaefer-Rube, Ulrich; Baskurt, Atilla M.; McDowall, Ian E.; Dolinsky,\n  Margaret. Proceedings of the SPIE, Volume 7864, pp. 78640S-78640S-8 (2011).\n  Conference Location: San Francisco Airport, California, USA ISBN:\n  9780819484017 Date: 10 March 2011", "journal-ref": null, "doi": "10.1117/12.872984", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper we describe a new formulation for the 3D salient local features\nbased on the voxel grid inspired by the Scale Invariant Feature Transform\n(SIFT). We use it to identify the salient keypoints (invariant points) on a 3D\nvoxelized model and calculate invariant 3D local feature descriptors at these\nkeypoints. We then use the bag of words approach on the 3D local features to\nrepresent the 3D models for shape retrieval. The advantages of the method are\nthat it can be applied to rigid as well as to articulated and deformable 3D\nmodels. Finally, this approach is applied for 3D Shape Retrieval on the McGill\narticulated shape benchmark and then the retrieval results are presented and\ncompared to other methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2011 18:25:15 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Godil", "Afzal", ""], ["Wagan", "Asim Imdad", ""]]}, {"id": "1105.2899", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Farokh Marvasti", "title": "Fast restoration of natural images corrupted by high-density impulse\n  noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we suggest a general model for the fixed-valued impulse noise\nand propose a two-stage method for high density noise suppression while\npreserving the image details. In the first stage, we apply an iterative impulse\ndetector, exploiting the image entropy, to identify the corrupted pixels and\nthen employ an Adaptive Iterative Mean filter to restore them. The filter is\nadaptive in terms of the number of iterations, which is different for each\nnoisy pixel, according to the Euclidean distance from the nearest uncorrupted\npixel. Experimental results show that the proposed filter is fast and\noutperforms the best existing techniques in both objective and subjective\nperformance measures.\n", "versions": [{"version": "v1", "created": "Sat, 14 May 2011 13:57:35 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2014 13:33:06 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Hosseini", "Hossein", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1105.4431", "submitter": "Mostafa Zaman Chowdhury", "authors": "Mostafa Zaman Chowdhury, Bui Minh Trung, Yeong Min Jang, Young-Il Kim,\n  and Won Ryu", "title": "Service Level Agreement for the QoS Guaranteed Mobile IPTV Services over\n  Mobile WiMAX Networks", "comments": "6 pages, 5 figures", "journal-ref": "The Journal of Korea Information and Communications Society\n  (KICS), vol.36, no.4, April 2011", "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While mobile IPTV services are supported through the mobile WiMAX networks,\nthere must need some guaranteed bandwidth for the IPTV services especially if\nIPTV and non-IPTV services are simultaneously supported by the mobile WiMAX\nnetworks. The quality of an IPTV service definitely depends on the allocated\nbandwidth for that channel. However, due to the high quality IPTV services and\nto support of huge non-IPTV traffic over mobile WiMAX networks, it is not\npossible to guarantee the sufficient amount of the limited mobile WiMAX\nbandwidth for the mobile IPTV services every time. A Service Level Agreement\n(SLA) between the mobile IPTV service provider and mobile WiMAX network\noperator to reserve sufficient bandwidth for the IPTV calls can increase the\nsatisfaction level of the mobile IPTV users. In this paper, we propose a SLA\nnegotiation procedure for mobile IPTV users over mobile WiMAX networks. The\nBandwidth Broker controls the allocated bandwidth for IPTV and non-IPTV users.\nThe proposed dynamically reserved bandwidth for the IPTV services increases the\nIPTV user's satisfaction level. The simulation results state that, our proposed\nscheme is able to provide better user satisfaction level for the IPTV users.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 08:30:58 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Chowdhury", "Mostafa Zaman", ""], ["Trung", "Bui Minh", ""], ["Jang", "Yeong Min", ""], ["Kim", "Young-Il", ""], ["Ryu", "Won", ""]]}, {"id": "1105.5553", "submitter": "Feng Shu", "authors": "Shu Feng, Wang Mao, Shi Xiajie, Liu Junhao, Sheng Weixin, and Xie\n  Renhong", "title": "A Frequency-domain Compensation Scheme for IQ-Imbalance in OFDM\n  Receivers", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A pilot pattern across two OFDM symbols with special structure is devised for\nchannel estimation in OFDM systems with IQ imbalance at receiver. Based on this\npilot pattern, a high-efficiency time-domain (TD) least square (LS) channel\nestimator is proposed to significantly suppress channel noise by a factor\nN/(L+1) in comparison with the frequency-domain LS one in [1] where N and L+1\nare the total number of subcarriers and the length of cyclic prefix,\nrespectively. Following this, a low-complexity frequency-domain (FD) Gaussian\nelimination (GE) equalizer is proposed to eliminate IQ distortion by using only\n2N complex multiplications per OFDM symbol. From simulation, the proposed\nscheme TD-LS/FD-GE using only two pilot OFDM symbols achieves the same bit\nerror rate (BER) performance under ideal channel knowledge and no IQ imbalances\nat low and medium signal-to-noise ratio (SNR) regions whereas these\ncompensation schemes including FD-LS/Post-FFT LS, FD-LS/Pre-FFT Corr, and\nSPP/Pre-FFT Corr in [1] require about twenty OFDM training symbols to reach the\nsame performance where A/B denotes compensation scheme with A being channel\nestimator and B being equalizer.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2011 13:08:30 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2011 10:06:07 GMT"}, {"version": "v3", "created": "Tue, 21 Jun 2011 11:19:14 GMT"}], "update_date": "2011-06-22", "authors_parsed": [["Feng", "Shu", ""], ["Mao", "Wang", ""], ["Xiajie", "Shi", ""], ["Junhao", "Liu", ""], ["Weixin", "Sheng", ""], ["Renhong", "Xie", ""]]}, {"id": "1105.5641", "submitter": "Suresh Jaganathan", "authors": "Suresh Jaganathan and Jeevan Eranti", "title": "High Quality of Service on Video Streaming in P2P Networks using FST-MDC", "comments": "11 pages, 8 figures, journal", "journal-ref": "International Journal of Multimedia & Its Applications (IJMA),\n  Vol:3, No:2, May 2011, 33-43", "doi": "10.5121/ijma.2011.3203", "report-no": null, "categories": "cs.DC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video streaming applications have newly attracted a large number of\nparticipants in a distribution network. Traditional client-server based video\nstreaming solutions sustain precious bandwidth provision rate on the server.\nRecently, several P2P streaming systems have been organized to provide\non-demand and live video streaming services on the wireless network at reduced\nserver cost. Peer-to-Peer (P2P) computing is a new pattern to construct\ndisseminated network applications. Typical error control techniques are not\nvery well matched and on the other hand error prone channels has increased\ngreatly for video transmission e.g., over wireless networks and IP. These two\nfacts united together provided the essential motivation for the development of\na new set of techniques (error concealment) capable of dealing with\ntransmission errors in video systems. In this paper, we propose an flexible\nmultiple description coding method named as Flexible Spatial-Temporal (FST)\nwhich improves error resilience in the sense of frame loss possibilities over\nindependent paths. It introduces combination of both spatial and temporal\nconcealment technique at the receiver and to conceal the lost frames more\neffectively. Experimental results show that, proposed approach attains\nreasonable quality of video performance over P2P wireless network.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2011 13:34:42 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Jaganathan", "Suresh", ""], ["Eranti", "Jeevan", ""]]}, {"id": "1105.5675", "submitter": "Jierui Xie", "authors": "Jierui Xie and Mandis S. Beigi", "title": "Scale-Invariant Local Descriptor for Event Recognition in 1D Sensor\n  Signals", "comments": null, "journal-ref": "IEEE International Conference on Multimedia &\n  Expo(ICME),Page(s):1226 - 1229, 2009", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a shape-based, time-scale invariant feature\ndescriptor for 1-D sensor signals. The time-scale invariance of the feature\nallows us to use feature from one training event to describe events of the same\nsemantic class which may take place over varying time scales such as walking\nslow and walking fast. Therefore it requires less training set. The descriptor\ntakes advantage of the invariant location detection in the scale space theory\nand employs a high level shape encoding scheme to capture invariant local\nfeatures of events. Based on this descriptor, a scale-invariant classifier with\n\"R\" metric (SIC-R) is designed to recognize multi-scale events of human\nactivities. The R metric combines the number of matches of keypoint in scale\nspace with the Dynamic Time Warping score. SICR is tested on various types of\n1-D sensors data from passive infrared, accelerometer and seismic sensors with\nmore than 90% classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2011 00:44:54 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Xie", "Jierui", ""], ["Beigi", "Mandis S.", ""]]}]