[{"id": "1408.0605", "submitter": "Viet Anh Nguyen", "authors": "Viet-Anh Nguyen, Jiangbo Lu, Shengkui Zhao, Tien Dung Vu, Hongsheng\n  Yang, Jones L. Douglas and Minh N. Do", "title": "ITEM: Immersive Telepresence for Entertainment and Meetings - A\n  Practical Approach", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2014.2375819", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an Immersive Telepresence system for Entertainment and\nMeetings (ITEM). The system aims to provide a radically new video communication\nexperience by seamlessly merging participants into the same virtual space to\nallow a natural interaction among them and shared collaborative contents. With\nthe goal to make a scalable, flexible system for various business solutions as\nwell as easily accessible by massive consumers, we address the challenges in\nthe whole pipeline of media processing, communication, and displaying in our\ndesign and realization of such a system. Particularly, in this paper we focus\non the system aspects that maximize the end-user experience, optimize the\nsystem and network resources, and enable various teleimmersive application\nscenarios. In addition, we also present a few key technologies, i.e. fast\nobject-based video coding for real world data and spatialized audio capture and\n3D sound localization for group teleconferencing. Our effort is to investigate\nand optimize the key system components and provide an efficient end-to-end\noptimization and integration by considering user needs and preferences.\nExtensive experiments show the developed system runs reliably and comfortably\nin real time with a minimal setup requirement (e.g. a webcam and/or a depth\ncamera, an optional microphone array, a laptop/desktop connected to the public\nInternet) for teleimmersive communication. With such a really minimal\ndeployment requirement, we present a variety of interesting applications and\nuser experiences created by ITEM.\n", "versions": [{"version": "v1", "created": "Mon, 4 Aug 2014 08:16:09 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Nguyen", "Viet-Anh", ""], ["Lu", "Jiangbo", ""], ["Zhao", "Shengkui", ""], ["Vu", "Tien Dung", ""], ["Yang", "Hongsheng", ""], ["Douglas", "Jones L.", ""], ["Do", "Minh N.", ""]]}, {"id": "1408.2313", "submitter": "Conrad Sanderson", "authors": "Sareh Shirazi, Conrad Sanderson, Chris McCool, Mehrtash T. Harandi", "title": "Bags of Affine Subspaces for Robust Object Tracking", "comments": "in International Conference on Digital Image Computing: Techniques\n  and Applications, 2015", "journal-ref": null, "doi": "10.1109/DICTA.2015.7371239", "report-no": null, "categories": "cs.CV cs.MM cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an adaptive tracking algorithm where the object is modelled as a\ncontinuously updated bag of affine subspaces, with each subspace constructed\nfrom the object's appearance over several consecutive frames. In contrast to\nlinear subspaces, affine subspaces explicitly model the origin of subspaces.\nFurthermore, instead of using a brittle point-to-subspace distance during the\nsearch for the object in a new frame, we propose to use a subspace-to-subspace\ndistance by representing candidate image areas also as affine subspaces.\nDistances between subspaces are then obtained by exploiting the non-Euclidean\ngeometry of Grassmann manifolds. Experiments on challenging videos (containing\nobject occlusions, deformations, as well as variations in pose and\nillumination) indicate that the proposed method achieves higher tracking\naccuracy than several recent discriminative trackers.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 05:13:15 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 02:58:39 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2016 07:35:54 GMT"}], "update_date": "2016-02-08", "authors_parsed": [["Shirazi", "Sareh", ""], ["Sanderson", "Conrad", ""], ["McCool", "Chris", ""], ["Harandi", "Mehrtash T.", ""]]}, {"id": "1408.2380", "submitter": "Dacheng Tao", "authors": "Xiaoyan Li and Dacheng Tao", "title": "Video Face Editing Using Temporal-Spatial-Smooth Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Editing faces in videos is a popular yet challenging aspect of computer\nvision and graphics, which encompasses several applications including facial\nattractiveness enhancement, makeup transfer, face replacement, and expression\nmanipulation. Simply applying image-based warping algorithms to video-based\nface editing produces temporal incoherence in the synthesized videos because it\nis impossible to consistently localize facial features in two frames\nrepresenting two different faces in two different videos (or even two\nconsecutive frames representing the same face in one video). Therefore, high\nperformance face editing usually requires significant manual manipulation. In\nthis paper we propose a novel temporal-spatial-smooth warping (TSSW) algorithm\nto effectively exploit the temporal information in two consecutive frames, as\nwell as the spatial smoothness within each frame. TSSW precisely estimates two\ncontrol lattices in the horizontal and vertical directions respectively from\nthe corresponding control lattices in the previous frame, by minimizing a novel\nenergy function that unifies a data-driven term, a smoothness term, and feature\npoint constraints. Corresponding warping surfaces then precisely map source\nframes to the target frames. Experimental testing on facial attractiveness\nenhancement, makeup transfer, face replacement, and expression manipulation\ndemonstrates that the proposed approaches can effectively preserve spatial\nsmoothness and temporal coherence in editing facial geometry, skin detail,\nidentity, and expression, which outperform the existing face editing methods.\nIn particular, TSSW is robust to subtly inaccurate localization of feature\npoints and is a vast improvement over image-based warping methods.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 11:48:46 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Li", "Xiaoyan", ""], ["Tao", "Dacheng", ""]]}, {"id": "1408.2700", "submitter": "Radu Horaud P", "authors": "Antoine Deleforge, Radu Horaud, Yoav Schechner and Laurent Girin", "title": "Co-Localization of Audio Sources in Images Using Binaural Features and\n  Locally-Linear Regression", "comments": "15 pages, 8 figures", "journal-ref": "IEEE Transactions on Audio, Speech, and Language Processing 23(4),\n  718-731, April, 2015", "doi": "10.1109/TASLP.2015.2405475", "report-no": null, "categories": "cs.SD cs.MM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of localizing audio sources using binaural\nmeasurements. We propose a supervised formulation that simultaneously localizes\nmultiple sources at different locations. The approach is intrinsically\nefficient because, contrary to prior work, it relies neither on source\nseparation, nor on monaural segregation. The method starts with a training\nstage that establishes a locally-linear Gaussian regression model between the\ndirectional coordinates of all the sources and the auditory features extracted\nfrom binaural measurements. While fixed-length wide-spectrum sounds (white\nnoise) are used for training to reliably estimate the model parameters, we show\nthat the testing (localization) can be extended to variable-length\nsparse-spectrum sounds (such as speech), thus enabling a wide range of\nrealistic applications. Indeed, we demonstrate that the method can be used for\naudio-visual fusion, namely to map speech signals onto images and hence to\nspatially align the audio and visual modalities, thus enabling to discriminate\nbetween speaking and non-speaking faces. We release a novel corpus of real-room\nrecordings that allow quantitative evaluation of the co-localization method in\nthe presence of one or two sound sources. Experiments demonstrate increased\naccuracy and speed relative to several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 12 Aug 2014 12:08:13 GMT"}, {"version": "v2", "created": "Wed, 22 Oct 2014 10:35:07 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2015 13:45:06 GMT"}, {"version": "v4", "created": "Fri, 15 Apr 2016 10:00:02 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Deleforge", "Antoine", ""], ["Horaud", "Radu", ""], ["Schechner", "Yoav", ""], ["Girin", "Laurent", ""]]}, {"id": "1408.3083", "submitter": "Madhur Srivastava", "authors": "Madhur Srivastava", "title": "Entropy Conserving Binarization Scheme for Video and Image Compression", "comments": "12 pages, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a binarization scheme that converts non-binary data into a\nset of binary strings. At present, there are many binarization algorithms, but\nthey are optimal for only specific probability distributions of the data\nsource. Overcoming the problem, it is shown in this paper that the presented\nbinarization scheme conserves the entropy of the original data having any\nprobability distribution of $m$-ary source. The major advantages of this scheme\nare that it conserves entropy without the knowledge of the source and the\nprobability distribution of the source symbols. The scheme has linear\ncomplexity in terms of the length of the input data. The binarization scheme\ncan be implemented in Context-based Adaptive Binary Arithmetic Coding (CABAC)\nfor video and image compression. It can also be utilized by various universal\ndata compression algorithms that have high complexity in compressing non-binary\ndata, and by binary data compression algorithms to optimally compress\nnon-binary data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 18:48:07 GMT"}], "update_date": "2014-08-14", "authors_parsed": [["Srivastava", "Madhur", ""]]}, {"id": "1408.3564", "submitter": "Minati Mishra", "authors": "Minati Mishra, Priyadarsini Mishra and M.C. Adhikary", "title": "Digital Image Data Hiding Techniques: A Comparative Study", "comments": "11 pages, ANVESA - The Journal of F.M. University, ISSN-0974-715X.\n  arXiv admin note: text overlap with\n  http://dx.doi.org/10.1016/j.sigpro.2009.08.010 by other authors", "journal-ref": "ANVESA,7(2), 105-115, 2012", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancements in the field of digital image processing during the\nlast decade, digital image data hiding techniques such as watermarking,\nSteganography have gained wide popularity. Digital image watermarking\ntechniques hide a small amount of data into a digital image which, later can be\nretrieved using some specific retrieval algorithms to prove the copyright of a\npiece of digital information whereas, Steganographic techniques are used to\nhide a large amount of data secretly into some innocuous looking digital\nmedium. In this paper we are providing an up-to-date review of these data\nhiding techniques.\n", "versions": [{"version": "v1", "created": "Fri, 15 Aug 2014 15:33:40 GMT"}], "update_date": "2014-08-18", "authors_parsed": [["Mishra", "Minati", ""], ["Mishra", "Priyadarsini", ""], ["Adhikary", "M. C.", ""]]}, {"id": "1408.3838", "submitter": "Minati Mishra", "authors": "Minati Mishra, Ashanta Ranjan Routray, Sunit Kumar", "title": "High Security Image Steganography with Modified Arnold cat map", "comments": "5 pages, International Journal of Computer Applications,Volume 37,\n  No.9, January 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information security is concerned with maintaining the secrecy, reliability\nand accessibility of data. The main objective of information security is to\nprotect information and information system from unauthorized access,\nrevelation, disruption, alteration, annihilation and use. This paper uses\nspatial domain LSB substitution method for information embedding and modified\nforms of Arnold transform are applied twice in two different phases to ensure\nsecurity. The system is tested and validated against a series of standard\nimages and the results show that the method is highly secure and provides high\ndata hiding capacity.\n", "versions": [{"version": "v1", "created": "Sun, 17 Aug 2014 17:07:29 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Mishra", "Minati", ""], ["Routray", "Ashanta Ranjan", ""], ["Kumar", "Sunit", ""]]}, {"id": "1408.4363", "submitter": "Xavier Giro-i-Nieto", "authors": "Eva Mohedano (1), Graham Healy (1), Kevin McGuinness (1), Xavier\n  Giro-i-Nieto (2), Noel E. O'Connor (1) and Alan F. Smeaton (1) ((1) Dublin\n  City University, (2) Universitat Politecnica de Catalunya)", "title": "Object Segmentation in Images using EEG Signals", "comments": "This is a preprint version prior to submission for peer-review of the\n  paper accepted to the 22nd ACM International Conference on Multimedia\n  (November 3-7, 2014, Orlando, Florida, USA) for the High Risk High Reward\n  session. 10 pages", "journal-ref": null, "doi": "10.1145/2647868.2654896", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the potential of brain-computer interfaces in segmenting\nobjects from images. Our approach is centered around designing an effective\nmethod for displaying the image parts to the users such that they generate\nmeasurable brain reactions. When an image region, specifically a block of\npixels, is displayed we estimate the probability of the block containing the\nobject of interest using a score based on EEG activity. After several such\nblocks are displayed, the resulting probability map is binarized and combined\nwith the GrabCut algorithm to segment the image into object and background\nregions. This study shows that BCI and simple EEG analysis are useful in\nlocating object boundaries in images.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 15:24:44 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Mohedano", "Eva", ""], ["Healy", "Graham", ""], ["McGuinness", "Kevin", ""], ["Giro-i-Nieto", "Xavier", ""], ["O'Connor", "Noel E.", ""], ["Smeaton", "Alan F.", ""]]}, {"id": "1408.5777", "submitter": "Saba Ahsan", "authors": "Saba Ahsan, Varun Singh and J\\\"org Ott", "title": "Characterizing Internet Video for Large-scale Active Measurements", "comments": "15 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of high definition video content on the web has brought\nabout a significant change in the characteristics of Internet video, but not\nmany studies on characterizing video have been done after this change. Video\ncharacteristics such as video length, format, target bit rate, and resolution\nprovide valuable input to design Adaptive Bit Rate (ABR) algorithms, sizing\nplayout buffers in Dynamic Adaptive HTTP streaming (DASH) players, model the\nvariability in video frame sizes, etc. This paper presents datasets collected\nin 2013 and 2014 that contains over 130,000 videos from YouTube's most viewed\n(or most popular) video charts in 58 countries. We describe the basic\ncharacteristics of the videos on YouTube for each category, format, video\nlength, file size, and data rate variation, observing that video length and\nfile size fit a log normal distribution. We show that three minutes of a video\nsuffice to represent its instant data rate fluctuation and that we can infer\ndata rate characteristics of different video resolutions from a single given\none. Based on our findings, we design active measurements for measuring the\nperformance of Internet video.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 16:38:25 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Ahsan", "Saba", ""], ["Singh", "Varun", ""], ["Ott", "J\u00f6rg", ""]]}, {"id": "1408.6974", "submitter": "Pui Tung Choi", "authors": "Pui Tung Choi, Lok Ming Lui", "title": "Fast Disk Conformal Parameterization of Simply-connected Open Surfaces", "comments": null, "journal-ref": "Journal of Scientific Computing 65, 1065-1090 (2015)", "doi": "10.1007/s10915-015-9998-2", "report-no": null, "categories": "cs.CG cs.CV cs.GR cs.MM math.DG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Surface parameterizations have been widely used in computer graphics and\ngeometry processing. In particular, as simply-connected open surfaces are\nconformally equivalent to the unit disk, it is desirable to compute the disk\nconformal parameterizations of the surfaces. In this paper, we propose a novel\nalgorithm for the conformal parameterization of a simply-connected open surface\nonto the unit disk, which significantly speeds up the computation, enhances the\nconformality and stability, and guarantees the bijectivity. The conformality\ndistortions at the inner region and on the boundary are corrected by two steps,\nwith the aid of an iterative scheme using quasi-conformal theories.\nExperimental results demonstrate the effectiveness of our proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 29 Aug 2014 10:31:56 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Choi", "Pui Tung", ""], ["Lui", "Lok Ming", ""]]}]