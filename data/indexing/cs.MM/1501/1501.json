[{"id": "1501.01203", "submitter": "Saikat Majumder", "authors": "Saikat Majumder, Shrish Verma", "title": "Iterative network-channel decoding with cooperative space-time\n  transmission", "comments": "11 pages in International Journal of Ad hoc, Sensor & Ubiquitous\n  Computing (IJASUC) Vol.5, No.6, December 2014", "journal-ref": null, "doi": "10.5121/ijasuc.2014.5602", "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most efficient methods of exploiting space diversity for portable\nwireless devices is cooperative communication utilizing space-time block codes.\nIn cooperative communication, users besides communicating their own\ninformation, also relay the information of other users. In this paper we\ninvestigate a scheme where cooperation is achieved using two methods, namely,\ndistributed space-time coding and network coding. Two cooperating users utilize\nAlamouti space time code for inter-user cooperation and in addition utilize a\nthird relay which performs network coding. The third relay does not have any of\nits information to be sent. In this paper we propose a scheme utilizing\nconvolutional code based network coding, instead of conventional XOR based\nnetwork code and utilize iterative joint network-channel decoder for efficient\ndecoding. Extrinsic information transfer (EXIT) chart analysis is performed to\ninvestigate the convergence property of the proposed decoder.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jan 2015 15:32:35 GMT"}], "update_date": "2015-01-07", "authors_parsed": [["Majumder", "Saikat", ""], ["Verma", "Shrish", ""]]}, {"id": "1501.01576", "submitter": "arXiv Admin", "authors": "Mohammad Tafaghodi, Meysam Ghaffari, Alimohammad Latif, Seyed Rasoul\n  Mousavi", "title": "Improving image watermarking based on Tabu search by Chaos", "comments": "This paper has been withdrawn by arXiv. arXiv admin note: author list\n  truncated due to disputed authorship and content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast development of communication and multimedia technology, the\nrights of the owners of multimedia products is vulnerable to the unauthorized\ncopies and watermarking is one of the best known methods for proving the\nownership of a product. In this paper we prosper the previous watermarking\nmethod which was based on Tabu search by Chaos. The modification applied in the\npermutation step of watermarking and the initial population generation of the\nTabu search. We analyze our method on some well known images and experimental\nresults shows the improvement in the quality and speed of the proposed\nwatermarking method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jan 2015 17:59:15 GMT"}, {"version": "v2", "created": "Sun, 21 Jun 2015 14:46:54 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2015 17:17:32 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Tafaghodi", "Mohammad", ""], ["Ghaffari", "Meysam", ""], ["Latif", "Alimohammad", ""], ["Mousavi", "Seyed Rasoul", ""]]}, {"id": "1501.01755", "submitter": "Hossein Bakhshi Golestani", "authors": "Hossein Bakhshi Golestani, Mohammed Ghanbari", "title": "Minimization of image watermarking side effects through subjective\n  optimization", "comments": "17 pages,11 figures, IET Image Processing Journal", "journal-ref": "IET Image Processing, vol. 7, no. 8, pp. 733-741, 2013", "doi": "10.1049/iet-ipr.2013.0086", "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of Structural Similaritys (SSIM) index on the\nminimized side effect to image watermarking. For fast implementation and more\ncompatibility with the standard DCT based codecs, watermark insertion is\ncarried out on the DCT coefficients and hence a SSIM model for DCT based\nwatermarking is developed. For faster implementation, the SSIM index is\nmaximized over independent 4x4 non-overlapped blocks but the disparity between\nthe adjacent blocks reduces the overall image quality. This problem is resolved\nthrough optimization of overlapped blocks, but, the higher image quality is\nachieved at a cost of high computational complexity. To reduce the\ncomputational complexity while preserving the good quality, optimization of\nsemi-overlapped blocks is introduced. We show that while SSIM-based\noptimization over overlapped blocks has as high as 64 times the complexity of\nthe 4x4 non-overlapped method, with semi-overlapped optimization the high\nquality of overlapped method is preserved only at a cost of less than 8 times\nthe non-overlapped method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 08:02:01 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Golestani", "Hossein Bakhshi", ""], ["Ghanbari", "Mohammed", ""]]}, {"id": "1501.01758", "submitter": "Hossein Bakhshi Golestani", "authors": "Hossein Bakhshi Golestani, Shahrokh Ghaemmaghami", "title": "Enhance Robustness of Image-in-Image Watermarking through Data\n  Partitioning", "comments": "5 pages, 7 figures, IEEE TENCON2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vulnerability of watermarking schemes against intense signal processing\nattacks is generally a major concern, particularly when there are techniques to\nreproduce an acceptable copy of the original signal with no chance for\ndetecting the watermark. In this paper, we propose a two-layer, data\npartitioning (DP) based, image in image watermarking method in the DCT domain\nto improve the watermark detection performance. Truncated singular value\ndecomposition, binary wavelet decomposition and spatial scalability idea in\nH.264/SVC are analyzed and employed as partitioning methods. It is shown that\nthe proposed scheme outperforms its two recent competitors in terms of both\ndata payload and robustness to intense attacks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2015 08:08:50 GMT"}], "update_date": "2015-01-09", "authors_parsed": [["Golestani", "Hossein Bakhshi", ""], ["Ghaemmaghami", "Shahrokh", ""]]}, {"id": "1501.02307", "submitter": "Steven Blostein", "authors": "Yu Cao, Steven D. Blostein, Wai-Yip Chan", "title": "Optimization of Unequal Error Protection Rateless Codes for Multimedia\n  Multicasting", "comments": "11 pages, 7 figures, 2 tables, to appear in Journal of Communications\n  and Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rateless codes have been shown to be able to provide greater flexibility and\nefficiency than fixed-rate codes for multicast applications. In the following,\nwe optimize rateless codes for unequal error protection (UEP) for multimedia\nmulticasting to a set of heterogeneous users. The proposed designs have the\nobjectives of providing either guaranteed or best-effort quality of service\n(QoS). A randomly interleaved rateless encoder is proposed whereby users only\nneed to decode symbols up to their own QoS level. The proposed coder is\noptimized based on measured transmission properties of standardized raptor\ncodes over wireless channels. It is shown that a guaranteed QoS problem\nformulation can be transformed into a convex optimization problem, yielding a\nglobally optimal solution. Numerical results demonstrate that the proposed\noptimized random interleaved UEP rateless coder's performance compares\nfavorably with that of other recently proposed UEP rateless codes.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2015 03:29:51 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Cao", "Yu", ""], ["Blostein", "Steven D.", ""], ["Chan", "Wai-Yip", ""]]}, {"id": "1501.02398", "submitter": "Denis Shestakov", "authors": "Denis Shestakov, Diana Moise", "title": "Scalable high-dimensional indexing and searching with Hadoop", "comments": "This paper has been withdrawn by the authors. The manuscript has been\n  withdrawn as having no new material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While high-dimensional search-by-similarity techniques reached their maturity\nand in overall provide good performance, most of them are unable to cope with\nvery large multimedia collections. The 'big data' challenge however has to be\naddressed as multimedia collections have been explosively growing and will grow\neven faster than ever within the next few years. Luckily, computational\nprocessing power has become more available to researchers due to easier access\nto distributed grid infrastructures. In this paper, we show how\nhigh-dimensional indexing and searching methods can be used on scientific grid\nenvironments and present a scalable workflow for indexing and searching over 30\nbillion SIFT descriptors using a cluster running Hadoop. Besides its\nscalability, the proposed scheme not only provides good search quality, but\nalso achieves a stable throughput of around 210ms per image when searching a\n100M image collection. Our findings could help other researchers and\npractitioners to cope with huge multimedia collections.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jan 2015 22:05:45 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2015 00:56:17 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Shestakov", "Denis", ""], ["Moise", "Diana", ""]]}, {"id": "1501.02528", "submitter": "Changsheng Chen", "authors": "Changsheng Chen and Wai Ho Mow", "title": "A Systematic Scheme for Measuring the Performance of the Display-Camera\n  Channel", "comments": "8 pages, preliminary conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Display-camera communication has become a promising direction in both\ncomputer vision and wireless communication communities. However, the\nconsistency of the channel measurement is an open issue since precise\ncalibration of the experimental setting has not been fully studied in the\nliteratures. This paper focuses on establishing a scheme for precise\ncalibration of the display-camera channel performance. To guarantee high\nconsistency of the experiment, we propose an accurate measurement scheme for\nthe geometric parameters, and identify some unstable channel factors, e.g.,\nMoire effect, rolling shutter effect, blocking artifacts, inconsistency in\nauto-focus, trembling and vibration. In the experiment, we first define the\nconsistency criteria according to the error-prone region in bit error rate\n(BER) plots of the channel measurements. It is demonstrated that the\nconsistency of the experimental result can be improved by the proposed precise\ncalibration scheme.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 03:13:34 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Chen", "Changsheng", ""], ["Mow", "Wai Ho", ""]]}, {"id": "1501.02659", "submitter": "Damianos Gavalas", "authors": "Thomas Chatzidimitris, Damianos Gavalas, Vlasios Kasapakis", "title": "PacMap: Transferring PacMan to the Physical Realm", "comments": "6 pages, 3 figures, Proceedings of the International Conference on\n  Pervasive Games (PERGAMES'2014), Rome, Italy, 27 October 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the implementation of the pervasive game PacMap.\nOpenness and portability have been the main design objectives for PacMap. We\nelaborate on programming techniques which may be applicable to a broad range of\nlocation-based games that involve the movement of virtual characters over map\ninterfaces. In particular, we present techniques to execute shortest path\nalgorithms on spatial environments bypassing the restrictions imposed by\ncommercial mapping services. Last, we present ways to improve the movement and\nenhance the intelligence of virtual characters taking into consideration the\nactions and position of players in location-based games.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 14:27:37 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Chatzidimitris", "Thomas", ""], ["Gavalas", "Damianos", ""], ["Kasapakis", "Vlasios", ""]]}, {"id": "1501.02686", "submitter": "Stavros Nikolopoulos D.", "authors": "Maria Chroni and Stavros D. Nikolopoulos", "title": "Watermarking PDF Documents using Various Representations of\n  Self-inverting Permutations", "comments": "17 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:1003.1796 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides to web users copyright protection of their Portable\nDocument Format (PDF) documents by proposing efficient and easily implementable\ntechniques for PDF watermarking; our techniques are based on the ideas of our\nrecently proposed watermarking techniques for software, image, and audio,\nexpanding thus the digital objects that can be efficiently watermarked through\nthe use of self-inverting permutations. In particular, we present various\nrepresentations of a self-inverting permutation $\\pi^*$ namely\n1D-representation, 2D-representation, and RPG-representation, and show that\ntheses representations can be efficiently applied to PDF watermarking. Indeed,\nwe first present an audio-based technique for marking a PDF document $T$ by\nexploiting the 1D-representation of a permutation $\\pi^*$, and then, since\npages of a PDF document $T$ are 2D objects, we present an image-based algorithm\nfor encoding $\\pi^*$ into $T$ by first mapping the elements of $\\pi^*$ into a\nmatrix $A^*$ and then using the information stored in $A^*$ to mark invisibly\nspecific areas of PDF document $T$. Finally, we describe a graph-based\nwatermarking algorithm for embedding a self-inverting permutation $\\pi^*$ into\nthe document structure of a PDF file $T$ by exploiting the RPG-representation\nof $\\pi^*$ and the structure of a PDF document. We have evaluated the embedding\nand extracting algorithms by testing them on various and different in\ncharacteristics PDF documents.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 16:09:48 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Chroni", "Maria", ""], ["Nikolopoulos", "Stavros D.", ""]]}, {"id": "1501.02894", "submitter": "Mahdi Salarian mr", "authors": "Mehdi. Salarian, Babak. Mohamadinia, Jalil Rasekhi", "title": "A Modified No Search Algorithm for Fractal Image Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractal image compression has some desirable properties like high quality at\nhigh compression ratio, fast decoding, and resolution independence. Therefore\nit can be used for many applications such as texture mapping and pattern\nrecognition and image watermarking. But it suffers from long encoding time due\nto its need to find the best match between sub blocks. This time is related to\nthe approach that is used. In this paper we present a fast encoding Algorithm\nbased on no search method. Our goal is that more blocks are covered in initial\nstep of quad tree algorithm. Experimental result has been compared with other\nnew fast fractal coding methods, showing it is better in term of bit rate in\nsame condition while the other parameters are fixed.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 07:19:17 GMT"}, {"version": "v2", "created": "Thu, 15 Jan 2015 07:22:07 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Salarian", "Mehdi.", ""], ["Mohamadinia", "Babak.", ""], ["Rasekhi", "Jalil", ""]]}, {"id": "1501.02995", "submitter": "Renato J Cintra", "authors": "U. S. Potluri, A. Madanayake, R. J. Cintra, F. M. Bayer, S.\n  Kulasekera, A. Edirisuriya", "title": "Improved 8-point Approximate DCT for Image and Video Compression\n  Requiring Only 14 Additions", "comments": "30 pages, 7 figures, 5 tables", "journal-ref": "Circuits and Systems I: Regular Papers, IEEE Transactions on,\n  Volume 61, Issue 6, June 2014, 1727--1740", "doi": "10.1109/TCSI.2013.2295022", "report-no": null, "categories": "cs.MM cs.CV cs.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video processing systems such as HEVC requiring low energy consumption needed\nfor the multimedia market has lead to extensive development in fast algorithms\nfor the efficient approximation of 2-D DCT transforms. The DCT is employed in a\nmultitude of compression standards due to its remarkable energy compaction\nproperties. Multiplier-free approximate DCT transforms have been proposed that\noffer superior compression performance at very low circuit complexity. Such\napproximations can be realized in digital VLSI hardware using additions and\nsubtractions only, leading to significant reductions in chip area and power\nconsumption compared to conventional DCTs and integer transforms. In this\npaper, we introduce a novel 8-point DCT approximation that requires only 14\naddition operations and no multiplications. The proposed transform possesses\nlow computational complexity and is compared to state-of-the-art DCT\napproximations in terms of both algorithm complexity and peak signal-to-noise\nratio. The proposed DCT approximation is a candidate for reconfigurable video\nstandards such as HEVC. The proposed transform and several other DCT\napproximations are mapped to systolic-array digital architectures and\nphysically realized as digital prototype circuits using FPGA technology and\nmapped to 45 nm CMOS technology.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jan 2015 13:26:40 GMT"}], "update_date": "2015-01-14", "authors_parsed": [["Potluri", "U. S.", ""], ["Madanayake", "A.", ""], ["Cintra", "R. J.", ""], ["Bayer", "F. M.", ""], ["Kulasekera", "S.", ""], ["Edirisuriya", "A.", ""]]}, {"id": "1501.03307", "submitter": "Andrea Tassi", "authors": "Andrew L. Jones, Ioannis Chatzigeorgiou, Andrea Tassi", "title": "Binary Systematic Network Coding for Progressive Packet Decoding", "comments": "Proc. of IEEE ICC 2015 - Communication Theory Symposium, to appear", "journal-ref": null, "doi": "10.1109/ICC.2015.7249031", "report-no": null, "categories": "cs.IT cs.MM cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider binary systematic network codes and investigate their capability\nof decoding a source message either in full or in part. We carry out a\nprobability analysis, derive closed-form expressions for the decoding\nprobability and show that systematic network coding outperforms conventional\nnetwork coding. We also develop an algorithm based on Gaussian elimination that\nallows progressive decoding of source packets. Simulation results show that the\nproposed decoding algorithm can achieve the theoretical optimal performance.\nFurthermore, we demonstrate that systematic network codes equipped with the\nproposed algorithm are good candidates for progressive packet recovery owing to\ntheir overall decoding delay characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 10:52:10 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Jones", "Andrew L.", ""], ["Chatzigeorgiou", "Ioannis", ""], ["Tassi", "Andrea", ""]]}, {"id": "1501.03310", "submitter": "Andrea Tassi", "authors": "Lorenzo Carl\\`a, Francesco Chiti, Romano Fantacci, Andrea Tassi", "title": "Sleep Period Optimization Model For Layered Video Service Delivery Over\n  eMBMS Networks", "comments": "Proc. of IEEE ICC 2015, Selected Areas in Communications Symposium -\n  Green Communications Track, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.MM cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Term Evolution-Advanced (LTE-A) and the evolved Multimedia Broadcast\nMulticast System (eMBMS) are the most promising technologies for the delivery\nof highly bandwidth demanding applications. In this paper we propose a green\nresource allocation strategy for the delivery of layered video streams to users\nwith different propagation conditions. The goal of the proposed model is to\nminimize the user energy consumption. That goal is achieved by minimizing the\ntime required by each user to receive the broadcast data via an efficient power\ntransmission allocation model. A key point in our system model is that the\nreliability of layered video communications is ensured by means of the Random\nLinear Network Coding (RLNC) approach. Analytical results show that the\nproposed resource allocation model ensures the desired quality of service\nconstraints, while the user energy footprint is significantly reduced.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 10:53:10 GMT"}], "update_date": "2015-01-15", "authors_parsed": [["Carl\u00e0", "Lorenzo", ""], ["Chiti", "Francesco", ""], ["Fantacci", "Romano", ""], ["Tassi", "Andrea", ""]]}, {"id": "1501.03311", "submitter": "Andrea Tassi", "authors": "Andrea Tassi, Ioannis Chatzigeorgiou, Dejan Vukobratovi\\'c, Andrew L.\n  Jones", "title": "Optimized Network-coded Scalable Video Multicasting over eMBMS Networks", "comments": "Proc. of IEEE ICC 2015 - Mobile and Wireless Networking Symposium, to\n  appear", "journal-ref": null, "doi": "10.1109/ICC.2015.7248795", "report-no": null, "categories": "cs.IT cs.MM cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delivery of multicast video services over fourth generation (4G) networks\nsuch as 3GPP Long Term Evolution-Advanced (LTE-A) is gaining momentum. In this\npaper, we address the issue of efficiently multicasting layered video services\nby defining a novel resource allocation framework that aims to maximize the\nservice coverage whilst keeping the radio resource footprint low. A key point\nin the proposed system mode is that the reliability of multicast video services\nis ensured by means of an Unequal Error Protection implementation of the\nNetwork Coding (UEP-NC) scheme. In addition, both the communication parameters\nand the UEP-NC scheme are jointly optimized by the proposed resource allocation\nframework. Numerical results show that the proposed allocation framework can\nsignificantly increase the service coverage when compared to a conventional\nMulti-rate Transmission (MrT) strategy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jan 2015 10:53:55 GMT"}, {"version": "v2", "created": "Tue, 20 Jan 2015 09:53:57 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Tassi", "Andrea", ""], ["Chatzigeorgiou", "Ioannis", ""], ["Vukobratovi\u0107", "Dejan", ""], ["Jones", "Andrew L.", ""]]}, {"id": "1501.03613", "submitter": "Lorenzo  Carl\\`a", "authors": "Lorenzo Carl\\`a, Romano Fantacci, Francesco Gei, Dania Marabissi,\n  Luigia Micciullo", "title": "LTE enhancements for Public Safety and Security communications to\n  support Group Multimedia Communications", "comments": "IEEE Network Magazine, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently Public Safety and Security communication systems rely on reliable\nand secure Professional Mobile Radio (PMR) Networks that are mainly devoted to\nprovide voice services. However, the evolution trend for PMR networks is\ntowards the provision of new value-added multimedia services such as video\nstreaming, in order to improve the situational awareness and enhance the\nlife-saving operations. The challenge here is to exploit the future commercial\nbroadband networks to deliver voice and multimedia services satisfying the PMR\nservice requirements. In particular, a viable solution till now seems that of\nadapting the new Long Term Evolution technology to provide IP-based broadband\nservices with the security and reliability typical of PMR networks. This paper\noutlines different alternatives to achieve this goal and, in particular,\nproposes a proper solution for providing multimedia services with PMR standards\nover commercial LTE networks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2015 09:46:22 GMT"}], "update_date": "2015-01-16", "authors_parsed": [["Carl\u00e0", "Lorenzo", ""], ["Fantacci", "Romano", ""], ["Gei", "Francesco", ""], ["Marabissi", "Dania", ""], ["Micciullo", "Luigia", ""]]}, {"id": "1501.04254", "submitter": "Zhisheng Yan", "authors": "Zhisheng Yan, Cedric Westphal, Xin Wang, Chang Wen Chen", "title": "Service Provisioning and Profit Maximization in Network-assisted\n  Adaptive HTTP Streaming", "comments": "ICIP 2015 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive HTTP streaming with centralized consideration of multiple streams\nhas gained increasing interest. It poses a special challenge that the interests\nof both content provider and network operator need to be deliberately balanced.\nMore importantly, the adaptation strategy is required to be flexible enough to\nbe ported to various systems that work under different network environments,\nQoE levels, and economic objectives. To address these challenges, we propose a\nMarkov Decision Process (MDP) based network-assisted adaptation framework,\nwherein cost of buffering, significant playback variation, bandwidth management\nand income of playback are jointly investigated. We then demonstrate its\npromising service provisioning and maximal profit for a mobile network in which\nfair or differentiated service is required.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2015 02:16:02 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Yan", "Zhisheng", ""], ["Westphal", "Cedric", ""], ["Wang", "Xin", ""], ["Chen", "Chang Wen", ""]]}, {"id": "1501.04560", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Timothy M. Hospedales, Tao Xiang and Shaogang Gong", "title": "Transductive Multi-view Zero-Shot Learning", "comments": "accepted by IEEE TPAMI, more info and longer report will be available\n  in :http://www.eecs.qmul.ac.uk/~yf300/embedding/index.html", "journal-ref": null, "doi": "10.1109/TPAMI.2015.2408354", "report-no": null, "categories": "cs.CV cs.DS cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing zero-shot learning approaches exploit transfer learning via an\nintermediate-level semantic representation shared between an annotated\nauxiliary dataset and a target dataset with different classes and no\nannotation. A projection from a low-level feature space to the semantic\nrepresentation space is learned from the auxiliary dataset and is applied\nwithout adaptation to the target dataset. In this paper we identify two\ninherent limitations with these approaches. First, due to having disjoint and\npotentially unrelated classes, the projection functions learned from the\nauxiliary dataset/domain are biased when applied directly to the target\ndataset/domain. We call this problem the projection domain shift problem and\npropose a novel framework, transductive multi-view embedding, to solve it. The\nsecond limitation is the prototype sparsity problem which refers to the fact\nthat for each target class, only a single prototype is available for zero-shot\nlearning given a semantic representation. To overcome this problem, a novel\nheterogeneous multi-view hypergraph label propagation method is formulated for\nzero-shot learning in the transductive embedding space. It effectively exploits\nthe complementary information offered by different semantic representations and\ntakes advantage of the manifold structures of multiple representation spaces in\na coherent manner. We demonstrate through extensive experiments that the\nproposed approach (1) rectifies the projection shift between the auxiliary and\ntarget domains, (2) exploits the complementarity of multiple semantic\nrepresentations, (3) significantly outperforms existing methods for both\nzero-shot and N-shot recognition on three image and video benchmark datasets,\nand (4) enables novel cross-view annotation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2015 17:04:11 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2015 04:43:44 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Fu", "Yanwei", ""], ["Hospedales", "Timothy M.", ""], ["Xiang", "Tao", ""], ["Gong", "Shaogang", ""]]}, {"id": "1501.06202", "submitter": "Yanwei  Fu", "authors": "Yanwei Fu, Timothy M. Hospedales, Tao Xiang, Jiechao Xiong, Shaogang\n  Gong, Yizhou Wang, and Yuan Yao", "title": "Robust Subjective Visual Property Prediction from Crowdsourced Pairwise\n  Labels", "comments": "14 pages, accepted by IEEE TPAMI", "journal-ref": null, "doi": "10.1109/TPAMI.2015.2456887", "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.SI math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of estimating subjective visual properties from image and video\nhas attracted increasing interest. A subjective visual property is useful\neither on its own (e.g. image and video interestingness) or as an intermediate\nrepresentation for visual recognition (e.g. a relative attribute). Due to its\nambiguous nature, annotating the value of a subjective visual property for\nlearning a prediction model is challenging. To make the annotation more\nreliable, recent studies employ crowdsourcing tools to collect pairwise\ncomparison labels because human annotators are much better at ranking two\nimages/videos (e.g. which one is more interesting) than giving an absolute\nvalue to each of them separately. However, using crowdsourced data also\nintroduces outliers. Existing methods rely on majority voting to prune the\nannotation outliers/errors. They thus require large amount of pairwise labels\nto be collected. More importantly as a local outlier detection method, majority\nvoting is ineffective in identifying outliers that can cause global ranking\ninconsistencies. In this paper, we propose a more principled way to identify\nannotation outliers by formulating the subjective visual property prediction\ntask as a unified robust learning to rank problem, tackling both the outlier\ndetection and learning to rank jointly. Differing from existing methods, the\nproposed method integrates local pairwise comparison labels together to\nminimise a cost that corresponds to global inconsistency of ranking order. This\nnot only leads to better detection of annotation outliers but also enables\nlearning with extremely sparse annotations. Extensive experiments on various\nbenchmark datasets demonstrate that our new approach significantly outperforms\nstate-of-the-arts alternatives.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jan 2015 20:02:45 GMT"}, {"version": "v2", "created": "Fri, 30 Jan 2015 05:13:45 GMT"}, {"version": "v3", "created": "Fri, 24 Jul 2015 18:40:56 GMT"}, {"version": "v4", "created": "Mon, 27 Jul 2015 14:42:17 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Fu", "Yanwei", ""], ["Hospedales", "Timothy M.", ""], ["Xiang", "Tao", ""], ["Xiong", "Jiechao", ""], ["Gong", "Shaogang", ""], ["Wang", "Yizhou", ""], ["Yao", "Yuan", ""]]}, {"id": "1501.07034", "submitter": "Valery Gorbachev", "authors": "V.N. Gorbachev, L.A. Denisov, E.M. Kainarova", "title": "Embedding of binary image in the Gray planes", "comments": "7 pages, 3 figures, Proceeding of 24rd International Conference on\n  Computer Graphics and Vision GraphiCon'2014, Sept.30 - Oct.3,2014,\n  Rostov-on-Don, Russia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For watermarking of the digital grayscale image its Gray planes have been\nused. With the help of the introduced representation over Gray planes the LSB\nembedding method and detection have been discussed. It found that data, a\nbinary image, hidden in the Gray planes is more robust to JPEG lossy\ncompression than in the bit planes.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 08:58:20 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Gorbachev", "V. N.", ""], ["Denisov", "L. A.", ""], ["Kainarova", "E. M.", ""]]}, {"id": "1501.07304", "submitter": "Miriam Redi", "authors": "Miriam Redi, Nikhil Rasiwasia, Gaurav Aggarwal, Alejandro Jaimes", "title": "The Beauty of Capturing Faces: Rating the Quality of Digital Portraits", "comments": "FG 2015, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital portrait photographs are everywhere, and while the number of face\npictures keeps growing, not much work has been done to on automatic portrait\nbeauty assessment. In this paper, we design a specific framework to\nautomatically evaluate the beauty of digital portraits. To this end, we procure\na large dataset of face images annotated not only with aesthetic scores but\nalso with information about the traits of the subject portrayed. We design a\nset of visual features based on portrait photography literature, and\nextensively analyze their relation with portrait beauty, exposing interesting\nfindings about what makes a portrait beautiful. We find that the beauty of a\nportrait is linked to its artistic value, and independent from age, race and\ngender of the subject. We also show that a classifier trained with our features\nto separate beautiful portraits from non-beautiful portraits outperforms\ngeneric aesthetic classifiers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jan 2015 22:51:23 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Redi", "Miriam", ""], ["Rasiwasia", "Nikhil", ""], ["Aggarwal", "Gaurav", ""], ["Jaimes", "Alejandro", ""]]}]