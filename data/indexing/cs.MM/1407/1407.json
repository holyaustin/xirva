[{"id": "1407.0623", "submitter": "Lamberto Ballan", "authors": "Lamberto Ballan, Marco Bertini, Giuseppe Serra, Alberto Del Bimbo", "title": "A Data-Driven Approach for Tag Refinement and Localization in Web Videos", "comments": "Preprint submitted to Computer Vision and Image Understanding (CVIU)", "journal-ref": null, "doi": "10.1016/j.cviu.2015.05.009", "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tagging of visual content is becoming more and more widespread as web-based\nservices and social networks have popularized tagging functionalities among\ntheir users. These user-generated tags are used to ease browsing and\nexploration of media collections, e.g. using tag clouds, or to retrieve\nmultimedia content. However, not all media are equally tagged by users. Using\nthe current systems is easy to tag a single photo, and even tagging a part of a\nphoto, like a face, has become common in sites like Flickr and Facebook. On the\nother hand, tagging a video sequence is more complicated and time consuming, so\nthat users just tag the overall content of a video. In this paper we present a\nmethod for automatic video annotation that increases the number of tags\noriginally provided by users, and localizes them temporally, associating tags\nto keyframes. Our approach exploits collective knowledge embedded in\nuser-generated tags and web sources, and visual similarity of keyframes and\nimages uploaded to social sites like YouTube and Flickr, as well as web sources\nlike Google and Bing. Given a keyframe, our method is able to select on the fly\nfrom these visual sources the training exemplars that should be the most\nrelevant for this test sample, and proceeds to transfer labels across similar\nimages. Compared to existing video tagging approaches that require training\nclassifiers for each tag, our system has few parameters, is easy to implement\nand can deal with an open vocabulary scenario. We demonstrate the approach on\ntag refinement and localization on DUT-WEBV, a large dataset of web videos, and\nshow state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 15:48:37 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2015 18:12:36 GMT"}, {"version": "v3", "created": "Thu, 28 May 2015 17:12:54 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Ballan", "Lamberto", ""], ["Bertini", "Marco", ""], ["Serra", "Giuseppe", ""], ["Del Bimbo", "Alberto", ""]]}, {"id": "1407.2221", "submitter": "Valerie Gouranton", "authors": "Laurent Simon (LIMSI), Florian Nouviale (INSA Rennes, INRIA - IRISA),\n  Ronan Gaugne (UR1), Val\\'erie Gouranton (INSA Rennes, INRIA - IRISA)", "title": "Sonic interaction with a virtual orchestra of factory machinery", "comments": "Sonic Interaction for Virtual Environments, Minneapolis : United\n  States (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an immersive application where users receive sound and\nvisual feedbacks on their interactions with a virtual environment. In this\napplication, the users play the part of conductors of an orchestra of factory\nmachines since each of their actions on interaction devices triggers a pair of\nvisual and audio responses. Audio stimuli were spatialized around the listener.\nThe application was exhibited during the 2013 Science and Music day and\ndesigned to be used in a large immersive system with head tracking, shutter\nglasses and a 10.2 loudspeaker configuration.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jul 2014 06:29:34 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Simon", "Laurent", "", "LIMSI"], ["Nouviale", "Florian", "", "INSA Rennes, INRIA - IRISA"], ["Gaugne", "Ronan", "", "UR1"], ["Gouranton", "Val\u00e9rie", "", "INSA Rennes, INRIA - IRISA"]]}, {"id": "1407.2729", "submitter": "Rohit  Tanwar", "authors": "Manisha Rana, Rohit Tanwar", "title": "Genetic Algorithm in Audio Steganography", "comments": "6 pages,2 figures Published with International Journal of Engineering\n  Trends and Technology (IJETT). arXiv admin note: text overlap with\n  arXiv:1003.4084, arXiv:1205.2800 by other authors without attribution", "journal-ref": "IJETT, V13(1),29-34 July 2014", "doi": "10.14445/22315381/IJETT-V13P206", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of communication technology,data is exchanged digitally\nover the network. At the other side the technology is also proven as a tool for\nunauthorized access to attackers. Thus the security of data to be transmitted\ndigitally should get prime focus. Data hiding is the common approach to secure\ndata. In steganography technique, the existence of data is concealed. GA is an\nemerging component of AI to provide suboptimal solutions. In this paper the use\nof GA in Steganography is explored to find future scope of research.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 09:07:03 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Rana", "Manisha", ""], ["Tanwar", "Rohit", ""]]}, {"id": "1407.2971", "submitter": "Tomoyoshi Shimobaba Dr.", "authors": "Tomoyoshi Shimobaba, Michal Makowski, Takashi Kakue, Naohisa Okada,\n  Yutaka Endo, Ryuji Hirayam, Daisuke Hiyama, Satoki Hasegawa, Yuki Nagahama,\n  Tomoyoshi Ito", "title": "Numerical investigation of lensless zoomable holographic multiple\n  projections to tilted planes", "comments": null, "journal-ref": null, "doi": "10.1016/j.optcom.2014.07.081", "report-no": null, "categories": "physics.optics cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper numerically investigates the feasibility of lensless zoomable\nholographic multiple projections to tilted planes. We have already developed\nlensless zoomable holographic single projection using scaled diffraction, which\ncalculates diffraction between parallel planes with different sampling pitches.\nThe structure of this zoomable holographic projection is very simple because it\ndoes not need a lens; however, it only projects a single image to a plane\nparallel to the hologram. The lensless zoomable holographic projection in this\npaper is capable of projecting multiple images onto tilted planes\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 21:27:03 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Shimobaba", "Tomoyoshi", ""], ["Makowski", "Michal", ""], ["Kakue", "Takashi", ""], ["Okada", "Naohisa", ""], ["Endo", "Yutaka", ""], ["Hirayam", "Ryuji", ""], ["Hiyama", "Daisuke", ""], ["Hasegawa", "Satoki", ""], ["Nagahama", "Yuki", ""], ["Ito", "Tomoyoshi", ""]]}, {"id": "1407.4735", "submitter": "Lalit Kumar Saini", "authors": "Lalit Kumar Saini, Vishal Shrivastava", "title": "A Survey of Digital Watermarking Techniques and its Applications", "comments": "4 Pages", "journal-ref": "IJCST V2(3): Page(70-73) May-June 2014", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Digital media is the need of a people now a day as the alternate of paper\nmedia.As the technology grown up digital media required protection while\ntransferring through internet or others mediums.Watermarking techniques have\nbeen developed to fulfill this requirement.This paper aims to provide a\ndetailed survey of all watermarking techniques specially focuses on image\nwatermarking types and its applications in today world.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 16:56:15 GMT"}], "update_date": "2014-07-18", "authors_parsed": [["Saini", "Lalit Kumar", ""], ["Shrivastava", "Vishal", ""]]}, {"id": "1407.4738", "submitter": "Lalit Kumar Saini", "authors": "Lalit Kumar Saini, Vishal Shrivastava", "title": "Analysis of Attacks on Hybrid DWT-DCT Algorithm for Digital Image\n  Watermarking With MATLAB", "comments": "4 Pages", "journal-ref": "IJCST V2(3): Page(123-125) May-June 2014. ISSN: 2347-8578.\n  www.ijcstjournal.org", "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Watermarking algorithms needs properties of robustness and perceptibility.\nBut these properties are affected by different -2 types of attacks performed on\nwatermarked images. The goal of performing attacks is destroy the information\nof watermark hidden in the watermarked image. So every Algorithms should be\npreviously tested by developers so that it would not affected by attacks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 17:07:13 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Saini", "Lalit Kumar", ""], ["Shrivastava", "Vishal", ""]]}, {"id": "1407.4865", "submitter": "Pushkar Dixit", "authors": "Pushkar Dixit, Nishant Singh, Jay Prakash Gupta", "title": "Robust Lossless Semi Fragile Information Protection in Images", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  diffusion process", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet security finds it difficult to keep the information secure and to\nmaintain the integrity of the data. Sending messages over the internet secretly\nis one of the major tasks as it is widely used for passing the message.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 01:37:21 GMT"}, {"version": "v2", "created": "Sat, 26 Jul 2014 13:19:04 GMT"}, {"version": "v3", "created": "Wed, 30 Jul 2014 00:47:07 GMT"}, {"version": "v4", "created": "Thu, 14 Aug 2014 12:10:59 GMT"}], "update_date": "2014-08-15", "authors_parsed": [["Dixit", "Pushkar", ""], ["Singh", "Nishant", ""], ["Gupta", "Jay Prakash", ""]]}, {"id": "1407.5145", "submitter": "Yongtao Hu", "authors": "Yongtao Hu, Jan Kautz, Yizhou Yu and Wenping Wang", "title": "Speaker-following Video Subtitles", "comments": null, "journal-ref": null, "doi": "10.1145/2632111", "report-no": null, "categories": "cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for improving the presentation of subtitles in video\n(e.g. TV and movies). With conventional subtitles, the viewer has to constantly\nlook away from the main viewing area to read the subtitles at the bottom of the\nscreen, which disrupts the viewing experience and causes unnecessary eyestrain.\nOur method places on-screen subtitles next to the respective speakers to allow\nthe viewer to follow the visual content while simultaneously reading the\nsubtitles. We use novel identification algorithms to detect the speakers based\non audio and visual information. Then the placement of the subtitles is\ndetermined using global optimization. A comprehensive usability study indicated\nthat our subtitle placement method outperformed both conventional\nfixed-position subtitling and another previous dynamic subtitling method in\nterms of enhancing the overall viewing experience and reducing eyestrain.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jul 2014 05:06:16 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Hu", "Yongtao", ""], ["Kautz", "Jan", ""], ["Yu", "Yizhou", ""], ["Wang", "Wenping", ""]]}, {"id": "1407.5527", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam and Mohamed Cheriet", "title": "Quality of Experience (QoE) beyond Quality of Service (QoS) as its\n  baseline: QoE at the Interface of Experience Domains", "comments": "31 pages, 3 figures, and 1 table. Working Paper WP-RFM-14-02", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a new approach to the definition of the quality of experience\nis presented. By considering the quality of service as a baseline, that portion\nof the QoE that can be inferred from the QoS is excluded, and then the rest of\nthe QoE is approached with the notion of QoE at a Boundary (QoEaaB). With the\nQoEaaB as the core of the proposed approach, various potential boundaries, and\ntheir associated unseen opportunities to improve the QoE are discussed. In\nparticular, property, contract, SLA, and content are explored in terms of their\nboundaries and also their associated QoEaaB. With an interest in online video\ndelivery, management of resource sharing and isolation associated with\nmulti-tenant operations is considered. It is concluded that the proposed QoEaaB\ncan bring a new perspective in QoE modeling and assessment toward a more\nenriched approach to improving the experience based on innovation and deep\nconnectivity among actors.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 15:13:06 GMT"}, {"version": "v2", "created": "Thu, 24 Jul 2014 16:30:35 GMT"}, {"version": "v3", "created": "Mon, 18 Aug 2014 18:20:23 GMT"}, {"version": "v4", "created": "Mon, 9 Feb 2015 21:23:13 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1407.6877", "submitter": "Minati Mishra", "authors": "Minati Mishra and M. C. Adhikary", "title": "An Easy yet Effective Method for Detecting Spatial Domain LSB\n  Steganography", "comments": "12 pages; International Journal of Computer Science and Business\n  Informatics, Dec 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digitization of image was a revolutionary step for the fields of photography\nand Image processing as this made the editing of images much effortless and\neasier. Image editing was not an issue until it was limited to corrective\nediting procedures used to enhance the quality of an image such as, contrast\nstretching, noise filtering, sharpening etc. But, it became a headache for many\nfields when image editing became manipulative. Digital images have become an\neasier source of tampering and forgery during last few decades. Today users and\nediting specialists, equipped with easily available image editing software,\nmanipulate digital images with varied goals. Photo journalists often tamper\nphotographs to give dramatic effect to their stories. Scientists and\nresearchers use this trick to get theirs works published. Patients' diagnoses\nare misrepresented by manipulating medical imageries. Lawyers and Politicians\nuse tampered images to direct the opinion of people or court to their favor.\nTerrorists, anti-social groups use manipulated Stego images for secret\ncommunication. In this paper we present an effective method for detecting\nspatial domain Steganography.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 12:58:23 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Mishra", "Minati", ""], ["Adhikary", "M. C.", ""]]}, {"id": "1407.6879", "submitter": "Minati Mishra", "authors": "Minati Mishra and M. C. Adhikary", "title": "Detection of Clones in Digital Images", "comments": "12 Pages, International Journal of Computer Science and Business\n  Informatics, Jan 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the recent years, tampering of digital images has become a general\nhabit among people and professionals. As a result, establishment of image\nauthenticity has become a key issue in fields those make use of digital images.\nAuthentication of an image involves separation of original camera outputs from\ntheir tampered or Stego counterparts. Digital image cloning being a popular\ntype of image tampering, in this paper we have experimentally analyzed seven\ndifferent algorithms of cloning detection such as the simple overlapped block\nmatching with lexicographic sorting (SOBMwLS) algorithm, block matching with\ndiscrete cosine transformation, principal component analysis, discrete wavelet\ntransformation and singular value decomposition performed on the blocks (DCT,\nDWT, PCA, SVD), two combination models where, DCT and DWT are combined with\nsingular value decomposition (DCTSVD and DWTSVD. A comparative study of all\nthese techniques with respect to their time complexities and robustness of\ndetection against various post processing operations such as cropping,\nbrightness and contrast adjustments are presented in the paper.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jul 2014 13:00:50 GMT"}], "update_date": "2014-07-28", "authors_parsed": [["Mishra", "Minati", ""], ["Adhikary", "M. C.", ""]]}, {"id": "1407.7223", "submitter": "Zhanpeng Huang", "authors": "Zhanpeng Huang, Pan Hui, Christoph Peylo", "title": "When Augmented Reality Meets Big Data", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.MM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With computing and sensing woven into the fabric of everyday life, we live in\nan era where we are awash in a flood of data from which we can gain rich\ninsights. Augmented reality (AR) is able to collect and help analyze the\ngrowing torrent of data about user engagement metrics within our personal\nmobile and wearable devices. This enables us to blend information from our\nsenses and the digitalized world in a myriad of ways that was not possible\nbefore. AR and big data have a logical maturity that inevitably converge them.\nThe tread of harnessing AR and big data to breed new interesting applications\nis starting to have a tangible presence. In this paper, we explore the\npotential to capture value from the marriage between AR and big data\ntechnologies, following with several challenges that must be addressed to fully\nrealize this potential.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 13:21:10 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Huang", "Zhanpeng", ""], ["Hui", "Pan", ""], ["Peylo", "Christoph", ""]]}, {"id": "1407.7337", "submitter": "Kang Qingbo", "authors": "Qingbo Kang, Ke Li, Jichun Yang", "title": "A Digital Watermarking Approach Based on DCT Domain Combining QR Code\n  and Chaotic Theory", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": "10.1109/WOCN.2014.6923098", "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a robust watermarking approach based on Discrete Cosine\nTransform domain that combines Quick Response Code and chaotic system.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2014 07:04:04 GMT"}], "update_date": "2015-02-12", "authors_parsed": [["Kang", "Qingbo", ""], ["Li", "Ke", ""], ["Yang", "Jichun", ""]]}, {"id": "1407.7636", "submitter": "Ming Yan", "authors": "Qianqian Xu and Ming Yan and Yuan Yao", "title": "Fast Adaptive Algorithm for Robust Evaluation of Quality of Experience", "comments": "13 pages, 2 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is an integral part of robust evaluation for\ncrowdsourceable Quality of Experience (QoE) and has attracted much attention in\nrecent years. In QoE for multimedia, outliers happen because of different test\nconditions, human errors, abnormal variations in context, {etc}. In this paper,\nwe propose a simple yet effective algorithm for outlier detection and robust\nQoE evaluation named iterative Least Trimmed Squares (iLTS). The algorithm\nassigns binary weights to samples, i.e., 0 or 1 indicating if a sample is an\noutlier, then the outlier-trimmed subset least squares solutions give robust\nranking scores. An iterative optimization is carried alternatively between\nupdating weights and ranking scores which converges to a local optimizer in\nfinite steps. In our test setting, iLTS is up to 190 times faster than\nLASSO-based methods with a comparable performance. Moreover, a varied version\nof this method shows adaptation in outlier detection, which provides an\nautomatic detection to determine whether a data sample is an outlier without\n\\emph{a priori} knowledge about the amount of the outliers. The effectiveness\nand efficiency of iLTS are demonstrated on both simulated examples and\nreal-world applications. A Matlab package is provided to researchers exploiting\ncrowdsourcing paired comparison data for robust ranking.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2014 06:20:42 GMT"}, {"version": "v2", "created": "Wed, 22 Oct 2014 05:56:35 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Xu", "Qianqian", ""], ["Yan", "Ming", ""], ["Yao", "Yuan", ""]]}, {"id": "1407.7667", "submitter": "Norbert Zsak", "authors": "Norbert Zsak, Christian Wolff", "title": "Impact of video quality and wireless network interface on power\n  consumption of mobile devices", "comments": "2 pages, 1 figure, unpublished short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last years, many improvements were made to the hardware capability\nof mobile devices. As mobile software also became more interactive and data\nprocessing intensive, the increased power demand could not be compensated by\nthe improvements on battery technology. Adaptive systems can help to balance\nthe demand of applications with the limitations of battery resources. For\neffective systems, the influence of multimedia quality on power consumption of\nthe components of mobile devices needs to be better understood. In this paper,\nwe analyze the impact of video quality and wireless network type on the energy\nconsumption of a mobile device. We have found that the additional power\nconsumption is up to 38% higher when a movie is played over a WiFi network\ninstead from internal memory and 64% higher in case of a mobile network (3G).\nWe have also discovered that a higher movie quality not only affects the power\nconsumption of the CPU but also the power consumption of the WiFi unit by up to\n58% and up to 72% respectively on mobile networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2014 09:10:05 GMT"}, {"version": "v2", "created": "Fri, 1 Aug 2014 09:25:38 GMT"}], "update_date": "2014-08-04", "authors_parsed": [["Zsak", "Norbert", ""], ["Wolff", "Christian", ""]]}]