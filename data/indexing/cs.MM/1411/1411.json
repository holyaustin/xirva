[{"id": "1411.1705", "submitter": "Yuanyi Xue", "authors": "Yuanyi Xue and Beril Erkin and Yao Wang", "title": "A Novel No-reference Video Quality Metric for Evaluating Temporal\n  Jerkiness due to Frame Freezing", "comments": null, "journal-ref": null, "doi": "10.1109/TMM.2014.2368272", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel no-reference (NR) video quality metric that\nevaluates the impact of frame freezing due to either packet loss or late\narrival. Our metric uses a trained neural network acting on features that are\nchosen to capture the impact of frame freezing on the perceived quality. The\nconsidered features include the number of freezes, freeze duration statistics,\ninter-freeze distance statistics, frame difference before and after the freeze,\nnormal frame difference, and the ratio of them. We use the neural network to\nfind the mapping between features and subjective test scores. We optimize the\nnetwork structure and the feature selection through a cross validation\nprocedure, using training samples extracted from both VQEG and LIVE video\ndatabases. The resulting feature set and network structure yields accurate\nquality prediction for both the training data containing 54 test videos and a\nseparate testing dataset including 14 videos, with Pearson Correlation\nCoefficients greater than 0.9 and 0.8 for the training set and the testing set,\nrespectively. Our proposed metric has low complexity and could be utilized in a\nsystem with realtime processing constraint.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 16:29:30 GMT"}], "update_date": "2014-11-07", "authors_parsed": [["Xue", "Yuanyi", ""], ["Erkin", "Beril", ""], ["Wang", "Yao", ""]]}, {"id": "1411.1897", "submitter": "Md Baharul Islam", "authors": "Md Baharul Islam, Arif Ahmed, Md Kabirul Islam and Abu Kalam\n  Shamsuddin", "title": "Child Education Through Animation: An Experimental Study", "comments": null, "journal-ref": "International Journal of Computer Graphics and Animation, Vol. 4,\n  No. 4, October 2014 pg 43-52", "doi": null, "report-no": null, "categories": "cs.CY cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Teachers have tried to teach their students by introducing text books along\nwith verbal instructions in traditional education system. However, teaching and\nlearning methods could be changed for developing Information and Communication\nTechnology. It's time to adapt students with interactive learning system so\nthat they can improve their learning, catching, and memorizing capabilities. It\nis indispensable to create high quality and realistic leaning environment for\nstudents. Visual learning can be easier to understand and deal with their\nlearning. We developed visual learning materials in the form of video for\nstudents of primary level using different multimedia application tools. The\nobjective of this paper is to examine the impact of students abilities to\nacquire new knowledge or skills through visual learning materials and blended\nleaning that is integration of visual learning materials with teachers\ninstructions. We visited a primary school in Dhaka city for this study and\nconducted teaching with three different groups of students, (i) teacher taught\nstudents by traditional system on same materials and marked level of students\nability to adapt by a set of questions, (ii) another group was taught with only\nvisual learning material and assessment was done with 15 questionnaires, (iii)\nthe third group was taught with the video of solar system combined with\nteachers instructions and assessed with the same questionnaires. This\nintegration of visual materials with verbal instructions is a blended approach\nof learning. The interactive blended approach greatly promoted students ability\nof acquisition of knowledge and skills. Students response and perception were\nvery positive towards the blended technique than the other two methods. This\ninteractive blending leaning system may be an appropriate method especially for\nschool children.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 13:08:07 GMT"}], "update_date": "2014-11-10", "authors_parsed": [["Islam", "Md Baharul", ""], ["Ahmed", "Arif", ""], ["Islam", "Md Kabirul", ""], ["Shamsuddin", "Abu Kalam", ""]]}, {"id": "1411.2075", "submitter": "Md Baharul Islam", "authors": "Md. Baharul Islam, Md. Kabirul Islam, Arif Ahmed, Abu Kalam Shamsuddin", "title": "Interactive Digital Learning Materials for Kindergarten Students in\n  Bangladesh", "comments": "2nd SMART Conference 2013, International Journal of Trends in\n  Computer Science, Volume 2, Issue 11, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The pedagogy of teaching and learning has changed with the proliferation of\ncommunication technology and it is necessary to develop interactive learning\nmaterials for children that may improve their learning, catching, and\nmemorizing capabilities. Perhaps, one of the most important innovations in the\nage of technology is multimedia and its application. It is imperative to create\nhigh quality and realistic learning environment for children. Interactive\nlearning materials can be easier to understand and deal with their first\nlearning. We developed some interactive learning materials in the form of a\nvideo for Playgroup using multimedia application tools. This study investigated\nthe impact of students' abilities to acquire new knowledge or skills through\ninteractive learning materials. We visited one kindergartens (Nursery schools),\ninterviewed class teachers about their teaching methods and level of students'\nability of recognizing English alphabets, pictures, etc. The course teachers\nwere provided interactive learning materials to show their playgroups for a\nnumber of sessions. The video included English alphabets with related words and\npictures, and motivational fun. We noticed that almost all children were very\ninterested to interact with their leaning video. The students were assessed\nindividually and asked to recognize the alphabets, and pictures. The students\nadapted with their first alphabets very quickly. However, there were individual\ndifferences in their cognitive development. This interactive multimedia can be\nan alternative to traditional pedagogy for teaching playgroups.\n", "versions": [{"version": "v1", "created": "Sat, 8 Nov 2014 02:21:43 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Islam", "Md. Baharul", ""], ["Islam", "Md. Kabirul", ""], ["Ahmed", "Arif", ""], ["Shamsuddin", "Abu Kalam", ""]]}, {"id": "1411.2860", "submitter": "Yiannis Andreopoulos", "authors": "Mohammad Ashraful Anam, Paul N. Whatmough and Yiannis Andreopoulos", "title": "Precision-Energy-Throughput Scaling Of Generic Matrix Multiplication and\n  Convolution Kernels Via Linear Projections", "comments": null, "journal-ref": "IEEE Transactions on Circuits and Systems for Video Technology,\n  vol. 24, no. 11, pp. 1860-1873, Nov. 2014", "doi": null, "report-no": null, "categories": "cs.MM cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic matrix multiplication (GEMM) and one-dimensional\nconvolution/cross-correlation (CONV) kernels often constitute the bulk of the\ncompute- and memory-intensive processing within image/audio recognition and\nmatching systems. We propose a novel method to scale the energy and processing\nthroughput of GEMM and CONV kernels for such error-tolerant multimedia\napplications by adjusting the precision of computation. Our technique employs\nlinear projections to the input matrix or signal data during the top-level GEMM\nand CONV blocking and reordering. The GEMM and CONV kernel processing then uses\nthe projected inputs and the results are accumulated to form the final outputs.\nThroughput and energy scaling takes place by changing the number of projections\ncomputed by each kernel, which in turn produces approximate results, i.e.\nchanges the precision of the performed computation. Results derived from a\nvoltage- and frequency-scaled ARM Cortex A15 processor running face recognition\nand music matching algorithms demonstrate that the proposed approach allows for\n280%~440% increase of processing throughput and 75%~80% decrease of energy\nconsumption against optimized GEMM and CONV kernels without any impact in the\nobtained recognition or matching accuracy. Even higher gains can be obtained if\none is willing to tolerate some reduction in the accuracy of the recognition\nand matching applications.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 15:59:35 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Anam", "Mohammad Ashraful", ""], ["Whatmough", "Paul N.", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1411.4080", "submitter": "Miriam Redi", "authors": "Miriam Redi, Neil O Hare, Rossano Schifanella, Michele Trevisiol,\n  Alejandro Jaimes", "title": "6 Seconds of Sound and Vision: Creativity in Micro-Videos", "comments": "8 pages, 1 figures, conference IEEE CVPR 2014", "journal-ref": null, "doi": "10.1109/CVPR.2014.544", "report-no": null, "categories": "cs.MM cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of creativity, as opposed to related concepts such as beauty or\ninterestingness, has not been studied from the perspective of automatic\nanalysis of multimedia content. Meanwhile, short online videos shared on social\nmedia platforms, or micro-videos, have arisen as a new medium for creative\nexpression. In this paper we study creative micro-videos in an effort to\nunderstand the features that make a video creative, and to address the problem\nof automatic detection of creative content. Defining creative videos as those\nthat are novel and have aesthetic value, we conduct a crowdsourcing experiment\nto create a dataset of over 3,800 micro-videos labelled as creative and\nnon-creative. We propose a set of computational features that we map to the\ncomponents of our definition of creativity, and conduct an analysis to\ndetermine which of these features correlate most with creative video. Finally,\nwe evaluate a supervised approach to automatically detect creative video, with\npromising results, showing that it is necessary to model both aesthetic value\nand novelty to achieve optimal classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 23:29:18 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Redi", "Miriam", ""], ["Hare", "Neil O", ""], ["Schifanella", "Rossano", ""], ["Trevisiol", "Michele", ""], ["Jaimes", "Alejandro", ""]]}, {"id": "1411.4290", "submitter": "Rui Guerreiro", "authors": "Rui F.C. Guerreiro, Pedro M.Q. Aguiar", "title": "Maximizing compression efficiency through block rotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Discrete Cosine Transform (DCT) is widely used in lossy image and video\ncompression schemes, e.g., JPEG and MPEG. In this paper, we show that the\ncompression efficiency of the DCT is dependent on the edge directions within a\nblock. In particular, higher compression ratios are achieved when edges are\naligned with the image axes. To maximize compression for general images, we\npropose a rotated block DCT method. It consists of rotating each block, before\napplying the DCT, by an angle that aligns the edges, and rotating back the\nblock in the decompression stage. We show how to compute the rotation angle and\nanalyze two alternative block rotation approaches. Our experiments show that\nour method enables both a perceptual improvement and a PSNR increase of up to\n2dB, compared with the standard DCT, for low and medium bit rates.\n", "versions": [{"version": "v1", "created": "Sun, 16 Nov 2014 18:52:54 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Guerreiro", "Rui F. C.", ""], ["Aguiar", "Pedro M. Q.", ""]]}, {"id": "1411.4738", "submitter": "Cuicui Kang", "authors": "Cuicui Kang, Shengcai Liao, Yonghao He, Jian Wang, Wenjia Niu, Shiming\n  Xiang, Chunhong Pan", "title": "Cross-Modal Similarity Learning : A Low Rank Bilinear Formulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cross-media retrieval problem has received much attention in recent years\ndue to the rapid increasing of multimedia data on the Internet. A new approach\nto the problem has been raised which intends to match features of different\nmodalities directly. In this research, there are two critical issues: how to\nget rid of the heterogeneity between different modalities and how to match the\ncross-modal features of different dimensions. Recently metric learning methods\nshow a good capability in learning a distance metric to explore the\nrelationship between data points. However, the traditional metric learning\nalgorithms only focus on single-modal features, which suffer difficulties in\naddressing the cross-modal features of different dimensions. In this paper, we\npropose a cross-modal similarity learning algorithm for the cross-modal feature\nmatching. The proposed method takes a bilinear formulation, and with the\nnuclear-norm penalization, it achieves low-rank representation. Accordingly,\nthe accelerated proximal gradient algorithm is successfully imported to find\nthe optimal solution with a fast convergence rate O(1/t^2). Experiments on\nthree well known image-text cross-media retrieval databases show that the\nproposed method achieves the best performance compared to the state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 05:53:06 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2015 01:25:27 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Kang", "Cuicui", ""], ["Liao", "Shengcai", ""], ["He", "Yonghao", ""], ["Wang", "Jian", ""], ["Niu", "Wenjia", ""], ["Xiang", "Shiming", ""], ["Pan", "Chunhong", ""]]}, {"id": "1411.4790", "submitter": "Fredrick Ishengoma", "authors": "Fredrick R. Ishengoma", "title": "The Art of Data Hiding with Reed-Solomon Error Correcting Codes", "comments": null, "journal-ref": "International Journal of Computer Applications 106(14):28-31,\n  November 2014", "doi": "10.5120/18590-9902", "report-no": null, "categories": "cs.MM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the tremendous advancements in technology and the Internet, data\nsecurity has become a major issue around the globe. To guarantee that data is\nprotected and does not go to an unintended endpoint, the art of data hiding\n(steganography) emerged. Steganography is the art of hiding information such\nthat it is not detectable to the naked eye. Various techniques have been\nproposed for hiding a secret message in a carrier document. In this paper, we\npresent a novel design that applies Reed-Solomon (RS) error correcting codes in\nsteganographic applications. The model works by substituting the redundant RS\ncodes with the steganographic message. The experimental results show that the\nproposed design is satisfactory with the percentage of decoded information 100%\nand percentage of decoded secret message 97. 36%. The proposed model proved\nthat it could be applied in various steganographic applications.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 10:05:23 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Ishengoma", "Fredrick R.", ""]]}, {"id": "1411.5547", "submitter": "Andrea Tassi", "authors": "Andrea Tassi, Ioannis Chatzigeorgiou, Dejan Vukobratovi\\'c", "title": "Resource Allocation Frameworks for Network-coded Layered Multimedia\n  Multicast Services", "comments": "IEEE Journal on Selected Areas in Communications - Special Issue on\n  Fundamental Approaches to Network Coding in Wireless Communication Systems.\n  To appear", "journal-ref": null, "doi": "10.1109/JSAC.2014.2384231", "report-no": null, "categories": "cs.IT cs.MM cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosive growth of content-on-the-move, such as video streaming to\nmobile devices, has propelled research on multimedia broadcast and multicast\nschemes. Multi-rate transmission strategies have been proposed as a means of\ndelivering layered services to users experiencing different downlink channel\nconditions. In this paper, we consider Point-to-Multipoint layered service\ndelivery across a generic cellular system and improve it by applying different\nrandom linear network coding approaches. We derive packet error probability\nexpressions and use them as performance metrics in the formulation of resource\nallocation frameworks. The aim of these frameworks is both the optimization of\nthe transmission scheme and the minimization of the number of broadcast packets\non each downlink channel, while offering service guarantees to a predetermined\nfraction of users. As a case of study, our proposed frameworks are then adapted\nto the LTE-A standard and the eMBMS technology. We focus on the delivery of a\nvideo service based on the H.264/SVC standard and demonstrate the advantages of\nlayered network coding over multi-rate transmission. Furthermore, we establish\nthat the choice of both the network coding technique and resource allocation\nmethod play a critical role on the network footprint, and the quality of each\nreceived video layer.\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 13:39:59 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Tassi", "Andrea", ""], ["Chatzigeorgiou", "Ioannis", ""], ["Vukobratovi\u0107", "Dejan", ""]]}, {"id": "1411.6928", "submitter": "Lin Jianbiao", "authors": "Jianbiao Lin, Ke Ji, Hui Lin, Enyan Wu, Xin Gao", "title": "A Tag Identification Approach Based On Fragile Watermark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a tag identify approach based on fragile Watermark that\nbased on Least significant bit of the replacement that we first use a special\nway to initialize the cover to ensure that we can use random positions to embed\nthe information of tag. Using this way enhance the security of other to get the\nright information of this tag. Finally as long as the covered information can\nbe decoded, the completeness and accuracy of the tag information can be\nguaranteed. the result of simulation experiment show that this approach has\nhigh sensitivity and security .\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 17:23:19 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Lin", "Jianbiao", ""], ["Ji", "Ke", ""], ["Lin", "Hui", ""], ["Wu", "Enyan", ""], ["Gao", "Xin", ""]]}, {"id": "1411.7084", "submitter": "Hong Zhao", "authors": "Hong Zhao and Yifan Chen and Rui Wang and Hafiz Malik", "title": "Audio Splicing Detection and Localization Using Environmental Signature", "comments": "Submitted to IEEE Transactions on Information Forensics and Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audio splicing is one of the most common manipulation techniques in the area\nof audio forensics. In this paper, the magnitudes of acoustic channel impulse\nresponse and ambient noise are proposed as the environmental signature.\nSpecifically, the spliced audio segments are detected according to the\nmagnitude correlation between the query frames and reference frames via a\nstatically optimal threshold. The detection accuracy is further refined by\ncomparing the adjacent frames. The effectiveness of the proposed method is\ntested on two data sets. One is generated from TIMIT database, and the other\none is made in four acoustic environments using a commercial grade microphones.\nExperimental results show that the proposed method not only detects the\npresence of spliced frames, but also localizes the forgery segments with near\nperfect accuracy. Comparison results illustrate that the identification\naccuracy of the proposed scheme is higher than the previous schemes. In\naddition, experimental results also show that the proposed scheme is robust to\nMP3 compression attack, which is also superior to the previous works.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 02:10:26 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Zhao", "Hong", ""], ["Chen", "Yifan", ""], ["Wang", "Rui", ""], ["Malik", "Hafiz", ""]]}]