[{"id": "1403.0259", "submitter": "Gauri Joshi", "authors": "Gauri Joshi, Yuval Kochman, Gregory Wornell", "title": "The Effect of Block-wise Feedback on the Throughput-Delay Trade-off in\n  Streaming", "comments": "Accepted to INFOCOM 2014 Workshop on Communication and Networking\n  Techniques for Contemporary Video", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike traditional file transfer where only total delay matters, streaming\napplications impose delay constraints on each packet and require them to be in\norder. To achieve fast in-order packet decoding, we have to compromise on the\nthroughput. We study this trade-off between throughput and in-order decoding\ndelay, and in particular how it is affected by the frequency of block-wise\nfeedback to the source. When there is immediate feedback, we can achieve the\noptimal throughput and delay simultaneously. But as the feedback delay\nincreases, we have to compromise on at least one of these metrics. We present a\nspectrum of coding schemes that span different points on the throughput-delay\ntrade-off. Depending upon the delay-sensitivity and bandwidth limitations of\nthe application, one can choose an appropriate operating point on this\ntrade-off.\n", "versions": [{"version": "v1", "created": "Sun, 2 Mar 2014 19:10:30 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Joshi", "Gauri", ""], ["Kochman", "Yuval", ""], ["Wornell", "Gregory", ""]]}, {"id": "1403.3710", "submitter": "Mohammad Ashraful Hoque Mohammad Ashraful Hoque", "authors": "Mohammad Ashraful Hoque, Matti Siekkinen, Jukka K. Nurminen, Sasu\n  Tarkoma, and Mika Aalto", "title": "Saving Energy in Mobile Devices for On-Demand Multimedia Streaming -- A\n  Cross-Layer Approach", "comments": "Accepted in ACM Transactions on Multimedia Computing, Communications\n  and Applications (ACM TOMCCAP), November 2013", "journal-ref": null, "doi": "10.1145/2556942", "report-no": null, "categories": "cs.MM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel energy-efficient multimedia delivery system\ncalled EStreamer. First, we study the relationship between buffer size at the\nclient, burst-shaped TCP-based multimedia traffic, and energy consumption of\nwireless network interfaces in smartphones. Based on the study, we design and\nimplement EStreamer for constant bit rate and rate-adaptive streaming.\nEStreamer can improve battery lifetime by 3x, 1.5x and 2x while streaming over\nWi-Fi, 3G and 4G respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 Mar 2014 21:08:28 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Hoque", "Mohammad Ashraful", ""], ["Siekkinen", "Matti", ""], ["Nurminen", "Jukka K.", ""], ["Tarkoma", "Sasu", ""], ["Aalto", "Mika", ""]]}, {"id": "1403.4158", "submitter": "Reza Rahimi", "authors": "A. A. Milani, Reza Rahimi", "title": "A Methodology for Implementation of MMS Client on Embedded Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MMS (Multimedia Messaging Service) is the next generation of messaging\nservices in multimedia mobile communications. MMS enables messaging with full\nmultimedia content including images, audios, videos, texts and data, from\nclient to client or e-mail. MMS is based on WAP technology, so it is technology\nindependent. This means that enabling messages from a GSM/GPRS network to be\nsent to a TDMA or WCDMA network. In this paper a methodology for implementing\nMMS client on embedded platforms especially on Wince OS is described.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2014 16:42:43 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Milani", "A. A.", ""], ["Rahimi", "Reza", ""]]}, {"id": "1403.4169", "submitter": "Reza Rahimi", "authors": "Reza Rahimi, J Hengmeechai", "title": "Pervasive Image Computation: A Mobile Phone Application for getting\n  Information of the Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although many of the information processing systems are text-based, much of\nthe information in the real life is generally multimedia objects, so there is a\nneed to define and standardize the frame works for multimedia-based information\nprocessing systems. In this paper we consider the application of such a system\nnamely pervasive image computation system, in which the user uses the cellphone\nfor taking the picture of the objects, and he wants to get some information\nabout them. We have implemented two architectures, the first one, called online\narchitecture, which the user sends the picture to the server and server sends\nthe picture information directly back to him. In the second one, which is\ncalled offline architecture, the user uploads the image in one public image\ndatabase such as Flickr and sends the ID of the image in this database to the\nserver. The server processes the image and adds the information of the image in\nthe database, and finally the user can connect to the database and download the\nimage information. The implementation results show that these architectures are\nvery flexible and could be easily extended to be used in more complicated\npervasive multimedia systems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2014 17:03:01 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Rahimi", "Reza", ""], ["Hengmeechai", "J", ""]]}, {"id": "1403.6025", "submitter": "Ruven Pillay", "authors": "Emmanuel Bertin, Ruven Pillay, Chiara Marmo", "title": "Web-Based Visualization of Very Large Scientific Astronomy Imagery", "comments": "Published in Astronomy & Computing. IIPImage server available from\n  http://iipimage.sourceforge.net . Visiomatic code and demos available from\n  http://www.visiomatic.org/", "journal-ref": "Astronomy and Computing, vol. 10, pp. 43-53, Apr. 2015", "doi": "10.1016/j.ascom.2014.12.006", "report-no": null, "categories": "astro-ph.IM cs.CE cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing and navigating through large astronomy images from a remote\nlocation with current astronomy display tools can be a frustrating experience\nin terms of speed and ergonomics, especially on mobile devices. In this paper,\nwe present a high performance, versatile and robust client-server system for\nremote visualization and analysis of extremely large scientific images.\nApplications of this work include survey image quality control, interactive\ndata query and exploration, citizen science, as well as public outreach. The\nproposed software is entirely open source and is designed to be generic and\napplicable to a variety of datasets. It provides access to floating point data\nat terabyte scales, with the ability to precisely adjust image settings in\nreal-time. The proposed clients are light-weight, platform-independent web\napplications built on standard HTML5 web technologies and compatible with both\ntouch and mouse-based devices. We put the system to the test and assess the\nperformance of the system and show that a single server can comfortably handle\nmore than a hundred simultaneous users accessing full precision 32 bit\nastronomy data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Mar 2014 16:24:57 GMT"}, {"version": "v2", "created": "Fri, 9 Jan 2015 14:21:56 GMT"}, {"version": "v3", "created": "Sun, 1 Feb 2015 22:29:40 GMT"}, {"version": "v4", "created": "Thu, 5 Feb 2015 10:40:31 GMT"}], "update_date": "2015-02-06", "authors_parsed": [["Bertin", "Emmanuel", ""], ["Pillay", "Ruven", ""], ["Marmo", "Chiara", ""]]}, {"id": "1403.6658", "submitter": "Stavros Nikolopoulos D.", "authors": "Ioannis Chionis, Maria Chroni, and Stavros D. Nikolopoulos", "title": "WaterRPG: A Graph-based Dynamic Watermarking Model for Software\n  Protection", "comments": "27 pages, 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software watermarking involves embedding a unique identifier or,\nequivalently, a watermark value within a software to prove owner's authenticity\nand thus to prevent or discourage copyright infringement. Towards the embedding\nprocess, several graph theoretic watermarking algorithmic techniques encode the\nwatermark values as graph structures and embed them in application programs.\nRecently, we presented an efficient codec system for encoding a watermark\nnumber $w$ as a reducible permutation graph $F[\\pi^*]$ through the use of\nself-inverting permutations $\\pi^*$. In this paper, we propose a dynamic\nwatermarking model, which we call WaterRPG, for embedding the watermark graph\n$F[\\pi^*]$ into an application program $P$. The main idea behind the proposed\nwatermarking model is a systematic use of appropriate calls of specific\nfunctions of the program $P$. More precisely, for a specific input $I_{key}$ of\nthe program $P$, our model takes the dynamic call-graph $G(P, I_{key})$ of $P$\nand the watermark graph $F[\\pi^*]$, and produces the watermarked program $P^*$\nhaving the following key property: its dynamic call-graph $G(P^*, I_{key})$ is\nisomorphic to the watermark graph $F[\\pi^*]$. Within this idea the program\n$P^*$ is produced by only altering appropriate calls of specific functions of\nthe input application program $P$. We have implemented our watermarking model\nWaterRPG in real application programs and evaluated its functionality under\nvarious and broadly used watermarking assessment criteria. The evaluation\nresults show that our model efficiently watermarks Java application programs\nwith respect to several watermarking metrics like data-rate, bytecode\ninstructions overhead, resiliency, time and space efficiency. Moreover, the\nembedded watermarks withstand several software obfuscation and optimization\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2014 11:31:49 GMT"}], "update_date": "2014-03-27", "authors_parsed": [["Chionis", "Ioannis", ""], ["Chroni", "Maria", ""], ["Nikolopoulos", "Stavros D.", ""]]}, {"id": "1403.6901", "submitter": "Sunil Kumar Kopparapu Dr", "authors": "Sapna Soni and Ahmed Imran and Sunil Kumar Kopparapu", "title": "Automatic Segmentation of Broadcast News Audio using Self Similarity\n  Matrix", "comments": "4 pages, 5 images", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generally audio news broadcast on radio is com- posed of music, commercials,\nnews from correspondents and recorded statements in addition to the actual news\nread by the newsreader. When news transcripts are available, automatic\nsegmentation of audio news broadcast to time align the audio with the text\ntranscription to build frugal speech corpora is essential. We address the\nproblem of identifying segmentation in the audio news broadcast corresponding\nto the news read by the newsreader so that they can be mapped to the text\ntranscripts. The existing techniques produce sub-optimal solutions when used to\nextract newsreader read segments. In this paper, we propose a new technique\nwhich is able to identify the acoustic change points reliably using an acoustic\nSelf Similarity Matrix (SSM). We describe the two pass technique in detail and\nverify its performance on real audio news broadcast of All India Radio for\ndifferent languages.\n", "versions": [{"version": "v1", "created": "Thu, 27 Mar 2014 01:32:09 GMT"}], "update_date": "2014-03-28", "authors_parsed": [["Soni", "Sapna", ""], ["Imran", "Ahmed", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "1403.7591", "submitter": "Yin Cui", "authors": "Yin Cui, Dong Liu, Jiawei Chen, Shih-Fu Chang", "title": "Building A Large Concept Bank for Representing Events in Video", "comments": "25 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept-based video representation has proven to be effective in complex\nevent detection. However, existing methods either manually design concepts or\ndirectly adopt concept libraries not specifically designed for events. In this\npaper, we propose to build Concept Bank, the largest concept library consisting\nof 4,876 concepts specifically designed to cover 631 real-world events. To\nconstruct the Concept Bank, we first gather a comprehensive event collection\nfrom WikiHow, a collaborative writing project that aims to build the world's\nlargest manual for any possible How-To event. For each event, we then search\nFlickr and discover relevant concepts from the tags of the returned images. We\ntrain a Multiple Kernel Linear SVM for each discovered concept as a concept\ndetector in Concept Bank. We organize the concepts into a five-layer tree\nstructure, in which the higher-level nodes correspond to the event categories\nwhile the leaf nodes are the event-specific concepts discovered for each event.\nBased on such tree ontology, we develop a semantic matching method to select\nrelevant concepts for each textual event query, and then apply the\ncorresponding concept detectors to generate concept-based video\nrepresentations. We use TRECVID Multimedia Event Detection 2013 and Columbia\nConsumer Video open source event definitions and videos as our test sets and\nshow very promising results on two video event detection tasks: event modeling\nover concept space and zero-shot event retrieval. To the best of our knowledge,\nthis is the largest concept library covering the largest number of real-world\nevents.\n", "versions": [{"version": "v1", "created": "Sat, 29 Mar 2014 05:17:29 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Cui", "Yin", ""], ["Liu", "Dong", ""], ["Chen", "Jiawei", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1403.8055", "submitter": "Hatem Abou-zeid", "authors": "Hatem Abou-zeid and Hossam S. Hassanein and Stefan Valentin", "title": "Energy-Efficient Adaptive Video Transmission: Exploiting Rate\n  Predictions in Wireless Networks", "comments": "14 pages, 14 figures, accepted for publication in IEEE Transactions\n  on Vehicular Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unprecedented growth of mobile video traffic is adding significant\npressure to the energy drain at both the network and the end user. Energy\nefficient video transmission techniques are thus imperative to cope with the\nchallenge of satisfying user demand at sustainable costs. In this paper, we\ninvestigate how predicted user rates can be exploited for energy efficient\nvideo streaming with the popular HTTP-based Adaptive Streaming (AS) protocols\n(e.g. DASH). To this end, we develop an energy-efficient Predictive Green\nStreaming (PGS) optimization framework that leverages predictions of wireless\ndata rates to achieve the following objectives 1) minimize the required\ntransmission airtime without causing streaming interruptions, 2) minimize total\ndownlink Base Station (BS) power consumption for cases where BSs can be\nswitched off in deep sleep, and 3) enable a trade-off between AS quality and\nenergy consumption. Our framework is first formulated as a Mixed Integer Linear\nProgram (MILP) where decisions on multi-user rate allocation, video segment\nquality, and BS transmit power are jointly optimized. Then, to provide an\nonline solution, we present a polynomial-time heuristic algorithm that\ndecouples the PGS problem into multiple stages. We provide a performance\nanalysis of the proposed methods by simulations, and numerical results\ndemonstrate that the PGS framework yields significant energy savings.\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2014 15:41:30 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Abou-zeid", "Hatem", ""], ["Hassanein", "Hossam S.", ""], ["Valentin", "Stefan", ""]]}]