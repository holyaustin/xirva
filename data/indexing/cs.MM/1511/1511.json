[{"id": "1511.00118", "submitter": "Christophe Guyeux", "authors": "Jacques M. Bahi and Christophe Guyeux", "title": "A new chaos-based watermarking algorithm", "comments": "SECRYPT 2010, International Conference on Security and Cryptograph.\n  Submitted as a regular paper, accepted as a short one. arXiv admin note: text\n  overlap with arXiv:0810.4713, arXiv:1012.4620", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new watermarking algorithm based on discrete chaotic\niterations. After defining some coefficients deduced from the description of\nthe carrier medium, chaotic discrete iterations are used to mix the watermark\nand to embed it in the carrier medium. It can be proved that this procedure\ngenerates topological chaos, which ensures that desired properties of a\nwatermarking algorithm are satisfied.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2015 12:30:52 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Bahi", "Jacques M.", ""], ["Guyeux", "Christophe", ""]]}, {"id": "1511.01794", "submitter": "Mingfu Li", "authors": "Mingfu Li", "title": "Queueing Analysis of Unicast IPTV With User Mobility and Adaptive\n  Modulation and Coding in Wireless Cellular Networks", "comments": "12 pages, 16 figures", "journal-ref": null, "doi": "10.1109/TVT.2017.2702626", "report-no": null, "categories": "cs.NI cs.IT cs.MM cs.PF math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unicast IPTV services that can support live TV, video-on-demand (VoD), video\nconferencing, and online gaming applications over broadband wireless cellular\nnetworks have been becoming popular in recent years. However, video streaming\nservices significantly impact the performance of wireless cellular networks\nbecause they are bandwidth hogs. To maintain the system performance, effective\nadmission control and resource allocation mechanisms based on an accurate\nmathematical analysis are required. On the other hand, the quality of a\nwireless link usually changes with time due to the user mobility or\ntime-varying channel characteristics. To counteract such time-varying channels\nand improve the spectral efficiency, adaptive modulation and coding (AMC)\nscheme can be adopted in offering unicast IPTV services for mobile users. In\nthis paper, closed-form solutions for the bandwidth usage, blocking rate, and\ndropping rate of unicast IPTV services over wireless cellular networks were\nderived based on the novel queueing model that considers both user mobility and\nAMC. Simulations were also conducted to validate the accuracy of analytical\nresults. Numerical results demonstrate that the presented analytical results\nare accurate. Based on the accurate closed-form solutions, network providers\ncan implement precise admission control and resource allocation for their\nnetworks to enhance the system performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 15:59:35 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Li", "Mingfu", ""]]}, {"id": "1511.02492", "submitter": "Amirhossein Habibian", "authors": "Amirhossein Habibian, Thomas Mensink, Cees G.M. Snoek", "title": "VideoStory Embeddings Recognize Events when Examples are Scarce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims for event recognition when video examples are scarce or even\ncompletely absent. The key in such a challenging setting is a semantic video\nrepresentation. Rather than building the representation from individual\nattribute detectors and their annotations, we propose to learn the entire\nrepresentation from freely available web videos and their descriptions using an\nembedding between video features and term vectors. In our proposed embedding,\nwhich we call VideoStory, the correlations between the terms are utilized to\nlearn a more effective representation by optimizing a joint objective balancing\ndescriptiveness and predictability.We show how learning the VideoStory using a\nmultimodal predictability loss, including appearance, motion and audio\nfeatures, results in a better predictable representation. We also propose a\nvariant of VideoStory to recognize an event in video from just the important\nterms in a text query by introducing a term sensitive descriptiveness loss. Our\nexperiments on three challenging collections of web videos from the NIST\nTRECVID Multimedia Event Detection and Columbia Consumer Videos datasets\ndemonstrate: i) the advantages of VideoStory over representations using\nattributes or alternative embeddings, ii) the benefit of fusing video\nmodalities by an embedding over common strategies, iii) the complementarity of\nterm sensitive descriptiveness and multimodal predictability for event\nrecognition without examples. By it abilities to improve predictability upon\nany underlying video feature while at the same time maximizing semantic\ndescriptiveness, VideoStory leads to state-of-the-art accuracy for both few-\nand zero-example recognition of events in video.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 14:59:14 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Habibian", "Amirhossein", ""], ["Mensink", "Thomas", ""], ["Snoek", "Cees G. M.", ""]]}, {"id": "1511.02656", "submitter": "Thaihung Le", "authors": "Hung. T Le, Hai N. Nguyen, Nam Pham Ngoc, Anh T. Pham, Truong Cong\n  Thang", "title": "A Novel Adaptation Method for HTTP Streaming of VBR Videos over Mobile\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, HTTP streaming has become very popular for delivering video over\nthe Internet. For adaptivity, a provider should generate multiple versions of a\nvideo as well as the related metadata. Various adaptation methods have been\nproposed to support a streaming client in coping with strong bandwidth\nvariations. However, most of existing methods target at constant bitrate (CBR)\nvideos only. In this paper, we present a new method for quality adaptation in\non-demand streaming of variable bitrate (VBR) videos. To cope with strong\nvariations of VBR bitrate, we use a local average bitrate as the representative\nbitrate of a version. A buffer-based algorithm is then proposed to\nconservatively adapt video quality. Through experiments, we show that our\nmethod can provide quality stability as well as buffer stability even under\nvery strong variations of bandwidth and video bitrates.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 12:20:11 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Le", "Hung. T", ""], ["Nguyen", "Hai N.", ""], ["Ngoc", "Nam Pham", ""], ["Pham", "Anh T.", ""], ["Thang", "Truong Cong", ""]]}, {"id": "1511.03351", "submitter": "Changsha Ma", "authors": "Changsha Ma and Chang Wen Chen", "title": "Attribute-Based Multi-Dimensional Scalable Access Control For Social\n  Media Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Media sharing is an extremely popular paradigm of social interaction in\nonline social networks (OSNs) nowadays. The scalable media access control is\nessential to perform information sharing among users with various access\nprivileges. In this paper, we present a multi-dimensional scalable media access\ncontrol (MD-SMAC) system based on the proposed scalable ciphertext policy\nattribute-based encryption (SCP-ABE) algorithm. In the proposed MD-SMAC system,\nfine-grained access control can be performed on the media contents encoded in a\nmulti-dimensional scalable manner based on data consumers' diverse attributes.\nThrough security analysis, we show that the proposed MC-SMAC system is able to\nresist collusion attacks. Additionally, we conduct experiments to evaluate the\nefficiency performance of the proposed system, especially on mobile devices.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 01:32:47 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Ma", "Changsha", ""], ["Chen", "Chang Wen", ""]]}, {"id": "1511.03398", "submitter": "Sudeng Hu", "authors": "Sudeng Hu, Haiqiang Wang and C.-C. Jay Kuo", "title": "A GMM-Based Stair Quality Model for Human Perceived JPEG Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the notion of just noticeable differences (JND), a stair quality\nfunction (SQF) was recently proposed to model human perception on JPEG images.\nFurthermore, a k-means clustering algorithm was adopted to aggregate JND data\ncollected from multiple subjects to generate a single SQF. In this work, we\npropose a new method to derive the SQF using the Gaussian Mixture Model (GMM).\nThe newly derived SQF can be interpreted as a way to characterize the mean\nviewer experience. Furthermore, it has a lower information criterion (BIC)\nvalue than the previous one, indicating that it offers a better model. A\nspecific example is given to demonstrate the advantages of the new approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 06:44:31 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Hu", "Sudeng", ""], ["Wang", "Haiqiang", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1511.04691", "submitter": "Xuanqin Mou", "authors": "Chao Wang, Xuanqin Mou, Lei Zhang", "title": "Optimization of the Block-level Bit Allocation in Perceptual Video\n  Coding based on MINMAX", "comments": "11 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In video coding, it is expected that the encoder could adaptively select the\nencoding parameters (e.g., quantization parameter) to optimize the bit\nallocation to different sources under the given constraint. However, in hybrid\nvideo coding, the dependency between sources brings high complexity for the bit\nallocation optimization, especially in the block-level, and existing\noptimization methods mostly focus on frame-level bit allocation. In this paper,\nwe propose a macroblock (MB) level bit allocation method based on the minimum\nmaximum (MINMAX) criterion, which has acceptable encoding complexity for\noffline applications. An iterative-based algorithm, namely maximum distortion\ndescend (MDD), is developed to reduce quality fluctuation among MBs within a\nframe, where the Structure SIMilarity (SSIM) index is used to measure the\nperceptual distortion of MBs. Our extensive experimental results on benchmark\nvideo sequences show that the proposed method can greatly enhance the encoding\nperformance in terms of both bits saving and perceptual quality improvement.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 12:27:43 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Wang", "Chao", ""], ["Mou", "Xuanqin", ""], ["Zhang", "Lei", ""]]}, {"id": "1511.04798", "submitter": "Boyang Li", "authors": "Baohan Xu, Yanwei Fu, Yu-Gang Jiang, Boyang Li and Leonid Sigal", "title": "Heterogeneous Knowledge Transfer in Video Emotion Recognition,\n  Attribution and Summarization", "comments": "13 pages, 11 figures. Published at the IEEE Transactions on Affective\n  Computing", "journal-ref": "IEEE Transactions on Affective Computing. 2016", "doi": "10.1109/TAFFC.2016.2622690", "report-no": null, "categories": "cs.CV cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion is a key element in user-generated videos. However, it is difficult\nto understand emotions conveyed in such videos due to the complex and\nunstructured nature of user-generated content and the sparsity of video frames\nexpressing emotion. In this paper, for the first time, we study the problem of\ntransferring knowledge from heterogeneous external sources, including image and\ntextual data, to facilitate three related tasks in understanding video emotion:\nemotion recognition, emotion attribution and emotion-oriented summarization.\nSpecifically, our framework (1) learns a video encoding from an auxiliary\nemotional image dataset in order to improve supervised video emotion\nrecognition, and (2) transfers knowledge from an auxiliary textual corpora for\nzero-shot recognition of emotion classes unseen during training. The proposed\ntechnique for knowledge transfer facilitates novel applications of emotion\nattribution and emotion-oriented summarization. A comprehensive set of\nexperiments on multiple datasets demonstrate the effectiveness of our\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 01:40:15 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 06:02:45 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Xu", "Baohan", ""], ["Fu", "Yanwei", ""], ["Jiang", "Yu-Gang", ""], ["Li", "Boyang", ""], ["Sigal", "Leonid", ""]]}, {"id": "1511.04855", "submitter": "Marc Chaumont", "authors": "Lionel Pibre, Pasquet J\\'er\\^ome, Dino Ienco, Marc Chaumont", "title": "Deep learning is a good steganalysis tool when embedding key is reused\n  for different images, even if there is a cover source-mismatch", "comments": "IS&T. Media Watermarking, Security, and Forensics, Part of IS&T\n  International Symposium on Electronic Imaging, EI'2016, Feb 2015, San\n  Fransisco, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the BOSS competition, in 2010, most steganalysis approaches use a\nlearning methodology involving two steps: feature extraction, such as the Rich\nModels (RM), for the image representation, and use of the Ensemble Classifier\n(EC) for the learning step. In 2015, Qian et al. have shown that the use of a\ndeep learning approach that jointly learns and computes the features, is very\npromising for the steganalysis. In this paper, we follow-up the study of Qian\net al., and show that, due to intrinsic joint minimization, the results\nobtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural\nNetwork (FNN), if well parameterized, surpass the conventional use of a RM with\nan EC. First, numerous experiments were conducted in order to find the best \"\nshape \" of the CNN. Second, experiments were carried out in the clairvoyant\nscenario in order to compare the CNN and FNN to an RM with an EC. The results\nshow more than 16% reduction in the classification error with our CNN or FNN.\nThird, experiments were also performed in a cover-source mismatch setting. The\nresults show that the CNN and FNN are naturally robust to the mismatch problem.\nIn Addition to the experiments, we provide discussions on the internal\nmechanisms of a CNN, and weave links with some previously stated ideas, in\norder to understand the impressive results we obtained.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 07:59:14 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 07:49:46 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Pibre", "Lionel", ""], ["J\u00e9r\u00f4me", "Pasquet", ""], ["Ienco", "Dino", ""], ["Chaumont", "Marc", ""]]}, {"id": "1511.05892", "submitter": "Andrea Tassi", "authors": "Andrea Tassi, Ioannis Chatzigeorgiou, Daniel E. Lucani", "title": "Analysis and Optimization of Sparse Random Linear Network Coding for\n  Reliable Multicast Services", "comments": "To appear on IEEE Transactions on Communications", "journal-ref": null, "doi": "10.1109/TCOMM.2015.2503398", "report-no": null, "categories": "cs.IT cs.MM cs.NI cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-to-multipoint communications are expected to play a pivotal role in\nnext-generation networks. This paper refers to a cellular system transmitting\nlayered multicast services to a multicast group of users. Reliability of\ncommunications is ensured via different Random Linear Network Coding (RLNC)\ntechniques. We deal with a fundamental problem: the computational complexity of\nthe RLNC decoder. The higher the number of decoding operations is, the more the\nuser's computational overhead grows and, consequently, the faster the battery\nof mobile devices drains. By referring to several sparse RLNC techniques, and\nwithout any assumption on the implementation of the RLNC decoder in use, we\nprovide an efficient way to characterize the performance of users targeted by\nultra-reliable layered multicast services. The proposed modeling allows to\nefficiently derive the average number of coded packet transmissions needed to\nrecover one or more service layers. We design a convex resource allocation\nframework that allows to minimize the complexity of the RLNC decoder by jointly\noptimizing the transmission parameters and the sparsity of the code. The\ndesigned optimization framework also ensures service guarantees to\npredetermined fractions of users. The performance of the proposed optimization\nframework is then investigated in a LTE-A eMBMS network multicasting H.264/SVC\nvideo services.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 17:41:26 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 00:31:19 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Tassi", "Andrea", ""], ["Chatzigeorgiou", "Ioannis", ""], ["Lucani", "Daniel E.", ""]]}, {"id": "1511.06815", "submitter": "Ju Shen Dr.", "authors": "Xinzhong Lu, Ju Shen, Saverio Perugini, Jianjun Yang", "title": "An Immersive Telepresence System using RGB-D Sensors and Head Mounted\n  Display", "comments": "IEEE International Symposium on Multimedia 2015", "journal-ref": null, "doi": "10.1109/ISM.2015.108", "report-no": null, "categories": "cs.CV cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a tele-immersive system that enables people to interact with each\nother in a virtual world using body gestures in addition to verbal\ncommunication. Beyond the obvious applications, including general online\nconversations and gaming, we hypothesize that our proposed system would be\nparticularly beneficial to education by offering rich visual contents and\ninteractivity. One distinct feature is the integration of egocentric pose\nrecognition that allows participants to use their gestures to demonstrate and\nmanipulate virtual objects simultaneously. This functionality enables the\ninstructor to ef- fectively and efficiently explain and illustrate complex\nconcepts or sophisticated problems in an intuitive manner. The highly\ninteractive and flexible environment can capture and sustain more student\nattention than the traditional classroom setting and, thus, delivers a\ncompelling experience to the students. Our main focus here is to investigate\npossible solutions for the system design and implementation and devise\nstrategies for fast, efficient computation suitable for visual data processing\nand network transmission. We describe the technique and experiments in details\nand provide quantitative performance results, demonstrating our system can be\nrun comfortably and reliably for different application scenarios. Our\npreliminary results are promising and demonstrate the potential for more\ncompelling directions in cyberlearning.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 01:57:47 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Lu", "Xinzhong", ""], ["Shen", "Ju", ""], ["Perugini", "Saverio", ""], ["Yang", "Jianjun", ""]]}, {"id": "1511.07004", "submitter": "Keunwoo Choi Mr", "authors": "Keunwoo Choi, George Fazekas, Mark Sandler", "title": "Understanding Music Playlists", "comments": "International Conference on Machine Learning (ICML) 2015, Machine\n  Learning for Music Discovery Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As music streaming services dominate the music industry, the playlist is\nbecoming an increasingly crucial element of music consumption. Con- sequently,\nthe music recommendation problem is often casted as a playlist generation prob-\nlem. Better understanding of the playlist is there- fore necessary for\ndeveloping better playlist gen- eration algorithms. In this work, we analyse\ntwo playlist datasets to investigate some com- monly assumed hypotheses about\nplaylists. Our findings indicate that deeper understanding of playlists is\nneeded to provide better prior infor- mation and improve machine learning\nalgorithms in the design of recommendation systems.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 12:33:08 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Choi", "Keunwoo", ""], ["Fazekas", "George", ""], ["Sandler", "Mark", ""]]}, {"id": "1511.07607", "submitter": "Rahul Anand Sharma Mr.", "authors": "Rahul Anand Sharma, Pramod Sankar K and CV Jawahar", "title": "Fine-Grain Annotation of Cricket Videos", "comments": "ACPR 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recognition of human activities is one of the key problems in video\nunderstanding. Action recognition is challenging even for specific categories\nof videos, such as sports, that contain only a small set of actions.\nInterestingly, sports videos are accompanied by detailed commentaries available\nonline, which could be used to perform action annotation in a weakly-supervised\nsetting. For the specific case of Cricket videos, we address the challenge of\ntemporal segmentation and annotation of ctions with semantic descriptions. Our\nsolution consists of two stages. In the first stage, the video is segmented\ninto \"scenes\", by utilizing the scene category information extracted from\ntext-commentary. The second stage consists of classifying video-shots as well\nas the phrases in the textual description into various categories. The relevant\nphrases are then suitably mapped to the video-shots. The novel aspect of this\nwork is the fine temporal scale at which semantic information is assigned to\nthe video. As a result of our approach, we enable retrieval of specific actions\nthat last only a few seconds, from several hours of video. This solution yields\na large number of labeled exemplars, with no manual effort, that could be used\nby machine learning algorithms to learn complex actions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 08:34:20 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 10:48:11 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Sharma", "Rahul Anand", ""], ["K", "Pramod Sankar", ""], ["Jawahar", "CV", ""]]}, {"id": "1511.08082", "submitter": "Ali Bakhshali", "authors": "Ali Bakhshali, Wai-Yip Chan, Steven D. Blosten, Yu Cao", "title": "QoE Optimization of Video Multicast with Heterogeneous Channels and\n  Playback Requirements", "comments": "29 pages, 5 tables, 11 figures, to appear in EURASIP Journal on\n  Wireless Communications and Networking", "journal-ref": null, "doi": "10.1186/s13638-015-0485-0", "report-no": null, "categories": "cs.IT cs.MM cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an application-layer forward error correction (AL-FEC) code rate\nallocation scheme to maximize the quality of experience (QoE) of a video\nmulticast. The allocation dynamically assigns multicast clients to the quality\nlayers of a scalable video bitstream, based on their heterogeneous channel\nqualities and video playback capabilities. Normalized mean opinion score (NMOS)\nis employed to value the client's quality of experience across various possible\nadaptations of a multilayer video, coded using mixed spatial-temporal-amplitude\nscalability. The scheme provides assurance of reception of the video layers\nusing fountain coding and effectively allocates coding rates across the layers\nto maximize a multicast utility measure. An advantageous feature of the\nproposed scheme is that the complexity of the optimization is independent of\nthe number of clients. Additionally, a convex formulation is proposed that\nattains close to the best performance and offers a reliable alternative when\nfurther reduction in computational complexity is desired. The optimization is\nextended to perform suppression of QoE fluctuations for clients with marginal\nchannel qualities. The scheme offers a means to trade-off service utility for\nthe entire multicast group and clients with the worst channels. According to\nthe simulation results, the proposed optimization framework is robust against\nsource rate variations and limited amount of client feedback.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 15:14:02 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Bakhshali", "Ali", ""], ["Chan", "Wai-Yip", ""], ["Blosten", "Steven D.", ""], ["Cao", "Yu", ""]]}, {"id": "1511.08507", "submitter": "Steffen Wendzel", "authors": "Steffen Wendzel, Carolin Palmer", "title": "Creativity in Mind: Evaluating and Maintaining Advances in Network\n  Steganographic Research", "comments": "to appear in Journal of Universal Computer Science (J.UCS)", "journal-ref": "Journal of Universal Computer Science, Vol. 21(12), 2015", "doi": "10.3217/jucs-021-12-1684", "report-no": null, "categories": "cs.MM cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research discipline of network steganography deals with the hiding of\ninformation within network transmissions, e.g. to transfer illicit information\nin networks with Internet censorship. The last decades of research on network\nsteganography led to more than hundred techniques for hiding data in network\ntransmissions. However, previous research has shown that most of these hiding\ntechniques are either based on the same idea or introduce limited novelty,\nenabling the application of existing countermeasures. In this paper, we provide\na link between the field of creativity and network steganographic research. We\npropose a framework and a metric to help evaluating the creativity bound to a\ngiven hiding technique. This way, we support two sides of the scientific peer\nreview process as both authors and reviewers can use our framework to analyze\nthe novelty and applicability of hiding techniques. At the same time, we\ncontribute to a uniform terminology in network steganography.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 21:07:05 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Wendzel", "Steffen", ""], ["Palmer", "Carolin", ""]]}, {"id": "1511.08865", "submitter": "Khan Muhammad", "authors": "Khan Muhammad", "title": "Steganography: A Secure way for Transmission in Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Addressing the security concerns in wireless sensor networks (WSN) is a\nchallenging task, which has attracted the attention of many researchers from\nthe last few decades. Researchers have presented various schemes in WSN,\naddressing the problems of processing, bandwidth, load balancing, and efficient\nrouting. However, little work has been done on security aspects of WSN. In a\ntypical WSN network, the tiny nodes installed on different locations sense the\nsurrounding environment, send the collected data to their neighbors, which in\nturn is forwarded to a sink node. The sink node aggregate the data received\nfrom different sensors and send it to the base station for further processing\nand necessary actions. In highly critical sensor networks such as military and\nlaw enforcement agencies networks, the transmission of such aggregated data via\nthe public network Internet is very sensitive and vulnerable to various attacks\nand risks. Therefore, this paper provides a solution for addressing these\nsecurity issues based on steganography, where the aggregated data can be\nembedded as a secret message inside an innocent-looking cover image. The stego\nimage containing the embedded data can be then sent to fusion center using\nInternet. At the fusion center, the hidden data is extracted from the image,\nthe required processing is performed and decision is taken accordingly.\nExperimentally, the proposed method is evaluated by objective analysis using\npeak signal-to-noise ratio (PSNR), mean square error (MSE), normalized cross\ncorrelation (NCC), and structural similarity index metric (SSIM), providing\npromising results in terms of security and image quality, thus validating its\nsuperiority.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2015 04:00:05 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Muhammad", "Khan", ""]]}, {"id": "1511.08899", "submitter": "Mohamed Moustafa", "authors": "Mohamed Moustafa", "title": "Applying deep learning to classify pornographic images and videos", "comments": "PSIVT 2015, the final publication is available at link.springer.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is no secret that pornographic material is now a one-click-away from\neveryone, including children and minors. General social media networks are\nstriving to isolate adult images and videos from normal ones. Intelligent image\nanalysis methods can help to automatically detect and isolate questionable\nimages in media. Unfortunately, these methods require vast experience to design\nthe classifier including one or more of the popular computer vision feature\ndescriptors. We propose to build a classifier based on one of the recently\nflourishing deep learning techniques. Convolutional neural networks contain\nmany layers for both automatic features extraction and classification. The\nbenefit is an easier system to build (no need for hand-crafting features and\nclassifiers). Additionally, our experiments show that it is even more accurate\nthan the state of the art methods on the most recent benchmark dataset.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2015 13:55:25 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Moustafa", "Mohamed", ""]]}]