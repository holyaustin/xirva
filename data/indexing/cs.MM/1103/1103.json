[{"id": "1103.0065", "submitter": "Xin Bai", "authors": "Xin Bai and Dana Fusco", "title": "Interdisciplinary Collaboration through Designing 3D Simulation Case\n  Studies", "comments": null, "journal-ref": null, "doi": "10.5121/ijma.2011.3109", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interdisciplinary collaboration is essential for the advance of research. As\ndomain subjects become more and more specialized, researchers need to cross\ndisciplines for insights from peers in other areas to have a broader and deeper\nunderstand of a topic at micro- and macro-levels. We developed a 3D virtual\nlearning environment that served as a platform for faculty to plan curriculum,\nshare educational beliefs, and conduct cross-discipline research for effective\nlearning. Based upon the scripts designed by faculty from five disciplines,\nvirtual doctors, nurses, or patients interact in a 3D virtual hospital. The\nteaching vignettes were then converted to video clips, allowing users to view,\npause, replay, or comment on the videos individually or in groups. Unlike many\nexisting platforms, we anticipated a value-added by adding a social networking\ncapacity to this virtual environment. The focus of this paper is on the\ncost-efficiency and system design of the virtual learning environment.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2011 02:02:54 GMT"}], "update_date": "2011-03-02", "authors_parsed": [["Bai", "Xin", ""], ["Fusco", "Dana", ""]]}, {"id": "1103.0540", "submitter": "Ling Shao", "authors": "Lijun Wang, Ling Shao", "title": "An Algorithm for Repairing Low-Quality Video Enhancement Techniques\n  Based on Trained Filter", "comments": "Part of the work is published as a journal paper titled \"Repairing\n  imperfect video enhancement algorithms using classification-based trained\n  filters\" in Signal, Image and Video Processing (Springer); Signal, Image and\n  Video Processing, 2011", "journal-ref": null, "doi": "10.1007/s11760-010-0202-8", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multifarious image enhancement algorithms have been used in different\napplications. Still, some algorithms or modules are imperfect for practical\nuse. When the image enhancement modules have been fixed or combined by a series\nof algorithms, we need to repair them as a whole part without changing the\ninside. This report aims to find an algorithm based on trained filters to\nrepair low-quality image enhancement modules. A brief review on basic image\nenhancement techniques and pixel classification methods will be presented, and\nthe procedure of trained filters will be described step by step. The\nexperiments and result comparisons for this algorithm will be described in\ndetail.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2011 20:50:22 GMT"}], "update_date": "2011-03-03", "authors_parsed": [["Wang", "Lijun", ""], ["Shao", "Ling", ""]]}, {"id": "1103.0829", "submitter": "Rajesh Kumar  Tiwari Dr.", "authors": "G. Sahoo and Rajesh Kumar Tiwari", "title": "Hiding Secret Information in Movie Clip: A Steganographic Approach", "comments": "Steganography, Frame, Stego-Frame, Stego-key, and Carrier", "journal-ref": "International Journal of Computing and Applications, Vol. 4, No.\n  1, June 2009, pp. 87-94", "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing hidden communication is an important subject of discussion that\nhas gained increasing importance nowadays with the development of the internet.\nOne of the key methods for establishing hidden communication is steganography.\nModern day steganography mainly deals with hiding information within files like\nimage, text, html, binary files etc. These file contains small irrelevant\ninformation that can be substituted for small secret data. To store a high\ncapacity secret data these carrier files are not very supportive. To overcome\nthe problem of storing the high capacity secret data with the utmost security\nfence, we have proposed a novel methodology for concealing a voluminous data\nwith high levels of security wall by using movie clip as a carrier file.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2011 05:38:59 GMT"}], "update_date": "2011-03-07", "authors_parsed": [["Sahoo", "G.", ""], ["Tiwari", "Rajesh Kumar", ""]]}, {"id": "1103.0837", "submitter": "Mostafa Zaman Chowdhury", "authors": "Mostafa Zaman Chowdhury and Yeong Min Jang", "title": "Priority based Interface Selection for Overlaying Heterogeneous Networks", "comments": "7 pages, 7 figures", "journal-ref": "The Journal of Korea Information and Communications Soceity\n  (KICS,), Vol. 35, No. 7, July 2010", "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offering of different attractive opportunities by different wireless\ntechnologies trends the convergence of heterogeneous networks for the future\nwireless communication system. To make a seamless handover among the\nheterogeneous networks, the optimization of the power consumption, and optimal\nselection of interface are the challenging issues for convergence networks. The\naccess of multi interfaces simultaneously reduces the handover latency and data\nloss in heterogeneous handover. The mobile node (MN) maintains one interface\nconnection while other interface is used for handover process. However, it\ncauses much battery power consumption. In this paper we propose an efficient\ninterface selection scheme including interface selection algorithms, interface\nselection procedures considering battery power consumption and user mobility\nwith other existing parameters for overlaying networks. We also propose a\npriority based network selection scheme according to the service types. MN's\nbattery power level, provision of QoS/QoE in the target network and our\nproposed priority parameters are considered as more important parameters for\nour interface selection algorithm. The performances of the proposed scheme are\nverified using numerical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2011 07:40:44 GMT"}], "update_date": "2011-03-07", "authors_parsed": [["Chowdhury", "Mostafa Zaman", ""], ["Jang", "Yeong Min", ""]]}, {"id": "1103.2756", "submitter": "Xinmei Tian", "authors": "Xinmei Tian and Dacheng Tao and Yong Rui", "title": "Sparse Transfer Learning for Interactive Video Search Reranking", "comments": "17 pages", "journal-ref": null, "doi": "10.1145/0000000.0000000", "report-no": null, "categories": "cs.IR cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual reranking is effective to improve the performance of the text-based\nvideo search. However, existing reranking algorithms can only achieve limited\nimprovement because of the well-known semantic gap between low level visual\nfeatures and high level semantic concepts. In this paper, we adopt interactive\nvideo search reranking to bridge the semantic gap by introducing user's\nlabeling effort. We propose a novel dimension reduction tool, termed sparse\ntransfer learning (STL), to effectively and efficiently encode user's labeling\ninformation. STL is particularly designed for interactive video search\nreranking. Technically, it a) considers the pair-wise discriminative\ninformation to maximally separate labeled query relevant samples from labeled\nquery irrelevant ones, b) achieves a sparse representation for the subspace to\nencodes user's intention by applying the elastic net penalty, and c) propagates\nuser's labeling information from labeled samples to unlabeled samples by using\nthe data distribution knowledge. We conducted extensive experiments on the\nTRECVID 2005, 2006 and 2007 benchmark datasets and compared STL with popular\ndimension reduction algorithms. We report superior performance by using the\nproposed STL based interactive video search reranking.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2011 19:48:20 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2011 03:49:33 GMT"}, {"version": "v3", "created": "Wed, 21 Dec 2011 00:12:42 GMT"}], "update_date": "2011-12-22", "authors_parsed": [["Tian", "Xinmei", ""], ["Tao", "Dacheng", ""], ["Rui", "Yong", ""]]}, {"id": "1103.3802", "submitter": "Sumit Kumar", "authors": "Sumit Kumar, Santosh Kumar, Sukumar Nandi", "title": "Stage Staffing Scheme for Copyright Protection in Multimedia", "comments": "13 pages, 7 figures", "journal-ref": "International Journal of Network Security & Its Applications\n  (IJNSA), Vol.3, No.2, March 2011", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copyright protection has become a need in today's world. To achieve a secure\ncopyright protection we embedded some information in images and videos and that\nimage or video is called copyright protected. The embedded information can't be\ndetected by human eye but some attacks and operations can tamper that\ninformation to breach protection. So in order to find a secure technique of\ncopyright protection, we have analyzed image processing techniques i.e. Spatial\nDomain (Least Significant Bit (LSB)), Transform Domain (Discrete Cosine\nTransform (DCT)), Discrete Wavelet Transform (DWT) and there are numerous\nalgorithm for watermarking using them. After having a good understanding of the\nsame we have proposed a novel algorithm named as Stage Staffing Algorithm that\ngenerates results with high effectiveness, additionally we can use self\nextracted-watermark technique to increase the security and automate the process\nof watermark image. The proposed algorithm provides protection in three stages.\nWe have implemented the algorithm and results of the simulations are shown. The\nvarious factors affecting spatial domain watermarking are also discussed.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2011 18:43:30 GMT"}], "update_date": "2011-03-22", "authors_parsed": [["Kumar", "Sumit", ""], ["Kumar", "Santosh", ""], ["Nandi", "Sukumar", ""]]}, {"id": "1103.4271", "submitter": "Emilio Ferrara", "authors": "Salvatore Catanese, Emilio Ferrara, Giacomo Fiumara, Francesco Pagano", "title": "Rendering of 3D Dynamic Virtual Environments", "comments": "8 pages, 11 figures, Proceedings of the 4th International ICST\n  Conference on Simulation Tools and Techniques (2011)", "journal-ref": null, "doi": "10.4108/icst.simutools.2011.245524", "report-no": null, "categories": "cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a framework for the rendering of dynamic 3D virtual\nenvironments which can be integrated in the development of videogames. It\nincludes methods to manage sounds and particle effects, paged static\ngeometries, the support of a physics engine and various input systems. It has\nbeen designed with a modular structure to allow future expansions. We exploited\nsome open-source state-of-the-art components such as OGRE, PhysX,\nParticleUniverse, etc.; all of them have been properly integrated to obtain\npeculiar physical and environmental effects. The stand-alone version of the\napplication is fully compatible with Direct3D and OpenGL APIs and adopts OpenAL\nAPIs to manage audio cards. Concluding, we devised a showcase demo which\nreproduces a dynamic 3D environment, including some particular effects: the\nalternation of day and night infuencing the lighting of the scene, the\nrendering of terrain, water and vegetation, the reproduction of sounds and\natmospheric agents.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2011 14:16:07 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2011 18:11:55 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Catanese", "Salvatore", ""], ["Ferrara", "Emilio", ""], ["Fiumara", "Giacomo", ""], ["Pagano", "Francesco", ""]]}, {"id": "1103.4712", "submitter": "Vijay Kumar K Mr", "authors": "Vijay Kumar Kodavalla and Dr. P.G. Krishna Mohan", "title": "Distributed Video Coding: Codec Architecture and Implementation", "comments": "Signal & Image Processing : An International Journal(SIPIJ) Vol.2,\n  No.1, March 2011", "journal-ref": null, "doi": "10.5121/sipij.2011.2111", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Video Coding (DVC) is a new coding paradigm for video\ncompression, based on Slepian- Wolf (lossless coding) and Wyner-Ziv (lossy\ncoding) information theoretic results. DVC is useful for emerging applications\nsuch as wireless video cameras, wireless low-power surveillance networks and\ndisposable video cameras for medical applications etc. The primary objective of\nDVC is low-complexity video encoding, where bulk of computation is shifted to\nthe decoder, as opposed to low-complexity decoder in conventional video\ncompression standards such as H.264 and MPEG etc. There are couple of early\narchitectures and implementations of DVC from Stanford University[2][3] in\n2002, Berkeley University PRISM (Power-efficient, Robust, hIgh-compression,\nSyndrome-based Multimedia coding)[4][5] in 2002 and European project DISCOVER\n(DIStributed COding for Video SERvices)[6] in 2007. Primarily there are two\ntypes of DVC techniques namely pixel domain and transform domain based.\nTransform domain design will have better rate-distortion (RD) performance as it\nexploits spatial correlation between neighbouring samples and compacts the\nblock energy into as few transform coefficients as possible (aka energy\ncompaction). In this paper, architecture, implementation details and \"C\" model\nresults of our transform domain DVC are presented.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2011 09:50:26 GMT"}], "update_date": "2011-03-25", "authors_parsed": [["Kodavalla", "Vijay Kumar", ""], ["Mohan", "Dr. P. G. Krishna", ""]]}]