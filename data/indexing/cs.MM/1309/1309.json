[{"id": "1309.0316", "submitter": "Attilio Fiandrotti", "authors": "Attilio Fiandrotti, Valerio Bioglio, Marco Grangetto, Rossano Gaeta,\n  and Enrico Magli", "title": "Band Codes for Energy-Efficient Network Coding with Application to P2P\n  Mobile Streaming", "comments": "To be published in IEEE Transacions on Multimedia", "journal-ref": null, "doi": "10.1109/TMM.2013.2285518", "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in random network coding (NC) lies in the complexity and energy\nconsumption associated with the packet decoding processes, which hinder its\napplication in mobile environments. Controlling and hence limiting such factors\nhas always been an important but elusive research goal, since the packet degree\ndistribution, which is the main factor driving the complexity, is altered in a\nnon-deterministic way by the random recombinations at the network nodes. In\nthis paper we tackle this problem proposing Band Codes (BC), a novel class of\nnetwork codes specifically designed to preserve the packet degree distribution\nduring packet encoding, ecombination and decoding. BC are random codes over\nGF(2) that exhibit low decoding complexity, feature limited and controlled\ndegree distribution by construction, and hence allow to effectively apply NC\neven in energy-constrained scenarios. In particular, in this paper we motivate\nand describe our new design and provide a thorough analysis of its performance.\nWe provide numerical simulations of the performance of BC in order to validate\nthe analysis and assess the overhead of BC with respect to a onventional NC\nscheme. Moreover, peer-to-peer media streaming experiments with a random-push\nprotocol show that BC reduce the decoding complexity by a factor of two, to a\npoint where NC-based mobile streaming to mobile devices becomes practically\nfeasible.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 07:58:45 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Fiandrotti", "Attilio", ""], ["Bioglio", "Valerio", ""], ["Grangetto", "Marco", ""], ["Gaeta", "Rossano", ""], ["Magli", "Enrico", ""]]}, {"id": "1309.2359", "submitter": "Ravi Bolimera", "authors": "Bolimera Ravi and T. Kishore Kumar", "title": "Speech Enhancement using Kernel and Normalized Kernel Affine Projection\n  Algorithm", "comments": null, "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.4, No.4, August 2013", "doi": "10.5121/sipij.2013.4411", "report-no": null, "categories": "cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to investigate the speech signal enhancement using\nKernel Affine Projection Algorithm (KAPA) and Normalized KAPA. The removal of\nbackground noise is very important in many applications like speech\nrecognition, telephone conversations, hearing aids, forensic, etc. Kernel\nadaptive filters shown good performance for removal of noise. If the evaluation\nof background noise is more slowly than the speech, i.e., noise signal is more\nstationary than the speech, we can easily estimate the noise during the pauses\nin speech. Otherwise it is more difficult to estimate the noise which results\nin degradation of speech. In order to improve the quality and intelligibility\nof speech, unlike time and frequency domains, we can process the signal in new\ndomain like Reproducing Kernel Hilbert Space (RKHS) for high dimensional to\nyield more powerful nonlinear extensions. For experiments, we have used the\ndatabase of noisy speech corpus (NOIZEUS). From the results, we observed the\nremoval noise in RKHS has great performance in signal to noise ratio values in\ncomparison with conventional adaptive filters.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 01:57:14 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Ravi", "Bolimera", ""], ["Kumar", "T. Kishore", ""]]}, {"id": "1309.2423", "submitter": "Anumol Joseph", "authors": "Anumol Joseph, K. Anusudha", "title": "Robust watermarking based on DWT SVD", "comments": "paper has bee withdrawn by the author due to error in equation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital information revolution has brought about many advantages and new\nissues. The protection of ownership and the prevention of unauthorized\nmanipulation of digital audio, image, and video materials has become an\nimportant concern due to the ease of editing and perfect reproduction.\nWatermarking is identified as a major means to achieve copyright protection. It\nis a branch of information hiding which is used to hide proprietary information\nin digital media like photographs, digital music, digital video etc. In this\npaper, a new image watermarking algorithm that is robust against various\nattacks is presented. DWT (Discrete Wavelet Transform) and SVD (Singular Value\nDecomposition) have been used to embed two watermarks in the HL and LH bands of\nthe host image. Simulation evaluation demonstrates that the proposed technique\nwithstand various attacks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 09:18:27 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2013 04:54:03 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2013 00:50:56 GMT"}, {"version": "v4", "created": "Mon, 23 Sep 2013 15:30:15 GMT"}, {"version": "v5", "created": "Tue, 24 Sep 2013 18:42:25 GMT"}, {"version": "v6", "created": "Thu, 26 Sep 2013 03:07:21 GMT"}, {"version": "v7", "created": "Fri, 27 Sep 2013 03:08:12 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Joseph", "Anumol", ""], ["Anusudha", "K.", ""]]}, {"id": "1309.2533", "submitter": "Jalil Boukhobza", "authors": "Yahia Benmoussa (Lab-STICC), Jalil Boukhobza (Lab-STICC), Eric Senn\n  (Lab-STICC), Djamel Benazzouz (MSS)", "title": "Evaluation of the Performance/Energy Overhead in DSP Video Decoding and\n  its Implications", "comments": null, "journal-ref": "Annual Metting of the GDR SoC SiP, Lyon : France (2013)", "doi": null, "report-no": null, "categories": "cs.AR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video decoding is considered as one of the most compute and energy intensive\napplication in energy constrained mobile devices. Some specific processing\nunits, such as DSPs, are added to those devices in order to optimize the\nperformance and the energy consumption. However, in DSP video decoding, the\ninter-processor communication overhead may have a considerable impact on the\nperformance and the energy consumption. In this paper, we propose to evaluate\nthis overhead and analyse its impact on the performance and the energy\nconsumption as compared to the GPP decoding. Our work revealed that the GPP can\nbe the best choice in many cases due to the a significant overhead in DSP\ndecoding which may represents 30% of the total decoding energy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 14:50:29 GMT"}], "update_date": "2013-09-11", "authors_parsed": [["Benmoussa", "Yahia", "", "Lab-STICC"], ["Boukhobza", "Jalil", "", "Lab-STICC"], ["Senn", "Eric", "", "Lab-STICC"], ["Benazzouz", "Djamel", "", "MSS"]]}, {"id": "1309.3314", "submitter": "Zeineb Abderrahim", "authors": "Zeineb Abderrahim, Elhem Techini, Mohamed Salim Bouhlel", "title": "Progressive Compression of 3D Objects with an Adaptive Quantization", "comments": "8 pages, 5 figures", "journal-ref": "IJCSI Volume 10, Issue 2,No 1, March 2013 , Pages 504-511", "doi": null, "report-no": null, "categories": "cs.GR cs.CG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new progressive compression method for triangular\nmeshes. This method, in fact, is based on a schema of irregular\nmulti-resolution analysis and is centered on the optimization of the\nrate-distortion trade-off. The quantization precision is adapted to each vertex\nduring the encoding / decoding process to optimize the rate-distortion\ncompromise. The Optimization of the treated mesh geometry improves the\napproximation quality and the compression ratio at each level of resolution.\nThe experimental results show that the proposed algorithm gives competitive\nresults compared to the previous works dealing with the rate-distortion\ncompromise.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 21:47:37 GMT"}], "update_date": "2013-09-16", "authors_parsed": [["Abderrahim", "Zeineb", ""], ["Techini", "Elhem", ""], ["Bouhlel", "Mohamed Salim", ""]]}, {"id": "1309.3908", "submitter": "Marco Guerini", "authors": "Marco Guerini, Jacopo Staiano, Davide Albanese", "title": "Exploring Image Virality in Google Plus", "comments": "8 pages, 8 figures. IEEE/ASE SocialCom 2013", "journal-ref": null, "doi": "10.1109/SocialCom.2013.101", "report-no": null, "categories": "cs.SI cs.CY cs.MM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactions to posts in an online social network show different dynamics\ndepending on several textual features of the corresponding content. Do similar\ndynamics exist when images are posted? Exploiting a novel dataset of posts,\ngathered from the most popular Google+ users, we try to give an answer to such\na question. We describe several virality phenomena that emerge when taking into\naccount visual characteristics of images (such as orientation, mean saturation,\netc.). We also provide hypotheses and potential explanations for the dynamics\nbehind them, and include cases for which common-sense expectations do not hold\ntrue in our experiments.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 11:35:19 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Guerini", "Marco", ""], ["Staiano", "Jacopo", ""], ["Albanese", "Davide", ""]]}, {"id": "1309.5491", "submitter": "Martin Dr\\\"axler", "authors": "Martin Dr\\\"axler, Johannes Blobel, Philipp Dreimann, Stefan Valentin,\n  Holger Karl", "title": "Anticipatory Buffer Control and Quality Selection for Wireless Video\n  Streaming", "comments": null, "journal-ref": null, "doi": "10.1109/NetSys.2015.7089073", "report-no": null, "categories": "cs.NI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video streaming is in high demand by mobile users, as recent studies\nindicate. In cellular networks, however, the unreliable wireless channel leads\nto two major problems. Poor channel states degrade video quality and interrupt\nthe playback when a user cannot sufficiently fill its local playout buffer:\nbuffer underruns occur. In contrast to that, good channel conditions cause\ncommon greedy buffering schemes to pile up very long buffers. Such\nover-buffering wastes expensive wireless channel capacity.\n  To keep buffering in balance, we employ a novel approach. Assuming that we\ncan predict data rates, we plan the quality and download time of the video\nsegments ahead. This anticipatory scheduling avoids buffer underruns by\ndownloading a large number of segments before a channel outage occurs, without\nwasting wireless capacity by excessive buffering. We formalize this approach as\nan optimization problem and derive practical heuristics for segmented video\nstreaming protocols (e.g., HLS or MPEG DASH). Simulation results and testbed\nmeasurements show that our solution essentially eliminates playback\ninterruptions without significantly decreasing video quality.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2013 15:40:29 GMT"}, {"version": "v2", "created": "Fri, 22 Aug 2014 12:44:16 GMT"}], "update_date": "2015-04-22", "authors_parsed": [["Dr\u00e4xler", "Martin", ""], ["Blobel", "Johannes", ""], ["Dreimann", "Philipp", ""], ["Valentin", "Stefan", ""], ["Karl", "Holger", ""]]}, {"id": "1309.7640", "submitter": "Georgios Pitsilis", "authors": "Mohamed El-Hadedy, Georgios Pitsilis, Svein J. Knapskog", "title": "An Efficient Authorship Protection Scheme for Shared Multimedia Content", "comments": "Extensive technical report of paper published in Sixth International\n  Conference on Image and Graphics (ICIG), pp.914-919, Hefei, Anhui, China,\n  August 12-15, 2011. ISBN: 978-0-7695-4541-7", "journal-ref": null, "doi": "10.1109/ICIG.2011.183", "report-no": null, "categories": "cs.MM cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many electronic content providers today like Flickr and Google, offer space\nto users to publish their electronic media (e.g. photos and videos) in their\ncloud infrastructures, so that they can be publicly accessed. Features like\nincluding other information, such as keywords or owner information into the\ndigital material is already offered by existing providers. Despite the useful\nfeatures made available to users by such infrastructures, the authorship of the\npublished content is not protected against various attacks such as compression.\nIn this paper we propose a robust scheme that uses digital invisible\nwatermarking and hashing to protect the authorship of the digital content and\nprovide resistance against malicious manipulation of multimedia content. The\nscheme is enhanced by an algorithm called MMBEC, that is an extension of an\nestablished scheme MBEC, towards higher resistance.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2013 19:17:18 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["El-Hadedy", "Mohamed", ""], ["Pitsilis", "Georgios", ""], ["Knapskog", "Svein J.", ""]]}]