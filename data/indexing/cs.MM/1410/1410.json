[{"id": "1410.1474", "submitter": "Mohammad Rahaman", "authors": "Farzana Afrin and Mohammad Saiedur Rahaman", "title": "An adaptive quasi harmonic broadcasting scheme with optimal bandwidth\n  requirement", "comments": "IEEE International Conference on Informatics, Electronics & Vision\n  (ICIEV), 2013, 6pages, 8 figures", "journal-ref": null, "doi": "10.1109/ICIEV.2013.6572684", "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of Harmonic Broadcasting protocol is to reduce the bandwidth usage in\nvideo-on-demand service where a video is divided into some equal sized segments\nand every segment is repeatedly transmitted over a number of channels that\nfollows harmonic series for channel bandwidth assignment. As the bandwidth of\nchannels differs from each other and users can join at any time to these\nmulticast channels, they may experience a synchronization problem between\ndownload and playback. To deal with this issue, some schemes have been\nproposed, however, at the cost of additional or wastage of bandwidth or sudden\nextreme bandwidth requirement. In this paper we present an adaptive quasi\nharmonic broadcasting scheme (AQHB) which delivers all data segment on time\nthat is the download and playback synchronization problem is eliminated while\nkeeping the bandwidth consumption as same as traditional harmonic broadcasting\nscheme without cost of any additional or wastage of bandwidth. It also ensures\nthe video server not to increase the channel bandwidth suddenly that is, also\neliminates the sudden buffer requirement at the client side. We present several\nanalytical results to exhibit the efficiency of our proposed broadcasting\nscheme over the existing ones.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 17:48:39 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Afrin", "Farzana", ""], ["Rahaman", "Mohammad Saiedur", ""]]}, {"id": "1410.2100", "submitter": "Wu Xianyan student", "authors": "Wu Xianyan, Han Qi, Le Dan, Niu Xiamu", "title": "A New Method for Estimating the Widths of JPEG Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image width is important for image understanding. We propose a novel method\nto estimate widths for JPEG images when their widths are not available. The key\nidea is that the distance between two decoded MCUs (Minimum Coded Unit)\nadjacent in the vertical direction is usually small, which is measured by the\naverage Euclidean distance between the pixels from the bottom row of the top\nMCU and the top row of the bottom MCU. On PASCAL VOC 2010 challenge dataset and\nUSC-SIPI image database, experimental results show the high performance of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 13:24:06 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Xianyan", "Wu", ""], ["Qi", "Han", ""], ["Dan", "Le", ""], ["Xiamu", "Niu", ""]]}, {"id": "1410.2259", "submitter": "Martin Prantl", "authors": "Martin Prantl", "title": "Image compression overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Compression plays a significant role in a data storage and a transmission. If\nwe speak about a generall data compression, it has to be a lossless one. It\nmeans, we are able to recover the original data 1:1 from the compressed file.\nMultimedia data (images, video, sound...), are a special case. In this area, we\ncan use something called a lossy compression. Our main goal is not to recover\ndata 1:1, but only keep them visually similar. This article is about an image\ncompression, so we will be interested only in image compression. For a human\neye, it is not a huge difference, if we recover RGB color with values\n[150,140,138] instead of original [151,140,137]. The magnitude of a difference\ndetermines the loss rate of the compression. The bigger difference usually\nmeans a smaller file, but also worse image quality and noticable differences\nfrom the original image. We want to cover compression techniques mainly from\nthe last decade. Many of them are variations of existing ones, only some of\nthem uses new principes.\n", "versions": [{"version": "v1", "created": "Sun, 14 Sep 2014 11:10:06 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Prantl", "Martin", ""]]}, {"id": "1410.2324", "submitter": "Xiaofeng Zhong", "authors": "Jian Sun, Xiaofeng Zhong, Xuan Zhou, Xiaolong Fu", "title": "Recommendation Scheme Based on Converging Properties for Contents\n  Broadcasting", "comments": "6 pages. This work is present at 2015 International Workshop on\n  Networking Issues in Multimedia Entertainment (NIME'15)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular videos are often clicked by a mount of users in a short period. With\ncontent recommendation, the popular contents could be broadcast to the\npotential users in wireless network, to save huge transmitting resource. In\nthis paper, the contents propagation model is analyzed due to users' historical\nbehavior, location, and the converging properties in wireless data\ntransmission, with the users' communication log in the Chinese commercial\ncellular network. And a recommendation scheme is proposed to achieve high\nenergy efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2014 00:53:11 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Sun", "Jian", ""], ["Zhong", "Xiaofeng", ""], ["Zhou", "Xuan", ""], ["Fu", "Xiaolong", ""]]}, {"id": "1410.3117", "submitter": "Soumendu Chakraborty", "authors": "Soumendu Chakraborty, Anand Singh Jalal and Charul Bhatnagar", "title": "An Efficient Bit Plane X-OR Algorithm for Irreversible Image\n  Steganography", "comments": null, "journal-ref": null, "doi": "10.1504/IJTMCC.2013.053263", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The science of hiding secret information in another message is known as\nSteganography; hence the presence of secret information is concealed. It is the\nmethod of hiding cognitive content in same or another media to avoid\nrecognition by the intruders. This paper introduces new method wherein\nirreversible steganography is used to hide an image in the same medium so that\nthe secret data is masked. The secret image is known as payload and the carrier\nis known as cover image. X-OR operation is used amongst mid level bit planes of\ncarrier image and high level bit planes of data image to generate new low level\nbit planes of the stego image. Recovery process includes the X-ORing of low\nlevel bit planes and mid level bit planes of the stego image. Based on the\nresult of the recovery, subsequent data image is generated. A RGB color image\nis used as carrier and the data image is a grayscale image of dimensions less\nthan or equal to the dimensions of the carrier image. The proposed method\ngreatly increases the embedding capacity without significantly decreasing the\nPSNR value.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 16:47:55 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Chakraborty", "Soumendu", ""], ["Jalal", "Anand Singh", ""], ["Bhatnagar", "Charul", ""]]}, {"id": "1410.3122", "submitter": "Soumendu Chakraborty", "authors": "Soumendu Chakraborty, Anand Singh Jalal and Charul Bhatnagar", "title": "Secret Image Sharing Using Grayscale Payload Decomposition and\n  Irreversible Image Steganography", "comments": null, "journal-ref": "J. of Info. Sec. and Appl. 18(4)(2013) 180-192", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide an added security level most of the existing reversible as well as\nirreversible image steganography schemes emphasize on encrypting the secret\nimage (payload) before embedding it to the cover image. The complexity of\nencryption for a large payload where the embedding algorithm itself is complex\nmay adversely affect the steganographic system. Schemes that can induce same\nlevel of distortion, as any standard encryption technique with lower\ncomputational complexity, can improve the performance of stego systems. In this\npaper we propose a secure secret image sharing scheme, which bears minimal\ncomputational complexity. The proposed scheme, as a replacement for encryption,\ndiversifies the payload into different matrices which are embedded into carrier\nimage (cover image) using bit X-OR operation. A payload is a grayscale image\nwhich is divided into frequency matrix, error matrix, and sign matrix. The\nfrequency matrix is scaled down using a mapping algorithm to produce Down\nScaled Frequency (DSF) matrix. The DSF matrix, error matrix, and sign matrix\nare then embedded in different cover images using bit X-OR operation between\nthe bit planes of the matrices and respective cover images. Analysis of the\nproposed scheme shows that it effectively camouflages the payload with minimum\ncomputation time.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 17:35:37 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Chakraborty", "Soumendu", ""], ["Jalal", "Anand Singh", ""], ["Bhatnagar", "Charul", ""]]}, {"id": "1410.3977", "submitter": "Ting-Yu Ho", "authors": "Ting-Yu Ho, Yi-Nung Yeh, and De-Nian Yang", "title": "Multi-View 3D Video Multicast for Broadband IP Networks", "comments": "9 pages, 10 figures, IEEE ICC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent emergence of 3D-supported TVs, video service providers now\nface an opportunity to provide high resolution multi-view 3D videos over IP\nnetworks. One simple way to support efficient communications between a video\nserver and multiple clients is to deliver each desired view in a multicast\nstream. Nevertheless, it is expected that significantly increased bandwidth\nwill be required to support the transmission of all views in multi-view 3D\nvideos. However, the recent emergence of a new video synthesis technique called\nDepth-Image-Based Rendering (DIBR) suggests that multi-view 3D video does not\nnecessarily require the transmission of all views. Therefore, we formulate a\nnew problem, named Multi-view and Multicast Delivery Selection Problem (MMDS),\nand design an algorithm, called MMDEA, to find the optimal solution. Simulation\nresults manifest that using DIBR can effectively reduce bandwidth consumption\nby 35% compared to the original multicast delivery scheme.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 09:09:10 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Ho", "Ting-Yu", ""], ["Yeh", "Yi-Nung", ""], ["Yang", "De-Nian", ""]]}, {"id": "1410.4730", "submitter": "Junhui Hou", "authors": "Junhui Hou and Lap-Pui Chau and Nadia Magnenat-Thalmann and Ying He", "title": "Human Motion Capture Data Tailored Transform Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human motion capture (mocap) is a widely used technique for digitalizing\nhuman movements. With growing usage, compressing mocap data has received\nincreasing attention, since compact data size enables efficient storage and\ntransmission. Our analysis shows that mocap data have some unique\ncharacteristics that distinguish themselves from images and videos. Therefore,\ndirectly borrowing image or video compression techniques, such as discrete\ncosine transform, does not work well. In this paper, we propose a novel\nmocap-tailored transform coding algorithm that takes advantage of these\nfeatures. Our algorithm segments the input mocap sequences into clips, which\nare represented in 2D matrices. Then it computes a set of data-dependent\northogonal bases to transform the matrices to frequency domain, in which the\ntransform coefficients have significantly less dependency. Finally, the\ncompression is obtained by entropy coding of the quantized coefficients and the\nbases. Our method has low computational cost and can be easily extended to\ncompress mocap databases. It also requires neither training nor complicated\nparameter setting. Experimental results demonstrate that the proposed scheme\nsignificantly outperforms state-of-the-art algorithms in terms of compression\nperformance and speed.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 14:16:08 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Hou", "Junhui", ""], ["Chau", "Lap-Pui", ""], ["Magnenat-Thalmann", "Nadia", ""], ["He", "Ying", ""]]}, {"id": "1410.4865", "submitter": "Kush Varshney", "authors": "Kush R. Varshney and Lav R. Varshney", "title": "Olfactory Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MM math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Olfaction, the sense of smell, has received scant attention from a signal\nprocessing perspective in comparison to audition and vision. In this paper, we\ndevelop a signal processing paradigm for olfactory signals based on new\nscientific discoveries including the psychophysics concept of olfactory white.\nWe describe a framework for predicting the perception of odorant compounds from\ntheir physicochemical features and use the prediction as a foundation for\nseveral downstream processing tasks. We detail formulations for odor\ncancellation and food steganography, and provide real-world empirical examples\nfor the two tasks. We also discuss adaptive filtering and other olfactory\nsignal processing tasks at a high level.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 21:09:55 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 17:13:30 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Varshney", "Kush R.", ""], ["Varshney", "Lav R.", ""]]}, {"id": "1410.5092", "submitter": "Muhammad Safdar", "authors": "Muhammad Safdar, Ming Ronnier Luo, and Xiaoyu Liu", "title": "Comparing CSI and PCA in Amalgamation with JPEG for Spectral Image\n  Compression", "comments": "Published in Proceedings of AIC2015, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuing our previous research on color image compression, we move towards\nspectral image compression. This enormous amount of data needs more space to\nstore and more time to transmit. To manage this sheer amount of data,\nresearchers have investigated different techniques so that image quality can be\nconserved and compressibility can be improved. The principle component analysis\n(PCA) can be employed to reduce the dimensions of spectral images to achieve\nhigh compressibility and performance. Due to processing complexity of PCA, a\nsimple interpolation technique called cubic spline interpolation (CSI) was\nconsidered to reduce the dimensionality of spectral domain of spectral images.\nThe CSI and PCA were employed one by one in the spectral domain and were\namalgamated with the JPEG, which was employed in spatial domain. Three measures\nincluding compression rate (CR), processing time (Tp) and color difference\nCIEDE2000 were used for performance analysis. Test results showed that for a\nfixed value of compression rate, CSI based algorithm performed poor in terms of\ndE00, in comparison with PCA, but is still reliable because of small color\ndifference. On the other hand it has lower complexity and is computationally\nmuch better as compared to PCA based algorithm, especially for spectral images\nwith large size.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 16:51:34 GMT"}, {"version": "v2", "created": "Fri, 12 Dec 2014 19:02:37 GMT"}, {"version": "v3", "created": "Sun, 15 Mar 2015 04:40:56 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2015 01:18:01 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Safdar", "Muhammad", ""], ["Luo", "Ming Ronnier", ""], ["Liu", "Xiaoyu", ""]]}, {"id": "1410.6592", "submitter": "Ankit Chaudhary", "authors": "Ankur Gupta, Ankit Chaudhary", "title": "Hiding Sound in Image by K-LSB Mutation", "comments": "appears in ISCBI 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel approach to hide sound files in a digital image is\nproposed and implemented such that it becomes difficult to conclude about the\nexistence of the hidden data inside the image. In this approach, we utilize the\nrightmost k-LSB of pixels in an image to embed MP3 sound bits into a pixel. The\npixels are so chosen that the distortion in image would be minimized due to\nembedding. This requires comparing all the possible permutations of pixel\nvalues, which may would lead to exponential time computation. To speed up this,\nCuckoo Search (CS) could be used to find the most optimal solution. The\nadvantage of using proposed CS is that it is easy to implement and is very\neffective at converging in relatively less iterations/generations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 06:36:48 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Gupta", "Ankur", ""], ["Chaudhary", "Ankit", ""]]}, {"id": "1410.6656", "submitter": "Benedikt Boehm", "authors": "Benedikt Boehm", "title": "StegExpose - A Tool for Detecting LSB Steganography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steganalysis tools play an important part in saving time and providing new\nangles of attack for forensic analysts. StegExpose is a solution designed for\nuse in the real world, and is able to analyse images for LSB steganography in\nbulk using proven attacks in a time efficient manner. When steganalytic methods\nare combined intelligently, they are able generate even more accurate results.\nThis is the prime focus of StegExpose.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 11:52:00 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Boehm", "Benedikt", ""]]}, {"id": "1410.6796", "submitter": "Wojciech Mazurczyk", "authors": "Wojciech Mazurczyk and Luca Caviglione", "title": "Steganography in Modern Smartphones and Mitigation Techniques", "comments": "25 pages, 8 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By offering sophisticated services and centralizing a huge volume of personal\ndata, modern smartphones changed the way we socialize, entertain and work. To\nthis aim, they rely upon complex hardware/software frameworks leading to a\nnumber of vulnerabilities, attacks and hazards to profile individuals or gather\nsensitive information. However, the majority of works evaluating the security\ndegree of smartphones neglects steganography, which can be mainly used to: i)\nexfiltrate confidential data via camouflage methods, and ii) conceal valuable\nor personal information into innocent looking carriers.\n  Therefore, this paper surveys the state of the art of steganographic\ntechniques for smartphones, with emphasis on methods developed over the period\n2005 to the second quarter of 2014. The different approaches are grouped\naccording to the portion of the device used to hide information, leading to\nthree different covert channels, i.e., local, object and network. Also, it\nreviews the relevant approaches used to detect and mitigate steganographic\nattacks or threats. Lastly, it showcases the most popular software applications\nto embed secret data into carriers, as well as possible future directions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 08:46:05 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Mazurczyk", "Wojciech", ""], ["Caviglione", "Luca", ""]]}, {"id": "1410.7540", "submitter": "Swaleha Saeed", "authors": "Swaleha Saeed, M Sarosh Umar, M Athar Ali and Musheer Ahmad", "title": "Fisher-Yates Chaotic Shuffling Based Image Encryption", "comments": null, "journal-ref": "International Journal of Information Processing, 8(3), 31-41, 2014\n  ISSN : 0973-8215 IK International Publishing House Pvt. Ltd., New Delhi,\n  India", "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Present era, information security is of utmost concern and encryption is\none of the alternatives to ensure security. Chaos based cryptography has\nbrought a secure and efficient way to meet the challenges of secure multimedia\ntransmission over the networks. In this paper, we have proposed a secure\nGrayscale image encryption methodology in wavelet domain. The proposed\nalgorithm performs shuffling followed by encryption using states of chaotic map\nin a secure manner. Firstly, the image is transformed from spatial domain to\nwavelet domain by the Haar wavelet. Subsequently, Fisher Yates chaotic\nshuffling technique is employed to shuffle the image in wavelet domain to\nconfuse the relationship between plain image and cipher image. A key dependent\npiece-wise linear chaotic map is used to generate chaos for the chaotic\nshuffling. Further, the resultant shuffled approximate coefficients are\nchaotically modulated. To enhance the statistical characteristics from\ncryptographic point of view, the shuffled image is self keyed diffused and\nmixing operation is carried out using keystream extracted from one-dimensional\nchaotic map and the plain-image. The proposed algorithm is tested over some\nstandard image dataset. The results of several experimental, statistical and\nsensitivity analyses proved that the algorithm provides an efficient and secure\nmethod to achieve trusted gray scale image encryption.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 07:48:03 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Saeed", "Swaleha", ""], ["Umar", "M Sarosh", ""], ["Ali", "M Athar", ""], ["Ahmad", "Musheer", ""]]}, {"id": "1410.8586", "submitter": "Tao Chen", "authors": "Tao Chen, Damian Borth, Trevor Darrell and Shih-Fu Chang", "title": "DeepSentiBank: Visual Sentiment Concept Classification with Deep\n  Convolutional Neural Networks", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a visual sentiment concept classification method based\non deep convolutional neural networks (CNNs). The visual sentiment concepts are\nadjective noun pairs (ANPs) automatically discovered from the tags of web\nphotos, and can be utilized as effective statistical cues for detecting\nemotions depicted in the images. Nearly one million Flickr images tagged with\nthese ANPs are downloaded to train the classifiers of the concepts. We adopt\nthe popular model of deep convolutional neural networks which recently shows\ngreat performance improvement on classifying large-scale web-based image\ndataset such as ImageNet. Our deep CNNs model is trained based on Caffe, a\nnewly developed deep learning framework. To deal with the biased training data\nwhich only contains images with strong sentiment and to prevent overfitting, we\ninitialize the model with the model weights trained from ImageNet. Performance\nevaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called\nDeepSentiBank) is significantly improved in both annotation accuracy and\nretrieval performance, compared to its predecessors which mainly use binary SVM\nclassification models.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 22:57:12 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Chen", "Tao", ""], ["Borth", "Damian", ""], ["Darrell", "Trevor", ""], ["Chang", "Shih-Fu", ""]]}]