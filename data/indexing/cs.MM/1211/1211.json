[{"id": "1211.0086", "submitter": "Yaser Sadra", "authors": "Sodeif Ahadpour, Mahdiyeh Majidpour, Yaser Sadra", "title": "Public key Steganography Using Discrete Cross-Coupled Chaotic Maps", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By cross-coupling two logistic maps a novel method is proposed for the public\nkey steganography in JPEG image. Chaotic maps entail high complexity in the\nused algorithm for embedding secret data in a medium. In this paper, discrete\ncross- coupled chaotic maps are used to specifying the location of the\ndifferent parts of the secret data in the image. Modifying JPEG format during\ncompressing and decompressing, and also using public key enhanced difficulty of\nthe algorithm. Simulation results show that in addition to excessive capacity,\nthis method has high robustness and resistance against hackers and can be\napplicable in secret communication. Also the PSNR value is high compared to the\nother works.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 04:09:10 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Ahadpour", "Sodeif", ""], ["Majidpour", "Mahdiyeh", ""], ["Sadra", "Yaser", ""]]}, {"id": "1211.0135", "submitter": "Jayakrishnan Unnikrishnan", "authors": "Jayakrishnan Unnikrishnan and Martin Vetterli", "title": "Sampling and Reconstruction of Spatial Fields using Mobile Sensors", "comments": "Submitted to IEEE Transactions on Signal Processing May 2012; revised\n  Oct 2012", "journal-ref": null, "doi": "10.1109/TSP.2013.2247599", "report-no": null, "categories": "cs.MM cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial sampling is traditionally studied in a static setting where static\nsensors scattered around space take measurements of the spatial field at their\nlocations. In this paper we study the emerging paradigm of sampling and\nreconstructing spatial fields using sensors that move through space. We show\nthat mobile sensing offers some unique advantages over static sensing in\nsensing time-invariant bandlimited spatial fields. Since a moving sensor\nencounters such a spatial field along its path as a time-domain signal, a\ntime-domain anti-aliasing filter can be employed prior to sampling the signal\nreceived at the sensor. Such a filtering procedure, when used by a\nconfiguration of sensors moving at constant speeds along equispaced parallel\nlines, leads to a complete suppression of spatial aliasing in the direction of\nmotion of the sensors. We analytically quantify the advantage of using such a\nsampling scheme over a static sampling scheme by computing the reduction in\nsampling noise due to the filter. We also analyze the effects of non-uniform\nsensor speeds on the reconstruction accuracy. Using simulation examples we\ndemonstrate the advantages of mobile sampling over static sampling in practical\nproblems.\n  We extend our analysis to sampling and reconstruction schemes for monitoring\ntime-varying bandlimited fields using mobile sensors. We demonstrate that in\nsome situations we require a lower density of sensors when using a mobile\nsensing scheme instead of the conventional static sensing scheme. The exact\nadvantage is quantified for a problem of sampling and reconstructing an audio\nfield.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 10:05:46 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Unnikrishnan", "Jayakrishnan", ""], ["Vetterli", "Martin", ""]]}, {"id": "1211.0377", "submitter": "Dr. Rajesh Kumar  Tiwari", "authors": "Rajesh Kumar Tiwari and Gadadhar Sahoo", "title": "Some New Methodologies for Image Hiding using Steganographic Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security and memory management are the major demands for electronics devices\nlike ipods, cell phones, pmps, iphones and digital cameras. In this paper, we\nhave suggested a high level of security mechanism by considering the concept of\nsteganography along with the principle of cryptography. Four different methods\nthat can save a considerable amount of memory space have been discussed. Based\non these methods, we have constructed secured stego image creator and secured\nmulti image viewer in Microsoft platform so as to provide high level of\nsecurity and using less memory space for storage of image files in the above\nsaid electronic devices\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2012 06:36:12 GMT"}], "update_date": "2012-11-05", "authors_parsed": [["Tiwari", "Rajesh Kumar", ""], ["Sahoo", "Gadadhar", ""]]}, {"id": "1211.1345", "submitter": "Bata Vasic Mr.", "authors": "Bata Vasic", "title": "Ordered Statistics Vertex Extraction and Tracing Algorithm (OSVETA)", "comments": "Accepted for publishing and Copyright transfered to Advances in\n  Electrical and Computer Engineering, November 23th 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for identifying vertices from three dimensional (3D)\nmeshes that are most important for a geometric shape creation. Extracting such\na set of vertices from a 3D mesh is important in applications such as digital\nwatermarking, but also as a component of optimization and triangulation. In the\nfirst step, the Ordered Statistics Vertex Extraction and Tracing Algorithm\n(OSVETA) estimates precisely the local curvature, and most important\ntopological features of mesh geometry. Using the vertex geometric importance\nranking, the algorithm traces and extracts a vector of vertices, ordered by\ndecreasing index of importance.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 18:39:50 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2012 14:30:35 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Vasic", "Bata", ""]]}, {"id": "1211.1572", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Embedding grayscale halftone pictures in QR Codes using Correction Trees", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Barcodes like QR Codes have made that encoded messages have entered our\neveryday life, what suggests to attach them a second layer of information:\ndirectly available to human receiver for informational or marketing purposes.\nWe will discuss a general problem of using codes with chosen statistical\nconstrains, for example reproducing given grayscale picture using halftone\ntechnique. If both sender and receiver know these constrains, the optimal\ncapacity can be easily approached by entropy coder. The problem is that this\ntime only the sender knows them - we will refer to these scenarios as\nconstrained coding. Kuznetsov and Tsybakov problem in which only the sender\nknows which bits are fixed can be seen as a special case, surprisingly\napproaching the same capacity as if both sides would know the constrains. We\nwill analyze Correction Trees to approach analogous capacity in the general\ncase - use weaker: statistical constrains, what allows to apply them to all\nbits. Finding satisfying coding is similar to finding the proper correction in\nerror correction problem, but instead of single ensured possibility, there are\nnow statistically expected some. While in standard steganography we hide\ninformation in the least important bits, this time we create codes resembling\ngiven picture - hide information in the freedom of realizing grayness by black\nand white pixels using halftone technique. We will also discuss combining with\nerror correction and application to rate distortion problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 15:19:23 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2012 08:59:33 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2012 08:44:38 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1211.2569", "submitter": "Ka Chun Lam", "authors": "Lok Ming Lui, Ka Chun Lam, Shing-Tung Yau, Xianfeng Gu", "title": "Teichm\\\"uller extremal mapping and its applications to landmark matching\n  registration", "comments": "26 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.GR cs.MM math.DG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Registration, which aims to find an optimal 1-1 correspondence between\nshapes, is an important process in different research areas. Conformal mappings\nhave been widely used to obtain a diffeomorphism between shapes that minimizes\nangular distortion. Conformal registrations are beneficial since it preserves\nthe local geometry well. However, when landmark constraints are enforced,\nconformal mappings generally do not exist. This motivates us to look for a\nunique landmark matching quasi-conformal registration, which minimizes the\nconformality distortion. Under suitable condition on the landmark constraints,\na unique diffeomporphism, called the Teichm\\\"uller extremal mapping between two\nsurfaces can be obtained, which minimizes the maximal conformality distortion.\nIn this paper, we propose an efficient iterative algorithm, called the\nQuasi-conformal (QC) iterations, to compute the Teichm\\\"uller mapping. The\nbasic idea is to represent the set of diffeomorphisms using Beltrami\ncoefficients (BCs), and look for an optimal BC associated to the desired\nTeichm\\\"uller mapping. The associated diffeomorphism can be efficiently\nreconstructed from the optimal BC using the Linear Beltrami Solver(LBS). Using\nBCs to represent diffeomorphisms guarantees the diffeomorphic property of the\nregistration. Using our proposed method, the Teichm\\\"uller mapping can be\naccurately and efficiently computed within 10 seconds. The obtained\nregistration is guaranteed to be bijective. The proposed algorithm can also be\nextended to compute Teichm\\\"uller mapping with soft landmark constraints. We\napplied the proposed algorithm to real applications, such as brain landmark\nmatching registration, constrained texture mapping and human face registration.\nExperimental results shows that our method is both effective and efficient in\ncomputing a non-overlap landmark matching registration with least amount of\nconformality distortion.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 11:16:31 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Lui", "Lok Ming", ""], ["Lam", "Ka Chun", ""], ["Yau", "Shing-Tung", ""], ["Gu", "Xianfeng", ""]]}, {"id": "1211.2699", "submitter": "Abdur Shahid Rahman Bin", "authors": "Abdur Shahid, Shahriar Badsha, Md. Rethwan Kabeer, Junaid Ahsan and\n  Mufti Mahmud", "title": "A Non-Blind Watermarking Scheme for Gray Scale Images in Discrete\n  Wavelet Transform Domain using Two Subbands", "comments": "9 pages, 7 figures", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 5, No 1, September 2012, page 101-109", "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Digital watermarking is the process to hide digital pattern directly into a\ndigital content. Digital watermarking techniques are used to address digital\nrights management, protect information and conceal secrets. An invisible\nnon-blind watermarking approach for gray scale images is proposed in this\npaper. The host image is decomposed into 3-levels using Discrete Wavelet\nTransform. Based on the parent-child relationship between the wavelet\ncoefficients the Set Partitioning in Hierarchical Trees (SPIHT) compression\nalgorithm is performed on the LH3, LH2, HL3 and HL2 subbands to find out the\nsignificant coefficients. The most significant coefficients of LH2 and HL2\nbands are selected to embed a binary watermark image. The selected significant\ncoefficients are modulated using Noise Visibility Function, which is considered\nas the best strength to ensure better imperceptibility. The approach is tested\nagainst various image processing attacks such as addition of noise, filtering,\ncropping, JPEG compression, histogram equalization and contrast adjustment. The\nexperimental results reveal the high effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 17:15:41 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Shahid", "Abdur", ""], ["Badsha", "Shahriar", ""], ["Kabeer", "Md. Rethwan", ""], ["Ahsan", "Junaid", ""], ["Mahmud", "Mufti", ""]]}, {"id": "1211.4014", "submitter": "Nikolaos Thomos", "authors": "Nikolaos Thomos, Rethnakaran Pulikkoonattu, and Pascal Frossard", "title": "Intermediate Performance Analysis of Growth Codes", "comments": "submitted to Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MM cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growth codes are a subclass of Rateless codes that have found interesting\napplications in data dissemination problems. Compared to other Rateless and\nconventional channel codes, Growth codes show improved intermediate performance\nwhich is particularly useful in applications where performance increases with\nthe number of decoded data units. In this paper, we provide a generic\nanalytical framework for studying the asymptotic performance of Growth codes in\ndifferent settings. Our analysis based on Wormald method applies to any class\nof Rateless codes that does not include a precoding step. We evaluate the\ndecoding probability model for short codeblocks and validate our findings by\nexperiments. We then exploit the decoding probability model in an illustrative\napplication of Growth codes to error resilient video transmission. The video\ntransmission problem is cast as a joint source and channel rate allocation\nproblem that is shown to be convex with respect to the channel rate. This\napplication permits to highlight the main advantage of Growth codes that is\nimproved performance (hence distortion in video) in the intermediate loss\nregion.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 20:32:57 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Thomos", "Nikolaos", ""], ["Pulikkoonattu", "Rethnakaran", ""], ["Frossard", "Pascal", ""]]}, {"id": "1211.4206", "submitter": "Pascal Frossard", "authors": "Enrico Magli, Mea Wang, Pascal Frossard, Athina Markopoulou", "title": "Network Coding Meets Multimedia: a Review", "comments": "Part of this work is under publication in IEEE Transactions on\n  Multimedia", "journal-ref": null, "doi": "10.1109/TMM.2013.2241415", "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While every network node only relays messages in a traditional communication\nsystem, the recent network coding (NC) paradigm proposes to implement simple\nin-network processing with packet combinations in the nodes. NC extends the\nconcept of \"encoding\" a message beyond source coding (for compression) and\nchannel coding (for protection against errors and losses). It has been shown to\nincrease network throughput compared to traditional networks implementation, to\nreduce delay and to provide robustness to transmission errors and network\ndynamics. These features are so appealing for multimedia applications that they\nhave spurred a large research effort towards the development of\nmultimedia-specific NC techniques. This paper reviews the recent work in NC for\nmultimedia applications and focuses on the techniques that fill the gap between\nNC theory and practical applications. It outlines the benefits of NC and\npresents the open challenges in this area. The paper initially focuses on\nmultimedia-specific aspects of network coding, in particular delay, in-network\nerror control, and media-specific error control. These aspects permit to handle\nvarying network conditions as well as client heterogeneity, which are critical\nto the design and deployment of multimedia systems. After introducing these\ngeneral concepts, the paper reviews in detail two applications that lend\nthemselves naturally to NC via the cooperation and broadcast models, namely\npeer-to-peer multimedia streaming and wireless networking.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2012 10:43:54 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Magli", "Enrico", ""], ["Wang", "Mea", ""], ["Frossard", "Pascal", ""], ["Markopoulou", "Athina", ""]]}, {"id": "1211.4591", "submitter": "Firas Ajil Jassim", "authors": "Firas A. Jassim, Hind E. Qassim", "title": "Five Modulus Method For Image Compression", "comments": "10 pages, 2 figures, 9 tables", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ),\n  Vol.3, No.5, October 2012", "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data is compressed by reducing its redundancy, but this also makes the data\nless reliable, more prone to errors. In this paper a novel approach of image\ncompression based on a new method that has been created for image compression\nwhich is called Five Modulus Method (FMM). The new method consists of\nconverting each pixel value in an 8-by-8 block into a multiple of 5 for each of\nthe R, G and B arrays. After that, the new values could be divided by 5 to get\nnew values which are 6-bit length for each pixel and it is less in storage\nspace than the original value which is 8-bits. Also, a new protocol for\ncompression of the new values as a stream of bits has been presented that gives\nthe opportunity to store and transfer the new compressed image easily.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 21:02:58 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Jassim", "Firas A.", ""], ["Qassim", "Hind E.", ""]]}, {"id": "1211.4683", "submitter": "Bhavesh Patel", "authors": "B. V. Patel and B. B. Meshram", "title": "Content based video retrieval", "comments": null, "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol.4, No.5, October 2012", "doi": "10.5121/ijma.2012.4506", "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content based video retrieval is an approach for facilitating the searching\nand browsing of large image collections over World Wide Web. In this approach,\nvideo analysis is conducted on low level visual properties extracted from video\nframe. We believed that in order to create an effective video retrieval system,\nvisual perception must be taken into account. We conjectured that a technique\nwhich employs multiple features for indexing and retrieval would be more\neffective in the discrimination and search tasks of videos. In order to\nvalidate this claim, content based indexing and retrieval systems were\nimplemented using color histogram, various texture features and other\napproaches. Videos were stored in Oracle 9i Database and a user study measured\ncorrectness of response.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 08:22:56 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Patel", "B. V.", ""], ["Meshram", "B. B.", ""]]}, {"id": "1211.4767", "submitter": "Gene Cheung", "authors": "Dongni Ren, S.-H. Gary Chan, Gene Cheung, Vicky Zhao, Pascal Frossard", "title": "Collaborative P2P Streaming of Interactive Live Free Viewpoint Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an interactive live streaming scenario where multiple peers pull\nstreams of the same free viewpoint video that are synchronized in time but not\nnecessarily in view. In free viewpoint video, each user can periodically select\na virtual view between two anchor camera views for display. The virtual view is\nsynthesized using texture and depth videos of the anchor views via\ndepth-image-based rendering (DIBR). In general, the distortion of the virtual\nview increases with the distance to the anchor views, and hence it is\nbeneficial for a peer to select the closest anchor views for synthesis. On the\nother hand, if peers interested in different virtual views are willing to\ntolerate larger distortion in using more distant anchor views, they can\ncollectively share the access cost of common anchor views.\n  Given anchor view access cost and synthesized distortion of virtual views\nbetween anchor views, we study the optimization of anchor view allocation for\ncollaborative peers. We first show that, if the network reconfiguration costs\ndue to view-switching are negligible, the problem can be optimally solved in\npolynomial time using dynamic programming. We then consider the case of\nnon-negligible reconfiguration costs (e.g., large or frequent view-switching\nleading to anchor-view changes). In this case, the view allocation problem\nbecomes NP-hard. We thus present a locally optimal and centralized allocation\nalgorithm inspired by Lloyd's algorithm in non-uniform scalar quantization. We\nalso propose a distributed algorithm with guaranteed convergence where each\npeer group independently make merge-and-split decisions with a well-defined\nfairness criteria. The results show that depending on the problem settings, our\nproposed algorithms achieve respective optimal and close-to-optimal performance\nin terms of total cost, and outperform a P2P scheme without collaborative\nanchor selection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 15:04:43 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Ren", "Dongni", ""], ["Chan", "S. -H. Gary", ""], ["Cheung", "Gene", ""], ["Zhao", "Vicky", ""], ["Frossard", "Pascal", ""]]}, {"id": "1211.5492", "submitter": "Mohammad Soleymani", "authors": "Mohammad Soleymani and Martha Larson and Thierry Pun and Alan Hanjalic", "title": "Corpus Development for Affective Video Indexing", "comments": "Manuscript published", "journal-ref": "IEEE Transactions on Multimedia 16(4):1075-1089, 2014", "doi": "10.1109/TMM.2014.2305573", "report-no": null, "categories": "cs.MM cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affective video indexing is the area of research that develops techniques to\nautomatically generate descriptions of video content that encode the emotional\nreactions which the video content evokes in viewers. This paper provides a set\nof corpus development guidelines based on state-of-the-art practice intended to\nsupport researchers in this field. Affective descriptions can be used for video\nsearch and browsing systems offering users affective perspectives. The paper is\nmotivated by the observation that affective video indexing has yet to fully\nprofit from the standard corpora (data sets) that have benefited conventional\nforms of video indexing. Affective video indexing faces unique challenges,\nsince viewer-reported affective reactions are difficult to assess. Moreover\naffect assessment efforts must be carefully designed in order to both cover the\ntypes of affective responses that video content evokes in viewers and also\ncapture the stable and consistent aspects of these responses. We first present\nbackground information on affect and multimedia and related work on affective\nmultimedia indexing, including existing corpora. Three dimensions emerge as\ncritical for affective video corpora, and form the basis for our proposed\nguidelines: the context of viewer response, personal variation among viewers,\nand the effectiveness and efficiency of corpus creation. Finally, we present\nexamples of three recent corpora and discuss how these corpora make progressive\nsteps towards fulfilling the guidelines.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2012 13:06:25 GMT"}, {"version": "v2", "created": "Tue, 19 Aug 2014 10:11:02 GMT"}, {"version": "v3", "created": "Fri, 28 Nov 2014 10:52:25 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Soleymani", "Mohammad", ""], ["Larson", "Martha", ""], ["Pun", "Thierry", ""], ["Hanjalic", "Alan", ""]]}, {"id": "1211.5614", "submitter": "Ankit Chaudhary", "authors": "Ankit Chaudhary, J. Vasavada, J.L. Raheja, S. Kumar, M. Sharma", "title": "A Hash based Approach for Secure Keyless Steganography in Lossless RGB\n  Images", "comments": "The paper is withdrawn due to license issue", "journal-ref": "The 22nd International Conference on Computer Graphics and Vision,\n  2012, pp.80-83", "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an improved steganography approach for hiding text\nmessages in lossless RGB images. The objective of this work is to increase the\nsecurity level and to improve the storage capacity with compression techniques.\nThe security level is increased by randomly distributing the text message over\nthe entire image instead of clustering within specific image portions. Storage\ncapacity is increased by utilizing all the color channels for storing\ninformation and providing the source text message compression. The degradation\nof the images can be minimized by changing only one least significant bit per\ncolor channel for hiding the message, incurring a very little change in the\noriginal image. Using steganography alone with simple LSB has a potential\nproblem that the secret message is easily detectable from the histogram\nanalysis method. To improve the security as well as the image embedding\ncapacity indirectly, a compression based scheme is introduced. Various tests\nhave been done to check the storage capacity and message distribution. These\ntestes show the superiority of the proposed approach with respect to other\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2012 21:34:53 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 16:41:40 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2013 01:27:39 GMT"}, {"version": "v4", "created": "Sun, 10 Mar 2013 08:21:45 GMT"}, {"version": "v5", "created": "Wed, 17 Apr 2013 00:20:00 GMT"}], "update_date": "2013-04-18", "authors_parsed": [["Chaudhary", "Ankit", ""], ["Vasavada", "J.", ""], ["Raheja", "J. L.", ""], ["Kumar", "S.", ""], ["Sharma", "M.", ""]]}, {"id": "1211.7102", "submitter": "Rowayda Sadek", "authors": "Rowayda A. Sadek", "title": "SVD Based Image Processing Applications: State of The Art, Contributions\n  and Research Challenges", "comments": null, "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications, Vol. 3, No. 7, 2012 26-34", "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular Value Decomposition (SVD) has recently emerged as a new paradigm for\nprocessing different types of images. SVD is an attractive algebraic transform\nfor image processing applications. The paper proposes an experimental survey\nfor the SVD as an efficient transform in image processing applications. Despite\nthe well-known fact that SVD offers attractive properties in imaging, the\nexploring of using its properties in various image applications is currently at\nits infancy. Since the SVD has many attractive properties have not been\nutilized, this paper contributes in using these generous properties in newly\nimage applications and gives a highly recommendation for more research\nchallenges. In this paper, the SVD properties for images are experimentally\npresented to be utilized in developing new SVD-based image processing\napplications. The paper offers survey on the developed SVD based image\napplications. The paper also proposes some new contributions that were\noriginated from SVD properties analysis in different image processing. The aim\nof this paper is to provide a better understanding of the SVD in image\nprocessing and identify important various applications and open research\ndirections in this increasingly important area; SVD based image processing in\nthe future research.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2012 21:52:00 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Sadek", "Rowayda A.", ""]]}]