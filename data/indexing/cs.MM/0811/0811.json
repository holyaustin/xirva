[{"id": "0811.0582", "submitter": "Jean Francois Nezan", "authors": "Maxime Pelcat (IETR), Slaheddine Aridhi, Jean Fran\\c{c}ois Nezan\n  (IETR)", "title": "Optimization of automatically generated multi-core code for the LTE\n  RACH-PD algorithm", "comments": null, "journal-ref": "DASIP 2008, Bruxelles : Belgique (2008)", "doi": null, "report-no": null, "categories": "cs.MM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded real-time applications in communication systems require high\nprocessing power. Manual scheduling devel-oped for single-processor\napplications is not suited to multi-core architectures. The Algorithm\nArchitecture Matching (AAM) methodology optimizes static application\nimplementation on multi-core architectures. The Random Access Channel Preamble\nDetection (RACH-PD) is an algorithm for non-synchronized access of Long Term\nEvolu-tion (LTE) wireless networks. LTE aims to improve the spectral efficiency\nof the next generation cellular system. This paper de-scribes a complete\nmethodology for implementing the RACH-PD. AAM prototyping is applied to the\nRACH-PD which is modelled as a Synchronous DataFlow graph (SDF). An efficient\nimplemen-tation of the algorithm onto a multi-core DSP, the TI C6487, is then\nexplained. Benchmarks for the solution are given.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2008 19:36:16 GMT"}], "update_date": "2008-11-05", "authors_parsed": [["Pelcat", "Maxime", "", "IETR"], ["Aridhi", "Slaheddine", "", "IETR"], ["Nezan", "Jean Fran\u00e7ois", "", "IETR"]]}, {"id": "0811.1959", "submitter": "Charles Robert", "authors": "Charles A. B. Robert (LORIA)", "title": "Characterization and collection of information from heterogeneous\n  multimedia sources with users' parameters for decision support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No single information source can be good enough to satisfy the divergent and\ndynamic needs of users all the time. Integrating information from divergent\nsources can be a solution to deficiencies in information content. We present\nhow Information from multimedia document can be collected based on associating\na generic database to a federated database. Information collected in this way\nis brought into relevance by integrating the parameters of usage and user's\nparameter for decision making. We identified seven different classifications of\nmultimedia document.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2008 20:10:00 GMT"}], "update_date": "2008-11-13", "authors_parsed": [["Robert", "Charles A. B.", "", "LORIA"]]}, {"id": "0811.2868", "submitter": "Hamed Firouzi", "authors": "Hamed Firouzi, Masoud Farivar, Massoud Babaie-Zadeh, Christian Jutten", "title": "Approximate Sparse Decomposition Based on Smoothed L0-Norm", "comments": "4 Pages, Submitted to ICASSP 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method to address the problem of source\nestimation for Sparse Component Analysis (SCA) in the presence of additive\nnoise. Our method is a generalization of a recently proposed method (SL0),\nwhich has the advantage of directly minimizing the L0-norm instead of L1-norm,\nwhile being very fast. SL0 is based on minimization of the smoothed L0-norm\nsubject to As=x. In order to better estimate the source vector for noisy\nmixtures, we suggest then to remove the constraint As=x, by relaxing exact\nequality to an approximation (we call our method Smoothed L0-norm Denoising or\nSL0DN). The final result can then be obtained by minimization of a proper\nlinear combination of the smoothed L0-norm and a cost function for the\napproximation. Experimental results emphasize on the significant enhancement of\nthe modified method in noisy cases.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2008 09:14:18 GMT"}], "update_date": "2008-11-19", "authors_parsed": [["Firouzi", "Hamed", ""], ["Farivar", "Masoud", ""], ["Babaie-Zadeh", "Massoud", ""], ["Jutten", "Christian", ""]]}, {"id": "0811.4138", "submitter": "Wojciech Mazurczyk", "authors": "Wojciech Mazurczyk, Jozef Lubacz", "title": "LACK - a VoIP Steganographic Method", "comments": "13 pages, 11 figures, final version of this paper will be published\n  in Springer's Telecommunication Systems Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a new steganographic method called LACK (Lost Audio\nPaCKets Steganography) which is intended mainly for VoIP. The method is\npresented in a broader context of network steganography and of VoIP\nsteganography in particular. The analytical results presented in the paper\nconcern the influence of LACK's hidden data insertion procedure on the method's\nimpact on quality of voice transmission and its resistance to steganalysis.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2008 17:25:13 GMT"}], "update_date": "2008-11-26", "authors_parsed": [["Mazurczyk", "Wojciech", ""], ["Lubacz", "Jozef", ""]]}, {"id": "0811.4483", "submitter": "Ga\\\"etan Le Guelvouit", "authors": "Ga\\\"etan Le Guelvouit, St\\'ephane Pateux", "title": "Wide spread spectrum watermarking with side information and interference\n  cancellation", "comments": "12 pages, 8 figures", "journal-ref": "Proc. IS&T/SPIE Electronic Imaging, vol. 5020, Santa Clara, CA,\n  Jan. 2003", "doi": "10.1117/12.476839", "report-no": null, "categories": "cs.MM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, a popular method used for additive watermarking is wide spread\nspectrum. It consists in adding a spread signal into the host document. This\nsignal is obtained by the sum of a set of carrier vectors, which are modulated\nby the bits to be embedded. To extract these embedded bits, weighted\ncorrelations between the watermarked document and the carriers are computed.\nUnfortunately, even without any attack, the obtained set of bits can be\ncorrupted due to the interference with the host signal (host interference) and\nalso due to the interference with the others carriers (inter-symbols\ninterference (ISI) due to the non-orthogonality of the carriers). Some recent\nwatermarking algorithms deal with host interference using side informed\nmethods, but inter-symbols interference problem is still open. In this paper,\nwe deal with interference cancellation methods, and we propose to consider ISI\nas side information and to integrate it into the host signal. This leads to a\ngreat improvement of extraction performance in term of signal-to-noise ratio\nand/or watermark robustness.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2008 16:28:59 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Guelvouit", "Ga\u00ebtan Le", ""], ["Pateux", "St\u00e9phane", ""]]}, {"id": "0811.4672", "submitter": "Kui Wu", "authors": "Emad Soroush, Kui Wu, Jian Pei", "title": "Fast and Quality-Guaranteed Data Streaming in Resource-Constrained\n  Sensor Networks", "comments": "Published in ACM MobiHoc 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many emerging applications, data streams are monitored in a network\nenvironment. Due to limited communication bandwidth and other resource\nconstraints, a critical and practical demand is to online compress data streams\ncontinuously with quality guarantee. Although many data compression and digital\nsignal processing methods have been developed to reduce data volume, their\nsuper-linear time and more-than-constant space complexity prevents them from\nbeing applied directly on data streams, particularly over resource-constrained\nsensor networks. In this paper, we tackle the problem of online quality\nguaranteed compression of data streams using fast linear approximation (i.e.,\nusing line segments to approximate a time series). Technically, we address two\nversions of the problem which explore quality guarantees in different forms. We\ndevelop online algorithms with linear time complexity and constant cost in\nspace. Our algorithms are optimal in the sense they generate the minimum number\nof segments that approximate a time series with the required quality guarantee.\nTo meet the resource constraints in sensor networks, we also develop a fast\nalgorithm which creates connecting segments with very simple computation. The\nlow cost nature of our methods leads to a unique edge on the applications of\nmassive and fast streaming environment, low bandwidth networks, and heavily\nconstrained nodes in computational power. We implement and evaluate our methods\nin the application of an acoustic wireless sensor network.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2008 20:59:55 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Soroush", "Emad", ""], ["Wu", "Kui", ""], ["Pei", "Jian", ""]]}, {"id": "0811.4681", "submitter": "Ga?tan Le Guelvouit", "authors": "Ga\\\"etan Le Guelvouit, Teddy Furon, Fran\\c{c}ois Cayre", "title": "The Good, the Bad, and the Ugly: three different approaches to break\n  their watermarking system", "comments": "8 pages, 8 figures", "journal-ref": "Proc. IS&T/SPIE Electronic Imaging, vol. 6505, San Jose, CA, Jan.\n  2007", "doi": "10.1117/12.703968", "report-no": null, "categories": "cs.GR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Good is Blondie, a wandering gunman with a strong personal sense of\nhonor. The Bad is Angel Eyes, a sadistic hitman who always hits his mark. The\nUgly is Tuco, a Mexican bandit who's always only looking out for himself.\nAgainst the backdrop of the BOWS contest, they search for a watermark in gold\nburied in three images. Each knows only a portion of the gold's exact location,\nso for the moment they're dependent on each other. However, none are\nparticularly inclined to share...\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2008 16:31:12 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Guelvouit", "Ga\u00ebtan Le", ""], ["Furon", "Teddy", ""], ["Cayre", "Fran\u00e7ois", ""]]}, {"id": "0811.4697", "submitter": "Ga\\\"etan Le Guelvouit", "authors": "Sofiane Braci, Claude Delpha, R\\'emy Boyer, Ga\\\"etan Le Guelvouit", "title": "Informed stego-systems in active warden context: statistical\n  undetectability and capacity", "comments": "6 pages, 8 figures", "journal-ref": "Proc. IEEE Conf. on Multimedia Signal Processing, Cairns,\n  Australia, Oct. 2008", "doi": "10.1109/MMSP.2008.4665167", "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several authors have studied stego-systems based on Costa scheme, but just a\nfew ones gave both theoretical and experimental justifications of these schemes\nperformance in an active warden context. We provide in this paper a\nsteganographic and comparative study of three informed stego-systems in active\nwarden context: scalar Costa scheme, trellis-coded quantization and spread\ntransform scalar Costa scheme. By leading on analytical formulations and on\nexperimental evaluations, we show the advantages and limits of each scheme in\nterm of statistical undetectability and capacity in the case of active warden.\nSuch as the undetectability is given by the distance between the stego-signal\nand the cover distance. It is measured by the Kullback-Leibler distance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2008 12:04:51 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Braci", "Sofiane", ""], ["Delpha", "Claude", ""], ["Boyer", "R\u00e9my", ""], ["Guelvouit", "Ga\u00ebtan Le", ""]]}, {"id": "0811.4700", "submitter": "Ga\\\"etan Le Guelvouit", "authors": "Ga\\\"etan Le Guelvouit", "title": "Trellis-coded quantization for public-key steganography", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with public-key steganography in the presence of a passive\nwarden. The aim is to hide secret messages within cover-documents without\nmaking the warden suspicious, and without any preliminar secret key sharing.\nWhereas a practical attempt has been already done to provide a solution to this\nproblem, it suffers of poor flexibility (since embedding and decoding steps\nhighly depend on cover-signals statistics) and of little capacity compared to\nrecent data hiding techniques. Using the same framework, this paper explores\nthe use of trellis-coded quantization techniques (TCQ and turbo TCQ) to design\na more efficient public-key scheme. Experiments on audio signals show great\nimprovements considering Cachin's security criterion.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2008 16:07:33 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Guelvouit", "Ga\u00ebtan Le", ""]]}, {"id": "0811.4702", "submitter": "Ga\\\"etan Le Guelvouit", "authors": "St\\'ephane Pateux, Ga\\\"etan Le Guelvouit, Christine Guillemot", "title": "Information-theoretic resolution of perceptual WSS watermarking of non\n  i.i.d. Gaussian signals", "comments": "4 pages, 3 figures", "journal-ref": "Proc. European Signal Processing Conf., Toulouse, France, Sep.\n  2002", "doi": null, "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theoretical foundations of data hiding have been revealed by formulating\nthe problem as message communication over a noisy channel. We revisit the\nproblem in light of a more general characterization of the watermark channel\nand of weighted distortion measures. Considering spread spectrum based\ninformation hiding, we release the usual assumption of an i.i.d. cover signal.\nThe game-theoretic resolution of the problem reveals a generalized\ncharacterization of optimum attacks. The paper then derives closed-form\nexpressions for the different parameters exhibiting a practical embedding and\nextraction technique.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2008 12:41:23 GMT"}], "update_date": "2008-12-01", "authors_parsed": [["Pateux", "St\u00e9phane", ""], ["Guelvouit", "Ga\u00ebtan Le", ""], ["Guillemot", "Christine", ""]]}]