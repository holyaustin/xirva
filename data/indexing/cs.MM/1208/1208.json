[{"id": "1208.0072", "submitter": "Ashish Khisti", "authors": "Ahmed Badr, Ashish Khisti, Wai-Tian Tan and John Apostolopoulos", "title": "Streaming Codes for Channels with Burst and Isolated Erasures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study low-delay error correction codes for streaming recovery over a class\nof packet-erasure channels that introduce both burst-erasures and isolated\nerasures. We propose a simple, yet effective class of codes whose parameters\ncan be tuned to obtain a tradeoff between the capability to correct burst and\nisolated erasures. Our construction generalizes previously proposed low-delay\ncodes which are effective only against burst erasures. We establish an\ninformation theoretic upper bound on the capability of any code to\nsimultaneously correct burst and isolated erasures and show that our proposed\nconstructions meet the upper bound in some special cases. We discuss the\noperational significance of column-distance and column-span metrics and\nestablish that the rate 1/2 codes discovered by Martinian and Sundberg [IT\nTrans.\\, 2004] through a computer search indeed attain the optimal\ncolumn-distance and column-span tradeoff. Numerical simulations over a\nGilbert-Elliott channel model and a Fritchman model show significant\nperformance gains over previously proposed low-delay codes and random linear\ncodes for certain range of channel parameters.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2012 03:36:44 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Badr", "Ahmed", ""], ["Khisti", "Ashish", ""], ["Tan", "Wai-Tian", ""], ["Apostolopoulos", "John", ""]]}, {"id": "1208.0950", "submitter": "Nilanjan  Dey", "authors": "Tanmay Bhattacharya, Nilanjan Dey, S. R. Bhadra Chaudhuri", "title": "A Session based Multiple Image Hiding Technique using DWT and DCT", "comments": "4 pages,16 figures, \"Published with International Journal of Computer\n  Applications (IJCA)\"", "journal-ref": "Tanmay Bhattacharya,Nilanjan Dey,Bhadra S R Chaudhuri. Article:A\n  Session Based Multiple Image Hiding Technique using DWT&DCT.International\n  Journal of Computer Applications 38(5):18-21,January 2012.Published by\n  Foundation of Computer Science", "doi": "10.5120/4684-6808 10.5120/4684-6808 10.5120/4684-6808", "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes Steganographic technique for hiding multiple images in a\ncolor image based on DWT and DCT. The cover image is decomposed into three\nseparate color planes namely R, G and B. Individual planes are decomposed into\nsubbands using DWT. DCT is applied in HH component of each plane. Secret images\nare dispersed among the selected DCT coefficients using a pseudo random\nsequence and a Session key. Secret images are extracted using the session key\nand the size of the images from the planer decomposed stego image. In this\napproach the stego image generated is of acceptable level of imperceptibility\nand distortion compared to the cover image and the overall security is high.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2012 18:10:35 GMT"}], "update_date": "2012-08-16", "authors_parsed": [["Bhattacharya", "Tanmay", ""], ["Dey", "Nilanjan", ""], ["Chaudhuri", "S. R. Bhadra", ""]]}, {"id": "1208.1418", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha, Bharatraaj Savardekar, Jay Padhya", "title": "Analysis of a Modern Voice Morphing Approach using Gaussian Mixture\n  Models for Laryngectomees", "comments": "6 pages, 4 figures, 4 tables; International Journal of Computer\n  Applications Volume 49, Number 21, July 2012", "journal-ref": null, "doi": "10.5120/7896-1235", "report-no": null, "categories": "cs.SD cs.MM eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a voice morphing system for people suffering from\nLaryngectomy, which is the surgical removal of all or part of the larynx or the\nvoice box, particularly performed in cases of laryngeal cancer. A primitive\nmethod of achieving voice morphing is by extracting the source's vocal\ncoefficients and then converting them into the target speaker's vocal\nparameters. In this paper, we deploy Gaussian Mixture Models (GMM) for mapping\nthe coefficients from source to destination. However, the use of the\ntraditional/conventional GMM-based mapping approach results in the problem of\nover-smoothening of the converted voice. Thus, we hereby propose a unique\nmethod to perform efficient voice morphing and conversion based on GMM,which\novercomes the traditional-method effects of over-smoothening. It uses a\ntechnique of glottal waveform separation and prediction of excitations and\nhence the result shows that not only over-smoothening is eliminated but also\nthe transformed vocal tract parameters match with the target. Moreover, the\nsynthesized speech thus obtained is found to be of a sufficiently high quality.\nThus, voice morphing based on a unique GMM approach has been proposed and also\ncritically evaluated based on various subjective and objective evaluation\nparameters. Further, an application of voice morphing for Laryngectomees which\ndeploys this unique approach has been recommended by this paper.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2012 13:33:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chadha", "Aman", ""], ["Savardekar", "Bharatraaj", ""], ["Padhya", "Jay", ""]]}, {"id": "1208.1880", "submitter": "Supreeth Rao", "authors": "Supreeth K. Rao (1), Arpitha Prasad B. (1), Anushree R. Shetty (1),\n  Chinmai (1), R. Bhakthavathsalam (2) and Rajeshwari Hegde (1) ((1) BMS\n  College of Engineering, Bangalore, India, (2) Indian Institute of Science,\n  Bangalore, India)", "title": "Stereo Acoustic Perception based on Real Time Video Acquisition for\n  Navigational Assistance", "comments": "12 pages, 8 figures, 1 table, SIPM-2012, pp. 97-108, 2012;\n  http://airccj.org/CSCP/vol2/csit2311.pdf", "journal-ref": null, "doi": "10.5121/csit.2012.2311", "report-no": null, "categories": "cs.CV cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A smart navigation system (an Electronic Travel Aid) based on an object\ndetection mechanism has been designed to detect the presence of obstacles that\nimmediately impede the path, by means of real time video processing. The\nalgorithm can be used for any general purpose navigational aid. This paper is\ndiscussed, keeping in mind the navigation of the visually impaired, and is not\nlimited to the same. A video camera feeds images of the surroundings to a Da-\nVinci Digital Media Processor, DM642, which works on the video, frame by frame.\nThe processor carries out image processing techniques whose result contains\ninformation about the object in terms of image pixels. The algorithm aims to\nselect the object which, among all others, poses maximum threat to the\nnavigation. A database containing a total of three sounds is constructed.\nHence, each image translates to a beep, where every beep informs the navigator\nof the obstacles directly in front of him. This paper implements an algorithm\nthat is more efficient as compared to its predecessors.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 11:46:10 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Rao", "Supreeth K.", ""], ["B.", "Arpitha Prasad", ""], ["Shetty", "Anushree R.", ""], ["Chinmai", "", ""], ["Bhakthavathsalam", "R.", ""], ["Hegde", "Rajeshwari", ""]]}, {"id": "1208.2547", "submitter": "Lexing Xie", "authors": "Yanxiang Wang, Hari Sundaram, Lexing Xie", "title": "Social Event Detection with Interaction Graph Modeling", "comments": "ACM Multimedia 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.MM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on detecting social, physical-world events from photos\nposted on social media sites. The problem is important: cheap media capture\ndevices have significantly increased the number of photos shared on these\nsites. The main contribution of this paper is to incorporate online social\ninteraction features in the detection of physical events. We believe that\nonline social interaction reflect important signals among the participants on\nthe \"social affinity\" of two photos, thereby helping event detection. We\ncompute social affinity via a random-walk on a social interaction graph to\ndetermine similarity between two photos on the graph. We train a support vector\nmachine classifier to combine the social affinity between photos and\nphoto-centric metadata including time, location, tags and description.\nIncremental clustering is then used to group photos to event clusters. We have\nvery good results on two large scale real-world datasets: Upcoming and\nMediaEval. We show an improvement between 0.06-0.10 in F1 on these datasets.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2012 11:20:05 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Wang", "Yanxiang", ""], ["Sundaram", "Hari", ""], ["Xie", "Lexing", ""]]}, {"id": "1208.3323", "submitter": "Pietro Murano Dr", "authors": "Pietro Murano, Tanvi Sethi", "title": "Anthropomorphic User Interface Feedback in a Sewing Context and\n  Affordances", "comments": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications,Vol. 2, No. 4, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the authors' research is to gain better insights into the\neffectiveness and user satisfaction of anthropomorphism at the user interface.\nTherefore, this paper presents a between users experiment and the results in\nthe context of anthropomorphism at the user interface and the giving of\ninstruction for learning sewing stitches. Two experimental conditions were\nused, where the information for learning sewing stitches was the same. However\nthe manner of presentation was varied. Therefore one condition was\nanthropomorphic and the other was non-anthropomorphic. Also the work is closely\nlinked with Hartson's theory of affordances applied to user interfaces. The\nresults suggest that facilitation of the affordances in an anthropomorphic user\ninterface lead to statistically significant results in terms of effectiveness\nand user satisfaction in the sewing context. Further some violation of the\naffordances leads to an interface being less usable in terms of effectiveness\nand user satisfaction.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2012 09:27:49 GMT"}], "update_date": "2012-08-17", "authors_parsed": [["Murano", "Pietro", ""], ["Sethi", "Tanvi", ""]]}, {"id": "1208.3718", "submitter": "Jian Zhang", "authors": "Jian Zhang, Ruiqin Xiong, Chen Zhao, Siwei Ma, and Debin Zhao", "title": "Exploiting Image Local And Nonlocal Consistency For Mixed\n  Gaussian-Impulse Noise Removal", "comments": "6 pages, 4 figures, 3 tables, to be published at IEEE Int. Conf. on\n  Multimedia & Expo (ICME) 2012", "journal-ref": null, "doi": "10.1109/ICME.2012.109", "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing image denoising algorithms can only deal with a single type of\nnoise, which violates the fact that the noisy observed images in practice are\noften suffered from more than one type of noise during the process of\nacquisition and transmission. In this paper, we propose a new variational\nalgorithm for mixed Gaussian-impulse noise removal by exploiting image local\nconsistency and nonlocal consistency simultaneously. Specifically, the local\nconsistency is measured by a hyper-Laplace prior, enforcing the local\nsmoothness of images, while the nonlocal consistency is measured by\nthree-dimensional sparsity of similar blocks, enforcing the nonlocal\nself-similarity of natural images. Moreover, a Split-Bregman based technique is\ndeveloped to solve the above optimization problem efficiently. Extensive\nexperiments for mixed Gaussian plus impulse noise show that significant\nperformance improvements over the current state-of-the-art schemes have been\nachieved, which substantiates the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2012 02:11:20 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Zhang", "Jian", ""], ["Xiong", "Ruiqin", ""], ["Zhao", "Chen", ""], ["Ma", "Siwei", ""], ["Zhao", "Debin", ""]]}, {"id": "1208.6335", "submitter": "Aman Chadha Mr.", "authors": "Aman Chadha, Sushmit Mallik and Ravdeep Johar", "title": "Comparative Study and Optimization of Feature-Extraction Techniques for\n  Content based Image Retrieval", "comments": "8 pages, 16 figures, 11 tables", "journal-ref": "International Journal of Computer Applications 52(20):35-42, 2012", "doi": "10.5120/8320-1959", "report-no": "Volume 52, Number 20, 2012", "categories": "cs.CV cs.AI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of a Content-Based Image Retrieval (CBIR) system, also known as Query\nby Image Content (QBIC), is to help users to retrieve relevant images based on\ntheir contents. CBIR technologies provide a method to find images in large\ndatabases by using unique descriptors from a trained image. The image\ndescriptors include texture, color, intensity and shape of the object inside an\nimage. Several feature-extraction techniques viz., Average RGB, Color Moments,\nCo-occurrence, Local Color Histogram, Global Color Histogram and Geometric\nMoment have been critically compared in this paper. However, individually these\ntechniques result in poor performance. So, combinations of these techniques\nhave also been evaluated and results for the most efficient combination of\ntechniques have been presented and optimized for each class of image query. We\nalso propose an improvement in image retrieval performance by introducing the\nidea of Query modification through image cropping. It enables the user to\nidentify a region of interest and modify the initial query to refine and\npersonalize the image retrieval results.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2012 23:50:06 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 01:34:05 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Chadha", "Aman", ""], ["Mallik", "Sushmit", ""], ["Johar", "Ravdeep", ""]]}, {"id": "1208.6389", "submitter": "Jalil Boukhobza", "authors": "Yahia Benmoussa (Lab-STICC), Jalil Boukhobza (Lab-STICC), Yassine\n  Hadjadj Aoul (INRIA - IRISA), Lo\\\"ic Lagadec (Lab-STICC), Djamel Benazzouz\n  (LMSS)", "title": "Behavioral Systel Level Power Consumption Modeling of Mobile Video\n  Streaming applications", "comments": "Colloque du GDR SoC SiP, Paris : France (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the use of mobile applications and terminals faces fundamental\nchallenges related to energy constraint. This is due to the limited battery\nlifetime as compared to the increasing hardware evolution. Video streaming is\none of the most energy consuming applications in a mobile system because of its\nintensive use of bandwidth, memory and processing power. In this work, we aim\nto propose a methodology for building and validating a high level global power\nconsumption model including a hardware and software elements. Our approach is\nbased on exploiting the interactions between power consumption sub-models of\nstandalone systems in the perspective to build more accurate global model. The\ninteractions are studied within the exclusive context of video streaming\napplications that are one of the most used mobile applications.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2012 06:31:01 GMT"}], "update_date": "2012-09-03", "authors_parsed": [["Benmoussa", "Yahia", "", "Lab-STICC"], ["Boukhobza", "Jalil", "", "Lab-STICC"], ["Aoul", "Yassine Hadjadj", "", "INRIA - IRISA"], ["Lagadec", "Lo\u00efc", "", "Lab-STICC"], ["Benazzouz", "Djamel", "", "LMSS"]]}]