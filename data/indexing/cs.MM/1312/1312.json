[{"id": "1312.3041", "submitter": "Fan Zhang Mr.", "authors": "Fan Zhang, Vincent K. N. Lau", "title": "Cross-Layer MIMO Transceiver Optimization for Multimedia Streaming in\n  Interference Networks", "comments": "16 pages, 12 figures, 1 table. This paper has been accepted by the\n  IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2013.2296878", "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider dynamic precoder/decorrelator optimization for\nmultimedia streaming in MIMO interference networks. We propose a truly\ncross-layer framework in the sense that the optimization objective is the\napplication level performance metrics for multimedia streaming, namely the\nplayback interruption and buffer overflow probabilities. The optimization\nvariables are the MIMO precoders/decorrelators at the transmitters and the\nreceivers, which are adaptive to both the instantaneous channel condition and\nthe playback queue length. The problem is a challenging multi-dimensional\nstochastic optimization problem and brute-force solution has exponential\ncomplexity. By exploiting the underlying timescale separation and special\nstructure in the problem, we derive a closed-form approximation of the value\nfunction based on continuous time perturbation. Using this approximation, we\npropose a low complexity dynamic MIMO precoder/decorrelator control algorithm\nby solving an equivalent weighted MMSE problem. We also establish the technical\nconditions for asymptotic optimality of the low complexity control algorithm.\nFinally, the proposed scheme is compared with various baselines through\nsimulations and it is shown that significant performance gain can be achieved.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 06:17:18 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Zhang", "Fan", ""], ["Lau", "Vincent K. N.", ""]]}, {"id": "1312.5050", "submitter": "Liang  Chen", "authors": "Liang Chen, Yipeng Zhou and Dah Ming Chiu", "title": "Fake View Analytics in Online Video Services", "comments": "25 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Online video-on-demand(VoD) services invariably maintain a view count for\neach video they serve, and it has become an important currency for various\nstakeholders, from viewers, to content owners, advertizers, and the online\nservice providers themselves. There is often significant financial incentive to\nuse a robot (or a botnet) to artificially create fake views. How can we detect\nthe fake views? Can we detect them (and stop them) using online algorithms as\nthey occur? What is the extent of fake views with current VoD service\nproviders? These are the questions we study in the paper. We develop some\nalgorithms and show that they are quite effective for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 06:41:12 GMT"}], "update_date": "2013-12-19", "authors_parsed": [["Chen", "Liang", ""], ["Zhou", "Yipeng", ""], ["Chiu", "Dah Ming", ""]]}, {"id": "1312.5457", "submitter": "Yonatan Vaizman", "authors": "Yonatan Vaizman, Brian McFee and Gert Lanckriet", "title": "Codebook based Audio Feature Representation for Music Information\n  Retrieval", "comments": "Journal paper. Submitted to IEEE transactions on Audio, Speech and\n  Language Processing. Submitted on Dec 18th, 2013", "journal-ref": null, "doi": "10.1109/TASLP.2014.2337842", "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital music has become prolific in the web in recent decades. Automated\nrecommendation systems are essential for users to discover music they love and\nfor artists to reach appropriate audience. When manual annotations and user\npreference data is lacking (e.g. for new artists) these systems must rely on\n\\emph{content based} methods. Besides powerful machine learning tools for\nclassification and retrieval, a key component for successful recommendation is\nthe \\emph{audio content representation}.\n  Good representations should capture informative musical patterns in the audio\nsignal of songs. These representations should be concise, to enable efficient\n(low storage, easy indexing, fast search) management of huge music\nrepositories, and should also be easy and fast to compute, to enable real-time\ninteraction with a user supplying new songs to the system.\n  Before designing new audio features, we explore the usage of traditional\nlocal features, while adding a stage of encoding with a pre-computed\n\\emph{codebook} and a stage of pooling to get compact vectorial\nrepresentations. We experiment with different encoding methods, namely\n\\emph{the LASSO}, \\emph{vector quantization (VQ)} and \\emph{cosine similarity\n(CS)}. We evaluate the representations' quality in two music information\nretrieval applications: query-by-tag and query-by-example. Our results show\nthat concise representations can be used for successful performance in both\napplications. We recommend using top-$\\tau$ VQ encoding, which consistently\nperforms well in both applications, and requires much less computation time\nthan the LASSO.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 09:40:03 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Vaizman", "Yonatan", ""], ["McFee", "Brian", ""], ["Lanckriet", "Gert", ""]]}, {"id": "1312.5547", "submitter": "Lassi A Liikkanen", "authors": "Lassi A Liikkanen", "title": "Three Metrics for Measuring User Engagement with Online Media and a\n  YouTube Case Study", "comments": "4 pages, 1 figure, 3 tables, 2 appendixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report discusses three metrics of user engagement with online\nmedia. They are Commenting frequency, Voting frequency, and Voting balance.\nThese relative figures can be derived from established, basic statistics\navailable for many services, prominently YouTube. The paper includes case a\nstudy of popular YouTube videos to illustrate the characteristics and\nusefulness of the measures. The study documents the range of observed values\nand their relationships. The empirical sample shows the three measures to be\nonly moderately correlated with the original statistics despite the common\nnumerators and denominators. The paper concludes by discussing future\napplications and the needs of the quantification of user interaction with new\nmedia services.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 13:45:11 GMT"}, {"version": "v2", "created": "Thu, 10 Apr 2014 12:18:57 GMT"}], "update_date": "2014-04-11", "authors_parsed": [["Liikkanen", "Lassi A", ""]]}, {"id": "1312.6090", "submitter": "Thomas Maugey", "authors": "Thomas Maugey, Antonio Ortega, and Pascal Frossard", "title": "Graph-based representation for multiview image coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new representation for multiview image sets. Our\napproach relies on graphs to describe geometry information in a compact and\ncontrollable way. The links of the graph connect pixels in different images and\ndescribe the proximity between pixels in the 3D space. These connections are\ndependent on the geometry of the scene and provide the right amount of\ninformation that is necessary for coding and reconstructing multiple views.\nThis multiview image representation is very compact and adapts the transmitted\ngeometry information as a function of the complexity of the prediction\nperformed at the decoder side. To achieve this, our GBR adapts the accuracy of\nthe geometry representation, in contrast with depth coding, which directly\ncompresses with losses the original geometry signal. We present the principles\nof this graph-based representation (GBR) and we build a complete prototype\ncoding scheme for multiview images. Experimental results demonstrate the\npotential of this new representation as compared to a depth-based approach. GBR\ncan achieve a gain of 2 dB in reconstructed quality over depth-based schemes\noperating at similar rates.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 19:55:33 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Maugey", "Thomas", ""], ["Ortega", "Antonio", ""], ["Frossard", "Pascal", ""]]}, {"id": "1312.6180", "submitter": "Weifeng Liu", "authors": "W. Liu, H. Liu, D.Tao, Y. Wang, K. Lu", "title": "Manifold regularized kernel logistic regression for web image annotation", "comments": "submitted to Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid advance of Internet technology and smart devices, users often\nneed to manage large amounts of multimedia information using smart devices,\nsuch as personal image and video accessing and browsing. These requirements\nheavily rely on the success of image (video) annotation, and thus large scale\nimage annotation through innovative machine learning methods has attracted\nintensive attention in recent years. One representative work is support vector\nmachine (SVM). Although it works well in binary classification, SVM has a\nnon-smooth loss function and can not naturally cover multi-class case. In this\npaper, we propose manifold regularized kernel logistic regression (KLR) for web\nimage annotation. Compared to SVM, KLR has the following advantages: (1) the\nKLR has a smooth loss function; (2) the KLR produces an explicit estimate of\nthe probability instead of class label; and (3) the KLR can naturally be\ngeneralized to the multi-class case. We carefully conduct experiments on MIR\nFLICKR dataset and demonstrate the effectiveness of manifold regularized kernel\nlogistic regression for image annotation.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 00:32:24 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Liu", "W.", ""], ["Liu", "H.", ""], ["Tao", "D.", ""], ["Wang", "Y.", ""], ["Lu", "K.", ""]]}, {"id": "1312.6497", "submitter": "Vania Estrela Dr.", "authors": "Vania V. Estrela and Alessandra M. Coelho", "title": "State-of-the Art Motion Estimation in the Context of 3D TV", "comments": null, "journal-ref": "Multimedia Networking and Coding. IGI Global, 2013. 148-173. Web.\n  23 Dec. 2013", "doi": "10.4018/978-1-4666-2660-7.ch006", "report-no": null, "categories": "cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Progress in image sensors and computation power has fueled studies to improve\nacquisition, processing, and analysis of 3D streams along with 3D\nscenes/objects reconstruction. The role of motion compensation/motion\nestimation (MCME) in 3D TV from end-to-end user is investigated in this\nchapter. Motion vectors (MVs) are closely related to the concept of\ndisparities, and they can help improving dynamic scene acquisition, content\ncreation, 2D to 3D conversion, compression coding, decompression/decoding,\nscene rendering, error concealment, virtual/augmented reality handling,\nintelligent content retrieval, and displaying. Although there are different 3D\nshape extraction methods, this chapter focuses mostly on shape-from-motion\n(SfM) techniques due to their relevance to 3D TV. SfM extraction can restore 3D\nshape information from a single camera data.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 09:43:09 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Estrela", "Vania V.", ""], ["Coelho", "Alessandra M.", ""]]}, {"id": "1312.6565", "submitter": "Feng Xia", "authors": "Feng Xia, Nana Yaw Asabere, Ahmedin Mohammed Ahmed, Jing Li, Xiangjie\n  Kong", "title": "Mobile Multimedia Recommendation in Smart Communities: A Survey", "comments": null, "journal-ref": "IEEE Access, vol.1, pp.606-624, 2013", "doi": null, "report-no": null, "categories": "cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rapid growth of internet broadband access and proliferation of\nmodern mobile devices, various types of multimedia (e.g. text, images, audios\nand videos) have become ubiquitously available anytime. Mobile device users\nusually store and use multimedia contents based on their personal interests and\npreferences. Mobile device challenges such as storage limitation have however\nintroduced the problem of mobile multimedia overload to users. In order to\ntackle this problem, researchers have developed various techniques that\nrecommend multimedia for mobile users. In this survey paper, we examine the\nimportance of mobile multimedia recommendation systems from the perspective of\nthree smart communities, namely, mobile social learning, mobile event guide and\ncontext-aware services. A cautious analysis of existing research reveals that\nthe implementation of proactive, sensor-based and hybrid recommender systems\ncan improve mobile multimedia recommendations. Nevertheless, there are still\nchallenges and open issues such as the incorporation of context and social\nproperties, which need to be tackled in order to generate accurate and\ntrustworthy mobile multimedia recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 15:01:35 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Xia", "Feng", ""], ["Asabere", "Nana Yaw", ""], ["Ahmed", "Ahmedin Mohammed", ""], ["Li", "Jing", ""], ["Kong", "Xiangjie", ""]]}, {"id": "1312.6782", "submitter": "Avinash Bhute", "authors": "Avinash N Bhute, B. B. Meshram", "title": "IVSS Integration of Color Feature Extraction Techniques for Intelligent\n  Video Search Systems", "comments": "5 pages, 9 figures. 2012 4th International Conference on Electronics\n  Computer Technology - ICECT 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As large amount of visual Information is available on web in form of images,\ngraphics, animations and videos, so it is important in internet era to have an\neffective video search system. As there are number of video search engine\n(blinkx, Videosurf, Google, YouTube, etc.) which search for relevant videos\nbased on user keyword or term, But very less commercial video search engine are\navailable which search videos based on visual image/clip/video. In this paper\nwe are recommending a system that will search for relevant video using color\nfeature of video in response of user Query.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2013 09:28:08 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Bhute", "Avinash N", ""], ["Meshram", "B. B.", ""]]}, {"id": "1312.7036", "submitter": "Qingbo Hu", "authors": "Qingbo Hu, Guan Wang, Philip S. Yu", "title": "Deriving Latent Social Impulses to Determine Longevous Videos", "comments": "Accepted by WWW '14 as a poster paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online video websites receive huge amount of videos daily from users all\naround the world. How to provide valuable recommendations to viewers is an\nimportant task for both video websites and related third parties, such as\nsearch engines. Previous work conducted numerous analysis on the view counts of\nvideos, which measure a video's value in terms of popularity. However, the\nlong-lasting value of an online video, namely longevity, is hidden behind the\nhistory that a video accumulates its \"popularity\" through time. Generally\nspeaking, a longevous video tends to constantly draw society's attention. With\nfocus on one of the leading video websites, Youtube, this paper proposes a\nscoring mechanism quantifying a video's longevity. Evaluating a video's\nlongevity can not only improve a video recommender system, but also help us to\ndiscover videos having greater advertising value, as well as adjust a video\nwebsite's strategy of storing videos to shorten its responding time. In order\nto accurately quantify longevity, we introduce the concept of latent social\nimpulses and how to use them measure a video's longevity. In order to derive\nlatent social impulses, we view the video website as a digital signal filter\nand formulate the task as a convex minimization problem. The proposed longevity\ncomputation is based on the derived social impulses. Unfortunately, the\nrequired information to derive social impulses are not always public, which\nmakes a third party unable to directly evaluate every video's longevity. To\nsolve this problem, we formulate a semi-supervised learning task by using part\nof videos having known longevity scores to predict the unknown longevity\nscores. We propose a Gaussian Random Markov model with Loopy Belief Propagation\nto solve this problem. The conducted experiments on Youtube demonstrate that\nthe proposed method significantly improves the prediction results comparing to\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2013 00:24:30 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Hu", "Qingbo", ""], ["Wang", "Guan", ""], ["Yu", "Philip S.", ""]]}, {"id": "1312.7442", "submitter": "Jamil Hamodi Mr.", "authors": "Jamil Hamodi, Khaled Salah, Ravindra Thool", "title": "Evaluating the Performance of IPTV over Fixed WiMAX", "comments": "9 Pages, 9 Figures. arXiv admin note: substantial text overlap with\n  other internet sources by other authors", "journal-ref": "International Journal of Computer Applications 84(6):35-43,\n  December 2013. Published by Foundation of Computer Science, New York, USA", "doi": "10.5120/14582-2812", "report-no": null, "categories": "cs.MM cs.NI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  IEEE specifies different modulation techniques for WiMAX; namely, BPSK, QPSK,\n16 QAM and 64 QAM. This paper studies the performance of Internet Protocol\nTelevision (IPTV) over Fixed WiMAX system considering different combinations of\ndigital modulation. The performance is studied taking into account a number of\nkey system parameters which include the variation in the video coding,\npath-loss, scheduling service classes different rated codes in FEC channel\ncoding. The performance study was conducted using OPNET simulation. The\nperformance is studied in terms of packet lost, packet jitter delay, end-to-end\ndelay, and network throughput. Simulation results show that higher order\nmodulation and coding schemes (namely, 16 QAM and 64 QAM) yield better\nperformance than that of QPSK.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2013 15:19:09 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Hamodi", "Jamil", ""], ["Salah", "Khaled", ""], ["Thool", "Ravindra", ""]]}]