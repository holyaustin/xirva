[{"id": "1305.0020", "submitter": "Firas Ajil Jassim", "authors": "Firas A. Jassim", "title": "Image Compression By Embedding Five Modulus Method Into JPEG", "comments": "9 pages, 6 tables, 6 figures", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.4, No.2, April 2013", "doi": "10.5121/sipij.2013.4203", "report-no": null, "categories": "cs.CV cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The standard JPEG format is almost the optimum format in image compression.\nThe compression ratio in JPEG sometimes reaches 30:1. The compression ratio of\nJPEG could be increased by embedding the Five Modulus Method (FMM) into the\nJPEG algorithm. The novel algorithm gives twice the time as the standard JPEG\nalgorithm or more. The novel algorithm was called FJPEG (Five-JPEG). The\nquality of the reconstructed image after compression is approximately\napproaches the JPEG. Standard test images have been used to support and\nimplement the suggested idea in this paper and the error metrics have been\ncomputed and compared with JPEG.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 20:28:37 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Jassim", "Firas A.", ""]]}, {"id": "1305.0218", "submitter": "Alon Schclar", "authors": "Dina Dushnik and Alon Schclar and Amir Averbuch", "title": "Video Segmentation via Diffusion Bases", "comments": "29 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying moving objects in a video sequence, which is produced by a static\ncamera, is a fundamental and critical task in many computer-vision\napplications. A common approach performs background subtraction, which\nidentifies moving objects as the portion of a video frame that differs\nsignificantly from a background model. A good background subtraction algorithm\nhas to be robust to changes in the illumination and it should avoid detecting\nnon-stationary background objects such as moving leaves, rain, snow, and\nshadows. In addition, the internal background model should quickly respond to\nchanges in background such as objects that start to move or stop. We present a\nnew algorithm for video segmentation that processes the input video sequence as\na 3D matrix where the third axis is the time domain. Our approach identifies\nthe background by reducing the input dimension using the \\emph{diffusion bases}\nmethodology. Furthermore, we describe an iterative method for extracting and\ndeleting the background. The algorithm has two versions and thus covers the\ncomplete range of backgrounds: one for scenes with static backgrounds and the\nother for scenes with dynamic (moving) backgrounds.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2013 16:22:55 GMT"}], "update_date": "2013-05-02", "authors_parsed": [["Dushnik", "Dina", ""], ["Schclar", "Alon", ""], ["Averbuch", "Amir", ""]]}, {"id": "1305.0870", "submitter": "Sameer Pawar", "authors": "Sameer Pawar and Kannan Ramchandran", "title": "Computing a k-sparse n-length Discrete Fourier Transform using at most\n  4k samples and O(k log k) complexity", "comments": "36 pages, 15 figures. To be presented at ISIT-2013, Istanbul Turkey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an $n$-length input signal $\\mbf{x}$, it is well known that its\nDiscrete Fourier Transform (DFT), $\\mbf{X}$, can be computed in $O(n \\log n)$\ncomplexity using a Fast Fourier Transform (FFT). If the spectrum $\\mbf{X}$ is\nexactly $k$-sparse (where $k<<n$), can we do better? We show that\nasymptotically in $k$ and $n$, when $k$ is sub-linear in $n$ (precisely, $k\n\\propto n^{\\delta}$ where $0 < \\delta <1$), and the support of the non-zero DFT\ncoefficients is uniformly random, we can exploit this sparsity in two\nfundamental ways (i) {\\bf {sample complexity}}: we need only $M=rk$\ndeterministically chosen samples of the input signal $\\mbf{x}$ (where $r < 4$\nwhen $0 < \\delta < 0.99$); and (ii) {\\bf {computational complexity}}: we can\nreliably compute the DFT $\\mbf{X}$ using $O(k \\log k)$ operations, where the\nconstants in the big Oh are small and are related to the constants involved in\ncomputing a small number of DFTs of length approximately equal to the sparsity\nparameter $k$. Our algorithm succeeds with high probability, with the\nprobability of failure vanishing to zero asymptotically in the number of\nsamples acquired, $M$.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2013 02:54:59 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2015 06:41:20 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Pawar", "Sameer", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1305.1887", "submitter": "Gaurav Pande", "authors": "Gaurav Pande", "title": "Performance Evaluation of Video Communications over 4G Network", "comments": "Accepted in ICACNI 2013. arXiv admin note: substantial text overlap\n  with arXiv:1304.3758", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With exponential increase in the volumes of video traffic in cellular\nnet-works, there is an increasing need for optimizing the quality of video\ndelivery. 4G networks (Long Term Evolution Advanced or LTE A) are being\nintroduced in many countries worldwide, which allow a downlink speed of upto 1\nGbps and uplink of 100 Mbps over a single base station. In this paper, we\ncharacterize the performance of LTE A physical layer in terms of transmitted\nvideo quality when the channel condi-tions and LTE settings are varied. We test\nthe performance achieved as the channel quality is changed and HARQ features\nare enabled in physical layer. Blocking and blurring metrics were used to model\nimage quality.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2013 17:19:50 GMT"}], "update_date": "2013-05-09", "authors_parsed": [["Pande", "Gaurav", ""]]}, {"id": "1305.1986", "submitter": "Madhur Srivastava", "authors": "Madhur Srivastava, Satish K. Singh, and Prasanta K. Panigrahi", "title": "An Adaptive Statistical Non-uniform Quantizer for Detail Wavelet\n  Components in Lossy JPEG2000 Image Compression", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a non-uniform quantization method for the Detail\ncomponents in the JPEG2000 standard. Incorporating the fact that the\ncoefficients lying towards the ends of the histogram plot of each Detail\ncomponent represent the structural information of an image, the quantization\nstep sizes become smaller at they approach the ends of the histogram plot. The\nvariable quantization step sizes are determined by the actual statistics of the\nwavelet coefficients. Mean and standard deviation are the two statistical\nparameters used iteratively to obtain the variable step sizes. Moreover, the\nmean of the coefficients lying within the step size is chosen as the quantized\nvalue, contrary to the deadzone uniform quantizer which selects the midpoint of\nthe quantization step size as the quantized value. The experimental results of\nthe deadzone uniform quantizer and the proposed non-uniform quantizer are\nobjectively compared by using Mean-Squared Error (MSE) and Mean Structural\nSimilarity Index Measure (MSSIM), to evaluate the quantization error and\nreconstructed image quality, respectively. Subjective analysis of the\nreconstructed images is also carried out. Through the objective and subjective\nassessments, it is shown that the non-uniform quantizer performs better than\nthe deadzone uniform quantizer in the perceptual quality of the reconstructed\nimage, especially at low bitrates. More importantly, unlike the deadzone\nuniform quantizer, the non-uniform quantizer accomplishes better visual quality\nwith a few quantized values.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2013 01:10:11 GMT"}, {"version": "v2", "created": "Sat, 12 Jul 2014 22:22:29 GMT"}, {"version": "v3", "created": "Thu, 14 Aug 2014 20:30:55 GMT"}], "update_date": "2014-08-18", "authors_parsed": [["Srivastava", "Madhur", ""], ["Singh", "Satish K.", ""], ["Panigrahi", "Prasanta K.", ""]]}, {"id": "1305.2251", "submitter": "Madhur Srivastava", "authors": "Madhur Srivastava, Subhayan R. Moulick and Prasanta K. Panigrahi", "title": "Quantum Image Representation Through Two-Dimensional Quantum States and\n  Normalized Amplitude", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method for image representation in quantum computers,\nwhich uses the two-dimensional (2-D) quantum states to locate each pixel in an\nimage through row-location and column-location vectors for identifying each\npixel location. The quantum state of an image is the linear superposition of\nthe tensor product of the m-qubits row-location vector and the n-qubits\ncolumn-location vector of each pixel. It enables the natural quantum\nrepresentation of rectangular images that other methods lack. The\namplitude/intensity of each pixel is incorporated into the coefficient values\nof the pixel's quantum state, without using any qubits. Due to the fact that\nlinear superposition, tensor product and qubits form the fundamental basis of\nquantum computing, the proposed method presents the machine level\nrepresentation of images on quantum computers. Unlike other methods, this\nmethod is a pure quantum representation without any classical components.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2013 02:53:07 GMT"}, {"version": "v2", "created": "Thu, 14 Aug 2014 20:31:38 GMT"}, {"version": "v3", "created": "Tue, 19 May 2015 19:58:50 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2015 10:29:44 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Srivastava", "Madhur", ""], ["Moulick", "Subhayan R.", ""], ["Panigrahi", "Prasanta K.", ""]]}, {"id": "1305.3021", "submitter": "Ijaz Bukhari ijaz bukhari", "authors": "Ijaz Bukhari, Nuhman-ul-Haq and Khizar Hyat", "title": "Wave Atom Based Watermarking", "comments": "I want to withdraw the paper due to serious error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Watermarking helps in ensuring originality, ownership and copyrights of a\ndigital image. This paper aims at embedding a Watermark in an image using Wave\nAtom Transform. Preference of Wave Atoms on other transformations has been due\nto its sparser expansion, adaptability to the direction of local pattern, and\nsharp frequency localization. In this scheme, we had tried to spread the\nwatermark in an image so that the information at one place is very small and\nundetectable. In order to extract the watermark and verify ownership of an\nimage, one would have the advantage of prior knowledge of embedded locations. A\nnoise of high amplitude will be needed to be added to the image for watermark\ndistortion. Furthermore, the information spread will ensure the robustness of\nthe watermark data. The proposed scheme has the ability to withstand malicious\noperations and attacks.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2013 05:27:52 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2015 13:06:09 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Bukhari", "Ijaz", ""], ["Nuhman-ul-Haq", "", ""], ["Hyat", "Khizar", ""]]}, {"id": "1305.3586", "submitter": "Dilip Bethanabhotla", "authors": "Dilip Bethanabhotla, Giuseppe Caire and Michael J. Neely", "title": "Utility Optimal Scheduling and Admission Control for Adaptive Video\n  Streaming in Small Cell Networks", "comments": "5 pages, 4 figures. Accepted and will be presented at IEEE\n  International Symposium on Information Theory (ISIT) 2013", "journal-ref": null, "doi": "10.1109/ISIT.2013.6620565", "report-no": null, "categories": "cs.IT cs.MM cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the jointly optimal design of a transmission scheduling and\nadmission control policy for adaptive video streaming over small cell networks.\nWe formulate the problem as a dynamic network utility maximization and observe\nthat it naturally decomposes into two subproblems: admission control and\ntransmission scheduling. The resulting algorithms are simple and suitable for\ndistributed implementation. The admission control decisions involve each user\nchoosing the quality of the video chunk asked for download, based on the\nnetwork congestion in its neighborhood. This form of admission control is\ncompatible with the current video streaming technology based on the DASH\nprotocol over TCP connections. Through simulations, we evaluate the performance\nof the proposed algorithm under realistic assumptions for a small-cell network.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2013 18:56:03 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Bethanabhotla", "Dilip", ""], ["Caire", "Giuseppe", ""], ["Neely", "Michael J.", ""]]}, {"id": "1305.3971", "submitter": "Mingli Song", "authors": "Chengxi Ye, Dacheng Tao, Mingli Song, David W. Jacobs, Min Wu", "title": "Sparse Norm Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization-based filtering smoothes an image by minimizing a fidelity\nfunction and simultaneously preserves edges by exploiting a sparse norm penalty\nover gradients. It has obtained promising performance in practical problems,\nsuch as detail manipulation, HDR compression and deblurring, and thus has\nreceived increasing attentions in fields of graphics, computer vision and image\nprocessing. This paper derives a new type of image filter called sparse norm\nfilter (SNF) from optimization-based filtering. SNF has a very simple form,\nintroduces a general class of filtering techniques, and explains several\nclassic filters as special implementations of SNF, e.g. the averaging filter\nand the median filter. It has advantages of being halo free, easy to implement,\nand low time and memory costs (comparable to those of the bilateral filter).\nThus, it is more generic than a smoothing operator and can better adapt to\ndifferent tasks. We validate the proposed SNF by a wide variety of applications\nincluding edge-preserving smoothing, outlier tolerant filtering, detail\nmanipulation, HDR compression, non-blind deconvolution, image segmentation, and\ncolorization.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2013 03:13:28 GMT"}], "update_date": "2013-05-20", "authors_parsed": [["Ye", "Chengxi", ""], ["Tao", "Dacheng", ""], ["Song", "Mingli", ""], ["Jacobs", "David W.", ""], ["Wu", "Min", ""]]}, {"id": "1305.4102", "submitter": "Wayne Goodridge Dr.", "authors": "Andrew Rudder, Wayne Goodridge and Shareeda Mohammed", "title": "Using Bias Optimization for Reversible Data Hiding Using Image\n  Interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we propose a reversible data hiding method in the spatial\ndomain for compressed grayscale images. The proposed method embeds secret bits\ninto a compressed thumbnail of the original image by using a novel\ninterpolation method and the Neighbour Mean Interpolation (NMI) technique as\nscaling up to the original image occurs. Experimental results presented in this\npaper show that the proposed method has significantly improved embedding\ncapacities over the approach proposed by Jung and Yoo.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2013 14:30:46 GMT"}], "update_date": "2013-05-20", "authors_parsed": [["Rudder", "Andrew", ""], ["Goodridge", "Wayne", ""], ["Mohammed", "Shareeda", ""]]}, {"id": "1305.4999", "submitter": "Saied Mehdian", "authors": "Saied Mehdian, Ben Liang", "title": "Optimal Frame Transmission for Scalable Video with Hierarchical\n  Prediction Structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optimal frame transmission scheme is presented for streaming scalable\nvideo over a link with limited capacity. The objective is to select a\ntransmission sequence of frames and their transmission schedule such that the\noverall video quality is maximized. The problem is solved for two general\nclasses of hierarchical prediction structures, which include as a special case\nthe popular dyadic structure. Based on a new characterization of the\ninterdependence among frames in terms of trees, structural properties of an\noptimal transmission schedule are derived. These properties lead to the\ndevelopment of a jointly optimal frame selection and scheduling algorithm,\nwhich has computational complexity that is quadratic in the number of frames.\nSimulation results show that the optimal scheme substantially outperforms three\nexisting alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2013 01:25:02 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2013 10:24:01 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Mehdian", "Saied", ""], ["Liang", "Ben", ""]]}, {"id": "1305.5216", "submitter": "Mingyue Ji", "authors": "Mingyue Ji, Giuseppe Caire, and Andreas F. Molisch", "title": "Wireless Device-to-Device Caching Networks: Basic Principles and System\n  Performance", "comments": "35 pages; 13 figures; Revised version of the manuscript submitted to\n  IEEE Journal on Selected Areas in Communications, Special Issue on Device to\n  Device Communications in Cellular Networks", "journal-ref": null, "doi": "10.1109/JSAC.2015.2452672", "report-no": null, "categories": "cs.IT cs.MM cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As wireless video transmission is the fastest-growing form of data traffic,\nmethods for spectrally efficient video on-demand wireless streaming are\nessential to service providers and users alike. A key property of video\non-demand is the asynchronous content reuse, such that a few dominant videos\naccount for a large part of the traffic, but are viewed by users at different\ntimes. Caching of content on devices in conjunction with D2D communications\nallows to exploit this property, and provide a network throughput that is\nsignificantly in excess of both the conventional approach of unicasting from\nthe base station and the traditional D2D networks for regular data traffic.\nThis paper presents in a semi-tutorial concise form some recent results on the\nthroughput scaling laws of wireless networks with caching and asynchronous\ncontent reuse, contrasting the D2D approach with a competing approach based on\ncombinatorial cache design and network coded transmission from the base station\n(BS) only, referred to as coded multicasting. Interestingly, the spatial reuse\ngain of the former and the coded multicasting gain of the latter yield, somehow\nsurprisingly, the same near-optimal throughput behavior in the relevant regime\nwhere the number of video files in the library is smaller than the number of\nstreaming users. Based on our recent theoretical results, we propose a holistic\nD2D system design that incorporates traditional microwave (2 GHz) as well as\nmillimeter-wave D2D links; the direct connections to the base station can be\nused to provide those rare video requests that cannot be found in local caches.\nWe provide extensive simulations under a variety of system settings, and\ncompare our scheme with other existing schemes by the BS. We show that, despite\nthe similar behavior of the scaling laws, the proposed D2D approach offers very\nsignificant throughput gains with respect to the BS-only schemes.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2013 18:03:46 GMT"}, {"version": "v2", "created": "Thu, 24 Apr 2014 23:43:27 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Ji", "Mingyue", ""], ["Caire", "Giuseppe", ""], ["Molisch", "Andreas F.", ""]]}, {"id": "1305.5464", "submitter": "Bruno Macchiavello", "authors": "Bruno Macchiavello, Camilo Dorea, Edson M. Hung, Gene Cheung and\n  Wai-tian Tan", "title": "Loss-resilient Coding of Texture and Depth for Free-viewpoint Video\n  Conferencing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Free-viewpoint video conferencing allows a participant to observe the remote\n3D scene from any freely chosen viewpoint. An intermediate virtual viewpoint\nimage is commonly synthesized using two pairs of transmitted texture and depth\nmaps from two neighboring captured viewpoints via depth-image-based rendering\n(DIBR). To maintain high quality of synthesized images, it is imperative to\ncontain the adverse effects of network packet losses that may arise during\ntexture and depth video transmission. Towards this end, we develop an\nintegrated approach that exploits the representation redundancy inherent in the\nmultiple streamed videos a voxel in the 3D scene visible to two captured views\nis sampled and coded twice in the two views. In particular, at the receiver we\nfirst develop an error concealment strategy that adaptively blends\ncorresponding pixels in the two captured views during DIBR, so that pixels from\nthe more reliable transmitted view are weighted more heavily. We then couple it\nwith a sender-side optimization of reference picture selection (RPS) during\nreal-time video coding, so that blocks containing samples of voxels that are\nvisible in both views are more error-resiliently coded in one view only, given\nadaptive blending will erase errors in the other view. Further, synthesized\nview distortion sensitivities to texture versus depth errors are analyzed, so\nthat relative importance of texture and depth code blocks can be computed for\nsystem-wide RPS optimization. Experimental results show that the proposed\nscheme can outperform the use of a traditional feedback channel by up to 0.82\ndB on average at 8% packet loss rate, and by as much as 3 dB for particular\nframes.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2013 18:06:04 GMT"}], "update_date": "2013-05-24", "authors_parsed": [["Macchiavello", "Bruno", ""], ["Dorea", "Camilo", ""], ["Hung", "Edson M.", ""], ["Cheung", "Gene", ""], ["Tan", "Wai-tian", ""]]}, {"id": "1305.5486", "submitter": "John Scoville", "authors": "John Scoville", "title": "Fast Autocorrelated Context Models for Data Compression", "comments": "v2 includes bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is presented to automatically generate context models of data by\ncalculating the data's autocorrelation function. The largest values of the\nautocorrelation function occur at the offsets or lags in the bitstream which\ntend to be the most highly correlated to any particular location. These offsets\nare ideal for use in predictive coding, such as predictive partial match (PPM)\nor context-mixing algorithms for data compression, making such algorithms more\nefficient and more general by reducing or eliminating the need for ad-hoc\nmodels based on particular types of data. Instead of using the definition of\nthe autocorrelation function, which considers the pairwise correlations of data\nrequiring O(n^2) time, the Weiner-Khinchin theorem is applied, quickly\nobtaining the autocorrelation as the inverse Fast Fourier transform of the\ndata's power spectrum in O(n log n) time, making the technique practical for\nthe compression of large data objects. The method is shown to produce the\nhighest levels of performance obtained to date on a lossless image compression\nbenchmark.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2013 17:11:39 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2013 06:24:43 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Scoville", "John", ""]]}, {"id": "1305.6216", "submitter": "Vikram Chandrasetty", "authors": "Vikram Arkalgud Chandrasetty and Syed Mahfuzul Aziz", "title": "Resource Efficient LDPC Decoders for Multimedia Communication", "comments": "10 pages, 12 figures, 4 tables, submitted to Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving high image quality is an important aspect in an increasing number\nof wireless multimedia applications. These applications require resource\nefficient error correction hardware to detect and correct errors introduced by\nthe communication channel. This paper presents an innovative flexible\narchitecture for error correction using Low-Density Parity-Check (LDPC) codes.\nThe proposed partially-parallel decoder architecture utilizes a novel code\nconstruction technique based on multi-level Hierarchical Quasi-Cyclic (HQC)\nmatrix with innovative layering of random sub-matrices. Simulation of a\nhigh-level MATLAB model shows that the proposed HQC matrices have bit error\nrate (BER) performance close to that of unstructured random matrices. The\nproposed decoder has been implemented on FPGA. It is very resource efficient\nand provides very high throughput compared to other decoders reported to date.\nPerformance evaluation of the decoder has been carried out by transmitting JPEG\nimages over an AWGN channel and comparing the quality of the reconstructed\nimages with those from other decoders.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2013 13:38:22 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2013 10:51:20 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Chandrasetty", "Vikram Arkalgud", ""], ["Aziz", "Syed Mahfuzul", ""]]}, {"id": "1305.6332", "submitter": "Kristin Erickson", "authors": "Kristin Grace Erickson", "title": "The Story of Telebrain: A multi-performer telematic platform for\n  performatization", "comments": "AISB symposium on Music and Unconventional Computing, conference\n  proceedings 2013, Exeter, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.ET cs.MM cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Telebrain, a browser-based performatization platform\ninvented for organizing real-time telematic performances. Performatization is\nthe human performance of algorithms. When computers and humans performatize\ncooperatively, the human-computer interaction (HCI) becomes the location of\ncomputation. Novel modes of machine-human communication are necessary for\norganizing performatizations. Telebrain is designed to facilitate machine-human\nlanguages. Capitalizing on the ubiquity and cross-platform compatibility of the\nInternet, Telebrain is an open-source web application supporting PerPL\n(Performer Programming Language), a human-interpreted configurable language of\nmulti-media instructions used to program performers. Telebrain facilitates a\nvariety of performance disciplines such as music, theater, dance, computational\nperformance, networked scoring (image and audio), prompted improvisation,\nreal-space multi-player gaming, collaborative transdisciplinary karaoke and\nquantum square-dancing. (http://telebrain.org)\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2013 21:28:04 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Erickson", "Kristin Grace", ""]]}]