[{"id": "1201.0598", "submitter": "Thomas Maugey", "authors": "Thomas Maugey and Pascal Frossard", "title": "Interactive multiview video system with non-complex navigation at the\n  decoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiview video with interactive and smooth view switching at the receiver is\na challenging application with several issues in terms of effective use of\nstorage and bandwidth resources, reactivity of the system, quality of the\nviewing experience and system complexity. The classical decoding system for\ngenerating virtual views first projects a reference or encoded frame to a given\nviewpoint and then fills in the holes due to potential occlusions. This last\nstep still constitutes a complex operation with specific software or hardware\nat the receiver and requires a certain quantity of information from the\nneighboring frames for insuring consistency between the virtual images. In this\nwork we propose a new approach that shifts most of the burden due to\ninteractivity from the decoder to the encoder, by anticipating the navigation\nof the decoder and sending auxiliary information that guarantees temporal and\ninterview consistency. This leads to an additional cost in terms of\ntransmission rate and storage, which we minimize by using optimization\ntechniques based on the user behavior modeling. We show by experiments that the\nproposed system represents a valid solution for interactive multiview systems\nwith classical decoders.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jan 2012 09:19:58 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Maugey", "Thomas", ""], ["Frossard", "Pascal", ""]]}, {"id": "1201.1383", "submitter": "Muhammad Fahad Khan", "authors": "Muhammad Fahad Khan and Saira Beg", "title": "Stereo image Transference & Retrieval over SMS", "comments": "3 pages,3 figuers,Journal", "journal-ref": "JOURNAL OF COMPUTING, VOLUME 3, ISSUE 7, JULY 2011, ISSN 2151-9617\n  WWW.JOURNALOFCOMPUTING.ORG", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Paper presents the way of transferring stereo images using SMS over GSM\nnetwork. Generally, Stereo image is composed of two stereoscopic images in such\nway that gives three dimensional affect when viewed. GSM have two short\nmessaging services, which can transfer images and sounds etc. Such services are\nknown as; MMS (Multimedia Messaging Service) and EMS (Extended Messaging\nService). EMS can send Predefined sounds, animation and images but have\nlimitation that it does not support widely. MMS can send much higher contents\nthan EMS but need 3G and other network capability in order to send large size\ndata up to 1000 bytes. Other limitations are Portability, content adaption etc.\nOur major aim in this paper is to provide an alternative way of sending stereo\nimages over SMS which is widely supported than EMS. We develop an application\nusing J2ME Platform.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2012 10:10:54 GMT"}], "update_date": "2012-01-09", "authors_parsed": [["Khan", "Muhammad Fahad", ""], ["Beg", "Saira", ""]]}, {"id": "1201.1668", "submitter": "Reza Keyvan", "authors": "Ashraf Sadat Jabari, Mohammadreza Keyvanpour", "title": "Identifying and Analysis of Scene Mining Methods Beased on Scenes\n  Extracted Features", "comments": null, "journal-ref": "International Journal of Engineering Science and Technology, Vol.\n  3 No. 9 September 2011, 7211-7217", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene mining is a subset of image mining in which scenes are classified to a\ndistinct set of classes based on analysis of their content. In other word in\nscene mining, a label is given to visual content of scene, for example,\nmountain, beach. Scene mining is used in applications such as medicine, movie,\ninformation retrieval, computer vision, recognition of traffic scene. Reviewing\nof represented methods shows there are various methods in scene mining. Scene\nmining applications extension and existence of various scenes, make comparison\nof methods hard. Scene mining can be followed by identifying scene mining\ncomponents and representing a framework to analyzing and evaluating methods. In\nthis paper, at first, components of scene mining are introduced, then a\nframework based on extracted features of scene is represented to classify scene\nmining methods. Finally, these methods are analyzed and evaluated via a\nproposal framework.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2012 23:45:27 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Jabari", "Ashraf Sadat", ""], ["Keyvanpour", "Mohammadreza", ""]]}, {"id": "1201.3018", "submitter": "Yiannis Andreopoulos", "authors": "Mohammad Ashraful Anam and Yiannis Andreopoulos", "title": "Throughput Scaling Of Convolution For Error-Tolerant Multimedia\n  Applications", "comments": "IEEE Trans. on Multimedia, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution and cross-correlation are the basis of filtering and pattern or\ntemplate matching in multimedia signal processing. We propose two throughput\nscaling options for any one-dimensional convolution kernel in programmable\nprocessors by adjusting the imprecision (distortion) of computation. Our\napproach is based on scalar quantization, followed by two forms of tight\npacking in floating-point (one of which is proposed in this paper) that allow\nfor concurrent calculation of multiple results. We illustrate how our approach\ncan operate as an optional pre- and post-processing layer for off-the-shelf\noptimized convolution routines. This is useful for multimedia applications that\nare tolerant to processing imprecision and for cases where the input signals\nare inherently noisy (error tolerant multimedia applications). Indicative\nexperimental results with a digital music matching system and an MPEG-7 audio\ndescriptor system demonstrate that the proposed approach offers up to 175%\nincrease in processing throughput against optimized (full-precision)\nconvolution with virtually no effect in the accuracy of the results. Based on\nmarginal statistics of the input data, it is also shown how the throughput and\ndistortion can be adjusted per input block of samples under constraints on the\nsignal-to-noise ratio against the full-precision convolution.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jan 2012 14:22:54 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Anam", "Mohammad Ashraful", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1201.3337", "submitter": "Reza Keyvan", "authors": "Fatemeh Alamdar, MohammadReza Keyvanpour", "title": "A New Color Feature Extraction Method Based on Dynamic Color\n  Distribution Entropy of Neighborhoods", "comments": null, "journal-ref": "International Journal of Computer Science Issues, Vol. 8, Issue 5,\n  No 1 (2011) 42-48", "doi": null, "report-no": null, "categories": "cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the important requirements in image retrieval, indexing,\nclassification, clustering and etc. is extracting efficient features from\nimages. The color feature is one of the most widely used visual features. Use\nof color histogram is the most common way for representing color feature. One\nof disadvantage of the color histogram is that it does not take the color\nspatial distribution into consideration. In this paper dynamic color\ndistribution entropy of neighborhoods method based on color distribution\nentropy is presented, which effectively describes the spatial information of\ncolors. The image retrieval results in compare to improved color distribution\nentropy show the acceptable efficiency of this approach.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jan 2012 23:36:19 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Alamdar", "Fatemeh", ""], ["Keyvanpour", "MohammadReza", ""]]}, {"id": "1201.5285", "submitter": "Ghalia Merzougui Mrs", "authors": "G. Merzougui and M. Djoudi", "title": "An Authoring System for Editing Lessons in Phonetic English in SMIL3.0", "comments": "6 pages, 6 figures and 2 codes", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 8,\n  Issue 6, No 3, November 2011", "doi": null, "report-no": null, "categories": "cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the difficulties of teaching English is the prosody, including the\nstress. French learners have difficulties to encode this information about the\nword because it is irrelevant for them. Therefore, they have difficulty to\nproduce this stress when they speak that language. Studies in this area have\nconcluded that the dual-coding approach (auditory and visual) of a phonetic\nphenomenon helps a lot to improve its perception and memorization for novice\nlearners. The aim of our work is to provide English teachers with an authoring\nnamed SaCoPh for editing multimedia courses that support this approach. This\ncourse is based on a template that fits the educational aspects of phonetics,\nexploiting the features of version 3.0 of the standard SMIL (Synchronized\nMultimedia Integration Language) for the publication of this course on the web.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jan 2012 14:39:39 GMT"}], "update_date": "2012-01-26", "authors_parsed": [["Merzougui", "G.", ""], ["Djoudi", "M.", ""]]}, {"id": "1201.6218", "submitter": "Wojciech Mazurczyk", "authors": "Artur Janicki, Wojciech Mazurczyk and Krzysztof Szczypiorski", "title": "Influence of Speech Codecs Selection on Transcoding Steganography", "comments": "17 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The typical approach to steganography is to compress the covert data in order\nto limit its size, which is reasonable in the context of a limited\nsteganographic bandwidth. TranSteg (Trancoding Steganography) is a new IP\ntelephony steganographic method that was recently proposed that offers high\nsteganographic bandwidth while retaining good voice quality. In TranSteg,\ncompression of the overt data is used to make space for the steganogram. In\nthis paper we focus on analyzing the influence of the selection of speech\ncodecs on hidden transmission performance, that is, which codecs would be the\nmost advantageous ones for TranSteg. Therefore, by considering the codecs which\nare currently most popular for IP telephony we aim to find out which codecs\nshould be chosen for transcoding to minimize the negative influence on voice\nquality while maximizing the obtained steganographic bandwidth.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jan 2012 14:16:35 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Janicki", "Artur", ""], ["Mazurczyk", "Wojciech", ""], ["Szczypiorski", "Krzysztof", ""]]}]