[{"id": "1410.1087", "submitter": "Aske Plaat", "authors": "Christine P.D.M. van der Aa, Monique M.H. Pollmann, Aske Plaat, Rutger\n  Jan van der Gaag", "title": "Computer-mediated communication in adults with high-functioning Autism\n  Spectrum Conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been suggested that people with Autism Spectrum Conditions (ASC) are\nattracted to computer-mediated communication (CMC). In this study, several open\nquestions regarding CMC use in people with ASC which are investigated. We\ncompare CMC use in adults with high-functioning ASC (N = 113) and a control\ngroup (N = 72). We find that people with ASC (1) spend more time on CMC than\ncontrols, (2) are more positive about CMC, (3) report relatively high levels of\nonline social life satisfaction, and that (4) CMC use is negatively related to\nsatisfaction with life for people with ASC. Our results indicate that the ASC\nsubjects in this study use CMC at least as enthusiastically as controls, and\nare proficient and successful in its use.\n", "versions": [{"version": "v1", "created": "Sat, 4 Oct 2014 20:09:20 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["van der Aa", "Christine P. D. M.", ""], ["Pollmann", "Monique M. H.", ""], ["Plaat", "Aske", ""], ["van der Gaag", "Rutger Jan", ""]]}, {"id": "1410.1490", "submitter": "Jeremiah Blocki", "authors": "Jeremiah Blocki and Saranga Komanduri and Lorrie Cranor and Anupam\n  Datta", "title": "Spaced Repetition and Mnemonics Enable Recall of Multiple Strong\n  Passwords", "comments": null, "journal-ref": null, "doi": "10.14722/ndss.2015.23094", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on a user study that provides evidence that spaced repetition and a\nspecific mnemonic technique enable users to successfully recall multiple strong\npasswords over time. Remote research participants were asked to memorize 4\nPerson-Action-Object (PAO) stories where they chose a famous person from a\ndrop-down list and were given machine-generated random action-object pairs.\nUsers were also shown a photo of a scene and asked to imagine the PAO story\ntaking place in the scene (e.g., Bill Gates---swallowing---bike on a beach).\nSubsequently, they were asked to recall the action-object pairs when prompted\nwith the associated scene-person pairs following a spaced repetition schedule\nover a period of 127+ days. While we evaluated several spaced repetition\nschedules, the best results were obtained when users initially returned after\n12 hours and then in $1.5\\times$ increasing intervals: 77% of the participants\nsuccessfully recalled all 4 stories in 10 tests over a period of 158 days. Much\nof the forgetting happened in the first test period (12 hours): 89% of\nparticipants who remembered their stories during the first test period\nsuccessfully remembered them in every subsequent round. These findings, coupled\nwith recent results on naturally rehearsing password schemes, suggest that 4\nPAO stories could be used to create usable and strong passwords for 14\nsensitive accounts following this spaced repetition schedule, possibly with a\nfew extra upfront rehearsals. In addition, we find that there is an\ninterference effect across multiple PAO stories: the recall rate of 100% (resp.\n90%) for participants who were asked to memorize 1 PAO story (resp. 2 PAO\nstories) is significantly better than the recall rate for participants who were\nasked to memorize 4 PAO stories. These findings yield concrete advice for\nimproving constructions of password management schemes and future user studies.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 18:55:48 GMT"}, {"version": "v2", "created": "Sat, 3 Jan 2015 06:23:55 GMT"}, {"version": "v3", "created": "Fri, 24 Jan 2020 00:14:35 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Blocki", "Jeremiah", ""], ["Komanduri", "Saranga", ""], ["Cranor", "Lorrie", ""], ["Datta", "Anupam", ""]]}, {"id": "1410.1648", "submitter": "Shengkai Zhang", "authors": "Shengkai Zhang and Pan Hui", "title": "A Survey on Mobile Affective Computing", "comments": "There will be another paper for this topic. This paper will be no\n  longer updated. Thanks for your attention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey presents recent progress on Affective Computing (AC) using mobile\ndevices. AC has been one of the most active research topics for decades. The\nprimary limitation of traditional AC research refers to as impermeable\nemotions. This criticism is prominent when emotions are investigated outside\nsocial contexts. It is problematic because some emotions are directed at other\npeople and arise from interactions with them. The development of smart mobile\nwearable devices (e.g., Apple Watch, Google Glass, iPhone, Fitbit) enables the\nwild and natural study for AC in the aspect of computer science. This survey\nemphasizes the AC study and system using smart wearable devices. Various\nmodels, methodologies and systems are discussed in order to examine the state\nof the art. Finally, we discuss remaining challenges and future works.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 09:19:30 GMT"}, {"version": "v2", "created": "Sat, 11 Oct 2014 05:25:18 GMT"}, {"version": "v3", "created": "Wed, 31 Dec 2014 08:54:52 GMT"}, {"version": "v4", "created": "Sat, 10 Jan 2015 14:58:27 GMT"}, {"version": "v5", "created": "Fri, 6 Feb 2015 03:59:12 GMT"}, {"version": "v6", "created": "Wed, 29 Jul 2015 04:25:50 GMT"}, {"version": "v7", "created": "Wed, 19 Jun 2019 02:32:23 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Zhang", "Shengkai", ""], ["Hui", "Pan", ""]]}, {"id": "1410.2828", "submitter": "Omar Alonso", "authors": "Omar Alonso, Vasilis Kandylas", "title": "A Study on Placement of Social Buttons in Web Pages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosion of social media in the last few years, web pages nowadays\ninclude different social network buttons where users can express if they\nsupport or recommend content. Those social buttons are very visual and their\npresentations, along with the counters, mark the importance of the social\nnetwork and the interest on the content. In this paper, we analyze the presence\nof four types of social buttons (Facebook, Twitter, Google+1, and LinkedIn) in\na large collection of web pages that we tracked over a period of time. We\nreport on the distribution and counts along with some characteristics per\ndomain. Finally, we outline some research directions.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 16:12:20 GMT"}], "update_date": "2014-10-13", "authors_parsed": [["Alonso", "Omar", ""], ["Kandylas", "Vasilis", ""]]}, {"id": "1410.3560", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi and Nesreen K. Ahmed", "title": "NetworkRepository: An Interactive Data Repository with Multi-scale\n  Visual Analytics", "comments": "AAAI 2015 DT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Repository (NR) is the first interactive data repository with a\nweb-based platform for visual interactive analytics. Unlike other data\nrepositories (e.g., UCI ML Data Repository, and SNAP), the network data\nrepository (networkrepository.com) allows users to not only download, but to\ninteractively analyze and visualize such data using our web-based interactive\ngraph analytics platform. Users can in real-time analyze, visualize, compare,\nand explore data along many different dimensions. The aim of NR is to make it\neasy to discover key insights into the data extremely fast with little effort\nwhile also providing a medium for users to share data, visualizations, and\ninsights. Other key factors that differentiate NR from the current data\nrepositories is the number of graph datasets, their size, and variety. While\nother data repositories are static, they also lack a means for users to\ncollaboratively discuss a particular dataset, corrections, or challenges with\nusing the data for certain applications. In contrast, we have incorporated many\nsocial and collaborative aspects into NR in hopes of further facilitating\nscientific research (e.g., users can discuss each graph, post observations,\nvisualizations, etc.).\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 03:35:37 GMT"}, {"version": "v2", "created": "Thu, 28 May 2015 19:58:23 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Ahmed", "Nesreen K.", ""]]}, {"id": "1410.4122", "submitter": "Anna Broniec Dr", "authors": "Anna Broniec", "title": "Analysis of EEG signal by Flicker Noise Spectroscopy: Identification of\n  right/left hand movement imagination", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flicker Noise Spectroscopy (FNS) has been used for the analysis of\nelectroencephalography (EEG) signal related to the movement imagination. The\nanalysis of sensorimotor rhythms in time-frequency maps reveals the\nevent-related desynchronization (ERD) and the post-movement event-related\nsynchronization (ERS), observed mainly in the contralateral hemisphere to the\nhand moved for the motor imagery. The signal has been parameterized in\naccordance with FNS method. The significant changes of the FNS parameters, at\nthe time when the subject imagines the movement, have been observed. The\nanalysis of these parameters allows to distinguish between imagination of right\nand left hands movement. Our study shows that the flicker-noise spectroscopy\ncan be an alternative method of analyzing EEG signal related to the imagination\nof movement in terms of a potential application in the brain-computer interface\n(BCI).\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 14:35:28 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Broniec", "Anna", ""]]}, {"id": "1410.5129", "submitter": "Abdul Razaque", "authors": "Khaled Elleithy, Abdul Razaque", "title": "Fostering of innovative usability testing to develop mobile application\n  for mobile collaborative learning (MCL)", "comments": "8 pages, 5 figures, ICGST-AIML Journal, Volume 12, Issue 1, July 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergence of latest technologies has diverted the focus of people form\nComputer-Supported Collaborative Learning (CSCL) to mobile supported\ncollaborative learning. MCL is highly demanded in educational organizations to\nsubstantiate the pedagogical activities. Some of the MCL supportive\narchitectures including applications are introduced in several fields to\nimprove the activities of those organizations, but they need more concise\nparadigm to support both types of collaboration: synchronous and asynchronous.\nThis paper introduces the new preusability testing method that provides\neducational support and gives complete picture for developing new pedagogical\ngroup application for MCL. The feature of application includes asynchronous and\nsynchronous collaboration support. To validate the features of application, we\nconduct the post usability testing and heuristic evaluation, which helps in\ncollecting the empirical data to prove the effectiveness and suitability of\nGroup application. Further, application aims to improve learning impact and\neducate people at anytime and anywhere.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 03:31:14 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Elleithy", "Khaled", ""], ["Razaque", "Abdul", ""]]}, {"id": "1410.5907", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt", "title": "Replacing the computer mouse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In a few months the computer mouse will be half-a-century-old. It is known to\nhave many drawbacks, the main ones being: loss of productivity due to constant\nswitching between keyboard and mouse, and health issues such as RSI. Like the\nkeyboard, it is an unnatural human-computer interface. However the vast\nmajority of computer users still use computer mice nowadays.\n  In this article, we explore computer mouse alternatives. Our research shows\nthat moving the mouse cursor can be done efficiently with camera-based head\ntracking system such as the SmartNav device, and mouse clicks can be emulated\nin many complementary ways. We believe that computer users can increase their\nproductivity and improve their long-term health by using these alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 03:36:53 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Dernoncourt", "Franck", ""]]}, {"id": "1410.6752", "submitter": "Pouyan R. Fard", "authors": "Pouyan R. Fard, Moritz Grosse-Wentrup", "title": "The Influence of Decoding Accuracy on Perceived Control: A Simulated BCI\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the relationship between the decoding accuracy of a\nbrain-computer interface (BCI) and a subject's subjective feeling of control is\nimportant for determining a lower limit on decoding accuracy for a BCI that is\nto be deployed outside a laboratory environment. We investigated this\nrelationship by systematically varying the level of control in a simulated BCI\ntask. We find that a binary decoding accuracy of 65% is required for users to\nreport more often than not that they are feeling in control of the system.\nDecoding accuracies above 75%, on the other hand, added little in terms of the\nlevel of perceived control. We further find that the probability of perceived\ncontrol does not only depend on the actual decoding accuracy, but is also in\ninfluenced by whether subjects successfully complete the given task in the\nallotted time frame.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 17:51:12 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Fard", "Pouyan R.", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1410.7670", "submitter": "Ciro Donalek", "authors": "Ciro Donalek, S.G. Djorgovski, Scott Davidoff, Alex Cioc, Anwell Wang,\n  Giuseppe Longo, Jeffrey S. Norris, Jerry Zhang, Elizabeth Lawler, Stacy Yeh,\n  Ashish Mahabal, Matthew Graham, Andrew Drake", "title": "Immersive and Collaborative Data Visualization Using Virtual Reality\n  Platforms", "comments": "6 pages, refereed proceedings of 2014 IEEE International Conference\n  on Big Data, page 609, ISBN 978-1-4799-5665-4", "journal-ref": null, "doi": "10.1109/BigData.2014.7004282", "report-no": null, "categories": "cs.HC astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective data visualization is a key part of the discovery process in the\nera of big data. It is the bridge between the quantitative content of the data\nand human intuition, and thus an essential component of the scientific path\nfrom data into knowledge and understanding. Visualization is also essential in\nthe data mining process, directing the choice of the applicable algorithms, and\nin helping to identify and remove bad data from the analysis. However, a high\ncomplexity or a high dimensionality of modern data sets represents a critical\nobstacle. How do we visualize interesting structures and patterns that may\nexist in hyper-dimensional data spaces? A better understanding of how we can\nperceive and interact with multi dimensional information poses some deep\nquestions in the field of cognition technology and human computer interaction.\nTo this effect, we are exploring the use of immersive virtual reality platforms\nfor scientific data visualization, both as software and inexpensive commodity\nhardware. These potentially powerful and innovative tools for multi dimensional\ndata visualization can also provide an easy and natural path to a collaborative\ndata visualization and exploration, where scientists can interact with their\ndata and their colleagues in the same visual space. Immersion provides benefits\nbeyond the traditional desktop visualization tools: it leads to a demonstrably\nbetter perception of a datascape geometry, more intuitive data understanding,\nand a better retention of the perceived relationships in the data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 15:46:44 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Donalek", "Ciro", ""], ["Djorgovski", "S. G.", ""], ["Davidoff", "Scott", ""], ["Cioc", "Alex", ""], ["Wang", "Anwell", ""], ["Longo", "Giuseppe", ""], ["Norris", "Jeffrey S.", ""], ["Zhang", "Jerry", ""], ["Lawler", "Elizabeth", ""], ["Yeh", "Stacy", ""], ["Mahabal", "Ashish", ""], ["Graham", "Matthew", ""], ["Drake", "Andrew", ""]]}, {"id": "1410.7850", "submitter": "EPTCS", "authors": "Christoph Benzm\\\"uller, Bruno Woltzenlogel Paleo", "title": "Proceedings Eleventh Workshop on User Interfaces for Theorem Provers", "comments": null, "journal-ref": "EPTCS 167, 2014", "doi": "10.4204/EPTCS.167", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The UITP workshop series brings together researchers interested in designing,\ndeveloping and evaluating user interfaces for automated reasoning tools, such\nas interactive proof assistants, automated theorem provers, model finders,\ntools for formal methods, and tools for visualising and manipulating logical\nformulas and proofs. The eleventh edition of UITP took place in Vienna,\nAustria, and was part of the Vienna Summer of Logic, the largest ever joint\nconference in the area of Logic. This proceedings contains the eight\ncontributed papers that were accepted for presentation at the workshop as well\nas the two invited papers.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 01:06:19 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Benzm\u00fcller", "Christoph", ""], ["Paleo", "Bruno Woltzenlogel", ""]]}, {"id": "1410.8215", "submitter": "EPTCS", "authors": "Bernhard Beckert (Karlsruhe Institute of Technology (KIT)), Sarah\n  Grebing (Karlsruhe Institute of Technology (KIT)), Florian B\\\"ohl (Karlsruhe\n  Institute of Technology (KIT))", "title": "How to Put Usability into Focus: Using Focus Groups to Evaluate the\n  Usability of Interactive Theorem Provers", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 4-13", "doi": "10.4204/EPTCS.167.3", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years the effectiveness of interactive theorem provers has\nincreased to an extent that the bottleneck in the interactive process shifted\nto efficiency: while in principle large and complex theorems are provable\n(effectiveness), it takes a lot of effort for the user interacting with the\nsystem (lack of efficiency). We conducted focus groups to evaluate the\nusability of Isabelle/HOL and the KeY system with two goals: (a) detect\nusability issues in the interaction between interactive theorem provers and\ntheir user, and (b) analyze how evaluation and survey methods commonly used in\nthe area of human-computer interaction, such as focus groups and co-operative\nevaluation, are applicable to the specific field of interactive theorem proving\n(ITP).\n  In this paper, we report on our experience using the evaluation method focus\ngroups and how we adapted this method to ITP. We describe our results and\nconclusions mainly on the \"meta-level,\" i.e., we focus on the impact that\nspecific characteristics of ITPs have on the setup and the results of focus\ngroups. On the concrete level, we briefly summarise insights into the usability\nof the ITPs used in our case study.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:02 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Beckert", "Bernhard", "", "Karlsruhe Institute of Technology"], ["Grebing", "Sarah", "", "Karlsruhe Institute of Technology"], ["B\u00f6hl", "Florian", "", "Karlsruhe\n  Institute of Technology"]]}, {"id": "1410.8216", "submitter": "EPTCS", "authors": "Andrew Butterfield (Trinity College Dublin)", "title": "UTP2: Higher-Order Equational Reasoning by Pointing", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 14-22", "doi": "10.4204/EPTCS.167.4", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a prototype theorem prover, UTP2, developed to match the style of\nhand-written proof work in the Unifying Theories of Programming semantical\nframework. This is based on alphabetised predicates in a 2nd-order logic, with\na strong emphasis on equational reasoning. We present here an overview of the\nuser-interface of this prover, which was developed from the outset using a\npoint-and-click approach. We contrast this with the command-line paradigm that\ncontinues to dominate the mainstream theorem provers, and raises the question:\ncan we have the best of both worlds?\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:15 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Butterfield", "Andrew", "", "Trinity College Dublin"]]}, {"id": "1410.8217", "submitter": "EPTCS", "authors": "Gudmund Grov (Heriot-Watt University), Aleks Kissinger (University of\n  Oxford), Yuhui Lin (Heriot-Watt University)", "title": "Tinker, tailor, solver, proof", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 23-34", "doi": "10.4204/EPTCS.167.5", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Tinker, a tool for designing and evaluating proof strategies\nbased on proof-strategy graphs, a formalism previously introduced by the\nauthors. We represent proof strategies as open-graphs, which are directed\ngraphs with additional input/output edges. Tactics appear as nodes in a graph,\nand can be `piped' together by adding edges between them. Goals are added to\nthe input edges of such a graph, and flow through the graph as the strategy is\nevaluated. Properties of the edges ensure that only the right `type' of goals\nare accepted. In this paper, we detail the Tinker tool and show how it can be\nintegrated with two different theorem provers: Isabelle and ProofPower.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:33 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Grov", "Gudmund", "", "Heriot-Watt University"], ["Kissinger", "Aleks", "", "University of\n  Oxford"], ["Lin", "Yuhui", "", "Heriot-Watt University"]]}, {"id": "1410.8218", "submitter": "EPTCS", "authors": "Tomer Libal (Microsoft Research - Inria Joint Center, Ecole\n  Polytechnique), Martin Riener (Institute of Computer Languages, Vienna\n  University of Technology), Mikheil Rukhaia (Institute of Applied Mathematics,\n  Tbilisi State University)", "title": "Advanced Proof Viewing in ProofTool", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 35-47", "doi": "10.4204/EPTCS.167.6", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequent calculus is widely used for formalizing proofs. However, due to the\nproliferation of data, understanding the proofs of even simple mathematical\narguments soon becomes impossible. Graphical user interfaces help in this\nmatter, but since they normally utilize Gentzen's original notation, some of\nthe problems persist. In this paper, we introduce a number of criteria for\nproof visualization which we have found out to be crucial for analyzing proofs.\nWe then evaluate recent developments in tree visualization with regard to these\ncriteria and propose the Sunburst Tree layout as a complement to the\ntraditional tree structure. This layout constructs inferences as concentric\ncircle arcs around the root inference, allowing the user to focus on the\nproof's structural content. Finally, we describe its integration into ProofTool\nand explain how it interacts with the Gentzen layout.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:47 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Libal", "Tomer", "", "Microsoft Research - Inria Joint Center, Ecole\n  Polytechnique"], ["Riener", "Martin", "", "Institute of Computer Languages, Vienna\n  University of Technology"], ["Rukhaia", "Mikheil", "", "Institute of Applied Mathematics,\n  Tbilisi State University"]]}, {"id": "1410.8219", "submitter": "EPTCS", "authors": "Florian Rabe (Jacobs University Bremen)", "title": "A Logic-Independent IDE", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 48-60", "doi": "10.4204/EPTCS.167.7", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The author's MMT system provides a framework for defining and implementing\nlogical systems. By combining MMT with the jEdit text editor, we obtain a\nlogic-independent IDE. The IDE functionality includes advanced features such as\ncontext-sensitive auto-completion, search, and change management.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:07:58 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Rabe", "Florian", "", "Jacobs University Bremen"]]}, {"id": "1410.8221", "submitter": "EPTCS", "authors": "Carst Tankink (Inria Saclay - \\^Ile-de-France)", "title": "PIDE for Asynchronous Interaction with Coq", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 73-83", "doi": "10.4204/EPTCS.167.9", "report-no": null, "categories": "cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the initial progress towards integrating the Coq proof\nassistant with the PIDE architecture initially developed for Isabelle. The\narchitecture is aimed at asynchronous, parallel interaction with proof\nassistants, and is tied in heavily with a plugin that allows the jEdit editor\nto work with Isabelle.\n  We have made some generalizations to the PIDE architecture to accommodate for\nmore provers than just Isabelle, and adapted Coq to understand the core\nprotocol: this delivered a working system in about two man-months.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:08:18 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Tankink", "Carst", "", "Inria Saclay - \u00cele-de-France"]]}, {"id": "1410.8222", "submitter": "EPTCS", "authors": "Makarius Wenzel (Univ. Paris-Sud, Laboratoire LRI, UMR8623)", "title": "System description: Isabelle/jEdit in 2014", "comments": "In Proceedings UITP 2014, arXiv:1410.7850", "journal-ref": "EPTCS 167, 2014, pp. 84-94", "doi": "10.4204/EPTCS.167.10", "report-no": null, "categories": "cs.LO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an updated system description for Isabelle/jEdit, according to the\nofficial release Isabelle2014 (August 2014). The following new PIDE concepts\nare explained: asynchronous print functions and document overlays, syntactic\nand semantic completion, editor navigation, management of auxiliary files\nwithin the document-model.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 01:08:32 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Wenzel", "Makarius", "", "Univ. Paris-Sud, Laboratoire LRI, UMR8623"]]}]