[{"id": "1704.00616", "submitter": "Mohammadreza Zolfaghari", "authors": "Mohammadreza Zolfaghari, Gabriel L. Oliveira, Nima Sedaghat, and\n  Thomas Brox", "title": "Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance\n  for Action Classification and Detection", "comments": "10 pages, 7 figures, ICCV 2017 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General human action recognition requires understanding of various visual\ncues. In this paper, we propose a network architecture that computes and\nintegrates the most important visual cues for action recognition: pose, motion,\nand the raw images. For the integration, we introduce a Markov chain model\nwhich adds cues successively. The resulting approach is efficient and\napplicable to action classification as well as to spatial and temporal action\nlocalization. The two contributions clearly improve the performance over\nrespective baselines. The overall approach achieves state-of-the-art action\nclassification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover,\nit yields state-of-the-art spatio-temporal action localization results on\nUCF101 and J-HMDB.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 14:29:40 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 18:40:14 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Zolfaghari", "Mohammadreza", ""], ["Oliveira", "Gabriel L.", ""], ["Sedaghat", "Nima", ""], ["Brox", "Thomas", ""]]}, {"id": "1704.00656", "submitter": "Arkaitz Zubiaga", "authors": "Arkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria Liakata, Rob\n  Procter", "title": "Detection and Resolution of Rumours in Social Media: A Survey", "comments": "ACM Computing Surveys", "journal-ref": "ACM Computing Surveys 51, 2, Article 32 (February 2018), 36 pages", "doi": "10.1145/3161603", "report-no": null, "categories": "cs.CL cs.HC cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the increasing use of social media platforms for information and news\ngathering, its unmoderated nature often leads to the emergence and spread of\nrumours, i.e. pieces of information that are unverified at the time of posting.\nAt the same time, the openness of social media platforms provides opportunities\nto study how users share and discuss rumours, and to explore how natural\nlanguage processing and data mining techniques may be used to find ways of\ndetermining their veracity. In this survey we introduce and discuss two types\nof rumours that circulate on social media; long-standing rumours that circulate\nfor long periods of time, and newly-emerging rumours spawned during fast-paced\nevents such as breaking news, where reports are released piecemeal and often\nwith an unverified status in their early stages. We provide an overview of\nresearch into social media rumours with the ultimate goal of developing a\nrumour classification system that consists of four components: rumour\ndetection, rumour tracking, rumour stance classification and rumour veracity\nclassification. We delve into the approaches presented in the scientific\nliterature for the development of each of these four components. We summarise\nthe efforts and achievements so far towards the development of rumour\nclassification systems and conclude with suggestions for avenues for future\nresearch in social media mining for detection and resolution of rumours.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 15:57:44 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 20:28:29 GMT"}, {"version": "v3", "created": "Tue, 3 Apr 2018 08:24:46 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Zubiaga", "Arkaitz", ""], ["Aker", "Ahmet", ""], ["Bontcheva", "Kalina", ""], ["Liakata", "Maria", ""], ["Procter", "Rob", ""]]}, {"id": "1704.00768", "submitter": "Qunwei Li", "authors": "Qunwei Li and Pramod K. Varshney", "title": "Does Confidence Reporting from the Crowd Benefit Crowdsourcing\n  Performance?", "comments": "6 pages, 4 figures, SocialSens 2017. arXiv admin note: text overlap\n  with arXiv:1602.00575", "journal-ref": null, "doi": "10.1145/3055601.3055607", "report-no": null, "categories": "cs.SI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the design of an effective crowdsourcing system for an $M$-ary\nclassification task. Crowd workers complete simple binary microtasks whose\nresults are aggregated to give the final classification decision. We consider\nthe scenario where the workers have a reject option so that they are allowed to\nskip microtasks when they are unable to or choose not to respond to binary\nmicrotasks. Additionally, the workers report quantized confidence levels when\nthey are able to submit definitive answers. We present an aggregation approach\nusing a weighted majority voting rule, where each worker's response is assigned\nan optimized weight to maximize crowd's classification performance. We obtain a\ncouterintuitive result that the classification performance does not benefit\nfrom workers reporting quantized confidence. Therefore, the crowdsourcing\nsystem designer should employ the reject option without requiring confidence\nreporting.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 19:09:08 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Li", "Qunwei", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1704.00961", "submitter": "Ruck Thawonmas", "authors": "Pujana Paliyawan, Takahiro Kusano, Yuto Nakagawa, Tomohiro Harada,\n  Ruck Thawonmas", "title": "Adaptive Motion Gaming AI for Health Promotion", "comments": "A revised version of our paper for 2017 AAAI Spring Symposium Series\n  (Well-Being AI: From Machine Learning to Subjective Oriented Computing), San\n  Francisco,USA, Mar. 27-29, 2017. Revised contents, due to our correction of\n  (8), are highlighted in red. Many apologies, but the effectiveness of the\n  proposed method/approach in the paper still holds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a design of a non-player character (AI) for promoting\nbalancedness in use of body segments when engaging in full-body motion gaming.\nIn our experiment, we settle a battle between the proposed AI and a player by\nusing FightingICE, a fighting game platform for AI development. A middleware\ncalled UKI is used to allow the player to control the game by using body motion\ninstead of the keyboard and mouse. During gameplay, the proposed AI analyze\nhealth states of the player; it determines its next action by predicting how\neach candidate action, recommended by a Monte-Carlo tree search algorithm, will\ninduce the player to move, and how the player's health tends to be affected.\nOur result demonstrates successful improvement in balancedness in use of body\nsegments on 4 out of 5 subjects.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 11:29:02 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Paliyawan", "Pujana", ""], ["Kusano", "Takahiro", ""], ["Nakagawa", "Yuto", ""], ["Harada", "Tomohiro", ""], ["Thawonmas", "Ruck", ""]]}, {"id": "1704.00972", "submitter": "Arianna D'Ulizia", "authors": "Patrizia Grifoni, Fernando Ferri, Maria Chiara Caschera, Arianna\n  D'Ulizia, Mauro Mazzei", "title": "MIS: Multimodal Interaction Services in a cloud perspective", "comments": "10 pages, 4 figures", "journal-ref": "Journal of Next Generation Information Technology (JNIT), Volume\n  5, Issue 4, Pages 1-10, November 2014", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Web is becoming more and more a wide software framework on which each one\ncan compose and use contents, software applications and services. It can offer\nadequate computational resources to manage the complexity implied by the use of\nthe five senses when involved in human machine interaction. The core of the\npaper describes how SOA (Service Oriented Architecture) can support multimodal\ninteraction by pushing the I/O processing and reasoning to the cloud, improving\nnaturalness. The benefits of cloud computing for multimodal interaction have\nbeen identified by emphasizing the flexibility and scalability of a SOA, and\nits characteristics to provide a more holistic view of interaction according to\nthe variety of situations and users.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 12:15:40 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Grifoni", "Patrizia", ""], ["Ferri", "Fernando", ""], ["Caschera", "Maria Chiara", ""], ["D'Ulizia", "Arianna", ""], ["Mazzei", "Mauro", ""]]}, {"id": "1704.01217", "submitter": "Harsh Taneja", "authors": "Harsh Taneja, Angela Xiao Wu, Stephanie Edgerly", "title": "Rethinking the Generational Gap in Online News Use: An Infrastructural\n  Perspective", "comments": "Harsh Taneja and Angela Xiao Wu are co-first authors. Cite as:\n  Taneja, H., Wu, A. X., & Edgerly, S. (Forthcoming). Rethinking the\n  Generational Gap in Online News Use: An Infrastructural Perspective. New\n  Media & Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our study investigates the role of infrastructures in shaping online news\nusage by contrasting use patterns of two social groups,millennials and\nboomers,that are specifically located in news infrastructures. Typically based\non self reported data, popular press and academics tend to highlight the\ngenerational gap in news usage and link it to divergence in values and\npreferences of the two age cohorts. In contrast, we conduct relational analyses\nof shared usage obtained from passively metered usage data across a vast range\nof online news outlets for millennials and boomers. We compare each cohort's\nusage networks comprising various types of news websites. Our analyses reveal a\nsmaller than commonly assumed generational gap in online news usage, with\ncharacteristics that manifest the multifarious effects of the infrastructural\naspect of the media environment, alongside those of preferences.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 23:21:44 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Taneja", "Harsh", ""], ["Wu", "Angela Xiao", ""], ["Edgerly", "Stephanie", ""]]}, {"id": "1704.01220", "submitter": "Parvez Ahammad", "authors": "Qingzhu Gao, Prasenjit Dey, and Parvez Ahammad", "title": "Perceived Performance of Webpages In the Wild: Insights from Large-scale\n  Crowdsourcing of Above-the-Fold QoE", "comments": "6 pages, 5 figures, submitted to ACM SIGCOMM 2nd Workshop on\n  QoE-based Analysis and Management of Data Communication Networks\n  (Internet-QoE 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.HC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clearly, no one likes webpages with poor quality of experience (QoE). Being\nperceived as slow or fast is a key element in the overall perceived QoE of web\napplications. While extensive effort has been put into optimizing web\napplications (both in industry and academia), not a lot of work exists in\ncharacterizing what aspects of webpage loading process truly influence human\nend-user's perception of the \"Speed\" of a page. In this paper we present\n\"SpeedPerception\", a large-scale web performance crowdsourcing framework\nfocused on understanding the perceived loading performance of above-the-fold\n(ATF) webpage content. Our end goal is to create free open-source benchmarking\ndatasets to advance the systematic analysis of how humans perceive webpage\nloading process. In Phase-1 of our \"SpeedPerception\" study using Internet\nRetailer Top 500 (IR 500) websites\n(https://github.com/pahammad/speedperception), we found that commonly used\nnavigation metrics such as \"onLoad\" and \"Time To First Byte (TTFB)\" fail (less\nthan 60% match) to represent majority human perception when comparing the speed\nof two webpages. We present a simple 3-variable-based machine learning model\nthat explains the majority end-user choices better (with $87 \\pm 2\\%$\naccuracy). In addition, our results suggest that the time needed by end-users\nto evaluate relative perceived speed of webpage is far less than the time of\nits \"visualComplete\" event.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 23:47:41 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Gao", "Qingzhu", ""], ["Dey", "Prasenjit", ""], ["Ahammad", "Parvez", ""]]}, {"id": "1704.01266", "submitter": "Parag Chandakkar", "authors": "Archana Paladugu, Parag S. Chandakkar, Peng Zhang and Baoxin Li", "title": "Supporting Navigation of Outdoor Shopping Complexes for\n  Visually-impaired Users through Multi-modal Data Fusion", "comments": "ICME 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outdoor shopping complexes (OSC) are extremely difficult for people with\nvisual impairment to navigate. Existing GPS devices are mostly designed for\nroadside navigation and seldom transition well into an OSC-like setting. We\nreport our study on the challenges faced by a blind person in navigating OSC\nthrough developing a new mobile application named iExplore. We first report an\nexploratory study aiming at deriving specific design principles for building\nthis system by learning the unique challenges of the problem. Then we present a\nmethodology that can be used to derive the necessary information for the\ndevelopment of iExplore, followed by experimental validation of the technology\nby a group of visually impaired users in a local outdoor shopping center. User\nfeedback and other experiments suggest that iExplore, while at its very initial\nphase, has the potential of filling a practical gap in existing assistive\ntechnologies for the visually impaired.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 04:24:41 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Paladugu", "Archana", ""], ["Chandakkar", "Parag S.", ""], ["Zhang", "Peng", ""], ["Li", "Baoxin", ""]]}, {"id": "1704.01347", "submitter": "Juhi Kulshrestha", "authors": "Juhi Kulshrestha, Motahhare Eslami, Johnnatan Messias, Muhammad Bilal\n  Zafar, Saptarshi Ghosh, Krishna P. Gummadi, Karrie Karahalios", "title": "Quantifying Search Bias: Investigating Sources of Bias for Political\n  Searches in Social Media", "comments": "In Proceedings of ACM Conference on Computer Supported Cooperative\n  Work & Social Computing (CSCW), Portland, USA, February 2017", "journal-ref": null, "doi": "10.1145/2998181.2998321", "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search systems in online social media sites are frequently used to find\ninformation about ongoing events and people. For topics with multiple competing\nperspectives, such as political events or political candidates, bias in the top\nranked results significantly shapes public opinion. However, bias does not\nemerge from an algorithm alone. It is important to distinguish between the bias\nthat arises from the data that serves as the input to the ranking system and\nthe bias that arises from the ranking system itself. In this paper, we propose\na framework to quantify these distinct biases and apply this framework to\npolitics-related queries on Twitter. We found that both the input data and the\nranking system contribute significantly to produce varying amounts of bias in\nthe search results and in different ways. We discuss the consequences of these\nbiases and possible mechanisms to signal this bias in social media search\nsystems' interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 10:12:56 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Kulshrestha", "Juhi", ""], ["Eslami", "Motahhare", ""], ["Messias", "Johnnatan", ""], ["Zafar", "Muhammad Bilal", ""], ["Ghosh", "Saptarshi", ""], ["Gummadi", "Krishna P.", ""], ["Karahalios", "Karrie", ""]]}, {"id": "1704.01442", "submitter": "Juhi Kulshrestha", "authors": "Juhi Kulshrestha, Muhammad Bilal Zafar, Lisette Espin-Noboa, Krishna\n  P. Gummadi, Saptarshi Ghosh", "title": "Characterizing Information Diets of Social Media Users", "comments": "In Proceeding of International AAAI Conference on Web and Social\n  Media (ICWSM), Oxford, UK, May 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread adoption of social media sites like Twitter and Facebook,\nthere has been a shift in the way information is produced and consumed.\nEarlier, the only producers of information were traditional news organizations,\nwhich broadcast the same carefully-edited information to all consumers over\nmass media channels. Whereas, now, in online social media, any user can be a\nproducer of information, and every user selects which other users she connects\nto, thereby choosing the information she consumes. Moreover, the personalized\nrecommendations that most social media sites provide also contribute towards\nthe information consumed by individual users. In this work, we define a concept\nof information diet -- which is the topical distribution of a given set of\ninformation items (e.g., tweets) -- to characterize the information produced\nand consumed by various types of users in the popular Twitter social media. At\na high level, we find that (i) popular users mostly produce very specialized\ndiets focusing on only a few topics; in fact, news organizations (e.g.,\nNYTimes) produce much more focused diets on social media as compared to their\nmass media diets, (ii) most users' consumption diets are primarily focused\ntowards one or two topics of their interest, and (iii) the personalized\nrecommendations provided by Twitter help to mitigate some of the topical\nimbalances in the users' consumption diets, by adding information on diverse\ntopics apart from the users' primary topics of interest.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 14:15:33 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Kulshrestha", "Juhi", ""], ["Zafar", "Muhammad Bilal", ""], ["Espin-Noboa", "Lisette", ""], ["Gummadi", "Krishna P.", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "1704.01570", "submitter": "Utku Kose", "authors": "Aslihan Tufekci, Kamuran Samanci, Utku Kose", "title": "Developing a FPGA-supported touchscreen writing / drawing system for\n  educational environments", "comments": "31 pages, 13 figures, 6 tables", "journal-ref": "Journal of Multidisciplinary Developments, 1(1), 2016, 60-90", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Developments in information and communication technologies have been greatly\ninfluential on the practices in all fields, and education is not an exception\nto this. To illustrate with, computers were first used in computer assisted\neducation in order to increase the efficiency of teaching process. Recently,\ncomputer has contributed more to the field through interactive and smart class\napplications that are specially designed for classroom use. The aim of this\nstudy is to develop a low cost, portable and projection supported touchscreen\nto be used in educational environments by using FPGA technology and to test its\nusability. For the purposes of the study, the above mentioned system was\ndeveloped by using the necessary hardware and software, and later it was tested\nin terms of usability. This usability test was administered to teachers, who\nwere the target end users of this touchscreen writing / drawing system. The aim\nof this test was to determine user friendliness, subservientness and usability\nof the system. Several tools were used to obtain data from the users that\nparticipated in the study. The analysis and evaluation of the data collected\nrevealed that the system has achieved its objectives successfully.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 18:28:50 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Tufekci", "Aslihan", ""], ["Samanci", "Kamuran", ""], ["Kose", "Utku", ""]]}, {"id": "1704.01942", "submitter": "Minsuk Kahng", "authors": "Minsuk Kahng, Pierre Y. Andrews, Aditya Kalro, Duen Horng Chau", "title": "ActiVis: Visual Exploration of Industry-Scale Deep Neural Network Models", "comments": "Will be presented at IEEE VAST 2017 and published in IEEE\n  Transactions on Visualization and Computer Graphics, 24(1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning models have achieved state-of-the-art accuracies for many\nprediction tasks, understanding these models remains a challenge. Despite the\nrecent interest in developing visual tools to help users interpret deep\nlearning models, the complexity and wide variety of models deployed in\nindustry, and the large-scale datasets that they used, pose unique design\nchallenges that are inadequately addressed by existing work. Through\nparticipatory design sessions with over 15 researchers and engineers at\nFacebook, we have developed, deployed, and iteratively improved ActiVis, an\ninteractive visualization system for interpreting large-scale deep learning\nmodels and results. By tightly integrating multiple coordinated views, such as\na computation graph overview of the model architecture, and a neuron activation\nview for pattern discovery and comparison, users can explore complex deep\nneural network models at both the instance- and subset-level. ActiVis has been\ndeployed on Facebook's machine learning platform. We present case studies with\nFacebook researchers and engineers, and usage scenarios of how ActiVis may work\nwith different models.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 17:18:02 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 00:22:56 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Kahng", "Minsuk", ""], ["Andrews", "Pierre Y.", ""], ["Kalro", "Aditya", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1704.02384", "submitter": "Eugene Wu", "authors": "Hamed Nilforoshan, Jiannan Wang, Eugene Wu", "title": "PreCog: Improving Crowdsourced Data Quality Before Acquisition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality control in crowdsourcing systems is crucial. It is typically done\nafter data collection, often using additional crowdsourced tasks to assess and\nimprove the quality. These post-hoc methods can easily add cost and latency to\nthe acquisition process--particularly if collecting high-quality data is\nimportant. In this paper, we argue for pre-hoc interface optimizations based on\nfeedback that helps workers improve data quality before it is submitted and is\nwell suited to complement post-hoc techniques. We propose the Precog system\nthat explicitly supports such interface optimizations for common integrity\nconstraints as well as more ambiguous text acquisition tasks where quality is\nill-defined. We then develop the Segment-Predict-Explain pattern for detecting\nlow-quality text segments and generating prescriptive explanations to help the\nworker improve their text input. Our unique combination of segmentation and\nprescriptive explanation are necessary for Precog to collect 2x more\nhigh-quality text data than non-Precog approaches on two real domains.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 21:53:13 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Nilforoshan", "Hamed", ""], ["Wang", "Jiannan", ""], ["Wu", "Eugene", ""]]}, {"id": "1704.02841", "submitter": "Maria Chiara Caschera Dr.", "authors": "Maria Chiara Caschera, Fernando Ferri, Patrizia Grifoni", "title": "From Modal to Multimodal Ambiguities: a Classification Approach", "comments": "23 pages", "journal-ref": "JNIT (Journal of Next Generation Information Technology), Volume 4\n  Issue 5, July, 2013,Pages 87-109, ISSN 2092-8637. GlobalCIS (Convergence\n  Information Society, Republic of Korea)", "doi": "10.4156/jnit.vol4.issue5.10", "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with classifying ambiguities for Multimodal Languages. It\nevolves the classifications and the methods of the literature on ambiguities\nfor Natural Language and Visual Language, empirically defining an original\nclassification of ambiguities for multimodal interaction using a linguistic\nperspective. This classification distinguishes between Semantic and Syntactic\nmultimodal ambiguities and their subclasses, which are intercepted using a\nrule-based method implemented in a software module. The experimental results\nhave achieved an accuracy of the obtained classification compared to the\nexpected one, which are defined by the human judgment, of 94.6% for the\nsemantic ambiguities classes, and 92.1% for the syntactic ambiguities classes.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 12:06:51 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Caschera", "Maria Chiara", ""], ["Ferri", "Fernando", ""], ["Grifoni", "Patrizia", ""]]}, {"id": "1704.03521", "submitter": "Igor Podlubny", "authors": "Matej Mikulszky, Jana Pocsova, Andrea Mojzisova, Igor Podlubny", "title": "Responsive Graphical User Interface (ReGUI) and its Implementation in\n  MATLAB", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the responsive graphical user interface (ReGUI)\napproach to creating applications, and demonstrate how this approach can be\nimplemented in MATLAB. The same general technique can be used in other\nprogramming languages.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 20:18:25 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Mikulszky", "Matej", ""], ["Pocsova", "Jana", ""], ["Mojzisova", "Andrea", ""], ["Podlubny", "Igor", ""]]}, {"id": "1704.03627", "submitter": "Ting-Hao Huang", "authors": "Ting-Hao 'Kenneth' Huang, Yun-Nung Chen, Jeffrey P. Bigham", "title": "Real-time On-Demand Crowd-powered Entity Extraction", "comments": "Accepted by the 5th Edition Of The Collective Intelligence Conference\n  (CI 2017) as an oral presentation. Interface code and data are available at:\n  https://github.com/windx0303/dialogue-esp-game", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Output-agreement mechanisms such as ESP Game have been widely used in human\ncomputation to obtain reliable human-generated labels. In this paper, we argue\nthat a \"time-limited\" output-agreement mechanism can be used to create a fast\nand robust crowd-powered component in interactive systems, particularly\ndialogue systems, to extract key information from user utterances on the fly.\nOur experiments on Amazon Mechanical Turk using the Airline Travel Information\nSystem (ATIS) dataset showed that the proposed approach achieves high-quality\nresults with an average response time shorter than 9 seconds.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 05:48:18 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 17:12:12 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Huang", "Ting-Hao 'Kenneth'", ""], ["Chen", "Yun-Nung", ""], ["Bigham", "Jeffrey P.", ""]]}, {"id": "1704.03931", "submitter": "Laurel Riek", "authors": "Laurel D. Riek", "title": "Healthcare Robotics", "comments": "8 pages, Communications of the ACM, 2017", "journal-ref": "Communications of the ACM, November 2017, Vol. 60 No. 11, Pages\n  68-78", "doi": "10.1145/3127874", "report-no": null, "categories": "cs.RO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots have the potential to be a game changer in healthcare: improving\nhealth and well-being, filling care gaps, supporting care givers, and aiding\nhealth care workers. However, before robots are able to be widely deployed, it\nis crucial that both the research and industrial communities work together to\nestablish a strong evidence-base for healthcare robotics, and surmount likely\nadoption barriers. This article presents a broad contextualization of robots in\nhealthcare by identifying key stakeholders, care settings, and tasks; reviewing\nrecent advances in healthcare robotics; and outlining major challenges and\nopportunities to their adoption.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 21:02:25 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Riek", "Laurel D.", ""]]}, {"id": "1704.03949", "submitter": "Alexander Lex", "authors": "Thomas Geymayer, Manuela Waldner, Alexander Lex, Dieter Schmalstieg", "title": "How Sensemaking Tools Influence Display Space Usage", "comments": "To appear in EuroVis Workshop on Visual Analytics (2017)", "journal-ref": null, "doi": "10.2312/eurova.20171112", "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We explore how the availability of a sensemaking tool influences users'\nknowledge externalization strategies. On a large display, users were asked to\nsolve an intelligence analysis task with or without a bidirectionally linked\nconcept-graph (BLC) to organize insights into concepts (nodes) and relations\n(edges). In BLC, both nodes and edges maintain \"deep links\" to the exact source\nphrases and sections in associated documents. In our control condition, we were\nable to reproduce previously described spatial organization behaviors using\ndocument windows on the large display. When using BLC, however, we found that\nanalysts apply spatial organization to BLC nodes instead, use significantly\nless display space and have significantly fewer open windows.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 22:47:32 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Geymayer", "Thomas", ""], ["Waldner", "Manuela", ""], ["Lex", "Alexander", ""], ["Schmalstieg", "Dieter", ""]]}, {"id": "1704.04561", "submitter": "Paul Rosen", "authors": "Paul Rosen, Anil Seth, Betsy Mills, Adam Ginsburg, Julia Kamenetzky,\n  Jeff Kern, Chris R. Johnson, Bei Wang", "title": "Using Contour Trees in the Analysis and Visualization of Radio Astronomy\n  Data Cubes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current generation of radio and millimeter telescopes, particularly the\nAtacama Large Millimeter Array (ALMA), offers enormous advances in observing\ncapabilities. While these advances represent an unprecedented opportunity to\nfacilitate scientific understanding, the increased complexity in the spatial\nand spectral structure of these ALMA data cubes lead to challenges in their\ninterpretation. In this paper, we perform a feasibility study for applying\ntopological data analysis and visualization techniques never before tested by\nthe ALMA community. Through techniques based on contour trees, we seek to\nimprove upon existing analysis and visualization workflows of ALMA data cubes,\nin terms of accuracy and speed in feature extraction. We review our application\ndevelopment process in building effective analysis and visualization\ncapabilities for the astrophysicists. We also summarize effective design\npractices by identifying domain-specific needs of simplicity, integrability,\nand reproducibility, in order to best target and service the large astrophysics\ncommunity.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 01:09:33 GMT"}, {"version": "v2", "created": "Wed, 24 Apr 2019 14:42:08 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Rosen", "Paul", ""], ["Seth", "Anil", ""], ["Mills", "Betsy", ""], ["Ginsburg", "Adam", ""], ["Kamenetzky", "Julia", ""], ["Kern", "Jeff", ""], ["Johnson", "Chris R.", ""], ["Wang", "Bei", ""]]}, {"id": "1704.05084", "submitter": "Poonam Yadav Dr", "authors": "Poonam Yadav and John Darlington", "title": "Conceptual Frameworks for Building Online Citizen Science Projects", "comments": null, "journal-ref": "Human Computation (2016) 3:1:213-223 ISSN: 2330-8001, DOI:\n  10.15346/hc.v3i1.12", "doi": "10.15346/hc.v3i1.12", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, citizen science has grown in popularity due to a number of\nreasons, including the emphasis on informal learning and creativity potential\nassociated with these initiatives. Citizen science projects address research\nquestions from various domains, ranging from Ecology to Astronomy. Due to the\nadvancement of communication technologies, which makes outreach and engagement\nof wider communities easier, scientists are keen to turn their own research\ninto citizen science projects. However, the development, deployment and\nmanagement of these projects remains challenging. One of the most important\nchallenges is building the project itself. There is no single tool or\nframework, which guides the step-by-step development of the project, since\nevery project has specific characteristics, such as geographical constraints or\nvolunteers' mode of participation. Therefore, in this article, we present a\nseries of conceptual frameworks for categorisation, decision and deployment,\nwhich guide a citizen science project creator in every step of creating a new\nproject starting from the research question to project deployment. The\nframeworks are designed with consideration to the properties of already\nexisting citizen science projects and could be easily extended to include other\ndimensions, which are not currently perceived.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 18:20:54 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Yadav", "Poonam", ""], ["Darlington", "John", ""]]}, {"id": "1704.05513", "submitter": "Pierre-Hadrien Arnoux", "authors": "Pierre-Hadrien Arnoux, Anbang Xu, Neil Boyette, Jalal Mahmud, Rama\n  Akkiraju, Vibha Sinha", "title": "25 Tweets to Know You: A New Model to Predict Personality with Social\n  Media", "comments": "Accepted as a short paper at ICWSM 2017. Please cite the ICWSM\n  version and not the ArXiv version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting personality is essential for social applications supporting\nhuman-centered activities, yet prior modeling methods with users written text\nrequire too much input data to be realistically used in the context of social\nmedia. In this work, we aim to drastically reduce the data requirement for\npersonality modeling and develop a model that is applicable to most users on\nTwitter. Our model integrates Word Embedding features with Gaussian Processes\nregression. Based on the evaluation of over 1.3K users on Twitter, we find that\nour model achieves comparable or better accuracy than state of the art\ntechniques with 8 times fewer data.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 20:16:31 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Arnoux", "Pierre-Hadrien", ""], ["Xu", "Anbang", ""], ["Boyette", "Neil", ""], ["Mahmud", "Jalal", ""], ["Akkiraju", "Rama", ""], ["Sinha", "Vibha", ""]]}, {"id": "1704.05543", "submitter": "Sreecharan Sankaranarayanan", "authors": "Gaurav Singh Tomar, Sreecharan Sankaranarayanan, Xu Wang and Carolyn\n  Penstein Ros\\'e", "title": "Coordinating Collaborative Chat in Massive Open Online Courses", "comments": "8 pages", "journal-ref": "Proceedings of the International Conference of the Learning\n  Sciences 2016, Volume 1, pp 607-614", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An earlier study of a collaborative chat intervention in a Massive Open\nOnline Course (MOOC) identified negative effects on attrition stemming from a\nrequirement for students to be matched with exactly one partner prior to\nbeginning the activity. That study raised questions about how to orchestrate a\ncollaborative chat intervention in a MOOC context in order to provide the\nbenefit of synchronous social engagement without the coordination difficulties.\nIn this paper we present a careful analysis of an intervention designed to\novercome coordination difficulties by welcoming students into the chat on a\nrolling basis as they arrive rather than requiring them to be matched with a\npartner before beginning. The results suggest the most positive impact when\nexperiencing a chat with exactly one partner rather than more or less. A\nqualitative analysis of the chat data reveals differential experiences between\nthese configurations that suggests a potential explanation for the effect and\nraises questions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 21:57:10 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Tomar", "Gaurav Singh", ""], ["Sankaranarayanan", "Sreecharan", ""], ["Wang", "Xu", ""], ["Ros\u00e9", "Carolyn Penstein", ""]]}, {"id": "1704.05753", "submitter": "Jonathan K Kummerfeld", "authors": "Youxuan Jiang, Jonathan K. Kummerfeld and Walter S. Lasecki", "title": "Understanding Task Design Trade-offs in Crowdsourced Paraphrase\n  Collection", "comments": "Published at ACL 2017", "journal-ref": "ACL (2017) 103-109", "doi": "10.18653/v1/P17-2017", "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linguistically diverse datasets are critical for training and evaluating\nrobust machine learning systems, but data collection is a costly process that\noften requires experts. Crowdsourcing the process of paraphrase generation is\nan effective means of expanding natural language datasets, but there has been\nlimited analysis of the trade-offs that arise when designing tasks. In this\npaper, we present the first systematic study of the key factors in\ncrowdsourcing paraphrase collection. We consider variations in instructions,\nincentives, data domains, and workflows. We manually analyzed paraphrases for\ncorrectness, grammaticality, and linguistic diversity. Our observations provide\nnew insight into the trade-offs between accuracy and diversity in crowd\nresponses that arise as a result of task design, providing guidance for future\nparaphrase generation procedures.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 14:41:21 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 23:04:39 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Jiang", "Youxuan", ""], ["Kummerfeld", "Jonathan K.", ""], ["Lasecki", "Walter S.", ""]]}, {"id": "1704.05841", "submitter": "Kevin Jasberg", "authors": "Kevin Jasberg and Sergej Sizov", "title": "The Magic Barrier Revisited: Accessing Natural Limitations of\n  Recommender Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems nowadays have many applications and are of great economic\nbenefit. Hence, it is imperative for success-oriented companies to compare\ndifferent of such systems and select the better one for their purposes. To this\nend, various metrics of predictive accuracy are commonly used, such as the Root\nMean Square Error (RMSE), or precision and recall. All these metrics more or\nless measure how well a recommender system can predict human behaviour.\n  Unfortunately, human behaviour is always associated with some degree of\nuncertainty, making the evaluation difficult, since it is not clear whether a\ndeviation is system-induced or just originates from the natural variability of\nhuman decision making. At this point, some authors speculated that we may be\nreaching some Magic Barrier where this variability prevents us from getting\nmuch more accurate.\n  In this article, we will extend the existing theory of the Magic Barrier into\na new probabilistic but a yet pragmatic model. In particular, we will use\nmethods from metrology and physics to develop easy-to-handle quantities for\ncomputation to describe the Magic Barrier for different accuracy metrics and\nprovide suggestions for common application. This discussion is substantiated by\ncomprehensive experiments with real users and large-scale simulations on a\nhigh-performance cluster.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 16:57:25 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Jasberg", "Kevin", ""], ["Sizov", "Sergej", ""]]}, {"id": "1704.05915", "submitter": "Yuri G. Gordienko", "authors": "S. Stirenko, Yu. Gordienko, T. Shemsedinov, O. Alienin, Yu. Kochura,\n  N. Gordienko, A. Rojbi, J.R. L\\'opez Benito, E. Artetxe Gonz\\'alez", "title": "User-driven Intelligent Interface on the Basis of Multimodal Augmented\n  Reality and Brain-Computer Interaction for People with Functional\n  Disabilities", "comments": "10 pages, 11 figures, 1 table, submitted to Future of Information and\n  Communication Conference (FICC) 2018, 5-6 April 2018, Singapore", "journal-ref": "In: Arai K., Kapoor S., Bhatia R. (eds) Advances in Information\n  and Communication Networks. FICC 2018. Advances in Intelligent Systems and\n  Computing, vol 886, pp.612-631. Springer, Cham", "doi": "10.1007/978-3-030-03402-3_43", "report-no": null, "categories": "cs.HC cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the current integration attempts of some modes and use cases\nof user-machine interaction is presented. The new concept of the user-driven\nintelligent interface is proposed on the basis of multimodal augmented reality\nand brain-computer interaction for various applications: in disabilities\nstudies, education, home care, health care, etc. The several use cases of\nmultimodal augmentation are presented. The perspectives of the better human\ncomprehension by the immediate feedback through neurophysical channels by means\nof brain-computer interaction are outlined. It is shown that brain-computer\ninterface (BCI) technology provides new strategies to overcome limits of the\ncurrently available user interfaces, especially for people with functional\ndisabilities. The results of the previous studies of the low end consumer and\nopen-source BCI-devices allow us to conclude that combination of machine\nlearning (ML), multimodal interactions (visual, sound, tactile) with BCI will\nprofit from the immediate feedback from the actual neurophysical reactions\nclassified by ML methods. In general, BCI in combination with other modes of AR\ninteraction can deliver much more information than these types of interaction\nthemselves. Even in the current state the combined AR-BCI interfaces could\nprovide the highly adaptable and personal services, especially for people with\nfunctional disabilities.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 21:03:52 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 22:51:53 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Stirenko", "S.", ""], ["Gordienko", "Yu.", ""], ["Shemsedinov", "T.", ""], ["Alienin", "O.", ""], ["Kochura", "Yu.", ""], ["Gordienko", "N.", ""], ["Rojbi", "A.", ""], ["Benito", "J. R. L\u00f3pez", ""], ["Gonz\u00e1lez", "E. Artetxe", ""]]}, {"id": "1704.06127", "submitter": "Nikolaos K Tselios", "authors": "Anastasia Revythi and Nikolaos Tselios", "title": "Extension of Technology Acceptance Model by using System Usability Scale\n  to assess behavioral intention to use e-learning", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This study examines the acceptance of technology and behavioral intention to\nuse learning management systems (LMS). In specific, the aim of this research is\nto examine whether students ultimately accept and use educational learning\nsystems such as e-class and the impact of behavioral intention on their\ndecision to use them. An extended version of technology acceptance model has\nbeen proposed and used by employing the System Usability Scale to measure\nperceived ease of use. 345 university students participated in the study and\nthe data analysis was based on partial least squares method. The results were\nconfirmed in most of the research hypotheses. In particular, social norm,\nsystem access and self-efficacy significantly affect behavioral intention to\nuse. As a result, it is suggested that e-learning developers and stakeholders\nshould focus on these factors to increase acceptance and effectiveness of\nlearning management systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 13:18:08 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 13:29:13 GMT"}, {"version": "v3", "created": "Tue, 6 Feb 2018 13:07:25 GMT"}, {"version": "v4", "created": "Mon, 7 May 2018 22:23:13 GMT"}, {"version": "v5", "created": "Fri, 1 Jun 2018 14:50:03 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Revythi", "Anastasia", ""], ["Tselios", "Nikolaos", ""]]}, {"id": "1704.06399", "submitter": "Zhaokang Chen", "authors": "Zhaokang Chen and Bertram E. Shi", "title": "Using Variable Dwell Time to Accelerate Gaze-Based Web Browsing with\n  Two-Step Selection", "comments": "This is an Accepted Manuscript of an article published by Taylor &\n  Francis in the International Journal of Human-Computer Interaction on 30\n  March, 2018, available online:\n  http://www.tandfonline.com/10.1080/10447318.2018.1452351 . For an eprint of\n  the final published article, please access:\n  https://www.tandfonline.com/eprint/T9d4cNwwRUqXPPiZYm8Z/full", "journal-ref": null, "doi": "10.1080/10447318.2018.1452351", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to avoid the \"Midas Touch\" problem, gaze-based interfaces for\nselection often introduce a dwell time: a fixed amount of time the user must\nfixate upon an object before it is selected. Past interfaces have used a\nuniform dwell time across all objects. Here, we propose a gaze-based browser\nusing a two-step selection policy with variable dwell time. In the first step,\na command, e.g. \"back\" or \"select\", is chosen from a menu using a dwell time\nthat is constant across the different commands. In the second step, if the\n\"select\" command is chosen, the user selects a hyperlink using a dwell time\nthat varies between different hyperlinks. We assign shorter dwell times to more\nlikely hyperlinks and longer dwell times to less likely hyperlinks. In order to\ninfer the likelihood each hyperlink will be selected, we have developed a\nprobabilistic model of natural gaze behavior while surfing the web. We have\nevaluated a number of heuristic and probabilistic methods for varying the dwell\ntimes using both simulation and experiment. Our results demonstrate that\nvarying dwell time improves the user experience in comparison with fixed dwell\ntime, resulting in fewer errors and increased speed. While all of the methods\nfor varying dwell time resulted in improved performance, the probabilistic\nmodels yielded much greater gains than the simple heuristics. The best\nperforming model reduces error rate by 50% compared to 100ms uniform dwell time\nwhile maintaining a similar response time. It reduces response time by 60%\ncompared to 300ms uniform dwell time while maintaining a similar error rate.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 05:00:17 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 09:35:54 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 02:52:28 GMT"}, {"version": "v4", "created": "Tue, 3 Apr 2018 13:27:47 GMT"}, {"version": "v5", "created": "Thu, 5 Apr 2018 02:52:39 GMT"}, {"version": "v6", "created": "Thu, 29 Aug 2019 13:03:16 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Chen", "Zhaokang", ""], ["Shi", "Bertram E.", ""]]}, {"id": "1704.06860", "submitter": "Hien To", "authors": "Hien To, Cyrus Shahabi", "title": "Location Privacy in Spatial Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial crowdsourcing (SC) is a new platform that engages individuals in\ncollecting and analyzing environmental, social and other spatiotemporal\ninformation. With SC, requesters outsource their spatiotemporal tasks to a set\nof workers, who will perform the tasks by physically traveling to the tasks'\nlocations. This chapter identifies privacy threats toward both workers and\nrequesters during the two main phases of spatial crowdsourcing, tasking and\nreporting. Tasking is the process of identifying which tasks should be assigned\nto which workers. This process is handled by a spatial crowdsourcing server\n(SC-server). The latter phase is reporting, in which workers travel to the\ntasks' locations, complete the tasks and upload their reports to the SC-server.\nThe challenge is to enable effective and efficient tasking as well as reporting\nin SC without disclosing the actual locations of workers (at least until they\nagree to perform a task) and the tasks themselves (at least to workers who are\nnot assigned to those tasks). This chapter aims to provide an overview of the\nstate-of-the-art in protecting users' location privacy in spatial\ncrowdsourcing. We provide a comparative study of a diverse set of solutions in\nterms of task publishing modes (push vs. pull), problem focuses (tasking and\nreporting), threats (server, requester and worker), and underlying technical\napproaches (from pseudonymity, cloaking, and perturbation to exchange-based and\nencryption-based techniques). The strengths and drawbacks of the techniques are\nhighlighted, leading to a discussion of open problems and future work.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 00:09:11 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["To", "Hien", ""], ["Shahabi", "Cyrus", ""]]}, {"id": "1704.06956", "submitter": "Sida Wang", "authors": "Sida I. Wang and Samuel Ginn and Percy Liang and Christoper D. Manning", "title": "Naturalizing a Programming Language via Interactive Learning", "comments": "10 pages, ACL2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to create a convenient natural language interface for performing\nwell-specified but complex actions such as analyzing data, manipulating text,\nand querying databases. However, existing natural language interfaces for such\ntasks are quite primitive compared to the power one wields with a programming\nlanguage. To bridge this gap, we start with a core programming language and\nallow users to \"naturalize\" the core language incrementally by defining\nalternative, more natural syntax and increasingly complex concepts in terms of\ncompositions of simpler ones. In a voxel world, we show that a community of\nusers can simultaneously teach a common system a diverse language and use it to\nbuild hundreds of complex voxel structures. Over the course of three days,\nthese users went from using only the core language to using the naturalized\nlanguage in 85.9\\% of the last 10K utterances.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 18:13:10 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Wang", "Sida I.", ""], ["Ginn", "Samuel", ""], ["Liang", "Percy", ""], ["Manning", "Christoper D.", ""]]}, {"id": "1704.07436", "submitter": "Anand Malpani", "authors": "Anand Malpani, S. Swaroop Vedula, Henry C. Lin, Gregory D. Hager and\n  Russell H. Taylor", "title": "Real-time Teaching Cues for Automated Surgical Coaching", "comments": null, "journal-ref": null, "doi": "10.1007/s11548-020-02156-5", "report-no": null, "categories": "cs.RO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With introduction of new technologies in the operating room like the da Vinci\nSurgical System, training surgeons to use them effectively and efficiently is\ncrucial in the delivery of better patient care. Coaching by an expert surgeon\nis effective in teaching relevant technical skills, but current methods to\ndeliver effective coaching are limited and not scalable. We present a virtual\nreality simulation-based framework for automated virtual coaching in surgical\neducation. We implement our framework within the da Vinci Skills Simulator. We\nprovide three coaching modes ranging from a hands-on teacher (continuous\nguidance) to a handsoff guide (assistance upon request). We present six\nteaching cues targeted at critical learning elements of a needle passing task,\nwhich are shown to the user based on the coaching mode. These cues are\ngraphical overlays which guide the user, inform them about sub-par performance,\nand show relevant video demonstrations. We evaluated our framework in a pilot\nrandomized controlled trial with 16 subjects in each arm. In a post-study\nquestionnaire, participants reported high comprehension of feedback, and\nperceived improvement in performance. After three practice repetitions of the\ntask, the control arm (independent learning) showed better motion efficiency\nwhereas the experimental arm (received real-time coaching) had better\nperformance of learning elements (as per the ACS Resident Skills Curriculum).\nWe observed statistically higher improvement in the experimental group based on\none of the metrics (related to needle grasp orientation). In conclusion, we\ndeveloped an automated coach that provides real-time cues for surgical training\nand demonstrated its feasibility.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 19:54:34 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Malpani", "Anand", ""], ["Vedula", "S. Swaroop", ""], ["Lin", "Henry C.", ""], ["Hager", "Gregory D.", ""], ["Taylor", "Russell H.", ""]]}, {"id": "1704.07480", "submitter": "Tanmay Sinha", "authors": "Tanmay Sinha, Zhen Bai, Justine Cassell", "title": "A New Theoretical Framework for Curiosity for Learning in Social\n  Contexts", "comments": "14 pages, 1 figure, 12th European Conference on Technology Enhanced\n  Learning (ECTEL 2017)", "journal-ref": null, "doi": "10.1007/978-3-319-66610-5_19", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curiosity is a vital metacognitive skill in educational contexts. Yet, little\nis known about how social factors influence curiosity in group work. We argue\nthat curiosity is evoked not only through individual, but also interpersonal\nactivities, and present what we believe to be the first theoretical framework\nthat articulates an integrated socio-cognitive account of curiosity based on\nliterature spanning psychology, learning sciences and group dynamics, along\nwith empirical observation of small-group science activity in an informal\nlearning environment. We make a bipartite distinction between individual and\ninterpersonal functions that contribute to curiosity, and multimodal behaviors\nthat fulfill these functions. We validate the proposed framework by leveraging\na longitudinal latent variable modeling approach. Findings confirm positive\npredictive relationship of the latent variables of individual and interpersonal\nfunctions on curiosity, with the interpersonal functions exercising a\ncomparatively stronger influence. Prominent behavioral realizations of these\nfunctions are also discovered in a data-driven way. This framework is a step\ntowards designing learning technologies that can recognize and evoke curiosity\nduring learning in social contexts.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 22:20:11 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 19:09:44 GMT"}, {"version": "v3", "created": "Mon, 26 Jun 2017 02:14:52 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Sinha", "Tanmay", ""], ["Bai", "Zhen", ""], ["Cassell", "Justine", ""]]}, {"id": "1704.07506", "submitter": "Luca de Alfaro", "authors": "Eugenio Tacchini, Gabriele Ballarin, Marco L. Della Vedova, Stefano\n  Moret, Luca de Alfaro", "title": "Some Like it Hoax: Automated Fake News Detection in Social Networks", "comments": null, "journal-ref": "Proceedings of the Second Workshop on Data Science for Social Good\n  (SoGood), Skopje, Macedonia, 2017. CEUR Workshop Proceedings Volume 1960,\n  2017", "doi": null, "report-no": "Technical Report UCSC-SOE-17-05, School of Engineering, University\n  of California, Santa Cruz", "categories": "cs.LG cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho \"liked\" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 01:20:40 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Tacchini", "Eugenio", ""], ["Ballarin", "Gabriele", ""], ["Della Vedova", "Marco L.", ""], ["Moret", "Stefano", ""], ["de Alfaro", "Luca", ""]]}, {"id": "1704.08393", "submitter": "Eduardo Castell\\'o Ferrer", "authors": "Eduardo Castell\\'o Ferrer", "title": "A wearable general-purpose solution for Human-Swarm Interaction", "comments": "9 pages, 15 figures", "journal-ref": null, "doi": "10.1007/978-3-030-02683-7_78", "report-no": null, "categories": "cs.RO cs.HC cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Swarms of robots will revolutionize many industrial applications, from\ntargeted material delivery to precision farming. Controlling the motion and\nbehavior of these swarms presents unique challenges for human operators, who\ncannot yet effectively convey their high-level intentions to a group of robots\nin application. This work proposes a new human-swarm interface based on novel\nwearable gesture-control and haptic-feedback devices. This work seeks to\ncombine a wearable gesture recognition device that can detect high-level\nintentions, a portable device that can detect Cartesian information and finger\nmovements, and a wearable advanced haptic device that can provide real-time\nfeedback. This project is the first to envisage a wearable Human-Swarm\nInteraction (HSI) interface that separates the input and feedback components of\nthe classical control loop (input, output, feedback), as well as being the\nfirst of its kind suitable for both indoor and outdoor environments.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 00:57:50 GMT"}, {"version": "v2", "created": "Sat, 24 Jun 2017 23:59:32 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Ferrer", "Eduardo Castell\u00f3", ""]]}, {"id": "1704.08533", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Brent J. Lance and Vernon J. Lawhern and Stephen Gordon\n  and Tzyy-Ping Jung and Chin-Teng Lin", "title": "EEG-Based User Reaction Time Estimation Using Riemannian Geometry\n  Features", "comments": "arXiv admin note: text overlap with arXiv:1702.02914", "journal-ref": "IEEE Trans. on Neural Systems and Rehabilitation Engineering,\n  25(11), pp. 2157-2168, 2017", "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Riemannian geometry has been successfully used in many brain-computer\ninterface (BCI) classification problems and demonstrated superior performance.\nIn this paper, for the first time, it is applied to BCI regression problems, an\nimportant category of BCI applications. More specifically, we propose a new\nfeature extraction approach for Electroencephalogram (EEG) based BCI regression\nproblems: a spatial filter is first used to increase the signal quality of the\nEEG trials and also to reduce the dimensionality of the covariance matrices,\nand then Riemannian tangent space features are extracted. We validate the\nperformance of the proposed approach in reaction time estimation from EEG\nsignals measured in a large-scale sustained-attention psychomotor vigilance\ntask, and show that compared with the traditional powerband features, the\ntangent space features can reduce the root mean square estimation error by\n4.30-8.30%, and increase the estimation correlation coefficient by 6.59-11.13%.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 12:30:05 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Wu", "Dongrui", ""], ["Lance", "Brent J.", ""], ["Lawhern", "Vernon J.", ""], ["Gordon", "Stephen", ""], ["Jung", "Tzyy-Ping", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "1704.08735", "submitter": "Hugo Barbosa", "authors": "Ru Zhao, Vivian Li, Hugo Barbosa, Gourab Ghoshal and Mohammed (Ehsan)\n  Hoque", "title": "Semi-Automated & Collaborative Online Training Module For Improving\n  Communication Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a description and evaluation of the ROC Speak system, a\nplatform that allows ubiquitous access to communication skills training. ROC\nSpeak (available at rocspeak.com) enables anyone to go to a website, record a\nvideo, and receive feedback on smile intensity, body movement, volume\nmodulation, filler word usage, unique word usage, word cloud of the spoken\nwords, in addition to overall assessment and subjective comments by peers. Peer\ncomments are automatically ranked and sorted for usefulness and sentiment\n(i.e., positive vs. negative). We evaluated the system with a diverse group of\n56 online participants for a 10-day period. Participants submitted responses to\ncareer oriented prompts every other day. The participants were randomly split\ninto two groups: 1) treatment - full feedback from the ROC Speak system; 2)\ncontrol - written feedback from online peers. When judged by peers (p<.001) and\nindependent raters (p<.05), participants from the treatment group demonstrated\nstatistically significant improvement in overall speaking skills rating while\nthe control group did not. Furthermore, in terms of speaking attributes,\ntreatment group showed an improvement in friendliness (p<.001), vocal variety\n(p<.05) and articulation (p<.01).\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 20:23:50 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Zhao", "Ru", "", "Ehsan"], ["Li", "Vivian", "", "Ehsan"], ["Barbosa", "Hugo", "", "Ehsan"], ["Ghoshal", "Gourab", "", "Ehsan"], ["Mohammed", "", "", "Ehsan"], ["Hoque", "", ""]]}]