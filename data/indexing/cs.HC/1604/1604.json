[{"id": "1604.00071", "submitter": "Ruining He", "authors": "Ruining He, Chunbin Lin, Julian McAuley", "title": "Fashionista: A Fashion-aware Graphical System for Exploring Visually\n  Similar Items", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To build a fashion recommendation system, we need to help users retrieve\nfashionable items that are visually similar to a particular query, for reasons\nranging from searching alternatives (i.e., substitutes), to generating stylish\noutfits that are visually consistent, among other applications. In domains like\nclothing and accessories, such considerations are particularly paramount as the\nvisual appearance of items is a critical feature that guides users' decisions.\nHowever, existing systems like Amazon and eBay still rely mainly on keyword\nsearch and recommending loosely consistent items (e.g. based on co-purchasing\nor browsing data), without an interface that makes use of visual information to\nserve the above needs. In this paper, we attempt to fill this gap by designing\nand implementing an image-based query system, called Fashionista, which\nprovides a graphical interface to help users efficiently explore those items\nthat are not only visually similar to a given query, but which are also\nfashionable, as determined by visually-aware recommendation approaches.\nMethodologically, Fashionista learns a low-dimensional visual space as well as\nthe evolution of fashion trends from large corpora of binary feedback data such\nas purchase histories of Women's Clothing & Accessories from Amazon, which we\nuse for this demonstration.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 22:50:40 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["He", "Ruining", ""], ["Lin", "Chunbin", ""], ["McAuley", "Julian", ""]]}, {"id": "1604.00080", "submitter": "Lilong Jiang", "authors": "Eugene Wu, Lilong Jiang, Larry Xu, Arnab Nandi", "title": "Graphical Perception in Animated Bar Charts", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive visual applications create animations that encode changes in the\ndata. For example, cross-filtering dynamically updates linked visualizations\nbased on the user's continuous brushing actions. The animated effects resulting\nfrom these interactions depends both on how interaction (e.g., brushing speed)\ncontrols properties of the animation such as frame rate, as well as how the\ndata that is being explored dictates the data encoded in the animation. Past\nwork has found that frame rate matters to general perception, however a\ncritical question is which of these animation and data properties affects the\nperceptual accuracy of judgement tasks, and to what extent. Although graphical\nperception has been well studied for static data visualizations, it is ripe for\nexploration in the animated setting. We designed two animated judgment tasks of\na target bar in an animated bar chart and empirically evaluate the effects of 2\nanimations properties - highlighting of the target bar and frame rate - as well\nas 3 data properties that affect the target bar's value throughout the\nanimation. In short, we find that the rate and timing of animation changes is\neasier detected in larger values; that encodings such as color are easier to\ndetect than shapes; and that timing is important - earlier changes were harder\nto perceive as compared to later changes in the animation. Our results are an\ninitial step to understanding perceptual accuracy for animated data\nvisualizations, both for presentations and ultimately as part of interactive\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2016 23:34:59 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Wu", "Eugene", ""], ["Jiang", "Lilong", ""], ["Xu", "Larry", ""], ["Nandi", "Arnab", ""]]}, {"id": "1604.00312", "submitter": "S L Happy", "authors": "S L Happy, A. Dasgupta, P. Patnaik, A. Routray", "title": "Automated Alertness and Emotion Detection for Empathic Feedback During\n  E-Learning", "comments": "IEEE International Conference on Technology for Education, Kharagpur,\n  India, 2013", "journal-ref": "IEEE International Conference on Technology for Education, 2013", "doi": "10.1109/T4E.2013.19", "report-no": null, "categories": "cs.CV cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of education technology, empathic interaction with the user\nand feedback by the learning system using multiple inputs such as video, voice\nand text inputs is an important area of research. In this paper, a\nnonintrusive, standalone model for intelligent assessment of alertness and\nemotional state as well as generation of appropriate feedback has been\nproposed. Using the non-intrusive visual cues, the system classifies emotion\nand alertness state of the user, and provides appropriate feedback according to\nthe detected cognitive state using facial expressions, ocular parameters,\npostures, and gestures. Assessment of alertness level using ocular parameters\nsuch as PERCLOS and saccadic parameters, emotional state from facial expression\nanalysis, and detection of both relevant cognitive and emotional states from\nupper body gestures and postures has been proposed. Integration of such a\nsystem in e-learning environment is expected to enhance students performance\nthrough interaction, feedback, and positive mood induction.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 16:13:05 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Happy", "S L", ""], ["Dasgupta", "A.", ""], ["Patnaik", "P.", ""], ["Routray", "A.", ""]]}, {"id": "1604.00417", "submitter": "Georgios Askalidis", "authors": "Georgios Askalidis, Edward C. Malthouse", "title": "Understanding and Overcoming Biases in Customer Reviews", "comments": "15 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our paper contributes to the literature recommending approaches to make\nonline reviews more credible and representative. We analyze data from four\ndiverse major online retailers and find that verified customers who are\nprompted (by an email) to write a review, submit, on average, up to 0.5 star\nhigher ratings than self-motivated web reviewers. Moreover, these\nemail-prompted reviews remain stable over time, whereas web reviews exhibit a\ndownward trend. This finding provides support for the existence of social\ninfluence and selection biases during the submission of a web review, when\nsocial signals are being displayed. In contrast, no information about the\ncurrent state of the reviews is displayed in the email promptings. Moreover, we\nfind that when a retailer decides to start sending email promptings, the\nexisting population of web reviewers is unaffected both in their volume as well\nas the characteristics of their submitted reviews. We explore how our combined\nfindings can suggest ways to mitigate various biases that govern online review\nsubmissions and help practitioners provide more credible, representative and\nhigher ratings to their customers.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 21:55:57 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Askalidis", "Georgios", ""], ["Malthouse", "Edward C.", ""]]}, {"id": "1604.00921", "submitter": "Hussein Abbass A", "authors": "Hussein A. Abbass, George Leu, Kathryn Merrick", "title": "A Review of Theoretical and Practical Challenges of Trusted Autonomy in\n  Big Data", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2016.2571058", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advances made in artificial intelligence, software agents, and\nrobotics, there is little we see today that we can truly call a fully\nautonomous system. We conjecture that the main inhibitor for advancing autonomy\nis lack of trust. Trusted autonomy is the scientific and engineering field to\nestablish the foundations and ground work for developing trusted autonomous\nsystems (robotics and software agents) that can be used in our daily life, and\ncan be integrated with humans seamlessly, naturally and efficiently.\n  In this paper, we review this literature to reveal opportunities for\nresearchers and practitioners to work on topics that can create a leap forward\nin advancing the field of trusted autonomy. We focus the paper on the `trust'\ncomponent as the uniting technology between humans and machines. Our inquiry\ninto this topic revolves around three sub-topics: (1) reviewing and positioning\nthe trust modelling literature for the purpose of trusted autonomy; (2)\nreviewing a critical subset of sensor technologies that allow a machine to\nsense human states; and (3) distilling some critical questions for advancing\nthe field of trusted autonomy. The inquiry is augmented with conceptual models\nthat we propose along the way by recompiling and reshaping the literature into\nforms that enables trusted autonomous systems to become a reality. The paper\noffers a vision for a Trusted Cyborg Swarm, an extension of our previous\nCognitive Cyber Symbiosis concept, whereby humans and machines meld together in\na harmonious, seamless, and coordinated manner.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 11:00:23 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Abbass", "Hussein A.", ""], ["Leu", "George", ""], ["Merrick", "Kathryn", ""]]}, {"id": "1604.01105", "submitter": "Amit Sharma", "authors": "Amit Sharma, Dan Cosley", "title": "Distinguishing between Personal Preferences and Social Influence in\n  Online Activity Feeds", "comments": "13 pages, ACM CSCW 2016", "journal-ref": null, "doi": "10.1145/2818048.2819982", "report-no": null, "categories": "cs.SI cs.HC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many online social networks thrive on automatic sharing of friends'\nactivities to a user through activity feeds, which may influence the user's\nnext actions. However, identifying such social influence is tricky because\nthese activities are simultaneously impacted by influence and homophily. We\npropose a statistical procedure that uses commonly available network and\nobservational data about people's actions to estimate the extent of\ncopy-influence---mimicking others' actions that appear in a feed. We assume\nthat non-friends don't influence users; thus, comparing how a user's activity\ncorrelates with friends versus non-friends who have similar preferences can\nhelp tease out the effect of copy-influence.\n  Experiments on datasets from multiple social networks show that estimates\nthat don't account for homophily overestimate copy-influence by varying, often\nlarge amounts. Further, copy-influence estimates fall below 1% of total actions\nin all networks: most people, and almost all actions, are not affected by the\nfeed. Our results question common perceptions around the extent of\ncopy-influence in online social networks and suggest improvements to diffusion\nand recommendation models.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 01:16:30 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Sharma", "Amit", ""], ["Cosley", "Dan", ""]]}, {"id": "1604.01219", "submitter": "Yuting Qaing", "authors": "Yuting Qiang, Yanwei Fu, Yanwen Guo, Zhi-Hua Zhou and Leonid Sigal", "title": "Learning to Generate Posters of Scientific Papers", "comments": "in Proceedings of the 30th AAAI Conference on Artificial Intelligence\n  (AAAI'16), Phoenix, AZ, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.HC cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers often summarize their work in the form of posters. Posters\nprovide a coherent and efficient way to convey core ideas from scientific\npapers. Generating a good scientific poster, however, is a complex and time\nconsuming cognitive task, since such posters need to be readable, informative,\nand visually aesthetic. In this paper, for the first time, we study the\nchallenging problem of learning to generate posters from scientific papers. To\nthis end, a data-driven framework, that utilizes graphical models, is proposed.\nSpecifically, given content to display, the key elements of a good poster,\nincluding panel layout and attributes of each panel, are learned and inferred\nfrom data. Then, given inferred layout and attributes, composition of graphical\nelements within each panel is synthesized. To learn and validate our model, we\ncollect and make public a Poster-Paper dataset, which consists of scientific\npapers and corresponding posters with exhaustively labelled panels and\nattributes. Qualitative and quantitative results indicate the effectiveness of\nour approach.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 11:18:04 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Qiang", "Yuting", ""], ["Fu", "Yanwei", ""], ["Guo", "Yanwen", ""], ["Zhou", "Zhi-Hua", ""], ["Sigal", "Leonid", ""]]}, {"id": "1604.01331", "submitter": "Pragathi Praveena", "authors": "Pragathi Praveena, Jobin J Kavalam, Namita Jacob", "title": "A smartphone-based vision simulator", "comments": "3 pages, 4 image, 3rd International Conference on Biomedical\n  Engineering and Assistive Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulators, as tools that can clearly bring out the effect of impairment, are\ninvaluable in the design and development process of an assistive device.\nSimulators are vital in meeting high standards of accessibility. Described is\nour work on a smartphone-based vision simulator for diabetic retinopathy that\nis economic, portable, flexible and easy-to-use.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 17:00:59 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Praveena", "Pragathi", ""], ["Kavalam", "Jobin J", ""], ["Jacob", "Namita", ""]]}, {"id": "1604.01574", "submitter": "Ramanathan Subramanian", "authors": "Syed Omer Gilani, Ramanathan Subramanian, Yan Yan, David Melcher, Nicu\n  Sebe, Stefan Winkler", "title": "PET: An Eye-tracking Dataset for Animal-centric PASCAL Object Classes", "comments": "Int'l Conference on Multimedia and Expo 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present the Pascal animal classes Eye Tracking database. Our database\ncomprises eye movement recordings compiled from forty users for the bird, cat,\ncow, dog, horse and sheep {trainval} sets from the VOC 2012 image set.\nDifferent from recent eye-tracking databases such as\n\\cite{kiwon_cvpr13_gaze,PapadopoulosCKF14}, a salient aspect of PET is that it\ncontains eye movements recorded for both the free-viewing and visual search\ntask conditions. While some differences in terms of overall gaze behavior and\nscanning patterns are observed between the two conditions, a very similar\nnumber of fixations are observed on target objects for both conditions. As a\nutility application, we show how feature pooling around fixated locations\nenables enhanced (animal) object classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 11:15:35 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Gilani", "Syed Omer", ""], ["Subramanian", "Ramanathan", ""], ["Yan", "Yan", ""], ["Melcher", "David", ""], ["Sebe", "Nicu", ""], ["Winkler", "Stefan", ""]]}, {"id": "1604.01797", "submitter": "Andres Ledesma", "authors": "Andres Ledesma and Hannu Nieminen and P\\\"aivi Valve and Miikka Ermes\n  and Holly Jimison and Misha Pavel", "title": "The shape of health: A comparison of five alternative ways of\n  visualizing personal health and wellbeing", "comments": "in Engineering in Medicine and Biology Society (EMBC), 2015 37th\n  Annual International Conference of the IEEE", "journal-ref": null, "doi": "10.1109/EMBC.2015.7320161", "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The combination of clinical and personal health and wellbeing data can tell\nus much about our behaviors, risks and overall status. The way this data is\nvisualized may affect our understanding of our own health. To study this\neffect, we conducted a small experiment with 30 participants in which we\npresented a holistic overview of the health and wellbeing of two modeled\nindividuals, one of them with metabolic syndrome. We used an insight-based\nmethodology to assess the effectiveness of the visualizations. The results show\nthat adequate visualization of holistic health data helps users without medical\nbackground to better understand the overall health situation and possible\nhealth risks related to lifestyles. Furthermore, we found that the application\nof insight-based methodology in the health and wellbeing domain remains\nunexplored and additional research and methodology development are needed.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 20:17:43 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Ledesma", "Andres", ""], ["Nieminen", "Hannu", ""], ["Valve", "P\u00e4ivi", ""], ["Ermes", "Miikka", ""], ["Jimison", "Holly", ""], ["Pavel", "Misha", ""]]}, {"id": "1604.01985", "submitter": "Stefan Ultes", "authors": "Stefan Ultes, Alexander Schmitt, and Wolfgang Minker", "title": "Analysis of Temporal Features for Interaction Quality Estimation", "comments": "7th International Workshop on Spoken Dialogue Systems (IWSDS), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many different approaches for estimating the Interaction Quality (IQ) of\nSpoken Dialogue Systems have been investigated. While dialogues clearly have a\nsequential nature, statistical classification approaches designed for\nsequential problems do not seem to work better on automatic IQ estimation than\nstatic approaches, i.e., regarding each turn as being independent of the\ncorresponding dialogue. Hence, we analyse this effect by investigating the\nsubset of temporal features used as input for statistical classification of IQ.\nWe extend the set of temporal features to contain the system and the user view.\nWe determine the contribution of each feature sub-group showing that temporal\nfeatures contribute most to the classification performance. Furthermore, for\nthe feature sub-group modeling the temporal effects with a window, we modify\nthe window size increasing the overall performance significantly by +15.69%.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 13:05:16 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Ultes", "Stefan", ""], ["Schmitt", "Alexander", ""], ["Minker", "Wolfgang", ""]]}, {"id": "1604.02005", "submitter": "Yaohua Xie", "authors": "Yaohua Xie, Danli Wang, Li Hao", "title": "MPP3D: Multi-Precision Pointing using the 3rd Dimension", "comments": "10 pages, 16 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant pointing is still not efficient, accurate or flexible enough for many\napplications, although many researchers have focused on it. To improve upon\ndistant pointing, we propose MPP3D, which is especially suitable for\nhigh-resolution displays. MPP3D uses two dimensions of hand positioning to move\na pointer, and it also uses the third dimension to adjust the precision of the\nmovement. Based on the idea of MPP3D, we propose four techniques which combine\ntwo ways of mapping and two techniques for precision adjustment. We further\nprovide three types of mapping scheme and visual feedback for each technique.\nThe potential of the proposed techniques was investigated through\nexperimentation. The results show that these techniques were competent for\nusual computer operations with a cursor, and the adjustment for pointing\nprecision was beneficial for both pointing efficiency and accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 14:06:18 GMT"}, {"version": "v2", "created": "Fri, 8 Apr 2016 05:16:05 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Xie", "Yaohua", ""], ["Wang", "Danli", ""], ["Hao", "Li", ""]]}, {"id": "1604.02006", "submitter": "Ann Drobnis", "authors": "Vasant G. Honavar, Mark D. Hill, and Katherine Yelick", "title": "Accelerating Science: A Computing Research Agenda", "comments": "Computing Community Consortium (CCC) white paper, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of \"big data\" offers unprecedented opportunities for not only\naccelerating scientific advances but also enabling new modes of discovery.\nScientific progress in many disciplines is increasingly enabled by our ability\nto examine natural phenomena through the computational lens, i.e., using\nalgorithmic or information processing abstractions of the underlying processes;\nand our ability to acquire, share, integrate and analyze disparate types of\ndata. However, there is a huge gap between our ability to acquire, store, and\nprocess data and our ability to make effective use of the data to advance\ndiscovery. Despite successful automation of routine aspects of data management\nand analytics, most elements of the scientific process currently require\nconsiderable human expertise and effort. Accelerating science to keep pace with\nthe rate of data acquisition and data processing calls for the development of\nalgorithmic or information processing abstractions, coupled with formal methods\nand tools for modeling and simulation of natural processes as well as major\ninnovations in cognitive tools for scientists, i.e., computational tools that\nleverage and extend the reach of human intellect, and partner with humans on a\nbroad range of tasks in scientific discovery (e.g., identifying, prioritizing\nformulating questions, designing, prioritizing and executing experiments\ndesigned to answer a chosen question, drawing inferences and evaluating the\nresults, and formulating new questions, in a closed-loop fashion). This calls\nfor concerted research agenda aimed at: Development, analysis, integration,\nsharing, and simulation of algorithmic or information processing abstractions\nof natural processes, coupled with formal methods and tools for their analyses\nand simulation; Innovations in cognitive tools that augment and extend human\nintellect and partner with humans in all aspects of science.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 18:43:00 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Honavar", "Vasant G.", ""], ["Hill", "Mark D.", ""], ["Yelick", "Katherine", ""]]}, {"id": "1604.02287", "submitter": "David Garcia", "authors": "David Garcia and Markus Strohmaier", "title": "The QWERTY effect on the web: How typing shapes the meaning of words in\n  online human-computer interaction", "comments": "In International WWW Conference, 2016. April 11-15, 2016, Montreal,\n  Quebec, Canada. 978-1-4503-4143-1/16/04", "journal-ref": null, "doi": "10.1145/2872427.2883019", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The QWERTY effect postulates that the keyboard layout influences word\nmeanings by linking positivity to the use of the right hand and negativity to\nthe use of the left hand. For example, previous research has established that\nwords with more right hand letters are rated more positively than words with\nmore left hand letters by human subjects in small scale experiments. In this\npaper, we perform large scale investigations of the QWERTY effect on the web.\nUsing data from eleven web platforms related to products, movies, books, and\nvideos, we conduct observational tests whether a hand-meaning relationship can\nbe found in decoding text on the web. Furthermore, we investigate whether\nencoding text on the web exhibits the QWERTY effect as well, by analyzing the\nrelationship between the text of online reviews and their star ratings in four\nadditional datasets. Overall, we find robust evidence for the QWERTY effect\nboth at the point of text interpretation (decoding) and at the point of text\ncreation (encoding). We also find under which conditions the effect might not\nhold. Our findings have implications for any algorithmic method aiming to\nevaluate the meaning of words on the web, including for example semantic or\nsentiment analysis, and show the existence of \"dactilar onomatopoeias\" that\nshape the dynamics of word-meaning associations. To the best of our knowledge,\nthis is the first work to reveal the extent to which the QWERTY effect exists\nin large scale human-computer interaction on the web.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 09:54:36 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Garcia", "David", ""], ["Strohmaier", "Markus", ""]]}, {"id": "1604.02892", "submitter": "Kim J.L. Nevelsteen", "authors": "Kim J.L. Nevelsteen", "title": "Distributed Technology-Sustained Pervasive Applications", "comments": "64 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": "15-016", "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Technology-sustained pervasive games, contrary to technology-supported\npervasive games, can be understood as computer games interfacing with the\nphysical world. Pervasive games are known to make use of 'non-standard input\ndevices' and with the rise of the Internet of Things (IoT), pervasive\napplications can be expected to move beyond games. This dissertation is\nrequirements- and development-focused Design Science research for distributed\ntechnology-sustained pervasive applications, incorporating knowledge from the\ndomains of Distributed Computing, Mixed Reality, Context-Aware Computing,\nGeographical Information Systems and IoT. Computer video games have existed for\ndecades, with a reusable game engine to drive them. If pervasive games can be\nunderstood as computer games interfacing with the physical world, can computer\ngame engines be used to stage pervasive games? Considering the use of\nnon-standard input devices in pervasive games and the rise of IoT, how will\nthis affect the architectures supporting the broader set of pervasive\napplications? The use of a game engine can be found in some existing pervasive\ngame projects, but general research into how the domain of pervasive games\noverlaps with that of video games is lacking. When an engine is used, a\ndiscussion of, what type of engine is most suitable and what properties are\nbeing fulfilled by the engine, is often not part of the discourse. This\ndissertation uses multiple iterations of the method framework for Design\nScience for the design and development of three software system architectures.\nIn the face of IoT, the problem of extending pervasive games into a fourth\nsoftware architecture, accommodating a broader set of pervasive applications,\nis explicated. The requirements, for technology-sustained pervasive games, are\nverified through the design, development and demonstration of the three\nsoftware system architectures. The ...\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 11:33:20 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Nevelsteen", "Kim J. L.", ""]]}, {"id": "1604.02935", "submitter": "Nathan Hodas", "authors": "Nathan Oken Hodas, Alex Endert", "title": "Adding Semantic Information into Data Models by Learning Domain\n  Expertise from User Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive visual analytic systems enable users to discover insights from\ncomplex data. Users can express and test hypotheses via user interaction,\nleveraging their domain expertise and prior knowledge to guide and steer the\nanalytic models in the system. For example, semantic interaction techniques\nenable systems to learn from the user's interactions and steer the underlying\nanalytic models based on the user's analytical reasoning. However, an open\nchallenge is how to not only steer models based on the dimensions or features\nof the data, but how to add dimensions or attributes to the data based on the\ndomain expertise of the user. In this paper, we present a technique for\ninferring and appending dimensions onto the dataset based on the prior\nexpertise of the user expressed via user interactions. Our technique enables\nusers to directly manipulate a spatial organization of data, from which both\nthe dimensions of the data are weighted, and also dimensions created to\nrepresent the prior knowledge the user brings to the system. We describe this\ntechnique and demonstrate its utility via a use case.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 18:15:49 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Hodas", "Nathan Oken", ""], ["Endert", "Alex", ""]]}, {"id": "1604.03019", "submitter": "Andreas Trier Poulsen", "authors": "Andreas Trier Poulsen, Simon Kamronn, Jacek Dmochowski, Lucas C.\n  Parra, and Lars Kai Hansen", "title": "EEG in the classroom: Synchronised neural recordings during video\n  presentation", "comments": "14 pages, 5 figures, 3 tables. Preprint version. Revision of original\n  preprint. Supplementary materials added as ancillary file", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We performed simultaneous recordings of electroencephalography (EEG) from\nmultiple students in a classroom, and measured the inter-subject correlation\n(ISC) of activity evoked by a common video stimulus. The neural reliability, as\nquantified by ISC, has been linked to engagement and attentional modulation in\nearlier studies that used high-grade equipment in laboratory settings. Here we\nreproduce many of the results from these studies using portable low-cost\nequipment, focusing on the robustness of using ISC for subjects experiencing\nnaturalistic stimuli. The present data shows that stimulus-evoked neural\nresponses, known to be modulated by attention, can be tracked in for groups of\nstudents with synchronized EEG acquisition. This is a step towards real-time\ninference of engagement in the classroom.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 16:19:16 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 14:07:43 GMT"}, {"version": "v3", "created": "Tue, 27 Dec 2016 21:38:47 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Poulsen", "Andreas Trier", ""], ["Kamronn", "Simon", ""], ["Dmochowski", "Jacek", ""], ["Parra", "Lucas C.", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1604.04389", "submitter": "Philippe Renevier Gonin", "authors": "Christian Brel (I3S, SPARKS), Philippe Renevier-Gonin (SPARKS, I3S)", "title": "Composing applications with OntoCompo", "comments": "d\\'emonstration \\`a la conf\\'erence IHM 2011", "journal-ref": "IHM 2011, 23\\`eme Conf\\'erence Francophone Sur l'Interaction Homme\n  Machine, Oct 2011, Biot, France. ACM, pp.141-144, 2011, IHM '11 Proceedings\n  of the 23rd Conference on l'Interaction Homme-Machine", "doi": "10.1145/2044354.2044384", "report-no": null, "categories": "cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an ontology-based approach to compose applications\nwhile preserving their former look. Our composition process relies on the\nmanipulation of User Interfaces (UI) and on several ontologies describing\nrelationships between tasks, UI and Functionalities. Our tool, called\nOntoCompo, supports compositions realized by the developer thanks to the\nselection, extraction and positioning of UI elements to constitute the\nnewapplication.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 07:42:39 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Brel", "Christian", "", "I3S, SPARKS"], ["Renevier-Gonin", "Philippe", "", "SPARKS, I3S"]]}, {"id": "1604.04721", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Juan M. Alberola, Elena Del Val, Victor Sanchez-Anguix, Alberto\n  Palomares and Maria Dolores Teruel", "title": "An artificial intelligence tool for heterogeneous team formation in the\n  classroom", "comments": null, "journal-ref": "Knowledge-Based Systems, 2016", "doi": "10.1016/j.knosys.2016.02.010", "report-no": null, "categories": "cs.AI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, there is increasing interest in the development of teamwork skills\nin the educational context. This growing interest is motivated by its\npedagogical effectiveness and the fact that, in labour contexts, enterprises\norganize their employees in teams to carry out complex projects. Despite its\ncrucial importance in the classroom and industry, there is a lack of support\nfor the team formation process. Not only do many factors influence team\nperformance, but the problem becomes exponentially costly if teams are to be\noptimized. In this article, we propose a tool whose aim it is to cover such a\ngap. It combines artificial intelligence techniques such as coalition structure\ngeneration, Bayesian learning, and Belbin's role theory to facilitate the\ngeneration of working groups in an educational context. This tool improves\ncurrent state of the art proposals in three ways: i) it takes into account the\nfeedback of other teammates in order to establish the most predominant role of\na student instead of self-perception questionnaires; ii) it handles uncertainty\nwith regard to each student's predominant team role; iii) it is iterative since\nit considers information from several interactions in order to improve the\nestimation of role assignments. We tested the performance of the proposed tool\nin an experiment involving students that took part in three different team\nactivities. The experiments suggest that the proposed tool is able to improve\ndifferent teamwork aspects such as team dynamics and student satisfaction.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 10:50:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Alberola", "Juan M.", ""], ["Del Val", "Elena", ""], ["Sanchez-Anguix", "Victor", ""], ["Palomares", "Alberto", ""], ["Teruel", "Maria Dolores", ""]]}, {"id": "1604.04749", "submitter": "Mohammad Allahbakhsh", "authors": "Mohammad Allahbakhsh, Saeed Arbabi, Hamid-Reza Motahari-Nezhad,\n  Boualem Benatallah", "title": "Big Data Analytics Using Cloud and Crowd", "comments": "19 pages, 1 figure. CSE UNSW Technical report", "journal-ref": null, "doi": null, "report-no": "UNSW-CSE-TR-201607", "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing application of social and human-enabled systems in people's\ndaily life from one side and from the other side the fast growth of mobile and\nsmart phones technologies have resulted in generating tremendous amount of\ndata, also referred to as big data, and a need for analyzing these data, i.e.,\nbig data analytics. Recently a trend has emerged to incorporate human computing\npower into big data analytics to solve some shortcomings of existing big data\nanalytics such as dealing with semi or unstructured data. Including crowd into\nbig data analytics creates some new challenges such as security, privacy and\navailability issues.\n  In this paper study hybrid human-machine big data analytics and propose a\nframework to study these systems from crowd involvement point of view. We\nidentify some open issues in the area and propose a set of research directions\nfor the future of big data analytics area.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 13:46:36 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Allahbakhsh", "Mohammad", ""], ["Arbabi", "Saeed", ""], ["Motahari-Nezhad", "Hamid-Reza", ""], ["Benatallah", "Boualem", ""]]}, {"id": "1604.04928", "submitter": "Yang Liu", "authors": "Yang Liu and Yiling Chen", "title": "Learning to Incentivize: Eliciting Effort via Output Agreement", "comments": "23 pages; short version is accepted to IJCAI 16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In crowdsourcing when there is a lack of verification for contributed\nanswers, output agreement mechanisms are often used to incentivize participants\nto provide truthful answers when the correct answer is hold by the majority. In\nthis paper, we focus on using output agreement mechanisms to elicit effort, in\naddition to eliciting truthful answers, from a population of workers. We\nconsider a setting where workers have heterogeneous cost of effort exertion and\nexamine the data requester's problem of deciding the reward level in output\nagreement for optimal elicitation. In particular, when the requester knows the\ncost distribution, we derive the optimal reward level for output agreement\nmechanisms. This is achieved by first characterizing Bayesian Nash equilibria\nof output agreement mechanisms for a given reward level. When the requester\ndoes not know the cost distribution, we develop sequential mechanisms that\ncombine learning the cost distribution with incentivizing effort exertion to\napproximately determine the optimal reward level.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 21:07:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Liu", "Yang", ""], ["Chen", "Yiling", ""]]}, {"id": "1604.05479", "submitter": "Andrew Connor", "authors": "Jacques Foottit, Dave Brown, Stefan Marks and Andy M. Connor", "title": "A wearable haptic game controller", "comments": null, "journal-ref": "International Journal of Game Theory & Technology, 2(1), 1-19\n  (2016)", "doi": "10.5121/ijgtt.2016.2101", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines the development of a wearable game controller\nincorporating vibrotacticle haptic feedback that provides a low cost, versatile\nand intuitive interface for controlling digital games. The device differs from\nmany traditional haptic feedback implementation in that it combines\nvibrotactile based haptic feedback with gesture based input, thus becoming a\ntwo way conduit between the user and the virtual environment. The device is\nintended to challenge what is considered an \"interface\" and draws on work in\nthe area of Actor-Network theory to purposefully blur the boundary between man\nand machine. This allows for a more immersive experience, so rather than making\nthe user feel like they are controlling an aircraft the intuitive interface\nallows the user to become the aircraft that is controlled by the movements of\nthe user's hand. This device invites playful action and thrill. It bridges new\nterritory on portable and low cost solutions for haptic controllers in a gaming\ncontext.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 09:04:34 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Foottit", "Jacques", ""], ["Brown", "Dave", ""], ["Marks", "Stefan", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.05572", "submitter": "Malte Paskuda", "authors": "Malte Paskuda and Myriam Lewkowicz", "title": "Does Anonymity Increase the Chance to Get Feedback?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To generate a hypothesis about the effects of anonymity on user participation\nin online communities, comments on Youtube were analysed for effects of the\nchange from allowing pseudonyms to Google+ with its real name policy. Small\ndifferences were detected, leading to the hypothesis that the option to remain\nanonymous leads to a less active environment for getting feedback, with less\npolite and less rude comments on the expense of neutral ones.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 14:01:57 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Paskuda", "Malte", ""], ["Lewkowicz", "Myriam", ""]]}, {"id": "1604.05791", "submitter": "Andrew Connor", "authors": "Jan Kruse, Ricardo Sosa and Andy M. Connor", "title": "Procedural urban environments for FPS games", "comments": null, "journal-ref": null, "doi": "10.1145/2843043.2843479", "report-no": null, "categories": "cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to procedural generation of urban maps\nfor First Person Shooter (FPS) games. A multi-agent evolutionary system is\nemployed to place streets, buildings and other items inside the Unity3D game\nengine, resulting in playable video game levels. A computational agent is\ntrained using machine learning techniques to capture the intent of the game\ndesigner as part of the multi-agent system, and to enable a semi-automated\naesthetic selection for the underlying genetic algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 02:39:04 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Kruse", "Jan", ""], ["Sosa", "Ricardo", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.05793", "submitter": "Andrew Connor", "authors": "Jenna Gavin and Andy M. Connor", "title": "Reinventing the Arcade: Computer Game Mediated Play Spaces for Physical\n  Interaction", "comments": null, "journal-ref": "EAI Endorsed Transactions on Creative Technologies 2(5) Paper e4\n  (2015)", "doi": "10.4108/eai.20-10-2015.150098", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper suggests that recent developments in video game technology have\noccurred in parallel to play being moved from public into private spaces, which\nhas had impact on the way people interact with games. The paper also argues and\nthat there is potentially value in the creation of public play spaces to create\nopportunities to utilise both technology and body for the benefit of community\nculture and experiences through gaming. Co-located social gaming coupled with\ntangible interfaces offer alternative possibilities for the local video game\nscene. This paper includes a descriptive account of Rabble Room Arcade, an\nexperimental social event combining custom-built tangible interface devices and\nmultiplayer video games. The event was designed around games that promoted a\nreturn to simplicity through the use of unique tangible controllers to allow\ncasual gamers to connect to the game and to each other, whilst also\ntransforming the event into a spectacle.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 02:46:23 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Gavin", "Jenna", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.05797", "submitter": "Andrew Connor", "authors": "Stefan Marks, Javier E. Estevez and Andy M. Connor", "title": "Towards the Holodeck: Fully Immersive Virtual Reality Visualisation of\n  Scientific and Engineering Data", "comments": null, "journal-ref": null, "doi": "10.1145/2683405.2683424", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the development and operating principles of an\nimmersive virtual reality (VR) visualisation environment that is designed\naround the use of consumer VR headsets in an existing wide area motion capture\nsuite. We present two case studies in the application areas of visualisation of\nscientific and engineering data. Each of these case studies utilise a different\nrender engine, namely a custom engine for one case and a commercial game engine\nfor the other. The advantages and appropriateness of each approach are\ndiscussed along with suggestions for future work.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 02:54:21 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Marks", "Stefan", ""], ["Estevez", "Javier E.", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.05942", "submitter": "Arash Tavakoli", "authors": "Arash Tavakoli, Haig Nalbandian, Nora Ayanian", "title": "Multiplayer Games for Learning Multirobot Coordination Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have an impressive ability to solve complex coordination problems in a\nfully distributed manner. This ability, if learned as a set of distributed\nmultirobot coordination strategies, can enable programming large groups of\nrobots to collaborate towards complex coordination objectives in a way similar\nto humans. Such strategies would offer robustness, adaptability,\nfault-tolerance, and, importantly, distributed decision-making. To that end, we\nhave designed a networked gaming platform to investigate human group behavior,\nspecifically in solving complex collaborative coordinated tasks. Through this\nplatform, we are able to limit the communication, sensing, and actuation\ncapabilities provided to the players. With the aim of learning coordination\nalgorithms for robots in mind, we define these capabilities to mimic those of a\nsimple ground robot.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 13:12:45 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Tavakoli", "Arash", ""], ["Nalbandian", "Haig", ""], ["Ayanian", "Nora", ""]]}, {"id": "1604.05957", "submitter": "Efthimios Bothos", "authors": "Evangelia Anagnostopoulou, Efthimios Bothos, Babis Magoutas, Johann\n  Schrammel, Gregoris Mentzas", "title": "Persuasive Technologies for Sustainable Urban Mobility", "comments": "Presented at the Persuasive 2016 Workshop \"Where are we bound for?\n  Persuasion in Transport Applications\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the persuasive interventions for inducing sustainable urban\nmobility behaviours has become a very active research field. This review paper\nsystematically analyses existing approaches and prototype systems and describes\nand classifies the persuasive strategies used for changing behaviour in the\ndomain of transport. It also studies the results and recommendations derived\nfrom pilot studies, and as a result of this analysis highlights the need for\npersonalizing and tailoring persuasive technology to various user\ncharacteristics. We also discuss the possible role of context-aware persuasive\nsystems for increasing the number of sustainable choices. Finally,\nrecommendations for future investigations on scholarly persuasive systems are\nproposed.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 13:45:55 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Anagnostopoulou", "Evangelia", ""], ["Bothos", "Efthimios", ""], ["Magoutas", "Babis", ""], ["Schrammel", "Johann", ""], ["Mentzas", "Gregoris", ""]]}, {"id": "1604.06157", "submitter": "Andrew Connor", "authors": "Jacques Foottit, Dave Brown, Stefan Marks and Andy M. Connor", "title": "An Intuitive Tangible Game Controller", "comments": "in Proceedings of the 2014 Conference on Interactive Entertainment", "journal-ref": null, "doi": "10.1145/2677758.2677774", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines the development of a sensory feedback device providing a\ntangible interface for controlling digital environments, in this example a\nflight simulator, where the intention for the device is that it is relatively\nlow cost, versatile and intuitive. Gesture based input allows for a more\nimmersive experience, so rather than making the user feel like they are\ncontrolling an aircraft the intuitive interface allows the user to become the\naircraft that is controlled by the movements of the user's hand. The movements\nare designed to allow a sense of immersion that would be difficult to achieve\nwith an alternative interface. A vibrotactile based haptic feedback is\nincorporated in the device to further enhance the connection between the user\nand the game environment by providing immediate confirmation of game events.\nWhen used for navigating an aircraft simulator, this device invites playful\naction and thrill. It bridges new territory on portable, low cost solutions for\nhaptic devices in gaming contexts.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 01:57:18 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Foottit", "Jacques", ""], ["Brown", "Dave", ""], ["Marks", "Stefan", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.06158", "submitter": "Andrew Connor", "authors": "Matthew Martin, James Charlton and Andy M. Connor", "title": "Augmented Body: Changing Interactive Body Play", "comments": null, "journal-ref": null, "doi": "10.1145/2677758.2677790", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the player's body as a system capable of unfamiliar\ninteractive movement achieved through digital mediation in a playful\nenvironment. Body interactions in both digital and non-digital environments can\nbe considered as a perceptually manipulative exploration of self. This implies\na player may alter how they perceive their body and its operations in order to\ncreate a new playful and original experience. This paper therefore questions\nhow player interaction can change as their perception of their body changes\nusing augmentative technology.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 02:02:13 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Martin", "Matthew", ""], ["Charlton", "James", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.06159", "submitter": "Andrew Connor", "authors": "Jenna Gavin, Ben Kenobi and Andy M. Connor", "title": "Social Play Spaces for Active Community Engagement", "comments": "arXiv admin note: substantial text overlap with arXiv:1604.05793", "journal-ref": null, "doi": "10.1145/2677758.2677789", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper puts forward the perspective that social play spaces are\nopportunities to utilise both technology and body for the benefit of community\nculture and engagement. Co-located social gaming coupled with tangible\ninterfaces offer active participant engagement and the development of the local\nvideo game scene. This paper includes a descriptive account of Rabble Room\nArcade, an experimental social event combining custom-built physical interface\ndevices and multiplayer video games.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 02:07:27 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Gavin", "Jenna", ""], ["Kenobi", "Ben", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.06252", "submitter": "Gangli Liu", "authors": "Gangli Liu", "title": "Knowledge model: a method to evaluate an individual's knowledge\n  quantitatively", "comments": "20 pages, LaTeX; supplements added, references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the quantity of human knowledge increasing rapidly, it is harder and\nharder to evaluate a knowledge worker's knowledge quantitatively. There are\nlots of demands for evaluating a knowledge worker's knowledge. For example,\naccurately finding out a researcher's research concentrations for the last\nthree years; searching for common topics for two scientists with different\nacademic backgrounds; helping a researcher discover his deficiencies on a\nresearch field etc. This paper proposes a method named knowledge model to\nevaluate a knowledge worker's knowledge quantitatively without taking an\nexamination. It records and analyzes an individual's each learning experience,\ndiscovering all the involved knowledge points and calculating their shares by\nanalyzing the text learning contents with topic model. It calculates a score\nfor a knowledge point by accumulating the effects of one's all learning\nexperiences about it. A preliminary knowledge evaluating system is developed to\ntestify the practicability of knowledge model.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 10:50:50 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 19:05:50 GMT"}, {"version": "v3", "created": "Sun, 18 Feb 2018 12:43:48 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Liu", "Gangli", ""]]}, {"id": "1604.06481", "submitter": "Yannis Kalantidis", "authors": "Yannis Kalantidis, Ayman Farahat, Lyndon Kennedy, Ricardo Baeza-Yates,\n  David A. Shamma", "title": "Visual Congruent Ads for Image Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of user experience online is affected by the relevance and\nplacement of advertisements. We propose a new system for selecting and\ndisplaying visual advertisements in image search result sets. Our method\ncompares the visual similarity of candidate ads to the image search results and\nselects the most visually similar ad to be displayed. The method further\nselects an appropriate location in the displayed image grid to minimize the\nperceptual visual differences between the ad and its neighbors. We conduct an\nexperiment with about 900 users and find that our proposed method provides\nsignificant improvement in the users' overall satisfaction with the image\nsearch experience, without diminishing the users' ability to see the ad or\nrecall the advertised brand.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 20:23:58 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Kalantidis", "Yannis", ""], ["Farahat", "Ayman", ""], ["Kennedy", "Lyndon", ""], ["Baeza-Yates", "Ricardo", ""], ["Shamma", "David A.", ""]]}, {"id": "1604.06899", "submitter": "Philipp Singer", "authors": "Philipp Singer, Emilio Ferrara, Farshad Kooti, Markus Strohmaier and\n  Kristina Lerman", "title": "Evidence of Online Performance Deterioration in User Sessions on Reddit", "comments": "Published in PlosOne", "journal-ref": "PLoS ONE 11(8): e0161636, 2016", "doi": "10.1371/journal.pone.0161636", "report-no": null, "categories": "cs.SI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents evidence of performance deterioration in online user\nsessions quantified by studying a massive dataset containing over 55 million\ncomments posted on Reddit in April 2015. After segmenting the sessions (i.e.,\nperiods of activity without a prolonged break) depending on their intensity\n(i.e., how many posts users produced during sessions), we observe a general\ndecrease in the quality of comments produced by users over the course of\nsessions. We propose mixed-effects models that capture the impact of session\nintensity on comments, including their length, quality, and the responses they\ngenerate from the community. Our findings suggest performance deterioration:\nSessions of increasing intensity are associated with the production of shorter,\nprogressively less complex comments, which receive declining quality scores (as\nrated by other users), and are less and less engaging (i.e., they attract fewer\nresponses). Our contribution evokes a connection between cognitive and\nattention dynamics and the usage of online social peer production platforms,\nspecifically the effects of deterioration of user performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Apr 2016 12:22:24 GMT"}, {"version": "v2", "created": "Fri, 26 Aug 2016 10:30:25 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Singer", "Philipp", ""], ["Ferrara", "Emilio", ""], ["Kooti", "Farshad", ""], ["Strohmaier", "Markus", ""], ["Lerman", "Kristina", ""]]}, {"id": "1604.07660", "submitter": "Haluk O. Bingol", "authors": "Dogukan Erenel and Haluk O. Bingol", "title": "An Accelerometer Based Calculator for Visually Impaired People Using\n  Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trend of touch-screen devices produces an accessibility barrier for\nvisually impaired people. On the other hand, these devices come with sensors\nsuch as accelerometer. This calls for new approaches to human computer\ninterface (HCI). In this study, our aim is to find an alternative approach to\nclassify 20 different hand gestures captured by iPhone 3GS's built-in\naccelerometer and make high accuracy on user-independent classifications using\nDynamic Time Warping (DTW) with dynamic warping window sizes. 20 gestures with\n1,100 gesture data are collected from 15 normal-visioned people. This data set\nis used for training. Experiment-1 based on this data set produced an accuracy\nrate of 96.7~\\%. In order for visually impaired people to use the system, a\ngesture recognition based \"talking\" calculator is implemented. In Experiment-2,\n4 visually impaired end-users used the calculator and obtained 95.5~\\% accuracy\nrate among 17 gestures with 720 gesture data totally. Contributions of the\ntechniques to the end result is also investigated. Dynamic warping window size\nis found to be the most effective one. The data and the code is available.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 12:55:28 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Erenel", "Dogukan", ""], ["Bingol", "Haluk O.", ""]]}, {"id": "1604.07906", "submitter": "Ruck Thawonmas", "authors": "YuXuan Jiang, Misaki Kaidan, Chun Yin Chu, Tomohiro Harada, and Ruck\n  Thawonmas", "title": "Procedural Generation of Angry Birds Levels using Building Constructive\n  Grammar with Chinese-Style and/or Japanese-Style Models", "comments": null, "journal-ref": "Proc. of ASIAGRAPH 2016, Toyama, Japan, pp. 53-54, Mar. 5-6, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a procedural generation method that creates visually\nattractive levels for the Angry Birds game. Besides being an immensely popular\nmobile game, Angry Birds has recently become a test bed for various artificial\nintelligence technologies. We propose a new approach for procedurally\ngenerating Angry Birds levels using Chinese style and Japanese style building\nstructures. A conducted experiment confirms the effectiveness of our approach\nwith statistical significance.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 02:21:28 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Jiang", "YuXuan", ""], ["Kaidan", "Misaki", ""], ["Chu", "Chun Yin", ""], ["Harada", "Tomohiro", ""], ["Thawonmas", "Ruck", ""]]}, {"id": "1604.08239", "submitter": "Sam Royston", "authors": "Sam Royston, Connor DeFanti and Ken Perlin", "title": "A Collaborative Untethered Virtual Reality Environment for Interactive\n  Social Network Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing prevalence of Virtual Reality technologies as a platform for\ngaming and video playback warrants research into how to best apply the current\nstate of the art to challenges in data visualization. Many current VR systems\nare noncollaborative, while data analysis and visualization is often a\nmulti-person process. Our goal in this paper is to address the technical and\nuser experience challenges that arise when creating VR environments for\ncollaborative data visualization. We focus on the integration of multiple\ntracking systems and the new interaction paradigms that this integration can\nenable, along with visual design considerations that apply specifically to\ncollaborative network visualization in virtual reality. We demonstrate a system\nfor collaborative interaction with large 3D layouts of Twitter friend/follow\nnetworks. The system is built by combining a 'Holojam' architecture (multiple\nGearVR Headsets within an OptiTrack motion capture stage) and Perception Neuron\nmotion suits, to offer an untethered, full-room multi-person visualization\nexperience.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 20:54:37 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Royston", "Sam", ""], ["DeFanti", "Connor", ""], ["Perlin", "Ken", ""]]}, {"id": "1604.08284", "submitter": "Yaohua Xie", "authors": "Yaohua Xie", "title": "Talk&Learn: Improving Conversation Experience and Creating Opportunities\n  for Foreign Language Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Real-Time Translation Interfaces (RTTI) do not provide experience as\nnatural and efficient as monolingual communication. Also, such systems do not\nprovide functions supporting language learning. This results in the waste of\nboth time and potential language context. In order to overcome the above\nlimitations, we propose a solution named \"Talk&Learn\". Its core idea is to\nrearrange (\"Delay-Match\") the real-time videos and translated texts or\nspeeches, so as to gain better naturalness and efficiency. At the same time,\nthis will create extra free time for users. So we further propose to utilize\nthe free time for contextual language learning.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 01:57:11 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Xie", "Yaohua", ""]]}, {"id": "1604.08322", "submitter": "Andrew Connor", "authors": "Jacques Foottit, Dave Brown, Stefan Marks and Andy M. Connor", "title": "Development of a wearable haptic game interface", "comments": "arXiv admin note: substantial text overlap with arXiv:1604.05479", "journal-ref": "EAI Endorsed Transactions on Creative Technologies, 3(6), e5\n  (2016)", "doi": "10.4108/eai.25-4-2016.151165", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines the development and evaluation of a wearable haptic game\ninterface. The device differs from many traditional haptic feedback\nimplementation in that it combines vibrotactile feedback with gesture based\ninput, thus becoming a two way conduit between the user and the virtual\nenvironment. The device is intended to challenge what is considered an\n\"interface\" and sets out to purposefully blur the boundary between man and\nmachine. This allows for a more immersive experience, and a user evaluation\nshows that the intuitive interface allows the user to become the aircraft that\nis controlled by the movements of the user's hand.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 07:01:59 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Foottit", "Jacques", ""], ["Brown", "Dave", ""], ["Marks", "Stefan", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.08620", "submitter": "Luca Giancardo PhD", "authors": "L. Giancardo, A. S\\'anchez-Ferro, T. Arroyo-Gallego, I. Butterworth,\n  C. S. Mendoza, P. Montero, M. Matarazzo, A. Obeso, M. L. Gray, San Jos\\'e\n  Est\\'epar", "title": "Computer keyboard interaction as an indicator of early Parkinson's\n  disease", "comments": "Available at: http://www.nature.com/articles/srep34468", "journal-ref": "Scientific Reports 6, Article number: 34468 (2016)", "doi": "10.1038/srep34468", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's disease (PD) is a slowly progressing neurodegenerative disease\nwith early manifestation of motor signs. Objective measurements of motor signs\nare of vital importance for diagnosing, monitoring and developing disease\nmodifying therapies, particularly for the early stages of the disease when\nputative neuroprotective treatments could stop neurodegeneration. Current\nmedical practice has limited tools to routinely monitor PD motor signs with\nenough frequency and without undue burden for patients and the healthcare\nsystem. In this paper, we present data indicating that the routine interaction\nwith computer keyboards can be used to detect motor signs in the early stages\nof PD. We explore a solution that measures the key hold times (the time\nrequired to press and release a key) during the normal use of a computer\nwithout any change in hardware and converts it to a PD motor index. This is\nachieved by the automatic discovery of patterns in the time series of key hold\ntimes using an ensemble regression algorithm. This new approach discriminated\nearly PD groups from controls with an AUC = 0.81 (n = 42/43; mean age =\n59.0/60.1; women = 43%/60%;PD/controls). The performance was comparable or\nbetter than two other quantitative motor performance tests used clinically:\nalternating finger tapping (AUC = 0.75) and single key tapping (AUC = 0.61).\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 21:13:25 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 16:10:38 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Giancardo", "L.", ""], ["S\u00e1nchez-Ferro", "A.", ""], ["Arroyo-Gallego", "T.", ""], ["Butterworth", "I.", ""], ["Mendoza", "C. S.", ""], ["Montero", "P.", ""], ["Matarazzo", "M.", ""], ["Obeso", "A.", ""], ["Gray", "M. L.", ""], ["Est\u00e9par", "San Jos\u00e9", ""]]}, {"id": "1604.08880", "submitter": "Shane Halloran", "authors": "Nils Y. Hammerla, Shane Halloran and Thomas Ploetz", "title": "Deep, Convolutional, and Recurrent Models for Human Activity Recognition\n  using Wearables", "comments": "Extended version has been accepted for publication at International\n  Joint Conference on Artificial Intelligence (IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition (HAR) in ubiquitous computing is beginning to\nadopt deep learning to substitute for well-established analysis techniques that\nrely on hand-crafted feature extraction and classification techniques. From\nthese isolated applications of custom deep architectures it is, however,\ndifficult to gain an overview of their suitability for problems ranging from\nthe recognition of manipulative gestures to the segmentation and identification\nof physical activities like running or ascending stairs. In this paper we\nrigorously explore deep, convolutional, and recurrent approaches across three\nrepresentative datasets that contain movement data captured with wearable\nsensors. We describe how to train recurrent approaches in this setting,\nintroduce a novel regularisation approach, and illustrate how they outperform\nthe state-of-the-art on a large benchmark dataset. Across thousands of\nrecognition experiments with randomly sampled model configurations we\ninvestigate the suitability of each model for different tasks in HAR, explore\nthe impact of hyperparameters using the fANOVA framework, and provide\nguidelines for the practitioner who wants to apply deep learning in their\nproblem setting.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 15:38:44 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Hammerla", "Nils Y.", ""], ["Halloran", "Shane", ""], ["Ploetz", "Thomas", ""]]}]