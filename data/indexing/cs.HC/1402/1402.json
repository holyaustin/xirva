[{"id": "1402.0200", "submitter": "David Coyle Dr", "authors": "Alison Burrows, Rachel Gooberman-Hill, Ian Craddock and David Coyle", "title": "SPHERE: Meaningful and Inclusive Sensor-Based Home Healthcare", "comments": "Presented at the ACM CSCW 2014 workshop on Designing with Users for\n  Domestic environments: Methods, Challenges, Lessons Learned", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given current demographic and health trends, and their economic implications,\nhome healthcare technology has become a fertile area for research and\ndevelopment. Motivated by the need for a radical reform of healthcare\nprovision, SPHERE is a large-scale Interdisciplinary Research Collaboration\nthat aims to develop home sensor systems to monitor people's health and\nwellbeing in the home. This paper outlines the unique circumstances of\ndesigning healthcare technology for the home environment, with a particular\nfocus on how to ensure future systems are meaningful to and desirable for the\nintended users.\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2014 15:15:30 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Burrows", "Alison", ""], ["Gooberman-Hill", "Rachel", ""], ["Craddock", "Ian", ""], ["Coyle", "David", ""]]}, {"id": "1402.0273", "submitter": "Siti Nurul Mahfuzah Mohamad", "authors": "Sazilah Salam, Siti Nurul Mahfuzah Mohamad, Norasiken Bakar, Linda\n  Khoo Mei Sui", "title": "The Designing of Online Multiple Intelligence Tools for Lecturers at\n  Polytechnic", "comments": "7 pages, 4 figures, 1 table, International Journal of Soft Computing\n  and Software Engineering [JSCSE], Vol. 3, No. 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the designing of Online Multiple Intelligence (MI)\nTeaching Tools for Polytechnic lecturers. These teaching tools can assist\nlecturers to create their own teaching materials without having any knowledge\nof Information Technology (IT) especially in programming. The theory of MI is\nused in this paper and this theory postulates that everybody has at least two\nor more intelligences. Multiple approaches embedded into a series of activities\nvia online teaching tools must be implemented in order to achieve effective\nteaching and learning in the classroom. The objectives of this paper are to\nidentify the relationship between the students self-perceived MI and their\nacademic achievement in Polytechnic, and design online MI tools for teaching at\nPolytechnic. This paper also addressed the theoretical framework and MI\nteaching activities. The instrument used for this study was Ujian Multiple\nIntelligence (UMI). The results showed Polytechnic students have strength in\nInterpersonal, Visual-Spatial and Verbal-Linguistic intelligences.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 03:13:49 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Salam", "Sazilah", ""], ["Mohamad", "Siti Nurul Mahfuzah", ""], ["Bakar", "Norasiken", ""], ["Sui", "Linda Khoo Mei", ""]]}, {"id": "1402.0672", "submitter": "Roshan Ragel", "authors": "A. K. B. Karunathilake, B. M. D. Balasuriya and R. G. Ragel", "title": "User Friendly Line CAPTCHAs", "comments": "6 pages", "journal-ref": "Industrial and Information Systems (ICIIS), 2009 International\n  Conference on , pp.210,215, 28-31 Dec. 2009", "doi": "10.1109/ICIINFS.2009.5429864", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CAPTCHAs or reverse Turing tests are real-time assessments used by programs\n(or computers) to tell humans and machines apart. This is achieved by assigning\nand assessing hard AI problems that could only be solved easily by human but\nnot by machines. Applications of such assessments range from stopping spammers\nfrom automatically filling online forms to preventing hackers from performing\ndictionary attack. Today, the race between makers and breakers of CAPTCHAs is\nat a juncture, where the CAPTCHAs proposed are not even answerable by humans.\nWe consider such CAPTCHAs as non user friendly. In this paper, we propose a\nnovel technique for reverse Turing test - we call it the Line CAPTCHAs - that\nmainly focuses on user friendliness while not compromising the security aspect\nthat is expected to be provided by such a system.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 09:39:32 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Karunathilake", "A. K. B.", ""], ["Balasuriya", "B. M. D.", ""], ["Ragel", "R. G.", ""]]}, {"id": "1402.0693", "submitter": "Kinjal Shah", "authors": "Kinjal N. Shah, Kirit R. Rathod, Shardul J. Agravat", "title": "A survey on Human Computer Interaction Mechanism Using Finger Tracking", "comments": "4 pages, 8 figures, International Journal of Computer Trends and\n  Technology (IJCTT)", "journal-ref": "IJCTT 7(3):174-177, January 2014", "doi": "10.14445/22312803/IJCTT-V7P148", "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Human Computer Interaction (HCI) is a field in which developer makes a user\nfriendly system. User can interact with a computer system without using any\nconventional peripheral devices. Marker is used to recognize hand movement\naccurately & successfully. Researchers establish the mechanism to interact with\ncomputer system using computer vision. The interaction is better than normal\nstatic keyboard and mouse. This paper represents most of innovative mechanisms\nof the finger tracking used to interact with a computer system using computer\nvision.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 11:13:56 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Shah", "Kinjal N.", ""], ["Rathod", "Kirit R.", ""], ["Agravat", "Shardul J.", ""]]}, {"id": "1402.1001", "submitter": "Tiago Guerreiro", "authors": "Hugo Nicolau, Jo\\~ao Guerreiro, Tiago Guerreiro", "title": "Stressing the Boundaries of Mobile Accessibility", "comments": "3 pages, two figures, ACM CHI 2013 Mobile Accessibility Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices gather the communication capabilities as no other gadget.\nPlus, they now comprise a wider set of applications while still maintaining\nreduced size and weight. They have started to include accessibility features\nthat enable the inclusion of disabled people. However, these inclusive efforts\nstill fall short considering the possibilities of such devices. This is mainly\ndue to the lack of interoperability and extensibility of current mobile\noperating systems (OS). In this paper, we present a case study of a\nmulti-impaired person where access to basic mobile applications was provided in\nan applicational basis. We outline the main flaws in current mobile OS and\nsuggest how these could further empower developers to provide accessibility\ncomponents. These could then be compounded to provide system-wide inclusion to\na wider range of (multi)-impairments.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 10:30:52 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Nicolau", "Hugo", ""], ["Guerreiro", "Jo\u00e3o", ""], ["Guerreiro", "Tiago", ""]]}, {"id": "1402.1036", "submitter": "Tiago Guerreiro", "authors": "Tiago Guerreiro", "title": "User-Sensitive Mobile Interfaces: Accounting for Individual Differences\n  amongst the Blind", "comments": "330 pages, PhD Thesis, Technical University of Lisbon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile phones pervade our daily lives and play ever expanding roles in many\ncontexts. Their ubiquitousness makes them pivotal in empowering disabled\npeople. However, if no inclusive approaches are provided, it becomes a strong\nvehicle of exclusion. Even though current solutions try to compensate for the\nlack of sight, not all information reaches the blind user. Good spatial ability\nis still required to make sense of the device and its interface, as well as the\nneed to memorize positions on screen or keys and associated actions in a\nkeypad. Those problems are compounded by many individual attributes such as\nage, age of blindness onset or tactile sensitivity which often are forgotten by\ndesigners. Worse, the entire blind population is recurrently thought of as\nhomogeneous (often stereotypically so). Thus all users face the same solutions,\nignoring their specific capabilities and needs. We usually ignore this\ndiversity as we have the ability to adapt and become experts in interfaces that\nwere probably maladjusted to begin with. This adaptation is not always within\nreach. Interaction with mobile devices is highly visually demanding which\nwidens this gap amongst blind people. It is paramount to understand the impact\nof individual differences and their relationship with demands to enable the\ndeployment of more inclusive solutions. We explore individual differences among\nblind people and assess how they are related with mobile interface demands,\nboth at low (e.g. performing an on-screen gesture) and high level (text-entry)\ntasks. Results confirmed that different ability levels have significant impact\non the performance attained by a blind person. Particularly, otherwise ignored\nattributes like tactile acuity, pressure sensitivity, spatial ability or verbal\nIQ have shown to be matched with specific mobile demands and parametrizations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 13:32:39 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Guerreiro", "Tiago", ""]]}, {"id": "1402.1037", "submitter": "Tiago Guerreiro", "authors": "Tiago Guerreiro, Hugo Nicolau, Jo\\~ao Oliveira, Joaquim Jorge, Daniel\n  Gon\\c{c}alves", "title": "Understanding Individual Differences: Towards Effective Mobile Interface\n  Design and Adaptation for the Blind", "comments": "3 pages, CHI 2011 Workshop on Dynamic Accessibility", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No two people are alike. We usually ignore this diversity as we have the\ncapability to adapt and, without noticing, become experts in interfaces that\nwere probably misadjusted to begin with. This adaptation is not always at the\nuser's reach. One neglected group is the blind. Spatial ability, memory, and\ntactile sensitivity are some characteristics that diverge between users.\nRegardless, all are presented with the same methods ignoring their capabilities\nand needs. Interaction with mobile devices is highly visually demanding which\nwidens the gap between blind people. Our research goal is to identify the\nindividual attributes that influence mobile interaction, considering the blind,\nand match them with mobile interaction modalities in a comprehensive and\nextensible design space. We aim to provide knowledge both for device design,\ndevice prescription and interface adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 5 Feb 2014 13:41:24 GMT"}], "update_date": "2014-02-06", "authors_parsed": [["Guerreiro", "Tiago", ""], ["Nicolau", "Hugo", ""], ["Oliveira", "Jo\u00e3o", ""], ["Jorge", "Joaquim", ""], ["Gon\u00e7alves", "Daniel", ""]]}, {"id": "1402.1243", "submitter": "Shafi'i Muhammad Abdulhamid Mr", "authors": "Shafii Muhammad Abdulhamid, Gana Usman", "title": "Destination Information Management System for Tourist", "comments": "8 pages. Computer Science and Telecommunications 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of information and communication technology in our day to day\nactivities is now unavoidable. In tourism developments, destination information\nand management systems are used to guide visitors and provide information to\nboth visitors and management of the tour sites. In this paper, information and\nnavigation system was designed for tourists, taking some Niger state of Nigeria\ntourism destinations into account. The information management system was\ndesigned using Java Applet (NetBeans IDE 6.1), Hypertext MarkUp Language\n(HTML), Personal Home Page (PHP), Java script and MySQL as the back-end\nintegration database. Two different MySQL servers were used, the MySQL query\nbrowser and the WAMP5 server to compare the effectiveness of the system\ndeveloped.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 04:30:39 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Abdulhamid", "Shafii Muhammad", ""], ["Usman", "Gana", ""]]}, {"id": "1402.1296", "submitter": "Tiago Guerreiro", "authors": "Ricardo Jo\\~ao Silveira Santos Gamboa", "title": "Mnemonical Body Shortcuts: Gestural Interface for Mobile Devices", "comments": "124 pages, MSc Thesis, Technical University of Lisbon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices' user interfaces are still quite similar to traditional\ninterfaces offered by desktop computers, but those can be highly problematic\nwhen used in a mobile context. Human gesture recognition in mobile interaction\nappears as an important area to provide suitable on-the-move usability. We\npresent a body space based approach to improve mobile device interaction and\nmobile performance, which we named as Mnemonical Body Shortcuts. The human body\nis presented as a rich repository of meaningful relations which are always\navailable to interact with. These body-based gestures allow the user to\nnaturally interact with mobile devices with no movement limitations.\nPreliminary studies using Radio Frequency Identification (RFID) technology were\nperformed, validating Mnemonical Body Shortcuts as an appropriate new mobile\ninteraction mechanism. Following those studies, we developed inertial sensing\nprototypes using an accelerometer, ending in the construction and user testing\nof a gestural interface for mobile devices capable of properly recognizing\nMnemonical Body Shortcuts and also providing suitable user control mechanisms\nand audio, visual and haptic feedback.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 09:54:25 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Gamboa", "Ricardo Jo\u00e3o Silveira Santos", ""]]}, {"id": "1402.1324", "submitter": "Tiago Guerreiro", "authors": "Ivo Rafael", "title": "UCAT: Ubiquitous Context Awareness Tools for The Blind", "comments": "93 pages, MSc Thesis, University of Lisbon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visually impaired people are often confronted with new environments and they\nfind themselves face to face with an innumerous amount of difficulties when\nfacing these environments. Having to surpass and deal with these difficulties\nthat arise with their condition is something that we can help diminish. They\nare one sense down when trying to understand their surrounding environments and\ngather information about what is happening around them. Nowadays, mobile\ndevices present significant computing and technological capacity which has been\nincreasing to the point where it is very common for most people to have access\nto a device with Bluetooth, GPS, Wi-Fi, and both high processing and storage\ncapacities. This allows us to think of applications that can do so much to help\npeople with difficulties. In the particular case of blind people, the lack of\nvisual information can be bypassed with other contextual information retrieved\nby their own personal devices. Our goal is to provide information to blind\nusers, be able to give them information about the context that surrounds them.\nWe wanted to provide the blind users with the tools to create information and\nbe able to share this information between each other, information about people,\nlocations or objects. Our approach was to split the project into a data and\ninformation gathering phase where we did our field search and interviewed and\nelaborated on how is the situation of environment perception for blind users,\nfollowed by a technical phase where we implement a system based on the first\nstage. Our results gathered from both the collecting phase and our implementing\nphase showed that there is potential to use these tools in the blind community\nand that they welcome the possibilities and horizons that it opens them.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 11:35:07 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Rafael", "Ivo", ""]]}, {"id": "1402.2149", "submitter": "Ben Khayut Z", "authors": "Ben Khayut, Lina Fabri and Maya Abukhana", "title": "Intelligent User Interface in Fuzzy Environment", "comments": "15 pages, 4 figures", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol. 5, No. 1, January 2014, pp. 63-78", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-Computer Interaction with the traditional User Interface is done using\na specified in advance script dialog menu, mainly based on human intellect and\nunproductive use of navigation. This approach does not lead to making\nqualitative decision in control systems, where the situations and processes\ncannot be structured in advance. Any dynamic changes in the controlled business\nprocess (as example, in organizational unit of the information fuzzy control\nsystem) make it necessary to modify the script dialogue in User Interface. This\ncircumstance leads to a redesign of the components of the User Interface and of\nthe entire control system. In the Intelligent User Interface, where the dialog\nsituations are unknown in advance, fuzzy structured and artificial intelligence\nis crucial, the redesign described above is impossible. To solve this and other\nproblems, we propose the data, information and knowledge based technology of\nSmart/ Intelligent User Interface (IUI) design, which interacts with users and\nsystems in natural and other languages, utilizing the principles of Situational\nControl and Fuzzy Logic theories, Artificial Intelligence, Linguistics,\nKnowledge Base technologies and others. The proposed technology of IUI design\nis defined by multi-agents of Situational Control and of data, information and\nknowledge, modelling of Fuzzy Logic Inference, Generalization, Representation\nand Explanation of knowledge, Planning and Decision-making, Dialog Control,\nReasoning and Systems Thinking, Fuzzy Control of organizational unit in\nreal-time, fuzzy conditions, heterogeneous domains, and multi-lingual\ncommunication under uncertainty and in Fuzzy Environment.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 14:00:56 GMT"}], "update_date": "2014-02-11", "authors_parsed": [["Khayut", "Ben", ""], ["Fabri", "Lina", ""], ["Abukhana", "Maya", ""]]}, {"id": "1402.3163", "submitter": "Xiaohao Yang", "authors": "Xiaohao Yang and Pavol Juhas and Christopher L. Farrow and Simon J. L.\n  Billinge", "title": "xPDFsuite: an end-to-end software solution for high throughput pair\n  distribution function transformation, visualization and analysis", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The xPDFsuite software program is described. It is for processing and\nanalyzing atomic pair distribution functions (PDF) from X-ray powder\ndiffraction data. It provides a convenient GUI for SrXplanr and PDFgetX3,\nallowing the users to easily obtain 1D diffraction pattern from raw 2D\ndiffraction images and then transform them to PDFs. It also bundles PDFgui\nwhich allows the users to create structure models and fit to the experiment\ndata. It is specially useful for working with large numbers of datasets such as\nfrom high throughout measurements. Some of the key features are: real time PDF\ntransformation and plotting; 2D waterfall, false color heatmap, and 3D contour\nplotting for multiple datasets; static and dynamic mask editing; geometric\ncalibration of powder diffraction image; configurations and project saving and\nloading; Pearson correlation analysis on selected datasets; written in Python\nand support multiple platforms.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 14:55:14 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2014 04:01:14 GMT"}, {"version": "v3", "created": "Mon, 23 Feb 2015 21:13:21 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Yang", "Xiaohao", ""], ["Juhas", "Pavol", ""], ["Farrow", "Christopher L.", ""], ["Billinge", "Simon J. L.", ""]]}, {"id": "1402.3657", "submitter": "V Karthikeyan VKK", "authors": "V. Karthikeyan, B. Praveen Kumar, S. Suresh Babu, R. Purusothaman,\n  shijin Thomas", "title": "A Narrative Vehicle Protection Representation for Vehicle Speed\n  Regulator Under Driver Exhaustion -- A Study", "comments": "4 pages 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driver fatigue is one of the important factors that cause traffic accidents,\nand the ever-increasing number due to diminished drivers vigilance level has\nbecome a problem of serious concern to society. Drivers with a diminished\nvigilance level suffer from a marked decline in their abilities of perception,\nrecognition, and vehicle control, and therefore pose serious danger to their\nown life and the lives of other people. Exhaustion resulting from sleep\ndeprivation or sleep disorders is an important factor in the creasing number of\naccidents. In this projected work, we discuss the various methods of the\nexisting and the proposed method based on a real time online safety prototype\nthat controls the vehicle speed under driver fatigue. The purpose of such a\nmodel is to advance a system to detect fatigue symptoms in drivers and control\nthe speed of vehicle to avoid accidents. This system was tested adequately with\nsubjects of different technology of various researchers finally the validity of\nthe proposed model for vehicle speed controller based on driver fatigue\ndetection is shown.\n", "versions": [{"version": "v1", "created": "Sat, 15 Feb 2014 06:51:00 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Karthikeyan", "V.", ""], ["Kumar", "B. Praveen", ""], ["Babu", "S. Suresh", ""], ["Purusothaman", "R.", ""], ["Thomas", "shijin", ""]]}, {"id": "1402.4410", "submitter": "Paniz Alipour Aghdam", "authors": "Paniz Alipour Aghdam and Reza Ravanmehr", "title": "A Novel Approach for Canvas Accessibility Problem in HTML5", "comments": "9 pages,8 Figures", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol 10,\n  2013, Page 116", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canvas is a pixel-based inherently inaccessible element in HTML5.Therefore\nweb users with vision disabilities cannot benefit from Canvas and its desired\nsemantics and functionality. Regarding to the Canvas application in designing\ninteractive graphical user interface, vision-impaired users may miss important\ninformation on web sites. This paper utilizes the content-based image retrieval\n(CBIR) technique as well as code mapping embedded in a Firefox extension to\npresent a novel approach in order to make Canvas interactive user interface\naccessible. This extension replaces Canvas with an accessible equivalent HTML\nenvironment. Unlike previously done works on Canvas accessibility, the proposed\napproach does not impose any rules on developers and designers during Canvas\ndesign.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 17:36:58 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Aghdam", "Paniz Alipour", ""], ["Ravanmehr", "Reza", ""]]}, {"id": "1402.4724", "submitter": "Onintra Poobrasert", "authors": "Onintra Poobrasert and Waragorn Gestubtim", "title": "Breaking Barriers: Assistive Technology Tool as Educational Software to\n  support Writing", "comments": "9 pages. IJCA 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preliminary report by Siriraj Hospital suggested that 6% of population\nwho are students in Thailand could be estimated to have learning disabilities.\nIt is therefore necessary for our institute to develop suitable ICT\ntechnologies to assist the education of these learning disabilities children.\nWe therefore developed a program called Thai Word Prediction Program. Thai Word\nPrediction program aims to assist students with learning disabilities in their\nwriting. After the usability engineering, we conducted the experiment with\nstudents with learning disabilities at the School in Bangkok. Hence, the\nresults indicated that all three students with learning disabilities in this\nstudy improved their ability of writing by 50%, 81.89% and 100% respectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 16:36:58 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Poobrasert", "Onintra", ""], ["Gestubtim", "Waragorn", ""]]}, {"id": "1402.5034", "submitter": "Lucas Paletta", "authors": "Sigal Sina, Sarit Kraus, Avi Rosenfeld", "title": "Using the Crowd to Generate Content for Scenario-Based Serious-Games", "comments": null, "journal-ref": null, "doi": null, "report-no": "IDGEI/2014/03", "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, scenario-based serious-games have become a main tool for\nlearning new skills and capabilities. An important factor in the development of\nsuch systems is the overhead in time, cost and human resources to manually\ncreate the content for these scenarios. We focus on how to create content for\nscenarios in medical, military, commerce and gaming applications where\nmaintaining the integrity and coherence of the content is integral for the\nsystem's success. To do so, we present an automatic method for generating\ncontent about everyday activities through combining computer science techniques\nwith the crowd. We use the crowd in three basic ways: to capture a database of\nscenarios of everyday activities, to generate a database of likely replacements\nfor specific events within that scenario, and to evaluate the resulting\nscenarios. We found that the generated scenarios were rated as reliable and\nconsistent by the crowd when compared to the scenarios that were originally\ncaptured. We also compared the generated scenarios to those created by\ntraditional planning techniques. We found that both methods were equally\neffective in generated reliable and consistent scenarios, yet the main\nadvantages of our approach is that the content we generate is more varied and\nmuch easier to create. We have begun integrating this approach within a\nscenario-based training application for novice investigators within the law\nenforcement departments to improve their questioning skills.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 15:33:03 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Sina", "Sigal", ""], ["Kraus", "Sarit", ""], ["Rosenfeld", "Avi", ""]]}, {"id": "1402.5045", "submitter": "Lucas Paletta", "authors": "Nicolas Sabouret, Haza\\\"el Jones, Magalie Ochs, Mathieu Chollet,\n  Catherine Pelachaud", "title": "Expressing social attitudes in virtual agents for social training games", "comments": null, "journal-ref": null, "doi": null, "report-no": "IDGEI/2014/11", "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of virtual agents in social coaching has increased rapidly in the\nlast decade. In order to train the user in different situations than can occur\nin real life, the virtual agent should be able to express different social\nattitudes. In this paper, we propose a model of social attitudes that enables a\nvirtual agent to reason on the appropriate social attitude to express during\nthe interaction with a user given the course of the interaction, but also the\nemotions, mood and personality of the agent. Moreover, the model enables the\nvirtual agent to display its social attitude through its non-verbal behaviour.\nThe proposed model has been developed in the context of job interview\nsimulation. The methodology used to develop such a model combined a theoretical\nand an empirical approach. Indeed, the model is based both on the literature in\nHuman and Social Sciences on social attitudes but also on the analysis of an\naudiovisual corpus of job interviews and on post-hoc interviews with the\nrecruiters on their expressed attitudes during the job interview.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 15:41:26 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Sabouret", "Nicolas", ""], ["Jones", "Haza\u00ebl", ""], ["Ochs", "Magalie", ""], ["Chollet", "Mathieu", ""], ["Pelachaud", "Catherine", ""]]}, {"id": "1402.5047", "submitter": "Lucas Paletta", "authors": "Stefano Piana, Alessandra Staglian\\`o, Francesca Odone, Alessandro\n  Verri, Antonio Camurri", "title": "Real-time Automatic Emotion Recognition from Body Gestures", "comments": null, "journal-ref": null, "doi": null, "report-no": "IDGEI/2014/02", "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although psychological research indicates that bodily expressions convey\nimportant affective information, to date research in emotion recognition\nfocused mainly on facial expression or voice analysis. In this paper we propose\nan approach to realtime automatic emotion recognition from body movements. A\nset of postural, kinematic, and geometrical features are extracted from\nsequences 3D skeletons and fed to a multi-class SVM classifier. The proposed\nmethod has been assessed on data acquired through two different systems: a\nprofessionalgrade optical motion capture system, and Microsoft Kinect. The\nsystem has been assessed on a \"six emotions\" recognition problem, and using a\nleave-one-subject-out cross validation strategy, reached an overall recognition\nrate of 61.3% which is very close to the recognition rate of 61.9% obtained by\nhuman observers. To provide further testing of the system, two games were\ndeveloped, where one or two users have to interact to understand and express\nemotions with their body.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 15:42:32 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Piana", "Stefano", ""], ["Staglian\u00f2", "Alessandra", ""], ["Odone", "Francesca", ""], ["Verri", "Alessandro", ""], ["Camurri", "Antonio", ""]]}, {"id": "1402.5187", "submitter": "Nordin Zakaria", "authors": "Chan-Yet Lai, Nordin Zakaria", "title": "Towards an Intelligent Framework for Pressure-based 3D Curve Drawing", "comments": "This paper was rejected from GI 2014. Comment from the chief\n  reviewer:All reviewers noted that the ideas behind this paper were promising,\n  but felt that research was not quite sufficiently developed...Although all\n  agreed that this idea is insightful and has the potential to lead to a\n  valuable contribution,... the idea is not yet sufficiently developed to\n  warrant publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pen pressure is an input channel typically available in tablet pen device. To\ndate, little attention has been paid to the use of pressure in the domain of\ngraphical interaction, its usage largely limited to drawing and painting\nprogram, typically for varying brush characteristic such as stroke width,\nopacity and color. In this paper, we explore the use of pressure in 3D curve\ndrawing. The act of controlling pressure using pen, pencil and brush in real\nlife appears effortless, but to mimic this natural ability to control pressure\nusing a pressure sensitive pen in the realm of electronic medium is difficult.\nPrevious pressure based interaction work have proposed various signal\nprocessing techniques to improve the accuracy in pressure control, but a\none-for-all signal processing solution tend not to work for different curve\ntypes. We propose instead a framework which applies signal processing\ntechniques tuned to individual curve type. A neural network classifier is used\nas a curve classifier. Based on the classification, a custom combination of\nsignal processing techniques is then applied. Results obtained point to the\nfeasibility and advantage of the approach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 02:09:32 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Lai", "Chan-Yet", ""], ["Zakaria", "Nordin", ""]]}, {"id": "1402.5255", "submitter": "Christian von der Weth", "authors": "Christian von der Weth, Manfred Hauswirth", "title": "Analysing Parallel and Passive Web Browsing Behavior and its Effects on\n  Website Metrics", "comments": "22 pages, 11 figures, 3 tables, 29 references. arXiv admin note: text\n  overlap with arXiv:1307.1542", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Getting deeper insights into the online browsing behavior of Web users has\nbeen a major research topic since the advent of the WWW. It provides useful\ninformation to optimize website design, Web browser design, search engines\nofferings, and online advertisement. We argue that new technologies and new\nservices continue to have significant effects on the way how people browse the\nWeb. For example, listening to music clips on YouTube or to a radio station on\nLast.fm does not require users to sit in front of their computer. Social media\nand networking sites like Facebook or micro-blogging sites like Twitter have\nattracted new types of users that previously were less inclined to go online.\nThese changes in how people browse the Web feature new characteristics which\nare not well understood so far. In this paper, we provide novel and unique\ninsights by presenting first results of DOBBS, our long-term effort to create a\ncomprehensive and representative dataset capturing online user behavior. We\nfirstly investigate the concepts of parallel browsing and passive browsing,\nshowing that browsing the Web is no longer a dedicated task for many users.\nBased on these results, we then analyze their impact on the calculation of a\nuser's dwell time -- i.e., the time the user spends on a webpage -- which has\nbecome an important metric to quantify the popularity of websites.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 11:15:02 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["von der Weth", "Christian", ""], ["Hauswirth", "Manfred", ""]]}]