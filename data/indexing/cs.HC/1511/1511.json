[{"id": "1511.01622", "submitter": "Nalin Asanka Gamagedara Arachchilage", "authors": "Nalin Asanka Gamagedara Arachchilage, Steve Love, Carsten Maple", "title": "Can a Mobile Game Teach Computer Users to Thwart Phishing Attacks?", "comments": "11 pages", "journal-ref": "International Journal for Infonomics (IJI), Volume 6, Issues 3/4,\n  ISSN: 1742 4712, pp. 720-730 (2013)", "doi": null, "report-no": null, "categories": "cs.CY cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phishing is an online fraudulent technique, which aims to steal sensitive\ninformation such as usernames, passwords and online banking details from its\nvictims. To prevent this, anti-phishing education needs to be considered. This\nresearch focuses on examining the effectiveness of mobile game based learning\ncompared to traditional online learning to thwart phishing threats. Therefore,\na mobile game prototype was developed based on the design introduced by\nArachchilage and Cole [3]. The game design aimed to enhance avoidance behaviour\nthrough motivation to thwart phishing threats. A website developed by\nAnti-Phishing Work Group (APWG) for the public Anti-phishing education\ninitiative was used as a traditional web based learning source. A think-aloud\nexperiment along with a pre- and post-test was conducted through a user study.\nThe study findings revealed that the participants who played the mobile game\nwere better able to identify fraudulent web sites compared to the participants\nwho read the website without any training.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 06:28:57 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Arachchilage", "Nalin Asanka Gamagedara", ""], ["Love", "Steve", ""], ["Maple", "Carsten", ""]]}, {"id": "1511.02281", "submitter": "Laurel Riek", "authors": "Laurel D. Riek", "title": "Robotics Technology in Mental Health Care", "comments": null, "journal-ref": "Artificial Intelligence in Behavioral Health and Mental Health\n  Care (2015) 185-203;", "doi": "10.1016/B978-0-12-420248-1.00008-8", "report-no": null, "categories": "cs.RO cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter discusses the existing and future use of robotics and\nintelligent sensing technology in mental health care. While the use of this\ntechnology is nascent in mental health care, it represents a potentially useful\ntool in the practitioner's toolbox. The goal of this chapter is to provide a\nbrief overview of the field, discuss the recent use of robotics technology in\nmental health care practice, explore some of the design issues and ethical\nissues of using robots in this space, and finally to explore the potential of\nemerging technology.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 01:58:51 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Riek", "Laurel D.", ""]]}, {"id": "1511.02590", "submitter": "Mathias Johanson", "authors": "Mathias Johanson", "title": "The Turing Test for Telepresence", "comments": "The International Journal of Multimedia and its Applications (IJMA),\n  Vol.7, No.4/5, October 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of high-end videoconferencing systems has improved significantly\nover the last few years enabling a class of applications known as\n\"telepresence\" wherein the users engaged in a communication session experience\na feeling of mutual presence in a shared virtual space. Telepresence systems\nhave reached a maturity level that seriously challenges the old familiar truism\nthat a face-to-face meeting is always better than a technology-mediated\nalternative. To explore the state of the art in telepresence technology and\noutline future opportunities, this paper proposes an optimality condition,\nexpressed as a \"Turing Test,\" whereby the subjective experience of using a\ntelepresence system is compared to the corresponding face-to-face situation.\nThe requirements and challenges of designing a system passing such a Turing\nTest for telepresence are analyzed with respect to the limits of human\nperception, and the feasibility of achieving this goal with currently available\nor near future technology is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 07:39:18 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Johanson", "Mathias", ""]]}, {"id": "1511.03193", "submitter": "Arkaitz Zubiaga", "authors": "Peter Tolmie, Rob Procter, Mark Rouncefield, Maria Liakata, Arkaitz\n  Zubiaga", "title": "Microblog Analysis as a Programme of Work", "comments": "Accepted for publication in ACM Transactions on Social Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a European project, PHEME, that requires the close analysis of\nTwitter-based conversations in order to look at the spread of rumors via social\nmedia, this paper has two objectives. The first of these is to take the\nanalysis of microblogs back to first principles and lay out what microblog\nanalysis should look like as a foundational programme of work. The other is to\ndescribe how this is of fundamental relevance to Human-Computer Interaction's\ninterest in grasping the constitution of people's interactions with technology\nwithin the social order. Our critical finding is that, despite some surface\nsimilarities, Twitter-based conversations are a wholly distinct social\nphenomenon requiring an independent analysis that treats them as unique\nphenomena in their own right, rather than as another species of conversation\nthat can be handled within the framework of existing Conversation Analysis.\nThis motivates the argument that Microblog Analysis be established as a\nfoundationally independent programme, examining the organizational\ncharacteristics of microblogging from the ground up. We articulate how aspects\nof this approach have already begun to shape our design activities within the\nPHEME project.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 17:36:29 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 15:42:31 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Tolmie", "Peter", ""], ["Procter", "Rob", ""], ["Rouncefield", "Mark", ""], ["Liakata", "Maria", ""], ["Zubiaga", "Arkaitz", ""]]}, {"id": "1511.03531", "submitter": "Alexander Kott", "authors": "Alexander Kott, Norbou Buchler, Kristin E. Schaefer", "title": "Kinetic and Cyber", "comments": "A version of this paper appeared as a book chapter in Cyber Defense\n  and Situational Awareness, Springer, 2014. Prepared by US Government\n  employees in their official duties; approved for public release, distribution\n  unlimited. Cyber Defense and Situational Awareness. Springer International\n  Publishing, 2014. 29-45", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare and contrast situation awareness in cyber warfare and in\nconventional, kinetic warfare. Situation awareness (SA) has a far longer\nhistory of study and applications in such areas as control of complex\nenterprises and in conventional warfare, than in cyber warfare. Far more is\nknown about the SA in conventional military conflicts, or adversarial\nengagements, than in cyber ones. By exploring what is known about SA in\nconventional, also commonly referred to as kinetic, battles, we may gain\ninsights and research directions relevant to cyber conflicts. We discuss the\nnature of SA in conventional (often called kinetic) conflict, review what is\nknown about this kinetic SA (KSA), and then offer a comparison with what is\ncurrently understood regarding the cyber SA (CSA). We find that challenges and\nopportunities of KSA and CSA are similar or at least parallel in several\nimportant ways. With respect to similarities, in both kinetic and cyber worlds,\nSA strongly impacts the outcome of the mission. Also similarly, cognitive\nbiases are found in both KSA and CSA. As an example of differences, KSA often\nrelies on commonly accepted, widely used organizing representation - map of the\nphysical terrain of the battlefield. No such common representation has emerged\nin CSA, yet.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 15:25:46 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Kott", "Alexander", ""], ["Buchler", "Norbou", ""], ["Schaefer", "Kristin E.", ""]]}, {"id": "1511.03603", "submitter": "Ali Mollahosseini", "authors": "Amir H. Kargar B., Ali Mollahosseini, Taylor Struemph, Wilson Pace,\n  Rodney D. Nielsen, Mohammad H. Mahoor", "title": "Automatic Measurement of Physical Mobility in Get-Up-and-Go Test Using\n  Kinect Sensor", "comments": "Published in: Engineering in Medicine and Biology Society (EMBC),\n  2014 36th Annual International Conference of the IEEE", "journal-ref": null, "doi": "10.1109/EMBC.2014.6944375", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Get-Up-and-Go Test is commonly used for assessing the physical mobility of\nthe elderly by physicians. This paper presents a method for automatic analysis\nand classification of human gait in the Get-Up-and-Go Test using a Microsoft\nKinect sensor. Two types of features are automatically extracted from the human\nskeleton data provided by the Kinect sensor. The first type of feature is\nrelated to the human gait (e.g., number of steps, step duration, and turning\nduration); whereas the other one describes the anatomical configuration (e.g.,\nknee angles, leg angle, and distance between elbows). These features\ncharacterize the degree of human physical mobility. State-of-the-art machine\nlearning algorithms (i.e. Bag of Words and Support Vector Machines) are used to\nclassify the severity of gaits in 12 subjects with ages ranging between 65 and\n90 enrolled in a pilot study. Our experimental results show that these features\ncan discriminate between patients who have a high risk for falling and patients\nwith a lower fall risk.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 18:58:11 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["B.", "Amir H. Kargar", ""], ["Mollahosseini", "Ali", ""], ["Struemph", "Taylor", ""], ["Pace", "Wilson", ""], ["Nielsen", "Rodney D.", ""], ["Mahoor", "Mohammad H.", ""]]}, {"id": "1511.04308", "submitter": "Cornelia Haisjackl", "authors": "Stefan Zugal, Jakob Pinggera", "title": "Low-Cost Eye-Trackers: Useful for Information Systems Research?", "comments": null, "journal-ref": "S. Zugal and J. Pinggera: Low-Cost Eye-Trackers: Useful for\n  Information Systems Research? In: Proc. Cognise'14, pp. 159-170, 2014", "doi": "10.1007/978-3-319-07869-4_14", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research investigating cognitive aspects of information systems is often\ndependent on detail-rich data. Eye-trackers promise to provide respective data,\nbut the associated costs are often beyond the researchers' budget. Recently,\neye-trackers have entered the market that promise eye-tracking support at a\nreasonable price. In this work, we explore whether such eye-trackers are of use\nfor information systems research and explore the accuracy of a low-cost\neye-tracker (Gazepoint GP3) in an empirical study. The results show that\nGazepoint GP3 is well suited for respective research, given that experimental\nmaterial acknowledges the limits of the eye-tracker. To foster replication and\ncomparison of results, all data, experimental material as well as the source\ncode developed for this study are made available online.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 15:50:37 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Zugal", "Stefan", ""], ["Pinggera", "Jakob", ""]]}, {"id": "1511.04664", "submitter": "Mohammad Abu Alsheikh", "authors": "Mohammad Abu Alsheikh, Ahmed Selim, Dusit Niyato, Linda Doyle, Shaowei\n  Lin, Hwee-Pink Tan", "title": "Deep Activity Recognition Models with Triaxial Accelerometers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread installation of accelerometers in almost all mobile\nphones and wearable devices, activity recognition using accelerometers is still\nimmature due to the poor recognition accuracy of existing recognition methods\nand the scarcity of labeled training data. We consider the problem of human\nactivity recognition using triaxial accelerometers and deep learning paradigms.\nThis paper shows that deep activity recognition models (a) provide better\nrecognition accuracy of human activities, (b) avoid the expensive design of\nhandcrafted features in existing systems, and (c) utilize the massive unlabeled\nacceleration samples for unsupervised feature extraction. Moreover, a hybrid\napproach of deep learning and hidden Markov models (DL-HMM) is presented for\nsequential activity recognition. This hybrid approach integrates the\nhierarchical representations of deep activity recognition models with the\nstochastic modeling of temporal sequences in the hidden Markov models. We show\nsubstantial recognition improvement on real world datasets over\nstate-of-the-art methods of human activity recognition using triaxial\naccelerometers.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 06:23:40 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2016 07:39:29 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Alsheikh", "Mohammad Abu", ""], ["Selim", "Ahmed", ""], ["Niyato", "Dusit", ""], ["Doyle", "Linda", ""], ["Lin", "Shaowei", ""], ["Tan", "Hwee-Pink", ""]]}, {"id": "1511.04750", "submitter": "Nikos Bikakis", "authors": "Nikos Bikakis, George Papastefanatos, Melina Skourla, Timos Sellis", "title": "A Hierarchical Aggregation Framework for Efficient Multilevel Visual\n  Exploration and Analysis", "comments": "Semantic Web Journal 2016 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data exploration and visualization systems are of great importance in the Big\nData era, in which the volume and heterogeneity of available information make\nit difficult for humans to manually explore and analyse data. Most traditional\nsystems operate in an offline way, limited to accessing preprocessed (static)\nsets of data. They also restrict themselves to dealing with small dataset\nsizes, which can be easily handled with conventional techniques. However, the\nBig Data era has realized the availability of a great amount and variety of big\ndatasets that are dynamic in nature; most of them offer API or query endpoints\nfor online access, or the data is received in a stream fashion. Therefore,\nmodern systems must address the challenge of on-the-fly scalable visualizations\nover large dynamic sets of data, offering efficient exploration techniques, as\nwell as mechanisms for information abstraction and summarization. In this work,\nwe present a generic model for personalized multilevel exploration and analysis\nover large dynamic sets of numeric and temporal data. Our model is built on top\nof a lightweight tree-based structure which can be efficiently constructed\non-the-fly for a given set of data. This tree structure aggregates input\nobjects into a hierarchical multiscale model. Considering different exploration\nscenarios over large datasets, the proposed model enables efficient multilevel\nexploration, offering incremental construction and prefetching via user\ninteraction, and dynamic adaptation of the hierarchies based on user\npreferences. A thorough theoretical analysis is presented, illustrating the\nefficiency of the proposed model. The proposed model is realized in a web-based\nprototype tool, called SynopsViz that offers multilevel visual exploration and\nanalysis over Linked Data datasets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 18:23:27 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2015 12:51:23 GMT"}, {"version": "v3", "created": "Fri, 22 Jan 2016 18:08:18 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2016 14:33:45 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Bikakis", "Nikos", ""], ["Papastefanatos", "George", ""], ["Skourla", "Melina", ""], ["Sellis", "Timos", ""]]}, {"id": "1511.05324", "submitter": "Milena Tsvetkova", "authors": "Milena Tsvetkova, Taha Yasseri, Eric T. Meyer, J. Brian Pickering,\n  Vegard Engen, Paul Walland, Marika L\\\"uders, Asbj{\\o}rn F{\\o}lstad, and\n  George Bravos", "title": "Understanding Human-Machine Networks: A Cross-Disciplinary Survey", "comments": "Forthcoming in ACM Computing Surveys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the current hyper-connected era, modern Information and Communication\nTechnology systems form sophisticated networks where not only do people\ninteract with other people, but also machines take an increasingly visible and\nparticipatory role. Such human-machine networks (HMNs) are embedded in the\ndaily lives of people, both for personal and professional use. They can have a\nsignificant impact by producing synergy and innovations. The challenge in\ndesigning successful HMNs is that they cannot be developed and implemented in\nthe same manner as networks of machines nodes alone, nor following a wholly\nhuman-centric view of the network. The problem requires an interdisciplinary\napproach. Here, we review current research of relevance to HMNs across many\ndisciplines. Extending the previous theoretical concepts of socio-technical\nsystems, actor-network theory, cyber-physical-social systems, and social\nmachines, we concentrate on the interactions among humans and between humans\nand machines. We identify eight types of HMNs: public-resource computing,\ncrowdsourcing, web search engines, crowdsensing, online markets, social media,\nmultiplayer online games and virtual worlds, and mass collaboration. We\nsystematically select literature on each of these types and review it with a\nfocus on implications for designing HMNs. Moreover, we discuss risks associated\nwith HMNs and identify emerging design and development trends.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 09:45:19 GMT"}, {"version": "v2", "created": "Wed, 18 Jan 2017 15:25:25 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Tsvetkova", "Milena", ""], ["Yasseri", "Taha", ""], ["Meyer", "Eric T.", ""], ["Pickering", "J. Brian", ""], ["Engen", "Vegard", ""], ["Walland", "Paul", ""], ["L\u00fcders", "Marika", ""], ["F\u00f8lstad", "Asbj\u00f8rn", ""], ["Bravos", "George", ""]]}, {"id": "1511.05672", "submitter": "Kemal Bicakci", "authors": "Yasin Uzun, Kemal Bicakci, Yusuf Uzunay", "title": "Could We Distinguish Child Users from Adults Using Keystroke Dynamics?", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant portion of contemporary computer users are children, who are\nvulnerable to threats coming from the Internet. To protect children from such\nthreats, in this study, we investigate how successfully typing data can be used\nto distinguish children from adults. For this purpose, we collect a dataset\ncomprising keystroke data of 100 users and show that distinguishing child\nInternet users from adults is possible using Keystroke Dynamics with equal\nerror rates less than 10 percent. However the error rates increase\nsignificantly when there are impostors in the system.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 07:06:55 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2016 21:12:54 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Uzun", "Yasin", ""], ["Bicakci", "Kemal", ""], ["Uzunay", "Yusuf", ""]]}, {"id": "1511.05737", "submitter": "Nitesh Goyal", "authors": "Nitesh Goyal, Susan R. Fussell", "title": "Designing for Collaborative Sensemaking: Leveraging Human Cognition For\n  Complex Tasks", "comments": "Conference. Companion of 15th IFIP TC 13 Human-Computer Interaction\n  INTERACT 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  My research aims to design systems for complex sensemaking by remotely\nlocated non-expert collaborators (crowds), to solve computationally hard\nproblems like crimes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 11:25:50 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 01:42:21 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Goyal", "Nitesh", ""], ["Fussell", "Susan R.", ""]]}, {"id": "1511.06001", "submitter": "Francesca Giordaniello", "authors": "Francesca Giordaniello", "title": "A pilot study on the daily control capability of s-EMG prosthetic hands\n  by amputees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface electromyography is a valid tool to gather muscular contraction\nsignals from intact and amputated subjects. Electromyographic signals can be\nused to control prosthetic devices in a noninvasive way distinguishing the\nmovements performed by the particular EMG electrodes activity. According to the\nliterature, several algorithms have been used to control prosthetic hands\nthrough s-EMG signals. The main issue is to correctly classify the signals\nacquired as the movement actually performed. This work presents a study on the\nSupport Vector Machine's performance in a short-time period, gained using two\ndifferent feature representation (Mean Absolute Value and Waveform Length) of\nthe sEMG signals. In particular, we paid close attention to the repeatability\nproblem, that is the capability to achieve a stable and satisfactory level of\naccuracy in repeated experiments. Results on a limited setting are encouraging,\nas they show an average accuracy above 73% even in the worst case scenario.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 22:13:39 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 10:06:14 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Giordaniello", "Francesca", ""]]}, {"id": "1511.06004", "submitter": "Mara Graziani Ms", "authors": "Mara Graziani", "title": "Studying the control of non invasive prosthetic hands over large time\n  spans", "comments": "10 pages, 18 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electromyography (EMG) signal is the electrical manifestation of a\nneuromuscular activation that provides access to physiological processes which\ncause the muscle to generate force and produce movement. Non invasive\nprostheses use such signals detected by the electrodes placed on the user's\nstump, as input to generate hand posture movements according to the intentions\nof the prosthesis wearer. The aim of this pilot study is to explore the\nrepeatability issue, i.e. the ability to classify 17 different hand postures,\nrepresented by EMG signal, across a time span of days by a control algorithm.\nData collection experiments lasted four days and signals were collected from\nthe forearm of a single subject. We find that Support Vector Machine (SVM)\nclassification results are high enough to guarantee a correct classification of\nmore than 10 postures in each moment of the considered time span.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 22:29:03 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Graziani", "Mara", ""]]}, {"id": "1511.06053", "submitter": "Nitesh Goyal", "authors": "Nitesh Goyal", "title": "Designing for Collaborative Sensemaking: Using Expert & Non-Expert Crowd", "comments": "conference in Companion of The Third AAAI Conference on Human\n  Computation and Crowdsourcing (HCOMP-2015). arXiv admin note: substantial\n  text overlap with arXiv:1511.05737", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crime solving is a domain where solution discovery is often serendipitous.\nUnstructured mechanisms, like Reddit, for crime solving through crowds have\nfailed so far. Mechanisms, collaborations, workflows, and micro-tasks necessary\nfor successful crime solving might also vary across different crimes.\nCognitively, while experts might have deeper domain knowledge, they might also\nfall prey to biased analysis. Non-experts, while lacking formal training, might\ninstead offer non-conventional perspectives requiring direction. The analytical\nprocess is itself an iterative process of foraging and sensemaking. Users would\nexplore to broaden solution space and narrow down to a solution iteratively\nuntil identifying the global maxima instead of local maxima. In this proposal,\nmy research aims to design systems for enabling complex sensemaking tasks that\nrequire collaboration between remotely located non-expert crowds with expert\ncrowds to compensate for their cognitive challenges and lack of training. This\nwould require better understanding of the structure, workflow, and micro-tasks\nnecessary for successful collaborations. This proposal builds upon previous\nwork on collaborative sensemaking between remote partners in lab experiments\nand endeavors to scale it across multiple team members, with varying expertise\nlevels.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 03:55:13 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 01:41:04 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Goyal", "Nitesh", ""]]}, {"id": "1511.06510", "submitter": "Renaud Gervais", "authors": "Renaud Gervais (Potioc), J\\'er\\'emy Frey (UB, LaBRI, Potioc), Alexis\n  Gay, Fabien Lotte (Potioc, LaBRI), Martin Hachet (Potioc, LaBRI)", "title": "TOBE: Tangible Out-of-Body Experience", "comments": null, "journal-ref": "Tangible, Embedded and Embodied Interaction (TEI), Feb 2016,\n  Eindhoven, Netherlands. 2016, \\&lt;http://www.tei-conf.org/16/\\&gt;.\n  \\&lt;10.1145/2839462.2839486\\&gt;", "doi": "10.1145/2839462.2839486", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a toolkit for creating Tangible Out-of-Body Experiences: exposing\nthe inner states of users using physiological signals such as heart rate or\nbrain activity. Tobe can take the form of a tangible avatar displaying live\nphysiological readings to reflect on ourselves and others. Such a toolkit could\nbe used by researchers and designers to create a multitude of potential\ntangible applications, including (but not limited to) educational tools about\nScience Technologies Engineering and Mathematics (STEM) and cognitive science,\nmedical applications or entertainment and social experiences with one or\nseveral users or Tobes involved. Through a co-design approach, we investigated\nhow everyday people picture their physiology and we validated the acceptability\nof Tobe in a scientific museum. We also give a practical example where two\nusers relax together, with insights on how Tobe helped them to synchronize\ntheir signals and share a moment.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 07:40:01 GMT"}], "update_date": "2016-08-06", "authors_parsed": [["Gervais", "Renaud", "", "Potioc"], ["Frey", "J\u00e9r\u00e9my", "", "UB, LaBRI, Potioc"], ["Gay", "Alexis", "", "Potioc, LaBRI"], ["Lotte", "Fabien", "", "Potioc, LaBRI"], ["Hachet", "Martin", "", "Potioc, LaBRI"]]}, {"id": "1511.06815", "submitter": "Ju Shen Dr.", "authors": "Xinzhong Lu, Ju Shen, Saverio Perugini, Jianjun Yang", "title": "An Immersive Telepresence System using RGB-D Sensors and Head Mounted\n  Display", "comments": "IEEE International Symposium on Multimedia 2015", "journal-ref": null, "doi": "10.1109/ISM.2015.108", "report-no": null, "categories": "cs.CV cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a tele-immersive system that enables people to interact with each\nother in a virtual world using body gestures in addition to verbal\ncommunication. Beyond the obvious applications, including general online\nconversations and gaming, we hypothesize that our proposed system would be\nparticularly beneficial to education by offering rich visual contents and\ninteractivity. One distinct feature is the integration of egocentric pose\nrecognition that allows participants to use their gestures to demonstrate and\nmanipulate virtual objects simultaneously. This functionality enables the\ninstructor to ef- fectively and efficiently explain and illustrate complex\nconcepts or sophisticated problems in an intuitive manner. The highly\ninteractive and flexible environment can capture and sustain more student\nattention than the traditional classroom setting and, thus, delivers a\ncompelling experience to the students. Our main focus here is to investigate\npossible solutions for the system design and implementation and devise\nstrategies for fast, efficient computation suitable for visual data processing\nand network transmission. We describe the technique and experiments in details\nand provide quantitative performance results, demonstrating our system can be\nrun comfortably and reliably for different application scenarios. Our\npreliminary results are promising and demonstrate the potential for more\ncompelling directions in cyberlearning.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 01:57:47 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Lu", "Xinzhong", ""], ["Shen", "Ju", ""], ["Perugini", "Saverio", ""], ["Yang", "Jianjun", ""]]}, {"id": "1511.07500", "submitter": "Volker Strobel", "authors": "Volker Strobel and Alexandra Kirsch", "title": "Planning in the Wild: Modeling Tools for PDDL", "comments": null, "journal-ref": "Strobel, Volker, and Alexandra Kirsch. \"Planning in the Wild:\n  Modeling Tools for PDDL.\" KI 2014: Advances in Artificial Intelligence.\n  Springer International Publishing, 2014. 273-284", "doi": "10.1007/978-3-319-11206-0_27", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though there are sophisticated AI planning algorithms, many integrated,\nlarge-scale projects do not use planning. One reason seems to be the missing\nsupport by engineering tools such as syntax highlighting and visualization. We\npropose myPDDL - a modular toolbox for efficiently creating PDDL domains and\nproblems. To evaluate myPDDL, we compare it to existing knowledge engineering\ntools for PDDL and experimentally assess its usefulness for novice PDDL users.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 22:49:08 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Strobel", "Volker", ""], ["Kirsch", "Alexandra", ""]]}, {"id": "1511.08464", "submitter": "Kim J.L. Nevelsteen", "authors": "Kim J.L. Nevelsteen", "title": "Virtual World, Defined from a Technological Perspective, and Applied to\n  Video Games, Mixed Reality and the Metaverse", "comments": "36 pages, 2 figures", "journal-ref": null, "doi": "10.1002/cav.1752", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is no generally accepted definition for a virtual world, with many\ncomplimentary terms and acronyms having emerged implying a virtual world.\nAdvances in systems architecture techniques such as, host migration of\ninstances, mobile ad-hoc networking, and distributed computing, bring in to\nquestion whether those architectures can actually support a virtual world.\nWithout a concrete definition, controversy ensues and it is problematic to\ndesign an architecture for a virtual world. Several researchers provided a\ndefinition but aspects of each definition are still problematic and simply can\nnot be applied to contemporary technologies. The approach of this article is to\nsample technologies using grounded theory, and obtain a definition for a\n`virtual world' that is directly applicable to technology. The obtained\ndefinition is compared with related work and used to classify advanced\ntechnologies, such as: a pseudo-persistent video game, a MANet, virtual and\nmixed reality, and the Metaverse. The results of this article include: a break\ndown of which properties set apart the various technologies; a definition that\nis validated by comparing it with other definitions; an ontology showing the\nrelation of the different complimentary terms and acronyms; and, the usage of\npseudo-persistence to categories those technologies which only mimic\npersistence.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 18:05:02 GMT"}, {"version": "v2", "created": "Sat, 7 May 2016 07:51:57 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Nevelsteen", "Kim J. L.", ""]]}, {"id": "1511.08844", "submitter": "Luiz Capretz Dr.", "authors": "Arif Raza, Luiz Fernando Capretz, Faheem Ahmed", "title": "An Empirical Study of Open Source Software Usability: The Industrial\n  Perspective", "comments": "arXiv admin note: text overlap with arXiv:1507.06882", "journal-ref": "International Journal of Open Source Software and Processes,\n  3(1):1-16, 2011", "doi": "10.4018/jossp.2011010101", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a sharp increase in the use of open source projects by\ncommon novice users; Open Source Software (OSS) is thus no longer a reserved\narena for software developers and computer gurus. Although user-centered\ndesigns are gaining popularity in OSS, usability is still not considered as one\nof the prime objectives in many design scenarios. In this paper, we analyze\nindustry users perception of usability factors, including understandability,\nlearnability, operability and attractiveness, on OSS usability. The research\nmodel of this empirical study establishes the relationship between the key\nusability factors and OSS usability from industrial perspective. In order to\nconduct the study, a data set of 105 industry users is included. The results of\nthe empirical investigation indicate the significance of the key factors for\nOSS usability.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 22:35:53 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Raza", "Arif", ""], ["Capretz", "Luiz Fernando", ""], ["Ahmed", "Faheem", ""]]}]