[{"id": "1507.01046", "submitter": "Allan Fowler Dr", "authors": "Allan Fowler", "title": "Understanding learning within a commercial video game: A case study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increasing interest in the debate on the value and\nrelevance using video games for learning. Some of the interest stems from\nfrustration with current educational methods. However, some of this interest\nalso stems from the observations of large numbers of children that play video\ngames. This paper finds that children can learn basic construction skills from\nplaying a video game called World of Goo. The study also employed novel\neye-tracking technology to measure endogenous eye blinks and eye gaze\nfixations. Measures of both these indicators of cognitive processing further\nsuggested that children in the study learned to play the two video games, World\nof Goo and Bad Piggies. Overall, the results of the study provide further\nsupport of the potential for children to learn by playing commercial video\ngames.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2015 22:42:48 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Fowler", "Allan", ""]]}, {"id": "1507.01057", "submitter": "Wang Hao", "authors": "Daqing Zhang, Hao Wang, Yasha Wang, Junyi Ma", "title": "Anti-Fall: A Non-intrusive and Real-time Fall Detector Leveraging CSI\n  from Commodity WiFi Devices", "comments": "13 pages,8 figures,corrected version, ICOST conference", "journal-ref": null, "doi": "10.1007/978-3-319-19312-0_15", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fall is one of the major health threats and obstacles to independent living\nfor elders, timely and reliable fall detection is crucial for mitigating the\neffects of falls. In this paper, leveraging the fine-grained Channel State\nInformation (CSI) and multi-antenna setting in commodity WiFi devices, we\ndesign and implement a real-time, non-intrusive, and low-cost indoor fall\ndetector, called Anti-Fall. For the first time, the CSI phase difference over\ntwo antennas is identified as the salient feature to reliably segment the fall\nand fall-like activities, both phase and amplitude information of CSI is then\nexploited to accurately separate the fall from other fall-like activities.\nExperimental results in two indoor scenarios demonstrate that Anti-Fall\nconsistently outperforms the state-of-the-art approach WiFall, with 10% higher\ndetection rate and 10% less false alarm rate on average.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2015 01:57:58 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Zhang", "Daqing", ""], ["Wang", "Hao", ""], ["Wang", "Yasha", ""], ["Ma", "Junyi", ""]]}, {"id": "1507.01147", "submitter": "Yan Wang", "authors": "Yan Wang, Sunghyun Cho, Jue Wang and Shih-Fu Chang", "title": "PanoSwarm: Collaborative and Synchronized Multi-Device Panoramic\n  Photography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking a picture has been traditionally a one-persons task. In this paper we\npresent a novel system that allows multiple mobile devices to work\ncollaboratively in a synchronized fashion to capture a panorama of a highly\ndynamic scene, creating an entirely new photography experience that encourages\nsocial interactions and teamwork. Our system contains two components: a client\napp that runs on all participating devices, and a server program that monitors\nand communicates with each device. In a capturing session, the server collects\nin realtime the viewfinder images of all devices and stitches them on-the-fly\nto create a panorama preview, which is then streamed to all devices as visual\nguidance. The system also allows one camera to be the host and to send direct\nvisual instructions to others to guide camera adjustment. When ready, all\ndevices take pictures at the same time for panorama stitching. Our preliminary\nstudy suggests that the proposed system can help users capture high quality\npanoramas with an enjoyable teamwork experience.\n  A demo video of the system in action is provided at\nhttp://youtu.be/PwQ6k_ZEQSs.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2015 21:31:54 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2015 03:08:24 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2015 13:28:08 GMT"}], "update_date": "2015-07-13", "authors_parsed": [["Wang", "Yan", ""], ["Cho", "Sunghyun", ""], ["Wang", "Jue", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1507.01148", "submitter": "Yan Wang", "authors": "Yan Wang, Jue Wang and Shih-Fu Chang", "title": "CamSwarm: Instantaneous Smartphone Camera Arrays for Collaborative\n  Photography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Camera arrays (CamArrays) are widely used in commercial filming projects for\nachieving special visual effects such as bullet time effect, but are very\nexpensive to set up. We propose CamSwarm, a low-cost and lightweight\nalternative to professional CamArrays for consumer applications. It allows the\nconstruction of a collaborative photography platform from multiple mobile\ndevices anywhere and anytime, enabling new capturing and editing experiences\nthat a single camera cannot provide. Our system allows easy team formation;\nuses real-time visualization and feedback to guide camera positioning; provides\na mechanism for synchronized capturing; and finally allows the user to\nefficiently browse and edit the captured imagery. Our user study suggests that\nCamSwarm is easy to use; the provided real-time guidance is helpful; and the\nfull system achieves high quality results promising for non-professional use.\n  A demo video is provided at https://www.youtube.com/watch?v=LgkHcvcyTTM.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2015 21:46:37 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2015 01:13:21 GMT"}], "update_date": "2015-07-10", "authors_parsed": [["Wang", "Yan", ""], ["Wang", "Jue", ""], ["Chang", "Shih-Fu", ""]]}, {"id": "1507.01282", "submitter": "Andres Monroy-Hernandez", "authors": "Andr\\'es Monroy-Hern\\'andez, Mitchel Resnick", "title": "Empowering Kids to Create and Share Programmable Media", "comments": "FEATURE: Empowering kids to create and share programmable media.\n  interactions. issue 15, volume 2 (March 2008), pages 50-53", "journal-ref": "Interactions 15, 2 (March 2008), 50-53", "doi": "10.1145/1340961.1340974", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article reflects on the first eight months of existence of the Scratch\nOnline Community by discussing the design rationale and learning theories\nunderlying Scratch and its website.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 22:01:50 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""], ["Resnick", "Mitchel", ""]]}, {"id": "1507.01284", "submitter": "Andres Monroy-Hernandez", "authors": "Benjamin Mako Hill, Andr\\'es Monroy-Hern\\'andez, Kristina R. Olson", "title": "Responses to remixing on a social media sharing website", "comments": "In Proceedings of the Fourth International AAAI Conference on Weblogs\n  and Social Media (ICWSM 2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we describe the ways participants of the Scratch online\ncommunity, primarily young people, engage in remixing of each others' shared\nanimations, games, and interactive projects. In particular, we try to answer\nthe following questions: How do users respond to remixing in a social media\nenvironment where remixing is explicitly permitted? What qualities of\noriginators and their projects correspond to a higher likelihood of plagiarism\naccusations? Is there a connection between plagiarism complaints and\nsimilarities between a remix and the work it is based on? Our findings indicate\nthat users have a very wide range of reactions to remixing and that as many\nusers react positively as accuse remixers of plagiarism. We test several\nhypotheses that might explain the high number of plagiarism accusations related\nto original project complexity, cumulative remixing, originators' integration\ninto remixing practice, and remixee-remixer project similarity, and find\nsupport for the first and last explanations.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 22:04:49 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Hill", "Benjamin Mako", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""], ["Olson", "Kristina R.", ""]]}, {"id": "1507.01285", "submitter": "Andres Monroy-Hernandez", "authors": "Andr\\'es Monroy-Hern\\'andez, Benjamin Mako Hill, Jazmin\n  Gonzalez-Rivero, Danah Boyd", "title": "Computers Can't Give Credit: How Automatic Attribution Falls Short in an\n  Online Remixing Community", "comments": "Proceedings of the SIGCHI Conference on Human Factors in Computing\n  Systems (CHI 2011), Best paper honorable mention, 10 pages", "journal-ref": null, "doi": "10.1145/1978942.1979452", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we explore the role that attribution plays in shaping user\nreactions to content reuse, or remixing, in a large user-generated content\ncommunity. We present two studies using data from the Scratch online community\n-- a social media platform where hundreds of thousands of young people share\nand remix animations and video games. First, we present a quantitative analysis\nthat examines the effects of a technological design intervention introducing\nautomated attribution of remixes on users' reactions to being remixed. We\ncompare this analysis to a parallel examination of \"manual\" credit-giving.\nSecond, we present a qualitative analysis of twelve in-depth, semi-structured,\ninterviews with Scratch participants on the subject of remixing and\nattribution. Results from both studies suggest that automatic attribution done\nby technological systems (i.e., the listing of names of contributors) plays a\nrole that is distinct from, and less valuable than, credit which may\nsuperficially involve identical information but takes on new meaning when it is\ngiven by a human remixer. We discuss the implications of these findings for the\ndesigners of online communities and social media platforms.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 22:05:40 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""], ["Hill", "Benjamin Mako", ""], ["Gonzalez-Rivero", "Jazmin", ""], ["Boyd", "Danah", ""]]}, {"id": "1507.01287", "submitter": "Andres Monroy-Hernandez", "authors": "Munmun De Choudhury, Andr\\'es Monroy-Hern\\'andez, and Gloria Mark", "title": "\"Narco\" Emotions: Affect and Desensitization in Social Media during the\n  Mexican Drug War", "comments": "Best paper award at the 32nd annual ACM conference on Human factors\n  in computing systems (CHI '14). ACM, New York, NY, USA, pages 3563-3572", "journal-ref": "In Proceedings of the 32nd annual ACM conference on Human factors\n  in computing systems (CHI 2014). ACM, New York, NY, USA, pages 3563-3572", "doi": "10.1145/2556288.2557197", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media platforms have emerged as prominent information sharing\necosystems in the context of a variety of recent crises, ranging from mass\nemergencies, to wars and political conflicts. We study affective responses in\nsocial media and how they might indicate desensitization to violence\nexperienced in communities embroiled in an armed conflict. Specifically, we\nexamine three established affect measures: negative affect, activation, and\ndominance as observed on Twitter in relation to a number of statistics on\nprotracted violence in four major cities afflicted by the Mexican Drug War.\nDuring a two year period (Aug 2010-Dec 2012), while violence was on the rise in\nthese regions, our findings show a decline in negative emotional expression as\nwell as a rise in emotional arousal and dominance in Twitter posts: aspects\nknown to be psychological markers of desensitization. We discuss the\nimplications of our work for behavioral health, facilitating rehabilitation\nefforts in communities enmeshed in an acute and persistent urban warfare, and\nthe impact on civic engagement.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 22:32:40 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["De Choudhury", "Munmun", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""], ["Mark", "Gloria", ""]]}, {"id": "1507.01291", "submitter": "Andres Monroy-Hernandez", "authors": "Andr\\'es Monroy-Hern\\'andez, danah boyd, Emre Kiciman, Munmun De\n  Choudhury, and Scott Counts", "title": "The New War Correspondents: the Rise of Civic Media Curation in Urban\n  Warfare", "comments": "In Proceedings of the 2013 conference on Computer supported\n  cooperative work (CSCW 2013). ACM, New York, NY, USA, 1443-1452", "journal-ref": null, "doi": "10.1145/2441776.2441938", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we examine the information sharing practices of people living\nin cities amid armed conflict. We describe the volume and frequency of\nmicroblogging activity on Twitter from four cities afflicted by the Mexican\nDrug War, showing how citizens use social media to alert one another and to\ncomment on the violence that plagues their communities. We then investigate the\nemergence of civic media \"curators,\" individuals who act as \"war\ncorrespondents\" by aggregating and disseminating information to large numbers\nof people on social media. We conclude by outlining the implications of our\nobservations for the design of civic media systems in wartime.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 22:49:09 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""], ["boyd", "danah", ""], ["Kiciman", "Emre", ""], ["De Choudhury", "Munmun", ""], ["Counts", "Scott", ""]]}, {"id": "1507.01292", "submitter": "Andres Monroy-Hernandez", "authors": "Andr\\'es Monroy-Hern\\'andez", "title": "ScratchR: Sharing User-generated Programmable Media", "comments": "In Proceedings of the 6th international conference on Interaction\n  Design and Children (IDC 2007). ACM, New York, NY, USA, 167-168", "journal-ref": null, "doi": "10.1145/1297277.1297315", "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, I describe a platform for sharing programmable media on the\nweb called ScratchR. As the backbone of an on-line community of creative\nlearners, ScratchR will give members access to an audience and inspirational\nideas from each other. ScratchR seeks to support different states of\nparticipation: from passive consumption to active creation. This platform is\nbeing evaluated with a group of middle-school students and a larger community\nof beta testers.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 22:56:01 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""]]}, {"id": "1507.01297", "submitter": "Andres Monroy-Hernandez", "authors": "Benjamin Mako Hill, Andr\\'es Monroy-Hern\\'andez", "title": "The Cost of Collaboration for Code and Art: Evidence from a Remixing\n  Community", "comments": "Best paper award at CSCW, In Proceedings of the 2013 conference on\n  Computer supported cooperative work (CSCW 2013). ACM", "journal-ref": null, "doi": "10.1145/2441776.2441893", "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we use evidence from a remixing community to evaluate two\npieces of common wisdom about collaboration. First, we test the theory that\njointly produced works tend to be of higher quality than individually authored\nproducts. Second, we test the theory that collaboration improves the quality of\nfunctional works like code, but that it works less well for artistic works like\nimages and sounds. We use data from Scratch, a large online community where\nhundreds of thousands of young users share and remix millions of animations and\ninteractive games. Using peer-ratings as a measure of quality, we estimate a\nseries of fitted regression models and find that collaborative Scratch projects\ntend to receive ratings that are lower than individually authored works. We\nalso find that code-intensive collaborations are rated higher than\nmedia-intensive efforts. We conclude by discussing the limitations and\nimplications of these findings.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 23:27:02 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Hill", "Benjamin Mako", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""]]}, {"id": "1507.01299", "submitter": "Andres Monroy-Hernandez", "authors": "J. Nathan Matias and Andr\\'es Monroy-Hern\\'andez", "title": "NewsPad: Designing for Collaborative Storytelling in Neighborhoods", "comments": "NewsPad: designing for collaborative storytelling in neighborhoods.\n  In Proceedings of the extended abstracts of the 32nd annual ACM conference on\n  Human factors in computing systems (CHI EA 2014)", "journal-ref": null, "doi": "10.1145/2559206.2581354", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces design explorations in neighborhood collaborative\nstorytelling. We focus on blogs and citizen journalism, which have been\ncelebrated as a means to meet the reporting needs of small local communities.\nThese bloggers have limited capacity and social media feeds seldom have the\ncontext or readability of news stories. We present NewsPad, a content editor\nthat helps communities create structured stories, collaborate in real time,\nrecruit contributors, and syndicate the editing process. We evaluate NewsPad in\nfour pilot deployments and find that the design elicits collaborative story\ncreation.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 23:34:15 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Matias", "J. Nathan", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""]]}, {"id": "1507.01300", "submitter": "Andres Monroy-Hernandez", "authors": "Elena Agapie and Andr\\'es Monroy-Hern\\'andez", "title": "Eventful: Crowdsourcing Local News Reporting", "comments": "Collective Intelligence Conference 2014, Boston, MA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present Eventful, a system for producing news reports of local events\nusing remote and locative crowd workers. The system recruits and guides novice\ncrowd workers as they perform the roles of field reporter, curator, or writer.\nField reporters attend the events in person, and use Eventful's mobile web app\nto get a personalized mission, submit content, and receive feedback. Missions\ninclude tasks such as taking a photo, and asking a question to an attendee. In\nparallel, remote curators approve, reject, and give real-time feedback on the\ncontent collected by field reporters. Finally, writers put together a report by\nmashing up and tweaking the content approved by the curators. We used Eventful\nto produce a news report for each of the six local events we decided to cover\nas we piloted the system. The process was typically completed under an hour and\ncosting under $150 USD.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 23:42:19 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Agapie", "Elena", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""]]}, {"id": "1507.01305", "submitter": "Andres Monroy-Hernandez", "authors": "Sarah Hallacher, Jenny Rodenhouse, and Andres Monroy-Hernandez", "title": "Mixsourcing: a remix framework as a form of crowdsourcing", "comments": "In CHI 2013 Extended Abstracts on Human Factors in Computing Systems\n  (CHI EA '13)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce the concept of mixsourcing as a modality of\ncrowdsourcing focused on using remixing as a framework to get people to perform\ncreative tasks. We explore this idea through the design of a system that helped\nus identify the promises and challenges of this peer-production modality.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 23:53:59 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Hallacher", "Sarah", ""], ["Rodenhouse", "Jenny", ""], ["Monroy-Hernandez", "Andres", ""]]}, {"id": "1507.01314", "submitter": "Andres Monroy-Hernandez", "authors": "Elena L. Glassman, Juho Kim, Andr\\'es Monroy-Hern\\'andez, Meredith\n  Ringel Morris", "title": "Mudslide: A Spatially Anchored Census of Student Confusion for Online\n  Lecture Videos", "comments": "Best paper honorable mention", "journal-ref": "In Proceedings of the 33rd Annual ACM Conference on Human Factors\n  in Computing Systems (CHI 2015). ACM, New York, NY, USA, 1555-1564", "doi": "10.1145/2702123.2702304", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Educators have developed an effective technique to get feedback after\nin-person lectures, called \"muddy card.\" Students are given time to reflect and\nwrite the \"muddiest\" (least clear) point on an index card, to hand in as they\nleave class. This practice of assigning end-of-lecture reflection tasks to\ngenerate explicit student feedback is well suited for adaptation to the\nchallenge of supporting feedback in online video lectures. We describe the\ndesign and evaluation of Mudslide, a prototype system that translates the\npractice of muddy cards into the realm of online lecture videos. Based on an\nin-lab study of students and teachers, we find that spatially contextualizing\nstudents' muddy point feedback with respect to particular lecture slides is\nadvantageous to both students and teachers. We also reflect on further\nopportunities for enhancing this feedback method based on teachers' and\nstudents' experiences with our prototype.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 01:04:39 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Glassman", "Elena L.", ""], ["Kim", "Juho", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""], ["Morris", "Meredith Ringel", ""]]}, {"id": "1507.01318", "submitter": "Andres Monroy-Hernandez", "authors": "Juho Kim, Elena L. Glassman, Andr\\'es Monroy-Hern\\'andez, Meredith\n  Ringel Morris", "title": "RIMES: Embedding Interactive Multimedia Exercises in Lecture Videos", "comments": null, "journal-ref": "In Proceedings of the 33rd Annual ACM Conference on Human Factors\n  in Computing Systems (CHI 2015). ACM, New York, NY, USA, 1535-1544", "doi": "10.1145/2702123.2702186", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teachers in conventional classrooms often ask learners to express themselves\nand show their thought processes by speaking out loud, drawing on a whiteboard,\nor even using physical objects. Despite the pedagogical value of such\nactivities, interactive exercises available in most online learning platforms\nare constrained to multiple-choice and short answer questions. We introduce\nRIMES, a system for easily authoring, recording, and reviewing interactive\nmultimedia exercises embedded in lecture videos. With RIMES, teachers can\nprompt learners to record their responses to an activity using video, audio,\nand inking while watching lecture videos. Teachers can then review and interact\nwith all the learners' responses in an aggregated gallery. We evaluated RIMES\nwith 19 teachers and 25 students. Teachers created a diverse set of activities\nacross multiple subjects that tested deep conceptual and procedural knowledge.\nTeachers found the exercises useful for capturing students' thought processes,\nidentifying misconceptions, and engaging students with content.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 01:12:47 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Kim", "Juho", ""], ["Glassman", "Elena L.", ""], ["Monroy-Hern\u00e1ndez", "Andr\u00e9s", ""], ["Morris", "Meredith Ringel", ""]]}, {"id": "1507.01677", "submitter": "Jagmohan Chauhan", "authors": "Jagmohan Chauhan, Mohamed Ali Kaafar, Anirban Mahanti", "title": "The Web for Under-Powered Mobile Devices: Lessons learned from Google\n  Glass", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines some of the potential challenges associated with enabling\na seamless web experience on underpowered mobile devices such as Google Glass\nfrom the perspective of web content providers, device, and the network. We\nconducted experiments to study the impact of webpage complexity, individual web\ncomponents and different application layer protocols while accessing webpages\non the performance of Glass browser, by measuring webpage load time,\ntemperature variation and power consumption and compare it to a smartphone. Our\nfindings suggest that (a) performance of Glass compared to a smartphone in\nterms of power consumption and webpage load time deteriorates with increasing\nwebpage complexity (b) execution time for popular JavaScript benchmarks is\nabout 3-8 times higher on Glass compared to a smartphone, (c) WebP is more\nenergy efficient image format than JPEG and PNG, and (d) seven out of 50\nwebsites studied are optimized for content delivery to Glass.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 05:20:51 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2015 07:44:44 GMT"}, {"version": "v3", "created": "Sat, 28 Nov 2015 04:58:13 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Chauhan", "Jagmohan", ""], ["Kaafar", "Mohamed Ali", ""], ["Mahanti", "Anirban", ""]]}, {"id": "1507.01882", "submitter": "Jeff Shrager", "authors": "Jeff Shrager", "title": "Demandance", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A demandance is a psychological \"pull\" exerted by a stimulus. It is closely\nrelated to the theory of \"affordance\". I introduce the theory of demandance,\noffer some motivating examples, briefly explore its psychological basis, and\nexamine some implications of the theory. I exemplify some of the positive and\nnegative implications of demandances for design, with special attention to\nyoung children and the design of educational products and practices. I suggest\nthat demandance offers an approach to one of the persistent mysteries of the\ntheory of affordance, specifically: Given that there may be many affordances in\nany particular setting, how do we choose which to actually act upon?\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 17:10:16 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Shrager", "Jeff", ""]]}, {"id": "1507.03482", "submitter": "Francisco Hernando-Gallego", "authors": "Francisco Hernando-Gallego and Antonio Art\\'es-Rodr\\'iguez", "title": "Individual performance calibration using physiological stress signals", "comments": "5 pages, 12 figures, Workshop of Shimmer sensors, IEEE Body Sensor\n  Networks Conference 2015 MIT Lab Boston (USA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relation between performance and stress is described by the Yerkes-Dodson\nLaw but varies significantly between individuals. This paper describes a method\nfor determining the individual optimal performance as a function of\nphysiological signals. The method is based on attention and reasoning tests of\nincreasing complexity under monitoring of three physiological signals: Galvanic\nSkin Response (GSR), Heart Rate (HR), and Electromyogram (EMG). Based on the\ntest results with 15 different individuals, we first show that two of the\nsignals, GSR and HR, have enough discriminative power to distinguish between\nrelax and stress periods. We then show a positive correlation between the\ncomplexity level of the tests and the GSR and HR signals, and we finally\ndetermine the optimal performance point as the signal level just before a\nperformance decrease. We also discuss the differences among signals depending\non the type of test.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 14:52:02 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Hernando-Gallego", "Francisco", ""], ["Art\u00e9s-Rodr\u00edguez", "Antonio", ""]]}, {"id": "1507.03767", "submitter": "Daniel Graziotin", "authors": "Daniel Graziotin, Xiaofeng Wang, and Pekka Abrahamsson", "title": "Understanding the Affect of Developers: Theoretical Background and\n  Guidelines for Psychoempirical Software Engineering", "comments": "9 pages, 2 figures", "journal-ref": "7th Intl. Workshop on Social Software Engineering, pp. 25-32, 2015", "doi": "10.1145/2804381.2804386", "report-no": null, "categories": "cs.SE cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affects---emotions and moods---have an impact on cognitive processing\nactivities and the working performance of individuals. It has been established\nthat software development tasks are undertaken through cognitive processing\nactivities. Therefore, we have proposed to employ psychology theory and\nmeasurements in software engineering (SE) research. We have called it\n\"psychoempirical software engineering\". However, we found out that existing SE\nresearch has often fallen into misconceptions about the affect of developers,\nlacking in background theory and how to successfully employ psychological\nmeasurements in studies. The contribution of this paper is threefold. (1) It\nhighlights the challenges to conduct proper affect-related studies with\npsychology; (2) it provides a comprehensive literature review in affect theory;\nand (3) it proposes guidelines for conducting psychoempirical software\nengineering.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 08:44:54 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2015 14:20:20 GMT"}], "update_date": "2015-09-18", "authors_parsed": [["Graziotin", "Daniel", ""], ["Wang", "Xiaofeng", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1507.03811", "submitter": "Liliana Lo Presti", "authors": "Liliana Lo Presti and Marco La Cascia", "title": "Ensemble of Hankel Matrices for Face Emotion Recognition", "comments": "Paper to appear in Proc. of ICIAP 2015. arXiv admin note: text\n  overlap with arXiv:1506.05001", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a face emotion is considered as the result of the composition\nof multiple concurrent signals, each corresponding to the movements of a\nspecific facial muscle. These concurrent signals are represented by means of a\nset of multi-scale appearance features that might be correlated with one or\nmore concurrent signals. The extraction of these appearance features from a\nsequence of face images yields to a set of time series. This paper proposes to\nuse the dynamics regulating each appearance feature time series to recognize\namong different face emotions. To this purpose, an ensemble of Hankel matrices\ncorresponding to the extracted time series is used for emotion classification\nwithin a framework that combines nearest neighbor and a majority vote schema.\nExperimental results on a public available dataset shows that the adopted\nrepresentation is promising and yields state-of-the-art accuracy in emotion\nclassification.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 11:26:31 GMT"}], "update_date": "2015-07-19", "authors_parsed": [["Presti", "Liliana Lo", ""], ["La Cascia", "Marco", ""]]}, {"id": "1507.04441", "submitter": "Keng-Teck Ma", "authors": "Keng-Teck Ma, Qianli Xu, Liyuan Li, Terence Sim, Mohan Kankanhalli,\n  Rosary Lim", "title": "Eye-2-I: Eye-tracking for just-in-time implicit user profiling", "comments": "A bug was found in the codes which resulted in information leak. New\n  experimental results will be updated at a later date. I assume all\n  responsibility for this mistake. KT Ma", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many applications, such as targeted advertising and content\nrecommendation, knowing users' traits and interests is a prerequisite. User\nprofiling is a helpful approach for this purpose. However, current methods,\ni.e. self-reporting, web-activity monitoring and social media mining are either\nintrusive or require data over long periods of time. Recently, there is growing\nevidence in cognitive science that a variety of users' profile is significantly\ncorrelated with eye-tracking data. We propose a novel just-in-time implicit\nprofiling method, Eye-2-I, which learns the user's interests, demographic and\npersonality traits from the eye-tracking data while the user is watching\nvideos. Although seemingly conspicuous by closely monitoring the user's eye\nbehaviors, our method is unobtrusive and privacy-preserving owing to its unique\ncharacteristics, including (1) fast speed - the profile is available by the\nfirst video shot, typically few seconds, and (2) self-contained - not relying\non historical data or functional modules. [Bug found. As a proof-of-concept,\nour method is evaluated in a user study with 51 subjects. It achieved a mean\naccuracy of 0.89 on 37 attributes of user profile with 9 minutes of\neye-tracking data.]\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2015 03:47:05 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2016 01:54:05 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Ma", "Keng-Teck", ""], ["Xu", "Qianli", ""], ["Li", "Liyuan", ""], ["Sim", "Terence", ""], ["Kankanhalli", "Mohan", ""], ["Lim", "Rosary", ""]]}, {"id": "1507.04961", "submitter": "Oded Nov", "authors": "Junius Gunaratne and Oded Nov", "title": "Using Interactive Information Labels to Assist Decision Making Under\n  Uncertainty: The Case for Long-term Saving", "comments": "This paper is withdrawn as it is still work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Product information labels can help users understand complex information\nleading them to make better decisions. One area where consumers are\nparticularly prone to make costly decision-making errors is long-term saving,\nwhich requires understanding of complex concepts such as uncertainty and\ntrade-offs. While most people are poorly equipped to deal with such concepts,\ninteractive design can potentially help users make better decisions. We\ndeveloped an interactive information label to assist consumers with retirement\nsaving decision-making. To evaluate it, we exposed 382 users to one of three\nuser interface conditions in a retirement saving simulator where they made 35\nyearly decisions under changing circumstances. We found significantly better\nability of users to reach their goals with the information label. Furthermore,\nusers who interacted with the label made better decisions than those who were\npresented with a static information label. Lastly, we found the label\nparticularly effective in helping novice savers.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 13:15:43 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2015 14:56:01 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2015 02:37:38 GMT"}, {"version": "v4", "created": "Sun, 18 Oct 2015 14:57:59 GMT"}, {"version": "v5", "created": "Wed, 21 Oct 2015 01:16:33 GMT"}, {"version": "v6", "created": "Tue, 15 Dec 2015 20:21:35 GMT"}, {"version": "v7", "created": "Mon, 18 Jan 2016 02:54:50 GMT"}, {"version": "v8", "created": "Wed, 20 Jan 2016 17:47:41 GMT"}, {"version": "v9", "created": "Tue, 21 Feb 2017 14:41:19 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Gunaratne", "Junius", ""], ["Nov", "Oded", ""]]}, {"id": "1507.05150", "submitter": "Amandianeze Nwana", "authors": "Amandianeze O. Nwana and Tshuan Chen", "title": "Towards Understanding User Preferences from User Tagging Behavior for\n  Personalization", "comments": "6 pages", "journal-ref": null, "doi": "10.1109/ISM.2015.79", "report-no": null, "categories": "cs.MM cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalizing image tags is a relatively new and growing area of research,\nand in order to advance this research community, we must review and challenge\nthe de-facto standard of defining tag importance. We believe that for greater\nprogress to be made, we must go beyond tags that merely describe objects that\nare visually represented in the image, towards more user-centric and subjective\nnotions such as emotion, sentiment, and preferences.\n  We focus on the notion of user preferences and show that the order that users\nlist tags on images is correlated to the order of preference over the tags that\nthey provided for the image. While this observation is not completely\nsurprising, to our knowledge, we are the first to explore this aspect of user\ntagging behavior systematically and report empirical results to support this\nobservation. We argue that this observation can be exploited to help advance\nthe image tagging (and related) communities.\n  Our contributions include: 1.) conducting a user study demonstrating this\nobservation, 2.) collecting a dataset with user tag preferences explicitly\ncollected.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2015 05:55:37 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 19:56:36 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Nwana", "Amandianeze O.", ""], ["Chen", "Tshuan", ""]]}, {"id": "1507.05215", "submitter": "Fan Du", "authors": "Fan Du, Joshua Brul\\'e, Peter Enns, Varun Manjunatha, Yoav Segev", "title": "MetroViz: Visual Analysis of Public Transportation Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the quality and usage of public transportation resources is\nimportant for schedule optimization and resource allocation. Ridership and\nadherence are the two main dimensions for evaluating the quality of service.\nUsing Automatic Vehicle Location (AVL), Automatic Passenger Count (APC), and\nGlobal Positioning System (GPS) data, ridership data and adherence data of\npublic transportation can be collected. In this paper, we discuss the\ndevelopment of a visualization tool for exploring public transportation data.\nWe introduce \"map view\" and \"route view\" to help users locate stops in the\ncontext of geography and route information. To visualize ridership and\nadherence information over several years, we introduce \"calendar view\" - a\nminiaturized calendar that provides an overview of data where users can\ninteractively select specific days to explore individual trips and stops (\"trip\nsubview\" and \"stop subview\"). MetroViz was evaluated via a series of usability\ntests that included researchers from the Center for Advanced Transportation\nTechnology (CATT) and students from the University of Maryland - College Park\nin which test participants used the tool to explore three years of bus transit\ndata from Blacksburg, Virginia.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2015 18:38:42 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Du", "Fan", ""], ["Brul\u00e9", "Joshua", ""], ["Enns", "Peter", ""], ["Manjunatha", "Varun", ""], ["Segev", "Yoav", ""]]}, {"id": "1507.06029", "submitter": "Jaderick Pabico", "authors": "Katrina Joy H. Magno and Jaderick P. Pabico", "title": "Towards Input Device Satisfaction Through Hand Anthropometry", "comments": "20 pages, 12 figures, appeared in A.L. Sioson (ed.) Proceedings\n  (CDROM) of the 10th National Conference on Information Technology Education\n  (NCITE 2012), Laoag City, Ilocos Norte, Philippines, 18-20 October 2012", "journal-ref": "Philippine Information Technology Journal 6(1):17-28 (2013)", "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We collected the hand anthropometric data of 91 respondents to come up with a\nFilipino-based measurement to determine the suitability of an input device for\na digital equipment, the standard PC keyboard. For correlation purposes, we\nalso collected other relevant information like age, height, province of origin,\nand gender, among others. We computed the percentiles for each finger to\nclassify various finger dimensions and identify length-specific anthropometric\ncut-points. We compared the percentiles of each finger dimension against the\nactual length of the longest key combinations when correct finger placement is\nused for typing, to determine whether the standard PC keyboard is fit for use\nby our sampled population. Our analysis shows that the members of the\npopulation with hand dimensions at extended position below 75th percentile and\nat 99th percentile are the ones who would most likely not reach the longest key\ncombination for the left and the right hands, respectively. Using machine\nvision and image processing techniques, we automated the anthropometric process\nand compared the accuracy of its measurements to that of manual process'. We\ncompared the measurement generated by our automated anthropometric process with\nthe measurements using the manual one and we found out that they have a very\nminimal absolute difference. The data collected from this study could be used\nin other studies such as determining a good design for mobile and other\nhandheld devices, or input devices other than keyboard. The automated method\nthat we developed could be used to easily measure hand dimensions given a\ndigital image of the hand and could be extended for measuring the entire human\nbody for various other applications.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2015 01:30:13 GMT"}], "update_date": "2015-07-23", "authors_parsed": [["Magno", "Katrina Joy H.", ""], ["Pabico", "Jaderick P.", ""]]}, {"id": "1507.06136", "submitter": "Antonio Brandao Moniz", "authors": "Ant\\'onio Brand\\~ao Moniz (IET)", "title": "Robots and humans as co-workers?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of work organisation systems with automated equipment is facing\nnew challenges and the emergence of new concepts. The social aspects that are\nrelated with new concepts on the complex work environments (CWE) are becoming\nmore relevant for that design. The work with autonomous systems implies options\nin the design of workplaces. Especially that happens in such complex\nenvironments. The concepts of \"agents\", \"co-working\" or \"human-centred\ntechnical systems\" reveal new dimensions related to human-computer interaction\n(HCI). With an increase in the number and complexity of those human-technology\ninterfaces, the capacities of human intervention can become limited,\noriginating further problems. The case of robotics is used to exemplify the\nissues related with automation in working environments and the emergence of new\nHCI approaches that would include social implications. We conclude that studies\non technology assessment of industrial robotics and autonomous agents on\nmanufacturing environment should also focus on the human involvement strategies\nin organisations. A needed participatory strategy implies a new approach to\nworkplaces design. This means that the research focus must be on the relation\nbetween technology and social dimensions not as separate entities, but\nintegrated in the design of an interaction system.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2015 11:28:58 GMT"}], "update_date": "2015-07-23", "authors_parsed": [["Moniz", "Ant\u00f3nio Brand\u00e3o", "", "IET"]]}, {"id": "1507.06469", "submitter": "Rakhi Gupta Mrs", "authors": "Rakhi Misuriya Gupta", "title": "MOBISPA: A Reference Framework for Mobile as a Personal Assistant", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile is taking center stage and becoming the device of preference for all\naspects of communication because of our increasingly on the go lifestyles. With\nthis the demands on mobile capability to execute increasingly complex\noperations are also on the rise. However, despite improvements in device\ncomputing power in the last couple of years a mobile device continues to have\nlimitations. Mobile driven everyday use cases are increasingly raising\nexpectations that rest on mobile technologies that are still evolving. A number\nof fragmented approaches and solutions have been created that address various\nrequirements unique to mobility, however there is a lack of a single framework\nthat serves as a unifying reference for industry and solution architectures.\nThe paper addresses this concern through the specification of a comprehensive\nreference framework for mobility that is generic and vendor neutral.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2015 12:45:34 GMT"}], "update_date": "2015-07-24", "authors_parsed": [["Gupta", "Rakhi Misuriya", ""]]}, {"id": "1507.06593", "submitter": "Ashwinkumar Ganesan", "authors": "Ashwinkumar Ganesan, Kiante Brantley, Shimei Pan, Jian Chen", "title": "LDAExplore: Visualizing Topic Models Generated Using Latent Dirichlet\n  Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LDAExplore, a tool to visualize topic distributions in a given\ndocument corpus that are generated using Topic Modeling methods. Latent\nDirichlet Allocation (LDA) is one of the basic methods that is predominantly\nused to generate topics. One of the problems with methods like LDA is that\nusers who apply them may not understand the topics that are generated. Also,\nusers may find it difficult to search correlated topics and correlated\ndocuments. LDAExplore, tries to alleviate these problems by visualizing topic\nand word distributions generated from the document corpus and allowing the user\nto interact with them. The system is designed for users, who have minimal\nknowledge of LDA or Topic Modelling methods. To evaluate our design, we run a\npilot study which uses the abstracts of 322 Information Visualization papers,\nwhere every abstract is considered a document. The topics generated are then\nexplored by users. The results show that users are able to find correlated\ndocuments and group them based on topics that are similar.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2015 18:15:03 GMT"}], "update_date": "2015-07-24", "authors_parsed": [["Ganesan", "Ashwinkumar", ""], ["Brantley", "Kiante", ""], ["Pan", "Shimei", ""], ["Chen", "Jian", ""]]}, {"id": "1507.06667", "submitter": "Elham Khabiri", "authors": "Fenno F. Heath III, Richard Hull, Elham Khabiri, Matthew Riemer, Noi\n  Sukaviriya, and Roman Vaculin", "title": "Alexandria: Extensible Framework for Rapid Exploration of Social Media", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Alexandria system under development at IBM Research provides an\nextensible framework and platform for supporting a variety of big-data\nanalytics and visualizations. The system is currently focused on enabling rapid\nexploration of text-based social media data. The system provides tools to help\nwith constructing \"domain models\" (i.e., families of keywords and extractors to\nenable focus on tweets and other social media documents relevant to a project),\nto rapidly extract and segment the relevant social media and its authors, to\napply further analytics (such as finding trends and anomalous terms), and\nvisualizing the results. The system architecture is centered around a variety\nof REST-based service APIs to enable flexible orchestration of the system\ncapabilities; these are especially useful to support knowledge-worker driven\niterative exploration of social phenomena. The architecture also enables rapid\nintegration of Alexandria capabilities with other social media analytics\nsystem, as has been demonstrated through an integration with IBM Research's\nSystemG. This paper describes a prototypical usage scenario for Alexandria,\nalong with the architecture and key underlying analytics.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2015 20:10:44 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Heath", "Fenno F.", "III"], ["Hull", "Richard", ""], ["Khabiri", "Elham", ""], ["Riemer", "Matthew", ""], ["Sukaviriya", "Noi", ""], ["Vaculin", "Roman", ""]]}, {"id": "1507.06768", "submitter": "Daniel Graziotin", "authors": "Ilona Kuzmickaja, Xiaofeng Wang, Daniel Graziotin, Gabriella Dodero,\n  Pekka Abrahamsson", "title": "In Need of Creative Mobile Service Ideas? Forget Adults and Ask Young\n  Children", "comments": "48 pagers, 3 figures. Accepted for publication at SAGE Open", "journal-ref": "SAGE Open Vol 5, Issue 3, 2015", "doi": "10.1177/2158244015601719", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well acknowledged that innovation is a key success factor in mobile\nservice domain. Having creative ideas is the first critical step in the\ninnovation process. Many studies suggest that customers are a valuable source\nof creative ideas. However, the literature also shows that adults may be\nconstrained by existing technology frames, which are known to hinder\ncreativity. Instead young children (aged 7-12) are considered digital natives\nyet are free from existing technology frames. This led us to study them as a\npotential source for creative mobile service ideas. A set of 41,000 mobile\nideas obtained from a research project in 2006 granted us a unique opportunity\nto study the mobile service ideas from young children. We randomly selected two\nsamples of ideas (N=400 each), one contained the ideas from young children, the\nother from adults (aged 17-50). These ideas were evaluated by several\nevaluators using an existing creativity framework. The results show that the\nmobile service ideas from the young children are significantly more original,\ntransformational, implementable, and relevant than those from the adults.\nTherefore, this study shows that young children are better sources of novel and\nquality ideas than adults in the mobile services domain. This study bears\nsignificant contributions to the creativity and innovation research. It also\nindicates a new and valuable source for the companies that seek for creative\nideas for innovative products and services.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 07:45:00 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Kuzmickaja", "Ilona", ""], ["Wang", "Xiaofeng", ""], ["Graziotin", "Daniel", ""], ["Dodero", "Gabriella", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1507.06956", "submitter": "Luiz Capretz Dr.", "authors": "David Carter, Luiz Fernando Capretz", "title": "A Three-Dimensional GUI for Windows Explorer", "comments": null, "journal-ref": "Journal of Three Dimensional Images, 18(1):136-141, 2004", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three-dimension will be a characteristic of future user interfaces, although\nwe are just starting to gain an understanding of how users can navigate and\nshare information within a virtual 3D environment. Three-dimensional graphical\nuser interfaces (3D-GUI) raise many issues of design, metaphor and usability.\nThis research is devoted to designing a 3D-GUI as a front-end tool for a file\nmanagement system, in this case, for Microsoft Windows\\c{opyright} Explorer; as\nwell as evaluating the efficiency of a 3D application. The software design was\nimplemented by extending the Half-Life 3D engine. This extension provides a\ndirectory traversal and basic file management functions, like cut, copy, paste,\ndelete, and so on. This paper shows the design and implementation of a\nreal-world application that contains an efficient 3D-GUI.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 18:54:16 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Carter", "David", ""], ["Capretz", "Luiz Fernando", ""]]}, {"id": "1507.08137", "submitter": "Gautier Marti", "authors": "Gautier Marti, Philippe Donnat, Frank Nielsen, Philippe Very", "title": "HCMapper: An interactive visualization tool to compare partition-based\n  flat clustering extracted from pairs of dendrograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new visualization tool, dubbed HCMapper, that visually helps to\ncompare a pair of dendrograms computed on the same dataset by displaying\nmultiscale partition-based layered structures. The dendrograms are obtained by\nhierarchical clustering techniques whose output reflects some hypothesis on the\ndata and HCMapper is specifically designed to grasp at first glance both\nwhether the two compared hypotheses broadly agree and the data points on which\nthey do not concur. Leveraging juxtaposition and explicit encodings, HCMapper\nfocus on two selected partitions while displaying coarser ones in context areas\nfor understanding multiscale structure and eventually switching the selected\npartitions. HCMapper utility is shown through the example of testing whether\nthe prices of credit default swap financial time series only undergo\ncorrelation. This use case is detailed in the supplementary material as well as\nexperiments with code on toy-datasets for reproducible research. HCMapper is\ncurrently released as a visualization tool on the DataGrapple time series and\nclustering analysis platorm at www.datagrapple.com.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 13:26:05 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 11:13:13 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Marti", "Gautier", ""], ["Donnat", "Philippe", ""], ["Nielsen", "Frank", ""], ["Very", "Philippe", ""]]}]