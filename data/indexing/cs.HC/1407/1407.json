[{"id": "1407.0153", "submitter": "Claudia Picardi", "authors": "Federica Cena, Silvia Likavec, Ilaria Lombardi, and Claudia Picardi", "title": "Should I Stay or Should I Go? Improving Event Recommendation in the\n  Social Web", "comments": "21 pages. Accepted for publication on Interacting with Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the recommendation of events in the Social Web, and\naddresses the problem of finding if, and to which extent, certain features,\nwhich are peculiar to events, are relevant in predicting the users' interests\nand should thereby be taken into account in recommendation.\n  We consider in particular three \"additional\" features that are usually shown\nto users within social networking environments: reachability from the user\nlocation, the reputation of the event in the community, and the participation\nof the user's friends. Our study is aimed at evaluating whether adding this\ninformation to the description of the event type and topic, and including in\nthe user profile the information on the relevance of these factors, can improve\nour capability to predict the user's interest.\n  We approached the problem by carrying out two surveys with users, who were\nasked to express %with a score their interest in a number of events. We then\ntrained, by means of linear regression, a scoring function defined as a linear\ncombination of the different factors, whose goal was to predict the user\nscores. We repeated this experiment under different hypotheses on the\nadditional factors, in order to assess their relevance by comparing the\npredictive capabilities of the resulting functions.\n  The compared results of our experiments show that additional factors, if\nproperly weighted, can improve the prediction accuracy with an error reduction\nof 4.1%. The best results were obtained by combining content-based factors and\nadditional factors in a proportion of approximately 10:4.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2014 09:29:04 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Cena", "Federica", ""], ["Likavec", "Silvia", ""], ["Lombardi", "Ilaria", ""], ["Picardi", "Claudia", ""]]}, {"id": "1407.0377", "submitter": "Walter Lasecki", "authors": "Laura Dabbish, Colleen Stuart, Jason Tsay, and Jim Herbsleb", "title": "Transparency and Coordination in Peer Production", "comments": null, "journal-ref": null, "doi": null, "report-no": "ci-2014/128", "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines coordination in transparent work environments -\nenvironments where the content of work artifacts, and the actions taken on\nthese artifacts, are fully visible to organizational members. Our qualitative\nstudy of a community of open source software developers revealed a coordination\nsystem characterized by interest-based, asynchronous interaction and knowledge\ntransfer. At the core of asynchronous knowledge transfer, lies the concept of\nquasi-codification, which occurs when rich process knowledge is implicitly\nencoded in work artifacts. Our findings suggest that members are able to more\nselectively form dependencies, monitor the trajectory of projects, and make\ntheir work understandable to others which facilitates coordination. We discuss\ntwo important characteristics that enable coordination activities in a\ntransparent environment: the presence of an imagined audience that dictates the\nway artifacts are crafted, and experience within the environment, that allows\nindividuals to derive knowledge from these artifacts. By showing how\ntransparency influences coordination, this research challenges previous\nconceptions of coordination for complex, collaborative work.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 02:39:45 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Dabbish", "Laura", ""], ["Stuart", "Colleen", ""], ["Tsay", "Jason", ""], ["Herbsleb", "Jim", ""]]}, {"id": "1407.0434", "submitter": "Prasant Misra", "authors": "Prasant Misra, Yogesh Simmhan, Jay Warrior", "title": "Towards a Practical Architecture for India Centric Internet of Things", "comments": null, "journal-ref": "IEEE Internet of Things Newsletter, January, 2015", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective architecture for the Internet of Things (IoT), particularly for\nan emerging nation like India with limited technology penetration at the\nnational scale, should be based on tangible technology advances in the present,\npractical application scenarios of social and entrepreneurial value, and\nubiquitous capabilities that make the realization of IoT affordable and\nsustainable. Humans, data, communication and devices play key roles in the IoT\necosystem that we perceive. In a push towards this sustainable and practical\nIoT Architecture for India, we synthesize ten design paradigms to consider.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 01:05:33 GMT"}, {"version": "v2", "created": "Mon, 14 Jul 2014 12:18:54 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Misra", "Prasant", ""], ["Simmhan", "Yogesh", ""], ["Warrior", "Jay", ""]]}, {"id": "1407.0566", "submitter": "Jacopo Staiano", "authors": "Jacopo Staiano, Nuria Oliver, Bruno Lepri, Rodrigo de Oliveira,\n  Michele Caraviello, Nicu Sebe", "title": "Money Walks: A Human-Centric Study on the Economics of Personal Mobile\n  Data", "comments": "15 pages, 2 figures. To appear in ACM International Joint Conference\n  on Pervasive and Ubiquitous Computing (Ubicomp 2014)", "journal-ref": null, "doi": "10.1145/2632048.2632074", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of a myriad of mobile apps which collect personally\nidentifiable information (PII) and a prospective market place of personal data,\nwe investigate a user-centric monetary valuation of mobile PII. During a 6-week\nlong user study in a living lab deployment with 60 participants, we collected\ntheir daily valuations of 4 categories of mobile PII (communication, e.g.\nphonecalls made/received, applications, e.g. time spent on different apps,\nlocation and media, photos taken) at three levels of complexity (individual\ndata points, aggregated statistics and processed, i.e. meaningful\ninterpretations of the data). In order to obtain honest valuations, we employ a\nreverse second price auction mechanism. Our findings show that the most\nsensitive and valued category of personal information is location. We report\nstatistically significant associations between actual mobile usage, personal\ndispositions, and bidding behavior. Finally, we outline key implications for\nthe design of mobile services and future markets of personal data.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2014 13:45:12 GMT"}, {"version": "v2", "created": "Thu, 10 Jul 2014 18:09:32 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Staiano", "Jacopo", ""], ["Oliver", "Nuria", ""], ["Lepri", "Bruno", ""], ["de Oliveira", "Rodrigo", ""], ["Caraviello", "Michele", ""], ["Sebe", "Nicu", ""]]}, {"id": "1407.0843", "submitter": "Michael Meder", "authors": "Michael Meder, Brijnesh-Johannes Jain", "title": "The Gamification Design Problem", "comments": "5 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the assumptions that (i) gamification consists of various types of\nusers that experience game design elements differently; and (ii) gamification\nis deployed in order to achieve some goal in the broadest sense, we pose the\ngamification problem as that of assigning each user a game design element that\nmaximizes their expected contribution in order to achieve that goal. We show\nthat this problem reduces to a statistical learning problem and suggest matrix\nfactorization as one solution when user interaction data is given. The\nhypothesis is that predictive models as intelligent tools for supporting users\nin decision-making may also have potential to support the design process in\ngamification.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jul 2014 10:09:57 GMT"}], "update_date": "2014-07-04", "authors_parsed": [["Meder", "Michael", ""], ["Jain", "Brijnesh-Johannes", ""]]}, {"id": "1407.1474", "submitter": "Kaveh Bakhtiyari", "authors": "Kaveh Bakhtiyari and Hafizah Husain", "title": "Fuzzy Model on Human Emotions Recognition", "comments": "12th WSEAS International Conference on Applications of Computer\n  Engineering (ACE '13), Cambridge, MA, USA, 30 Jan. - 1 Feb. 2013 ISBN:\n  978-1-61804-156-2, Pages 77-82", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a fuzzy model for multi-level human emotions recognition\nby computer systems through keyboard keystrokes, mouse and touchscreen\ninteractions. This model can also be used to detect the other possible emotions\nat the time of recognition. Accuracy measurements of human emotions by the\nfuzzy model are discussed through two methods; the first is accuracy analysis\nand the second is false positive rate analysis. This fuzzy model detects more\nemotions, but on the other hand, for some of emotions, a lower accuracy was\nobtained with the comparison with the non-fuzzy human emotions detection\nmethods. This system was trained and tested by Support Vector Machine (SVM) to\nrecognize the users' emotions. Overall, this model represents a closer\nsimilarity between human brain detection of emotions and computer systems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jul 2014 09:38:21 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Bakhtiyari", "Kaveh", ""], ["Husain", "Hafizah", ""]]}, {"id": "1407.2107", "submitter": "Raghu Machiraju", "authors": "Hao Ding, Chao Wang, Kun Huang and Raghu Machiraju", "title": "iGPSe: A Visual Analytic System for Integrative Genomic Based Cancer\n  Patient Stratification", "comments": "BioVis 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Cancers are highly heterogeneous with different subtypes. These\nsubtypes often possess different genetic variants, present different\npathological phenotypes, and most importantly, show various clinical outcomes\nsuch as varied prognosis and response to treatment and likelihood for\nrecurrence and metastasis. Recently, integrative genomics (or panomics)\napproaches are often adopted with the goal of combining multiple types of omics\ndata to identify integrative biomarkers for stratification of patients into\ngroups with different clinical outcomes. Results: In this paper we present a\nvisual analytic system called Interactive Genomics Patient Stratification\nexplorer (iGPSe) which significantly reduces the computing burden for\nbiomedical researchers in the process of exploring complicated integrative\ngenomics data. Our system integrates unsupervised clustering with graph and\nparallel sets visualization and allows direct comparison of clinical outcomes\nvia survival analysis. Using a breast cancer dataset obtained from the The\nCancer Genome Atlas (TCGA) project, we are able to quickly explore different\ncombinations of gene expression (mRNA) and microRNA features and identify\npotential combined markers for survival prediction. Conclusions: Visualization\nplays an important role in the process of stratifying given population\npatients. Visual tools allowed for the selection of possibly features across\nvarious datasets for the given patient population. We essentially made a case\nfor visualization for a very important problem in translational informatics.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 14:30:15 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Ding", "Hao", ""], ["Wang", "Chao", ""], ["Huang", "Kun", ""], ["Machiraju", "Raghu", ""]]}, {"id": "1407.2112", "submitter": "Carsten Marr", "authors": "Justin Feigelman, Fabian J. Theis and Carsten Marr", "title": "MCA: Multiresolution Correlation Analysis, a graphical tool for\n  subpopulation identification in single-cell gene expression data", "comments": "BioVis 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Biological data often originate from samples containing mixtures\nof subpopulations, corresponding e.g. to distinct cellular phenotypes. However,\nidentification of distinct subpopulations may be difficult if biological\nmeasurements yield distributions that are not easily separable. Results: We\npresent Multiresolution Correlation Analysis (MCA), a method for visually\nidentifying subpopulations based on the local pairwise correlation between\ncovariates, without needing to define an a priori interaction scale. We\ndemonstrate that MCA facilitates the identification of differentially regulated\nsubpopulations in simulated data from a small gene regulatory network, followed\nby application to previously published single-cell qPCR data from mouse\nembryonic stem cells. We show that MCA recovers previously identified\nsubpopulations, provides additional insight into the underlying correlation\nstructure, reveals potentially spurious compartmentalizations, and provides\ninsight into novel subpopulations. Conclusions: MCA is a useful method for the\nidentification of subpopulations in low-dimensional expression data, as\nemerging from qPCR or FACS measurements. With MCA it is possible to investigate\nthe robustness of covariate correlations with respect subpopulations,\ngraphically identify outliers, and identify factors contributing to\ndifferential regulation between pairs of covariates. MCA thus provides a\nframework for investigation of expression correlations for genes of interests\nand biological hypothesis generation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 14:42:30 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Feigelman", "Justin", ""], ["Theis", "Fabian J.", ""], ["Marr", "Carsten", ""]]}, {"id": "1407.2117", "submitter": "Andy Taylor", "authors": "Andy Taylor, Kenneth McLeod, Chris Armit, Richard Baldock and Albert\n  Burger", "title": "Visualization of gene expression information within the context of the\n  mouse anatomy", "comments": "BioVis 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.GR q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The eMouse Atlas of Gene Expression (EMAGE) is an online resource\nthat publishes the results of in situ gene expression experiments on the\ndevelopmental mouse. The resource provides comprehensive search facilities, but\nfew analytical tools or visual mechanisms for navigating the data set. To deal\nwith the missing visual navigation, this paper explores the application of\nsunburst and icicle visualizations within EMAGE. Results: A prototype solution\ndelivered a simple user interface that helps the user query EMAGE and generate\na sunburst/icicle diagram. An evaluation featuring test subjects from the EMAGE\nstaff studied the visualizations and provided a range of suggested\nimprovements. Moreover the evaluation discovered that in addition to providing\na visual means of walking through the data, when grouped, the sunburst delivers\nan interactive overview that assists with analysing sets of related genes.\nConclusions: The sunburst and icicle visualizations have been shown to be\neffective tools for summarising gene expression data. The sunburst with its\nspace saving radial layout was found especially useful for providing an\noverview of gene families or pathways. Work is ongoing to integrate these\nvisualizations into EMAGE.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2014 14:50:04 GMT"}], "update_date": "2014-07-09", "authors_parsed": [["Taylor", "Andy", ""], ["McLeod", "Kenneth", ""], ["Armit", "Chris", ""], ["Baldock", "Richard", ""], ["Burger", "Albert", ""]]}, {"id": "1407.2807", "submitter": "Allan Oliveira Mr.", "authors": "Allan Oliveira and Regina Araujo", "title": "A human centered perspective of E-maintenance", "comments": "Presented in the IX Workshop of Virtual and Augmented Reality - 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-maintenance is a technology aiming to organize and structure the ICT during\nthe whole life cycle of the product, to develop a maintenance support system\nthat is effective and efficient. A current challenge of E-maintenance is the\ndevelopment of generic visualization solutions for users responsible for the\nmaintenance. AR can be a potential technology for E-maintenance visualization,\nsince it can bring knowledge to the real physical world, to assist the\ntechnician perform his/her work without the need to interrupt to consult\nmanuals for information. This paper proposes a methodology for the development\nof advanced interfaces for human aware E-maintenance so that complex\nmaintenance processes can be made safer, better quality, faster, anytime and\nanywhere.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2014 14:36:10 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Oliveira", "Allan", ""], ["Araujo", "Regina", ""]]}, {"id": "1407.3692", "submitter": "Paul Shaw", "authors": "Paul D. Shaw, Martin Graham, Jessie Kennedy, Iain Milne and David F.\n  Marshall", "title": "Helium: Visualization of Large Scale Plant Pedigrees", "comments": "BioVis 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Plant breeders are utilising an increasingly diverse range of\ndata types in order to identify lines that have desirable characteristics which\nare suitable to be taken forward in plant breeding programmes. There are a\nnumber of key morphological and physiological traits such as disease resistance\nand yield that are required to be maintained, and improved upon if a commercial\nvariety is to be successful. Computational tools that provide the ability to\npull this data together, and integrate with pedigree structure, will enable\nbreeders to make better decisions on which plant lines are used in crossings to\nmeet both critical demands for increased yield/production and adaptation to\nclimate change. Results: We have used a large and unique set of experimental\nbarley (H. vulgare) data to develop a prototype pedigree visualization system\nand performed a subjective user evaluation with domain experts to guide and\ndirect the development of an interactive pedigree visualization tool which we\nhave called Helium. Conclusions: We show that Helium allows users to easily\nintegrate a number of data types along with large plant pedigrees to offer an\nintegrated environment in which they can explore pedigree data. We have also\nverified that users were happy with the abstract representation of pedigrees\nthat we have used in our visualization tool.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jul 2014 16:26:59 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Shaw", "Paul D.", ""], ["Graham", "Martin", ""], ["Kennedy", "Jessie", ""], ["Milne", "Iain", ""], ["Marshall", "David F.", ""]]}, {"id": "1407.3757", "submitter": "Ivan Kolesar", "authors": "Ivan Kolesar, Julius Parulek, Ivan Viola, Stefan Bruckner,\n  Anne-Kristin Stavrum and Helwig Hauser", "title": "Illustrating Polymerization using Three-level Model Fusion", "comments": "BioVis 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in cell biology is steadily contributing new knowledge about many\ndifferent aspects of physiological processes like polymerization, both with\nrespect to the involved molecular structures as well as their related function.\nIllustrations of the spatio-temporal development of such processes are not only\nused in biomedical education, but also can serve scientists as an additional\nplatform for in-silico experiments. In this paper, we contribute a new,\nthree-level modeling approach to illustrate physiological processes from the\nclass of polymerization at different time scales. We integrate physical and\nempirical modeling, according to which approach suits the different involved\nlevels of detail best, and we additionally enable a simple form of interactive\nsteering while the process is illustrated. We demonstrate the suitability of\nour approach in the context of several polymerization processes and report from\na first evaluation with domain experts.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2014 20:18:05 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Kolesar", "Ivan", ""], ["Parulek", "Julius", ""], ["Viola", "Ivan", ""], ["Bruckner", "Stefan", ""], ["Stavrum", "Anne-Kristin", ""], ["Hauser", "Helwig", ""]]}, {"id": "1407.3948", "submitter": "Denys Matthies", "authors": "Denys J.C. Matthies, Felix M. Manke, Franz M\\\"uller, Charalampia\n  Makri, Christoph Anthes, Dieter Kranzlm\\\"uller", "title": "VR-Stepper: A Do-It-Yourself Game Interface For Locomotion In Virtual\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared to real world tasks, completing tasks in a virtual environment (VE)\nseldom involves the whole spectrum of skills the human body offers. User input\nin a VE is commonly accomplished through simple finger gestures, such as\nwalking in a scene by simply pressing a button, even if this kind of\ninteraction is not very suitable. In order to create a more intuitive and\nnatural interaction, diverse projects try to tackle the problem of locomotion\nin VEs by trying to enable a natural walking movement, which is also supposed\nto increase the level of immersion. Existing solutions such as treadmills are\nstill expensive and need additional fixation of the body. In this paper, we\ndescribe a simple and inexpensive way to build a useful locomotion interface\nusing a conventional sports stepper and an Arduino. This device enables control\nin a VE by walking-in-place and without the need for any additional fixation\ngadgets. We conducted a user study with 10 participants to evaluate the\nimpression on the joy and ease of use, immersion and reliability in comparison\nto other interfaces used for locomotion, such as the Wii Balance Board and a\nWand Joystick. We found out that the stepper is experienced slightly better in\nterms of immersion and joy of use. Furthermore, found that pressing buttons on\na Joystick was perceived to be more reliable.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 11:40:10 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Matthies", "Denys J. C.", ""], ["Manke", "Felix M.", ""], ["M\u00fcller", "Franz", ""], ["Makri", "Charalampia", ""], ["Anthes", "Christoph", ""], ["Kranzlm\u00fcller", "Dieter", ""]]}, {"id": "1407.3950", "submitter": "Anders Drachen Dr.", "authors": "Anders Drachen, Christian Thurau, Rafet Sifa, Christian Bauckhage", "title": "A Comparison of Methods for Player Clustering via Behavioral Telemetry", "comments": "Foundations of Digital Games 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of user behavior in digital games has been aided by the\nintroduction of user telemetry in game development, which provides\nunprecedented access to quantitative data on user behavior from the installed\ngame clients of the entire population of players. Player behavior telemetry\ndatasets can be exceptionally complex, with features recorded for a varying\npopulation of users over a temporal segment that can reach years in duration.\nCategorization of behaviors, whether through descriptive methods (e.g.\nsegmention) or unsupervised/supervised learning techniques, is valuable for\nfinding patterns in the behavioral data, and developing profiles that are\nactionable to game developers. There are numerous methods for unsupervised\nclustering of user behavior, e.g. k-means/c-means, Non-negative Matrix\nFactorization, or Principal Component Analysis. Although all yield behavior\ncategorizations, interpretation of the resulting categories in terms of actual\nplay behavior can be difficult if not impossible. In this paper, a range of\nunsupervised techniques are applied together with Archetypal Analysis to\ndevelop behavioral clusters from playtime data of 70,014 World of Warcraft\nplayers, covering a five year interval. The techniques are evaluated with\nrespect to their ability to develop actionable behavioral profiles from the\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 11:41:39 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Drachen", "Anders", ""], ["Thurau", "Christian", ""], ["Sifa", "Rafet", ""], ["Bauckhage", "Christian", ""]]}, {"id": "1407.4071", "submitter": "Cameron Mura", "authors": "Cameron Mura", "title": "Ten Simple Rules for Creating Biomolecular Graphics", "comments": "3 pages, 0 figures; see also the full-length article in PLoS\n  Computational Biology (cited below)", "journal-ref": "PLoS Computational Biology (2010), 6(8): e1000918", "doi": "10.1371/journal.pcbi.1000918", "report-no": null, "categories": "q-bio.BM cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One need only compare the number of three-dimensional molecular illustrations\nin the first (1990) and third (2004) editions of Voet & Voet's \"Biochemistry\"\nin order to appreciate this field's profound communicative value in modern\nbiological sciences -- ranging from medicine, physiology, and cell biology, to\npharmaceutical chemistry and drug design, to structural and computational\nbiology. The clich\\'e about a picture being worth a thousand words is quite\npoignant here: The information 'content' of an effectively-constructed piece of\nmolecular graphics can be immense. Because biological function arises from\nstructure, it is difficult to overemphasize the utility of visualization and\ngraphics in molding our current understanding of the molecular nature of\nbiological systems. Nevertheless, creating effective molecular graphics is not\neasy -- neither conceptually, nor in terms of effort required. The present\ncollection of Rules is meant as a guide for those embarking upon their first\nmolecular illustrations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jul 2014 17:48:16 GMT"}], "update_date": "2014-07-16", "authors_parsed": [["Mura", "Cameron", ""]]}, {"id": "1407.4395", "submitter": "Ming Jin", "authors": "Ming Jin, Ruoxi Jia, Zhoayi Kang, Ioannis C. Konstantakopoulos, Costas\n  Spanos", "title": "PresenceSense: Zero-training Algorithm for Individual Presence Detection\n  based on Power Monitoring", "comments": "BuildSys 2014", "journal-ref": null, "doi": "10.1109/TMC.2017.2684806", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-intrusive presence detection of individuals in commercial buildings is\nmuch easier to implement than intrusive methods such as passive infrared,\nacoustic sensors, and camera. Individual power consumption, while providing\nuseful feedback and motivation for energy saving, can be used as a valuable\nsource for presence detection. We conduct pilot experiments in an office\nsetting to collect individual presence data by ultrasonic sensors, acceleration\nsensors, and WiFi access points, in addition to the individual power monitoring\ndata. PresenceSense (PS), a semi-supervised learning algorithm based on power\nmeasurement that trains itself with only unlabeled data, is proposed, analyzed\nand evaluated in the study. Without any labeling efforts, which are usually\ntedious and time consuming, PresenceSense outperforms popular models whose\nparameters are optimized over a large training set. The results are interpreted\nand potential applications of PresenceSense on other data sources are\ndiscussed. The significance of this study attaches to space security, occupancy\nbehavior modeling, and energy saving of plug loads.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 17:51:55 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Jin", "Ming", ""], ["Jia", "Ruoxi", ""], ["Kang", "Zhoayi", ""], ["Konstantakopoulos", "Ioannis C.", ""], ["Spanos", "Costas", ""]]}, {"id": "1407.4409", "submitter": "Ming Jin", "authors": "Ruoxi Jia, Ming Jin, Costas J. Spanos", "title": "SoundLoc: Acoustic Method for Indoor Localization without Infrastructure", "comments": "BuildSys 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying locations of occupants is beneficial to energy management in\nbuildings. A key observation in indoor environment is that distinct functional\nareas are typically controlled by separate HVAC and lighting systems and room\nlevel localization is sufficient to provide a powerful tool for energy usage\nreduction by occupancy-based actuation of the building facilities. Based upon\nthis observation, this paper focuses on identifying the room where a person or\na mobile device is physically present. Existing room localization methods,\nhowever, require special infrastructure to annotate rooms.\n  SoundLoc is a room-level localization system that exploits the intrinsic\nacoustic properties of individual rooms and obviates the needs for\ninfrastructures. As we show in the study, rooms' acoustic properties can be\ncharacterized by Room Impulse Response (RIR). Nevertheless, obtaining precise\nRIRs is a time-consuming and expensive process. The main contributions of our\nwork are the following. First, a cost-effective RIR measurement system is\nimplemented and the Noise Adaptive Extraction of Reverberation (NAER) algorithm\nis developed to estimate room acoustic parameters in noisy conditions. Second,\na comprehensive physical and statistical analysis of features extracted from\nRIRs is performed. Also, SoundLoc is evaluated using the dataset consisting of\nten (10) different rooms. The overall accuracy of 97.8% achieved demonstrates\nthe potential to be integrated into automatic mapping of building space.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 18:16:00 GMT"}], "update_date": "2014-07-17", "authors_parsed": [["Jia", "Ruoxi", ""], ["Jin", "Ming", ""], ["Spanos", "Costas J.", ""]]}, {"id": "1407.4454", "submitter": "Mitja Trampus", "authors": "Daniele Pighin, Enrique Alfonseca, Felix Leif Keppmann, and Mitja\n  Trampus", "title": "Evaluation of the DiversiNews diversified news service", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we present the outcome of an extensive evaluation of the\nDiversiNews platform [8, 10] for diversified browsing of news, developed in the\nscope of the RENDER project. The evaluation was carried out along two main\ndirections: a component evaluation, in which we assessed the maturity of the\ncomponents underlying DiversiNews, and a user experience (UX) evaluation\ninvolving users of online news services. The results of the evaluation confirm\nthe high value of DiversiNews as a novel paradigm for diversity-aware news\nbrowsing.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2014 17:16:31 GMT"}], "update_date": "2014-07-20", "authors_parsed": [["Pighin", "Daniele", ""], ["Alfonseca", "Enrique", ""], ["Keppmann", "Felix Leif", ""], ["Trampus", "Mitja", ""]]}, {"id": "1407.4705", "submitter": "Paul Vickers", "authors": "Paul Vickers and Chris Laing and Tom Fairfax", "title": "Sonification of a Network's Self-Organized Criticality", "comments": null, "journal-ref": null, "doi": "10.1016/j.displa.2016.05.002", "report-no": null, "categories": "cs.HC cs.NI cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication networks involve the transmission and reception of large\nvolumes of data. Research indicates that network traffic volumes will continue\nto increase. These traffic volumes will be unprecedented and the behaviour of\nglobal information infrastructures when dealing with these data volumes is\nunknown. It has been shown that complex systems (including computer networks)\nexhibit self-organized criticality under certain conditions. Given the\npossibility in such systems of a sudden and spontaneous system reset the\ndevelopment of techniques to inform system administrators of this behaviour\ncould be beneficial. This article focuses on the combination of two dissimilar\nresearch concepts, namely sonification (a form of auditory display) and\nself-organized criticality (SOC). A system is described that sonifies in real\ntime an information infrastructure's self-organized criticality to alert the\nnetwork administrators of both normal and abnormal network traffic and\noperation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jul 2014 15:20:26 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Vickers", "Paul", ""], ["Laing", "Chris", ""], ["Fairfax", "Tom", ""]]}, {"id": "1407.4881", "submitter": "Bernard Meade", "authors": "Bernard F Meade, Christopher J Fluke, Steven Manos and Richard O\n  Sinnott", "title": "Are tiled display walls needed for astronomy?", "comments": "19 pages, 15 figures, accepted for publication in PASA (Publications\n  of the Astronomical Society of Australia)", "journal-ref": null, "doi": "10.1017/pasa.2014.29", "report-no": null, "categories": "astro-ph.IM cs.HC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Clustering commodity displays into a Tiled Display Wall (TDW) provides a\ncost-effective way to create an extremely high resolution display, capable of\napproaching the image sizes now gen- erated by modern astronomical instruments.\nAstronomers face the challenge of inspecting single large images, many similar\nimages simultaneously, and heterogeneous but related content. Many research\ninstitutions have constructed TDWs on the basis that they will improve the\nscientific outcomes of astronomical imagery. We test this concept by presenting\nsample images to astronomers and non- astronomers using a standard desktop\ndisplay (SDD) and a TDW. These samples include standard English words, wide\nfield galaxy surveys and nebulae mosaics from the Hubble telescope. These\nexperiments show that TDWs provide a better environment for searching for small\ntargets in large images than SDDs. It also shows that astronomers tend to be\nbetter at searching images for targets than non-astronomers, both groups are\ngenerally better when employing physical navigation as opposed to virtual\nnavigation, and that the combination of two non-astronomers using a TDW rivals\nthe experience of a single astronomer. However, there is also a large\ndistribution in aptitude amongst the participants and the nature of the content\nalso plays a significant role is success.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 03:42:01 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Meade", "Bernard F", ""], ["Fluke", "Christopher J", ""], ["Manos", "Steven", ""], ["Sinnott", "Richard O", ""]]}, {"id": "1407.5145", "submitter": "Yongtao Hu", "authors": "Yongtao Hu, Jan Kautz, Yizhou Yu and Wenping Wang", "title": "Speaker-following Video Subtitles", "comments": null, "journal-ref": null, "doi": "10.1145/2632111", "report-no": null, "categories": "cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for improving the presentation of subtitles in video\n(e.g. TV and movies). With conventional subtitles, the viewer has to constantly\nlook away from the main viewing area to read the subtitles at the bottom of the\nscreen, which disrupts the viewing experience and causes unnecessary eyestrain.\nOur method places on-screen subtitles next to the respective speakers to allow\nthe viewer to follow the visual content while simultaneously reading the\nsubtitles. We use novel identification algorithms to detect the speakers based\non audio and visual information. Then the placement of the subtitles is\ndetermined using global optimization. A comprehensive usability study indicated\nthat our subtitle placement method outperformed both conventional\nfixed-position subtitling and another previous dynamic subtitling method in\nterms of enhancing the overall viewing experience and reducing eyestrain.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jul 2014 05:06:16 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Hu", "Yongtao", ""], ["Kautz", "Jan", ""], ["Yu", "Yizhou", ""], ["Wang", "Wenping", ""]]}, {"id": "1407.5527", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam and Mohamed Cheriet", "title": "Quality of Experience (QoE) beyond Quality of Service (QoS) as its\n  baseline: QoE at the Interface of Experience Domains", "comments": "31 pages, 3 figures, and 1 table. Working Paper WP-RFM-14-02", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a new approach to the definition of the quality of experience\nis presented. By considering the quality of service as a baseline, that portion\nof the QoE that can be inferred from the QoS is excluded, and then the rest of\nthe QoE is approached with the notion of QoE at a Boundary (QoEaaB). With the\nQoEaaB as the core of the proposed approach, various potential boundaries, and\ntheir associated unseen opportunities to improve the QoE are discussed. In\nparticular, property, contract, SLA, and content are explored in terms of their\nboundaries and also their associated QoEaaB. With an interest in online video\ndelivery, management of resource sharing and isolation associated with\nmulti-tenant operations is considered. It is concluded that the proposed QoEaaB\ncan bring a new perspective in QoE modeling and assessment toward a more\nenriched approach to improving the experience based on innovation and deep\nconnectivity among actors.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2014 15:13:06 GMT"}, {"version": "v2", "created": "Thu, 24 Jul 2014 16:30:35 GMT"}, {"version": "v3", "created": "Mon, 18 Aug 2014 18:20:23 GMT"}, {"version": "v4", "created": "Mon, 9 Feb 2015 21:23:13 GMT"}], "update_date": "2015-02-11", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1407.5903", "submitter": "Felipe Ortega", "authors": "Felipe Ortega, Gregorio Convertino, Massimo Zancanaro, Tiziano\n  Piccardi", "title": "Assessing the Performance of Question-and-Answer Communities Using\n  Survival Analysis", "comments": "10 pages, 3 figures, example code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Question-&-Answer (QA) websites have emerged as efficient platforms for\nknowledge sharing and problem solving. In particular, the Stack Exchange\nplatform includes some of the most popular QA communities to date, such as\nStack Overflow. Initial metrics used to assess the performance of these\ncommunities include summative statistics like the percentage of resolved\nquestions or the average time to receive and validate correct answers. However,\nmore advanced methods for longitudinal data analysis can provide further\ninsights on the QA process, by enabling identification of key predictive\nfactors and systematic comparison of performance across different QA\ncommunities. In this paper, we apply survival analysis to a selection of\ncommunities from the Stack Exchange platform. We illustrate the advantages of\nusing the proposed methodology to characterize and evaluate the performance of\nQA communities, and then point to some implications for the design and\nmanagement of QA platforms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 15:29:49 GMT"}, {"version": "v2", "created": "Tue, 29 Jul 2014 08:24:00 GMT"}], "update_date": "2014-07-30", "authors_parsed": [["Ortega", "Felipe", ""], ["Convertino", "Gregorio", ""], ["Zancanaro", "Massimo", ""], ["Piccardi", "Tiziano", ""]]}, {"id": "1407.5910", "submitter": "Rajib Rana", "authors": "Rajib Rana, John Reilly, Raja Jurdak, Wen Hu, Xue Li, Jeffrey Soar", "title": "Affect Sensing on Smartphone - Possibilities of Understanding Cognitive\n  Decline in Aging Population", "comments": "This paper has been withdrawn due to some conceptual error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to increasing sensing capacity, smartphones offer unprecedented\nopportunity to monitor human health. Affect sensing is one such essential\nmonitoring that can be achieved on smartphones. Information about affect can be\nuseful for many modern applications. In particular, it can be potentially used\nfor understanding cognitive decline in aging population. In this paper we\npresent an overview of the existing literature that offer affect sensing on\nsmartphone platform. Most importantly, we present the challenges that need to\nbe addressed to make affect sensing on smartphone a reality.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jul 2014 15:44:35 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2015 01:24:14 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2015 03:49:18 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Rana", "Rajib", ""], ["Reilly", "John", ""], ["Jurdak", "Raja", ""], ["Hu", "Wen", ""], ["Li", "Xue", ""], ["Soar", "Jeffrey", ""]]}, {"id": "1407.7131", "submitter": "Tanmay Sinha", "authors": "Tanmay Sinha, Patrick Jermann, Nan Li, Pierre Dillenbourg", "title": "Your click decides your fate: Inferring Information Processing and\n  Attrition Behavior from MOOC Video Clickstream Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore video lecture interaction in Massive Open Online\nCourses (MOOCs), which is central to student learning experience on these\neducational platforms. As a research contribution, we operationalize video\nlecture clickstreams of students into cognitively plausible higher level\nbehaviors, and construct a quantitative information processing index, which can\naid instructors to better understand MOOC hurdles and reason about\nunsatisfactory learning outcomes. Our results illustrate how such a metric\ninspired by cognitive psychology can help answer critical questions regarding\nstudents' engagement, their future click interactions and participation\ntrajectories that lead to in-video & course dropouts. Implications for research\nand practice are discussed\n", "versions": [{"version": "v1", "created": "Sat, 26 Jul 2014 14:18:00 GMT"}, {"version": "v2", "created": "Tue, 16 Sep 2014 23:41:58 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Sinha", "Tanmay", ""], ["Jermann", "Patrick", ""], ["Li", "Nan", ""], ["Dillenbourg", "Pierre", ""]]}, {"id": "1407.7143", "submitter": "Tanmay Sinha", "authors": "Tanmay Sinha", "title": "\"Your click decides your fate\": Leveraging clickstream patterns from\n  MOOC videos to infer students' information processing & attrition behavior", "comments": "Undergraduate (B.Tech, Computer Science) Thesis Report, 2014, Vellore\n  Institute of Technology, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With an expansive and ubiquitously available gold mine of educational data,\nMassive Open Online courses (MOOCs) have become the an important foci of\nlearning analytics research. The hope is that this new surge of development\nwill bring the vision of equitable access to lifelong learning opportunities\nwithin practical reach. MOOCs offer many valuable learning experiences to\nstudents, from video lectures, readings, assignments and exams, to\nopportunities to connect and collaborate with others through threaded\ndiscussion forums and other Web 2.0 technologies. Nevertheless, despite all\nthis potential, MOOCs have so far failed to produce evidence that this\npotential is being realized in the current instantiation of MOOCs. In this\nwork, we primarily explore video lecture interaction in Massive Open Online\nCourses (MOOCs), which is central to student learning experience on these\neducational platforms. As a research contribution, we operationalize video\nlecture clickstreams of students into behavioral actions, and construct a\nquantitative information processing index, that can aid instructors to better\nunderstand MOOC hurdles and reason about unsatisfactory learning outcomes. Our\nresults illuminate the effectiveness of developing such a metric inspired by\ncognitive psychology, towards answering critical questions regarding students'\nengagement, their future click interactions and participation trajectories that\nlead to in-video dropouts. We leverage recurring click behaviors to\ndifferentiate distinct video watching profiles for students in MOOCs.\nAdditionally, we discuss about prediction of complete course dropouts,\nincorporating diverse perspectives from statistics and machine learning, to\noffer a more nuanced view into how the second generation of MOOCs be benefited,\nif course instructors were to better comprehend factors that lead to student\nattrition.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jul 2014 17:53:58 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Sinha", "Tanmay", ""]]}, {"id": "1407.7276", "submitter": "Philipp Mayr", "authors": "Zeljko Carevic, Philipp Mayr", "title": "Recommender Systems using Pennant Diagrams in Digital Libraries", "comments": "3 pages, paper accepted for the 13th European Networked Knowledge\n  Organization Systems (NKOS) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In digital libraries recommendations can be valuable for researchers, e.g.\nrecommending related literature to a given context. Typically, in a scientific\ncontext the simple presentation of related content is not sufficient. Often the\nusers demand a more detailed view on the connection of a document and its\nspecific recommendations. The aim of pennants introduced by Howard White (2007)\nis to provide the user with a graph showing the relatedness / distance between\na given document and related documents. Co-citation but also co-occurrence\nanalysis are established methods for finding related documents to a seed. A\nseed could be for instance an author, a keyword, or a publication. In this\npaper we introduce a recommender system in the digital library sowiport using\npennant diagrams which can be created from co-citation and/or co-occurrence\nanalysis. The presentation at the NKOS workshop will present demos of pennants\nin sowiport and will elaborate on practical questions in visualizing pennants\nand evaluating the utility of pennants for search.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 19:39:55 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Carevic", "Zeljko", ""], ["Mayr", "Philipp", ""]]}, {"id": "1407.7277", "submitter": "Mahdi Nasrullah Al-Ameen", "authors": "Mahdi Nasrullah Al-Ameen (1), S M Taiabul Haque (1), Matthew Wright\n  (1) ((1) The University of Texas at Arlington, Arlington, TX, USA)", "title": "Q-A: Towards the Solution of Usability-Security Tension in User\n  Authentication", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users often choose passwords that are easy to remember but also easy to guess\nby attackers. Recent studies have revealed the vulnerability of textual\npasswords to shoulder surfing and keystroke loggers. It remains a critical\nchallenge in password research to develop an authentication scheme that\naddresses these security issues, in addition to offering good memorability.\nMotivated by psychology research on humans' cognitive strengths and weaknesses,\nwe explore the potential of cognitive questions as a way to address the major\nchallenges in user authentication. We design, implement, and evaluate Q-A, a\nnovel cognitive-question-based password system that requires a user to enter\nthe letter at a given position in her answer for each of six personal questions\n(e.g. \"What is the name of your favorite childhood teacher?\"). In this scheme,\nthe user does not need to memorize new, artificial information as her\nauthentication secret. Our scheme offers 28 bits of theoretical password space,\nwhich has been found sufficient to prevent online brute-force attacks. Q-A is\nalso robust against shoulder surfing and keystroke loggers. We conducted a\nmulti-session in-lab user study to evaluate the usability of Q-A; 100% of users\nwere able to remember their Q-A password over the span of one week, although\nlogin times were high. We compared our scheme with random six character\npasswords and found that login success rate in Q-A was significantly higher.\nBased on our results, we suggest that Q-A would be most appropriate in contexts\nthat demand high security and where logins occur infrequently (e.g., online\nbank accounts).\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 19:41:55 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Al-Ameen", "Mahdi Nasrullah", "", "The University of Texas at Arlington, Arlington, TX, USA"], ["Haque", "S M Taiabul", "", "The University of Texas at Arlington, Arlington, TX, USA"], ["Wright", "Matthew", "", "The University of Texas at Arlington, Arlington, TX, USA"]]}, {"id": "1407.7313", "submitter": "Himanshu Raghuvanshi", "authors": "Pawan Patidar, Himanshu Raghuvanshi, Sayan Sarcar", "title": "Quickpie: An Interface for Fast and Accurate Eye Gazed based Text Entry", "comments": "This 6 page paper has been accepted as a student design contest paper\n  at India HCI 2013 Conference, held at Bangalore, India during 24th to 27th\n  September,2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pie menus are suggested as powerful tool for eye gaze based text entry among\nvarious interfaces developed so far. If pie menus are used with multiple depth\nlayers then multiple saccades are required per selection of item, which is\ninefficient because it consumes more time. Also dwell time selection method is\nlimited in performance because higher dwell time suffers from inefficiency\nwhile lower one from inaccuracy. To overcome problems with multiple depth\nlayers and dwell time, we designed Quickpie, an interface for eye gaze based\ntext entry with only one depth layer of pie menu and selection border as\nselection method instead of dwell time. We investigated various parameters like\nnumber of slices in pie menu, width characters and safe region, enlarged angle\nof slice and selection methods to achieve better performance. Our experiment\nresults indicates that six number of slices with width of characters area 120\npx performs better as compared to other designs.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2014 03:49:09 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Patidar", "Pawan", ""], ["Raghuvanshi", "Himanshu", ""], ["Sarcar", "Sayan", ""]]}, {"id": "1407.7314", "submitter": "Wu-Chen Su", "authors": "Wu-Chen Su", "title": "A Preliminary Survey of Knowledge Discovery on Smartphone Applications\n  (apps): Principles, Techniques and Research Directions for E-health", "comments": "6 pages, 2 figures, 2 tables, 2014 ICME International Conference on\n  Complex Medical Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People usually seek out varied information to deal with their health\nproblems. However, the large volume of information available may present\nchallenges for the public to distinguish good from suboptimal advice. How to\nensure the right information for the right person at the right time and place\nhas always been a challenge. For example, smart phone application vendor\nmarkets provide a varied selection of health applications for users. However,\nthere is a lack of substantive reference information for consumers to base\nwell-informed decisions about whether or not to adopt the applications they\nreview and to ascertain the validity of the information provided by these\ne-health solutions. Thus, this study aims to review the existing relevant\nresearch about smart phone applications and identify pertinent research\nquestions in the field of knowledge discovery for health applications that can\nbe addressed in future research. Therefore, this study can be seen as an\nimportant step for researchers to explore this domain and extend our work for\nthe well-being of public.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2014 03:49:34 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Su", "Wu-Chen", ""]]}, {"id": "1407.8004", "submitter": "Karen Renaud", "authors": "Tony McBryan, Karen Renaud, J. Paul Siebert", "title": "An Investigation into the use of Images as Password Cues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Computer users are generally authenticated by means of a password.\nUnfortunately passwords are often forgotten and replacement is expensive and\ninconvenient. Some people write their passwords down but these records can\neasily be lost or stolen. The option we explore is to find a way to cue\npasswords securely. The specific cueing technique we report on in this paper\nemploys images as cues. The idea is to elicit textual descriptions of the\nimages, which can then be used as passwords. We have defined a set of metrics\nfor the kind of image that could function effectively as a password cue. We\nidentified five candidate image types and ran an experiment to identify the\nimage class with the best performance in terms of the defined metrics.\n  The first experiment identified inkblot-type images as being superior. We\ntested this image, called a cueblot, in a real-life environment. We allowed\nusers to tailor their cueblot until they felt they could describe it, and they\nthen entered a description of the cueblot as their password. The cueblot was\ndisplayed at each subsequent authentication attempt to cue the password.\nUnfortunately, we found that users did not exploit the cueing potential of the\ncueblot, and while there were a few differences between textual descriptions of\ncueblots and non-cued passwords, they were not compelling. Hence our attempts\nto alleviate the difficulties people experience with passwords, by giving them\naccess to a tailored cue, did not have the desired effect. We have to conclude\nthat the password mechanism might well be unable to benefit from bolstering\nactivities such as this one.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 11:37:13 GMT"}, {"version": "v2", "created": "Sat, 9 Aug 2014 09:34:39 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["McBryan", "Tony", ""], ["Renaud", "Karen", ""], ["Siebert", "J. Paul", ""]]}, {"id": "1407.8007", "submitter": "Karen Renaud", "authors": "Karen Renaud and Judith Ramsay", "title": "How Helpful is Colour-Cueing of PIN Entry?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  21st Century citizens are faced with the need to remember numbers of PINs\n(Personal Identification Numbers) in order to do their daily business, and they\noften have difficulties due to human memory limitations. One way of helping\nthem could be by providing cues during the PIN entry process. The provision of\ncues that would only be helpful to the PIN owner is challenging because the cue\nshould only make sense to the legitimate user, and not to a random observer. In\nthis paper we report on an empirical study where we added colour to the PINpad\nto provide an implicit memory cue to PINpad users. We compared the impact of\ncolour PINpads as opposed to grey ones. As expected, the ability to recall a\nPIN deteriorated significantly over time irrespective of the type of PINpad\nused. However, there was ultimately no improvement in the ability to recall\nPINs when using colour PINpads.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jul 2014 11:50:25 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Renaud", "Karen", ""], ["Ramsay", "Judith", ""]]}]