[{"id": "1503.00174", "submitter": "Julia Haines", "authors": "Julia Katherine Haines", "title": "CSCW Principles to Support Citizen Science", "comments": "Proceedings of the 5th International Conference on Collaborative\n  Innovation Networks COINs15, Tokyo, Japan March 12-14, 2015\n  (arXiv:1502.01142)", "journal-ref": null, "doi": null, "report-no": "coins15/2015/33", "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Citizen science changes the way scientific research is pursued. It opens up\ndata collection and analysis to the general public, to the wisdom of crowds. In\nthis emerging area, there is much research to be done to better understand how\nwe can develop citizen science infrastructure and continue the democratization\nof science. In creating such systems, there is much we can learn from\nprinciples that have emerged out of computer-supported cooperative work (CSCW)\nresearch. In this paper, I use a nine-step framework to highlight where CSCW\nknowledge can contribute.\n", "versions": [{"version": "v1", "created": "Sat, 28 Feb 2015 20:32:13 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Haines", "Julia Katherine", ""]]}, {"id": "1503.00197", "submitter": "Jeffrey Horon", "authors": "Jeff Horon", "title": "Emerging Methods and Tools for Sparking New Global Creative Networks", "comments": "Proceedings of the 5th International Conference on Collaborative\n  Innovation Networks COINs15, Tokyo, Japan March 12-14, 2015\n  (arXiv:1502.01142)", "journal-ref": null, "doi": null, "report-no": "coins15/2015/29", "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging methods and tools are changing the ways participants in global\ncreative networks become aware of each other and proceed to interact. Some\nweb-based resources intended to spark new collaborations in creative networks\nhave been plagued by dependence on fragmented or out-of-date information,\nhaving shallow recall (e.g. limited to a list of manually curated keywords),\noffering poor interconnectivity with other systems, and/or obtaining low\nend-user adoption. Increased availability of information about creative network\nparticipants' activities and outputs (e.g. completed sponsored research\nprojects and published results, aggregated into global databases), coupled with\nadvancement in information processing techniques like Natural Language\nProcessing, enables new web-based technologies for discovering subject matter\nexperts, facilities, and networks of current and potential collaborators.\nLarge-scale data resources and NLP allow modern versions of these tools to\navoid the problems of having sparse data and also provide for deep recall\nacross many disciplinary vocabularies. These are \"passive\" technologies, from\nthe perspective of the network participant, because the agent must undertake an\naction to use the information resources. Emerging \"active\" methods and tools\nutilize the same types of information and technologies, but actively intervene\nin the formation of the creative network by suggesting connections and\narranging virtual or physical interactions. Active approaches can achieve very\nhigh end-user adoption rates. Both active and passive methods strive to use\ndata-driven approaches to form better-than-chance awareness among networks of\npotential collaborators. Recent case studies suggest the existence of\nrepeatable strategies for facilitating data-driven matching and\nbetter-than-chance interactions designed to spark new global creative networks.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 00:26:08 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Horon", "Jeff", ""]]}, {"id": "1503.00288", "submitter": "Yang Song", "authors": "Yang Song and Robert van Boeschoten", "title": "Success factors for Crowdfunding founders and funders", "comments": "Proceedings of the 5th International Conference on Collaborative\n  Innovation Networks COINs15, Tokyo, Japan March 12-14, 2015\n  (arXiv:1502.01142)", "journal-ref": null, "doi": null, "report-no": "coins15/2015/26", "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdfunding has been used as one of the effective ways for entrepreneurs to\nraise funding especially in creative industries. Individuals as well as\norganizations are paying more attentions to the emergence of new crowdfunding\nplatforms. In the Netherlands, the government is also trying to help artists\naccess financial resources through crowdfunding platforms. This research aims\nat discovering the success factors for crowdfunding projects through\ncrowdfunding platforms from both founders and funders perspective. We designed\nour own website for founders and funders to observe crowdfunding behaviors. Our\nresearch will contribute to crowdfunding success factors related to issues of\ntrust and decision making and provide practical recommendations for\npractitioners and researchers.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2015 14:44:28 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Song", "Yang", ""], ["van Boeschoten", "Robert", ""]]}, {"id": "1503.00561", "submitter": "Riccardo Spolaor", "authors": "Mauro Conti, Claudio Guarisco and Riccardo Spolaor", "title": "CAPTCHaStar! A novel CAPTCHA based on interactive shape discovery", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, most websites on which users can register (e.g., email\nproviders and social networks) adopted CAPTCHAs (Completely Automated Public\nTuring test to tell Computers and Humans Apart) as a countermeasure against\nautomated attacks. The battle of wits between designers and attackers of\nCAPTCHAs led to current ones being annoying and hard to solve for users, while\nstill being vulnerable to automated attacks.\n  In this paper, we propose CAPTCHaStar, a new image-based CAPTCHA that relies\non user interaction. This novel CAPTCHA leverages the innate human ability to\nrecognize shapes in a confused environment. We assess the effectiveness of our\nproposal for the two key aspects for CAPTCHAs, i.e., usability, and resiliency\nto automated attacks. In particular, we evaluated the usability, carrying out a\nthorough user study, and we tested the resiliency of our proposal against\nseveral types of automated attacks: traditional ones; designed ad-hoc for our\nproposal; and based on machine learning. Compared to the state of the art, our\nproposal is more user friendly (e.g., only some 35% of the users prefer current\nsolutions, such as text-based CAPTCHAs) and more resilient to automated\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2015 15:07:04 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2015 09:42:00 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Conti", "Mauro", ""], ["Guarisco", "Claudio", ""], ["Spolaor", "Riccardo", ""]]}, {"id": "1503.00582", "submitter": "Bahador Saket", "authors": "Bahador Saket, Carlos Scheidegger and Stephen Kobourov", "title": "Towards Understanding Enjoyment and Flow in Information Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, evaluation studies in information visualization have measured\neffectiveness by assessing performance time and accuracy. More recently, there\nhas been a concerted effort to understand aspects beyond time and errors. In\nthis paper we study enjoyment, which, while arguably not the primary goal of\nvisualization, has been shown to impact performance and memorability. Different\nmodels of enjoyment have been proposed in psychology, education and gaming; yet\nthere is no standard approach to evaluate and measure enjoyment in\nvisualization. In this paper we relate the flow model of Csikszentmihalyi to\nMunzner's nested model of visualization evaluation and previous work in the\narea. We suggest that, even though previous papers tackled individual elements\nof flow, in order to understand what specifically makes a visualization\nenjoyable, it might be necessary to measure all specific elements.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2015 15:46:49 GMT"}], "update_date": "2015-03-03", "authors_parsed": [["Saket", "Bahador", ""], ["Scheidegger", "Carlos", ""], ["Kobourov", "Stephen", ""]]}, {"id": "1503.01145", "submitter": "Todd Davies", "authors": "Lu Xiao, Weiyu Zhang, Anna Przybylska, Anna De Liddo, Gregorio\n  Convertino, Todd Davies, Mark Klein", "title": "Design for Online Deliberative Processes and Technologies: Towards a\n  Multidisciplinary Research Agenda", "comments": "CHI'15 Extended Abstracts, Apr 18-23, 2015, Seoul, Republic of Korea,\n  ACM 978-1-4503-3146-3/15/04, 4 pages", "journal-ref": null, "doi": "10.1145/2702613.2727687", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been rapidly growing interest in studying and designing online\ndeliberative processes and technologies. This SIG aims at providing a venue for\ncontinuous and constructive dialogue between social, political and cognitive\nsciences as well as computer science, HCI, and CSCW. Through an online\ncommunity and a modified version of world cafe discussions, we contribute to\nthe definition of the theoretical building blocks, the identification of a\nresearch agenda for the CHI community, and the network of individuals from\nacademia, industry, and the public sector who share interests in different\naspects of online deliberation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 22:07:47 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2015 03:12:50 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Xiao", "Lu", ""], ["Zhang", "Weiyu", ""], ["Przybylska", "Anna", ""], ["De Liddo", "Anna", ""], ["Convertino", "Gregorio", ""], ["Davies", "Todd", ""], ["Klein", "Mark", ""]]}, {"id": "1503.01732", "submitter": "Stefan Hellweger", "authors": "Stefan Hellweger, Xiaofeng Wang, Pekka Abrahamsson", "title": "The Contemporary Understanding of User Experience in Practice", "comments": "8 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  User Experience (UX) has been a buzzword in agile literature in recent years.\nHowever, often UX remains as a vague concept and it may be hard to understand\nthe very nature of it in the context of agile software development. This paper\nexplores the multifaceted UX literature, emphasizes the multi-dimensional\nnature of the concept and organizes the current state-of-the-art knowledge. As\na starting point to better understand the contemporary meaning of UX assigned\nby practitioners, we selected four UX blogs and performed an analysis using a\nframework derived from the literature review. The preliminary results show that\nthe practitioners more often focus on interaction between product and user and\nview UX from design perspective predominantly. While the economical perspective\nreceives little attention in literature, it is evident in practitioners\nwritings. Our study opens up a promising line of request of the contemporary\nmeaning of UX in practice.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2015 19:07:31 GMT"}], "update_date": "2015-03-09", "authors_parsed": [["Hellweger", "Stefan", ""], ["Wang", "Xiaofeng", ""], ["Abrahamsson", "Pekka", ""]]}, {"id": "1503.01850", "submitter": "Stefan Hellweger", "authors": "Stefan Hellweger and Xiaofeng Wang", "title": "What is User Experience Really: towards a UX Conceptual Framework", "comments": "4 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1503.01732", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  For more then a decade the term User Experience (UX) has been highly debated\nand defined in many ways. However, often UX remains as a vague concept and it\nmay be hard to understand the very nature of it. In this paper we aimed at\nproviding a better understanding of this concept. We explored the multi-faceted\nUX literature, reviewing the current state-of- the-art knowledge and\nemphasizing the multi-dimensional nature of the concept. Based on the\nliterature review we built a conceptual framework of UX using the elements that\nare linked to it and reported in different studies. To show the potential use\nof the framework, we examined the UX delivered by different phone applications\non different mobile devices using the elements in the framework. Several\ninteresting insights have been obtained in terms of how the phone applications\ndeliver different UX. Our study opens up a promising line of investigating the\ncontemporary meaning of UX.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2015 05:22:16 GMT"}], "update_date": "2015-03-09", "authors_parsed": [["Hellweger", "Stefan", ""], ["Wang", "Xiaofeng", ""]]}, {"id": "1503.01895", "submitter": "Charith Perera", "authors": "Charith Perera, Saeed Aghaee, Alan Blackwell", "title": "Natural Notation for the Domestic Internet of Things", "comments": "Proceedings of the 5th International symposium on End-User\n  Development (IS-EUD), Madrid, Spain, May, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study explores the use of natural language to give instructions that\nmight be interpreted by Internet of Things (IoT) devices in a domestic `smart\nhome' environment. We start from the proposition that reminders can be\nconsidered as a type of end-user programming, in which the executed actions\nmight be performed either by an automated agent or by the author of the\nreminder. We conducted an experiment in which people wrote sticky notes\nspecifying future actions in their home. In different conditions, these notes\nwere addressed to themselves, to others, or to a computer agent.We analyse the\nlinguistic features and strategies that are used to achieve these tasks,\nincluding the use of graphical resources as an informal visual language. The\nfindings provide a basis for design guidance related to end-user development\nfor the Internet of Things.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2015 10:00:07 GMT"}], "update_date": "2015-03-09", "authors_parsed": [["Perera", "Charith", ""], ["Aghaee", "Saeed", ""], ["Blackwell", "Alan", ""]]}, {"id": "1503.02314", "submitter": "Mahdi Nasrullah Al-Ameen", "authors": "Mahdi Nasrullah Al-Ameen, Matthew Wright, Shannon Scielzo", "title": "Towards Making Random Passwords Memorable: Leveraging Users' Cognitive\n  Ability Through Multiple Cues", "comments": "Will appear at CHI 2015 Conference, to be held at Seoul, Korea", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the choice, users produce passwords reflecting common strategies and\npatterns that ease recall but offer uncertain and often weak security.\nSystem-assigned passwords provide measurable security but suffer from poor\nmemorability. To address this usability-security tension, we argue that systems\nshould assign random passwords but also help with memorization and recall. We\ninvestigate the feasibility of this approach with CuedR, a novel\ncued-recognition authentication scheme that provides users with multiple cues\n(visual, verbal, and spatial) and lets them choose the cues that best fit their\nlearning process for later recognition of system-assigned keywords. In our lab\nstudy, all 37 of our participants could log in within three attempts one week\nafter registration (mean login time: 38.0 seconds). A pilot study on using\nmultiple CuedR passwords also showed 100% recall within three attempts. Based\non our results, we suggest appropriate applications for CuedR, such as\nfinancial and e-commerce accounts.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2015 19:47:24 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Al-Ameen", "Mahdi Nasrullah", ""], ["Wright", "Matthew", ""], ["Scielzo", "Shannon", ""]]}, {"id": "1503.02377", "submitter": "Xianyi Gao", "authors": "Xianyi Gao, Gradeigh D. Clark, Janne Lindqvist", "title": "Of Two Minds, Multiple Addresses, and One History: Characterizing\n  Opinions, Knowledge, and Perceptions of Bitcoin Across Groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital currencies represent a new method for exchange and investment that\ndiffers strongly from any other fiat money seen throughout history. A digital\ncurrency makes it possible to perform all financial transactions without the\nintervention of a third party to act as an arbiter of verification; payments\ncan be made between two people with degrees of anonymity, across continents, at\nany denomination, and without any transaction fees going to a central\nauthority. The most successful example of this is Bitcoin, introduced in 2008,\nwhich has experienced a recent boom of popularity, media attention, and\ninvestment. With this surge of attention, we became interested in finding out\nhow people both inside and outside the Bitcoin community perceive Bitcoin --\nwhat do they think of it, how do they feel, and how knowledgeable they are.\nTowards this end, we conducted the first interview study (N = 20) with\nparticipants to discuss Bitcoin and other related financial topics. Some of our\nmajor findings include: not understanding how Bitcoin works is not a barrier\nfor entry, although non-user participants claim it would be for them and that\nuser participants are in a state of cognitive dissonance concerning the role of\ngovernments in the system. Our findings, overall, contribute to knowledge\nconcerning Bitcoin and attitudes towards digital currencies in general.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2015 06:06:53 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Gao", "Xianyi", ""], ["Clark", "Gradeigh D.", ""], ["Lindqvist", "Janne", ""]]}, {"id": "1503.02903", "submitter": "Tomasz Rutkowski", "authors": "Moonjeong Chang and Tomasz M. Rutkowski", "title": "Two-step Input Spatial Auditory BCI for Japanese Kana Characters", "comments": "7 pages, 2 figures, accepted for publication in Advances in Cognitive\n  Neurodynamics Volume 5 -- Proceedings of the 5th International Conference on\n  Cognitive Neurodynamics (ICCN 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present an auditory stimulus optimization and a pilot study of a two-step\ninput speller application combined with a spatial auditory brain-computer\ninterface (saBCI) for paralyzed users. The application has been developed for\n45, out of 48 defining the full set, Japanese kana characters in a two-step\ninput procedure setting for an easy-to-use BCI-speller interface. The user\nfirst selects the representative letter of a subset, defining the second step.\nIn the second step, the final choice is made. At each interfacing step, the\nchoices are classified based on the P300 event related potential (ERP)\nresponses captured in the EEG, as in the classic oddball paradigm. The BCI\nonline experiment and EEG responses classification results of the pilot study\nconfirm the effectiveness of the proposed spelling method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2015 13:51:34 GMT"}], "update_date": "2015-03-11", "authors_parsed": [["Chang", "Moonjeong", ""], ["Rutkowski", "Tomasz M.", ""]]}, {"id": "1503.03400", "submitter": "Karthik Gopalakrishnan", "authors": "Dhruv Chand, Karthik Gopalakrishnan, Nisha KK, Mudit Sinha, Shreya\n  Sriram", "title": "Get 'em Moles! : Learning Spelling and Pronunciation through an\n  Educational Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Get 'em Moles! is a single-player educational game inspired by the classic\narcade game Whac-A-Mole. Primarily designed for touchscreen devices, Get 'em\nMoles! aims to teach English spelling and pronunciation through engaging game\nplay. This paper describes the game, design decisions in the form of elements\nthat support learning, preliminary play-testing results, and future work.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2015 16:14:16 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2015 13:33:54 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Chand", "Dhruv", ""], ["Gopalakrishnan", "Karthik", ""], ["KK", "Nisha", ""], ["Sinha", "Mudit", ""], ["Sriram", "Shreya", ""]]}, {"id": "1503.03403", "submitter": "Karthik Gopalakrishnan", "authors": "Dhruv Chand, Karthik Gopalakrishnan, Nisha KK, Mudit Sinha, Shreya\n  Sriram", "title": "Bublz! : Playing with Bubbles to Develop Mathematical Thinking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We encounter mathematical problems in various forms in our lives, thus making\nmathematical thinking an important human ability. In this paper, we present\nBublz!, a simple, click-driven game for children to engage in and develop\nmathematical thinking in an enjoyable manner.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2015 16:20:51 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2015 13:28:19 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Chand", "Dhruv", ""], ["Gopalakrishnan", "Karthik", ""], ["KK", "Nisha", ""], ["Sinha", "Mudit", ""], ["Sriram", "Shreya", ""]]}, {"id": "1503.03584", "submitter": "Maria Spichkova", "authors": "Maria Spichkova, Huai Liu, Mohsen Laali, Heinz W. Schmidt", "title": "Human Factors in Software Reliability Engineering", "comments": "Preprint, Workshop on Applications of Human Error Research to Improve\n  Software Engineering (WAHESE) at ICSE 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our vision of the integration of human factors\nengineering into the software development process. The aim of this approach is\nto improve the quality of software and to deal with human errors in a\nsystematic way.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 04:40:08 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Spichkova", "Maria", ""], ["Liu", "Huai", ""], ["Laali", "Mohsen", ""], ["Schmidt", "Heinz W.", ""]]}, {"id": "1503.03614", "submitter": "Ankit Chaudhary", "authors": "Jagdish L. Raheja, A. Singhal, A. Chaudhary", "title": "Android based Portable Hand Sign Recognition System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These days mobile devices like phones or tablets are very common among people\nof all age. They are connected with network and provide seamless communications\nthrough internet or cellular services. These devices can be a big help for the\npeople who are not able to communicate properly and even in emergency\nconditions. A disabled person who is not able to speak or a person who speak a\ndifferent language, these devices can be a boon for them as understanding,\ntranslating and speaking systems for these people. This chapter discusses a\nportable android based hand sign recognition system which can be used by\ndisabled people. This chapter shows a part of on-going project. Computer Vision\nbased techniques were used for image analysis and PCA was used after image\ntokenizer for recognition. This method was tested with webcam results to make\nsystem more robust.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 07:27:27 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Raheja", "Jagdish L.", ""], ["Singhal", "A.", ""], ["Chaudhary", "A.", ""]]}, {"id": "1503.03660", "submitter": "Zeon Trevor Fernando", "authors": "Zeon Trevor Fernando", "title": "Capturing, Documenting and Visualizing Search Contexts for building\n  Multimedia Corpora", "comments": "Undergraduate (B.Tech Hons, Computer Science) Thesis Report, 2014,\n  Vellore Institute of Technology, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Social Science research, multimedia documents are often collected to\nanswer particular research questions like: \"Which of the aesthetic properties\nof a photo are considered important on the web\" or \"How has Street Art\ndeveloped over the past 50 years\". Therefore, a researcher generally issues\nmultiple queries to a number of search engines. This activity may span over\nlong time intervals and results in a collection which can be further analyzed.\nDocumenting the collection building process which includes the context of the\ncarried out searches is imperative for social scientists to reproduce their\nresearch. Such context documentation consists of several user actions and\nsearch attributes like: the issued queries; the results clicked and saved;\nduration a particular result was viewed for; the set of results that was\ndisplayed but neither clicked, nor saved; as well as user annotations like\ncomments or tags. In this work we will describe a search process tracking\nmodule and a search history visualization module. These modules can be\nintegrated into keyword based search systems through a REST API which was\ndeveloped to help capture, document and revisit past search contexts while\nbuilding a web corpora. Finally, we detail the implementation of how the module\nwas integrated into the LearnWeb2.0 platform - a multimedia web2.0 search and\nsharing application which can obtain resources from various web2.0 tools such\nas Youtube, Bing, Flickr, etc using keyword search.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 10:11:59 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Fernando", "Zeon Trevor", ""]]}, {"id": "1503.03790", "submitter": "Nikolaos Karapanos", "authors": "Nikolaos Karapanos, Claudio Marforio, Claudio Soriente and Srdjan\n  Capkun", "title": "Sound-Proof: Usable Two-Factor Authentication Based on Ambient Sound", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-factor authentication protects online accounts even if passwords are\nleaked. Most users, however, prefer password-only authentication. One reason\nwhy two-factor authentication is so unpopular is the extra steps that the user\nmust complete in order to log in. Currently deployed two-factor authentication\nmechanisms require the user to interact with his phone to, for example, copy a\nverification code to the browser. Two-factor authentication schemes that\neliminate user-phone interaction exist, but require additional software to be\ndeployed.\n  In this paper we propose Sound-Proof, a usable and deployable two-factor\nauthentication mechanism. Sound-Proof does not require interaction between the\nuser and his phone. In Sound-Proof the second authentication factor is the\nproximity of the user's phone to the device being used to log in. The proximity\nof the two devices is verified by comparing the ambient noise recorded by their\nmicrophones. Audio recording and comparison are transparent to the user, so\nthat the user experience is similar to the one of password-only authentication.\nSound-Proof can be easily deployed as it works with current phones and major\nbrowsers without plugins. We build a prototype for both Android and iOS. We\nprovide empirical evidence that ambient noise is a robust discriminant to\ndetermine the proximity of two devices both indoors and outdoors, and even if\nthe phone is in a pocket or purse. We conduct a user study designed to compare\nthe perceived usability of Sound-Proof with Google 2-Step Verification.\nParticipants ranked Sound-Proof as more usable and the majority would be\nwilling to use Sound-Proof even for scenarios in which two-factor\nauthentication is optional.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2015 16:06:59 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2015 13:23:25 GMT"}, {"version": "v3", "created": "Mon, 3 Aug 2015 11:52:39 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Karapanos", "Nikolaos", ""], ["Marforio", "Claudio", ""], ["Soriente", "Claudio", ""], ["Capkun", "Srdjan", ""]]}, {"id": "1503.04208", "submitter": "Robert West", "authors": "Robert West, Ashwin Paranjape, Jure Leskovec", "title": "Mining Missing Hyperlinks from Human Navigation Traces: A Case Study of\n  Wikipedia", "comments": null, "journal-ref": null, "doi": "10.1145/2736277.2741666", "report-no": null, "categories": "cs.SI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperlinks are an essential feature of the World Wide Web. They are\nespecially important for online encyclopedias such as Wikipedia: an article can\noften only be understood in the context of related articles, and hyperlinks\nmake it easy to explore this context. But important links are often missing,\nand several methods have been proposed to alleviate this problem by learning a\nlinking model based on the structure of the existing links. Here we propose a\nnovel approach to identifying missing links in Wikipedia. We build on the fact\nthat the ultimate purpose of Wikipedia links is to aid navigation. Rather than\nmerely suggesting new links that are in tune with the structure of existing\nlinks, our method finds missing links that would immediately enhance\nWikipedia's navigability. We leverage data sets of navigation paths collected\nthrough a Wikipedia-based human-computation game in which users must find a\nshort path from a start to a target article by only clicking links encountered\nalong the way. We harness human navigational traces to identify a set of\ncandidates for missing links and then rank these candidates. Experiments show\nthat our procedure identifies missing links of high quality.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2015 20:03:07 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["West", "Robert", ""], ["Paranjape", "Ashwin", ""], ["Leskovec", "Jure", ""]]}, {"id": "1503.04375", "submitter": "Xiao Zhang", "authors": "Xiao Zhang, Kan Fang, Gregory Francis", "title": "Optimization of Switch Keyboards", "comments": "In Proceedings of the 15th International ACM SIGACCESS Conference on\n  Computers and Accessibility 2013", "journal-ref": null, "doi": "10.1145/2513383.2513394", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients with motor control difficulties often \"type\" on a computer using a\nswitch keyboard to guide a scanning cursor to text elements. We show how to\noptimize some parts of the design of switch keyboards by casting the design\nproblem as mixed integer programming. A new algorithm to find an optimized\ndesign solution is approximately 3600 times faster than a previous algorithm,\nwhich was also susceptible to finding a non-optimal solution. The optimization\nrequires a model of the probability of an entry error, and we show how to build\nsuch a model from experimental data. Example optimized keyboards are\ndemonstrated.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2015 02:48:08 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2015 01:05:42 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Zhang", "Xiao", ""], ["Fang", "Kan", ""], ["Francis", "Gregory", ""]]}, {"id": "1503.04967", "submitter": "Stefan Profanter", "authors": "Stefan Profanter", "title": "Implementation and Evaluation of multimodal input/output channels for\n  task-based industrial robot programming", "comments": "Master Thesis in Robotics, Cognition, Intelligence", "journal-ref": null, "doi": "10.13140/2.1.1044.0008", "report-no": null, "categories": "cs.RO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming industrial robots is not very intuitive, and the programmer has\nto be a domain expert for e.g. welding and programming to know how the task is\noptimally executed. For SMEs such employees are not affordable, nor\ncost-effective. Therefore a new system is needed where domain experts from a\nspecific area, like welding or assembly, can easily program a robot without\nknowing anything about programming languages or how to use TeachPads. Such a\nsystem needs to be flexible to adapt to new tasks and functions. These\nrequirements can be met by using a task based programming approach where the\nrobot program is built up using a hierarchical structure of process, tasks and\nskills. It also needs to be intuitive so that domain experts don't need much\ntraining time on handling the system. Intuitive interaction is achieved by\nusing different input and output modalities like gesture input, speech input,\nor touch input which are suitable for the current task.\n  This master thesis focuses on the implementation of a user interface (GUI)\nfor task based industrial robot programming and evaluates different input\nmodalities (gesture, speech, touch, pen input) for the interaction with the\nsystem. The evaluation is based on a user study conducted with 30 participants\nas a Wizard-Of-Oz experiment, where non expert users had to program assembly\nand welding tasks to an industrial robot, using the previously developed GUI\nand various input and output modalities.\n  The findings of the task analysis and user study are then used for creating a\nsemantic description which will be used in the cognitive robotics-worker cell\nfor automatically inferring required system components, and to provide the best\nsuited input modality.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 09:50:01 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Profanter", "Stefan", ""]]}, {"id": "1503.04973", "submitter": "Stephan Sigg", "authors": "Stephan Sigg and Kai Kunze and Xiaoming Fu", "title": "Recent Advances and Challenges in Ubiquitous Sensing", "comments": "Submitted to PIEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous sensing is tightly coupled with activity recognition. This survey\nreviews recent advances in Ubiquitous sensing and looks ahead on promising\nfuture directions. In particular, Ubiquitous sensing crosses new barriers\ngiving us new ways to interact with the environment or to inspect our psyche.\nThrough sensing paradigms that parasitically utilise stimuli from the noise of\nenvironmental, third-party pre-installed systems, sensing leaves the boundaries\nof the personal domain. Compared to previous environmental sensing approaches,\nthese new systems mitigate high installation and placement cost by providing a\nrobustness towards process noise. On the other hand, sensing focuses inward and\nattempts to capture mental activities such as cognitive load, fatigue or\nemotion through advances in, for instance, eye-gaze sensing systems or\ninterpretation of body gesture or pose. This survey summarises these\ndevelopments and discusses current research questions and promising future\ndirections.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 10:03:59 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Sigg", "Stephan", ""], ["Kunze", "Kai", ""], ["Fu", "Xiaoming", ""]]}, {"id": "1503.05959", "submitter": "Pietro Michelucci", "authors": "Pietro Michelucci", "title": "Human Computation and Convergence", "comments": "Pre-publication draft of chapter. 24 pages, 3 figures; added\n  references to page 1 and 3, and corrected typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are the most effective integrators and producers of information,\ndirectly and through the use of information-processing inventions. As these\ninventions become increasingly sophisticated, the substantive role of humans in\nprocessing information will tend toward capabilities that derive from our most\ncomplex cognitive processes, e.g., abstraction, creativity, and applied world\nknowledge. Through the advancement of human computation - methods that leverage\nthe respective strengths of humans and machines in distributed\ninformation-processing systems - formerly discrete processes will combine\nsynergistically into increasingly integrated and complex information processing\nsystems. These new, collective systems will exhibit an unprecedented degree of\npredictive accuracy in modeling physical and techno-social processes, and may\nultimately coalesce into a single unified predictive organism, with the\ncapacity to address societies most wicked problems and achieve planetary\nhomeostasis.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 22:34:42 GMT"}, {"version": "v2", "created": "Wed, 6 May 2015 18:54:29 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Michelucci", "Pietro", ""]]}, {"id": "1503.05972", "submitter": "Jing Du", "authors": "Jing Du", "title": "Serious Game for Human Environmental Consciousness Education in\n  Residents Daily Life", "comments": "Incomplete study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been challenging to find ways to educate people to have better\nenvironmental consciousness. In some cases, people do not know what the right\nbehaviors are to protect the environment. Game engine has been used in the AEC\nindustry for visualization. However, it has barely been used in environmental\nconsciousness education, for example, what operation can reduce building energy\nconsumption, what items are recyclables. As social psychology studies show that\nvideo game can influence human behavior, a good designed game should provide\nthe game player with right incentives and guide the users to make wiser choices\nfor better environmental protection. This paper discussed a method to use\nserious game engines to educate the players the right actions that should be\ntaken under in different scenarios. These actions in real life will results in\na better environmental protection. The game proposed in this study is for\nresidential home operation. Other scenarios such as restaurant operation,\ngrocery store operations are discussed as expansion of this study. The game\nplayers points will be calculated based on their performance on different\nchoices and when they surpass a certain level, different rewards will be gained\nin order for them to adjust their current living style. The purpose of the game\nis to raise the environmental consciousness among the game players and educate\nthem the right actions they can make to better protect the environment while\nthey are spending time on games.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 00:24:29 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 00:20:03 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Du", "Jing", ""]]}, {"id": "1503.06009", "submitter": "Anamika Chhabra", "authors": "Anamika Chhabra, S. R. S. Iyengar, Poonam Saini, Rajesh Shreedhar Bhat", "title": "A Framework for Textbook Enhancement and Learning using Crowdsourced\n  Annotations", "comments": "11 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a significant improvement in the educational aids in terms of\neffective teaching-learning process, most of the educational content available\nto the students is less than optimal in the context of being up-to-date,\nexhaustive and easy-to-understand. There is a need to iteratively improve the\neducational material based on the feedback collected from the students'\nlearning experience. This can be achieved by observing the students'\ninteractions with the content, and then having the authors modify it based on\nthis feedback. Hence, we aim to facilitate and promote communication between\nthe communities of authors, instructors and students in order to gradually\nimprove the educational material. Such a system will also help in students'\nlearning process by encouraging student-to-student teaching. Underpinning these\nobjectives, we provide the framework of a platform named Crowdsourced\nAnnotation System (CAS) where the people from these communities can collaborate\nand benefit from each other. We use the concept of in-context annotations,\nthrough which, the students can add their comments about the given text while\nlearning it. An experiment was conducted on 60 students who try to learn an\narticle of a textbook by annotating it for four days. According to the result\nof the experiment, most of the students were highly satisfied with the use of\nCAS. They stated that the system is extremely useful for learning and they\nwould like to use it for learning other concepts in future.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 07:25:04 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 09:45:40 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2015 06:20:54 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Chhabra", "Anamika", ""], ["Iyengar", "S. R. S.", ""], ["Saini", "Poonam", ""], ["Bhat", "Rajesh Shreedhar", ""]]}, {"id": "1503.06300", "submitter": "Rylan Conway", "authors": "Rylan T. Conway and Evan W. Sangaline", "title": "A Monte Carlo Simulation Approach for Quantitatively Evaluating Keyboard\n  Layouts for Gesture Input", "comments": "24 pages, 11 figures, 1 table", "journal-ref": null, "doi": "10.1016/j.ijhcs.2016.10.001", "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Gesture typing is a method of text entry that is ergonomically well-suited to\nthe form factor of touchscreen devices and allows for much faster input than\ntapping each letter individually. The QWERTY keyboard was, however, not\ndesigned with gesture input in mind and its particular layout results in a high\nfrequency of gesture recognition errors. In this paper, we describe a new\napproach to quantifying the frequency of gesture input recognition errors\nthrough the use of modeling and simulating realistically imperfect user input.\nWe introduce new methodologies for modeling randomized gesture inputs,\nefficiently reconstructing words from gestures on arbitrary keyboard layouts,\nand using these in conjunction with a frequency weighted lexicon to perform\nMonte Carlo evaluations of keyboard error rates or any other arbitrary metric.\nAn open source framework, Dodona, is also provided that allows for these\ntechniques to be easily employed and customized in the evaluation of a wide\nspectrum of possible keyboards and input methods. Finally, we perform an\noptimization procedure over permutations of the QWERTY keyboard to demonstrate\nthe effectiveness of this approach and describe ways that future analyses can\nbuild upon these results.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2015 13:32:59 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 16:29:19 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Conway", "Rylan T.", ""], ["Sangaline", "Evan W.", ""]]}, {"id": "1503.06555", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Sumitkumar Kanoje, Sheetal Girase, Debajyoti Mukhopadhyay", "title": "User Profiling for Recommendation System", "comments": "5 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation system is a type of information filtering systems that\nrecommend various objects from a vast variety and quantity of items which are\nof the user interest. This results in guiding an individual in personalized way\nto interesting or useful objects in a large space of possible options. Such\nsystems also help many businesses to achieve more profits to sustain in their\nfiled against their rivals. But looking at the amount of information which a\nbusiness holds it becomes difficult to identify the items of user interest.\nTherefore personalization or user profiling is one of the challenging tasks\nthat give access to user relevant information which can be used in solving the\ndifficult task of classification and ranking items according to an individuals\ninterest. Profiling can be done in various ways such assupervised or\nunsupervised, individual or group profiling, distributive or and non\ndistributive profiling. Our focus in this paper will be on the dataset which we\nwill use, we identify some interesting facts by using Weka Tool that can be\nused for recommending the items from dataset. Our aim is to present a novel\ntechnique to achieve user profiling in recommendation system.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 08:47:35 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Kanoje", "Sumitkumar", ""], ["Girase", "Sheetal", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1503.06958", "submitter": "Rushan Ziatdinov", "authors": "Sajid Musa, Rushan Ziatdinov, Omer Faruk Sozcu, Carol Griffiths", "title": "Developing Educational Computer Animation Based on Human Personality\n  Types", "comments": "19 pages, 19 figures, 18 tables", "journal-ref": "European Journal of Contemporary Education, 2015, Vol. 11, Issue\n  1, pp. 52-71", "doi": "10.13187/ejced.2015.11.52", "report-no": null, "categories": "cs.HC cs.CY cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer animation in the past decade has become one of the most noticeable\nfeatures of technology-based learning environments. With today's high\neducational demands as well as the lack of time provided for certain courses,\nclassical educational methods have shown deficiencies in keeping up with the\ndrastic changes observed in the digital era. Without taking into account\nvarious significant factors such as gender, age, level of interest and memory\nlevel, educational animation may turn out to be insufficient for learners or\nfail to meet their needs. However, we have noticed that the applications of\nanimation for education have been given only inadequate attention, and\nstudents' personality types have never been taken into account. We suggest\nthere is an interesting relationship here, and propose essential factors in\ncreating educational animations based on students' personality types.\nParticularly, we investigate how information in computer animation may be\npresented in a preferable way based on the fundamental elements of computer\nanimation. The present study believes that it is likely to have wide benefits\nin the field of education. Considering the personality types in designing\neducational computer animations with the aid of gathered empirical results\nmight be a promising avenue to enhance the learning process.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 09:27:14 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["Musa", "Sajid", ""], ["Ziatdinov", "Rushan", ""], ["Sozcu", "Omer Faruk", ""], ["Griffiths", "Carol", ""]]}, {"id": "1503.07001", "submitter": "Eug\\'enio Rodrigues", "authors": "Eug\\'enio Rodrigues, Ana Rita Amaral, Ad\\'elio Rodrigues Gaspar,\n  \\'Alvaro Gomes, Manuel Carlos Gameiro da Silva, Carlos Henggeler Antunes", "title": "GerAPlanO - A new building design tool: design generation, thermal\n  assessment and performance optimization", "comments": "6 pages, 3 figures, Proceedings of Energy for Sustainability 2015\n  Conference: Sustainable Cities: Designing for People and the Planet, Coimbra,\n  14-15 May, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building practitioners (architects, engineers, energy managers) are showing a\ngrowing interest in the design of more energy efficient and livable buildings.\nThe best way to predict how a building will behave regarding energy consumption\nand thermal comfort is to use a dynamic simulation tool. However, the use of\nthis kind of tools is difficult on a daily basis practice due to the heuristic\nand exploratory nature of the architectural design process. To deal with this\ndifficulty, the University of Coimbra and three companies have been working on\nthe development of a prototype design aiding tool, specifically devoted to the\nspace planning phase of building design, under the project GerAPlanO (Automatic\nGeneration of Architecture Floor plans with Energy Optimization). This project\naims to combine the capabilities of design generation techniques, thermal\nassessment programs, and design optimization methods to provide assistance to\ndecision makers. This paper presents the overall concept, as well as the\ncurrent status of development of this tool.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 12:12:43 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["Rodrigues", "Eug\u00e9nio", ""], ["Amaral", "Ana Rita", ""], ["Gaspar", "Ad\u00e9lio Rodrigues", ""], ["Gomes", "\u00c1lvaro", ""], ["da Silva", "Manuel Carlos Gameiro", ""], ["Antunes", "Carlos Henggeler", ""]]}, {"id": "1503.07159", "submitter": "Preeti Bhargava", "authors": "Preeti Bhargava, Shivsubramani Krishnamoorthy, Ashok Agrawala", "title": "Modeling context and situations in pervasive computing environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pervasive computing environments, various entities often have to cooperate\nand integrate seamlessly in a \\emph{situation} which can, thus, be considered\nas an amalgamation of the context of several entities interacting and\ncoordinating with each other, and often performing one or more activities.\nHowever, none of the existing context models and ontologies address situation\nmodeling. In this paper, we describe the design, structure and implementation\nof a generic, flexible and extensible context ontology called Rover Context\nModel Ontology (RoCoMO) for context and situation modeling in pervasive\ncomputing systems and environments. We highlight several limitations of the\nexisting context models and ontologies, such as lack of provision for\nprovenance, traceability, quality of context, multiple representation of\ncontextual information, as well as support for security, privacy and\ninteroperability, and explain how we are addressing these limitations in our\napproach. We also illustrate the applicability and utility of RoCoMO using a\npractical and extensive case study.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 17:14:02 GMT"}], "update_date": "2015-03-26", "authors_parsed": [["Bhargava", "Preeti", ""], ["Krishnamoorthy", "Shivsubramani", ""], ["Agrawala", "Ashok", ""]]}, {"id": "1503.07401", "submitter": "Keisuke Hasegawa", "authors": "Keisuke Hasegawa, Tatsuma Sakurai, Yasutoshi Makino, Hiroyuki Shinoda", "title": "Manual Character Transmission by Presenting Trajectories of 7mm-high\n  Letters in One Second", "comments": "Submitted in IEEE Transactions on Haptics", "journal-ref": null, "doi": "10.1109/TOH.2016.2517625", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report a method of intuitively transmitting symbolic\ninformation to untrained users via only their hands without using any visual or\nauditory cues. Our simple concept is presenting three-dimensional letter\ntrajectories to the user's hand via a stylus which is mechanically manipulated.\nBy this simple method, in our experiments, participants were able to read 14\nmm-high lower-case letters displayed at a rate of one letter per second with an\naccuracy rate of 71.9% in their first trials, which was improved to 91.3% after\na five-minute training period. These results showed small individual\ndifferences among participants (standard deviation of 12.7% in the first trials\nand 6.7% after training). We also found that this accuracy was still retained\nto a high level (85.1% with SD of 8.2%) even when the letters were reduced to a\nheight of 7 mm. Thus, we revealed that sighted adults potentially possess the\nability to read small letters accurately at normal writing speed using their\nhands.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2015 08:43:02 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2015 08:11:19 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Hasegawa", "Keisuke", ""], ["Sakurai", "Tatsuma", ""], ["Makino", "Yasutoshi", ""], ["Shinoda", "Hiroyuki", ""]]}, {"id": "1503.07716", "submitter": "Gayatri Venugopal Miss", "authors": "Gayatri Venugopal", "title": "A Review of Popular Applications on Google Play - Do They Cater to\n  Visually Impaired Users?", "comments": "19 pages, 1 figure, 3 tables", "journal-ref": "Indian Journal of Science and Technology, Vol 8 S4, 221 to 239,\n  February 2015", "doi": "10.17485/ijst/2015/v8iS4/61436", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of applications on online mobile application stores is increasing\nat a rapid rate. Smart-phones are used by a wide range of people varying in\nage, and also in the ability to use a smart phone. With the increasing\ndependency on smart-phones, the paper aims to determine whether the popular\napplications on Google Play, the official store for Android applications, can\nbe used by people with vision impairment. The accessibility of the applications\nwas tested using an external keyboard, and TalkBack, an accessibility tool\ndeveloped by Google. It was found that several popular applications on the\nstore were not designed keeping accessibility in mind. It was observed that\nthere exists a weak positive relationship between the popularity of the\napplication and its accessibility. A framework is proposed that can be used by\ndevelopers to improve the accessibility of an application. The paper also\ndiscusses the programming aspects to be considered while developing an Android\napplication, so that the application can be used by sighted as well as visually\nimpaired users.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 12:56:20 GMT"}], "update_date": "2015-03-27", "authors_parsed": [["Venugopal", "Gayatri", ""]]}, {"id": "1503.08398", "submitter": "Zimu Yuan", "authors": "Zimu Yuan", "title": "A Cyber-Human Interaction Based System on Mobile Phone for Indoor\n  Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study the Cyber-Human Interaction (CHI) based approach\nthat the \"Human\" part sets a list of location-based objectives and makes the\npathway decision whereas the \"Cyber\" part provides the pathway suggestion,\ninfer heuristics from the environment along the pathway and incrementally\nresolve the location-based objectives with new heuristics for indoor\nlocalization. For this study, we implement a CHI-based system on mobile phone.\nThe CHI-based system offers the pathway suggestion and the solution of the\nlocation-based objectives based on its trajectory management. Without any\npriori knowledge on the area of interest and any aid from other equipments, a\nlaborer can achieve his location-based objectives by walking through the area\nof interest and simultaneously online interacting with the CHI-based system\ninstalled in his phone. In evaluation, we conduct the experiments and show the\nadvantage CHI in reducing the time cost and the expense cost for the laborer.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2015 08:35:33 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Yuan", "Zimu", ""]]}, {"id": "1503.08866", "submitter": "Bin Li", "authors": "Bin Li, Berenice Mettler, Timonthy M. Kowalewski", "title": "Towards Data-Driven Hierarchical Surgical Skill Analysis", "comments": "M2CAI 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper evaluates methods of hierarchical skill analysis developed in\naerospace to the problem of surgical skill assessment and modeling. The\nanalysis employs tool motion data of Fundamental of Laparoscopic Skills (FLS)\ntasks collected from clinicians of various skill levels at three different\nclinical teaching hospitals in the United States. Outcomes are evaluated based\non their ability to provide relevant information about the underlying processes\nacross the entire system hierarchy including control, guidance and planning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2015 22:35:03 GMT"}], "update_date": "2015-04-01", "authors_parsed": [["Li", "Bin", ""], ["Mettler", "Berenice", ""], ["Kowalewski", "Timonthy M.", ""]]}]