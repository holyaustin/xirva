[{"id": "1612.00185", "submitter": "Lo\\\"ic Sevrin", "authors": "Lo\\\"ic Sevrin, Norbert Noury, Nacer Abouchi, Fabrice Jumel, Bertrand\n  Massot, Jacques Saraydaryan", "title": "Detection of collaborative activity with Kinect depth cameras", "comments": "Engineering in Medicine and Biology Society (EMBC), 2016", "journal-ref": null, "doi": "10.1109/EMBC.2016.7592089", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The health status of elderly subjects is highly correlated to their\nactivities together with their social interactions. Thus, the long term\nmonitoring in home of their health status, shall also address the analysis of\ncollaborative activities. This paper proposes a preliminary approach of such a\nsystem which can detect the simultaneous presence of several subjects in a\ncommon area using Kinect depth cameras. Most areas in home being dedicated to\nspecific tasks, the localization enables the classification of tasks, whether\ncollaborative or not. A scenario of a 24 hours day shrunk into 24 minutes was\nused to validate our approach. It pointed out the need of artifacts removal to\nreach high specificity and good sensitivity.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 09:26:45 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Sevrin", "Lo\u00efc", ""], ["Noury", "Norbert", ""], ["Abouchi", "Nacer", ""], ["Jumel", "Fabrice", ""], ["Massot", "Bertrand", ""], ["Saraydaryan", "Jacques", ""]]}, {"id": "1612.00203", "submitter": "Alessia Amelio Dr.", "authors": "Darko Brodi\\'c, Alessia Amelio", "title": "Analysis of the Human-Computer Interaction on the Example of Image-based\n  CAPTCHA by Association Rule Mining", "comments": "13 pages, 2 figures, 6 tables, 5th International Workshop on\n  Symbiotic Interaction (Symbiotic), Padua, Italy, 29-30 September 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper analyzes the interaction between humans and computers in terms of\nresponse time in solving the image-based CAPTCHA. In particular, the analysis\nfocuses on the attitude of the different Internet users in easily solving four\ndifferent types of image-based CAPTCHAs which include facial expressions like:\nanimated character, old woman, surprised face, worried face. To pursue this\ngoal, an experiment is realized involving 100 Internet users in solving the\nfour types of CAPTCHAs, differentiated by age, Internet experience, and\neducation level. The response times are collected for each user. Then,\nassociation rules are extracted from user data, for evaluating the dependence\nof the response time in solving the CAPTCHA from age, education level and\nexperience in internet usage by statistical analysis. The results implicitly\ncapture the users' psychological states showing in what states the users are\nmore sensible. It reveals to be a novelty and a meaningful analysis in the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 11:24:09 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 12:52:21 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Brodi\u0107", "Darko", ""], ["Amelio", "Alessia", ""]]}, {"id": "1612.00347", "submitter": "Arash Eshghi", "authors": "Dimitrios Kalatzis, Arash Eshghi, Oliver Lemon", "title": "Bootstrapping incremental dialogue systems: using linguistic knowledge\n  to learn from minimal data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for inducing new dialogue systems from very small amounts\nof unannotated dialogue data, showing how word-level exploration using\nReinforcement Learning (RL), combined with an incremental and semantic grammar\n- Dynamic Syntax (DS) - allows systems to discover, generate, and understand\nmany new dialogue variants. The method avoids the use of expensive and\ntime-consuming dialogue act annotations, and supports more natural\n(incremental) dialogues than turn-based systems. Here, language generation and\ndialogue management are treated as a joint decision/optimisation problem, and\nthe MDP model for RL is constructed automatically. With an implemented system,\nwe show that this method enables a wide range of dialogue variations to be\nautomatically captured, even when the system is trained from only a single\ndialogue. The variants include question-answer pairs, over- and\nunder-answering, self- and other-corrections, clarification interaction,\nsplit-utterances, and ellipsis. This generalisation property results from the\nstructural knowledge and constraints present within the DS grammar, and\nhighlights some limitations of recent systems built using machine learning\ntechniques only.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 16:49:04 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Kalatzis", "Dimitrios", ""], ["Eshghi", "Arash", ""], ["Lemon", "Oliver", ""]]}, {"id": "1612.00582", "submitter": "Stina Carstensen", "authors": "Stina Lyck Carstensen, Jens Madsen and Jan Larsen", "title": "Predicting Changes in Affective States using Neural Networks", "comments": "NIPS 2016 Workshop on Machine Learning for Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge of patients affective state could prove to be crucial for\nhealth-care professionals in both diagnosis and treatment, however, this\nrequires patients to report how they feel. In practice the sampling rate of\naffective states needs to be kept low, in order to ensure that the patients can\nrest. Furthermore using traditional methods of measuring affective states, is\nnot always possible, e.g. patients can be incapable of verbal communications.\nIn this study we explore the prediction of peoples self-reported affective\nstate by measuring multiple physiological signals. We use different Neural\nnetworks (NN) setups and compare with different multiple linear regression\n(MLR) setups for prediction of changes in affective states. The results showed\nthat NN and MLR predicted the change in affective states with accuracies of\n91.88% and 89.10%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 07:44:00 GMT"}, {"version": "v2", "created": "Thu, 11 May 2017 12:47:30 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Carstensen", "Stina Lyck", ""], ["Madsen", "Jens", ""], ["Larsen", "Jan", ""]]}, {"id": "1612.00653", "submitter": "Antti Kangasr\\\"a\\\"asi\\\"o", "authors": "Antti Kangasr\\\"a\\\"asi\\\"o, Kumaripaba Athukorala, Andrew Howes, Jukka\n  Corander, Samuel Kaski, Antti Oulasvirta", "title": "Inferring Cognitive Models from Data using Approximate Bayesian\n  Computation", "comments": "To appear in CHI'2017", "journal-ref": null, "doi": "10.1145/3025453.3025576", "report-no": null, "categories": "cs.HC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem for HCI researchers is to estimate the parameter values\nof a cognitive model from behavioral data. This is a difficult problem, because\nof the substantial complexity and variety in human behavioral strategies. We\nreport an investigation into a new approach using approximate Bayesian\ncomputation (ABC) to condition model parameters to data and prior knowledge. As\nthe case study we examine menu interaction, where we have click time data only\nto infer a cognitive model that implements a search behaviour with parameters\nsuch as fixation duration and recall probability. Our results demonstrate that\nABC (i) improves estimates of model parameter values, (ii) enables meaningful\ncomparisons between model variants, and (iii) supports fitting models to\nindividual users. ABC provides ample opportunities for theoretical HCI research\nby allowing principled inference of model parameter values and their\nuncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 12:20:47 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 12:15:47 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Kangasr\u00e4\u00e4si\u00f6", "Antti", ""], ["Athukorala", "Kumaripaba", ""], ["Howes", "Andrew", ""], ["Corander", "Jukka", ""], ["Kaski", "Samuel", ""], ["Oulasvirta", "Antti", ""]]}, {"id": "1612.00985", "submitter": "Fabian Fl\\\"ock", "authors": "Martin K\\\"orner, Tatiana Sennikova, Florian Windh\\\"auser, Claudia\n  Wagner and Fabian Fl\\\"ock", "title": "Wikiwhere: An interactive tool for studying the geographical provenance\n  of Wikipedia references", "comments": "4 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikipedia articles about the same topic in different language editions are\nbuilt around different sources of information. For example, one can find very\ndifferent news articles linked as references in the English Wikipedia article\ntitled \"Annexation of Crimea by the Russian Federation\" than in its German\ncounterpart (determined via Wikipedia's language links). Some of this\ndifference can of course be attributed to the different language proficiencies\nof readers and editors in separate language editions, yet, although including\nEnglish-language news sources seems to be no issue in the German edition,\nEnglish references that are listed do not overlap highly with the ones in the\narticle's English version. Such patterns could be an indicator of bias towards\ncertain national contexts when referencing facts and statements in Wikipedia.\nHowever, determining for each reference which national context it can be traced\nback to, and comparing the link distributions to each other is infeasible for\ncasual readers or scientists with non-technical backgrounds. Wikiwhere answers\nthe question where Web references stem from by analyzing and visualizing the\ngeographic location of external reference links that are included in a given\nWikipedia article. Instead of relying solely on the IP location of a given URL\nour machine learning models consider several features.\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2016 16:45:26 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 10:44:56 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["K\u00f6rner", "Martin", ""], ["Sennikova", "Tatiana", ""], ["Windh\u00e4user", "Florian", ""], ["Wagner", "Claudia", ""], ["Fl\u00f6ck", "Fabian", ""]]}, {"id": "1612.01067", "submitter": "Junnan Yu", "authors": "Junnan Yu, Xuna Ma, Ting Han", "title": "Four-Dimensional Usability Investigation of Image CAPTCHA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image CAPTCHA, aiming at effectively distinguishing human users from\nmalicious script attacks, has been an important mechanism to protect online\nsystems from spams and abuses. Despite the increasing interests in developing\nand deploying image CAPTCHAs, the usability aspect of those CAPTCHAs has hardly\nbeen explored systematically. In this paper, the universal design factors of\nimage CAPTCHAs, such as image layouts, quantities, sizes, tilting angles and\ncolors were experimentally evaluated through the following four dimensions:\neye-tracking, efficiency, effectiveness and satisfaction. The cognitive\nprocesses revealed by eye-tracking indicate that the distribution of eye gaze\nis equally assigned to each candidate image and irrelevant to the variation of\nimage contents. In addition, the gazing plot suggests that more than 70% of the\nparticipants inspected CAPTCHA images row-by-row, which is more efficient than\nscanning randomly. Those four-dimensional evaluations essentially suggest that\nsquare and horizontal rectangle are the preferred layout; image quantities may\nnot exceed 16 while the image color is insignificant. Meanwhile, the image size\nand tilting angle are suggested to be larger than 55 pixels x 55 pixels and\nwithin -45~45 degrees, respectively. Basing on those usability experiment\nresults, we proposed a design guideline that is expected to be useful for\ndeveloping more usable image CAPTCHAs.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 05:18:53 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Yu", "Junnan", ""], ["Ma", "Xuna", ""], ["Han", "Ting", ""]]}, {"id": "1612.01070", "submitter": "Junnan Yu", "authors": "Junnan Yu, Xuna Ma, Ting Han", "title": "Usability Investigation on the Localization of Text CAPTCHAs: Take\n  Chinese Characters as a Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text CAPTCHA has been an effective means to protect online systems from spams\nand abuses caused by automatic scripts which pretend to be human beings.\nHowever, nearly all the Text CAPTCHA designs in nowadays are based on English\ncharacters, which may not be the most user-friendly option for non-English\nspeakers. Therefore, under the background of globalization, there is an\nincreasing interest in designing local-language CAPTCHA, which is expected to\nbe more usable for native speakers. However, systematic studies on the\nusability of localized CAPTCHAs are rare, and a general procedure for the\ndesign of usable localized CAPTCHA is still unavailable. Here, we\ncomprehensively explored the design of CAPTCHAs based on Chinese characters\nfrom a usability perspective: cognitive processes of solving alphanumeric and\nChinese CAPTCHAs are analyzed, followed by a usability comparison of those two\ntypes of CAPTCHAs and the evaluation of intrinsic design factors of Chinese\nCAPTCHAs. It was found that Chinese CAPTCHAs could be equally usable comparing\nwith alphanumeric ones. Meanwhile, guidelines for the design of usable Chinese\nCAPTCHAs were also presented. Moreover, those design practices were also\nsummarized as a general procedure which is expected to be applicable for the\ndesign of CAPTCHAs based on other languages.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 05:34:58 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Yu", "Junnan", ""], ["Ma", "Xuna", ""], ["Han", "Ting", ""]]}, {"id": "1612.02172", "submitter": "Anders Drachen Dr.", "authors": "Adam Als\\'en, Julian Runge, Anders Drachen, Daniel Klapper", "title": "Play With Me? Understanding and Measuring the Social Aspect of Casual\n  Gaming", "comments": "Preprint version for PA workshop 2016. 7 pages. 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social gaming is today a pervasive phenomenon. Driven by the advent of social\nnetworks and the digitization of game distribution. In this paper the impact of\ndigitization and so-cial networks such as Facebook on digital games is\nde-scribed and evaluated. This impact follows several vectors, including the\nintroduction of new game formats and extend-ing the traditional audiences for\ngames, which in turn has increased industrial revenue. The industry is in turn\nshaped by new business model such as Free-to-Play, digital distri-bution and\nthe use of viral social features. These changes do not only appear\nirreversible, but more importantly, play a part in shaping the future of\ndigital game design, notably for mobile devices. The paper presents new\nknowledge from controlled live experiments from a casual social game across\nFacebook and mobile platforms, finding positive re-turns by adding social\ngameplay features. This suggests that not only social network games, but also\ncasual mobile games can benefit from deeper social gameplay mechanics. Given\nthe impact of social features on gameplay, Game An-alytics will need to evolve\nto be able to handle requirements that arise from the introduction of social\nfeatures, e.g. how to measure engagement against social features and shaping\norganic and viral spreading of a game.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 09:57:15 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Als\u00e9n", "Adam", ""], ["Runge", "Julian", ""], ["Drachen", "Anders", ""], ["Klapper", "Daniel", ""]]}, {"id": "1612.02314", "submitter": "Martin Pielot", "authors": "Martin Pielot and Luz Rello", "title": "Productive, Anxious, Lonely - 24 Hours Without Push Notifications", "comments": null, "journal-ref": null, "doi": "10.1145/3098279.3098526", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report from the Do Not Disturb Challenge where 30 volunteers disabled\nnotification alerts for 24 hours across all devices. The effect of the absence\nof notifications on the participants was isolated through an experimental study\ndesign: we compared self-reported feedback from the day without notifications\nagainst a baseline day. The evidence indicates that notifications have locked\nus in a dilemma: without notifications, participants felt less distracted and\nmore productive. But, they also felt no longer able to be as responsive as\nexpected, which made some participants anxious. And, they felt less connected\nwith one's social group. In contrast to previous reports, about two third of\nthe participants expressed the intention to change how they manage\nnotifications. Two years later, half of the participants are still following\nthrough with their plans.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 16:23:33 GMT"}, {"version": "v2", "created": "Tue, 4 Jul 2017 05:40:59 GMT"}, {"version": "v3", "created": "Wed, 5 Jul 2017 07:19:27 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Pielot", "Martin", ""], ["Rello", "Luz", ""]]}, {"id": "1612.02707", "submitter": "Lovedeep Gondara", "authors": "Lovedeep Gondara", "title": "CrowdMI: Multiple Imputation via Crowdsourcing", "comments": "Updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can humans impute missing data with similar proficiency as machines? This is\nthe question we aim to answer in this paper. We present a novel idea of\nconverting observations with missing data in to a survey questionnaire, which\nis presented to crowdworkers for completion. We replicate a multiple imputation\nframework by having multiple unique crowdworkers complete our questionnaire.\nExperimental results demonstrate that using our method, it is possible to\ngenerate valid imputations for qualitative and quantitative missing data, with\nresults comparable to imputations generated by complex statistical models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 16:10:08 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 15:15:14 GMT"}, {"version": "v3", "created": "Mon, 20 Nov 2017 18:19:11 GMT"}, {"version": "v4", "created": "Fri, 23 Feb 2018 16:00:34 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Gondara", "Lovedeep", ""]]}, {"id": "1612.02802", "submitter": "Homayun Afrabandpey", "authors": "Homayun Afrabandpey, Tomi Peltola, Samuel Kaski", "title": "Interactive Prior Elicitation of Feature Similarities for Small Sample\n  Size Prediction", "comments": null, "journal-ref": null, "doi": "10.1145/3079628.3079698", "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression under the \"small $n$, large $p$\" conditions, of small sample size\n$n$ and large number of features $p$ in the learning data set, is a recurring\nsetting in which learning from data is difficult. With prior knowledge about\nrelationships of the features, $p$ can effectively be reduced, but explicating\nsuch prior knowledge is difficult for experts. In this paper we introduce a new\nmethod for eliciting expert prior knowledge about the similarity of the roles\nof features in the prediction task. The key idea is to use an interactive\nmultidimensional-scaling (MDS) type scatterplot display of the features to\nelicit the similarity relationships, and then use the elicited relationships in\nthe prior distribution of prediction parameters. Specifically, for learning to\npredict a target variable with Bayesian linear regression, the feature\nrelationships are used to construct a Gaussian prior with a full covariance\nmatrix for the regression coefficients. Evaluation of our method in experiments\nwith simulated and real users on text data confirm that prior elicitation of\nfeature similarities improves prediction accuracy. Furthermore, elicitation\nwith an interactive scatterplot display outperforms straightforward elicitation\nwhere the users choose feature pairs from a feature list.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 20:35:46 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 15:00:29 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Afrabandpey", "Homayun", ""], ["Peltola", "Tomi", ""], ["Kaski", "Samuel", ""]]}, {"id": "1612.03053", "submitter": "Tim Althoff", "authors": "Tim Althoff and Pranav Jindal and Jure Leskovec", "title": "Online Actions with Offline Impact: How Online Social Networks Influence\n  Online and Offline User Behavior", "comments": "Published in Proceedings of tenth ACM International Conference on Web\n  Search and Data Mining, WSDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of today's most widely used computing applications utilize social\nnetworking features and allow users to connect, follow each other, share\ncontent, and comment on others' posts. However, despite the widespread adoption\nof these features, there is little understanding of the consequences that\nsocial networking has on user retention, engagement, and online as well as\noffline behavior. Here, we study how social networks influence user behavior in\na physical activity tracking application. We analyze 791 million online and\noffline actions of 6 million users over the course of 5 years, and show that\nsocial networking leads to a significant increase in users' online as well as\noffline activities. Specifically, we establish a causal effect of how social\nnetworks influence user behavior. We show that the creation of new social\nconnections increases user online in-application activity by 30%, user\nretention by 17%, and user offline real-world physical activity by 7% (about\n400 steps per day). By exploiting a natural experiment we distinguish the\neffect of social influence of new social connections from the simultaneous\nincrease in user's motivation to use the app and take more steps. We show that\nsocial influence accounts for 55% of the observed changes in user behavior,\nwhile the remaining 45% can be explained by the user's increased motivation to\nuse the app. Further, we show that subsequent, individual edge formations in\nthe social network lead to significant increases in daily steps. These effects\ndiminish with each additional edge and vary based on edge attributes and user\ndemographics. Finally, we utilize these insights to develop a model that\naccurately predicts which users will be most influenced by the creation of new\nsocial network connections.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 15:20:47 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 11:31:14 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Althoff", "Tim", ""], ["Jindal", "Pranav", ""], ["Leskovec", "Jure", ""]]}, {"id": "1612.03328", "submitter": "Pedram Daee", "authors": "Pedram Daee, Tomi Peltola, Marta Soare, Samuel Kaski", "title": "Knowledge Elicitation via Sequential Probabilistic Inference for\n  High-Dimensional Prediction", "comments": "22 pages, 9 figures. The paper is published in Machine Learning\n  journal (http://rdcu.be/t9KF). Codes and data available at\n  https://github.com/HIIT/knowledge-elicitation-for-linear-regression, Machine\n  Learning, (2017)", "journal-ref": null, "doi": "10.1007/s10994-017-5651-7", "report-no": null, "categories": "cs.AI cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction in a small-sized sample with a large number of covariates, the\n\"small n, large p\" problem, is challenging. This setting is encountered in\nmultiple applications, such as precision medicine, where obtaining additional\nsamples can be extremely costly or even impossible, and extensive research\neffort has recently been dedicated to finding principled solutions for accurate\nprediction. However, a valuable source of additional information, domain\nexperts, has not yet been efficiently exploited. We formulate knowledge\nelicitation generally as a probabilistic inference process, where expert\nknowledge is sequentially queried to improve predictions. In the specific case\nof sparse linear regression, where we assume the expert has knowledge about the\nvalues of the regression coefficients or about the relevance of the features,\nwe propose an algorithm and computational approximation for fast and efficient\ninteraction, which sequentially identifies the most informative features on\nwhich to query expert knowledge. Evaluations of our method in experiments with\nsimulated and real users show improved prediction accuracy already with a small\neffort from the expert.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 18:11:32 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 13:08:56 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Daee", "Pedram", ""], ["Peltola", "Tomi", ""], ["Soare", "Marta", ""], ["Kaski", "Samuel", ""]]}, {"id": "1612.03640", "submitter": "Hubert Cecotti", "authors": "Hubert Cecotti and Bertrand Rivet", "title": "Toward improving the visual stimulus meaning for increasing the P300\n  detection", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P300 speller is a well known Brain-Computer Interface paradigm that has\nbeen used for over two decades. A new P300 speller paradigm (XP300) is\nproposed. It includes several characteristics: (i) the items are not\nintensified by using rows and columns, (ii) the order of the visual stimuli is\npseudo-random, (iii) a visual feedback is added on each item to increase the\nstimulus meaning, which is the main novelty. XP300 has been tested on ten\nhealthy subjects on copy spelling mode, with only eight sensors. It has been\ncompared with the classical P300 paradigm (CP300). With five repetitions, the\naverage recognition rate across subjects is 85.25% for XP300 and 77.25% for\nCP300. Single-trial detection is significantly higher with XP300 by comparing\nthe AUC (Area Under Curve) of the ROC (Receiver Operating Characteristic)\ncurve. The mean AUC is 0.86 for XP300, 0.80 for CP300. More importantly, XP300\nhas also been judged as more convenient and user-friendly than CP300, hence\nbeing able to allow longer sessions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 12:17:50 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Cecotti", "Hubert", ""], ["Rivet", "Bertrand", ""]]}, {"id": "1612.04391", "submitter": "Mason Bretan", "authors": "Mason Bretan, Deepak Gopinath, Philip Mullins, Gil Weinberg", "title": "A Robotic Prosthesis for an Amputee Drummer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design and evaluation of a robotic prosthesis for a drummer with a\ntransradial amputation is presented. The principal objective of the prosthesis\nis to simulate the role fingers play in drumming. This primarily includes\ncontrolling the manner in which the drum stick rebounds after initial impact.\nThis is achieved using a DC motor driven by a variable impedance control\nframework in a shared control system. The user's ability to perform with and\ncontrol the prosthesis is evaluated using a musical synchronization study. A\nsecondary objective of the prosthesis is to explore the implications of musical\nexpression and human-robotic interaction when a second, completely autonomous,\nstick is added to the prosthesis. This wearable robotic musician interacts with\nthe user by listening to the music and responding with different rhythms and\nbehaviors. We recount some empirical findings based on the user's experience of\nperforming under such a paradigm.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 21:03:34 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Bretan", "Mason", ""], ["Gopinath", "Deepak", ""], ["Mullins", "Philip", ""], ["Weinberg", "Gil", ""]]}, {"id": "1612.04418", "submitter": "Alexey Drutsa", "authors": "Alexey Drutsa (Yandex, Moscow, Russia), Andrey Shutovich (Yandex,\n  Moscow, Russia), Philipp Pushnyakov (Yandex, Moscow, Russia), Evgeniy\n  Krokhalyov (Yandex, Moscow, Russia), Gleb Gusev (Yandex, Moscow, Russia),\n  Pavel Serdyukov (Yandex, Moscow, Russia)", "title": "User Model-Based Intent-Aware Metrics for Multilingual Search Evaluation", "comments": "7 pages, 1 figure, 3 tables", "journal-ref": "NIPS 2016 Workshop \"What If? Inference and Learning of\n  Hypothetical and Counterfactual Interventions in Complex Systems\" (What If\n  2016) pre-print", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing importance of multilingual aspect of web search, no\nappropriate offline metrics to evaluate its quality are proposed so far. At the\nsame time, personal language preferences can be regarded as intents of a query.\nThis approach translates the multilingual search problem into a particular task\nof search diversification. Furthermore, the standard intent-aware approach\ncould be adopted to build a diversified metric for multilingual search on the\nbasis of a classical IR metric such as ERR. The intent-aware approach estimates\nuser satisfaction under a user behavior model. We show however that the\nunderlying user behavior models is not realistic in the multilingual case, and\nthe produced intent-aware metric do not appropriately estimate the user\nsatisfaction. We develop a novel approach to build intent-aware user behavior\nmodels, which overcome these limitations and convert to quality metrics that\nbetter correlate with standard online metrics of user satisfaction.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 22:09:24 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Drutsa", "Alexey", "", "Yandex, Moscow, Russia"], ["Shutovich", "Andrey", "", "Yandex,\n  Moscow, Russia"], ["Pushnyakov", "Philipp", "", "Yandex, Moscow, Russia"], ["Krokhalyov", "Evgeniy", "", "Yandex, Moscow, Russia"], ["Gusev", "Gleb", "", "Yandex, Moscow, Russia"], ["Serdyukov", "Pavel", "", "Yandex, Moscow, Russia"]]}, {"id": "1612.04598", "submitter": "Stefan Wagner", "authors": "Sebastian Winter and Stefan Wagner and Florian Deissenboeck", "title": "A Comprehensive Model of Usability", "comments": "18 pages, 3 figures", "journal-ref": "Engineering Interactive Systems: EIS 2007 Joint Working\n  Conferences, EHCI 2007, DSV-IS 2007, HCSE 2007. Springer, 2008", "doi": "10.1007/978-3-540-92698-6_7", "report-no": null, "categories": "cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usability is a key quality attribute of successful software systems.\nUnfortunately, there is no common understanding of the factors influencing\nusability and their interrelations. Hence, the lack of a comprehensive basis\nfor designing, analyzing, and improving user interfaces. This paper proposes a\n2-dimensional model of usability that associates system properties with the\nactivities carried out by the user. By separating activities and properties,\nsound quality criteria can be identified, thus facilitating statements\nconcerning their interdependencies. This model is based on a tested quality\nmeta-model that fosters preciseness and completeness. A case study demonstrates\nthe manner by which such a model aids in revealing contradictions and omissions\nin existing usability standards. Furthermore, the model serves as a central and\nstructured knowledge base for the entire quality assurance process, e.g. the\nautomatic generation of guideline documents.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 12:17:54 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Winter", "Sebastian", ""], ["Wagner", "Stefan", ""], ["Deissenboeck", "Florian", ""]]}, {"id": "1612.04687", "submitter": "Memo Akten", "authors": "Memo Akten and Mick Grierson", "title": "Real-time interactive sequence generation and control with Recurrent\n  Neural Network ensembles", "comments": "Demo presentation at NIPS 2016, and poster presentation at the RNN\n  Symposium at NIPS 2016. 7 pages including 1 page references, 1 page appendix,\n  2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN), particularly Long Short Term Memory (LSTM)\nRNNs, are a popular and very successful method for learning and generating\nsequences. However, current generative RNN techniques do not allow real-time\ninteractive control of the sequence generation process, thus aren't well suited\nfor live creative expression. We propose a method of real-time continuous\ncontrol and 'steering' of sequence generation using an ensemble of RNNs and\ndynamically altering the mixture weights of the models. We demonstrate the\nmethod using character based LSTM networks and a gestural interface allowing\nusers to 'conduct' the generation of text.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 15:22:57 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 21:25:53 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Akten", "Memo", ""], ["Grierson", "Mick", ""]]}, {"id": "1612.04978", "submitter": "EPTCS", "authors": "Ladislav Peska (Charles University in Prague, Faculty of Mathematics\n  and Physics)", "title": "Using the Context of User Feedback in Recommender Systems", "comments": "In Proceedings MEMICS 2016, arXiv:1612.04037", "journal-ref": "EPTCS 233, 2016, pp. 1-12", "doi": "10.4204/EPTCS.233.1", "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our work is generally focused on recommending for small or medium-sized\ne-commerce portals, where explicit feedback is absent and thus the usage of\nimplicit feedback is necessary. Nonetheless, for some implicit feedback\nfeatures, the presentation context may be of high importance. In this paper, we\npresent a model of relevant contextual features affecting user feedback,\npropose methods leveraging those features, publish a dataset of real e-commerce\nusers containing multiple user feedback indicators as well as its context and\nfinally present results of purchase prediction and recommendation experiments.\nOff-line experiments with real users of a Czech travel agency website\ncorroborated the importance of leveraging presentation context in both purchase\nprediction and recommendation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 08:49:50 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Peska", "Ladislav", "", "Charles University in Prague, Faculty of Mathematics\n  and Physics"]]}, {"id": "1612.05083", "submitter": "Ben Nassi", "authors": "Ben Nassi, Lior Rokach, Yuval Elovici", "title": "Virtual Breathalyzer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Driving under the influence of alcohol is a widespread phenomenon in the US\nwhere it is considered a major cause of fatal accidents. In this research we\npresent a novel approach and concept for detecting intoxication from motion\ndifferences obtained by the sensors of wearable devices. We formalize the\nproblem of drunkenness detection as a supervised machine learning task, both as\na binary classification problem (drunk or sober) and a regression problem (the\nbreath alcohol content level).\n  In order to test our approach, we collected data from 30 different subjects\n(patrons at three bars) using Google Glass and the LG G-watch, Microsoft Band,\nand Samsung Galaxy S4. We validated our results against an admissible\nbreathalyzer used by the police.\n  A system based on this concept, successfully detected intoxication and\nachieved the following results: 0.95 AUC and 0.05 FPR, given a fixed TPR of\n1.0. Applications based on our system can be used to analyze the free gait of\ndrinkers when they walk from the car to the bar and vice-versa, in order to\nalert people, or even a connected car and prevent people from driving under the\ninfluence of alcohol.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 16:07:14 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Nassi", "Ben", ""], ["Rokach", "Lior", ""], ["Elovici", "Yuval", ""]]}, {"id": "1612.05922", "submitter": "Mahmoud Fayed", "authors": "Mahmoud Samir Fayed and Ehab Aziz Khalil", "title": "Super Event Driven System OOP GUI Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a new proposal design of GUI and new technology in\nprogramming Namely \"Super Technology\" which can be applied for supporting the\nproposal design of GUI\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 14:58:37 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Fayed", "Mahmoud Samir", ""], ["Khalil", "Ehab Aziz", ""]]}, {"id": "1612.06025", "submitter": "Bharathan Balaji", "authors": "Bharathan Balaji, Nadir Weibel, Yuvraj Agarwal", "title": "Managing Commercial HVAC Systems: What do Building Operators Really\n  Need?", "comments": "5 pages, Paper rejected from CHI 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buildings form an essential part of modern life; people spend a significant\namount of their time in them, and they consume large amounts of energy. A\nvariety of systems provide services such as lighting, air conditioning and\nsecurity which are managed using Building Management Systems (BMS) by building\noperators. To better understand the capability of current BMS and characterize\ncommon practices of building operators, we investigated their use across five\ninstitutions in the US. We interviewed ten operators and discovered that BMS do\nnot address a number of key concerns for the management of buildings. Our\nanalysis is rooted in the everyday work of building operators and highlights a\nnumber of design suggestions to help improve the user experience and management\nof BMS, ultimately leading to improvements in productivity, as well as\nbuildings comfort and energy efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 02:12:21 GMT"}], "update_date": "2016-12-31", "authors_parsed": [["Balaji", "Bharathan", ""], ["Weibel", "Nadir", ""], ["Agarwal", "Yuvraj", ""]]}, {"id": "1612.06114", "submitter": "Alexander Hewer", "authors": "Kristy James (DFKI), Alexander Hewer (DFKI), Ingmar Steiner (DFKI),\n  Stefanie Wuhrer (MORPHEO)", "title": "A real-time framework for visual feedback of articulatory data using\n  statistical shape models", "comments": "17th Annual Conference of the International Speech Communication\n  Association (Interspeech), Oct 2016, San Francisco, United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel open-source framework for visualizing electromagnetic\narticulography (EMA) data in real-time, with a modular framework and\nanatomically accurate tongue and palate models derived by multilinear subspace\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 10:42:57 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["James", "Kristy", "", "DFKI"], ["Hewer", "Alexander", "", "DFKI"], ["Steiner", "Ingmar", "", "DFKI"], ["Wuhrer", "Stefanie", "", "MORPHEO"]]}, {"id": "1612.06189", "submitter": "Stephan Sigg", "authors": "Muneeba Raja and Stephan Sigg", "title": "RFexpress! - Exploiting the wireless network edge for RF-based emotion\n  sensing", "comments": "Submitted to ICDCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present RFexpress! the first-ever network-edge based system to recognize\nemotion from movement, gesture and pose via Device-Free Activity Recognition\n(DFAR). With the proliferation of the IoT, also wireless access points are\ndeployed at increasingly dense scale. in particular, this includes vehicular\nnodes (in-car WiFi or Bluetooth), office (Wlan APs, WiFi printer or projector)\nand private indoor domains (home WiFi mesh, Wireless media access), as well as\npublic spaces (City/open WiFi, Cafes, shopping spaces). Processing\nRF-fluctuation at such edge-devices, enables environmental perception. In this\npaper, we focus on the distinction between neutral and agitated emotional\nstates of humans from RF-fluctuation at the wireless network edge in realistic\nenvironments. In particular, the system is able to detect risky driving\nbehaviour in a vehicular setting as well as spotting angry conversations in an\nindoor environment. We also study the effectiveness of edge-based DFAR emotion\nand activity recognition systems in real environments such as cafes, malls,\noutdoor and office spaces. We measure radio characteristics in these\nenvironments at different days and times and analyse the impact of variations\nin the Signal to Noise Ratio (SNR) on the accuracy of DFAR emotion and activity\nrecognition. In a case study with 5 subjects, we then exploit the limits of\nedge-based DFAR by deriving critical SNR values under which activity and\nemotion recognition results are no longer reliable. In case studies with 8 and\n5 subjects the system further could achieve recognition accuracies of 82.9\\%\nand 64\\% for vehicular and stationary wireless network edge in the wild\n(non-laboratory noisy environments and non-scripted, natural individual\nbehaviour patterns).\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 14:14:13 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Raja", "Muneeba", ""], ["Sigg", "Stephan", ""]]}, {"id": "1612.06209", "submitter": "Stephan Sigg", "authors": "Le Ngu Nguyen and Stephan Sigg", "title": "Personalized Image-based User Authentication using Wearable Cameras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal devices (e.g. laptops, tablets, and mobile phones) are conventional\nin daily life and have the ability to store users' private data. The security\nproblems related to these appliances have become a primary concern for both\nusers and researchers. In this paper, we analyse first-person-view videos to\ndevelop a personalized user authentication mechanism. Our proposed algorithm\ngenerates provisional image-based passwords which benefit a variety of purposes\nsuch as unlocking a mobile device or fallback authentication. First,\nrepresentative frames are extracted from the egocentric videos. Then, they are\nsplit into distinguishable segments before a clustering procedure is applied to\ndiscard repetitive scenes. The whole process aims to retain memorable images to\nform the authentication challenges. We integrate eye tracking data to select\ninformative sequences of video frames and suggest a blurriness-based method if\nan eye-facing camera is not available. To evaluate our system, we perform\nexperiments in different settings including object-interaction activities and\ntraveling contexts. Even though our mechanism produces variable graphical\npasswords, the log-in effort for the user is comparable with approaches based\non static challenges. We verified the authentication challenges in the presence\nof a random and an informed attacker who is familiar with the environment and\nobserved that the time required and the number of attempts are significantly\nhigher than for the legitimate user, making it possible to detect attacks on\nthe authentication system.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 14:50:27 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 10:39:39 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Nguyen", "Le Ngu", ""], ["Sigg", "Stephan", ""]]}, {"id": "1612.06232", "submitter": "Alexander Rind", "authors": "Markus Wagner (1 and 2), Alexander Rind (1 and 2), Niklas Th\\\"ur (1),\n  Wolfgang Aigner (1 and 2) ((1) St. Poelten University of Applied Sciences,\n  Austria, (2) Vienna University of Technology, Austria)", "title": "A Knowledge-Assisted Visual Malware Analysis System: Design, Validation,\n  and Reflection of KAMAS", "comments": "15 pages, 8 figures", "journal-ref": "Computers & Security, Vol. 67, p. 1-15 (2017)", "doi": "10.1016/j.cose.2017.02.003", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  IT-security experts engage in behavior-based malware analysis in order to\nlearn about previously unknown samples of malicious software (malware) or\nmalware families. For this, they need to find and categorize suspicious\npatterns from large collections of execution traces. Currently available\nsystems do not meet the analysts' needs described as: visual access suitable\nfor complex data structures, visual representations appropriate for IT-security\nexperts, provide work flow-specific interaction techniques, and the ability to\nexternalize knowledge in the form of rules to ease analysis and for sharing\nwith colleagues. To close this gap, we designed and developed KAMAS, a\nknowledge-assisted visualization system for behavior-based malware analysis.\nKAMAS supports malware analysts with visual analytics and knowledge\nexternalization methods for the analysis process. The paper at hand is a design\nstudy that describes the design, implementation, and evaluation of the\nprototype. We report on the validation of KAMAS by expert reviews, a user study\nwith domain experts, and focus group meetings with analysts from industry.\nAdditionally, we reflect the gained insights of the design study and discuss\nthe advantages and disadvantages of the applied visualization methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 15:48:48 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 12:23:08 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2017 10:10:28 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Wagner", "Markus", "", "1 and 2"], ["Rind", "Alexander", "", "1 and 2"], ["Th\u00fcr", "Niklas", "", "1 and 2"], ["Aigner", "Wolfgang", "", "1 and 2"]]}, {"id": "1612.07303", "submitter": "Johannes Feldmaier", "authors": "Johannes Feldmaier, Tamara Marmat, Johannes Kuhn, Klaus Diepold", "title": "Evaluation of a RGB-LED-based Emotion Display for Affective Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology has become an essential part in every aspect of our lives. However\nthe key to a successful implementation of a technology depends on the\nacceptance by the general public. In order to increase the acceptance various\napproaches can be applied. In this paper, we will examine the human-robot\nemotional interaction by investigating the capabilities of a developed\nlow-resolution RGB-LED display in the context of artificial emotions. We are\nfocusing on four of the most representative human emotions which include\nhappiness, anger, sadness and fear. We will work with colors and dynamic light\npatterns which are supposed to evoke various associations. In an experiment,\nthe use these patterns as expressions of emotions are validated. The results of\nthe conducted study show that some of the considered basic emotions can be\nrecognized by human observers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 20:12:08 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Feldmaier", "Johannes", ""], ["Marmat", "Tamara", ""], ["Kuhn", "Johannes", ""], ["Diepold", "Klaus", ""]]}, {"id": "1612.07677", "submitter": "Andreas Henelius", "authors": "Andreas Henelius", "title": "A short review and primer on cardiovascular signals in human computer\n  interaction applications", "comments": "13 pages, 1 figure. Part of a journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of psychophysiologic signals in human-computer interaction is a\ngrowing field with significant potential for future smart personalised systems.\nWorking in this emerging field requires comprehension of different\nphysiological signals and analysis techniques.\n  Cardiovascular signals such as heart rate variability and blood pressure\nvariability are commonly used in psychophysiology in order to investigate\nphenomena such as mental workload. In this paper we present a short review of\ndifferent cardiovascular metrics useful in the context of human-computer\ninteraction.\n  This paper aims to serve as a primer for the novice, enabling rapid\nfamiliarisation with the latest core concepts. We emphasise everyday\nhuman-computer interface applications to distinguish from the more common\nclinical or sports uses of psychophysiology.\n  This paper is an extract from a comprehensive review of the entire field of\nambulatory psychophysiology, with 12 similar chapters, plus application\nguidelines and systematic review. Any citation to this paper should be made\nusing the following reference:\n  B. Cowley, M. Filetti, K. Lukander, J. Torniainen, A. Henelius, L. Ahonen, O.\nBarral, I. Kosunen, T. Valtonen, M. Huotilainen, N. Ravaja, G. Jacucci. The\nPsychophysiology Primer: a guide to methods and a broad review with a focus on\nhuman-computer interaction. Foundations and Trends in Human-Computer\nInteraction, vol. 9, no. 3-4, pp. 150--307, 2016.\nhttp://dx.doi.org/10.1561/1100000065\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 16:18:09 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Henelius", "Andreas", ""]]}, {"id": "1612.07714", "submitter": "Gangli Liu", "authors": "Gangli Liu", "title": "Understanding Tree: a tool to estimate one's understanding of knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People learn whenever and wherever possible, and whatever they like or\nencounter--Mathematics, Drama, Art, Languages, Physics, Philosophy, and so on.\nWith the bursting of knowledge, evaluation of one's possession of knowledge\nbecomes increasingly difficult. There are a lot of demands to evaluate one's\nunderstanding of a piece of knowledge. Assessment of understanding of knowledge\nis conventionally through tests or interviews, but they have some limitations\nsuch as low-efficiency and not-comprehensive. This paper proposes a method\ncalled Understanding Tree to estimate one's understanding of knowledge, by\nkeeping track of his/her learning activities. It overcomes some limitations of\ntraditional methods, hence complements traditional methods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 17:28:38 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Liu", "Gangli", ""]]}, {"id": "1612.07778", "submitter": "Rajib Rana", "authors": "Rajib Rana", "title": "Gated Recurrent Unit (GRU) for Emotion Classification from Noisy Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the enormous interest in emotion classification from speech, the\nimpact of noise on emotion classification is not well understood. This is\nimportant because, due to the tremendous advancement of the smartphone\ntechnology, it can be a powerful medium for speech emotion recognition in the\noutside laboratory natural environment, which is likely to incorporate\nbackground noise in the speech. We capitalize on the current breakthrough of\nRecurrent Neural Network (RNN) and seek to investigate its performance for\nemotion classification from noisy speech. We particularly focus on the recently\nproposed Gated Recurrent Unit (GRU), which is yet to be explored for emotion\nrecognition from speech. Experiments conducted with speech compounded with\neight different types of noises reveal that GRU incurs an 18.16% smaller\nrun-time while performing quite comparably to the Long Short-Term Memory\n(LSTM), which is the most popular Recurrent Neural Network proposed to date.\nThis result is promising for any embedded platform in general and will initiate\nfurther studies to utilize GRU to its full potential for emotion recognition on\nsmartphones.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 03:32:47 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Rana", "Rajib", ""]]}, {"id": "1612.07863", "submitter": "Hamed Alhoori", "authors": "Hamed Alhoori, Mohammed Samaka, Richard Furuta, Edward A. Fox", "title": "Anatomy of Scholarly Information Behavior Patterns in the Wake of\n  Academic Social Media Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more scholarly content is born digital or converted to a digital format,\ndigital libraries are becoming increasingly vital to researchers seeking to\nleverage scholarly big data for scientific discovery. Although scholarly\nproducts are available in abundance-especially in environments created by the\nadvent of social networking services-little is known about international\nscholarly information needs, information-seeking behavior, or information use.\nThe purpose of this paper is to address these gaps via an in-depth analysis of\nthe information needs and information-seeking behavior of researchers, both\nstudents and faculty, at two universities, one in the U.S. and the other in\nQatar. Based on this analysis, the study identifies and describes new behavior\npatterns on the part of researchers as they engage in the information-seeking\nprocess. The analysis reveals that the use of academic social networks has\nnotable effects on various scholarly activities. Further, this study identifies\ndifferences between students and faculty members in regard to their use of\nacademic social networks, and it identifies differences between researchers\naccording to discipline. Although the researchers who participated in the\npresent study represent a range of disciplinary and cultural backgrounds, the\nstudy reports a number of similarities in terms of the researchers' scholarly\nactivities.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 03:26:40 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 23:59:54 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Alhoori", "Hamed", ""], ["Samaka", "Mohammed", ""], ["Furuta", "Richard", ""], ["Fox", "Edward A.", ""]]}, {"id": "1612.08117", "submitter": "Michael Mozer", "authors": "Ronald T. Kneusel and Michael C. Mozer", "title": "Improving Human-Machine Cooperative Visual Search With Soft Highlighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine learning have produced systems that attain human-level\nperformance on certain visual tasks, e.g., object identification. Nonetheless,\nother tasks requiring visual expertise are unlikely to be entrusted to machines\nfor some time, e.g., satellite and medical imagery analysis. We describe a\nhuman-machine cooperative approach to visual search, the aim of which is to\noutperform either human or machine acting alone. The traditional route to\naugmenting human performance with automatic classifiers is to draw boxes around\nregions of an image deemed likely to contain a target. Human experts typically\nreject this type of hard highlighting. We propose instead a soft highlighting\ntechnique in which the saliency of regions of the visual field is modulated in\na graded fashion based on classifier confidence level. We report on experiments\nwith both synthetic and natural images showing that soft highlighting achieves\na performance synergy surpassing that attained by hard highlighting.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 00:06:02 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Kneusel", "Ronald T.", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1612.08227", "submitter": "Li Du", "authors": "Li Du", "title": "An Overview of Mobile Capacitive Touch Technologies Trends", "comments": "4 pages, 7 figures", "journal-ref": null, "doi": "10.1017/S1743921315010388", "report-no": null, "categories": "cs.ET cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Touch sensing, as a major human/machine interface, is widely used in various\ncommercial products such as smart watches, mobile phones, tablets and TVs.\nState-of-the-art touch detections are mainly based on mutual capacitive\nsensing, which requires necessary contact-touch, limiting the mobile user\nexperience. Recently, remote gesture sensing is widely reported in both academy\nand industry as it can provide additional user-experience for mobile interface.\nThe capacitive remote gesture sensing is mainly based on detecting\nself-capacitance, achieving high resolution through eliminating the parasitic\nmutual capacitance. In this work, we overview the different generations of\ntouchscreen technology, comparing the touch and remote gesture sensing\ntechnologies difference. In addition, different remote gesture sensing\ntechnologies are also compared. The limitations and potentials of different\ntopologies are discussed and a final conclusion about the technology trends is\nsummarized in the end.\n", "versions": [{"version": "v1", "created": "Sun, 25 Dec 2016 00:41:01 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Du", "Li", ""]]}, {"id": "1612.08440", "submitter": "Tanushree Mitra", "authors": "Tanushree Mitra, Graham Wright, Eric Gilbert", "title": "Credibility and Dynamics of Collective Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Today, social media provide the means by which billions of people experience\nnews and events happening around the world. However, the absence of traditional\njournalistic gatekeeping allows information to flow unencumbered through these\nplatforms, often raising questions of veracity and credibility of the reported\ninformation. Here we ask: How do the dynamics of collective attention directed\ntoward an event reported on social media vary with its perceived credibility?\nBy examining the first large-scale, systematically tracked credibility database\nof public Twitter messages (47M messages corresponding to 1,138 real-world\nevents over a span of three months), we established a relationship between the\ntemporal dynamics of events reported on social media and their associated level\nof credibility judgments. Representing collective attention by the aggregate\ntemporal signatures of an event reportage, we found that the amount of\ncontinued attention focused on an event provides information about its\nassociated levels of perceived credibility. Events exhibiting sustained,\nintermittent bursts of attention were found to be associated with lower levels\nof perceived credibility. In other words, as more people showed interest during\nmoments of transient collective attention, the associated uncertainty\nsurrounding these events also increased.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 21:25:50 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Mitra", "Tanushree", ""], ["Wright", "Graham", ""], ["Gilbert", "Eric", ""]]}, {"id": "1612.08555", "submitter": "Samuel L. Smith", "authors": "Samuel L Smith", "title": "Monte Carlo Sort for unreliable human comparisons", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms which sort lists of real numbers into ascending order have been\nstudied for decades. They are typically based on a series of pairwise\ncomparisons and run entirely on chip. However people routinely sort lists which\ndepend on subjective or complex judgements that cannot be automated. Examples\ninclude marketing research; where surveys are used to learn about customer\npreferences for products, the recruiting process; where interviewers attempt to\nrank potential employees, and sporting tournaments; where we infer team\nrankings from a series of one on one matches. We develop a novel sorting\nalgorithm, where each pairwise comparison reflects a subjective human judgement\nabout which element is bigger or better. We introduce a finite and large error\nrate to each judgement, and we take the cost of each comparison to\nsignificantly exceed the cost of other computational steps. The algorithm must\nrequest the most informative sequence of comparisons from the user; in order to\nidentify the correct sorted list with minimum human input. Our Discrete\nAdiabatic Monte Carlo approach exploits the gradual acquisition of information\nby tracking a set of plausible hypotheses which are updated after each\nadditional comparison.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 09:54:07 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Smith", "Samuel L", ""]]}, {"id": "1612.09352", "submitter": "Ingmar Steiner", "authors": "Ingmar Steiner, S\\'ebastien Le Maguer and Alexander Hewer", "title": "Synthesis of Tongue Motion and Acoustics from Text using a Multimodal\n  Articulatory Database", "comments": null, "journal-ref": "IEEE/ACM Transactions on Audio, Speech, and Language Processing 25\n  (2017) 2351 - 2361", "doi": "10.1109/TASLP.2017.2756818", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end text-to-speech (TTS) synthesis system that generates\naudio and synchronized tongue motion directly from text. This is achieved by\nadapting a 3D model of the tongue surface to an articulatory dataset and\ntraining a statistical parametric speech synthesis system directly on the\ntongue model parameters. We evaluate the model at every step by comparing the\nspatial coordinates of predicted articulatory movements against the reference\ndata. The results indicate a global mean Euclidean distance of less than 2.8\nmm, and our approach can be adapted to add an articulatory modality to\nconventional TTS applications without the need for extra data.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 00:05:03 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 15:35:43 GMT"}, {"version": "v3", "created": "Tue, 12 Dec 2017 15:28:14 GMT"}, {"version": "v4", "created": "Fri, 13 Apr 2018 14:36:28 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Steiner", "Ingmar", ""], ["Maguer", "S\u00e9bastien Le", ""], ["Hewer", "Alexander", ""]]}, {"id": "1612.09423", "submitter": "Ivan Svogor", "authors": "Ivan \\v{S}vogor, Tonimir Ki\\v{s}asondi", "title": "Two factor authentication using EEG augmented passwords", "comments": "Preliminary communication", "journal-ref": null, "doi": "10.2498/iti.2012.0441", "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current research with EEG devices in the user authentication context has\nsome deficiencies that address expensive equipment, the requirement of\nlaboratory conditions and applicability. In this paper we address this issue by\nusing widely available and inexpensive EEG device to verify its capability for\nauthentication. As a part of this research, we developed two phase\nauthentication that enables users to enhance their password with the mental\nstate by breaking the password into smaller, marry them with mental state, and\ngenerate one time pad for a secure session.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 08:52:26 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["\u0160vogor", "Ivan", ""], ["Ki\u0161asondi", "Tonimir", ""]]}]