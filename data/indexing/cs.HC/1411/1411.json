[{"id": "1411.1170", "submitter": "Ong Sing Goh", "authors": "Ong Sing Goh, Lance Fung", "title": "An Intelligent Personal Robot Assistant", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error", "journal-ref": null, "doi": null, "report-no": "TJ211.G63 2004", "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent development in developing humanoid robot poses new challenges to\nhuman-machine interaction communication. A major challenge is to develop robots\nthat can behave like and interact with human in the most natural way possible.\nThis paper proposes a system to develop a robot that can receive command, and\ntalk to people in natural language. In addition, the robot can also be\n\"trained\" to become an expert in sepcific areas to provide expert advice to\nhuman-beings. Most important of all, the robot can display emotions through\nfacial expression, speech and gesture so that the interaction process will\nbecome more comprehensive and compelling.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 07:24:59 GMT"}, {"version": "v2", "created": "Tue, 2 Dec 2014 01:13:31 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Goh", "Ong Sing", ""], ["Fung", "Lance", ""]]}, {"id": "1411.1316", "submitter": "David Buckley", "authors": "David Buckley, Ke Chen, Joshua Knowles", "title": "Rapid Skill Capture in a First-Person Shooter", "comments": "16 pages, 28 figures, journal paper submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various aspects of computer game design, including adaptive elements of game\nlevels, characteristics of 'bot' behavior, and player matching in multiplayer\ngames, would ideally be sensitive to a player's skill level. Yet, while\ndifficulty and player learning have been explored in the context of games,\nthere has been little work analyzing skill per se, and how it pertains to a\nplayer's input. To this end, we present a data set of 476 game logs from over\n40 players of a first-person shooter game (Red Eclipse) as a basis of a case\nstudy. We then analyze different metrics of skill and show that some of these\ncan be predicted using only a few seconds of keyboard and mouse input. We argue\nthat the techniques used here are useful for adapting games to match players'\nskill levels rapidly, perhaps more rapidly than solutions based on performance\naveraging such as TrueSkill.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 16:41:12 GMT"}, {"version": "v2", "created": "Thu, 6 Nov 2014 13:04:25 GMT"}], "update_date": "2014-11-07", "authors_parsed": [["Buckley", "David", ""], ["Chen", "Ke", ""], ["Knowles", "Joshua", ""]]}, {"id": "1411.2156", "submitter": "Heba Aly", "authors": "Nesma Mohssen, Rana Momtaz, Heba Aly, Moustafa Youssef", "title": "It's the Human that Matters: Accurate User Orientation Estimation for\n  Mobile Computing Applications", "comments": "Accepted for publication in the 11th International Conference on\n  Mobile and Ubiquitous Systems: Computing, Networking and Services\n  (Mobiquitous 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquity of Internet-connected and sensor-equipped portable devices sparked a\nnew set of mobile computing applications that leverage the proliferating\nsensing capabilities of smart-phones. For many of these applications, accurate\nestimation of the user heading, as compared to the phone heading, is of\nparamount importance. This is of special importance for many crowd-sensing\napplications, where the phone can be carried in arbitrary positions and\norientations relative to the user body. Current state-of-the-art focus mainly\non estimating the phone orientation, require the phone to be placed in a\nparticular position, require user intervention, and/or do not work accurately\nindoors; which limits their ubiquitous usability in different applications. In\nthis paper we present Humaine, a novel system to reliably and accurately\nestimate the user orientation relative to the Earth coordinate system.\n  Humaine requires no prior-configuration nor user intervention and works\naccurately indoors and outdoors for arbitrary cell phone positions and\norientations relative to the user body. The system applies statistical analysis\ntechniques to the inertial sensors widely available on today's cell phones to\nestimate both the phone and user orientation. Implementation of the system on\ndifferent Android devices with 170 experiments performed at different indoor\nand outdoor testbeds shows that Humaine significantly outperforms the\nstate-of-the-art in diverse scenarios, achieving a median accuracy of\n$15^\\circ$ averaged over a wide variety of phone positions. This is $558\\%$\nbetter than the-state-of-the-art. The accuracy is bounded by the error in the\ninertial sensors readings and can be enhanced with more accurate sensors and\nsensor fusion.\n", "versions": [{"version": "v1", "created": "Sat, 8 Nov 2014 19:54:00 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Mohssen", "Nesma", ""], ["Momtaz", "Rana", ""], ["Aly", "Heba", ""], ["Youssef", "Moustafa", ""]]}, {"id": "1411.2190", "submitter": "Ichiroh Kanaya Dr.", "authors": "Ichiroh Kanaya, Masataka Imura, Mayuko Kanazawa", "title": "Interactive Art To Go", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional artworks like paintings, photographs, or films can be reproduced\nby conventional media like printing or video. This makes visitors of museums\npossible to purchase postcards, posters, books, and DVDs of pictures and/or\nmovies shown at the exhibition. However, newly developing arts so called\ninteractive art, or new media art, has not been able to be reproduced due to\nlimitation of functionalities of the conventional media. In this article, the\nauthors report a novel approach of sharing such interactive art outside the\nexhibition, so that the visitors of the museum can take a copy to home, and\neven share it with non-visitors. The authors build up their new\nprojector-and-camera (ProCam) based interactive artwork for exhibition at\nMuseum of Contemporary Art Tokyo (MOT) by using Apple's iPhone. The exactly\nsame software driving this artwork was downloadable from Apple's App Store --\nthus all visitors or even non-visitors could enjoy the same experience at home\nor wherever they like.\n", "versions": [{"version": "v1", "created": "Sun, 9 Nov 2014 03:07:41 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Kanaya", "Ichiroh", ""], ["Imura", "Masataka", ""], ["Kanazawa", "Mayuko", ""]]}, {"id": "1411.2878", "submitter": "Os Keyes", "authors": "Aaron Halfaker, Os Keyes, Daniel Kluver, Jacob Thebault-Spieker, Tien\n  Nguyen, Kenneth Shores, Anuradha Uduwage, Morten Warncke-Wang", "title": "User Session Identification Based on Strong Regularities in\n  Inter-activity Time", "comments": "9 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Session identification is a common strategy used to develop metrics for web\nanalytics and behavioral analyses of user-facing systems. Past work has argued\nthat session identification strategies based on an inactivity threshold is\ninherently arbitrary or advocated that thresholds be set at about 30 minutes.\nIn this work, we demonstrate a strong regularity in the temporal rhythms of\nuser initiated events across several different domains of online activity\n(incl. video gaming, search, page views and volunteer contributions). We\ndescribe a methodology for identifying clusters of user activity and argue that\nregularity with which these activity clusters appear implies a good\nrule-of-thumb inactivity threshold of about 1 hour. We conclude with\nimplications that these temporal rhythms may have for system design based on\nour observations and theories of goal-directed human activity.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 16:36:00 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 16:51:56 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Halfaker", "Aaron", ""], ["Keyes", "Os", ""], ["Kluver", "Daniel", ""], ["Thebault-Spieker", "Jacob", ""], ["Nguyen", "Tien", ""], ["Shores", "Kenneth", ""], ["Uduwage", "Anuradha", ""], ["Warncke-Wang", "Morten", ""]]}, {"id": "1411.3214", "submitter": "Sandra Servia-Rodr\\'iguez", "authors": "Sandra Servia-Rodr\\'iguez, Bernardo A. Huberman, Sitaram Asur", "title": "Deciding what to display: maximizing the information value of social\n  media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In information-rich environments, the competition for users' attention leads\nto a flood of content from which people often find hard to sort out the most\nrelevant and useful pieces. Using Twitter as a case study, we applied an\nattention economy solution to generate the most informative tweets for its\nusers. By considering the novelty and popularity of tweets as objective\nmeasures of their relevance and utility, we used the Huberman-Wu algorithm to\nautomatically select the ones that will receive the most attention in the next\ntime interval. Their predicted popularity was confirmed by using Twitter data\ncollected for a period of 2 months.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 15:47:41 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Servia-Rodr\u00edguez", "Sandra", ""], ["Huberman", "Bernardo A.", ""], ["Asur", "Sitaram", ""]]}, {"id": "1411.3489", "submitter": "Lu\\'is F.  Seoane MSc", "authors": "Lu\\'is F. Seoane, Stephan Gabler, Benjamin Blankertz", "title": "Images from the Mind: BCI image evolution based on Rapid Serial Visual\n  Presentation of polygon primitives", "comments": "22 pages, 8 figures", "journal-ref": null, "doi": "10.1080/2326263X.2015.1060819", "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a proof of concept for an EEG-based reconstruction of a\nvisual image which is on a user's mind. Our approach is based on the Rapid\nSerial Visual Presentation (RSVP) of polygon primitives and Brain-Computer\nInterface (BCI) technology. The presentation of polygons that contribute to\nbuild a target image (because they match the shape and/or color of the target)\ntrigger attention-related EEG patterns. Accordingly, these target primitives\ncan be determined using BCI classification of Event-Related Potentials (ERPs).\nThey are then accumulated in the display until a satisfactory reconstruction is\nreached. Selection steps have an average classification accuracy of $75\\%$.\n$25\\%$ of the images could be reconstructed completely, while more than $65\\%$\nof the available visual details could be captured on average. Most of the\nmisclassifications were not misinterpretations of the BCI concerning users'\nintent; rather, users tried to select polygons that were different than what\nwas intended by the experimenters. Open problems and alternatives to develop a\npractical BCI-based image reconstruction application are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 10:19:14 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2015 13:44:50 GMT"}], "update_date": "2015-07-14", "authors_parsed": [["Seoane", "Lu\u00eds F.", ""], ["Gabler", "Stephan", ""], ["Blankertz", "Benjamin", ""]]}, {"id": "1411.4076", "submitter": "Amiraj Dhawan", "authors": "Amiraj Dhawan, Shruti Bhave, Amrita Aurora, Vishwanathan Iyer", "title": "Association Rule Based Flexible Machine Learning Module for Embedded\n  System Platforms like Android", "comments": "International Journal of Advanced Research in Artificial\n  Intelligence(IJARAI), Volume 3 Issue 1, 2014", "journal-ref": null, "doi": "10.14569/IJARAI.2014.030101", "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have seen a tremendous growth in the popularity of\nsmartphones. As newer features continue to be added to smartphones to increase\ntheir utility, their significance will only increase in future. Combining\nmachine learning with mobile computing can enable smartphones to become\n'intelligent' devices, a feature which is hitherto unseen in them. Also, the\ncombination of machine learning and context aware computing can enable\nsmartphones to gauge user's requirements proactively, depending upon their\nenvironment and context. Accordingly, necessary services can be provided to\nusers.\n  In this paper, we have explored the methods and applications of integrating\nmachine learning and context aware computing on the Android platform, to\nprovide higher utility to the users. To achieve this, we define a Machine\nLearning (ML) module which is incorporated in the basic Android architecture.\nFirstly, we have outlined two major functionalities that the ML module should\nprovide. Then, we have presented three architectures, each of which\nincorporates the ML module at a different level in the Android architecture.\nThe advantages and shortcomings of each of these architectures have been\nevaluated. Lastly, we have explained a few applications in which our proposed\nsystem can be incorporated such that their functionality is improved.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 22:55:13 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Dhawan", "Amiraj", ""], ["Bhave", "Shruti", ""], ["Aurora", "Amrita", ""], ["Iyer", "Vishwanathan", ""]]}, {"id": "1411.4080", "submitter": "Miriam Redi", "authors": "Miriam Redi, Neil O Hare, Rossano Schifanella, Michele Trevisiol,\n  Alejandro Jaimes", "title": "6 Seconds of Sound and Vision: Creativity in Micro-Videos", "comments": "8 pages, 1 figures, conference IEEE CVPR 2014", "journal-ref": null, "doi": "10.1109/CVPR.2014.544", "report-no": null, "categories": "cs.MM cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of creativity, as opposed to related concepts such as beauty or\ninterestingness, has not been studied from the perspective of automatic\nanalysis of multimedia content. Meanwhile, short online videos shared on social\nmedia platforms, or micro-videos, have arisen as a new medium for creative\nexpression. In this paper we study creative micro-videos in an effort to\nunderstand the features that make a video creative, and to address the problem\nof automatic detection of creative content. Defining creative videos as those\nthat are novel and have aesthetic value, we conduct a crowdsourcing experiment\nto create a dataset of over 3,800 micro-videos labelled as creative and\nnon-creative. We propose a set of computational features that we map to the\ncomponents of our definition of creativity, and conduct an analysis to\ndetermine which of these features correlate most with creative video. Finally,\nwe evaluate a supervised approach to automatically detect creative video, with\npromising results, showing that it is necessary to model both aesthetic value\nand novelty to achieve optimal classification accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 23:29:18 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Redi", "Miriam", ""], ["Hare", "Neil O", ""], ["Schifanella", "Rossano", ""], ["Trevisiol", "Michele", ""], ["Jaimes", "Alejandro", ""]]}, {"id": "1411.4086", "submitter": "Hongwei Li", "authors": "Hongwei Li and Bin Yu", "title": "Error Rate Bounds and Iterative Weighted Majority Voting for\n  Crowdsourcing", "comments": "Journal Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has become an effective and popular tool for human-powered\ncomputation to label large datasets. Since the workers can be unreliable, it is\ncommon in crowdsourcing to assign multiple workers to one task, and to\naggregate the labels in order to obtain results of high quality. In this paper,\nwe provide finite-sample exponential bounds on the error rate (in probability\nand in expectation) of general aggregation rules under the Dawid-Skene\ncrowdsourcing model. The bounds are derived for multi-class labeling, and can\nbe used to analyze many aggregation methods, including majority voting,\nweighted majority voting and the oracle Maximum A Posteriori (MAP) rule. We\nshow that the oracle MAP rule approximately optimizes our upper bound on the\nmean error rate of weighted majority voting in certain setting. We propose an\niterative weighted majority voting (IWMV) method that optimizes the error rate\nbound and approximates the oracle MAP rule. Its one step version has a provable\ntheoretical guarantee on the error rate. The IWMV method is intuitive and\ncomputationally simple. Experimental results on simulated and real data show\nthat IWMV performs at least on par with the state-of-the-art methods, and it\nhas a much lower computational cost (around one hundred times faster) than the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 15 Nov 2014 00:02:34 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Li", "Hongwei", ""], ["Yu", "Bin", ""]]}, {"id": "1411.4726", "submitter": "Reza Rawassizadeh", "authors": "Reza Rawassizadeh and Elaheh Momeni and Prajna Shetty", "title": "Scalable Mining of Daily Behavioral Patterns in Context Sensing Life-Log\n  Data", "comments": "10 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advent of wearable devices and the proliferation of smartphones,\nthere still is no ideal platform that can continuously sense and precisely\ncollect all available contextual information. Ideally, mobile sensing data\ncollection approaches should deal with uncertainty and data loss originating\nfrom software and hardware restrictions. We have conducted life logging data\ncollection experiments from 35 users and created a rich dataset (9.26 million\nrecords) to represent the real-world deployment issues of mobile sensing\nsystems. We create a novel set of algorithms to identify human behavioral\nmotifs while considering the uncertainty of collected data objects. Our work\nbenefits from combinations of sensors available on a device and identifies\nbehavioral patterns with a temporal granularity similar to human time\nperception. Employing a combination of sensors rather than focusing on only one\nsensor can handle uncertainty by neglecting sensor data that is not available\nand focusing instead on available data. Moreover, by experimenting on two real,\nlarge datasets, we demonstrate that using a sliding window significantly\nimproves the scalability of our algorithms, which can be used by applications\nfor small devices, such as smartphones and wearables.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 03:33:10 GMT"}, {"version": "v2", "created": "Mon, 16 Feb 2015 04:29:09 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2015 14:57:48 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Rawassizadeh", "Reza", ""], ["Momeni", "Elaheh", ""], ["Shetty", "Prajna", ""]]}, {"id": "1411.5137", "submitter": "Sandeep Vasave L", "authors": "Sandeep Vasave, Amol Plave", "title": "Study of Gesture Recognition methods and augmented reality", "comments": "7 PAGES, 5 FUGURES", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  With the growing technology, we humans always need something that stands out\nfrom the other thing. Gestures are most desirable source to Communicate with\nthe Machines. Human Computer Interaction finds its importance when it comes to\nworking with the Human gestures to control the computer applications. Usually\nwe control the applications using mouse, keyboard, laser pointers etc. but,\nwith the recent advent in the technology it has even left behind their usage by\nintroducing more efficient techniques to control applications. There are many\nGesture Recognition techniques that have been implemented using image\nprocessing in the past.\n  However recognizing the gestures in the noisy background has always been a\ndifficult task to achieve. In the proposed system, we are going to use one such\ntechnique called Augmentation in Image processing to control Media Player. We\nwill recognize Gestures using which we are going to control the operations on\nMedia player. Augmentation usually is one step ahead when it comes to virtual\nreality. It has no restrictions on the background. Moreover it also does not\nrely on certain things like gloves, color pointers etc. for recognizing the\ngesture. This system mainly appeals to those users who always looks out for a\nbetter option that makes their interaction with computer more simpler or\neasier.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 07:52:04 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Vasave", "Sandeep", ""], ["Plave", "Amol", ""]]}, {"id": "1411.5331", "submitter": "Michelle Greene", "authors": "Michelle R. Greene, Abraham P. Botros, Diane M. Beck and Li Fei-Fei", "title": "Visual Noise from Natural Scene Statistics Reveals Human Scene Category\n  Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Our perceptions are guided both by the bottom-up information entering our\neyes, as well as our top-down expectations of what we will see. Although\nbottom-up visual processing has been extensively studied, comparatively little\nis known about top-down signals. Here, we describe REVEAL (Representations\nEnvisioned Via Evolutionary ALgorithm), a method for visualizing an observer's\ninternal representation of a complex, real-world scene, allowing us to, for the\nfirst time, visualize the top-down information in an observer's mind. REVEAL\nrests on two innovations for solving this high dimensional problem: visual\nnoise that samples from natural image statistics, and a computer algorithm that\ncollaborates with human observers to efficiently obtain a solution. In this\nwork, we visualize observers' internal representations of a visual scene\ncategory (street) using an experiment in which the observer views the\nnaturalistic visual noise and collaborates with the algorithm to externalize\nhis internal representation. As no scene information was presented, observers\nhad to use their internal knowledge of the target, matching it with the visual\nfeatures in the noise. We matched reconstructed images with images of\nreal-world street scenes to enhance visualization. Critically, we show that the\nvisualized mental images can be used to predict rapid scene detection\nperformance, as each observer had faster and more accurate responses to\ndetecting real-world images that were the most similar to his reconstructed\nstreet templates. These results show that it is possible to visualize\npreviously unobservable mental representations of real world stimuli. More\nbroadly, REVEAL provides a general method for objectively examining the content\nof previously private, subjective mental experiences.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 19:38:50 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Greene", "Michelle R.", ""], ["Botros", "Abraham P.", ""], ["Beck", "Diane M.", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1411.5340", "submitter": "Michelle Greene", "authors": "Michelle R. Greene, Christopher Baldassano, Andre Esteva, Diane M.\n  Beck and Li Fei-Fei", "title": "Affordances Provide a Fundamental Categorization Principle for Visual\n  Scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  How do we know that a kitchen is a kitchen by looking? Relatively little is\nknown about how we conceptualize and categorize different visual environments.\nTraditional models of visual perception posit that scene categorization is\nachieved through the recognition of a scene's objects, yet these models cannot\naccount for the mounting evidence that human observers are relatively\ninsensitive to the local details in an image. Psychologists have long theorized\nthat the affordances, or actionable possibilities of a stimulus are pivotal to\nits perception. To what extent are scene categories created from similar\naffordances? Using a large-scale experiment using hundreds of scene categories,\nwe show that the activities afforded by a visual scene provide a fundamental\ncategorization principle. Affordance-based similarity explained the majority of\nthe structure in the human scene categorization patterns, outperforming\nalternative similarities based on objects or visual features. We all models\nwere combined, affordances provided the majority of the predictive power in the\ncombined model, and nearly half of the total explained variance is captured\nonly by affordances. These results challenge many existing models of high-level\nvisual perception, and provide immediately testable hypotheses for the\nfunctional organization of the human perceptual system.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 19:58:59 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Greene", "Michelle R.", ""], ["Baldassano", "Christopher", ""], ["Esteva", "Andre", ""], ["Beck", "Diane M.", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1411.5394", "submitter": "Shyamnath Gollakota", "authors": "Rajalakshmi Nandakumar and Bryce Kellogg and Shyamnath Gollakota", "title": "Wi-Fi Gesture Recognition on Existing Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the first wireless gesture recognition system that\noperates using existingWi-Fi signals and devices. To achieve this, we first\nidentify limitations of existing wireless gesture recognition approaches that\nlimit their applicability to Wi-Fi. We then introduce algorithms that can\nclassify gestures using information that is readily available on Wi-Fi devices.\nWe demonstrate the feasibility of our design using a prototype implementation\non off-the-shelf Wi-Fi devices. Our results show that we can achieve a\nclassification accuracy of 91% while classifying four gestures across six\nparticipants, without the need for per-participant training. Finally, we show\nthe feasibility of gesture recognition in non-line-ofsight situations with the\nparticipants interacting with a Wi-Fi device placed in a backpack.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 21:55:20 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Nandakumar", "Rajalakshmi", ""], ["Kellogg", "Bryce", ""], ["Gollakota", "Shyamnath", ""]]}, {"id": "1411.5795", "submitter": "Tony", "authors": "Tie Luo and Chen-Khong Tham", "title": "Fairness and Social Welfare in Incentivizing Participatory Sensing", "comments": "Game theory; demand-supply model; network economics; stochastic\n  programming; chance-constrained programming", "journal-ref": "Proc. IEEE SECON, June 2012, pp. 425-433", "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.HC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Participatory sensing has emerged recently as a promising approach to\nlarge-scale data collection. However, without incentives for users to regularly\ncontribute good quality data, this method is unlikely to be viable in the long\nrun. In this paper, we link incentive to users' demand for consuming compelling\nservices, as an approach complementary to conventional credit or reputation\nbased approaches. With this demand-based principle, we design two incentive\nschemes, Incentive with Demand Fairness (IDF) and Iterative Tank Filling (ITF),\nfor maximizing fairness and social welfare, respectively. Our study shows that\nthe IDF scheme is max-min fair and can score close to 1 on the Jain's fairness\nindex, while the ITF scheme maximizes social welfare and achieves a unique Nash\nequilibrium which is also Pareto and globally optimal. We adopted a game\ntheoretic approach to derive the optimal service demands. Furthermore, to\naddress practical considerations, we use a stochastic programming technique to\nhandle uncertainty that is often encountered in real life situations.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 08:46:55 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Luo", "Tie", ""], ["Tham", "Chen-Khong", ""]]}, {"id": "1411.5977", "submitter": "Nihar Shah", "authors": "Nihar B. Shah and Dengyong Zhou", "title": "On the Impossibility of Convex Inference in Human Computation", "comments": "AAAI 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human computation or crowdsourcing involves joint inference of the\nground-truth-answers and the worker-abilities by optimizing an objective\nfunction, for instance, by maximizing the data likelihood based on an assumed\nunderlying model. A variety of methods have been proposed in the literature to\naddress this inference problem. As far as we know, none of the objective\nfunctions in existing methods is convex. In machine learning and applied\nstatistics, a convex function such as the objective function of support vector\nmachines (SVMs) is generally preferred, since it can leverage the\nhigh-performance algorithms and rigorous guarantees established in the\nextensive literature on convex optimization. One may thus wonder if there\nexists a meaningful convex objective function for the inference problem in\nhuman computation. In this paper, we investigate this convexity issue for human\ncomputation. We take an axiomatic approach by formulating a set of axioms that\nimpose two mild and natural assumptions on the objective function for the\ninference. Under these axioms, we show that it is unfortunately impossible to\nensure convexity of the inference problem. On the other hand, we show that\ninterestingly, in the absence of a requirement to model \"spammers\", one can\nconstruct reasonable objective functions for crowdsourcing that guarantee\nconvex inference.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 18:51:10 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Shah", "Nihar B.", ""], ["Zhou", "Dengyong", ""]]}, {"id": "1411.7090", "submitter": "Han Yu", "authors": "Han Yu and Zhiqi Shen and Qiong Wu and Chunyan Miao", "title": "Designing Socially Intelligent Virtual Companions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual companions that interact with users in a socially complex environment\nrequire a wide range of social skills. Displaying curiosity is simultaneously a\nfactor to improve a companion's believability and to unobtrusively affect the\nuser's activities over time. Curiosity represents a drive to know new things.\nIt is a major driving force for engaging learners in active learning. Existing\nresearch work pays little attention in curiosity. In this paper, we enrich the\nsocial skills of a virtual companion by infusing curiosity into its mental\nmodel. A curious companion residing in a Virtual Learning Environment (VLE) to\nstimulate user's curiosity is proposed. The curious companion model is\ndeveloped based on multidisciplinary considerations. The effectiveness of the\ncurious companion is demonstrated by a preliminary field study.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 02:42:21 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Yu", "Han", ""], ["Shen", "Zhiqi", ""], ["Wu", "Qiong", ""], ["Miao", "Chunyan", ""]]}, {"id": "1411.7960", "submitter": "Emilio Leonardi", "authors": "Alberto Tarable, Alessandro Nordio, Emilio Leonardi, Marco Ajmone\n  Marsan", "title": "The Importance of Being Earnest in Crowdsourcing Systems", "comments": "To appear at Infocom 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first systematic investigation of the potential\nperformance gains for crowdsourcing systems, deriving from available\ninformation at the requester about individual worker earnestness (reputation).\nIn particular, we first formalize the optimal task assignment problem when\nworkers' reputation estimates are available, as the maximization of a monotone\n(submodular) function subject to Matroid constraints. Then, being the optimal\nproblem NP-hard, we propose a simple but efficient greedy heuristic task\nallocation algorithm. We also propose a simple ``maximum a-posteriori``\ndecision rule. Finally, we test and compare different solutions, showing that\nsystem performance can greatly benefit from information about workers'\nreputation. Our main findings are that: i) even largely inaccurate estimates of\nworkers' reputation can be effectively exploited in the task assignment to\ngreatly improve system performance; ii) the performance of the maximum\na-posteriori decision rule quickly degrades as worker reputation estimates\nbecome inaccurate; iii) when workers' reputation estimates are significantly\ninaccurate, the best performance can be obtained by combining our proposed task\nassignment algorithm with the LRA decision rule introduced in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 16:20:29 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Tarable", "Alberto", ""], ["Nordio", "Alessandro", ""], ["Leonardi", "Emilio", ""], ["Marsan", "Marco Ajmone", ""]]}]