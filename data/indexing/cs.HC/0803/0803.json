[{"id": "0803.0164", "submitter": "Grenville Croll", "authors": "Simon Thorne, David Ball", "title": "Considering Functional Spreadsheet Operator Usage Suggests the Value of\n  Example Driven Modelling for Decision Support Systems", "comments": "12 Pages, 6 Figures, 3 Tables", "journal-ref": "roc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 147-158\n  ISBN:1-905617-08-9", "doi": null, "report-no": null, "categories": "cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most spreadsheet surveys both for reporting use and error focus on the\npractical application of the spreadsheet in a particular industry. Typically\nthese studies will illustrate that a particular percentage of spreadsheets are\nused for optimisation and a further percentage are used for 'What if' analysis.\nMuch less common is examining the classes of function, as defined by the\nvendor, used by modellers to build their spreadsheet models. This alternative\nanalysis allows further insight into the programming nature of spreadsheets and\nmay assist researchers in targeting particular structures in spreadsheet\nsoftware for further investigation. Further, understanding the functional\nmake-up of spreadsheets allows effective evaluation of novel approaches from a\nprogramming point of view. It allows greater insight into studies that report\nwhat spreadsheets are used for since it is explicit which functional structures\nare in use in spreadsheets. We conclude that a deeper understanding of the use\nof operators and the operator's relationship to error would provide fresh\ninsight into the spreadsheet error problem. Considering functional spreadsheet\noperator usage suggests the value of Example Driven Modelling for Decision\nSupport Systems\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2008 01:25:41 GMT"}], "update_date": "2008-03-10", "authors_parsed": [["Thorne", "Simon", ""], ["Ball", "David", ""]]}, {"id": "0803.0165", "submitter": "Grenville Croll", "authors": "Raymond Payette", "title": "Documenting Spreadsheets", "comments": "12 Pages, 15 screen shots", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 163-173\n  ISBN:1-905617-08-9", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses spreadsheets documentation and new means to achieve this\nend by using Excel's built-in \"Comment\" function. By structuring comments, they\ncan be used as an essential tool to fully explain spreadsheet. This will\ngreatly facilitate spreadsheet change control, risk management and auditing. It\nwill fill a crucial gap in corporate governance by adding essential information\nthat can be managed in order to satisfy internal controls and accountability\nstandards.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2008 01:34:30 GMT"}], "update_date": "2008-03-10", "authors_parsed": [["Payette", "Raymond", ""]]}, {"id": "0803.0166", "submitter": "Grenville Croll", "authors": "Richard Brath, Michael Peters", "title": "Spreadsheet Validation and Analysis through Content Visualization", "comments": "10 Pages, 11 Colour Figures", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 175-183\n  ISBN:1-905617-08-9", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing spreadsheet content provides analytic insight and visual\nvalidation of large amounts of spreadsheet data. Oculus Excel Visualizer is a\npoint and click data visualization experiment which directly visualizes Excel\ndata and re-uses the layout and formatting already present in the spreadsheet.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2008 01:40:31 GMT"}], "update_date": "2008-03-10", "authors_parsed": [["Brath", "Richard", ""], ["Peters", "Michael", ""]]}, {"id": "0803.0167", "submitter": "Grenville Croll", "authors": "Michael Purser, David Chadwick", "title": "Does an awareness of differing types of spreadsheet errors aid end-users\n  in identifying spreadsheets errors?", "comments": "20 Pages, 14 Tables and Figures, many in colour", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 185-204\n  ISBN:1-905617-08-9", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research presented in this paper establishes a valid, and simplified,\nrevision of previous spreadsheet error classifications. This investigation is\nconcerned with the results of a web survey and two web-based gender and\ndomain-knowledge free spreadsheet error identification exercises. The\nparticipants of the survey and exercises were a test group of professionals\n(all of whom regularly use spreadsheets) and a control group of students from\nthe University of Greenwich (UK). The findings show that over 85% of users are\nalso the spreadsheet's developer, supporting the revised spreadsheet error\nclassification. The findings also show that spreadsheet error identification\nability is directly affected both by spreadsheet experience and by error-type\nawareness. In particular, that spreadsheet error-type awareness significantly\nimproves the user's ability to identify, the more surreptitious, qualitative\nerror.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2008 01:49:03 GMT"}], "update_date": "2008-03-10", "authors_parsed": [["Purser", "Michael", ""], ["Chadwick", "David", ""]]}, {"id": "0803.0168", "submitter": "Grenville Croll", "authors": "Kenneth R. Baker, Stephen G. Powell, Barry Lawson, and Lynn\n  Foster-Johnson", "title": "Comparison of Characteristics and Practices amongst Spreadsheet Users\n  with Different Levels of Experience", "comments": "16 Pages, 11 Tables", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 205-219\n  ISBN:1-905617-08-9", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed an internet-based questionnaire on spreadsheet use that we\nadministered to a large number of users in several companies and organizations\nto document how spreadsheets are currently being developed and used in\nbusiness. In this paper, we discuss the results drawn from of a comparison of\nresponses from individuals with the most experience and expertise with those\nfrom individuals with the least. These results describe two views of\nspreadsheet design and use in organizations, and reflect gaps between these two\ngroups and between these groups and the entire population of nearly 1600\nrespondents. Moreover, our results indicate that these gaps have multiple\ndimensions: they reflect not only the context, skill, and practices of\nindividual users but also the policies of large organizations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2008 01:55:40 GMT"}], "update_date": "2008-03-10", "authors_parsed": [["Baker", "Kenneth R.", ""], ["Powell", "Stephen G.", ""], ["Lawson", "Barry", ""], ["Foster-Johnson", "Lynn", ""]]}, {"id": "0803.0169", "submitter": "Grenville Croll", "authors": "Paul J. Blayney", "title": "An Investigation of the Incidence and Effect of Spreadsheet Errors\n  Caused by the Hard Coding of Input Data Values into Formulas", "comments": "10 Pages, 5 Tables", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 22-230\n  ISBN:1-905617-08-9", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hard coding of input data or constants into spreadsheet formulas is\nwidely recognised as poor spreadsheet model design. However, the importance of\navoiding such practice appears to be underestimated perhaps in light of the\nlack of quantitative error at the time of occurrence and the recognition that\nthis design defect may never result in a bottom-line error. The paper examines\nboth the academic and practitioner view of such hard coding design flaws. The\npractitioner or industry viewpoint is gained indirectly through a review of\ncommercial spreadsheet auditing software. The development of an automated\n(electronic) means for detecting such hard coding is described together with a\ndiscussion of some results obtained through analysis of a number of student and\npractitioner spreadsheet models.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2008 02:00:53 GMT"}], "update_date": "2008-03-10", "authors_parsed": [["Blayney", "Paul J.", ""]]}, {"id": "0803.0515", "submitter": "Christopher Pearson", "authors": "Christopher Pearson, Celina Gibbs, Yvonne Coady", "title": "Intuitive Source Code Visualization Tools for Improving Student\n  Comprehension: BRICS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even relatively simple code analysis can be a daunting task for many first\nyear students. Perceived complexity, coupled with foreign and harsh syntax,\noften outstrips the ability for students to take in what they are seeing in\nterms of their verbal memory. That is, first year students often lack the\nexperience to encode critical building blocks in source code, and their\ninterrelationships, into their own words. We believe this argues for the need\nfor IDEs to provide additional support for representations that would appeal\ndirectly to visual memory. In this paper, we examine this need for intuitive\nsource code visualization tools that are easily accessible to novice\nprogrammers, discuss the requirements for such a tool, and suggest a novel idea\nthat takes advantage of human peripheral vision to achieve stronger overall\ncode structure awareness.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2008 18:46:49 GMT"}], "update_date": "2008-03-05", "authors_parsed": [["Pearson", "Christopher", ""], ["Gibbs", "Celina", ""], ["Coady", "Yvonne", ""]]}, {"id": "0803.1104", "submitter": "Michael Hahsler", "authors": "Michael Hahsler", "title": "Optimizing Web Sites for Customer Retention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With customer relationship management (CRM) companies move away from a mainly\nproduct-centered view to a customer-centered view. Resulting from this change,\nthe effective management of how to keep contact with customers throughout\ndifferent channels is one of the key success factors in today's business world.\nCompany Web sites have evolved in many industries into an extremely important\nchannel through which customers can be attracted and retained. To analyze and\noptimize this channel, accurate models of how customers browse through the Web\nsite and what information within the site they repeatedly view are crucial.\nTypically, data mining techniques are used for this purpose. However, there\nalready exist numerous models developed in marketing research for traditional\nchannels which could also prove valuable to understanding this new channel. In\nthis paper we propose the application of an extension of the Logarithmic Series\nDistribution (LSD) model repeat-usage of Web-based information and thus to\nanalyze and optimize a Web Site's capability to support one goal of CRM, to\nretain customers. As an example, we use the university's blended learning web\nportal with over a thousand learning resources to demonstrate how the model can\nbe used to evaluate and improve the Web site's effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 7 Mar 2008 14:50:21 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Hahsler", "Michael", ""]]}, {"id": "0803.1716", "submitter": "Lokman Meho", "authors": "Lokman I. Meho and Yvonne Rogers", "title": "Citation Counting, Citation Ranking, and h-Index of Human-Computer\n  Interaction Researchers: A Comparison between Scopus and Web of Science", "comments": "35 pages, 9 tables, 3 figures, accepted for publication in the\n  Journal of the American Society for Information Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study examines the differences between Scopus and Web of Science in the\ncitation counting, citation ranking, and h-index of 22 top human-computer\ninteraction (HCI) researchers from EQUATOR--a large British Interdisciplinary\nResearch Collaboration project. Results indicate that Scopus provides\nsignificantly more coverage of HCI literature than Web of Science, primarily\ndue to coverage of relevant ACM and IEEE peer-reviewed conference proceedings.\nNo significant differences exist between the two databases if citations in\njournals only are compared. Although broader coverage of the literature does\nnot significantly alter the relative citation ranking of individual\nresearchers, Scopus helps distinguish between the researchers in a more nuanced\nfashion than Web of Science in both citation counting and h-index. Scopus also\ngenerates significantly different maps of citation networks of individual\nscholars than those generated by Web of Science. The study also presents a\ncomparison of h-index scores based on Google Scholar with those based on the\nunion of Scopus and Web of Science. The study concludes that Scopus can be used\nas a sole data source for citation-based research and evaluation in HCI,\nespecially if citations in conference proceedings are sought and that h scores\nshould be manually calculated instead of relying on system calculations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2008 08:09:19 GMT"}], "update_date": "2008-03-13", "authors_parsed": [["Meho", "Lokman I.", ""], ["Rogers", "Yvonne", ""]]}, {"id": "0803.1754", "submitter": "Grenville Croll", "authors": "Simon Thorne, David Ball, Zoe Lawson", "title": "A Novel Approach to Formulae Production and Overconfidence Measurement\n  to Reduce Risk in Spreadsheet Modelling", "comments": "12 pages, 7 figures", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 71-83\n  ISBN 1 902724 94 1", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on formulae production in spreadsheets has established the practice\nas high risk yet unrecognised as such by industry. There are numerous software\napplications that are designed to audit formulae and find errors. However these\nare all post creation, designed to catch errors before the spreadsheet is\ndeployed. As a general conclusion from EuSpRIG 2003 conference it was decided\nthat the time has come to attempt novel solutions based on an understanding of\nhuman factors. Hence in this paper we examine one such possibility namely a\nnovel example driven modelling approach. We discuss a control experiment that\ncompares example driven modelling against traditional approaches over several\nprogressively more difficult tests. The results are very interesting and\ncertainly point to the value of further investigation of the example driven\npotential. Lastly we propose a method for statistically analysing the problem\nof overconfidence in spreadsheet modellers.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2008 11:47:41 GMT"}], "update_date": "2008-03-13", "authors_parsed": [["Thorne", "Simon", ""], ["Ball", "David", ""], ["Lawson", "Zoe", ""]]}, {"id": "0803.1862", "submitter": "Grenville Croll", "authors": "Simon Thorne, David Ball", "title": "Exploring Human Factors in Spreadsheet Development", "comments": "11 pages, 3 figures, 2 tables", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2005 161-172\n  ISBN:1-902724-16-X", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider human factors and their impact on spreadsheet\ndevelopment in strategic decision-making. This paper brings forward research\nfrom many disciplines both directly related to spreadsheets and a broader\nspectrum from psychology to industrial processing. We investigate how human\nfactors affect a simplified development cycle and what the potential\nconsequences are.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2008 22:09:59 GMT"}], "update_date": "2008-03-14", "authors_parsed": [["Thorne", "Simon", ""], ["Ball", "David", ""]]}, {"id": "0803.1866", "submitter": "Grenville Croll", "authors": "Deborah Cernauskas, Andrew Kumiega, Ben VanVliet", "title": "Risk Management for Complex Calculations: EuSpRIG Best Practices in\n  Hybrid Applications", "comments": "11 pages, 8 figures", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 25-36\n  ISBN 978-905617-58-6", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the need for advanced, interactive mathematical models has increased,\nuser/programmers are increasingly choosing the MatLab scripting language over\nspreadsheets. However, applications developed in these tools have high error\nrisk, and no best practices exist. We recommend that advanced, highly\nmathematical applications incorporate these tools with spreadsheets into hybrid\napplications, where developers can apply EuSpRIG best practices. Development of\nhybrid applications can reduce the potential for errors, shorten development\ntime, and enable higher level operations. We believe that hybrid applications\nare the future and over the course of this paper, we apply and extend\nspreadsheet best practices to reduce or prevent risks in hybrid Excel/MatLab\napplications.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2008 22:30:10 GMT"}], "update_date": "2008-03-14", "authors_parsed": [["Cernauskas", "Deborah", ""], ["Kumiega", "Andrew", ""], ["VanVliet", "Ben", ""]]}, {"id": "0803.1875", "submitter": "Grenville Croll", "authors": "Ziv Hellman", "title": "Breaking Out of the Cell: On The Benefits of a New Spreadsheet\n  User-Interaction Paradigm", "comments": "12 Pages, 2 Diagrams", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2005 113-124\n  ISBN:1-902724-16-X", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary spreadsheets are plagued by a profusion of errors, auditing\ndifficulties, lack of uniform development methodologies, and barriers to easy\ncomprehension of the underlying business models they represent. This paper\npresents a case that most of these difficulties stem from the fact that the\nstandard spreadsheet user-interaction paradigm - the 'cell-matrix' approach -\nis appropriate for spreadsheet data presentation but has significant drawbacks\nwith respect to spreadsheet creation, maintenance and comprehension when\nworkbooks pass a minimal threshold of complexity. An alternative paradigm for\nthe automated generation of spreadsheets directly from plain-language business\nmodel descriptions is presented along with its potential benefits. Sunsight\nModeller (TM), a working software system implementing the suggested paradigm,\nis briefly described.\n", "versions": [{"version": "v1", "created": "Thu, 13 Mar 2008 00:15:40 GMT"}], "update_date": "2008-03-14", "authors_parsed": [["Hellman", "Ziv", ""]]}, {"id": "0803.2527", "submitter": "Grenville Croll", "authors": "Vipin Samar, Sangeeta Patni", "title": "Controlling the Information Flow in Spreadsheets", "comments": "9 pages", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2005 125-134\n  ISBN:1-902724-16-X", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no denying that spreadsheets have become critical for all\noperational processes including financial reporting, budgeting, forecasting,\nand analysis. Microsoft Excel has essentially become a scratch pad and a data\nbrowser that can quickly be put to use for information gathering and\ndecision-making. However, there is little control in how data comes into Excel,\nand how it gets updated. The information supply chain feeding into Excel\nremains ad hoc and without any centralized IT control. This paper discusses\nsome of the pitfalls of the data collection and maintenance process in Excel.\nIt then suggests service-oriented architecture (SOA) based information\ngathering and control techniques to ameliorate the pitfalls of this scratch pad\nwhile improving the integrity of data, boosting the productivity of the\nbusiness users, and building controls to satisfy the requirements of Section\n404 of the Sarbanes-Oxley Act.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2008 20:46:12 GMT"}], "update_date": "2008-03-19", "authors_parsed": [["Samar", "Vipin", ""], ["Patni", "Sangeeta", ""]]}, {"id": "0803.3186", "submitter": "Denis Pallez", "authors": "Denis Pallez (I3S), Laurent Brisson (I3S), Thierry Baccino (LPEQ)", "title": "Towards a human eye behavior model by applying Data Mining Techniques on\n  Gaze Information from IEC", "comments": null, "journal-ref": "Dans Proceedings of the Third International Conference on Human\n  Centered Processes - Human Centered Processes, Delft : Pays-Bas (2008)", "doi": null, "report-no": null, "categories": "cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we firstly present what is Interactive Evolutionary\nComputation (IEC) and rapidly how we have combined this artificial intelligence\ntechnique with an eye-tracker for visual optimization. Next, in order to\ncorrectly parameterize our application, we present results from applying data\nmining techniques on gaze information coming from experiments conducted on\nabout 80 human individuals.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2008 15:38:25 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Pallez", "Denis", "", "I3S"], ["Brisson", "Laurent", "", "I3S"], ["Baccino", "Thierry", "", "LPEQ"]]}, {"id": "0803.3394", "submitter": "Grenville Croll", "authors": "Patrick O'Beirne", "title": "Facing the Facts", "comments": "7 pages, 1 table, 1 figure", "journal-ref": "Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 209-214\n  ISBN 978-905617-58-6", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human error research on overconfidence supports the benefits of early\nvisibility of defects and disciplined development. If risk to the enterprise is\nto be reduced, individuals need to become aware of the reality of the quality\nof their work. Several cycles of inspection and defect removal are inevitable.\nSoftware Quality Management measurements of defect density and removal\nefficiency are applicable. Research of actual spreadsheet error rates shows\ndata consistent with other software depending on the extent to which the work\nproduct was reviewed before inspection. The paper argues that the payback for\nan investment in early review time is justified by the saving in project delay\nand expensive errors in use.\n  'If debugging is the process of removing bugs, then programming must be the\nprocess of putting them in' - Anon.\n", "versions": [{"version": "v1", "created": "Mon, 24 Mar 2008 12:01:16 GMT"}], "update_date": "2008-03-25", "authors_parsed": [["O'Beirne", "Patrick", ""]]}, {"id": "0803.3482", "submitter": "Tad Hogg", "authors": "Tad Hogg and Gabor Szabo", "title": "Diversity of Online Community Activities", "comments": "14 pages", "journal-ref": null, "doi": "10.1209/0295-5075/86/38003", "report-no": null, "categories": "cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web sites where users create and rate content as well as form networks with\nother users display long-tailed distributions in many aspects of behavior.\nUsing behavior on one such community site, Essembly, we propose and evaluate\nplausible mechanisms to explain these behaviors. Unlike purely descriptive\nmodels, these mechanisms rely on user behaviors based on information available\nlocally to each user. For Essembly, we find the long-tails arise from large\ndifferences among user activity rates and qualities of the rated content, as\nwell as the extensive variability in the time users devote to the site. We show\nthat the models not only explain overall behavior but also allow estimating the\nquality of content from their early behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2008 00:23:05 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Hogg", "Tad", ""], ["Szabo", "Gabor", ""]]}, {"id": "0803.4018", "submitter": "Jose Javier Ramasco", "authors": "Bruno Goncalves, Jose J. Ramasco", "title": "Human dynamics revealed through Web analytics", "comments": "7 pages, 8 figures", "journal-ref": "Physical Review E 78, 026123 (2008)", "doi": "10.1103/PhysRevE.78.026123", "report-no": null, "categories": "cs.HC cond-mat.stat-mech cs.CY physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the World Wide Web was first conceived as a way to facilitate the\nsharing of scientific information at the CERN (European Center for Nuclear\nResearch) few could have imagined the role it would come to play in the\nfollowing decades. Since then, the increasing ubiquity of Internet access and\nthe frequency with which people interact with it raise the possibility of using\nthe Web to better observe, understand, and monitor several aspects of human\nsocial behavior. Web sites with large numbers of frequently returning users are\nideal for this task. If these sites belong to companies or universities, their\nusage patterns can furnish information about the working habits of entire\npopulations. In this work, we analyze the properly anonymized logs detailing\nthe access history to Emory University's Web site. Emory is a medium size\nuniversity located in Atlanta, Georgia. We find interesting structure in the\nactivity patterns of the domain and study in a systematic way the main forces\nbehind the dynamics of the traffic. In particular, we show that both linear\npreferential linking and priority based queuing are essential ingredients to\nunderstand the way users navigate the Web.\n", "versions": [{"version": "v1", "created": "Thu, 27 Mar 2008 21:19:54 GMT"}, {"version": "v2", "created": "Wed, 21 May 2008 17:39:20 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Goncalves", "Bruno", ""], ["Ramasco", "Jose J.", ""]]}]