[{"id": "1409.0052", "submitter": "Rawan Alabdulrahman Miss", "authors": "Arwa Alamoudi, Noura Alomar, Rawan Alabdulrahman, Sarah Alkoblan and\n  Wea'am Alrashed", "title": "Usability Engineering of Games: A Comparative Analysis of Measuring\n  Excitement Using Sensors, Direct Observations and Self-Reported Data", "comments": "Wearable technology, Usability testing, Affective computing, Q\n  Sensor, Xbox Kinect, International Journal Of UbiComp (IJU), July 2014,\n  Volume 5, Number 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usability engineering and usability testing are concepts that continue to\nevolve. Interesting research studies and new ideas come up every now and then.\nThis paper tests the hypothesis of using an EDA based physiological\nmeasurements as a usability testing tool by considering three measures which\nare observers opinions, self reported data and EDA based physiological sensor\ndata. These data were analyzed comparatively and statistically. It concludes by\ndiscussing the findings that has been obtained from those subjective and\nobjective measures, which partially supports the hypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 29 Aug 2014 22:37:28 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Alamoudi", "Arwa", ""], ["Alomar", "Noura", ""], ["Alabdulrahman", "Rawan", ""], ["Alkoblan", "Sarah", ""], ["Alrashed", "Wea'am", ""]]}, {"id": "1409.0107", "submitter": "Marco Congedo", "authors": "Alexandre Barachant and Marco Congedo", "title": "A Plug&Play P300 BCI Using Information Geometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new classification methods for Event Related Potentials\n(ERP) based on an Information geometry framework. Through a new estimation of\ncovariance matrices, this work extend the use of Riemannian geometry, which was\npreviously limited to SMR-based BCI, to the problem of classification of ERPs.\nAs compared to the state-of-the-art, this new method increases performance,\nreduces the number of data needed for the calibration and features good\ngeneralisation across sessions and subjects. This method is illustrated on data\nrecorded with the P300-based game brain invaders. Finally, an online and\nadaptive implementation is described, where the BCI is initialized with generic\nparameters derived from a database and continuously adapt to the individual,\nallowing the user to play the game without any calibration while keeping a high\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 30 Aug 2014 12:17:15 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Barachant", "Alexandre", ""], ["Congedo", "Marco", ""]]}, {"id": "1409.0128", "submitter": "Jerome Baum", "authors": "Arne Renkema-Padmos and Jerome Baum", "title": "Through the Frosted Glass: Security Problems in a Translucent UI", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Translucency is now a common design element in at least one popular mobile\noperating system. This raises security concerns as it can make it harder for\nusers to correctly identify and interpret trusted interaction elements. In this\npaper, we demonstrate this security problem using the example of the Safari\nbrowser in the latest iOS version on Apple tablets and phones (iOS7), and\ndiscuss technical challenges of an attack as well as solutions to these\nchallenges. We conclude with a survey-based user study, where we seek to\nquantify the security impact, and find that further investigation is warranted.\n", "versions": [{"version": "v1", "created": "Sat, 30 Aug 2014 15:45:19 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Renkema-Padmos", "Arne", ""], ["Baum", "Jerome", ""]]}, {"id": "1409.0925", "submitter": "Ahmad Hassanat", "authors": "Ahmad B. A. Hassanat", "title": "Bypassing Captcha By Machine A Proof For Passing The Turing Test", "comments": "European Scientific Journal May 2014 edition vol.10, No.15 ISSN:\n  1857-7881 (Print) e-ISSN 1857-7431", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the last ten years, CAPTCHAs have been widely used by websites to prevent\ntheir data being automatically updated by machines. By supposedly allowing only\nhumans to do so, CAPTCHAs take advantage of the reverse Turing test (TT),\nknowing that humans are more intelligent than machines. Generally, CAPTCHAs\nhave defeated machines, but things are changing rapidly as technology improves.\nHence, advanced research into optical character recognition (OCR) is overtaking\nattempts to strengthen CAPTCHAs against machine-based attacks. This paper\ninvestigates the immunity of CAPTCHA, which was built on the failure of the TT.\nWe show that some CAPTCHAs are easily broken using a simple OCR machine built\nfor the purpose of this study. By reviewing other techniques, we show that even\nmore difficult CAPTCHAs can be broken using advanced OCR machines. Current\nadvances in OCR should enable machines to pass the TT in the image recognition\ndomain, which is exactly where machines are seeking to overcome CAPTCHAs. We\nenhance traditional CAPTCHAs by employing not only characters, but also natural\nlanguage and multiple objects within the same CAPTCHA. The proposed CAPTCHAs\nmight be able to hold out against machines, at least until the advent of a\nmachine that passes the TT completely.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 00:05:28 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["Hassanat", "Ahmad B. A.", ""]]}, {"id": "1409.1496", "submitter": "Giovanni Luca Ciampaglia", "authors": "Giovanni Luca Ciampaglia, Dario Taraborelli", "title": "MoodBar: Increasing new user retention in Wikipedia through lightweight\n  socialization", "comments": "9 pages, 5 figures, accepted for presentation at CSCW'15", "journal-ref": null, "doi": "10.1145/2675133.2675181", "report-no": null, "categories": "cs.SI cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Socialization in online communities allows existing members to welcome and\nrecruit newcomers, introduce them to community norms and practices, and sustain\ntheir early participation. However, socializing newcomers does not come for\nfree: in large communities, socialization can result in a significant workload\nfor mentors and is hard to scale. In this study we present results from an\nexperiment that measured the effect of a lightweight socialization tool on the\nactivity and retention of newly registered users attempting to edit for the\nfirst time Wikipedia. Wikipedia is struggling with the retention of newcomers\nand our results indicate that a mechanism to elicit lightweight feedback and to\nprovide early mentoring to newcomers improves their chances of becoming\nlong-term contributors.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 17:11:54 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Ciampaglia", "Giovanni Luca", ""], ["Taraborelli", "Dario", ""]]}, {"id": "1409.1981", "submitter": "Ramesh G.P", "authors": "Ramesh.GP, Aravind.CV, Rajparthiban.R, N.Soysa", "title": "A Body Area Network through Wireless Technology", "comments": "6 Pages, 6 Figures, 1 table", "journal-ref": "International Journal of Computer Science and Engineering\n  Communications, Volume 2,2014,pp 432-437", "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A physiological signal monitoring system and alerting system using wireless\ntechnology is presented. The two types of physiological signal monitoring are\ncaptured from the body through leads and using the radio-frequency transmitting\nand receiving module the data are interfaced to computer systems. Furthering\nusing a developed user interface module the captured signals are analyzed for\nchecking abnormality. Any significant recordings are transmitted to the\nphysicians hand phone by using external serial SMS modem. ECG signal de-noising\nis conducted by using low-pass and high-pass filters. EEG signals de-noising is\nconducted by using band-pass filters set. A comparative evaluation of the\nmodule with the manual recording shows encouraging results. The ECG and EEG\npattern are presented in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 6 Sep 2014 04:18:49 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["GP", "Ramesh.", ""], ["CV", "Aravind.", ""], ["R", "Rajparthiban.", ""], ["Soysa", "N.", ""]]}, {"id": "1409.2153", "submitter": "Ankit Chaudhary", "authors": "J. L. Raheja, Dhiraj, D. Gopinath, Ankit Chaudhary", "title": "GUI system for Elders/Patients in Intensive Care", "comments": "In proceedings of the 4th IEEE International Conference on\n  International Technology Management Conference, Chicago, IL USA, 12-15 June,\n  2014", "journal-ref": null, "doi": "10.1109/ITMC.2014.6918605", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the old age, few people need special care if they are suffering from\nspecific diseases as they can get stroke while they are in normal life routine.\nAlso patients of any age, who are not able to walk, need to be taken care of\npersonally but for this, either they have to be in hospital or someone like\nnurse should be with them for better care. This is costly in terms of money and\nman power. A person is needed for 24x7 care of these people. To help in this\naspect we purposes a vision based system which will take input from the patient\nand will provide information to the specified person, who is currently may not\nin the patient room. This will reduce the need of man power, also a continuous\nmonitoring would not be needed. The system is using MS Kinect for gesture\ndetection for better accuracy and this system can be installed at home or\nhospital easily. The system provides GUI for simple usage and gives visual and\naudio feedback to user. This system work on natural hand interaction and need\nno training before using and also no need to wear any glove or color strip.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 19:02:32 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Raheja", "J. L.", ""], ["Dhiraj", "", ""], ["Gopinath", "D.", ""], ["Chaudhary", "Ankit", ""]]}, {"id": "1409.2208", "submitter": "Christopher Tucker Ph.D.", "authors": "Christopher A. Tucker", "title": "A wireless hand-held platform for robotic behavior control", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for customizable properties in autonomous robotic platforms, such as\nin-home nursing care for the elderly and parallel implementations of\nhuman-to-machine control interfaces creates an opportunity to introduce methods\ndeploying commonly available mobile devices running robotic command\napplications in managed code. This paper will discuss a human-to-machine\ninterface and demonstrate a prototype consisting of a mobile device running a\nconfigurable application communicating with a mobile robot using a managed,\ntype-safe language, C#.NET, over Bluetooth.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 05:09:49 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Tucker", "Christopher A.", ""]]}, {"id": "1409.2897", "submitter": "Sunsern Cheamanunkul", "authors": "Sunsern Cheamanunkul and Yoav Freund", "title": "Co-adaptation in a Handwriting Recognition System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Handwriting is a natural and versatile method for human-computer interaction,\nespecially on small mobile devices such as smart phones. However, as\nhandwriting varies significantly from person to person, it is difficult to\ndesign handwriting recognizers that perform well for all users. A natural\nsolution is to use machine learning to adapt the recognizer to the user. One\ncomplicating factor is that, as the computer adapts to the user, the user also\nadapts to the computer and probably changes their handwriting. This paper\ninvestigates the dynamics of co-adaptation, a process in which both the\ncomputer and the user are adapting their behaviors in order to improve the\nspeed and accuracy of the communication through handwriting. We devised an\ninformation-theoretic framework for quantifying the efficiency of a handwriting\nsystem where the system includes both the user and the computer. Using this\nframework, we analyzed data collected from an adaptive handwriting recognition\nsystem and characterized the impact of machine adaptation and of human\nadaptation. We found that both machine adaptation and human adaptation have\nsignificant impact on the input rate and must be considered together in order\nto improve the efficiency of the system as a whole.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 21:06:14 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Cheamanunkul", "Sunsern", ""], ["Freund", "Yoav", ""]]}, {"id": "1409.3174", "submitter": "Eytan Bakshy", "authors": "Eytan Bakshy, Dean Eckles, Michael S. Bernstein", "title": "Designing and Deploying Online Field Experiments", "comments": "Proceedings of the 23rd international conference on World wide web,\n  283-292", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.PL cs.SI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online experiments are widely used to compare specific design alternatives,\nbut they can also be used to produce generalizable knowledge and inform\nstrategic decision making. Doing so often requires sophisticated experimental\ndesigns, iterative refinement, and careful logging and analysis. Few tools\nexist that support these needs. We thus introduce a language for online field\nexperiments called PlanOut. PlanOut separates experimental design from\napplication code, allowing the experimenter to concisely describe experimental\ndesigns, whether common \"A/B tests\" and factorial designs, or more complex\ndesigns involving conditional logic or multiple experimental units. These\nlatter designs are often useful for understanding causal mechanisms involved in\nuser behaviors. We demonstrate how experiments from the literature can be\nimplemented in PlanOut, and describe two large field experiments conducted on\nFacebook with PlanOut. For common scenarios in which experiments are run\niteratively and in parallel, we introduce a namespaced management system that\nencourages sound experimental practice.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 18:27:47 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Bakshy", "Eytan", ""], ["Eckles", "Dean", ""], ["Bernstein", "Michael S.", ""]]}, {"id": "1409.3554", "submitter": "Ankit Chaudhary", "authors": "Ankit Chaudhary", "title": "Finger-Stylus for Non Touch-Enable Systems", "comments": "JKSU Engineering Sciences, Elsevier, 2015", "journal-ref": null, "doi": "10.1016/j.jksues.2014.02.002", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since computer was invented, people are using many devices to interact with\ncomputer. Initially there were keyboard, mouse etc. but with the advancement of\ntechnology, new ways are being discovered that are quite usual and natural to\nthe humans like stylus, touch-enable systems. In the current age of technology,\nuser is expected to touch the machine interface to give input. Hand gesture is\nsuch a way to interact with machines where natural bare hand is used to\ncommunicate without touching machine interface. It gives a feeling to user that\nhe is interacting in natural way to some human, not with traditional machines.\nThis paper presents a technique where user needs not to touch the machine\ninterface to draw on screen. Here hand finger draws shapes on monitor like\nstylus, without touching the monitor. This method can be used in many\napplications including games. The finger was used as an input device that acts\nlike paint-brush or finger-stylus and is used to make shapes in front of the\ncamera. Fingertip extraction and motion tracking were done in Matlab with real\ntime constraints. This work is an early attempt to replace stylus with the\nnatural finger without touching screen.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 19:20:45 GMT"}, {"version": "v2", "created": "Sat, 27 Sep 2014 06:24:09 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Chaudhary", "Ankit", ""]]}, {"id": "1409.3993", "submitter": "Rishabh Jain", "authors": "Rishabh Jain, Rupanta Rwiteej Dutta, Rajat Tandon", "title": "Clear, Concise and Effective UI: Opinion and Suggestions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most important aspect of any Software is the operability for the intended\naudience. This factor of operability is encompassed in the user interface,\nwhich serves as the only window to the features of the system. It is thus\nessential that the User Interface provided is robust, concise and lucid.\nPresently there are no properly defined rules or guidelines for user interface\ndesign enabling a perfect design, since such a system cannot be perceived. This\narticle aims at providing suggestions in the design of the User Interface,\nwhich would make it easier for the user to navigate through the system features\nand also the developers to guide the users towards better utilization of the\nfeatures.\n", "versions": [{"version": "v1", "created": "Sat, 13 Sep 2014 21:43:45 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Jain", "Rishabh", ""], ["Dutta", "Rupanta Rwiteej", ""], ["Tandon", "Rajat", ""]]}, {"id": "1409.4194", "submitter": "Pariya Kashfi", "authors": "Pariya Kashfi, Robert Feldt, Agneta Nilsson, Richard Berntsson\n  Svensson", "title": "A Conceptual UX-aware Model of Requirements", "comments": "6th International Working Conference on Human-Centred Software\n  Engineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User eXperience (UX) is becoming increasingly important for success of\nsoftware products. Yet, many companies still face various challenges in their\nwork with UX. Part of these challenges relate to inadequate knowledge and\nawareness of UX and that current UX models are commonly not practical nor well\nintegrated into existing Software Engineering (SE) models and concepts.\nTherefore, we present a conceptual UX-aware model of requirements for software\ndevelopment practitioners. This layered model shows the interrelation between\nUX and functional and quality requirements. The model is developed based on\ncurrent models of UX and software quality characteristics. Through the model we\nhighlight the main differences between various requirement types in particular\nessentially subjective and accidentally subjective quality requirements. We\nalso present the result of an initial validation of the model through\ninterviews with 12 practitioners and researchers. Our results show that the\nmodel can raise practitioners' knowledge and awareness of UX in particular in\nrelation to requirement and testing activities. It can also facilitate\nUX-related communication among stakeholders with different backgrounds.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 09:45:48 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 20:02:58 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Kashfi", "Pariya", ""], ["Feldt", "Robert", ""], ["Nilsson", "Agneta", ""], ["Svensson", "Richard Berntsson", ""]]}, {"id": "1409.5024", "submitter": "Agrima Seth", "authors": "Agrima Seth, Deepak Mishra", "title": "Comparative Study of Geometric and Image Based Modelling and Rendering\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a comparative study of the traditional 3D computer graphics technique\nof geometric modelling and image-based rendering techniques that were surveyed\nand implemented.We have discussed the classifications and representative\nmethods of both the techniques. The study has shown that there is a strong\ncontinuum between both the techniques and a hybrid of the two is most suitable\nfor further implementations.This hybridisation study is underway to create\nmodels of real life situations and provide disaster management training.\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 00:46:26 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Seth", "Agrima", ""], ["Mishra", "Deepak", ""]]}, {"id": "1409.5282", "submitter": "Paul Vickers", "authors": "Paul Vickers and Christopher Laing and Mohamed Debashi and Tom Fairfax", "title": "Sonification Aesthetics and Listening for Network Situational Awareness", "comments": "Workshop paper presented at SoniHED --- Conference on Sonification of\n  Health and Environmental Data, York, UK, 12 September, 2014", "journal-ref": null, "doi": "10.13140/2.1.4225.6648", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper looks at the problem of using sonification to enable network\nadministrators to maintaining situational awareness about their network\nenvironment. Network environments generate a lot of data and the need for\ncontinuous monitoring means that sonification systems must be designed in such\na way as to maximise acceptance while minimising annoyance and listener\nfatigue. It will be argued that solutions based on the concept of the\nsoundscape offer an ecological advantage over other sonification designs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 12:25:04 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["Vickers", "Paul", ""], ["Laing", "Christopher", ""], ["Debashi", "Mohamed", ""], ["Fairfax", "Tom", ""]]}, {"id": "1409.5758", "submitter": "Pierre De Loor", "authors": "Elisabetta Bevacqua (CERV, Lab-STICC), Sankovic Igor (CERV,\n  Lab-STICC), Maatalaoui Ayoub (Lab-STICC), A. N\\'ed\\'elec (Lab-STICC), Pierre\n  De Loor (CERV, Lab-STICC)", "title": "Effects of Coupling in Human-Virtual Agent Body Interaction", "comments": "appears in Intelligent Virtual Agents, 14th International Conference,\n  IVA 2014, Boston : \\'Etats-Unis (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study of the dynamic coupling between a user and a\nvirtual character during body interaction. Coupling is directly linked with\nother dimensions, such as co-presence, engagement, and believability, and was\nmeasured in an experiment that allowed users to describe their subjective\nfeelings about those dimensions of interest. The experiment was based on a\ntheatrical game involving the imitation of slow upper-body movements and the\nproposal of new movements by the user and virtual agent. The agent's behaviour\nvaried in autonomy: the agent could limit itself to imitating the user's\nmovements only, initiate new movements, or combine both behaviours. After the\ngame, each participant completed a questionnaire regarding their engagement in\nthe interaction, their subjective feeling about the co-presence of the agent,\netc. Based on four main dimensions of interest, we tested several hypotheses\nagainst our experimental results, which are discussed here.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 18:49:11 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Bevacqua", "Elisabetta", "", "CERV, Lab-STICC"], ["Igor", "Sankovic", "", "CERV,\n  Lab-STICC"], ["Ayoub", "Maatalaoui", "", "Lab-STICC"], ["N\u00e9d\u00e9lec", "A.", "", "Lab-STICC"], ["De Loor", "Pierre", "", "CERV, Lab-STICC"]]}, {"id": "1409.6678", "submitter": "Anant Bhardwaj", "authors": "Anant Bhardwaj, Dave Luciano, and Scott Klemmer", "title": "Redprint: Integrating API specific \"instant example\" and \"instant\n  documentation\" display interface in IDEs", "comments": "UIST 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software libraries for most of the modern programming languages are numerous,\nlarge and complex. Remembering the syntax and usage of APIs is a difficult task\nfor not just novices but also expert programmers. IDEs (Integrated Development\nEnvironment) provide capabilities like autocomplete and intellisense to assist\nprogrammers; however, programmers still need to visit search engines like\nGoogle to find API (Application Program Interface) documentation and samples.\nThis paper evaluates Redprint - a browser based development environment for PHP\nthat integrates API specific \"Instant Example\" and \"Instant Documentation\"\ndisplay interfaces. A comparative laboratory study shows that integrating API\nspecific \"Instant Example\" and \"Instant Documentation\" display interfaces into\na development environment significantly reduces the cost of searching and thus\nsignificantly reduces the time to develop software.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2014 17:42:31 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Bhardwaj", "Anant", ""], ["Luciano", "Dave", ""], ["Klemmer", "Scott", ""]]}, {"id": "1409.6680", "submitter": "Anant Bhardwaj", "authors": "Anant Bhardwaj, Juho Kim, Steven Dow, David Karger, Sam Madden, Rob\n  Miller, Haoqi Zhang", "title": "Attendee-Sourcing: Exploring The Design Space of Community-Informed\n  Conference Scheduling", "comments": "HCOMP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing a good conference schedule for a large multi-track conference\nneeds to take into account the preferences and constraints of organizers,\nauthors, and attendees. Creating a schedule which has fewer conflicts for\nauthors and attendees, and thematically coherent sessions is a challenging\ntask.\n  Cobi introduced an alternative approach to conference scheduling by engaging\nthe community to play an active role in the planning process. The current Cobi\npipeline consists of committee-sourcing and author-sourcing to plan a\nconference schedule. We further explore the design space of community-sourcing\nby introducing attendee-sourcing -- a process that collects input from\nconference attendees and encodes them as preferences and constraints for\ncreating sessions and schedule. For CHI 2014, a large multi-track conference in\nhuman-computer interaction with more than 3,000 attendees and 1,000 authors, we\ncollected attendees' preferences by making available all the accepted papers at\nthe conference on a paper recommendation tool we built called Confer, for a\nperiod of 45 days before announcing the conference program (sessions and\nschedule). We compare the preferences marked on Confer with the preferences\ncollected from Cobi's author-sourcing approach. We show that attendee-sourcing\ncan provide insights beyond what can be discovered by author-sourcing. For CHI\n2014, the results show value in the method and attendees' participation. It\nproduces data that provides more alternatives in scheduling and complements\ndata collected from other methods for creating coherent sessions and reducing\nconflicts.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2014 17:45:39 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Bhardwaj", "Anant", ""], ["Kim", "Juho", ""], ["Dow", "Steven", ""], ["Karger", "David", ""], ["Madden", "Sam", ""], ["Miller", "Rob", ""], ["Zhang", "Haoqi", ""]]}, {"id": "1409.7256", "submitter": "Yihui Xie", "authors": "Yihui Xie, Heike Hofmann, Xiaoyue Cheng", "title": "Reactive Programming for Interactive Graphics", "comments": "Published in at http://dx.doi.org/10.1214/14-STS477 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2014, Vol. 29, No. 2, 201-213", "doi": "10.1214/14-STS477", "report-no": "IMS-STS-STS477", "categories": "cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the big challenges of developing interactive statistical applications\nis the management of the data pipeline, which controls transformations from\ndata to plot. The user's interactions needs to be propagated through these\nmodules and reflected in the output representation at a fast pace. Each\nindividual module may be easy to develop and manage, but the dependency\nstructure can be quite challenging. The MVC (Model/View/Controller) pattern is\nan attempt to solve the problem by separating the user's interaction from the\nrepresentation of the data. In this paper we discuss the paradigm of reactive\nprogramming in the framework of the MVC architecture and show its applicability\nto interactive graphics. Under this paradigm, developers benefit from the\nseparation of user interaction from the graphical representation, which makes\nit easier for users and developers to extend interactive applications. We show\nthe central role of reactive data objects in an interactive graphics system,\nimplemented as the R package cranvas, which is freely available on GitHub and\nthe main developers include the authors of this paper.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 10:39:46 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Xie", "Yihui", ""], ["Hofmann", "Heike", ""], ["Cheng", "Xiaoyue", ""]]}, {"id": "1409.7489", "submitter": "Jisun An", "authors": "Jisun An, Daniele Quercia, Jon Crowcroft", "title": "Recommending Investors for Crowdfunding Projects", "comments": "Published in Proc. of WWW 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.HC physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To bring their innovative ideas to market, those embarking in new ventures\nhave to raise money, and, to do so, they have often resorted to banks and\nventure capitalists. Nowadays, they have an additional option: that of\ncrowdfunding. The name refers to the idea that funds come from a network of\npeople on the Internet who are passionate about supporting others' projects.\nOne of the most popular crowdfunding sites is Kickstarter. In it, creators post\ndescriptions of their projects and advertise them on social media sites (mainly\nTwitter), while investors look for projects to support. The most common reason\nfor project failure is the inability of founders to connect with a sufficient\nnumber of investors, and that is mainly because hitherto there has not been any\nautomatic way of matching creators and investors. We thus set out to propose\ndifferent ways of recommending investors found on Twitter for specific\nKickstarter projects. We do so by conducting hypothesis-driven analyses of\npledging behavior and translate the corresponding findings into different\nrecommendation strategies. The best strategy achieves, on average, 84% of\naccuracy in predicting a list of potential investors' Twitter accounts for any\ngiven project. Our findings also produced key insights about the whys and\nwherefores of investors deciding to support innovative efforts.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 07:57:28 GMT"}, {"version": "v2", "created": "Sun, 12 Oct 2014 11:23:36 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["An", "Jisun", ""], ["Quercia", "Daniele", ""], ["Crowcroft", "Jon", ""]]}, {"id": "1409.7591", "submitter": "Arun Maiya", "authors": "Arun S. Maiya and Robert M. Rolfe", "title": "Topic Similarity Networks: Visual Analytics for Large Document Sets", "comments": "9 pages; 2014 IEEE International Conference on Big Data (IEEE BigData\n  2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate ways in which to improve the interpretability of LDA topic\nmodels by better analyzing and visualizing their outputs. We focus on examining\nwhat we refer to as topic similarity networks: graphs in which nodes represent\nlatent topics in text collections and links represent similarity among topics.\nWe describe efficient and effective approaches to both building and labeling\nsuch networks. Visualizations of topic models based on these networks are shown\nto be a powerful means of exploring, characterizing, and summarizing large\ncollections of unstructured text documents. They help to \"tease out\"\nnon-obvious connections among different sets of documents and provide insights\ninto how topics form larger themes. We demonstrate the efficacy and\npracticality of these approaches through two case studies: 1) NSF grants for\nbasic research spanning a 14 year period and 2) the entire English portion of\nWikipedia.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 15:11:57 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["Maiya", "Arun S.", ""], ["Rolfe", "Robert M.", ""]]}, {"id": "1409.7724", "submitter": "Vijay Gadepally", "authors": "Zachary Weber and Vijay Gadepally", "title": "Using 3D Printing to Visualize Social Media Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data volume continues to grow at unprecedented rates. One of the key\nfeatures that makes big data valuable is the promise to find unknown patterns\nor correlations that may be able to improve the quality of processes or\nsystems. Unfortunately, with the exponential growth in data, users often have\ndifficulty in visualizing the often-unstructured, non-homogeneous data coming\nfrom a variety of sources. The recent growth in popularity of 3D printing has\nushered in a revolutionary way to interact with big data. Using a 3D printed\nmockup up a physical or notional environment, one can display data on the\nmockup to show real-time data patterns. In this poster and demonstration, we\ndescribe the process of 3D printing and demonstrate an application of\ndisplaying Twitter data on a 3D mockup of the Massachusetts Institute of\nTechnology (MIT) campus, known as LuminoCity.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2014 19:17:11 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Weber", "Zachary", ""], ["Gadepally", "Vijay", ""]]}, {"id": "1409.8280", "submitter": "Didier Fass", "authors": "Didier Fass (LORIA)", "title": "Reclaiming human machine nature", "comments": "Published in HCI International 2014, Heraklion : Greece (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending and modifying his domain of life by artifact production is one of\nthe main characteristics of humankind. From the first hominid, who used a wood\nstick or a stone for extending his upper limbs and augmenting his gesture\nstrength, to current systems engineers who used technologies for augmenting\nhuman cognition, perception and action, extending human body capabilities\nremains a big issue. From more than fifty years cybernetics, computer and\ncognitive sciences have imposed only one reductionist model of human machine\nsystems: cognitive systems. Inspired by philosophy, behaviorist psychology and\nthe information treatment metaphor, the cognitive system paradigm requires a\nfunction view and a functional analysis in human systems design process.\nAccording that design approach, human have been reduced to his metaphysical and\nfunctional properties in a new dualism. Human body requirements have been left\nto physical ergonomics or \"physiology\". With multidisciplinary convergence, the\nissues of \"human-machine\" systems and \"human artifacts\" evolve. The loss of\nbiological and social boundaries between human organisms and interactive and\ninformational physical artifact questions the current engineering methods and\nergonomic design of cognitive systems. New developpment of human machine\nsystems for intensive care, human space activities or bio-engineering sytems\nrequires grounding human systems design on a renewed epistemological framework\nfor future human systems model and evidence based \"bio-engineering\". In that\ncontext, reclaiming human factors, augmented human and human machine nature is\na necessity\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2014 18:26:41 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Fass", "Didier", "", "LORIA"]]}]