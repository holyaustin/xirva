[{"id": "1304.0357", "submitter": "Arkadiusz Stopczynski Mr.", "authors": "Arkadiusz Stopczynski, Carsten Stahlhut, Jakob Eg Larsen, Michael Kai\n  Petersen, and Lars Kai Hansen", "title": "The Smartphone Brain Scanner: A Mobile Real-time Neuroimaging System", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0086733", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining low cost wireless EEG sensors with smartphones offers novel\nopportunities for mobile brain imaging in an everyday context. We present a\nframework for building multi-platform, portable EEG applications with real-time\n3D source reconstruction. The system - Smartphone Brain Scanner - combines an\noff-the-shelf neuroheadset or EEG cap with a smartphone or tablet, and as such\nrepresents the first fully mobile system for real-time 3D EEG imaging. We\ndiscuss the benefits and challenges of a fully portable system, including\ntechnical limitations as well as real-time reconstruction of 3D images of brain\nactivity. We present examples of the brain activity captured in a simple\nexperiment involving imagined finger tapping, showing that the acquired signal\nin a relevant brain region is similar to that obtained with standard EEG lab\nequipment. Although the quality of the signal in a mobile solution using a\noff-the-shelf consumer neuroheadset is lower compared to that obtained using\nhigh density standard EEG equipment, we propose that mobile application\ndevelopment may offset the disadvantages and provide completely new\nopportunities for neuroimaging in natural settings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2013 13:51:52 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Stopczynski", "Arkadiusz", ""], ["Stahlhut", "Carsten", ""], ["Larsen", "Jakob Eg", ""], ["Petersen", "Michael Kai", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1304.0954", "submitter": "Marko Horvat", "authors": "Marko Horvat, Anton Grbin, Gordan Gledec", "title": "Labeling and Retrieval of Emotionally-Annotated Images using WordNet", "comments": "16 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1302.2223", "journal-ref": "International Journal of Knowledge-Based and Intelligent\n  Engineering Systems, Vol. 17, No. 2, pp. 157-166, 2013", "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repositories of images with semantic and emotion content descriptions are\nvaluable tools in many areas such as Affective Computing and Human-Computer\nInteraction, but they are also important in the development of multimodal\nsearchable online databases. Ever growing number of image documents available\non the Internet continuously motivates research of better annotation models and\nmore efficient retrieval methods which use mash-up of available data on\nsemantics, scenes, objects, events, context and emotion. Formal knowledge\nrepresentation of such high-level semantics requires rich, explicit, human but\nalso machine-processable information. To achieve these goals we present an\nonline ontology-based image annotation tool WNtags and demonstrate its\nusefulness in knowledge representation and image retrieval using the\nInternational Affective Picture System database. The WNtags uses WordNet as\nimage tagging glossary but considers Suggested Upper Merged Ontology as the\npreferred upper labeling formalism. The retrieval is performed using node\ndistance metrics to establish semantic relatedness between a query and the\ncollaboratively weighted tags describing high-level image semantics, after\nwhich the result is ranked according to the derived importance. We also\nelaborate plans to improve the WNtags to create a collaborative Web-based\nmultimedia repository for research in human emotion and attention.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2013 13:58:56 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2014 23:27:00 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Horvat", "Marko", ""], ["Grbin", "Anton", ""], ["Gledec", "Gordan", ""]]}, {"id": "1304.1332", "submitter": "Karl Voit", "authors": "Karl Voit", "title": "What really happened on September 15th 2008? Getting The Most from Your\n  Personal Information with Memacs", "comments": "6 pages, 3 figures, 21 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Combining and summarizing meta-data from various kinds of data sources is one\npossible solution to the data fragmentation we are suffering from. Multiple\nprojects have addressed this issue already. This paper presents a new approach\nnamed Memacs. It automatically generates a detailed linked diary of our digital\nartifacts scattered across local files of multiple formats as well as data\nsilos of the internet. Being elegantly simple and open, Memacs uses already\nexisting visualization features of GNU Emacs and Org-mode to provide a\npromising platform for life-logging, Quantified Self movement, and people\nlooking for advanced Personal Information Management (PIM) in general.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 11:43:09 GMT"}], "update_date": "2013-04-05", "authors_parsed": [["Voit", "Karl", ""]]}, {"id": "1304.1428", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson", "title": "Information and Computation", "comments": "9 pages, 3 figures. Draft of a chapter to be published in Michelucci,\n  P. (Ed.) Handbook of Human Computation, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.HC cs.SI math.IT nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, concepts related to information and computation are reviewed\nin the context of human computation. A brief introduction to information theory\nand different types of computation is given. Two examples of human computation\nsystems, online social networks and Wikipedia, are used to illustrate how these\ncan be described and compared in terms of information and computation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2013 16:53:46 GMT"}, {"version": "v2", "created": "Fri, 24 May 2013 16:44:34 GMT"}], "update_date": "2013-05-27", "authors_parsed": [["Gershenson", "Carlos", ""]]}, {"id": "1304.1636", "submitter": "Bernhard Haslhofer", "authors": "Bernhard Haslhofer, Werner Robitza, Carl Lagoze, Francois Guimbretiere", "title": "Semantic Tagging on Historical Maps", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tags assigned by users to shared content can be ambiguous. As a possible\nsolution, we propose semantic tagging as a collaborative process in which a\nuser selects and associates Web resources drawn from a knowledge context. We\napplied this general technique in the specific context of online historical\nmaps and allowed users to annotate and tag them. To study the effects of\nsemantic tagging on tag production, the types and categories of obtained tags,\nand user task load, we conducted an in-lab within-subject experiment with 24\nparticipants who annotated and tagged two distinct maps. We found that the\nsemantic tagging implementation does not affect these parameters, while\nproviding tagging relationships to well-defined concept definitions. Compared\nto label-based tagging, our technique also gathers positive and negative\ntagging relationships. We believe that our findings carry implications for\ndesigners who want to adopt semantic tagging in other contexts and systems on\nthe Web.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2013 08:23:44 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Haslhofer", "Bernhard", ""], ["Robitza", "Werner", ""], ["Lagoze", "Carl", ""], ["Guimbretiere", "Francois", ""]]}, {"id": "1304.2031", "submitter": "Taha Yasseri", "authors": "Taha Yasseri, Giovanni Quattrone, and Afra Mashhadi", "title": "Temporal Analysis of Activity Patterns of Editors in Collaborative\n  Mapping Project of OpenStreetMap", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SI physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years Wikis have become an attractive platform for social\nstudies of the human behaviour. Containing millions records of edits across the\nglobe, collaborative systems such as Wikipedia have allowed researchers to gain\na better understanding of editors participation and their activity patterns.\nHowever, contributions made to Geo-wikis_wiki-based collaborative mapping\nprojects_ differ from systems such as Wikipedia in a fundamental way due to\nspatial dimension of the content that limits the contributors to a set of those\nwho posses local knowledge about a specific area and therefore cross-platform\nstudies and comparisons are required to build a comprehensive image of online\nopen collaboration phenomena. In this work, we study the temporal behavioural\npattern of OpenStreetMap editors, a successful example of geo-wiki, for two\nEuropean capital cities. We categorise different type of temporal patterns and\nreport on the historical trend within a period of 7 years of the project age.\nWe also draw a comparison with the previously observed editing activity\npatterns of Wikipedia.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2013 17:43:26 GMT"}], "update_date": "2013-04-09", "authors_parsed": [["Yasseri", "Taha", ""], ["Quattrone", "Giovanni", ""], ["Mashhadi", "Afra", ""]]}, {"id": "1304.2401", "submitter": "Elizabeth Murnane", "authors": "Elizabeth L. Murnane, Bernhard Haslhofer, Carl Lagoze", "title": "RESLVE: Leveraging User Interest to Improve Entity Disambiguation on\n  Short Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the Named Entity Disambiguation (NED) problem for short,\nuser-generated texts on the social Web. In such settings, the lack of\nlinguistic features and sparse lexical context result in a high degree of\nambiguity and sharp performance drops of nearly 50% in the accuracy of\nconventional NED systems. We handle these challenges by developing a model of\nuser-interest with respect to a personal knowledge context; and Wikipedia, a\nparticularly well-established and reliable knowledge base, is used to\ninstantiate the procedure. We conduct systematic evaluations using individuals'\nposts from Twitter, YouTube, and Flickr and demonstrate that our novel\ntechnique is able to achieve substantial performance gains beyond\nstate-of-the-art NED methods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2013 20:00:20 GMT"}], "update_date": "2013-04-10", "authors_parsed": [["Murnane", "Elizabeth L.", ""], ["Haslhofer", "Bernhard", ""], ["Lagoze", "Carl", ""]]}, {"id": "1304.2610", "submitter": "Abdelhakim Herrouz", "authors": "Abdelhakim Herrouz, Chabane Khentout and Mahieddine Djoudi", "title": "Overview of Visualization Tools for Web Browser History Data", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol.9,\n  Issue 6, No3, November 2012, pp. 92-98, 2012", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the Web has become one of the most widespread platforms for\ninformation change and retrieval. As it becomes easier to publish documents, as\nthe number of users, and thus publishers, increases and as the number of\ndocuments grows, searching for information is turning into a cumbersome and\ntime-consuming operation. Because of the loose interconnection between\ndocuments, people have difficulty remembering where they have been and\nreturning to previously visited pages. Navigation through the web faces\nproblems of locating oneself with respect to space and time. The idea of\ngraphical assistance navigation is to help users to find their paths in\nhyperspace by adapting the style of link presentation to the goals, knowledge\nand other characteristics of an individual user. We first introduce the\nconcepts related to web navigation; we then present an overview of different\ngraphical navigation tools and techniques. We conclude by presenting a\ncomparative table of these tools based on some pertinent criteria.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 04:52:28 GMT"}], "update_date": "2013-07-04", "authors_parsed": [["Herrouz", "Abdelhakim", ""], ["Khentout", "Chabane", ""], ["Djoudi", "Mahieddine", ""]]}, {"id": "1304.3940", "submitter": "Antonio Lieto", "authors": "Antonio Lieto and Fabiana Vernero", "title": "Unveiling the link between logical fallacies and web persuasion", "comments": "6 pages, 3 figures, in proceedings of the WebSci'13 Conference,\n  Paris, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade Human-Computer Interaction (HCI) has started to focus\nattention on forms of persuasive interaction where computer technologies have\nthe goal of changing users behavior and attitudes according to a predefined\ndirection. In this work, we hypothesize a strong connection between logical\nfallacies (forms of reasoning which are logically invalid but cognitively\neffective) and some common persuasion strategies adopted within web\ntechnologies. With the aim of empirically evaluating our hypothesis, we carried\nout a pilot study on a sample of 150 e-commerce websites.\n", "versions": [{"version": "v1", "created": "Sun, 14 Apr 2013 19:48:07 GMT"}, {"version": "v2", "created": "Thu, 9 May 2013 10:48:55 GMT"}], "update_date": "2013-05-10", "authors_parsed": [["Lieto", "Antonio", ""], ["Vernero", "Fabiana", ""]]}, {"id": "1304.4652", "submitter": "Ankit Chaudhary", "authors": "Ankit Chaudhary, Jagdish L. Raheja", "title": "A Health Monitoring System for Elder and Sick Persons", "comments": null, "journal-ref": "International Journal of Computer Theory and Engineering, Vol. 5,\n  No. 3, June 2013", "doi": "10.7763/IJCTE.2013.V5.723", "report-no": null, "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses a vision based health monitoring system which would be\nvery easy in use and deployment. Elder and sick people who are not able to talk\nor walk they are dependent on other human beings for their daily needs and need\ncontinuous monitoring. The developed system provides facility to the sick or\nelder person to describe his or her need to their caretaker in lingual\ndescription by showing particular hand gesture with the developed system. This\nsystem uses fingertip detection technique for gesture extraction and artificial\nneural network for gesture classification and recognition. The system is able\nto work in different light conditions and can be connected to different devices\nto announce users need on a distant location.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 00:33:21 GMT"}], "update_date": "2013-04-18", "authors_parsed": [["Chaudhary", "Ankit", ""], ["Raheja", "Jagdish L.", ""]]}, {"id": "1304.4889", "submitter": "Nicholas Cheney", "authors": "Nick Cheney, Jeff Clune, Jason Yosinski, Hod Lipson", "title": "Hands-free Evolution of 3D-printable Objects via Eye Tracking", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive evolution has shown the potential to create amazing and complex\nforms in both 2-D and 3-D settings. However, the algorithm is slow and users\nquickly become fatigued. We propose that the use of eye tracking for\ninteractive evolution systems will both reduce user fatigue and improve\nevolutionary success. We describe a systematic method for testing the\nhypothesis that eye tracking driven interactive evolution will be a more\nsuccessful and easier-to-use design method than traditional interactive\nevolution methods driven by mouse clicks. We provide preliminary results that\nsupport the possibility of this proposal, and lay out future work to\ninvestigate these advantages in extensive clinical trials.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2013 17:02:28 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 00:33:42 GMT"}, {"version": "v3", "created": "Fri, 19 Apr 2013 18:11:06 GMT"}], "update_date": "2013-04-22", "authors_parsed": [["Cheney", "Nick", ""], ["Clune", "Jeff", ""], ["Yosinski", "Jason", ""], ["Lipson", "Hod", ""]]}, {"id": "1304.6499", "submitter": "Frank Nielsen", "authors": "Frank Nielsen", "title": "Logging safely in public spaces using color PINs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, we are increasingly logging on many different Internet sites to\naccess private data like emails or photos remotely stored in the clouds. This\nmakes us all the more concerned with digital identity theft and passwords being\nstolen either by key loggers or shoulder-surfing attacks. Quite surprisingly,\nthe current bottleneck of computer security when logging for authentication is\nthe User Interface (UI): How can we enter safely secret passwords when\nconcealed spy cameras or key loggers may be recording the login session?\nLogging safely requires to design a secure Human Computer Interface (HCI)\nrobust to those attacks. We describe a novel method and system based on\nentering secret ID passwords by means of associative secret UI passwords that\nprovides zero-knowledge to observers. We demonstrate the principles using a\ncolor Personal Identification Numbers (PINs) login system and describes its\nvarious extensions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 07:52:22 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Nielsen", "Frank", ""]]}, {"id": "1304.6626", "submitter": "Makarius Wenzel", "authors": "Makarius Wenzel", "title": "PIDE as front-end technology for Coq", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isabelle/PIDE is the current Prover IDE technology for Isabelle. It has been\ndeveloped in ML and Scala in the past 4-5 years for this particular proof\nassistant, but with an open mind towards other systems. PIDE is based on an\nasynchronous document model, where the prover receives edits continuously and\nupdates its internal state accordingly. The interpretation of edits and the\npolicies for proof document processing are determined by the prover. The editor\nfront-end merely takes care of visual rendering of formal document content.\n  Here we report on an experiment to connect Coq to the PIDE infrastructure of\nIsabelle. This requires to re-implement the core PIDE protocol layer of\nIsabelle/ML in OCaml. The payload for semantic processing of proof document\ncontent is restricted to lexical analysis in the sense of existing CoqIde\nfunctionality. This is sufficient as proof-of-concept for PIDE connectivity.\nActual proof processing is then a matter of improving Coq towards timeless and\nstateless proof processing, independently of PIDE technicalities. The\nimplementation worked out smoothly and required minimal changes to the refined\nPIDE architecture of Isabelle2013.\n  This experiment substantiates PIDE as general approach to prover interaction.\nIt illustrates how other provers of the greater ITP family can participate by\nfollowing similar reforms of the classic TTY loop as was done for Isabelle in\nthe past few years.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2013 15:21:29 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Wenzel", "Makarius", ""]]}, {"id": "1304.7819", "submitter": "Michael Adrir Scott", "authors": "Michael 'Adrir' Scott", "title": "Vocalnayno: Designing a Game-Based Intervention to Support Reading\n  Development in Primary Schools", "comments": "Presented at the 6th European Conference on Games-Based Learning, Oct\n  4-5, 2012, Cork, Ireland", "journal-ref": "Proceedings of the 6th European Conference on Games-Based\n  Learning. ACPI: Reading, UK. 654--657", "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encouraging children to read frequently and helping them to develop their\nreading skills as effectively as possible can be a challenge for some primary\nschools. This research questions whether the use of a game-based intervention\ncan integrate into the existing teaching culture to aid volunteer teaching\nassistants in achieving a more significant impact on pupil reading development.\nA prototype based on the initial process of requirements gathering is presented\nusing Multimedia Fusion Developer 2. The design incorporates a game-like\nexercise where a foam volcano character releases bubbles containing letters and\nwords. Pupils must read these aloud in order to burst them open, which is\nrecorded as a metric of reading ability.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2013 23:58:35 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Scott", "Michael 'Adrir'", ""]]}, {"id": "1304.7856", "submitter": "EPTCS", "authors": "Caleb Eggensperger", "title": "Proof Pad: A New Development Environment for ACL2", "comments": "In Proceedings ACL2 2013, arXiv:1304.7123", "journal-ref": "EPTCS 114, 2013, pp. 13-28", "doi": "10.4204/EPTCS.114.2", "report-no": null, "categories": "cs.SE cs.HC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most software development projects rely on Integrated Development\nEnvironments (IDEs) based on the desktop paradigm, with an interactive,\nmouse-driven user interface. The standard installation of ACL2, on the other\nhand, is designed to work closely with Emacs. ACL2 experts, on the whole, like\nthis mode of operation, but students and other new programmers who have learned\nto program with desktop IDEs often react negatively to the process of adapting\nto an unfamiliar form of interaction.\n  This paper discusses Proof Pad, a new IDE for ACL2. Proof Pad is not the only\nattempt to provide ACL2 IDEs catering to students and beginning programmers.\nThe ACL2 Sedan and DrACuLa systems arose from similar motivations. Proof Pad\nbuilds on the work of those systems, while also taking into account the unique\nworkflow of the ACL2 theorem proving system.\n  The design of Proof Pad incorporated user feedback from the outset, and that\nprocess continued through all stages of development. Feedback took the form of\ndirect observation of users interacting with the IDE as well as questionnaires\ncompleted by users of Proof Pad and other ACL2 IDEs. The result is a\nstreamlined interface and fast, responsive system that supports using ACL2 as a\nprogramming language and a theorem proving system. Proof Pad also provides a\nproperty-based testing environment with random data generation and automated\ninterpretation of properties as ACL2 theorem definitions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2013 04:14:06 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Eggensperger", "Caleb", ""]]}, {"id": "1304.8013", "submitter": "Kamlesh Sharma", "authors": "Kamlesh Sharma, T. Suryakanthi, T. V. Prasad", "title": "Exploration of Speech enabled System for English", "comments": "9 pages, Proc. of the International Conference on System Modeling and\n  Advancement in Research Trends (SMART), Teerthankar Mahaveer University,\n  Moradabad, UP, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents exploration of speech enable operating systems, software,\nand applications. It begins with a description of how such systems work, and\nthe level of accuracy that can be expected. It explains the applications of\nspeech recognition technology in different areas education, medical, mobile\ncomputing, railway reservation, dictation, and web browsing. A brief comparison\nof the operating systems supported for voice, speech recognition software or\ntool. It gives the brief introduction about the potential of voice/speech\nrecognition software. It explains the feature of different speech enable\nOperating system and speech recognition software. Windows speech recognition\nhave many innovative features for Windows operating system and efficiently\nassist the computer to control, dictate, navigate, selecting the words, sending\nemails and correcting the words or sentences. It also explains the benefits and\nissue related to speech technology. In last era speech recognition technology\ngrew tremendously. There are large number of companies who are working in these\narea and developing software for the people who are not able to control the\nsystem through keyboard or mouse such as physically impaired and senior\ncitizens. This paper gives a brief introduction of speech enabled OS and speech\nrecognition software.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2013 10:19:11 GMT"}], "update_date": "2013-05-01", "authors_parsed": [["Sharma", "Kamlesh", ""], ["Suryakanthi", "T.", ""], ["Prasad", "T. V.", ""]]}]