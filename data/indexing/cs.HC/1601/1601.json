[{"id": "1601.00481", "submitter": "Eduardo Graells-Garrido", "authors": "Eduardo Graells-Garrido, Mounia Lalmas, Ricardo Baeza-Yates", "title": "Data Portraits and Intermediary Topics: Encouraging Exploration of\n  Politically Diverse Profiles", "comments": "12 pages, 7 figures. To be presented at ACM Intelligent User\n  Interfaces 2016", "journal-ref": null, "doi": "10.1145/2856767.2856776", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In micro-blogging platforms, people connect and interact with others.\nHowever, due to cognitive biases, they tend to interact with like-minded people\nand read agreeable information only. Many efforts to make people connect with\nthose who think differently have not worked well. In this paper, we\nhypothesize, first, that previous approaches have not worked because they have\nbeen direct -- they have tried to explicitly connect people with those having\nopposing views on sensitive issues. Second, that neither recommendation or\npresentation of information by themselves are enough to encourage behavioral\nchange. We propose a platform that mixes a recommender algorithm and a\nvisualization-based user interface to explore recommendations. It recommends\npolitically diverse profiles in terms of distance of latent topics, and\ndisplays those recommendations in a visual representation of each user's\npersonal content. We performed an \"in the wild\" evaluation of this platform,\nand found that people explored more recommendations when using a biased\nalgorithm instead of ours. In line with our hypothesis, we also found that the\nmixture of our recommender algorithm and our user interface, allowed\npolitically interested users to exhibit an unbiased exploration of the\nrecommended profiles. Finally, our results contribute insights in two aspects:\nfirst, which individual differences are important when designing platforms\naimed at behavioral change; and second, which algorithms and user interfaces\nshould be mixed to help users avoid cognitive mechanisms that lead to biased\nbehavior.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 12:41:50 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Graells-Garrido", "Eduardo", ""], ["Lalmas", "Mounia", ""], ["Baeza-Yates", "Ricardo", ""]]}, {"id": "1601.01092", "submitter": "Joy Bose", "authors": "Joy Bose, Amit Singhai, Anish Patankar, Ankit Kumar", "title": "Attention Sensitive Web Browsing", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a number of cheap commercial dry EEG kits available today, it is\npossible to look at user attention driven scenarios for interaction with the\nweb browser. Using EEG to determine the user's attention level is preferable to\nusing methods such as gaze tracking or time spent on the webpage. In this paper\nwe use the attention level in three different ways. First, as a control\nmechanism, to control user interface elements such as menus or buttons. Second,\nto make the web browser responsive to the current attention level. Third, as a\nmeans for the web developer to control the user experience based on the level\nof attention paid by the user, thus creating attention sensitive websites. We\npresent implementation details for each of these, using the NeuroSky MindWave\nsensor. We also explore issues in the system, and possibility of an EEG based\nweb standard.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 06:34:21 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Bose", "Joy", ""], ["Singhai", "Amit", ""], ["Patankar", "Anish", ""], ["Kumar", "Ankit", ""]]}, {"id": "1601.01497", "submitter": "Anna Yankovskaya", "authors": "Anna Yankovskaya and Artem Yamshanov", "title": "Family of 2-simplex cognitive tools and their application for\n  decision-making and its justifications", "comments": "14 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urgency of application and development of cognitive graphic tools for usage\nin intelligent systems of data analysis, decision making and its justifications\nis given. Cognitive graphic tool \"2-simplex prism\" and examples of its usage\nare presented. Specificity of program realization of cognitive graphics tools\ninvariant to problem areas is described. Most significant results are given and\ndiscussed. Future investigations are connected with usage of new approach to\nrendering, cross-platform realization, cognitive features improving and\nexpanding of n-simplex family.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 11:52:47 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Yankovskaya", "Anna", ""], ["Yamshanov", "Artem", ""]]}, {"id": "1601.01645", "submitter": "Luis Valente", "authors": "Luis Valente (1), Esteban Clua (1), Alexandre Ribeiro Silva (2), Bruno\n  Feij\\'o (3) ((1) Universidade Federal Fluminense, (2) Instituto Federal do\n  Tri\\^angulo Mineiro, (3) PUC-Rio)", "title": "Live-action Virtual Reality Games", "comments": "10 pages, technical report published at \"Monografias em Ci\\^encia da\n  Computa\\c{c}\\~ao, PUC-Rio\" (ISSN 0103-9741), MCC03/15, July 2015", "journal-ref": null, "doi": null, "report-no": "MCC03/15", "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the concept of \"live-action virtual reality games\" as a\nnew genre of digital games based on an innovative combination of live-action,\nmixed-reality, context-awareness, and interaction paradigms that comprise\ntangible objects, context-aware input devices, and embedded/embodied\ninteractions. Live-action virtual reality games are \"live-action games\" because\na player physically acts out (using his/her real body and senses) his/her\n\"avatar\" (his/her virtual representation) in the game stage, which is the\nmixed-reality environment where the game happens. The game stage is a kind of\n\"augmented virtuality\"; a mixed-reality where the virtual world is augmented\nwith real-world information. In live-action virtual reality games, players wear\nHMD devices and see a virtual world that is constructed using the physical\nworld architecture as the basic geometry and context information. Physical\nobjects that reside in the physical world are also mapped to virtual elements.\nLive-action virtual reality games keeps the virtual and real-worlds\nsuperimposed, requiring players to physically move in the environment and to\nuse different interaction paradigms (such as tangible and embodied interaction)\nto complete game activities. This setup enables the players to touch physical\narchitectural elements (such as walls) and other objects, \"feeling\" the game\nstage. Players have free movement and may interact with physical objects placed\nin the game stage, implicitly and explicitly. Live-action virtual reality games\ndiffer from similar game concepts because they sense and use contextual\ninformation to create unpredictable game experiences, giving rise to emergent\ngameplay.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 19:30:37 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Valente", "Luis", ""], ["Clua", "Esteban", ""], ["Silva", "Alexandre Ribeiro", ""], ["Feij\u00f3", "Bruno", ""]]}, {"id": "1601.01747", "submitter": "Vineet Pandey", "authors": "Tianyin Xu, Vineet Pandey, and Scott Klemmer", "title": "An HCI View of Configuration Problems", "comments": "9 pages of exploratory research on understanding system configuration\n  problems using Human-Computer Interaction principles", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, configuration problems have drawn tremendous attention\nbecause of their increasing prevalence and their big impact on system\navailability. We believe that many of these problems are attributable to\ntoday's configuration interfaces that have not evolved to accommodate the\nenormous shift of the system administrator group. Plain text files, as the de\nfacto configuration interfaces, assume administrators' understanding of the\nsystem under configuration. They ask administrators to directly edit the\ncorresponding entries with little guidance or assistance. However, this\nassumption no longer holds for todays administrator group which has expanded\ngreatly to include non- and semi-professional administrators. In this paper, we\nprovide an HCI view of today's configuration problems, and articulate system\nconfiguration as a new HCI problem. Moreover, we present the top obstacles to\ncorrectly and efficiently configuring software systems, and most importantly\ntheir implications on the design and implementation of new-generation\nconfiguration interfaces.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 02:07:47 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Xu", "Tianyin", ""], ["Pandey", "Vineet", ""], ["Klemmer", "Scott", ""]]}, {"id": "1601.01815", "submitter": "Przemys{\\l}aw Kucharski", "authors": "Przemys{\\l}aw Kucharski", "title": "Design and implementation of a user interface for a multi-device\n  spatially-aware mobile system", "comments": "PhD thesis, Lodz University of Technology, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aim of this thesis was the design and development of an interactive\nsystem enhancing collaborative sensemaking. The system design was based on\nrelated work research and preliminary user study. The system is based on\nmultiple spatially-aware mobile devices. The spatial awareness is established\nwith a motion tracking system. The information about position of tablets is\nreceived by a server. The server communicates with the devices and manages the\ncontent of each device. The implemented system supports managing the elements\nof information across the devices basing on their relative spatial arrangement.\nThe evaluation of the system was done by a user study.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 10:13:55 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Kucharski", "Przemys\u0142aw", ""]]}, {"id": "1601.02071", "submitter": "Eduardo Graells-Garrido", "authors": "Eduardo Graells-Garrido, Mounia Lalmas, Ricardo Baeza-Yates", "title": "Sentiment Visualisation Widgets for Exploratory Search", "comments": "Presented at the Social Personalization Workshop held jointly with\n  ACM Hypertext 2014. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the usage of \\emph{visualisation widgets} for exploratory\nsearch with \\emph{sentiment} as a facet. Starting from specific design goals\nfor depiction of ambivalence in sentiment, two visualization widgets were\nimplemented: \\emph{scatter plot} and \\emph{parallel coordinates}. Those widgets\nwere evaluated against a text baseline in a small-scale usability study with\nexploratory tasks using Wikipedia as dataset. The study results indicate that\nusers spend more time browsing with scatter plots in a positive way. A post-hoc\nanalysis of individual differences in behavior revealed that when considering\ntwo types of users, \\emph{explorers} and \\emph{achievers}, engagement with\nscatter plots is positive and significantly greater \\textit{when users are\nexplorers}. We discuss the implications of these findings for sentiment-based\nexploratory search and personalised user interfaces.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jan 2016 03:48:07 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Graells-Garrido", "Eduardo", ""], ["Lalmas", "Mounia", ""], ["Baeza-Yates", "Ricardo", ""]]}, {"id": "1601.02197", "submitter": "Wei-Long Zheng", "authors": "Wei-Long Zheng, Jia-Yi Zhu, Bao-Liang Lu", "title": "Identifying Stable Patterns over Time for Emotion Recognition from EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate stable patterns of electroencephalogram (EEG)\nover time for emotion recognition using a machine learning approach. Up to now,\nvarious findings of activated patterns associated with different emotions have\nbeen reported. However, their stability over time has not been fully\ninvestigated yet. In this paper, we focus on identifying EEG stability in\nemotion recognition. To validate the efficiency of the machine learning\nalgorithms used in this study, we systematically evaluate the performance of\nvarious popular feature extraction, feature selection, feature smoothing and\npattern classification methods with the DEAP dataset and a newly developed\ndataset for this study. The experimental results indicate that stable patterns\nexhibit consistency across sessions; the lateral temporal areas activate more\nfor positive emotion than negative one in beta and gamma bands; the neural\npatterns of neutral emotion have higher alpha responses at parietal and\noccipital sites; and for negative emotion, the neural patterns have significant\nhigher delta responses at parietal and occipital sites and higher gamma\nresponses at prefrontal sites. The performance of our emotion recognition\nsystem shows that the neural patterns are relatively stable within and between\nsessions.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2016 10:43:24 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Zheng", "Wei-Long", ""], ["Zhu", "Jia-Yi", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "1601.02433", "submitter": "Lavdim Halilaj", "authors": "Lavdim Halilaj, Irl\\'an Grangel-Gonz\\'alez, G\\\"okhan Coskun and\n  S\\\"oren Auer", "title": "Git4Voc: Git-based Versioning for Collaborative Vocabulary Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative vocabulary development in the context of data integration is\nthe process of finding consensus between the experts of the different systems\nand domains. The complexity of this process is increased with the number of\ninvolved people, the variety of the systems to be integrated and the dynamics\nof their domain. In this paper we advocate that the realization of a powerful\nversion control system is the heart of the problem. Driven by this idea and the\nsuccess of Git in the context of software development, we investigate the\napplicability of Git for collaborative vocabulary development. Even though\nvocabulary development and software development have much more similarities\nthan differences there are still important differences. These need to be\nconsidered within the development of a successful versioning and collaboration\nsystem for vocabulary development. Therefore, this paper starts by presenting\nthe challenges we were faced with during the creation of vocabularies\ncollaboratively and discusses its distinction to software development. Based on\nthese insights we propose Git4Voc which comprises guidelines how Git can be\nadopted to vocabulary development. Finally, we demonstrate how Git hooks can be\nimplemented to go beyond the plain functionality of Git by realizing\nvocabulary-specific features like syntactic validation and semantic diffs.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 13:11:51 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Halilaj", "Lavdim", ""], ["Grangel-Gonz\u00e1lez", "Irl\u00e1n", ""], ["Coskun", "G\u00f6khan", ""], ["Auer", "S\u00f6ren", ""]]}, {"id": "1601.02543", "submitter": "Sunil Kumar Kopparapu Dr", "authors": "Vinod Kumar Pandey, Sunil Kumar Kopparapu", "title": "Evaluating the Performance of a Speech Recognition based System", "comments": "7 pages, 2 figure, ACC 2011", "journal-ref": "ACC (3) 2011: 230-238", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech based solutions have taken center stage with growth in the services\nindustry where there is a need to cater to a very large number of people from\nall strata of the society. While natural language speech interfaces are the\ntalk in the research community, yet in practice, menu based speech solutions\nthrive. Typically in a menu based speech solution the user is required to\nrespond by speaking from a closed set of words when prompted by the system. A\nsequence of human speech response to the IVR prompts results in the completion\nof a transaction. A transaction is deemed successful if the speech solution can\ncorrectly recognize all the spoken utterances of the user whenever prompted by\nthe system. The usual mechanism to evaluate the performance of a speech\nsolution is to do an extensive test of the system by putting it to actual\npeople use and then evaluating the performance by analyzing the logs for\nsuccessful transactions. This kind of evaluation could lead to dissatisfied\ntest users especially if the performance of the system were to result in a poor\ntransaction completion rate. To negate this the Wizard of Oz approach is\nadopted during evaluation of a speech system. Overall this kind of evaluations\nis an expensive proposition both in terms of time and cost. In this paper, we\npropose a method to evaluate the performance of a speech solution without\nactually putting it to people use. We first describe the methodology and then\nshow experimentally that this can be used to identify the performance\nbottlenecks of the speech solution even before the system is actually used thus\nsaving evaluation time and expenses.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 18:01:56 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Pandey", "Vinod Kumar", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "1601.02605", "submitter": "Sunil Kumar Kopparapu Dr", "authors": "Vinod K. Pandey, Arun Pande, Sunil Kumar Kopparapu", "title": "A Mobile Phone based Speech Therapist", "comments": "6 pages, 6 figures, SimPe. [2011] Remote Speech Therapist Vinod\n  Pandey, Arun Pande, Sunil Kopparapu SiMPE 2011, Stockholm, Sweden, Aug 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients with articulatory disorders often have difficulty in speaking. These\npatients need several speech therapy sessions to enable them speak normally.\nThese therapy sessions are conducted by a specialized speech therapist. The\ngoal of speech therapy is to develop good speech habits as well as to teach how\nto articulate sounds the right way. Speech therapy is critical for continuous\nimprovement to regain normal speech. Speech therapy sessions require a patient\nto travel to a hospital or a speech therapy center for extended periods of time\nregularly; this makes the process of speech therapy not only time consuming but\nalso very expensive. Additionally, there is a severe shortage of trained speech\ntherapists around the globe in general and in developing countries in\nparticular. In this paper, we propose a low cost mobile speech therapist, a\nsystem that enables speech therapy using a mobile phone which eliminates the\nneed of the patient to frequently travel to a speech therapist in a far away\nhospital. The proposed system, which is being built, enables both synchronous\nand asynchronous interaction between the speech therapist and the patient\nanytime anywhere\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 18:12:53 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Pandey", "Vinod K.", ""], ["Pande", "Arun", ""], ["Kopparapu", "Sunil Kumar", ""]]}, {"id": "1601.02644", "submitter": "Julian Steil", "authors": "Mohsen Mansouryar, Julian Steil, Yusuke Sugano, Andreas Bulling", "title": "3D Gaze Estimation from 2D Pupil Positions on Monocular Head-Mounted Eye\n  Trackers", "comments": null, "journal-ref": null, "doi": "10.1145/2857491.2857530", "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D gaze information is important for scene-centric attention analysis but\naccurate estimation and analysis of 3D gaze in real-world environments remains\nchallenging. We present a novel 3D gaze estimation method for monocular\nhead-mounted eye trackers. In contrast to previous work, our method does not\naim to infer 3D eyeball poses but directly maps 2D pupil positions to 3D gaze\ndirections in scene camera coordinate space. We first provide a detailed\ndiscussion of the 3D gaze estimation task and summarize different methods,\nincluding our own. We then evaluate the performance of different 3D gaze\nestimation approaches using both simulated and real data. Through experimental\nvalidation, we demonstrate the effectiveness of our method in reducing parallax\nerror, and we identify research challenges for the design of 3D calibration\nprocedures.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 21:11:31 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 14:27:41 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Mansouryar", "Mohsen", ""], ["Steil", "Julian", ""], ["Sugano", "Yusuke", ""], ["Bulling", "Andreas", ""]]}, {"id": "1601.02768", "submitter": "Jeremy Frey", "authors": "J\\'er\\'emy Frey (Potioc, UB), Maxime Daniel, Julien Castet, Martin\n  Hachet (INRIA, Potioc), Fabien Lotte (Potioc, INRIA)", "title": "Framework for Electroencephalography-based Evaluation of User Experience", "comments": "in ACM. CHI '16 - SIGCHI Conference on Human Factors in Computing\n  System, May 2016, San Jose, United States", "journal-ref": null, "doi": "10.1145/2858036.2858525", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring brain activity with electroencephalography (EEG) is mature enough\nto assess mental states. Combined with existing methods, such tool can be used\nto strengthen the understanding of user experience. We contribute a set of\nmethods to estimate continuously the user's mental workload, attention and\nrecognition of interaction errors during different interaction tasks. We\nvalidate these measures on a controlled virtual environment and show how they\ncan be used to compare different interaction techniques or devices, by\ncomparing here a keyboard and a touch-based interface. Thanks to such a\nframework, EEG becomes a promising method to improve the overall usability of\ncomplex computer systems.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 08:32:26 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Frey", "J\u00e9r\u00e9my", "", "Potioc, UB"], ["Daniel", "Maxime", "", "INRIA, Potioc"], ["Castet", "Julien", "", "INRIA, Potioc"], ["Hachet", "Martin", "", "INRIA, Potioc"], ["Lotte", "Fabien", "", "Potioc, INRIA"]]}, {"id": "1601.02852", "submitter": "Tae-Hyun Oh", "authors": "Jinsoo Choi, Tae-Hyun Oh, In So Kweon", "title": "Human Attention Estimation for Natural Images: An Automatic Gaze\n  Refinement Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photo collections and its applications today attempt to reflect user\ninteractions in various forms. Moreover, photo collections aim to capture the\nusers' intention with minimum effort through applications capturing user\nintentions. Human interest regions in an image carry powerful information about\nthe user's behavior and can be used in many photo applications. Research on\nhuman visual attention has been conducted in the form of gaze tracking and\ncomputational saliency models in the computer vision community, and has shown\nconsiderable progress. This paper presents an integration between implicit gaze\nestimation and computational saliency model to effectively estimate human\nattention regions in images on the fly. Furthermore, our method estimates human\nattention via implicit calibration and incremental model updating without any\nactive participation from the user. We also present extensive analysis and\npossible applications for personal photo collections.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 13:31:38 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Choi", "Jinsoo", ""], ["Oh", "Tae-Hyun", ""], ["Kweon", "In So", ""]]}, {"id": "1601.03022", "submitter": "Xavier Navarro-Sune", "authors": "X Navarro-Sune, A.L. Hudson, F. De Vico Fallani, J. Martinerie, A.\n  Witon, P. Pouget, M. Raux, T. Similowski and M. Chavez", "title": "Riemannian geometry applied to detection of respiratory states from EEG\n  signals: the basis for a brain-ventilator interface", "comments": "14 pages, 7 figures", "journal-ref": "IEEE Transactions on Biomedical Engineering, 2016", "doi": "10.1109/TBME.2016.2592820", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During mechanical ventilation, patient-ventilator disharmony is frequently\nobserved and may result in increased breathing effort, compromising the\npatient's comfort and recovery. This circumstance requires clinical\nintervention and becomes challenging when verbal communication is difficult. In\nthis work, we propose a brain computer interface (BCI) to automatically and\nnon-invasively detect patient-ventilator disharmony from\nelectroencephalographic (EEG) signals: a brain-ventilator interface (BVI). Our\nframework exploits the cortical activation provoked by the inspiratory\ncompensation when the subject and the ventilator are desynchronized. Use of a\none-class approach and Riemannian geometry of EEG covariance matrices allows\neffective classification of respiratory states. The BVI is validated on nine\nhealthy subjects that performed different respiratory tasks that mimic a\npatient-ventilator disharmony. Classification performances, in terms of areas\nunder ROC curves, are significantly improved using EEG signals compared to\ndetection based on air flow. Reduction in the number of electrodes that can\nachieve discrimination can often be desirable (e.g. for portable BCI systems).\nBy using an iterative channel selection technique, the Common Highest Order\nRanking (CHOrRa), we find that a reduced set of electrodes (n=6) can slightly\nimprove for an intra-subject configuration, and it still provides fairly good\nperformances for a general inter-subject setting. Results support the\ndiscriminant capacity of our approach to identify anomalous respiratory states,\nby learning from a training set containing only normal respiratory epochs. The\nproposed framework opens the door to brain-ventilator interfaces for monitoring\npatient's breathing comfort and adapting ventilator parameters to patient\nrespiratory needs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 20:32:30 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 14:09:22 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Navarro-Sune", "X", ""], ["Hudson", "A. L.", ""], ["Fallani", "F. De Vico", ""], ["Martinerie", "J.", ""], ["Witon", "A.", ""], ["Pouget", "P.", ""], ["Raux", "M.", ""], ["Similowski", "T.", ""], ["Chavez", "M.", ""]]}, {"id": "1601.03192", "submitter": "Benjamin Gagl", "authors": "Benjamin Gagl", "title": "Blue hypertext is a perfect design decision: No perceptual disadvantage\n  in reading and successful highlighting of relevant information", "comments": "15 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Highlighted text in the Internet (i.e. Hypertext) is predominantly blue and\nunderlined. The percept of these hypertext characteristics were heavily\nquestioned by applied research and empirical tests resulted in inconclusive\nresults. The ability to identify blue text in foveal and parafoveal vision was\nidentified as potentially constrained by the low number of foveally centered\nblue light sensitive retinal cells. The present study investigates if foveal\nand parafoveal perceptibility of hypertext is reduced during reading. A\nsilent-sentence reading study with simultaneous eye movement recordings and the\ninvisible boundary paradigm, which allows the investigation of foveal and\nparafoveal perceptibility, separately, was realized. Target words in sentences\nwere presented in either black or blue and either underlined or normal. No\neffect of color and underlining, but a preview benefit could be detected for\nfirst pass reading measures (comparing fixation times after degraded vs. un-\ndegraded parafoveal previews). Fixation time measures that included re-reading\n(i.e., total viewing times) showed, in addition to a preview effect, a reduced\nfixation time for not highlighted (black not underlined) in contrast to\nhighlighted target words (either blue or underlined or both). Thus, the present\npattern reflects no detectable perceptual disadvantage of hyperlink stimuli but\nincreased attraction of attention resources, after first pass reading, through\nhighlighting. Blue or underlined text allows readers to easily perceive\nhypertext and at the same time readers re-visited hypertext longer as a\nconsequence of highlighting. On the basis of the present evidence blue\nhypertext can be safely recommended to web designers for future use.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 10:27:56 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Gagl", "Benjamin", ""]]}, {"id": "1601.03278", "submitter": "Longqi Yang", "authors": "Longqi Yang, Diana Freed, Alex Wu, Judy Wu, JP Pollak, Deborah Estrin", "title": "Your Activities of Daily Living (YADL): An Image-based Survey Technique\n  for Patients with Arthritis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthcare professionals use Activities of Daily Living (ADL) to characterize\na patient's functional status and to evaluate the effectiveness of treatment\nplans. ADLs are traditionally measured using standardized text-based\nquestionnaires and the only form of personalization is in the form of question\nbranching logic. Pervasive smartphone adoption makes it feasible to consider\nmore frequent patient-reporting on ADLs. However, asking generic sets of\nquestions repeatedly introduces user burden and fatigue that threatens to\ninterfere with their utility. We introduce an approach called YADL (Your\nActivities of Daily Living) which uses images of ADLs and personalization to\nimprove survey efficiency and the patient-experience. It offers several\npotential benefits: wider coverage of ADLs, improved engagement, and accurate\ncapture of individual health situations. In this paper, we discuss our system\ndesign and the wide applicability of the design process for survey tools in\nhealthcare and beyond. Interactions with with a small number of patients with\nArthritis throughout the design process have been promising and we share\ndetailed insights.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 15:27:58 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Yang", "Longqi", ""], ["Freed", "Diana", ""], ["Wu", "Alex", ""], ["Wu", "Judy", ""], ["Pollak", "JP", ""], ["Estrin", "Deborah", ""]]}, {"id": "1601.04029", "submitter": "Julian Ramos Rojas", "authors": "Julian Ramos, Zhen Li, Johana Rosas, Nikola Banovic, Jennifer Mankoff,\n  Anind Dey", "title": "Keyboard Surface Interaction: Making the keyboard into a pointing device", "comments": "8 figures, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointing devices that reside on the keyboard can reduce the overall time\nneeded to perform mixed pointing and typing tasks, since the hand of the user\ndoes not have to reach for the pointing device. However, previous\nimplementations of this kind of device have a higher movement time compared to\nthe mouse and trackpad due to large error rate, low speed and spatial\nresolution. In this paper we introduce Keyboard Surface Interaction (KSI), an\ninteraction approach that turns the surface of a keyboard into an interaction\nsurface and allows users to rest their hands on the keyboard at all times to\nminimize fatigue. We developed a proof-of-concept implementation, Fingers,\nwhich we optimized over a series of studies. Finally, we evaluated Fingers\nagainst the mouse and trackpad in a user study with 25 participants on a Fitts\nlaw test style, mixed typing and pointing task. Results showed that for users\nwith more exposure to KSI, our KSI device had better performance (reduced\nmovement and homing time) and reduced discomfort compared to the trackpad. When\ncompared to the mouse, KSI had reduced homing time and reduced discomfort, but\nincreased movement time. This interaction approach is not only a new way to\ncapitalize on the space on top of the keyboard, but also a call to innovate and\nthink beyond the touchscreen, touchpad, and mouse as our main pointing devices.\nThe results of our studies serve as a specification for future KSI devices.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 18:40:35 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Ramos", "Julian", ""], ["Li", "Zhen", ""], ["Rosas", "Johana", ""], ["Banovic", "Nikola", ""], ["Mankoff", "Jennifer", ""], ["Dey", "Anind", ""]]}, {"id": "1601.04066", "submitter": "Olanrewaju Eluyefa", "authors": "Eluyefa Olanrewaju Andrew", "title": "Human Computer Symbiosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human Computer Symbiosis is similar to Human Computer Interaction in the\nsense that it is about how humans and computer interact with each other. For\nthis interaction to be made there needs to be a symbiotic relationship between\nman and computer. Man can interact with computer in many ways, either just by\ntyping with the keyboard or surfing the web. The cyber-physical-socio space is\nan important aspect to be looked into when referring to the interaction between\nman and computer. This paper investigates various aspects related to human\ncomputer symbiosis. Alongside the aspects related to the topic, this paper\nwould also look into the limitations of Human Computer Symbiosis and evaluate\nsome previously proposed solutions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2016 01:04:23 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Andrew", "Eluyefa Olanrewaju", ""]]}, {"id": "1601.04436", "submitter": "Nancy Rodriguez", "authors": "Nancy Rodriguez (ICAR)", "title": "Development of a wheelchair simulator for children with multiple\n  disabilities", "comments": "from 3rd International Workshop on Virtual and Augmented Assistive\n  Technology (VAAT), IEEE Virtual Reality 2015, 2015, Arles, France. 2015", "journal-ref": null, "doi": "10.1109/VAAT.2015.7155405", "report-no": null, "categories": "cs.HC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual reality allows to create situations which can be experimented under\nthe control of the user, without risks, in a very flexible way. This allows to\ndevelop skills and to have confidence to work in real conditions with real\nequipment. VR is then widely used as a training and learning tool. More\nrecently, VR has also showed its potential in rehabilitation and therapy fields\nbecause it provides users with the ability of repeat their actions several\ntimes and to progress at their own pace. In this communication, we present our\nwork in the development of a wheelchair simulator designed to allow children\nwith multiple disabilities to familiarize themselves with the wheelchair.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 09:23:46 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Rodriguez", "Nancy", "", "ICAR"]]}, {"id": "1601.05483", "submitter": "Joseph Maguire", "authors": "Joseph Maguire and Karen Renaud", "title": "Alternative Authentication in the Wild", "comments": null, "journal-ref": null, "doi": "10.1109/STAST.2015.13", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alphanumeric authentication routinely fails to regulate access to resources\nwith the required stringency, primarily due to usability issues. Initial\ndeployment did not reveal the problems of passwords, deep and profound flaws\nonly emerged once passwords were deployed in the wild. The need for a\nreplacement is widely acknowledged yet despite over a decade of research into\nknowledge-based alternatives, few, if any, have been adopted by industry.\nAlternatives are unconvincing for three primary reasons. The first is that\nalternatives are rarely investigated beyond the initial proposal, with only the\nresults from a constrained lab test provided to convince adopters of their\nviability. The second is that alternatives are seldom tested realistically\nwhere the authenticator mediates access to something of value. The third is\nthat the testing rarely varies the device or context beyond that initially\ntargeted. In the modern world different devices are used across a variety of\ncontexts. What works well in one context may easily fail in another.\nConsequently, the contribution of this paper is an \"in the wild\" evaluation of\nan alternative authentication mechanism that had demonstrated promise in its\nlab evaluation. In the field test the mechanism was deployed to actual users to\nregulate access to an application in a context beyond that initially proposed.\nThe performance of the mechanism is reported and discussed. We conclude by\nreflecting on the value of field evaluations of alternative authentication\nmechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 00:58:11 GMT"}], "update_date": "2016-01-22", "authors_parsed": [["Maguire", "Joseph", ""], ["Renaud", "Karen", ""]]}, {"id": "1601.05561", "submitter": "Han Yu", "authors": "Xinjia Yu", "title": "Emotional Interaction between Artificial Companion Agents and the\n  Elderly", "comments": "This is a book draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial companion agents are defined as hardware or software entities\ndesigned to provide companionship to a person. The senior population are facing\na special demand for companionship. Artificial companion agents have been\ndemonstrated to be useful in therapy, offering emotional companionship and\nfacilitating socialization. However, there is lack of empirical studies on what\nthe artificial agents should do and how they can communicate with human beings\nbetter. To address these functional research problems, we attempt to establish\na model to guide artificial companion designers to meet the emotional needs of\nthe elderly through fulfilling absent roles in their social interactions. We\ncall this model the Role Fulfilling Model. This model aims to use role as a key\nconcept to analyse the demands from the elderly for functionalities from an\nemotional perspective in artificial companion agent designs and technologies.\nTo evaluate the effectiveness of this model, we proposed a serious game\nplatform named Happily Aging in Place. This game will help us to involve a\nlarge scale of senior users through crowdsourcing to test our model and\nhypothesis.\n  To improve the emotional communication between artificial companion agents\nand users, This book draft addresses an important but largely overlooked aspect\nof affective computing: how to enable companion agents to express mixed\nemotions with facial expressions? And furthermore, for different users, do\nindividual heterogeneity affects the perception of the same facial expressions?\nSome preliminary results about gender differences have been found. The\nperception of facial expressions between different age groups or cultural\nbackgrounds will be held in future study.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2016 09:17:44 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2016 01:59:46 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Yu", "Xinjia", ""]]}, {"id": "1601.06128", "submitter": "Rodrigo Nogueira", "authors": "Aline Bessa, Fernando de Mesentier Silva, Rodrigo Frassetto Nogueira,\n  Enrico Bertini, and Juliana Freire", "title": "RioBusData: Outlier Detection in Bus Routes of Rio de Janeiro", "comments": "In Symposium on Visualization in Data Science (VDS at IEEE VIS),\n  Chicago, Illinois, US, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Buses are the primary means of public transportation in the city of Rio de\nJaneiro, carrying around 100 million passengers every month. Recently,\nreal-time GPS coordinates of all operating public buses has been made publicly\navailable - roughly 1 million GPS entries each captured each day. In an initial\nstudy, we observed that a substantial number of buses follow trajectories that\ndo not follow the expected behavior. In this paper, we present RioBusData, a\ntool that helps users identify and explore, through different visualizations,\nthe behavior of outlier trajectories. We describe how the system automatically\ndetects these outliers using a Convolutional Neural Network (CNN) and we also\ndiscuss a series of case studies which show how RioBusData helps users better\nunderstand not only the flow and service of outlier buses but also the bus\nsystem as a whole.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 19:46:33 GMT"}], "update_date": "2016-01-25", "authors_parsed": [["Bessa", "Aline", ""], ["Silva", "Fernando de Mesentier", ""], ["Nogueira", "Rodrigo Frassetto", ""], ["Bertini", "Enrico", ""], ["Freire", "Juliana", ""]]}, {"id": "1601.06230", "submitter": "Jinghua Hou", "authors": "Jinghua Hou", "title": "Coping with Prospective Memory Failures: An Optimal Reminder System\n  Design", "comments": "This is a book draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forgetting is in common in daily life, and 50-80% everyday's forgetting is\ndue to prospective memory failures, which have significant impacts on our life.\nMore seriously, some of these memory lapses can bring fatal consequences such\nas forgetting a sleeping infant in the back seat of a car. People tend to use\nvarious techniques to improve their prospective memory performance. Setting up\na reminder is one of the most important techniques. The existing studies\nprovide evidences in support of using reminders to cope with prospective memory\nfailures. However, people are not satisfied with existing reminders because of\ntheir limitations in different aspects including reliability, optimization, and\nadaption.\n  Through analysing the functions and features of existing reminder systems,\nthis book draft summarizes their advantages and limitations. We are motivated\nto improve the performance of reminder systems. For the improvements, the\nrelevant theories and mechanisms of prospective memory from psychology must be\ncomplied with, incorporated, and applied in this new study.\n  Based on the literature review, a new reminder model is proposed, which\nincludes a novel reminder planer, a prospective memory based agent, and a\npersonalized user model. The reminder planer is responsible for determining the\noptimal reminder plan (including the optimal number of reminders, the optimal\nreminding schedule and the optimal reminding way). The prospective memory agent\nis responsible for executing the reminding processes. The personalized user\nmodel is proposed to learn from users' behaviors and preferences based on\nhuman-system interactions and is responsible for adapting the reminder plan to\nmeet users' preferences as much as possible.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 04:56:39 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Hou", "Jinghua", ""]]}, {"id": "1601.06359", "submitter": "Sayan Sarcar", "authors": "Sayan Sarcar", "title": "Usability Evaluation of Dwell-free Eye Typing Techniques", "comments": "11 Pages (with reference), accepted in IDHF 2014 conference held in\n  Kochi, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dwelling is an essential task to be performed to select keys from an\non-screen keyboard present in the eye typing interface. This selection task can\nbe performed by fixing eye gaze on a key for a prolonged time. Spending\nsufficient amount of time on each key effectively decreases the overall eye\ntyping rate. To address the problem, researchers proposed mechanisms, which\ndiminish the dwell time. We conducted a within-subject usability evaluation of\nfour dwell-free eye typing techniques. The results of first-time usability\nstudy, longitudinal study and subjective evaluation conducted with 15\nparticipants confirm the superiority of controlled eye movement based advanced\neye typing method (Adv-EyeK) than the other three techniques.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2016 08:45:10 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Sarcar", "Sayan", ""]]}, {"id": "1601.06439", "submitter": "Amandianeze Nwana", "authors": "Amandianeze O. Nwana and Tsuhan Chen", "title": "Who Ordered This?: Exploiting Implicit User Tag Order Preferences for\n  Personalized Image Tagging", "comments": null, "journal-ref": null, "doi": "10.1109/ICMEW.2016.7574753", "report-no": null, "categories": "cs.IR cs.HC cs.MM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What makes a person pick certain tags over others when tagging an image? Does\nthe order that a person presents tags for a given image follow an implicit bias\nthat is personal? Can these biases be used to improve existing automated image\ntagging systems? We show that tag ordering, which has been largely overlooked\nby the image tagging community, is an important cue in understanding user\ntagging behavior and can be used to improve auto-tagging systems. Inspired by\nthe assumption that people order their tags, we propose a new way of measuring\ntag preferences, and also propose a new personalized tagging objective function\nthat explicitly considers a user's preferred tag orderings. We also provide a\n(partially) greedy algorithm that produces good solutions to our new objective\nand under certain conditions produces an optimal solution. We validate our\nmethod on a subset of Flickr images that spans 5000 users, over 5200 tags, and\nover 90,000 images. Our experiments show that exploiting personalized tag\norders improves the average performance of state-of-art approaches both on\nper-image and per-user bases.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jan 2016 21:03:29 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Nwana", "Amandianeze O.", ""], ["Chen", "Tsuhan", ""]]}, {"id": "1601.06869", "submitter": "Zhengxiang Pan", "authors": "Zhengxiang Pan", "title": "The Roles of Familiarity Design in Active Ageing", "comments": "This is a book draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The elderly often struggle when interacting with technologies. This is\nbecause the software and hardware components of the technologies are not\nfamiliar to the elderly's mental model. This is a lack of empirical studies\nabout how the concept of familiarity can be infused into the design of\ninteractive technology systems to bridge the digital divide preventing today's\nelderly people from actively engaging with such technologies. In this paper, a\nmulti pronged approach is utilized. We investigate the Effects of Familiarity\nin Design on the Adoption of Wellness Games by the Elderly, familiarity in\nproductive ageing, familiarity in efficient collaborative crowdsourcing,\nproductive ageing through familiarity based Intelligent Personalized\nCrowdsourcing and familiarity based Agent Augmented Inter-generational\nCrowdsourcing. The results show that familiarity in design improves the\nperceived satisfaction and adoption likelihood significantly among the elderly\nusers. These results can potentially benefit intelligent interface agent design\nwhen such agents need to interact with elderly users. A Crowdsourcing\nalgorithm, CrowdAsm is developed. By using CrowdAsm we are able to dynamically\nassemble teams of workers considering the budgets, the availability of workers\nwith the required skills and their track records to complete crowdsourcing\ntasks requiring collaboration among workers with heterogeneous skills.\nTheoretical analysis has shown that CrowdAsm can achieve close to optimal\nprofit for a collaborative crowdsourcing system if workers follow the\nrecommendations.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 02:33:53 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Pan", "Zhengxiang", ""]]}, {"id": "1601.06906", "submitter": "Santiago Lombeyda", "authors": "Santiago V. Lombeyda", "title": "Distinct 3D Glyphs with Data Layering for Highly Dense Multivariate Data\n  Plots", "comments": "6 pages. 9 figures. written in 2009. originally destined as a public\n  internal CACR/Caltech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A carefully constructed scatterplot can reveal plenty about an underlying\ndata set. However, in most cases visually mining and understanding a large\nmultivariate data set requires more finesse, and greater level of interactivity\nto really grasp the full spectrum of the information being presented. We\npresent a paradigm for glyph design and use in the creation of single plots\npresenting multiple variables of information. We center our design on two key\nconcepts. The first concept is that visually it is easier to discriminate\nbetween completely distinct shapes rather than subtly different ones, specially\nwhen partially occluded. The second one is that users ingest information in\nlayers, i.e. in an order of visual relevance. Using this paradigm, we present\ncomplex data as binned into desired and relevant discrete categories. We show\nresults in the areas of high energy physics and security, displaying over 6\ndistinct data variables in each single plot, yielding a clear, highly readable,\nand effective visualization.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 07:09:45 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Lombeyda", "Santiago V.", ""]]}, {"id": "1601.07229", "submitter": "Bharathan Balaji", "authors": "Bharathan Balaji, Jason Koh, Nadir Weibel, Yuvraj Agarwal", "title": "Genie: A Longitudinal Study Comparing Physical and Software-augmented\n  Thermostats in Office Buildings", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thermostats are primary interfaces for occupants of office buildings to\nexpress their comfort preferences. However, standard thermostats are often\nineffective due to inaccessibility, lack of information, or limited\nresponsiveness, leading to occupant discomfort. Software thermostats based on\nweb or smartphone applications provide alternative interfaces to occupants with\nminimal deployment cost. However, their usage and effectiveness have not been\nstudied extensively in real settings. In this paper we present Genie, a novel\nsoftware-augmented thermostat that we deployed and studied at our university\nover a period of 21 months. Our data shows that providing wider thermal control\nto users does not lead to system abuse and that the effect on energy\nconsumption is minimal while improving comfort and energy awareness. We believe\nthat increased introduction of software thermostats in office buildings will\nhave important effects on comfort and energy consumption and we provide key\ndesign recommendations for their implementation and deployment.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 23:48:11 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Balaji", "Bharathan", ""], ["Koh", "Jason", ""], ["Weibel", "Nadir", ""], ["Agarwal", "Yuvraj", ""]]}, {"id": "1601.07250", "submitter": "Yuting Zheng", "authors": "Yuting Zheng", "title": "Living Innovation Laboratory Model Design and Implementation", "comments": "This is a book draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Living Innovation Laboratory (LIL) is an open and recyclable way for\nmultidisciplinary researchers to remote control resources and co-develop user\ncentered projects. In the past few years, there were several papers about LIL\npublished and trying to discuss and define the model and architecture of LIL.\nPeople all acknowledge about the three characteristics of LIL: user centered,\nco-creation, and context aware, which make it distinguished from test platform\nand other innovation approaches. Its existing model consists of five phases:\ninitialization, preparation, formation, development, and evaluation.\n  Goal Net is a goal-oriented methodology to formularize a progress. In this\nthesis, Goal Net is adopted to subtract a detailed and systemic methodology for\nLIL. LIL Goal Net Model breaks the five phases of LIL into more detailed steps.\nBig data, crowd sourcing, crowd funding and crowd testing take place in\nsuitable steps to realize UUI, MCC and PCA throughout the innovation process in\nLIL 2.0. It would become a guideline for any company or organization to develop\na project in the form of an LIL 2.0 project.\n  To prove the feasibility of LIL Goal Net Model, it was applied to two real\ncases. One project is a Kinect game and the other one is an Internet product.\nThey were both transformed to LIL 2.0 successfully, based on LIL goal net based\nmethodology. The two projects were evaluated by phenomenography, which was a\nqualitative research method to study human experiences and their relations in\nhope of finding the better way to improve human experiences. Through\nphenomenographic study, the positive evaluation results showed that the new\ngeneration of LIL had more advantages in terms of effectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 03:07:03 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Zheng", "Yuting", ""]]}, {"id": "1601.07264", "submitter": "Su Fang Lim", "authors": "Su Fang Lim", "title": "Persuasive Teachable Agent for Intergenerational Learning", "comments": "This is a book draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teachable agents are computer agents based on the pedagogical concept of\nlearning-by-teaching. During the tutoring process, where students take on the\nrole of the tutor to teach a computer agent tutee, learners have been observed\nto gain deeper understanding of the subject matter. Teachable agents are\ncommonly used in the areas of science and mathematics learning where learners\nare able to learn complex concepts and deep reasoning by teaching the teachable\nagent through graphic representation such as concept maps.\n  Literature review on teachable agents as well as observations during field\nstudies conducted by the researcher, have shown that many current teachable\nagents lack the interaction abilities required to keep learners engage in\nlearning tasks. The result of this is learners deviating from the teaching\nprocess, and thus the learners are unable to benefit fully from learning with\nthe teachable agent. The applications of teachable agents are restricted to the\nlearning of academic subjects such as mathematics and science.\n  In this book, we have proposed the Persuasive Teachable Agent (PTA), a\nteachable agent based on the theoretical framework of persuasion, computational\nand goal-oriented agent modelling. We argue that the PTA, an autonomous agent,\ncapable of encouraging attitude and behavioural change can offer a more\nmeaningful and engaging learning experiences for learners from different age\ngroups. Based on the findings from our research we argue that persuasive\nfeedback actions generated by the PTA provide significant influence over\nlearner's decision to participate in intergenerational learning. The PTA plays\na crucial role in the development of future persuasive technologies in\nartificially intelligent agents.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 05:02:55 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Lim", "Su Fang", ""]]}, {"id": "1601.07273", "submitter": "Gangli Liu", "authors": "Gangli Liu, Ling Feng", "title": "A Method to Support Difficult Re-finding Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Re-finding electronic documents from a personal computer is a frequent demand\nto users. In a simple re-finding task, people can use many methods to retrieve\na document, such as navigating directly to the document's folder, searching\nwith a desktop search engine, or checking the Recent Files List. However, when\nencountering a difficult re-finding task, people usually cannot remember the\nattributes used by conventional re-finding methods, such as file path, file\nname, keywords etc., the re-finding would fail. We propose a new method to\nsupport difficult re-finding tasks. When a user is reading a document, we\ncollect all kinds of possible memory pieces of the user about the document,\nsuch as number of pages, number of images, number of math formulas, cumulative\nreading time, reading frequency, printing experiences etc. If the user wants to\nre-find a document later, we use these collected attributes to filter out the\ntarget document. To alleviate the user's cognitive burden, we use a question\nand answer wizard interface and provide recommendations to the answers for the\nuser, the recommendations are generated by analyzing the collected attributes\nof each document and the user's experiences about them.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 06:27:56 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Liu", "Gangli", ""], ["Feng", "Ling", ""]]}, {"id": "1601.08030", "submitter": "Carine Edith Toure", "authors": "Carine Tour\\'e (SICAL, SCP), Christine Michel (SICAL), Jean-Charles\n  Marty (SICAL)", "title": "What if we considered awareness for sustainable Kwowledge Management ?\n  Towards a model for self regulated knowledge management systems based on\n  acceptance models of technologies and awareness", "comments": "Knowledge Management and Information Sharing (KMIS), Oct 2014, Rome,\n  Italy. 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose, in this paper, a model of continuous use of corporate\ncollaborative KMS. Companies do not always have the guaranty that their KMS\nwill be continuously used. This statement can constitute an important obstacle\nfor knowledge management processes. Our work is based on the analysis of\nclassical models for initial and continuous use of technologies. We also\nanalyse the regulation concept and explain how it is valuable to support a\ncontinuous use of KMS. We observed that awareness may be a regulation means\nthat allows taking this problem into account. Awareness is a concept, which has\nbeen profusely used to improve user experience in collaborative environments.\nIt is an important element for regulation of activity. In our model, we assume\nthat one can integrate awareness in information systems to positively influence\nbeliefs about them. The final objective of our work is to refine some concepts\nto fit the particularities of collaborative KMS and to propose an awareness\nregulation process using the traces of the users' interactions with the\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 10:22:23 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Tour\u00e9", "Carine", "", "SICAL, SCP"], ["Michel", "Christine", "", "SICAL"], ["Marty", "Jean-Charles", "", "SICAL"]]}, {"id": "1601.08032", "submitter": "Carine Edith Toure", "authors": "Carine Tour\\'e (SICAL, SCP), Christine Michel (SICAL), Jean-Charles\n  Marty (SICAL)", "title": "Re-designing knowledge management systems : Towards user-centred design\n  methods integrating information architecture", "comments": "in Knowledge Management and Information Sharing, Oct 2014, Rome,\n  Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work presented in this paper focuses on the improvement of corporate\nknowledge management systems. For the implementation of such systems, companies\ndeploy can important means for small gains. Indeed, management services often\nnotice very limited use compared to what they actually expect. We present a\nfive-step redesigning approach which takes into account different factors to\nincrease the use of these systems. We use as an example the knowledge sharing\nplatform implemented for the employees of Soci{\\'e}t{\\'e} du Canal de Provence\n(SCP). This system was taken into production but very occasionally used. We\ndescribe the reasons for this limited use and we propose a design methodology\nadapted to the context. Promoting the effective use of the system, our approach\nhas been experimented and evaluated with a panel of users working at SCP.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 10:25:01 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Tour\u00e9", "Carine", "", "SICAL, SCP"], ["Michel", "Christine", "", "SICAL"], ["Marty", "Jean-Charles", "", "SICAL"]]}, {"id": "1601.08059", "submitter": "Nikos Bikakis", "authors": "Nikos Bikakis, Timos Sellis", "title": "Exploration and Visualization in the Web of Big Linked Data: A Survey of\n  the State of the Art", "comments": "6th International Workshop on Linked Web Data Management (LWDM 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data exploration and visualization systems are of great importance in the Big\nData era. Exploring and visualizing very large datasets has become a major\nresearch challenge, of which scalability is a vital requirement. In this\nsurvey, we describe the major prerequisites and challenges that should be\naddressed by the modern exploration and visualization systems. Considering\nthese challenges, we present how state-of-the-art approaches from the Database\nand Information Visualization communities attempt to handle them. Finally, we\nsurvey the systems developed by Semantic Web community in the context of the\nWeb of Linked Data, and discuss to which extent these satisfy the contemporary\nrequirements.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 11:30:44 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Bikakis", "Nikos", ""], ["Sellis", "Timos", ""]]}]