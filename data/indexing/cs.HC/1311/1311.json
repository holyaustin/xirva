[{"id": "1311.0251", "submitter": "Andrew Mao", "authors": "Andrew Mao, Hossein Azari Soufiani, Yiling Chen, David C. Parkes", "title": "Capturing Variation and Uncertainty in Human Judgment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-studied problem of statistical rank aggregation has been applied to\ncomparing sports teams, information retrieval, and most recently to data\ngenerated by human judgment. Such human-generated rankings may be substantially\ndifferent from traditional statistical ranking data. In this work, we show that\na recently proposed generalized random utility model reveals distinctive\npatterns in human judgment across three different domains, and provides a\nsuccinct representation of variance in both population preferences and\nimperfect perception. In contrast, we also show that classical statistical\nranking models fail to capture important features from human-generated input.\nOur work motivates the use of more flexible ranking models for representing and\ndescribing the collective preferences or decision-making of human participants.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 21:30:59 GMT"}, {"version": "v2", "created": "Mon, 3 Nov 2014 22:10:36 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Mao", "Andrew", ""], ["Soufiani", "Hossein Azari", ""], ["Chen", "Yiling", ""], ["Parkes", "David C.", ""]]}, {"id": "1311.0352", "submitter": "John-John Cabibihan", "authors": "John-John Cabibihan, Hifza Javed, Marcelo Ang Jr., and Sharifah Mariam\n  Aljunied", "title": "Why robots? A survey on the roles and benefits of social robots in the\n  therapy of children with autism", "comments": null, "journal-ref": "International Journal of Social Robotics, 2013, 5(4), 593-618", "doi": "10.1007/s12369-013-0202-2", "report-no": null, "categories": "cs.RO cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper reviews the use of socially interactive robots to assist in the\ntherapy of children with autism. The extent to which the robots were successful\nin helping the children in their social, emotional, and communication deficits\nwas investigated. Child-robot interactions were scrutinized with respect to the\ndifferent target behaviors that are to be elicited from a child during therapy.\nThese behaviors were thoroughly examined with respect to a childs development\nneeds. Most importantly, experimental data from the surveyed works were\nextracted and analyzed in terms of the target behaviors and how each robot was\nused during a therapy session to achieve these behaviors. The study concludes\nby categorizing the different therapeutic roles that these robots were observed\nto play, and highlights the important design features that enable them to\nachieve high levels of effectiveness in autism therapy.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2013 07:15:08 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Cabibihan", "John-John", ""], ["Javed", "Hifza", ""], ["Ang", "Marcelo", "Jr."], ["Aljunied", "Sharifah Mariam", ""]]}, {"id": "1311.0527", "submitter": "Harris Kyriakou", "authors": "Harris Kyriakou, Jeffrey V. Nickerson", "title": "Idea Inheritance, Originality, and Collective Innovation", "comments": "Workshop on Information in Networks, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In order to create new products, inventors search and combine previous ideas.\nFew studies have examined the characteristics of search that lead to new\nproducts; most have focused on patent citations, which are often retrospective\nand may not reflect the usefulness of inventions.\n  Through the analysis of collaborations in an online virtual community, the\nimpact of originality on popularity and practicality is tested. These tests in\nturn are based on a method for measuring the distance between 3D shapes. In\nsum, this paper presents a new method for gauging innovation, and suggests ways\nof further understanding the role technology plays in encouraging creativity.\nFrom an organization perspective, this work provides insights into the creative\nprocess, and in particular the open innovation process, in which thousands of\nindividuals together evolve designs, without belonging to the same corporate\nstructure, without claiming IP rights, without exchanging money.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2013 20:58:29 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Kyriakou", "Harris", ""], ["Nickerson", "Jeffrey V.", ""]]}, {"id": "1311.0529", "submitter": "Harris Kyriakou", "authors": "Harris Kyriakou, Steven Englehardt, Jeffrey V. Nickerson", "title": "Networks of Innovation in 3D Printing", "comments": "Workshop on Information in Networks, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Innovation inside companies is difficult to see. But an emerging online\ncommunity of inventors who publicly post 3D CAD drawings of their work provide\na way to observe - and perhaps amplify - innovation. In this paper we analyze\nthe network structure of Thingiverse, a website oriented toward 3D printing.\nThis form of printing blurs the line between creating information and\nmanufacturing objects: drawings can be sent to devices that build 3D objects\nout of many materials, including resin, ceramics, and metal. As an exploratory\nstudy, we analyzed the structure of Thingiverse links. Our results suggest that\nanalysis of remix network structure may provide ways of tracing innovation\nprocesses and detecting the emergence of new ideas, combination of disparate\nideas.\n", "versions": [{"version": "v1", "created": "Sun, 3 Nov 2013 21:05:45 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Kyriakou", "Harris", ""], ["Englehardt", "Steven", ""], ["Nickerson", "Jeffrey V.", ""]]}, {"id": "1311.0663", "submitter": "Ai-Ju Huang", "authors": "Ai-Ju Huang, Hao-Chuan Wang, Chien Wen Yuan", "title": "De-Virtualizing Social Events: Understanding the Gap between Online and\n  Offline Participation for Event Invitations", "comments": "Proc. 17th ACM Conference on Computer Supported Cooperative Work and\n  Social Computing (CSCW), 2014", "journal-ref": null, "doi": "10.1145/2531602.2531606", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One growing use of computer-based communication media is for gathering people\nto initiate or sustain social events. Although the use of computer-mediated\ncommunication and social network sites such as Facebook for event promotion is\nbecoming popular, online participation in an event does not always translate to\noffline attendance. In this paper, we report on an interview study of 31\nparticipants that examines how people handle online event invitations and what\ninfluences their online and offline participation. The results show that\npeople's event participation is shaped by their social perceptions of the\nevent's nature (e.g., public or private), their relationships to others (e.g.,\nthe strength of their connections to other invitees), and the medium used to\ncommunicate event information (e.g., targeted invitation via email or spam\ncommunication via Facebook event page). By exploring how people decide whether\nto participate online or offline, the results illuminate the sophisticated\nnature of the mechanisms that affect participation and have design implications\nthat can bridge virtual and real attendance.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 12:07:27 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Huang", "Ai-Ju", ""], ["Wang", "Hao-Chuan", ""], ["Yuan", "Chien Wen", ""]]}, {"id": "1311.0667", "submitter": "Wilko van Hoek", "authors": "Wilko van Hoek", "title": "Developing a Visual Interactive Search History Exploration System", "comments": "KNOWeSCAPE 2013, 2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As users advance in their search within a system, different queries are\nconducted and various results are examined by them. These objects form an\nimplicit individual library representing the acquired knowledge. In our\nresearch we aim to supply the user with visualizations of the search history\nand interaction methods to organize the history. The fundamental question is\nwhat role search history exploration can play in the users search process. In\nthis paper we want to introduce Ideas of a prototypical system for search\nhistory exploration and discuss methods to address the questions mentioned\nabove.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 12:13:50 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["van Hoek", "Wilko", ""]]}, {"id": "1311.0709", "submitter": "Yanshan Wang", "authors": "Yanshan Wang", "title": "A novel soft keyboard for touchscreen phones: QWERT", "comments": null, "journal-ref": "Int. J. of Human Factors and Ergonomics, 2013 Vol.2, No.4, pp.246\n  - 261", "doi": "10.1504/IJHFE.2013.059374", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of touchscreen phones has been growing around the world since\nthe iPhones and Android phones were released. More and more mobile phones with\nlarge touchscreen have been produced, however, the phones with small size\ndisplays are still in the majority of touch phones. The foremost interface on\ntouch smartphones is the information input module using soft keyboards.\nTraditional input methods on touch phones have either too small key buttons\n(such as QWERTY) or too many functions (such as 3$\\times$4 keyboard), which are\ninconvenient to use. Moreover, the conventional soft keyboards only use tapping\nto input texts while current touch smartphones allow various gestures on the\ntouchscreen, such as sliding. In this paper, a novel soft keyboard called QWERT\nis proposed for touchscreen-based smartphones. The users can interact with\nphones via finger gestures of tapping or sliding when input text by using the\nQWERT. In doing so, the interactions between users and smartphones will be\nfaster and easier. An experiment carried out on inexperienced human subjects\nshows that they can learn very fast due to their familiarities with QWERTY. A\nsimulation experiment based on a cognitive architecture, ACT-R, was also\nconducted to predict the movement time (MT) of experienced human subjects. The\nsimulation results show that the MT using QWERT outperforms other default\nkeyboards. These outcomes imply that the novel QWERT is a viable option for\ntouch smartphone users. Based on the novel design, an application is released\non Android systems. This application is expected to give better user experience\nfor customers who use touch smartphones.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 14:25:29 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Wang", "Yanshan", ""]]}, {"id": "1311.1132", "submitter": "Jalaluddin Qureshi", "authors": "Hamed Ketabdar, Jalaluddin Qureshi, Pan Hui", "title": "Motion and audio analysis in mobile devices for remote monitoring of\n  physical activities and user authentication", "comments": null, "journal-ref": "Journal of Location Based Services, Volume 5, Issue 3-4, 2011, pp.\n  180-200, Special Issue: The social and behavioural implications of\n  location-based services", "doi": "10.1080/17489725.2011.644331", "report-no": null, "categories": "cs.HC cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this article we propose the use of accelerometer embedded by default in\nsmartphone as a cost-effective, reliable and efficient way to provide remote\nphysical activity monitoring for the elderly and people requiring healthcare\nservice. Mobile phones are regularly carried by users during their day-to-day\nwork routine, physical movement information can be captured by the mobile phone\naccelerometer, processed and sent to a remote server for monitoring. The\nacceleration pattern can deliver information related to the pattern of physical\nactivities the user is engaged in. We further show how this technique can be\nextended to provide implicit real-time security by analysing unexpected\nmovements captured by the phone accelerometer, and automatically locking the\nphone in such situation to prevent unauthorised access. This technique is also\nshown to provide implicit continuous user authentication, by capturing regular\nuser movements such as walking, and requesting for re-authentication whenever\nit detects a non-regular movement.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 17:30:17 GMT"}], "update_date": "2013-11-06", "authors_parsed": [["Ketabdar", "Hamed", ""], ["Qureshi", "Jalaluddin", ""], ["Hui", "Pan", ""]]}, {"id": "1311.1213", "submitter": "Lav Varshney", "authors": "Lav R. Varshney, Florian Pinel, Kush R. Varshney, Debarun\n  Bhattacharjya, Angela Schoergendorfer, and Yi-Min Chee", "title": "A Big Data Approach to Computational Creativity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational creativity is an emerging branch of artificial intelligence\nthat places computers in the center of the creative process. Broadly,\ncreativity involves a generative step to produce many ideas and a selective\nstep to determine the ones that are the best. Many previous attempts at\ncomputational creativity, however, have not been able to achieve a valid\nselective step. This work shows how bringing data sources from the creative\ndomain and from hedonic psychophysics together with big data analytics\ntechniques can overcome this shortcoming to yield a system that can produce\nnovel and high-quality creative artifacts. Our data-driven approach is\ndemonstrated through a computational creativity system for culinary recipes and\nmenus we developed and deployed, which can operate either autonomously or\nsemi-autonomously with human interaction. We also comment on the volume,\nvelocity, variety, and veracity of data in computational creativity.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 21:00:14 GMT"}], "update_date": "2013-11-07", "authors_parsed": [["Varshney", "Lav R.", ""], ["Pinel", "Florian", ""], ["Varshney", "Kush R.", ""], ["Bhattacharjya", "Debarun", ""], ["Schoergendorfer", "Angela", ""], ["Chee", "Yi-Min", ""]]}, {"id": "1311.1725", "submitter": "Norman Gray", "authors": "Norman Gray and Nicolas Labrosse and Sarah Honeychurch and Steve\n  Draper and Niall Barr", "title": "Tagging and Linking Lecture Audio Recordings: Goals and Practice", "comments": "10 pages, 1 figure; draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ed-ph cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making and distributing audio recordings of lectures is cheap and technically\nstraightforward, and these recordings represent an underexploited teaching\nresource. We explore the reasons why such recordings are not more used; we\nbelieve the barriers inhibiting such use should be easily overcome. Students\ncan listen to a lecture they missed, or re-listen to a lecture at revision\ntime, but their interaction is limited by the affordances of the replaying\ntechnology. Listening to lecture audio is generally solitary, linear, and\ndisjoint from other available media.\n  In this paper, we describe a tool we are developing at the University of\nGlasgow, which enriches students' interactions with lecture audio. We describe\nour experiments with this tool in session 2012--13. Fewer students used the\ntool than we expected would naturally do so, and we discuss some possible\nexplanations for this.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 16:04:18 GMT"}], "update_date": "2013-11-08", "authors_parsed": [["Gray", "Norman", ""], ["Labrosse", "Nicolas", ""], ["Honeychurch", "Sarah", ""], ["Draper", "Steve", ""], ["Barr", "Niall", ""]]}, {"id": "1311.1935", "submitter": "Serge Smidtas", "authors": "Serge Smidtas, Magalie Peyrot", "title": "Unsupervised learning human's activities by overexpressed recognized\n  non-speech sounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity and environment produces sounds such as, at home, the noise\nproduced by water, cough, or television. These sounds can be used to determine\nthe activity in the environment. The objective is to monitor a person's\nactivity or determine his environment using a single low cost microphone by\nsound analysis. The purpose is to adapt programs to the activity or environment\nor detect abnormal situations. Some patterns of over expressed repeatedly in\nthe sequences of recognized sounds inter and intra environment allow to\ncharacterize activities such as the entrance of a person in the house, or a tv\nprogram watched. We first manually annotated 1500 sounds of daily life activity\nof old persons living at home recognized sounds. Then we inferred an ontology\nand enriched the database of annotation with a crowed sourced manual annotation\nof 7500 sounds to help with the annotation of the most frequent sounds. Using\nlearning sound algorithms, we defined 50 types of the most frequent sounds. We\nused this set of recognizable sounds as a base to tag sounds and put tags on\nthem. By using over expressed number of motifs of sequences of the tags, we\nwere able to categorize using only a single low-cost microphone, complex\nactivities of daily life of a persona at home as watching TV, entrance in the\napartment of a person, or phone conversation including detecting unknown\nactivities as repeated tasks performed by users.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 11:18:42 GMT"}], "update_date": "2013-11-11", "authors_parsed": [["Smidtas", "Serge", ""], ["Peyrot", "Magalie", ""]]}, {"id": "1311.2222", "submitter": "Jeremy Frey", "authors": "J\\'er\\'emy Frey (INRIA Bordeaux - Sud-Ouest, LaBRI), Christian M\\\"uhl\n  (INRIA Bordeaux - Sud-Ouest), Fabien Lotte (INRIA Bordeaux - Sud-Ouest,\n  LaBRI), Martin Hachet (INRIA Bordeaux - Sud-Ouest, LaBRI)", "title": "Review of the Use of Electroencephalography as an Evaluation Method for\n  Human-Computer Interaction", "comments": "PhyCS 2014 - International Conference on Physiological Computing\n  Systems (2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating human-computer interaction is essential as a broadening population\nuses machines, sometimes in sensitive contexts. However, traditional evaluation\nmethods may fail to combine real-time measures, an \"objective\" approach and\ndata contextualization. In this review we look at how adding neuroimaging\ntechniques can respond to such needs. We focus on electroencephalography (EEG),\nas it could be handled effectively during a dedicated evaluation phase. We\nidentify workload, attention, vigilance, fatigue, error recognition, emotions,\nengagement, flow and immersion as being recognizable by EEG. We find that\nworkload, attention and emotions assessments would benefit the most from EEG.\nMoreover, we advocate to study further error recognition through neuroimaging\nto enhance usability and increase user experience.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2013 21:35:44 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Frey", "J\u00e9r\u00e9my", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"], ["M\u00fchl", "Christian", "", "INRIA Bordeaux - Sud-Ouest"], ["Lotte", "Fabien", "", "INRIA Bordeaux - Sud-Ouest,\n  LaBRI"], ["Hachet", "Martin", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"]]}, {"id": "1311.2504", "submitter": "Bradly  Alicea", "authors": "Bradly Alicea", "title": "A Semi-automated Peer-review System", "comments": "6 pages, 2 figures, 1 table. Associated code an pseudo-code at:\n  https://github.com/balicea/semi-auto-peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.HC cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semi-supervised model of peer review is introduced that is intended to\novercome the bias and incompleteness of traditional peer review. Traditional\napproaches are reliant on human biases, while consensus decision-making is\nconstrained by sparse information. Here, the architecture for one potential\nimprovement (a semi-supervised, human-assisted classifier) to the traditional\napproach will be introduced and evaluated. To evaluate the potential advantages\nof such a system, hypothetical receiver operating characteristic (ROC) curves\nfor both approaches will be assessed. This will provide more specific\nindications of how automation would be beneficial in the manuscript evaluation\nprocess. In conclusion, the implications for such a system on measurements of\nscientific impact and improving the quality of open submission repositories\nwill be discussed.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 17:07:16 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Alicea", "Bradly", ""]]}, {"id": "1311.2702", "submitter": "Tobias Kuhn", "authors": "Tobias Kuhn, Alexandre Bergel", "title": "Verifiable Source Code Documentation in Controlled Natural Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.CL cs.HC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing documentation about software internals is rarely considered a\nrewarding activity. It is highly time-consuming and the resulting documentation\nis fragile when the software is continuously evolving in a multi-developer\nsetting. Unfortunately, traditional programming environments poorly support the\nwriting and maintenance of documentation. Consequences are severe as the lack\nof documentation on software structure negatively impacts the overall quality\nof the software product. We show that using a controlled natural language with\na reasoner and a query engine is a viable technique for verifying the\nconsistency and accuracy of documentation and source code. Using ACE, a\nstate-of-the-art controlled natural language, we present positive results on\nthe comprehensibility and the general feasibility of creating and verifying\ndocumentation. As a case study, we used automatic documentation verification to\nidentify and fix severe flaws in the architecture of a non-trivial piece of\nsoftware. Moreover, a user experiment shows that our language is faster and\neasier to learn and understand than other formal languages for software\ndocumentation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 07:44:10 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Kuhn", "Tobias", ""], ["Bergel", "Alexandre", ""]]}, {"id": "1311.3130", "submitter": "Niranjan  Kumar Parvatham", "authors": "Niranjan Kumar Parvatham", "title": "Impact of Indentation in Programming", "comments": null, "journal-ref": "International Journal of Programming Languages and Applications (\n  IJPLA ) Vol.3, No.4, October 2013", "doi": "10.5121/ijpla.2013.3403", "report-no": null, "categories": "cs.PL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer programming languages, indentation formats program source code to\nimprove readability. Programming languages make use of indentation to define\nprogram structure .Programmers use indentation to understand the structure of\ntheir programs to human readers. Especially, indentation is the better way to\nrepresent the relationship between control flow constructs such as selection\nstatements or loops and code contained within and outside them. This paper\ndescribes about different indentation styles used in Programming and also\ndescribes context of each indentation style. It also describes indentation\nstyles used for various programming constructs and the best practice for a\nparticular programming construct. This paper helps the beginners to understand\nvarious indentation styles used in programming and also to choose suitable\nindentation style.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 13:51:55 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Parvatham", "Niranjan Kumar", ""]]}, {"id": "1311.3371", "submitter": "Gayatri Venugopal Miss", "authors": "Gayatri Venugopal", "title": "Android Note Manager Application for People with Visual Impairment", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": "10.5121/ijmnct.2013.3502", "report-no": null, "categories": "cs.HC cs.CY", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  With the outburst of smart-phones today, the market is exploding with various\nmobile applications. This paper proposes an application using which visually\nimpaired people can type a note in Grade 1 Braille and save it in the external\nmemory of their smart-phone. The application also shows intelligence by\nactivating reminders and/or calling certain contacts based on the content in\nthe notes.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 03:12:54 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Venugopal", "Gayatri", ""]]}, {"id": "1311.3672", "submitter": "Zhaodan Kong", "authors": "Berenice Mettler and Zhaodan Kong", "title": "Hierarchical Model of Human Guidance Performance Based on Interaction\n  Patterns in Behavior", "comments": "2nd International Conference on Application and Theory of Automation\n  in Command and Control Systems (ICARUS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a framework for the investigation and modeling of human\nspatial guidance behavior in complex environments. The model is derived from\nthe concept of interaction patterns, which represent the invariances or\nsymmetries inherent in the interactions between an agent and its environment.\nThese patterns provide the basic elements needed for the formalization of\nspatial behavior and determine a natural hierarchy that can be unified under a\nhierarchical hidden Markov model.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 21:06:50 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Mettler", "Berenice", ""], ["Kong", "Zhaodan", ""]]}, {"id": "1311.4349", "submitter": "Paul Vickers", "authors": "James L. Alty and Paul Vickers", "title": "The CAITLIN Auralization System: Hierarchical Leitmotif Design as a Clue\n  to Program Comprehension", "comments": "In ICAD '97 Fourth International Conference on Auditory Display (J.\n  A. Ballas and E. D. Mynatt, eds.), (Palo Alto), pp. 89-96, Xerox PARC, Palo\n  Alto, CA 94304, 1997, 7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early experiments have suggested that program auralization can convey\ninformation about program structure [8]. Languages like Pascal contain classes\nof construct that are similar in nature allowing hierarchical classification of\ntheir features. This taxonomy can be reflected in the design of musical\nsignatures which are used within the CAITLIN program auralization system.\nExperiments using these hierarchical leitmotifs indicate whether or not their\nsimilarities can be put to good use in communicating information about program\nstructure and state. (Note, at time of going to press experimental results\ncould not be included. These will be presented at the conference and included\nlater.)\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 11:51:16 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Alty", "James L.", ""], ["Vickers", "Paul", ""]]}, {"id": "1311.4376", "submitter": "Paul Vickers", "authors": "Paul Vickers and Joe Faith and Nick Rossiter", "title": "Understanding Visualization: A Formal Approach using Category Theory and\n  Semiotics", "comments": "15 pages, 14 figures", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics, vol. 19,\n  pp. 1048-1061, 2013", "doi": "10.1109/TVCG.2012.294", "report-no": null, "categories": "cs.LO cs.GR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article combines the vocabulary of semiotics and category theory to\nprovide a formal analysis of visualization. It shows how familiar processes of\nvisualization fit the semiotic frameworks of both Saussure and Peirce, and\nextends these structures using the tools of category theory to provide a\ngeneral framework for understanding visualization in practice, including:\nrelationships between systems, data collected from those systems, renderings of\nthose data in the form of representations, the reading of those representations\nto create visualizations, and the use of those visualizations to create\nknowledge and understanding of the system under inspection. The resulting\nframework is validated by demonstrating how familiar information visualization\nconcepts (such as literalness, sensitivity, redundancy, ambiguity,\ngeneralizability, and chart junk) arise naturally from it and can be defined\nformally and precisely. This article generalizes previous work on the formal\ncharacterization of visualization by, inter alia, Ziemkiewicz and Kosara and\nallows us to formally distinguish properties of the visualization process that\nprevious work does not.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 13:51:27 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Vickers", "Paul", ""], ["Faith", "Joe", ""], ["Rossiter", "Nick", ""]]}, {"id": "1311.4658", "submitter": "Eduardo Graells-Garrido", "authors": "Eduardo Graells-Garrido, Mounia Lalmas, Daniele Quercia", "title": "Data Portraits: Connecting People of Opposing Views", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Social networks allow people to connect with each other and have\nconversations on a wide variety of topics. However, users tend to connect with\nlike-minded people and read agreeable information, a behavior that leads to\ngroup polarization. Motivated by this scenario, we study how to take advantage\nof partial homophily to suggest agreeable content to users authored by people\nwith opposite views on sensitive issues. We introduce a paradigm to present a\ndata portrait of users, in which their characterizing topics are visualized and\ntheir corresponding tweets are displayed using an organic design. Among their\ntweets we inject recommended tweets from other people considering their views\non sensitive issues in addition to topical relevance, indirectly motivating\nconnections between dissimilar people. To evaluate our approach, we present a\ncase study on Twitter about a sensitive topic in Chile, where we estimate user\nstances for regular people and find intermediary topics. We then evaluated our\ndesign in a user study. We found that recommending topically relevant content\nfrom authors with opposite views in a baseline interface had a negative\nemotional effect. We saw that our organic visualization design reverts that\neffect. We also observed significant individual differences linked to\nevaluation of recommendations. Our results suggest that organic visualization\nmay revert the negative effects of providing potentially sensitive content.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 09:01:36 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Graells-Garrido", "Eduardo", ""], ["Lalmas", "Mounia", ""], ["Quercia", "Daniele", ""]]}, {"id": "1311.5426", "submitter": "Paul Vickers", "authors": "Paul Vickers and Bennett Hogg", "title": "Sonification Abstraite/Sonification Concr\\`ete: An 'Aesthetic\n  Perspective Space' for Classifying Auditory Displays in the Ars Musica Domain", "comments": "in ICAD 2006, The 12th Meeting of the International Conference on\n  Auditory Display (T. Stockman, L. V. Nickerson, C. Frauenberger, A. D. N.\n  Edwards, and D. Brock, eds.), (London, UK), pp. 210-216, 20-23 June 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses {\\ae}sthetic issues of sonifications and the\nrelationships between sonification (ars informatica) and music & sound art (ars\nmusica). It is posited that many sonifications have suffered from poor internal\necological validity which makes listening more difficult, thereby resulting in\npoorer data extraction and inference on the part of the listener. Lessons are\ndrawn from the electroacoustic music and musique concr\\`ete communities as it\nis argued that it is not instructive to distinguish between sonifications and\nmusic/sound art.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 14:46:40 GMT"}], "update_date": "2013-11-22", "authors_parsed": [["Vickers", "Paul", ""], ["Hogg", "Bennett", ""]]}, {"id": "1311.5434", "submitter": "Paul Vickers", "authors": "Paul Vickers and James L Alty", "title": "The Well-tempered Compiler? The Aesthetics of Program Auralization", "comments": "in Aesthetic Computing (P. A. Fishwick, ed.), ch. 17, pp. 335-354,\n  Boston, MA: MIT Press, 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter we are concerned with external auditory representations of\nprograms, also known as program auralization. As program auralization systems\ntend to use musical representations they are necessarily affected by artistic\nand aesthetic considerations. Therefore, it is instructive to explore program\nauralization in the light of aesthetic computing principles.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 15:00:46 GMT"}], "update_date": "2013-11-22", "authors_parsed": [["Vickers", "Paul", ""], ["Alty", "James L", ""]]}, {"id": "1311.5757", "submitter": "Paul Vickers", "authors": "Paul Vickers", "title": "Lemma 4: Haptic Input + Auditory Display = Musical Instrument?", "comments": "in Haptic and Audio Interaction Design: First International Workshop,\n  HAID 2006, Glasgow, UK, August 31 - September 1, 2006. Proceedings (D.\n  McGookin and S. Brewster, eds.), vol. 4129/2006 of Lecture Notes in Computer\n  Science, pp. 56-67, Springer-Verlag, 2006", "journal-ref": null, "doi": "10.1007/11821731", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we look at some of the design issues that affect the success of\nmultimodal displays that combine acoustic and haptic modalities. First, issues\naffecting successful sonification design are explored and suggestions are made\nabout how the language of electroacoustic music can assist. Next, haptic\ninteraction is introduced in the light of this discussion, particularly\nfocusing on the roles of gesture and mimesis. Finally, some observations are\nmade regarding some of the issues that arise when the haptic and acoustic\nmodalities are combined in the interface. This paper looks at examples of where\nauditory and haptic interaction have been successfully combined beyond the\nstrict confines of the human-computer application interface (musical\ninstruments in particular) and discusses lessons that may be drawn from these\ndomains and applied to the world of multimodal human-computer interaction. The\nargument is made that combined haptic-auditory interaction schemes can be\nthought of as musical instruments and some of the possible ramifications of\nthis are raised.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 14:32:41 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Vickers", "Paul", ""]]}, {"id": "1311.5763", "submitter": "Peter Sarlin", "authors": "Peter Sarlin", "title": "Automated and Weighted Self-Organizing Time Maps", "comments": "Preprint submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes schemes for automated and weighted Self-Organizing Time\nMaps (SOTMs). The SOTM provides means for a visual approach to evolutionary\nclustering, which aims at producing a sequence of clustering solutions. This\ntask we denote as visual dynamic clustering. The implication of an automated\nSOTM is not only a data-driven parametrization of the SOTM, but also the\nfeature of adjusting the training to the characteristics of the data at each\ntime step. The aim of the weighted SOTM is to improve learning from more\ntrustworthy or important data with an instance-varying weight. The schemes for\nautomated and weighted SOTMs are illustrated on two real-world datasets: (i)\ncountry-level risk indicators to measure the evolution of global imbalances,\nand (ii) credit applicant data to measure the evolution of firm-level credit\nrisks.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2013 14:34:38 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Sarlin", "Peter", ""]]}, {"id": "1311.5880", "submitter": "Paul Vickers", "authors": "Paul Vickers", "title": "Ways of Listening and Modes of Being: Electroacoustic Auditory Display", "comments": "available at http://journal.sonicstudies.org/vol02/nr01/a04", "journal-ref": "Journal of Sonic Studies, Vol 2, 2012, ISSN 2212-6252", "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auditory display is concerned with the use of non-speech sound to communicate\ninformation. If the term seems at first oxymoronic, then consider auditory\ndisplay as an activity of perceptualization, that is, the process of making\nperceptible to humans aspects or features of a given data set or system. Most\ncommonly this is done using visual representations (which process we call\nvisualization) but it is not limited to the visual channel and recent years\nhave witnessed the increased use of auditory representations in the production\nof tools for exploring data. By way of semiotics and an aesthetic perspective\nshift this article posits that auditory display may be considered a form of\norganized sound and explores the listening experience in this context.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 08:56:20 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Vickers", "Paul", ""]]}, {"id": "1311.6996", "submitter": "Tim Dwyer", "authors": "Tim Dwyer, Christopher Mears, Kerri Morgan, Todd Niven, Kim Marriott,\n  Mark Wallace", "title": "Improved Optimal and Approximate Power Graph Compression for Clearer\n  Visualisation of Dense Graphs", "comments": "Extended technical report accompanying the PacificVis 2013 paper of\n  the same name", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawings of highly connected (dense) graphs can be very difficult to read.\nPower Graph Analysis offers an alternate way to draw a graph in which sets of\nnodes with common neighbours are shown grouped into modules. An edge connected\nto the module then implies a connection to each member of the module. Thus, the\nentire graph may be represented with much less clutter and without loss of\ndetail. A recent experimental study has shown that such lossless compression of\ndense graphs makes it easier to follow paths. However, computing optimal power\ngraphs is difficult. In this paper, we show that computing the optimal\npower-graph with only one module is NP-hard and therefore likely NP-hard in the\ngeneral case. We give an ILP model for power graph computation and discuss why\nILP and CP techniques are poorly suited to the problem. Instead, we are able to\nfind optimal solutions much more quickly using a custom search method. We also\nshow how to restrict this type of search to allow only limited back-tracking to\nprovide a heuristic that has better speed and better results than previously\nknown heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 03:28:44 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Dwyer", "Tim", ""], ["Mears", "Christopher", ""], ["Morgan", "Kerri", ""], ["Niven", "Todd", ""], ["Marriott", "Kim", ""], ["Wallace", "Mark", ""]]}]