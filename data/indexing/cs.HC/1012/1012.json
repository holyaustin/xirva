[{"id": "1012.0084", "submitter": "Karthik Shastry R", "authors": "Harshith C, Karthik R. Shastry, Manoj Ravindran, M.V.V.N.S. Srikanth,\n  Naveen Lakshmikhanth", "title": "Survey on Various Gesture Recognition Techniques for Interfacing\n  Machines Based on Ambient Intelligence", "comments": "12 PAGES", "journal-ref": null, "doi": "10.5121/ijcses.2010.1203", "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gesture recognition is mainly apprehensive on analyzing the functionality of\nhuman wits. The main goal of gesture recognition is to create a system which\ncan recognize specific human gestures and use them to convey information or for\ndevice control. Hand gestures provide a separate complementary modality to\nspeech for expressing ones ideas. Information associated with hand gestures in\na conversation is degree,discourse structure, spatial and temporal structure.\nThe approaches present can be mainly divided into Data-Glove Based and Vision\nBased approaches. An important face feature point is the nose tip. Since nose\nis the highest protruding point from the face. Besides that, it is not affected\nby facial expressions.Another important function of the nose is that it is able\nto indicate the head pose. Knowledge of the nose location will enable us to\nalign an unknown 3D face with those in a face database. Eye detection is\ndivided into eye position detection and eye contour detection. Existing works\nin eye detection can be classified into two major categories: traditional\nimage-based passive approaches and the active IR based approaches. The former\nuses intensity and shape of eyes for detection and the latter works on the\nassumption that eyes have a reflection under near IR illumination and produce\nbright/dark pupil effect. The traditional methods can be broadly classified\ninto three categories: template based methods,appearance based methods and\nfeature based methods. The purpose of this paper is to compare various human\nGesture recognition systems for interfacing machines directly to human wits\nwithout any corporeal media in an ambient environment.\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 02:54:24 GMT"}], "update_date": "2010-12-02", "authors_parsed": [["C", "Harshith", ""], ["Shastry", "Karthik R.", ""], ["Ravindran", "Manoj", ""], ["Srikanth", "M. V. V. N. S.", ""], ["Lakshmikhanth", "Naveen", ""]]}, {"id": "1012.0467", "submitter": "Uwe Laufs", "authors": "Uwe Laufs, Christopher Ruff, Jan Zibuschka", "title": "MT4j - A Cross-platform Multi-touch Development Framework", "comments": "ACM EICS 2010, Workshop: Engineering patterns for multi-touch\n  interfaces (2010), p. 52-57", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes requirements and challenges of crossplatform\nmulti-touch software engineering, and presents the open source framework\nMulti-Touch for Java (MT4j) as a solution. MT4j is designed for rapid\ndevelopment of graphically rich applications on a variety of contemporary\nhardware, from common PCs and notebooks to large-scale ambient displays, as\nwell as different operating systems. The framework has a special focus on\nmaking multi-touch software development easier and more efficient. Architecture\nand abstractions used by MT4j are described, and implementations of several\ncommon use cases are presented.\n", "versions": [{"version": "v1", "created": "Thu, 2 Dec 2010 16:01:21 GMT"}], "update_date": "2010-12-03", "authors_parsed": [["Laufs", "Uwe", ""], ["Ruff", "Christopher", ""], ["Zibuschka", "Jan", ""]]}, {"id": "1012.1623", "submitter": "Adrian Paschke", "authors": "Theodore Dalamagas, Tryfon Farmakakis, Manolis Maragkakis, Artemis\n  Hatzigeorgiou", "title": "FreePub: Collecting and Organizing Scientific Material Using Mindmaps", "comments": "in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott\n  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on\n  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,\n  December 8-10, 2010", "journal-ref": null, "doi": null, "report-no": "SWAT4LS 2010", "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a creativity support tool, called FreePub, to collect and\norganize scientific material using mindmaps. Mindmaps are visual, graph-based\nrepresenations of concepts, ideas, notes, tasks, etc. They generally take a\nhierarchical or tree branch format, with ideas branching into their\nsubsections. FreePub supports creativity cycles. A user starts such a cycle by\nsetting up her domain of interest using mindmaps. Then, she can browse mindmaps\nand launch search tasks to gather relevant publications from several data\nsources. FreePub, besides publications, identifies helpful supporting material\n(e.g., blog posts, presentations). All retrieved information from FreePub can\nbe imported and organized in mindmaps. FreePub has been fully implemented on\ntop of FreeMind, a popular open-source, mindmapping tool.\n", "versions": [{"version": "v1", "created": "Tue, 7 Dec 2010 21:58:25 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Dalamagas", "Theodore", ""], ["Farmakakis", "Tryfon", ""], ["Maragkakis", "Manolis", ""], ["Hatzigeorgiou", "Artemis", ""]]}, {"id": "1012.1671", "submitter": "Kazutaka Kurihara", "authors": "Kazutaka Kurihara, Naoshi Nagano, Yuta Watanabe, Yuichi Fujimura,\n  Akinori Minaduki, Hidehiko Hayashi, and Yohei Tsuchiya", "title": "Localizing Audiences' Gaze using a Multi-touch Electronic Whiteboard\n  with sPieMenu", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct-touch presentation devices such as touch-sensitive electronic\nwhiteboards have two serious problems. First, the presenter's hand movements\ntend to distract the audience's attention from content. Second, the presenter'\ns manipulation tends to obscure content. In this paper we describe a new\nelectronic whiteboard system that supports multi-touch gestures and employs a\nspecial pie menu interface named \"sPieMenu.\" This pie menu is displayed under\nthe presenter's palm and is thus invisible to the audience. A series of\nexperiments shows that the proposed system allows both novice and expert users\nto efficiently manipulate the electronic whiteboard, and that the proposed\nsystem decreases distraction to the audience compared to traditional\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 8 Dec 2010 01:55:51 GMT"}], "update_date": "2010-12-09", "authors_parsed": [["Kurihara", "Kazutaka", ""], ["Nagano", "Naoshi", ""], ["Watanabe", "Yuta", ""], ["Fujimura", "Yuichi", ""], ["Minaduki", "Akinori", ""], ["Hayashi", "Hidehiko", ""], ["Tsuchiya", "Yohei", ""]]}, {"id": "1012.2832", "submitter": "Lin Zhong", "authors": "Ahmad Rahmati and Lin Zhong", "title": "A Longitudinal Study of Non-Voice Mobile Phone Usage by Teens from an\n  Underserved Urban Community", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a user study of over four months on the non-voice usage of mobile\nphones by teens from an underserved urban community in the USA where a\ncommunity-wide, open-access Wi-Fi network exists. We instrumented the phones to\nrecord quantitative information regarding their usage and location in a\nprivacy-respecting manner. We conducted focus group meetings and interviewed\nparticipants regularly for qualitative data. We present our findings on what\napplications our participants used and how their usage changed over time. The\nfindings highlight the challenges to evaluating the usability of mobile systems\nand the value of long-term methodologies. Based on our findings, we analyze the\nunique values of mobile phones, as a platform technology. Our study shows that\nthe usage is highly mobile, location-dependent, and serves multiple social\npurposes for the participants. Furthermore, we present concrete findings on how\nto perform and analyze similar user studies on mobile phones, including four\ncontributing factors to usage evolution, and provide guidelines for their\ndesign and evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 13 Dec 2010 18:47:19 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Rahmati", "Ahmad", ""], ["Zhong", "Lin", ""]]}, {"id": "1012.4559", "submitter": "Weidong Huang", "authors": "Peter Eades, Weidong Huang, Seok-Hee Hong", "title": "A Force-Directed Method for Large Crossing Angle Graph Drawing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recent empirical research has indicated that human graph reading performance\nimproves when crossing angles increase. However, crossing angle has not been\nused as an aesthetic criterion for graph drawing algorithms so far. In this\npaper, we introduce a force-directed method that aims to construct graph\ndrawings with large crossing angles. Experiments indicate that our method\nsignificantly increases crossing angles. Surprisingly, the experimental results\nfurther demonstrate that the resulting drawings produced by our method have\nfewer edge crossings, a shorter total edge length and more uniform edge\nlengths, compared to classical spring algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 07:39:45 GMT"}], "update_date": "2010-12-22", "authors_parsed": [["Eades", "Peter", ""], ["Huang", "Weidong", ""], ["Hong", "Seok-Hee", ""]]}]