[{"id": "1401.0561", "submitter": "Janne Lindqvist", "authors": "Michael Sherman, Gradeigh Clark, Yulong Yang, Shridatt Sugrim, Arttu\n  Modig, Janne Lindqvist, Antti Oulasvirta, Teemu Roos", "title": "User-Generated Free-Form Gestures for Authentication: Security and\n  Memorability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the security and memorability of free-form multitouch\ngestures for mobile authentication. Towards this end, we collected a dataset\nwith a generate-test-retest paradigm where participants (N=63) generated\nfree-form gestures, repeated them, and were later retested for memory. Half of\nthe participants decided to generate one-finger gestures, and the other half\ngenerated multi-finger gestures. Although there has been recent work on\ntemplate-based gestures, there are yet no metrics to analyze security of either\ntemplate or free-form gestures. For example, entropy-based metrics used for\ntext-based passwords are not suitable for capturing the security and\nmemorability of free-form gestures. Hence, we modify a recently proposed metric\nfor analyzing information capacity of continuous full-body movements for this\npurpose. Our metric computed estimated mutual information in repeated sets of\ngestures. Surprisingly, one-finger gestures had higher average mutual\ninformation. Gestures with many hard angles and turns had the highest mutual\ninformation. The best-remembered gestures included signatures and simple\nangular shapes. We also implemented a multitouch recognizer to evaluate the\npracticality of free-form gestures in a real authentication system and how they\nperform against shoulder surfing attacks. We conclude the paper with strategies\nfor generating secure and memorable free-form gestures, which present a robust\nmethod for mobile authentication.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 23:15:27 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Sherman", "Michael", ""], ["Clark", "Gradeigh", ""], ["Yang", "Yulong", ""], ["Sugrim", "Shridatt", ""], ["Modig", "Arttu", ""], ["Lindqvist", "Janne", ""], ["Oulasvirta", "Antti", ""], ["Roos", "Teemu", ""]]}, {"id": "1401.0585", "submitter": "Thomas Sandholm", "authors": "Thomas Sandholm, Dongman Lee, Bjorn Tegelund, Seonyeong Han,\n  Byoungheon Shin, Byoungoh Kim", "title": "CloudFridge: A Testbed for Smart Fridge Interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a testbed for exploring novel smart refrigerator interactions, and\nidentify three key adoption-limiting interaction shortcomings of\nstate-of-the-art smart fridges: lack of 1) user experience focus, 2)\nlow-intrusion object recognition and 2) automatic item position detection. Our\ntestbed system addresses these limitations by a combination of sensors,\nsoftware filters, architectural components and a RESTful API to track\ninteraction events in real-time, and retrieve current state and historical data\nto learn patterns and recommend user actions. We evaluate the accuracy and\noverhead of our system in a realistic interaction flow. The accuracy was\nmeasured to 83-88% and the overhead compared to a representative\nstate-of-the-art barcode scanner improved by 27%. We also showcase two\napplications built on top of our testbed, one for finding expired items and\ningredients of dishes; and one to monitor your health. The pattern that these\napplications have in common is that they cast the interaction as an\nitem-recommendation problem triggered when the user takes something out. Our\ntestbed could help reveal further user-experience centric interaction patterns\nand new classes of applications for smart fridges that inherently, by relying\non our testbed primitives, mitigate the issues with existing approaches.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 04:45:49 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Sandholm", "Thomas", ""], ["Lee", "Dongman", ""], ["Tegelund", "Bjorn", ""], ["Han", "Seonyeong", ""], ["Shin", "Byoungheon", ""], ["Kim", "Byoungoh", ""]]}, {"id": "1401.0598", "submitter": "Wu Wu", "authors": "Wu Wu, Jiulin Hu, Xiaofang Huang, Huijie Chen, Bo Sun", "title": "Flight trajectory recreation and playback system of aerial mission based\n  on ossimplanet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recreation of flight trajectory is important among research areas. The design\nof a flight trajectory recreation and playback system is presented in this\npaper. Rather than transferring the flight data to diagram, graph and table,\nflight data is visualized on the 3D global of ossimPlanet. ossimPlanet is an\nopen-source 3D global geo-spatial viewer and the system realization is based on\nanalysis it. Users are allowed to choose their interested flight of aerial\nmission. The aerial photographs and corresponding configuration files in which\nflight data is included would be read in. And the flight statuses would be\nstored. The flight trajectory is then recreated. Users can view the photographs\nand flight trajectory marks on the correct positions of 3D global. The scene\nalong flight trajectory is also simulated at the plane's eye point. This paper\nprovides a more intuitive way for recreation of flight trajectory. The cost is\ndecreased remarkably and security is ensured by secondary development on\nopen-source platform.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 07:10:25 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Wu", "Wu", ""], ["Hu", "Jiulin", ""], ["Huang", "Xiaofang", ""], ["Chen", "Huijie", ""], ["Sun", "Bo", ""]]}, {"id": "1401.1031", "submitter": "Noreen Jamil", "authors": "Noreen Jamil", "title": "Constraint Solvers for User Interface Layout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraints have played an important role in the construction of GUIs, where\nthey are mainly used to define the layout of the widgets. Resizing behavior is\nvery important in GUIs because areas have domain specific parameters such as\nform the resizing of windows. If linear objective function is used and window\nis resized then error is not distributed equally. To distribute the error\nequally, a quadratic objective function is introduced. Different algorithms are\nwidely used for solving linear constraints and quadratic problems in a variety\nof different scientific areas. The linear relxation, Kaczmarz, direct and\nlinear programming methods are common methods for solving linear constraints\nfor GUI layout. The interior point and active set methods are most commonly\nused techniques to solve quadratic programming problems. Current constraint\nsolvers designed for GUI layout do not use interior point methods for solving a\nquadratic objective function subject to linear equality and inequality\nconstraints. In this paper, performance aspects and the convergence speed of\ninterior point and active set methods are compared along with one most commonly\nused linear programming method when they are implemented for graphical user\ninterface layout. The performance and convergence of the proposed algorithms\nare evaluated empirically using randomly generated UI layout specifications of\nvarious sizes. The results show that the interior point algorithms perform\nsignificantly better than the Simplex method and QOCA-solver, which uses the\nactive set method implementation for solving quadratic optimization.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 10:29:07 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Jamil", "Noreen", ""]]}, {"id": "1401.1486", "submitter": "Zeeshan Bhatti", "authors": "Imdad Ali Ismaili, Zeeshan Bhatti, Azhar Ali Shah", "title": "Design & Development of the Graphical User Interface for Sindhi Language", "comments": null, "journal-ref": "Mehran University Research Journal of Engineering & Technology,\n  Volume 30, No. 4, October 2011 [ISSN 0254-7821]", "doi": null, "report-no": null, "categories": "cs.HC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and implementation of a Unicode-based GUISL\n(Graphical User Interface for Sindhi Language). The idea is to provide a\nsoftware platform to the people of Sindh as well as Sindhi diasporas living\nacross the globe to make use of computing for basic tasks such as editing,\ncomposition, formatting, and printing of documents in Sindhi by using GUISL.\nThe implementation of the GUISL has been done in the Java technology to make\nthe system platform independent. The paper describes several design issues of\nSindhi GUI in the context of existing software tools and technologies and\nexplains how mapping and concatenation techniques have been employed to achieve\nthe cursive shape of Sindhi script.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 20:07:51 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Ismaili", "Imdad Ali", ""], ["Bhatti", "Zeeshan", ""], ["Shah", "Azhar Ali", ""]]}, {"id": "1401.1690", "submitter": "Sergey Andreyev", "authors": "Sergey Andreyev", "title": "Tendencies, Dead-ends, and Promising Ways. From Interface Ideas to New\n  Programs", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mechanism of communication between users and devices is called interface.\nFrom time to time changes in interface significantly improve our work with\ncomputers even without any serious changes in programs themselves. Main ideas\nin PCs interface were introduced many years ago and since then there are no\nsignificant changes, while new devices show promising ways by using direct\nmanipulation of screen objects. Users' direct action with all the screen\nobjects of our ordinary PCs turns standard screens into touch screens of very\nhigh resolution and not only changes the interface of familiar programs but\ncreates the new type of programs: user-driven applications.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2014 13:22:42 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Andreyev", "Sergey", ""]]}, {"id": "1401.1752", "submitter": "Noreen Jamil", "authors": "Noreen Jamil, Johannes M\\\"uller, Christof Lutteroth and Gerald Weber", "title": "Speeding up SOR Solvers for Constraint-based GUIs with a Warm-Start\n  Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computer programs have graphical user interfaces (GUIs), which need good\nlayout to make efficient use of the available screen real estate. Most GUIs do\nnot have a fixed layout, but are resizable and able to adapt themselves.\nConstraints are a powerful tool for specifying adaptable GUI layouts: they are\nused to specify a layout in a general form, and a constraint solver is used to\nfind a satisfying concrete layout, e.g.\\ for a specific GUI size. The\nconstraint solver has to calculate a new layout every time a GUI is resized or\nchanged, so it needs to be efficient to ensure a good user experience. One\napproach for constraint solvers is based on the Gauss-Seidel algorithm and\nsuccessive over-relaxation (SOR).\n  Our observation is that a solution after resizing or changing is similar in\nstructure to a previous solution. Thus, our hypothesis is that we can increase\nthe computational performance of an SOR-based constraint solver if we reuse the\nsolution of a previous layout to warm-start the solving of a new layout. In\nthis paper we report on experiments to test this hypothesis experimentally for\nthree common use cases: big-step resizing, small-step resizing and constraint\nchange. In our experiments, we measured the solving time for randomly generated\nGUI layout specifications of various sizes. For all three cases we found that\nthe performance is improved if an existing solution is used as a starting\nsolution for a new layout.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2014 10:29:32 GMT"}], "update_date": "2014-01-09", "authors_parsed": [["Jamil", "Noreen", ""], ["M\u00fcller", "Johannes", ""], ["Lutteroth", "Christof", ""], ["Weber", "Gerald", ""]]}, {"id": "1401.3090", "submitter": "Bin Guo", "authors": "Bin Guo, Zhiwen Yu, Daqing Zhang, Xingshe Zhou", "title": "From Participatory Sensing to Mobile Crowd Sensing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research on the efforts of combining human and machine intelligence has a\nlong history. With the development of mobile sensing and mobile Internet\ntechniques, a new sensing paradigm called Mobile Crowd Sensing (MCS), which\nleverages the power of citizens for large-scale sensing has become popular in\nrecent years. As an evolution of participatory sensing, MCS has two unique\nfeatures: (1) it involves both implicit and explicit participation; (2) MCS\ncollects data from two user-participant data sources: mobile social networks\nand mobile sensing. This paper presents the literary history of MCS and its\nunique issues. A reference framework for MCS systems is also proposed. We\nfurther clarify the potential fusion of human and machine intelligence in MCS.\nFinally, we discuss the future research trends as well as our efforts to MCS.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 07:32:50 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Guo", "Bin", ""], ["Yu", "Zhiwen", ""], ["Zhang", "Daqing", ""], ["Zhou", "Xingshe", ""]]}, {"id": "1401.3519", "submitter": "Kamlesh Sharma", "authors": "Kamlesh Sharma, Dr. T.V Prasad", "title": "Swar The Voice Operated PC", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyboard, although a popular medium, is not very convenient as it requires a\ncertain amount of skill for effective usage. A mouse on the other hand requires\na good hand-eye co-ordination. Also current computer interfaces also assume a\ncertain level of literacy from the user. It also expect the user to have\ncertain level of proficiency in English. In our country where the literacy\nlevel is as low as 50% in some states, if information technology has to reach\nthe grass root level; these constraints have to be eliminated. As a solution\nfor these, Speech Recognition and hence the concept of Voice operated computer\nsystem comes into picture. In this paper we propose a technique to develop a\nvoice recognition system which will be used for controlling computer via speech\ninput from any user i.e. without the use of mouse and / or keyboard. Once\ndeveloped this system would be of great benefit to physically handicapped\npeople as Instead of scrolling through written procedures on a laptop or\nhandheld computer, they can wear a headset and have their hands and eyes free.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 08:58:56 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Sharma", "Kamlesh", ""], ["Prasad", "Dr. T. V", ""]]}, {"id": "1401.3836", "submitter": "Liyue Zhao", "authors": "Liyue Zhao, Yu Zhang and Gita Sukthankar", "title": "An Active Learning Approach for Jointly Estimating Worker Performance\n  and Annotation Reliability with Crowdsourced Data", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing platforms offer a practical solution to the problem of\naffordably annotating large datasets for training supervised classifiers.\nUnfortunately, poor worker performance frequently threatens to compromise\nannotation reliability, and requesting multiple labels for every instance can\nlead to large cost increases without guaranteeing good results. Minimizing the\nrequired training samples using an active learning selection procedure reduces\nthe labeling requirement but can jeopardize classifier training by focusing on\nerroneous annotations. This paper presents an active learning approach in which\nworker performance, task difficulty, and annotation reliability are jointly\nestimated and used to compute the risk function guiding the sample selection\nprocedure. We demonstrate that the proposed approach, which employs active\nlearning with Bayesian networks, significantly improves training accuracy and\ncorrectly ranks the expertise of unknown labelers in the presence of annotation\nnoise.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 04:51:19 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Zhao", "Liyue", ""], ["Zhang", "Yu", ""], ["Sukthankar", "Gita", ""]]}, {"id": "1401.4158", "submitter": "Tom Froese", "authors": "Tom Froese, Hiroyuki Iizuka and Takashi Ikegami", "title": "Embodied social interaction constitutes social cognition in pairs of\n  humans: A minimalist virtual reality experiment", "comments": "10 pages, 5 figures, 2 tables", "journal-ref": "Froese, T., Iizuka, H. & Ikegami, T. Embodied social interaction\n  constitutes social cognition in pairs of humans: A minimalist virtual reality\n  experiment. Sci. Rep. 4, 3672; DOI:10.1038/srep03672 (2014)", "doi": "10.1038/srep03672", "report-no": null, "categories": "nlin.AO cs.HC cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Scientists have traditionally limited the mechanisms of social cognition to\none brain, but recent approaches claim that interaction also realizes cognitive\nwork. Experiments under constrained virtual settings revealed that interaction\ndynamics implicitly guide social cognition. Here we show that embodied social\ninteraction can be constitutive of agency detection and of experiencing\nanother`s presence. Pairs of participants moved their \"avatars\" along an\ninvisible virtual line and could make haptic contact with three identical\nobjects, two of which embodied the other`s motions, but only one, the other`s\navatar, also embodied the other`s contact sensor and thereby enabled responsive\ninteraction. Co-regulated interactions were significantly correlated with\nidentifications of the other`s avatar and reports of the clearest awareness of\nthe other`s presence. These results challenge folk psychological notions about\nthe boundaries of mind, but make sense from evolutionary and developmental\nperspectives: an extendible mind can offload cognitive work into its\nenvironment.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 20:42:32 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Froese", "Tom", ""], ["Iizuka", "Hiroyuki", ""], ["Ikegami", "Takashi", ""]]}, {"id": "1401.4276", "submitter": "Xiaohui Wang", "authors": "Xiaohui Wang, Jia Jia, Lianhong Cai, Jie Tang", "title": "Modeling Emotion Influence from Images in Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images become an important and prevalent way to express users' activities,\nopinions and emotions. In a social network, individual emotions may be\ninfluenced by others, in particular by close friends. We focus on understanding\nhow users embed emotions into the images they uploaded to the social websites\nand how social influence plays a role in changing users' emotions. We first\nverify the existence of emotion influence in the image networks, and then\npropose a probabilistic factor graph based emotion influence model to answer\nthe questions of \"who influences whom\". Employing a real network from Flickr as\nexperimental data, we study the effectiveness of factors in the proposed model\nwith in-depth data analysis. Our experiments also show that our model, by\nincorporating the emotion influence, can significantly improve the accuracy\n(+5%) for predicting emotions from images. Finally, a case study is used as the\nanecdotal evidence to further demonstrate the effectiveness of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2014 09:16:25 GMT"}], "update_date": "2014-01-20", "authors_parsed": [["Wang", "Xiaohui", ""], ["Jia", "Jia", ""], ["Cai", "Lianhong", ""], ["Tang", "Jie", ""]]}, {"id": "1401.4578", "submitter": "Vito Domenico Pietro Servedio", "authors": "Saverio Caminiti, Claudio Cicali, Pietro Gravino, Vittorio Loreto,\n  Vito D.P. Servedio, Alina S\\^irbu and Francesca Tria", "title": "XTribe: a web-based social computation platform", "comments": "11 pages, 2 figures, 1 table, 2013 Third International Conference on\n  Cloud and Green Computing (CGC), Sept. 30 2013-Oct. 2 2013, Karlsruhe,\n  Germany", "journal-ref": "IEEE Xplore, Cloud and Green Computing (CGC), 2013 Third\n  International Conference on, 397-403 (2013)", "doi": "10.1109/CGC.2013.69", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years the Web has progressively acquired the status of an\ninfrastructure for social computation that allows researchers to coordinate the\ncognitive abilities of human agents in on-line communities so to steer the\ncollective user activity towards predefined goals. This general trend is also\ntriggering the adoption of web-games as a very interesting laboratory to run\nexperiments in the social sciences and whenever the contribution of human\nbeings is crucially required for research purposes. Nowadays, while the number\nof on-line users has been steadily growing, there is still a need of\nsystematization in the approach to the web as a laboratory. In this paper we\npresent Experimental Tribe (XTribe in short), a novel general purpose web-based\nplatform for web-gaming and social computation. Ready to use and already\noperational, XTribe aims at drastically reducing the effort required to develop\nand run web experiments. XTribe has been designed to speed up the\nimplementation of those general aspects of web experiments that are independent\nof the specific experiment content. For example, XTribe takes care of user\nmanagement by handling their registration and profiles and in case of\nmulti-player games, it provides the necessary user grouping functionalities.\nXTribe also provides communication facilities to easily achieve both\nbidirectional and asynchronous communication. From a practical point of view,\nresearchers are left with the only task of designing and implementing the game\ninterface and logic of their experiment, on which they maintain full control.\nMoreover, XTribe acts as a repository of different scientific experiments, thus\nrealizing a sort of showcase that stimulates users' curiosity, enhances their\nparticipation, and helps researchers in recruiting volunteers.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2014 18:35:34 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Caminiti", "Saverio", ""], ["Cicali", "Claudio", ""], ["Gravino", "Pietro", ""], ["Loreto", "Vittorio", ""], ["Servedio", "Vito D. P.", ""], ["S\u00eerbu", "Alina", ""], ["Tria", "Francesca", ""]]}, {"id": "1401.5039", "submitter": "Katherine Driggs-Campbell", "authors": "Katherine Driggs-Campbell, Guillaume Bellegarda, Victor Shia, S.\n  Shankar Sastry, and Ruzena Bajcsy", "title": "Experimental Design for Human-in-the-Loop Driving Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes a new experimental setup for human-in-the-loop\nsimulations. A force feedback simulator with four axis motion has been setup\nfor real-time driving experiments. The simulator will move to simulate the\nforces a driver feels while driving, which allows for a realistic experience\nfor the driver. This setup allows for flexibility and control for the\nresearcher in a realistic simulation environment. Experiments concerning driver\ndistraction can also be carried out safely in this test bed, in addition to\nmulti-agent experiments. All necessary code to run the simulator, the\nadditional sensors, and the basic processing is available for use.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 20:05:52 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Driggs-Campbell", "Katherine", ""], ["Bellegarda", "Guillaume", ""], ["Shia", "Victor", ""], ["Sastry", "S. Shankar", ""], ["Bajcsy", "Ruzena", ""]]}, {"id": "1401.5111", "submitter": "Dave Stikkolorum", "authors": "Dave R. Stikkolorum, Michel R.V. Chaudron, Oswald de Bruin", "title": "The Art of Software Design, a Video Game for Learning Software Design\n  Principles", "comments": "Winning paper gamification contest at ACM/IEEE 15th International\n  Conference on Model Driven Engineering Languages and Systems (Models 2012,\n  Innsbruck)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces our gamification of a part of our software design\ncurriculum. Based on typical design principles a motivating learning game is\ndeveloped to train students in software design. We use Bloom's taxonomy to\ndetermine learning objectives. We keep the player engaged with direct feedback\nin a challenging level based game with increasing complexity. Players can\nevaluate their design actions with the help of the visualisation of control and\ndata flows. The main learning objective: applying design principles, fits the\ngame's main activity. This supports the learning by doing approach of\nlecturers. A user test indicates possible learning effects and a playable game.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 22:36:27 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Stikkolorum", "Dave R.", ""], ["Chaudron", "Michel R. V.", ""], ["de Bruin", "Oswald", ""]]}, {"id": "1401.5181", "submitter": "Umer Asgher", "authors": "Fahad Moazzam Dar, Umer Asgher, Daniyal Malik, Emmad Adil, Hassan\n  Shahzad, Anees Ali", "title": "Automation of Prosthetic Upper Limbs for Transhumeral Amputees Using\n  Switch-controlled Motors", "comments": "7 Pages, The International Journal of Soft Computing and Software\n  Engineering [JSCSE], Vol. 3, No. 3, Special Issue The Proceeding of\n  International Conference on Soft Computing and Software Engineering 2013\n  [SCSE 13], San Francisco State University, CA, U.S.A., March 2013", "journal-ref": "The International Journal of Soft Computing and Software\n  Engineering [JSCSE], Vol. 3, No. 3, 2013. e-ISSN: 2251-7545", "doi": "10.7321/jscse.v3.n3.90", "report-no": "e-ISSN: 2251-7545", "categories": "cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The issues of research required in the field of bio medical engineering and\nexternally-powered prostheses are attracting attention of regulatory bodies and\nthe common people in various parts of the globe. Today, 90 percent of\nprostheses used are conventional body powered cable-controlled ones which are\nvery uncomfortable to the amputees as fairly large amount of forces and\nexcursions have to be generated by the amputee. Additionally, its amount of\nrotation is limited. Alternatively, prosthetic limbs driven using electrical\nmotors might deliver added functionality and improved control, accompanied by\nbetter cosmesis, however,it could be bulky and costly. Presently existing\nproposals usually require fewer bodily response and need additional upkeep than\nthe cable operated prosthetic limbs. Due to the motives mentioned, proposal for\nmechanization of body-powered prostheses, with ease of maintenance and cost in\nmind, is presented in this paper. The prosthetic upper limb which is being\nautomated is for Transhumeral type of amputees that is amputated from above\nelbow. The study consists of two main portions: one is lifting mechanism of the\nlimb and the other is gripping mechanism for the hand using switch controls,\nwhich is the most cost effective and optimized solution, rather than using\ncomplex and expensive myoelectric control signals.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 05:26:34 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Dar", "Fahad Moazzam", ""], ["Asgher", "Umer", ""], ["Malik", "Daniyal", ""], ["Adil", "Emmad", ""], ["Shahzad", "Hassan", ""], ["Ali", "Anees", ""]]}, {"id": "1401.5289", "submitter": "Stanislav Simeonov", "authors": "Stanislav Simeonov, Neli Simeonova", "title": "Graphical Interface for Visually Impaired People Based on Bi-stable\n  Solenoids", "comments": "4 pages, 5 figures, The International Journal of Soft Computing and\n  Software Engineering, ISSN:2251-7545", "journal-ref": null, "doi": "10.7321/jscse", "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper a concept for hardware realization of graphic tactile display\nfor visually impaired peoples is presented. For realization of tactile\nactuators bi-stable, solenoids and PIC based control board are used. The\nselected algorithm for series activation of each row of display allows using\nminimal number of active components to set and reset the solenoids. Finally, a\nprogram algorithm of control board is discussed. The project is funded by\nBulgarian National Science Fund NSF Grant D ID 02 14, 2009 2013\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 12:21:48 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Simeonov", "Stanislav", ""], ["Simeonova", "Neli", ""]]}, {"id": "1401.6365", "submitter": "Behnam Faghih", "authors": "Behnam Faghih, Dr. Mohammad Reza Azadehfar, Prof. S. D. Katebi", "title": "User Interface Design for E-Learning Software", "comments": "9 pages", "journal-ref": "International Journal of Soft Computing and Software Engineering\n  [JSCSE], Vol. 3, No. 3, pp. 786-794, 2013", "doi": "10.7321/jscse.v3.n3.119", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User interface (UI) is point of interaction between user and computer\nsoftware. The success and failure of a software application depends on User\nInterface Design (UID). Possibility of using a software, easily using and\nlearning are issues influenced by UID. The UI is significant in designing of\neducational software (e-Learning). Principles and concepts of learning should\nbe considered in addition to UID principles in UID for e-learning. In this\nregard, to specify the logical relationship between education, learning, UID\nand multimedia at first we readdress the issues raised in previous studies. It\nis followed by examining the principle concepts of e-learning and UID. Then, we\nwill see how UID contributes to e-learning through the educational software\nbuilt by authors. Also we show the way of using UI to improve learning and\nmotivating the learners and to improve the time efficiency of using e-learning\nsoftware.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 15:04:05 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Faghih", "Behnam", ""], ["Azadehfar", "Dr. Mohammad Reza", ""], ["Katebi", "Prof. S. D.", ""]]}, {"id": "1401.6679", "submitter": "Robert Jeansoulin", "authors": "Robert Jeansoulin and Nic Wilson", "title": "Quality of Geographic Information: Ontological approach and Artificial\n  Intelligence Tools", "comments": "12 pages, 8th EC-GIS Workshop (European Commission), Dublin, Ireland,\n  July, 3-5, 2002", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective is to present one important aspect of the European IST-FET\nproject \"REV!GIS\"1: the methodology which has been developed for the\ntranslation (interpretation) of the quality of the data into a \"fitness for\nuse\" information, that we can confront to the user needs in its application.\nThis methodology is based upon the notion of \"ontologies\" as a conceptual\nframework able to capture the explicit and implicit knowledge involved in the\napplication. We do not address the general problem of formalizing such\nontologies, instead, we rather try to illustrate this with three applications\nwhich are particular cases of the more general \"data fusion\" problem. In each\napplication, we show how to deploy our methodology, by comparing several\npossible solutions, and we try to enlighten where are the quality issues, and\nwhat kind of solution to privilege, even at the expense of a highly complex\ncomputational approach. The expectation of the REV!GIS project is that\ncomputationally tractable solutions will be available among the next generation\nAI tools.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 18:52:05 GMT"}], "update_date": "2015-01-21", "authors_parsed": [["Jeansoulin", "Robert", ""], ["Wilson", "Nic", ""]]}, {"id": "1401.7193", "submitter": "Hussein Abbass A", "authors": "Antony W. Iorio, Hussein A. Abbass, Svetoslav Gaidow, Axel Bender", "title": "Visualizing Cognitive Moves for Assessing Information Perception Biases\n  in Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In decision making a key source of uncertainty is people's perception of\ninformation which is influenced by their attitudes toward risk. Both,\nperception of information and risk attitude, affect the interpretation of\ninformation and hence the choice of suitable courses of action in a variety of\ncontexts ranging from project planning to military operations. Visualization\nassociated with the dynamics of cognitive states of people processing\ninformation and making decision is therefore not only important for analysis\nbut has also significant practical applications, in particular in the military\ncommand and control domain. In this paper, we focus on a major concept that\naffect human cognition in this context: reliability of information. We\nintroduce Cognitive Move Diagrams (CMD)---a simple visualization tool---to\nrepresent and evaluate the impact of this concept on decision making. We\ndemonstrate through both a hypothetical example and a subject matter expert\nbased experiment that CMD are effective in visualizing, detecting and\nqualifying human biases.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 14:25:15 GMT"}], "update_date": "2014-01-29", "authors_parsed": [["Iorio", "Antony W.", ""], ["Abbass", "Hussein A.", ""], ["Gaidow", "Svetoslav", ""], ["Bender", "Axel", ""]]}, {"id": "1401.7735", "submitter": "Nitesh Goyal", "authors": "Anuj Tewari, Nitesh Goyal, Matthew K Chan, Tina Yau, John Canny, Ulrik\n  Schroeder", "title": "SPRING: speech and pronunciation improvement through games, for Hispanic\n  children", "comments": "ACM ICTD 2010", "journal-ref": null, "doi": "10.1145/2369220.2369265", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of proper English pronunciations is a major problem for immigrant\npopulation in developed countries like U.S. This poses various problems,\nincluding a barrier to entry into mainstream society. This paper presents a\nresearch study that explores the use of speech technologies merged with\nactivity-based and arcade-based games to do pronunciation feedback for Hispanic\nchildren within the U.S. A 3-month long study with immigrant population in\nCalifornia was used to investigate and analyze the effectiveness of computer\naided pronunciation feedback through games. In addition to quantitative\nfindings that point to statistically significant gains in pronunciation\nquality, the paper also explores qualitative findings, interaction patterns and\nchallenges faced by the researchers in dealing with this community. It also\ndescribes the issues involved in dealing with pronunciation as a competency.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 04:50:19 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Tewari", "Anuj", ""], ["Goyal", "Nitesh", ""], ["Chan", "Matthew K", ""], ["Yau", "Tina", ""], ["Canny", "John", ""], ["Schroeder", "Ulrik", ""]]}, {"id": "1401.7821", "submitter": "Stephen Allen", "authors": "Stephen Allen", "title": "Spatial Modelling Techniques in Microsoft Excel", "comments": "9 pages, 5 colour figures, 1 table, Proc. European Spreadsheet Risks\n  Int. Grp. (EuSpRIG) 2013, ISBN: 978-1-9054045-1-3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We begin by considering the expectations of the creators of VisiCalc, the\nfirst spreadsheet. The emphasis is on the nature of the spreadsheet grid. The\ngrid is taken as a presentational method for showing a solution to a Sudoku\npuzzle. We consider methods or approaches for the solution. We look at the\nrelationship between this model and academic papers on the methods for\ndescribing and categorising end-user models generally. We consider whether the\ntype of model described here should be categorised separately. The complexity\nof the model is reviewed in the context of commendations to minimise overly\nsophisticated presentational constructs and formulae.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 12:29:46 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Allen", "Stephen", ""]]}, {"id": "1401.8212", "submitter": "Amin Rasekh", "authors": "Amin Rasekh, Chien-An Chen, Yan Lu", "title": "Human Activity Recognition using Smartphone", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition has wide applications in medical research and\nhuman survey system. In this project, we design a robust activity recognition\nsystem based on a smartphone. The system uses a 3-dimentional smartphone\naccelerometer as the only sensor to collect time series signals, from which 31\nfeatures are generated in both time and frequency domain. Activities are\nclassified using 4 different passive learning methods, i.e., quadratic\nclassifier, k-nearest neighbor algorithm, support vector machine, and\nartificial neural networks. Dimensionality reduction is performed through both\nfeature extraction and subset selection. Besides passive learning, we also\napply active learning algorithms to reduce data labeling expense. Experiment\nresults show that the classification rate of passive learning reaches 84.4% and\nit is robust to common positions and poses of cellphone. The results of active\nlearning on real data demonstrate a reduction of labeling labor to achieve\ncomparable performance with passive learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2014 17:28:10 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["Rasekh", "Amin", ""], ["Chen", "Chien-An", ""], ["Lu", "Yan", ""]]}]