[{"id": "1602.00238", "submitter": "Mar Gonzalez-Franco", "authors": "Jacob Thorn, Rodrigo Pizarro, Bernhard Spanlang, Pablo Bermell-Garcia\n  and Mar Gonzalez-Franco", "title": "Assessing 3D scan quality in Virtual Reality through paired-comparisons\n  psychophysics test", "comments": "9 pages, 10 figures, video: https://youtu.be/vC3Tx07szXU", "journal-ref": "Proceedings of the 2016 ACM on Multimedia Conference (MM '16).\n  ACM, New York, NY, USA, 147-151", "doi": "10.1145/2964284.2967200", "report-no": null, "categories": "cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumer 3D scanners and depth cameras are increasingly being used to\ngenerate content and avatars for Virtual Reality (VR) environments and avoid\nthe inconveniences of hand modeling; however, it is sometimes difficult to\nevaluate quantitatively the mesh quality at which 3D scans should be exported,\nand whether the object perception might be affected by its shading. We propose\nusing a paired-comparisons test based on psychophysics of perception to do that\nevaluation. As psychophysics is not subject to opinion, skill level, mental\nstate, or economic situation it can be considered a quantitative way to measure\nhow people perceive the mesh quality. In particular, we propose using the\npsychophysical measure for the comparison of four different levels of mesh\nquality (1K, 5K, 10K and 20K triangles). We present two studies within\nsubjects: in one we investigate the quality perception variations of seeing an\nobject in a regular screen monitor against an stereoscopic Head Mounted Display\n(HMD); while in the second experiment we aim at detecting the effects of\nshading into quality perception. At each iteration of the pair-test comparisons\nparticipants pick the mesh that they think had higher quality; by the end of\nthe experiment we compile a preference matrix. The matrix evidences the\ncorrelation between real quality and assessed quality. Regarding the shading\nmode, we find an interaction with quality and shading when the model has high\ndefinition. Furthermore, we assess the subjective realism of the most/least\npreferred scans using an Immersive Augmented Reality (IAR) video-see-through\nsetup. Results show higher levels of realism were perceived through the HMD\nthan when using a monitor, although the quality was similarly perceived in both\nsystems.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 12:43:34 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 22:09:27 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Thorn", "Jacob", ""], ["Pizarro", "Rodrigo", ""], ["Spanlang", "Bernhard", ""], ["Bermell-Garcia", "Pablo", ""], ["Gonzalez-Franco", "Mar", ""]]}, {"id": "1602.00251", "submitter": "Kaveh Bakhtiyari", "authors": "Kaveh Bakhtiyari", "title": "Do we have privacy in the digital world?", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.2492.5203/2", "report-no": null, "categories": "cs.CR cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not really.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 14:22:47 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 15:53:55 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Bakhtiyari", "Kaveh", ""]]}, {"id": "1602.00370", "submitter": "Jian Tang", "authors": "Jian Tang, Jingzhou Liu, Ming Zhang and Qiaozhu Mei", "title": "Visualizing Large-scale and High-dimensional Data", "comments": "WWW 2016", "journal-ref": null, "doi": "10.1145/2872427.2883041", "report-no": null, "categories": "cs.LG cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of visualizing large-scale and high-dimensional data in\na low-dimensional (typically 2D or 3D) space. Much success has been reported\nrecently by techniques that first compute a similarity structure of the data\npoints and then project them into a low-dimensional space with the structure\npreserved. These two steps suffer from considerable computational costs,\npreventing the state-of-the-art methods such as the t-SNE from scaling to\nlarge-scale and high-dimensional data (e.g., millions of data points and\nhundreds of dimensions). We propose the LargeVis, a technique that first\nconstructs an accurately approximated K-nearest neighbor graph from the data\nand then layouts the graph in the low-dimensional space. Comparing to t-SNE,\nLargeVis significantly reduces the computational cost of the graph construction\nstep and employs a principled probabilistic model for the visualization step,\nthe objective of which can be effectively optimized through asynchronous\nstochastic gradient descent with a linear time complexity. The whole procedure\nthus easily scales to millions of high-dimensional data points. Experimental\nresults on real-world data sets demonstrate that the LargeVis outperforms the\nstate-of-the-art methods in both efficiency and effectiveness. The\nhyper-parameters of LargeVis are also much more stable over different data\nsets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 03:01:33 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 03:59:57 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Tang", "Jian", ""], ["Liu", "Jingzhou", ""], ["Zhang", "Ming", ""], ["Mei", "Qiaozhu", ""]]}, {"id": "1602.00801", "submitter": "Zhiyan Li", "authors": "Zhiyan Li", "title": "A Novel Human Computer Interaction Platform based College Mathematical\n  Education Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes the analysis on novel human computer interaction (HCI)\nplatform based college mathematical education methodology. Above for the\napplication of virtual reality technology in teaching the problems in the\nstudy, only through the organization focus on the professional and technical\npersonnel, and constantly improve researchers in development process of\nprofessional knowledge, close to the actual needs of the teaching can we\nachieve the satisfactory result. To obtain better education output, we combine\nthe Kinect to form the HCI based teaching environment. We firstly review the\nlatest HCI technique and principles of college math courses, then we introduce\nbasic components of the Kinect including the gesture segmentation, systematic\nimplementation and the primary characteristics of the platform. As the further\nstep, we implement the system with the re-write of script code to build up the\npersonalized HCI assisted education scenario. The verification and simulation\nproves the feasibility of our method.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 06:26:37 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2016 08:07:14 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Li", "Zhiyan", ""]]}, {"id": "1602.00804", "submitter": "Zhiyan Li", "authors": "Yang Yang, Zhiyan Li", "title": "Research on Information Security Enhancement Approaches and the\n  Applications on HCI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid development of computer techniques, the human computer interaction\nscenarios are becoming more and more frequent. The development history of the\nhuman-computer interaction is from a person to adapt to the computer to the\ncomputer and continually adapt to the rapid development. Facing the process of\nhuman-computer interaction, information system daily operation to produce huge\namounts of data, how to ensure human-computer interaction interface clear,\ngenerated data safe and reliable, has become a problem to be solved in the\nworld of information. To deal with the challenging, we propose the information\nsecurity enhancement approaches and the core applications on HCI systems.\nThrough reviewing the other state-of-the-art methods, we propose the data\nencryption system to deal with the issues that uses mixed encryption system to\nmake full use of the symmetric cipher algorithm encryption speed and encryption\nintensity is high while the encryption of large amounts of data efficiently.\nOur method could enhance the general safety of the HCI system, the experimental\nresult verities the feasibility and general robustness of our approach.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 06:36:39 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Yang", "Yang", ""], ["Li", "Zhiyan", ""]]}, {"id": "1602.00831", "submitter": "Paul Issartel", "authors": "Paul Issartel (LIMSI), Florimond Gu\\'eniat (FSU), Sabine Coquillart\n  (PRIMA), Mehdi Ammi (LIMSI)", "title": "Perceiving Mass in Mixed Reality through Pseudo-Haptic Rendering of\n  Newton's Third Law", "comments": null, "journal-ref": null, "doi": "10.1109/VR.2015.7223322", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mixed reality, real objects can be used to interact with virtual objects.\nHowever, unlike in the real world, real objects do not encounter any opposite\nreaction force when pushing against virtual objects. The lack of reaction force\nduring manipulation prevents users from perceiving the mass of virtual objects.\nAlthough this could be addressed by equipping real objects with force-feedback\ndevices, such a solution remains complex and impractical.In this work, we\npresent a technique to produce an illusion of mass without any active\nforce-feedback mechanism. This is achieved by simulating the effects of this\nreaction force in a purely visual way. A first study demonstrates that our\ntechnique indeed allows users to differentiate light virtual objects from heavy\nvirtual objects. In addition, it shows that the illusion is immediately\neffective, with no prior training. In a second study, we measure the lowest\nmass difference (JND) that can be perceived with this technique. The\neffectiveness and ease of implementation of our solution provides an\nopportunity to enhance mixed reality interaction at no additional cost.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 08:53:44 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Issartel", "Paul", "", "LIMSI"], ["Gu\u00e9niat", "Florimond", "", "FSU"], ["Coquillart", "Sabine", "", "PRIMA"], ["Ammi", "Mehdi", "", "LIMSI"]]}, {"id": "1602.00904", "submitter": "Vangelis Oikonomou", "authors": "Vangelis P. Oikonomou, Georgios Liaros, Kostantinos Georgiadis,\n  Elisavet Chatzilari, Katerina Adam, Spiros Nikolopoulos and Ioannis\n  Kompatsiaris", "title": "Comparative evaluation of state-of-the-art algorithms for SSVEP-based\n  BCIs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interfaces (BCIs) have been gaining momentum in making\nhuman-computer interaction more natural, especially for people with\nneuro-muscular disabilities. Among the existing solutions the systems relying\non electroencephalograms (EEG) occupy the most prominent place due to their\nnon-invasiveness. However, the process of translating EEG signals into computer\ncommands is far from trivial, since it requires the optimization of many\ndifferent parameters that need to be tuned jointly. In this report, we focus on\nthe category of EEG-based BCIs that rely on Steady-State-Visual-Evoked\nPotentials (SSVEPs) and perform a comparative evaluation of the most promising\nalgorithms existing in the literature. More specifically, we define a set of\nalgorithms for each of the various different parameters composing a BCI system\n(i.e. filtering, artifact removal, feature extraction, feature selection and\nclassification) and study each parameter independently by keeping all other\nparameters fixed. The results obtained from this evaluation process are\nprovided together with a dataset consisting of the 256-channel, EEG signals of\n11 subjects, as well as a processing toolbox for reproducing the results and\nsupporting further experimentation. In this way, we manage to make available\nfor the community a state-of-the-art baseline for SSVEP-based BCIs that can be\nused as a basis for introducing novel methods and approaches.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 12:31:48 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2016 09:59:44 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Oikonomou", "Vangelis P.", ""], ["Liaros", "Georgios", ""], ["Georgiadis", "Kostantinos", ""], ["Chatzilari", "Elisavet", ""], ["Adam", "Katerina", ""], ["Nikolopoulos", "Spiros", ""], ["Kompatsiaris", "Ioannis", ""]]}, {"id": "1602.00985", "submitter": "Pouya Bashivan", "authors": "Pouya Bashivan, Irina Rish, Steve Heisig", "title": "Mental State Recognition via Wearable EEG", "comments": "Presented at MLINI-2015 workshop, 2015 (arXiv:cs/0101200)", "journal-ref": "Proceedings of 5th NIPS workshop on Machine Learning and\n  Interpretation in Neuroimaging (MLINI15) (2015) 5-1", "doi": null, "report-no": "MLINI/2015/20", "categories": "cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing quality and affordability of consumer electroencephalogram\n(EEG) headsets make them attractive for situations where medical grade devices\nare impractical. Predicting and tracking cognitive states is possible for tasks\nthat were previously not conducive to EEG monitoring. For instance, monitoring\noperators for states inappropriate to the task (e.g. drowsy drivers), tracking\nmental health (e.g. anxiety) and productivity (e.g. tiredness) are among\npossible applications for the technology. Consumer grade EEG headsets are\naffordable and relatively easy to use, but they lack the resolution and quality\nof signal that can be achieved using medical grade EEG devices. Thus, the key\nquestions remain: to what extent are wearable EEG devices capable of mental\nstate recognition, and what kind of mental states can be accurately recognized\nwith these devices? In this work, we examined responses to two different types\nof input: instructional (logical) versus recreational (emotional) videos, using\na range of machine-learning methods. We tried SVMs, sparse logistic regression,\nand Deep Belief Networks, to discriminate between the states of mind induced by\ndifferent types of video input, that can be roughly labeled as logical vs.\nemotional. Our results demonstrate a significant potential of wearable EEG\ndevices in differentiating cognitive states between situations with large\ncontextual but subtle apparent differences.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 15:55:20 GMT"}, {"version": "v2", "created": "Sun, 5 Jun 2016 14:18:48 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Bashivan", "Pouya", ""], ["Rish", "Irina", ""], ["Heisig", "Steve", ""]]}, {"id": "1602.01944", "submitter": "Mar Gonzalez-Franco", "authors": "Mar Gonzalez-Franco, Julio Cermeron, Katie Li, Rodrigo Pizarro, Jacob\n  Thorn, Windo Hutabarat, Ashutosh Tiwari, Pablo Bermell-Garcia", "title": "Immersive Augmented Reality Training for Complex Manufacturing Scenarios", "comments": "6 pages, 4 figures, Video: https://youtu.be/xCbvmGkL6Y4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the complex manufacturing sector a considerable amount of resources are\nfocused on developing new skills and training workers. In that context,\nincreasing the effectiveness of those processes and reducing the investment\nrequired is an outstanding issue. In this paper we present an experiment that\nshows how modern Human Computer Interaction (HCI) metaphors such as\ncollaborative mixed-reality can be used to transmit procedural knowledge and\ncould eventually replace other forms of face-to-face training. We implement a\nreal-time Immersive Augmented Reality (IAR) setup with see-through cameras that\nallows for collaborative interactions that can simulate conventional forms of\ntraining. The obtained results indicate that people who took the IAR training\nachieved the same performance than people in the conventional face-to-face\ntraining condition. These results, their implications for future training and\nthe use of HCI paradigms in this context are discussed in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 07:50:25 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 19:04:01 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Gonzalez-Franco", "Mar", ""], ["Cermeron", "Julio", ""], ["Li", "Katie", ""], ["Pizarro", "Rodrigo", ""], ["Thorn", "Jacob", ""], ["Hutabarat", "Windo", ""], ["Tiwari", "Ashutosh", ""], ["Bermell-Garcia", "Pablo", ""]]}, {"id": "1602.02574", "submitter": "Lo Lo", "authors": "Lo\\\"ic Sevrin, Norbert Noury, Nacer Abouchi, Fabrice Jumel, Bertrand\n  Massot, Jacques Saraydaryan", "title": "Characterization of a Multi-User Indoor Positioning System Based on Low\n  Cost Depth Vision (Kinect) for Monitoring Human Activity in a Smart Home", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of systems use indoor positioning for many scenarios\nsuch as asset tracking, health care, games, manufacturing, logistics, shopping,\nand security. Many technologies are available and the use of depth cameras is\nbecoming more and more attractive as this kind of device becomes affordable and\neasy to handle. This paper contributes to the effort of creating an indoor\npositioning system based on low cost depth cameras (Kinect). A method is\nproposed to optimize the calibration of the depth cameras, to describe the\nmulti-camera data fusion and to specify a global positioning projection to\nmaintain the compatibility with outdoor positioning systems.\n  The monitoring of the people trajectories at home is intended for the early\ndetection of a shift in daily activities which highlights disabilities and loss\nof autonomy. This system is meant to improve homecare health management at home\nfor a better end of life at a sustainable cost for the community.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 14:14:49 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Sevrin", "Lo\u00efc", ""], ["Noury", "Norbert", ""], ["Abouchi", "Nacer", ""], ["Jumel", "Fabrice", ""], ["Massot", "Bertrand", ""], ["Saraydaryan", "Jacques", ""]]}, {"id": "1602.02665", "submitter": "Bruno Gon\\c{c}alves", "authors": "Johan Bollen, Bruno Gon\\c{c}alves, Ingrid van de Leemput, Guangchen\n  Ruan", "title": "The happiness paradox: your friends are happier than you", "comments": "15 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most individuals in social networks experience a so-called Friendship\nParadox: they are less popular than their friends on average. This effect may\nexplain recent findings that widespread social network media use leads to\nreduced happiness. However the relation between popularity and happiness is\npoorly understood. A Friendship paradox does not necessarily imply a Happiness\nparadox where most individuals are less happy than their friends. Here we\nreport the first direct observation of a significant Happiness Paradox in a\nlarge-scale online social network of $39,110$ Twitter users. Our results reveal\nthat popular individuals are indeed happier and that a majority of individuals\nexperience a significant Happiness paradox. The magnitude of the latter effect\nis shaped by complex interactions between individual popularity, happiness, and\nthe fact that users cluster assortatively by level of happiness. Our results\nindicate that the topology of online social networks and the distribution of\nhappiness in some populations can cause widespread psycho-social effects that\naffect the well-being of billions of individuals.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 17:46:18 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Bollen", "Johan", ""], ["Gon\u00e7alves", "Bruno", ""], ["van de Leemput", "Ingrid", ""], ["Ruan", "Guangchen", ""]]}, {"id": "1602.03277", "submitter": "Yuan Liu", "authors": "Yuan Liu and Chunyan Miao", "title": "A Survey of Incentives and Mechanism Design for Human Computation\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human computation systems (HCSs) have been widely adopted in various domains.\nTheir goal is to harness human intelligence to solve computational problems\nthat are beyond the capability of modern computers. One of the most challenging\nproblems in HCSs is how to incentivize a broad range of users to participate in\nthe system and make high efforts. This article surveys the field of HCSs from\nthe perspective of incentives and mechanism design. We first review\nstate-of-the-art HCSs, focusing on how incentives are provided to users. We\nthen use mechanism design to theoretically analyze different incentives. We\nsurvey the mechanisms derived from state-of-the-art HCSs as well as classic\nmechanisms that have been used in HCSs. Finally, we discuss eight promising\nresearch directions for designing incentives in HCSs.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 06:25:57 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Liu", "Yuan", ""], ["Miao", "Chunyan", ""]]}, {"id": "1602.03291", "submitter": "Habibur Rahman", "authors": "Habibur Rahman and Lucas Joppa and Senjuti Basu Roy", "title": "Feature Based Task Recommendation in Crowdsourcing with Implicit\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research in crowdsourcing has investigated how to recommend tasks to\nworkers based on which task the workers have already completed, referred to as\n{\\em implicit feedback}. We, on the other hand, investigate the task\nrecommendation problem, where we leverage both implicit feedback and explicit\nfeatures of the task. We assume that we are given a set of workers, a set of\ntasks, interactions (such as the number of times a worker has completed a\nparticular task), and the presence of explicit features of each task (such as,\ntask location). We intend to recommend tasks to the workers by exploiting the\nimplicit interactions, and the presence or absence of explicit features in the\ntasks. We formalize the problem as an optimization problem, propose two\nalternative problem formulations and respective solutions that exploit implicit\nfeedback, explicit features, as well as similarity between the tasks. We\ncompare the efficacy of our proposed solutions against multiple\nstate-of-the-art techniques using two large scale real world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 08:06:32 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2016 05:13:51 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Rahman", "Habibur", ""], ["Joppa", "Lucas", ""], ["Roy", "Senjuti Basu", ""]]}, {"id": "1602.03481", "submitter": "Sewoong Oh", "authors": "Ashish Khetan and Sewoong Oh", "title": "Achieving Budget-optimality with Adaptive Schemes in Crowdsourcing", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing platforms provide marketplaces where task requesters can pay to\nget labels on their data. Such markets have emerged recently as popular venues\nfor collecting annotations that are crucial in training machine learning models\nin various applications. However, as jobs are tedious and payments are low,\nerrors are common in such crowdsourced labels. A common strategy to overcome\nsuch noise in the answers is to add redundancy by getting multiple answers for\neach task and aggregating them using some methods such as majority voting. For\nsuch a system, there is a fundamental question of interest: how can we maximize\nthe accuracy given a fixed budget on how many responses we can collect on the\ncrowdsourcing system. We characterize this fundamental trade-off between the\nbudget (how many answers the requester can collect in total) and the accuracy\nin the estimated labels. In particular, we ask whether adaptive task assignment\nschemes lead to a more efficient trade-off between the accuracy and the budget.\n  Adaptive schemes, where tasks are assigned adaptively based on the data\ncollected thus far, are widely used in practical crowdsourcing systems to\nefficiently use a given fixed budget. However, existing theoretical analyses of\ncrowdsourcing systems suggest that the gain of adaptive task assignments is\nminimal. To bridge this gap, we investigate this question under a strictly more\ngeneral probabilistic model, which has been recently introduced to model\npractical crowdsourced annotations. Under this generalized Dawid-Skene model,\nwe characterize the fundamental trade-off between budget and accuracy. We\nintroduce a novel adaptive scheme that matches this fundamental limit. We\nfurther quantify the fundamental gap between adaptive and non-adaptive schemes,\nby comparing the trade-off with the one for non-adaptive schemes. Our analyses\nconfirm that the gap is significant.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 18:46:30 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 04:31:25 GMT"}, {"version": "v3", "created": "Fri, 25 Aug 2017 16:35:55 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Khetan", "Ashish", ""], ["Oh", "Sewoong", ""]]}, {"id": "1602.03742", "submitter": "Carlos Palma", "authors": "Carlos Palma, Augusto Salazar, Francisco Vargas", "title": "HMM and DTW for evaluation of therapeutical gestures using kinect", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic recognition of the quality of movement in human beings is a\nchallenging task, given the difficulty both in defining the constraints that\nmake a movement correct, and the difficulty in using noisy data to determine if\nthese constraints were satisfied. This paper presents a method for the\ndetection of deviations from the correct form in movements from physical\ntherapy routines based on Hidden Markov Models, which is compared to Dynamic\nTime Warping. The activities studied include upper an lower limbs movements,\nthe data used comes from a Kinect sensor. Correct repetitions of the activities\nof interest were recorded, as well as deviations from these correct forms. The\nability of the proposed approach to detect these deviations was studied.\nResults show that a system based on HMM is much more likely to determine if a\ncertain movement has deviated from the specification.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 14:22:26 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Palma", "Carlos", ""], ["Salazar", "Augusto", ""], ["Vargas", "Francisco", ""]]}, {"id": "1602.03757", "submitter": "Didier Fass", "authors": "R\\'emi Nazin (MOSEL), Didier Fass (MOSEL)", "title": "Human Machine Epistemology Survey", "comments": null, "journal-ref": "Vincent G. Duffy. HCI Interantional 2016, Aug 2015, Los Angeles,\n  United States. Springer, LNCS 9184, pp.12, 2015, Digital Human Modeling.\n  Applications in Health, Safety, Ergonomics and Risk Management: Human\n  Modeling", "doi": "10.1007/978-3-319-21073-5_35", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pluridisciplinar convergence is a major problem that had emerged with\nHuman-Artefact Systems and so-called \" Augmented Humanity \" as academical\nfields and even more as technical fields. Problems come mainly from the\njuxtaposition of two very different types of system, a biological one and an\nartificial one. Thus, conceiving and designing the multiple couplings between\nthem has become a major difficulty. Some came with reductionnist solutions to\nanswer these problems but since we know that a biological system and a\ntechnical system are different, this approach is limited from its beginning.\nUsing a specifically designed questionnaire and statistical analysis we\ndetermined how specialists (medical practitioners, ergonomists and engineers)\nin the domain conceive themselves what is a Human-Artifact System and how they\nrelate to existent traditions and showed that some of them relate to the\nintegrativist views.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 18:31:17 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Nazin", "R\u00e9mi", "", "MOSEL"], ["Fass", "Didier", "", "MOSEL"]]}, {"id": "1602.03814", "submitter": "Vasanth Sarathy", "authors": "Vasanth Sarathy, Jason R. Wilson, Thomas Arnold and Matthias Scheutz", "title": "Enabling Basic Normative HRI in a Cognitive Robotic Architecture", "comments": "Presented at \"2nd Workshop on Cognitive Architectures for Social\n  Human-Robot Interaction 2016 (arXiv:1602.01868)\"", "journal-ref": null, "doi": null, "report-no": "CogArch4sHRI/2016/04", "categories": "cs.RO cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative human activities are grounded in social and moral norms, which\nhumans consciously and subconsciously use to guide and constrain their\ndecision-making and behavior, thereby strengthening their interactions and\npreventing emotional and physical harm. This type of norm-based processing is\nalso critical for robots in many human-robot interaction scenarios (e.g., when\nhelping elderly and disabled persons in assisted living facilities, or\nassisting humans in assembly tasks in factories or even the space station). In\nthis position paper, we will briefly describe how several components in an\nintegrated cognitive architecture can be used to implement processes that are\nrequired for normative human-robot interactions, especially in collaborative\ntasks where actions and situations could potentially be perceived as\nthreatening and thus need a change in course of action to mitigate the\nperceived threats.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 18:18:14 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Sarathy", "Vasanth", ""], ["Wilson", "Jason R.", ""], ["Arnold", "Thomas", ""], ["Scheutz", "Matthias", ""]]}, {"id": "1602.03956", "submitter": "Daniel Filipe Farinha", "authors": "Daniel Filipe G. Farinha", "title": "Grokya: a Privacy-Friendly Framework for Ubiquitous Computing", "comments": "Master thesis", "journal-ref": null, "doi": "10.13140/RG.2.1.2452.3281", "report-no": null, "categories": "cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a world where for-profit enterprises are increasingly looking to maximize\nprofits by engaging in privacy invading consumer-profiling techniques, the rise\nof ubiquitous computing and the Internet of Things (IoT) poses a major problem.\nIf not acted upon quickly, the combination of Big Data with IoT will explode\ninto a dystopian world that even George Orwell could not have predicted. The\nproposed project aims to fill a gap that no other solution is addressing, which\nis to reach a win-win scenario that works for both the enterprises and the\nconsumers. It aims to do this by creating the building blocks for a consumer\nowned infrastructure that can provide both privacy for the user, and still\nenable the enterprises to achieve their high-level goals.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 03:18:47 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2016 07:19:01 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Farinha", "Daniel Filipe G.", ""]]}, {"id": "1602.04032", "submitter": "Satyanath Bhat", "authors": "Satyanath Bhat and Divya Padmanabhan and Shweta Jain and Y Narahari", "title": "A Truthful Mechanism with Biparameter Learning for Online Crowdsourcing", "comments": "To appear as Extended Abstract in AAMAS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a problem of allocating divisible jobs, arriving online, to workers\nin a crowdsourcing setting which involves learning two parameters of\nstrategically behaving workers. Each job is split into a certain number of\ntasks that are then allocated to workers. Each arriving job has to be completed\nwithin a deadline and each task has to be completed satisfying an upper bound\non probability of failure. The job population is homogeneous while the workers\nare heterogeneous in terms of costs, completion times, and times to failure.\nThe job completion time and time to failure of each worker are stochastic with\nfixed but unknown means. The requester is faced with the challenge of learning\ntwo separate parameters of each (strategically behaving) worker simultaneously,\nnamely, the mean job completion time and the mean time to failure. The time to\nfailure of a worker depends on the duration of the task handled by the worker.\nAssuming non-strategic workers to start with, we solve this biparameter\nlearning problem by applying the Robust UCB algorithm. Then, we non-trivially\nextend this algorithm to the setting where the workers are strategic about\ntheir costs. Our proposed mechanism is dominant strategy incentive compatible\nand ex-post individually rational with asymptotically optimal regret\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 12:36:13 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Bhat", "Satyanath", ""], ["Padmanabhan", "Divya", ""], ["Jain", "Shweta", ""], ["Narahari", "Y", ""]]}, {"id": "1602.04281", "submitter": "Nicholas Bolten", "authors": "Nicholas Bolten, Amirhossein Amini, Yun Hao, Vaishnavi Ravichandran,\n  Andre Stephens, Anat Caspi", "title": "Urban sidewalks: visualization and routing for individuals with limited\n  mobility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People with limited mobility in the U.S. (defined as having difficulty or\ninability to walk a quarter of a mile without help and without the use of\nspecial equipment) face a growing informational gap: while pedestrian routing\nalgorithms are getting faster and more informative, planning a route with a\nwheeled device in urban centers is very difficult due to lack of integrated\npertinent information regarding accessibility along the route. Moreover,\nreducing access to street-spaces translates to reduced access to other public\ninformation and services that are increasingly made available to the public\nalong urban streets. To adequately plan a commute, a traveler with limited or\nwheeled mobility must know whether her path may be blocked by construction,\nwhether the sidewalk would be too steep or rendered unusable due to poor\nconditions, whether the street can be crossed or a highway is blocking the way,\nor whether there is a sidewalk at all. These details populate different\ndatasets in many modern municipalities, but they are not immediately available\nin a convenient, integrated format to be useful to people with limited\nmobility. Our project, AccessMap, in its first phase (v.1) overlayed the\ninformation that is most relevant to people with limited mobility on a map,\nenabling self-planning of routes. Here, we describe the next phase of the\nproject: synthesizing commonly available open data (including streets,\nsidewalks, curb ramps, elevation data, and construction permit information) to\ngenerate a graph of paths to enable variable cost-function accessible routing.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 03:42:17 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Bolten", "Nicholas", ""], ["Amini", "Amirhossein", ""], ["Hao", "Yun", ""], ["Ravichandran", "Vaishnavi", ""], ["Stephens", "Andre", ""], ["Caspi", "Anat", ""]]}, {"id": "1602.04506", "submitter": "Ranjay Krishna", "authors": "Ranjay Krishna, Kenji Hata, Stephanie Chen, Joshua Kravitz, David A.\n  Shamma, Li Fei-Fei, Michael S. Bernstein", "title": "Embracing Error to Enable Rapid Crowdsourcing", "comments": "10 pages, 7 figures, CHI '16, CHI: ACM Conference on Human Factors in\n  Computing Systems (2016)", "journal-ref": null, "doi": "10.1145/2858036.2858115", "report-no": null, "categories": "cs.HC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microtask crowdsourcing has enabled dataset advances in social science and\nmachine learning, but existing crowdsourcing schemes are too expensive to scale\nup with the expanding volume of data. To scale and widen the applicability of\ncrowdsourcing, we present a technique that produces extremely rapid judgments\nfor binary and categorical labels. Rather than punishing all errors, which\ncauses workers to proceed slowly and deliberately, our technique speeds up\nworkers' judgments to the point where errors are acceptable and even expected.\nWe demonstrate that it is possible to rectify these errors by randomizing task\norder and modeling response latency. We evaluate our technique on a breadth of\ncommon labeling tasks such as image verification, word similarity, sentiment\nanalysis and topic classification. Where prior work typically achieves a 0.25x\nto 1x speedup over fixed majority vote, our approach often achieves an order of\nmagnitude (10x) speedup.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 20:56:01 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Krishna", "Ranjay", ""], ["Hata", "Kenji", ""], ["Chen", "Stephanie", ""], ["Kravitz", "Joshua", ""], ["Shamma", "David A.", ""], ["Fei-Fei", "Li", ""], ["Bernstein", "Michael S.", ""]]}, {"id": "1602.04529", "submitter": "Jonathan Vitale", "authors": "Jonathan Vitale, Mary-Anne Williams, Benjamin Johnston", "title": "Socially Impaired Robots: Human Social Disorders and Robots'\n  Socio-Emotional Intelligence", "comments": "International Conference on Social Robotics 2014", "journal-ref": null, "doi": "10.1007/978-3-319-11973-1_36", "report-no": null, "categories": "cs.RO cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social robots need intelligence in order to safely coexist and interact with\nhumans. Robots without functional abilities in understanding others and unable\nto empathise might be a societal risk and they may lead to a society of\nsocially impaired robots. In this work we provide a survey of three relevant\nhuman social disorders, namely autism, psychopathy and schizophrenia, as a\nmeans to gain a better understanding of social robots' future capability\nrequirements. We provide evidence supporting the idea that social robots will\nrequire a combination of emotional intelligence and social intelligence, namely\nsocio-emotional intelligence. We argue that a robot with a simple\nsocio-emotional process requires a simulation-driven model of intelligence.\nFinally, we provide some critical guidelines for designing future\nsocio-emotional robots.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 00:06:34 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Vitale", "Jonathan", ""], ["Williams", "Mary-Anne", ""], ["Johnston", "Benjamin", ""]]}, {"id": "1602.04841", "submitter": "Matthew Howard", "authors": "R. B. Ribas Manero and J. Grewal and B. Michael and A. Shafti and K.\n  Althoefer and J. Ll. Ribas Fernandez and M. J. Howard", "title": "Wearable Embroidered Muscle Activity Sensing Device for the Human Upper\n  Leg", "comments": "Preprint submitted to IEEE-EMBC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the last decade, running has become one of the most popular physical\nactivities in the world. Although the benefits of running are numerous, there\nis a risk of Running Related Injuries (RRI) of the lower extremities.\nElectromyography (EMG) techniques have previously been used to study causes of\nRRIs, but the complexity of this technology limits its use to a laboratory\nsetting. As running is primarily an outdoors activity, this lack of technology\nacts as a barrier to the study of RRIs in natural environments. This study\npresents a minimally invasive wearable muscle sensing device consisting of\njogging leggings with embroidered surface EMG (sEMG) electrodes capable of\nrecording muscle activity data of the quadriceps group. To test the use of the\ndevice, a proof of concept study consisting of $N=2$ runners performing a set\nof $5km$ running trials is presented in which the effect of running surfaces on\nmuscle fatigue, a potential cause of RRIs, is evaluated. Results show that\nmuscle fatigue can be analysed from the sEMG data obtained through the wearable\ndevice, and that running on soft surfaces (such as sand) may increase the\nlikelihood of suffering from RRIs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 21:23:09 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Manero", "R. B. Ribas", ""], ["Grewal", "J.", ""], ["Michael", "B.", ""], ["Shafti", "A.", ""], ["Althoefer", "K.", ""], ["Fernandez", "J. Ll. Ribas", ""], ["Howard", "M. J.", ""]]}, {"id": "1602.04983", "submitter": "Sreyasi Nag Chowdhury", "authors": "Sreyasi Nag Chowdhury, Mateusz Malinowski, Andreas Bulling, Mario\n  Fritz", "title": "Contextual Media Retrieval Using Natural Language Queries", "comments": "8 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread integration of cameras in hand-held and head-worn devices as\nwell as the ability to share content online enables a large and diverse visual\ncapture of the world that millions of users build up collectively every day. We\nenvision these images as well as associated meta information, such as GPS\ncoordinates and timestamps, to form a collective visual memory that can be\nqueried while automatically taking the ever-changing context of mobile users\ninto account. As a first step towards this vision, in this work we present\nXplore-M-Ego: a novel media retrieval system that allows users to query a\ndynamic database of images and videos using spatio-temporal natural language\nqueries. We evaluate our system using a new dataset of real user queries as\nwell as through a usability study. One key finding is that there is a\nconsiderable amount of inter-user variability, for example in the resolution of\nspatial relations in natural language utterances. We show that our retrieval\nsystem can cope with this variability using personalisation through an online\nlearning-based retrieval formulation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 11:04:29 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Chowdhury", "Sreyasi Nag", ""], ["Malinowski", "Mateusz", ""], ["Bulling", "Andreas", ""], ["Fritz", "Mario", ""]]}, {"id": "1602.05109", "submitter": "Chakib Tadj", "authors": "Somia Belaidouni, Moeiz Miraoui, Chakib Tadj", "title": "Towards an Efficient Smart Space Architecture", "comments": null, "journal-ref": "International Journal of Advanced Studies in Computer Science and\n  Engineering, IJASCSE, Volume 5, Issue 1, 2016", "doi": null, "report-no": null, "categories": "cs.CY cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A smart space offers entirely new opportunities for end users by adapting\nservices accordingly to make life easy. A number of architectural designs have\nbeen proposed to design context awareness systems and adaptation behavior.\nHowever, the quality of the system depends on the degree of satisfaction of the\ninitials needs. In this paper, we discuss three main indicators of quality\ndesign for smart spaces that are strongly related to the context modules and\nreasoning process: functionality, reusability and changeability. A general\nlayered architecture system is presented to define the principal components\nthat should constitute any context aware adaptive system.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 16:45:10 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Belaidouni", "Somia", ""], ["Miraoui", "Moeiz", ""], ["Tadj", "Chakib", ""]]}, {"id": "1602.05751", "submitter": "Federico Cabitza", "authors": "Federico Cabitza and Angela Locoro", "title": "Human-Data Interaction in Healthcare", "comments": "10 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we focus on an emerging strand of IT-oriented research, namely\nHuman-Data Interaction (HDI) and how this can be applied to healthcare. HDI\nregards both how humans create and use data by means of interactive systems,\nwhich can both assist and constrain them, as well as to passively collect and\nproactively generate data. Healthcare provides a challenging arena to test the\npotential of HDI to provide a new, user-centered perspective on how data work\nshould be supported and assessed, especially in the light of the fact that data\nare becoming increasingly big and that many tools are now available for the lay\npeople, including doctors and nurses, to interact with health-related data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 10:49:47 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 15:48:14 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Cabitza", "Federico", ""], ["Locoro", "Angela", ""]]}, {"id": "1602.05753", "submitter": "Toma\\v{z} Erjavec", "authors": "Mark A. Finlayson and Toma\\v{z} Erjavec", "title": "Overview of Annotation Creation: Processes & Tools", "comments": "To appear in: James Pustejovsky and Nancy Ide (eds.) \"Handbook of\n  Linguistic Annotation.\" 2016. New York: Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating linguistic annotations requires more than just a reliable annotation\nscheme. Annotation can be a complex endeavour potentially involving many\npeople, stages, and tools. This chapter outlines the process of creating\nend-to-end linguistic annotations, identifying specific tasks that researchers\noften perform. Because tool support is so central to achieving high quality,\nreusable annotations with low cost, the focus is on identifying capabilities\nthat are necessary or useful for annotation tools, as well as common problems\nthese tools present that reduce their utility. Although examples of specific\ntools are provided in many cases, this chapter concentrates more on abstract\ncapabilities and problems because new tools appear continuously, while old\ntools disappear into disuse or disrepair. The two core capabilities tools must\nhave are support for the chosen annotation scheme and the ability to work on\nthe language under study. Additional capabilities are organized into three\ncategories: those that are widely provided; those that often useful but found\nin only a few tools; and those that have as yet little or no available tool\nsupport.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 10:56:46 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Finlayson", "Mark A.", ""], ["Erjavec", "Toma\u017e", ""]]}, {"id": "1602.06401", "submitter": "Nikos Bikakis", "authors": "Nikos Bikakis, John Liagouris, Maria Krommyda, George Papastefanatos,\n  Timos Sellis", "title": "graphVizdb: A Scalable Platform for Interactive Large Graph\n  Visualization", "comments": "32nd IEEE International Conference on Data Engineering (ICDE '16)", "journal-ref": null, "doi": "10.1109/ICDE.2016.7498340", "report-no": null, "categories": "cs.HC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel platform for the interactive visualization of very large\ngraphs. The platform enables the user to interact with the visualized graph in\na way that is very similar to the exploration of maps at multiple levels. Our\napproach involves an offline preprocessing phase that builds the layout of the\ngraph by assigning coordinates to its nodes with respect to a Euclidean plane.\nThe respective points are indexed with a spatial data structure, i.e., an\nR-tree, and stored in a database. Multiple abstraction layers of the graph\nbased on various criteria are also created offline, and they are indexed\nsimilarly so that the user can explore the dataset at different levels of\ngranularity, depending on her particular needs. Then, our system translates\nuser operations into simple and very efficient spatial operations (i.e., window\nqueries) in the backend. This technique allows for a fine-grained access to\nvery large graphs with extremely low latency and memory requirements and\nwithout compromising the functionality of the tool. Our web-based prototype\nsupports three main operations: (1) interactive navigation, (2) multi-level\nexploration, and (3) keyword search on the graph metadata.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 12:49:09 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Bikakis", "Nikos", ""], ["Liagouris", "John", ""], ["Krommyda", "Maria", ""], ["Papastefanatos", "George", ""], ["Sellis", "Timos", ""]]}, {"id": "1602.06634", "submitter": "Niloufar Salehi", "authors": "Ryo Suzuki, Niloufar Salehi, Michelle S. Lam, Juan C. Marroquin,\n  Michael S. Bernstein", "title": "Atelier: Repurposing Expert Crowdsourcing Tasks as Micro-internships", "comments": "CHI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert crowdsourcing marketplaces have untapped potential to empower workers'\ncareer and skill development. Currently, many workers cannot afford to invest\nthe time and sacrifice the earnings required to learn a new skill, and a lack\nof experience makes it difficult to get job offers even if they do. In this\npaper, we seek to lower the threshold to skill development by repurposing\nexisting tasks on the marketplace as mentored, paid, real-world work\nexperiences, which we refer to as micro-internships. We instantiate this idea\nin Atelier, a micro-internship platform that connects crowd interns with crowd\nmentors. Atelier guides mentor-intern pairs to break down expert crowdsourcing\ntasks into milestones, review intermediate output, and problem-solve together.\nWe conducted a field experiment comparing Atelier's mentorship model to a\nnon-mentored alternative on a real-world programming crowdsourcing task,\nfinding that Atelier helped interns maintain forward progress and absorb best\npractices.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 03:18:24 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Suzuki", "Ryo", ""], ["Salehi", "Niloufar", ""], ["Lam", "Michelle S.", ""], ["Marroquin", "Juan C.", ""], ["Bernstein", "Michael S.", ""]]}, {"id": "1602.06678", "submitter": "Giuseppe Scavo Giuseppe Scavo", "authors": "Giuseppe Scavo, Zied Ben Houidi, Stefano Traverso, Renata Teixeira,\n  Marco Mellia", "title": "WeBrowse: Mining HTTP logs online for network-based content\n  recommendation", "comments": "13 pages, 10 figures, 4 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A powerful means to help users discover new content in the overwhelming\namount of information available today is sharing in online communities such as\nsocial networks or crowdsourced platforms. This means comes short in the case\nof what we call communities of a place: people who study, live or work at the\nsame place. Such people often share common interests but either do not know\neach other or fail to actively engage in submitting and relaying information.\nTo counter this effect, we propose passive crowdsourced content discovery, an\napproach that leverages the passive observation of web-clicks as an indication\nof users' interest in a piece of content. We design, implement, and evaluate\nWeBrowse , a passive crowdsourced system which requires no active user\nengagement to promote interesting content to users of a community of a place.\nInstead, it extracts the URLs users visit from traffic traversing a network\nlink to identify popular and interesting pieces of information. We first\nprototype WeBrowse and evaluate it using both ground-truths and real traces\nfrom a large European Internet Service Provider. Then, we deploy WeBrowse in a\ncampus of 15,000 users, and in a neighborhood. Evaluation based on our\ndeployments shows the feasibility of our approach. The majority of WeBrowse's\nusers welcome the quality of content it promotes. Finally, our analysis of\npopular topics across different communities confirms that users in the same\ncommunity of a place share common interests, compared to users from different\ncommunities, thus confirming the promise of WeBrowse's approach.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 08:33:19 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 14:50:39 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Scavo", "Giuseppe", ""], ["Houidi", "Zied Ben", ""], ["Traverso", "Stefano", ""], ["Teixeira", "Renata", ""], ["Mellia", "Marco", ""]]}, {"id": "1602.06700", "submitter": "Maurits Kaptein", "authors": "Jules Kruijswijk, Robin van Emden, Petri Parvinen, Maurits Kaptein", "title": "StreamingBandit; Experimenting with Bandit Policies", "comments": "47 pages, 15 figures, accepted for publication in Journal of\n  Statistical Software (JSS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of statistical decision problems in the social sciences and\nbeyond can be framed as a (contextual) multi-armed bandit problem. However, it\nis notoriously hard to develop and evaluate policies that tackle these types of\nproblem, and to use such policies in applied studies. To address this issue,\nthis paper introduces StreamingBandit, a Python web application for developing\nand testing bandit policies in field studies. StreamingBandit can sequentially\nselect treatments using (online) policies in real time. Once StreamingBandit is\nimplemented in an applied context, different policies can be tested, altered,\nnested, and compared. StreamingBandit makes it easy to apply a multitude of\nbandit policies for sequential allocation in field experiments, and allows for\nthe quick development and re-use of novel policies. In this article, we detail\nthe implementation logic of StreamingBandit and provide several examples of its\nuse.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 09:37:24 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 09:54:07 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Kruijswijk", "Jules", ""], ["van Emden", "Robin", ""], ["Parvinen", "Petri", ""], ["Kaptein", "Maurits", ""]]}, {"id": "1602.06977", "submitter": "Ethan Fast", "authors": "Ethan Fast, William McGrath, Pranav Rajpurkar, Michael Bernstein", "title": "Augur: Mining Human Behaviors from Fiction to Power Interactive Systems", "comments": "CHI: ACM Conference on Human Factors in Computing Systems 2016", "journal-ref": null, "doi": "10.1145/2858036.2858528", "report-no": null, "categories": "cs.HC cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From smart homes that prepare coffee when we wake, to phones that know not to\ninterrupt us during important conversations, our collective visions of HCI\nimagine a future in which computers understand a broad range of human\nbehaviors. Today our systems fall short of these visions, however, because this\nrange of behaviors is too large for designers or programmers to capture\nmanually. In this paper, we instead demonstrate it is possible to mine a broad\nknowledge base of human behavior by analyzing more than one billion words of\nmodern fiction. Our resulting knowledge base, Augur, trains vector models that\ncan predict many thousands of user activities from surrounding objects in\nmodern contexts: for example, whether a user may be eating food, meeting with a\nfriend, or taking a selfie. Augur uses these predictions to identify actions\nthat people commonly take on objects in the world and estimate a user's future\nactivities given their current situation. We demonstrate Augur-powered,\nactivity-based systems such as a phone that silences itself when the odds of\nyou answering it are low, and a dynamic music player that adjusts to your\npresent activity. A field deployment of an Augur-powered wearable camera\nresulted in 96% recall and 71% precision on its unsupervised predictions of\ncommon daily activities. A second evaluation where human judges rated the\nsystem's predictions over a broad set of input images found that 94% were rated\nsensible.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 21:44:05 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 20:54:28 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Fast", "Ethan", ""], ["McGrath", "William", ""], ["Rajpurkar", "Pranav", ""], ["Bernstein", "Michael", ""]]}, {"id": "1602.07063", "submitter": "Bo-Wei Chen", "authors": "Bo-Wei Chen and Wen Ji", "title": "Geo-Conquesting Based on Graph Analysis for Crowdsourced Metatrails from\n  Mobile Sensing", "comments": "Mobile sensing, crowdsensing, crowdsourcing, graph analysis, graph\n  mining, hotspot network, affinity network, transition network,\n  geo-conquesting, intelligent marketing, smart footprint, smart city, urban\n  planning, urban monitoring", "journal-ref": null, "doi": "10.1109/MCOM.2017.1600223CM", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates graph analysis for intelligent marketing in smart\ncities, where metatrails are crowdsourced by mobile sensing for marketing\nstrategies. Unlike most works that focused on client sides, this study is\nintended for market planning, from the perspective of enterprises. Several\nnovel crowdsourced features based on metatrails, including hotspot networks,\ncrowd transitions, affinity subnetworks, and sequential visiting patterns, are\ndiscussed in the article. These smart footprints can reflect crowd preferences\nand the topology of a site of interest. Marketers can utilize such information\nfor commercial resource planning and deployment. Simulations were conducted to\ndemonstrate the performance. At the end, this study also discusses different\nscenarios for practical geo-conquesting applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 07:26:53 GMT"}, {"version": "v2", "created": "Wed, 28 Dec 2016 13:19:43 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Chen", "Bo-Wei", ""], ["Ji", "Wen", ""]]}, {"id": "1602.07185", "submitter": "Ingmar Weber", "authors": "Ingmar Weber and Yelena Mejova", "title": "Crowdsourcing Health Labels: Inferring Body Weight from Profile Pictures", "comments": "This is a preprint of an article appearing at ACM DigitalHealth 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To use social media for health-related analysis, one key step is the\ndetection of health-related labels for users. But unlike transient conditions\nlike flu, social media users are less vocal about chronic conditions such as\nobesity, as users might not tweet \"I'm still overweight\". As, however,\nobesity-related conditions such as diabetes, heart disease, osteoarthritis, and\neven cancer are on the rise, this obese-or-not label could be one of the most\nuseful for studies in public health.\n  In this paper we investigate the feasibility of using profile pictures to\ninfer if a user is overweight or not. We show that this is indeed possible and\nfurther show that the fraction of labeled-as-overweight users is higher in U.S.\ncounties with higher obesity rates. Going from public to individual health\nanalysis, we then find differences both in behavior and social networks, for\nexample finding users labeled as overweight to have fewer followers.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 15:07:02 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Weber", "Ingmar", ""], ["Mejova", "Yelena", ""]]}, {"id": "1602.07199", "submitter": "Taha Yasseri", "authors": "Aslak Wegner Eide, J. Brian Pickering, Taha Yasseri, George Bravos,\n  Asbj{\\o}rn F{\\o}lstad, Vegard Engen, Milena Tsvetkova, Eric T. Meyer, Paul\n  Walland, Marika L\\\"uders", "title": "Human-Machine Networks: Towards a Typology and Profiling Framework", "comments": "Pre-print; To be presented at the 18th International Conference on\n  Human-Computer Interaction International, Toronto, Canada, 17 - 22 July 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we outline an initial typology and framework for the purpose of\nprofiling human-machine networks, that is, collective structures where humans\nand machines interact to produce synergistic effects. Profiling a human-machine\nnetwork along the dimensions of the typology is intended to facilitate access\nto relevant design knowledge and experience. In this way the profiling of an\nenvisioned or existing human-machine network will both facilitate relevant\ndesign discussions and, more importantly, serve to identify the network type.\nWe present experiences and results from two case trials: a crisis management\nsystem and a peer-to-peer reselling network. Based on the lessons learnt from\nthe case trials we suggest potential benefits and challenges, and point out\nneeded future work.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 15:34:59 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2016 16:48:20 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Eide", "Aslak Wegner", ""], ["Pickering", "J. Brian", ""], ["Yasseri", "Taha", ""], ["Bravos", "George", ""], ["F\u00f8lstad", "Asbj\u00f8rn", ""], ["Engen", "Vegard", ""], ["Tsvetkova", "Milena", ""], ["Meyer", "Eric T.", ""], ["Walland", "Paul", ""], ["L\u00fcders", "Marika", ""]]}, {"id": "1602.07388", "submitter": "Keith Burghardt", "authors": "Keith Burghardt, Emanuel F. Alsina, Michelle Girvan, William Rand, and\n  Kristina Lerman", "title": "The Myopia of Crowds: A Study of Collective Evaluation on Stack Exchange", "comments": "10 pages, 9 figures", "journal-ref": "PLoS ONE 12(3): e0173610", "doi": "10.1371/journal.pone.0173610", "report-no": null, "categories": "cs.HC cs.CY cs.LG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowds can often make better decisions than individuals or small groups of\nexperts by leveraging their ability to aggregate diverse information. Question\nanswering sites, such as Stack Exchange, rely on the \"wisdom of crowds\" effect\nto identify the best answers to questions asked by users. We analyze data from\n250 communities on the Stack Exchange network to pinpoint factors affecting\nwhich answers are chosen as the best answers. Our results suggest that, rather\nthan evaluate all available answers to a question, users rely on simple\ncognitive heuristics to choose an answer to vote for or accept. These cognitive\nheuristics are linked to an answer's salience, such as the order in which it is\nlisted and how much screen space it occupies. While askers appear to depend\nmore on heuristics, compared to voting users, when choosing an answer to accept\nas the most helpful one, voters use acceptance itself as a heuristic: they are\nmore likely to choose the answer after it is accepted than before that very\nsame answer was accepted. These heuristics become more important in explaining\nand predicting behavior as the number of available answers increases. Our\nfindings suggest that crowd judgments may become less reliable as the number of\nanswers grow.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 03:55:15 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Burghardt", "Keith", ""], ["Alsina", "Emanuel F.", ""], ["Girvan", "Michelle", ""], ["Rand", "William", ""], ["Lerman", "Kristina", ""]]}, {"id": "1602.08225", "submitter": "Wei Liu", "authors": "Wei Liu, Wei-Long Zheng, Bao-Liang Lu", "title": "Multimodal Emotion Recognition Using Multimodal Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enhance the performance of affective models and reduce the cost of\nacquiring physiological signals for real-world applications, we adopt\nmultimodal deep learning approach to construct affective models from multiple\nphysiological signals. For unimodal enhancement task, we indicate that the best\nrecognition accuracy of 82.11% on SEED dataset is achieved with shared\nrepresentations generated by Deep AutoEncoder (DAE) model. For multimodal\nfacilitation tasks, we demonstrate that the Bimodal Deep AutoEncoder (BDAE)\nachieves the mean accuracies of 91.01% and 83.25% on SEED and DEAP datasets,\nrespectively, which are much superior to the state-of-the-art approaches. For\ncross-modal learning task, our experimental results demonstrate that the mean\naccuracy of 66.34% is achieved on SEED dataset through shared representations\ngenerated by EEG-based DAE as training samples and shared representations\ngenerated by eye-based DAE as testing sample, and vice versa.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 07:43:14 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Liu", "Wei", ""], ["Zheng", "Wei-Long", ""], ["Lu", "Bao-Liang", ""]]}, {"id": "1602.08237", "submitter": "Vegard Engen", "authors": "Vegard Engen, J. Brian Pickering and Paul Walland", "title": "Machine Agency in Human-Machine Networks; Impacts and Trust Implications", "comments": "Pre-print; To be presented at the 18th International Conference on\n  Human-Computer Interaction International, Toronto, Canada, 17 - 22 July 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We live in an emerging hyper-connected era in which people are in contact and\ninteracting with an increasing number of other people and devices.\nIncreasingly, modern IT systems form networks of humans and machines that\ninteract with one another. As machines take a more active role in such\nnetworks, they exert an in-creasing level of influence on other participants.\nWe review the existing literature on agency and propose a definition of agency\nthat is practical for describing the capabilities and impact human and machine\nactors may have in a human-machine network. On this basis, we discuss and\ndemonstrate the impact and trust implica-tions for machine actors in\nhuman-machine networks for emergency decision support, healthcare and future\nsmart homes. We maintain that machine agency not only facilitates human to\nmachine trust, but also interpersonal trust; and that trust must develop to be\nable to seize the full potential of future technology.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 08:43:28 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Engen", "Vegard", ""], ["Pickering", "J. Brian", ""], ["Walland", "Paul", ""]]}, {"id": "1602.08358", "submitter": "Jeremy Frey", "authors": "J\\'er\\'emy Frey (Potioc, LaBRI, UB)", "title": "Remote Heart Rate Sensing and Projection to Renew Traditional Board\n  Games and Foster Social Interactions", "comments": null, "journal-ref": "CHI '16 Extended Abstracts, May 2016, San Jose, United States.\n  2016", "doi": "10.1145/2851581.2892391", "report-no": null, "categories": "cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While physiological sensors enter the mass market and reach the general\npublic, they are still mainly employed to monitor health -- whether it is for\nmedical purpose or sports. We describe an application that uses heart rate\nfeedback as an incentive for social interactions. A traditional board game has\nbeen \"augmented\" through remote physiological sensing, using webcams.\nProjection helped to conceal the technological aspects from users. We detail\nhow players reacted -- stressful situations could emerge when users are\ndeprived from their own signals -- and we give directions for game designers to\nintegrate physiological sensors.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 15:02:07 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Frey", "J\u00e9r\u00e9my", "", "Potioc, LaBRI, UB"]]}, {"id": "1602.08423", "submitter": "Muhammad Imran", "authors": "Muhammad Imran, Patrick Meier, Carlos Castillo, Andre Lesa, Manuel\n  Garcia Herranz", "title": "Enabling Digital Health by Automatic Classification of Short Messages", "comments": "Accepted at the ACM Digital Health Conference, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In response to the growing HIV/AIDS and other health-related issues, UNICEF\nthrough their U-Report platform receives thousands of messages (SMS) every day\nto provide prevention strategies, health case advice, and counsel- ing support\nto vulnerable population. Due to a rapid increase in U-Report usage (up to 300%\nin last 3 years), plus approximately 1,000 new registrations each day, the\nvolume of messages has thus continued to increase, which made it impossible for\nthe team at UNICEF to process them in a timely manner. In this paper, we\npresent a platform designed to perform automatic classification of short\nmessages (SMS) in real-time to help UNICEF categorize and prioritize\nhealth-related messages as they arrive. We employ a hybrid approach, which\ncombines human and machine intelligence that seeks to resolve the information\noverload issue by introducing processing of large-scale data at high-speed\nwhile maintaining a high classification accuracy. The system has recently been\ntested in conjunction with UNICEF in Zambia to classify short messages received\nvia the U-Report platform on various health related issues. The system is\ndesigned to enable UNICEF make sense of a large volume of short messages in a\ntimely manner. In terms of evaluation, we report design choices, challenges,\nand performance of the system observed during the deployment to validate its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 18:25:39 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Imran", "Muhammad", ""], ["Meier", "Patrick", ""], ["Castillo", "Carlos", ""], ["Lesa", "Andre", ""], ["Herranz", "Manuel Garcia", ""]]}, {"id": "1602.08750", "submitter": "Carl Thom\\'e", "authors": "Carl Thom\\'e", "title": "Filtering Video Noise as Audio with Motion Detection to Form a Musical\n  Instrument", "comments": "Received the 2015 best paper award in the KTH Royal Institute of\n  Technology course \"Musical Communication and Music Technology\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SD", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Even though they differ in the physical domain, digital video and audio share\nmany characteristics. Both are temporal data streams often stored in buffers\nwith 8-bit values. This paper investigates a method for creating harmonic\nsounds with a video signal as input. A musical instrument is proposed, that\nutilizes video in both a sound synthesis method, and in a controller interface\nfor selecting musical notes at specific velocities. The resulting instrument\nwas informally determined by the author to sound both pleasant and interesting,\nbut hard to control, and therefore suited for synth pad sounds.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 18:31:31 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Thom\u00e9", "Carl", ""]]}]