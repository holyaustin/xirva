[{"id": "1901.02874", "submitter": "Johannes Vorwerk", "authors": "Sophie Schrader, Andreas Westhoff, Maria Carla Piastra, Tuuli\n  Miinalainen, Sampsa Pursiainen, Johannes Vorwerk, Heinrich Brinck, Carsten H.\n  Wolters, Christian Engwer", "title": "DUNEuro -- A software toolbox for forward modeling in\n  bioelectromagnetism", "comments": null, "journal-ref": "PLoS ONE 16.6 (2021): e0252431", "doi": "10.1371/journal.pone.0252431", "report-no": null, "categories": "cs.MS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and efficient source analysis in electro- and magnetoencephalography\nusing sophisticated realistic head geometries requires advanced numerical\napproaches. This paper presents DUNEuro, a free and open source C++ software\ntoolbox for forward modeling in bioelectromagnetism. Building upon the DUNE\nframework, it provides implementations of modern fitted and unfitted finite\nelement methods to efficiently solve the forward problems in electro- and\nmagnetoencephalography. The user can choose between a variety of different\nsource models that are implemented. The software's aim is to provide interfaces\nthat are extendible and easy-to-use. In order to enable a closer integration\ninto existing analysis pipelines, interfaces to Python and Matlab are provided.\nThe practical use is demonstrated by a source analysis example of somatosensory\nevoked potentials using a realistic six compartment head model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:52:01 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 12:13:53 GMT"}, {"version": "v3", "created": "Sat, 19 Jan 2019 12:06:16 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 17:46:20 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Schrader", "Sophie", ""], ["Westhoff", "Andreas", ""], ["Piastra", "Maria Carla", ""], ["Miinalainen", "Tuuli", ""], ["Pursiainen", "Sampsa", ""], ["Vorwerk", "Johannes", ""], ["Brinck", "Heinrich", ""], ["Wolters", "Carsten H.", ""], ["Engwer", "Christian", ""]]}, {"id": "1901.04098", "submitter": "Steven Roberts", "authors": "Steven Roberts, Andrey A. Popov, and Adrian Sandu", "title": "ODE Test Problems: a MATLAB suite of initial value problems", "comments": null, "journal-ref": null, "doi": null, "report-no": "CSL-TR-19-1", "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ODE Test Problems (OTP) is an object-oriented MATLAB package offering a broad\nrange of initial value problems which can be used to test numerical methods\nsuch as time integration methods and data assimilation (DA) methods. It\nincludes problems that are linear and nonlinear, homogeneous and\nnonhomogeneous, autonomous and nonautonomous, scalar and high-dimensional,\nstiff and nonstiff, and chaotic and nonchaotic. Many are real-world problems\nfrom fields such as chemistry, astrophysics, meteorology, and electrical\nengineering. OTP also supports partitioned ODEs for testing IMEX methods,\nmultirate methods, and other multimethods. Functions for plotting solutions and\ncreating movies are available for all problems, and exact solutions are\nprovided when available. OTP is desgined for ease of use-meaning that working\nwith and modifying problems is simple and intuitive.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 01:04:05 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Roberts", "Steven", ""], ["Popov", "Andrey A.", ""], ["Sandu", "Adrian", ""]]}, {"id": "1901.04289", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson (LFANT)", "title": "Faster arbitrary-precision dot product and matrix multiplication", "comments": null, "journal-ref": "26th IEEE Symposium on Computer Arithmetic (ARITH26), Jun 2019,\n  Kyoto, Japan", "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms for real and complex dot product and matrix\nmultiplication in arbitrary-precision floating-point and ball arithmetic. A\nlow-overhead dot product is implemented on the level of GMP limb arrays; it is\nabout twice as fast as previous code in MPFR and Arb at precision up to several\nhundred bits. Up to 128 bits, it is 3-4 times as fast, costing 20-30 cycles per\nterm for floating-point evaluation and 40-50 cycles per term for balls. We\nhandle large matrix multiplications even more efficiently via blocks of scaled\ninteger matrices. The new methods are implemented in Arb and significantly\nspeed up polynomial operations and linear algebra.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 13:25:49 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 13:26:16 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Johansson", "Fredrik", "", "LFANT"]]}, {"id": "1901.06015", "submitter": "Devangi Parikh", "authors": "Field G. Van Zee, Devangi N. Parikh, Robert A. van de Geijn", "title": "Supporting mixed-datatype matrix multiplication within the BLIS\n  framework", "comments": null, "journal-ref": null, "doi": null, "report-no": "FLAME Working Note #89, The University of Texas at Austin,\n  Department of Computer Science, Technical Report TR-19-01", "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We approach the problem of implementing mixed-datatype support within the\ngeneral matrix multiplication (GEMM) operation of the BLIS framework, whereby\neach matrix operand A, B, and C may be stored as single- or double-precision\nreal or complex values. Another factor of complexity, whereby the computation\nis allowed to take place in a precision different from the storage precisions\nof either A or B, is also included in the discussion. We first break the\nproblem into mostly orthogonal dimensions, considering the mixing of domains\nseparately from mixing precisions. Support for all combinations of matrix\noperands stored in either the real or complex domain is mapped out by\nenumerating the cases and describing an implementation approach for each.\nSupporting all combinations of storage and computation precisions is handled by\ntypecasting the matrices at key stages of the computation---during packing\nand/or accumulation, as needed. Several optional optimizations are also\ndocumented. Performance results gathered on a 56-core Marvell ThunderX2 and a\n52-core Intel Xeon Platinum demonstrate that high performance is mostly\npreserved, with modest slowdowns incurred from unavoidable typecast\ninstructions. The mixed-datatype implementation confirms that combinatoric\nintractability is avoided, with the framework relying on only two assembly\nmicrokernels to implement 128 datatype combinations.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 21:53:24 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 00:21:38 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Van Zee", "Field G.", ""], ["Parikh", "Devangi N.", ""], ["van de Geijn", "Robert A.", ""]]}, {"id": "1901.06043", "submitter": "Tamara Kolda", "authors": "Grey Ballard and Alicia Klinvex and Tamara G. Kolda", "title": "TuckerMPI: A Parallel C++/MPI Software Package for Large-scale Data\n  Compression via the Tucker Tensor Decomposition", "comments": null, "journal-ref": "ACM Transactions on Mathematical Software, Vol. 46, No. 2, Article\n  13, June 2020", "doi": "10.1145/3378445", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is compression of massive-scale grid-structured data, such as the\nmulti-terabyte output of a high-fidelity computational simulation. For such\ndata sets, we have developed a new software package called TuckerMPI, a\nparallel C++/MPI software package for compressing distributed data. The\napproach is based on treating the data as a tensor, i.e., a multidimensional\narray, and computing its truncated Tucker decomposition, a higher-order\nanalogue to the truncated singular value decomposition of a matrix. The result\nis a low-rank approximation of the original tensor-structured data. Compression\nefficiency is achieved by detecting latent global structure within the data,\nwhich we contrast to most compression methods that are focused on local\nstructure. In this work, we describe TuckerMPI, our implementation of the\ntruncated Tucker decomposition, including details of the data distribution and\nin-memory layouts, the parallel and serial implementations of the key kernels,\nand analysis of the storage, communication, and computational costs. We test\nthe software on 4.5 terabyte and 6.7 terabyte data sets distributed across 100s\nof nodes (1000s of MPI processes), achieving compression rates between\n100-200,000$\\times$ which equates to 99-99.999% compression (depending on the\ndesired accuracy) in substantially less time than it would take to even read\nthe same dataset from a parallel filesystem. Moreover, we show that our method\nalso allows for reconstruction of partial or down-sampled data on a single\nnode, without a parallel computer so long as the reconstructed portion is small\nenough to fit on a single machine, e.g., in the instance of\nreconstructing/visualizing a single down-sampled time step or computing summary\nstatistics.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 00:38:44 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 23:45:27 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Ballard", "Grey", ""], ["Klinvex", "Alicia", ""], ["Kolda", "Tamara G.", ""]]}]