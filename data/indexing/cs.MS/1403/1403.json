[{"id": "1403.1140", "submitter": "Ioannis Emiris", "authors": "Ioannis Z. Emiris", "title": "Matrix Methods for Solving Algebraic Systems", "comments": "13 pages. arXiv admin note: text overlap with arXiv:1201.5810", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our public-domain software for the following tasks in sparse (or\ntoric) elimination theory, given a well-constrained polynomial system. First, C\ncode for computing the mixed volume of the system. Second, Maple code for\ndefining an overconstrained system and constructing a Sylvester-type matrix of\nits sparse resultant. Third, C code for a Sylvester-type matrix of the sparse\nresultant and a superset of all common roots of the initial well-constrained\nsystem by computing the eigen-decomposition of a square matrix obtained from\nthe resultant matrix. We conclude with experiments in computing molecular\nconformations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 14:14:12 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Emiris", "Ioannis Z.", ""]]}, {"id": "1403.1200", "submitter": "Javier Segura", "authors": "A. Gil, J. Segura, N. M. Temme", "title": "Recent software developments for special functions in the\n  Santander-Amsterdam project", "comments": "To appear in Science of Computer Programming", "journal-ref": null, "doi": "10.1016/j.scico.2013.11.004", "report-no": null, "categories": "math.CA cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an overview of published algorithms by our group and of current\nactivities and future plans. In particular, we give details on methods for\ncomputing special functions and discuss in detail two current lines of\nresearch. Firstly, we describe the recent developments for the computation of\ncentral and non-central chi-square cumulative distributions (also called Marcum\nQ-functions), and we present a new quadrature method for computing them.\nSecondly, we describe the fourth-order methods for computing zeros of special\nfunctions recently developed, and we provide an explicit example for the\ncomputation of complex zeros of Bessel functions. We end with an overview of\npublished software by our group for computing special functions.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 17:36:34 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Gil", "A.", ""], ["Segura", "J.", ""], ["Temme", "N. M.", ""]]}, {"id": "1403.2036", "submitter": "Mathew McLean", "authors": "Mathew W. McLean", "title": "Straightforward Bibliography Management in R with the RefManageR Package", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.MS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces the R package RefManageR, which provides tools for\nimporting and working with bibliographic references. It extends the bibentry\nclass in R in a number of useful ways, including providing R with previously\nunavailable support for BibLaTeX. BibLaTeX provides a superset of the\nfunctionality of BibTeX, including full Unicode support, no memory limitations,\nadditional fields and entry types, and more sophisticated sorting of\nreferences. RefManageR provides functions for citing and generating a\nbibliography with hyperlinks for documents prepared with RMarkdown or RHTML.\nExisting .bib files can be read into R and converted from BibTeX to BibLaTeX\nand vice versa. References can also be imported via queries to NCBI's Entrez,\nZotero libraries, Google Scholar, and CrossRef. Additionally, references can be\ncreated by reading PDFs stored on the user's machine with the help of Poppler.\nEntries stored in the reference manager can be easily searched by any field, by\ndate ranges, and by various formats for name lists (author by last names,\ntranslator by full names, etc.). Entries can also be updated, combined, sorted,\nprinted in a number of styles, and exported.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2014 08:09:02 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["McLean", "Mathew W.", ""]]}, {"id": "1403.2630", "submitter": "Edinah Gnang K", "authors": "Edinah K. Gnang, Ori Parzanchevski, Yuval Filmus", "title": "A SageTeX Hypermatrix Algebra Package", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe here a rudimentary sage implementation of the Bhattacharya-Mesner\nhypermatrix algebra package.\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 16:23:23 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Gnang", "Edinah K.", ""], ["Parzanchevski", "Ori", ""], ["Filmus", "Yuval", ""]]}, {"id": "1403.2805", "submitter": "Jeroen Ooms", "authors": "Jeroen Ooms", "title": "The jsonlite Package: A Practical and Consistent Mapping Between JSON\n  Data and R Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A naive realization of JSON data in R maps JSON arrays to an unnamed list,\nand JSON objects to a named list. However, in practice a list is an awkward,\ninefficient type to store and manipulate data. Most statistical applications\nwork with (homogeneous) vectors, matrices or data frames. Therefore JSON\npackages in R typically define certain special cases of JSON structures which\nmap to simpler R types. Currently there exist no formal guidelines, or even\nconsensus between implementations on how R data should be represented in JSON.\nFurthermore, upon closer inspection, even the most basic data structures in R\nactually do not perfectly map to their JSON counterparts and leave some\nambiguity for edge cases. These problems have resulted in different behavior\nbetween implementations and can lead to unexpected output. This paper\nexplicitly describes a mapping between R classes and JSON data, highlights\npotential problems, and proposes conventions that generalize the mapping to\ncover all common structures. We emphasize the importance of type consistency\nwhen using JSON to exchange dynamic data, and illustrate using examples and\nanecdotes. The jsonlite R package is used throughout the paper as a reference\nimplementation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2014 04:21:10 GMT"}], "update_date": "2014-03-13", "authors_parsed": [["Ooms", "Jeroen", ""]]}, {"id": "1403.4238", "submitter": "Guohui Wang", "authors": "Guohui Wang, Yingen Xiong, Jay Yun, and Joseph R. Cavallaro", "title": "Computer Vision Accelerators for Mobile Systems based on OpenCL GPGPU\n  Co-Processing", "comments": "15 pages, 15 figures. Submitted and accepted for publication in\n  Journal of Signal Processing Systems, 2014", "journal-ref": null, "doi": "10.1007/s11265-014-0878-z", "report-no": null, "categories": "cs.DC cs.CV cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an OpenCL-based heterogeneous implementation of a\ncomputer vision algorithm -- image inpainting-based object removal algorithm --\non mobile devices. To take advantage of the computation power of the mobile\nprocessor, the algorithm workflow is partitioned between the CPU and the GPU\nbased on the profiling results on mobile devices, so that the\ncomputationally-intensive kernels are accelerated by the mobile GPGPU\n(general-purpose computing using graphics processing units). By exploring the\nimplementation trade-offs and utilizing the proposed optimization strategies at\ndifferent levels including algorithm optimization, parallelism optimization,\nand memory access optimization, we significantly speed up the algorithm with\nthe CPU-GPU heterogeneous implementation, while preserving the quality of the\noutput images. Experimental results show that heterogeneous computing based on\nGPGPU co-processing can significantly speed up the computer vision algorithms\nand makes them practical on real-world mobile devices.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2014 18:26:41 GMT"}], "update_date": "2014-03-19", "authors_parsed": [["Wang", "Guohui", ""], ["Xiong", "Yingen", ""], ["Yun", "Jay", ""], ["Cavallaro", "Joseph R.", ""]]}, {"id": "1403.5355", "submitter": "Konstantin G. Savvidy", "authors": "Konstantin G. Savvidy", "title": "The MIXMAX random number generator", "comments": "15 pages, 3 Figures", "journal-ref": null, "doi": "10.1016/j.cpc.2015.06.003", "report-no": "NITS-PHY-2014003", "categories": "hep-lat cs.MS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we give a practical solution to the problem of determining the\nmaximal period of matrix generators of pseudo-random numbers which are based on\nan integer-valued unimodular matrix of size NxN known as MIXMAX and arithmetic\ndefined on a Galois field GF[p] with large prime modulus p. The existing theory\nof Galois finite fields is adapted to the present case, and necessary and\nsufficient condition to attain the maximum period is formulated. Three\nefficient algorithms are presented. First, allowing to compute the\nmultiplication by the MIXMAX matrix with O(N) operations. Second, to\nrecursively compute the characteristic polynomial with O(N^2) operations, and\nthird, to apply skips of large number of steps S to the sequence in O(N^2\nlog(S)) operations. It is demonstrated that the dynamical properties of this\ngenerator dramatically improve with the size of the matrix N, as compared to\nthe classes of generators based on sparse matrices and/or sparse characteristic\npolynomials. Finally, we present the implementation details of the generator\nand the results of rigorous statistical testing.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2014 03:45:08 GMT"}, {"version": "v2", "created": "Tue, 1 Apr 2014 15:06:14 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Savvidy", "Konstantin G.", ""]]}, {"id": "1403.6426", "submitter": "Elmar Peise", "authors": "Elmar Peise (1), Diego Fabregat-Traver (1), Paolo Bientinesi (1) ((1)\n  AICES, RWTH Aachen)", "title": "High Performance Solutions for Big-data GWAS", "comments": "Submitted to Parallel Computing. arXiv admin note: substantial text\n  overlap with arXiv:1304.2272", "journal-ref": null, "doi": null, "report-no": "AICES-2013/12-01", "categories": "q-bio.GN cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to associate complex traits with genetic polymorphisms, genome-wide\nassociation studies process huge datasets involving tens of thousands of\nindividuals genotyped for millions of polymorphisms. When handling these\ndatasets, which exceed the main memory of contemporary computers, one faces two\ndistinct challenges: 1) Millions of polymorphisms and thousands of phenotypes\ncome at the cost of hundreds of gigabytes of data, which can only be kept in\nsecondary storage; 2) the relatedness of the test population is represented by\na relationship matrix, which, for large populations, can only fit in the\ncombined main memory of a distributed architecture. In this paper, by using\ndistributed resources such as Cloud or clusters, we address both challenges:\nThe genotype and phenotype data is streamed from secondary storage using a\ndouble buffer- ing technique, while the relationship matrix is kept across the\nmain memory of a distributed memory system. With the help of these solutions,\nwe develop separate algorithms for studies involving only one or a multitude of\ntraits. We show that these algorithms sustain high-performance and allow the\nanalysis of enormous datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2014 17:21:55 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Peise", "Elmar", ""], ["Fabregat-Traver", "Diego", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1403.6870", "submitter": "Christopher McFarland", "authors": "Christopher D McFarland", "title": "A modified ziggurat algorithm for generating exponentially- and\n  normally-distributed pseudorandom numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ziggurat Algorithm is a very fast rejection sampling method for\ngenerating PseudoRandom Numbers (PRNs) from common statistical distributions.\nThe algorithm divides a distribution into rectangular layers that stack on top\nof each other (resembling a Ziggurat), subsuming the desired distribution.\nRandom values within these rectangular layers are then sampled by rejection.\nThis implementation splits layers into two types: those constituting the\nmajority that fall completely under the distribution and can be sampled\nextremely fast without a rejection test, and a few additional layers that\nencapsulate the fringe of the distribution and require a rejection test. This\nmethod offers speedups of 65% for exponentially- and 82% for\nnormally-distributed PRNs when compared to the best available C implementations\nof these generators. Even greater speedups are obtained when the algorithm is\nextended to the Python and MATLAB/OCTAVE programming environments.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2014 21:51:41 GMT"}, {"version": "v2", "created": "Mon, 21 Apr 2014 17:28:01 GMT"}], "update_date": "2014-04-22", "authors_parsed": [["McFarland", "Christopher D", ""]]}, {"id": "1403.7645", "submitter": "Andrew Karl", "authors": "Andrew T. Karl, Randy Eubank, Jelena Milovanovic, Mark Reiser and\n  Dennis Young", "title": "Using RngStreams for Parallel Random Number Generation in C++ and R", "comments": "This paper has been accepted by Computational Statistics and is\n  currently in press", "journal-ref": "Computational Statistics, 2014, 29:1301-1320", "doi": "10.1007/s00180-014-0492-3", "report-no": null, "categories": "cs.MS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RngStreams software package provides one viable solution to the problem\nof creating independent random number streams for simulations in parallel\nprocessing environments. Techniques are presented for effectively using\nRngStreams with C++ programs that are parallelized via OpenMP or MPI. Ways to\naccess the backbone generator from RngStreams in R through the parallel and\nrstream packages are also described. The ideas in the paper are illustrated\nwith both a simple running example and a Monte Carlo integration application.\n", "versions": [{"version": "v1", "created": "Sat, 29 Mar 2014 16:30:21 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Karl", "Andrew T.", ""], ["Eubank", "Randy", ""], ["Milovanovic", "Jelena", ""], ["Reiser", "Mark", ""], ["Young", "Dennis", ""]]}]