[{"id": "1511.00863", "submitter": "Topi Siro M. Sc.", "authors": "Topi Siro, Ari Harju", "title": "Exact diagonalization of quantum lattice models on coprocessors", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2016.07.018", "report-no": null, "categories": "cond-mat.str-el cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement the Lanczos algorithm on an Intel Xeon Phi coprocessor and\ncompare its performance to a multi-core Intel Xeon CPU and an NVIDIA graphics\nprocessor. The Xeon and the Xeon Phi are parallelized with OpenMP and the\ngraphics processor is programmed with CUDA. The performance is evaluated by\nmeasuring the execution time of a single step in the Lanczos algorithm. We\nstudy two quantum lattice models with different particle numbers, and conclude\nthat for small systems, the multi-core CPU is the fastest platform, while for\nlarge systems, the graphics processor is the clear winner, reaching speedups of\nup to 7.6 compared to the CPU. The Xeon Phi outperforms the CPU with\nsufficiently large particle number, reaching a speedup of 2.5.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 11:26:28 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 11:20:06 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Siro", "Topi", ""], ["Harju", "Ari", ""]]}, {"id": "1511.02134", "submitter": "Huber Markus", "authors": "Bj\\\"orn Gmeiner and Markus Huber and Lorenz John and Ulrich R\\\"ude and\n  Barbara Wohlmuth", "title": "A quantitative performance analysis for Stokes solvers at the extreme\n  scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a systematic quantitative performance analysis for\nlarge finite element computations on extreme scale computing systems. Three\nparallel iterative solvers for the Stokes system, discretized by low order\ntetrahedral elements, are compared with respect to their numerical efficiency\nand their scalability running on up to $786\\,432$ parallel threads. A genuine\nmultigrid method for the saddle point system using an Uzawa-type smoother\nprovides the best overall performance with respect to memory consumption and\ntime-to-solution. The largest system solved on a Blue Gene/Q system has more\nthan ten trillion ($1.1 \\cdot 10 ^{13}$) unknowns and requires about 13 minutes\ncompute time. Despite the matrix free and highly optimized implementation, the\nmemory requirement for the solution vector and the auxiliary vectors is about\n200 TByte. Brandt's notion of \"textbook multigrid efficiency\" is employed to\nstudy the algorithmic performance of iterative solvers. A recent extension of\nthis paradigm to \"parallel textbook multigrid efficiency\" makes it possible to\nassess also the efficiency of parallel iterative solvers for a given hardware\narchitecture in absolute terms. The efficiency of the method is demonstrated\nfor simulating incompressible fluid flow in a pipe filled with spherical\nobstacles.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 16:07:04 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Gmeiner", "Bj\u00f6rn", ""], ["Huber", "Markus", ""], ["John", "Lorenz", ""], ["R\u00fcde", "Ulrich", ""], ["Wohlmuth", "Barbara", ""]]}, {"id": "1511.02166", "submitter": "Lukas Einkemmer", "authors": "Lukas Einkemmer", "title": "Evaluation of the Intel Xeon Phi 7120 and NVIDIA K80 as accelerators for\n  two-dimensional panel codes", "comments": null, "journal-ref": "PLoS ONE 12(6): e0178156, 2017", "doi": "10.1371/journal.pone.0178156", "report-no": null, "categories": "cs.DC cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To optimize the geometry of airfoils for a specific application is an\nimportant engineering problem. In this context genetic algorithms have enjoyed\nsome success as they are able to explore the search space without getting stuck\nin local optima. However, these algorithms require the computation of\naerodynamic properties for a significant number of airfoil geometries.\nConsequently, for low-speed aerodynamics, panel methods are most often used as\nthe inner solver.\n  In this paper we evaluate the performance of such an optimization algorithm\non modern accelerators (more specifically, the Intel Xeon Phi 7120 and the\nNVIDIA K80). For that purpose, we have implemented an optimized version of the\nalgorithm on the CPU and Xeon Phi (based on OpenMP, vectorization, and the\nIntel MKL library) and on the GPU (based on CUDA and the MAGMA library). We\npresent timing results for all codes and discuss the similarities and\ndifferences between the three implementations. Overall, we observe a speedup of\napproximately $2.5$ for adding an Intel Xeon Phi 7120 to a dual socket\nworkstation and a speedup between $3.4$ and $3.8$ for adding a NVIDIA K80 to a\ndual socket workstation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 17:17:36 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 15:07:53 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Einkemmer", "Lukas", ""]]}, {"id": "1511.02171", "submitter": "Francisco Igual", "authors": "Sandra Catal\\'an, Jos\\'e R. Herrero, Francisco D. Igual, Rafael\n  Rodr\\'iguez-S\\'anchez, Enrique S. Quintana-Ort\\'i", "title": "Multi-Threaded Dense Linear Algebra Libraries for Low-Power Asymmetric\n  Multicore Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense linear algebra libraries, such as BLAS and LAPACK, provide a relevant\ncollection of numerical tools for many scientific and engineering applications.\nWhile there exist high performance implementations of the BLAS (and LAPACK)\nfunctionality for many current multi-threaded architectures,the adaption of\nthese libraries for asymmetric multicore processors (AMPs)is still pending. In\nthis paper we address this challenge by developing an asymmetry-aware\nimplementation of the BLAS, based on the BLIS framework, and tailored for AMPs\nequipped with two types of cores: fast/power hungry versus slow/energy\nefficient. For this purpose, we integrate coarse-grain and fine-grain\nparallelization strategies into the library routines which, respectively,\ndynamically distribute the workload between the two core types and statically\nrepartition this work among the cores of the same type.\n  Our results on an ARM big.LITTLE processor embedded in the Exynos 5422 SoC,\nusing the asymmetry-aware version of the BLAS and a plain migration of the\nlegacy version of LAPACK, experimentally assess the benefits, limitations, and\npotential of this approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 17:36:20 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Catal\u00e1n", "Sandra", ""], ["Herrero", "Jos\u00e9 R.", ""], ["Igual", "Francisco D.", ""], ["Rodr\u00edguez-S\u00e1nchez", "Rafael", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""]]}, {"id": "1511.03167", "submitter": "Davide Pagano", "authors": "Davide Pagano", "title": "BOAT: a cross-platform software for data analysis and numerical\n  computing with arbitrary-precision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BOAT is a free cross-platform software for statistical data analysis and\nnumerical computing. Thanks to its multiple-precision floating point engine, it\nallows arbitrary-precision calculations, whose digits of precision are only\nlimited by the amount of memory of the host machine. At the core of the\nsoftware is a simple and efficient expression language, whose use is\nfacilitated by the assisted typing, the auto-complete engine and the built-in\nhelp for the syntax. In this paper a quick overview of the software is given.\nDetailed information, together with its applications to some case studies, is\navailable at the BOAT web page.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 16:22:27 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Pagano", "Davide", ""]]}, {"id": "1511.03415", "submitter": "Bernd Flemisch", "authors": "Oliver Sander, Timo Koch, Natalie Schr\\\"oder, Bernd Flemisch", "title": "The Dune FoamGrid implementation for surface and network grids", "comments": null, "journal-ref": "Archive of Numerical Software Vol 5 No 1 2017", "doi": "10.11588/ans.2017.1.28490", "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FoamGrid, a new implementation of the DUNE grid interface.\nFoamGrid implements one- and two-dimensional grids in a physical space of\narbitrary dimension, which allows for grids for curved domains. Even more, the\ngrids are not expected to have a manifold structure, i.e., more than two\nelements can share a common facet. This makes FoamGrid the grid data structure\nof choice for simulating structures such as foams, discrete fracture networks,\nor network flow problems. FoamGrid implements adaptive non-conforming\nrefinement with element parametrizations. As an additional feature it allows\nremoval and addition of elements in an existing grid, which makes FoamGrid\nsuitable for network growth problems. We show how to use FoamGrid, with\nparticular attention to the extensions of the grid interface needed to handle\nnon-manifold topology and grid growth. Three numerical examples demonstrate the\npossibilities offered by FoamGrid.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 08:23:46 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Sander", "Oliver", ""], ["Koch", "Timo", ""], ["Schr\u00f6der", "Natalie", ""], ["Flemisch", "Bernd", ""]]}, {"id": "1511.03614", "submitter": "Alexander Smirnov", "authors": "Alexander V. Smirnov", "title": "FIESTA 4: optimized Feynman integral calculations with GPU support", "comments": "arXiv admin note: substantial text overlap with arXiv:1312.3186", "journal-ref": "Comp. Phys. Comm, 204, 2016, p, 189-199", "doi": "10.1016/j.cpc.2016.03.013", "report-no": "TTP15-036", "categories": "hep-ph cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new major release of the program FIESTA (Feynman\nIntegral Evaluation by a Sector decomposiTion Approach). The new release is\nmainly aimed at optimal performance at large scales when one is increasing the\nnumber of sampling points in order to reduce the uncertainty estimates. The\nrelease now supports graphical processor units (GPU) for the numerical\nintegration, methods to optimize cluster-usage, as well as other speed, memory,\nand stability improvements.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2015 16:07:56 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Smirnov", "Alexander V.", ""]]}, {"id": "1511.03703", "submitter": "Eric Phipps", "authors": "E. Phipps, M. D'Elia, H. C. Edwards, M. Hoemmen, J. Hu, S.\n  Rajamanickam", "title": "Embedded Ensemble Propagation for Improving Performance, Portability and\n  Scalability of Uncertainty Quantification on Emerging Computational\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAND2015-9921 J", "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying simulation uncertainties is a critical component of rigorous\npredictive simulation. A key component of this is forward propagation of\nuncertainties in simulation input data to output quantities of interest.\nTypical approaches involve repeated sampling of the simulation over the\nuncertain input data, and can require numerous samples when accurately\npropagating uncertainties from large numbers of sources. Often simulation\nprocesses from sample to sample are similar and much of the data generated from\neach sample evaluation could be reused. We explore a new method for\nimplementing sampling methods that simultaneously propagates groups of samples\ntogether in an embedded fashion, which we call embedded ensemble propagation.\nWe show how this approach takes advantage of properties of modern computer\narchitectures to improve performance by enabling reuse between samples,\nreducing memory bandwidth requirements, improving memory access patterns,\nimproving opportunities for fine-grained parallelization, and reducing\ncommunication costs. We describe a software technique for implementing embedded\nensemble propagation based on the use of C++ templates and describe its\nintegration with various scientific computing libraries within Trilinos. We\ndemonstrate improved performance, portability and scalability for the approach\napplied to the simulation of partial differential equations on a variety of\nCPU, GPU, and accelerator architectures, including up to 131,072 cores on a\nCray XK7 (Titan).\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 21:55:35 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Phipps", "E.", ""], ["D'Elia", "M.", ""], ["Edwards", "H. C.", ""], ["Hoemmen", "M.", ""], ["Hu", "J.", ""], ["Rajamanickam", "S.", ""]]}, {"id": "1511.03742", "submitter": "Anton Lokhmotov", "authors": "Anton Lokhmotov", "title": "GEMMbench: a framework for reproducible and collaborative benchmarking\n  of matrix multiplication", "comments": "ADAPT'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generic matrix-matrix multiplication (GEMM) is arguably the most popular\ncomputational kernel of the 20th century. Yet, surprisingly, no common\nmethodology for evaluating GEMM performance has been established over the many\ndecades of using GEMM for comparing architectures, compilers and ninja-class\nprogrammers.\n  We introduce GEMMbench, a framework and methodology for evaluating\nperformance of GEMM implementations. GEMMbench is implemented on top of\nCollective Knowledge (CK), a lightweight framework for reproducible and\ncollaborative R&D in computer systems. Using CK allows the R&D community to\ncrowdsource hand-written and compiler-generated GEMM implementations and to\nstudy their performance across multiple platforms, data sizes and data types.\n  Our initial implementation supports hand-written OpenCL kernels operating on\nmatrices consisting of single- and double-precision floating-point values, and\nproducing single or multiple output elements per work-item (via thread\ncoarsening and vectorization).\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 01:02:58 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 21:28:05 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Lokhmotov", "Anton", ""]]}, {"id": "1511.05986", "submitter": "Sheldon Axler", "authors": "Sheldon Axler", "title": "Computing with Harmonic Functions", "comments": "77 pages. Software available at http://axler.net/HFT_Math.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document is the manual for a free Mathematica package for computing with\nharmonic functions. This package allows the user to make calculations that\nwould take a prohibitive amount of time if done without a computer. For\nexample, the Poisson integral of any polynomial can be computed exactly. This\nsoftware can find exact solutions to Dirichlet, Neumann, and biDirichlet\nproblems in R^n with polynomial data on balls, ellipsoids, and annular regions.\nIt can also find bases for spaces of spherical harmonics, compute projections\nonto the harmonic Bergman space, and perform other manipulations with harmonic\nfunctions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 19:33:39 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 05:06:40 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Axler", "Sheldon", ""]]}, {"id": "1511.06487", "submitter": "Charles Jordan", "authors": "David Avis and Charles Jordan", "title": "mplrs: A scalable parallel vertex/facet enumeration code", "comments": "Revision incorporating additional suggested changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new parallel implementation, mplrs, of the vertex enumeration\ncode lrs that uses the MPI parallel environment and can be run on a network of\ncomputers. The implementation makes use of a C wrapper that essentially uses\nthe existing lrs code with only minor modifications. mplrs was derived from the\nearlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses\nthe Boost library and runs on a shared memory machine. In developing mplrs we\ndiscovered a method of balancing the parallel tree search, called budgeting,\nthat greatly improves parallelization beyond the bottleneck encountered\npreviously at around 32 cores.\n  This method can be readily adapted for use in other reverse search\nenumeration codes. We also report some preliminary computational results\ncomparing parallel and sequential codes for vertex/facet enumeration problems\nfor convex polyhedra. The problems chosen span the range from simple to highly\ndegenerate polytopes. For most problems tested, the results clearly show the\nadvantage of using the parallel implementation mplrs of the reverse search\nbased code lrs, even when as few as 8 cores are available. For some problems\nalmost linear speedup was observed up to 1200 cores, the largest number of\ncores tested.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 04:54:22 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 07:08:43 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 04:33:01 GMT"}, {"version": "v4", "created": "Thu, 12 Oct 2017 01:44:42 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Avis", "David", ""], ["Jordan", "Charles", ""]]}, {"id": "1511.07174", "submitter": "Bogdan Oancea", "authors": "Bogdan Oancea, Tudorel Andrei", "title": "Developing a High Performance Software Library with MPI and CUDA for\n  Matrix Computations", "comments": "in Computational Methods for Social Sciences, VOL. I, ISSUE 2/2013", "journal-ref": "Computational Methods for Social Sciences, VOL. I, ISSUE 2/2013", "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, the paradigm of parallel computing is changing. CUDA is now a\npopular programming model for general purpose computations on GPUs and a great\nnumber of applications were ported to CUDA obtaining speedups of orders of\nmagnitude comparing to optimized CPU implementations. Hybrid approaches that\ncombine the message passing model with the shared memory model for parallel\ncomputing are a solution for very large applications. We considered a\nheterogeneous cluster that combines the CPU and GPU computations using MPI and\nCUDA for developing a high performance linear algebra library. Our library\ndeals with large linear systems solvers because they are a common problem in\nthe fields of science and engineering. Direct methods for computing the\nsolution of such systems can be very expensive due to high memory requirements\nand computational cost. An efficient alternative are iterative methods which\ncomputes only an approximation of the solution. In this paper we present an\nimplementation of a library that uses a hybrid model of computation using MPI\nand CUDA implementing both direct and iterative linear systems solvers. Our\nlibrary implements LU and Cholesky factorization based solvers and some of the\nnon-stationary iterative methods using the MPI/CUDA combination. We compared\nthe performance of our MPI/CUDA implementation with classic programs written to\nbe run on a single CPU.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 11:06:12 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Oancea", "Bogdan", ""], ["Andrei", "Tudorel", ""]]}, {"id": "1511.07261", "submitter": "Martin Bauer", "authors": "Martin Bauer, Florian Schornbaum, Christian Godenschwager, Matthias\n  Markl, Daniela Anderl, Harald K\\\"ostler, Ulrich R\\\"ude", "title": "A Python Extension for the Massively Parallel Multiphysics Simulation\n  Framework waLBerla", "comments": null, "journal-ref": null, "doi": "10.1080/17445760.2015.1118478", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Python extension to the massively parallel HPC simulation\ntoolkit waLBerla. waLBerla is a framework for stencil based algorithms\noperating on block-structured grids, with the main application field being\nfluid simulations in complex geometries using the lattice Boltzmann method.\nCareful performance engineering results in excellent node performance and good\nscalability to over 400,000 cores. To increase the usability and flexibility of\nthe framework, a Python interface was developed. Python extensions are used at\nall stages of the simulation pipeline: They simplify and automate scenario\nsetup, evaluation, and plotting. We show how our Python interface outperforms\nthe existing text-file-based configuration mechanism, providing features like\nautomatic nondimensionalization of physical quantities and handling of complex\nparameter dependencies. Furthermore, Python is used to process and evaluate\nresults while the simulation is running, leading to smaller output files and\nthe possibility to adjust parameters dependent on the current simulation state.\nC++ data structures are exported such that a seamless interfacing to other\nnumerical Python libraries is possible. The expressive power of Python and the\nperformance of C++ make development of efficient code with low time effort\npossible.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 15:06:47 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Bauer", "Martin", ""], ["Schornbaum", "Florian", ""], ["Godenschwager", "Christian", ""], ["Markl", "Matthias", ""], ["Anderl", "Daniela", ""], ["K\u00f6stler", "Harald", ""], ["R\u00fcde", "Ulrich", ""]]}, {"id": "1511.07727", "submitter": "Atilim Gunes Baydin", "authors": "Atilim Gunes Baydin, Barak A. Pearlmutter, Jeffrey Mark Siskind", "title": "DiffSharp: Automatic Differentiation Library", "comments": "5 pages, 1 figure, minor fixes, added coauthor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce DiffSharp, an automatic differentiation (AD)\nlibrary designed with machine learning in mind. AD is a family of techniques\nthat evaluate derivatives at machine precision with only a small constant\nfactor of overhead, by systematically applying the chain rule of calculus at\nthe elementary operator level. DiffSharp aims to make an extensive array of AD\ntechniques available, in convenient form, to the machine learning community.\nThese including arbitrary nesting of forward/reverse AD operations, AD with\nlinear algebra primitives, and a functional API that emphasizes the use of\nhigher-order functions and composition. The library exposes this functionality\nthrough an API that provides gradients, Hessians, Jacobians, directional\nderivatives, and matrix-free Hessian- and Jacobian-vector products. Bearing the\nperformance requirements of the latest machine learning techniques in mind, the\nunderlying computations are run through a high-performance BLAS/LAPACK backend,\nusing OpenBLAS by default. GPU support is currently being implemented.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 14:28:13 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2015 16:32:40 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Baydin", "Atilim Gunes", ""], ["Pearlmutter", "Barak A.", ""], ["Siskind", "Jeffrey Mark", ""]]}]