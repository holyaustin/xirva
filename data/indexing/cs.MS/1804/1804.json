[{"id": "1804.02338", "submitter": "Nathan Sime", "authors": "Paul Houston and Nathan Sime", "title": "Automatic symbolic computation for discontinuous Galerkin finite element\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of discontinuous Galerkin finite element methods (DGFEMs)\nrepresents a very challenging computational task, particularly for systems of\ncoupled nonlinear PDEs, including multiphysics problems, whose parameters may\nconsist of power series or functionals of the solution variables. Thereby, the\nexploitation of symbolic algebra to express a given DGFEM approximation of a\nPDE problem within a high level language, whose syntax closely resembles the\nmathematical definition, is an invaluable tool. Indeed, this then facilitates\nthe automatic assembly of the resulting system of (nonlinear) equations, as\nwell as the computation of Fr\\'echet derivative(s) of the DGFEM scheme, needed,\nfor example, within a Newton-type solver. However, even exploiting symbolic\nalgebra, the discretisation of coupled systems of PDEs can still be extremely\nverbose and hard to debug. Thereby, in this article we develop a further layer\nof abstraction by designing a class structure for the automatic computation of\nDGFEM formulations. This work has been implemented within the FEniCS package,\nbased on exploiting the Unified Form Language. Numerical examples are presented\nwhich highlight the simplicity of implementation of DGFEMs for the numerical\napproximation of a range of PDE problems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 16:09:06 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Houston", "Paul", ""], ["Sime", "Nathan", ""]]}, {"id": "1804.03807", "submitter": "Jan Verschelde", "authors": "Jan Verschelde", "title": "A Blackbox Polynomial System Solver on Parallel Shared Memory Computers", "comments": "Accepted for publication in the proceedings of CASC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.SC math.AG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A numerical irreducible decomposition for a polynomial system provides\nrepresentations for the irreducible factors of all positive dimensional\nsolution sets of the system, separated from its isolated solutions. Homotopy\ncontinuation methods are applied to compute a numerical irreducible\ndecomposition. Load balancing and pipelining are techniques in a parallel\nimplementation on a computer with multicore processors. The application of the\nparallel algorithms is illustrated on solving the cyclic $n$-roots problems, in\nparticular for $n = 8, 9$, and~12.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 04:41:49 GMT"}, {"version": "v2", "created": "Sun, 17 Jun 2018 19:57:36 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Verschelde", "Jan", ""]]}, {"id": "1804.04021", "submitter": "Henrik Barthels M.Sc.", "authors": "Henrik Barthels, Marcin Copik, Paolo Bientinesi", "title": "The Generalized Matrix Chain Algorithm", "comments": null, "journal-ref": "Proceedings of 2018 IEEE/ACM International Symposium on Code\n  Generation and Optimization, Vienna, Austria, February 24-28, 2018", "doi": "10.1145/3168804", "report-no": null, "categories": "cs.MS cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a generalized version of the matrix chain algorithm\nto generate efficient code for linear algebra problems, a task for which human\nexperts often invest days or even weeks of works. The standard matrix chain\nproblem consists in finding the parenthesization of a matrix product $M := A_1\nA_2 \\cdots A_n$ that minimizes the number of scalar operations. In practical\napplications, however, one frequently encounters more complicated expressions,\ninvolving transposition, inversion, and matrix properties. Indeed, the\ncomputation of such expressions relies on a set of computational kernels that\noffer functionality well beyond the simple matrix product. The challenge then\nshifts from finding an optimal parenthesization to finding an optimal mapping\nof the input expression to the available kernels. Furthermore, it is often the\ncase that a solution based on the minimization of scalar operations does not\nresult in the optimal solution in terms of execution time. In our experiments,\nthe generated code outperforms other libraries and languages on average by a\nfactor of about 9. The motivation for this work comes from the fact\nthat---despite great advances in the development of compilers---the task of\nmapping linear algebra problems to optimized kernels is still to be done\nmanually. In order to relieve the user from this complex task, new techniques\nfor the compilation of linear algebra expressions have to be developed.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 16:32:49 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Barthels", "Henrik", ""], ["Copik", "Marcin", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1804.04737", "submitter": "Demetrios Coutinho Mr.", "authors": "Demetrios Coutinho, Felipe O. Lins e Silva, Daniel Aloise, Samuel and\n  Xavier-de-Souza", "title": "A Scalable Shared-Memory Parallel Simplex for Large-Scale Linear\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Simplex tableau has been broadly used and investigated in the industry\nand academia. With the advent of the big data era, ever larger problems are\nposed to be solved in ever larger machines whose architecture type did not\nexist in the conception of this algorithm. In this paper, we present a\nshared-memory parallel implementation of the Simplex tableau algorithm for\ndense large-scale Linear Programming (LP) problems for use in modern multi-core\narchitectures. We present the general scheme and explain the strategies taken\nto parallelize each step of the standard simplex algorithm, emphasizing the\nsolutions found to solve performance bottlenecks. We analyzed the speedup and\nthe parallel efficiency for the proposed implementation relative to the\nstandard Simplex algorithm using a shared-memory system with 64 processing\ncores. The experiments were performed for several different problems, with up\nto 8192 variables and constraints, in their primal and dual formulations. The\nresults show that the performance is mostly much better when we use the\nformulation with more variables than inequality constraints. Also, they show\nthat the parallelization strategies applied to avoid bottlenecks lead the\nimplementation to scale well with the problem size and the core count up to a\ncertain limit of problem size. Further analysis showed that this scaling limit\nwas an effect of resource limitation. Even though, our implementation was able\nto reach speedups in the order of 19x.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 21:59:40 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 19:52:48 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Coutinho", "Demetrios", ""], ["Silva", "Felipe O. Lins e", ""], ["Aloise", "Daniel", ""], ["Samuel", "", ""], ["Xavier-de-Souza", "", ""]]}, {"id": "1804.04806", "submitter": "Yosuke Oyama", "authors": "Yosuke Oyama, Tal Ben-Nun, Torsten Hoefler, Satoshi Matsuoka", "title": "{\\mu}-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching", "comments": "11 pages, 14 figures. Part of the content have been published in IPSJ\n  SIG Technical Report, Vol. 2017-HPC-162, No. 22, pp. 1-9, 2017. (DOI:\n  http://id.nii.ac.jp/1001/00184814)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used\nin deep learning. Specifically, cuDNN implements several equivalent convolution\nalgorithms, whose performance and memory footprint may vary considerably,\ndepending on the layer dimensions. When an algorithm is automatically selected\nby cuDNN, the decision is performed on a per-layer basis, and thus it often\nresorts to slower algorithms that fit the workspace size constraints. We\npresent {\\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides\nlayers' mini-batch computation into several micro-batches. Based on Dynamic\nProgramming and Integer Linear Programming, {\\mu}-cuDNN enables faster\nalgorithms by decreasing the workspace requirements. At the same time,\n{\\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples\nstatistical efficiency from the hardware efficiency safely. We demonstrate the\neffectiveness of {\\mu}-cuDNN over two frameworks, Caffe and TensorFlow,\nachieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2\nGPU. These results indicate that using micro-batches can seamlessly increase\nthe performance of deep learning, while maintaining the same memory footprint.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 07:20:44 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Oyama", "Yosuke", ""], ["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""], ["Matsuoka", "Satoshi", ""]]}, {"id": "1804.06373", "submitter": "Huber Markus", "authors": "Markus Huber and Ulrich R\\\"ude and Barbara Wohlmuth", "title": "Adaptive control in rollforward recovery for extreme scale multigrid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of compute components, failures in future\nexa-scale computer systems are expected to become more frequent. This motivates\nthe study of novel resilience techniques. Here, we extend a recently proposed\nalgorithm-based recovery method for multigrid iterations by introducing an\nadaptive control. After a fault, the healthy part of the system continues the\niterative solution process, while the solution in the faulty domain is\nre-constructed by an asynchronous on-line recovery. The computations in both\nthe faulty and healthy subdomains must be coordinated in a sensitive way, in\nparticular, both under and over-solving must be avoided. Both of these waste\ncomputational resources and will therefore increase the overall\ntime-to-solution. To control the local recovery and guarantee an optimal\nre-coupling, we introduce a stopping criterion based on a mathematical error\nestimator. It involves hierarchical weighted sums of residuals within the\ncontext of uniformly refined meshes and is well-suited in the context of\nparallel high-performance computing. The re-coupling process is steered by\nlocal contributions of the error estimator. We propose and compare two criteria\nwhich differ in their weights. Failure scenarios when solving up to\n$6.9\\cdot10^{11}$ unknowns on more than 245\\,766 parallel processes will be\nreported on a state-of-the-art peta-scale supercomputer demonstrating the\nrobustness of the method.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 16:58:50 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Huber", "Markus", ""], ["R\u00fcde", "Ulrich", ""], ["Wohlmuth", "Barbara", ""]]}, {"id": "1804.07017", "submitter": "Sandra Catalan", "authors": "Sandra Catal\\'an, Adri\\'an Castell\\'o, Francisco D. Igual, Rafael\n  Rodr\\'iguez-S\\'anchez, Enrique S. Quintana-Ort\\'i", "title": "Programming Parallel Dense Matrix Factorizations with Look-Ahead and\n  OpenMP", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a parallelization strategy for dense matrix factorization\n(DMF) algorithms, using OpenMP, that departs from the legacy (or conventional)\nsolution, which simply extracts concurrency from a multithreaded version of\nBLAS. This approach is also different from the more sophisticated\nruntime-assisted implementations, which decompose the operation into tasks and\nidentify dependencies via directives and runtime support. Instead, our strategy\nattains high performance by explicitly embedding a static look-ahead technique\ninto the DMF code, in order to overcome the performance bottleneck of the panel\nfactorization, and realizing the trailing update via a cache-aware\nmulti-threaded implementation of the BLAS. Although the parallel algorithms are\nspecified with a highlevel of abstraction, the actual implementation can be\neasily derived from them, paving the road to deriving a high performance\nimplementation of a considerable fraction of LAPACK functionality on any\nmulticore platform with an OpenMP-like runtime.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 07:14:36 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Catal\u00e1n", "Sandra", ""], ["Castell\u00f3", "Adri\u00e1n", ""], ["Igual", "Francisco D.", ""], ["Rodr\u00edguez-S\u00e1nchez", "Rafael", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""]]}, {"id": "1804.07236", "submitter": "Niek J. Bouman", "authors": "Niek J. Bouman", "title": "Multiprecision Arithmetic for Cryptology in C++ - Compile-Time\n  Computations and Beating the Performance of Hand-Optimized Assembly at\n  Run-Time", "comments": "9 pages (14 pages including references and appendices)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new C++ library for multiprecision arithmetic for numbers in\nthe order of 100--500 bits, i.e., representable with just a few limbs. The\nlibrary is written in \"optimizing-compiler-friendly\" C++, with an emphasis on\nthe use of fixed-size arrays and particular function-argument-passing styles\n(including the avoidance of naked pointers) to allow the limbs to be allocated\non the stack or even in registers. Depending on the particular functionality,\nwe get close to, or significantly beat the performance of existing libraries\nfor multiprecision arithmetic that employ hand-optimized assembly code.\n  Most functions in the library are constant-time, which is a necessity for\nsecure implementations of cryptographic protocols.\n  Beyond the favorable runtime performance, our library is, to the best of the\nauthor's knowledge, the first library that offers big-integer computations\nduring compile-time. For example, when implementing finite-field arithmetic\nwith a fixed modulus, this feature enables the automatic precomputation (at\ncompile time) of the special modulus-dependent constants required for Barrett\nand Montgomery reduction. Another application is to parse (at compile-time) a\nbase-10-encoded big-integer literal.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:36:15 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bouman", "Niek J.", ""]]}, {"id": "1804.07598", "submitter": "Ivo Sbalzarini", "authors": "Pietro Incardona, Antonio Leo, Yaroslav Zaluzhnyi, Rajesh Ramaswamy,\n  Ivo F. Sbalzarini", "title": "OpenFPM: A scalable open framework for particle and particle-mesh codes\n  on parallel computers", "comments": "32 pages, 12 figures", "journal-ref": null, "doi": "10.1016/j.cpc.2019.03.007", "report-no": null, "categories": "cs.DC cs.MS cs.SE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalable and efficient numerical simulations continue to gain importance, as\ncomputation is firmly established as the third pillar of discovery, alongside\ntheory and experiment. Meanwhile, the performance of computing hardware grows\nthrough increasing heterogeneous parallelism, enabling simulations of ever more\ncomplex models. However, efficiently implementing scalable codes on\nheterogeneous, distributed hardware systems becomes the bottleneck. This\nbottleneck can be alleviated by intermediate software layers that provide\nhigher-level abstractions closer to the problem domain, hence allowing the\ncomputational scientist to focus on the simulation. Here, we present OpenFPM,\nan open and scalable framework that provides an abstraction layer for numerical\nsimulations using particles and/or meshes. OpenFPM provides transparent and\nscalable infrastructure for shared-memory and distributed-memory\nimplementations of particles-only and hybrid particle-mesh simulations of both\ndiscrete and continuous models, as well as non-simulation codes. This\ninfrastructure is complemented with portable implementations of frequently used\nnumerical routines, as well as interfaces to third-party libraries. We present\nthe architecture and design of OpenFPM, detail the underlying abstractions, and\nbenchmark the framework in applications ranging from Smoothed-Particle\nHydrodynamics (SPH) to Molecular Dynamics (MD), Discrete Element Methods (DEM),\nVortex Methods, stencil codes, high-dimensional Monte Carlo sampling (CMA-ES),\nand Reaction-Diffusion solvers, comparing it to the current state of the art\nand existing software frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 13:18:50 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Incardona", "Pietro", ""], ["Leo", "Antonio", ""], ["Zaluzhnyi", "Yaroslav", ""], ["Ramaswamy", "Rajesh", ""], ["Sbalzarini", "Ivo F.", ""]]}, {"id": "1804.09536", "submitter": "Mikael Mortensen", "authors": "Lisandro Dalcin, Mikael Mortensen, David E Keyes", "title": "Fast parallel multidimensional FFT using advanced MPI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for performing global redistributions of\nmultidimensional arrays essential to parallel fast Fourier (or similar)\ntransforms. Traditional methods use standard all-to-all collective\ncommunication of contiguous memory buffers, thus necessary requiring local data\nrealignment steps intermixed in-between redistribution and transform steps.\nInstead, our method takes advantage of subarray datatypes and generalized\nall-to-all scatter/gather from the MPI-2 standard to communicate discontiguous\nmemory buffers, effectively eliminating the need for local data realignments.\nDespite generalized all-to-all communication of discontiguous data being\ngenerally slower, our proposal economizes in local work. For a range of strong\nand weak scaling tests, we found the overall performance of our method to be on\npar and often better than well-established libraries like MPI-FFTW, P3DFFT, and\n2DECOMP&FFT. We provide compact routines implemented at the highest possible\nlevel using the MPI bindings for the C programming language. These routines\napply to any global redistribution, over any two directions of a\nmultidimensional array, decomposed on arbitrary Cartesian processor grids (1D\nslabs, 2D pencils, or even higher-dimensional decompositions). The high level\nimplementation makes the code easy to read, maintain, and eventually extend.\nOur approach enables for future speedups from optimizations in the internal\ndatatype handling engines within MPI implementations.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 13:20:53 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Dalcin", "Lisandro", ""], ["Mortensen", "Mikael", ""], ["Keyes", "David E", ""]]}, {"id": "1804.10112", "submitter": "Stephen Chou", "authors": "Stephen Chou, Fredrik Kjolstad, Saman Amarasinghe", "title": "Format Abstraction for Sparse Tensor Algebra Compilers", "comments": "Presented at OOPSLA 2018", "journal-ref": "Proc. ACM Program. Lang. 2, OOPSLA, Article 123 (November 2018)", "doi": "10.1145/3276493", "report-no": null, "categories": "cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how to build a sparse tensor algebra compiler that is\nagnostic to tensor formats (data layouts). We develop an interface that\ndescribes formats in terms of their capabilities and properties, and show how\nto build a modular code generator where new formats can be added as plugins. We\nthen describe six implementations of the interface that compose to form the\ndense, CSR/CSF, COO, DIA, ELL, and HASH tensor formats and countless variants\nthereof. With these implementations at hand, our code generator can generate\ncode to compute any tensor algebra expression on any combination of the\naforementioned formats.\n  To demonstrate our technique, we have implemented it in the taco tensor\nalgebra compiler. Our modular code generator design makes it simple to add\nsupport for new tensor formats, and the performance of the generated code is\ncompetitive with hand-optimized implementations. Furthermore, by extending taco\nto support a wider range of formats specialized for different application and\ndata characteristics, we can improve end-user application performance. For\nexample, if input data is provided in the COO format, our technique allows\ncomputing a single matrix-vector multiplication directly with the data in COO,\nwhich is up to 3.6$\\times$ faster than by first converting the data to CSR.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 20:57:59 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 02:16:20 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Chou", "Stephen", ""], ["Kjolstad", "Fredrik", ""], ["Amarasinghe", "Saman", ""]]}, {"id": "1804.10120", "submitter": "Adam Lewis", "authors": "Adam G.M. Lewis and Harald P. Pfeiffer", "title": "Automatic generation of CUDA code performing tensor manipulations using\n  C++ expression templates", "comments": "46 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a C++ library, TLoops, which uses a hierarchy of expression\ntemplates to represent operations upon tensorial quantities in single lines of\nC++ code that resemble analytic equations. These expressions may be run as-is,\nbut may also be used to emit equivalent low-level C or CUDA code, which either\nperforms the operations more quickly on the CPU, or allows them to be rapidly\nported to run on NVIDIA GPUs. We detail the expression template and C++-class\nhierarchy that represents the expressions and which makes automatic\ncode-generation possible. We then present benchmarks of the expression-template\ncode, the automatically generated C code, and the automatically generated CUDA\ncode running on several generations of NVIDIA GPU.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:54:12 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Lewis", "Adam G. M.", ""], ["Pfeiffer", "Harald P.", ""]]}, {"id": "1804.10694", "submitter": "R. Baghdadi", "authors": "Riyadh Baghdadi, Jessica Ray, Malek Ben Romdhane, Emanuele Del Sozzo,\n  Abdurrahman Akkas, Yunming Zhang, Patricia Suriana, Shoaib Kamil, Saman\n  Amarasinghe", "title": "Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.00419", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.MS cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Tiramisu, a polyhedral framework designed to generate\nhigh performance code for multiple platforms including multicores, GPUs, and\ndistributed machines. Tiramisu introduces a scheduling language with novel\nextensions to explicitly manage the complexities that arise when targeting\nthese systems. The framework is designed for the areas of image processing,\nstencils, linear algebra and deep learning. Tiramisu has two main features: it\nrelies on a flexible representation based on the polyhedral model and it has a\nrich scheduling language allowing fine-grained control of optimizations.\nTiramisu uses a four-level intermediate representation that allows full\nseparation between the algorithms, loop transformations, data layouts, and\ncommunication. This separation simplifies targeting multiple hardware\narchitectures with the same algorithm. We evaluate Tiramisu by writing a set of\nimage processing, deep learning, and linear algebra benchmarks and compare them\nwith state-of-the-art compilers and hand-tuned libraries. We show that Tiramisu\nmatches or outperforms existing compilers and libraries on different hardware\narchitectures, including multicore CPUs, GPUs, and distributed machines.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 21:28:44 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 19:58:57 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 21:24:44 GMT"}, {"version": "v4", "created": "Tue, 18 Dec 2018 02:41:00 GMT"}, {"version": "v5", "created": "Thu, 20 Dec 2018 16:25:40 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Baghdadi", "Riyadh", ""], ["Ray", "Jessica", ""], ["Romdhane", "Malek Ben", ""], ["Del Sozzo", "Emanuele", ""], ["Akkas", "Abdurrahman", ""], ["Zhang", "Yunming", ""], ["Suriana", "Patricia", ""], ["Kamil", "Shoaib", ""], ["Amarasinghe", "Saman", ""]]}]