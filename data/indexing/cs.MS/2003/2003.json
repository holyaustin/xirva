[{"id": "2003.00142", "submitter": "Huckleberry Febbo", "authors": "Huckleberry Febbo, Paramsothy Jayakumar, Jeffrey L. Stein, Tulga Ersal", "title": "NLOptControl: A modeling language for solving optimal control problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current direct-collocation-based optimal control software is either easy to\nuse or fast, but not both. This is a major limitation for users that are trying\nto formulate complex optimal control problems (OCPs) for use in on-line\napplications. This paper introduces NLOptControl, an open-source modeling\nlanguage that allows users to both easily formulate and quickly solve nonlinear\nOCPs using direct-collocation methods. To achieve these attributes,\nNLOptControl (1) is written in an efficient, dynamically-typed computing\nlanguage called Julia, (2) extends an optimization modeling language called\nJuMP to provide a natural algebraic syntax for modeling nonlinear OCPs; and (3)\nuses reverse automatic differentiation with the acrylic-coloring method to\nexploit sparsity in the Hessian matrix. This work explores the novel design\nfeatures of NLOptControl and compares its syntax and speed to those of PROPT.\nThe syntax comparisons shows that NLOptControl models OCPs more concisely than\nPROPT. The speeds of various collocation methods within PROPT and NLOptControl\nare benchmarked over a range of collocation points using performance profiles;\noverall, NLOptControl's single, two, and four interval pseudospectral methods\nare roughly $14$, $26$, and $36$ times faster than PROPT's, respectively.\nNLOptControl is well-suited to improve existing off-line and on-line control\nsystems and to engender new ones.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 00:55:28 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 18:44:31 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Febbo", "Huckleberry", ""], ["Jayakumar", "Paramsothy", ""], ["Stein", "Jeffrey L.", ""], ["Ersal", "Tulga", ""]]}, {"id": "2003.02088", "submitter": "Jens Saak", "authors": "Peter Benner, Martin K\\\"ohler, Jens Saak", "title": "Matrix Equations, Sparse Solvers: M-M.E.S.S.-2.0.1 -- Philosophy,\n  Features and Application for (Parametric) Model", "comments": "18 pages, 4 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix equations are omnipresent in (numerical) linear algebra and systems\ntheory. Especially in model order reduction (MOR) they play a key role in many\nbalancing based reduction methods for linear dynamical systems. When these\nsystems arise from spatial discretizations of evolutionary partial differential\nequations, their coefficient matrices are typically large and sparse. Moreover,\nthe numbers of inputs and outputs of these systems are typically far smaller\nthan the number of spatial degrees of freedom. Then, in many situations the\nsolutions of the corresponding large-scale matrix equations are observed to\nhave low (numerical) rank. This feature is exploited by M-M.E.S.S. to find\nsuccessively larger low-rank factorizations approximating the solutions. This\ncontribution describes the basic philosophy behind the implementation and the\nfeatures of the package, as well as its application in the model order\nreduction of large-scale linear time-invariant (LTI) systems and parametric LTI\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 14:02:21 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 12:42:10 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Benner", "Peter", ""], ["K\u00f6hler", "Martin", ""], ["Saak", "Jens", ""]]}, {"id": "2003.03099", "submitter": "Brian Castellani", "authors": "Corey Schimpf and Brian Castellani", "title": "COMPLEX-IT: A Case-Based Modeling and Scenario Simulation Platform for\n  Social Inquiry", "comments": null, "journal-ref": "Journal of Open Research Software (2020) 8:25", "doi": "10.5334/jors.298", "report-no": null, "categories": "cs.MS cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COMPLEX-IT is a case-based, mixed-methods platform for social inquiry into\ncomplex data/systems, designed to increase non-expert access to the tools of\ncomputational social science (i.e., cluster analysis, artificial intelligence,\ndata visualization, data forecasting, and scenario simulation). In particular,\nCOMPLEX-IT aids social inquiry though a heavy emphasis on learning about the\ncomplex data/system under study, which it does by (a) identifying and\nforecasting major and minor clusters/trends; (b) visualizing their complex\ncausality; and (c) simulating scenarios for potential interventions. COMPLEX-IT\nis accessible through the web or can be run locally and is powered by R and the\nShiny web framework.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 09:27:10 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Schimpf", "Corey", ""], ["Castellani", "Brian", ""]]}, {"id": "2003.03994", "submitter": "Divyam Aggarwal", "authors": "Divyam Aggarwal, Dhish Kumar Saxena, Thomas B\\\"ack, Michael Emmerich", "title": "Airline Crew Pairing Optimization Framework for Large Networks with\n  Multiple Crew Bases and Hub-and-Spoke Subnetworks", "comments": "28 pages, 3 figures, 9 tables, manuscript submitted for review in a\n  refereed journal. A patent application, based on this research, has been\n  filed in the Netherlands Patent Office. Moreover, D. Aggarwal (author)\n  received the IEEE-ITSS Young Professionals Travelling Fellowship Award for\n  presenting this research work at IEEE ITSC 2019, held in Auckland, New\n  Zealand in October 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.OC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Crew Pairing Optimization aims at generating a set of flight sequences (crew\npairings), covering all flights in an airline's flight schedule, at minimum\ncost, while satisfying several legality constraints. CPO is critically\nimportant for airlines' business viability, considering that the crew operating\ncost is their second-largest expense. It poses an NP-hard combinatorial\noptimization problem, to tackle which, the state-of-the-art relies on relaxing\nthe underlying Integer Programming Problem (IPP) into a Linear Programming\nProblem (LPP), solving the latter through Column Generation (CG) technique, and\nintegerization of the resulting LPP solution. However, with the growing scale\nand complexity of the flight networks (those with a large number of flights,\nmultiple crew bases and/or multiple hub-and-spoke subnetworks), the utility of\nthe conventional CG-practices has become questionable. This paper proposed an\nAirline Crew Pairing Optimization Framework, AirCROP, whose constitutive\nmodules include the Legal Crew Pairing Generator, Initial Feasible Solution\nGenerator, and an Optimization Engine built on heuristic-based\nCG-implementation. In this paper, besides the design of AirCROP's modules,\ninsights into important questions related to how these modules interact, which\nthe literature is otherwise silent on, have been shared. These relate to the\nsensitivity of AirCROP's performance towards: sources of variability over\nmultiple runs for a given problem, initialization method, and termination\nparameters for LPP-solutioning and IPP-solutioning. The efficacy of the AirCROP\nhas been demonstrated on real-world large-scale and complex flight networks\n(with over 4200 flights, 15 crew bases, and billion-plus pairings). It is hoped\nthat with the emergence of such complex flight networks, this paper shall serve\nas an important milestone for affiliated research and applications.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 09:34:20 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 23:27:33 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Aggarwal", "Divyam", ""], ["Saxena", "Dhish Kumar", ""], ["B\u00e4ck", "Thomas", ""], ["Emmerich", "Michael", ""]]}, {"id": "2003.04103", "submitter": "Ryan Curtin", "authors": "Ryan R. Curtin, Marcus Edel, Rahul Ganesh Prabhu, Suryoday Basak,\n  Zhihao Lou, Conrad Sanderson", "title": "Flexible numerical optimization with ensmallen", "comments": "https://ensmallen.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG cs.SE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report provides an introduction to the ensmallen numerical optimization\nlibrary, as well as a deep dive into the technical details of how it works. The\nlibrary provides a fast and flexible C++ framework for mathematical\noptimization of arbitrary user-supplied functions. A large set of pre-built\noptimizers is provided, including many variants of Stochastic Gradient Descent\nand Quasi-Newton optimizers. Several types of objective functions are\nsupported, including differentiable, separable, constrained, and categorical\nobjective functions. Implementation of a new optimizer requires only one\nmethod, while a new objective function requires typically only one or two C++\nmethods. Through internal use of C++ template metaprogramming, ensmallen\nprovides support for arbitrary user-supplied callbacks and automatic inference\nof unsupplied methods without any runtime overhead. Empirical comparisons show\nthat ensmallen outperforms other optimization frameworks (such as Julia and\nSciPy), sometimes by large margins. The library is available at\nhttps://ensmallen.org and is distributed under the permissive BSD license.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 12:57:42 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 12:12:28 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2020 12:48:01 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Curtin", "Ryan R.", ""], ["Edel", "Marcus", ""], ["Prabhu", "Rahul Ganesh", ""], ["Basak", "Suryoday", ""], ["Lou", "Zhihao", ""], ["Sanderson", "Conrad", ""]]}, {"id": "2003.04776", "submitter": "Mirko Myllykoski", "authors": "Carl Christian Kjelgaard Mikkelsen and Mirko Myllykoski", "title": "Parallel Robust Computation of Generalized Eigenvectors of Matrix\n  Pencils", "comments": "This manuscript was accepted to 13th International Conference on\n  Parallel Processing and Applied Mathematics (PPAM2019), Bialystok, Poland,\n  September 8-11, 2019. The final authenticated version is available online at\n  https://doi.org/10.1007/978-3-030-43229-4_6 (DOI valid from May 8, 2020\n  onward). First author's first name is \"Carl Christian\" and last name\n  \"Kjelgaard Mikkelsen\"", "journal-ref": "LNCS 12043 (2020) 58-69", "doi": "10.1007/978-3-030-43229-4_6", "report-no": null, "categories": "cs.MS cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of computing generalized eigenvectors\nof a matrix pencil in real Schur form. In exact arithmetic, this problem can be\nsolved using substitution. In practice, substitution is vulnerable to\nfloating-point overflow. The robust solvers xTGEVC in LAPACK prevent overflow\nby dynamically scaling the eigenvectors. These subroutines are sequential\nscalar codes which compute the eigenvectors one by one. In this paper we\ndiscuss how to derive robust blocked algorithms. The new StarNEig library\ncontains a robust task-parallel solver Zazamoukh which runs on top of StarPU.\nOur numerical experiments show that Zazamoukh achieves a super-linear speedup\ncompared with DTGEVC for sufficiently large matrices.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 14:37:39 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Mikkelsen", "Carl Christian Kjelgaard", ""], ["Myllykoski", "Mirko", ""]]}, {"id": "2003.05361", "submitter": "Pratik Nayak", "authors": "Pratik Nayak, Terry Cojean, Hartwig Anzt", "title": "Evaluating Abstract Asynchronous Schwarz solvers on GPUs", "comments": "Preprint submitted to IJHPCA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the commencement of the exascale computing era, we realize that the\nmajority of the leadership supercomputers are heterogeneous and massively\nparallel even on a single node with multiple co-processors such as GPUs and\nmultiple cores on each node. For example, ORNLs Summit accumulates six NVIDIA\nTesla V100s and 42 core IBM Power9s on each node. Synchronizing across all\nthese compute resources in a single node or even across multiple nodes is\nprohibitively expensive. Hence it is necessary to develop and study\nasynchronous algorithms that circumvent this issue of bulk-synchronous\ncomputing for massive parallelism. In this study, we examine the asynchronous\nversion of the abstract Restricted Additive Schwarz method as a solver where we\ndo not explicitly synchronize, but allow for communication of the data between\nthe sub-domains to be completely asynchronous thereby removing the bulk\nsynchronous nature of the algorithm.\n  We accomplish this by using the onesided RMA functions of the MPI standard.\nWe study the benefits of using such an asynchronous solver over its synchronous\ncounterpart on both multi-core architectures and on multiple GPUs. We also\nstudy the communication patterns and local solvers and their effect on the\nglobal solver. Finally, we show that this concept can render attractive runtime\nbenefits over the synchronous counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 15:28:53 GMT"}, {"version": "v2", "created": "Tue, 5 May 2020 12:14:52 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Nayak", "Pratik", ""], ["Cojean", "Terry", ""], ["Anzt", "Hartwig", ""]]}, {"id": "2003.05755", "submitter": "Uwe Naumann", "authors": "Uwe Naumann", "title": "Optimization of Generalized Jacobian Chain Products without Memory\n  Constraints", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DM cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient computation of Jacobians represents a fundamental challenge in\ncomputational science and engineering. Large-scale modular numerical simulation\nprograms can be regarded as sequences of evaluations of in our case\ndifferentiable modules with corresponding local Jacobians. The latter are\ntypically not available. Tangent and adjoint versions of the individual modules\nare assumed to be given as results of algorithmic differentiation instead. The\nclassical (Jacobian) matrix chain product formulation is extended with the\noptional evaluation of matrix-free Jacobian-matrix and matrix-Jacobian products\nas tangents and adjoints. We propose a dynamic programming algorithm for the\nminimization of the computational cost of such generalized Jacobian chain\nproducts without considering constraints on the available persistent system\nmemory. In other words, the naive evaluation of an adjoint of the entire\nsimulation program is assumed to be a feasible option. No checkpointing is\nrequired. Under the given assumptions we obtain optimal solutions which improve\nthe best state of the art methods by factors of up to seven on a set of\nrandomly generated problem instances of growing size.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 12:49:19 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 16:01:18 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 18:30:08 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Naumann", "Uwe", ""]]}, {"id": "2003.05825", "submitter": "Petar Mlinari\\'c", "authors": "Petar Mlinari\\'c, Stephan Rave, Jens Saak", "title": "Parametric model order reduction using pyMOR", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA cs.SY eess.SY math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  pyMOR is a free software library for model order reduction that includes both\nreduced basis and system-theoretic methods. All methods are implemented in\nterms of abstract vector and operator interfaces, which allows direct\nintegration of pyMOR's algorithms with a wide array of external PDE solvers. In\nthis contribution, we give a brief overview of the available methods and\nexperimentally compare them for the parametric instationary thermal-block\nbenchmark defined in arXiv:2003.00846.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 14:50:53 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 15:20:02 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Mlinari\u0107", "Petar", ""], ["Rave", "Stephan", ""], ["Saak", "Jens", ""]]}, {"id": "2003.06181", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson (LFANT)", "title": "FunGrim: a symbolic library for special functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Mathematical Functions Grimoire (FunGrim), a website and\ndatabase of formulas and theorems for special functions. We also discuss the\nsymbolic computation library used as the backend and main development tool for\nFunGrim, and the Grim formula language used in these projects to represent\nmathematical content semantically.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 10:07:21 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Johansson", "Fredrik", "", "LFANT"]]}, {"id": "2003.06316", "submitter": "Jon Lee", "authors": "Hessa Al-Thani and Jon Lee", "title": "An R Package for generating covariance matrices for maximum-entropy\n  sampling from precipitation chemistry data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an open-source R package (MESgenCov v 0.1.0) for temporally\nfitting multivariate precipitation chemistry data and extracting a covariance\nmatrix for use in the MESP (maximum-entropy sampling problem). We provide\nmultiple functionalities for modeling and model assessment. The package is\ntightly coupled with NADP/NTN (National Atmospheric Deposition Program /\nNational Trends Network) data from their set of 379 monitoring sites,\n1978--present. The user specifies the sites, chemicals, and time period\ndesired, fits an appropriate user-specified univariate model for each site and\nchemical selected, and the package produces a covariance matrix for use by MESP\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 14:23:22 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 15:06:22 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Al-Thani", "Hessa", ""], ["Lee", "Jon", ""]]}, {"id": "2003.06701", "submitter": "Vedran Novakovi\\'c", "authors": "Vedran Novakovi\\'c and Sanja Singer", "title": "A Kogbetliantz-type algorithm for the hyperbolic SVD", "comments": "a major revision version with 35 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a two-sided, parallel Kogbetliantz-type algorithm for the\nhyperbolic singular value decomposition (HSVD) of real and complex square\nmatrices is developed, with a single assumption that the input matrix, of order\n$n$, admits such a decomposition into the product of a unitary, a non-negative\ndiagonal, and a $J$-unitary matrix, where $J$ is a given diagonal matrix of\npositive and negative signs. When $J=\\pm I$, the proposed algorithm computes\nthe ordinary SVD. The paper's most important contribution -- a derivation of\nformulas for the HSVD of $2\\times 2$ matrices -- is presented first, followed\nby the details of their implementation in floating-point arithmetic. Next, the\neffects of the hyperbolic transformations on the columns of the iteration\nmatrix are discussed. These effects then guide a redesign of the dynamic pivot\nordering, being already a well-established pivot strategy for the ordinary\nKogbetliantz algorithm, for the general, $n\\times n$ HSVD. A heuristic but\nsound convergence criterion is then proposed, which contributes to high\naccuracy demonstrated in the numerical testing results. Such a $J$-Kogbetliantz\nalgorithm as presented here is intrinsically slow, but is nevertheless usable\nfor matrices of small orders.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 20:54:39 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 22:54:16 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 20:41:21 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Novakovi\u0107", "Vedran", ""], ["Singer", "Sanja", ""]]}, {"id": "2003.07798", "submitter": "Francesco Rizzi", "authors": "Francesco Rizzi, Patrick J. Blonigan, Kevin T. Carlberg", "title": "Pressio: Enabling projection-based model reduction for large-scale\n  nonlinear dynamical systems", "comments": "32 pages, 5 figures, supplement of 6 pages; Added references in\n  intro, corrected fig5b, few more clarifications in sec4.2", "journal-ref": null, "doi": null, "report-no": "SAND2020-1279 J, SAND2020-1445 J", "categories": "cs.MS cs.CE physics.comp-ph physics.flu-dyn", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work introduces Pressio, an open-source project aimed at enabling\nleading-edge projection-based reduced order models (ROMs) for large-scale\nnonlinear dynamical systems in science and engineering. Pressio provides\nmodel-reduction methods that can reduce both the number of spatial and temporal\ndegrees of freedom for any dynamical system expressible as a system of\nparameterized ordinary differential equations (ODEs). We leverage this simple,\nexpressive mathematical framework as a pivotal design choice to enable a\nminimal application programming interface (API) that is natural to dynamical\nsystems. The core component of Pressio is a C++11 header-only library that\nleverages generic programming to support applications with arbitrary data types\nand arbitrarily complex programming models. This is complemented with Python\nbindings to expose these C++ functionalities to Python users with negligible\noverhead and no user-required binding code. We discuss the distinguishing\ncharacteristics of Pressio relative to existing model-reduction libraries,\noutline its key design features, describe how the user interacts with it, and\npresent two test cases---including one with over 20 million degrees of\nfreedom---that highlight the performance results of Pressio and illustrate the\nbreath of problems that can be addressed with it.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:25:10 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 12:42:46 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Rizzi", "Francesco", ""], ["Blonigan", "Patrick J.", ""], ["Carlberg", "Kevin T.", ""]]}, {"id": "2003.09956", "submitter": "Leonid Sokolinsky", "authors": "Leonid B. Sokolinsky, Irina M. Sokolinskaya", "title": "Scalable parallel algorithm for solving non-stationary systems of linear\n  inequalities", "comments": "This a preprint of the Work accepted for publication in Lobachevskii\n  Journal of Mathematics, \\c{opyright} 2020, Springer Nature", "journal-ref": "Lobachevskii J. Math. 41 (2020) 1571-1580", "doi": "10.1134/S1995080220080181", "report-no": null, "categories": "cs.MS cs.NA math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a scalable iterative projection-type algorithm for solving\nnon-stationary systems of linear inequalities is considered. A non-stationary\nsystem is understood as a large-scale system of inequalities in which\ncoefficients and constant terms can change during the calculation process. The\nproposed parallel algorithm uses the concept of pseudo-projection which\ngeneralizes the notion of orthogonal projection. The parallel pseudo-projection\nalgorithm is implemented using the parallel BSF-skeleton. An analytical\nestimation of the algorithm scalability boundary is obtained on the base of the\nBSF cost metric. The large-scale computational experiments were performed on a\ncluster computing system. The obtained results confirm the efficiency of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 17:44:23 GMT"}, {"version": "v2", "created": "Fri, 21 Aug 2020 06:12:56 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Sokolinsky", "Leonid B.", ""], ["Sokolinskaya", "Irina M.", ""]]}, {"id": "2003.11914", "submitter": "Sivan Toledo", "authors": "Nir Goren, Dan Halperin, and Sivan Toledo", "title": "Geometric Sparsification of Closeness Relations: Eigenvalue Clustering\n  for Computing Matrix Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to efficiently solve a clustering problem that arises in a method\nto evaluate functions of matrices. The problem requires finding the connected\ncomponents of a graph whose vertices are eigenvalues of a real or complex\nmatrix and whose edges are pairs of eigenvalues that are at most \\delta away\nfrom each other. Davies and Higham proposed solving this problem by enumerating\nthe edges of the graph, which requires at least $\\Omega(n^{2})$ work. We show\nthat the problem can be solved by computing the Delaunay triangulation of the\neigenvalues, removing from it long edges, and computing the connected\ncomponents of the remaining edges in the triangulation. This leads to an\n$O(n\\log n)$ algorithm. We have implemented both algorithms using CGAL, a\nmature and sophisticated computational-geometry software library, and we\ndemonstrate that the new algorithm is much faster in practice than the naive\nalgorithm. We also present a tight analysis of the naive algorithm, showing\nthat it performs $\\Theta(n^{2})$ work, and correct a misrepresentation in the\noriginal statement of the problem. To the best of our knowledge, this is the\nfirst application of computational geometry to solve a real-world problem in\nnumerical linear algebra.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 08:21:58 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Goren", "Nir", ""], ["Halperin", "Dan", ""], ["Toledo", "Sivan", ""]]}, {"id": "2003.12029", "submitter": "Jan Legersk\\'y", "authors": "Georg Grasegger and Jan Legersk\\'y", "title": "FlexRiLoG -- A SageMath Package for Motions of Graphs", "comments": null, "journal-ref": "In: Bigatti A., Carette J., Davenport J., Joswig M., de Wolff T.\n  (eds) Mathematical Software - ICMS 2020. Lecture Notes in Computer Science,\n  vol. 12097", "doi": "10.1007/978-3-030-52200-1_44", "report-no": null, "categories": "cs.MS cs.RO math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the SageMath package FlexRiLoG (short for flexible\nand rigid labelings of graphs). Based on recent results the software generates\nmotions of graphs using special edge colorings. The package computes and\nillustrates the colorings and the motions. We present the structure and usage\nof the package.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:50:43 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Grasegger", "Georg", ""], ["Legersk\u00fd", "Jan", ""]]}, {"id": "2003.12787", "submitter": "Anne Reinarz", "authors": "Jean-Matthieu Gallard, Leonhard Rannabauer, Anne Reinarz, Michael\n  Bader", "title": "Vectorization and Minimization of Memory Footprint for Linear High-Order\n  Discontinuous Galerkin Schemes", "comments": "PDSEC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a sequence of optimizations to the performance-critical compute\nkernels of the high-order discontinuous Galerkin solver of the hyperbolic PDE\nengine ExaHyPE -- successively tackling bottlenecks due to SIMD operations,\ncache hierarchies and restrictions in the software design.\n  Starting from a generic scalar implementation of the numerical scheme, our\nfirst optimized variant applies state-of-the-art optimization techniques by\nvectorizing loops, improving the data layout and using Loop-over-GEMM to\nperform tensor contractions via highly optimized matrix multiplication\nfunctions provided by the LIBXSMM library. We show that memory stalls due to a\nmemory footprint exceeding our L2 cache size hindered the vectorization gains.\nWe therefore introduce a new kernel that applies a sum factorization approach\nto reduce the kernel's memory footprint and improve its cache locality. With\nthe L2 cache bottleneck removed, we were able to exploit additional\nvectorization opportunities, by introducing a hybrid\nArray-of-Structure-of-Array data layout that solves the data layout conflict\nbetween matrix multiplications kernels and the point-wise functions to\nimplement PDE-specific terms.\n  With this last kernel, evaluated in a benchmark simulation at high polynomial\norder, only 2\\% of the floating point operations are still performed using\nscalar instructions and 22.5\\% of the available performance is achieved.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 13:27:09 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Gallard", "Jean-Matthieu", ""], ["Rannabauer", "Leonhard", ""], ["Reinarz", "Anne", ""], ["Bader", "Michael", ""]]}, {"id": "2003.12861", "submitter": "Stephan Hageboeck", "authors": "Stephan Hageboeck and Lorenzo Moneta", "title": "Making RooFit Ready for Run 3", "comments": "5 pages, 5 figures. Proceedings of ACAT 2019. Submitted to Journal Of\n  Physics: Conference Series", "journal-ref": "2020 J. Phys.: Conf. Ser. 1525 012114", "doi": "10.1088/1742-6596/1525/1/012114", "report-no": null, "categories": "cs.MS hep-ex physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used\nin most searches and measurements at the Large Hadron Collider. The data to be\ncollected in Run 3 will enable measurements with higher precision and models\nwith larger complexity, but also require faster data processing. In this work,\nfirst results on modernising RooFit's collections, restructuring data flow and\nvectorising likelihood fits in RooFit will be discussed. These improvements\nwill enable the LHC experiments to process larger datasets without having to\ncompromise with respect to model complexity, as fitting times would increase\nsignificantly with the large datasets to be expected in Run 3.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 18:22:20 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Hageboeck", "Stephan", ""], ["Moneta", "Lorenzo", ""]]}, {"id": "2003.12875", "submitter": "Stephan Hageboeck", "authors": "Stephan Hageboeck", "title": "A Faster, More Intuitive RooFit", "comments": "6 pages, 2 figures. Proceedings of 24th International Conference on\n  Computing in High Energy & Nuclear Physics. Submitted to EPJ Web of\n  Conferences v2: Correct a function name, minor improvements of wording\n  suggested by reviewer v3: Update a code listing", "journal-ref": "EPJ Web Conf. 245 (2020) 06007", "doi": "10.1051/epjconf/202024506007", "report-no": null, "categories": "cs.MS hep-ex physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used\nin most searches and measurements at the Large Hadron Collider as well as at\n$B$ factories. Larger datasets to be collected at e.g. the High-Luminosity LHC\nwill enable measurements with higher precision, but will require faster data\nprocessing to keep fitting times stable. In this work, a simplification of\nRooFit's interfaces and a redesign of its internal dataflow is presented.\nInterfaces are being extended to look and feel more STL-like to be more\naccessible both from C++ and Python to improve interoperability and ease of\nuse, while maintaining compatibility with old code. The redesign of the\ndataflow improves cache locality and data loading, and can be used to process\nbatches of data with vectorised SIMD computations. This reduces the time for\ncomputing unbinned likelihoods by a factor four to 16. This will allow to fit\nlarger datasets of the future in the same time or faster than today's fits.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 19:12:32 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 10:16:56 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 12:36:28 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Hageboeck", "Stephan", ""]]}]