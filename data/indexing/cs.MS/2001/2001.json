[{"id": "2001.00532", "submitter": "Ryan Senanayake", "authors": "Ryan Senanayake, Fredrik Kjolstad, Changwan Hong, Shoaib Kamil, and\n  Saman Amarasinghe", "title": "A Unified Iteration Space Transformation Framework for Sparse and Dense\n  Tensor Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of optimizing mixed sparse and dense tensor algebra in\na compiler. We show that standard loop transformations, such as strip-mining,\ntiling, collapsing, parallelization and vectorization, can be applied to\nirregular loops over sparse iteration spaces. We also show how these\ntransformations can be applied to the contiguous value arrays of sparse tensor\ndata structures, which we call their position space, to unlock load-balanced\ntiling and parallelism.\n  We have prototyped these concepts in the open-source TACO system, where they\nare exposed as a scheduling API similar to the Halide domain-specific language\nfor dense computations. Using this scheduling API, we show how to optimize\nmixed sparse/dense tensor algebra expressions, how to generate load-balanced\ncode by scheduling sparse tensor algebra in position space, and how to generate\nsparse tensor algebra GPU code. Our evaluation shows that our transformations\nlet us generate good code that is competitive with many hand-optimized\nimplementations from the literature.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 23:17:48 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Senanayake", "Ryan", ""], ["Kjolstad", "Fredrik", ""], ["Hong", "Changwan", ""], ["Kamil", "Shoaib", ""], ["Amarasinghe", "Saman", ""]]}, {"id": "2001.01496", "submitter": "Mantas Mikaitis", "authors": "Mantas Mikaitis", "title": "Issues with rounding in the GCC implementation of the ISO 18037:2008\n  standard fixed-point arithmetic", "comments": "To appear in the proceedings of the 27th IEEE Symposium on Computer\n  Arithmetic", "journal-ref": null, "doi": "10.1109/ARITH48897.2020.00028", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe various issues caused by the lack of round-to-nearest mode in the\n\\textit{gcc} compiler implementation of the fixed-point arithmetic data types\nand operations. We demonstrate that round-to-nearest is not performed in the\nconversion of constants, conversion from one numerical type to a less precise\ntype and results of multiplications. Furthermore, we show that mixed-precision\noperations in fixed-point arithmetic lose precision on arguments, even before\ncarrying out arithmetic operations. The ISO 18037:2008 standard was created to\nstandardize C language extensions, including fixed-point arithmetic, for\nembedded systems. Embedded systems are usually based on ARM processors, of\nwhich approximately 100 billion have been manufactured by now. Therefore, the\nobservations about numerical issues that we discuss in this paper can be rather\ndangerous and are important to address, given the wide ranging type of\napplications that these embedded systems are running.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 11:37:04 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 10:24:09 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2020 09:58:03 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Mikaitis", "Mantas", ""]]}, {"id": "2001.01583", "submitter": "Yong-Lei Wang", "authors": "Sheng-Chun Yang and Yong-Lei Wang", "title": "A Hybrid MPI-CUDA Approach for Nonequispaced Discrete Fourier\n  Transformation", "comments": "16 pages, 16 figures", "journal-ref": "Comput. Phys. Commun. (2020)", "doi": "10.1016/j.cpc.2020.107513", "report-no": null, "categories": "cs.MS cond-mat.soft physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonequispaced discrete Fourier transformation (NDFT) is widely applied in all\naspects of computational science and engineering. The computational efficiency\nand accuracy of NDFT has always been a critical issue in hindering its\ncomprehensive applications both in intensive and in extensive aspects of\nscientific computing. In our previous work (2018, S.-C. Yang et al., Appl.\nComput. Harmon. Anal. 44, 273), a CUNFFT method was proposed and it shown\noutstanding performance in handling NDFT at intermediate scale based on CUDA\n(Compute Unified Device Architecture) technology. In the current work, we\nfurther improved the computational efficiency of the CUNTTF method using an\nefficient MPI-CUDA hybrid parallelization (HP) scheme of NFFT to achieve a\ncutting-edge treatment of NDFT at super extended scale. Within this HP-NFFT\nmethod, the spatial domain of NDFT is decomposed into several parts according\nto the accumulative feature of NDFT and the detailed number of CPU and GPU\nnodes. These decomposed NDFT subcells are independently calculated on different\nCPU nodes using a MPI process-level parallelization mode, and on different GPU\nnodes using a CUDA threadlevel parallelization mode and CUNFFT algorithm. A\nmassive benchmarking of the HP-NFFT method indicates that this method exhibit a\ndramatic improvement in computational efficiency for handling NDFT at super\nextended scale without loss of computational precision. Furthermore, the\nHP-NFFT method is validated via the calculation of Madelung constant of\nfluorite crystal structure, and thereafter verified that this method is robust\nfor the calculation of electrostatic interactions between charged ions in\nmolecular dynamics simulation systems.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 07:01:00 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Yang", "Sheng-Chun", ""], ["Wang", "Yong-Lei", ""]]}, {"id": "2001.02491", "submitter": "Krzysztof Lis", "authors": "Pascal Fua, Krzysztof Lis", "title": "Comparing Python, Go, and C++ on the N-Queens Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Python currently is the dominant language in the field of Machine Learning\nbut is often criticized for being slow to perform certain tasks. In this\nreport, we use the well-known $N$-queens puzzle as a benchmark to show that\nonce compiled using the Numba compiler it becomes competitive with C++ and Go\nin terms of execution speed while still allowing for very fast prototyping.\nThis is true of both sequential and parallel programs. In most cases that arise\nin an academic environment, it therefore makes sense to develop in ordinary\nPython, identify computational bottlenecks, and use Numba to remove them.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 13:09:11 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Fua", "Pascal", ""], ["Lis", "Krzysztof", ""]]}, {"id": "2001.02609", "submitter": "Stephen Chou", "authors": "Stephen Chou, Fredrik Kjolstad, Saman Amarasinghe", "title": "Automatic Generation of Efficient Sparse Tensor Format Conversion\n  Routines", "comments": "Presented at PLDI 2020", "journal-ref": null, "doi": "10.1145/3385412.3385963", "report-no": null, "categories": "cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how to generate code that efficiently converts sparse\ntensors between disparate storage formats (data layouts) such as CSR, DIA, ELL,\nand many others. We decompose sparse tensor conversion into three logical\nphases: coordinate remapping, analysis, and assembly. We then develop a\nlanguage that precisely describes how different formats group together and\norder a tensor's nonzeros in memory. This lets a compiler emit code that\nperforms complex remappings of nonzeros when converting between formats. We\nalso develop a query language that can extract statistics about sparse tensors,\nand we show how to emit efficient analysis code that computes such queries.\nFinally, we define an abstract interface that captures how data structures for\nstoring a tensor can be efficiently assembled given specific statistics about\nthe tensor. Disparate formats can implement this common interface, thus letting\na compiler emit optimized sparse tensor conversion code for arbitrary\ncombinations of many formats without hard-coding for any specific combination.\n  Our evaluation shows that the technique generates sparse tensor conversion\nroutines with performance between 1.00 and 2.01$\\times$ that of hand-optimized\nversions in SPARSKIT and Intel MKL, two popular sparse linear algebra\nlibraries. And by emitting code that avoids materializing temporaries, which\nboth libraries need for many combinations of source and target formats, our\ntechnique outperforms those libraries by 1.78 to 4.01$\\times$ for CSC/COO to\nDIA/ELL conversion.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 16:43:35 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2020 22:51:30 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 02:09:40 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Chou", "Stephen", ""], ["Kjolstad", "Fredrik", ""], ["Amarasinghe", "Saman", ""]]}, {"id": "2001.06307", "submitter": "Jim Pivarski", "authors": "Jim Pivarski (1), Peter Elmer (1), David Lange (1) ((1) Princeton\n  University)", "title": "Awkward Arrays in Python, C++, and Numba", "comments": "To be published in CHEP 2019 proceedings, EPJ Web of Conferences;\n  post-review update", "journal-ref": null, "doi": "10.1051/epjconf/202024505023", "report-no": null, "categories": "cs.MS hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Awkward Array library has been an important tool for physics analysis in\nPython since September 2018. However, some interface and implementation issues\nhave been raised in Awkward Array's first year that argue for a\nreimplementation in C++ and Numba. We describe those issues, the new\narchitecture, and present some examples of how the new interface will look to\nusers. Of particular importance is the separation of kernel functions from data\nstructure management, which allows a C++ implementation and a Numba\nimplementation to share kernel functions, and the algorithm that transforms\nrecord-oriented data into columnar Awkward Arrays.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 16:48:07 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 20:46:11 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Pivarski", "Jim", ""], ["Elmer", "Peter", ""], ["Lange", "David", ""]]}, {"id": "2001.07625", "submitter": "Fredrik Bagge Carlson", "authors": "Fredrik Bagge Carlson", "title": "MonteCarloMeasurements.jl: Nonlinear Propagation of Arbitrary\n  Multivariate Distributions by means of Method Overloading", "comments": "5 pages, 4 figure, 5 code blocks, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS stat.CO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript outlines a software package that facilitates working with\nprobability distributions by means of Monte-Carlo methods, in a way that allows\nfor propagation of multivariate probability distributions through arbitrary\nfunctions. We provide a \\emph{type} that represents probability distributions\nby an internal vector of unweighted samples, \\texttt{Particles}, which is a\nsubtype of a \\texttt{Real} number and behaves just like a regular real number\nin calculations by means of method overloading. This makes the software easy to\nwork with and presents minimal friction for the user. We highlight how this\ndesign facilitates optimal usage of SIMD instructions and showcase the package\nfor uncertainty propagation through an off-the-shelf ODE solver, as well as for\nrobust probabilistic optimization with automatic differentiation.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 16:03:57 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Carlson", "Fredrik Bagge", ""]]}, {"id": "2001.07938", "submitter": "Bruce Collie", "authors": "Philip Ginsbach, Bruce Collie, Michael F.P. O'Boyle", "title": "Automatically Harnessing Sparse Acceleration", "comments": "Accepted to CC 2020", "journal-ref": null, "doi": "10.1145/3377555.3377893", "report-no": null, "categories": "cs.PF cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse linear algebra is central to many scientific programs, yet compilers\nfail to optimize it well. High-performance libraries are available, but\nadoption costs are significant. Moreover, libraries tie programs into\nvendor-specific software and hardware ecosystems, creating non-portable code.\n  In this paper, we develop a new approach based on our specification Language\nfor implementers of Linear Algebra Computations (LiLAC). Rather than requiring\nthe application developer to (re)write every program for a given library, the\nburden is shifted to a one-off description by the library implementer. The\nLiLAC-enabled compiler uses this to insert appropriate library routines without\nsource code changes.\n  LiLAC provides automatic data marshaling, maintaining state between calls and\nminimizing data transfers. Appropriate places for library insertion are\ndetected in compiler intermediate representation, independent of source\nlanguages.\n  We evaluated on large-scale scientific applications written in FORTRAN;\nstandard C/C++ and FORTRAN benchmarks; and C++ graph analytics kernels. Across\nheterogeneous platforms, applications and data sets we show speedups of\n1.1$\\times$ to over 10$\\times$ without user intervention.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 10:04:36 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Ginsbach", "Philip", ""], ["Collie", "Bruce", ""], ["O'Boyle", "Michael F. P.", ""]]}, {"id": "2001.08849", "submitter": "Gang Mei", "authors": "Zenan Huo, Gang Mei, Nengxiong Xu", "title": "juSFEM: A Julia-based Open-source Package of Parallel Smoothed Finite\n  Element Method (S-FEM) for Elastic Problems", "comments": "Revised version submitted to Computers & Mathematics with\n  Applications on Dec. 4, 2019", "journal-ref": "Computers & Mathematics with Applications, 2020", "doi": "10.1016/j.camwa.2020.01.027", "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Smoothed Finite Element Method (S-FEM) proposed by Liu G.R. can achieve\nmore accurate results than the conventional FEM. Currently, much commercial\nsoftware and many open-source packages have been developed to analyze various\nscience and engineering problems using the FEM. However, there is little work\nfocusing on designing and developing software or packages for the S-FEM. In\nthis paper, we design and implement an open-source package of the parallel\nS-FEM for elastic problems by utilizing the Julia language on multi-core CPU.\nThe Julia language is a fast, easy-to-use, and open-source programming language\nthat was originally designed for high-performance computing. We term our\npackage as juSFEM. To the best of the authors knowledge, juSFEM is the first\npackage of parallel S-FEM developed with the Julia language. To verify the\ncorrectness and evaluate the efficiency of juSFEM, two groups of benchmark\ntests are conducted. The benchmark results show that (1) juSFEM can achieve\naccurate results when compared to commercial FEM software ABAQUS, and (2)\njuSFEM only requires 543 seconds to calculate the displacements of a 3D elastic\ncantilever beam model which is composed of approximately 2 million tetrahedral\nelements, while in contrast the commercial FEM software needs 930 seconds for\nthe same calculation model; (3) the parallel juSFEM executed on the 24-core CPU\nis approximately 20x faster than the corresponding serial version. Moreover,\nthe structure and function of juSFEM are easily modularized, and the code in\njuSFEM is clear and readable, which is convenient for further development.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 23:37:15 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Huo", "Zenan", ""], ["Mei", "Gang", ""], ["Xu", "Nengxiong", ""]]}, {"id": "2001.09253", "submitter": "Haysn Hornbeck", "authors": "Haysn Hornbeck", "title": "Fast Cubic Spline Interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Numerical Recipes series of books are a useful resource, but all the\nalgorithms they contain cannot be used within open-source projects. In this\npaper we develop drop-in alternatives to the two algorithms they present for\ncubic spline interpolation, showing as much of our work as possible to allow\nfor replication or criticsm. The output of the new algorithms is compared to\nthe old, and found to be no different within the limits imposed by\nfloating-point precision. Benchmarks of all these algorithms, plus variations\nwhich may run faster in certain instances, are performed. In general, all these\nalgorithms have approximately the same execution time when interpolating curves\nwith few control points on feature-rich Intel processors; as the number of\ncontrol points increases or processor features are removed, the new algorithms\nbecome consistently faster than the old. Exceptions to that generalization are\nexplored to create implementation guidelines, such as when to expect division\nto be faster than multiplication.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 02:06:31 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Hornbeck", "Haysn", ""]]}, {"id": "2001.09258", "submitter": "Naoki Shibata", "authors": "Naoki Shibata and Francesco Petrogalli", "title": "SLEEF: A Portable Vectorized Library of C Standard Mathematical\n  Functions", "comments": "in IEEE Transactions on Parallel and Distributed Systems. This is a\n  version with all appendices included in a PDF. Accompanying software can be\n  accessed at https://sleef.org or https://codeocean.com/capsule/6861013", "journal-ref": null, "doi": "10.1109/TPDS.2019.2960333", "report-no": null, "categories": "cs.MS cs.DC cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present techniques used to implement our portable\nvectorized library of C standard mathematical functions written entirely in C\nlanguage. In order to make the library portable while maintaining good\nperformance, intrinsic functions of vector extensions are abstracted by inline\nfunctions or preprocessor macros. We implemented the functions so that they can\nuse sub-features of vector extensions such as fused multiply-add, mask\nregisters and extraction of mantissa. In order to make computation with SIMD\ninstructions efficient, the library only uses a small number of conditional\nbranches, and all the computation paths are vectorized. We devised a variation\nof the Payne-Hanek argument reduction for trigonometric functions and a\nfloating point remainder, both of which are suitable for vector computation. We\ncompare the performance of our library to Intel SVML.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jan 2020 03:05:52 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Shibata", "Naoki", ""], ["Petrogalli", "Francesco", ""]]}, {"id": "2001.11806", "submitter": "Martin Bauer", "authors": "Martin Bauer, Harald K\\\"ostler, Ulrich R\\\"ude", "title": "lbmpy: Automatic code generation for efficient parallel lattice\n  Boltzmann methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice Boltzmann methods are a popular mesoscopic alternative to macroscopic\ncomputational fluid dynamics solvers. Many variants have been developed that\nvary in complexity, accuracy, and computational cost. Extensions are available\nto simulate multi-phase, multi-component, turbulent, or non-Newtonian flows. In\nthis work we present lbmpy, a code generation package that supports a wide\nvariety of different methods and provides a generic development environment for\nnew schemes as well. A high-level domain-specific language allows the user to\nformulate, extend and test various lattice Boltzmann schemes. The method\nspecification is represented in a symbolic intermediate representation.\nTransformations that operate on this intermediate representation optimize and\nparallelize the method, yielding highly efficient lattice Boltzmann compute\nkernels not only for single- and two-relaxation-time schemes but also for\nmulti-relaxation-time, cumulant, and entropically stabilized methods. An\nintegration into the HPC framework waLBerla makes massively parallel,\ndistributed simulations possible, which is demonstrated through scaling\nexperiments on the SuperMUC-NG supercomputing system\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 13:00:26 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 09:09:36 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Bauer", "Martin", ""], ["K\u00f6stler", "Harald", ""], ["R\u00fcde", "Ulrich", ""]]}]