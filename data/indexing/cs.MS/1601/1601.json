[{"id": "1601.02683", "submitter": "Andrew MacFie", "authors": "Andrew MacFie", "title": "Software for enumerative and analytic combinatorics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey some general-purpose symbolic software packages that implement\nalgorithms from enumerative and analytic combinatorics. Software for the\nfollowing areas is covered: basic combinatorial objects, symbolic\ncombinatorics, P\\'olya theory, combinatorial species, and asymptotics. We\ndescribe the capabilities that the packages offer as well as some of the\nalgorithms used, and provide links to original documentation. Most of the\npackages are freely downloadable from the web.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 23:03:10 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["MacFie", "Andrew", ""]]}, {"id": "1601.03623", "submitter": "Martina Prugger", "authors": "Martina Prugger, Lukas Einkemmer, Alexander Ostermann", "title": "Evaluation of the Partitioned Global Address Space (PGAS) model for an\n  inviscid Euler solver", "comments": "Parallel Computing 2016", "journal-ref": "Parallel Computing, Volume 60, December 2016, Pages 22-40", "doi": "10.1016/j.parco.2016.11.001", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we evaluate the performance of Unified Parallel C (which\nimplements the partitioned global address space programming model) using a\nnumerical method that is widely used in fluid dynamics. In order to evaluate\nthe incremental approach to parallelization (which is possible with UPC) and\nits performance characteristics, we implement different levels of optimization\nof the UPC code and compare it with an MPI parallelization on four different\nclusters of the Austrian HPC infrastructure (LEO3, LEO3E, VSC2, VSC3) and on an\nIntel Xeon Phi. We find that UPC is significantly easier to develop in compared\nto MPI and that the performance achieved is comparable to MPI in most\nsituations. The obtained results show worse performance (on VSC2), competitive\nperformance (on LEO3, LEO3E and VSC3), and superior performance (on the Intel\nXeon Phi).\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2016 15:30:47 GMT"}, {"version": "v2", "created": "Sat, 12 Nov 2016 20:50:57 GMT"}], "update_date": "2017-01-06", "authors_parsed": [["Prugger", "Martina", ""], ["Einkemmer", "Lukas", ""], ["Ostermann", "Alexander", ""]]}, {"id": "1601.04458", "submitter": "Frank T.  Bergmann", "authors": "Christoph Zimmer and Frank T. Bergmann and Sven Sahle", "title": "Reducing local minima in fitness landscapes of parameter estimation by\n  using piecewise evaluation and state estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary differential equations (ODE) are widely used for modeling in Systems\nBiology. As most commonly only some of the kinetic parameters are measurable or\nprecisely known, parameter estimation techniques are applied to parametrize the\nmodel to experimental data. A main challenge for the parameter estimation is\nthe complexity of the parameter space, especially its high dimensionality and\nlocal minima.\n  Parameter estimation techniques consist of an objective function, measuring\nhow well a certain parameter set describes the experimental data, and an\noptimization algorithm that optimizes this objective function. A lot of effort\nhas been spent on developing highly sophisticated optimization algorithms to\ncope with the complexity in the parameter space, but surprisingly few articles\naddress the influence of the objective function on the computational complexity\nin finding global optima. We extend a recently developed multiple shooting for\nstochastic systems (MSS) objective function for parameter estimation of\nstochastic models and apply it to parameter estimation of ODE models. This MSS\nobjective function treats the intervals between measurement points separately.\nThis separate treatment allows the ODE trajectory to stay closer to the data\nand we show that it reduces the complexity of the parameter space.\n  We use examples from Systems Biology, namely a Lotka-Volterra model, a\nFitzHugh-Nagumo oscillator and a Calcium oscillation model, to demonstrate the\npower of the MSS approach for reducing the complexity and the number of local\nminima in the parameter space. The approach is fully implemented in the COPASI\nsoftware package and, therefore, easily accessible for a wide community of\nresearchers.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 10:38:52 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Zimmer", "Christoph", ""], ["Bergmann", "Frank T.", ""], ["Sahle", "Sven", ""]]}, {"id": "1601.05871", "submitter": "Kyungjoo Kim", "authors": "Kyungjoo Kim, Sivasankaran Rajamanickam, George Stelle, H. Carter\n  Edwards, and Stephen L. Olivier", "title": "Task Parallel Incomplete Cholesky Factorization using 2D\n  Partitioned-Block Layout", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": "SAND2016-0637 R", "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a task-parallel algorithm for sparse incomplete Cholesky\nfactorization that utilizes a 2D sparse partitioned-block layout of a matrix.\nOur factorization algorithm follows the idea of algorithms-by-blocks by using\nthe block layout. The algorithm-by-blocks approach induces a task graph for the\nfactorization. These tasks are inter-related to each other through their data\ndependences in the factorization algorithm. To process the tasks on various\nmanycore architectures in a portable manner, we also present a portable tasking\nAPI that incorporates different tasking backends and device-specific features\nusing an open-source framework for manycore platforms i.e., Kokkos. A\nperformance evaluation is presented on both Intel Sandybridge and Xeon Phi\nplatforms for matrices from the University of Florida sparse matrix collection\nto illustrate merits of the proposed task-based factorization. Experimental\nresults demonstrate that our task-parallel implementation delivers about 26.6x\nspeedup (geometric mean) over single-threaded incomplete Cholesky-by-blocks and\n19.2x speedup over serial Cholesky performance which does not carry tasking\noverhead using 56 threads on the Intel Xeon Phi processor for sparse matrices\narising from various application problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 03:19:45 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Kim", "Kyungjoo", ""], ["Rajamanickam", "Sivasankaran", ""], ["Stelle", "George", ""], ["Edwards", "H. Carter", ""], ["Olivier", "Stephen L.", ""]]}, {"id": "1601.07789", "submitter": "Andrew Anderson", "authors": "Andrew Anderson and David Gregg", "title": "Vectorization of Multibyte Floating Point Data Formats", "comments": null, "journal-ref": null, "doi": "10.1145/2967938.2967966", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a scheme for reduced-precision representation of floating point\ndata on a continuum between IEEE-754 floating point types. Our scheme enables\nthe use of lower precision formats for a reduction in storage space\nrequirements and data transfer volume. We describe how our scheme can be\naccelerated using existing hardware vector units on a general-purpose processor\n(GPP). Exploiting native vector hardware allows us to support reduced precision\nfloating point with low overhead. We demonstrate that supporting reduced\nprecision in the compiler as opposed to using a library approach can yield a\nlow overhead solution for GPPs.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 13:24:40 GMT"}, {"version": "v2", "created": "Wed, 23 Mar 2016 16:33:22 GMT"}, {"version": "v3", "created": "Fri, 22 Jul 2016 14:38:42 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Anderson", "Andrew", ""], ["Gregg", "David", ""]]}, {"id": "1601.07944", "submitter": "Andrew Giuliani", "authors": "Martin Fuhry, Andrew Giuliani, Lilia Krivodonova", "title": "Discontinuous Galerkin methods on graphics processing units for\n  nonlinear hyperbolic conservation laws", "comments": "36 pages, 14 figures, 6 tables", "journal-ref": "International Journal for Numerical Methods in Fluids, 76(12),\n  982-1003 (2014)", "doi": "10.1002/fld.3963", "report-no": null, "categories": "cs.DC cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel implementation of the modal discontinuous Galerkin (DG)\nmethod for hyperbolic conservation laws in two dimensions on graphics\nprocessing units (GPUs) using NVIDIA's Compute Unified Device Architecture\n(CUDA). Both flexible and highly accurate, DG methods accommodate parallel\narchitectures well as their discontinuous nature produces element-local\napproximations. High performance scientific computing suits GPUs well, as these\npowerful, massively parallel, cost-effective devices have recently included\nsupport for double-precision floating point numbers. Computed examples for\nEuler equations over unstructured triangle meshes demonstrate the effectiveness\nof our implementation on an NVIDIA GTX 580 device. Profiling of our method\nreveals performance comparable to an existing nodal DG-GPU implementation for\nlinear problems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 22:49:50 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Fuhry", "Martin", ""], ["Giuliani", "Andrew", ""], ["Krivodonova", "Lilia", ""]]}]