[{"id": "2002.01895", "submitter": "John Maclean", "authors": "John Maclean and J. E. Bunder and A. J. Roberts", "title": "A toolbox of Equation-Free functions in Matlab\\Octave for efficient\n  system level simulation", "comments": "35 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The `equation-free toolbox' empowers the computer-assisted analysis of\ncomplex, multiscale systems. Its aim is to enable you to immediately use\nmicroscopic simulators to perform macro-scale system level tasks and analysis,\nbecause micro-scale simulations are often the best available description of a\nsystem. The methodology bypasses the derivation of macroscopic evolution\nequations by computing the micro-scale simulator only over short bursts in time\non small patches in space, with bursts and patches well-separated in time and\nspace respectively. We introduce the suite of coded equation-free functions in\nan accessible way, link to more detailed descriptions, discuss their\nmathematical support, and introduce a novel and efficient algorithm for\nProjective Integration. Some facets of toolbox development of equation-free\nfunctions are then detailed. Download the toolbox functions\n(https://github.com/uoa1184615/EquationFreeGit) and use to empower efficient\nand accurate simulation in a wide range of your science and engineering\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:20:04 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 04:33:03 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Maclean", "John", ""], ["Bunder", "J. E.", ""], ["Roberts", "A. J.", ""]]}, {"id": "2002.03260", "submitter": "Tianjian Lu", "authors": "Tianjian Lu, Yi-Fan Chen, Blake Hechtman, Tao Wang, and John Anderson", "title": "Large-Scale Discrete Fourier Transform on TPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present two parallel algorithms for the large-scale discrete\nFourier transform (DFT) on Tensor Processing Unit (TPU) clusters. The two\nparallel algorithms are associated with two formulations of DFT: one is based\non the Kronecker product, to be specific, dense matrix multiplications between\nthe input data and the Vandermonde matrix, denoted as KDFT in this work; the\nother is based on the famous Cooley-Tukey algorithm and phase adjustment,\ndenoted as FFT in this work. Both KDFT and FFT formulations take full advantage\nof TPU's strength in matrix multiplications. The KDFT formulation allows direct\nuse of nonuniform inputs without additional step. In the two parallel\nalgorithms, the same strategy of data decomposition is applied to the input\ndata. Through the data decomposition, the dense matrix multiplications in KDFT\nand FFT are kept local within TPU cores, which can be performed completely in\nparallel. The communication among TPU cores is achieved through the one-shuffle\nscheme in both parallel algorithms, with which sending and receiving data takes\nplace simultaneously between two neighboring cores and along the same direction\non the interconnect network. The one-shuffle scheme is designed for the\ninterconnect topology of TPU clusters, minimizing the time required by the\ncommunication among TPU cores. Both KDFT and FFT are implemented in TensorFlow.\nThe three-dimensional complex DFT is performed on an example of dimension $8192\n\\times 8192 \\times 8192$ with a full TPU Pod: the run time of KDFT is 12.66\nseconds and that of FFT is 8.3 seconds. Scaling analysis is provided to\ndemonstrate the high parallel efficiency of the two DFT implementations on\nTPUs.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 01:15:13 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 08:15:14 GMT"}, {"version": "v3", "created": "Fri, 11 Dec 2020 20:55:42 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Lu", "Tianjian", ""], ["Chen", "Yi-Fan", ""], ["Hechtman", "Blake", ""], ["Wang", "Tao", ""], ["Anderson", "John", ""]]}, {"id": "2002.03400", "submitter": "Yang Liu", "authors": "Yang Liu, Xin Xing, Han Guo, Eric Michielssen, Pieter Ghysels, Xiaoye\n  Sherry Li", "title": "Butterfly factorization via randomized matrix-vector multiplications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an adaptive randomized algorithm for computing the\nbutterfly factorization of a $m\\times n$ matrix with $m\\approx n$ provided that\nboth the matrix and its transpose can be rapidly applied to arbitrary vectors.\nThe resulting factorization is composed of $O(\\log n)$ sparse factors, each\ncontaining $O(n)$ nonzero entries. The factorization can be attained using\n$O(n^{3/2}\\log n)$ computation and $O(n\\log n)$ memory resources. The proposed\nalgorithm applies to matrices with strong and weak admissibility conditions\narising from surface integral equation solvers with a rigorous error bound, and\nis implemented in parallel.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2020 17:19:44 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Liu", "Yang", ""], ["Xing", "Xin", ""], ["Guo", "Han", ""], ["Michielssen", "Eric", ""], ["Ghysels", "Pieter", ""], ["Li", "Xiaoye Sherry", ""]]}, {"id": "2002.04504", "submitter": "Julian Blank", "authors": "Julian Blank, Kalyanmoy Deb", "title": "pymoo: Multi-objective Optimization in Python", "comments": null, "journal-ref": "IEEE Access 8 (2020) 89497-89509", "doi": "10.1109/ACCESS.2020.2990567", "report-no": "COIN-2020001", "categories": "cs.NE cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Python has become the programming language of choice for research and\nindustry projects related to data science, machine learning, and deep learning.\nSince optimization is an inherent part of these research fields, more\noptimization related frameworks have arisen in the past few years. Only a few\nof them support optimization of multiple conflicting objectives at a time, but\ndo not provide comprehensive tools for a complete multi-objective optimization\ntask. To address this issue, we have developed pymoo, a multi-objective\noptimization framework in Python. We provide a guide to getting started with\nour framework by demonstrating the implementation of an exemplary constrained\nmulti-objective optimization scenario. Moreover, we give a high-level overview\nof the architecture of pymoo to show its capabilities followed by an\nexplanation of each module and its corresponding sub-modules. The\nimplementations in our framework are customizable and algorithms can be\nmodified/extended by supplying custom operators. Moreover, a variety of single,\nmulti and many-objective test problems are provided and gradients can be\nretrieved by automatic differentiation out of the box. Also, pymoo addresses\npractical needs, such as the parallelization of function evaluations, methods\nto visualize low and high-dimensional spaces, and tools for multi-criteria\ndecision making. For more information about pymoo, readers are encouraged to\nvisit: https://pymoo.org\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:04:24 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Blank", "Julian", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2002.04807", "submitter": "Eric Polizzi", "authors": "Eric Polizzi", "title": "FEAST Eigenvalue Solver v4.0 User Guide", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The FEAST library package represents an unified framework for solving various\nfamily of eigenvalue problems and achieving accuracy, robustness,\nhigh-performance and scalability on parallel architectures. Its originality\nlies with a new transformative numerical approach to the traditional eigenvalue\nalgorithm design - the FEAST algorithm. The algorithm gathers key elements from\ncomplex analysis, numerical linear algebra and approximation theory, to\nconstruct an optimal subspace iteration technique using approximate spectral\nprojectors. FEAST can be used for solving both standard and generalized forms\nof the Hermitian or non-Hermitian problems (linear or non-linear), and it\nbelongs to the family of contour integration eigensolvers. FEAST's main\ncomputational task consists of a numerical quadrature computation that involves\nsolving independent linear systems along a complex contour, each with multiple\nright hand sides. In v4.0, FEAST has been reimplemented using an inverse\nresidual iteration algorithm which enables the linear systems to be solved with\nvery low accuracy (in single precision) with no impact on the FEAST double\nprecision convergence rate. As a result, v4.0 is on average 3-4 times faster\nthan v2.1 and v3.0 using new default optimization parameters (v2.1 has been\nfeatured as Intel-MKL's principal HPC eigensolver since 2013). v4.0 also\nimplements new important features such as IFEAST (using Inexact Iterative\nsolver), Non-linear polynomial FEAST, and PFEAST with its 3-MPI levels of\nparallelism. FEAST is both a comprehensive library package, and an easy to use\nsoftware. It includes flexible reverse communication interfaces and ready to\nuse driver interfaces for dense, banded and sparse systems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 05:26:04 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Polizzi", "Eric", ""]]}, {"id": "2002.04955", "submitter": "Michael Kohlhase", "authors": "Katja Bercic, Jacques Carette, William M. Farmer, Michael Kohlhase,\n  Dennis M\\\"uller, Florian Rabe, and Yasmine Sharoda", "title": "The Space of Mathematical Software Systems -- A Survey of Paradigmatic\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Mathematical software systems are becoming more and more important in pure\nand applied mathematics in order to deal with the complexity and scalability\nissues inherent in mathematics. In the last decades we have seen a cambric\nexplosion of increasingly powerful but also diverging systems. To give\nresearchers a guide to this space of systems, we devise a novel\nconceptualization of mathematical software that focuses on five aspects:\ninference covers formal logic and reasoning about mathematical statements via\nproofs and models, typically with strong emphasis on correctness; computation\ncovers algorithms and software libraries for representing and manipulating\nmathematical objects, typically with strong emphasis on efficiency;\nconcretization covers generating and maintaining collections of mathematical\nobjects conforming to a certain pattern, typically with strong emphasis on\ncomplete enumeration; narration covers describing mathematical contexts and\nrelations, typically with strong emphasis on human readability; finally,\norganization covers representing mathematical contexts and objects in\nmachine-actionable formal languages, typically with strong emphasis on\nexpressivity and system interoperability. Despite broad agreement that an ideal\nsystem would seamlessly integrate all these aspects, research has diversified\ninto families of highly specialized systems focusing on a single aspect and\npossibly partially integrating others, each with their own communities,\nchallenges, and successes. In this survey, we focus on the commonalities and\ndifferences of these systems from the perspective of a future multi-aspect\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 12:46:17 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Bercic", "Katja", ""], ["Carette", "Jacques", ""], ["Farmer", "William M.", ""], ["Kohlhase", "Michael", ""], ["M\u00fcller", "Dennis", ""], ["Rabe", "Florian", ""], ["Sharoda", "Yasmine", ""]]}, {"id": "2002.05024", "submitter": "Mirko Myllykoski", "authors": "Mirko Myllykoski, Carl Christian Kjelgaard Mikkelsen", "title": "Task-based, GPU-accelerated and Robust Library for Solving Dense\n  Nonsymmetric Eigenvalue Problems", "comments": "18 pages, 11 figures (18 when counting sub-figures), 1 tex-files.\n  Invited article submitted to Concurrency and Computation: Practice and\n  Experience. Second author's first name is \"Carl Christian\" and last name\n  \"Kjelgaard Mikkelsen\"", "journal-ref": "Concurrency Computat Pract Exper. (2020) e5915", "doi": "10.1002/cpe.5915", "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the StarNEig library for solving dense nonsymmetric\nstandard and generalized eigenvalue problems. The library is built on top of\nthe StarPU runtime system and targets both shared and distributed memory\nmachines. Some components of the library have support for GPU acceleration. The\nlibrary is currently in an early beta state and supports only real matrices.\nSupport for complex matrices is planned for a future release. This paper is\naimed at potential users of the library. We describe the design choices and\ncapabilities of the library, and contrast them to existing software such as\nScaLAPACK. StarNEig implements a ScaLAPACK compatibility layer which should\nassist new users in the transition to StarNEig. We demonstrate the performance\nof the library with a sample of computational experiments.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2020 14:28:55 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Myllykoski", "Mirko", ""], ["Mikkelsen", "Carl Christian Kjelgaard", ""]]}, {"id": "2002.06960", "submitter": "Gregorio Quintana-Ort\\'i", "authors": "Nathan Heavner, Per-Gunnar Martinsson, Gregorio Quintana-Ort\\'i", "title": "Computing rank-revealing factorizations of matrices stored out-of-core", "comments": "23 pages, 11 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CL cs.DC cs.DS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes efficient algorithms for computing rank-revealing\nfactorizations of matrices that are too large to fit in RAM, and must instead\nbe stored on slow external memory devices such as solid-state or spinning disk\nhard drives (out-of-core or out-of-memory). Traditional algorithms for\ncomputing rank revealing factorizations, such as the column pivoted QR\nfactorization, or techniques for computing a full singular value decomposition\nof a matrix, are very communication intensive. They are naturally expressed as\na sequence of matrix-vector operations, which become prohibitively expensive\nwhen data is not available in main memory. Randomization allows these methods\nto be reformulated so that large contiguous blocks of the matrix can be\nprocessed in bulk. The paper describes two distinct methods. The first is a\nblocked version of column pivoted Householder QR, organized as a \"left-looking\"\nmethod to minimize the number of write operations (which are more expensive\nthan read operations on a spinning disk drive). The second method results in a\nso called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where\n$U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an\nalgorithm-by-blocks, in which floating point operations overlap read and write\noperations. The second method incorporates power iterations, and is\nexceptionally good at revealing the numerical rank; it can often be used as a\nsubstitute for a full singular value decomposition. Numerical experiments\ndemonstrate that the new algorithms are almost as fast when processing data\nstored on a hard drive as traditional algorithms are for data stored in main\nmemory. To be precise, the computational time for fully factorizing an $n\\times\nn$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only\nmarginally larger when the matrix is stored out of core.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 13:58:08 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 12:18:40 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Heavner", "Nathan", ""], ["Martinsson", "Per-Gunnar", ""], ["Quintana-Ort\u00ed", "Gregorio", ""]]}, {"id": "2002.08110", "submitter": "Martin Kronbichler", "authors": "Peter Munch, Katharina Kormann, Martin Kronbichler", "title": "hyper.deal: An efficient, matrix-free finite-element library for\n  high-dimensional partial differential equations", "comments": "33 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents the efficient, matrix-free finite-element library\nhyper.deal for solving partial differential equations in two to six dimensions\nwith high-order discontinuous Galerkin methods. It builds upon the\nlow-dimensional finite-element library deal.II to create complex\nlow-dimensional meshes and to operate on them individually. These meshes are\ncombined via a tensor product on the fly and the library provides new\nspecial-purpose highly optimized matrix-free functions exploiting domain\ndecomposition as well as shared memory via MPI-3.0 features. Both node-level\nperformance analyses and strong/weak-scaling studies on up to 147,456 CPU cores\nconfirm the efficiency of the implementation. Results of the library hyper.deal\nare reported for high-dimensional advection problems and for the solution of\nthe Vlasov--Poisson equation in up to 6D phase space.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 11:25:35 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Munch", "Peter", ""], ["Kormann", "Katharina", ""], ["Kronbichler", "Martin", ""]]}, {"id": "2002.11423", "submitter": "Jaime Pizarroso Gonzalo", "authors": "J. Pizarroso, J. Portela and A. Mu\\~noz", "title": "NeuralSens: Sensitivity Analysis of Neural Networks", "comments": "28 pages, 12 figures, submitted to Journal of Statistical Software\n  (JSS) https://www.jstatsoft.org/index", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are important tools for data-intensive analysis and are\ncommonly applied to model non-linear relationships between dependent and\nindependent variables. However, neural networks are usually seen as \"black\nboxes\" that offer minimal information about how the input variables are used to\npredict the response in a fitted model. This article describes the\n\\pkg{NeuralSens} package that can be used to perform sensitivity analysis of\nneural networks using the partial derivatives method. Functions in the package\ncan be used to obtain the sensitivities of the output with respect to the input\nvariables, evaluate variable importance based on sensitivity measures and\ncharacterize relationships between input and output variables. Methods to\ncalculate sensitivities are provided for objects from common neural network\npackages in \\proglang{R}, including \\pkg{neuralnet}, \\pkg{nnet}, \\pkg{RSNNS},\n\\pkg{h2o}, \\pkg{neural}, \\pkg{forecast} and \\pkg{caret}. The article presents\nan overview of the techniques for obtaining information from neural network\nmodels, a theoretical foundation of how are calculated the partial derivatives\nof the output with respect to the inputs of a multi-layer perceptron model, a\ndescription of the package structure and functions, and applied examples to\ncompare \\pkg{NeuralSens} functions with analogous functions from other\navailable \\proglang{R} packages.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 12:05:59 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 07:01:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Pizarroso", "J.", ""], ["Portela", "J.", ""], ["Mu\u00f1oz", "A.", ""]]}, {"id": "2002.12323", "submitter": "Konstantin Key", "authors": "Markus Frings (1), Norbert Hosters (1), Corinna M\\\"uller (1), Max\n  Spahn (1), Christoph Susen (1), Konstantin Key (1), Stefanie Elgeti (1) ((1)\n  Chair for Computational Analysis of Technical Systems, Aachen, Germany)", "title": "SplineLib: A Modern Multi-Purpose C++ Spline Library", "comments": "16 pages, 4 figures, submitted to Advances in Engineering Software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides the description of a novel, multi-purpose spline library.\nIn accordance with the increasingly diverse modes of usage of splines, it is\nmulti-purpose in the sense that it supports geometry representation, finite\nelement analysis, and optimization. The library features reading and writing\nfor various file formats and a wide range of spline manipulation algorithms.\nFurther, a new efficient and objective-oriented algorithm for B-spline basis\nfunction evaluation is included. All features are available by a spline-type\nindependent interface. The library is written in modern C++ with CMake as build\nsystem. This enables it for usage in typical scientific applications. It is\nprovided as open-source library.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 18:43:07 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Frings", "Markus", ""], ["Hosters", "Norbert", ""], ["M\u00fcller", "Corinna", ""], ["Spahn", "Max", ""], ["Susen", "Christoph", ""], ["Key", "Konstantin", ""], ["Elgeti", "Stefanie", ""]]}, {"id": "2002.12682", "submitter": "Steffen W. R. Werner", "authors": "Peter Benner, Steffen W. R. Werner", "title": "MORLAB -- The Model Order Reduction LABoratory", "comments": "17 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA cs.SY eess.SY math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an easy use of model order reduction techniques in applications, software\nsolutions are needed. In this paper, we describe the MORLAB, Model Order\nReduction LABoratory, toolbox as an efficient implementation of model reduction\ntechniques for dense, medium-scale linear time-invariant systems. Giving an\nintroduction to the underlying programming principles of the toolbox, we show\nthe basic idea of spectral splitting and present an overview about implemented\nmodel reduction techniques. Two numerical examples are used to illustrate\ndifferent use cases of the MORLAB toolbox.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 12:42:26 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Benner", "Peter", ""], ["Werner", "Steffen W. R.", ""]]}]