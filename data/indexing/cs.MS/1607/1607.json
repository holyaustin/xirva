[{"id": "1607.00145", "submitter": "Paul Springer", "authors": "Paul Springer and Paolo Bientinesi", "title": "Design of a high-performance GEMM-like Tensor-Tensor Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present \"GEMM-like Tensor-Tensor multiplication\" (GETT), a novel approach\nto tensor contractions that mirrors the design of a high-performance general\nmatrix-matrix multiplication (GEMM). The critical insight behind GETT is the\nidentification of three index sets, involved in the tensor contraction, which\nenable us to systematically reduce an arbitrary tensor contraction to loops\naround a highly tuned \"macro-kernel\". This macro-kernel operates on suitably\nprepared (\"packed\") sub-tensors that reside in a specified level of the cache\nhierarchy. In contrast to previous approaches to tensor contractions, GETT\nexhibits desirable features such as unit-stride memory accesses,\ncache-awareness, as well as full vectorization, without requiring auxiliary\nmemory. To compare our technique with other modern tensor contractions, we\nintegrate GETT alongside the so called Transpose-Transpose-GEMM-Transpose and\nLoops-over-GEMM approaches into an open source \"Tensor Contraction Code\nGenerator\" (TCCG). The performance results for a wide range of tensor\ncontractions suggest that GETT has the potential of becoming the method of\nchoice: While GETT exhibits excellent performance across the board, its\neffectiveness for bandwidth-bound tensor contractions is especially impressive,\noutperforming existing approaches by up to $12.4\\times$. More precisely, GETT\nachieves speedups of up to $1.41\\times$ over an equivalent-sized GEMM for\nbandwidth-bound tensor contractions while attaining up to $91.3\\%$ of peak\nfloating-point performance for compute-bound tensor contractions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 08:13:50 GMT"}, {"version": "v2", "created": "Sat, 30 Jul 2016 07:28:12 GMT"}, {"version": "v3", "created": "Tue, 7 Nov 2017 08:21:02 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Springer", "Paul", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1607.00291", "submitter": "Devin Matthews", "authors": "Devin A. Matthews", "title": "High-Performance Tensor Contraction without Transposition", "comments": "24 pages, 8 figures, uses pgfplots", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor computations--in particular tensor contraction (TC)--are important\nkernels in many scientific computing applications. Due to the fundamental\nsimilarity of TC to matrix multiplication (MM) and to the availability of\noptimized implementations such as the BLAS, tensor operations have\ntraditionally been implemented in terms of BLAS operations, incurring both a\nperformance and a storage overhead. Instead, we implement TC using the flexible\nBLIS framework, which allows for transposition (reshaping) of the tensor to be\nfused with internal partitioning and packing operations, requiring no explicit\ntransposition operations or additional workspace. This implementation, TBLIS,\nachieves performance approaching that of MM, and in some cases considerably\nhigher than that of traditional TC. Our implementation supports multithreading\nusing an approach identical to that used for MM in BLIS, with similar\nperformance characteristics. The complexity of managing tensor-to-matrix\ntransformations is also handled automatically in our approach, greatly\nsimplifying its use in scientific applications.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 15:37:59 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2016 21:16:54 GMT"}, {"version": "v3", "created": "Fri, 10 Feb 2017 20:49:01 GMT"}, {"version": "v4", "created": "Tue, 11 Jul 2017 15:03:52 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Matthews", "Devin A.", ""]]}, {"id": "1607.00346", "submitter": "Yingzhou Li", "authors": "Yingzhou Li and Lexing Ying", "title": "Distributed-memory Hierarchical Interpolative Factorization", "comments": null, "journal-ref": null, "doi": "10.1186/s40687-017-0100-6", "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hierarchical interpolative factorization (HIF) offers an efficient way\nfor solving or preconditioning elliptic partial differential equations. By\nexploiting locality and low-rank properties of the operators, the HIF achieves\nquasi-linear complexity for factorizing the discrete positive definite elliptic\noperator and linear complexity for solving the associated linear system. In\nthis paper, the distributed-memory HIF (DHIF) is introduced as a parallel and\ndistributed-memory implementation of the HIF. The DHIF organizes the processes\nin a hierarchical structure and keep the communication as local as possible.\nThe computation complexity is $O\\left(\\frac{N\\log N}{P}\\right)$ and\n$O\\left(\\frac{N}{P}\\right)$ for constructing and applying the DHIF,\nrespectively, where $N$ is the size of the problem and $P$ is the number of\nprocesses. The communication complexity is $O\\left(\\sqrt{P}\\log^3\nP\\right)\\alpha + O\\left(\\frac{N^{2/3}}{\\sqrt{P}}\\right)\\beta$ where $\\alpha$ is\nthe latency and $\\beta$ is the inverse bandwidth. Extensive numerical examples\nare performed on the NERSC Edison system with up to 8192 processes. The\nnumerical results agree with the complexity analysis and demonstrate the\nefficiency and scalability of the DHIF.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 18:37:34 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 19:48:33 GMT"}, {"version": "v3", "created": "Wed, 25 Jan 2017 07:30:09 GMT"}, {"version": "v4", "created": "Thu, 23 Feb 2017 07:42:28 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Li", "Yingzhou", ""], ["Ying", "Lexing", ""]]}, {"id": "1607.00648", "submitter": "Tobias Weinzierl", "authors": "Marion Weinzierl, Tobias Weinzierl", "title": "Quasi-matrix-free hybrid multigrid on dynamically adaptive Cartesian\n  grids", "comments": null, "journal-ref": null, "doi": "10.1145/3165280", "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a family of spacetree-based multigrid realizations using the\ntree's multiscale nature to derive coarse grids. They align with matrix-free\ngeometric multigrid solvers as they never assemble the system matrices which is\ncumbersome for dynamically adaptive grids and full multigrid. The most\nsophisticated realizations use BoxMG to construct operator-dependent\nprolongation and restriction in combination with Galerkin/Petrov-Galerkin\ncoarse-grid operators. This yields robust solvers for nontrivial elliptic\nproblems. We embed the algebraic, problem- and grid-dependent multigrid\noperators as stencils into the grid and evaluate all matrix-vector products\nin-situ throughout the grid traversals. While such an approach is not literally\nmatrix-free---the grid carries the matrix---we propose to switch to a\nhierarchical representation of all operators. Only differences of algebraic\noperators to their geometric counterparts are held. These hierarchical\ndifferences can be stored and exchanged with small memory footprint. Our\nrealizations support arbitrary dynamically adaptive grids while they vertically\nintegrate the multilevel operations through spacetree linearization. This\nyields good memory access characteristics, while standard colouring of mesh\nentities with domain decomposition allows us to use parallel manycore clusters.\nAll realization ingredients are detailed such that they can be used by other\ncodes.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jul 2016 14:54:45 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2016 06:44:08 GMT"}, {"version": "v3", "created": "Thu, 21 Jul 2016 10:00:41 GMT"}, {"version": "v4", "created": "Mon, 14 Nov 2016 08:31:26 GMT"}, {"version": "v5", "created": "Mon, 17 Jul 2017 20:45:30 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Weinzierl", "Marion", ""], ["Weinzierl", "Tobias", ""]]}, {"id": "1607.00844", "submitter": "Michael Klemm", "authors": "Michael Klemm, Freddie Witherden, Peter Vincent", "title": "Using the pyMIC Offload Module in PyFR", "comments": null, "journal-ref": null, "doi": null, "report-no": "euroscipy-proceedings2015-01", "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  PyFR is an open-source high-order accurate computational fluid dynamics\nsolver for unstructured grids. It is designed to efficiently solve the\ncompressible Navier-Stokes equations on a range of hardware platforms,\nincluding GPUs and CPUs. In this paper we will describe how the Python Offload\nInfrastructure for the Intel Many Integrated Core Architecture (pyMIC) was used\nto enable PyFR to run with near native performance on the Intel Xeon Phi\ncoprocessor. We will introduce the architecture of both pyMIC and PyFR and\npresent a variety of examples showcasing the capabilities of pyMIC. Further, we\nwill also compare the contrast pyMIC to other approaches including native\nexecution and OpenCL. The process of adding support for pyMIC into PyFR will be\ndescribed in detail. Benchmark results show that for a standard cylinder flow\nproblem PyFR with pyMIC is able achieve 240 GFLOP/s of sustained double\nprecision floating point performance; for a 1.85 times improvement over PyFR\nwith C/OpenMP on a 12 core Intel Xeon E5-2697 v2 CPU.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 18:59:11 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Klemm", "Michael", ""], ["Witherden", "Freddie", ""], ["Vincent", "Peter", ""]]}, {"id": "1607.00850", "submitter": "Mikael Mortensen", "authors": "Mikael Mortensen", "title": "Massively parallel implementation in Python of a pseudo-spectral DNS\n  code for turbulent flows", "comments": null, "journal-ref": null, "doi": null, "report-no": "euroscipy-proceedings2015-01", "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Direct Numerical Simulations (DNS) of the Navier Stokes equations is a\nvaluable research tool in fluid dynamics, but there are very few publicly\navailable codes and, due to heavy number crunching, codes are usually written\nin low-level languages. In this work a \\textasciitilde{}100 line standard\nscientific Python DNS code is described that nearly matches the performance of\npure C for thousands of processors and billions of unknowns. With optimization\nof a few routines in Cython, it is found to match the performance of a more or\nless identical solver implemented from scratch in C++. Keys to the efficiency\nof the solver are the mesh decomposition and three dimensional FFT routines,\nimplemented directly in Python using MPI, wrapped through MPI for Python, and a\nserial FFT module (both numpy.fft or pyFFTW may be used). Two popular\ndecomposition strategies, slab and pencil, have been implemented and tested.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 19:05:11 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Mortensen", "Mikael", ""]]}, {"id": "1607.01191", "submitter": "Christian Himpe", "authors": "J\\\"org Fehr, Jan Heiland, Christian Himpe, Jens Saak", "title": "Best Practices for Replicability, Reproducibility and Reusability of\n  Computer-Based Experiments Exemplified by Model Reduction Software", "comments": null, "journal-ref": "AIMS Mathematics 2016, Volume 1, Issue 3", "doi": "10.3934/Math.2016.3.261", "report-no": null, "categories": "cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the recent years the importance of numerical experiments has gradually\nbeen more recognized. Nonetheless, sufficient documentation of how\ncomputational results have been obtained is often not available. Especially in\nthe scientific computing and applied mathematics domain this is crucial, since\nnumerical experiments are usually employed to verify the proposed hypothesis in\na publication. This work aims to propose standards and best practices for the\nsetup and publication of numerical experiments. Naturally, this amounts to a\nguideline for development, maintenance, and publication of numerical research\nsoftware. Such a primer will enable the replicability and reproducibility of\ncomputer-based experiments and published results and also promote the\nreusability of the associated software.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 11:02:45 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Fehr", "J\u00f6rg", ""], ["Heiland", "Jan", ""], ["Himpe", "Christian", ""], ["Saak", "Jens", ""]]}, {"id": "1607.01249", "submitter": "Paul Springer", "authors": "Paul Springer, Aravind Sankaran, Paolo Bientinesi", "title": "TTC: A Tensor Transposition Compiler for Multiple Architectures", "comments": null, "journal-ref": null, "doi": "10.1145/2935323.2935328", "report-no": null, "categories": "cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of transposing tensors of arbitrary dimension and\ndescribe TTC, an open source domain-specific parallel compiler. TTC generates\noptimized parallel C++/CUDA C code that achieves a significant fraction of the\nsystem's peak memory bandwidth. TTC exhibits high performance across multiple\narchitectures, including modern AVX-based systems (e.g.,~Intel Haswell, AMD\nSteamroller), Intel's Knights Corner as well as different CUDA-based GPUs such\nas NVIDIA's Kepler and Maxwell architectures. We report speedups of TTC over a\nmeaningful baseline implementation generated by external C++ compilers; the\nresults suggest that a domain-specific compiler can outperform its general\npurpose counterpart significantly: For instance, comparing with Intel's latest\nC++ compiler on the Haswell and Knights Corner architecture, TTC yields\nspeedups of up to $8\\times$ and $32\\times$, respectively. We also showcase\nTTC's support for multiple leading dimensions, making it a suitable candidate\nfor the generation of performance-critical packing functions that are at the\ncore of the ubiquitous BLAS 3 routines.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 13:53:57 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Springer", "Paul", ""], ["Sankaran", "Aravind", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1607.01404", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Eloy Romero, Andreas Stathopoulos", "title": "PRIMME_SVDS: A High-Performance Preconditioned SVD Solver for Accurate\n  Large-Scale Computations", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing number of applications requiring the solution of large scale\nsingular value problems have rekindled interest in iterative methods for the\nSVD. Some promising recent ad- vances in large scale iterative methods are\nstill plagued by slow convergence and accuracy limitations for computing\nsmallest singular triplets. Furthermore, their current implementations in\nMATLAB cannot address the required large problems. Recently, we presented a\npreconditioned, two-stage method to effectively and accurately compute a small\nnumber of extreme singular triplets. In this research, we present a\nhigh-performance software, PRIMME SVDS, that implements our hybrid method based\non the state-of-the-art eigensolver package PRIMME for both largest and\nsmallest singular values. PRIMME SVDS fills a gap in production level software\nfor computing the partial SVD, especially with preconditioning. The numerical\nexperiments demonstrate its superior performance compared to other\nstate-of-the-art software and its good parallel performance under strong and\nweak scaling.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 20:15:56 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 18:27:56 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Wu", "Lingfei", ""], ["Romero", "Eloy", ""], ["Stathopoulos", "Andreas", ""]]}, {"id": "1607.01477", "submitter": "Tim Moon", "authors": "Tim Moon and Jack Poulson", "title": "Accelerating eigenvector and pseudospectra computation using blocked\n  multi-shift triangular solves", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-shift triangular solves are basic linear algebra calculations with\napplications in eigenvector and pseudospectra computation. We propose blocked\nalgorithms that efficiently exploit Level 3 BLAS to perform multi-shift\ntriangular solves and safe multi-shift triangular solves. Numerical experiments\nindicate that computing triangular eigenvectors with a safe multi-shift\ntriangular solve achieves speedups by a factor of 60 relative to LAPACK. This\nalgorithm accelerates the calculation of general eigenvectors threefold. When\nusing multi-shift triangular solves to compute pseudospectra, we report\nninefold speedups relative to EigTool.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jul 2016 04:19:04 GMT"}, {"version": "v2", "created": "Sat, 30 Jul 2016 16:52:39 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Moon", "Tim", ""], ["Poulson", "Jack", ""]]}, {"id": "1607.02835", "submitter": "Tobias Weinzierl", "authors": "Tobias Weinzierl", "title": "Form Follows Function -- Do algorithms and applications challenge or\n  drag behind the hardware evolution?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We summarise some of the key statements made at the workshop Form Follows\nFunction at ISC High Performance 2016. The summary highlights what type of\nco-design the presented projects experience; often in the absence of an\nexplicit co-design agenda. Their software development picks up hardware trends\nbut it also influences the hardware development. Observations illustrate that\nthis cycle not always is optimal for both sides as it is not proactively\nsteered. Key statements characterise ideas how it might be possible to\nintegrate both hardware and software creation closer to the best of both\nworlds---again even without classic co-design in mind where new pieces of\nhardware are created. The workshop finally identified three development idioms\nthat might help to improve software and system design with respect to emerging\nhardware.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2016 06:51:50 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Weinzierl", "Tobias", ""]]}, {"id": "1607.02904", "submitter": "Markus H\\\"ohnerbach", "authors": "Markus H\\\"ohnerbach, Ahmed E. Ismail, Paolo Bientinesi", "title": "The Vectorization of the Tersoff Multi-Body Potential: An Exercise in\n  Performance Portability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular dynamics simulations, an indispensable research tool in\ncomputational chemistry and materials science, consume a significant portion of\nthe supercomputing cycles around the world. We focus on multi-body potentials\nand aim at achieving performance portability. Compared with well-studied pair\npotentials, multibody potentials deliver increased simulation accuracy but are\ntoo complex for effective compiler optimization. Because of this, achieving\ncross-platform performance remains an open question. By abstracting from target\narchitecture and computing precision, we develop a vectorization scheme\napplicable to both CPUs and accelerators. We present results for the Tersoff\npotential within the molecular dynamics code LAMMPS on several architectures,\ndemonstrating efficiency gains not only for computational kernels, but also for\nlarge-scale simulations. On a cluster of Intel Xeon Phi's, our optimized solver\nis between 3 and 5 times faster than the pure MPI reference.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2016 11:23:04 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["H\u00f6hnerbach", "Markus", ""], ["Ismail", "Ahmed E.", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1607.03252", "submitter": "Ulrich Ruede", "authors": "Bj\\\"orn Gmeiner and Daniel Drzisga and Ulrich Ruede and Robert\n  Scheichl and Barbara Wohlmuth", "title": "Scheduling massively parallel multigrid for multilevel Monte Carlo\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of naive, sampling-based uncertainty\nquantification for 3D partial differential equations is extremely high.\nMultilevel approaches, such as multilevel Monte Carlo (MLMC), can reduce the\ncomplexity significantly, but to exploit them fully in a parallel environment,\nsophisticated scheduling strategies are needed. Often fast algorithms that are\nexecuted in parallel are essential to compute fine level samples in 3D, whereas\nto compute individual coarse level samples only moderate numbers of processors\ncan be employed efficiently. We make use of multiple instances of a parallel\nmultigrid solver combined with advanced load balancing techniques. In\nparticular, we optimize the concurrent execution across the three layers of the\nMLMC method: parallelization across levels, across samples, and across the\nspatial grid. The overall efficiency and performance of these methods will be\nanalyzed. Here the scalability window of the multigrid solver is revealed as\nbeing essential, i.e., the property that the solution can be computed with a\nrange of process numbers while maintaining good parallel efficiency. We\nevaluate the new scheduling strategies in a series of numerical tests, and\nconclude the paper demonstrating large 3D scaling experiments.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 07:47:45 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Gmeiner", "Bj\u00f6rn", ""], ["Drzisga", "Daniel", ""], ["Ruede", "Ulrich", ""], ["Scheichl", "Robert", ""], ["Wohlmuth", "Barbara", ""]]}, {"id": "1607.04091", "submitter": "Robert Dahl Jacobsen", "authors": "Robert Dahl Jacobsen and Morten Nielsen and Morten Grud Rasmussen", "title": "Generalized Sampling in Julia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized sampling is a numerically stable framework for obtaining\nreconstructions of signals in different bases and frames from their samples. In\nthis paper, we will introduce a carefully documented toolbox for performing\ngeneralized sampling in Julia. Julia is a new language for technical computing\nwith focus on performance, which is ideally suited to handle the large size\nproblems often encountered in generalized sampling. The toolbox provides\nspecialized solutions for the setup of Fourier bases and wavelets. The\nperformance of the toolbox is compared to existing implementations of\ngeneralized sampling in MATLAB.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 11:26:28 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 09:58:28 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Jacobsen", "Robert Dahl", ""], ["Nielsen", "Morten", ""], ["Rasmussen", "Morten Grud", ""]]}, {"id": "1607.04245", "submitter": "Matthew Knepley", "authors": "Matthew G. Knepley and Karl Rupp and Andy R. Terrel", "title": "Finite Element Integration with Quadrature on the GPU", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel, quadrature-based finite element integration method for\nlow-order elements on GPUs, using a pattern we call \\textit{thread\ntransposition} to avoid reductions while vectorizing aggressively. On the\nNVIDIA GTX580, which has a nominal single precision peak flop rate of 1.5 TF/s\nand a memory bandwidth of 192 GB/s, we achieve close to 300 GF/s for element\nintegration on first-order discretization of the Laplacian operator with\nvariable coefficients in two dimensions, and over 400 GF/s in three dimensions.\nFrom our performance model we find that this corresponds to 90\\% of our\nmeasured achievable bandwidth peak of 310 GF/s. Further experimental results\nalso match the predicted performance when used with double precision (120 GF/s\nin two dimensions, 150 GF/s in three dimensions). Results obtained for the\nlinear elasticity equations (220 GF/s and 70 GF/s in two dimensions, 180 GF/s\nand 60 GF/s in three dimensions) also demonstrate the applicability of our\nmethod to vector-valued partial differential equations.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 18:53:48 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Knepley", "Matthew G.", ""], ["Rupp", "Karl", ""], ["Terrel", "Andy R.", ""]]}, {"id": "1607.04254", "submitter": "Matthew Knepley", "authors": "Peter R. Brune and Matthew G. Knepley and Barry F. Smith and Xuemin Tu", "title": "Composing Scalable Nonlinear Algebraic Solvers", "comments": "29 pages, 14 figures, 13 tables", "journal-ref": "SIAM Review 57(4), 535-565, 2015", "doi": "10.1137/130936725", "report-no": null, "categories": "math.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most efficient linear solvers use composable algorithmic components, with the\nmost common model being the combination of a Krylov accelerator and one or more\npreconditioners. A similar set of concepts may be used for nonlinear algebraic\nsystems, where nonlinear composition of different nonlinear solvers may\nsignificantly improve the time to solution. We describe the basic concepts of\nnonlinear composition and preconditioning and present a number of solvers\napplicable to nonlinear partial differential equations. We have developed a\nsoftware framework in order to easily explore the possible combinations of\nsolvers. We show that the performance gains from using composed solvers can be\nsubstantial compared with gains from standard Newton-Krylov methods.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 19:21:43 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Brune", "Peter R.", ""], ["Knepley", "Matthew G.", ""], ["Smith", "Barry F.", ""], ["Tu", "Xuemin", ""]]}, {"id": "1607.04767", "submitter": "Ahmad Eid H. A.", "authors": "Ahmad Hosney Awad Eid", "title": "Optimized Automatic Code Generation for Geometric Algebra Based\n  Algorithms with Ray Tracing Application", "comments": "PhD Thesis, 2010, 249 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic code generation for low-dimensional geometric algorithms is capable\nof producing efficient low-level software code through a high-level geometric\ndomain specific language. Geometric Algebra (GA) is one of the most suitable\nalgebraic systems for being the base for such code generator. This work\npresents an attempt at realizing such idea in practice. A novel GA-based\ngeometric code generator, called GMac, is proposed. Comparisons to similar\nGA-based code generators are provided. The possibility of fully benefiting from\nthe symbolic power of GA while obtaining good performance and maintainability\nof software implementations is illustrated through a ray tracing application.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jul 2016 16:54:39 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Eid", "Ahmad Hosney Awad", ""]]}, {"id": "1607.07892", "submitter": "Jarrett Revels", "authors": "Jarrett Revels, Miles Lubin, and Theodore Papamarkou", "title": "Forward-Mode Automatic Differentiation in Julia", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ForwardDiff, a Julia package for forward-mode automatic\ndifferentiation (AD) featuring performance competitive with low-level languages\nlike C++. Unlike recently developed AD tools in other popular high-level\nlanguages such as Python and MATLAB, ForwardDiff takes advantage of\njust-in-time (JIT) compilation to transparently recompile AD-unaware user code,\nenabling efficient support for higher-order differentiation and differentiation\nusing custom number types (including complex numbers). For gradient and\nJacobian calculations, ForwardDiff provides a variant of vector-forward mode\nthat avoids expensive heap allocation and makes better use of memory bandwidth\nthan traditional vector mode. In our numerical experiments, we demonstrate that\nfor nontrivially large dimensions, ForwardDiff's gradient computations can be\nfaster than a reverse-mode implementation from the Python-based autograd\npackage. We also illustrate how ForwardDiff is used effectively within JuMP, a\nmodeling language for optimization. According to our usage statistics, 41\nunique repositories on GitHub depend on ForwardDiff, with users from diverse\nfields such as astronomy, optimization, finite element analysis, and\nstatistics.\n  This document is an extended abstract that has been accepted for presentation\nat the AD2016 7th International Conference on Algorithmic Differentiation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 20:32:29 GMT"}], "update_date": "2016-07-28", "authors_parsed": [["Revels", "Jarrett", ""], ["Lubin", "Miles", ""], ["Papamarkou", "Theodore", ""]]}]