[{"id": "2006.04391", "submitter": "Johannes Bl\\\"uhdorn", "authors": "Johannes Bl\\\"uhdorn, Nicolas R. Gauger, Matthias Kabel", "title": "AutoMat -- Automatic Differentiation for Generalized Standard Materials\n  on GPUs", "comments": "28 pages, 15 figures, 7 tables; new layout, more detailed proof of\n  Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a universal method for the evaluation of generalized standard\nmaterials that greatly simplifies the material law implementation process. By\nmeans of automatic differentiation and a numerical integration scheme, AutoMat\nreduces the implementation effort to two potential functions. By moving AutoMat\nto the GPU, we close the performance gap to conventional evaluation routines\nand demonstrate in detail that the expression level reverse mode of automatic\ndifferentiation as well as its extension to second order derivatives can be\napplied inside CUDA kernels. We underline the effectiveness and the\napplicability of AutoMat by integrating it into the FFT-based homogenization\nscheme of Moulinec and Suquet and discuss the benefits of using AutoMat with\nrespect to runtime and solution accuracy for an elasto-viscoplastic example.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 07:38:28 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 11:41:40 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Bl\u00fchdorn", "Johannes", ""], ["Gauger", "Nicolas R.", ""], ["Kabel", "Matthias", ""]]}, {"id": "2006.05373", "submitter": "Eric Neiva", "authors": "Santiago Badia, Alberto F. Mart\\'in, Eric Neiva and Francesc Verdugo", "title": "The aggregated unfitted finite element method on parallel tree-based\n  adaptive meshes", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an adaptive unfitted finite element scheme that\ncombines the aggregated finite element method with parallel adaptive mesh\nrefinement. We introduce a novel scalable distributed-memory implementation of\nthe resulting scheme on locally-adapted Cartesian forest-of-trees meshes. We\npropose a two-step algorithm to construct the finite element space at hand by\nmeans of a discrete extension operator that carefully mixes aggregation\nconstraints of problematic degrees of freedom, which get rid of the small cut\ncell problem, and standard hanging degree of freedom constraints, which ensure\ntrace continuity on non-conforming meshes. Following this approach, we derive a\nfinite element space that can be expressed as the original one plus\nwell-defined linear constraints. Moreover, it requires minimum parallelization\neffort, using standard functionality available in existing large-scale finite\nelement codes. Numerical experiments demonstrate its optimal mesh adaptation\ncapability, robustness to cut location and parallel efficiency, on classical\nPoisson $hp$-adaptivity benchmarks. Our work opens the path to functional and\ngeometrical error-driven dynamic mesh adaptation with the aggregated finite\nelement method in large-scale realistic scenarios. Likewise, it can offer\nguidance for bridging other scalable unfitted methods and parallel adaptive\nmesh refinement.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 16:08:13 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 12:10:49 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Badia", "Santiago", ""], ["Mart\u00edn", "Alberto F.", ""], ["Neiva", "Eric", ""], ["Verdugo", "Francesc", ""]]}, {"id": "2006.06052", "submitter": "Denis Demidov", "authors": "Denis Demidov, Lin Mu, Bin Wang", "title": "Accelerating linear solvers for Stokes problems with C++ metaprogramming", "comments": null, "journal-ref": null, "doi": "10.1016/j.jocs.2020.101285", "report-no": null, "categories": "cs.MS cs.DC cs.DS physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient solution of large sparse saddle point systems is very important\nin computational fluid mechanics. The discontinuous Galerkin finite element\nmethods have become increasingly popular for incompressible flow problems but\ntheir application is limited due to high computational cost. We describe the\nC++ programming techniques that may help to accelerate linear solvers for such\nproblems. The approach is based on the policy-based design pattern and partial\ntemplate specialization, and is implemented in the open source AMGCL library.\nThe efficiency is demonstrated with the example of accelerating an iterative\nsolver of a discontinuous Galerkin finite element method for the Stokes\nproblem. The implementation allows selecting algorithmic components of the\nsolver by adjusting template parameters without any changes to the codebase. It\nis possible to switch the system matrix to use small statically sized blocks to\nstore the nonzero values, or use a mixed precision solution, which results in\nup to 4 times speedup, and reduces the memory footprint of the algorithm by\nabout 40\\%. We evaluate both monolithic and composite preconditioning\nstrategies for the 3 benchmark problems. The performance of the proposed\nsolution is compared with a multithreaded direct Pardiso solver and a parallel\niterative PETSc solver.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 20:20:05 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 15:39:23 GMT"}, {"version": "v3", "created": "Tue, 22 Dec 2020 06:02:43 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Demidov", "Denis", ""], ["Mu", "Lin", ""], ["Wang", "Bin", ""]]}, {"id": "2006.06825", "submitter": "Andreas Varga", "authors": "Andreas Varga", "title": "On Computing the Kronecker Structure of Polynomial and Rational Matrices\n  using Julia", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss the mathematical background and the computational\naspects which underly the implementation of a collection of Julia functions in\nthe MatrixPencils package for the determination of structural properties of\npolynomial and rational matrices. We primarily focus on the computation of the\nfinite and infinite spectral structures (e.g., eigenvalues, zeros, poles) as\nwell as the left and right singular structures (e.g., Kronecker indices), which\nplay a fundamental role in the structure of the solution of many problems\ninvolving polynomial and rational matrices. The basic analysis tool is the\ndetermination of the Kronecker structure of linear matrix pencils using\nnumerically reliable algorithms, which is used in conjunction with several\nlinearization techniques of polynomial and rational matrices. Examples of\npolynomial and rational matrices, which exhibit all relevant structural\nfeatures, are considered to illustrate the main mathematical concepts and the\ncapabilities of implemented tools.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 08:36:42 GMT"}, {"version": "v2", "created": "Sun, 6 Sep 2020 11:44:24 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Varga", "Andreas", ""]]}, {"id": "2006.10256", "submitter": "K. Jarrod Millman", "authors": "Charles R. Harris, K. Jarrod Millman, St\\'efan J. van der Walt, Ralf\n  Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor,\n  Sebastian Berg, Nathaniel J. Smith, Robert Kern, Matti Picus, Stephan Hoyer,\n  Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime Fern\\'andez del\n  R\\'io, Mark Wiebe, Pearu Peterson, Pierre G\\'erard-Marchant, Kevin Sheppard,\n  Tyler Reddy, Warren Weckesser, Hameer Abbasi, Christoph Gohlke, Travis E.\n  Oliphant", "title": "Array Programming with NumPy", "comments": null, "journal-ref": "Nature 585, 357 (2020)", "doi": "10.1038/s41586-020-2649-2", "report-no": null, "categories": "cs.MS stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Array programming provides a powerful, compact, expressive syntax for\naccessing, manipulating, and operating on data in vectors, matrices, and\nhigher-dimensional arrays. NumPy is the primary array programming library for\nthe Python language. It plays an essential role in research analysis pipelines\nin fields as diverse as physics, chemistry, astronomy, geoscience, biology,\npsychology, material science, engineering, finance, and economics. For example,\nin astronomy, NumPy was an important part of the software stack used in the\ndiscovery of gravitational waves and the first imaging of a black hole. Here we\nshow how a few fundamental array concepts lead to a simple and powerful\nprogramming paradigm for organizing, exploring, and analyzing scientific data.\nNumPy is the foundation upon which the entire scientific Python universe is\nconstructed. It is so pervasive that several projects, targeting audiences with\nspecialized needs, have developed their own NumPy-like interfaces and array\nobjects. Because of its central position in the ecosystem, NumPy increasingly\nplays the role of an interoperability layer between these new array computation\nlibraries.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 03:39:27 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Harris", "Charles R.", ""], ["Millman", "K. Jarrod", ""], ["van der Walt", "St\u00e9fan J.", ""], ["Gommers", "Ralf", ""], ["Virtanen", "Pauli", ""], ["Cournapeau", "David", ""], ["Wieser", "Eric", ""], ["Taylor", "Julian", ""], ["Berg", "Sebastian", ""], ["Smith", "Nathaniel J.", ""], ["Kern", "Robert", ""], ["Picus", "Matti", ""], ["Hoyer", "Stephan", ""], ["van Kerkwijk", "Marten H.", ""], ["Brett", "Matthew", ""], ["Haldane", "Allan", ""], ["del R\u00edo", "Jaime Fern\u00e1ndez", ""], ["Wiebe", "Mark", ""], ["Peterson", "Pearu", ""], ["G\u00e9rard-Marchant", "Pierre", ""], ["Sheppard", "Kevin", ""], ["Reddy", "Tyler", ""], ["Weckesser", "Warren", ""], ["Abbasi", "Hameer", ""], ["Gohlke", "Christoph", ""], ["Oliphant", "Travis E.", ""]]}, {"id": "2006.11042", "submitter": "Eric Neiva", "authors": "Eric Neiva and Santiago Badia", "title": "Robust and scalable h-adaptive aggregated unfitted finite elements for\n  interface elliptic problems", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": "10.1016/j.cma.2021.113769", "report-no": null, "categories": "math.NA cs.CE cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel, fully robust and highly-scalable, $h$-adaptive\naggregated unfitted finite element method for large-scale interface elliptic\nproblems. The new method is based on a recent distributed-memory implementation\nof the aggregated finite element method atop a highly-scalable Cartesian\nforest-of-trees mesh engine. It follows the classical approach of weakly\ncoupling nonmatching discretisations at the interface to model internal\ndiscontinuities at the interface. We propose a natural extension of a\nsingle-domain parallel cell aggregation scheme to problems with a finite number\nof interfaces; it straightforwardly leads to aggregated finite element spaces\nthat have the structure of a Cartesian product. We demonstrate, through\nstandard numerical analysis and exhaustive numerical experimentation on several\ncomplex Poisson and linear elasticity benchmarks, that the new technique enjoys\nthe following properties: well-posedness, robustness with respect to cut\nlocation and material contrast, optimal ($h$-adaptive) approximation\nproperties, high scalability and easy implementation in large-scale finite\nelement codes. As a result, the method offers great potential as a useful\nfinite element solver for large-scale interface problems modelled by partial\ndifferential equations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 09:50:02 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 12:20:12 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Neiva", "Eric", ""], ["Badia", "Santiago", ""]]}, {"id": "2006.12992", "submitter": "Max Sagebaum", "authors": "Max Sagebaum, Johannes Bl\\\"uhdorn, Nicolas R. Gauger", "title": "Index handling and assign optimization for Algorithmic Differentiation\n  reuse index managers", "comments": "20 pages, 14 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For operator overloading Algorithmic Differentiation tools, the\nidentification of primal variables and adjoint variables is usually done via\nindices. Two common schemes exist for their management and distribution. The\nlinear approach is easy to implement and supports memory optimization with\nrespect to copy statements. On the other hand, the reuse approach requires more\nimplementation effort but results in much smaller adjoint vectors, which are\nmore suitable for the vector mode of Algorithmic Differentiation. In this\npaper, we present both approaches, how to implement them, and discuss their\nadvantages, disadvantages and properties of the resulting Algorithmic\nDifferentiation type. In addition, a new management scheme is presented which\nsupports copy optimizations and the reuse of indices, thus combining the\nadvantages of the other two. The implementations of all three schemes are\ncompared on a simple synthetic example and on a real world example using the\ncomputational fluid dynamics solver in SU2.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 13:40:46 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 14:22:31 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Sagebaum", "Max", ""], ["Bl\u00fchdorn", "Johannes", ""], ["Gauger", "Nicolas R.", ""]]}, {"id": "2006.14290", "submitter": "Yuhsiang Tsai", "authors": "Yuhsiang M. Tsai (1), Terry Cojean (1), Tobias Ribizel (1), Hartwig\n  Anzt (1 and 2) ((1) Karlsruhe Institute of Technology, (2) University of\n  Tennessee, Innovative Computing Lab)", "title": "Preparing Ginkgo for AMD GPUs -- A Testimonial on Porting CUDA Code to\n  HIP", "comments": "Preprint submitted to HeteroPar", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With AMD reinforcing their ambition in the scientific high performance\ncomputing ecosystem, we extend the hardware scope of the Ginkgo linear algebra\npackage to feature a HIP backend for AMD GPUs. In this paper, we report and\ndiscuss the porting effort from CUDA, the extension of the HIP framework to add\nmissing features such as cooperative groups, the performance price of compiling\nHIP code for AMD architectures, and the design of a library providing native\nbackends for NVIDIA and AMD GPUs while minimizing code duplication by using a\nshared code base.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 10:22:02 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Tsai", "Yuhsiang M.", "", "1 and 2"], ["Cojean", "Terry", "", "1 and 2"], ["Ribizel", "Tobias", "", "1 and 2"], ["Anzt", "Hartwig", "", "1 and 2"]]}, {"id": "2006.15419", "submitter": "Xingguo Li", "authors": "Xingguo Li, Tuo Zhao, Xiaoming Yuan, Han Liu", "title": "The flare Package for High Dimensional Linear Regression and Precision\n  Matrix Estimation in R", "comments": null, "journal-ref": "Journal of Machine Learning Research 16 (2015) 553-557", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an R package named flare, which implements a family of\nnew high dimensional regression methods (LAD Lasso, SQRT Lasso, $\\ell_q$ Lasso,\nand Dantzig selector) and their extensions to sparse precision matrix\nestimation (TIGER and CLIME). These methods exploit different nonsmooth loss\nfunctions to gain modeling flexibility, estimation robustness, and tuning\ninsensitiveness. The developed solver is based on the alternating direction\nmethod of multipliers (ADMM). The package flare is coded in double precision C,\nand called from R by a user-friendly interface. The memory usage is optimized\nby using the sparse matrix output. The experiments show that flare is efficient\nand can scale up to large problems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 18:01:56 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Li", "Xingguo", ""], ["Zhao", "Tuo", ""], ["Yuan", "Xiaoming", ""], ["Liu", "Han", ""]]}, {"id": "2006.16465", "submitter": "Mohammad Islam", "authors": "Mohammad Shafaet Islam, Qiqi Wang", "title": "Hierarchical Jacobi Iteration for Structured Matrices on GPUs using\n  Shared Memory", "comments": "22 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High fidelity scientific simulations modeling physical phenomena typically\nrequire solving large linear systems of equations which result from\ndiscretization of a partial differential equation (PDE) by some numerical\nmethod. This step often takes a vast amount of computational time to complete,\nand therefore presents a bottleneck in simulation work. Solving these linear\nsystems efficiently requires the use of massively parallel hardware with high\ncomputational throughput, as well as the development of algorithms which\nrespect the memory hierarchy of these hardware architectures to achieve high\nmemory bandwidth.\n  In this paper, we present an algorithm to accelerate Jacobi iteration for\nsolving structured problems on graphics processing units (GPUs) using a\nhierarchical approach in which multiple iterations are performed within on-chip\nshared memory every cycle. A domain decomposition style procedure is adopted in\nwhich the problem domain is partitioned into subdomains whose data is copied to\nthe shared memory of each GPU block. Jacobi iterations are performed internally\nwithin each block's shared memory, avoiding the need to perform expensive\nglobal memory accesses every step. We test our algorithm on the linear systems\narising from discretization of Poisson's equation in 1D and 2D, and observe\nspeedup in convergence using our shared memory approach compared to a\ntraditional Jacobi implementation which only uses global memory on the GPU. We\nobserve a x8 speedup in convergence in the 1D problem and a nearly x6 speedup\nin the 2D case from the use of shared memory compared to a conventional GPU\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 01:36:58 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Islam", "Mohammad Shafaet", ""], ["Wang", "Qiqi", ""]]}, {"id": "2006.16767", "submitter": "Chao Yang", "authors": "Min Li and Yulong Ao and Chao Yang", "title": "Adaptive SpMV/SpMSpV on GPUs for Input Vectors of Varied Sparsity", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite numerous efforts for optimizing the performance of Sparse Matrix and\nVector Multiplication (SpMV) on modern hardware architectures, few works are\ndone to its sparse counterpart, Sparse Matrix and Sparse Vector Multiplication\n(SpMSpV), not to mention dealing with input vectors of varied sparsity. The key\nchallenge is that depending on the sparsity levels, distribution of data, and\ncompute platform, the optimal choice of SpMV/SpMSpV kernel can vary, and a\nstatic choice does not suffice. In this paper, we propose an adaptive\nSpMV/SpMSpV framework, which can automatically select the appropriate\nSpMV/SpMSpV kernel on GPUs for any sparse matrix and vector at the runtime.\nBased on systematic analysis on key factors such as computing pattern, workload\ndistribution and write-back strategy, eight candidate SpMV/SpMSpV kernels are\nencapsulated into the framework to achieve high performance in a seamless\nmanner. A comprehensive study on machine learning based kernel selector is\nperformed to choose the kernel and adapt with the varieties of both the input\nand hardware from both accuracy and overhead perspectives. Experiments\ndemonstrate that the adaptive framework can substantially outperform the\nprevious state-of-the-art in real-world applications on NVIDIA Tesla K40m, P100\nand V100 GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 13:20:02 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2020 01:32:10 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 12:28:15 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Li", "Min", ""], ["Ao", "Yulong", ""], ["Yang", "Chao", ""]]}, {"id": "2006.16852", "submitter": "Pratik Nayak", "authors": "Hartwig Anzt, Terry Cojean, Goran Flegar, Fritz G\\\"obel, Thomas\n  Gr\\\"utzmacher, Pratik Nayak, Tobias Ribizel, Yuhsiang Mike Tsai, Enrique S.\n  Quintana-Ort\\'i", "title": "Ginkgo: A Modern Linear Operator Algebra Framework for High Performance\n  Computing", "comments": "Preprint submitted to ACM Transactions on Mathematical Software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Ginkgo, a modern C++ math library for scientific\nhigh performance computing. While classical linear algebra libraries act on\nmatrix and vector objects, Ginkgo's design principle abstracts all\nfunctionality as \"linear operators\", motivating the notation of a \"linear\noperator algebra library\". Ginkgo's current focus is oriented towards providing\nsparse linear algebra functionality for high performance GPU architectures, but\ngiven the library design, this focus can be easily extended to accommodate\nother algorithms and hardware architectures. We introduce this sophisticated\nsoftware architecture that separates core algorithms from architecture-specific\nback ends and provide details on extensibility and sustainability measures. We\nalso demonstrate Ginkgo's usability by providing examples on how to use its\nfunctionality inside the MFEM and deal.ii finite element ecosystems. Finally,\nwe offer a practical demonstration of Ginkgo's high performance on\nstate-of-the-art GPU architectures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:42:48 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 08:31:08 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Anzt", "Hartwig", ""], ["Cojean", "Terry", ""], ["Flegar", "Goran", ""], ["G\u00f6bel", "Fritz", ""], ["Gr\u00fctzmacher", "Thomas", ""], ["Nayak", "Pratik", ""], ["Ribizel", "Tobias", ""], ["Tsai", "Yuhsiang Mike", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""]]}]