[{"id": "1905.00104", "submitter": "Juan Michael Sargado", "authors": "Juan Michael Sargado", "title": "A new object-oriented framework for solving multiphysics problems via\n  combination of different numerical methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many interesting phenomena are characterized by the complex interaction of\ndifferent physical processes, each often best modeled numerically via a\nspecific approach. In this paper, we present the design and implementation of\nan object-oriented framework for performing multiphysics simulations that\nallows for the monolithic coupling of different numerical schemes. In contrast,\nmost of the currently available simulation tools are tailored towards a\nspecific numerical model, so that one must resort to coupling different codes\nexternally based on operator splitting. The current framework has been\ndeveloped following the C++11 standard, and its main aim is to provide an\nenvironment that affords enough flexibility for developers to implement complex\nmodels while at the same time giving end users a maximum amount of control over\nfiner details of the simulation without having to write additional code. The\nmain challenges towards realizing these objectives are discussed in the paper,\ntogether with the manner in which they are addressed. Along with core objects\nrepresenting the framework skeleton, we present the various polymorphic classes\nthat may be utilized by developers to implement new formulations, material\nmodels and solution algorithms. The code architecture is designed to allow\nachievement of the aforementioned functionalities with a minimum level of\ninheritance in order to improve the learning curve for programmers who are not\nacquainted with the software. Key capabilities of the framework are\ndemonstrated via the solution of numerical examples dealing on composite\ntorsion, Biot poroelasticity (featuring a combined finite element-finite volume\nformulation), and brittle crack propagation using a phase-field approach.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 06:24:06 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Sargado", "Juan Michael", ""]]}, {"id": "1905.00562", "submitter": "Akshay Agrawal", "authors": "Akshay Agrawal and Stephen Boyd", "title": "Disciplined Quasiconvex Programming", "comments": "p. 4: corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a composition rule involving quasiconvex functions that\ngeneralizes the classical composition rule for convex functions. This rule\ncomplements well-known rules for the curvature of quasiconvex functions under\nincreasing functions and pointwise maximums. We refer to the class of\noptimization problems generated by these rules, along with a base set of\nquasiconvex and quasiconcave functions, as disciplined quasiconvex programs.\nDisciplined quasiconvex programming generalizes disciplined convex programming,\nthe class of optimization problems targeted by most modern domain-specific\nlanguages for convex optimization. We describe an implementation of disciplined\nquasiconvex programming that makes it possible to specify and solve quasiconvex\nprograms in CVXPY 1.0.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2019 03:19:49 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 17:13:26 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 20:03:44 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Agrawal", "Akshay", ""], ["Boyd", "Stephen", ""]]}, {"id": "1905.01213", "submitter": "Waleed Yousef", "authors": "Ahmed A. Elsayed and Waleed A. Yousef", "title": "Matlab vs. OpenCV: A Comparative Study of Different Machine Learning\n  Algorithms", "comments": "This manuscript was composed in 2011 as part of a research pursued\n  that time", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific Computing relies on executing computer algorithms coded in some\nprogramming languages. Given a particular available hardware, algorithms speed\nis a crucial factor. There are many scientific computing environments used to\ncode such algorithms. Matlab is one of the most tremendously successful and\nwidespread scientific computing environments that is rich of toolboxes,\nlibraries, and data visualization tools. OpenCV is a (C++)-based library\nwritten primarily for Computer Vision and its related areas. This paper\npresents a comparative study using 20 different real datasets to compare the\nspeed of Matlab and OpenCV for some Machine Learning algorithms. Although\nMatlab is more convenient in developing and data presentation, OpenCV is much\nfaster in execution, where the speed ratio reaches more than 80 in some cases.\nThe best of two worlds can be achieved by exploring using Matlab or similar\nenvironments to select the most successful algorithm; then, implementing the\nselected algorithm using OpenCV or similar environments to gain a speed factor.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:58:58 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 00:15:30 GMT"}, {"version": "v3", "created": "Fri, 9 Aug 2019 14:41:09 GMT"}, {"version": "v4", "created": "Wed, 14 Aug 2019 12:20:37 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Elsayed", "Ahmed A.", ""], ["Yousef", "Waleed A.", ""]]}, {"id": "1905.02241", "submitter": "Pramod Kumbhar", "authors": "Pramod Kumbhar, Omar Awile, Liam Keegan, Jorge Blanco Alonso, James\n  King, Michael Hines, Felix Sch\\\"urmann", "title": "An optimizing multi-platform source-to-source compiler framework for the\n  NEURON MODeling Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific languages (DSLs) play an increasingly important role in the\ngeneration of high performing software. They allow the user to exploit specific\nknowledge encoded in the constructs for the generation of code adapted to a\nparticular hardware architecture; at the same time, they make it easier to\ngenerate optimized code for a multitude of platforms as the transformation has\nto be encoded only once. Here, we describe a new code generation framework\n(NMODL) for an existing DSL in the NEURON framework, a widely used software for\nmassively parallel simulation of biophysically detailed brain tissue models.\nExisting NMODL DSL transpilers lack either essential features to generate\noptimized code or capability to parse the diversity of existing models in the\nuser community. Our NMODL framework has been tested against a large number of\npreviously published user models and offers high-level domain-specific\noptimizations and symbolic algebraic simplifications before target code\ngeneration. Furthermore, rich analysis tools are provided allowing the\nscientist to introspect models. NMODL implements multiple SIMD and SPMD targets\noptimized for modern hardware. Benchmarks were performed on Intel Skylake,\nIntel KNL and AMD Naples platforms. When comparing NMODL-generated kernels with\nNEURON we observe a speedup of up to 20x, resulting into overall speedups of\ntwo different production simulations by $\\sim$10x. When compared to a\npreviously published SIMD optimized version that heavily relied on\nauto-vectorization by the compiler still a speedup of up to $\\sim$2x is\nobserved.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 19:20:54 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Kumbhar", "Pramod", ""], ["Awile", "Omar", ""], ["Keegan", "Liam", ""], ["Alonso", "Jorge Blanco", ""], ["King", "James", ""], ["Hines", "Michael", ""], ["Sch\u00fcrmann", "Felix", ""]]}, {"id": "1905.02803", "submitter": "Dmitry Pekurovsky", "authors": "Dmitry Pekurovsky", "title": "P3DFFT: a framework for parallel computations of Fourier transforms in\n  three dimensions", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing, 34(4), C192-C209 (2012)", "doi": "10.1137/11082748X", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier and related transforms is a family of algorithms widely employed in\ndiverse areas of computational science, notoriously difficult to scale on\nhigh-performance parallel computers with large number of processing elements\n(cores). This paper introduces a popular software package called P3DFFT\nimplementing Fast Fourier Transforms (FFT) in three dimensions (3D) in a highly\nefficient and scalable way. It overcomes a well-known scalability bottleneck of\n3D FFT implementations by using two-dimensional domain decomposition. Designed\nfor portable performance, P3DFFT achieves excellent timings for a number of\nsystems and problem sizes. On Cray XT5 system P3DFFT attains 45% efficiency in\nweak scaling from 128 to 65,536 computational cores. Library features include\nFourier and Chebyshev transforms, Fortran and C interfaces, in- and\nout-of-place transforms, uneven data grids, single and double precision. P3DFFT\nis available as open source at http://code.google.com/p/p3dfft/. This paper\ndiscusses P3DFFT implementation and performance in a way that helps guide the\nuser in making optimal choices for parameters of their runs.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 20:47:58 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Pekurovsky", "Dmitry", ""]]}, {"id": "1905.03136", "submitter": "Georg Hager", "authors": "Dominik Ernst, Georg Hager, Jonas Thies, Gerhard Wellein", "title": "Performance Engineering for Real and Complex Tall & Skinny Matrix\n  Multiplication Kernels on GPUs", "comments": "12 pages, 22 figures. Extended version of arXiv:1905.03136v1 for\n  journal submission", "journal-ref": null, "doi": "10.1007/978-3-030-43229-4_43", "report-no": null, "categories": "cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General matrix-matrix multiplications with double-precision real and complex\nentries (DGEMM and ZGEMM) in vendor-supplied BLAS libraries are best optimized\nfor square matrices but often show bad performance for tall & skinny matrices,\nwhich are much taller than wide. NVIDIA's current CUBLAS implementation\ndelivers only a fraction of the potential performance as indicated by the\nroofline model in this case. We describe the challenges and key characteristics\nof an implementation that can achieve close to optimal performance. We further\nevaluate different strategies of parallelization and thread distribution, and\ndevise a flexible, configurable mapping scheme. To ensure flexibility and allow\nfor highly tailored implementations we use code generation combined with\nautotuning. For a large range of matrix sizes in the domain of interest we\nachieve at least 2/3 of the roofline performance and often substantially\noutperform state-of-the art CUBLAS results on an NVIDIA Volta GPGPU.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 15:11:46 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 15:54:31 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Ernst", "Dominik", ""], ["Hager", "Georg", ""], ["Thies", "Jonas", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1905.04033", "submitter": "Jakub \\v{C}erven\\'y", "authors": "Jakub \\v{C}erven\\'y, Veselin Dobrev, Tzanio Kolev", "title": "Non-Conforming Mesh Refinement for High-Order Finite Elements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general algorithm for non-conforming adaptive mesh refinement\n(AMR) of unstructured meshes in high-order finite element codes. Our focus is\non h-refinement with a fixed polynomial order. The algorithm handles\ntriangular, quadrilateral, hexahedral and prismatic meshes of arbitrarily high\norder curvature, for any order finite element space in the de Rham sequence. We\npresent a flexible data structure for meshes with hanging nodes and a general\nprocedure to construct the conforming interpolation operator, both in serial\nand in parallel. The algorithm and data structure allow anisotropic refinement\nof tensor product elements in 2D and 3D, and support unlimited refinement\nratios of adjacent elements. We report numerical experiments verifying the\ncorrectness of the algorithms, and perform a parallel scaling study to show\nthat we can adapt meshes containing billions of elements and run efficiently on\n393,000 parallel tasks. Finally, we illustrate the integration of dynamic AMR\ninto a high-order Lagrangian hydrodynamics solver.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:41:30 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["\u010cerven\u00fd", "Jakub", ""], ["Dobrev", "Veselin", ""], ["Kolev", "Tzanio", ""]]}, {"id": "1905.04642", "submitter": "Julio C\\'esar P\\'erez Sansalvador", "authors": "Ricardo Serrato Barrera and Gustavo Rodr\\'iguez G\\'omez and Julio\n  C\\'esar P\\'erez Sansalvador and Saul E. Pomares Hern\\'andez and Leticia\n  Flores Pulido and Antonio Mu\\~noz", "title": "Software System Design based on Patterns for Newton-Type Methods", "comments": "19 pages, 11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of engineering applications uses optimisation techniques as part\nof their solution process. The researcher uses specialized software that\nimplements well-known optimisation techniques to solve his problem. However,\nwhen it comes to develop original optimisation techniques that fit a particular\nproblem the researcher has no option but to implement his own new method from\nscratch. This leads to large development times and error prone code that, in\ngeneral, will not be reused for any other application. In this work, we present\na novel methodology that simplifies, fasten and improves the development\nprocess of scientific software. This methodology guide us on the identification\nof design patterns. The application of this methodology generates reusable,\nflexible and high quality scientific software. Furthermore, the produced\nsoftware becomes a documented tool to transfer the knowledge on the development\nprocess of scientific software. We apply this methodology for the design of an\noptimisation framework implementing Newton's type methods which can be used as\na fast prototyping tool of new optimisation techniques based on Newton's type\nmethods. The abstraction, reusability and flexibility of the developed\nframework is measured by means of Martin's metric. The results indicate that\nthe developed software is highly reusable.\n", "versions": [{"version": "v1", "created": "Sun, 12 May 2019 04:04:22 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Barrera", "Ricardo Serrato", ""], ["G\u00f3mez", "Gustavo Rodr\u00edguez", ""], ["Sansalvador", "Julio C\u00e9sar P\u00e9rez", ""], ["Hern\u00e1ndez", "Saul E. Pomares", ""], ["Pulido", "Leticia Flores", ""], ["Mu\u00f1oz", "Antonio", ""]]}, {"id": "1905.04975", "submitter": "Mirko Myllykoski", "authors": "Mirko Myllykoski and Carl Christian Kjelgaard Mikkelsen", "title": "Introduction to StarNEig -- A Task-based Library for Solving\n  Nonsymmetric Eigenvalue Problems", "comments": "10 pages, 4 figures (10 when counting sub-figures), 2 tex-files.\n  Submitted to PPAM 2019, 13th international conference on parallel processing\n  and applied mathematics, September 8-11, 2019. Proceedings will be published\n  after the conference by Springer in the LNCS series. Second author's first\n  name is \"Carl Christian\" and last name \"Kjelgaard Mikkelsen\"", "journal-ref": "LNCS 12043 (2020) 70-81", "doi": "10.1007/978-3-030-43229-4_7", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the StarNEig library for solving dense\nnon-symmetric (generalized) eigenvalue problems. The library is built on top of\nthe StarPU runtime system and targets both shared and distributed memory\nmachines. Some components of the library support GPUs. The library is currently\nin an early beta state and only real arithmetic is supported. Support for\ncomplex data types is planned for a future release. This paper is aimed for\npotential users of the library. We describe the design choices and capabilities\nof the library, and contrast them to existing software such as ScaLAPACK.\nStarNEig implements a ScaLAPACK compatibility layer that should make it easy\nfor a new user to transition to StarNEig. We demonstrate the performance of the\nlibrary with a small set of computational experiments.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 11:20:09 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Myllykoski", "Mirko", ""], ["Mikkelsen", "Carl Christian Kjelgaard", ""]]}, {"id": "1905.07622", "submitter": "Andrew Loeb", "authors": "Andrew Loeb, Christopher Earls", "title": "Analysis of heterogeneous computing approaches to simulating heat\n  transfer in heterogeneous material", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The simulation of heat flow through heterogeneous material is important for\nthe design of structural and electronic components. Classical analytical\nsolutions to the heat equation PDE are not known for many such domains, even\nthose having simple geometries. The finite element method can provide\napproximations to a weak form continuum solution, with increasing accuracy as\nthe number of degrees of freedom in the model increases. This comes at a cost\nof increased memory usage and computation time; even when taking advantage of\nsparse matrix techniques for the finite element system matrix. We summarize\nrecent approaches in solving problems in structural mechanics and steady state\nheat conduction which do not require the explicit assembly of any system\nmatrices, and adapt them to a method for solving the time-depended flow of\nheat. These approaches are highly parallelizable, and can be performed on\ngraphical processing units (GPUs). Furthermore, they lend themselves to the\nsimulation of heterogeneous material, with a minimum of added complexity. We\npresent the mathematical framework of assembly-free FEM approaches, through\nwhich we summarize the benefits of GPU computation. We discuss our\nimplementation using the OpenCL computing framework, and show how it is further\nadapted for use on multiple GPUs. We compare the performance of single and dual\nGPUs implementations of our method with previous GPU computing strategies from\nthe literature and a CPU sparse matrix approach. The utility of the novel\nmethod is demonstrated through the solution of a real-world coefficient inverse\nproblem that requires thousands of transient heat flow simulations, each of\nwhich involves solving a 1 million degree of freedom linear system over\nhundreds of time steps.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 18:35:41 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Loeb", "Andrew", ""], ["Earls", "Christopher", ""]]}, {"id": "1905.07987", "submitter": "Anne Reinarz", "authors": "Anne Reinarz, Dominic E. Charrier, Michael Bader, Luke Bovard, Michael\n  Dumbser, Kenneth Duru, Francesco Fambri, Alice-Agnes Gabriel, Jean-Matthieu\n  Gallard, Sven K\\\"oppel, Lukas Krenz, Leonhard Rannabauer, Luciano Rezzolla,\n  Philipp Samfass, Maurizio Tavelli, Tobias Weinzierl", "title": "ExaHyPE: An Engine for Parallel Dynamically Adaptive Simulations of Wave\n  Problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2020.107251", "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ExaHyPE (\"An Exascale Hyperbolic PDE Engine\") is a software engine for\nsolving systems of first-order hyperbolic partial differential equations\n(PDEs). Hyperbolic PDEs are typically derived from the conservation laws of\nphysics and are useful in a wide range of application areas. Applications\npowered by ExaHyPE can be run on a student's laptop, but are also able to\nexploit thousands of processor cores on state-of-the-art supercomputers. The\nengine is able to dynamically increase the accuracy of the simulation using\nadaptive mesh refinement where required. Due to the robustness and shock\ncapturing abilities of ExaHyPE's numerical methods, users of the engine can\nsimulate linear and non-linear hyperbolic PDEs with very high accuracy. Users\ncan tailor the engine to their particular PDE by specifying evolved quantities,\nfluxes, and source terms. A complete simulation code for a new hyperbolic PDE\ncan often be realised within a few hours - a task that, traditionally, can take\nweeks, months, often years for researchers starting from scratch. In this\npaper, we showcase ExaHyPE's workflow and capabilities through real-world\nscenarios from our two main application areas: seismology and astrophysics.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 10:53:27 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 13:16:40 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 11:43:55 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Reinarz", "Anne", ""], ["Charrier", "Dominic E.", ""], ["Bader", "Michael", ""], ["Bovard", "Luke", ""], ["Dumbser", "Michael", ""], ["Duru", "Kenneth", ""], ["Fambri", "Francesco", ""], ["Gabriel", "Alice-Agnes", ""], ["Gallard", "Jean-Matthieu", ""], ["K\u00f6ppel", "Sven", ""], ["Krenz", "Lukas", ""], ["Rannabauer", "Leonhard", ""], ["Rezzolla", "Luciano", ""], ["Samfass", "Philipp", ""], ["Tavelli", "Maurizio", ""], ["Weinzierl", "Tobias", ""]]}, {"id": "1905.08423", "submitter": "Fande Kong", "authors": "Fande Kong", "title": "Parallel memory-efficient all-at-once algorithms for the sparse matrix\n  triple products in multigrid methods", "comments": "14 pages, 10 figures. Submitted to The International Journal of High\n  Performance Computing Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilevel/multigrid methods is one of the most popular approaches for\nsolving a large sparse linear system of equations, typically, arising from the\ndiscretization of partial differential equations. One critical step in the\nmultilevel/multigrid methods is to form coarse matrices through a sequence of\nsparse matrix triple products. A commonly used approach for the triple products\nexplicitly involves two steps, and during each step a sparse matrix-matrix\nmultiplication is employed. This approach works well for many applications with\na good computational efficiency, but it has a high memory overhead since some\nauxiliary matrices need to be temporarily stored for accomplishing the\ncalculations. In this work, we propose two new algorithms that construct a\ncoarse matrix with taking one pass through the input matrices without involving\nany auxiliary matrices for saving memory. The new approaches are referred to as\n\"all-at-once\" and \"merged all-at-once\", and the traditional method is denoted\nas \"two-step\". The all-at-once and the merged all-at-once algorithms are\nimplemented based on hash tables in PETSc as part of this work with a careful\nconsideration on the performance in terms of the compute time and the memory\nusage. We numerically show that the proposed algorithms and their\nimplementations are perfectly scalable in both the compute time and the memory\nusage with up to 32,768 processor cores for a model problem with 27 billions of\nunknowns. The scalability is also demonstrated for a realistic neutron\ntransport problem with over 2 billion unknowns on a supercomputer with 10,000\nprocessor cores. Compared with the traditional two-step method, the all-at-once\nand the merged all-at-once algorithms consume much less memory for both the\nmodel problem and the realistic neutron transport problem meanwhile they are\nable to maintain the computational efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 03:20:38 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Kong", "Fande", ""]]}, {"id": "1905.09539", "submitter": "Daniel Kressner", "authors": "Minhong Chen, Daniel Kressner", "title": "Recursive blocked algorithms for linear systems with Kronecker product\n  structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive blocked algorithms have proven to be highly efficient at the\nnumerical solution of the Sylvester matrix equation and its generalizations. In\nthis work, we show that these algorithms extend in a seamless fashion to\nhigher-dimensional variants of generalized Sylvester matrix equations, as they\narise from the discretization of PDEs with separable coefficients or the\napproximation of certain models in macroeconomics. By combining recursions with\na mechanism for merging dimensions, an efficient algorithm is derived that\noutperforms existing approaches based on Sylvester solvers.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 08:54:45 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Chen", "Minhong", ""], ["Kressner", "Daniel", ""]]}, {"id": "1905.10206", "submitter": "Ivan Dolgakov", "authors": "Ivan Dolgakov and Dmitry Pavlov", "title": "Landau: language for dynamical systems with automatic differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most numerical solvers used to determine free variables of dynamical systems\nrely on first-order derivatives of the state of the system w.r.t. the free\nvariables. The number of the free variables can be fairly large. One of the\napproaches of obtaining those derivatives is the integration of the derivatives\nsimultaneously with the dynamical equations, which is best done with the\nautomatic differentiation technique. Even though there exist many automatic\ndifferentiation tools, none have been found to be scalable and usable for\npractical purposes of dynamic systems modeling. Landau is a Turing incomplete\nstatically typed domain-specific language aimed to fill this gap. The Turing\nincompleteness provides the ability of sophisticated source code analysis and,\nas a result, a highly optimized compiled code. Among other things, the language\nsyntax supports functions, compile-time ranged for loops, if/else branching\nconstructions, real variables and arrays, and the ability to manually discard\ncalculation where the automatic derivatives values are expected to be\nnegligibly small. In spite of reasonable restrictions, the language is rich\nenough to express and differentiate any cumbersome paper-equation with\npractically no effort.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 12:52:05 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Dolgakov", "Ivan", ""], ["Pavlov", "Dmitry", ""]]}, {"id": "1905.10574", "submitter": "Angelika Schwarz", "authors": "Angelika Schwarz and Carl Christian Kjelgaard Mikkelsen", "title": "Robust Task-Parallel Solution of the Triangular Sylvester Equation", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bartels-Stewart algorithm is a standard approach to solving the dense\nSylvester equation. It reduces the problem to the solution of the triangular\nSylvester equation. The triangular Sylvester equation is solved with a variant\nof backward substitution. Backward substitution is prone to overflow. Overflow\ncan be avoided by dynamic scaling of the solution matrix. An algorithm which\nprevents overflow is said to be robust. The standard library LAPACK contains\nthe robust scalar sequential solver dtrsyl. This paper derives a robust,\nlevel-3 BLAS-based task-parallel solver. By adding overflow protection, our\nrobust solver closes the gap between problems solvable by LAPACK and problems\nsolvable by existing non-robust task-parallel solvers. We demonstrate that our\nrobust solver achieves a similar performance as non-robust solvers.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 11:31:17 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Schwarz", "Angelika", ""], ["Mikkelsen", "Carl Christian Kjelgaard", ""]]}]