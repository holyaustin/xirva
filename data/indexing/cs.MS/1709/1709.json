[{"id": "1709.00302", "submitter": "Rafael Rodriguez-Sanchez", "authors": "Rafael Rodr\\'iguez-S\\'anchez, Sandra Catal\\'an, Jos\\'e R. Herrero,\n  Enrique S. Quintana-Ort\\'i, Andr\\'es E. Tom\\'as", "title": "Look-Ahead in the Two-Sided Reduction to Compact Band Forms for\n  Symmetric Eigenvalue Problems and the SVD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the reduction to compact band forms, via unitary similarity\ntransformations, for the solution of symmetric eigenvalue problems and the\ncomputation of the singular value decomposition (SVD). Concretely, in the first\ncase we revisit the reduction to symmetric band form while, for the second\ncase, we propose a similar alternative, which transforms the original matrix to\n(unsymmetric) band form, replacing the conventional reduction method that\nproduces a triangular--band output. In both cases, we describe algorithmic\nvariants of the standard Level-3 BLAS-based procedures, enhanced with\nlook-ahead, to overcome the performance bottleneck imposed by the panel\nfactorization. Furthermore, our solutions employ an algorithmic block size that\ndiffers from the target bandwidth, illustrating the important performance\nbenefits of this decision. Finally, we show that our alternative compact band\nform for the SVD is key to introduce an effective look-ahead strategy into the\ncorresponding reduction procedure.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 13:34:32 GMT"}, {"version": "v2", "created": "Mon, 6 Nov 2017 12:52:00 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Rodr\u00edguez-S\u00e1nchez", "Rafael", ""], ["Catal\u00e1n", "Sandra", ""], ["Herrero", "Jos\u00e9 R.", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""], ["Tom\u00e1s", "Andr\u00e9s E.", ""]]}, {"id": "1709.01054", "submitter": "Dylan Hutchison", "authors": "Dylan Hutchison", "title": "Distributed Triangle Counting in the Graphulo Matrix Math Library", "comments": "Honorable mention in the 2017 IEEE HPEC's Graph Challenge", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091041", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triangle counting is a key algorithm for large graph analysis. The Graphulo\nlibrary provides a framework for implementing graph algorithms on the Apache\nAccumulo distributed database. In this work we adapt two algorithms for\ncounting triangles, one that uses the adjacency matrix and another that also\nuses the incidence matrix, to the Graphulo library for server-side processing\ninside Accumulo. Cloud-based experiments show a similar performance profile for\nthese different approaches on the family of power law Graph500 graphs, for\nwhich data skew increasingly bottlenecks. These results motivate the design of\nskew-aware hybrid algorithms that we propose for future work.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 06:03:31 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 04:37:43 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Hutchison", "Dylan", ""]]}, {"id": "1709.01126", "submitter": "Ronald Caplan", "authors": "Ronald M. Caplan, Zoran Mikic and Jon A. Linker", "title": "From MPI to MPI+OpenACC: Conversion of a legacy FORTRAN PCG solver for\n  the spherical Laplace equation", "comments": "18 pages, 4 figures. Work presented at the 2017 NVIDIA GPU Technology\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real-world example of adding OpenACC to a legacy MPI FORTRAN Preconditioned\nConjugate Gradient code is described, and timing results for multi-node\nmulti-GPU runs are shown. The code is used to obtain three-dimensional\nspherical solutions to the Laplace equation. Its application is finding\npotential field solutions of the solar corona, a useful tool in space weather\nmodeling. We highlight key tips, strategies, and challenges faced when adding\nOpenACC. Performance results are shown for running the code with MPI-only on\nmultiple CPUs, and with MPI+OpenACC on multiple GPUs and CPUs.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 19:26:03 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 21:49:27 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Caplan", "Ronald M.", ""], ["Mikic", "Zoran", ""], ["Linker", "Jon A.", ""]]}, {"id": "1709.03636", "submitter": "Nicolas Sawaya", "authors": "E. Schuyler Fried, Nicolas P. D. Sawaya, Yudong Cao, Ian D. Kivlichan,\n  Jhonathan Romero, Al\\'an Aspuru-Guzik", "title": "qTorch: The Quantum Tensor Contraction Handler", "comments": "21 pages, 8 figures", "journal-ref": "PLoS ONE 13(12): e0208510. (2018)", "doi": "10.1371/journal.pone.0208510", "report-no": null, "categories": "quant-ph cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical simulation of quantum computation is necessary for studying the\nnumerical behavior of quantum algorithms, as there does not yet exist a large\nviable quantum computer on which to perform numerical tests. Tensor network\n(TN) contraction is an algorithmic method that can efficiently simulate some\nquantum circuits, often greatly reducing the computational cost over methods\nthat simulate the full Hilbert space. In this study we implement a tensor\nnetwork contraction program for simulating quantum circuits using multi-core\ncompute nodes. We show simulation results for the Max-Cut problem on 3- through\n7-regular graphs using the quantum approximate optimization algorithm (QAOA),\nsuccessfully simulating up to 100 qubits. We test two different methods for\ngenerating the ordering of tensor index contractions: one is based on the tree\ndecomposition of the line graph, while the other generates ordering using a\nstraight-forward stochastic scheme. Through studying instances of QAOA\ncircuits, we show the expected result that as the treewidth of the quantum\ncircuit's line graph decreases, TN contraction becomes significantly more\nefficient than simulating the whole Hilbert space. The results in this work\nsuggest that tensor contraction methods are superior only when simulating\nMax-Cut/QAOA with graphs of regularities approximately five and below. Insight\ninto this point of equal computational cost helps one determine which\nsimulation method will be more efficient for a given quantum circuit. The\nstochastic contraction method outperforms the line graph based method only when\nthe time to calculate a reasonable tree decomposition is prohibitively\nexpensive. Finally, we release our software package, qTorch (Quantum TensOR\nContraction Handler), intended for general quantum circuit simulation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 00:56:22 GMT"}, {"version": "v2", "created": "Sat, 22 Dec 2018 17:43:10 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Fried", "E. Schuyler", ""], ["Sawaya", "Nicolas P. D.", ""], ["Cao", "Yudong", ""], ["Kivlichan", "Ian D.", ""], ["Romero", "Jhonathan", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "1709.04423", "submitter": "Antun Balaz", "authors": "Luis E. Young-S., Paulsamy Muruganandam, Sadhan K. Adhikari, Vladimir\n  Loncar, Dusan Vudragovic, Antun Balaz", "title": "OpenMP GNU and Intel Fortran programs for solving the time-dependent\n  Gross-Pitaevskii equation", "comments": "5 pages, 2 figures; to download the programs, click 'Other formats'\n  and download the source", "journal-ref": "Comput. Phys. Commun. 220 (2017) 503", "doi": "10.1016/j.cpc.2017.07.013", "report-no": null, "categories": "physics.comp-ph cond-mat.quant-gas cs.MS nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Open Multi-Processing (OpenMP) version of Fortran 90 programs for\nsolving the Gross-Pitaevskii (GP) equation for a Bose-Einstein condensate in\none, two, and three spatial dimensions, optimized for use with GNU and Intel\ncompilers. We use the split-step Crank-Nicolson algorithm for imaginary- and\nreal-time propagation, which enables efficient calculation of stationary and\nnon-stationary solutions, respectively. The present OpenMP programs are\ndesigned for computers with multi-core processors and optimized for compiling\nwith both commercially-licensed Intel Fortran and popular free open-source GNU\nFortran compiler. The programs are easy to use and are elaborated with helpful\ncomments for the users. All input parameters are listed at the beginning of\neach program. Different output files provide physical quantities such as\nenergy, chemical potential, root-mean-square sizes, densities, etc. We also\npresent speedup test results for new versions of the programs.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 17:12:15 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Young-S.", "Luis E.", ""], ["Muruganandam", "Paulsamy", ""], ["Adhikari", "Sadhan K.", ""], ["Loncar", "Vladimir", ""], ["Vudragovic", "Dusan", ""], ["Balaz", "Antun", ""]]}, {"id": "1709.04494", "submitter": "Akshay Agrawal", "authors": "Akshay Agrawal, Robin Verschueren, Steven Diamond, Stephen Boyd", "title": "A Rewriting System for Convex Optimization Problems", "comments": "Updated Jan. 22, 2019 to fix typos. Page 1: \"is the one composed of\"\n  changed to \"contains\"; page 2: added a missing parenthesis to the code\n  example, changed `max` to `maximum`", "journal-ref": "J.Control.Decis. 5 (2018) 42-60", "doi": null, "report-no": null, "categories": "math.OC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a modular rewriting system for translating optimization problems\nwritten in a domain-specific language to forms compatible with low-level solver\ninterfaces. Translation is facilitated by reductions, which accept a category\nof problems and transform instances of that category to equivalent instances of\nanother category. Our system proceeds in two key phases: analysis, in which we\nattempt to find a suitable solver for a supplied problem, and canonicalization,\nin which we rewrite the problem in the selected solver's standard form. We\nimplement the described system in version 1.0 of CVXPY, a domain-specific\nlanguage for mathematical and especially convex optimization. By treating\nreductions as first-class objects, our method makes it easy to match problems\nto solvers well-suited for them and to support solvers with a wide variety of\nstandard forms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 18:31:24 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 01:04:59 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Agrawal", "Akshay", ""], ["Verschueren", "Robin", ""], ["Diamond", "Steven", ""], ["Boyd", "Stephen", ""]]}, {"id": "1709.06483", "submitter": "Lukas Einkemmer", "authors": "N. Auer and L. Einkemmer and P. Kandolf and A. Ostermann", "title": "Magnus integrators on multicore CPUs and GPUs", "comments": null, "journal-ref": "Computer Physics Communications, Volume 228, Pages 115-122, 2018", "doi": "10.1016/j.cpc.2018.02.019", "report-no": null, "categories": "physics.comp-ph cs.CE cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we consider numerical methods to solve the discrete\nSchr\\\"odinger equation with a time dependent Hamiltonian (motivated by problems\nencountered in the study of spin systems). We will consider both short-range\ninteractions, which lead to evolution equations involving sparse matrices, and\nlong-range interactions, which lead to dense matrices. Both of these settings\nshow very different computational characteristics. We use Magnus integrators\nfor time integration and employ a framework based on Leja interpolation to\ncompute the resulting action of the matrix exponential. We consider both\ntraditional Magnus integrators (which are extensively used for these types of\nproblems in the literature) as well as the recently developed commutator-free\nMagnus integrators and implement them on modern CPU and GPU (graphics\nprocessing unit) based systems.\n  We find that GPUs can yield a significant speed-up (up to a factor of $10$ in\nthe dense case) for these types of problems. In the sparse case GPUs are only\nadvantageous for large problem sizes and the achieved speed-ups are more\nmodest. In most cases the commutator-free variant is superior but especially on\nthe GPU this advantage is rather small. In fact, none of the advantage of\ncommutator-free methods on GPUs (and on multi-core CPUs) is due to the\nelimination of commutators. This has important consequences for the design of\nmore efficient numerical methods.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 15:13:04 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 13:19:03 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Auer", "N.", ""], ["Einkemmer", "L.", ""], ["Kandolf", "P.", ""], ["Ostermann", "A.", ""]]}, {"id": "1709.07229", "submitter": "Max Sagebaum", "authors": "Max Sagebaum, Tim Albring, Nicolas R. Gauger", "title": "High-Performance Derivative Computations using CoDiPack", "comments": "21 pages, 11 figures, 6 tables, CoDiPack:\n  https://github.com/SciCompKL/CoDiPack", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several AD tools available, which all implement different\nstrategies for the reverse mode of AD. The major strategies are primal value\ntaping (implemented e.g. by ADOL-c) and Jacobi taping (implemented e.g. by\nadept and dco/c++). Especially for Jacobi taping, recent advances by using\nexpression templates make this approach very attractive for large scale\nsoftware. The current implementations are either closed source or miss\nessential features and flexibility. Therefore, we present the new AD tool\nCoDiPack (Code Differentiation Package) in this paper. It is specifically\ndesigned for a minimal memory consumption and optimal runtime, such that it can\nbe used for the differentiation of large scale software. An essential part of\nthe design of CoDiPack is the modular layout and the recursive data structures,\nwhich do not only allow the efficient implementation of the Jacobi taping\napproach, but will also enable other approaches like the primal value taping or\nnew research ideas. We will also present the performance value of CoDiPack on a\ngeneric PDE example and on the SU2 code.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 09:28:36 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Sagebaum", "Max", ""], ["Albring", "Tim", ""], ["Gauger", "Nicolas R.", ""]]}, {"id": "1709.08018", "submitter": "Alessandro Rosa", "authors": "Alessandro Rosa", "title": "A new indexed approach to render the attractors of Kleinian groups", "comments": "9 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One widespread procedure to render the attractor of Kleinian groups,\npublished in the renown book \"Indra's Pearls\" and based upon a combinatorial\ntree model, wants huge memory resources to compute and store all the words\nrequired. We will present here a new faster and lighter version which drops the\noriginal words array and pulls out words from integer numbers.\n", "versions": [{"version": "v1", "created": "Sat, 23 Sep 2017 08:00:31 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Rosa", "Alessandro", ""]]}, {"id": "1709.09108", "submitter": "Lenore Mullin", "authors": "John L. Gustafson and Lenore M. Mullin", "title": "Tensors Come of Age: Why the AI Revolution will help HPC", "comments": "To be published in this years 30th anniversary edition of HPCwire", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses how the automation of tensor algorithms, based on A\nMathematics of Arrays and Psi Calculus, and a new way to represent numbers,\nUnum Arithmetic, enables mechanically provable, scalable, portable, and more\nnumerically accurate software.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 16:11:43 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Gustafson", "John L.", ""], ["Mullin", "Lenore M.", ""]]}, {"id": "1709.09713", "submitter": "Satya Pramod Jammy", "authors": "Satya P. Jammy, Christian T. Jacobs, David J. Lusher, Neil D. Sandham", "title": "Energy efficiency of finite difference algorithms on multicore CPUs,\n  GPUs, and Intel Xeon Phi processors", "comments": "Submitted to Computers and Fluids", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PF physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to hardware wall-time restrictions commonly seen in\nhigh-performance computing systems, it is likely that future systems will also\nbe constrained by energy budgets. In the present work, finite difference\nalgorithms of varying computational and memory intensity are evaluated with\nrespect to both energy efficiency and runtime on an Intel Ivy Bridge CPU node,\nan Intel Xeon Phi Knights Landing processor, and an NVIDIA Tesla K40c GPU. The\nconventional way of storing the discretised derivatives to global arrays for\nsolution advancement is found to be inefficient in terms of energy consumption\nand runtime. In contrast, a class of algorithms in which the discretised\nderivatives are evaluated on-the-fly or stored as thread-/process-local\nvariables (yielding high compute intensity) is optimal both with respect to\nenergy consumption and runtime. On all three hardware architectures considered,\na speed-up of ~2 and an energy saving of ~2 are observed for the high compute\nintensive algorithms compared to the memory intensive algorithm. The energy\nconsumption is found to be proportional to runtime, irrespective of the power\nconsumed and the GPU has an energy saving of ~5 compared to the same algorithm\non a CPU node.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 19:52:03 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Jammy", "Satya P.", ""], ["Jacobs", "Christian T.", ""], ["Lusher", "David J.", ""], ["Sandham", "Neil D.", ""]]}]