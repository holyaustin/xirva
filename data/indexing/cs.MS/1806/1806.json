[{"id": "1806.01656", "submitter": "Mofreh Zaghloul", "authors": "Mofreh R Zaghloul", "title": "Efficient Multi-Accuracy Computations of Complex Functions with Complex\n  Arguments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient multi-accuracy algorithm for the computations of a\nset of special functions of a complex argument, z=x+iy. These functions include\nthe complex probability function w(z), and closely related functions such as\nthe error function erf(z), complementary error function erfc(z), imaginary\nerror function erfi(z), scaled complementary error function, erfcx(z), the\nplasma dispersion function Z(z), Dawson s function Daw(z), and Fresnel\nintegrals S(z) and C(z). Computational results from the present algorithm are\ncompared with results from competitive algorithms and widely used software\npackages showing superior accuracy and efficiency of the present algorithm. In\nparticular, the present results highlight concerns about the accuracy of\nevaluating such special functions using commercial packages like Mathematica\nand free/open source packages like the MIT-C++ package.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 13:38:11 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 14:53:22 GMT"}, {"version": "v3", "created": "Tue, 22 Jan 2019 16:39:04 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Zaghloul", "Mofreh R", ""]]}, {"id": "1806.02136", "submitter": "Amir Shaikhha", "authors": "Amir Shaikhha, Andrew Fitzgibbon, Dimitrios Vytiniotis, Simon Peyton\n  Jones, Christoph Koch", "title": "Efficient Differentiable Programming in a Functional Array-Processing\n  Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG cs.PL cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a system for the automatic differentiation of a higher-order\nfunctional array-processing language. The core functional language underlying\nthis system simultaneously supports both source-to-source automatic\ndifferentiation and global optimizations such as loop transformations. Thanks\nto this feature, we demonstrate how for some real-world machine learning and\ncomputer vision benchmarks, the system outperforms the state-of-the-art\nautomatic differentiation tools.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 11:54:34 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Shaikhha", "Amir", ""], ["Fitzgibbon", "Andrew", ""], ["Vytiniotis", "Dimitrios", ""], ["Jones", "Simon Peyton", ""], ["Koch", "Christoph", ""]]}, {"id": "1806.02883", "submitter": "Hjalte Frellesvig Dr.", "authors": "Hjalte Frellesvig", "title": "Generalized Polylogarithms in Maple", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes generalized polylogarithms, multiple polylogarithms, and\nmultiple zeta values, along with their implementation in Maple 2018. This set\nof related functions is of interest in high energy physics as well as in number\ntheory. Algorithms for the analytical manipulation and numerical evaluation of\nthese functions are described, along with the way these features are\nimplemented in Maple.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 19:42:58 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Frellesvig", "Hjalte", ""]]}, {"id": "1806.04941", "submitter": "Luca Franceschi", "authors": "Luca Franceschi, Riccardo Grazzi, Massimiliano Pontil, Saverio Salzo,\n  Paolo Frasconi", "title": "Far-HO: A Bilevel Programming Package for Hyperparameter Optimization\n  and Meta-Learning", "comments": "This submission is a reduced version of (Franceschi et al.,\n  arXiv:1806.04910) which has been accepted at the main ICML 2018 conference.\n  In this paper we illustrate the software framework, material that could not\n  be included in the conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In (Franceschi et al., 2018) we proposed a unified mathematical framework,\ngrounded on bilevel programming, that encompasses gradient-based hyperparameter\noptimization and meta-learning. We formulated an approximate version of the\nproblem where the inner objective is solved iteratively, and gave sufficient\nconditions ensuring convergence to the exact problem. In this work we show how\nto optimize learning rates, automatically weight the loss of single examples\nand learn hyper-representations with Far-HO, a software package based on the\npopular deep learning framework TensorFlow that allows to seamlessly tackle\nboth HO and ML problems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 10:46:32 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Franceschi", "Luca", ""], ["Grazzi", "Riccardo", ""], ["Pontil", "Massimiliano", ""], ["Salzo", "Saverio", ""], ["Frasconi", "Paolo", ""]]}, {"id": "1806.05713", "submitter": "Hiroshi Watanabe", "authors": "Hiroshi Watanabe and Koh M. Nakagawa", "title": "SIMD Vectorization for the Lennard-Jones Potential with AVX2 and AVX-512\n  instructions", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": "10.1016/j.cpc.2018.10.028", "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes the SIMD vectorization of the force calculation of the\nLennard-Jones potential with Intel AVX2 and AVX-512 instruction sets. Since the\nforce-calculation kernel of the molecular dynamics method involves indirect\naccess to memory, the data layout is one of the most important factors in\nvectorization. We find that the Array of Structures (AoS) with padding exhibits\nbetter performance than Structure of Arrays (SoA) with appropriate\nvectorization and optimizations. In particular, AoS with 512-bit width exhibits\nthe best performance among the architectures. While the difference in\nperformance between AoS and SoA is significant for the vectorization with AVX2,\nthat with AVX-512 is minor. The effect of other optimization techniques, such\nas software pipelining together with vectorization, is also discussed. We\npresent results for benchmarks on three CPU architectures: Intel Haswell (HSW),\nKnights Landing (KNL), and Skylake (SKL). The performance gains by\nvectorization are about 42\\% on HSW compared with the code optimized without\nvectorization. On KNL, the hand-vectorized codes exhibit 34\\% better\nperformance than the codes vectorized automatically by the Intel compiler. On\nSKL, the code vectorized with AVX2 exhibits slightly better performance than\nthat with vectorized AVX-512.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 08:53:58 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 09:53:05 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Watanabe", "Hiroshi", ""], ["Nakagawa", "Koh M.", ""]]}, {"id": "1806.06725", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson (LFANT)", "title": "Numerical Evaluation of Elliptic Functions, Elliptic Integrals and\n  Modular Forms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe algorithms to compute elliptic functions and their relatives\n(Jacobi theta functions, modular forms, elliptic integrals, and the\narithmetic-geometric mean) numerically to arbitrary precision with rigorous\nerror bounds for arbitrary complex variables. Implementations in ball\narithmetic are available in the open source Arb library. We discuss the\nalgorithms from a concrete implementation point of view, with focus on\nperformance at tens to thousands of digits of precision.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 14:19:18 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Johansson", "Fredrik", "", "LFANT"]]}, {"id": "1806.07060", "submitter": "Flavio Vella", "authors": "Marco Cianfriglia, Flavio Vella, Cedric Nugteren, Anton Lokhmotov,\n  Grigori Fursin", "title": "A model-driven approach for a new generation of adaptive libraries", "comments": "New detailed analysis will be provided", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient high-performance libraries often expose multiple tunable parameters\nto provide highly optimized routines. These can range from simple loop unroll\nfactors or vector sizes all the way to algorithmic changes, given that some\nimplementations can be more suitable for certain devices by exploiting hardware\ncharacteristics such as local memories and vector units. Traditionally, such\nparameters and algorithmic choices are tuned and then hard-coded for a specific\narchitecture and for certain characteristics of the inputs. However, emerging\napplications are often data-driven, thus traditional approaches are not\neffective across the wide range of inputs and architectures used in practice.\nIn this paper, we present a new adaptive framework for data-driven applications\nwhich uses a predictive model to select the optimal algorithmic parameters by\ntraining with synthetic and real datasets. We demonstrate the effectiveness of\na BLAS library and specifically on its matrix multiplication routine. We\npresent experimental results for two GPU architectures and show significant\nperformance gains of up to 3x (on a high-end NVIDIA Pascal GPU) and 2.5x (on an\nembedded ARM Mali GPU) when compared to a traditionally optimized library.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 06:17:38 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Cianfriglia", "Marco", ""], ["Vella", "Flavio", ""], ["Nugteren", "Cedric", ""], ["Lokhmotov", "Anton", ""], ["Fursin", "Grigori", ""]]}, {"id": "1806.07247", "submitter": "Canyi Lu", "authors": "Canyi Lu", "title": "Tensor-Tensor Product Toolbox", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.03728.\n  Carnegie Mellon University", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tensor-tensor product (t-product) [M. E. Kilmer and C. D. Martin, 2011]\nis a natural generalization of matrix multiplication. Based on t-product, many\noperations on matrix can be extended to tensor cases, including tensor SVD,\ntensor spectral norm, tensor nuclear norm [C. Lu, et al., 2018] and many\nothers. The linear algebraic structure of tensors are similar to the matrix\ncases. We develop a Matlab toolbox to implement several basic operations on\ntensors based on t-product. The toolbox is available at\nhttps://github.com/canyilu/tproduct.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 08:14:42 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 03:23:18 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Lu", "Canyi", ""]]}, {"id": "1806.07984", "submitter": "Tobias Weinzierl", "authors": "Dominic E. Charrier and Benjamin Hazelwood and Tobias Weinzierl", "title": "Enclave Tasking for Discontinuous Galerkin Methods on Dynamically\n  Adaptive Meshes", "comments": null, "journal-ref": null, "doi": "10.1137/19M1276194", "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-order Discontinuous Galerkin (DG) methods promise to be an excellent\ndiscretisation paradigm for partial differential equation solvers by combining\nhigh arithmetic intensity with localised data access. They also facilitate\ndynamic adaptivity without the need for conformal meshes. A parallel evaluation\nof DG's weak formulation within a mesh traversal is non-trivial, as dependency\ngraphs over dynamically adaptive meshes change, as causal constraints along\nresolution transitions have to be preserved, and as data sends along MPI domain\nboundaries have to be triggered in the correct order. We propose to process\nmesh elements subject to constraints with high priority or, where needed,\nserially throughout a traversal. The remaining cells form enclaves and are\nspawned into a task system. This introduces concurrency, mixes memory-intensive\nDG integrations with compute-bound Riemann solves, and overlaps computation and\ncommunication. We discuss implications on MPI and show that MPI parallelisation\nimproves by a factor of three through enclave tasking, while we obtain an\nadditional factor of two from shared memory if grids are dynamically adaptive.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 14:09:42 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 04:40:26 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 08:17:01 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Charrier", "Dominic E.", ""], ["Hazelwood", "Benjamin", ""], ["Weinzierl", "Tobias", ""]]}, {"id": "1806.07985", "submitter": "Grey Ballard", "authors": "Grey Ballard and Koby Hayashi and Ramakrishnan Kannan", "title": "Parallel Nonnegative CP Decomposition of Dense Tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CP tensor decomposition is a low-rank approximation of a tensor. We\npresent a distributed-memory parallel algorithm and implementation of an\nalternating optimization method for computing a CP decomposition of dense\ntensor data that can enforce nonnegativity of the computed low-rank factors.\nThe principal task is to parallelize the matricized-tensor times Khatri-Rao\nproduct (MTTKRP) bottleneck subcomputation. The algorithm is computation\nefficient, using dimension trees to avoid redundant computation across MTTKRPs\nwithin the alternating method. Our approach is also communication efficient,\nusing a data distribution and parallel algorithm across a multidimensional\nprocessor grid that can be tuned to minimize communication. We benchmark our\nsoftware on synthetic as well as hyperspectral image and neuroscience dynamic\nfunctional connectivity data, demonstrating that our algorithm scales well to\n100s of nodes (up to 4096 cores) and is faster and more general than the\ncurrently available parallel software.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 13:52:12 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Ballard", "Grey", ""], ["Hayashi", "Koby", ""], ["Kannan", "Ramakrishnan", ""]]}, {"id": "1806.08299", "submitter": "Nicholas Sim", "authors": "Nicholas Sim", "title": "Optimising finite-difference methods for PDEs through parameterised\n  time-tiling in Devito", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-difference methods are widely used in solving partial differential\nequations. In a large problem set, approximations can take days or weeks to\nevaluate, yet the bulk of computation may occur within a single loop nest. The\nmodelling process for researchers is not straightforward either, requiring\nmodels with differential equations to be translated into stencil kernels, then\noptimised separately. One tool that seeks to speed up and eliminate mistakes\nfrom this tedious procedure is Devito, used to efficiently employ\nfinite-difference methods.\n  In this work, we implement time-tiling, a loop nest optimisation, in Devito\nyielding a decrease in runtime of up to 45%, and at least 20% across stencils\nfrom the acoustic wave equation family, widely used in Devito's target domain\nof seismic imaging. We present an estimator for arithmetic intensity under\ntime-tiling and a model to predict runtime improvements in stencil\ncomputations. We also consider generalisation of time-tiling to imperfect loop\nnests, a less widely studied problem.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 15:50:20 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Sim", "Nicholas", ""]]}, {"id": "1806.09545", "submitter": "Oliver Sander", "authors": "Christian Engwer, Carsten Gr\\\"aser, Steffen M\\\"uthing, Oliver Sander", "title": "Function space bases in the dune-functions module", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dune-functions Dune module provides interfaces for functions and function\nspace bases. It forms one abstraction level above grids, shape functions, and\nlinear algebra, and provides infrastructure for full discretization frameworks\nlike dune-pdelab and dune-fem. This document describes the function space bases\nprovided by dune-functions. These are based on an abstract description of bases\nfor product spaces as trees of simpler bases. From this description, many\ndifferent numberings of degrees of freedom by multi-indices can be derived in a\nnatural way. We describe the abstract concepts, document the programmer\ninterface, and give a complete example program that solves the stationary\nStokes equation using Taylor-Hood elements.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 15:58:53 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Engwer", "Christian", ""], ["Gr\u00e4ser", "Carsten", ""], ["M\u00fcthing", "Steffen", ""], ["Sander", "Oliver", ""]]}, {"id": "1806.09997", "submitter": "Pierre Denis Mr.", "authors": "Pierre Denis", "title": "Probabilistic Inference Using Generators - The Statues Algorithm", "comments": "50 pages, incl. 3 appendices (v2: typos and minor corrections, added\n  appendix C with proof of correctness)", "journal-ref": null, "doi": "10.1007/978-3-030-52246-9_10", "report-no": null, "categories": "cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here a new probabilistic inference algorithm that gives exact\nresults in the domain of discrete probability distributions. This algorithm,\nnamed the Statues algorithm, calculates the marginal probability distribution\non probabilistic models defined as direct acyclic graphs. These models are made\nup of well-defined primitives that allow to express, in particular, joint\nprobability distributions, Bayesian networks, discrete Markov chains,\nconditioning and probabilistic arithmetic. The Statues algorithm relies on a\nvariable binding mechanism based on the generator construct, a special form of\ncoroutine; being related to the enumeration algorithm, this new algorithm\nbrings important improvements in terms of efficiency, which makes it valuable\nin regard to other exact marginalization algorithms. After introduction of\nseveral definitions, primitives and compositional rules, we present in details\nthe Statues algorithm. Then, we briefly discuss the interest of this algorithm\ncompared to others and we present possible extensions. Finally, we introduce\nLea and MicroLea, two Python libraries implementing the Statues algorithm,\nalong with several use cases. A proof of the correctness of the algorithm is\nprovided in appendix.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jun 2018 23:00:29 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 07:19:02 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Denis", "Pierre", ""]]}, {"id": "1806.10164", "submitter": "R\\'emi Imbach", "authors": "R\\'emi Imbach, Marc Pouget and Chee Yap", "title": "Clustering Complex Zeros of Triangular Systems of Polynomials", "comments": "Research report V6: description of the main algorithm updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives the first algorithm for finding a set of natural\n$\\epsilon$-clusters of complex zeros of a triangular system of polynomials\nwithin a given polybox in $\\mathbb{C}^n$, for any given $\\epsilon>0$. Our\nalgorithm is based on a recent near-optimal algorithm of Becker et al (2016)\nfor clustering the complex roots of a univariate polynomial where the\ncoefficients are represented by number oracles.\n  Our algorithm is numeric, certified and based on subdivision. We implemented\nit and compared it with two well-known homotopy solvers on various triangular\nsystems. Our solver always gives correct answers, is often faster than the\nhomotopy solver that often gives correct answers, and sometimes faster than the\none that gives sometimes correct results.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 18:40:12 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 20:40:18 GMT"}, {"version": "v3", "created": "Mon, 25 Mar 2019 21:11:23 GMT"}, {"version": "v4", "created": "Wed, 27 Mar 2019 12:39:26 GMT"}, {"version": "v5", "created": "Mon, 8 Apr 2019 13:34:32 GMT"}, {"version": "v6", "created": "Thu, 26 Sep 2019 22:33:28 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Imbach", "R\u00e9mi", ""], ["Pouget", "Marc", ""], ["Yap", "Chee", ""]]}, {"id": "1806.10469", "submitter": "Milan Batista", "authors": "Milan Batista", "title": "Elfun18 A collection of Matlab functions for the computation of\n  Elliptical Integrals and Jacobian elliptic functions of real arguments", "comments": null, "journal-ref": "SoftwareX, Volume 10, 2019", "doi": "10.1016/j.softx.2019.100245", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the article we outline the set of Matlab functions that enable the\ncomputation of elliptic Integrals and Jacobian elliptic functions for real\narguments. Correctness, robustness, efficiency and accuracy of the functions\nare discussed in some details. An example from the elasticity theory\nillustrates use of the collection.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 10:07:22 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 15:56:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Batista", "Milan", ""]]}, {"id": "1806.10584", "submitter": "R\\'emi Imbach", "authors": "R\\'emi Imbach, Victor Y. Pan and Chee Yap", "title": "Implementation of a Near-Optimal Complex Root Clustering Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Ccluster, a software for computing natural $\\epsilon$-clusters of\ncomplex roots in a given box of the complex plane. This algorithm from Becker\net al.~(2016) is near-optimal when applied to the benchmark problem of\nisolating all complex roots of an integer polynomial. It is one of the first\nimplementations of a near-optimal algorithm for complex roots. We describe some\nlow level techniques for speeding up the algorithm. Its performance is compared\nwith the well-known MPSolve library and Maple.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 17:31:48 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 20:58:12 GMT"}, {"version": "v3", "created": "Wed, 1 Aug 2018 18:50:36 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Imbach", "R\u00e9mi", ""], ["Pan", "Victor Y.", ""], ["Yap", "Chee", ""]]}, {"id": "1806.11558", "submitter": "Peter Zaspel", "authors": "Helmut Harbrecht, Peter Zaspel", "title": "A scalable H-matrix approach for the solution of boundary integral\n  equations on multi-GPU clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the solution of boundary integral equations by\nmeans of a scalable hierarchical matrix approach on clusters equipped with\ngraphics hardware, i.e. graphics processing units (GPUs). To this end, we\nextend our existing single-GPU hierarchical matrix library hmglib such that it\nis able to scale on many GPUs and such that it can be coupled to arbitrary\napplication codes. Using a model GPU implementation of a boundary element\nmethod (BEM) solver, we are able to achieve more than 67 percent relative\nparallel speed-up going from 128 to 1024 GPUs for a model geometry test case\nwith 1.5 million unknowns and a real-world geometry test case with almost 1.2\nmillion unknowns. On 1024 GPUs of the cluster Titan, it takes less than 6\nminutes to solve the 1.5 million unknowns problem, with 5.7 minutes for the\nsetup phase and 20 seconds for the iterative solver. To the best of the\nauthors' knowledge, we here discuss the first fully GPU-based\ndistributed-memory parallel hierarchical matrix Open Source library using the\ntraditional H-matrix format and adaptive cross approximation with an\napplication to BEM problems.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 07:39:20 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Harbrecht", "Helmut", ""], ["Zaspel", "Peter", ""]]}]