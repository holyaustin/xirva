[{"id": "1803.01592", "submitter": "Matthew England Dr", "authors": "James H. Davenport, Matthew England, Roberto Sebastiani, Patrick\n  Trentin", "title": "OpenMath and SMT-LIB", "comments": "Presented in the OpenMath 2017 Workshop, at CICM 2017, Edinburgh, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenMath and SMT-LIB are languages with very different origins, but both\n\"represent mathematics\". We describe SMT-LIB for the OpenMath community and\nconsider adaptations for both languages to support the growing SC-Square\ninitiative.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 10:33:50 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Davenport", "James H.", ""], ["England", "Matthew", ""], ["Sebastiani", "Roberto", ""], ["Trentin", "Patrick", ""]]}, {"id": "1803.02156", "submitter": "Georg Hager", "authors": "Moritz Kreutzer, Georg Hager, Dominik Ernst, Holger Fehske, Alan R.\n  Bishop, Gerhard Wellein", "title": "Chebyshev Filter Diagonalization on Modern Manycore Processors and\n  GPGPUs", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": "10.1007/978-3-319-92040-5_17", "report-no": null, "categories": "cs.MS cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chebyshev filter diagonalization is well established in quantum chemistry and\nquantum physics to compute bulks of eigenvalues of large sparse matrices.\nChoosing a block vector implementation, we investigate optimization\nopportunities on the new class of high-performance compute devices featuring\nboth high-bandwidth and low-bandwidth memory. We focus on the transparent\naccess to the full address space supported by both architectures under\nconsideration: Intel Xeon Phi \"Knights Landing\" and Nvidia \"Pascal.\"\n  We propose two optimizations: (1) Subspace blocking is applied for improved\nperformance and data access efficiency. We also show that it allows\ntransparently handling problems much larger than the high-bandwidth memory\nwithout significant performance penalties. (2) Pipelining of communication and\ncomputation phases of successive subspaces is implemented to hide communication\ncosts without extra memory traffic.\n  As an application scenario we use filter diagonalization studies on\ntopological insulator materials. Performance numbers on up to 512 nodes of the\nOakForest-PACS and Piz Daint supercomputers are presented, achieving beyond 100\nTflop/s for computing 100 inner eigenvalues of sparse matrices of dimension one\nbillion.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 13:13:23 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Kreutzer", "Moritz", ""], ["Hager", "Georg", ""], ["Ernst", "Dominik", ""], ["Fehske", "Holger", ""], ["Bishop", "Alan R.", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1803.02481", "submitter": "Luke Olson", "authors": "Andrew Reisner, Luke N. Olson, J. David Moulton", "title": "Scaling Structured Multigrid to 500K+ Cores through Coarse-Grid\n  Redistribution", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": "Los Alamos Report LA-UR-17-22886", "categories": "cs.MS cs.NA cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient solution of sparse, linear systems resulting from the\ndiscretization of partial differential equations is crucial to the performance\nof many physics-based simulations. The algorithmic optimality of multilevel\napproaches for common discretizations makes them a good candidate for an\nefficient parallel solver. Yet, modern architectures for high-performance\ncomputing systems continue to challenge the parallel scalability of multilevel\nsolvers. While algebraic multigrid methods are robust for solving a variety of\nproblems, the increasing importance of data locality and cost of data movement\nin modern architectures motivates the need to carefully exploit structure in\nthe problem.\n  Robust logically structured variational multigrid methods, such as Black Box\nMultigrid (BoxMG), maintain structure throughout the multigrid hierarchy. This\navoids indirection and increased coarse-grid communication costs typical in\nparallel algebraic multigrid. Nevertheless, the parallel scalability of\nstructured multigrid is challenged by coarse-grid problems where the overhead\nin communication dominates computation. In this paper, an algorithm is\nintroduced for redistributing coarse-grid problems through incremental\nagglomeration. Guided by a predictive performance model, this algorithm\nprovides robust redistribution decisions for structured multilevel solvers.\n  A two-dimensional diffusion problem is used to demonstrate the significant\ngain in performance of this algorithm over the previous approach that used\nagglomeration to one processor. In addition, the parallel scalability of this\napproach is demonstrated on two large-scale computing systems, with solves on\nup to 500K+ cores.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 23:57:38 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Reisner", "Andrew", ""], ["Olson", "Luke N.", ""], ["Moulton", "J. David", ""]]}, {"id": "1803.04154", "submitter": "Max Sagebaum", "authors": "Max Sagebaum and Nicolas R. Gauger", "title": "Algorithmic Differentiation for Domain Specific Languages", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic Differentiation (AD) can be used to automate the generation of\nderivatives in arbitrary software projects. This will generate maintainable\nderivatives, that are always consistent with the computation of the software.\nIf a domain specific language (DSL) is used in a software the state of the art\napproach is to differentiate the DSL library with the same AD tool. The\ndrawback of this solution is the reduced performance since the compiler is no\nlonger able to optimize the e.g. SIMD operations. The new approach in this\npaper integrates the types and operations of the DSL into the AD tool. It will\nbe an operator overloading tool that is generated from an abstract definition\nof a DSL. This approach enables the compiler to optimize again e.g. for SIMD\noperation since all calculations are still performed with the original data\ntypes. This will also reduce the required memory for AD since the statements\ninside the DLS implementation are no longer seen by the AD tool. The\nimplementation is presented in the paper and first results for the performance\nof the solution are presented.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 08:39:30 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Sagebaum", "Max", ""], ["Gauger", "Nicolas R.", ""]]}, {"id": "1803.05320", "submitter": "Farhad Merchant", "authors": "Farhad Merchant, Tarun Vatwani, Anupam Chattopadhyay, Soumyendu Raha,\n  S K Nandy, Ranjani Narayan, and Rainer Leupers", "title": "Efficient Realization of Givens Rotation through Algorithm-Architecture\n  Co-design for Acceleration of QR Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present efficient realization of Generalized Givens Rotation (GGR) based\nQR factorization that achieves 3-100x better performance in terms of\nGflops/watt over state-of-the-art realizations on multicore, and General\nPurpose Graphics Processing Units (GPGPUs). GGR is an improvement over\nclassical Givens Rotation (GR) operation that can annihilate multiple elements\nof rows and columns of an input matrix simultaneously. GGR takes 33% lesser\nmultiplications compared to GR. For custom implementation of GGR, we identify\nmacro operations in GGR and realize them on a Reconfigurable Data-path (RDP)\ntightly coupled to pipeline of a Processing Element (PE). In PE, GGR attains\nspeed-up of 1.1x over Modified Householder Transform (MHT) presented in the\nliterature. For parallel realization of GGR, we use REDEFINE, a scalable\nmassively parallel Coarse-grained Reconfigurable Architecture, and show that\nthe speed-up attained is commensurate with the hardware resources in REDEFINE.\nGGR also outperforms General Matrix Multiplication (gemm) by 10% in-terms of\nGflops/watt which is counter-intuitive.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 14:41:52 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 08:41:53 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Merchant", "Farhad", ""], ["Vatwani", "Tarun", ""], ["Chattopadhyay", "Anupam", ""], ["Raha", "Soumyendu", ""], ["Nandy", "S K", ""], ["Narayan", "Ranjani", ""], ["Leupers", "Rainer", ""]]}, {"id": "1803.06226", "submitter": "Markus Quade", "authors": "Markus Quade and Julien Gout and Markus Abel", "title": "Glyph: Symbolic Regression Tools", "comments": "Submitted to JOSR. arXiv admin note: text overlap with\n  arXiv:1612.05276", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NE math.OC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Glyph - a Python package for genetic programming based symbolic\nregression. Glyph is designed for usage let by numerical simulations let by\nreal world experiments. For experimentalists, glyph-remote provides a\nseparation of tasks: a ZeroMQ interface splits the genetic programming\noptimization task from the evaluation of an experimental (or numerical) run.\nGlyph can be accessed at http://github.com/ambrosys/glyph . Domain experts are\nbe able to employ symbolic regression in their experiments with ease, even if\nthey are not expert programmers. The reuse potential is kept high by a generic\ninterface design. Glyph is available on PyPI and Github.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:57:49 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 10:06:54 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Quade", "Markus", ""], ["Gout", "Julien", ""], ["Abel", "Markus", ""]]}, {"id": "1803.06934", "submitter": "Edwin Tye", "authors": "Edwin Tye, Tom Finnie, Ian Hall, Steve Leach", "title": "PyGOM - A Python Package for Simplifying Modelling with Systems of\n  Ordinary Differential Equations", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary Differential Equations (ODE) are used throughout science where the\ncapture of rates of change in states is sought. While both pieces of commercial\nand open software exist to study such systems, their efficient and accurate\nusage frequently requires deep understanding of mathematics and programming.\nThe package we present here, PyGOM, seeks to remove these obstacles for models\nbased on ODE systems. We provide a simple interface for the construction of\nsuch systems backed by a comprehensive and easy to use tool--box. This\ntool--box implements functions to easily perform common operations for ODE\nsystems such as solving, parameter estimation, and stochastic simulation. The\npackage source is freely available and organized in a way that permits easy\nextension. With both the algebraic and numeric calculations performed\nautomatically (but still accessible), the end user is freed to focus on model\ndevelopment.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:02:44 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Tye", "Edwin", ""], ["Finnie", "Tom", ""], ["Hall", "Ian", ""], ["Leach", "Steve", ""]]}, {"id": "1803.09948", "submitter": "Mustafa Abduljabbar", "authors": "Mustafa Abduljabbar, Mohammed Al Farhan, Noha Al-Harthi, Rui Chen, Rio\n  Yokota, Hakan Bagci, and David Keyes", "title": "Extreme Scale FMM-Accelerated Boundary Integral Equation Solver for Wave\n  Scattering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithmic and architecture-oriented optimizations are essential for\nachieving performance worthy of anticipated energy-austere exascale systems. In\nthis paper, we present an extreme scale FMM-accelerated boundary integral\nequation solver for wave scattering, which uses FMM as a matrix-vector\nmultiplication inside the GMRES iterative method. Our FMM Helmholtz kernels\ntreat nontrivial singular and near-field integration points. We implement\nhighly optimized kernels for both shared and distributed memory, targeting\nemerging Intel extreme performance HPC architectures. We extract the potential\nthread- and data-level parallelism of the key Helmholtz kernels of FMM. Our\napplication code is well optimized to exploit the AVX-512 SIMD units of Intel\nSkylake and Knights Landing architectures. We provide different performance\nmodels for tuning the task-based tree traversal implementation of FMM, and\ndevelop optimal architecture-specific and algorithm aware partitioning, load\nbalancing, and communication reducing mechanisms to scale up to 6,144 compute\nnodes of a Cray XC40 with 196,608 hardware cores. With shared memory\noptimizations, we achieve roughly 77% of peak single precision floating point\nperformance of a 56-core Skylake processor, and on average 60% of peak single\nprecision floating point performance of a 72-core KNL. These numbers represent\nnearly 5.4x and 10x speedup on Skylake and KNL, respectively, compared to the\nbaseline scalar code. With distributed memory optimizations, on the other hand,\nwe report near-optimal efficiency in the weak scalability study with respect to\nboth the logarithmic communication complexity as well as the theoretical\nscaling complexity of FMM. In addition, we exhibit up to 85% efficiency in\nstrong scaling. We compute in excess of 2 billion DoF on the full-scale of the\nCray XC40 supercomputer.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 08:12:13 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Abduljabbar", "Mustafa", ""], ["Farhan", "Mohammed Al", ""], ["Al-Harthi", "Noha", ""], ["Chen", "Rui", ""], ["Yokota", "Rio", ""], ["Bagci", "Hakan", ""], ["Keyes", "David", ""]]}]