[{"id": "1406.0089", "submitter": "Tobin Isaac", "authors": "Tobin Isaac, Carsten Burstedde, Lucas C. Wilcox, Omar Ghattas", "title": "Recursive Algorithms for Distributed Forests of Octrees", "comments": "35 pages, 15 figures, 3 tables", "journal-ref": null, "doi": "10.1137/140970963", "report-no": null, "categories": "cs.DC cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The forest-of-octrees approach to parallel adaptive mesh refinement and\ncoarsening (AMR) has recently been demonstrated in the context of a number of\nlarge-scale PDE-based applications. Although linear octrees, which store only\nleaf octants, have an underlying tree structure by definition, it is not often\nexploited in previously published mesh-related algorithms. This is because the\nbranches are not explicitly stored, and because the topological relationships\nin meshes, such as the adjacency between cells, introduce dependencies that do\nnot respect the octree hierarchy. In this work we combine hierarchical and\ntopological relationships between octree branches to design efficient recursive\nalgorithms.\n  We present three important algorithms with recursive implementations. The\nfirst is a parallel search for leaves matching any of a set of multiple search\ncriteria. The second is a ghost layer construction algorithm that handles\narbitrarily refined octrees that are not covered by previous algorithms, which\nrequire a 2:1 condition between neighboring leaves. The third is a universal\nmesh topology iterator. This iterator visits every cell in a domain partition,\nas well as every interface (face, edge and corner) between these cells. The\niterator calculates the local topological information for every interface that\nit visits, taking into account the nonconforming interfaces that increase the\ncomplexity of describing the local topology. To demonstrate the utility of the\ntopology iterator, we use it to compute the numbering and encoding of\nhigher-order $C^0$ nodal basis functions.\n  We analyze the complexity of the new recursive algorithms theoretically, and\nassess their performance, both in terms of single-processor efficiency and in\nterms of parallel scalability, demonstrating good weak and strong scaling up to\n458k cores of the JUQUEEN supercomputer.\n", "versions": [{"version": "v1", "created": "Sat, 31 May 2014 16:02:54 GMT"}, {"version": "v2", "created": "Tue, 18 Nov 2014 21:00:39 GMT"}, {"version": "v3", "created": "Thu, 20 Aug 2015 03:26:29 GMT"}], "update_date": "2015-11-05", "authors_parsed": [["Isaac", "Tobin", ""], ["Burstedde", "Carsten", ""], ["Wilcox", "Lucas C.", ""], ["Ghattas", "Omar", ""]]}, {"id": "1406.0292", "submitter": "Lars Hupel", "authors": "Lars Hupel", "title": "Interactive Simplifier Tracing and Debugging in Isabelle", "comments": "Conferences on Intelligent Computer Mathematics, 2014", "journal-ref": null, "doi": "10.1007/978-3-319-08434-3_24", "report-no": null, "categories": "cs.MS cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Isabelle proof assistant comes equipped with a very powerful tactic for\nterm simplification. While tremendously useful, the results of simplifying a\nterm do not always match the user's expectation: sometimes, the resulting term\nis not in the form the user expected, or the simplifier fails to apply a rule.\nWe describe a new, interactive tracing facility which offers insight into the\nhierarchical structure of the simplification with user-defined filtering,\nmemoization and search. The new simplifier trace is integrated into the\nIsabelle/jEdit Prover IDE.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 08:44:33 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Hupel", "Lars", ""]]}, {"id": "1406.1066", "submitter": "Stefan Engblom", "authors": "Stefan Engblom and Dimitar Lukarski", "title": "Fast Matlab compatible sparse assembly on multicore computers", "comments": null, "journal-ref": "Parallel Comput. 56:1--17 (2016)", "doi": "10.1016/j.parco.2016.04.001", "report-no": null, "categories": "cs.DC cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and implement in this paper a fast sparse assembly algorithm, the\nfundamental operation which creates a compressed matrix from raw index data.\nSince it is often a quite demanding and sometimes critical operation, it is of\ninterest to design a highly efficient implementation. We show how to do this,\nand moreover, we show how our implementation can be parallelized to utilize the\npower of modern multicore computers. Our freely available code, fully Matlab\ncompatible, achieves about a factor of 5 times in speedup on a typical 6-core\nmachine and 10 times on a dual-socket 16 core machine compared to the built-in\nserial implementation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 15:01:23 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2015 09:54:33 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2015 10:58:34 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Engblom", "Stefan", ""], ["Lukarski", "Dimitar", ""]]}, {"id": "1406.1238", "submitter": "EPTCS", "authors": "Freek Verbeek (Open University of The Netherlands), Julien Schmaltz\n  (Eindhoven University of Technology)", "title": "Proceedings Twelfth International Workshop on the ACL2 Theorem Prover\n  and its Applications", "comments": null, "journal-ref": "EPTCS 152, 2014", "doi": "10.4204/EPTCS.152", "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of the Twelfth International Workshop on\nthe ACL2 Theorem Prover and Its Applications, ACL2'14, a two-day workshop held\nin Vienna, Austria, on July 12-13, 2014. ACL2 workshops occur at approximately\n18-month intervals and provide a major technical forum for researchers to\npresent and discuss improvements and extensions to the theorem prover,\ncomparisons of ACL2 with other systems, and applications of ACL2 in formal\nverification. These proceedings include 13 peer reviewed technical papers.\n  ACL2 is a state-of-the-art automated reasoning system that has been\nsuccessfully applied in academia, government, and industry for specification\nand verification of computing systems and in teaching computer science courses.\nIn 2005, Boyer, Kaufmann, and Moore were awarded the 2005 ACM Software System\nAward for their work in ACL2 and the other theorem provers in the Boyer-Moore\nfamily.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 23:49:33 GMT"}], "update_date": "2014-06-06", "authors_parsed": [["Verbeek", "Freek", "", "Open University of The Netherlands"], ["Schmaltz", "Julien", "", "Eindhoven University of Technology"]]}, {"id": "1406.1556", "submitter": "EPTCS", "authors": "Matt Kaufmann (UT Austin), J Strother Moore (UT Austin)", "title": "Enhancements to ACL2 in Versions 6.2, 6.3, and 6.4", "comments": "In Proceedings ACL2 2014, arXiv:1406.1238", "journal-ref": "EPTCS 152, 2014, pp. 1-7", "doi": "10.4204/EPTCS.152.1", "report-no": null, "categories": "cs.AI cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on improvements to ACL2 made since the 2013 ACL2 Workshop.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 01:46:54 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Kaufmann", "Matt", "", "UT Austin"], ["Moore", "J Strother", "", "UT Austin"]]}, {"id": "1406.1561", "submitter": "EPTCS", "authors": "Ruben Gamboa (University of Wyoming), John Cowles (University of\n  Wyoming)", "title": "Formal Verification of Medina's Sequence of Polynomials for\n  Approximating Arctangent", "comments": "In Proceedings ACL2 2014, arXiv:1406.1238", "journal-ref": "EPTCS 152, 2014, pp. 101-110", "doi": "10.4204/EPTCS.152.9", "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The verification of many algorithms for calculating transcendental functions\nis based on polynomial approximations to these functions, often Taylor series\napproximations. However, computing and verifying approximations to the\narctangent function are very challenging problems, in large part because the\nTaylor series converges very slowly to arctangent-a 57th-degree polynomial is\nneeded to get three decimal places for arctan(0.95). Medina proposed a series\nof polynomials that approximate arctangent with far faster convergence-a\n7th-degree polynomial is all that is needed to get three decimal places for\narctan(0.95). We present in this paper a proof in ACL2(r) of the correctness\nand convergence rate of this sequence of polynomials. The proof is particularly\nbeautiful, in that it uses many results from real analysis. Some of these\nnecessary results were proven in prior work, but some were proven as part of\nthis effort.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 01:48:16 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Gamboa", "Ruben", "", "University of Wyoming"], ["Cowles", "John", "", "University of\n  Wyoming"]]}, {"id": "1406.1796", "submitter": "Paul Tarau", "authors": "Paul Tarau", "title": "A Generic Numbering System based on Catalan Families of Combinatorial\n  Objects", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe arithmetic algorithms on a canonical number representation based\non the Catalan family of combinatorial objects specified as a Haskell type\nclass.\n  Our algorithms work on a {\\em generic} representation that we illustrate on\ninstances members of the Catalan family, like ordered binary and multiway\ntrees. We validate the correctness of our algorithms by defining an instance of\nthe same type class based the usual bitstring-based natural numbers.\n  While their average and worst case complexity is within constant factors of\ntheir traditional counterparts, our algorithms provide super-exponential gains\nfor numbers corresponding to Catalan objects of low representation size.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 19:22:44 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 21:15:15 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Tarau", "Paul", ""]]}, {"id": "1406.2079", "submitter": "Garry Pantelis", "authors": "Garry Pantelis", "title": "Program Verification of Numerical Computation - Part 2", "comments": "arXiv admin note: text overlap with arXiv:1401.1290", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes present some extensions of a formal method introduced in an\nearlier paper. The formal method is designed as a tool for program verification\nof numerical computation and forms the basis of the software package VPC.\nIncluded in the extensions that are presented here are disjunctions and methods\nfor detecting non-computable programs. A more comprehensive list of the\nconstruction rules as higher order constructs is also presented.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jun 2014 05:36:44 GMT"}, {"version": "v2", "created": "Tue, 17 Jun 2014 18:13:56 GMT"}, {"version": "v3", "created": "Wed, 25 Jun 2014 21:36:43 GMT"}, {"version": "v4", "created": "Thu, 20 Nov 2014 08:28:13 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Pantelis", "Garry", ""]]}, {"id": "1406.2266", "submitter": "EPTCS", "authors": "Jared Davis (Centaur Technology), Matt Kaufmann (University of Texas\n  at Austin)", "title": "Industrial-Strength Documentation for ACL2", "comments": "In Proceedings ACL2 2014, arXiv:1406.1238", "journal-ref": "EPTCS 152, 2014, pp. 9-25", "doi": "10.4204/EPTCS.152.2", "report-no": null, "categories": "cs.SE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ACL2 theorem prover is a complex system. Its libraries are vast.\nIndustrial verification efforts may extend this base with hundreds of thousands\nof lines of additional modeling tools, specifications, and proof scripts. High\nquality documentation is vital for teams that are working together on projects\nof this scale. We have developed XDOC, a flexible, scalable documentation tool\nfor ACL2 that can incorporate the documentation for ACL2 itself, the Community\nBooks, and an organization's internal formal verification projects, and which\nhas many features that help to keep the resulting manuals up to date. Using\nthis tool, we have produced a comprehensive, publicly available ACL2+Books\nManual that brings better documentation to all ACL2 users. We have also\ndeveloped an extended manual for use within Centaur Technology that extends the\npublic manual to cover Centaur's internal books. We expect that other\norganizations using ACL2 will wish to develop similarly extended manuals.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 01:47:12 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Davis", "Jared", "", "Centaur Technology"], ["Kaufmann", "Matt", "", "University of Texas\n  at Austin"]]}, {"id": "1406.4806", "submitter": "Jeroen Ooms", "authors": "Jeroen Ooms", "title": "The OpenCPU System: Towards a Universal Interface for Scientific\n  Computing through Separation of Concerns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications integrating analysis components require a programmable interface\nwhich defines statistical operations independently of any programming language.\nBy separating concerns of scientific computing from application and\nimplementation details we can derive an interoperable API for data analysis.\nBut what exactly are the concerns of scientific computing? To answer this\nquestion, the paper starts with an exploration of the purpose, problems,\ncharacteristics, struggles, culture, and community of this unique branch of\ncomputing. By mapping out the domain logic, we try to unveil the fundamental\nprinciples and concepts behind statistical software. Along the way we highlight\nimportant problems and bottlenecks that need to be addressed by the system in\norder to facilitate reliable and scalable analysis units. Finally, the OpenCPU\nsoftware is introduced as an example implementation that builds on HTTP and R\nto expose a simple, abstracted interface for scientific computing.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 00:03:52 GMT"}], "update_date": "2014-06-19", "authors_parsed": [["Ooms", "Jeroen", ""]]}, {"id": "1406.4923", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, William Arcand, David Bestor, Bill Bergeron, Chansup\n  Byun, Vijay Gadepally, Matthew Hubbell, Peter Michaleas, Julie Mullen, Andrew\n  Prout, Albert Reuther, Antonio Rosa, Charles Yee (MIT)", "title": "Achieving 100,000,000 database inserts per second using Accumulo and D4M", "comments": "6 pages; to appear in IEEE High Performance Extreme Computing (HPEC)\n  2014", "journal-ref": null, "doi": "10.1109/HPEC.2014.7040945", "report-no": null, "categories": "cs.DB astro-ph.IM cs.CE cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Apache Accumulo database is an open source relaxed consistency database\nthat is widely used for government applications. Accumulo is designed to\ndeliver high performance on unstructured data such as graphs of network data.\nThis paper tests the performance of Accumulo using data from the Graph500\nbenchmark. The Dynamic Distributed Dimensional Data Model (D4M) software is\nused to implement the benchmark on a 216-node cluster running the MIT\nSuperCloud software stack. A peak performance of over 100,000,000 database\ninserts per second was achieved which is 100x larger than the highest\npreviously published value for any other database. The performance scales\nlinearly with the number of ingest clients, number of database servers, and\ndata size. The performance was achieved by adapting several supercomputing\ntechniques to this application: distributed arrays, domain decomposition,\nadaptive load balancing, and single-program-multiple-data programming.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jun 2014 00:44:12 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Kepner", "Jeremy", "", "MIT"], ["Arcand", "William", "", "MIT"], ["Bestor", "David", "", "MIT"], ["Bergeron", "Bill", "", "MIT"], ["Byun", "Chansup", "", "MIT"], ["Gadepally", "Vijay", "", "MIT"], ["Hubbell", "Matthew", "", "MIT"], ["Michaleas", "Peter", "", "MIT"], ["Mullen", "Julie", "", "MIT"], ["Prout", "Andrew", "", "MIT"], ["Reuther", "Albert", "", "MIT"], ["Rosa", "Antonio", "", "MIT"], ["Yee", "Charles", "", "MIT"]]}, {"id": "1406.5369", "submitter": "Harald Koestler Dr.", "authors": "Harald Koestler, Christian Schmitt, Sebastian Kuckuk, Frank Hannig,\n  Juergen Teich, Ulrich Ruede", "title": "A Scala Prototype to Generate Multigrid Solver Implementations for\n  Different Problems and Target Multi-Core Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in computational science and engineering involve partial\ndifferential equations and thus require the numerical solution of large, sparse\n(non)linear systems of equations. Multigrid is known to be one of the most\nefficient methods for this purpose. However, the concrete multigrid algorithm\nand its implementation highly depend on the underlying problem and hardware.\nTherefore, changes in the code or many different variants are necessary to\ncover all relevant cases. In this article we provide a prototype implementation\nin Scala for a framework that allows abstract descriptions of PDEs, their\ndiscretization, and their numerical solution via multigrid algorithms. From\nthese, one is able to generate data structures and implementations of multigrid\ncomponents required to solve elliptic PDEs on structured grids. Two different\ntest problems showcase our proposed automatic generation of multigrid solvers\nfor both CPU and GPU target platforms.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 12:46:27 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Koestler", "Harald", ""], ["Schmitt", "Christian", ""], ["Kuckuk", "Sebastian", ""], ["Hannig", "Frank", ""], ["Teich", "Juergen", ""], ["Ruede", "Ulrich", ""]]}, {"id": "1406.5550", "submitter": "Andrei Zinovyev Dr.", "authors": "Alexander N. Gorban, Alexander Pitenko, Andrei Zinovyev", "title": "ViDaExpert: user-friendly tool for nonlinear visualization and analysis\n  of multidimensional vectorial data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS stat.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  ViDaExpert is a tool for visualization and analysis of multidimensional\nvectorial data. ViDaExpert is able to work with data tables of \"object-feature\"\ntype that might contain numerical feature values as well as textual labels for\nrows (objects) and columns (features). ViDaExpert implements several\nstatistical methods such as standard and weighted Principal Component Analysis\n(PCA) and the method of elastic maps (non-linear version of PCA), Linear\nDiscriminant Analysis (LDA), multilinear regression, K-Means clustering, a\nvariant of decision tree construction algorithm. Equipped with several\nuser-friendly dialogs for configuring data point representations (size, shape,\ncolor) and fast 3D viewer, ViDaExpert is a handy tool allowing to construct an\ninteractive 3D-scene representing a table of data in multidimensional space and\nperform its quick and insightfull statistical analysis, from basic to advanced\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 22:31:25 GMT"}, {"version": "v2", "created": "Fri, 27 Jun 2014 14:40:04 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Gorban", "Alexander N.", ""], ["Pitenko", "Alexander", ""], ["Zinovyev", "Andrei", ""]]}, {"id": "1406.5565", "submitter": "Sam  Keene", "authors": "Kenneth D. Morton Jr., Peter Torrione, Leslie Collins, Sam Keene", "title": "An Open Source Pattern Recognition Toolbox for MATLAB", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern recognition and machine learning are becoming integral parts of\nalgorithms in a wide range of applications. Different algorithms and approaches\nfor machine learning include different tradeoffs between performance and\ncomputation, so during algorithm development it is often necessary to explore a\nvariety of different approaches to a given task. A toolbox with a unified\nframework across multiple pattern recognition techniques enables algorithm\ndevelopers the ability to rapidly evaluate different choices prior to\ndeployment. MATLAB is a widely used environment for algorithm development and\nprototyping, and although several MATLAB toolboxes for pattern recognition are\ncurrently available these are either incomplete, expensive, or restrictively\nlicensed. In this work we describe a MATLAB toolbox for pattern recognition and\nmachine learning known as the PRT (Pattern Recognition Toolbox), licensed under\nthe permissive MIT license. The PRT includes many popular techniques for data\npreprocessing, supervised learning, clustering, regression and feature\nselection, as well as a methodology for combining these components using a\nsimple, uniform syntax. The resulting algorithms can be evaluated using\ncross-validation and a variety of scoring metrics to ensure robust performance\nwhen the algorithm is deployed. This paper presents an overview of the PRT as\nwell as an example of usage on Fisher's Iris dataset.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jun 2014 01:50:54 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Morton", "Kenneth D.", "Jr."], ["Torrione", "Peter", ""], ["Collins", "Leslie", ""], ["Keene", "Sam", ""]]}, {"id": "1406.5597", "submitter": "Anando Chatterjee", "authors": "A. G. Chatterjee, M. K. Verma, and M. Chaudhuri", "title": "Transpose-free Fast Fourier Transform for Turbulence Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE cs.DS physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-spectral method is one of the most accurate techniques for simulating\nturbulent flows. Fast Fourier transform (FFT) is an integral part of this\nmethod. In this paper, we present a new procedure to compute FFT in which we\nsave operations during interprocess communications by avoiding transpose of the\narray. As a result, our transpose-free FFT is 15\\% to 20\\% faster than FFTW.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jun 2014 11:19:59 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Chatterjee", "A. G.", ""], ["Verma", "M. K.", ""], ["Chaudhuri", "M.", ""]]}, {"id": "1406.6900", "submitter": "Christian Kuehn", "authors": "Christian Kuehn", "title": "Efficient Gluing of Numerical Continuation and a Multiple Solution\n  Method for Elliptic PDEs", "comments": "Revised version based upon referee comments, 11 figures, shortened\n  online abstract and slightly lower quality figures due to arXiv size\n  limitations", "journal-ref": "Applied Mathematics and Computation, Vol. 266, pp. 656-674, 2015", "doi": "10.1016/j.amc.2015.05.120", "report-no": null, "categories": "math.DS cs.MS math.NA nlin.PS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical continuation calculations for ordinary differential equations\n(ODEs) are, by now, an established tool for bifurcation analysis in dynamical\nsystems theory as well as across almost all natural and engineering sciences.\nAlthough several excellent standard software packages are available for ODEs,\nthere are - for good reasons - no standard numerical continuation toolboxes\navailable for partial differential equations (PDEs), which cover a broad range\nof different classes of PDEs automatically. A natural approach to this problem\nis to look for efficient gluing computation approaches, with independent\ncomponents developed by researchers in numerical analysis, dynamical systems,\nscientific computing and mathematical modelling. In this paper, we shall study\nseveral elliptic PDEs (Lane-Emden-Fowler, Lane-Emden-Fowler with microscopic\nforce, Caginalp) via the numerical continuation software pde2path and develop a\ngluing component to determine a set of starting solutions for the continuation\nby exploting the variational structures of the PDEs. In particular, we solve\nthe initialization problem of numerical continuation for PDEs via a minimax\nalgorithm to find multiple unstable solution. Furthermore, for the Caginalp\nsystem, we illustrate the efficient gluing link of pde2path to the underlying\nmesh generation and the FEM MatLab pdetoolbox. Even though the approach works\nefficiently due to the high-level programming language and without developing\nany new algorithms, we still obtain interesting bifurcation diagrams and\ndirectly applicable conclusions about the three elliptic PDEs we study, in\nparticular with respect to symmetry-breaking. In particular, we show for a\nmodified Lane-Emden-Fowler equation with an asymmetric microscopic force, how a\nfully connected bifurcation diagram splits up into C-shaped isolas on which\nlocalized pattern deformation appears towards two different regimes.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 14:37:40 GMT"}, {"version": "v2", "created": "Wed, 30 Jul 2014 17:48:12 GMT"}, {"version": "v3", "created": "Sat, 18 Oct 2014 14:17:34 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Kuehn", "Christian", ""]]}, {"id": "1406.6924", "submitter": "Paolo Lella", "authors": "Davide Alberelli and Paolo Lella", "title": "Strongly stable ideals and Hilbert polynomials", "comments": "Source code available as an ancillary file. Final version", "journal-ref": "J. Softw. Alg. Geom. 9 (2019) 1-9", "doi": "10.2140/jsag.2019.9.1", "report-no": null, "categories": "cs.SC cs.MS math.AC math.AG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\texttt{StronglyStableIdeals} package for \\textit{Macaulay2} provides a\nmethod to compute all saturated strongly stable ideals in a given polynomial\nring with a fixed Hilbert polynomial. A description of the main method and\nauxiliary tools is given.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 15:35:00 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 07:59:45 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Alberelli", "Davide", ""], ["Lella", "Paolo", ""]]}, {"id": "1406.7648", "submitter": "Marco Scutari", "authors": "Marco Scutari", "title": "Bayesian Network Constraint-Based Structure Learning Algorithms:\n  Parallel and Optimised Implementations in the bnlearn R Package", "comments": "20 pages, 4 figures", "journal-ref": "Journal of Statistical Software (2017), 77(2), 1-20", "doi": null, "report-no": null, "categories": "stat.CO cs.AI cs.MS stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known in the literature that the problem of learning the structure\nof Bayesian networks is very hard to tackle: its computational complexity is\nsuper-exponential in the number of nodes in the worst case and polynomial in\nmost real-world scenarios.\n  Efficient implementations of score-based structure learning benefit from past\nand current research in optimisation theory, which can be adapted to the task\nby using the network score as the objective function to maximise. This is not\ntrue for approaches based on conditional independence tests, called\nconstraint-based learning algorithms. The only optimisation in widespread use,\nbacktracking, leverages the symmetries implied by the definitions of\nneighbourhood and Markov blanket.\n  In this paper we illustrate how backtracking is implemented in recent\nversions of the bnlearn R package, and how it degrades the stability of\nBayesian network structure learning for little gain in terms of speed. As an\nalternative, we describe a software architecture and framework that can be used\nto parallelise constraint-based structure learning algorithms (also implemented\nin bnlearn) and we demonstrate its performance using four reference networks\nand two real-world data sets from genetics and systems biology. We show that on\nmodern multi-core or multiprocessor hardware parallel implementations are\npreferable over backtracking, which was developed when single-processor\nmachines were the norm.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2014 09:56:20 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2015 10:27:23 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Scutari", "Marco", ""]]}]