[{"id": "1606.00094", "submitter": "Matthew Moskewicz", "authors": "Matthew Moskewicz and Forrest Iandola and Kurt Keutzer", "title": "Boda-RTC: Productive Generation of Portable, Efficient Code for\n  Convolutional Neural Networks on Mobile Computing Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of neural networks (NNs) spans academia, industry, and popular\nculture. In particular, convolutional neural networks (CNNs) have been applied\nto many image based machine learning tasks and have yielded strong results. The\navailability of hardware/software systems for efficient training and deployment\nof large and/or deep CNN models has been, and continues to be, an important\nconsideration for the field. Early systems for NN computation focused on\nleveraging existing dense linear algebra techniques and libraries. Current\napproaches use low-level machine specific programming and/or closed-source,\npurpose-built vendor libraries. In this work, we present an open source system\nthat, compared to existing approaches, achieves competitive computational speed\nwhile achieving higher portability. We achieve this by targeting the\nvendor-neutral OpenCL platform using a code-generation approach. We argue that\nour approach allows for both: (1) the rapid development of new computational\nkernels for existing hardware targets, and (2) the rapid tuning of existing\ncomputational kernels for new hardware targets. Results are presented for a\ncase study of targeting the Qualcomm Snapdragon 820 mobile computing platform\nfor CNN deployment.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 02:17:26 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 16:20:09 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Moskewicz", "Matthew", ""], ["Iandola", "Forrest", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1606.00541", "submitter": "Hui Liu Mr", "authors": "Zhangxin Chen, Hui Liu, Bo Yang", "title": "Parallel Triangular Solvers on GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate GPU based parallel triangular solvers\nsystematically. The parallel triangular solvers are fundamental to incomplete\nLU factorization family preconditioners and algebraic multigrid solvers. We\ndevelop a new matrix format suitable for GPU devices. Parallel lower triangular\nsolvers and upper triangular solvers are developed for this new data structure.\nWith these solvers, ILU preconditioners and domain decomposition\npreconditioners are developed. Numerical results show that we can speed\ntriangular solvers around seven times faster.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 05:54:09 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Chen", "Zhangxin", ""], ["Liu", "Hui", ""], ["Yang", "Bo", ""]]}, {"id": "1606.00545", "submitter": "Hui Liu Mr", "authors": "Bo Yang, Hui Liu, Zhangxin Chen", "title": "Development of Krylov and AMG linear solvers for large-scale sparse\n  matrices on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research introduce our work on developing Krylov subspace and AMG\nsolvers on NVIDIA GPUs. As SpMV is a crucial part for these iterative methods,\nSpMV algorithms for single GPU and multiple GPUs are implemented. A HEC matrix\nformat and a communication mechanism are established. And also, a set of\nspecific algorithms for solving preconditioned systems in parallel environments\nare designed, including ILU(k), RAS and parallel triangular solvers. Based on\nthese work, several Krylov solvers and AMG solvers are developed. According to\nnumerical experiments, favorable acceleration performance is acquired from our\nKrylov solver and AMG solver under various parameter conditions.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 06:01:05 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Yang", "Bo", ""], ["Liu", "Hui", ""], ["Chen", "Zhangxin", ""]]}, {"id": "1606.01289", "submitter": "Darren Engwirda", "authors": "Darren Engwirda", "title": "Conforming restricted Delaunay mesh generation for piecewise smooth\n  complexes", "comments": "To appear at the 25th International Meshing Roundtable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CE cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Frontal-Delaunay refinement algorithm for mesh generation in piecewise\nsmooth domains is described. Built using a restricted Delaunay framework, this\nnew algorithm combines a number of novel features, including: (i) an\nunweighted, conforming restricted Delaunay representation for domains specified\nas a (non-manifold) collection of piecewise smooth surface patches and curve\nsegments, (ii) a protection strategy for domains containing curve segments that\nsubtend sharply acute angles, and (iii) a new class of off-centre refinement\nrules designed to achieve high-quality point-placement along embedded curve\nfeatures. Experimental comparisons show that the new Frontal-Delaunay algorithm\noutperforms a classical (statically weighted) restricted Delaunay-refinement\ntechnique for a number of three-dimensional benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 22:06:58 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 18:06:16 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Engwirda", "Darren", ""]]}, {"id": "1606.04987", "submitter": "Yuxiang Wang", "authors": "Yuxiang Wang and Gregory J. Gerling", "title": "Automatic finite element implementation of hyperelastic material with a\n  double numerical differentiation algorithm", "comments": "19 pages, 3 figures, and 2 tables. Was presented as a podium\n  presentation at the Computer Methods in Biomechanics and Biomedical\n  Engineering 2015, September 3rd, Montreal, Quebec, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to accelerate implementation of hyperelastic materials for finite\nelement analysis, we developed an automatic numerical algorithm that only\nrequires the strain energy function. This saves the effort on analytical\nderivation and coding of stress and tangent modulus, which is time-consuming\nand prone to human errors. Using the one-sided Newton difference quotients, the\nproposed algorithm first perturbs deformation gradients and calculate the\ndifference on strain energy to approximate stress. Then, we perturb again to\nget difference in stress to approximate tangent modulus. Accuracy of the\napproximations were evaluated across the perturbation parameter space, where we\nfind the optimal amount of perturbation being $10^{-6}$ to obtain stress and\n$10^{-4}$ to obtain tangent modulus. Single element verification in ABAQUS with\nNeo-Hookean material resulted in a small stress error of only $7\\times10^{-5}$\non average across uniaxial compression and tension, biaxial tension and simple\nshear situations. A full 3D model with Holzapfel anisotropic material for\nartery inflation generated a small relative error of $4\\times10^{-6}$ for\ninflated radius at $25 kPa$ pressure. Results of the verification tests suggest\nthat the proposed numerical method has good accuracy and convergence\nperformance, therefore a good material implementation algorithm in small scale\nmodels and a useful debugging tool for large scale models.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 17:54:41 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Wang", "Yuxiang", ""], ["Gerling", "Gregory J.", ""]]}, {"id": "1606.05385", "submitter": "Theo Steininger", "authors": "T. Steininger, M. Greiner, F. Beaujean, T. En{\\ss}lin", "title": "D2O - a distributed data object for parallel high-performance computing\n  in Python", "comments": null, "journal-ref": null, "doi": "10.1186/s40537-016-0052-5", "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce D2O, a Python module for cluster-distributed multi-dimensional\nnumerical arrays. It acts as a layer of abstraction between the algorithm code\nand the data-distribution logic. The main goal is to achieve usability without\nlosing numerical performance and scalability. D2O's global interface is similar\nto the one of a numpy.ndarray, whereas the cluster node's local data is\ndirectly accessible for use in customized high-performance modules. D2O is\nwritten in pure Python which makes it portable and easy to use and modify.\nExpensive operations are carried out by dedicated external libraries like numpy\nand mpi4py. The performance of D2O is on a par with numpy for serial\napplications and scales well when moving to an MPI cluster. D2O is open-source\nsoftware available under the GNU General Public License v3 (GPL-3) at\nhttps://gitlab.mpcdf.mpg.de/ift/D2O\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 23:19:58 GMT"}, {"version": "v2", "created": "Sat, 13 Aug 2016 08:28:59 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Steininger", "T.", ""], ["Greiner", "M.", ""], ["Beaujean", "F.", ""], ["En\u00dflin", "T.", ""]]}, {"id": "1606.05563", "submitter": "Jan Verschelde", "authors": "Nathan Bliss and Jan Verschelde", "title": "Computing all Space Curve Solutions of Polynomial Systems by Polyhedral\n  Methods", "comments": "14 pages, 1 figure, accepted for presentation at Computer Algebra in\n  Scientific Computing, CASC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.MS math.AG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A polyhedral method to solve a system of polynomial equations exploits its\nsparse structure via the Newton polytopes of the polynomials. We propose a\nhybrid symbolic-numeric method to compute a Puiseux series expansion for every\nspace curve that is a solution of a polynomial system. The focus of this paper\nconcerns the difficult case when the leading powers of the Puiseux series of\nthe space curve are contained in the relative interior of a higher dimensional\ncone of the tropical prevariety. We show that this difficult case does not\noccur for polynomials with generic coefficients. To resolve this case, we\npropose to apply polyhedral end games to recover tropisms hidden in the\ntropical prevariety.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 15:28:40 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Bliss", "Nathan", ""], ["Verschelde", "Jan", ""]]}, {"id": "1606.05790", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Peter Aaltonen, David Bader, Ayd{\\i}n Buluc, Franz\n  Franchetti, John Gilbert, Dylan Hutchison, Manoj Kumar, Andrew Lumsdaine,\n  Henning Meyerhenke, Scott McMillan, Jose Moreira, John D. Owens, Carl Yang,\n  Marcin Zalewski, Timothy Mattson", "title": "Mathematical Foundations of the GraphBLAS", "comments": "9 pages; 11 figures; accepted to IEEE High Performance Extreme\n  Computing (HPEC) conference 2016", "journal-ref": null, "doi": "10.1109/HPEC.2016.7761646", "report-no": null, "categories": "cs.MS astro-ph.IM cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GraphBLAS standard (GraphBlas.org) is being developed to bring the\npotential of matrix based graph algorithms to the broadest possible audience.\nMathematically the Graph- BLAS defines a core set of matrix-based graph\noperations that can be used to implement a wide class of graph algorithms in a\nwide range of programming environments. This paper provides an introduction to\nthe mathematics of the GraphBLAS. Graphs represent connections between vertices\nwith edges. Matrices can represent a wide range of graphs using adjacency\nmatrices or incidence matrices. Adjacency matrices are often easier to analyze\nwhile incidence matrices are often better for representing data. Fortunately,\nthe two are easily connected by matrix mul- tiplication. A key feature of\nmatrix mathematics is that a very small number of matrix operations can be used\nto manipulate a very wide range of graphs. This composability of small number\nof operations is the foundation of the GraphBLAS. A standard such as the\nGraphBLAS can only be effective if it has low performance overhead. Performance\nmeasurements of prototype GraphBLAS implementations indicate that the overhead\nis low.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2016 18:46:20 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 02:52:48 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Kepner", "Jeremy", ""], ["Aaltonen", "Peter", ""], ["Bader", "David", ""], ["Buluc", "Ayd\u0131n", ""], ["Franchetti", "Franz", ""], ["Gilbert", "John", ""], ["Hutchison", "Dylan", ""], ["Kumar", "Manoj", ""], ["Lumsdaine", "Andrew", ""], ["Meyerhenke", "Henning", ""], ["McMillan", "Scott", ""], ["Moreira", "Jose", ""], ["Owens", "John D.", ""], ["Yang", "Carl", ""], ["Zalewski", "Marcin", ""], ["Mattson", "Timothy", ""]]}, {"id": "1606.06311", "submitter": "Andrei Turkin", "authors": "Andrei Turkin, Aung Thu", "title": "Benchmarking Python Tools for Automatic Differentiation", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we compare several Python tools for automatic differentiation.\nIn order to assess the difference in performance and precision, the problem of\nfinding the optimal geometrical structure of the cluster with identical atoms\nis used as follows. First, we compare performance of calculating gradients for\nthe objective function. We showed that the PyADOL-C and PyCppAD tools have much\nbetter performance for big clusters than the other ones. Second, we assess\nprecision of these two tools by calculating the difference between the obtained\nat the optimal configuration gradient norms. We conclude that PyCppAD has the\nbest performance among others, while having almost the same precision as the\nsecond- best performing tool - PyADOL-C.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 20:14:12 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Turkin", "Andrei", ""], ["Thu", "Aung", ""]]}, {"id": "1606.06604", "submitter": "Dmitry Kulyabov PhD", "authors": "M. N. Gevorkyan, T. R. Velieva, A. V. Korolkova, D. S. Kulyabov, L. A.\n  Sevastyanov", "title": "Stochastic Runge-Kutta Software Package for Stochastic Differential\n  Equations", "comments": "in English, in Russian. M.N. Gevorkyan, T.R. Velieva, A.V. Korolkova,\n  D.S. Kulyabov, L.A. Sevastyanov, Stochastic Runge-Kutta Software Package for\n  Stochastic Differential Equations, in Dependability Engineering and Complex\n  Systems, Vol. 470, 2016, pp. 169-179", "journal-ref": null, "doi": "10.1007/978-3-319-39639-2_15", "report-no": null, "categories": "physics.comp-ph cs.MS cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a result of the application of a technique of multistep processes\nstochastic models construction the range of models, implemented as a\nself-consistent differential equations, was obtained. These are partial\ndifferential equations (master equation, the Fokker--Planck equation) and\nstochastic differential equations (Langevin equation). However, analytical\nmethods do not always allow to research these equations adequately. It is\nproposed to use the combined analytical and numerical approach studying these\nequations. For this purpose the numerical part is realized within the framework\nof symbolic computation. It is recommended to apply stochastic Runge--Kutta\nmethods for numerical study of stochastic differential equations in the form of\nthe Langevin. Under this approach, a program complex on the basis of analytical\ncalculations metasystem Sage is developed. For model verification logarithmic\nwalks and Black--Scholes two-dimensional model are used. To illustrate the\nstochastic \"predator--prey\" type model is used. The utility of the combined\nnumerical-analytical approach is demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 14:51:11 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Gevorkyan", "M. N.", ""], ["Velieva", "T. R.", ""], ["Korolkova", "A. V.", ""], ["Kulyabov", "D. S.", ""], ["Sevastyanov", "L. A.", ""]]}, {"id": "1606.06977", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson", "title": "Computing hypergeometric functions rigorously", "comments": "v2: corrected example in section 3.1; corrected timing data for case\n  E-G in section 8.5 (table 6, figure 2); adjusted paper size", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient implementation of hypergeometric functions in\narbitrary-precision interval arithmetic. The functions ${}_0F_1$, ${}_1F_1$,\n${}_2F_1$ and ${}_2F_0$ (or the Kummer $U$-function) are supported for\nunrestricted complex parameters and argument, and by extension, we cover\nexponential and trigonometric integrals, error functions, Fresnel integrals,\nincomplete gamma and beta functions, Bessel functions, Airy functions, Legendre\nfunctions, Jacobi polynomials, complete elliptic integrals, and other special\nfunctions. The output can be used directly for interval computations or to\ngenerate provably correct floating-point approximations in any format.\nPerformance is competitive with earlier arbitrary-precision software, and\nsometimes orders of magnitude faster. We also partially cover the generalized\nhypergeometric function ${}_pF_q$ and computation of high-order parameter\nderivatives.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 15:07:11 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2016 11:58:14 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Johansson", "Fredrik", ""]]}, {"id": "1606.07085", "submitter": "Dylan Hutchison", "authors": "Dylan Hutchison, Jeremy Kepner, Vijay Gadepally, Bill Howe", "title": "From NoSQL Accumulo to NewSQL Graphulo: Design and Utility of Graph\n  Algorithms inside a BigTable Database", "comments": "9 pages, to appear in 2016 IEEE High Performance Extreme Computing\n  Conference (HPEC)", "journal-ref": null, "doi": "10.1109/HPEC.2016.7761577", "report-no": null, "categories": "cs.DB cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Google BigTable's scale-out design for distributed key-value storage inspired\na generation of NoSQL databases. Recently the NewSQL paradigm emerged in\nresponse to analytic workloads that demand distributed computation local to\ndata storage. Many such analytics take the form of graph algorithms, a trend\nthat motivated the GraphBLAS initiative to standardize a set of matrix math\nkernels for building graph algorithms. In this article we show how it is\npossible to implement the GraphBLAS kernels in a BigTable database by\npresenting the design of Graphulo, a library for executing graph algorithms\ninside the Apache Accumulo database. We detail the Graphulo implementation of\ntwo graph algorithms and conduct experiments comparing their performance to two\nmain-memory matrix math systems. Our results shed insight into the conditions\nthat determine when executing a graph algorithm is faster inside a database\nversus an external system---in short, that memory requirements and relative I/O\nare critical factors.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 20:08:47 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2016 04:09:48 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Hutchison", "Dylan", ""], ["Kepner", "Jeremy", ""], ["Gadepally", "Vijay", ""], ["Howe", "Bill", ""]]}, {"id": "1606.07399", "submitter": "Eran Treister", "authors": "Lars Ruthotto, Eran Treister and Eldad Haber", "title": "jInv -- a flexible Julia package for PDE parameter estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating parameters of Partial Differential Equations (PDEs) from noisy and\nindirect measurements often requires solving ill-posed inverse problems. These\nso called parameter estimation or inverse medium problems arise in a variety of\napplications such as geophysical, medical imaging, and nondestructive testing.\nTheir solution is computationally intense since the underlying PDEs need to be\nsolved numerous times until the reconstruction of the parameters is\nsufficiently accurate. Typically, the computational demand grows significantly\nwhen more measurements are available, which poses severe challenges to\ninversion algorithms as measurement devices become more powerful.\n  In this paper we present jInv, a flexible framework and open source software\nthat provides parallel algorithms for solving parameter estimation problems\nwith many measurements. Being written in the expressive programming language\nJulia, jInv is portable, easy to understand and extend, cross-platform tested,\nand well-documented. It provides novel parallelization schemes that exploit the\ninherent structure of many parameter estimation problems and can be used to\nsolve multiphysics inversion problems as is demonstrated using numerical\nexperiments motivated by geophysical imaging.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 18:37:41 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 07:58:27 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Ruthotto", "Lars", ""], ["Treister", "Eran", ""], ["Haber", "Eldad", ""]]}]