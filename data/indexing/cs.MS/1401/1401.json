[{"id": "1401.0763", "submitter": "Sparsh Mittal", "authors": "Sparsh Mittal", "title": "A Study of Successive Over-relaxation Method Parallelization Over Modern\n  HPC Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successive over-relaxation (SOR) is a computationally intensive, yet\nextremely important iterative solver for solving linear systems. Due to recent\ntrends of exponential growth in amount of data generated and increasing problem\nsizes, serial platforms have proved to be insufficient in providing the\nrequired computational power. In this paper, we present parallel\nimplementations of red-black SOR method using three modern programming\nlanguages namely Chapel, D and Go. We employ SOR method for solving 2D\nsteady-state heat conduction problem. We discuss the optimizations incorporated\nand the features of these languages which are crucial for improving the program\nperformance. Experiments have been performed using 2, 4, and 8 threads and\nperformance results are compared with serial execution. The analysis of results\nprovides important insights into working of SOR method.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 01:31:48 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Mittal", "Sparsh", ""]]}, {"id": "1401.0827", "submitter": "Kamel Ibn Aziz Derouiche kiaderouiche", "authors": "K.I.A.Derouiche", "title": "Interaction entre math\\'ematique et informatique Libre/Open Source par\n  le logiciel math\\'ematique", "comments": "11 pages, written in French, In Proceedings of the S\\'eminaire\n  National sur la didactique des Math\\'ematiques, 25-26 Novembre Tebessa,\n  Alg\\'erie (SNDM'13). 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CY math.HO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This article focuses on the application of model development and opening the\nsource code available and implemented by the Free Software and Open Source\nFLOSS to the instructional and teaching has both mathematics and computer by\nthe read-write(R/W) of mathematical software, including the most famous cases\nare numerical and symbolic computation. The article analysis the development of\nthe mathematical model of Free/Open Source(math FLOSS) software has proven its\nimportance in the area of research in mathematics and computer science .\nHowever, although their actual use, is very readable in higher education\ncourses. We discuss the feasibility of this model to the characteristics of the\ndomain, actors, interaction they have and the communities they form during the\ndevelopment of the software. Finally, we propose a mathematical example of\nFree/Open Source(Math FlOSS) software as analysis device .\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 16:42:05 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Derouiche", "K. I. A.", ""]]}, {"id": "1401.1290", "submitter": "Garry Pantelis", "authors": "Garry Pantelis", "title": "Program Verification of Numerical Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes outline a formal method for program verification of numerical\ncomputation. It forms the basis of the software package VPC in its initial\nphase of development. Much of the style of presentation is in the form of notes\nthat outline the definitions and rules upon which VPC is based. The initial\nmotivation of this project was to address some practical issues of computation,\nespecially of numerically intensive programs that are commonplace in computer\nmodels. The project evolved into a wider area for program construction as\nproofs leading to a model of inference in a more general sense. Some basic\nresults of machine arithmetic are derived as a demonstration of VPC.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2014 07:07:49 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Pantelis", "Garry", ""]]}, {"id": "1401.1942", "submitter": "Ankur Sinha PhD", "authors": "Ankur Sinha and Pekka Malo and Kalyanmoy Deb", "title": "Test Problem Construction for Single-Objective Bilevel Optimization", "comments": "arXiv admin note: text overlap with arXiv:1303.3901", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a procedure for designing controlled test problems\nfor single-objective bilevel optimization. The construction procedure is\nflexible and allows its user to control the different complexities that are to\nbe included in the test problems independently of each other. In addition to\nproperties that control the difficulty in convergence, the procedure also\nallows the user to introduce difficulties caused by interaction of the two\nlevels. As a companion to the test problem construction framework, the paper\npresents a standard test suite of twelve problems, which includes eight\nunconstrained and four constrained problems. Most of the problems are scalable\nin terms of variables and constraints. To provide baseline results, we have\nsolved the proposed test problems using a nested bilevel evolutionary\nalgorithm. The results can be used for comparison, while evaluating the\nperformance of any other bilevel optimization algorithm. The codes related to\nthe paper may be accessed from the website \\url{http://bilevel.org}.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 10:22:26 GMT"}, {"version": "v2", "created": "Wed, 18 Jun 2014 10:41:13 GMT"}, {"version": "v3", "created": "Tue, 16 Aug 2016 16:28:15 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Sinha", "Ankur", ""], ["Malo", "Pekka", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "1401.2248", "submitter": "Willi-Hans Steeb WHS", "authors": "Yorick Hardy and Willi-Hans Steeb", "title": "Boolean Functions, Quantum Gates, Hamilton Operators, Spin Systems and\n  Computer Algebra", "comments": "title extended, construction of spin system added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the construction of quantum gates (unitary operators) from\nboolean functions and give a number of applications. Both non-reversible and\nreversible boolean functions are considered. The construction of the Hamilton\noperator for a quantum gate is also described with the Hamilton operator\nexpressed as spin system. Computer algebra implementations are provided.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 08:12:46 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2014 15:45:36 GMT"}, {"version": "v3", "created": "Fri, 14 Nov 2014 08:10:07 GMT"}, {"version": "v4", "created": "Fri, 2 Jan 2015 11:10:05 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Hardy", "Yorick", ""], ["Steeb", "Willi-Hans", ""]]}, {"id": "1401.2720", "submitter": "Vedran Novakovic", "authors": "Vedran Novakovi\\'c", "title": "A hierarchically blocked Jacobi SVD algorithm for single and multiple\n  graphics processing units", "comments": "Accepted for publication in SIAM Journal on Scientific Computing", "journal-ref": "SIAM J. Sci. Comput. 37 (2015), C1-C30", "doi": "10.1137/140952429", "report-no": null, "categories": "cs.NA cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hierarchically blocked one-sided Jacobi algorithm for the\nsingular value decomposition (SVD), targeting both single and multiple graphics\nprocessing units (GPUs). The blocking structure reflects the levels of GPU's\nmemory hierarchy. The algorithm may outperform MAGMA's dgesvd, while retaining\nhigh relative accuracy. To this end, we developed a family of parallel pivot\nstrategies on GPU's shared address space, but applicable also to inter-GPU\ncommunication. Unlike common hybrid approaches, our algorithm in a single GPU\nsetting needs a CPU for the controlling purposes only, while utilizing GPU's\nresources to the fullest extent permitted by the hardware. When required by the\nproblem size, the algorithm, in principle, scales to an arbitrary number of GPU\nnodes. The scalability is demonstrated by more than twofold speedup for\nsufficiently large matrices on a Tesla S2050 system with four GPUs vs. a single\nFermi card.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 06:12:17 GMT"}, {"version": "v2", "created": "Sat, 7 Jun 2014 14:23:33 GMT"}, {"version": "v3", "created": "Sat, 27 Sep 2014 22:51:33 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Novakovi\u0107", "Vedran", ""]]}, {"id": "1401.3013", "submitter": "James Elliott", "authors": "James Elliott and Mark Hoemmen and Frank Mueller", "title": "Resilience in Numerical Methods: A Position on Fault Models and\n  Methodologies", "comments": "Position Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.ET math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future extreme-scale computer systems may expose silent data corruption (SDC)\nto applications, in order to save energy or increase performance. However,\nresilience research struggles to come up with useful abstract programming\nmodels for reasoning about SDC. Existing work randomly flips bits in running\napplications, but this only shows average-case behavior for a low-level,\nartificial hardware model. Algorithm developers need to understand worst-case\nbehavior with the higher-level data types they actually use, in order to make\ntheir algorithms more resilient. Also, we know so little about how SDC may\nmanifest in future hardware, that it seems premature to draw conclusions about\nthe average case. We argue instead that numerical algorithms can benefit from a\nnumerical unreliability fault model, where faults manifest as unbounded\nperturbations to floating-point data. Algorithms can use inexpensive \"sanity\"\nchecks that bound or exclude error in the results of computations. Given a\nselective reliability programming model that requires reliability only when and\nwhere needed, such checks can make algorithms reliable despite unbounded\nfaults. Sanity checks, and in general a healthy skepticism about the\ncorrectness of subroutines, are wise even if hardware is perfectly reliable.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 21:18:48 GMT"}], "update_date": "2014-01-15", "authors_parsed": [["Elliott", "James", ""], ["Hoemmen", "Mark", ""], ["Mueller", "Frank", ""]]}, {"id": "1401.3301", "submitter": "Caroline Japhet", "authors": "Fran\\c{c}ois Cuvelier, Caroline Japhet, Gilles Scarella", "title": "An efficient way to assemble finite element matrices in vector languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Matlab codes in 2D and 3D have been proposed recently to assemble\nfinite element matrices. In this paper we present simple, compact and efficient\nvectorized algorithms, which are variants of these codes, in arbitrary\ndimension, without the use of any lower level language. They can be easily\nimplemented in many vector languages (e.g. Matlab, Octave, Python, Scilab, R,\nJulia, C++ with STL,...). The principle of these techniques is general, we\npresent it for the assembly of several finite element matrices in arbitrary\ndimension, in the P1 finite element case. We also provide an extension of the\nalgorithms to the case of a system of PDE's. Then we give an extension to\npiecewise polynomials of higher order. We compare numerically the performance\nof these algorithms in Matlab, Octave and Python, with that in FreeFEM++ and in\na compiled language such as C. Examples show that, unlike what is commonly\nbelieved, the performance is not radically worse than that of C : in the\nbest/worst cases, selected vector languages are respectively 2.3/3.5 and\n2.9/4.1 times slower than C in the scalar and vector cases. We also present\nnumerical results which illustrate the computational costs of these algorithms\ncompared to standard algorithms and to other recent ones.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2014 19:36:39 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 09:17:43 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Cuvelier", "Fran\u00e7ois", ""], ["Japhet", "Caroline", ""], ["Scarella", "Gilles", ""]]}, {"id": "1401.4950", "submitter": "Matthias Petschow", "authors": "Matthias Petschow (1), ((1) AICES, RWTH Aachen)", "title": "MRRR-based Eigensolvers for Multi-core Processors and Supercomputers", "comments": "PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The real symmetric tridiagonal eigenproblem is of outstanding importance in\nnumerical computations; it arises frequently as part of eigensolvers for\nstandard and generalized dense Hermitian eigenproblems that are based on a\nreduction to tridiagonal form. For its solution, the algorithm of Multiple\nRelatively Robust Representations (MRRR or MR3 in short) - introduced in the\nlate 1990s - is among the fastest methods. To compute k eigenpairs of a real\nn-by-n tridiagonal T, MRRR only requires O(kn) arithmetic operations; in\ncontrast, all the other practical methods require O(k^2 n) or O(n^3) operations\nin the worst case. This thesis centers around the performance and accuracy of\nMRRR.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 15:52:03 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Petschow", "Matthias", "", "AICES, RWTH Aachen"]]}, {"id": "1401.5353", "submitter": "Blake Barker", "authors": "Blake Barker", "title": "STABLAB Documentation for KdV : Numerical proof of stability of roll\n  waves in the small-amplitude limit for inclined thin film flow", "comments": "Documentation, 255 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We document the MATLAB code used in the following study: Numerical proof of\nstability of roll waves in the small-amplitude limit for inclined thin film\nflow.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 15:43:52 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Barker", "Blake", ""]]}, {"id": "1401.6694", "submitter": "Daniel Roche", "authors": "Andrew Arnold, Daniel S. Roche", "title": "Multivariate sparse interpolation using randomized Kronecker\n  substitutions", "comments": "21 pages, 2 tables, 1 procedure. Accepted to ISSAC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.DS cs.MS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  We present new techniques for reducing a multivariate sparse polynomial to a\nunivariate polynomial. The reduction works similarly to the classical and\nwidely-used Kronecker substitution, except that we choose the degrees randomly\nbased on the number of nonzero terms in the multivariate polynomial, that is,\nits sparsity. The resulting univariate polynomial often has a significantly\nlower degree than the Kronecker substitution polynomial, at the expense of a\nsmall number of term collisions. As an application, we give a new algorithm for\nmultivariate interpolation which uses these new techniques along with any\nexisting univariate interpolation algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 21:37:51 GMT"}, {"version": "v2", "created": "Fri, 2 May 2014 05:01:05 GMT"}], "update_date": "2014-05-05", "authors_parsed": [["Arnold", "Andrew", ""], ["Roche", "Daniel S.", ""]]}, {"id": "1401.7372", "submitter": "Jeroen Ooms", "authors": "Dirk Eddelbuettel, Murray Stokely, Jeroen Ooms", "title": "RProtoBuf: Efficient Cross-Language Data Serialization in R", "comments": null, "journal-ref": null, "doi": "10.18637/jss.v071.i02", "report-no": null, "categories": "stat.CO cs.MS cs.SE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Modern data collection and analysis pipelines often involve a sophisticated\nmix of applications written in general purpose and specialized programming\nlanguages. Many formats commonly used to import and export data between\ndifferent programs or systems, such as CSV or JSON, are verbose, inefficient,\nnot type-safe, or tied to a specific programming language. Protocol Buffers are\na popular method of serializing structured data between applications - while\nremaining independent of programming languages or operating systems. They offer\na unique combination of features, performance, and maturity that seems\nparticularly well suited for data-driven applications and numerical computing.\nThe RProtoBuf package provides a complete interface to Protocol Buffers from\nthe R environment for statistical computing. This paper outlines the general\nclass of data serialization requirements for statistical computing, describes\nthe implementation of the RProtoBuf package, and illustrates its use with\nexample applications in large-scale data collection pipelines and web services.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2014 23:57:02 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Eddelbuettel", "Dirk", ""], ["Stokely", "Murray", ""], ["Ooms", "Jeroen", ""]]}, {"id": "1401.7962", "submitter": "Cornelia Victoria Anghel Drugarin", "authors": "Anghel Drugarin, Cornelia Victoria", "title": "Numerical application and Turbo C program using the Gauss-Jordan Method", "comments": "in Romanian", "journal-ref": "Algebra liniara. Programare liniara, vol.1, Eftimie Murgu,Press\n  Resita (2003). AGIR Press, vol.22, 2012, pp.171-176", "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents the general notions and algorithm about the Gauss-Jordan\nmethod. An eloquent example is given and the Turbo C program illustrated this\nmethod. We conclude that we can obtain by this method the determinant, by\nsimple calculations and reducing the rounding errors\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 10:44:45 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Drugarin", "Anghel", ""], ["Victoria", "Cornelia", ""]]}, {"id": "1401.8230", "submitter": "Vadim Demchik", "authors": "Vadim Demchik and Alexey Gulov", "title": "Increasing precision of uniform pseudorandom number generators", "comments": "5 pages, 1 figure; additional description of algorithm is applied", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general method to produce uniformly distributed pseudorandom numbers with\nextended precision by combining two pseudorandom numbers with lower precision\nis proposed. In particular, this method can be used for pseudorandom number\ngeneration with extended precision on graphics processing units (GPU), where\nthe performance of single and double precision operations can vary\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 20:20:18 GMT"}, {"version": "v2", "created": "Mon, 12 May 2014 12:45:45 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["Demchik", "Vadim", ""], ["Gulov", "Alexey", ""]]}]