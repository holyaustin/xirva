[{"id": "1402.0622", "submitter": "Adam Strzebonski", "authors": "Adam Strzebonski", "title": "Divide-And-Conquer Computation of Cylindrical Algebraic Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a divide-and-conquer version of the Cylindrical Algebraic\nDecomposition (CAD) algorithm. The algorithm represents the input as a Boolean\ncombination of subformulas, computes cylindrical algebraic decompositions of\nsolution sets of the subformulas, and combines the results. We propose a\ngraph-based heuristic to find a suitable partitioning of the input and present\nempirical comparison with direct CAD computation.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 05:52:47 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Strzebonski", "Adam", ""]]}, {"id": "1402.1285", "submitter": "Jorge Gonz\\'alez-Dom\\'inguez", "authors": "Jorge Gonz\\'alez-Dom\\'inguez, Evangelos Georganas, Yili Zheng, Mar\\'ia\n  J. Mart\\'in", "title": "Constructing Performance Models for Dense Linear Algebra Algorithms on\n  Cray XE Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hiding or minimizing the communication cost is key in order to obtain good\nperformance on large-scale systems. While communication overlapping attempts to\nhide communications cost, 2.5D communication avoiding algorithms improve\nperformance scalability by reducing the volume of data transfers at the cost of\nextra memory usage. Both approaches can be used together or separately and the\nbest choice depends on the machine, the algorithm and the problem size. Thus,\nthe development of performance models is crucial to determine the best option\nfor each scenario. In this paper, we present a methodology for constructing\nperformance models for parallel numerical routines on Cray XE systems. Our\nmodels use portable benchmarks that measure computational cost and network\ncharacteristics, as well as performance degradation caused by simultaneous\naccesses to the network. We validate our methodology by constructing the\nperformance models for the 2D and 2.5D approaches, with and without\noverlapping, of two matrix multiplication algorithms (Cannon's and SUMMA),\ntriangular solve (TRSM) and Cholesky. We compare the estimations provided by\nthese models with the experimental results using up to 24,576 cores of a Cray\nXE6 system and predict the performance of the algorithms on larger systems.\nResults prove that the estimations significantly improve when taking into\naccount network contention.\n", "versions": [{"version": "v1", "created": "Thu, 6 Feb 2014 09:16:38 GMT"}], "update_date": "2014-02-07", "authors_parsed": [["Gonz\u00e1lez-Dom\u00ednguez", "Jorge", ""], ["Georganas", "Evangelos", ""], ["Zheng", "Yili", ""], ["Mart\u00edn", "Mar\u00eda J.", ""]]}, {"id": "1402.2626", "submitter": "Jan Verschelde", "authors": "Jan Verschelde and Xiangcheng Yu", "title": "GPU acceleration of Newton's method for large systems of polynomial\n  equations in double double and quad double arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to compensate for the higher cost of double double and quad double\narithmetic when solving large polynomial systems, we investigate the\napplication of NVIDIA Tesla K20C general purpose graphics processing unit. The\nfocus on this paper is on Newton's method, which requires the evaluation of the\npolynomials, their derivatives, and the solution of a linear system to compute\nthe update to the current approximation for the solution. The reverse mode of\nalgorithmic differentiation for a product of variables is rewritten in a binary\ntree fashion so all threads in a block can collaborate in the computation. For\ndouble arithmetic, the evaluation and differentiation problem is memory bound,\nwhereas for complex quad double arithmetic the problem is compute bound. With\nacceleration we can double the dimension and get results that are twice as\naccurate in about the same time.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 20:18:31 GMT"}, {"version": "v2", "created": "Tue, 13 May 2014 13:38:42 GMT"}], "update_date": "2014-05-14", "authors_parsed": [["Verschelde", "Jan", ""], ["Yu", "Xiangcheng", ""]]}, {"id": "1402.3809", "submitter": "Michael Heroux", "authors": "Michael A. Heroux", "title": "Toward Resilient Algorithms and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade, the high performance computing community has become\nincreasingly concerned that preserving the reliable, digital machine model will\nbecome too costly or infeasible. In this paper we discuss four approaches for\ndeveloping new algorithms that are resilient to hard and soft failures.\n", "versions": [{"version": "v1", "created": "Sun, 16 Feb 2014 15:43:05 GMT"}, {"version": "v2", "created": "Thu, 13 Mar 2014 17:55:31 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Heroux", "Michael A.", ""]]}, {"id": "1402.5086", "submitter": "Aravindh Krishnamoorthy", "authors": "Aravindh Krishnamoorthy", "title": "Symmetric QR Algorithm with Permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the QR Algorithm with Permutations that shows an\nimproved convergence rate compared to the classical QR algorithm. We determine\na bound for performance based on best instantaneous convergence, and develop\nlow complexity methods for computing the permutation matrices at every\niteration. We use simulations to verify the improvement, and to compare the\nperformance of proposed algorithms to the classical QR algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 17:34:49 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Krishnamoorthy", "Aravindh", ""]]}, {"id": "1402.5835", "submitter": "J\\'er\\^ome Kunegis", "authors": "J\\'er\\^ome Kunegis", "title": "Polcovar: Software for Computing the Mean and Variance of Subgraph\n  Counts in Random Graphs", "comments": "5 pages; fixed some wording; added link to Github", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The mean and variance of the number of appearances of a given subgraph $H$ in\nan Erd\\H{o}s--R\\'enyi random graph over $n$ nodes are rational polynomials in\n$n$. We present a piece of software named Polcovar (from \"polynomial\" and\n\"covariance\") that computes the exact rational coefficients of these\npolynomials in function of $H$.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 14:26:08 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 20:34:48 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Kunegis", "J\u00e9r\u00f4me", ""]]}, {"id": "1402.5897", "submitter": "Elmar Peise", "authors": "Elmar Peise (1), Paolo Bientinesi (1) ((1) AICES, RWTH Aachen)", "title": "A Study on the Influence of Caching: Sequences of Dense Linear Algebra\n  Kernels", "comments": "Submitted to the Ninth International Workshop on Automatic\n  Performance Tuning (iWAPT2014)", "journal-ref": null, "doi": null, "report-no": "AICES-2014/02-1", "categories": "cs.MS cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is universally known that caching is critical to attain high- performance\nimplementations: In many situations, data locality (in space and time) plays a\nbigger role than optimizing the (number of) arithmetic floating point\noperations. In this paper, we show evidence that at least for linear algebra\nalgorithms, caching is also a crucial factor for accurate performance modeling\nand performance prediction.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 12:23:19 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Peise", "Elmar", "", "AICES, RWTH Aachen"], ["Bientinesi", "Paolo", "", "AICES, RWTH Aachen"]]}, {"id": "1402.6076", "submitter": "Sergei Izrailev", "authors": "Sergei Izrailev and Jeremy M. Stanley", "title": "Machine Learning at Scale", "comments": "Submitted to KDD'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It takes skill to build a meaningful predictive model even with the abundance\nof implementations of modern machine learning algorithms and readily available\ncomputing resources. Building a model becomes challenging if hundreds of\nterabytes of data need to be processed to produce the training data set. In a\ndigital advertising technology setting, we are faced with the need to build\nthousands of such models that predict user behavior and power advertising\ncampaigns in a 24/7 chaotic real-time production environment. As data\nscientists, we also have to convince other internal departments critical to\nimplementation success, our management, and our customers that our machine\nlearning system works. In this paper, we present the details of the design and\nimplementation of an automated, robust machine learning platform that impacts\nbillions of advertising impressions monthly. This platform enables us to\ncontinuously optimize thousands of campaigns over hundreds of millions of\nusers, on multiple continents, against varying performance objectives.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2014 07:50:50 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Izrailev", "Sergei", ""], ["Stanley", "Jeremy M.", ""]]}, {"id": "1402.6246", "submitter": "Sebastiano Vigna", "authors": "Sebastiano Vigna", "title": "An experimental exploration of Marsaglia's xorshift generators,\n  scrambled", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Marsaglia proposed recently xorshift generators as a class of very fast,\ngood-quality pseudorandom number generators. Subsequent analysis by Panneton\nand L'Ecuyer has lowered the expectations raised by Marsaglia's paper, showing\nseveral weaknesses of such generators, verified experimentally using the\nTestU01 suite. Nonetheless, many of the weaknesses of xorshift generators fade\naway if their result is scrambled by a non-linear operation (as originally\nsuggested by Marsaglia). In this paper we explore the space of possible\ngenerators obtained by multiplying the result of a xorshift generator by a\nsuitable constant. We sample generators at 100 equispaced points of their state\nspace and obtain detailed statistics that lead us to choices of parameters that\nimprove on the current ones. We then explore for the first time the space of\nhigh-dimensional xorshift generators, following another suggestion in\nMarsaglia's paper, finding choices of parameters providing periods of length\n$2^{1024} - 1$ and $2^{4096} - 1$. The resulting generators are of extremely\nhigh quality, faster than current similar alternatives, and generate\nlong-period sequences passing strong statistical tests using only eight logical\noperations, one addition and one multiplication by a constant.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2014 19:18:20 GMT"}, {"version": "v2", "created": "Sun, 23 Mar 2014 18:54:48 GMT"}, {"version": "v3", "created": "Mon, 14 Dec 2015 09:44:46 GMT"}, {"version": "v4", "created": "Sun, 3 Jan 2016 23:36:58 GMT"}, {"version": "v5", "created": "Thu, 13 Oct 2016 06:56:03 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Vigna", "Sebastiano", ""]]}, {"id": "1402.6635", "submitter": "Dmitry Kulyabov PhD", "authors": "A. V. Korolkova, D. S. Kulyabov, L. A. Sevastyanov", "title": "Tensor computations in computer algebra systems", "comments": "in Russian; in English", "journal-ref": "A. V. Korol'kova, D. S. Kulyabov, and L. A. Sevast'yanov. Tensor\n  computations in computer algebra systems. Programming and Computer Software,\n  39(3):135--142, 2013", "doi": "10.1134/S0361768813030031", "report-no": null, "categories": "cs.SC cs.MS gr-qc", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper considers three types of tensor computations. On their basis, we\nattempt to formulate criteria that must be satisfied by a computer algebra\nsystem dealing with tensors. We briefly overview the current state of tensor\ncomputations in different computer algebra systems. The tensor computations are\nillustrated with appropriate examples implemented in specific systems: Cadabra\nand Maxima.\n", "versions": [{"version": "v1", "created": "Sat, 22 Feb 2014 15:47:58 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Korolkova", "A. V.", ""], ["Kulyabov", "D. S.", ""], ["Sevastyanov", "L. A.", ""]]}]