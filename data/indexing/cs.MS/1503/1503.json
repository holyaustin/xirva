[{"id": "1503.00855", "submitter": "Nathan Uyttendaele", "authors": "Nathan Uyttendaele", "title": "How to speed up R code: an introduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most calculations performed by the average R user are unremarkable in the\nsense that nowadays, any computer can crush the related code in a matter of\nseconds. But more and more often, heavy calculations are also performed using\nR, something especially true in some fields such as statistics. The user then\nfaces total execution times of his codes that are hard to work with: hours,\ndays, even weeks. In this paper, how to reduce the total execution time of\nvarious codes will be shown and typical bottlenecks will be discussed. As a\nlast resort, how to run your code on a cluster of computers (most workplaces\nhave one) in order to make use of a larger processing power than the one\navailable on an average computer will also be discussed through two examples.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 08:21:32 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Uyttendaele", "Nathan", ""]]}, {"id": "1503.01034", "submitter": "Vladimir Zamdzhiev", "authors": "Aleks Kissinger and Vladimir Zamdzhiev", "title": "Quantomatic: A Proof Assistant for Diagrammatic Reasoning", "comments": "International Conference on Automated Deduction, CADE 2015 (CADE-25).\n  The final publication is available at Springer via\n  http://dx.doi.org/10.1007/978-3-319-21401-6_22", "journal-ref": null, "doi": "10.1007/978-3-319-21401-6_22", "report-no": null, "categories": "cs.LO cs.MS math.CT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monoidal algebraic structures consist of operations that can have multiple\noutputs as well as multiple inputs, which have applications in many areas\nincluding categorical algebra, programming language semantics, representation\ntheory, algebraic quantum information, and quantum groups. String diagrams\nprovide a convenient graphical syntax for reasoning formally about such\nstructures, while avoiding many of the technical challenges of a term-based\napproach. Quantomatic is a tool that supports the (semi-)automatic construction\nof equational proofs using string diagrams. We briefly outline the theoretical\nbasis of Quantomatic's rewriting engine, then give an overview of the core\nfeatures and architecture and give a simple example project that computes\nnormal forms for commutative bialgebras.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 18:20:39 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2015 15:30:29 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Kissinger", "Aleks", ""], ["Zamdzhiev", "Vladimir", ""]]}, {"id": "1503.01073", "submitter": "Vinzenz Maurer", "authors": "Vinzenz Maurer", "title": "T3PS: Tool for Parallel Processing in Parameter Scans", "comments": "50 pages, 7 figures, available for download at\n  http://t3ps.hepforge.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  T3PS is a program that can be used to quickly design and perform parameter\nscans while easily taking advantage of the multi-core architecture of current\nprocessors. It takes an easy to read and write parameter scan definition file\nformat as input. Based on the parameter ranges and other options contained\ntherein, it distributes the calculation of the parameter space over multiple\nprocesses and possibly computers. The derived data is saved in a plain text\nfile format readable by most plotting software. The supported scanning\nstrategies include: grid scan, random scan, Markov Chain Monte Carlo, numerical\noptimization. Several example parameter scans are shown and compared with\nresults in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 27 Feb 2015 08:48:24 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Maurer", "Vinzenz", ""]]}, {"id": "1503.01095", "submitter": "Endre Somogyi", "authors": "Endre T. Somogyi, Jean-Marie Bouteiller, James A. Glazier, Matthias\n  K\\\"onig, Kyle Medley, Maciej H. Swat, Herbert M. Sauro", "title": "libRoadRunner: A High Performance SBML Simulation and Analysis Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.SC cs.MS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents libRoadRunner, an extensible, high-performance,\ncross-platform, open-source software library for the simulation and analysis of\nmodels \\ expressed using Systems Biology Markup Language (SBML). SBML is the\nmost widely used standard for representing dynamic networks, especially\nbiochemical networks. libRoadRunner supports solution of both large models and\nmultiple replicas of a single model on desktop, mobile and cluster computers.\nlibRoadRunner is a self-contained library, able to run both as a component\ninside other tools via its C++ and C bindings andnteractively through its\nPython interface. The Python Application Programming Interface (API) is similar\nto the APIs of Matlab and SciPy, making it fast and easy to learn, even for new\nusers. libRoadRunner uses a custom Just-In-Time (JIT) compiler built on the\nwidely-used LLVM JIT compiler framework to compile SBML-specified models\ndirectly into very fast native machine code for a variety of processors, making\nit appropriate for solving very large models or multiple replicas of smaller\nmodels. libRoadRunner is flexible, supporting the bulk of the SBML\nspecification (except for delay and nonlinear algebraic equations) and several\nof its extensions. It offers multiple deterministic and stochastic integrators,\nas well as tools for steady-state, stability analyses and flux balance\nanalysis. We regularly update libRoadRunner binary distributions for Mac OS X,\nLinux and Windows and license them under Apache License Version 2.0.\nhttp://www.libroadrunner.org provides online documentation, full build\ninstructions, binaries and a git source repository.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2015 20:40:39 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Somogyi", "Endre T.", ""], ["Bouteiller", "Jean-Marie", ""], ["Glazier", "James A.", ""], ["K\u00f6nig", "Matthias", ""], ["Medley", "Kyle", ""], ["Swat", "Maciej H.", ""], ["Sauro", "Herbert M.", ""]]}, {"id": "1503.04099", "submitter": "Jonathan Spreer", "authors": "Benjamin A. Burton, Cl\\'ement Maria, Jonathan Spreer", "title": "Algorithms and complexity for Turaev-Viro invariants", "comments": "17 pages, 5 figures", "journal-ref": "Journal of Applied and Computational Topology, 2018", "doi": "10.1007/s41468-018-0016-2", "report-no": null, "categories": "math.GT cs.CC cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Turaev-Viro invariants are a powerful family of topological invariants\nfor distinguishing between different 3-manifolds. They are invaluable for\nmathematical software, but current algorithms to compute them require\nexponential time.\n  The invariants are parameterised by an integer $r \\geq 3$. We resolve the\nquestion of complexity for $r=3$ and $r=4$, giving simple proofs that computing\nTuraev-Viro invariants for $r=3$ is polynomial time, but for $r=4$ is \\#P-hard.\nMoreover, we give an explicit fixed-parameter tractable algorithm for arbitrary\n$r$, and show through concrete implementation and experimentation that this\nalgorithm is practical---and indeed preferable---to the prior state of the art\nfor real computation.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2015 15:21:06 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Burton", "Benjamin A.", ""], ["Maria", "Cl\u00e9ment", ""], ["Spreer", "Jonathan", ""]]}, {"id": "1503.04501", "submitter": "Shigeo Kawata", "authors": "Shigeo Kawata", "title": "Computer Assisted Parallel Program Generation", "comments": "10 pages and 8 figures. Prepared for a book entitled \"Encyclopedia of\n  Information Science and Technology\", IGI global", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel computation is widely employed in scientific researches, engineering\nactivities and product development. Parallel program writing itself is not\nalways a simple task depending on problems solved. Large-scale scientific\ncomputing, huge data analyses and precise visualizations, for example, would\nrequire parallel computations, and the parallel computing needs the\nparallelization techniques. In this Chapter a parallel program generation\nsupport is discussed, and a computer-assisted parallel program generation\nsystem P-NCAS is introduced. Computer assisted problem solving is one of key\nmethods to promote innovations in science and engineering, and contributes to\nenrich our society and our life toward a programming-free environment in\ncomputing science. Problem solving environments (PSE) research activities had\nstarted to enhance the programming power in 1970's. The P-NCAS is one of the\nPSEs; The PSE concept provides an integrated human-friendly computational\nsoftware and hardware system to solve a target class of problems\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2015 02:07:50 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Kawata", "Shigeo", ""]]}, {"id": "1503.04955", "submitter": "Christoph L\\\"uders", "authors": "Christoph L\\\"uders", "title": "Fast Multiplication of Large Integers: Implementation and Analysis of\n  the DKSS Algorithm", "comments": "Diploma Thesis, Universit\\\"at Bonn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sch\\\"onhage-Strassen algorithm (SSA) is the de-facto standard for\nmultiplication of large integers. For $N$-bit numbers it has a time bound of\n$O(N \\cdot \\log N \\cdot \\log \\log N)$. De, Kurur, Saha and Saptharishi (DKSS)\npresented an asymptotically faster algorithm with a better time bound of $N\n\\cdot \\log N \\cdot 2^{O(\\log^* N)}$. In this diploma thesis, results of an\nimplementation of DKSS multiplication are presented: run-time is about 30 times\nlarger than SSA, while memory requirements are about 3.75 times higher than\nSSA. A possible crossover point is estimated to be out of reach even if we\nutilized the whole universe for computer memory.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 09:03:34 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["L\u00fcders", "Christoph", ""]]}, {"id": "1503.05032", "submitter": "Weifeng Liu", "authors": "Weifeng Liu, Brian Vinter", "title": "CSR5: An Efficient Storage Format for Cross-Platform Sparse\n  Matrix-Vector Multiplication", "comments": "12 pages, 10 figures, In Proceedings of the 29th ACM International\n  Conference on Supercomputing (ICS '15)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (SpMV) is a fundamental building block\nfor numerous applications. In this paper, we propose CSR5 (Compressed Sparse\nRow 5), a new storage format, which offers high-throughput SpMV on various\nplatforms including CPUs, GPUs and Xeon Phi. First, the CSR5 format is\ninsensitive to the sparsity structure of the input matrix. Thus the single\nformat can support an SpMV algorithm that is efficient both for regular\nmatrices and for irregular matrices. Furthermore, we show that the overhead of\nthe format conversion from the CSR to the CSR5 can be as low as the cost of a\nfew SpMV operations. We compare the CSR5-based SpMV algorithm with 11\nstate-of-the-art formats and algorithms on four mainstream processors using 14\nregular and 10 irregular matrices as a benchmark suite. For the 14 regular\nmatrices in the suite, we achieve comparable or better performance over the\nprevious work. For the 10 irregular matrices, the CSR5 obtains average\nperformance improvement of 17.6\\%, 28.5\\%, 173.0\\% and 293.3\\% (up to 213.3\\%,\n153.6\\%, 405.1\\% and 943.3\\%) over the best existing work on dual-socket Intel\nCPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively. For\nreal-world applications such as a solver with only tens of iterations, the CSR5\nformat can be more practical because of its low-overhead for format conversion.\nThe source code of this work is downloadable at\nhttps://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2015 13:18:49 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2015 21:28:03 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Liu", "Weifeng", ""], ["Vinter", "Brian", ""]]}, {"id": "1503.05464", "submitter": "Fran\\c{c}ois-Henry Rouet", "authors": "Fran\\c{c}ois-Henry Rouet, Xiaoye S. Li, Pieter Ghysels, Artem Napov", "title": "A distributed-memory package for dense Hierarchically Semi-Separable\n  matrix computations using randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed-memory library for computations with dense\nstructured matrices. A matrix is considered structured if its off-diagonal\nblocks can be approximated by a rank-deficient matrix with low numerical rank.\nHere, we use Hierarchically Semi-Separable representations (HSS). Such matrices\nappear in many applications, e.g., finite element methods, boundary element\nmethods, etc. Exploiting this structure allows for fast solution of linear\nsystems and/or fast computation of matrix-vector products, which are the two\nmain building blocks of matrix computations. The compression algorithm that we\nuse, that computes the HSS form of an input dense matrix, relies on randomized\nsampling with a novel adaptive sampling mechanism. We discuss the\nparallelization of this algorithm and also present the parallelization of\nstructured matrix-vector product, structured factorization and solution\nroutines. The efficiency of the approach is demonstrated on large problems from\ndifferent academic and industrial applications, on up to 8,000 cores.\n  This work is part of a more global effort, the STRUMPACK (STRUctured Matrices\nPACKage) software package for computations with sparse and dense structured\nmatrices. Hence, although useful on their own right, the routines also\nrepresent a step in the direction of a distributed-memory sparse solver.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2015 16:01:25 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2015 18:59:36 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Rouet", "Fran\u00e7ois-Henry", ""], ["Li", "Xiaoye S.", ""], ["Ghysels", "Pieter", ""], ["Napov", "Artem", ""]]}, {"id": "1503.05743", "submitter": "Ken Miura", "authors": "Ken Miura and Tatsuya Harada", "title": "Implementation of a Practical Distributed Calculation System with\n  Browsers and JavaScript, and Application to Distributed Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.MS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning can achieve outstanding results in various fields. However, it\nrequires so significant computational power that graphics processing units\n(GPUs) and/or numerous computers are often required for the practical\napplication. We have developed a new distributed calculation framework called\n\"Sashimi\" that allows any computer to be used as a distribution node only by\naccessing a website. We have also developed a new JavaScript neural network\nframework called \"Sukiyaki\" that uses general purpose GPUs with web browsers.\nSukiyaki performs 30 times faster than a conventional JavaScript library for\ndeep convolutional neural networks (deep CNNs) learning. The combination of\nSashimi and Sukiyaki, as well as new distribution algorithms, demonstrates the\ndistributed deep learning of deep CNNs only with web browsers on various\ndevices. The libraries that comprise the proposed methods are available under\nMIT license at http://mil-tokyo.github.io/.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2015 12:41:29 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Miura", "Ken", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1503.06182", "submitter": "Walter T. Giele", "authors": "John M. Campbell, R. Keith Ellis, Walter T. Giele", "title": "A Multi-Threaded Version of MCFM", "comments": "7 pages, 3 figures, MCFM-7.0 which runs under the OpenMP protocol as\n  described in this paper can be downloaded from http://mcfm.fnal.gov", "journal-ref": null, "doi": null, "report-no": "Fermilab-PUB-15-043-T", "categories": "physics.comp-ph cs.DC cs.MS hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on our findings modifying MCFM using OpenMP to implement\nmulti-threading. By using OpenMP, the modified MCFM will execute on any\nprocessor, automatically adjusting to the number of available threads. We\nmodified the integration routine VEGAS to distribute the event evaluation over\nthe threads, while combining all events at the end of every iteration to\noptimize the numerical integration. Special care has been taken that the\nresults of the Monte Carlo integration are independent of the number of threads\nused, to facilitate the validation of the OpenMP version of MCFM.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2015 18:02:33 GMT"}], "update_date": "2015-03-23", "authors_parsed": [["Campbell", "John M.", ""], ["Ellis", "R. Keith", ""], ["Giele", "Walter T.", ""]]}, {"id": "1503.06544", "submitter": "Sou-Cheng Choi", "authors": "Sou-Cheng T. Choi and Yuhan Ding and Fred J. Hickernell and Lan Jiang\n  and Llu\\'is Antoni Jim\\'enez Rugama and Xin Tong and Yizhi Zhang and Xuan\n  Zhou", "title": "GAIL---Guaranteed Automatic Integration Library in MATLAB: Documentation\n  for Version 2.1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic and adaptive approximation, optimization, or integration of\nfunctions in a cone with guarantee of accuracy is a relatively new paradigm.\nOur purpose is to create an open-source MATLAB package, Guaranteed Automatic\nIntegration Library (GAIL), following the philosophy of reproducible research\nand sustainable practices of robust scientific software development. For our\nconviction that true scholarship in computational sciences are characterized by\nreliable reproducibility, we employ the best practices in mathematical research\nand software engineering known to us and available in MATLAB. This document\ndescribes the key features of functions in GAIL, which includes one-dimensional\nfunction approximation and minimization using linear splines, one-dimensional\nnumerical integration using trapezoidal rule, and last but not least, mean\nestimation and multidimensional integration by Monte Carlo methods or Quasi\nMonte Carlo methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2015 07:45:09 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2015 00:53:39 GMT"}], "update_date": "2015-03-25", "authors_parsed": [["Choi", "Sou-Cheng T.", ""], ["Ding", "Yuhan", ""], ["Hickernell", "Fred J.", ""], ["Jiang", "Lan", ""], ["Rugama", "Llu\u00eds Antoni Jim\u00e9nez", ""], ["Tong", "Xin", ""], ["Zhang", "Yizhi", ""], ["Zhou", "Xuan", ""]]}, {"id": "1503.07659", "submitter": "Andreas Kl\\\"ockner", "authors": "Andreas Kl\\\"ockner", "title": "Loo.py: From Fortran to performance via transformation and substitution\n  rules", "comments": "ARRAY 2015 - 2nd ACM SIGPLAN International Workshop on Libraries,\n  Languages and Compilers for Array Programming (ARRAY 2015)", "journal-ref": null, "doi": "10.1145/2774959.2774969", "report-no": null, "categories": "cs.PL cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large amount of numerically-oriented code is written and is being written\nin legacy languages. Much of this code could, in principle, make good use of\ndata-parallel throughput-oriented computer architectures. Loo.py, a\ntransformation-based programming system targeted at GPUs and general\ndata-parallel architectures, provides a mechanism for user-controlled\ntransformation of array programs. This transformation capability is designed to\nnot just apply to programs written specifically for Loo.py, but also those\nimported from other languages such as Fortran. It eases the trade-off between\nachieving high performance, portability, and programmability by allowing the\nuser to apply a large and growing family of transformations to an input\nprogram. These transformations are expressed in and used from Python and may be\napplied from a variety of settings, including a pragma-like manner from other\nlanguages.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2015 09:40:56 GMT"}, {"version": "v2", "created": "Sat, 16 May 2015 08:14:18 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Kl\u00f6ckner", "Andreas", ""]]}, {"id": "1503.08376", "submitter": "Alexei Botchkarev", "authors": "Alexei Botchkarev", "title": "Assessing Excel VBA Suitability for Monte Carlo Simulation", "comments": null, "journal-ref": "Spreadsheets in Education (eJSiE): 2015, Vol. 8: Iss. 2, Article 3", "doi": null, "report-no": null, "categories": "cs.MS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo (MC) simulation includes a wide range of stochastic techniques\nused to quantitatively evaluate the behavior of complex systems or processes.\nMicrosoft Excel spreadsheets with Visual Basic for Applications (VBA) software\nis, arguably, the most commonly employed general purpose tool for MC\nsimulation. Despite the popularity of the Excel in many industries and\neducational institutions, it has been repeatedly criticized for its flaws and\noften described as questionable, if not completely unsuitable, for statistical\nproblems. The purpose of this study is to assess suitability of the Excel\n(specifically its 2010 and 2013 versions) with VBA programming as a tool for MC\nsimulation. The results of the study indicate that Microsoft Excel (versions\n2010 and 2013) is a strong Monte Carlo simulation application offering a solid\nframework of core simulation components including spreadsheets for data input\nand output, VBA development environment and summary statistics functions. This\nframework should be complemented with an external high-quality pseudo-random\nnumber generator added as a VBA module. A large and diverse category of Excel\nincidental simulation components that includes statistical distributions,\nlinear and non-linear regression and other statistical, engineering and\nbusiness functions require execution of due diligence to determine their\nsuitability for a specific MC project.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2015 01:51:49 GMT"}], "update_date": "2015-07-22", "authors_parsed": [["Botchkarev", "Alexei", ""]]}]