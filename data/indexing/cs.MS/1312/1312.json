[{"id": "1312.0455", "submitter": "Olga Kupriianova", "authors": "O. Kupriianova, Ch. Lauter, J.-M. Muller", "title": "Radix Conversion for IEEE754-2008 Mixed Radix Floating-Point Arithmetic", "comments": null, "journal-ref": null, "doi": "10.1109/ACSSC.2013.6810471", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversion between binary and decimal floating-point representations is\nubiquitous. Floating-point radix conversion means converting both the exponent\nand the mantissa. We develop an atomic operation for FP radix conversion with\nsimple straight-line algorithm, suitable for hardware design. Exponent\nconversion is performed with a small multiplication and a lookup table. It\nyields the correct result without error. Mantissa conversion uses a few\nmultiplications and a small lookup table that is shared amongst all types of\nconversions. The accuracy changes by adjusting the computing precision.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2013 13:47:14 GMT"}], "update_date": "2014-07-21", "authors_parsed": [["Kupriianova", "O.", ""], ["Lauter", "Ch.", ""], ["Muller", "J. -M.", ""]]}, {"id": "1312.2266", "submitter": "Timo Heister", "authors": "Wolfgang Bangerth, Timo Heister, Luca Heltai, Guido Kanschat, Martin\n  Kronbichler, Matthias Maier, Bruno Turcksin, Toby D. Young", "title": "The deal.II Library, Version 8.1", "comments": "v4: for deal.II version 8.1 v3: minor fixes. v2: correct the citation\n  inside the article", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an overview of the new features of the finite element\nlibrary deal.II version 8.1.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2013 21:31:14 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2013 19:25:04 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2013 10:00:08 GMT"}, {"version": "v4", "created": "Tue, 31 Dec 2013 12:47:20 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Bangerth", "Wolfgang", ""], ["Heister", "Timo", ""], ["Heltai", "Luca", ""], ["Kanschat", "Guido", ""], ["Kronbichler", "Martin", ""], ["Maier", "Matthias", ""], ["Turcksin", "Bruno", ""], ["Young", "Toby D.", ""]]}, {"id": "1312.2674", "submitter": "Austin Benson", "authors": "Austin R. Benson, Sven Schmit, Robert Schreiber", "title": "Silent error detection in numerical time-stepping schemes", "comments": null, "journal-ref": "The International Journal of High Performance Computing\n  Applications, 29(4), 2015", "doi": "10.1177/1094342014532297", "report-no": null, "categories": "cs.NA cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Errors due to hardware or low level software problems, if detected, can be\nfixed by various schemes, such as recomputation from a checkpoint. Silent\nerrors are errors in application state that have escaped low-level error\ndetection. At extreme scale, where machines can perform astronomically many\noperations per second, silent errors threaten the validity of computed results.\n  We propose a new paradigm for detecting silent errors at the application\nlevel. Our central idea is to frequently compare computed values to those\nprovided by a cheap checking computation, and to build error detectors based on\nthe difference between the two output sequences. Numerical analysis provides us\nwith usable checking computations for the solution of initial-value problems in\nODEs and PDEs, arguably the most common problems in computational science.\nHere, we provide, optimize, and test methods based on Runge-Kutta and linear\nmultistep methods for ODEs, and on implicit and explicit finite difference\nschemes for PDEs. We take the heat equation and Navier-Stokes equations as\nexamples. In tests with artificially injected errors, this approach effectively\ndetects almost all meaningful errors, without significant slowdown.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 05:31:23 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Benson", "Austin R.", ""], ["Schmit", "Sven", ""], ["Schreiber", "Robert", ""]]}, {"id": "1312.2873", "submitter": "Vissarion Fisikopoulos", "authors": "Ioannis Z. Emiris, Vissarion Fisikopoulos", "title": "Efficient Random-Walk Methods for Approximating Polytope Volume", "comments": "15 pages, 2 figures, 8 tables, in Proc. of SoCG'14", "journal-ref": "ACM Transactions on Mathematical Software 2018", "doi": "10.1145/3194656", "report-no": null, "categories": "cs.CG cs.MS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We experimentally study the fundamental problem of computing the volume of a\nconvex polytope given as an intersection of linear inequalities. We implement\nand evaluate practical randomized algorithms for accurately approximating the\npolytope's volume in high dimensions (e.g. one hundred). To carry out this\nefficiently we experimentally correlate the effect of parameters, such as\nrandom walk length and number of sample points, on accuracy and runtime.\nMoreover, we exploit the problem's geometry by implementing an iterative\nrounding procedure, computing partial generations of random points and\ndesigning fast polytope boundary oracles. Our publicly available code is\nsignificantly faster than exact computation and more accurate than existing\napproximation methods. We provide volume approximations for the Birkhoff\npolytopes B_11,...,B_15, whereas exact methods have only computed that of B_10.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 16:58:04 GMT"}, {"version": "v2", "created": "Sat, 29 Mar 2014 11:37:07 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Emiris", "Ioannis Z.", ""], ["Fisikopoulos", "Vissarion", ""]]}, {"id": "1312.3020", "submitter": "Huasha Zhao Mr", "authors": "Huasha Zhao, John Canny", "title": "Sparse Allreduce: Efficient Scalable Communication for Power-Law Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many large datasets exhibit power-law statistics: The web graph, social\nnetworks, text data, click through data etc. Their adjacency graphs are termed\nnatural graphs, and are known to be difficult to partition. As a consequence\nmost distributed algorithms on these graphs are communication intensive. Many\nalgorithms on natural graphs involve an Allreduce: a sum or average of\npartitioned data which is then shared back to the cluster nodes. Examples\ninclude PageRank, spectral partitioning, and many machine learning algorithms\nincluding regression, factor (topic) models, and clustering. In this paper we\ndescribe an efficient and scalable Allreduce primitive for power-law data. We\npoint out scaling problems with existing butterfly and round-robin networks for\nSparse Allreduce, and show that a hybrid approach improves on both.\nFurthermore, we show that Sparse Allreduce stages should be nested instead of\ncascaded (as in the dense case). And that the optimum throughput Allreduce\nnetwork should be a butterfly of heterogeneous degree where degree decreases\nwith depth into the network. Finally, a simple replication scheme is introduced\nto deal with node failures. We present experiments showing significant\nimprovements over existing systems such as PowerGraph and Hadoop.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 02:33:45 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Zhao", "Huasha", ""], ["Canny", "John", ""]]}, {"id": "1312.3270", "submitter": "Juan L. Varona", "authors": "Antonio J. Dur\\'an, Mario P\\'erez, Juan L. Varona", "title": "Misfortunes of a mathematicians' trio using Computer Algebra Systems:\n  Can we trust?", "comments": "4 pages", "journal-ref": "Notices Amer. Math. Soc. 61 (2014), 1249-1252", "doi": null, "report-no": null, "categories": "cs.SC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer algebra systems are a great help for mathematical research but\nsometimes unexpected errors in the software can also badly affect it. As an\nexample, we show how we have detected an error of Mathematica computing\ndeterminants of matrices of integer numbers: not only it computes the\ndeterminants wrongly, but also it produces different results if one evaluates\nthe same determinant twice.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 18:25:46 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2013 00:02:00 GMT"}], "update_date": "2016-08-26", "authors_parsed": [["Dur\u00e1n", "Antonio J.", ""], ["P\u00e9rez", "Mario", ""], ["Varona", "Juan L.", ""]]}, {"id": "1312.6182", "submitter": "Weifeng Liu", "authors": "W. Liu, H. Zhang, D. Tao, Y. Wang, K. Lu", "title": "Large-Scale Paralleled Sparse Principal Component Analysis", "comments": "submitted to Multimedia Tools and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a statistical technique commonly used\nin multivariate data analysis. However, PCA can be difficult to interpret and\nexplain since the principal components (PCs) are linear combinations of the\noriginal variables. Sparse PCA (SPCA) aims to balance statistical fidelity and\ninterpretability by approximating sparse PCs whose projections capture the\nmaximal variance of original data. In this paper we present an efficient and\nparalleled method of SPCA using graphics processing units (GPUs), which can\nprocess large blocks of data in parallel. Specifically, we construct parallel\nimplementations of the four optimization formulations of the generalized power\nmethod of SPCA (GP-SPCA), one of the most efficient and effective SPCA\napproaches, on a GPU. The parallel GPU implementation of GP-SPCA (using CUBLAS)\nis up to eleven times faster than the corresponding CPU implementation (using\nCBLAS), and up to 107 times faster than a MatLab implementation. Extensive\ncomparative experiments in several real-world datasets confirm that SPCA offers\na practical advantage.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 00:38:02 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Liu", "W.", ""], ["Zhang", "H.", ""], ["Tao", "D.", ""], ["Wang", "Y.", ""], ["Lu", "K.", ""]]}, {"id": "1312.6488", "submitter": "Zheng Li", "authors": "Zheng Li and Liam O'Brien and Rajiv Ranjan and Miranda Zhang", "title": "Early Observations on Performance of Google Compute Engine for\n  Scientific Computing", "comments": "Proceedings of the 5th International Conference on Cloud Computing\n  Technologies and Science (CloudCom 2013), pp. 1-8, Bristol, UK, December 2-5,\n  2013", "journal-ref": null, "doi": "10.1109/CloudCom.2013.7", "report-no": null, "categories": "cs.DC cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Cloud computing emerged for business applications in industry,\npublic Cloud services have been widely accepted and encouraged for scientific\ncomputing in academia. The recently available Google Compute Engine (GCE) is\nclaimed to support high-performance and computationally intensive tasks, while\nlittle evaluation studies can be found to reveal GCE's scientific capabilities.\nConsidering that fundamental performance benchmarking is the strategy of\nearly-stage evaluation of new Cloud services, we followed the Cloud Evaluation\nExperiment Methodology (CEEM) to benchmark GCE and also compare it with Amazon\nEC2, to help understand the elementary capability of GCE for dealing with\nscientific problems. The experimental results and analyses show both potential\nadvantages of, and possible threats to applying GCE to scientific computing.\nFor example, compared to Amazon's EC2 service, GCE may better suit applications\nthat require frequent disk operations, while it may not be ready yet for single\nVM-based parallel computing. Following the same evaluation methodology,\ndifferent evaluators can replicate and/or supplement this fundamental\nevaluation of GCE. Based on the fundamental evaluation results, suitable GCE\nenvironments can be further established for case studies of solving real\nscience problems.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 09:12:09 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Li", "Zheng", ""], ["O'Brien", "Liam", ""], ["Ranjan", "Rajiv", ""], ["Zhang", "Miranda", ""]]}]