[{"id": "1910.00279", "submitter": "Richard Gerum", "authors": "Richard Gerum", "title": "pylustrator: Code generation for reproducible figures for publication", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": "10.21105/joss.01989", "report-no": null, "categories": "cs.GR cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One major challenge in science is to make all results potentially\nreproducible. Thus, along with the raw data, every step from basic processing\nof the data, evaluation, to the generation of the figures, has to be documented\nas clearly as possible. While there are many programming libraries that cover\nthe basic processing and plotting steps (e.g. Matplotlib in Python), no library\nyet addresses the reproducible composing of single plots into meaningful\nfigures for publication. Thus, up to now it is still state-of-the-art to\ngenerate publishable figures using image-processing or vector-drawing software\nleading to unwanted alterations of the presented data in the worst case and to\nfigure quality reduction in the best case. Pylustrator a open source library\nbased on the Matplotlib aims to fill this gap and provides a tool to easily\ngenerate the code necessary to compose publication figures from single plots.\nIt provides a graphical user interface where the user can interactively compose\nthe figures. All changes are tracked and converted to code that is\nautomatically integrated into the calling script file. Thus, this software\nprovides the missing link from raw data to the complete plot published in\nscientific journals and thus contributes to the transparency of the complete\nevaluation procedure.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 09:46:46 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 11:22:30 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Gerum", "Richard", ""]]}, {"id": "1910.01412", "submitter": "Francesc Verdugo Phd", "authors": "Francesc Verdugo and Santiago Badia", "title": "A user-guide to Gridap -- grid-based approximation of partial\n  differential equations in Julia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Gridap, a new scientific software library for the numerical\napproximation of partial differential equations (PDEs) using grid-based\napproximations. Gridap is an open-source software project exclusively written\nin the Julia programming language. The main motivation behind the development\nof this library is to provide an easy-to-use framework for the development of\ncomplex PDE solvers in a dynamically typed style without sacrificing the\nperformance of statically typed languages. This work is a tutorial-driven user\nguide to the library. It covers some popular linear and nonlinear PDE systems\nfor scalar and vector fields, single and multi-field problems, conforming and\nnonconforming finite element discretizations, on structured and unstructured\nmeshes of simplices and hexahedra.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 11:42:32 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 12:19:57 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Verdugo", "Francesc", ""], ["Badia", "Santiago", ""]]}, {"id": "1910.01972", "submitter": "Karel Ad\\'amek", "authors": "Karel Ad\\'amek, Sofia Dimoudi, Mike Giles, Wesley Armour", "title": "GPU Fast Convolution via the Overlap-and-Save Method in Shared Memory", "comments": "accepted to ACM TACO", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an implementation of the overlap-and-save method, a method for the\nconvolution of very long signals with short response functions, which is\ntailored to GPUs. We have implemented several FFT algorithms (using the CUDA\nprogramming language) which exploit GPU shared memory, allowing for GPU\naccelerated convolution. We compare our implementation with an implementation\nof the overlap-and-save algorithm utilizing the NVIDIA FFT library (cuFFT). We\ndemonstrate that by using a shared memory based FFT we can achieved significant\nspeed-ups for certain problem sizes and lower the memory requirements of the\noverlap-and-save method on GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 14:41:10 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 15:04:13 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Ad\u00e1mek", "Karel", ""], ["Dimoudi", "Sofia", ""], ["Giles", "Mike", ""], ["Armour", "Wesley", ""]]}, {"id": "1910.02371", "submitter": "Edgar Solomonik", "authors": "Navjot Singh, Zecheng Zhang, Xiaoxiao Wu, Naijing Zhang, Siyuan Zhang,\n  and Edgar Solomonik", "title": "Distributed-Memory Tensor Completion for Generalized Loss Functions in\n  Python using New Sparse Tensor Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor computations are increasingly prevalent numerical techniques in data\nscience, but pose unique challenges for high-performance implementation. We\nprovide novel algorithms and systems infrastructure which enable efficient\nparallel implementation of algorithms for tensor completion with generalized\nloss functions. Specifically, we consider alternating minimization, coordinate\nminimization, and a quasi-Newton (generalized Gauss-Newton) method. By\nextending the Cyclops library, we implement all of these methods in high-level\nPython syntax. To make possible tensor completion for very sparse tensors, we\nintroduce new multi-tensor primitives, for which we provide specialized\nparallel implementations. We compare these routines to pairwise contraction of\nsparse tensors by reduction to hypersparse matrix formats, and find that the\nmulti-tensor routines are more efficient in theoretical cost and execution time\nin experiments. We provide microbenchmarking results on the Stampede2\nsupercomputer to demonstrate the efficiency of the new primitives and Cyclops\nfunctionality. We then study the performance of the tensor completion methods\nfor a synthetic tensor with 10 billion nonzeros and the Netflix dataset,\nconsidering both least squares and Poisson loss functions.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 04:48:05 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 05:36:52 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 22:31:55 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Singh", "Navjot", ""], ["Zhang", "Zecheng", ""], ["Wu", "Xiaoxiao", ""], ["Zhang", "Naijing", ""], ["Zhang", "Siyuan", ""], ["Solomonik", "Edgar", ""]]}, {"id": "1910.02749", "submitter": "Jonas Schmitt", "authors": "Jonas Schmitt, Sebastian Kuckuk, Harald K\\\"ostler", "title": "Optimizing Geometric Multigrid Methods with Evolutionary Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many linear and nonlinear systems that arise from the discretization of\npartial differential equations the construction of an efficient multigrid\nsolver is a challenging task. Here we present a novel approach for the\noptimization of geometric multigrid methods that is based on evolutionary\ncomputation, a generic program optimization technique inspired by the principle\nof natural evolution. A multigrid solver is represented as a tree of\nmathematical expressions which we generate based on a tailored grammar. The\nquality of each solver is evaluated in terms of convergence and compute\nperformance using automated local Fourier analysis (LFA) and roofline\nperformance modeling, respectively. Based on these objectives a multi-objective\noptimization is performed using strongly typed genetic programming with a\nnon-dominated sorting based selection. To evaluate the model-based prediction\nand to target concrete applications, scalable implementations of an evolved\nsolver can be automatically generated with the ExaStencils framework. We\ndemonstrate our approach by constructing multigrid solvers for the steady-state\nheat equation with constant and variable coefficients that consistently perform\nbetter than common V- and W-cycles.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:23:28 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 08:44:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Schmitt", "Jonas", ""], ["Kuckuk", "Sebastian", ""], ["K\u00f6stler", "Harald", ""]]}, {"id": "1910.04796", "submitter": "Alfio Lazzaro", "authors": "Ilia Sivkov, Alfio Lazzaro, Juerg Hutter", "title": "DBCSR: A Library for Dense Matrix Multiplications on Distributed\n  GPU-Accelerated Systems", "comments": "5 pages, 4 figures, proceeding of the 2019 International\n  Multi-Conference on Engineering, Computer and Information Sciences (SIBIRCON)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most, if not all the modern scientific simulation packages utilize matrix\nalgebra operations. Among the operation of the linear algebra, one of the most\nimportant kernels is the multiplication of matrices, dense and sparse. Examples\nof application of such a kernel are in electronic structure calculations,\nmachine learning, data mining, graph processing, and digital signal processing.\nSeveral optimized libraries exist that can achieve high-performance on\ndistributed systems. Only a few of them target distributed GPU-accelerated\nsystems. In most of the cases, these libraries are provided and optimized by\nsystem vendors for their specific computer systems. In this paper, we present\nthe DBCSR library (Distributed Block Compressed Sparse Row) for the distributed\ndense matrix-matrix multiplications. Although the library is specifically\ndesigned for block-sparse matrix-matrix multiplications, we optimized it for\nthe dense case on GPU-accelerated systems. We show that the DBCSR outperforms\nthe multiplication of matrices of different sizes and shapes provided by a\nvendor optimized GPU version of the ScaLAPACK library up to 2.5x (1.4x on\naverage).\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 18:23:26 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Sivkov", "Ilia", ""], ["Lazzaro", "Alfio", ""], ["Hutter", "Juerg", ""]]}, {"id": "1910.04891", "submitter": "Eike Neumann", "authors": "Michal Kone\\v{c}n\\'y and Eike Neumann", "title": "Implementing evaluation strategies for continuous real functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a technical overview of our exact-real implementation of various\nrepresentations of the space of continuous unary real functions over the unit\ndomain and a family of associated (partial) operations, including integration,\nrange computation, as well as pointwise addition, multiplication, division,\nsine, cosine, square root and maximisation.\n  We use several representations close to the usual theoretical model, based on\nan oracle that evaluates the function at a point or over an interval. We also\ninclude several representations based on an oracle that computes a converging\nsequence of rigorous (piecewise or one-piece) polynomial and rational\napproximations over the whole unit domain. Finally, we describe \"local\"\nrepresentations that combine both approaches, i.e. oracle-like representations\nthat return a rigorous symbolic approximation of the function over a requested\ninterval sub-domain with a requested effort.\n  See also our paper \"Representations and evaluation strategies for feasibly\napproximable functions\" which compares the efficiency of these representations\nand algorithms and also formally describes and analyses one of the key\nalgorithms, namely a polynomial-time division of functions in a\npiecewise-polynomial representation. We do not reproduce this division\nalgorithm here.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 22:05:52 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Kone\u010dn\u00fd", "Michal", ""], ["Neumann", "Eike", ""]]}, {"id": "1910.05623", "submitter": "Zvonimir Bujanovi\\'c", "authors": "Zvonimir Bujanovi\\'c, Zlatko Drma\\v{c}", "title": "New robust ScaLAPACK routine for computing the QR factorization with\n  column pivoting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we describe two modifications of the ScaLAPACK subroutines\nPxGEQPF for computing the QR factorization with the Businger-Golub column\npivoting. First, we resolve a subtle numerical instability in the same way as\nwe have done it for the LAPACK subroutines xGEQPF, xGEQP3 in 2006. [LAPACK\nWorking Note 176 (2006); ACM Trans. Math. Softw. 2008]. The problem originates\nin the first release of LINPACK in the 1970's: due to severe cancellations in\nthe down-dating of partial column norms, the pivoting procedure may be in the\ndark completely about the true norms of the pivot column candidates. This may\ncause miss-pivoting, and as a result loss of the important rank revealing\nstructure of the computed triangular factor, with severe consequences on other\nsolvers that rely on the rank revealing pivoting. The instability is so subtle\nthat, e.g., inserting a WRITE statement or changing the process topology can\ndrastically change the result. Secondly, we also correct a programming error in\nthe complex subroutines PCGEQPF, PZGEQPF, which also causes wrong pivoting\nbecause of erroneous use of PSCNRM2, PDZNRM2 for the explicit norm computation.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 18:43:25 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Bujanovi\u0107", "Zvonimir", ""], ["Drma\u010d", "Zlatko", ""]]}, {"id": "1910.06117", "submitter": "Erivelton Geraldo Nepomuceno", "authors": "P. F. S. Guedes, E. G. Nepomuceno", "title": "Some remarks on the performance of Matlab, Python and Octave in\n  simulating dynamical systems", "comments": "SBAI 2019 - Simposio Brasileiro de Automacao Inteligente - Ouro\n  Preto. 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matlab has been considered as a leader computational platform for many\nengineering fields. Well documented and reliable, Matlab presents as a great\nadvantage its ability to increase the user productivity. However, Python and\nOctave are among some of the languages that have challenged Matlab. Octave and\nPython are well known examples of high-level scripting languages, with a great\nadvantage of being open source software. The novelty of this paper is devoted\nto offer a comparison among these tree languages in the simulation of dynamical\nsystems. We have applied the lower bound error to estimate the error of\nsimulation. The comparison was performed with the chaotic systems Duffing-Ueda\noscillator and the Chua's circuit, both identified with polynomial NARMAX.\nOctave presents the best reliable outcome. Nevertheless, Matlab needs the\nlowest time to undertake the same activity. Python has presented the worse\nresult for the stop simulation criterion.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 12:59:45 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Guedes", "P. F. S.", ""], ["Nepomuceno", "E. G.", ""]]}, {"id": "1910.10641", "submitter": "Johannes Holke", "authors": "Johannes Holke and David Knapp and Carsten Burstedde", "title": "An Optimized, Parallel Computation of the Ghost Layer for Adaptive\n  Hybrid Forest Meshes", "comments": "33 pages, 12 figures, 13 tables. arXiv admin note: substantial text\n  overlap with arXiv:1803.04970", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss parallel algorithms to gather topological information about\noff-process mesh neighbor elements. This information is commonly called the\nghost layer, whose creation is a fundamental, necessary task in executing most\nparallel, element-based computer simulations. Approaches differ in that the\nghost layer may either be inherently part of the mesh data structure that is\nmaintained and modified, or kept separate and constructed/deleted as needed.\n  In this work, we present an updated design following the latter approach,\nwhich we favor for its modularity of algorithms and data structures. We target\narbitrary adaptive, non-conforming forest-of-(oc)trees meshes of mixed element\nshapes, such as cubes, prisms, and tetrahedra, and restrict ourselves to\nface-ghosts. Our algorithm has low complexity and redundancy since we reduce it\nto generic codimension-1 subalgorithms that can be flexibly combined. We cover\nseveral existing solutions as special cases and optimize further using\nrecursive, amortized tree searches and traversals.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 11:54:16 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Holke", "Johannes", ""], ["Knapp", "David", ""], ["Burstedde", "Carsten", ""]]}, {"id": "1910.11712", "submitter": "Jose E. Roman", "authors": "Carmen Campos, Jose E. Roman", "title": "NEP: a module for the parallel solution of nonlinear eigenvalue problems\n  in SLEPc", "comments": null, "journal-ref": "ACM Trans. Math. Software, 47(3), Article 23, 2021", "doi": "10.1145/3447544", "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SLEPc is a parallel library for the solution of various types of large-scale\neigenvalue problems. In the last years we have been developing a module within\nSLEPc, called NEP, that is intended for solving nonlinear eigenvalue problems.\nThese problems can be defined by means of a matrix-valued function that depends\nnonlinearly on a single scalar parameter. We do not consider the particular\ncase of polynomial eigenvalue problems (which are implemented in a different\nmodule in SLEPc) and focus here on rational eigenvalue problems and other\ngeneral nonlinear eigenproblems involving square roots or any other nonlinear\nfunction. The paper discusses how the NEP module has been designed to fit the\nneeds of applications and provides a description of the available solvers,\nincluding some implementation details such as parallelization. Several test\nproblems coming from real applications are used to evaluate the performance and\nreliability of the solvers.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 13:28:04 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 17:43:51 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 16:46:13 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Campos", "Carmen", ""], ["Roman", "Jose E.", ""]]}, {"id": "1910.13247", "submitter": "Luca Heltai", "authors": "Daniel Arndt, Wolfgang Bangerth, Denis Davydov, Timo Heister, Luca\n  Heltai, Martin Kronbichler, Matthias Maier, Jean-Paul Pelteret, Bruno\n  Turcksin, David Wells", "title": "The deal.II finite element library: design, features, and insights", "comments": "36 pages, 3 figures", "journal-ref": "Computers {\\&} Mathematics with Applications, 81: 407--422, 2021", "doi": "10.1016/j.camwa.2020.02.022", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  deal.II is a state-of-the-art finite element library focused on generality,\ndimension-independent programming, parallelism, and extensibility. Herein, we\noutline its primary design considerations and its sophisticated features such\nas distributed meshes, $hp$-adaptivity, support for complex geometries, and\nmatrix-free algorithms. But deal.II is more than just a software library: It is\nalso a diverse and worldwide community of developers and users, as well as an\neducational platform. We therefore also discuss some of the technical and\nsocial challenges and lessons learned in running a large community software\nproject over the course of two decades.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 13:40:13 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 11:06:13 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Arndt", "Daniel", ""], ["Bangerth", "Wolfgang", ""], ["Davydov", "Denis", ""], ["Heister", "Timo", ""], ["Heltai", "Luca", ""], ["Kronbichler", "Martin", ""], ["Maier", "Matthias", ""], ["Pelteret", "Jean-Paul", ""], ["Turcksin", "Bruno", ""], ["Wells", "David", ""]]}, {"id": "1910.13251", "submitter": "S. Weinzierl", "authors": "Marco Besier, Pascal Wasser, Stefan Weinzierl", "title": "RationalizeRoots: Software Package for the Rationalization of Square\n  Roots", "comments": "37 pages, 4 ancillary files, v2: version to be published", "journal-ref": null, "doi": "10.1016/j.cpc.2020.107197", "report-no": null, "categories": "cs.MS cs.SC hep-ph hep-th math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of Feynman integrals often involves square roots. One way to\nobtain a solution in terms of multiple polylogarithms is to rationalize these\nsquare roots by a suitable variable change. We present a program that can be\nused to find such transformations. After an introduction to the theoretical\nbackground, we explain in detail how to use the program in practice.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 18:00:10 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 14:00:11 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Besier", "Marco", ""], ["Wasser", "Pascal", ""], ["Weinzierl", "Stefan", ""]]}]