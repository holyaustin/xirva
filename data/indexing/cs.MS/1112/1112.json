[{"id": "1112.4523", "submitter": "Bjarke Hammersholt Roune", "authors": "Bjarke Hammersholt Roune, Eduardo S\\'aenz de Cabez\\'on", "title": "Complexity and Algorithms for Euler Characteristic of Simplicial\n  Complexes", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CC cs.DS cs.MS cs.SC math.AC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing the Euler characteristic of an abstract\nsimplicial complex given by its vertices and facets. We show that this problem\nis #P-complete and present two new practical algorithms for computing Euler\ncharacteristic. The two new algorithms are derived using combinatorial\ncommutative algebra and we also give a second description of them that requires\nno algebra. We present experiments showing that the two new algorithms can be\nimplemented to be faster than previous Euler characteristic implementations by\na large margin.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 22:51:21 GMT"}], "update_date": "2011-12-21", "authors_parsed": [["Roune", "Bjarke Hammersholt", ""], ["de Cabez\u00f3n", "Eduardo S\u00e1enz", ""]]}, {"id": "1112.5588", "submitter": "Georg Hager", "authors": "Moritz Kreutzer, Georg Hager, Gerhard Wellein, Holger Fehske, Achim\n  Basermann, Alan R. Bishop", "title": "Sparse matrix-vector multiplication on GPGPU clusters: A new storage\n  format and a scalable implementation", "comments": "10 pages, 5 figures. Added reference to other recent sparse matrix\n  formats", "journal-ref": null, "doi": "10.1109/IPDPSW.2012.211", "report-no": null, "categories": "cs.DC cs.MS cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (spMVM) is the dominant operation in many\nsparse solvers. We investigate performance properties of spMVM with matrices of\nvarious sparsity patterns on the nVidia \"Fermi\" class of GPGPUs. A new \"padded\njagged diagonals storage\" (pJDS) format is proposed which may substantially\nreduce the memory overhead intrinsic to the widespread ELLPACK-R scheme. In our\ntest scenarios the pJDS format cuts the overall spMVM memory footprint on the\nGPGPU by up to 70%, and achieves 95% to 130% of the ELLPACK-R performance.\nUsing a suitable performance model we identify performance bottlenecks on the\nnode level that invalidate some types of matrix structures for efficient\nmulti-GPGPU parallelization. For appropriate sparsity patterns we extend\nprevious work on distributed-memory parallel spMVM to demonstrate a scalable\nhybrid MPI-GPGPU code, achieving efficient overlap of communication and\ncomputation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 14:03:56 GMT"}, {"version": "v2", "created": "Wed, 29 Feb 2012 07:40:22 GMT"}], "update_date": "2013-03-08", "authors_parsed": [["Kreutzer", "Moritz", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""], ["Fehske", "Holger", ""], ["Basermann", "Achim", ""], ["Bishop", "Alan R.", ""]]}, {"id": "1112.5717", "submitter": "Cl\\'ement Pernet", "authors": "Claude-Pierre Jeannerod and Cl\\'ement Pernet and Arne Storjohann", "title": "Rank-profile revealing Gaussian elimination and the CUP matrix\n  decomposition", "comments": "35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transforming a matrix over a field to echelon form, or decomposing the matrix\nas a product of structured matrices that reveal the rank profile, is a\nfundamental building block of computational exact linear algebra. This paper\nsurveys the well known variations of such decompositions and transformations\nthat have been proposed in the literature. We present an algorithm to compute\nthe CUP decomposition of a matrix, adapted from the LSP algorithm of Ibarra,\nMoran and Hui (1982), and show reductions from the other most common Gaussian\nelimination based matrix transformations and decompositions to the CUP\ndecomposition. We discuss the advantages of the CUP algorithm over other\nexisting algorithms by studying time and space complexities: the asymptotic\ntime complexity is rank sensitive, and comparing the constants of the leading\nterms, the algorithms for computing matrix invariants based on the CUP\ndecomposition are always at least as good except in one case. We also show that\nthe CUP algorithm, as well as the computation of other invariants such as\ntransformation to reduced column echelon form using the CUP algorithm, all work\nin place, allowing for example to compute the inverse of a matrix on the same\nstorage as the input matrix.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2011 11:30:09 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2012 16:37:59 GMT"}], "update_date": "2012-01-10", "authors_parsed": [["Jeannerod", "Claude-Pierre", ""], ["Pernet", "Cl\u00e9ment", ""], ["Storjohann", "Arne", ""]]}]