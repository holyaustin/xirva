[{"id": "1608.00044", "submitter": "Mathias Jacquelin", "authors": "Mathias Jacquelin, Yili Zheng, Esmond Ng, Katherine Yelick", "title": "An Asynchronous Task-based Fan-Both Sparse Cholesky Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems of linear equations arise at the heart of many scientific and\nengineering applications. Many of these linear systems are sparse; i.e., most\nof the elements in the coefficient matrix are zero. Direct methods based on\nmatrix factorizations are sometimes needed to ensure accurate solutions. For\nexample, accurate solution of sparse linear systems is needed in shift-invert\nLanczos to compute interior eigenvalues. The performance and resource usage of\nsparse matrix factorizations are critical to time-to-solution and maximum\nproblem size solvable on a given platform. In many applications, the\ncoefficient matrices are symmetric, and exploiting symmetry will reduce both\nthe amount of work and storage cost required for factorization. When the\nfactorization is performed on large-scale distributed memory platforms,\ncommunication cost is critical to the performance of the algorithm. At the same\ntime, network topologies have become increasingly complex, so that modern\nplatforms exhibit a high level of performance variability. This makes\nscheduling of computations an intricate and performance-critical task. In this\npaper, we investigate the use of an asynchronous task paradigm, one-sided\ncommunication and dynamic scheduling in implementing sparse Cholesky\nfactorization (symPACK) on large-scale distributed memory platforms. Our solver\nsymPACK relies on efficient and flexible communication primitives provided by\nthe UPC++ library. Performance evaluation shows good scalability and that\nsymPACK outperforms state-of-the-art parallel distributed memory factorization\npackages, validating our approach on practical cases.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2016 22:37:07 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2016 04:04:56 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Jacquelin", "Mathias", ""], ["Zheng", "Yili", ""], ["Ng", "Esmond", ""], ["Yelick", "Katherine", ""]]}, {"id": "1608.00099", "submitter": "Oliver Serang", "authors": "Florian Heyl, Oliver Serang", "title": "TRIOT: Faster tensor manipulation in C++11", "comments": null, "journal-ref": "The Art, Science, and Engineering of Programming, 2017, Vol. 1,\n  Issue 2, Article 6", "doi": "10.22152/programming-journal.org/2017/1/6", "report-no": null, "categories": "cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [abridged] Context: Multidimensional arrays are used by many different\nalgorithms. As such, indexing and broadcasting complex operations over\nmultidimensional arrays are ubiquitous tasks and can be performance limiting.\nInquiry: Simultaneously indexing two or more multidimensional arrays with\ndifferent shapes (e.g., copying data from one tensor to another larger, zero\npadded tensor in anticipation of a convolution) is difficult to do efficiently:\nHard-coded nested for loops in C, Fortran, and Go cannot be applied when the\ndimension of a tensor is unknown at compile time. Likewise, boost::multi_array\ncannot be used unless the dimensions of the array are known at compile time,\nand the style of implementation restricts the user from using the index tuple\ninside a vectorized operation (as would be required to compute an expected\nvalue of a multidimensional distribution). On the other hand, iteration methods\nthat do not require the dimensionality or shape to be known at compile time\n(e.g., incrementing and applying carry operations to index tuples or remapping\ninteger indices in the flat array), can be substantially slower than hard-coded\nnested for loops. ... Importance: Manipulation of multidimensional arrays is a\ncommon task in software, especially in high performance numerical methods. This\npaper proposes a novel way to leverage template recursion to iterate over and\napply operations to multidimensional arrays, and then demonstrates the superior\nperformance and flexibility of operations that can be achieved using this new\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jul 2016 10:40:29 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 22:40:34 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Heyl", "Florian", ""], ["Serang", "Oliver", ""]]}, {"id": "1608.00206", "submitter": "Oliver Serang", "authors": "Oliver Serang", "title": "An exact, cache-localized algorithm for the sub-quadratic convolution of\n  hypercubes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast multidimensional convolution can be performed naively in quadratic time\nand can often be performed more efficiently via the Fourier transform; however,\nwhen the dimensionality is large, these algorithms become more challenging. A\nmethod is proposed for performing exact hypercube convolution in sub-quadratic\ntime. The method outperforms FFTPACK, called via numpy, and FFTW, called via\npyfftw) for hypercube convolution. Embeddings in hypercubes can be paired with\nsub-quadratic hypercube convolution method to construct sub-quadratic\nalgorithms for variants of vector convolution.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jul 2016 10:22:40 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Serang", "Oliver", ""]]}, {"id": "1608.00476", "submitter": "Neeraj Bokde", "authors": "Neeraj Bokde, Kishore Kulat, Marcus W Beck, Gualberto Asencio-Cort\\'es", "title": "R package imputeTestbench to compare imputations methods for univariate\n  time series", "comments": null, "journal-ref": null, "doi": "10.32614/RJ-2018-024", "report-no": null, "categories": "stat.ME cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the R package imputeTestbench that provides a testbench\nfor comparing imputation methods for missing data in univariate time series.\nThe imputeTestbench package can be used to simulate the amount and type of\nmissing data in a complete dataset and compare filled data using different\nimputation methods. The user has the option to simulate missing data by\nremoving observations completely at random or in blocks of different sizes.\nSeveral default imputation methods are included with the package, including\nhistorical means, linear interpolation, and last observation carried forward.\nThe testbench is not limited to the default functions and users can add or\nremove additional methods using a simple two-step process. The testbench\ncompares the actual missing and imputed data for each method with different\nerror metrics, including RMSE, MAE, and MAPE. Alternative error metrics can\nalso be supplied by the user. The simplicity of use and significant reduction\nin time to compare imputation methods for missing data in univariate time\nseries is a significant advantage of the package. This paper provides an\noverview of the core functions, including a demonstration with examples.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2016 15:54:26 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 05:55:32 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Bokde", "Neeraj", ""], ["Kulat", "Kishore", ""], ["Beck", "Marcus W", ""], ["Asencio-Cort\u00e9s", "Gualberto", ""]]}, {"id": "1608.02148", "submitter": "N. Benjamin Erichson", "authors": "N. Benjamin Erichson, Sergey Voronin, Steven L. Brunton, J. Nathan\n  Kutz", "title": "Randomized Matrix Decompositions using R", "comments": null, "journal-ref": "Journal of Statistical Software. May 2019, Volume 89, Issue 11", "doi": "10.18637/jss.v089.i11", "report-no": null, "categories": "stat.CO cs.MS stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix decompositions are fundamental tools in the area of applied\nmathematics, statistical computing, and machine learning. In particular,\nlow-rank matrix decompositions are vital, and widely used for data analysis,\ndimensionality reduction, and data compression. Massive datasets, however, pose\na computational challenge for traditional algorithms, placing significant\nconstraints on both memory and processing power. Recently, the powerful concept\nof randomness has been introduced as a strategy to ease the computational load.\nThe essential idea of probabilistic algorithms is to employ some amount of\nrandomness in order to derive a smaller matrix from a high-dimensional data\nmatrix. The smaller matrix is then used to compute the desired low-rank\napproximation. Such algorithms are shown to be computationally efficient for\napproximating matrices with low-rank structure. We present the \\proglang{R}\npackage rsvd, and provide a tutorial introduction to randomized matrix\ndecompositions. Specifically, randomized routines for the singular value\ndecomposition, (robust) principal component analysis, interpolative\ndecomposition, and CUR decomposition are discussed. Several examples\ndemonstrate the routines, and show the computational advantage over other\nmethods implemented in R.\n", "versions": [{"version": "v1", "created": "Sat, 6 Aug 2016 19:47:48 GMT"}, {"version": "v2", "created": "Sat, 3 Sep 2016 20:03:57 GMT"}, {"version": "v3", "created": "Tue, 3 Oct 2017 23:01:44 GMT"}, {"version": "v4", "created": "Sun, 1 Apr 2018 21:26:59 GMT"}, {"version": "v5", "created": "Tue, 26 Nov 2019 23:33:14 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Erichson", "N. Benjamin", ""], ["Voronin", "Sergey", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1608.04041", "submitter": "Jeremy Kepner", "authors": "Alexander Chen, Alan Edelman, Jeremy Kepner, Vijay Gadepally, Dylan\n  Hutchison", "title": "Julia Implementation of the Dynamic Distributed Dimensional Data Model", "comments": "7 pages, 16 figures, IEEE HPEC 2016", "journal-ref": null, "doi": "10.1109/HPEC.2016.7761626", "report-no": null, "categories": "cs.MS cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Julia is a new language for writing data analysis programs that are easy to\nimplement and run at high performance. Similarly, the Dynamic Distributed\nDimensional Data Model (D4M) aims to clarify data analysis operations while\nretaining strong performance. D4M accomplishes these goals through a\ncomposable, unified data model on associative arrays. In this work, we present\nan implementation of D4M in Julia and describe how it enables and facilitates\ndata analysis. Several experiments showcase scalable performance in our new\nJulia version as compared to the original Matlab implementation.\n", "versions": [{"version": "v1", "created": "Sun, 14 Aug 2016 00:58:41 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Chen", "Alexander", ""], ["Edelman", "Alan", ""], ["Kepner", "Jeremy", ""], ["Gadepally", "Vijay", ""], ["Hutchison", "Dylan", ""]]}, {"id": "1608.04152", "submitter": "Javier Segura", "authors": "A. Gil, D. Ruiz-Antol\\'in, J. Segura, N. M. Temme", "title": "Computation of the incomplete gamma function for negative values of the\n  argument", "comments": "To appear in ACM Trans. Math. Softw", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for computing the incomplete gamma function $\\gamma^*(a,z)$ for\nreal values of the parameter $a$ and negative real values of the argument $z$\nis presented. The algorithm combines the use of series expansions,\nPoincar\\'e-type expansions, uniform asymptotic expansions and recurrence\nrelations, depending on the parameter region. A relative accuracy $\\sim\n10^{-13}$ in the parameter region $(a,z) \\in [-500,\\,500] \\times [-500,\\,0)$\ncan be obtained when computing the function $\\gamma^*(a,z)$ with the Fortran 90\nmodule IncgamNEG implementing the algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 14 Aug 2016 23:17:03 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Gil", "A.", ""], ["Ruiz-Antol\u00edn", "D.", ""], ["Segura", "J.", ""], ["Temme", "N. M.", ""]]}, {"id": "1608.04815", "submitter": "Shaohui Liu", "authors": "Shaohui Liu, Tianshi Wang, Youran Zhang", "title": "A Functional Package for Automatic Solution of Ordinary Differential\n  Equations with Spectral Methods", "comments": "This paper has been withdrawn by the author due to some serious\n  mistakes made in the context since it is for the first time for all the\n  authors to do independent research. Hope that we can fix all the problems\n  soon and come back with some better results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Python module named PyCheb, to solve the ordinary differential\nequations by using spectral collocation method. PyCheb incorporates\ndiscretization using Chebyshev points, barycentric interpolation and iterate\nmethods. With this Python module, users can initialize the ODEsolver class by\npassing attributes, including the both sides of a given differential equation,\nboundary conditions, and the number of Chebyshev points, which can also be\ngenerated automatically by the ideal precision, to the constructor of ODEsolver\nclass. Then, the instance of the ODEsolver class can be used to automatically\ndetermine the resolution of the differential equation as well as generate the\ngraph of the high-precision approximate solution. (If you have any questions,\nplease send me an email and I will reply ASAP.\ne-mail:shaohui_liu@qq.com/2013141482143@stu.scu.edu.cn)\n", "versions": [{"version": "v1", "created": "Wed, 17 Aug 2016 00:06:48 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2016 12:20:40 GMT"}, {"version": "v3", "created": "Fri, 4 Nov 2016 08:20:36 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Liu", "Shaohui", ""], ["Wang", "Tianshi", ""], ["Zhang", "Youran", ""]]}, {"id": "1608.07573", "submitter": "Garth Wells", "authors": "Jack S. Hale, Lizao Li, Chris N. Richardson and Garth N. Wells", "title": "Containers for portable, productive and performant scientific computing", "comments": null, "journal-ref": null, "doi": "10.1109/MCSE.2017.2421459", "report-no": null, "categories": "cs.DC cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Containers are an emerging technology that hold promise for improving\nproductivity and code portability in scientific computing. We examine Linux\ncontainer technology for the distribution of a non-trivial scientific computing\nsoftware stack and its execution on a spectrum of platforms from laptop\ncomputers through to high performance computing (HPC) systems. We show on a\nworkstation and a leadership-class HPC system that when deployed appropriately\nthere are no performance penalties running scientific programs inside\ncontainers. For Python code run on large parallel computers, the run time is\nreduced inside a container due to faster library imports. The software\ndistribution approach and data that we present will help developers and users\ndecide on whether container technology is appropriate for them. We also provide\nguidance for the vendors of HPC systems that rely on proprietary libraries for\nperformance on what they can do to make containers work seamlessly and without\nperformance penalty.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2016 11:58:00 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 18:21:56 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Hale", "Jack S.", ""], ["Li", "Lizao", ""], ["Richardson", "Chris N.", ""], ["Wells", "Garth N.", ""]]}, {"id": "1608.08658", "submitter": "Navjot Kukreja", "authors": "Navjot Kukreja, Mathias Louboutin, Felippe Vieira, Fabio Luporini,\n  Michael Lange, Gerard Gorman", "title": "Devito: automated fast finite difference computation", "comments": "Accepted at WolfHPC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain specific languages have successfully been used in a variety of fields\nto cleanly express scientific problems as well as to simplify implementation\nand performance opti- mization on different computer architectures. Although a\nlarge number of stencil languages are available, finite differ- ence domain\nspecific languages have proved challenging to design because most practical use\ncases require additional features that fall outside the finite difference\nabstraction. Inspired by the complexity of real-world seismic imaging problems,\nwe introduce Devito, a domain specific language in which high level equations\nare expressed using symbolic expressions from the SymPy package. Complex\nequations are automatically manipulated, optimized, and translated into highly\noptimized C code that aims to perform compa- rably or better than hand-tuned\ncode. All this is transpar- ent to users, who only see concise symbolic\nmathematical expressions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2016 21:05:21 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2016 13:15:52 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Kukreja", "Navjot", ""], ["Louboutin", "Mathias", ""], ["Vieira", "Felippe", ""], ["Luporini", "Fabio", ""], ["Lange", "Michael", ""], ["Gorman", "Gerard", ""]]}]