[{"id": "1408.0074", "submitter": "Ross Adelman", "authors": "Ross Adelman, Nail A. Gumerov, and Ramani Duraiswami", "title": "Software for Computing the Spheroidal Wave Functions Using Arbitrary\n  Precision Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spheroidal wave functions, which are the solutions to the Helmholtz\nequation in spheroidal coordinates, are notoriously difficult to compute.\nBecause of this, practically no programming language comes equipped with the\nmeans to compute them. This makes problems that require their use hard to\ntackle. We have developed computational software for calculating these special\nfunctions. Our software is called spheroidal and includes several novel\nfeatures, such as: using arbitrary precision arithmetic; adaptively choosing\nthe number of expansion coefficients to compute and use; and using the\nWronskian to choose from several different methods for computing the spheroidal\nradial functions to improve their accuracy. There are two types of spheroidal\nwave functions: the prolate kind when prolate spheroidal coordinates are used;\nand the oblate kind when oblate spheroidal coordinate are used. In this paper,\nwe describe both, methods for computing them, and our software. We have made\nour software freely available on our webpage.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 04:29:30 GMT"}], "update_date": "2014-08-04", "authors_parsed": [["Adelman", "Ross", ""], ["Gumerov", "Nail A.", ""], ["Duraiswami", "Ramani", ""]]}, {"id": "1408.0393", "submitter": "Jeremy Kepner", "authors": "Tim Mattson (Intel Corporation), David Bader (Georgia Institute of\n  Technology), Jon Berry (Sandia National Laboratory), Aydin Buluc (Lawrence\n  Berkeley National Laboratory), Jack Dongarra (University of Tennessee),\n  Christos Faloutsos (Carnegie Melon University), John Feo (Pacific Northwest\n  National Laboratory), John Gilbert (University of California at Santa\n  Barbara), Joseph Gonzalez (University of California at Berkeley), Bruce\n  Hendrickson (Sandia National Laboratory), Jeremy Kepner (Massachusetts\n  Institute of Technology), Charles Leiserson (Massachusetts Institute of\n  Technology), Andrew Lumsdaine (Indiana University), David Padua (University\n  of Illinois at Urbana-Champaign), Stephen Poole (Oak Ridge National\n  Laboratory), Steve Reinhardt (Cray Corporation), Mike Stonebraker\n  (Massachusetts Institute of Technology), Steve Wallach (Convey Corporation),\n  Andrew Yoo (Lawrence Livermore National Laboratory)", "title": "Standards for Graph Algorithm Primitives", "comments": "2 pages, IEEE HPEC 2013", "journal-ref": null, "doi": "10.1109/HPEC.2013.6670338", "report-no": null, "categories": "cs.MS cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is our view that the state of the art in constructing a large collection\nof graph algorithms in terms of linear algebraic operations is mature enough to\nsupport the emergence of a standard set of primitive building blocks. This\npaper is a position paper defining the problem and announcing our intention to\nlaunch an open effort to define this standard.\n", "versions": [{"version": "v1", "created": "Sat, 2 Aug 2014 16:17:40 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Mattson", "Tim", "", "Intel Corporation"], ["Bader", "David", "", "Georgia Institute of\n  Technology"], ["Berry", "Jon", "", "Sandia National Laboratory"], ["Buluc", "Aydin", "", "Lawrence\n  Berkeley National Laboratory"], ["Dongarra", "Jack", "", "University of Tennessee"], ["Faloutsos", "Christos", "", "Carnegie Melon University"], ["Feo", "John", "", "Pacific Northwest\n  National Laboratory"], ["Gilbert", "John", "", "University of California at Santa\n  Barbara"], ["Gonzalez", "Joseph", "", "University of California at Berkeley"], ["Hendrickson", "Bruce", "", "Sandia National Laboratory"], ["Kepner", "Jeremy", "", "Massachusetts\n  Institute of Technology"], ["Leiserson", "Charles", "", "Massachusetts Institute of\n  Technology"], ["Lumsdaine", "Andrew", "", "Indiana University"], ["Padua", "David", "", "University\n  of Illinois at Urbana-Champaign"], ["Poole", "Stephen", "", "Oak Ridge National\n  Laboratory"], ["Reinhardt", "Steve", "", "Cray Corporation"], ["Stonebraker", "Mike", "", "Massachusetts Institute of Technology"], ["Wallach", "Steve", "", "Convey Corporation"], ["Yoo", "Andrew", "", "Lawrence Livermore National Laboratory"]]}, {"id": "1408.0854", "submitter": "Ross Adelman", "authors": "Ross Adelman, Nail A. Gumerov, and Ramani Duraiswami", "title": "Semi-Analytical Computation of Acoustic Scattering by Spheroids and\n  Disks", "comments": null, "journal-ref": null, "doi": "10.1121/1.4901318", "report-no": null, "categories": "cs.MS cs.SD physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analytical solutions to acoustic scattering problems involving nonspherical\nshapes, such as spheroids and disks, have long been known and have many\napplications. However, these solutions require special functions that are not\neasily computable. For this reason, their asymptotic forms are typically used\nsince they are more readily available. We explore these solutions and provide\ncomputational software for calculating their nonasymptotic forms, which are\naccurate over a wide range of frequencies and distances. This software, which\nruns in MATLAB, computes the solutions to acoustic scattering problems\ninvolving spheroids and disks by semi-analytical means, and is freely available\nfrom our webpage.\n", "versions": [{"version": "v1", "created": "Tue, 5 Aug 2014 03:18:28 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Adelman", "Ross", ""], ["Gumerov", "Nail A.", ""], ["Duraiswami", "Ramani", ""]]}, {"id": "1408.1363", "submitter": "Elizabeth Jessup", "authors": "Boyana Norris and Sa-Lin Bernstein and Ramya Nair and Elizabeth Jessup", "title": "Lighthouse: A User-Centered Web Service for Linear Algebra Software", "comments": "10 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various fields of science and engineering rely on linear algebra for large\nscale data analysis, modeling and simulation, machine learning, and other\napplied problems. Linear algebra computations often dominate the execution time\nof such applications. Meanwhile, experts in these domains typically lack the\ntraining or time required to develop efficient, high-performance\nimplementations of linear algebra algorithms. In the Lighthouse project, we\nenable developers with varied backgrounds to readily discover and effectively\napply the best available numerical software for their problems. We have\ndeveloped a search-based expert system that combines expert knowledge, machine\nlearningbased classification of existing numerical software collections, and\nautomated code generation and optimization. Lighthouse provides a novel\nsoftware engineering environment aimed at maximizing both developer\nproductivity and application performance for dense and sparse linear algebra\ncomputations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 17:37:03 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Norris", "Boyana", ""], ["Bernstein", "Sa-Lin", ""], ["Nair", "Ramya", ""], ["Jessup", "Elizabeth", ""]]}, {"id": "1408.1727", "submitter": "Andrey Vladimirov", "authors": "Andrey Vladimirov and Cliff Addison", "title": "Cluster-level tuning of a shallow water equation solver on the Intel MIC\n  architecture", "comments": "Colfax Research publication. 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE cs.DC physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper demonstrates the optimization of the execution environment of a\nhybrid OpenMP+MPI computational fluid dynamics code (shallow water equation\nsolver) on a cluster enabled with Intel Xeon Phi coprocessors. The discussion\nincludes: (1) Controlling the number and affinity of OpenMP threads to optimize\naccess to memory bandwidth; (2) Tuning the inter-operation of OpenMP and MPI to\npartition the problem for better data locality; (3) Ordering the MPI ranks in a\nway that directs some of the traffic into faster communication channels; (4)\nUsing efficient peer-to-peer communication between Xeon Phi coprocessors based\non the InfiniBand fabric.\n  With tuning, the application has 90% percent efficiency of parallel scaling\nup to 8 Intel Xeon Phi coprocessors in 2 compute nodes. For larger problems,\nscalability is even better, because of the greater computation to communication\nratio. However, problems of that size do not fit in the memory of one\ncoprocessor. The performance of the solver on one Intel Xeon Phi coprocessor\n7120P exceeds the performance on a dual-socket Intel Xeon E5-2697 v2 CPU by a\nfactor of 1.6x. In a 2-node cluster with 4 coprocessors per compute node, the\nMIC architecture yields 5.8x more performance than the CPUs. Only one line of\nlegacy Fortran code had to be changed in order to achieve the reported\nperformance on the MIC architecture (not counting changes to the command-line\ninterface). The methodology discussed in this paper is directly applicable to\nother bandwidth-bound stencil algorithms utilizing a hybrid OpenMP+MPI\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 22:53:51 GMT"}], "update_date": "2014-08-11", "authors_parsed": [["Vladimirov", "Andrey", ""], ["Addison", "Cliff", ""]]}, {"id": "1408.1900", "submitter": "Ayse Ferhan Yesil", "authors": "Ayse Ferhan Yesil, M. Cemal Yalabik", "title": "A Report of a Significant Error On a Frequently Used Pseudo Random\n  Number Generator", "comments": "9 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cond-mat.stat-mech cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergence of stochastic simulations as an extensively used computational tool\nfor scientific purposes intensified the need for more accurate ways of\ngenerating sufficiently long sequences of uncorrelated random numbers. Even\nthough several different methods have been proposed for this end, deterministic\nalgorithms known as pseudo-random number generators (PRNGs) emerged to be the\nmost widely used tool as a replicable, portable and easy to use method to\ngenerate such random number sequences. Here, we introduce a simple Poisson\nprocess whose simulation gives systematic errors when the very commonly used\nrandom number generator of the GNU C Library (Glibc) is utilised. The PRNG of\nGlibc is an additive lagged Fibonacci generator, the family of such PRNGs are\naccepted as relatively safe among other PRNGs. The systematic errors indicate\ncomplex correlation relations among random numbers which requires a further\nexplanation.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 07:16:07 GMT"}], "update_date": "2014-08-14", "authors_parsed": [["Yesil", "Ayse Ferhan", ""], ["Yalabik", "M. Cemal", ""]]}, {"id": "1408.2858", "submitter": "Francesco Silvestri", "authors": "Matteo Ceccarello and Francesco Silvestri", "title": "Experimental Evaluation of Multi-Round Matrix Multiplication on\n  MapReduce", "comments": "Proc. of 17th Meeting on Algorithm Engineering and Experiments\n  (ALENEX), 2015. The code is publicly available at http://www.dei.unipd.it/m3", "journal-ref": null, "doi": "10.1137/1.9781611973754.11", "report-no": null, "categories": "cs.DC cs.DS cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach in the design of MapReduce algorithms is to minimize the\nnumber of rounds. Indeed, there are many examples in the literature of\nmonolithic MapReduce algorithms, which are algorithms requiring just one or two\nrounds. However, we claim that the design of monolithic algorithms may not be\nthe best approach in cloud systems. Indeed, multi-round algorithms may exploit\nsome features of cloud platforms by suitably setting the round number according\nto the execution context. In this paper we carry out an experimental study of\nmulti-round MapReduce algorithms aiming at investigating the performance of the\nmulti-round approach. We use matrix multiplication as a case study. We first\npropose a scalable Hadoop library, named M$_3$, for matrix multiplication in\nthe dense and sparse cases which allows to tradeoff round number with the\namount of data shuffled in each round and the amount of memory required by\nreduce functions. Then, we present an extensive study of this library on an\nin-house cluster and on Amazon Web Services aiming at showing its performance\nand at comparing monolithic and multi-round approaches. The experiments show\nthat, even without a low level optimization, it is possible to design\nmulti-round algorithms with a small running time overhead.\n", "versions": [{"version": "v1", "created": "Tue, 12 Aug 2014 21:23:11 GMT"}, {"version": "v2", "created": "Tue, 20 Jan 2015 22:25:08 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Ceccarello", "Matteo", ""], ["Silvestri", "Francesco", ""]]}, {"id": "1408.3082", "submitter": "Benjamin Ong", "authors": "Benjamin Ong, Ronald Haynes and Kyle Ladd", "title": "Algorithm xxx: RIDC Methods -- A Family of Parallel Time-Integrators", "comments": null, "journal-ref": null, "doi": "10.1145/2964377", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revisionist integral deferred correction (RIDC) methods are a family of\nparallel--in--time methods to solve systems of initial values problems. The\napproach is able to bootstrap lower order time integrators to provide high\norder approximations in approximately the same wall clock time, hence providing\na multiplicative increase in the number of compute cores utilized. Here we\nprovide a C++ framework which automatically produces a parallel--in--time\nsolution of a system of initial value problems given user supplied code for the\nright hand side of the system and a sequential code for a first-order time\nstep. The user supplied time step routine may be explicit or implicit and may\nmake use of any auxiliary libraries which take care of the solution of any\nnonlinear algebraic systems which may arise or the numerical linear algebra\nrequired. The code contains six examples of increasing complexity which also\nserve as templates to solve user defined problems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 18:42:01 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2015 19:36:57 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Ong", "Benjamin", ""], ["Haynes", "Ronald", ""], ["Ladd", "Kyle", ""]]}, {"id": "1408.3264", "submitter": "Mohammad Ali Keyvanrad", "authors": "Mohammad Ali Keyvanrad, Mohammad Mehdi Homayounpour", "title": "A brief survey on deep belief networks and introducing a new object\n  oriented toolbox (DeeBNet)", "comments": "Technical Report 27 pages, Ver3.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, this is very popular to use the deep architectures in machine\nlearning. Deep Belief Networks (DBNs) are deep architectures that use stack of\nRestricted Boltzmann Machines (RBM) to create a powerful generative model using\ntraining data. DBNs have many ability like feature extraction and\nclassification that are used in many applications like image processing, speech\nprocessing and etc. This paper introduces a new object oriented MATLAB toolbox\nwith most of abilities needed for the implementation of DBNs. In the new\nversion, the toolbox can be used in Octave. According to the results of the\nexperiments conducted on MNIST (image), ISOLET (speech), and 20 Newsgroups\n(text) datasets, it was shown that the toolbox can learn automatically a good\nrepresentation of the input from unlabeled data with better discrimination\nbetween different classes. Also on all datasets, the obtained classification\nerrors are comparable to those of state of the art classifiers. In addition,\nthe toolbox supports different sampling methods (e.g. Gibbs, CD, PCD and our\nnew FEPCD method), different sparsity methods (quadratic, rate distortion and\nour new normal method), different RBM types (generative and discriminative),\nusing GPU, etc. The toolbox is a user-friendly open source software and is\nfreely available on the website\nhttp://ceit.aut.ac.ir/~keyvanrad/DeeBNet%20Toolbox.html .\n", "versions": [{"version": "v1", "created": "Thu, 14 Aug 2014 12:37:57 GMT"}, {"version": "v2", "created": "Mon, 8 Dec 2014 14:44:02 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2015 12:44:01 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2015 13:21:02 GMT"}, {"version": "v5", "created": "Wed, 22 Jul 2015 14:25:13 GMT"}, {"version": "v6", "created": "Mon, 7 Sep 2015 14:44:47 GMT"}, {"version": "v7", "created": "Wed, 6 Jan 2016 13:20:11 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Keyvanrad", "Mohammad Ali", ""], ["Homayounpour", "Mohammad Mehdi", ""]]}, {"id": "1408.3270", "submitter": "Joseph Lizier", "authors": "Joseph T. Lizier", "title": "JIDT: An information-theoretic toolkit for studying the dynamics of\n  complex systems", "comments": "37 pages, 4 figures", "journal-ref": "Frontiers in Robotics and AI, 1:11, 2014", "doi": "10.3389/frobt.2014.00011", "report-no": null, "categories": "cs.IT cs.MS cs.SI math.IT nlin.AO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems are increasingly being viewed as distributed information\nprocessing systems, particularly in the domains of computational neuroscience,\nbioinformatics and Artificial Life. This trend has resulted in a strong uptake\nin the use of (Shannon) information-theoretic measures to analyse the dynamics\nof complex systems in these fields. We introduce the Java Information Dynamics\nToolkit (JIDT): a Google code project which provides a standalone, (GNU GPL v3\nlicensed) open-source code implementation for empirical estimation of\ninformation-theoretic measures from time-series data. While the toolkit\nprovides classic information-theoretic measures (e.g. entropy, mutual\ninformation, conditional mutual information), it ultimately focusses on\nimplementing higher-level measures for information dynamics. That is, JIDT\nfocusses on quantifying information storage, transfer and modification, and the\ndynamics of these operations in space and time. For this purpose, it includes\nimplementations of the transfer entropy and active information storage, their\nmultivariate extensions and local or pointwise variants. JIDT provides\nimplementations for both discrete and continuous-valued data for each measure,\nincluding various types of estimator for continuous data (e.g. Gaussian,\nbox-kernel and Kraskov-Stoegbauer-Grassberger) which can be swapped at run-time\ndue to Java's object-oriented polymorphism. Furthermore, while written in Java,\nthe toolkit can be used directly in MATLAB, GNU Octave, Python and other\nenvironments. We present the principles behind the code design, and provide\nseveral examples to guide users.\n", "versions": [{"version": "v1", "created": "Thu, 14 Aug 2014 13:11:15 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 13:02:48 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Lizier", "Joseph T.", ""]]}, {"id": "1408.4587", "submitter": "Pier Stanislao Paolucci", "authors": "Pier Stanislao Paolucci, Iuliana Bacivarov, Devendra Rai, Lars Schor,\n  Lothar Thiele, Hoeseok Yang, Elena Pastorelli, Roberto Ammendola, Andrea\n  Biagioni, Ottorino Frezza, Francesca Lo Cicero, Alessandro Lonardo, Francesco\n  Simula, Laura Tosoratto, Piero Vicini", "title": "EURETILE D7.3 - Dynamic DAL benchmark coding, measurements on MPI\n  version of DPSNN-STDP (distributed plastic spiking neural net) and\n  improvements to other DAL codes", "comments": "34 pages. arXiv admin note: substantial text overlap with\n  arXiv:1310.8478", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.MS cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EURETILE project required the selection and coding of a set of dedicated\nbenchmarks. The project is about the software and hardware architecture of\nfuture many-tile distributed fault-tolerant systems. We focus on dynamic\nworkloads characterised by heavy numerical processing requirements. The\nambition is to identify common techniques that could be applied to both the\nEmbedded Systems and HPC domains. This document is the first public deliverable\nof Work Package 7: Challenging Tiled Applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Aug 2014 10:00:15 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["Paolucci", "Pier Stanislao", ""], ["Bacivarov", "Iuliana", ""], ["Rai", "Devendra", ""], ["Schor", "Lars", ""], ["Thiele", "Lothar", ""], ["Yang", "Hoeseok", ""], ["Pastorelli", "Elena", ""], ["Ammendola", "Roberto", ""], ["Biagioni", "Andrea", ""], ["Frezza", "Ottorino", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Simula", "Francesco", ""], ["Tosoratto", "Laura", ""], ["Vicini", "Piero", ""]]}, {"id": "1408.4701", "submitter": "Olga Lopez-Acevedo", "authors": "J. Lehtom\\\"aki, I. Makkonen, M. A. Caro, A. Harju and O. Lopez-Acevedo", "title": "Orbital-Free Density Functional Theory Implementation with the Projector\n  Augmented-Wave Method", "comments": "accepted in Journal of Chemical Physics", "journal-ref": "J. Chem. Phys. 141, 234102 (2014)", "doi": "10.1063/1.4903450", "report-no": null, "categories": "physics.comp-ph cs.CE cs.MS physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational scheme for orbital-free density functional theory\n(OFDFT) that simultaneously provides access to all-electron values and\npreserves the OFDFT linear scaling as a function of the system size. Using the\nprojector augmented-wave method (PAW) in combination with real-space methods we\novercome some obstacles faced by other available implementation schemes.\nSpecifically, the advantages of using the PAW method are two fold. First, PAW\nreproduces all-electron values offering freedom in adjusting the convergence\nparameters and the atomic setups allow tuning the numerical accuracy per\nelement. Second, PAW can provide a solution to some of the convergence problems\nexhibited in other OFDFT implementations based on Kohn-Sham codes. Using PAW\nand real-space methods, our orbital-free results agree with the reference\nall-electron values with a mean absolute error of 10~meV and the number of\niterations required by the self-consistent cycle is comparable to the KS\nmethod. The comparison of all-electron and pseudopotential bulk modulus and\nlattice constant reveal an enormous difference, demonstrating that in order to\nassess the performance of OFDFT functionals it is necessary to use\nimplementations that obtain all-electron values. The proposed combination of\nmethods is the most promising route currently available. We finally show that a\nparametrized kinetic energy functional can give lattice constants and bulk\nmoduli comparable in accuracy to those obtained by the KS PBE method,\nexemplified with the case of diamond.\n", "versions": [{"version": "v1", "created": "Wed, 20 Aug 2014 15:46:07 GMT"}, {"version": "v2", "created": "Fri, 28 Nov 2014 11:09:12 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Lehtom\u00e4ki", "J.", ""], ["Makkonen", "I.", ""], ["Caro", "M. A.", ""], ["Harju", "A.", ""], ["Lopez-Acevedo", "O.", ""]]}, {"id": "1408.5535", "submitter": "Lingfei Wu", "authors": "Lingfei Wu, Andreas Stathopoulos", "title": "A Preconditioned Hybrid SVD Method for Computing Accurately Singular\n  Triplets of Large Matrices", "comments": "24 pages, 20 figures, and 8 tables. Accepted to SIAM Journal on\n  Scientific Computing", "journal-ref": null, "doi": "10.1137/140979381", "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of a few singular triplets of large, sparse matrices is a\nchallenging task, especially when the smallest magnitude singular values are\nneeded in high accuracy. Most recent efforts try to address this problem\nthrough variations of the Lanczos bidiagonalization method, but they are still\nchallenged even for medium matrix sizes due to the difficulty of the problem.\nWe propose a novel SVD approach that can take advantage of preconditioning and\nof any well designed eigensolver to compute both largest and smallest singular\ntriplets. Accuracy and efficiency is achieved through a hybrid, two-stage\nmeta-method, PHSVDS. In the first stage, PHSVDS solves the normal equations up\nto the best achievable accuracy. If further accuracy is required, the method\nswitches automatically to an eigenvalue problem with the augmented matrix. Thus\nit combines the advantages of the two stages, faster convergence and accuracy,\nrespectively. For the augmented matrix, solving the interior eigenvalue is\nfacilitated by a proper use of the good initial guesses from the first stage\nand an efficient implementation of the refined projection method. We also\ndiscuss how to precondition PHSVDS and to cope with some issues that arise.\nNumerical experiments illustrate the efficiency and robustness of the method.\n", "versions": [{"version": "v1", "created": "Sat, 23 Aug 2014 23:19:39 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2015 01:49:26 GMT"}, {"version": "v3", "created": "Wed, 13 May 2015 20:25:34 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Wu", "Lingfei", ""], ["Stathopoulos", "Andreas", ""]]}, {"id": "1408.5925", "submitter": "Frank Winter", "authors": "F. T. Winter, M. A. Clark, R. G. Edwards, B. Jo\\'o", "title": "A Framework for Lattice QCD Calculations on GPUs", "comments": "10 pages, 6 figures, as published in the proceedings of IPDPS '14", "journal-ref": null, "doi": "10.1109/IPDPS.2014.112", "report-no": null, "categories": "hep-lat cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing platforms equipped with accelerators like GPUs have proven to\nprovide great computational power. However, exploiting such platforms for\nexisting scientific applications is not a trivial task. Current GPU programming\nframeworks such as CUDA C/C++ require low-level programming from the developer\nin order to achieve high performance code. As a result porting of applications\nto GPUs is typically limited to time-dominant algorithms and routines, leaving\nthe remainder not accelerated which can open a serious Amdahl's law issue. The\nlattice QCD application Chroma allows to explore a different porting strategy.\nThe layered structure of the software architecture logically separates the\ndata-parallel from the application layer. The QCD Data-Parallel software layer\nprovides data types and expressions with stencil-like operations suitable for\nlattice field theory and Chroma implements algorithms in terms of this\nhigh-level interface. Thus by porting the low-level layer one can effectively\nmove the whole application in one swing to a different platform. The\nQDP-JIT/PTX library, the reimplementation of the low-level layer, provides a\nframework for lattice QCD calculations for the CUDA architecture. The complete\nsoftware interface is supported and thus applications can be run unaltered on\nGPU-based parallel computers. This reimplementation was possible due to the\navailability of a JIT compiler (part of the NVIDIA Linux kernel driver) which\ntranslates an assembly-like language (PTX) to GPU code. The expression template\ntechnique is used to build PTX code generators and a software cache manages the\nGPU memory. This reimplementation allows us to deploy an efficient\nimplementation of the full gauge-generation program with dynamical fermions on\nlarge-scale GPU-based machines such as Titan and Blue Waters which accelerates\nthe algorithm by more than an order of magnitude.\n", "versions": [{"version": "v1", "created": "Mon, 25 Aug 2014 20:50:08 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Winter", "F. T.", ""], ["Clark", "M. A.", ""], ["Edwards", "R. G.", ""], ["Jo\u00f3", "B.", ""]]}, {"id": "1408.6373", "submitter": "Thomas Hahn", "authors": "T. Hahn", "title": "Concurrent Cuba", "comments": "LaTeX, 14 pages", "journal-ref": null, "doi": null, "report-no": "MPP-2014-327", "categories": "physics.comp-ph cs.MS hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parallel version of the multidimensional numerical integration package\nCuba is presented and achievable speed-ups discussed.\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 10:13:45 GMT"}], "update_date": "2014-08-28", "authors_parsed": [["Hahn", "T.", ""]]}]