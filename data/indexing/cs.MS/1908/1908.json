[{"id": "1908.00420", "submitter": "David Eriksson", "authors": "David Eriksson, David Bindel, Christine A. Shoemaker", "title": "pySOT and POAP: An event-driven asynchronous framework for surrogate\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Plumbing for Optimization with Asynchronous Parallelism\n(POAP) and the Python Surrogate Optimization Toolbox (pySOT). POAP is an\nevent-driven framework for building and combining asynchronous optimization\nstrategies, designed for global optimization of expensive functions where\nconcurrent function evaluations are useful. POAP consists of three components:\na worker pool capable of function evaluations, strategies to propose\nevaluations or other actions, and a controller that mediates the interaction\nbetween the workers and strategies. pySOT is a collection of synchronous and\nasynchronous surrogate optimization strategies, implemented in the POAP\nframework. We support the stochastic RBF method by Regis and Shoemaker along\nwith various extensions of this method, and a general surrogate optimization\nstrategy that covers most Bayesian optimization methods. We have implemented\nmany different surrogate models, experimental designs, acquisition functions,\nand a large set of test problems. We make an extensive comparison between\nsynchronous and asynchronous parallelism and find that the advantage of\nasynchronous computation increases as the variance of the evaluation time or\nnumber of processors increases. We observe a close to linear speed-up with 4,\n8, and 16 processors in both the synchronous and asynchronous setting.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 18:06:18 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Eriksson", "David", ""], ["Bindel", "David", ""], ["Shoemaker", "Christine A.", ""]]}, {"id": "1908.00891", "submitter": "Alberto F. Mart\\'in", "authors": "Santiago Badia and Alberto F. Mart\\'in", "title": "A tutorial-driven introduction to the parallel finite element library\n  FEMPAR v1.0.0", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2019.107059", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a user guide to the FEMPAR scientific software library. FEMPAR\nis an open-source object-oriented framework for the simulation of partial\ndifferential equations (PDEs) using finite element methods on\ndistributed-memory platforms. It provides a rich set of tools for numerical\ndiscretization and built-in scalable solvers for the resulting linear systems\nof equations. An application expert that wants to simulate a PDE-governed\nproblem has to extend the framework with a description of the weak form of the\nPDE at hand (and additional perturbation terms for non-conforming\napproximations). We show how to use the library by going through three\ndifferent tutorials. The first tutorial simulates a linear PDE (Poisson\nequation) in a serial environment for a structured mesh using both continuous\nand discontinuous Galerkin finite element methods. The second tutorial extends\nit with adaptive mesh refinement on octree meshes. The third tutorial is a\ndistributed-memory version of the previous one that combines a scalable octree\nhandler and a scalable domain decomposition solver. The exposition is\nrestricted to linear PDEs and simple geometries to keep it concise. The\ninterested user can dive into more tutorials available in the FEMPAR public\nrepository to learn about further capabilities of the library, e.g., nonlinear\nPDEs and nonlinear solvers, time integration, multi-field PDEs, block\npreconditioning, or unstructured mesh handling.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:45:02 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Badia", "Santiago", ""], ["Mart\u00edn", "Alberto F.", ""]]}, {"id": "1908.01407", "submitter": "Carl Yang", "authors": "Carl Yang, Aydin Buluc, John D. Owens", "title": "GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on\n  the GPU", "comments": "50 pages, 14 figures, 14 tables, to appear in ACM Transactions on\n  Mathematical Software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance implementations of graph algorithms are challenging to\nimplement on new parallel hardware such as GPUs because of three challenges:\n(1) the difficulty of coming up with graph building blocks, (2) load imbalance\non parallel hardware, and (3) graph problems having low arithmetic intensity.\nTo address some of these challenges, GraphBLAS is an innovative, on-going\neffort by the graph analytics community to propose building blocks based on\nsparse linear algebra, which will allow graph algorithms to be expressed in a\nperformant, succinct, composable and portable manner. In this paper, we examine\nthe performance challenges of a linear-algebra-based approach to building graph\nframeworks and describe new design principles for overcoming these bottlenecks.\nAmong the new design principles is exploiting input sparsity, which allows\nusers to write graph algorithms without specifying push and pull direction.\nExploiting output sparsity allows users to tell the backend which values of the\noutput in a single vectorized computation they do not want computed.\nLoad-balancing is an important feature for balancing work amongst parallel\nworkers. We describe the important load-balancing features for handling graphs\nwith different characteristics. The design principles described in this paper\nhave been implemented in \"GraphBLAST\", the first high-performance linear\nalgebra-based graph framework on NVIDIA GPUs that is open-source. The results\nshow that on a single GPU, GraphBLAST has on average at least an order of\nmagnitude speedup over previous GraphBLAS implementations SuiteSparse and GBTL,\ncomparable performance to the fastest GPU hardwired primitives and\nshared-memory graph frameworks Ligra and Gunrock, and better performance than\nany other GPU graph framework, while offering a simpler and more concise\nprogramming model.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 21:54:05 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 17:09:39 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 09:00:37 GMT"}, {"version": "v4", "created": "Sat, 14 Nov 2020 07:32:47 GMT"}, {"version": "v5", "created": "Tue, 15 Jun 2021 03:29:49 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Yang", "Carl", ""], ["Buluc", "Aydin", ""], ["Owens", "John D.", ""]]}, {"id": "1908.02518", "submitter": "Ulrich Bauer", "authors": "Ulrich Bauer", "title": "Ripser: efficient computation of Vietoris-Rips persistence barcodes", "comments": "26 pages. Software available at http://ripser.org", "journal-ref": "Journal of Applied and Computational Topology (2021)", "doi": "10.1007/s41468-021-00071-5", "report-no": null, "categories": "math.AT cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for the computation of Vietoris-Rips persistence\nbarcodes and describe its implementation in the software Ripser. The method\nrelies on implicit representations of the coboundary operator and the\nfiltration order of the simplices, avoiding the explicit construction and\nstorage of the filtration coboundary matrix. Moreover, it makes use of apparent\npairs, a simple but powerful method for constructing a discrete gradient field\nfrom a total order on the simplices of a simplicial complex, which is also of\nindependent interest. Our implementation shows substantial improvements over\nprevious software both in time and memory usage.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 10:33:51 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 19:39:06 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Bauer", "Ulrich", ""]]}, {"id": "1908.03075", "submitter": "Mehdi Karimi", "authors": "Mehdi Karimi and Levent Tun\\c{c}el", "title": "Domain-Driven Solver (DDS) Version 2.0: a MATLAB-based Software Package\n  for Convex Optimization Problems in Domain-Driven Form", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-Driven Solver (DDS) is a MATLAB-based software package for convex\noptimization problems in Domain-Driven form [Karimi and Tun\\c{c}el,\narXiv:1804.06925]. The current version of DDS accepts every combination of the\nfollowing function/set constraints: (1) symmetric cones (LP, SOCP, and SDP);\n(2) quadratic constraints that are SOCP representable; (3) direct sums of an\narbitrary collection of 2-dimensional convex sets defined as the epigraphs of\nunivariate convex functions (including as special cases geometric programming\nand entropy programming); (4) generalized power cone; (5) epigraphs of matrix\nnorms (including as a special case minimization of nuclear norm over a linear\nsubspace); (6) vector relative entropy; (7) epigraphs of quantum entropy and\nquantum relative entropy; and (8) constraints involving hyperbolic polynomials.\nDDS is a practical implementation of the infeasible-start primal-dual algorithm\ndesigned and analyzed in [Karimi and Tun\\c{c}el, arXiv:1804.06925]. This\nmanuscript contains the users' guide, as well as theoretical results needed for\nthe implementation of the algorithms. To help the users, we included many\nexamples. We also discussed some implementation details and techniques we used\nto improve the efficiency and further expansion of the software to cover the\nemerging classes of convex optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 17:37:47 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 23:10:18 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Karimi", "Mehdi", ""], ["Tun\u00e7el", "Levent", ""]]}, {"id": "1908.03869", "submitter": "Eleftherios Avramidis Dr", "authors": "Eleftherios Avramidis, Marta Lalik, Ozgur E. Akman", "title": "SODECL: An Open Source Library for Calculating Multiple Orbits of a\n  System of Stochastic Differential Equations in Parallel", "comments": "19 pages, 11 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic differential equations (SDEs) are widely used to model systems\naffected by random processes. In general, the analysis of an SDE model requires\nnumerical solutions to be generated many times over multiple parameter\ncombinations. However, this process often requires considerable computational\nresources to be practicable. Due to the embarrassingly parallel nature of the\ntask, devices such as multi-core processors and graphics processing units\n(GPUs) can be employed for acceleration.\n  Here, we present {\\bf SODECL} (\\url{https://github.com/avramidis/sodecl}), a\nsoftware library that utilises such devices to calculate multiple orbits of an\nSDE model. To evaluate the acceleration provided by SODECL, we compared the\ntime required to calculate multiple orbits of an exemplar stochastic model when\none CPU core is used, to the time required when using all CPU cores or a GPU.\nIn addition, to assess scalability, we investigated how the model size affected\nexecution time on different parallel compute devices.\n  Our results show that when using all 32 CPU cores of a high-end\nhigh-performance computing node, the task is accelerated by a factor of up to\n$\\simeq$6.7, compared to when using a single CPU core. Executing the task on a\nhigh-end GPU yielded accelerations of up to $\\simeq$4.5, compared to a single\nCPU core.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 08:28:55 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 19:38:33 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Avramidis", "Eleftherios", ""], ["Lalik", "Marta", ""], ["Akman", "Ozgur E.", ""]]}, {"id": "1908.04009", "submitter": "Gabriel Gomes", "authors": "Gabriel Gomes", "title": "Open Traffic Models -- A framework for hybrid simulation of\n  transportation networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new approach to hybrid traffic modeling, along with\nits implementation in software. The software allows modelers to assign traffic\nmodels to individual links in a network. Each model implements a series of\nmethods, refered to as the modeling interface. These methods are used by the\nprogram to exchange information between adjacent models. Traffic controllers\nare implemented in a similar manner. The paper outlines the important\ncomponents of the method: the network description, the description of demands,\nand the modeling and control interfaces. We include tests demonstrating the\npropagation of congestion between pairs of macroscpoic, mesoscopic, and\nmicroscopic models. Open Traffic Models is an open source implementation of\nthese concepts, and is available at https://github.com/ggomes/otm-sim.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 05:46:21 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gomes", "Gabriel", ""]]}, {"id": "1908.09301", "submitter": "Radoslava Hristova", "authors": "S. Dimova, I. Hristov, R. Hristova, I. Puzynin, T. Puzynina, Z.\n  Sharipov, N. Shegunov, Z. Tukhliev", "title": "OpenMP parallelization of multiple precision Taylor series method", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenMP parallelization of multiple precision Taylor series method is\nproposed. A very good parallel performance scalability and parallel efficiency\ninside one computation node of a CPU-cluster is observed. We explain the\ndetails of the parallelization on the classical example of the Lorentz\nequations. The same approach can be applied straightforwardly to a large class\nof chaotic dynamical systems.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 11:21:56 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Dimova", "S.", ""], ["Hristov", "I.", ""], ["Hristova", "R.", ""], ["Puzynin", "I.", ""], ["Puzynina", "T.", ""], ["Sharipov", "Z.", ""], ["Shegunov", "N.", ""], ["Tukhliev", "Z.", ""]]}, {"id": "1908.10169", "submitter": "Matthias Bollh\\\"ofer", "authors": "Matthias Bollh\\\"ofer and Olaf Schenk and Fabio Verbosio", "title": "High Performance Block Incomplete LU Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many application problems that lead to solving linear systems make use of\npreconditioned Krylov subspace solvers to compute their solution. Among the\nmost popular preconditioning approaches are incomplete factorization methods\neither as single-level approaches or within a multilevel framework. We will\npresent a block incomplete factorization that is based on skillfully blocking\nthe system initially and throughout the factorization. This approach allows for\nthe use of cache-optimized dense matrix kernels such as level-3 BLAS or LAPACK.\nWe will demonstrate how this block approach outperforms the scalar method often\nby orders of magnitude on modern architectures, paving the way for its\nprospective use inside various multilevel incomplete factorization approaches\nor other applications where the core part relies on an incomplete\nfactorization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 12:54:20 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Bollh\u00f6fer", "Matthias", ""], ["Schenk", "Olaf", ""], ["Verbosio", "Fabio", ""]]}, {"id": "1908.11807", "submitter": "Andrey Prokopenko", "authors": "D. Lebrun-Grandi\\'e, A. Prokopenko, B. Turcksin, S.R. Slattery", "title": "ArborX: A Performance Portable Geometric Search Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching for geometric objects that are close in space is a fundamental\ncomponent of many applications. The performance of search algorithms comes to\nthe forefront as the size of a problem increases both in terms of total object\ncount as well as in the total number of search queries performed. Scientific\napplications requiring modern leadership-class supercomputers also pose an\nadditional requirement of performance portability, i.e. being able to\nefficiently utilize a variety of hardware architectures. In this paper, we\nintroduce a new open-source C++ search library, ArborX, which we have designed\nfor modern supercomputing architectures. We examine scalable search algorithms\nwith a focus on performance, including a highly efficient parallel bounding\nvolume hierarchy implementation, and propose a flexible interface making it\neasy to integrate with existing applications. We demonstrate the performance\nportability of ArborX on multi-core CPUs and GPUs, and compare it to the\nstate-of-the-art libraries such as Boost.Geometry.Index and nanoflann.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 18:17:32 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 16:10:40 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Lebrun-Grandi\u00e9", "D.", ""], ["Prokopenko", "A.", ""], ["Turcksin", "B.", ""], ["Slattery", "S. R.", ""]]}]