[{"id": "1205.0790", "submitter": "Eric Phipps", "authors": "Roger P. Pawlowski, Eric T. Phipps, and Andrew G. Salinger", "title": "Automating embedded analysis capabilities and managing software\n  complexity in multiphysics simulation part I: template-based generic\n  programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach for incorporating embedded simulation and analysis capabilities\nin complex simulation codes through template-based generic programming is\npresented. This approach relies on templating and operator overloading within\nthe C++ language to transform a given calculation into one that can compute a\nvariety of additional quantities that are necessary for many state-of-the-art\nsimulation and analysis algorithms. An approach for incorporating these ideas\ninto complex simulation codes through general graph-based assembly is also\npresented. These ideas have been implemented within a set of packages in the\nTrilinos framework and are demonstrated on a simple problem from chemical\nengineering.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 18:24:54 GMT"}, {"version": "v2", "created": "Tue, 15 May 2012 20:19:22 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Pawlowski", "Roger P.", ""], ["Phipps", "Eric T.", ""], ["Salinger", "Andrew G.", ""]]}, {"id": "1205.1098", "submitter": "Jeremy Siek", "authors": "Geoffrey Belter, Elizabeth Jessup, Thomas Nelson, Boyana Norris,\n  Jeremy G. Siek", "title": "Reliable Generation of High-Performance Matrix Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific programmers often turn to vendor-tuned Basic Linear Algebra\nSubprograms (BLAS) to obtain portable high performance. However, many numerical\nalgorithms require several BLAS calls in sequence, and those successive calls\nresult in suboptimal performance. The entire sequence needs to be optimized in\nconcert. Instead of vendor-tuned BLAS, a programmer could start with source\ncode in Fortran or C (e.g., based on the Netlib BLAS) and use a\nstate-of-the-art optimizing compiler. However, our experiments show that\noptimizing compilers often attain only one-quarter the performance of\nhand-optimized code. In this paper we present a domain-specific compiler for\nmatrix algebra, the Build to Order BLAS (BTO), that reliably achieves high\nperformance using a scalable search algorithm for choosing the best combination\nof loop fusion, array contraction, and multithreading for data parallelism. The\nBTO compiler generates code that is between 16% slower and 39% faster than\nhand-optimized code.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2012 04:30:14 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Belter", "Geoffrey", ""], ["Jessup", "Elizabeth", ""], ["Nelson", "Thomas", ""], ["Norris", "Boyana", ""], ["Siek", "Jeremy G.", ""]]}, {"id": "1205.2107", "submitter": "Paolo Bientinesi", "authors": "Matthias Petschow (1), Elmar Peise (1) and Paolo Bientinesi (1) ((1)\n  AICES, RWTH Aachen)", "title": "High-Performance Solvers for Dense Hermitian Eigenproblems", "comments": null, "journal-ref": null, "doi": null, "report-no": "AICES-2011/09-2", "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new collection of solvers - subsequently called EleMRRR - for\nlarge-scale dense Hermitian eigenproblems. EleMRRR solves various types of\nproblems: generalized, standard, and tridiagonal eigenproblems. Among these,\nthe last is of particular importance as it is a solver on its own right, as\nwell as the computational kernel for the first two; we present a fast and\nscalable tridiagonal solver based on the Algorithm of Multiple Relatively\nRobust Representations - referred to as PMRRR. Like the other EleMRRR solvers,\nPMRRR is part of the freely available Elemental library, and is designed to\nfully support both message-passing (MPI) and multithreading parallelism (SMP).\nAs a result, the solvers can equally be used in pure MPI or in hybrid MPI-SMP\nfashion. We conducted a thorough performance study of EleMRRR and ScaLAPACK's\nsolvers on two supercomputers. Such a study, performed with up to 8,192 cores,\nprovides precise guidelines to assemble the fastest solver within the ScaLAPACK\nframework; it also indicates that EleMRRR outperforms even the fastest solvers\nbuilt from ScaLAPACK's components.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 21:20:55 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2012 02:59:01 GMT"}], "update_date": "2012-09-27", "authors_parsed": [["Petschow", "Matthias", ""], ["Peise", "Elmar", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1205.2129", "submitter": "Vinh Phu Vinh Phu Nguyen Vinh Phu Nguyen", "authors": "Vinh Phu Nguyen, St\\'ephane P.A. Bordas, Timon Rabczuk", "title": "Isogeometric analysis: an overview and computer implementation aspects", "comments": null, "journal-ref": null, "doi": "10.1016/j.matcom.2015.05.008", "report-no": null, "categories": "cs.NA cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isogeometric analysis (IGA) represents a recently developed technology in\ncomputational mechanics that offers the possibility of integrating methods for\nanalysis and Computer Aided Design (CAD) into a single, unified process. The\nimplications to practical engineering design scenarios are profound, since the\ntime taken from design to analysis is greatly reduced, leading to dramatic\ngains in efficiency. The tight coupling of CAD and analysis within IGA requires\nknowledge from both fields and it is one of the goals of the present paper to\noutline much of the commonly used notation. In this manuscript, through a clear\nand simple Matlab implementation, we present an introduction to IGA applied to\nthe Finite Element (FE) method and related computer implementation aspects.\nFurthermore, implemen- tation of the extended IGA which incorporates enrichment\nfunctions through the partition of unity method (PUM) is also presented, where\nseveral examples for both two-dimensional and three-dimensional fracture are\nillustrated. The open source Matlab code which accompanies the present paper\ncan be applied to one, two and three-dimensional problems for linear\nelasticity, linear elastic fracture mechanics, structural mechanics\n(beams/plates/shells including large displacements and rotations) and Poisson\nproblems with or without enrichment. The Bezier extraction concept that allows\nFE analysis to be performed efficiently on T-spline geometries is also\nincorporated. The article includes a summary of recent trends and developments\nwithin the field of IGA.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 00:48:08 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2013 12:40:51 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Nguyen", "Vinh Phu", ""], ["Bordas", "St\u00e9phane P. A.", ""], ["Rabczuk", "Timon", ""]]}, {"id": "1205.2927", "submitter": "Paolo D'Alberto", "authors": "Paolo D'Alberto", "title": "A Heterogeneous Accelerated Matrix Multiplication: OpenCL + APU + GPU+\n  Fast Matrix Multiply", "comments": "15 pages, 6 Figure, Fusion AMD Fusion Developer Summit 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As users and developers, we are witnessing the opening of a new computing\nscenario: the introduction of hybrid processors into a single die, such as an\naccelerated processing unit (APU) processor, and the plug-and-play of\nadditional graphics processing units (GPUs) onto a single motherboard. These\nAPU processors provide multiple symmetric cores with their memory hierarchies\nand an integrated GPU. Moreover, these processors are designed to work with\nexternal GPUs that can push the peak performance towards the TeraFLOPS\nboundary. We present a case study for the development of dense Matrix\nMultiplication (MM) codes for matrix sizes up to 19K\\times19K, thus using all\nof the above computational engines, and an achievable peak performance of 200\nGFLOPS for, literally, a made- at-home built. We present the results of our\nexperience, the quirks, the pitfalls, the achieved performance, and the\nachievable peak performance.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 01:37:41 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["D'Alberto", "Paolo", ""]]}, {"id": "1205.3506", "submitter": "Eric Phipps", "authors": "Eric Phipps and Roger Pawlowski", "title": "Efficient Expression Templates for Operator Overloading-based Automatic\n  Differentiation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expression templates are a well-known set of techniques for improving the\nefficiency of operator overloading-based forward mode automatic differentiation\nschemes in the C++ programming language by translating the differentiation from\nindividual operators to whole expressions. However standard expression template\napproaches result in a large amount of duplicate computation, particularly for\nlarge expression trees, degrading their performance. In this paper we describe\nseveral techniques for improving the efficiency of expression templates and\ntheir implementation in the automatic differentiation package Sacado. We\ndemonstrate their improved efficiency through test functions as well as their\napplication to differentiation of a large-scale fluid dynamics simulation code.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2012 20:42:23 GMT"}], "update_date": "2012-05-21", "authors_parsed": [["Phipps", "Eric", ""], ["Pawlowski", "Roger", ""]]}, {"id": "1205.3952", "submitter": "Eric Phipps", "authors": "Roger P. Pawlowski, Eric T. Phipps, Andrew G. Salinger, Steven J.\n  Owen, Christopher M. Siefert, and Matthew L. Staten", "title": "Automating embedded analysis capabilities and managing software\n  complexity in multiphysics simulation part II: application to partial\n  differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A template-based generic programming approach was presented in a previous\npaper that separates the development effort of programming a physical model\nfrom that of computing additional quantities, such as derivatives, needed for\nembedded analysis algorithms. In this paper, we describe the implementation\ndetails for using the template-based generic programming approach for\nsimulation and analysis of partial differential equations (PDEs). We detail\nseveral of the hurdles that we have encountered, and some of the software\ninfrastructure developed to overcome them. We end with a demonstration where we\npresent shape optimization and uncertainty quantification results for a 3D PDE\napplication.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 15:18:00 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Pawlowski", "Roger P.", ""], ["Phipps", "Eric T.", ""], ["Salinger", "Andrew G.", ""], ["Owen", "Steven J.", ""], ["Siefert", "Christopher M.", ""], ["Staten", "Matthew L.", ""]]}, {"id": "1205.4212", "submitter": "Gheorghe Ivan", "authors": "Mihai Ivan and Gheorghe Ivan", "title": "Sample programs in C++ for matrix computations in max plus algebra", "comments": "29 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main purpose of this paper is to propose five programs in C++ for matrix\ncomputations and solving recurrent equations systems with entries in max plus\nalgebra.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2012 07:32:57 GMT"}], "update_date": "2012-05-21", "authors_parsed": [["Ivan", "Mihai", ""], ["Ivan", "Gheorghe", ""]]}, {"id": "1205.5975", "submitter": "Paolo Bientinesi", "authors": "Diego Fabregat-Traver (1) and Paolo Bientinesi (1), ((1) AICES, RWTH\n  Aachen)", "title": "A Domain-Specific Compiler for Linear Algebra Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": "AICES-2012/01-2", "categories": "cs.MS cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a prototypical linear algebra compiler that automatically exploits\ndomain-specific knowledge to generate high-performance algorithms. The input to\nthe compiler is a target equation together with knowledge of both the structure\nof the problem and the properties of the operands. The output is a variety of\nhigh-performance algorithms, and the corresponding source code, to solve the\ntarget equation. Our approach consists in the decomposition of the input\nequation into a sequence of library-supported kernels. Since in general such a\ndecomposition is not unique, our compiler returns not one but a number of\nalgorithms. The potential of the compiler is shown by means of its application\nto a challenging equation arising within the genome-wide association study. As\na result, the compiler produces multiple \"best\" algorithms that outperform the\nbest existing libraries.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2012 15:22:23 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Fabregat-Traver", "Diego", ""], ["Bientinesi", "Paolo", ""]]}]