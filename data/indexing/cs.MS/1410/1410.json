[{"id": "1410.0564", "submitter": "Diego Fabregat-Traver", "authors": "Diego Fabregat-Traver and Paolo Bientinesi", "title": "Automatic Generation of Loop-Invariants for Matrix Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years it has been shown that for many linear algebra operations it\nis possible to create families of algorithms following a very systematic\nprocedure. We do not refer to the fine tuning of a known algorithm, but to a\nmethodology for the actual generation of both algorithms and routines to solve\na given target matrix equation. Although systematic, the methodology relies on\ncomplex algebraic manipulations and non-obvious pattern matching, making the\nprocedure challenging to be performed by hand, our goal is the development of a\nfully automated system that from the sole description of a target equation\ncreates multiple algorithms and routines. We present CL1ck, a symbolic system\nwritten in Mathematica, that starts with an equation, decomposes it into\nmultiple equations, and returns a set of loop-invariants for the algorithms --\nyet to be generated -- that will solve the equation. In a successive step each\nloop-invariant is then mapped to its corresponding algorithm and routine. For a\nlarge class of equations, the methodology generates known algorithms as well as\nmany previously unknown ones. Most interestingly, the methodology unifies\nalgorithms traditionally developed in isolation. As an example, the five well\nknown algorithms for the LU factorization are for the first time unified under\na common root.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 14:27:17 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Fabregat-Traver", "Diego", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1410.0567", "submitter": "Diego Fabregat-Traver", "authors": "Diego Fabregat-Traver and Paolo Bientinesi", "title": "Knowledge-Based Automatic Generation of Partitioned Matrix Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a series of papers it has been shown that for many linear algebra\noperations it is possible to generate families of algorithms by following a\nsystematic procedure. Although powerful, such a methodology involves complex\nalgebraic manipulation, symbolic computations and pattern matching, making the\ngeneration a process challenging to be performed by hand. We aim for a fully\nautomated system that from the sole description of a target operation creates\nmultiple algorithms without any human intervention. Our approach consists of\nthree main stages. The first stage yields the core object for the entire\nprocess, the Partitioned Matrix Expression (PME), which establishes how the\ntarget problem may be decomposed in terms of simpler sub-problems. In the\nsecond stage the PME is inspected to identify predicates, the Loop-Invariants,\nto be used to set up the skeleton of a family of proofs of correctness. In the\nthird and last stage the actual algorithms are constructed so that each of them\nsatisfies its corresponding proof of correctness. In this paper we focus on the\nfirst stage of the process, the automatic generation of Partitioned Matrix\nExpressions. In particular, we discuss the steps leading to a PME and the\nknowledge necessary for a symbolic system to perform such steps. We also\nintroduce Cl1ck, a prototype system written in Mathematica that generates PMEs\nautomatically.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 14:33:43 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Fabregat-Traver", "Diego", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1410.0759", "submitter": "Bryan Catanzaro", "authors": "Sharan Chetlur, Cliff Woolley, Philippe Vandermersch, Jonathan Cohen,\n  John Tran, Bryan Catanzaro, Evan Shelhamer", "title": "cuDNN: Efficient Primitives for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a library of efficient implementations of deep learning\nprimitives. Deep learning workloads are computationally intensive, and\noptimizing their kernels is difficult and time-consuming. As parallel\narchitectures evolve, kernels must be reoptimized, which makes maintaining\ncodebases difficult over time. Similar issues have long been addressed in the\nHPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS).\nHowever, there is no analogous library for deep learning. Without such a\nlibrary, researchers implementing deep learning workloads on parallel\nprocessors must create and optimize their own implementations of the main\ncomputational kernels, and this work must be repeated as new parallel\nprocessors emerge. To address this problem, we have created a library similar\nin intent to BLAS, with optimized routines for deep learning workloads. Our\nimplementation contains routines for GPUs, although similarly to the BLAS\nlibrary, these routines could be implemented for other platforms. The library\nis easy to integrate into existing frameworks, and provides optimized\nperformance and memory usage. For example, integrating cuDNN into Caffe, a\npopular framework for convolutional networks, improves performance by 36% on a\nstandard model while also reducing memory consumption.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 06:16:43 GMT"}, {"version": "v2", "created": "Thu, 9 Oct 2014 06:00:21 GMT"}, {"version": "v3", "created": "Thu, 18 Dec 2014 01:13:16 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Chetlur", "Sharan", ""], ["Woolley", "Cliff", ""], ["Vandermersch", "Philippe", ""], ["Cohen", "Jonathan", ""], ["Tran", "John", ""], ["Catanzaro", "Bryan", ""], ["Shelhamer", "Evan", ""]]}, {"id": "1410.1387", "submitter": "David Medina", "authors": "David S. Medina, Amik St-Cyr and Timothy Warburton", "title": "High-Order Finite-differences on multi-threaded architectures using OCCA", "comments": "ICOSAHOM 2014 conference paper, 9 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-order finite-difference methods are commonly used in wave propagators\nfor industrial subsurface imaging algorithms. Computational aspects of the\nreduced linear elastic vertical transversely isotropic propagator are\nconsidered. Thread parallel algorithms suitable for implementing this\npropagator on multi-core and many-core processing devices are introduced.\nPortability is addressed through the use of the \\OCCA runtime programming\ninterface. Finally, performance results are shown for various architectures on\na representative synthetic test case.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 18:15:22 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Medina", "David S.", ""], ["St-Cyr", "Amik", ""], ["Warburton", "Timothy", ""]]}, {"id": "1410.1726", "submitter": "Ahmad Abdelfattah", "authors": "Ahmad Abdelfattah, David Keyes, Hatem Ltaief", "title": "KBLAS: An Optimized Library for Dense Matrix-Vector Multiplication on\n  GPU Accelerators", "comments": "Submitted to the ACM Transactions on Mathematical Software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  KBLAS is a new open source high performance library that provides optimized\nkernels for a subset of Level 2 BLAS functionalities on CUDA-enabled GPUs.\nSince performance of dense matrix-vector multiplication is hindered by the\noverhead of memory accesses, a double-buffering optimization technique is\nemployed to overlap data motion with computation. After identifying a proper\nset of tuning parameters, KBLAS is able to efficiently run on various GPU\narchitectures across different generations, avoiding the time-consuming step of\ncode rewriting, while still being compliant with the standard BLAS API. Another\nadvanced optimization technique allows to ensure coalesced memory access when\ndealing with submatrices, especially in the context of high level dense linear\nalgebra algorithms. All four precisions KBLAS kernels have been leveraged to\nmulti-GPUs environment, which requires the introduction of new APIs to ease\nusers' experiences on these challenging systems. The KBLAS performance\noutperforms existing state-of-the-art implementations on all matrix sizes,\nachieves asymptotically up to 50% and 60% speedup on single GPU and multi-GPUs\nsystems, respectively, and validates our performance model. A subset of KBLAS\nhigh performance kernels has been integrated into NVIDIA's standard BLAS\nimplementation (cuBLAS) for larger dissemination, starting version 6.0.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 13:43:53 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Abdelfattah", "Ahmad", ""], ["Keyes", "David", ""], ["Ltaief", "Hatem", ""]]}, {"id": "1410.1764", "submitter": "Erik Schnetter", "authors": "Erik Schnetter, Marek Blazewicz, Steven R. Brandt, David M. Koppelman,\n  Frank L\\\"offler", "title": "Chemora: A PDE Solving Framework for Modern HPC Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern HPC architectures consist of heterogeneous multi-core, many-node\nsystems with deep memory hierarchies. Modern applications employ ever more\nadvanced discretisation methods to study multi-physics problems. Developing\nsuch applications that explore cutting-edge physics on cutting-edge HPC systems\nhas become a complex task that requires significant HPC knowledge and\nexperience. Unfortunately, this combined knowledge is currently out of reach\nfor all but a few groups of application developers.\n  Chemora is a framework for solving systems of Partial Differential Equations\n(PDEs) that targets modern HPC architectures. Chemora is based on Cactus, which\nsees prominent usage in the computational relativistic astrophysics community.\nIn Chemora, PDEs are expressed either in a high-level \\LaTeX-like language or\nin Mathematica. Discretisation stencils are defined separately from equations,\nand can include Finite Differences, Discontinuous Galerkin Finite Elements\n(DGFE), Adaptive Mesh Refinement (AMR), and multi-block systems.\n  We use Chemora in the Einstein Toolkit to implement the Einstein Equations on\nCPUs and on accelerators, and study astrophysical systems such as black hole\nbinaries, neutron stars, and core-collapse supernovae.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 20:53:26 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Schnetter", "Erik", ""], ["Blazewicz", "Marek", ""], ["Brandt", "Steven R.", ""], ["Koppelman", "David M.", ""], ["L\u00f6ffler", "Frank", ""]]}, {"id": "1410.4054", "submitter": "Karl Rupp", "authors": "Karl Rupp, Josef Weinbub, Ansgar J\\\"ungel, Tibor Grasser", "title": "Pipelined Iterative Solvers with Kernel Fusion for Graphics Processing\n  Units", "comments": "27 pages, 9 figures, 3 tables", "journal-ref": "ACM Transactions on Mathematical Software (TOMS), Volume 43, Issue\n  2, Article No. 11 (2016)", "doi": "10.1145/2907944", "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the implementation of iterative solvers on discrete graphics\nprocessing units and demonstrate the benefit of implementations using extensive\nkernel fusion for pipelined formulations over conventional implementations of\nclassical formulations. The proposed implementations with both CUDA and OpenCL\nare freely available in ViennaCL and are shown to be competitive with or even\nsuperior to other solver packages for graphics processing units. Highest\nperformance gains are obtained for small to medium-sized systems, while our\nimplementations are on par with vendor-tuned implementations for very large\nsystems. Our results are especially beneficial for transient problems, where\nmany small to medium-sized systems instead of a single big system need to be\nsolved.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 13:23:31 GMT"}, {"version": "v2", "created": "Mon, 15 Dec 2014 15:56:36 GMT"}, {"version": "v3", "created": "Fri, 4 Nov 2016 11:18:16 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Rupp", "Karl", ""], ["Weinbub", "Josef", ""], ["J\u00fcngel", "Ansgar", ""], ["Grasser", "Tibor", ""]]}, {"id": "1410.4345", "submitter": "Joel Akeret", "authors": "Joel Akeret, Lukas Gamper, Adam Amara, Alexandre Refregier (ETH\n  Zurich)", "title": "HOPE: A Python Just-In-Time compiler for astrophysical computations", "comments": "Accepted for publication in Astronomy and Computing. 14 pages, 1\n  figure. The code is available at http://hope.phys.ethz.ch", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.MS cs.PL physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Python programming language is becoming increasingly popular for\nscientific applications due to its simplicity, versatility, and the broad range\nof its libraries. A drawback of this dynamic language, however, is its low\nruntime performance which limits its applicability for large simulations and\nfor the analysis of large data sets, as is common in astrophysics and\ncosmology. While various frameworks have been developed to address this\nlimitation, most focus on covering the complete language set, and either force\nthe user to alter the code or are not able to reach the full speed of an\noptimised native compiled language. In order to combine the ease of Python and\nthe speed of C++, we developed HOPE, a specialised Python just-in-time (JIT)\ncompiler designed for numerical astrophysical applications. HOPE focuses on a\nsubset of the language and is able to translate Python code into C++ while\nperforming numerical optimisation on mathematical expressions at runtime. To\nenable the JIT compilation, the user only needs to add a decorator to the\nfunction definition. We assess the performance of HOPE by performing a series\nof benchmarks and compare its execution speed with that of plain Python, C++\nand the other existing frameworks. We find that HOPE improves the performance\ncompared to plain Python by a factor of 2 to 120, achieves speeds comparable to\nthat of C++, and often exceeds the speed of the existing solutions. We discuss\nthe differences between HOPE and the other frameworks, as well as future\nextensions of its capabilities. The fully documented HOPE package is available\nat http://hope.phys.ethz.ch and is published under the GPLv3 license on PyPI\nand GitHub.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 09:28:18 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2014 15:08:33 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Akeret", "Joel", "", "ETH\n  Zurich"], ["Gamper", "Lukas", "", "ETH\n  Zurich"], ["Amara", "Adam", "", "ETH\n  Zurich"], ["Refregier", "Alexandre", "", "ETH\n  Zurich"]]}, {"id": "1410.4821", "submitter": "Madeleine Udell", "authors": "Madeleine Udell, Karanveer Mohan, David Zeng, Jenny Hong, Steven\n  Diamond, and Stephen Boyd", "title": "Convex Optimization in Julia", "comments": "To appear in Proceedings of the Workshop on High Performance\n  Technical Computing in Dynamic Languages (HPTCDL) 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Convex, a convex optimization modeling framework in\nJulia. Convex translates problems from a user-friendly functional language into\nan abstract syntax tree describing the problem. This concise representation of\nthe global structure of the problem allows Convex to infer whether the problem\ncomplies with the rules of disciplined convex programming (DCP), and to pass\nthe problem to a suitable solver. These operations are carried out in Julia\nusing multiple dispatch, which dramatically reduces the time required to verify\nDCP compliance and to parse a problem into conic form. Convex then\nautomatically chooses an appropriate backend solver to solve the conic form\nproblem.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 18:53:04 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Udell", "Madeleine", ""], ["Mohan", "Karanveer", ""], ["Zeng", "David", ""], ["Hong", "Jenny", ""], ["Diamond", "Steven", ""], ["Boyd", "Stephen", ""]]}, {"id": "1410.5263", "submitter": "Lorenzo Livi", "authors": "Lorenzo Livi, Guido Del Vescovo, Antonello Rizzi, Fabio Massimo\n  Frattale Mascioli", "title": "Building pattern recognition applications with the SPARE library", "comments": "Home page: https://sourceforge.net/p/libspare/home/Spare/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the SPARE C++ library, an open source software tool\nconceived to build pattern recognition and soft computing systems. The library\nfollows the requirement of the generality: most of the implemented algorithms\nare able to process user-defined input data types transparently, such as\nlabeled graphs and sequences of objects, as well as standard numeric vectors.\nHere we present a high-level picture of the SPARE library characteristics,\nfocusing instead on the specific practical possibility of constructing pattern\nrecognition systems for different input data types. In particular, as a proof\nof concept, we discuss two application instances involving clustering of\nreal-valued multidimensional sequences and classification of labeled graphs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 13:18:33 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 15:56:36 GMT"}], "update_date": "2015-02-23", "authors_parsed": [["Livi", "Lorenzo", ""], ["Del Vescovo", "Guido", ""], ["Rizzi", "Antonello", ""], ["Mascioli", "Fabio Massimo Frattale", ""]]}, {"id": "1410.6910", "submitter": "Thomas Kreuz", "authors": "Thomas Kreuz and Mario Mulansky and Nebojsa Bozanic", "title": "SPIKY: A graphical user interface for monitoring spike train synchrony", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.MS cs.SE physics.bio-ph physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for recording large-scale neuronal spiking activity are developing\nvery fast. This leads to an increasing demand for algorithms capable of\nanalyzing large amounts of experimental spike train data. One of the most\ncrucial and demanding tasks is the identification of similarity patterns with a\nvery high temporal resolution and across different spatial scales. To address\nthis task, in recent years three time-resolved measures of spike train\nsynchrony have been proposed, the ISI-distance, the SPIKE-distance, and event\nsynchronization. The Matlab source codes for calculating and visualizing these\nmeasures have been made publicly available. However, due to the many different\npossible representations of the results the use of these codes is rather\ncomplicated and their application requires some basic knowledge of Matlab. Thus\nit became desirable to provide a more user-friendly and interactive interface.\nHere we address this need and present SPIKY, a graphical user interface which\nfacilitates the application of time-resolved measures of spike train synchrony\nto both simulated and real data. SPIKY includes implementations of the\nISI-distance, the SPIKE-distance and SPIKE-synchronization (an improved and\nsimplified extension of event synchronization) which have been optimized with\nrespect to computation speed and memory demand. It also comprises a spike train\ngenerator and an event detector which makes it capable of analyzing continuous\ndata. Finally, the SPIKY package includes additional complementary programs\naimed at the analysis of large numbers of datasets and the estimation of\nsignificance levels.\n", "versions": [{"version": "v1", "created": "Sat, 25 Oct 2014 11:02:26 GMT"}, {"version": "v2", "created": "Sat, 24 Jan 2015 22:29:28 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2015 16:40:11 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Kreuz", "Thomas", ""], ["Mulansky", "Mario", ""], ["Bozanic", "Nebojsa", ""]]}, {"id": "1410.7176", "submitter": "Fredrik Johansson", "authors": "Fredrik Johansson", "title": "Efficient implementation of elementary functions in the medium-precision\n  range", "comments": "Submitted to ARITH 22", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new implementation of the elementary transcendental functions\nexp, sin, cos, log and atan for variable precision up to approximately 4096\nbits. Compared to the MPFR library, we achieve a maximum speedup ranging from a\nfactor 3 for cos to 30 for atan. Our implementation uses table-based argument\nreduction together with rectangular splitting to evaluate Taylor series. We\ncollect denominators to reduce the number of divisions in the Taylor series,\nand avoid overhead by doing all multiprecision arithmetic using the mpn layer\nof the GMP library. Our implementation provides rigorous error bounds.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 10:35:42 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2015 07:14:40 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Johansson", "Fredrik", ""]]}, {"id": "1410.8507", "submitter": "Mark Taylor", "authors": "M. B. Taylor", "title": "External Use of TOPCAT's Plotting Library", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The table analysis application TOPCAT uses a custom Java plotting library for\nhighly configurable high-performance interactive or exported visualisations in\ntwo and three dimensions. We present here a variety of ways for end users or\napplication developers to make use of this library outside of the TOPCAT\napplication: via the command-line suite STILTS or its Jython variant JyStilts,\nvia a traditional Java API, or by programmatically assigning values to a set of\nparameters in java code or using some form of inter-process communication. The\nlibrary has been built with large datasets in mind; interactive plots scale\nwell up to several million points, and static output to standard graphics\nformats is possible for unlimited sized input data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 19:29:08 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Taylor", "M. B.", ""]]}, {"id": "1410.8772", "submitter": "Anish Varghese", "authors": "Anish Varghese, Bob Edwards, Gaurav Mitra and Alistair P. Rendell", "title": "Programming the Adapteva Epiphany 64-core Network-on-chip Coprocessor", "comments": "14 pages, submitted to IJHPCA Journal special edition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the construction of exascale computing systems energy efficiency and power\nconsumption are two of the major challenges. Low-power high performance\nembedded systems are of increasing interest as building blocks for large scale\nhigh- performance systems. However, extracting maximum performance out of such\nsystems presents many challenges. Various aspects from the hardware\narchitecture to the programming models used need to be explored. The Epiphany\narchitecture integrates low-power RISC cores on a 2D mesh network and promises\nup to 70 GFLOPS/Watt of processing efficiency. However, with just 32 KB of\nmemory per eCore for storing both data and code, and only low level inter-core\ncommunication support, programming the Epiphany system presents several\nchallenges. In this paper we evaluate the performance of the Epiphany system\nfor a variety of basic compute and communication operations. Guided by this\ndata we explore strategies for implementing scientific applications on memory\nconstrained low-powered devices such as the Epiphany. With future systems\nexpected to house thousands of cores in a single chip, the merits of such\narchitectures as a path to exascale is compared to other competing systems.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 08:29:11 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Varghese", "Anish", ""], ["Edwards", "Bob", ""], ["Mitra", "Gaurav", ""], ["Rendell", "Alistair P.", ""]]}]