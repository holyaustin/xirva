[{"id": "1809.02666", "submitter": "Fande Kong", "authors": "Fande Kong, Roy H. Stogner, Derek R. Gaston, John W. Peterson, Cody J.\n  Permann, Andrew E. Slaughter, Richard C. Martineau", "title": "A general-purpose hierarchical mesh partitioning method with node\n  balancing strategies for large-scale numerical simulations", "comments": "9 pages. Accepted by 2018 IEEE/ACM 9th Workshop on Latest Advances in\n  Scalable Algorithms for Large-Scale Systems (scalA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale parallel numerical simulations are essential for a wide range of\nengineering problems that involve complex, coupled physical processes\ninteracting across a broad range of spatial and temporal scales. The data\nstructures involved in such simulations (meshes, sparse matrices, etc.) are\nfrequently represented as graphs, and these graphs must be optimally\npartitioned across the available computational resources in order for the\nunderlying calculations to scale efficiently. Partitions which minimize the\nnumber of graph edges that are cut (edge-cuts) while simultaneously maintaining\na balance in the amount of work (i.e. graph nodes) assigned to each processor\ncore are desirable, and the performance of most existing partitioning software\nbegins to degrade in this metric for partitions with more than than $O(10^3)$\nprocessor cores. In this work, we consider a general-purpose hierarchical\npartitioner which takes into account the existence of multiple processor cores\nand shared memory in a compute node while partitioning a graph into an\narbitrary number of subgraphs. We demonstrate that our algorithms significantly\nimprove the preconditioning efficiency and overall performance of realistic\nnumerical simulations running on up to 32,768 processor cores with nearly\n$10^9$ unknowns.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 20:40:26 GMT"}, {"version": "v2", "created": "Wed, 10 Oct 2018 16:00:08 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Kong", "Fande", ""], ["Stogner", "Roy H.", ""], ["Gaston", "Derek R.", ""], ["Peterson", "John W.", ""], ["Permann", "Cody J.", ""], ["Slaughter", "Andrew E.", ""], ["Martineau", "Richard C.", ""]]}, {"id": "1809.04424", "submitter": "Gregory Henselman", "authors": "Alan Hylton, Gregory Henselman-Petrusek, Janche Sang, Robert Short", "title": "Tuning the Performance of a Computational Persistent Homology Package", "comments": "29 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, persistent homology has become an attractive method for data\nanalysis. It captures topological features, such as connected components,\nholes, and voids from point cloud data and summarizes the way in which these\nfeatures appear and disappear in a filtration sequence. In this project, we\nfocus on improving the performance of Eirene, a computational package for\npersistent homology. Eirene is a 5000-line open-source software library\nimplemented in the dynamic programming language Julia. We use the Julia\nprofiling tools to identify performance bottlenecks and develop novel methods\nto manage them, including the parallelization of some time-consuming functions\non multicore/manycore hardware. Empirical results show that performance can be\ngreatly improved.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 01:51:45 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Hylton", "Alan", ""], ["Henselman-Petrusek", "Gregory", ""], ["Sang", "Janche", ""], ["Short", "Robert", ""]]}, {"id": "1809.05794", "submitter": "Thiago Serra", "authors": "Egon Balas and Thiago Serra", "title": "When Lift-and-Project Cuts are Different", "comments": "INFORMS Journal on Computing (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method to determine if a lift-and-project cut for\na mixed-integer linear program is irregular, in which case the cut is not\nequivalent to any intersection cut from the bases of the linear relaxation.\nThis is an important question due to the intense research activity for the past\ndecade on cuts from multiple rows of simplex tableau as well as on\nlift-and-project cuts from non-split disjunctions. While it is known since\nBalas and Perregaard (2003) that lift-and-project cuts from split disjunctions\nare always equivalent to intersection cuts and consequently to such multi-row\ncuts, Balas and Kis (2016) have recently shown that there is a necessary and\nsufficient condition in the case of arbitrary disjunctions: a lift-and-project\ncut is regular if, and only if, it corresponds to a regular basic solution of\nthe Cut Generating Linear Program (CGLP). This paper has four contributions.\nFirst, we state a result that simplifies the verification of regularity for\nbasic CGLP solutions from Balas and Kis (2016). Second, we provide a\nmixed-integer formulation that checks whether there is a regular CGLP solution\nfor a given cut that is regular in a broader sense, which also encompasses\nirregular cuts that are implied by the regular cut closure. Third, we describe\na numerical procedure based on such formulation that identifies irregular\nlift-and-project cuts. Finally, we use this method to evaluate how often\nlift-and-project cuts from simple $t$-branch split disjunctions are irregular,\nand thus not equivalent to multi-row cuts, on 74 instances of the MIPLIB\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 02:03:24 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 11:39:11 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Balas", "Egon", ""], ["Serra", "Thiago", ""]]}, {"id": "1809.06520", "submitter": "Kellie Ottoboni", "authors": "Kellie Ottoboni and Philip B. Stark", "title": "Random problems with R", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  R (Version 3.5.1 patched) has an issue with its random sampling\nfunctionality. R generates random integers between $1$ and $m$ by multiplying\nrandom floats by $m$, taking the floor, and adding $1$ to the result.\nWell-known quantization effects in this approach result in a non-uniform\ndistribution on $\\{ 1, \\ldots, m\\}$. The difference, which depends on $m$, can\nbe substantial. Because the sample function in R relies on generating random\nintegers, random sampling in R is biased. There is an easy fix: construct\nrandom integers directly from random bits, rather than multiplying a random\nfloat by $m$. That is the strategy taken in Python's numpy.random.randint()\nfunction, among others. Example source code in Python is available at\nhttps://github.com/statlab/cryptorandom/blob/master/cryptorandom/cryptorandom.py\n(see functions getrandbits() and randbelow_from_randbits()).\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 03:46:47 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 17:16:04 GMT"}, {"version": "v3", "created": "Tue, 13 Nov 2018 17:25:07 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Ottoboni", "Kellie", ""], ["Stark", "Philip B.", ""]]}, {"id": "1809.07763", "submitter": "Alicja Gosiewska", "authors": "Alicja Gosiewska, Przemyslaw Biecek", "title": "auditor: an R Package for Model-Agnostic Visual Validation and\n  Diagnostics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models have spread to almost every area of life. They are\nsuccessfully applied in biology, medicine, finance, physics, and other fields.\nWith modern software it is easy to train even a~complex model that fits the\ntraining data and results in high accuracy on the test set. The problem arises\nwhen models fail confronted with real-world data.\n  This paper describes methodology and tools for model-agnostic audit.\nIntroduced techniques facilitate assessing and comparing the goodness of fit\nand performance of models. In~addition, they may be used for the analysis of\nthe similarity of residuals and for identification of~outliers and influential\nobservations. The examination is carried out by diagnostic scores and visual\nverification.\n  Presented methods were implemented in the auditor package for R. Due to\nflexible and~consistent grammar, it is simple to validate models of any\nclasses.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 19:14:46 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 06:28:36 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 18:01:43 GMT"}, {"version": "v4", "created": "Tue, 26 May 2020 15:15:19 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1809.09175", "submitter": "Tamara Kolda", "authors": "Eric Phipps and Tamara G. Kolda", "title": "Software for Sparse Tensor Decomposition on Emerging Computing\n  Architectures", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing, Vol. 41, No. 3, pp.\n  C269-C290, 22 pages, 2019", "doi": "10.1137/18M1210691", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop software for decomposing sparse tensors that is\nportable to and performant on a variety of multicore, manycore, and GPU\ncomputing architectures. The result is a single code whose performance matches\noptimized architecture-specific implementations. The key to a portable approach\nis to determine multiple levels of parallelism that can be mapped in different\nways to different architectures, and we explain how to do this for the\nmatricized tensor times Khatri-Rao product (MTTKRP) which is the key kernel in\ncanonical polyadic tensor decomposition. Our implementation leverages the\nKokkos framework, which enables a single code to achieve high performance\nacross multiple architectures that differ in how they approach fine-grained\nparallelism. We also introduce a new construct for portable thread-local\narrays, which we call compile-time polymorphic arrays. Not only are the\nspecifics of our approaches and implementation interesting for tuning tensor\ncomputations, but they also provide a roadmap for developing other portable\nhigh-performance codes. As a last step in optimizing performance, we modify the\nMTTKRP algorithm itself to do a permuted traversal of tensor nonzeros to reduce\natomic-write contention. We test the performance of our implementation on 16-\nand 68-core Intel CPUs and the K80 and P100 NVIDIA GPUs, showing that we are\ncompetitive with state-of-the-art architecture-specific codes while having the\nadvantage of being able to run on a variety of architectures.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 19:19:05 GMT"}, {"version": "v2", "created": "Tue, 22 Jan 2019 00:34:29 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Phipps", "Eric", ""], ["Kolda", "Tamara G.", ""]]}, {"id": "1809.09851", "submitter": "Matthias M\\\"oller", "authors": "Matthias M\\\"oller, Andrzej Jaeschke", "title": "FDBB: Fluid Dynamics Building Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance computing platforms are becoming more and more\nheterogeneous, which makes it very difficult for researchers and scientific\nsoftware developers to keep up with the rapid changes on the hardware market.\nIn this paper, the open-source project FDBB (Fluid Dynamics Building Blocks) is\npresented, which eases the development of fluid dynamics applications for\nheterogeneous systems. It consists of a low-level API that provides a unified\ninterface to many different linear algebra back-ends and a lightweight and\nextendible high-level expression template library, which provides largely\ncustomizable fluid dynamics building blocks, like transformations between\nprimary and secondary variables as well as expressions for Riemann invariants,\nequations of state, inviscid fluxes and their flux-Jacobians. The performance\nof the developed approach is assessed both for synthetic micro-benchmarks and\nwithin mini-applications.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 08:50:08 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["M\u00f6ller", "Matthias", ""], ["Jaeschke", "Andrzej", ""]]}, {"id": "1809.10572", "submitter": "Andrew Anderson", "authors": "Andrew Anderson, David Gregg", "title": "Scalar Arithmetic Multiple Data: Customizable Precision for Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/ARITH.2019.00018", "report-no": null, "categories": "cs.PF cs.CV cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization of weights and activations in Deep Neural Networks (DNNs) is a\npowerful technique for network compression, and has enjoyed significant\nattention and success. However, much of the inference-time benefit of\nquantization is accessible only through the use of customized hardware\naccelerators or by providing an FPGA implementation of quantized arithmetic.\n  Building on prior work, we show how to construct arbitrary bit-precise signed\nand unsigned integer operations using a software technique which logically\n\\emph{embeds} a vector architecture with custom bit-width lanes in universally\navailable fixed-width scalar arithmetic.\n  We evaluate our approach on a high-end Intel Haswell processor, and an\nembedded ARM processor. Our approach yields very fast implementations of\nbit-precise custom DNN operations, which often match or exceed the performance\nof operations quantized to the sizes supported in native arithmetic. At the\nstrongest level of quantization, our approach yields a maximum speedup of\n$\\thicksim6\\times$ on the Intel platform, and $\\thicksim10\\times$ on the ARM\nplatform versus quantization to native 8-bit integers.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 15:25:02 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 15:39:59 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Anderson", "Andrew", ""], ["Gregg", "David", ""]]}]