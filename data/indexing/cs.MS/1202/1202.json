[{"id": "1202.1055", "submitter": "Michael McKerns", "authors": "M. McKerns, H. Owhadi, C. Scovel, T.J. Sullivan, and M. Ortiz", "title": "The Optimal Uncertainty Algorithm in the Mystic Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recently proposed a rigorous framework for Uncertainty Quantification\n(UQ) in which UQ objectives and assumption/information set are brought into the\nforefront, providing a framework for the communication and comparison of UQ\nresults. In particular, this framework does not implicitly impose inappropriate\nassumptions nor does it repudiate relevant information. This framework, which\nwe call Optimal Uncertainty Quantification (OUQ), is based on the observation\nthat given a set of assumptions and information, there exist bounds on\nuncertainties obtained as values of optimization problems and that these bounds\nare optimal. It provides a uniform environment for the optimal solution of the\nproblems of validation, certification, experimental design, reduced order\nmodeling, prediction, extrapolation, all under aleatoric and epistemic\nuncertainties. OUQ optimization problems are extremely large, and even though\nunder general conditions they have finite-dimensional reductions, they must\noften be solved numerically. This general algorithmic framework for OUQ has\nbeen implemented in the mystic optimization framework. We describe this\nimplementation, and demonstrate its use in the context of the Caltech surrogate\nmodel for hypervelocity impact.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 06:45:53 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["McKerns", "M.", ""], ["Owhadi", "H.", ""], ["Scovel", "C.", ""], ["Sullivan", "T. J.", ""], ["Ortiz", "M.", ""]]}, {"id": "1202.1056", "submitter": "Michael McKerns", "authors": "Michael M. McKerns, Leif Strand, Tim Sullivan, Alta Fang, and Michael\n  A. G. Aivazis", "title": "Building a Framework for Predictive Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key questions that scientists and engineers typically want to address can be\nformulated in terms of predictive science. Questions such as: \"How well does my\ncomputational model represent reality?\", \"What are the most important\nparameters in the problem?\", and \"What is the best next experiment to perform?\"\nare fundamental in solving scientific problems. Mystic is a framework for\nmassively-parallel optimization and rigorous sensitivity analysis that enables\nthese motivating questions to be addressed quantitatively as global\noptimization problems. Often realistic physics, engineering, and materials\nmodels may have hundreds of input parameters, hundreds of constraints, and may\nrequire execution times of seconds or longer. In more extreme cases, realistic\nmodels may be multi-scale, and require the use of high-performance computing\nclusters for their evaluation. Predictive calculations, formulated as a global\noptimization over a potential surface in design parameter space, may require an\nalready prohibitively large simulation to be performed hundreds, if not\nthousands, of times. The need to prepare, schedule, and monitor thousands of\nmodel evaluations, and dynamically explore and analyze results, is a\nchallenging problem that requires a software infrastructure capable of\ndistributing and managing computations on large-scale heterogeneous resources.\nIn this paper, we present the design behind an optimization framework, and also\na framework for heterogeneous computing, that when utilized together, can make\ncomputationally intractable sensitivity and optimization problems much more\ntractable.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 06:53:25 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["McKerns", "Michael M.", ""], ["Strand", "Leif", ""], ["Sullivan", "Tim", ""], ["Fang", "Alta", ""], ["Aivazis", "Michael A. G.", ""]]}, {"id": "1202.1490", "submitter": "Aravindh Krishnamoorthy", "authors": "Aravindh Krishnamoorthy, Kenan Kocagoez", "title": "Singular Values using Cholesky Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper two ways to compute singular values are presented which use\nCholesky decomposition as their basic operation.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2012 18:37:07 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Krishnamoorthy", "Aravindh", ""], ["Kocagoez", "Kenan", ""]]}, {"id": "1202.1820", "submitter": "Riccardo Murri", "authors": "Riccardo Murri", "title": "Fatgraph Algorithms and the Homology of the Kontsevich Complex", "comments": "61 pages, 12 figures. Corrected attributions, claims, and\n  bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CG cs.MS math.GT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Fatgraphs are multigraphs enriched with a cyclic order of the edges incident\nto a vertex. This paper presents algorithms to: (1) generate the set of all\nfatgraphs having a given genus and number of boundary cycles; (2) compute\nautomorphisms of any given fatgraph; (3) compute the homology of the fatgraph\ncomplex. The algorithms are suitable for effective computer implementation.\n  In particular, this allows us to compute the rational homology of the moduli\nspace of Riemann surfaces with marked points. We thus compute the Betti numbers\nof $M_{g,n}$ with $(2g + n) \\leq 6$, corroborating known results.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 20:58:11 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2012 20:04:49 GMT"}], "update_date": "2012-02-16", "authors_parsed": [["Murri", "Riccardo", ""]]}, {"id": "1202.2736", "submitter": "Andr\\'e Gaul", "authors": "Andr\\'e Gaul", "title": "Function call overhead benchmarks with MATLAB, Octave, Python, Cython\n  and C", "comments": "The benchmark's source code is available under GPL3 at\n  https://bitbucket.org/andrenarchy/funcall", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.MS math.NA", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We consider the overhead of function calls in the programming languages\nMATLAB/Octave, Python, Cython and C. In many applications a function has to be\ncalled very often inside a loop. One such application in numerical analysis is\nthe finite element method where integrals have to be computed on each element\nin a loop. The called functions can often be evaluated efficiently but the\nfunction call itself may be time-consuming. We present a benchmark whose goal\nis to identify and quantify optimization potentials with respect to time\nconsumption caused by function calls in the mentioned programming languages.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2012 14:14:00 GMT"}], "update_date": "2012-02-14", "authors_parsed": [["Gaul", "Andr\u00e9", ""]]}, {"id": "1202.4061", "submitter": "Matthias Walter", "authors": "Matthias Walter and Klaus Truemper", "title": "Implementation of a Unimodularity Test", "comments": "19 pages, minor reformulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes implementation and computational results of a polynomial\ntest of total unimodularity. The test is a simplified version of a prior\nmethod. The program also decides two related unimodularity properties. The\nsoftware is available free of charge in source code form under the Boost\nSoftware License.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2012 06:49:39 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2012 07:27:24 GMT"}], "update_date": "2012-04-25", "authors_parsed": [["Walter", "Matthias", ""], ["Truemper", "Klaus", ""]]}, {"id": "1202.4384", "submitter": "Paolo Lella", "authors": "Paolo Lella", "title": "Computable Hilbert Schemes", "comments": "This is the PhD thesis of the author. Most of the results appeared or\n  are going to appear in some paper. However the thesis contains more detailed\n  explanations, proofs and remarks and it can be used also as handbook for all\n  algorithms proposed and available at\n  http://www.personalweb.unito.it/paolo.lella/HSC/index.html . arXiv admin\n  note: text overlap with arXiv:1101.2866 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.MS cs.SC math.AC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this PhD thesis we propose an algorithmic approach to the study of the\nHilbert scheme. Developing algorithmic methods, we also obtain general results\nabout Hilbert schemes. In Chapter 1 we discuss the equations defining the\nHilbert scheme as subscheme of a suitable Grassmannian and in Chapter 5 we\ndetermine a new set of equations of degree lower than the degree of equations\nknown so far. In Chapter 2 we study the most important objects used to project\nalgorithmic techniques, namely Borel-fixed ideals. We determine an algorithm\ncomputing all the saturated Borel-fixed ideals with Hilbert polynomial assigned\nand we investigate their combinatorial properties. In Chapter 3 we show a new\ntype of flat deformations of Borel-fixed ideals which lead us to give a new\nproof of the connectedness of the Hilbert scheme. In Chapter 4 we construct\nfamilies of ideals that generalize the notion of family of ideals sharing the\nsame initial ideal with respect to a fixed term ordering. Some of these\nfamilies correspond to open subsets of the Hilbert scheme and can be used to a\nlocal study of the Hilbert scheme. In Chapter 6 we deal with the problem of the\nconnectedness of the Hilbert scheme of locally Cohen-Macaulay curves in the\nprojective 3-space. We show that one of the Hilbert scheme considered a \"good\"\ncandidate to be non-connected, is instead connected. Moreover there are three\nappendices that present and explain how to use the implementations of the\nalgorithms proposed.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 17:05:30 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Lella", "Paolo", ""]]}, {"id": "1202.4535", "submitter": "EPTCS", "authors": "Pedro Quaresma (University of Coimbra, Portugal), Ralph-Johan Back\n  ({\\AA}bo Akademi University, Finland)", "title": "Proceedings First Workshop on CTP Components for Educational Software", "comments": null, "journal-ref": "EPTCS 79, 2012", "doi": "10.4204/EPTCS.79", "report-no": null, "categories": "cs.SY cs.LO cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The THedu'11 workshop received thirteen submissions, twelve of which were\naccepted and presented during the workshop. For the post-conference proceedings\nnine submission where received and accepted. The submissions are within the\nscope of the following points, which have been announced in the call of papers:\nCTP-based software tools for education; CTP technology combined with novel\ninterfaces, drag and drop, etc.; technologies to access ITP knowledge relevant\nfor a certain step of problem solving; usability considerations on representing\nITP knowledge; combination of deduction and computation; formal problem\nspecifications; effectiveness of ATP in checking user input; formats for\ndeductive content in proof documents, geometric constructions, etc; formal\ndomain models for e-learning in mathematics and applications.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 05:56:10 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["Quaresma", "Pedro", "", "University of Coimbra, Portugal"], ["Back", "Ralph-Johan", "", "\u00c5bo Akademi University, Finland"]]}, {"id": "1202.4828", "submitter": "EPTCS", "authors": "Serge Autexier (German Research Center for Artificial Intelligence\n  (DFKI), Bremen, Germany), Dominik Dietrich (German Research Center for\n  Artificial Intelligence (DFKI), Bremen, Germany), Marvin Schiller (Brunel\n  University, London, UK)", "title": "Towards an Intelligent Tutor for Mathematical Proofs", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 1-28", "doi": "10.4204/EPTCS.79.1", "report-no": null, "categories": "cs.AI cs.LO cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-supported learning is an increasingly important form of study since\nit allows for independent learning and individualized instruction. In this\npaper, we discuss a novel approach to developing an intelligent tutoring system\nfor teaching textbook-style mathematical proofs. We characterize the\nparticularities of the domain and discuss common ITS design models. Our\napproach is motivated by phenomena found in a corpus of tutorial dialogs that\nwere collected in a Wizard-of-Oz experiment. We show how an intelligent tutor\nfor textbook-style mathematical proofs can be built on top of an adapted\nassertion-level proof assistant by reusing representations and proof search\nstrategies originally developed for automated and interactive theorem proving.\nThe resulting prototype was successfully evaluated on a corpus of tutorial\ndialogs and yields good results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:41:20 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Autexier", "Serge", "", "German Research Center for Artificial Intelligence"], ["Dietrich", "Dominik", "", "German Research Center for\n  Artificial Intelligence"], ["Schiller", "Marvin", "", "Brunel\n  University, London, UK"]]}, {"id": "1202.4830", "submitter": "EPTCS", "authors": "Francisco Botana, Miguel A. Ab\\'anades", "title": "Automatic Deduction in Dynamic Geometry using Sage", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 49-62", "doi": "10.4204/EPTCS.79.3", "report-no": null, "categories": "cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a symbolic tool that provides robust algebraic methods to handle\nautomatic deduction tasks for a dynamic geometry construction. The main\nprototype has been developed as two different worksheets for the open source\ncomputer algebra system Sage, corresponding to two different ways of coding a\ngeometric construction. In one worksheet, diagrams constructed with the open\nsource dynamic geometry system GeoGebra are accepted. In this worksheet,\nGroebner bases are used to either compute the equation of a geometric locus in\nthe case of a locus construction or to determine the truth of a general\ngeometric statement included in the GeoGebra construction as a boolean\nvariable. In the second worksheet, locus constructions coded using the common\nfile format for dynamic geometry developed by the Intergeo project are accepted\nfor computation. The prototype and several examples are provided for testing.\nMoreover, a third Sage worksheet is presented in which a novel algorithm to\neliminate extraneous parts in symbolically computed loci has been implemented.\nThe algorithm, based on a recent work on the Groebner cover of parametric\nsystems, identifies degenerate components and extraneous adherence points in\nloci, both natural byproducts of general polynomial algebraic methods. Detailed\nexamples are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:41:37 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Botana", "Francisco", ""], ["Ab\u00e1nades", "Miguel A.", ""]]}, {"id": "1202.4831", "submitter": "EPTCS", "authors": "Filip Mari\\'c (Faculty of Mathematics, University of Belgrade,\n  Serbia), Ivan Petrovi\\'c (Faculty of Mathematics, University of Belgrade,\n  Serbia), Danijela Petrovi\\'c (Faculty of Mathematics, University of Belgrade,\n  Serbia), Predrag Jani\\v{c}i\\'c (Faculty of Mathematics, University of\n  Belgrade, Serbia)", "title": "Formalization and Implementation of Algebraic Methods in Geometry", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 63-81", "doi": "10.4204/EPTCS.79.4", "report-no": null, "categories": "cs.SC cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our ongoing project of formalization of algebraic methods for\ngeometry theorem proving (Wu's method and the Groebner bases method), their\nimplementation and integration in educational tools. The project includes\nformal verification of the algebraic methods within Isabelle/HOL proof\nassistant and development of a new, open-source Java implementation of the\nalgebraic methods. The project should fill-in some gaps still existing in this\narea (e.g., the lack of formal links between algebraic methods and synthetic\ngeometry and the lack of self-contained implementations of algebraic methods\nsuitable for integration with dynamic geometry tools) and should enable new\napplications of theorem proving in education.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:41:45 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Mari\u0107", "Filip", "", "Faculty of Mathematics, University of Belgrade,\n  Serbia"], ["Petrovi\u0107", "Ivan", "", "Faculty of Mathematics, University of Belgrade,\n  Serbia"], ["Petrovi\u0107", "Danijela", "", "Faculty of Mathematics, University of Belgrade,\n  Serbia"], ["Jani\u010di\u0107", "Predrag", "", "Faculty of Mathematics, University of\n  Belgrade, Serbia"]]}, {"id": "1202.4833", "submitter": "EPTCS", "authors": "Vanda Santos (CISUC/ESTGV - IPV), Pedro Quaresma (CISUC/Department of\n  Mathematics, University of Coimbra)", "title": "Integrating DGSs and GATPs in an Adaptative and Collaborative\n  Blended-Learning Web-Environment", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 111-123", "doi": "10.4204/EPTCS.79.7", "report-no": null, "categories": "cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The area of geometry with its very strong and appealing visual contents and\nits also strong and appealing connection between the visual content and its\nformal specification, is an area where computational tools can enhance, in a\nsignificant way, the learning environments.\n  The dynamic geometry software systems (DGSs) can be used to explore the\nvisual contents of geometry. This already mature tools allows an easy\nconstruction of geometric figures build from free objects and elementary\nconstructions. The geometric automated theorem provers (GATPs) allows formal\ndeductive reasoning about geometric constructions, extending the reasoning via\nconcrete instances in a given model to formal deductive reasoning in a\ngeometric theory.\n  An adaptative and collaborative blended-learning environment where the DGS\nand GATP features could be fully explored would be, in our opinion a very rich\nand challenging learning environment for teachers and students.\n  In this text we will describe the Web Geometry Laboratory a Web environment\nincorporating a DGS and a repository of geometric problems, that can be used in\na synchronous and asynchronous fashion and with some adaptative and\ncollaborative features.\n  As future work we want to enhance the adaptative and collaborative aspects of\nthe environment and also to incorporate a GATP, constructing a dynamic and\nindividualised learning environment for geometry.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:42:02 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Santos", "Vanda", "", "CISUC/ESTGV - IPV"], ["Quaresma", "Pedro", "", "CISUC/Department of\n  Mathematics, University of Coimbra"]]}, {"id": "1202.4834", "submitter": "EPTCS", "authors": "Wolfgang Schreiner", "title": "Computer-Assisted Program Reasoning Based on a Relational Semantics of\n  Programs", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 124-142", "doi": "10.4204/EPTCS.79.8", "report-no": null, "categories": "cs.LO cs.MS cs.PL cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to program reasoning which inserts between a program\nand its verification conditions an additional layer, the denotation of the\nprogram expressed in a declarative form. The program is first translated into\nits denotation from which subsequently the verification conditions are\ngenerated. However, even before (and independently of) any verification\nattempt, one may investigate the denotation itself to get insight into the\n\"semantic essence\" of the program, in particular to see whether the denotation\nindeed gives reason to believe that the program has the expected behavior.\nErrors in the program and in the meta-information may thus be detected and\nfixed prior to actually performing the formal verification. More concretely,\nfollowing the relational approach to program semantics, we model the effect of\na program as a binary relation on program states. A formal calculus is devised\nto derive from a program a logic formula that describes this relation and is\nsubject for inspection and manipulation. We have implemented this idea in a\ncomprehensive form in the RISC ProgramExplorer, a new program reasoning\nenvironment for educational purposes which encompasses the previously developed\nRISC ProofNavigator as an interactive proving assistant.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:42:11 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Schreiner", "Wolfgang", ""]]}, {"id": "1202.4835", "submitter": "EPTCS", "authors": "Makarius Wenzel, Burkhart Wolff", "title": "Isabelle/PIDE as Platform for Educational Tools", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 143-153", "doi": "10.4204/EPTCS.79.9", "report-no": null, "categories": "cs.LO cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Isabelle/PIDE platform addresses the question whether proof assistants of\nthe LCF family are suitable as technological basis for educational tools. The\ntraditionally strong logical foundations of systems like HOL, Coq, or Isabelle\nhave so far been counter-balanced by somewhat inaccessible interaction via the\nTTY (or minor variations like the well-known Proof General / Emacs interface).\nThus the fundamental question of math education tools with fully-formal\nbackground theories has often been answered negatively due to accidental\nweaknesses of existing proof engines.\n  The idea of \"PIDE\" (which means \"Prover IDE\") is to integrate existing\nprovers like Isabelle into a larger environment, that facilitates access by\nend-users and other tools. We use Scala to expose the proof engine in ML to the\nJVM world, where many user-interfaces, editor frameworks, and educational tools\nalready exist. This shall ultimately lead to combined mathematical assistants,\nwhere the logical engine is in the background, without obstructing the view on\napplications of formal methods, formalized mathematics, and math education in\nparticular.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:42:17 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Wenzel", "Makarius", ""], ["Wolff", "Burkhart", ""]]}, {"id": "1202.4837", "submitter": "EPTCS", "authors": "Jordi Saludes (UPC), Sebastian Xamb\\'o (UPC)", "title": "The GF Mathematics Library", "comments": "In Proceedings THedu'11, arXiv:1202.4535", "journal-ref": "EPTCS 79, 2012, pp. 102-110", "doi": "10.4204/EPTCS.79.6", "report-no": null, "categories": "cs.MS cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to present the Mathematics Grammar Library, a system\nfor multilingual mathematical text processing. We explain the context in which\nit originated, its current design and functionality and the current development\ngoals. We also present two prototype services and comment on possible future\napplications in the area of artificial mathematics assistants.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 06:43:11 GMT"}], "update_date": "2012-02-23", "authors_parsed": [["Saludes", "Jordi", "", "UPC"], ["Xamb\u00f3", "Sebastian", "", "UPC"]]}, {"id": "1202.5964", "submitter": "Olivia Saierli", "authors": "Muhammad Taimoor Khan and Anila Usman", "title": "Technique detection software for Sparse Matrices", "comments": "10 pages", "journal-ref": "Ann. Univ. Tibiscus Comp. Sci. Series VII/2 (2009), 57-66", "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse storage formats are techniques for storing and processing the sparse\nmatrix data efficiently. The performance of these storage formats depend upon\nthe distribution of non-zeros, within the matrix in different dimensions. In\norder to have better results we need a technique that suits best the\norganization of data in a particular matrix. So the decision of selecting a\nbetter technique is the main step towards improving the system's results\notherwise the efficiency can be decreased. The purpose of this research is to\nhelp identify the best storage format in case of reduced storage size and high\nprocessing efficiency for a sparse matrix.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2012 15:02:13 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["Khan", "Muhammad Taimoor", ""], ["Usman", "Anila", ""]]}, {"id": "1202.6522", "submitter": "Nathana\\\"el Schaeffer", "authors": "Nathana\\\"el Schaeffer", "title": "Efficient Spherical Harmonic Transforms aimed at pseudo-spectral\n  numerical simulations", "comments": "8 pages", "journal-ref": "Geochemistry, Geophysics, Geosystems, American Geophysical Union\n  (AGU), 2013, 14 (3), pp.751-758", "doi": "10.1002/ggge.20071", "report-no": null, "categories": "physics.comp-ph cs.MS cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report on very efficient algorithms for the spherical\nharmonic transform (SHT). Explicitly vectorized variations of the algorithm\nbased on the Gauss-Legendre quadrature are discussed and implemented in the\nSHTns library which includes scalar and vector transforms. The main\nbreakthrough is to achieve very efficient on-the-fly computations of the\nLegendre associated functions, even for very high resolutions, by taking\nadvantage of the specific properties of the SHT and the advanced capabilities\nof current and future computers. This allows us to simultaneously and\nsignificantly reduce memory usage and computation time of the SHT. We measure\nthe performance and accuracy of our algorithms. Even though the complexity of\nthe algorithms implemented in SHTns are in $O(N^3)$ (where N is the maximum\nharmonic degree of the transform), they perform much better than any third\nparty implementation, including lower complexity algorithms, even for\ntruncations as high as N=1023. SHTns is available at\nhttps://bitbucket.org/nschaeff/shtns as open source software.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 12:05:12 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2012 13:37:52 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2013 13:20:31 GMT"}, {"version": "v4", "created": "Thu, 20 Nov 2014 15:14:32 GMT"}, {"version": "v5", "created": "Wed, 7 Jan 2015 14:40:46 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Schaeffer", "Nathana\u00ebl", ""]]}, {"id": "1202.6548", "submitter": "Davide Albanese", "authors": "Davide Albanese and Roberto Visintainer and Stefano Merler and\n  Samantha Riccadonna and Giuseppe Jurman and Cesare Furlanello", "title": "mlpy: Machine Learning Python", "comments": "Corrected a few typos; rephrased two sentences in the Overview\n  section", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  mlpy is a Python Open Source Machine Learning library built on top of\nNumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of\nstate-of-the-art machine learning methods for supervised and unsupervised\nproblems and it is aimed at finding a reasonable compromise among modularity,\nmaintainability, reproducibility, usability and efficiency. mlpy is\nmultiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at\nthe website http://mlpy.fbk.eu.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 13:49:10 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2012 13:31:54 GMT"}], "update_date": "2012-03-02", "authors_parsed": [["Albanese", "Davide", ""], ["Visintainer", "Roberto", ""], ["Merler", "Stefano", ""], ["Riccadonna", "Samantha", ""], ["Jurman", "Giuseppe", ""], ["Furlanello", "Cesare", ""]]}]