[{"id": "2012.00280", "submitter": "Alberto F. Mart\\'in", "authors": "Santiago Badia and Manuel Caicedo and Alberto F. Mart\\'in and Javier\n  Principe", "title": "A robust and scalable unfitted adaptive finite element framework for\n  nonlinear solid mechanics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we bridge standard adaptive mesh refinement and coarsening on\nscalable octree background meshes and robust unfitted finite element\nformulations for the automatic and efficient solution of large-scale nonlinear\nsolid mechanics problems posed on complex geometries, as an alternative to\nstandard body-fitted formulations, unstructured mesh generation and graph\npartitioning strategies. We pay special attention to those aspects requiring a\nspecialized treatment in the extension of the unfitted h-adaptive aggregated\nfinite element method on parallel tree-based adaptive meshes, recently\ndeveloped for linear scalar elliptic problems, to handle nonlinear problems in\nsolid mechanics. In order to accurately and efficiently capture localized\nphenomena that frequently occur in nonlinear solid mechanics problems, we\nperform pseudo time-stepping in combination with h-adaptive dynamic mesh\nrefinement and rebalancing driven by a-posteriori error estimators. The method\nis implemented considering both irreducible and mixed (u/p) formulations and\nthus it is able to robustly face problems involving incompressible materials.\nIn the numerical experiments, both formulations are used to model the inelastic\nbehavior of a wide range of compressible and incompressible materials. First, a\nselected set of benchmarks are reproduced as a verification step. Second, a set\nof experiments is presented with problems involving complex geometries. Among\nthem, we model a cantilever beam problem with spherical hollows distributed in\na Simple Cubic array. This test involves a discrete domain with up to 11.7M\nDegrees Of Freedom solved in less than two hours on 3072 cores of a parallel\nsupercomputer.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 05:37:24 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 00:34:04 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 07:20:36 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Badia", "Santiago", ""], ["Caicedo", "Manuel", ""], ["Mart\u00edn", "Alberto F.", ""], ["Principe", "Javier", ""]]}, {"id": "2012.00506", "submitter": "Shengguo Li", "authors": "Shengguo Li, Xinzhe Wu, Jose E. Roman, Ziyang Yuan and Lizhi Cheng", "title": "A Parallel Direct Eigensolver for Sequences of Hermitian Eigenvalue\n  Problems with No Tridiagonalization", "comments": "24 pages and 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, a Parallel Direct Eigensolver for Sequences of Hermitian\nEigenvalue Problems with no tridiagonalization is proposed, denoted by\n\\texttt{PDESHEP}, and it combines direct methods with iterative methods.\n\\texttt{PDESHEP} first reduces a Hermitian matrix to its banded form, then\napplies a spectrum slicing algorithm to the banded matrix, and finally computes\nthe eigenvectors of the original matrix via backtransform. Therefore, compared\nwith conventional direct eigensolvers, \\texttt{PDESHEP} avoids\ntridiagonalization, which consists of many memory-bounded operations. In this\nwork, the iterative method in \\texttt{PDESHEP} is based on the contour integral\nmethod implemented in FEAST. The combination of direct methods with iterative\nmethods for banded matrices requires some efficient data redistribution\nalgorithms both from 2D to 1D and from 1D to 2D data structures. Hence, some\ntwo-step data redistribution algorithms are proposed, which can be $10\\times$\nfaster than ScaLAPACK routine \\texttt{PXGEMR2D}. For the symmetric\nself-consistent field (SCF) eigenvalue problems, \\texttt{PDESHEP} can be on\naverage $1.25\\times$ faster than the state-of-the-art direct solver in ELPA\nwhen using $4096$ processes. Numerical results are obtained for dense Hermitian\nmatrices from real applications and large real sparse matrices from the\nSuiteSparse collection.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 14:21:18 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Li", "Shengguo", ""], ["Wu", "Xinzhe", ""], ["Roman", "Jose E.", ""], ["Yuan", "Ziyang", ""], ["Cheng", "Lizhi", ""]]}, {"id": "2012.01520", "submitter": "Daniel Dunlavy", "authors": "Jeremy M. Myers, Daniel M. Dunlavy, Keita Teranishi, D. S. Hollman", "title": "Parameter Sensitivity Analysis of the SparTen High Performance Sparse\n  Tensor Decomposition Software: Extended Analysis", "comments": "33 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": "SAND2020-11901R", "categories": "math.NA cs.MS cs.NA cs.PF stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition models play an increasingly important role in modern\ndata science applications. One problem of particular interest is fitting a\nlow-rank Canonical Polyadic (CP) tensor decomposition model when the tensor has\nsparse structure and the tensor elements are nonnegative count data. SparTen is\na high-performance C++ library which computes a low-rank decomposition using\ndifferent solvers: a first-order quasi-Newton or a second-order damped Newton\nmethod, along with the appropriate choice of runtime parameters. Since default\nparameters in SparTen are tuned to experimental results in prior published work\non a single real-world dataset conducted using MATLAB implementations of these\nmethods, it remains unclear if the parameter defaults in SparTen are\nappropriate for general tensor data. Furthermore, it is unknown how sensitive\nalgorithm convergence is to changes in the input parameter values. This report\naddresses these unresolved issues with large-scale experimentation on three\nbenchmark tensor data sets. Experiments were conducted on several different CPU\narchitectures and replicated with many initial states to establish generalized\nprofiles of algorithm convergence behavior.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 20:47:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Myers", "Jeremy M.", ""], ["Dunlavy", "Daniel M.", ""], ["Teranishi", "Keita", ""], ["Hollman", "D. S.", ""]]}, {"id": "2012.02590", "submitter": "Ryan Krueger", "authors": "Ryan Krueger, Jesse Michael Han and Daniel Selsam", "title": "Automatically Building Diagrams for Olympiad Geometry Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for automatically building diagrams for olympiad-level\ngeometry problems and implement our approach in a new open-source software\ntool, the Geometry Model Builder (GMB). Central to our method is a new\ndomain-specific language, the Geometry Model-Building Language (GMBL), for\nspecifying geometry problems along with additional metadata useful for building\ndiagrams. A GMBL program specifies (1) how to parameterize geometric objects\n(or sets of geometric objects) and initialize these parameterized quantities,\n(2) which quantities to compute directly from other quantities, and (3)\nadditional constraints to accumulate into a (differentiable) loss function. A\nGMBL program induces a (usually) tractable numerical optimization problem whose\nsolutions correspond to diagrams of the original problem statement, and that we\ncan solve reliably using gradient descent. Of the 39 geometry problems since\n2000 appearing in the International Mathematical Olympiad, 36 can be expressed\nin our logic and our system can produce diagrams for 94% of them on average. To\nthe best of our knowledge, our method is the first in automated geometry\ndiagram construction to generate models for such complex problems.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 05:56:25 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 00:41:22 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Krueger", "Ryan", ""], ["Han", "Jesse Michael", ""], ["Selsam", "Daniel", ""]]}, {"id": "2012.02746", "submitter": "Stephan Hageboeck", "authors": "Stephan Hageboeck", "title": "What the new RooFit can do for your analysis", "comments": "6 pages, 4 figures, submitted to Proceedings of Science (ICHEP 2020)\n  v2: Minor rephrasing to address comments by reviewers", "journal-ref": "PoS(ICHEP2020)910", "doi": "10.22323/1.390.0910", "report-no": null, "categories": "physics.data-an cs.MS hep-ex", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  RooFit is a toolkit for statistical modelling and fitting, and together with\nRooStats it is used for measurements and statistical tests by most experiments\nin particle physics. Since one year, RooFit is being modernised. In this talk,\nimprovements already released with ROOT will be discussed, such as faster data\nloading, vectorised computations and more standard-like interfaces. These allow\nfor speeding up unbinned fits by several factors, and make RooFit easier to use\nfrom both C++ and Python.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 17:55:30 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 13:55:25 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Hageboeck", "Stephan", ""]]}, {"id": "2012.03437", "submitter": "Matthew Francis-Landau", "authors": "Matthew Francis-Landau", "title": "MFST: A Python OpenFST Wrapper With Support for Custom Semirings and\n  Jupyter Notebooks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces mFST, a new Python library for working with\nFinite-State Machines based on OpenFST. mFST is a thin wrapper for OpenFST and\nexposes all of OpenFST's methods for manipulating FSTs. Additionally, mFST is\nthe only Python wrapper for OpenFST that exposes OpenFST's ability to define a\ncustom semirings. This makes mFST ideal for developing models that involve\nlearning the weights on a FST or creating neuralized FSTs. mFST has been\ndesigned to be easy to get started with and has been previously used in\nhomework assignments for a NLP class as well in projects for integrating FSTs\nand neural networks. In this paper, we exhibit mFST API and how to use mFST to\nbuild a simple neuralized FST with PyTorch.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 03:36:54 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Francis-Landau", "Matthew", ""]]}, {"id": "2012.03771", "submitter": "Seth Troisi", "authors": "Seth Troisi", "title": "Combined Sieve Algorithm for Prime Gaps", "comments": "10 pages, 4 figures, Open source code (GitHub), active development", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NT cs.MS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A new Combined Sieve algorithm is presented with cost proportional to the\nnumber of enumerated factors over a series of intervals. This algorithm\nachieves a significant speedup, over a traditional sieve, when handling many\n([10^4, 10^7]) intervals concurrently. The speedup comes from a space-time\ntradeoff and a novel solution to a modular equation. In real world tests, this\nnew algorithm regularly runs 10,000x faster. This faster sieve paired with\nhigher sieving limits eliminates more composites and accelerates the search for\nlarge prime gaps by 30-70%. During the development and testing of this new\nalgorithm, two top-10 record merit prime gaps were discovered.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 10:25:20 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Troisi", "Seth", ""]]}, {"id": "2012.04740", "submitter": "Jacob Montiel", "authors": "Jacob Montiel, Max Halford, Saulo Martiello Mastelini, Geoffrey\n  Bolmier, Raphael Sourty, Robin Vaysse, Adil Zouitine, Heitor Murilo Gomes,\n  Jesse Read, Talel Abdessalem, Albert Bifet", "title": "River: machine learning for streaming data in Python", "comments": "Submitted to JMLR MLOSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  River is a machine learning library for dynamic data streams and continual\nlearning. It provides multiple state-of-the-art learning methods, data\ngenerators/transformers, performance metrics and evaluators for different\nstream learning problems. It is the result from the merger of the two most\npopular packages for stream learning in Python: Creme and scikit-multiflow.\nRiver introduces a revamped architecture based on the lessons learnt from the\nseminal packages. River's ambition is to be the go-to library for doing machine\nlearning on streaming data. Additionally, this open source package brings under\nthe same umbrella a large community of practitioners and researchers. The\nsource code is available at https://github.com/online-ml/river.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 21:04:44 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Montiel", "Jacob", ""], ["Halford", "Max", ""], ["Mastelini", "Saulo Martiello", ""], ["Bolmier", "Geoffrey", ""], ["Sourty", "Raphael", ""], ["Vaysse", "Robin", ""], ["Zouitine", "Adil", ""], ["Gomes", "Heitor Murilo", ""], ["Read", "Jesse", ""], ["Abdessalem", "Talel", ""], ["Bifet", "Albert", ""]]}, {"id": "2012.06144", "submitter": "Markus Holzer", "authors": "Markus Holzer, Martin Bauer, Ulrich R\\\"ude", "title": "Highly Efficient Lattice-Boltzmann Multiphase Simulations of Immiscible\n  Fluids at High-Density Ratios on CPUs and GPUs through Code Generation", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A high-performance implementation of a multiphase lattice Boltzmann method\nbased on the conservative Allen-Cahn model supporting high-density ratios and\nhigh Reynolds numbers is presented. Metaprogramming techniques are used to\ngenerate optimized code for CPUs and GPUs automatically. The coupled model is\nspecified in a high-level symbolic description and optimized through automatic\ntransformations. The memory footprint of the resulting algorithm is reduced\nthrough the fusion of compute kernels. A roofline analysis demonstrates the\nexcellent efficiency of the generated code on a single GPU. The resulting\nsingle GPU code has been integrated into the multiphysics framework waLBerla to\nrun massively parallel simulations on large domains. Communication hiding and\nGPUDirect-enabled MPI yield near-perfect scaling behaviour. Scaling experiments\nare conducted on the Piz Daint supercomputer with up to 2048 GPUs, simulating\nseveral hundred fully resolved bubbles. Further, validation of the\nimplementation is shown in a physically relevant scenario-a three-dimensional\nrising air bubble in water.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:07:58 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Holzer", "Markus", ""], ["Bauer", "Martin", ""], ["R\u00fcde", "Ulrich", ""]]}, {"id": "2012.06607", "submitter": "Jan Verschelde", "authors": "Jan Verschelde", "title": "Parallel Software to Offset the Cost of Higher Precision", "comments": "The paper corresponds to a talk given by the author at the HILT 2020\n  Workshop on Safe Languages and Technologies for Structured and Efficient\n  Parallel and Distributed/Cloud Computing, 16-17 November 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA cs.SC math.AG math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware double precision is often insufficient to solve large scientific\nproblems accurately. Computing in higher precision defined by software causes\nsignificant computational overhead. The application of parallel algorithms\ncompensates for this overhead. Newton's method to develop power series\nexpansions of algebraic space curves is the use case for this application.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 19:23:55 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Verschelde", "Jan", ""]]}, {"id": "2012.08208", "submitter": "Abhinav Gupta", "authors": "Abhinav Gupta, Rajib Chowdhury, Anupam Chakrabarti, Timon Rabczuk", "title": "A 55-line code for large-scale parallel topology optimization in 2D and\n  3D", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a 55-line code written in python for 2D and 3D topology\noptimization (TO) based on the open-source finite element computing software\n(FEniCS), equipped with various finite element tools and solvers. PETSc is used\nas the linear algebra back-end, which results in significantly less\ncomputational time than standard python libraries. The code is designed based\non the popular solid isotropic material with penalization (SIMP) methodology.\nExtensions to multiple load cases, different boundary conditions, and\nincorporation of passive elements are also presented. Thus, this implementation\nis the most compact implementation of SIMP based topology optimization for 3D\nas well as 2D problems.\n  Utilizing the concept of Euclidean distance matrix to vectorize the\ncomputation of the weight matrix for the filter, we have achieved a substantial\nreduction in the computational time and have also made it possible for the code\nto work with complex ground structure configurations. We have also presented\nthe code's extension to large-scale topology optimization problems with support\nfor parallel computations on complex structural configuration, which could help\nstudents and researchers explore novel insights into the TO problem with dense\nmeshes. Appendix-A contains the complete code, and the website:\n\\url{https://github.com/iitrabhi/topo-fenics} also contains the complete code.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 10:57:16 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Gupta", "Abhinav", ""], ["Chowdhury", "Rajib", ""], ["Chakrabarti", "Anupam", ""], ["Rabczuk", "Timon", ""]]}, {"id": "2012.11011", "submitter": "Theodore Omtzigt", "authors": "E. Theodore L. Omtzigt, Peter Gottschling, Mark Seligman, William Zorn", "title": "Universal Numbers Library: design and implementation of a\n  high-performance reproducible number systems library", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the proliferation of embedded systems requiring intelligent behavior,\ncustom number systems to optimize performance per Watt of the entire system\nbecome essential components for successful commercial products. We present the\nUniversal Number Library, a high-performance number systems library that\nincludes arbitrary integer, decimal, fixed-point, floating-point, and\nintroduces two tapered floating-point types, posit and valid, that support\nreproducible arithmetic computation in arbitrary concurrency environments. We\ndiscuss the design of the Universal library as a run-time for application\ndevelopment, and as a platform for application-driven hardware validation. The\nlibrary implementation is described, and examples are provided to show\neducational examples to elucidate the number system properties, and how\nspecialization is used to yield very high-performance emulation on existing\nx86, ARM, and POWER processors. We will highlight the integration of the\nlibrary in larger application environments in computational science and\nengineering to enable multi-precision and adaptive precision algorithms to\nimprove performance and efficiency of large scale and real-time applications.\nWe will demonstrate the integration of the Universal library into a\nhigh-performance reproducible linear algebra run-time. We will conclude with\nthe roadmap of additional functionality of the library as we are targeting new\napplication domains, such as Software Defined Radio, instrumentation, sensor\nfusion, and model-predictive control.\n", "versions": [{"version": "v1", "created": "Sun, 20 Dec 2020 20:07:57 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Omtzigt", "E. Theodore L.", ""], ["Gottschling", "Peter", ""], ["Seligman", "Mark", ""], ["Zorn", "William", ""]]}, {"id": "2012.12264", "submitter": "Oylum \\c{S}eker", "authors": "Oylum \\c{S}eker and Neda Tanoumand and Merve Bodur", "title": "Digital Annealer for quadratic unconstrained binary optimization: a\n  comparative performance analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Annealer (DA) is a computer architecture designed for tackling\ncombinatorial optimization problems formulated as quadratic unconstrained\nbinary optimization (QUBO) models. In this paper, we present the results of an\nextensive computational study to evaluate the performance of DA in a systematic\nway in comparison to multiple state-of-the-art solvers for different problem\nclasses. We examine pure QUBO models, as well as QUBO reformulations of three\nconstrained problems, namely quadratic assignment, quadratic cycle partition,\nand selective graph coloring, with the last two being new applications for DA.\nFor the selective graph coloring problem, we also present a size reduction\nheuristic that significantly increases the number of eligible instances for DA.\nOur experimental results show that despite being in its development stage, DA\ncan provide high-quality solutions quickly and in that regard rivals the state\nof the art, particularly for large instances. Moreover, as opposed to\nestablished solvers, within its limit on the number of decision variables, DA's\nsolution times are not affected by the increase in instance size. These\nfindings illustrate that DA has the potential to become a successful technology\nin tackling combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 09:12:27 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["\u015eeker", "Oylum", ""], ["Tanoumand", "Neda", ""], ["Bodur", "Merve", ""]]}, {"id": "2012.12696", "submitter": "Michael Lindner", "authors": "Michael Lindner and Lucas Lincoln and Fenja Drauschke and Julia Monika\n  Koulen and Hans W\\\"urfel and Anton Plietzsch and Frank Hellmann", "title": "NetworkDynamics.jl -- Composing and simulating complex networks in Julia", "comments": "This article may be downloaded for personal use only. Any other use\n  requires prior permission of the author and AIP Publishing. This article\n  appeared in Chaos 31, 063133 (2021) and may be found at\n  https://aip.scitation.org/doi/10.1063/5.0051387", "journal-ref": "Chaos 31, 063133 (2021)", "doi": "10.1063/5.0051387", "report-no": null, "categories": "cs.MS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NetworkDynamics.jl is an easy-to-use and computationally efficient package\nfor working with heterogeneous dynamical systems on complex networks, written\nin Julia, a high-level, high-performance, dynamic programming language. By\ncombining state of the art solver algorithms from DifferentialEquations.jl with\nefficient data structures, NetworkDynamics.jl achieves top performance while\nsupporting advanced features like events, algebraic constraints, time-delays,\nnoise terms and automatic differentiation.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 11:41:24 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 14:39:02 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 08:21:31 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lindner", "Michael", ""], ["Lincoln", "Lucas", ""], ["Drauschke", "Fenja", ""], ["Koulen", "Julia Monika", ""], ["W\u00fcrfel", "Hans", ""], ["Plietzsch", "Anton", ""], ["Hellmann", "Frank", ""]]}, {"id": "2012.14287", "submitter": "Simon Dirckx", "authors": "Simon Dirckx and Daan Huybrechs and Karl Meerbergen", "title": "Frequency extraction for BEM-matrices arising from the 3D scalar\n  Helmholtz equation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The discretisation of boundary integral equations for the scalar Helmholtz\nequation leads to large dense linear systems. Efficient boundary element\nmethods (BEM), such as the fast multipole method (FMM) and H-matrix based\nmethods, focus on structured low-rank approximations of subblocks in these\nsystems. It is known that the ranks of these subblocks increase with the\nwavenumber. We explore a data-sparse representation of BEM-matrices valid for a\nrange of frequencies, based on extracting the known phase of the Green's\nfunction. Algebraically, this leads to a Hadamard product of a frequency matrix\nwith an H-matrix. We show that the frequency dependency of this H-matrix can be\ndetermined using a small number of frequency samples, even for geometrically\ncomplex three-dimensional scattering obstacles. We describe an efficient\nconstruction of the representation by combining adaptive cross approximation\nwith adaptive rational approximation in the continuous frequency dimension. We\nshow that our data-sparse representation allows to efficiently sample the full\nBEM-matrix at any given frequency, and as such it may be useful as part of an\nefficient sweeping routine.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 15:32:34 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Dirckx", "Simon", ""], ["Huybrechs", "Daan", ""], ["Meerbergen", "Karl", ""]]}]