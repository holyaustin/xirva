[{"id": "2107.01243", "submitter": "Niclas Jansson", "authors": "Niclas Jansson, Martin Karp, Artur Podobas, Stefano Markidis, Philipp\n  Schlatter", "title": "Neko: A Modern, Portable, and Scalable Framework for High-Fidelity\n  Computational Fluid Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends and advancement in including more diverse and heterogeneous\nhardware in High-Performance Computing is challenging software developers in\ntheir pursuit for good performance and numerical stability. The well-known\nmaxim \"software outlives hardware\" may no longer necessarily hold true, and\ndevelopers are today forced to re-factor their codebases to leverage these\npowerful new systems. CFD is one of the many application domains affected. In\nthis paper, we present Neko, a portable framework for high-order spectral\nelement flow simulations. Unlike prior works, Neko adopts a modern\nobject-oriented approach, allowing multi-tier abstractions of the solver stack\nand facilitating hardware backends ranging from general-purpose processors down\nto exotic vector processors and FPGAs. We show that Neko's performance and\naccuracy are comparable to NekRS, and thus on-par with Nek5000's successor on\nmodern CPU machines. Furthermore, we develop a performance model, which we use\nto discuss challenges and opportunities for high-order solvers on emerging\nhardware.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 19:28:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Jansson", "Niclas", ""], ["Karp", "Martin", ""], ["Podobas", "Artur", ""], ["Markidis", "Stefano", ""], ["Schlatter", "Philipp", ""]]}, {"id": "2107.01384", "submitter": "Wouter Baert", "authors": "Wouter Baert, Nick Vannieuwenhoven", "title": "ATC: an Advanced Tucker Compression library for multidimensional data", "comments": "The ATC software is publicly available at the following repository:\n  https://gitlab.kuleuven.be/u0118878/atc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ATC, a C++ library for advanced Tucker-based compression of\nmultidimensional numerical data, based on the sequentially truncated\nhigher-order singular value decomposition (ST-HOSVD) and bit plane truncation.\nSeveral techniques are proposed to improve compression rate, speed, memory\nusage and error control. First, a hybrid truncation scheme is described which\ncombines Tucker rank truncation and TTHRESH quantization [Ballester-Ripoll et\nal., IEEE Trans. Visual. Comput. Graph., 2020]. We derive a novel expression to\napproximate the error of truncated Tucker decompositions in the case of core\nand factor perturbations. Furthermore, a Householder-reflector-based approach\nis proposed to compress the orthogonal Tucker factors. Certain key improvements\nto the quantization procedure are also discussed. Moreover, particular\nimplementation aspects are described, such as ST-HOSVD procedure using only a\nsingle transposition. We also discuss several usability features of ATC,\nincluding the presence of multiple interfaces, extensive data type support and\nintegrated downsampling of the decompressed data. Numerical results show that\nATC maintains state-of-the-art Tucker compression rates, while providing\naverage speed-ups of 2.6-3.6 and halving memory usage. Furthermore, our\ncompressor provides precise error control, only deviating 1.4% from the\nrequested error on average. Finally, ATC often achieves significantly higher\ncompression than non-Tucker-based compressors in the high-error domain.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 08:58:42 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Baert", "Wouter", ""], ["Vannieuwenhoven", "Nick", ""]]}, {"id": "2107.02205", "submitter": "Linas Stripinis Dr.", "authors": "Linas Stripinis and Remigijus Paulavi\\v{c}ius", "title": "DGO: A new DIRECT-type MATLAB toolbox for derivative-free global\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we introduce DGO, a new MATLAB toolbox for derivative-free\nglobal optimization. DGO collects various deterministic derivative-free\nDIRECT-type algorithms for box-constrained, generally-constrained, and problems\nwith hidden constraints. Each sequential algorithm is implemented in two\ndifferent ways: using static and dynamic data structures for more efficient\ninformation storage and organization. Furthermore, parallel schemes are applied\nto some promising algorithms within DGO. The toolbox is equipped with a\ngraphical user interface (GUI), which ensures the user-friendly use of all\nfunctionalities available in DGO. Available features are demonstrated in\ndetailed computational studies using a created comprehensive library of global\noptimization problems. Additionally, eleven classical engineering design\nproblems are used to illustrate the potential of DGO to solve challenging\nreal-world problems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:13:21 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Stripinis", "Linas", ""], ["Paulavi\u010dius", "Remigijus", ""]]}, {"id": "2107.04097", "submitter": "Alex Massarenti", "authors": "Antonio Laface, Alex Massarenti, Rick Rischter", "title": "Decomposition algorithms for tensors and polynomials", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give algorithms to compute decompositions of a given polynomial, or more\ngenerally mixed tensor, as sum of rank one tensors, and to establish whether\nsuch a decomposition is unique. In particular, we present methods to compute\nthe decomposition of a general plane quintic in seven powers, and of a general\nspace cubic in five powers; the two decompositions of a general plane sextic of\nrank nine, and the five decompositions of a general plane septic. Furthermore,\nwe give Magma implementations of all our algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 20:31:05 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Laface", "Antonio", ""], ["Massarenti", "Alex", ""], ["Rischter", "Rick", ""]]}, {"id": "2107.04121", "submitter": "Robert Cimrman", "authors": "Robert Cimrman", "title": "Fast Evaluation of Finite Element Weak Forms Using Python Tensor\n  Contraction Packages", "comments": null, "journal-ref": null, "doi": "10.1016/j.advengsoft.2021.103033", "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In finite element calculations, the integral forms are usually evaluated\nusing nested loops over elements, and over quadrature points. Many such forms\n(e.g. linear or multi-linear) can be expressed in a compact way, without the\nexplicit loops, using a single tensor contraction expression by employing the\nEinstein summation convention. To automate this process and leverage existing\nhigh performance codes, we first introduce a notation allowing trivial\ndifferentiation of multi-linear finite element forms. Based on that we propose\nand describe a new transpiler from Einstein summation based expressions,\naugmented to allow defining multi-linear finite element weak forms, to regular\ntensor contraction expressions. The resulting expressions are compatible with a\nnumber of Python scientific computing packages, that implement, optimize and in\nsome cases parallelize the general tensor contractions. We assess the\nperformance of those packages, as well as the influence of operand memory\nlayouts and tensor contraction paths optimizations on the elapsed time and\nmemory requirements of the finite element form evaluations. We also compare the\nefficiency of the transpiled weak form implementations to the C-based functions\navailable in the finite element package SfePy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:08:24 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Cimrman", "Robert", ""]]}, {"id": "2107.04632", "submitter": "Mart\\'i Pedemonte", "authors": "Mart\\'i Pedemonte, Jordi Vitri\\`a and \\'Alvaro Parafita (Universitat\n  de Barcelona)", "title": "Algorithmic Causal Effect Identification with causaleffect", "comments": "40 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.AI math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our evolution as a species made a huge step forward when we understood the\nrelationships between causes and effects. These associations may be trivial for\nsome events, but they are not in complex scenarios. To rigorously prove that\nsome occurrences are caused by others, causal theory and causal inference were\nformalized, introducing the $do$-operator and its associated rules. The main\ngoal of this report is to review and implement in Python some algorithms to\ncompute conditional and non-conditional causal queries from observational data.\nTo this end, we first present some basic background knowledge on probability\nand graph theory, before introducing important results on causal theory, used\nin the construction of the algorithms. We then thoroughly study the\nidentification algorithms presented by Shpitser and Pearl in 2006, explaining\nour implementation in Python alongside. The main identification algorithm can\nbe seen as a repeated application of the rules of $do$-calculus, and it\neventually either returns an expression for the causal query from experimental\nprobabilities or fails to identify the causal effect, in which case the effect\nis non-identifiable. We introduce our newly developed Python library and give\nsome usage examples.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 19:00:33 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Pedemonte", "Mart\u00ed", "", "Universitat\n  de Barcelona"], ["Vitri\u00e0", "Jordi", "", "Universitat\n  de Barcelona"], ["Parafita", "\u00c1lvaro", "", "Universitat\n  de Barcelona"]]}, {"id": "2107.05395", "submitter": "Enda Carroll", "authors": "Enda Carroll, Andrew Gloster, Miguel D. Bustamante, Lennon \\'O'\n  N\\'araigh", "title": "A Batched GPU Methodology for Numerical Solutions of Partial\n  Differential Equations", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.04539", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a methodology for data accesses when solving batches\nof Tridiagonal and Pentadiagonal matrices that all share the same\nleft-hand-side (LHS) matrix. The intended application is to the numerical\nsolution of Partial Differential Equations via the finite-difference method,\nalthough the methodology is applicable more broadly. By only storing one copy\nof this matrix, a significant reduction in storage overheads is obtained,\ntogether with a corresponding decrease in compute time. Taken together, these\ntwo performance enhancements lead to an overall more efficient implementation\nover the current state of the art algorithms cuThomasBatch and cuPentBatch,\nallowing for a greater number of systems to be solved on a single GPU. We\ndemonstrate the methodology in the case of the Diffusion Equation,\nHyperdiffusion Equation, and the Cahn--Hilliard Equation, all in one spatial\ndimension. In this last example, we demonstrate how the method can be used to\nperform $2^{20}$ independent simulations of phase separation in one dimension.\nIn this way, we build up a robust statistical description of the coarsening\nphenomenon which is the defining behavior of phase separation. We anticipate\nthat the method will be of further use in other similar contexts requiring\nstatistical simulation of physical systems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 14:41:05 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Carroll", "Enda", ""], ["Gloster", "Andrew", ""], ["Bustamante", "Miguel D.", ""], ["N\u00e1raigh", "Lennon \u00d3'", ""]]}, {"id": "2107.05412", "submitter": "Matteo Caorsi", "authors": "Juli\\'an Burella P\\'erez, Sydney Hauke, Umberto Lupo, Matteo Caorsi,\n  Alberto Dassatti", "title": "Giotto-ph: A Python Library for High-Performance Computation of\n  Persistent Homology of Vietoris--Rips Filtrations", "comments": "18 apges, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce giotto-ph, a high-performance, open-source software package for\nthe computation of Vietoris--Rips barcodes. giotto-ph is based on Morozov and\nNigmetov's lockfree (multicore) implementation of Ulrich Bauer's Ripser\npackage. It also contains a re-implementation of Boissonnat and Pritam's \"Edge\nCollapser\", implemented so far only in the GUDHI library. Our contribution is\ntwofold: on the one hand, we integrate existing state-of-the-art ideas\ncoherently in a single library and provide Python bindings to the C++ code. On\nthe other hand, we increase parallelization opportunities and improve overall\nperformance by adopting higher performance data structures. The final\nimplementation of our persistent homology backend establishes a new state of\nthe art, surpassing even GPU-accelerated implementations such as Ripser++ when\nusing as few as 5--10 CPU cores. Furthermore, our implementation of the edge\ncollapser algorithm has reduced dependencies and significantly improved\nrun-times.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 13:30:45 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["P\u00e9rez", "Juli\u00e1n Burella", ""], ["Hauke", "Sydney", ""], ["Lupo", "Umberto", ""], ["Caorsi", "Matteo", ""], ["Dassatti", "Alberto", ""]]}, {"id": "2107.05613", "submitter": "Delyan Kalchev", "authors": "Delyan Z. Kalchev and Panayot S. Vassilevski and Umberto Villa", "title": "Parallel Element-based Algebraic Multigrid for H(curl) and H(div)\n  Problems Using the ParELAG Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents the use of element-based algebraic multigrid (AMGe)\nhierarchies, implemented in the ParELAG (Parallel Element Agglomeration\nAlgebraic Multigrid Upscaling and Solvers) library, to produce multilevel\npreconditioners and solvers for H(curl) and H(div) formulations. ParELAG\nconstructs hierarchies of compatible nested spaces, forming an exact de Rham\nsequence on each level. This allows the application of hybrid smoothers on all\nlevels and AMS (Auxiliary-space Maxwell Solver) or ADS (Auxiliary-space\nDivergence Solver) on the coarsest levels, obtaining complete multigrid cycles.\nNumerical results are presented, showing the parallel performance of the\nproposed methods. As a part of the exposition, this paper demonstrates some of\nthe capabilities of ParELAG and outlines some of the components and procedures\nwithin the library.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 17:48:29 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Kalchev", "Delyan Z.", ""], ["Vassilevski", "Panayot S.", ""], ["Villa", "Umberto", ""]]}, {"id": "2107.05761", "submitter": "Ian Briggs", "authors": "Ian Briggs and Pavel Panchekha", "title": "Faster Math Functions, Soundly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Standard library implementations of functions like sin and exp optimize for\naccuracy, not speed, because they are intended for general-purpose use. But\napplications tolerate inaccuracy from cancellation, rounding error, and\nsingularities-sometimes even very high error-and many application could\ntolerate error in function implementations as well. This raises an intriguing\npossibility: speeding up numerical code by tuning standard function\nimplementations. This paper thus introduces OpTuner, an automatic method for\nselecting the best implementation of mathematical functions at each use site.\nOpTuner assembles dozens of implementations for the standard mathematical\nfunctions from across the speed-accuracy spectrum. OpTuner then uses error\nTaylor series and integer linear programming to compute optimal assignments of\nfunction implementation to use site and presents the user with a speed-accuracy\nPareto curve they can use to speed up their code. In a case study on the\nPOV-Ray ray tracer, OpTuner speeds up a critical computation, leading to a\nwhole program speedup of 9% with no change in the program output (whereas human\nefforts result in slower code and lower-quality output). On a broader study of\n37 standard benchmarks, OpTuner matches 216 implementations to 89 use sites and\ndemonstrates speed-ups of 107% for negligible decreases in accuracy and of up\nto 438% for error-tolerant applications.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:12:33 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Briggs", "Ian", ""], ["Panchekha", "Pavel", ""]]}, {"id": "2107.06640", "submitter": "Lukas Krenz", "authors": "Lukas Krenz, Carsten Uphoff, Thomas Ulrich, Alice-Agnes Gabriel,\n  Lauren S. Abrahams, Eric M. Dunham, Michael Bader", "title": "3D Acoustic-Elastic Coupling with Gravity: The Dynamics of the 2018\n  Palu, Sulawesi Earthquake and Tsunami", "comments": "13 pages, 6 figures; Accepted at the International Conference for\n  High Performance Computing, Networking, Storage and Analysis 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.MS physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a highly scalable 3D fully-coupled Earth & ocean model of\nearthquake rupture and tsunami generation and perform the first fully coupled\nsimulation of an actual earthquake-tsunami event and a 3D benchmark problem of\ntsunami generation by a mega-thrust dynamic earthquake rupture. Multi-petascale\nsimulations, with excellent performance demonstrated on three different\nplatforms, allow high-resolution forward modeling. Our largest mesh has\n$\\approx$261 billion degrees of freedom, resolving at least 15 Hz of the\nacoustic wave field. We self-consistently model seismic, acoustic and surface\ngravity wave propagation in elastic (Earth) and acoustic (ocean) materials\nsourced by physics-based non-linear earthquake dynamic rupture, thereby gaining\ninsight into the tsunami generation process without relying on approximations\nthat have previously been applied to permit solution of this challenging\nproblem. Complicated geometries, including high-resolution bathymetry,\ncoastlines and segmented earthquake faults are discretized by adaptive\nunstructured tetrahedral meshes. This leads inevitably to large differences in\nelement sizes and wave speeds which can be mitigated by ADER local\ntime-stepping and a Discontinuous Galerkin discretisation yielding high-order\naccuracy in time and space.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:09:04 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Krenz", "Lukas", ""], ["Uphoff", "Carsten", ""], ["Ulrich", "Thomas", ""], ["Gabriel", "Alice-Agnes", ""], ["Abrahams", "Lauren S.", ""], ["Dunham", "Eric M.", ""], ["Bader", "Michael", ""]]}, {"id": "2107.07461", "submitter": "Dmitry Kulyabov", "authors": "Migran N. Gevorkyan and Anna V. Korolkova and Dmitry S. Kulyabov", "title": "Using a template engine as a computer algebra tool", "comments": "in English; in Russian", "journal-ref": null, "doi": "10.1134/S0361768821010047", "report-no": null, "categories": "math.NA cs.MS cs.NA cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In research problems that involve the use of numerical methods for solving\nsystems of ordinary differential equations (ODEs), it is often required to\nselect the most efficient method for a particular problem. To solve a Cauchy\nproblem for a system of ODEs, Runge-Kutta methods (explicit or implicit ones,\nwith or without step-size control, etc.) are employed. In that case, it is\nrequired to search through many implementations of the numerical method and\nselect coefficients or other parameters of its numerical scheme. This paper\nproposes a library and scripts for automated generation of routine functions in\nthe Julia programming language for a set of numerical schemes of Runge-Kutta\nmethods. For symbolic manipulations, we use a template substitution tool. The\nproposed approach to automated generation of program code allows us to use a\nsingle template for editing, instead of modifying each individual function to\nbe compared. On the one hand, this provides universality in the implementation\nof a numerical scheme and, on the other hand, makes it possible to minimize the\nnumber of errors in the process of modifying the compared implementations of\nthe numerical method. We consider Runge-Kutta methods without step-size\ncontrol, embedded methods with step-size control, and Rosenbrock methods with\nstep-size control. The program codes for the numerical schemes, which are\ngenerated automatically using the proposed library, are tested by numerical\nsolution of several well-known problems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:04:02 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Gevorkyan", "Migran N.", ""], ["Korolkova", "Anna V.", ""], ["Kulyabov", "Dmitry S.", ""]]}, {"id": "2107.07763", "submitter": "Juan Cante", "authors": "Daniel Yago, Juan Cante, Oriol Lloberas-Valls, Javier Oliver", "title": "Topology optimization using the unsmooth variational topology\n  optimization (UNVARTOP) method. An educational implementation in Matlab", "comments": null, "journal-ref": "Structural and Multidisciplinary Optimization, 2021", "doi": "10.1007/s00158-020-02722-0", "report-no": null, "categories": "cs.CE cs.MS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents an efficient and comprehensive MATLAB code to solve\ntwo-dimensional structural topology optimization problems, including minimum\nmean compliance, compliant mechanism synthesis and multi-load compliance\nproblems. The Unsmooth Variational Topology Optimization (UNVARTOP) method,\ndeveloped by the authors in a previous work, is used in the topology\noptimization code, based on the finite element method (FEM), to compute the\nsensitivity and update the topology. The paper also includes instructions to\nimprove the bisection algorithm, modify the computation of the Lagrangian\nmultiplier by using an Augmented Lagrangian to impose the constraint, implement\nheat conduction problems and extend the code to three-dimensional topology\noptimization problems. The code, intended for students and newcomers in\ntopology optimization, is included as an appendix (Appendix A) and it can be\ndownloaded from https://github.com/DanielYago together with supplementary\nmaterial.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 08:39:47 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Yago", "Daniel", ""], ["Cante", "Juan", ""], ["Lloberas-Valls", "Oriol", ""], ["Oliver", "Javier", ""]]}, {"id": "2107.08145", "submitter": "Eric Wright", "authors": "Eric Wright, Damien Przybylski, Matthias Rempel, Cena Miller, Supreeth\n  Suresh, Shiquan Su, Richard Loft, Sunita Chandrasekaran", "title": "Refactoring the MPS/University of Chicago Radiative MHD(MURaM) Model for\n  GPU/CPU Performance Portability Using OpenACC Directives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.space-ph cs.CE cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The MURaM (Max Planck University of Chicago Radiative MHD) code is a solar\natmosphere radiative MHD model that has been broadly applied to solar phenomena\nranging from quiet to active sun, including eruptive events such as flares and\ncoronal mass ejections. The treatment of physics is sufficiently realistic to\nallow for the synthesis of emission from visible light to extreme UV and\nX-rays, which is critical for a detailed comparison with available and future\nmulti-wavelength observations. This component relies critically on the\nradiation transport solver (RTS) of MURaM; the most computationally intensive\ncomponent of the code. The benefits of accelerating RTS are multiple fold: A\nfaster RTS allows for the regular use of the more expensive multi-band\nradiation transport needed for comparison with observations, and this will pave\nthe way for the acceleration of ongoing improvements in RTS that are critical\nfor simulations of the solar chromosphere. We present challenges and strategies\nto accelerate a multi-physics, multi-band MURaM using a directive-based\nprogramming model, OpenACC in order to maintain a single source code across\nCPUs and GPUs. Results for a $288^3$ test problem show that MURaM with the\noptimized RTS routine achieves 1.73x speedup using a single NVIDIA V100 GPU\nover a fully subscribed 40-core Intel Skylake CPU node and with respect to the\nnumber of simulation points (in millions) per second, a single NVIDIA V100 GPU\nis equivalent to 69 Skylake cores. We also measure parallel performance on up\nto 96 GPUs and present weak and strong scaling results.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 23:35:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Wright", "Eric", ""], ["Przybylski", "Damien", ""], ["Rempel", "Matthias", ""], ["Miller", "Cena", ""], ["Suresh", "Supreeth", ""], ["Su", "Shiquan", ""], ["Loft", "Richard", ""], ["Chandrasekaran", "Sunita", ""]]}, {"id": "2107.09443", "submitter": "Christopher Rackauckas", "authors": "Kirill Zubov, Zoe McCarthy, Yingbo Ma, Francesco Calisto, Valerio\n  Pagliarino, Simone Azeglio, Luca Bottero, Emmanuel Luj\\'an, Valentin Sulzer,\n  Ashutosh Bharambe, Nand Vinchhi, Kaushik Balakrishnan, Devesh Upadhyay, Chris\n  Rackauckas", "title": "NeuralPDE: Automating Physics-Informed Neural Networks (PINNs) with\n  Error Approximations", "comments": "74 pages, 20+ figures, 20+ tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Physics-informed neural networks (PINNs) are an increasingly powerful way to\nsolve partial differential equations, generate digital twins, and create neural\nsurrogates of physical models. In this manuscript we detail the inner workings\nof NeuralPDE.jl and show how a formulation structured around numerical\nquadrature gives rise to new loss functions which allow for adaptivity towards\nbounded error tolerances. We describe the various ways one can use the tool,\ndetailing mathematical techniques like using extended loss functions for\nparameter estimation and operator discovery, to help potential users adopt\nthese PINN-based techniques into their workflow. We showcase how NeuralPDE uses\na purely symbolic formulation so that all of the underlying training code is\ngenerated from an abstract formulation, and show how to make use of GPUs and\nsolve systems of PDEs. Afterwards we give a detailed performance analysis which\nshowcases the trade-off between training techniques on a large set of PDEs. We\nend by focusing on a complex multiphysics example, the Doyle-Fuller-Newman\n(DFN) Model, and showcase how this PDE can be formulated and solved with\nNeuralPDE. Together this manuscript is meant to be a detailed and approachable\ntechnical report to help potential users of the technique quickly get a sense\nof the real-world performance trade-offs and use cases of the PINN techniques.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 12:38:31 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Zubov", "Kirill", ""], ["McCarthy", "Zoe", ""], ["Ma", "Yingbo", ""], ["Calisto", "Francesco", ""], ["Pagliarino", "Valerio", ""], ["Azeglio", "Simone", ""], ["Bottero", "Luca", ""], ["Luj\u00e1n", "Emmanuel", ""], ["Sulzer", "Valentin", ""], ["Bharambe", "Ashutosh", ""], ["Vinchhi", "Nand", ""], ["Balakrishnan", "Kaushik", ""], ["Upadhyay", "Devesh", ""], ["Rackauckas", "Chris", ""]]}, {"id": "2107.10346", "submitter": "Benjamin Michalowicz", "authors": "Benjamin Michalowicz, Eric Raut, Yan Kang, Tony Curtis, Barbara\n  Chapman, Dossay Oryspayev", "title": "Comparing OpenMP Implementations With Applications Across A64FX\n  Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The development of the A64FX processor by Fujitsu has created a massive\ninnovation in High-Performance Computing and the birth of Fugaku: the current\nworld's fastest supercomputer. A variety of tools are used to analyze the\nrun-times and performances of several applications, and in particular, how\nthese applications scale on the A64FX processor. We examine the performance and\nbehavior of applications through OpenMP scaling and how their performance\ndiffers across different compilers on the new Ookami cluster at Stony Brook\nUniversity as well as the Fugaku supercomputer at RIKEN in Japan.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 20:28:38 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Michalowicz", "Benjamin", ""], ["Raut", "Eric", ""], ["Kang", "Yan", ""], ["Curtis", "Tony", ""], ["Chapman", "Barbara", ""], ["Oryspayev", "Dossay", ""]]}, {"id": "2107.12322", "submitter": "Anton Khritankov", "authors": "Anton Khritankov, Nikita Pershin, Nikita Ukhov and Artem Ukhov", "title": "MLDev: Data Science Experiment Automation and Reproducibility Software", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the challenges of automating experiments in data\nscience. We propose an extensible experiment model as a foundation for\nintegration of different open source tools for running research experiments. We\nimplement our approach in a prototype open source MLDev software package and\nevaluate it in a series of experiments yielding promising results. Comparison\nwith other state-of-the-art tools signifies novelty of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 16:51:44 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Khritankov", "Anton", ""], ["Pershin", "Nikita", ""], ["Ukhov", "Nikita", ""], ["Ukhov", "Artem", ""]]}, {"id": "2107.12550", "submitter": "Tomonori Kouya", "authors": "Tomonori Kouya", "title": "Accelerated Multiple Precision Direct Method and Mixed Precision\n  Iterative Refinement on Python Programming Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Python programming environment does not have any reliable and\nefficient multiple precision floating-point (MPF) arithmetic except ``mpmath\"\nand ``gmpy2\" packages based on GNU MP(GMP) and MPFR libraries. Although it is\nwell known that multi-component-type MPF library can be utilized for middle\nlength precision arithmetic under 200 bits, they are not widely used on Python\nenvironment. In this paper, we describe our accelerated MPF direct method with\nAVX2 techniques and its application to mixed precision iterative refinement\ncombined with mpmath, and demonstrate their efficiency on x86\\_64 computational\nenvironments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 01:57:03 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kouya", "Tomonori", ""]]}, {"id": "2107.13500", "submitter": "Nick Brown", "authors": "Nick Brown", "title": "Accelerating advection for atmospheric modelling on Xilinx and Intel\n  FPGAs", "comments": "Preprint of article in the IEEE Cluster FPGA for HPC Workshop 2021\n  (HPC FPGA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfigurable architectures, such as FPGAs, enable the execution of code at\nthe electronics level, avoiding the assumptions imposed by the general purpose\nblack-box micro-architectures of CPUs and GPUs. Such tailored execution can\nresult in increased performance and power efficiency, and as the HPC community\nmoves towards exascale an important question is the role such hardware\ntechnologies can play in future supercomputers.\n  In this paper we explore the porting of the PW advection kernel, an important\ncode component used in a variety of atmospheric simulations and accounting for\naround 40\\% of the runtime of the popular Met Office NERC Cloud model (MONC).\nBuilding upon previous work which ported this kernel to an older generation of\nXilinx FPGA, we target latest generation Xilinx Alveo U280 and Intel Stratix 10\nFPGAs. Exploring the development of a dataflow design which is performance\nportable between vendors, we then describe implementation differences between\nthe tool chains and compare kernel performance between FPGA hardware. This is\nfollowed by a more general performance comparison, scaling up the number of\nkernels on the Xilinx Alveo and Intel Stratix 10, against a 24 core Xeon\nPlatinum Cascade Lake CPU and NVIDIA Tesla V100 GPU. When overlapping the\ntransfer of data to and from the boards with compute, the FPGA solutions\nconsiderably outperform the CPU and, whilst falling short of the GPU in terms\nof performance, demonstrate power usage benefits, with the Alveo being\nespecially power efficient. The result of this work is a comparison and set of\ndesign techniques that apply both to this specific atmospheric advection kernel\non Xilinx and Intel FPGAs, and that are also of interest more widely when\nlooking to accelerate HPC codes on a variety of reconfigurable architectures.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 17:14:01 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Brown", "Nick", ""]]}, {"id": "2107.14027", "submitter": "Will Trojak", "authors": "Will Trojak, Rob Watson, and Freddie Witherden", "title": "Hyperbolic Diffusion in Flux Reconstruction: Optimisation through Kernel\n  Fusion within Tensor-Product Elements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Novel methods are presented for the fusion of GPU kernels in the artificial\ncompressibility method (ACM), using tensor product elements and flux\nreconstruction. This is made possible through the hyperbolisation of the\ndiffusion terms, which eliminates the expensive algorithmic steps needed to\nform the viscous stresses. Two fusion approaches are presented, which offer\ndiffering levels of parallelism. This is found to be necessary for the change\nin workload as the order of accuracy of the elements is increased. Several\nfurther optimisations of these approaches are demonstrated, including a\ngeneration time memory manager which maximises resource usage. The fused\nkernels are able to achieve 3-4 times speedup, which compares favourably with a\ntheoretical maximum speedup of 4. In three dimensional test cases, the\ngenerated fused kernels are found to reduce total runtime by ${\\sim}25\\%$, and,\nwhen compared to the standard ACM formulation, simulations demonstrate that a\nspeedup of $2.3$ times can be achieved.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 18:22:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Trojak", "Will", ""], ["Watson", "Rob", ""], ["Witherden", "Freddie", ""]]}]