[{"id": "1411.1607", "submitter": "Alan Edelman", "authors": "Jeff Bezanson, Alan Edelman, Stefan Karpinski, Viral B. Shah", "title": "Julia: A Fresh Approach to Numerical Computing", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bridging cultures that have often been distant, Julia combines expertise from\nthe diverse fields of computer science and computational science to create a\nnew approach to numerical computing. Julia is designed to be easy and fast.\nJulia questions notions generally held as \"laws of nature\" by practitioners of\nnumerical computing:\n  1. High-level dynamic programs have to be slow.\n  2. One must prototype in one language and then rewrite in another language\nfor speed or deployment, and\n  3. There are parts of a system for the programmer, and other parts best left\nuntouched as they are built by the experts.\n  We introduce the Julia programming language and its design --- a dance\nbetween specialization and abstraction. Specialization allows for custom\ntreatment. Multiple dispatch, a technique from computer science, picks the\nright algorithm for the right circumstance. Abstraction, what good computation\nis really about, recognizes what remains the same after differences are\nstripped away. Abstractions in mathematics are captured as code through another\ntechnique from computer science, generic programming.\n  Julia shows that one can have machine performance without sacrificing human\nconvenience.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 13:39:40 GMT"}, {"version": "v2", "created": "Fri, 7 Nov 2014 11:19:21 GMT"}, {"version": "v3", "created": "Fri, 12 Dec 2014 22:40:09 GMT"}, {"version": "v4", "created": "Sun, 19 Jul 2015 19:58:28 GMT"}], "update_date": "2015-07-21", "authors_parsed": [["Bezanson", "Jeff", ""], ["Edelman", "Alan", ""], ["Karpinski", "Stefan", ""], ["Shah", "Viral B.", ""]]}, {"id": "1411.1830", "submitter": "Fabrizio Lecci", "authors": "Brittany Terese Fasy, Jisu Kim, Fabrizio Lecci, Cl\\'ement Maria", "title": "Introduction to the R package TDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a short tutorial and introduction to using the R package TDA,\nwhich provides some tools for Topological Data Analysis. In particular, it\nincludes implementations of functions that, given some data, provide\ntopological information about the underlying space, such as the distance\nfunction, the distance to a measure, the kNN density estimator, the kernel\ndensity estimator, and the kernel distance. The salient topological features of\nthe sublevel sets (or superlevel sets) of these functions can be quantified\nwith persistent homology. We provide an R interface for the efficient\nalgorithms of the C++ libraries GUDHI, Dionysus and PHAT, including a function\nfor the persistent homology of the Rips filtration, and one for the persistent\nhomology of sublevel sets (or superlevel sets) of arbitrary functions evaluated\nover a grid of points. The significance of the features in the resulting\npersistence diagrams can be analyzed with functions that implement recently\ndeveloped statistical methods. The R package TDA also includes the\nimplementation of an algorithm for density clustering, which allows us to\nidentify the spatial organization of the probability mass associated to a\ndensity function and visualize it by means of a dendrogram, the cluster tree.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 05:10:34 GMT"}, {"version": "v2", "created": "Thu, 29 Jan 2015 17:21:36 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Fasy", "Brittany Terese", ""], ["Kim", "Jisu", ""], ["Lecci", "Fabrizio", ""], ["Maria", "Cl\u00e9ment", ""]]}, {"id": "1411.2860", "submitter": "Yiannis Andreopoulos", "authors": "Mohammad Ashraful Anam, Paul N. Whatmough and Yiannis Andreopoulos", "title": "Precision-Energy-Throughput Scaling Of Generic Matrix Multiplication and\n  Convolution Kernels Via Linear Projections", "comments": null, "journal-ref": "IEEE Transactions on Circuits and Systems for Video Technology,\n  vol. 24, no. 11, pp. 1860-1873, Nov. 2014", "doi": null, "report-no": null, "categories": "cs.MM cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generic matrix multiplication (GEMM) and one-dimensional\nconvolution/cross-correlation (CONV) kernels often constitute the bulk of the\ncompute- and memory-intensive processing within image/audio recognition and\nmatching systems. We propose a novel method to scale the energy and processing\nthroughput of GEMM and CONV kernels for such error-tolerant multimedia\napplications by adjusting the precision of computation. Our technique employs\nlinear projections to the input matrix or signal data during the top-level GEMM\nand CONV blocking and reordering. The GEMM and CONV kernel processing then uses\nthe projected inputs and the results are accumulated to form the final outputs.\nThroughput and energy scaling takes place by changing the number of projections\ncomputed by each kernel, which in turn produces approximate results, i.e.\nchanges the precision of the performed computation. Results derived from a\nvoltage- and frequency-scaled ARM Cortex A15 processor running face recognition\nand music matching algorithms demonstrate that the proposed approach allows for\n280%~440% increase of processing throughput and 75%~80% decrease of energy\nconsumption against optimized GEMM and CONV kernels without any impact in the\nobtained recognition or matching accuracy. Even higher gains can be obtained if\none is willing to tolerate some reduction in the accuracy of the recognition\nand matching applications.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 15:59:35 GMT"}], "update_date": "2014-11-12", "authors_parsed": [["Anam", "Mohammad Ashraful", ""], ["Whatmough", "Paul N.", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1411.2940", "submitter": "Andrew McRae", "authors": "Andrew T. T. McRae, Gheorghe-Teodor Bercea, Lawrence Mitchell, David\n  A. Ham, Colin J. Cotter", "title": "Automated generation and symbolic manipulation of tensor product finite\n  elements", "comments": "Submitted to SISC special issue on CSE Software. Updated version,\n  following reviewer comments", "journal-ref": "SIAM Journal on Scientific Computing 38(5):S25-S47 (2016)", "doi": "10.1137/15M1021167", "report-no": null, "categories": "math.NA cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and implement a symbolic algebra for scalar and vector-valued\nfinite elements, enabling the computer generation of elements with tensor\nproduct structure on quadrilateral, hexahedral and triangular prismatic cells.\nThe algebra is implemented as an extension to the domain-specific language UFL,\nthe Unified Form Language. This allows users to construct many finite element\nspaces beyond those supported by existing software packages. We have made\ncorresponding extensions to FIAT, the FInite element Automatic Tabulator, to\nenable numerical tabulation of such spaces. This tabulation is consequently\nused during the automatic generation of low-level code that carries out local\nassembly operations, within the wider context of solving finite element\nproblems posed over such function spaces. We have done this work within the\ncode-generation pipeline of the software package Firedrake; we make use of the\nfull Firedrake package to present numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 19:47:45 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2015 17:31:00 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2016 11:12:45 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["McRae", "Andrew T. T.", ""], ["Bercea", "Gheorghe-Teodor", ""], ["Mitchell", "Lawrence", ""], ["Ham", "David A.", ""], ["Cotter", "Colin J.", ""]]}, {"id": "1411.3834", "submitter": "Bijan Chokoufe Nejad", "authors": "Bijan Chokoufe Nejad, Thorsten Ohl, J\\\"urgen Reuter", "title": "Simple, Parallel, High-Performance Virtual Machines for Extreme\n  Computations", "comments": "19 pages, 8 figures", "journal-ref": "Computer Physics Communications (2015), pp. 58-69", "doi": "10.1016/j.cpc.2015.05.015", "report-no": "DESY 14-206", "categories": "physics.comp-ph cs.MS hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a high-performance virtual machine (VM) written in a numerically\nfast language like Fortran or C to evaluate very large expressions. We discuss\nthe general concept of how to perform computations in terms of a VM and present\nspecifically a VM that is able to compute tree-level cross sections for any\nnumber of external legs, given the corresponding byte code from the optimal\nmatrix element generator, O'Mega. Furthermore, this approach allows to\nformulate the parallel computation of a single phase space point in a simple\nand obvious way. We analyze hereby the scaling behaviour with multiple threads\nas well as the benefits and drawbacks that are introduced with this method. Our\nimplementation of a VM can run faster than the corresponding native, compiled\ncode for certain processes and compilers, especially for very high\nmultiplicities, and has in general runtimes in the same order of magnitude. By\navoiding the tedious compile and link steps, which may fail for source code\nfiles of gigabyte sizes, new processes or complex higher order corrections that\nare currently out of reach could be evaluated with a VM given enough computing\npower.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 09:15:48 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Nejad", "Bijan Chokoufe", ""], ["Ohl", "Thorsten", ""], ["Reuter", "J\u00fcrgen", ""]]}, {"id": "1411.4439", "submitter": "Mathias Wagner", "authors": "O. Kaczmarek, C. Schmidt, P. Steinbrecher and M. Wagner", "title": "Conjugate gradient solvers on Intel Xeon Phi and NVIDIA GPUs", "comments": "7 pages, proceedings, presented at 'GPU Computing in High Energy\n  Physics', September 10-12, 2014, Pisa, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.MS hep-lat", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice Quantum Chromodynamics simulations typically spend most of the\nruntime in inversions of the Fermion Matrix. This part is therefore frequently\noptimized for various HPC architectures. Here we compare the performance of the\nIntel Xeon Phi to current Kepler-based NVIDIA Tesla GPUs running a conjugate\ngradient solver. By exposing more parallelism to the accelerator through\ninverting multiple vectors at the same time, we obtain a performance greater\nthan 300 GFlop/s on both architectures. This more than doubles the performance\nof the inversions. We also give a short overview of the Knights Corner\narchitecture, discuss some details of the implementation and the effort\nrequired to obtain the achieved performance.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 11:27:55 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Kaczmarek", "O.", ""], ["Schmidt", "C.", ""], ["Steinbrecher", "P.", ""], ["Wagner", "M.", ""]]}]