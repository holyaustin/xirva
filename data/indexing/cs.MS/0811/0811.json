[{"id": "0811.1081", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "Parallel GPU Implementation of Iterative PCA Algorithms", "comments": "45 pages, 1 figure, source code included", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a key statistical technique for\nmultivariate data analysis. For large data sets the common approach to PCA\ncomputation is based on the standard NIPALS-PCA algorithm, which unfortunately\nsuffers from loss of orthogonality, and therefore its applicability is usually\nlimited to the estimation of the first few components. Here we present an\nalgorithm based on Gram-Schmidt orthogonalization (called GS-PCA), which\neliminates this shortcoming of NIPALS-PCA. Also, we discuss the GPU (Graphics\nProcessing Unit) parallel implementation of both NIPALS-PCA and GS-PCA\nalgorithms. The numerical results show that the GPU parallel optimized\nversions, based on CUBLAS (NVIDIA) are substantially faster (up to 12 times)\nthan the CPU optimized versions based on CBLAS (GNU Scientific Library).\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2008 04:34:01 GMT"}], "update_date": "2008-11-10", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "0811.1714", "submitter": "Martin Albrecht", "authors": "Martin Albrecht, Gregory Bard, William Hart", "title": "Efficient Multiplication of Dense Matrices over GF(2)", "comments": null, "journal-ref": null, "doi": "10.1145/1644001.1644010", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an efficient implementation of a hierarchy of algorithms for\nmultiplication of dense matrices over the field with two elements (GF(2)). In\nparticular we present our implementation -- in the M4RI library -- of\nStrassen-Winograd matrix multiplication and the \"Method of the Four Russians\"\nmultiplication (M4RM) and compare it against other available implementations.\nGood performance is demonstrated on on AMD's Opteron and particulary good\nperformance on Intel's Core 2 Duo. The open-source M4RI library is available\nstand-alone as well as part of the Sage mathematics software.\n  In machine terms, addition in GF(2) is logical-XOR, and multiplication is\nlogical-AND, thus a machine word of 64-bits allows one to operate on 64\nelements of GF(2) in parallel: at most one CPU cycle for 64 parallel additions\nor multiplications. As such, element-wise operations over GF(2) are relatively\ncheap. In fact, in this paper, we conclude that the actual bottlenecks are\nmemory reads and writes and issues of data locality. We present our empirical\nfindings in relation to minimizing these and give an analysis thereof.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2008 14:23:49 GMT"}], "update_date": "2012-03-27", "authors_parsed": [["Albrecht", "Martin", ""], ["Bard", "Gregory", ""], ["Hart", "William", ""]]}]