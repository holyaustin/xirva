[{"id": "1504.01023", "submitter": "Krzysztof Bana\\'s", "authors": "Krzysztof Bana\\'s, Filip Kru\\.zel, Jan Biela\\'nski", "title": "Finite element numerical integration for first order approximations on\n  multi-core architectures", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2016.03.038", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents investigations on the implementation and performance of\nthe finite element numerical integration algorithm for first order\napproximations and three processor architectures, popular in scientific\ncomputing, classical CPU, Intel Xeon Phi and NVIDIA Kepler GPU. A unifying\nprogramming model and portable OpenCL implementation is considered for all\narchitectures. Variations of the algorithm due to different problems solved and\ndifferent element types are investigated and several optimizations aimed at\nproper optimization and mapping of the algorithm to computer architectures are\ndemonstrated. Performance models of execution are developed for different\nprocessors and tested in practical experiments. The results show the varying\nlevels of performance for different architectures, but indicate that the\nalgorithm can be effectively ported to all of them. The general conclusion is\nthat the finite element numerical integration can achieve sufficient\nperformance on different multi- and many-core architectures and should not\nbecome a performance bottleneck for finite element simulation codes. Specific\nobservations lead to practical advises on how to optimize the kernels and what\nperformance can be expected for the tested architectures.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2015 16:56:02 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Bana\u015b", "Krzysztof", ""], ["Kru\u017cel", "Filip", ""], ["Biela\u0144ski", "Jan", ""]]}, {"id": "1504.01161", "submitter": "Sylwester Arabas", "authors": "Dorota Jarecka, Sylwester Arabas, Davide Del Vento", "title": "Python bindings for libcloudph++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.MS physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical note introduces the Python bindings for libcloudph++. The\nlibcloudph++ is a C++ library of algorithms for representing atmospheric cloud\nmicrophysics in numerical models. The bindings expose the complete\nfunctionality of the library to the Python users. The bindings are implemented\nusing the Boost.Python C++ library and use NumPy arrays. This note includes\nlistings with Python scripts exemplifying the use of selected library\ncomponents. An example solution for using the Python bindings to access\nlibcloudph++ from Fortran is presented.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2015 20:58:18 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["Jarecka", "Dorota", ""], ["Arabas", "Sylwester", ""], ["Del Vento", "Davide", ""]]}, {"id": "1504.01329", "submitter": "Ray Grout", "authors": "R.W. Grout and H. Kolla and M.L. Minion and J.B. Bell", "title": "Achieving algorithmic resilience for temporal integration through\n  spectral deferred corrections", "comments": null, "journal-ref": "Commun. Appl. Math. Comput. Sci. 12 (2017) 25-50", "doi": "10.2140/camcos.2017.12.25", "report-no": null, "categories": "cs.CE cs.MS", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Spectral deferred corrections (SDC) is an iterative approach for constructing\nhigher- order accurate numerical approximations of ordinary differential\nequations. SDC starts with an initial approximation of the solution defined at\na set of Gaussian or spectral collocation nodes over a time interval and uses\nan iterative application of lower-order time discretizations applied to a\ncorrection equation to improve the solution at these nodes. Each deferred\ncorrection sweep increases the formal order of accuracy of the method up to the\nlimit inherent in the accuracy defined by the collocation points. In this\npaper, we demonstrate that SDC is well suited to recovering from soft\n(transient) hardware faults in the data. A strategy where extra correction\niterations are used to recover from soft errors and provide algorithmic\nresilience is proposed. Specifically, in this approach the iteration is\ncontinued until the residual (a measure of the error in the approximation) is\nsmall relative to the residual on the first correction iteration and changes\nslowly between successive iterations. We demonstrate the effectiveness of this\nstrategy for both canonical test problems and a comprehen- sive situation\ninvolving a mature scientific application code that solves the reacting\nNavier-Stokes equations for combustion research.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 17:26:32 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Grout", "R. W.", ""], ["Kolla", "H.", ""], ["Minion", "M. L.", ""], ["Bell", "J. B.", ""]]}, {"id": "1504.01380", "submitter": "Maitham Alhubail", "authors": "Maitham Makki Alhubail and Qiqi Wang", "title": "The swept rule for breaking the latency barrier in time advancing PDEs", "comments": "30 pages", "journal-ref": "Journal of Computational Physics (2016), pp. 110-121", "doi": "10.1016/j.jcp.2015.11.026", "report-no": null, "categories": "cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article investigates the swept rule of space-time domain decomposition,\nan idea to break the latency barrier via communicating less often when\nexplicitly solving time-dependent PDEs. The swept rule decomposes space and\ntime among computing nodes in ways that exploit the domains of influence and\nthe domain of dependency, making it possible to communicate once per many\ntimesteps without redundant computation. The article presents simple\ntheoretical analysis to the performance of the swept rule which then was shown\nto be accurate by conducting numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 16:00:32 GMT"}, {"version": "v2", "created": "Sat, 14 Nov 2015 16:26:05 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Alhubail", "Maitham Makki", ""], ["Wang", "Qiqi", ""]]}, {"id": "1504.02366", "submitter": "Dhagash Mehta", "authors": "Dhagash Mehta, Crina Grosan", "title": "A Collection of Challenging Optimization Problems in Science,\n  Engineering and Economics", "comments": "Accepted as an invited contribution to the special session on\n  Evolutionary Computation for Nonlinear Equation Systems at the 2015 IEEE\n  Congress on Evolutionary Computation (at Sendai International Center, Sendai,\n  Japan, from 25th to 28th May, 2015.)", "journal-ref": null, "doi": "10.1109/CEC.2015.7257223", "report-no": "ADP-15-9/T911", "categories": "cs.NA cs.MS cs.NE math.AG math.NA math.OC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Function optimization and finding simultaneous solutions of a system of\nnonlinear equations (SNE) are two closely related and important optimization\nproblems. However, unlike in the case of function optimization in which one is\nrequired to find the global minimum and sometimes local minima, a database of\nchallenging SNEs where one is required to find stationary points (extrama and\nsaddle points) is not readily available. In this article, we initiate building\nsuch a database of important SNE (which also includes related function\noptimization problems), arising from Science, Engineering and Economics. After\nproviding a short review of the most commonly used mathematical and\ncomputational approaches to find solutions of such systems, we provide a\npreliminary list of challenging problems by writing the Mathematical\nformulation down, briefly explaning the origin and importance of the problem\nand giving a short account on the currently known results, for each of the\nproblems. We anticipate that this database will not only help benchmarking\nnovel numerical methods for solving SNEs and function optimization problems but\nalso will help advancing the corresponding research areas.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 16:31:25 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Mehta", "Dhagash", ""], ["Grosan", "Crina", ""]]}, {"id": "1504.02914", "submitter": "Radford M. Neal", "authors": "Radford M. Neal", "title": "Representing numeric data in 32 bits while preserving 64-bit precision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data files often consist of numbers having only a few significant decimal\ndigits, whose information content would allow storage in only 32 bits. However,\nwe may require that arithmetic operations involving these numbers be done with\n64-bit floating-point precision, which precludes simply representing the data\nas 32-bit floating-point values. Decimal floating point gives a compact and\nexact representation, but requires conversion with a slow division operation\nbefore it can be used. Here, I show that interesting subsets of 64-bit\nfloating-point values can be compactly and exactly represented by the 32 bits\nconsisting of the sign, exponent, and high-order part of the mantissa, with the\nlower-order 32 bits of the mantissa filled in by table lookup, indexed by bits\nfrom the part of the mantissa retained, and possibly from the exponent. For\nexample, decimal data with 4 or fewer digits to the left of the decimal point\nand 2 or fewer digits to the right of the decimal point can be represented in\nthis way using the lower-order 5 bits of the retained part of the mantissa as\nthe index. Data consisting of 6 decimal digits with the decimal point in any of\nthe 7 positions before or after one of the digits can also be represented this\nway, and decoded using 19 bits from the mantissa and exponent as the index.\nEncoding with such a scheme is a simple copy of half the 64-bit value, followed\nif necessary by verification that the value can be represented, by checking\nthat it decodes correctly. Decoding requires only extraction of index bits and\na table lookup. Lookup in a small table will usually reference cache; even with\nlarger tables, decoding is still faster than conversion from decimal floating\npoint with a division operation. I discuss how such schemes perform on recent\ncomputer systems, and how they might be used to automatically compress large\narrays in interpretive languages such as R.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2015 20:33:06 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Neal", "Radford M.", ""]]}, {"id": "1504.04714", "submitter": "Mathias Jacquelin", "authors": "Mathias Jacquelin and Lin Lin and Nathan Wichmann and Chao Yang", "title": "Enhancing the scalability and load balancing of the parallel selected\n  inversion algorithm via tree-based asynchronous communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for improving the parallel scalability of the recently\ndeveloped parallel selected inversion algorithm [Jacquelin, Lin and Yang 2014],\nnamed PSelInv, on massively parallel distributed memory machines. In the\nPSelInv method, we compute selected elements of the inverse of a sparse matrix\nA that can be decomposed as A = LU, where L is lower triangular and U is upper\ntriangular. Updating these selected elements of A-1 requires restricted\ncollective communications among a subset of processors within each column or\nrow communication group created by a block cyclic distribution of L and U. We\ndescribe how this type of restricted collective communication can be\nimplemented by using asynchronous point-to-point MPI communication functions\ncombined with a binary tree based data propagation scheme. Because multiple\nrestricted collective communications may take place at the same time in the\nparallel selected inversion algorithm, we need to use a heuristic to prevent\nprocessors participating in multiple collective communications from receiving\ntoo many messages. This heuristic allows us to reduce communication load\nimbalance and improve the overall scalability of the selected inversion\nalgorithm. For instance, when 6,400 processors are used, we observe over 5x\nspeedup for test matrices. It also mitigates the performance variability\nintroduced by an inhomogeneous network topology.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2015 12:46:33 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Jacquelin", "Mathias", ""], ["Lin", "Lin", ""], ["Wichmann", "Nathan", ""], ["Yang", "Chao", ""]]}, {"id": "1504.05022", "submitter": "Weifeng Liu", "authors": "Weifeng Liu, Brian Vinter", "title": "A Framework for General Sparse Matrix-Matrix Multiplication on GPUs and\n  Heterogeneous Processors", "comments": "25 pages, 12 figures, published at Journal of Parallel and\n  Distributed Computing (JPDC)", "journal-ref": null, "doi": "10.1016/j.jpdc.2015.06.010", "report-no": null, "categories": "cs.MS cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General sparse matrix-matrix multiplication (SpGEMM) is a fundamental\nbuilding block for numerous applications such as algebraic multigrid method\n(AMG), breadth first search and shortest path problem. Compared to other sparse\nBLAS routines, an efficient parallel SpGEMM implementation has to handle extra\nirregularity from three aspects: (1) the number of nonzero entries in the\nresulting sparse matrix is unknown in advance, (2) very expensive parallel\ninsert operations at random positions in the resulting sparse matrix dominate\nthe execution time, and (3) load balancing must account for sparse data in both\ninput matrices.\n  In this work we propose a framework for SpGEMM on GPUs and emerging CPU-GPU\nheterogeneous processors. This framework particularly focuses on the above\nthree problems. Memory pre-allocation for the resulting matrix is organized by\na hybrid method that saves a large amount of global memory space and\nefficiently utilizes the very limited on-chip scratchpad memory. Parallel\ninsert operations of the nonzero entries are implemented through the GPU merge\npath algorithm that is experimentally found to be the fastest GPU merge\napproach. Load balancing builds on the number of necessary arithmetic\noperations on the nonzero entries and is guaranteed in all stages.\n  Compared with the state-of-the-art CPU and GPU SpGEMM methods, our approach\ndelivers excellent absolute performance and relative speedups on various\nbenchmarks multiplying matrices with diverse sparsity structures. Furthermore,\non heterogeneous processors, our SpGEMM approach achieves higher throughput by\nusing re-allocatable shared virtual memory.\n  The source code of this work is available at\nhttps://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 11:58:05 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2015 07:38:29 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Liu", "Weifeng", ""], ["Vinter", "Brian", ""]]}, {"id": "1504.06474", "submitter": "Weifeng Liu", "authors": "Weifeng Liu, Brian Vinter", "title": "Speculative Segmented Sum for Sparse Matrix-Vector Multiplication on\n  Heterogeneous Processors", "comments": "22 pages, 8 figures, Published at Parallel Computing (PARCO)", "journal-ref": null, "doi": "10.1016/j.parco.2015.04.004", "report-no": null, "categories": "cs.MS cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (SpMV) is a central building block for\nscientific software and graph applications. Recently, heterogeneous processors\ncomposed of different types of cores attracted much attention because of their\nflexible core configuration and high energy efficiency. In this paper, we\npropose a compressed sparse row (CSR) format based SpMV algorithm utilizing\nboth types of cores in a CPU-GPU heterogeneous processor. We first\nspeculatively execute segmented sum operations on the GPU part of a\nheterogeneous processor and generate a possibly incorrect results. Then the CPU\npart of the same chip is triggered to re-arrange the predicted partial sums for\na correct resulting vector. On three heterogeneous processors from Intel, AMD\nand nVidia, using 20 sparse matrices as a benchmark suite, the experimental\nresults show that our method obtains significant performance improvement over\nthe best existing CSR-based SpMV algorithms. The source code of this work is\ndownloadable at https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 11:23:38 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2015 09:59:24 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Liu", "Weifeng", ""], ["Vinter", "Brian", ""]]}, {"id": "1504.06734", "submitter": "Anton Kochnev", "authors": "Anton Kochnev, Nicolai Savelov", "title": "Symmetric matrix inversion using modified Gaussian elimination", "comments": "5 pages, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper we present two different variants of method for symmetric\nmatrix inversion, based on modified Gaussian elimination. Both methods avoid\ncomputation of square roots and have a reduced machine time's spending.\nFurther, both of them can be used efficiently not only for positive (semi-)\ndefinite, but for any non-singular symmetric matrix inversion. We use\nsimulation to verify results, which represented in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2015 14:45:33 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Kochnev", "Anton", ""], ["Savelov", "Nicolai", ""]]}, {"id": "1504.07890", "submitter": "Diego Fabregat-Traver", "authors": "Alvaro Frank, Diego Fabregat-Traver and Paolo Bientinesi", "title": "Large-scale linear regression: Development of high-performance routines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In statistics, series of ordinary least squares problems (OLS) are used to\nstudy the linear correlation among sets of variables of interest; in many\nstudies, the number of such variables is at least in the millions, and the\ncorresponding datasets occupy terabytes of disk space. As the availability of\nlarge-scale datasets increases regularly, so does the challenge in dealing with\nthem. Indeed, traditional solvers---which rely on the use of black-box\"\nroutines optimized for one single OLS---are highly inefficient and fail to\nprovide a viable solution for big-data analyses. As a case study, in this paper\nwe consider a linear regression consisting of two-dimensional grids of related\nOLS problems that arise in the context of genome-wide association analyses, and\ngive a careful walkthrough for the development of {\\sc ols-grid}, a\nhigh-performance routine for shared-memory architectures; analogous steps are\nrelevant for tailoring OLS solvers to other applications. In particular, we\nfirst illustrate the design of efficient algorithms that exploit the structure\nof the OLS problems and eliminate redundant computations; then, we show how to\neffectively deal with datasets that do not fit in main memory; finally, we\ndiscuss how to cast the computation in terms of efficient kernels and how to\nachieve scalability. Importantly, each design decision along the way is\njustified by simple performance models. {\\sc ols-grid} enables the solution of\n$10^{11}$ correlated OLS problems operating on terabytes of data in a matter of\nhours.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 15:24:33 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Frank", "Alvaro", ""], ["Fabregat-Traver", "Diego", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1504.08035", "submitter": "Elmar Peise", "authors": "Elmar Peise (1), Paolo Bientinesi (1) ((1) AICES, RWTH Aachen)", "title": "The ELAPS Framework: Experimental Linear Algebra Performance Studies", "comments": "Submitted to SC15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal use of computing resources requires extensive coding, tuning and\nbenchmarking. To boost developer productivity in these time consuming tasks, we\nintroduce the Experimental Linear Algebra Performance Studies framework\n(ELAPS), a multi-platform open source environment for fast yet powerful\nperformance experimentation with dense linear algebra kernels, algorithms, and\nlibraries. ELAPS allows users to construct experiments to investigate how\nperformance and efficiency vary depending on factors such as caching,\nalgorithmic parameters, problem size, and parallelism. Experiments are designed\neither through Python scripts or a specialized GUI, and run on the whole\nspectrum of architectures, ranging from laptops to clusters, accelerators, and\nsupercomputers. The resulting experiment reports provide various metrics and\nstatistics that can be analyzed both numerically and visually. We demonstrate\nthe use of ELAPS in four concrete application scenarios and in as many\ncomputing environments, illustrating its practical value in supporting critical\nperformance decisions.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 21:58:50 GMT"}], "update_date": "2015-05-01", "authors_parsed": [["Peise", "Elmar", "", "AICES, RWTH Aachen"], ["Bientinesi", "Paolo", "", "AICES, RWTH Aachen"]]}]