[{"id": "1309.0238", "submitter": "Gael Varoquaux", "authors": "Lars Buitinck (ILPS), Gilles Louppe, Mathieu Blondel, Fabian Pedregosa\n  (INRIA Saclay - Ile de France), Andreas Mueller, Olivier Grisel, Vlad\n  Niculae, Peter Prettenhofer, Alexandre Gramfort (INRIA Saclay - Ile de\n  France, LTCI), Jaques Grobler (INRIA Saclay - Ile de France), Robert Layton,\n  Jake Vanderplas, Arnaud Joly, Brian Holt, Ga\\\"el Varoquaux (INRIA Saclay -\n  Ile de France)", "title": "API design for machine learning software: experiences from the\n  scikit-learn project", "comments": null, "journal-ref": "European Conference on Machine Learning and Principles and\n  Practices of Knowledge Discovery in Databases (2013)", "doi": null, "report-no": null, "categories": "cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scikit-learn is an increasingly popular machine learning li- brary. Written\nin Python, it is designed to be simple and efficient, accessible to\nnon-experts, and reusable in various contexts. In this paper, we present and\ndiscuss our design choices for the application programming interface (API) of\nthe project. In particular, we describe the simple and elegant interface shared\nby all learning and processing units in the library and then discuss its\nadvantages in terms of composition and reusability. The paper also comments on\nimplementation details specific to the Python ecosystem and analyzes obstacles\nfaced by users and developers of the library.\n", "versions": [{"version": "v1", "created": "Sun, 1 Sep 2013 16:22:48 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Buitinck", "Lars", "", "ILPS"], ["Louppe", "Gilles", "", "INRIA Saclay - Ile de France"], ["Blondel", "Mathieu", "", "INRIA Saclay - Ile de France"], ["Pedregosa", "Fabian", "", "INRIA Saclay - Ile de France"], ["Mueller", "Andreas", "", "INRIA Saclay - Ile de\n  France, LTCI"], ["Grisel", "Olivier", "", "INRIA Saclay - Ile de\n  France, LTCI"], ["Niculae", "Vlad", "", "INRIA Saclay - Ile de\n  France, LTCI"], ["Prettenhofer", "Peter", "", "INRIA Saclay - Ile de\n  France, LTCI"], ["Gramfort", "Alexandre", "", "INRIA Saclay - Ile de\n  France, LTCI"], ["Grobler", "Jaques", "", "INRIA Saclay - Ile de France"], ["Layton", "Robert", "", "INRIA Saclay -\n  Ile de France"], ["Vanderplas", "Jake", "", "INRIA Saclay -\n  Ile de France"], ["Joly", "Arnaud", "", "INRIA Saclay -\n  Ile de France"], ["Holt", "Brian", "", "INRIA Saclay -\n  Ile de France"], ["Varoquaux", "Ga\u00ebl", "", "INRIA Saclay -\n  Ile de France"]]}, {"id": "1309.0671", "submitter": "Ruben Martinez-Cantin", "authors": "Ruben Martinez-Cantin", "title": "BayesOpt: A Library for Bayesian optimization with Robotics Applications", "comments": "Robotics: Science and Systems, Workshop on Active Learning in\n  Robotics: Exploration, Curiosity, and Interaction", "journal-ref": "Journal of Machine Learning Research, 15(Nov), 3915-3919, 2014", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is twofold. On one side, we present a general\nframework for Bayesian optimization and we compare it with some related fields\nin active learning and Bayesian numerical analysis. On the other hand, Bayesian\noptimization and related problems (bandits, sequential experimental design) are\nhighly dependent on the surrogate model that is selected. However, there is no\nclear standard in the literature. Thus, we present a fast and flexible toolbox\nthat allows to test and combine different models and criteria with little\neffort. It includes most of the state-of-the-art contributions, algorithms and\nmodels. Its speed also removes part of the stigma that Bayesian optimization\nmethods are only good for \"expensive functions\". The software is free and it\ncan be used in many operating systems and computer languages.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 13:38:05 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Martinez-Cantin", "Ruben", ""]]}, {"id": "1309.1199", "submitter": "Eric Heien", "authors": "Eric M. Heien, Todd L. Miller, Becky Gietzel, Louise H. Kellogg", "title": "Experiences with Automated Build and Test for Geodynamics Simulation\n  Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Computational Infrastructure for Geodynamics (CIG) is an NSF funded\nproject that develops, supports, and disseminates community-accessible software\nfor the geodynamics research community. CIG software supports a variety of\ncomputational geodynamic research from mantle and core dynamics, to crustal and\nearthquake dynamics, to magma migration and seismology. To support this type of\nproject a backend computational infrastructure is necessary.\n  Part of this backend infrastructure is an automated build and testing system\nto ensure codes and changes to them are compatible with multiple platforms and\nthat the changes do not significantly affect the scientific results. In this\npaper we describe the build and test infrastructure for CIG based on the BaTLab\nsystem, how it is organized, and how it assists in operations. We demonstrate\nthe use of this type of testing for a suite of geophysics codes, show why codes\nmay compile on one platform but not on another, and demonstrate how minor\nchanges may alter the computed results in unexpected ways that can influence\nthe scientific interpretation. Finally, we examine result comparison between\nplatforms and show how the compiler or operating system may affect results.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2013 22:22:52 GMT"}], "update_date": "2013-09-06", "authors_parsed": [["Heien", "Eric M.", ""], ["Miller", "Todd L.", ""], ["Gietzel", "Becky", ""], ["Kellogg", "Louise H.", ""]]}, {"id": "1309.1204", "submitter": "Matthew Knepley", "authors": "Matthew G. Knepley, Jed Brown, Karl Rupp, Barry F. Smith", "title": "Achieving High Performance with Unified Residual Evaluation", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine residual evaluation, perhaps the most basic operation in numerical\nsimulation. By raising the level of abstraction in this operation, we can\neliminate specialized code, enable optimization, and greatly increase the\nextensibility of existing code.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2013 23:03:33 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2013 19:35:43 GMT"}], "update_date": "2013-09-09", "authors_parsed": [["Knepley", "Matthew G.", ""], ["Brown", "Jed", ""], ["Rupp", "Karl", ""], ["Smith", "Barry F.", ""]]}, {"id": "1309.1780", "submitter": "Anshu Dubey", "authors": "A. Dubey, S. Brandt, R. Brower, M. Giles, P. Hovland, D.Q. Lamb, F.\n  Loffler, B. Norris, B. OShea, C. Rebbi, M. Snir, R. Thakur", "title": "Software Abstractions and Methodologies for HPC Simulation Codes on\n  Future Architectures", "comments": "Position Paper", "journal-ref": null, "doi": "10.5334/jors.aw", "report-no": null, "categories": "cs.CE cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large, complex, multi-scale, multi-physics simulation codes, running on high\nperformance com-puting (HPC) platforms, have become essential to advancing\nscience and engineering. These codes simulate multi-scale, multi-physics\nphenomena with unprecedented fidelity on petascale platforms, and are used by\nlarge communities. Continued ability of these codes to run on future platforms\nis as crucial to their communities as continued improvements in instruments and\nfacilities are to experimental scientists. However, the ability of code\ndevelopers to do these things faces a serious challenge with the paradigm shift\nunderway in platform architecture. The complexity and uncertainty of the future\nplatforms makes it essential to approach this challenge cooperatively as a\ncommunity. We need to develop common abstractions, frameworks, programming\nmodels and software development methodologies that can be applied across a\nbroad range of complex simulation codes, and common software infrastructure to\nsupport them. In this position paper we express and discuss our belief that\nsuch an infrastructure is critical to the deployment of existing and new large,\nmulti-scale, multi-physics codes on future HPC platforms.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 21:41:20 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Dubey", "A.", ""], ["Brandt", "S.", ""], ["Brower", "R.", ""], ["Giles", "M.", ""], ["Hovland", "P.", ""], ["Lamb", "D. Q.", ""], ["Loffler", "F.", ""], ["Norris", "B.", ""], ["OShea", "B.", ""], ["Rebbi", "C.", ""], ["Snir", "M.", ""], ["Thakur", "R.", ""]]}, {"id": "1309.1781", "submitter": "Anshu Dubey", "authors": "A. Dubey, B. Van Straalen", "title": "Experiences from Software Engineering of Large Scale AMR Multiphysics\n  Code Frameworks", "comments": "Experience Report", "journal-ref": null, "doi": "10.5334/jors.am", "report-no": null, "categories": "cs.CE cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the present generation of multiphysics HPC simulation codes there are\nmany that are built upon general infrastructural frameworks. This is especially\ntrue of the codes that make use of structured adaptive mesh refinement (SAMR)\nbecause of unique demands placed on the housekeeping aspects of the code. They\nhave varying degrees of abstractions between the infrastructure such as mesh\nmanagement and IO and the numerics of the physics solvers. In this experience\nreport we summarize the experiences and lessons learned from two of such major\nsoftware efforts, FLASH and Chombo.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 21:48:39 GMT"}], "update_date": "2014-10-24", "authors_parsed": [["Dubey", "A.", ""], ["Van Straalen", "B.", ""]]}, {"id": "1309.1783", "submitter": "Markus Blatt", "authors": "Makus Blatt", "title": "DUNE as an Example of Sustainable Open Source Scientific Software\n  Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.SE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper we describe how DUNE, an open source scientific software\nframework, is developed. Having a sustainable software framework for the\nsolution of partial differential equations is the main driver of DUNE's\ndevelopment. We take a look how DUNE strives to stay sustainable software.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 21:55:23 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2013 19:56:50 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Blatt", "Makus", ""]]}, {"id": "1309.1812", "submitter": "Frank L\\\"offler", "authors": "Frank L\\\"offler, Steven R. Brandt, Gabrielle Allen and Erik Schnetter", "title": "Cactus: Issues for Sustainable Simulation Software", "comments": "submitted to the Workshop on Sustainable Software for Science:\n  Practice and Experiences 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.MS cs.SE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The Cactus Framework is an open-source, modular, portable programming\nenvironment for the collaborative development and deployment of scientific\napplications using high-performance computing. Its roots reach back to 1996 at\nthe National Center for Supercomputer Applications and the Albert Einstein\nInstitute in Germany, where its development jumpstarted. Since then, the Cactus\nframework has witnessed major changes in hardware infrastructure as well as its\nown community. This paper describes its endurance through these past changes\nand, drawing upon lessons from its past, also discusses future\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2013 03:18:51 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2013 01:33:06 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["L\u00f6ffler", "Frank", ""], ["Brandt", "Steven R.", ""], ["Allen", "Gabrielle", ""], ["Schnetter", "Erik", ""]]}, {"id": "1309.4962", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk and Josef Urban", "title": "HOL(y)Hammer: Online ATP Service for HOL Light", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DL cs.LG cs.LO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HOL(y)Hammer is an online AI/ATP service for formal (computer-understandable)\nmathematics encoded in the HOL Light system. The service allows its users to\nupload and automatically process an arbitrary formal development (project)\nbased on HOL Light, and to attack arbitrary conjectures that use the concepts\ndefined in some of the uploaded projects. For that, the service uses several\nautomated reasoning systems combined with several premise selection methods\ntrained on all the project proofs. The projects that are readily available on\nthe server for such query answering include the recent versions of the\nFlyspeck, Multivariate Analysis and Complex Analysis libraries. The service\nruns on a 48-CPU server, currently employing in parallel for each task 7 AI/ATP\ncombinations and 4 decision procedures that contribute to its overall\nperformance. The system is also available for local installation by interested\nusers, who can customize it for their own proof development. An Emacs interface\nallowing parallel asynchronous queries to the service is also provided. The\noverall structure of the service is outlined, problems that arise and their\nsolutions are discussed, and an initial account of using the system is given.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 13:22:31 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1309.5377", "submitter": "Ivan Girotto", "authors": "Ivan Girotto, Axel Kohlmeyer, David Grellscheid, Shawn T. Brown", "title": "Advanced Techniques for Scientific Programming and Collaborative\n  Development of Open Source Software Packages at the International Centre for\n  Theoretical Physics (ICTP)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of computational scientific research projects make use of open\nsource software packages. However, the development process of such tools\nfrequently differs from conventional software development; partly because of\nthe nature of research, where the problems being addressed are not always fully\nunderstood; partly because the majority of the development is often carried out\nby scientists with limited experience and exposure to best practices of\nsoftware engineering. Often the software development suffers from the pressure\nto publish scientific results and that credit for software development is\nlimited in comparison. Fundamental components of software engineering like\nmodular and reusable design, validation, documentation, and software\nintegration as well as effective maintenance and user support tend to be\ndisregarded due to lack of resources and qualified specialists. Thus innovative\ndevelopments are often hindered by steep learning curves required to master\ndevelopment for legacy software packages full of ad hoc solutions. The growing\ncomplexity of research, however, requires suitable and maintainable\ncomputational tools, resulting in a widening gap between the potential users\n(often growing in number) and contributors to the development of such a\npackage. In this paper we share our experiences aiming to improve the situation\nby training particularly young scientists, through disseminating our own\nexperiences at contributing to open source software packages and practicing key\ncomponents of software engineering adapted for scientists and scientific\nsoftware development. Specifically we summarize the outcome of the Workshop in\nAdvanced Techniques for Scientific Programming and Collaborative Development of\nOpen Source Software Packages run at the Abdus Salam International Centre for\nTheoretical Physics in March 2013, and discuss our conclusions for future\nefforts.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2013 15:07:47 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Girotto", "Ivan", ""], ["Kohlmeyer", "Axel", ""], ["Grellscheid", "David", ""], ["Brown", "Shawn T.", ""]]}, {"id": "1309.5479", "submitter": "Robert Gower", "authors": "Robert M. Gower and Artur L. Gower", "title": "Higher-order Reverse Automatic Differentiation with emphasis on the\n  third-order", "comments": null, "journal-ref": null, "doi": "10.1007/s10107-014-0827-4", "report-no": null, "categories": "cs.MS cs.SC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly assumed that calculating third order information is too\nexpensive for most applications. But we show that the directional derivative of\nthe Hessian ($D^3f(x)\\cdot d$) can be calculated at a cost proportional to that\nof a state-of-the-art method for calculating the Hessian matrix. We do this by\nfirst presenting a simple procedure for designing high order reverse methods\nand applying it to deduce several methods including a reverse method that\ncalculates $D^3f(x)\\cdot d$. We have implemented this method taking into\naccount symmetry and sparsity, and successfully calculated this derivative for\nfunctions with a million variables. These results indicate that the use of\nthird order information in a general nonlinear solver, such as Halley-Chebyshev\nmethods, could be a practical alternative to Newton's method.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2013 14:00:40 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Gower", "Robert M.", ""], ["Gower", "Artur L.", ""]]}, {"id": "1309.5498", "submitter": "Foster Morrison", "authors": "Foster Morrison", "title": "High Precision Arithmetic for Scientific Applications", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All but a few digital computers used for scientific computations have\nsupported floating-point and digital arithmetic of rather limited numerical\nprecision. The underlying assumptions were that the systems being studied were\nbasically deterministic and of limited complexity. The ideal scientific\nparadigm was the orbits of the major planets, which could be observed with high\nprecision, predicted for thousands of years into the future, and extrapolated\nfor thousands of years into the past. Much the same technology that has made\ncomputers possible has also provided instrumentation that has vastly expanded\nthe scope and precision of scientific analysis. Complex nonlinear systems\nexhibiting so-called chaotic dynamics are now fair game for scientists and\nengineers in every discipline. Today it seems that computers need to enhance\nthe precision of their numerical computations to support the needs of science.\nHowever, there is no need to wait for the necessary updates in both hardware\nand software; it is easy enough to monitor numerical precision with a few minor\nmodifications to existing software.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2013 16:45:13 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Morrison", "Foster", ""]]}]