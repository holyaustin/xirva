[{"id": "1209.0735", "submitter": "Darko Veberic", "authors": "Darko Veberic", "title": "Lambert W Function for Applications in Physics", "comments": "9 pages, 12 figures. Extended version of arXiv:1003.1628, updated\n  link to sources", "journal-ref": "Computer Physics Communications 183 (2012) 2622-2628", "doi": "10.1016/j.cpc.2012.07.008", "report-no": null, "categories": "cs.MS cs.NA physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Lambert W(x) function and its possible applications in physics are\npresented. The actual numerical implementation in C++ consists of Halley's and\nFritsch's iterations with initial approximations based on branch-point\nexpansion, asymptotic series, rational fits, and continued-logarithm recursion.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2012 21:07:48 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 14:33:32 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Veberic", "Darko", ""]]}, {"id": "1209.0960", "submitter": "Markus Blatt", "authors": "Markus Blatt, Olaf Ippisch, Peter Bastian", "title": "A Massively Parallel Algebraic Multigrid Preconditioner based on\n  Aggregation for Elliptic Problems with Heterogeneous Coefficients", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a massively parallel algebraic multigrid method based on\nnon-smoothed aggregation. It is especially suited for solving heterogeneous\nelliptic problems as it uses a greedy heuristic algorithm for the aggregation\nthat detects changes in the coefficients and prevents aggregation across them.\nUsing decoupled aggregation on each process with data agglomeration onto fewer\nprocesses on the coarse level, it weakly scales well in terms of both total\ntime to solution and time per iteration to nearly 300,000 cores. Because of\nsimple piecewise constant interpolation between the levels, its memory\nconsumption is low and allows solving problems with more than 100,000,000,000\ndegrees of freedom.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 13:07:36 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2013 15:12:57 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Blatt", "Markus", ""], ["Ippisch", "Olaf", ""], ["Bastian", "Peter", ""]]}, {"id": "1209.1003", "submitter": "Alejandro Arag\\'on PhD", "authors": "Alejandro M. Arag\\'on", "title": "A C++11 implementation of arbitrary-rank tensors for high-performance\n  computing", "comments": "21 pages, 6 figures, 1 table", "journal-ref": "Computer Physics Communications, 185(6): 1681 - 1696, 2014", "doi": "10.1016/j.cpc.2014.01.005", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article discusses an efficient implementation of tensors of arbitrary\nrank by using some of the idioms introduced by the recently published C++ ISO\nStandard (C++11). With the aims at providing a basic building block for\nhigh-performance computing, a single Array class template is carefully crafted,\nfrom which vectors, matrices, and even higher-order tensors can be created. An\nexpression template facility is also built around the array class template to\nprovide convenient mathematical syntax. As a result, by using templates, an\nextra high-level layer is added to the C++ language when dealing with algebraic\nobjects and their operations, without compromising performance. The\nimplementation is tested running on both CPU and GPU.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2012 14:58:51 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2013 18:29:05 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2013 09:44:48 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2013 19:56:21 GMT"}, {"version": "v5", "created": "Fri, 30 May 2014 10:25:54 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Arag\u00f3n", "Alejandro M.", ""]]}, {"id": "1209.1711", "submitter": "Matthew Knepley", "authors": "Matthew G. Knepley", "title": "Programming Languages for Scientific Computing", "comments": "21 pages", "journal-ref": "Encyclopedia of Applied and Computational Mathematics, Springer,\n  2012", "doi": "10.1007/978-3-540-70529-1", "report-no": null, "categories": "cs.PL cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific computation is a discipline that combines numerical analysis,\nphysical understanding, algorithm development, and structured programming.\nSeveral yottacycles per year on the world's largest computers are spent\nsimulating problems as diverse as weather prediction, the properties of\nmaterial composites, the behavior of biomolecules in solution, and the quantum\nnature of chemical compounds. This article is intended to review specfic\nlanguages features and their use in computational science. We will review the\nstrengths and weaknesses of different programming styles, with examples taken\nfrom widely used scientific codes.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2012 12:31:50 GMT"}, {"version": "v2", "created": "Tue, 9 Jan 2018 15:22:10 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Knepley", "Matthew G.", ""]]}, {"id": "1209.2364", "submitter": "Elmar Peise", "authors": "Elmar Peise (1), Paolo Bientinesi (1) ((1) AICES, RWTH Aachen)", "title": "Performance Modeling for Dense Linear Algebra", "comments": "3rd International Workshop on Performance Modeling, Benchmarking and\n  Simulation of High Performance Computer Systems (PMBS12), International\n  Conference for High Performance Computing, Networking, Storage and Analysis\n  2012 (SC12)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the behavior of dense linear algebra algorithms is\ngreatly influenced by factors like target architecture, underlying libraries\nand even problem size; because of this, the accurate prediction of their\nperformance is a real challenge. In this article, we are not interested in\ncreating accurate models for a given algorithm, but in correctly ranking a set\nof equivalent algorithms according to their performance. Aware of the\nhierarchical structure of dense linear algebra routines, we approach the\nproblem by developing a framework for the automatic generation of statistical\nperformance models for BLAS and LAPACK libraries. This allows us to obtain\npredictions through evaluating and combining such models. We demonstrate that\nour approach is successful in both single- and multi-core environments, not\nonly in the ranking of algorithms but also in tuning their parameters.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2012 16:37:20 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2012 01:51:36 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Peise", "Elmar", "", "AICES, RWTH Aachen"], ["Bientinesi", "Paolo", "", "AICES, RWTH Aachen"]]}, {"id": "1209.4233", "submitter": "Laurent Najman", "authors": "Roland Levillain (LIGM, LRDE), Thierry G\\'eraud (LRDE), Laurent Najman\n  (LIGM)", "title": "Writing Reusable Digital Geometry Algorithms in a Generic Image\n  Processing Framework", "comments": "Workshop on Applications of Discrete Geometry and Mathematical\n  Morphology, Istanb : France (2010)", "journal-ref": null, "doi": "10.1007/978-3-642-32313-3_10", "report-no": null, "categories": "cs.MS cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Geometry software should reflect the generality of the underlying\nmathe- matics: mapping the latter to the former requires genericity. By\ndesigning generic solutions, one can effectively reuse digital geometry data\nstructures and algorithms. We propose an image processing framework focused on\nthe Generic Programming paradigm in which an algorithm on the paper can be\nturned into a single code, written once and usable with various input types.\nThis approach enables users to design and implement new methods at a lower\ncost, try cross-domain experiments and help generalize results\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2012 15:17:10 GMT"}], "update_date": "2012-09-20", "authors_parsed": [["Levillain", "Roland", "", "LIGM, LRDE"], ["G\u00e9raud", "Thierry", "", "LRDE"], ["Najman", "Laurent", "", "LIGM"]]}, {"id": "1209.5429", "submitter": "Yasser Gonzalez Fernandez", "authors": "Yasser Gonzalez-Fernandez, Marta Soto", "title": "copulaedas: An R Package for Estimation of Distribution Algorithms Based\n  on Copulas", "comments": null, "journal-ref": "Yasser Gonzalez-Fernandez, Marta Soto (2014). copulaedas: An R\n  Package for Estimation of Distribution Algorithms Based on Copulas. Journal\n  of Statistical Software, 58(9), 1-34. URL http://www.jstatsoft.org/v58/i09/", "doi": null, "report-no": null, "categories": "cs.NE cs.MS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The use of copula-based models in EDAs (estimation of distribution\nalgorithms) is currently an active area of research. In this context, the\ncopulaedas package for R provides a platform where EDAs based on copulas can be\nimplemented and studied. The package offers complete implementations of various\nEDAs based on copulas and vines, a group of well-known optimization problems,\nand utility functions to study the performance of the algorithms. Newly\ndeveloped EDAs can be easily integrated into the package by extending an S4\nclass with generic functions for their main components. This paper presents\ncopulaedas by providing an overview of EDAs based on copulas, a description of\nthe implementation of the package, and an illustration of its use through\nexamples. The examples include running the EDAs defined in the package,\nimplementing new algorithms, and performing an empirical study to compare the\nbehavior of different algorithms on benchmark functions and a real-world\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2012 21:24:17 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2013 18:33:27 GMT"}, {"version": "v3", "created": "Sat, 17 May 2014 20:52:15 GMT"}, {"version": "v4", "created": "Tue, 1 Jul 2014 19:08:59 GMT"}], "update_date": "2014-07-02", "authors_parsed": [["Gonzalez-Fernandez", "Yasser", ""], ["Soto", "Marta", ""]]}, {"id": "1209.6626", "submitter": "Jean-Guillaume Dumas", "authors": "Jean-Guillaume Dumas (CASYS)", "title": "On Newton-Raphson iteration for multiplicative inverses modulo prime\n  powers", "comments": null, "journal-ref": "IEEE Transactions on Computers, Institute of Electrical and\n  Electronics Engineers, 2014, 63 (8), pp.2106-2109", "doi": "10.1109/TC.2013.94", "report-no": null, "categories": "cs.SC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithms for the fast computation of modular inverses.\nNewton-Raphson iteration over $p$-adic numbers gives a recurrence relation\ncomputing modular inverse modulo $p^m$, that is logarithmic in $m$. We solve\nthe recurrence to obtain an explicit formula for the inverse. Then we study\ndifferent implementation variants of this iteration and show that our explicit\nformula is interesting for small exponent values but slower or large exponent,\nsay of more than $700$ bits. Overall we thus propose a hybrid combination of\nour explicit formula and the best asymptotic variants. This hybrid combination\nyields then a constant factor improvement, also for large exponents.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 19:52:06 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2012 13:37:53 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2012 14:33:00 GMT"}, {"version": "v4", "created": "Mon, 15 Jan 2018 13:38:23 GMT"}, {"version": "v5", "created": "Tue, 15 May 2018 10:10:49 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Dumas", "Jean-Guillaume", "", "CASYS"]]}]