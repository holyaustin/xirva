[{"id": "1704.00032", "submitter": "Sven Karol", "authors": "Sven Karol, Tobias Nett, Jeronimo Castrillon, Ivo F. Sbalzarini", "title": "A Domain-Specific Language and Editor for Parallel Particle Methods", "comments": "Submitted to ACM Transactions on Mathematical Software on Dec. 25,\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain-specific languages (DSLs) are of increasing importance in scientific\nhigh-performance computing to reduce development costs, raise the level of\nabstraction and, thus, ease scientific programming. However, designing and\nimplementing DSLs is not an easy task, as it requires knowledge of the\napplication domain and experience in language engineering and compilers.\nConsequently, many DSLs follow a weak approach using macros or text generators,\nwhich lack many of the features that make a DSL a comfortable for programmers.\nSome of these features---e.g., syntax highlighting, type inference, error\nreporting, and code completion---are easily provided by language workbenches,\nwhich combine language engineering techniques and tools in a common ecosystem.\nIn this paper, we present the Parallel Particle-Mesh Environment (PPME), a DSL\nand development environment for numerical simulations based on particle methods\nand hybrid particle-mesh methods. PPME uses the meta programming system (MPS),\na projectional language workbench. PPME is the successor of the Parallel\nParticle-Mesh Language (PPML), a Fortran-based DSL that used conventional\nimplementation strategies. We analyze and compare both languages and\ndemonstrate how the programmer's experience can be improved using static\nanalyses and projectional editing. Furthermore, we present an explicit domain\nmodel for particle abstractions and the first formal type system for particle\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 19:39:27 GMT"}, {"version": "v2", "created": "Sun, 17 Sep 2017 13:50:08 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Karol", "Sven", ""], ["Nett", "Tobias", ""], ["Castrillon", "Jeronimo", ""], ["Sbalzarini", "Ivo F.", ""]]}, {"id": "1704.00206", "submitter": "Dmitry Kulyabov PhD", "authors": "M. N. Gevorkyan, A. V. Demidova, A. V. Korolkova, D. S. Kulyabov, L.\n  A. Sevastianov", "title": "The Stochastic Processes Generation in OpenModelica", "comments": "in English, in Russian", "journal-ref": null, "doi": "10.1007/978-3-319-51917-3_46", "report-no": null, "categories": "cs.MS physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background: Component-based modeling language Modelica (OpenModelica is open\nsource implementation) is used for the numerical simulation of complex\nprocesses of different nature represented by ODE system. However, in\nOpenModelica standard library there is no routines for pseudo-random numbers\ngeneration, which makes it impossible to use for stochastic modeling processes.\nPurpose: The goal of this article is a brief overview of a number of algorithms\nfor generation a sequence of uniformly distributed pseudo random numbers and\nquality assessment of the sequence given by them, as well as the ways to\nimplement some of these algorithms in OpenModelica system. Methods: All the\nalgorithms are implemented in C language, and the results of their work tested\nusing open source package DieHarder. For those algorithms that do not use bit\noperations, we describe there realisation using OpwnModelica. The other\nalgorithms can be called in OpenModelica as C functions Results: We have\nimplemented and tested about nine algorithms. DieHarder testing revealed the\nhighest quality pseudo-random number generators. Also we have reviewed\nlibraries Noise and AdvancedNoise, who claim to be adding to the Modelica\nStandard Library. Conclusions: In OpenModelica system can be implemented\ngenerators of uniformly distributed pseudo-random numbers, which is the first\nstep towards to make OpenModelica suitable for simulation of stochastic\nprocesses.\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 18:17:50 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Gevorkyan", "M. N.", ""], ["Demidova", "A. V.", ""], ["Korolkova", "A. V.", ""], ["Kulyabov", "D. S.", ""], ["Sevastianov", "L. A.", ""]]}, {"id": "1704.00605", "submitter": "Daniel Lemire", "authors": "Wojciech Mu{\\l}a and Daniel Lemire", "title": "Faster Base64 Encoding and Decoding Using AVX2 Instructions", "comments": "software at https://github.com/lemire/fastbase64", "journal-ref": "ACM Transactions on the Web 12 (3), 2018", "doi": "10.1145/3132709", "report-no": null, "categories": "cs.MS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Web developers use base64 formats to include images, fonts, sounds and other\nresources directly inside HTML, JavaScript, JSON and XML files. We estimate\nthat billions of base64 messages are decoded every day. We are motivated to\nimprove the efficiency of base64 encoding and decoding. Compared to\nstate-of-the-art implementations, we multiply the speeds of both the encoding\n(~10x) and the decoding (~7x). We achieve these good results by using the\nsingle-instruction-multiple-data (SIMD) instructions available on recent Intel\nprocessors (AVX2). Our accelerated software abides by the specification and\nreports errors when encountering characters outside of the base64 set. It is\navailable online as free software under a liberal license.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 19:04:09 GMT"}, {"version": "v2", "created": "Mon, 24 Apr 2017 00:25:35 GMT"}, {"version": "v3", "created": "Sat, 12 Aug 2017 03:04:27 GMT"}, {"version": "v4", "created": "Wed, 17 Jan 2018 19:27:41 GMT"}, {"version": "v5", "created": "Thu, 14 Jun 2018 21:02:13 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Mu\u0142a", "Wojciech", ""], ["Lemire", "Daniel", ""]]}, {"id": "1704.01145", "submitter": "Javier Segura", "authors": "T. M. Dunster, A. Gil, J. Segura, N. M. Temme", "title": "Conical: an extended module for computing a numerically satisfactory\n  pair of solutions of the differential equation for conical functions", "comments": "To appear in Computer Physics Communications", "journal-ref": null, "doi": "10.1016/j.cpc.2017.04.007", "report-no": null, "categories": "cs.MS math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conical functions appear in a large number of applications in physics and\nengineering. In this paper we describe an extension of our module CONICAL for\nthe computation of conical functions. Specifically, the module includes now a\nroutine for computing the function ${{\\rm R}}^{m}_{-\\frac{1}{2}+i\\tau}(x)$, a\nreal-valued numerically satisfactory companion of the function ${\\rm\nP}^m_{-\\tfrac12+i\\tau}(x)$ for $x>1$. In this way, a natural basis for solving\nDirichlet problems bounded by conical domains is provided.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 18:28:01 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Dunster", "T. M.", ""], ["Gil", "A.", ""], ["Segura", "J.", ""], ["Temme", "N. M.", ""]]}, {"id": "1704.02457", "submitter": "Gianluca Frison", "authors": "Gianluca Frison, Dimitris Kouzoupis, Tommaso Sartor, Andrea Zanelli,\n  Moritz Diehl", "title": "BLASFEO: basic linear algebra subroutines for embedded optimization", "comments": null, "journal-ref": "ACM Transactions on Mathematical Software (TOMS): Volume 44 Issue\n  4, August 2018", "doi": "10.1145/3210754", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BLASFEO is a dense linear algebra library providing high-performance\nimplementations of BLAS- and LAPACK-like routines for use in embedded\noptimization. A key difference with respect to existing high-performance\nimplementations of BLAS is that the computational performance is optimized for\nsmall to medium scale matrices, i.e., for sizes up to a few hundred. BLASFEO\ncomes with three different implementations: a high-performance implementation\naiming at providing the highest performance for matrices fitting in cache, a\nreference implementation providing portability and embeddability and optimized\nfor very small matrices, and a wrapper to standard BLAS and LAPACK providing\nhigh-performance on large matrices. The three implementations of BLASFEO\ntogether provide high-performance dense linear algebra routines for matrices\nranging from very small to large. Compared to both open-source and proprietary\nhighly-tuned BLAS libraries, for matrices of size up to about one hundred the\nhigh-performance implementation of BLASFEO is about 20-30% faster than the\ncorresponding level 3 BLAS routines and 2-3 times faster than the corresponding\nLAPACK routines.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 09:00:22 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 15:44:53 GMT"}, {"version": "v3", "created": "Sun, 7 Jan 2018 17:38:05 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Frison", "Gianluca", ""], ["Kouzoupis", "Dimitris", ""], ["Sartor", "Tommaso", ""], ["Zanelli", "Andrea", ""], ["Diehl", "Moritz", ""]]}, {"id": "1704.03092", "submitter": "Jianyu Huang", "authors": "Jianyu Huang, Devin A. Matthews, Robert A. van de Geijn", "title": "Strassen's Algorithm for Tensor Contraction", "comments": null, "journal-ref": null, "doi": null, "report-no": "FLAME Working Note #84, The University of Texas at Austin,\n  Department of Computer Science, Technical Report TR-17-02", "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor contraction (TC) is an important computational kernel widely used in\nnumerous applications. It is a multi-dimensional generalization of matrix\nmultiplication (GEMM). While Strassen's algorithm for GEMM is well studied in\ntheory and practice, extending it to accelerate TC has not been previously\npursued. Thus, we believe this to be the first paper to demonstrate how one can\nin practice speed up tensor contraction with Strassen's algorithm. By adopting\na Block-Scatter-Matrix format, a novel matrix-centric tensor layout, we can\nconceptually view TC as GEMM for a general stride storage, with an implicit\ntensor-to-matrix transformation. This insight enables us to tailor a recent\nstate-of-the-art implementation of Strassen's algorithm to TC, avoiding\nexplicit transpositions (permutations) and extra workspace, and reducing the\noverhead of memory movement that is incurred. Performance benefits are\ndemonstrated with a performance model as well as in practice on modern single\ncore, multicore, and distributed memory parallel architectures, achieving up to\n1.3x speedup. The resulting implementations can serve as a drop-in replacement\nfor various applications with significant speedup.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 00:37:59 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Huang", "Jianyu", ""], ["Matthews", "Devin A.", ""], ["van de Geijn", "Robert A.", ""]]}, {"id": "1704.04084", "submitter": "James Mitchell", "authors": "J. Jonu\\v{s}as, J. D. Mitchell, and M. Pfeiffer", "title": "Two variants of the Froiduire-Pin Algorithm for finite semigroups", "comments": "19 pages, 7 figures (v2 revised according to referees comments to\n  improve the readability, and add a further 1198 examples)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.GR cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present two algorithms based on the Froidure-Pin Algorithm\nfor computing the structure of a finite semigroup from a generating set. As was\nthe case with the original algorithm of Froidure and Pin, the algorithms\npresented here produce the left and right Cayley graphs, a confluent\nterminating rewriting system, and a reduced word of the rewriting system for\nevery element of the semigroup.\n  If $U$ is any semigroup, and $A$ is a subset of $U$, then we denote by\n$\\langle A\\rangle$ the least subsemigroup of $U$ containing $A$. If $B$ is any\nother subset of $U$, then, roughly speaking, the first algorithm we present\ndescribes how to use any information about $\\langle A\\rangle$, that has been\nfound using the Froidure-Pin Algorithm, to compute the semigroup $\\langle A\\cup\nB\\rangle$. More precisely, we describe the data structure for a finite\nsemigroup $S$ given by Froidure and Pin, and how to obtain such a data\nstructure for $\\langle A\\cup B\\rangle$ from that for $\\langle A\\rangle$. The\nsecond algorithm is a lock-free concurrent version of the Froidure-Pin\nAlgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 12:05:37 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 17:00:57 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Jonu\u0161as", "J.", ""], ["Mitchell", "J. D.", ""], ["Pfeiffer", "M.", ""]]}, {"id": "1704.04374", "submitter": "Paul Springer", "authors": "Paul Springer, Tong Su, Paolo Bientinesi", "title": "HPTT: A High-Performance Tensor Transposition C++ Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we presented TTC, a domain-specific compiler for tensor\ntranspositions. Despite the fact that the performance of the generated code is\nnearly optimal, due to its offline nature, TTC cannot be utilized in all the\napplication codes in which the tensor sizes and the necessary tensor\npermutations are determined at runtime. To overcome this limitation, we\nintroduce the open-source C++ library High-Performance Tensor Transposition\n(HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking,\nmulti-threading, and explicit vectorization; furthermore it decomposes any\ntransposition into multiple loops around a so called micro-kernel. This modular\ndesign---inspired by BLIS---makes HPTT easy to port to different architectures,\nby only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose).\nHPTT also offers an optional autotuning framework---guided by a performance\nmodel---that explores a vast search space of implementations at runtime\n(similar to FFTW). Across a wide range of different tensor transpositions and\narchitectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM\nPower7), HPTT attains a bandwidth comparable to that of SAXPY, and yields\nremarkable speedups over Eigen's tensor transposition implementation. Most\nimportantly, the integration of HPTT into the Cyclops Tensor Framework (CTF)\nimproves the overall performance of tensor contractions by up to 3.1x.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 09:45:06 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 21:34:51 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Springer", "Paul", ""], ["Su", "Tong", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1704.05594", "submitter": "Ahmed Attia", "authors": "Ahmed Attia and Adrian Sandu", "title": "DATeS: A Highly-Extensible Data Assimilation Testing Suite v1.0", "comments": null, "journal-ref": null, "doi": null, "report-no": "CSTR-5/2017", "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A flexible and highly-extensible data assimilation testing suite, named\nDATeS, is described in this paper. DATeS aims to offer a unified testing\nenvironment that allows researchers to compare different data assimilation\nmethodologies and understand their performance in various settings. The core of\nDATeS is implemented in Python and takes advantage of its object-oriented\ncapabilities. The main components of the package (the numerical models, the\ndata assimilation algorithms, the linear algebra solvers, and the time\ndiscretization routines) are independent of each other, which offers great\nflexibility to configure data assimilation applications. DATeS can interface\neasily with large third-party numerical models written in Fortran or in C, and\nwith a plethora of external solvers.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 02:58:23 GMT"}, {"version": "v2", "created": "Mon, 2 Jul 2018 03:06:51 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Attia", "Ahmed", ""], ["Sandu", "Adrian", ""]]}, {"id": "1704.08579", "submitter": "B\\'erenger Bramas", "authors": "Berenger Bramas", "title": "A Novel Hybrid Quicksort Algorithm Vectorized using AVX-512 on Intel\n  Skylake", "comments": "8 pages, research paper", "journal-ref": "Article Published in International Journal of Advanced Computer\n  Science and Applications(IJACSA), Volume 8 Issue 10, 2017", "doi": "10.14569/IJACSA.2017.081044", "report-no": null, "categories": "cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The modern CPU's design, which is composed of hierarchical memory and\nSIMD/vectorization capability, governs the potential for algorithms to be\ntransformed into efficient implementations. The release of the AVX-512 changed\nthings radically, and motivated us to search for an efficient sorting algorithm\nthat can take advantage of it. In this paper, we describe the best strategy we\nhave found, which is a novel two parts hybrid sort, based on the well-known\nQuicksort algorithm. The central partitioning operation is performed by a new\nalgorithm, and small partitions/arrays are sorted using a branch-free\nBitonic-based sort. This study is also an illustration of how classical\nalgorithms can be adapted and enhanced by the AVX-512 extension. We evaluate\nthe performance of our approach on a modern Intel Xeon Skylake and assess the\ndifferent layers of our implementation by sorting/partitioning integers, double\nfloating-point numbers, and key/value pairs of integers. Our results\ndemonstrate that our approach is faster than two libraries of reference: the\nGNU \\emph{C++} sort algorithm by a speedup factor of 4, and the Intel IPP\nlibrary by a speedup factor of 1.4.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 12:34:29 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 11:39:00 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Bramas", "Berenger", ""]]}, {"id": "1704.08907", "submitter": "Maria Bruna", "authors": "Martin Robinson and Maria Bruna", "title": "Particle-based and Meshless Methods with Aboria", "comments": null, "journal-ref": "SoftwareX 6 (2017)", "doi": "10.1016/j.softx.2017.07.002", "report-no": null, "categories": "cs.MS cond-mat.soft q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aboria is a powerful and flexible C++ library for the implementation of\nparticle-based numerical methods. The particles in such methods can represent\nactual particles (e.g. Molecular Dynamics) or abstract particles used to\ndiscretise a continuous function over a domain (e.g. Radial Basis Functions).\nAboria provides a particle container, compatible with the Standard Template\nLibrary, spatial search data structures, and a Domain Specific Language to\nspecify non-linear operators on the particle set. This paper gives an overview\nof Aboria's design, an example of use, and a performance benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 12:49:43 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 20:50:12 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Robinson", "Martin", ""], ["Bruna", "Maria", ""]]}]