[{"id": "1603.00293", "submitter": "Ulrich Matter", "authors": "Ulrich Matter", "title": "RWebData: A High-Level Interface to the Programmable Web", "comments": "Working Paper. Keywords: R, programmable web, big public data, web\n  api, rest", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of the programmable web offers new opportunities for the empirically\ndriven social sciences. The access, compilation and preparation of data from\nthe programmable web for statistical analysis can, however, involve substantial\nup-front costs for the practical researcher. The R-package RWebData provides a\nhigh-level framework that allows data to be easily collected from the\nprogrammable web in a format that can directly be used for statistical analysis\nin R (R Core Team 2013) without bothering about the data's initial format and\nnesting structure. It was developed specifically for users who have no\nexperience with web technologies and merely use R as a statistical software.\nThe core idea and methodological contribution of the package are the\ndisentangling of parsing web data and mapping them with a generic algorithm\n(independent of the initial data structure) to a flat table-like\nrepresentation. This paper provides an overview of the high-level functions for\nR-users, explains the basic architecture of the package, and illustrates the\nimplemented data mapping algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 14:44:47 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2016 15:48:04 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Matter", "Ulrich", ""]]}, {"id": "1603.01793", "submitter": "Andrey Shanin V", "authors": "J. Poblet-Puig and A. V. Shanin", "title": "A New Numerical Method for Solving the Acoustic Radiation Problem", "comments": null, "journal-ref": "Poblet-Puig J., Shanin A.V., A new numerical method for solving\n  the acoustic radiation problem. Acoustical Physics. Vol. 64, no. 2. PP.\n  252-259 (2018)", "doi": "10.1134/S1063771018020148", "report-no": null, "categories": "cs.NA cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A numerical method of solving the problem of acoustic wave radiation in the\npresence of a rigid scatterer is described. It combines the finite element\nmethod and the boundary algebraic equations. In the proposed method, the\nexterior domain around the scatterer is discretized, so that there appear an\ninfinite domain with regular discretization and a relatively small layer with\nirregular mesh. For the infinite regular mesh, the boundary algebraic equation\nmethod is used with spurious resonance suppression according to Burton and\nMiller. In the thin layer with irregular mesh, the finite element method is\nused. The proposed method is characterized by simple implementation, fair\naccuracy, and absence of spurious resonances.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2016 06:21:30 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 08:51:02 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Poblet-Puig", "J.", ""], ["Shanin", "A. V.", ""]]}, {"id": "1603.02297", "submitter": "Paul Springer", "authors": "Paul Springer and Jeff R. Hammond and Paolo Bientinesi", "title": "TTC: A high-performance Compiler for Tensor Transpositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present TTC, an open-source parallel compiler for multidimensional tensor\ntranspositions. In order to generate high-performance C++ code, TTC explores a\nnumber of optimizations, including software prefetching, blocking,\nloop-reordering, and explicit vectorization. To evaluate the performance of\nmultidimensional transpositions across a range of possible use-cases, we also\nrelease a benchmark covering arbitrary transpositions of up to six dimensions.\nPerformance results show that the routines generated by TTC achieve close to\npeak memory bandwidth on both the Intel Haswell and the AMD Steamroller\narchitectures, and yield significant performance gains over modern compilers.\nBy implementing a set of pruning heuristics, TTC allows users to limit the\nnumber of potential solutions; this option is especially useful when dealing\nwith high-dimensional tensors, as the search space might become prohibitively\nlarge. Experiments indicate that when only 100 potential solutions are\nconsidered, the resulting performance is about 99% of that achieved with\nexhaustive search.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 21:13:00 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Springer", "Paul", ""], ["Hammond", "Jeff R.", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1603.02526", "submitter": "Nate Derbinsky", "authors": "Ning Hao and AmirReza Oghbaee and Mohammad Rostami and Nate Derbinsky\n  and Jos\\'e Bento", "title": "Testing fine-grained parallelism for the ADMM on a factor-graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an ongoing effort to develop tools that apply distributed\ncomputational resources to tackle large problems or reduce the time to solve\nthem. In this context, the Alternating Direction Method of Multipliers (ADMM)\narises as a method that can exploit distributed resources like the dual ascent\nmethod and has the robustness and improved convergence of the augmented\nLagrangian method. Traditional approaches to accelerate the ADMM using multiple\ncores are problem-specific and often require multi-core programming. By\ncontrast, we propose a problem-independent scheme of accelerating the ADMM that\ndoes not require the user to write any parallel code. We show that this scheme,\nan interpretation of the ADMM as a message-passing algorithm on a factor-graph,\ncan automatically exploit fine-grained parallelism both in GPUs and\nshared-memory multi-core computers and achieves significant speedup in such\ndiverse application domains as combinatorial optimization, machine learning,\nand optimal control. Specifically, we obtain 10-18x speedup using a GPU, and\n5-9x using multiple CPU cores, over a serial, optimized C-version of the ADMM,\nwhich is similar to the typical speedup reported for existing GPU-accelerated\nlibraries, including cuFFT (19x), cuBLAS (17x), and cuRAND (8x).\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2016 14:13:38 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Hao", "Ning", ""], ["Oghbaee", "AmirReza", ""], ["Rostami", "Mohammad", ""], ["Derbinsky", "Nate", ""], ["Bento", "Jos\u00e9", ""]]}, {"id": "1603.03236", "submitter": "Sebastian Weichwald", "authors": "James Townsend, Niklas Koep, Sebastian Weichwald", "title": "Pymanopt: A Python Toolbox for Optimization on Manifolds using Automatic\n  Differentiation", "comments": null, "journal-ref": "Journal of Machine Learning Research, 17(137):1-5, 2016 (\n  https://jmlr.org/papers/v17/16-177.html )", "doi": null, "report-no": null, "categories": "cs.MS cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization on manifolds is a class of methods for optimization of an\nobjective function, subject to constraints which are smooth, in the sense that\nthe set of points which satisfy the constraints admits the structure of a\ndifferentiable manifold. While many optimization problems are of the described\nform, technicalities of differential geometry and the laborious calculation of\nderivatives pose a significant barrier for experimenting with these methods.\n  We introduce Pymanopt (available at https://pymanopt.github.io), a toolbox\nfor optimization on manifolds, implemented in Python, that---similarly to the\nManopt Matlab toolbox---implements several manifold geometries and optimization\nalgorithms. Moreover, we lower the barriers to users further by using automated\ndifferentiation for calculating derivative information, saving users time and\nsaving them from potential calculation and implementation errors.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 12:23:12 GMT"}, {"version": "v2", "created": "Fri, 8 Apr 2016 12:46:31 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2016 10:04:13 GMT"}, {"version": "v4", "created": "Thu, 8 Sep 2016 09:23:08 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Townsend", "James", ""], ["Koep", "Niklas", ""], ["Weichwald", "Sebastian", ""]]}, {"id": "1603.04483", "submitter": "Jan Cieslinski L.", "authors": "Leonid V. Moroz, Cezary J. Walczyk, Andriy Hrynchyshyn, Vijay Holimath\n  and Jan L. Cie\\'sli\\'nski", "title": "Fast calculation of inverse square root with the use of magic constant\n  $-$ analytical approach", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mathematical analysis of transformations used in fast\ncalculation of inverse square root for single-precision floating-point numbers.\nOptimal values of the so called magic constants are derived in a systematic\nway, minimizing either absolute or relative errors at subsequent stages of the\ndiscussed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 21:28:46 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Moroz", "Leonid V.", ""], ["Walczyk", "Cezary J.", ""], ["Hrynchyshyn", "Andriy", ""], ["Holimath", "Vijay", ""], ["Cie\u015bli\u0144ski", "Jan L.", ""]]}, {"id": "1603.04787", "submitter": "Jaros{\\l}aw Miszczak", "authors": "J.A. Miszczak", "title": "States and channels in quantum mechanics without complex numbers", "comments": "10 pages, 2 figures, presented at ACA2015, July 20-23, 2015,\n  Kalamata, Greece", "journal-ref": "Springer Proceedings in Mathematics & Statistics, vol 198 (2017)", "doi": "10.1007/978-3-319-56932-1_21", "report-no": null, "categories": "physics.comp-ph cs.MS quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the presented note we aim at exploring the possibility of abandoning\ncomplex numbers in the representation of quantum states and operations. We\ndemonstrate a simplified version of quantum mechanics in which the states are\nrepresented using real numbers only. The main advantage of this approach is\nthat the simulation of the $n$-dimensional quantum system requires $n^2$ real\nnumbers, in contrast to the standard case where $n^4$ real numbers are\nrequired. The main disadvantage is the lack of hermicity in the representation\nof quantum states. Using Mathematica computer algebra system we develop a set\nof functions for manipulating real-only quantum states. With the help of this\ntool we study the properties of the introduced representation and the induced\nrepresentation of quantum channels.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2016 18:00:52 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Miszczak", "J. A.", ""]]}, {"id": "1603.05835", "submitter": "Hendrik Dirks", "authors": "Hendrik Dirks", "title": "A Flexible Primal-Dual Toolbox", "comments": "10 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\textbf{FlexBox} is a flexible MATLAB toolbox for finite dimensional convex\nvariational problems in image processing and beyond. Such problems often\nconsist of non-differentiable parts and involve linear operators. The toolbox\nuses a primal-dual scheme to avoid (computationally) inefficient operator\ninversion and to get reliable error estimates. From the user-side,\n\\textbf{FlexBox} expects the primal formulation of the problem, automatically\ndecouples operators and dualizes the problem. For large-scale problems,\n\\textbf{FlexBox} also comes with a \\cpp-module, which can be used stand-alone\nor together with MATLAB via MEX-interfaces. Besides various pre-implemented\ndata-fidelities and regularization-terms, \\textbf{FlexBox} is able to handle\narbitrary operators while being easily extendable, due to its object-oriented\ndesign. The toolbox is available at\n\\href{http://www.flexbox.im}{http://www.flexbox.im}\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2016 11:01:23 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 13:11:14 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Dirks", "Hendrik", ""]]}, {"id": "1603.06017", "submitter": "Hamoon Mousavi", "authors": "Hamoon Mousavi", "title": "Automatic Theorem Proving in Walnut", "comments": "Added a few more sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.LO cs.MS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Walnut is a software package that implements a mechanical decision procedure\nfor deciding certain combinatorial properties of some special words referred to\nas automatic words or automatic sequences. Walnut is written in Java and is\nopen source. It is licensed under GNU General Public License.\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2016 23:53:10 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 23:20:24 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Mousavi", "Hamoon", ""]]}, {"id": "1603.06424", "submitter": "Nicolas Thi\\'ery M.", "authors": "Paul-Olivier Dehaye, Michael Kohlhase, Alexander Konovalov, Samuel\n  Leli\\`evre, Markus Pfeiffer, Nicolas M. Thi\\'ery", "title": "Interoperability in the OpenDreamKit Project: The Math-in-the-Middle\n  Approach", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": "10.1007/978-3-319-42547-4_9", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenDreamKit --- \"Open Digital Research Environment Toolkit for the\nAdvancement of Mathematics\" --- is an H2020 EU Research Infrastructure project\nthat aims at supporting, over the period 2015--2019, the ecosystem of\nopen-source mathematical software systems. From that, OpenDreamKit will deliver\na flexible toolkit enabling research groups to set up Virtual Research\nEnvironments, customised to meet the varied needs of research projects in pure\nmathematics and applications.\n  An important step in the OpenDreamKit endeavor is to foster the\ninteroperability between a variety of systems, ranging from computer algebra\nsystems over mathematical databases to front-ends. This is the mission of the\nintegration work package (WP6). We report on experiments and future plans with\nthe \\emph{Math-in-the-Middle} approach. This information architecture consists\nin a central mathematical ontology that documents the domain and fixes a joint\nvocabulary, combined with specifications of the functionalities of the various\nsystems. Interaction between systems can then be enriched by pivoting off this\ninformation architecture.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2016 13:18:44 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Dehaye", "Paul-Olivier", ""], ["Kohlhase", "Michael", ""], ["Konovalov", "Alexander", ""], ["Leli\u00e8vre", "Samuel", ""], ["Pfeiffer", "Markus", ""], ["Thi\u00e9ry", "Nicolas M.", ""]]}, {"id": "1603.06907", "submitter": "Nuno Fachada", "authors": "Nuno Fachada, Jo\\~ao Rodrigues, Vitor V. Lopes, Rui C. Martins,\n  Agostinho C. Rosa", "title": "micompr: An R Package for Multivariate Independent Comparison of\n  Observations", "comments": "The peer-reviewed version of this paper is published in The R Journal\n  at\n  https://journal.r-project.org/archive/2016-2/fachada-rodrigues-lopes-etal.pdf\n  . This version is typeset by the authors and differs only in pagination and\n  typographical detail", "journal-ref": "The R Journal, 8(2): 405-420 (2016)", "doi": "10.32614/RJ-2016-055", "report-no": null, "categories": "cs.MS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The R package micompr implements a procedure for assessing if two or more\nmultivariate samples are drawn from the same distribution. The procedure uses\nprincipal component analysis to convert multivariate observations into a set of\nlinearly uncorrelated statistical measures, which are then compared using a\nnumber of statistical methods. This technique is independent of the\ndistributional properties of samples and automatically selects features that\nbest explain their differences. The procedure is appropriate for comparing\nsamples of time series, images, spectrometric measures or similar\nhigh-dimension multivariate observations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 18:57:41 GMT"}, {"version": "v2", "created": "Sun, 8 May 2016 19:43:40 GMT"}, {"version": "v3", "created": "Sun, 16 Oct 2016 16:35:57 GMT"}, {"version": "v4", "created": "Fri, 17 Feb 2017 11:12:09 GMT"}, {"version": "v5", "created": "Tue, 21 Feb 2017 19:06:05 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fachada", "Nuno", ""], ["Rodrigues", "Jo\u00e3o", ""], ["Lopes", "Vitor V.", ""], ["Martins", "Rui C.", ""], ["Rosa", "Agostinho C.", ""]]}, {"id": "1603.06914", "submitter": "Nuno Fachada", "authors": "Nuno Fachada, Vitor V. Lopes, Rui C. Martins, Agostinho C. Rosa", "title": "SimOutUtils - Utilities for analyzing time series simulation output", "comments": "The peer-reviewed version of this paper is published in the Journal\n  of Open Research Software at http://doi.org/10.5334/jors.110 . This version\n  is typeset by the authors and differs only in pagination and typographical\n  detail", "journal-ref": "Journal of Open Research Software. 4(1), p.e38, 2016", "doi": "10.5334/jors.110", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SimOutUtils is a suite of MATLAB/Octave functions for studying and analyzing\ntime series-like output from stochastic simulation models. More specifically,\nSimOutUtils allows modelers to study and visualize simulation output dynamics,\nperform distributional analysis of output statistical summaries, as well as\ncompare these summaries in order to assert the statistical equivalence of two\nor more model implementations. Additionally, the provided functions are able to\nproduce publication quality figures and tables showcasing results from the\nspecified simulation output studies.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 19:11:07 GMT"}, {"version": "v2", "created": "Wed, 27 Apr 2016 18:42:18 GMT"}, {"version": "v3", "created": "Sat, 22 Oct 2016 16:36:06 GMT"}, {"version": "v4", "created": "Fri, 6 Jan 2017 12:10:24 GMT"}], "update_date": "2017-01-09", "authors_parsed": [["Fachada", "Nuno", ""], ["Lopes", "Vitor V.", ""], ["Martins", "Rui C.", ""], ["Rosa", "Agostinho C.", ""]]}, {"id": "1603.07008", "submitter": "Lukas Einkemmer", "authors": "Lukas Einkemmer", "title": "A mixed precision semi-Lagrangian algorithm and its performance on\n  accelerators", "comments": null, "journal-ref": null, "doi": "10.1109/HPCSim.2016.7568318", "report-no": null, "categories": "cs.MS math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a mixed precision algorithm in the context of the\nsemi-Lagrangian discontinuous Galerkin method. The performance of this approach\nis evaluated on a traditional dual socket workstation as well as on a Xeon Phi\nand an NVIDIA K80. We find that the mixed precision algorithm can be\nimplemented efficiently on these architectures. This implies that, in addition\nto the considerable reduction in memory, a substantial increase in performance\ncan be observed as well. Moreover, we discuss the relative performance of our\nimplementations.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 22:07:18 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Einkemmer", "Lukas", ""]]}, {"id": "1603.07342", "submitter": "Arkadiusz Hypki Dr", "authors": "Arkadiusz Hypki", "title": "BEANS - a software package for distributed Big Data analysis", "comments": "14 pages, 6 figures, submitted to MNRAS, comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BEANS software is a web based, easy to install and maintain, new tool to\nstore and analyse data in a distributed way for a massive amount of data. It\nprovides a clear interface for querying, filtering, aggregating, and plotting\ndata from an arbitrary number of datasets. Its main purpose is to simplify the\nprocess of storing, examining and finding new relations in the so-called Big\nData.\n  Creation of BEANS software is an answer to the growing needs of the\nastronomical community to have a versatile tool to store, analyse and compare\nthe complex astrophysical numerical simulations with observations (e.g.\nsimulations of the Galaxy or star clusters with the Gaia archive). However,\nthis software was built in a general form and it is ready to use in any other\nresearch field or open source software.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 20:14:34 GMT"}], "update_date": "2016-03-25", "authors_parsed": [["Hypki", "Arkadiusz", ""]]}, {"id": "1603.07916", "submitter": "Remi Imbach", "authors": "R\\'emi Imbach (VEGAS)", "title": "A Subdivision Solver for Systems of Large Dense Polynomials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe here the package {\\tt subdivision\\\\_solver} for the mathematical\nsoftware {\\tt SageMath}. It provides a solver on real numbers for square\nsystems of large dense polynomials. By large polynomials we mean multivariate\npolynomials with large degrees, which coefficients have large bit-size. While\nstaying robust, symbolic approaches to solve systems of polynomials see their\nperformances dramatically affected by high degree and bit-size of input\npolynomials.Available numeric approaches suffer from the cost of the evaluation\nof large polynomials and their derivatives.Our solver is based on interval\nanalysis and bisections of an initial compact domain of $\\R^n$ where solutions\nare sought. Evaluations on intervals with Horner scheme is performed by the\npackage {\\tt fast\\\\_polynomial} for {\\tt SageMath}.The non-existence of a\nsolution within a box is certified by an evaluation scheme that uses a Taylor\nexpansion at order 2, and existence and uniqueness of a solution within a box\nis certified with krawczyk operator.The precision of the working arithmetic is\nadapted on the fly during the subdivision process and we present a new\nheuristic criterion to decide if the arithmetic precision has to be increased.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2016 14:07:49 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 14:38:23 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Imbach", "R\u00e9mi", "", "VEGAS"]]}, {"id": "1603.08785", "submitter": "Nikolaus Hansen", "authors": "Nikolaus Hansen (RANDOPT), Anne Auger (RANDOPT), Raymond Ros (TAO),\n  Olaf Mersmann (TU), Tea Tu\\v{s}ar (IJS), Dimo Brockhoff (RANDOPT)", "title": "COCO: A Platform for Comparing Continuous Optimizers in a Black-Box\n  Setting", "comments": "Optimization Methods and Software, Taylor & Francis, In press,\n  pp.1-31", "journal-ref": null, "doi": "10.1080/10556788.2020.1808977", "report-no": null, "categories": "cs.AI cs.MS cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce COCO, an open source platform for Comparing Continuous\nOptimizers in a black-box setting. COCO aims at automatizing the tedious and\nrepetitive task of benchmarking numerical optimization algorithms to the\ngreatest possible extent. The platform and the underlying methodology allow to\nbenchmark in the same framework deterministic and stochastic solvers for both\nsingle and multiobjective optimization. We present the rationales behind the\n(decade-long) development of the platform as a general proposition for\nguidelines towards better benchmarking. We detail underlying fundamental\nconcepts of COCO such as the definition of a problem as a function instance,\nthe underlying idea of instances, the use of target values, and runtime defined\nby the number of function calls as the central performance measure. Finally, we\ngive a quick overview of the basic code structure and the currently available\ntest suites.\n", "versions": [{"version": "v1", "created": "Tue, 29 Mar 2016 14:18:52 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 06:27:09 GMT"}, {"version": "v3", "created": "Mon, 1 Aug 2016 15:19:31 GMT"}, {"version": "v4", "created": "Wed, 9 Sep 2020 14:41:57 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Hansen", "Nikolaus", "", "RANDOPT"], ["Auger", "Anne", "", "RANDOPT"], ["Ros", "Raymond", "", "TAO"], ["Mersmann", "Olaf", "", "TU"], ["Tu\u0161ar", "Tea", "", "IJS"], ["Brockhoff", "Dimo", "", "RANDOPT"]]}]