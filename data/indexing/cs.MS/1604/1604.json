[{"id": "1604.01416", "submitter": "Steven Eliuk", "authors": "Steven Eliuk, Cameron Upright, Anthony Skjellum", "title": "dMath: A Scalable Linear Algebra and Math Library for Heterogeneous\n  GP-GPU Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new scalable parallel math library, dMath, is presented in this paper that\ndemonstrates leading scaling when using intranode, or internode,\nhybrid-parallelism for deep-learning. dMath provides easy-to-use distributed\nbase primitives and a variety of domain-specific algorithms. These include\nmatrix multiplication, convolutions, and others allowing for rapid development\nof highly scalable applications, including Deep Neural Networks (DNN), whereas\npreviously one was restricted to libraries that provided effective primitives\nfor only a single GPU, like Nvidia cublas and cudnn or DNN primitives from\nNervana neon framework. Development of HPC software is difficult,\nlabor-intensive work, requiring a unique skill set. dMath allows a wide range\nof developers to utilize parallel and distributed hardware easily. One\ncontribution of this approach is that data is stored persistently on the GPU\nhardware, avoiding costly transfers between host and device. Advanced memory\nmanagement techniques are utilized, including caching of transferred data and\nmemory reuse through pooling. A key contribution of dMath is that it delivers\nperformance, portability, and productivity to its specific domain of support.\nIt enables algorithm and application programmers to quickly solve problems\nwithout managing the significant complexity associated with multi-level\nparallelism.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 20:28:26 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Eliuk", "Steven", ""], ["Upright", "Cameron", ""], ["Skjellum", "Anthony", ""]]}, {"id": "1604.02528", "submitter": "Mathias Jacquelin", "authors": "Mathias Jacquelin, Lin Lin, Weile Jia, Yonghua Zhao, Chao Yang", "title": "A Left-Looking Selected Inversion Algorithm and Task Parallelism on\n  Shared Memory Systems", "comments": "9 pages, 7 figures, submitted to SuperComputing 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sparse matrix $A$, the selected inversion algorithm is an efficient\nmethod for computing certain selected elements of $A^{-1}$. These selected\nelements correspond to all or some nonzero elements of the LU factors of $A$.\nIn many ways, the type of matrix updates performed in the selected inversion\nalgorithm is similar to that performed in the LU factorization, although the\nsequence of operation is different. In the context of LU factorization, it is\nknown that the left-looking and right-looking algorithms exhibit different\nmemory access and data communication patterns, and hence different behavior on\nshared memory and distributed memory parallel machines. Corresponding to\nright-looking and left-looking LU factorization, selected inversion algorithm\ncan be organized as a left-looking and a right-looking algorithm. The parallel\nright-looking version of the algorithm has been developed in [1]. The sequence\nof operations performed in this version of the selected inversion algorithm is\nsimilar to those performed in a left-looking LU factorization algorithm. In\nthis paper, we describe the left-looking variant of the selected inversion\nalgorithm, and based on task parallel method, present an efficient\nimplementation of the algorithm for shared memory machines. We demonstrate that\nwith the task scheduling features provided by OpenMP 4.0, the left-looking\nselected inversion algorithm can scale well both on the Intel Haswell multicore\narchitecture and on the Intel Knights Corner (KNC) manycore architecture.\nCompared to the right-looking selected inversion algorithm, the left-looking\nformulation facilitates pipelining of work along different branches of the\nelimination tree, and can be a promising candidate for future development of\nmassively parallel selected inversion algorithms on heterogeneous architecture.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 06:15:15 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Jacquelin", "Mathias", ""], ["Lin", "Lin", ""], ["Jia", "Weile", ""], ["Zhao", "Yonghua", ""], ["Yang", "Chao", ""]]}, {"id": "1604.03570", "submitter": "Weiqun Zhang", "authors": "Weiqun Zhang and Ann Almgren and Marcus Day and Tan Nguyen and John\n  Shalf and Didem Unat", "title": "BoxLib with Tiling: An AMR Software Framework", "comments": "Accepted for publication in SIAM J. on Scientific Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a block-structured adaptive mesh refinement (AMR)\nsoftware framework that incorporates tiling, a well-known loop transformation.\nBecause the multiscale, multiphysics codes built in BoxLib are designed to\nsolve complex systems at high resolution, performance on current and next\ngeneration architectures is essential. With the expectation of many more cores\nper node on next generation architectures, the ability to effectively utilize\nthreads within a node is essential, and the current model for parallelization\nwill not be sufficient. We describe a new version of BoxLib in which the tiling\nconstructs are embedded so that BoxLib-based applications can easily realize\nexpected performance gains without extra effort on the part of the application\ndeveloper. We also discuss a path forward to enable future versions of BoxLib\nto take advantage of NUMA-aware optimizations using the TiDA portable library.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 20:13:04 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Zhang", "Weiqun", ""], ["Almgren", "Ann", ""], ["Day", "Marcus", ""], ["Nguyen", "Tan", ""], ["Shalf", "John", ""], ["Unat", "Didem", ""]]}, {"id": "1604.05872", "submitter": "Fabio Luporini", "authors": "Fabio Luporini, David A. Ham, Paul H. J. Kelly", "title": "An algorithm for the optimization of finite element integration loops", "comments": null, "journal-ref": null, "doi": "10.1145/3054944", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm for the optimization of a class of finite element\nintegration loop nests. This algorithm, which exploits fundamental mathematical\nproperties of finite element operators, is proven to achieve a locally optimal\noperation count. In specified circumstances the optimum achieved is global.\nExtensive numerical experiments demonstrate significant performance\nimprovements over the state of the art in finite element code generation in\nalmost all cases. This validates the effectiveness of the algorithm presented\nhere, and illustrates its limitations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 09:39:29 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Luporini", "Fabio", ""], ["Ham", "David A.", ""], ["Kelly", "Paul H. J.", ""]]}, {"id": "1604.05937", "submitter": "Lawrence Mitchell", "authors": "Gheorghe-Teodor Bercea, Andrew T. T. McRae, David A. Ham, Lawrence\n  Mitchell, Florian Rathgeber, Luigi Nardi, Fabio Luporini, Paul H. J. Kelly", "title": "A structure-exploiting numbering algorithm for finite elements on\n  extruded meshes, and its performance evaluation in Firedrake", "comments": "Bibliography fixes, 23 pages", "journal-ref": "Geoscientific Model Development 9:3803-3815 (2016)", "doi": "10.5194/gmd-9-3803-2016", "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic algorithm for numbering and then efficiently iterating\nover the data values attached to an extruded mesh. An extruded mesh is formed\nby replicating an existing mesh, assumed to be unstructured, to form layers of\nprismatic cells. Applications of extruded meshes include, but are not limited\nto, the representation of 3D high aspect ratio domains employed by geophysical\nfinite element simulations. These meshes are structured in the extruded\ndirection. The algorithm presented here exploits this structure to avoid the\nperformance penalty traditionally associated with unstructured meshes. We\nevaluate the implementation of this algorithm in the Firedrake finite element\nsystem on a range of low compute intensity operations which constitute worst\ncases for data layout performance exploration. The experiments show that having\nstructure along the extruded direction enables the cost of the indirect data\naccesses to be amortized after 10-20 layers as long as the underlying mesh is\nwell-ordered. We characterise the resulting spatial and temporal reuse in a\nrepresentative set of both continuous-Galerkin and discontinuous-Galerkin\ndiscretisations. On meshes with realistic numbers of layers the performance\nachieved is between 70% and 90% of a theoretical hardware-specific limit.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 13:05:04 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 09:44:58 GMT"}, {"version": "v3", "created": "Fri, 28 Oct 2016 11:28:32 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Bercea", "Gheorghe-Teodor", ""], ["McRae", "Andrew T. T.", ""], ["Ham", "David A.", ""], ["Mitchell", "Lawrence", ""], ["Rathgeber", "Florian", ""], ["Nardi", "Luigi", ""], ["Luporini", "Fabio", ""], ["Kelly", "Paul H. J.", ""]]}, {"id": "1604.06112", "submitter": "Bernardete Ribeiro Prof", "authors": "Alexander Kova\\v{c}ec, Bernardete Ribeiro", "title": "Convex Hull Calculations: a Matlab Implementation and Correctness Proofs\n  for the lrs-Algorithm", "comments": "21 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides full \\Matlab-code and informal correctness proofs for the\nlexicographic reverse search algorithm for convex hull calculations. The\nimplementation was tested on a 1993 486-PC for various small and some larger,\npartially highly degenerate combinatorial polytopes, one of which (a certain\n13-dimensional 24 vertex polyhedron) occurs naturally in the study of a well\nknown problem posed by Professor Graciano de Oliveira: see end of section 1.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 20:07:48 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Kova\u010dec", "Alexander", ""], ["Ribeiro", "Bernardete", ""]]}, {"id": "1604.07163", "submitter": "Dave May", "authors": "Dave A. May, Patrick Sanan, Karl Rupp, Matthew G. Knepley and Barry F.\n  Smith", "title": "Extreme-scale Multigrid Components within PETSc", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elliptic partial differential equations (PDEs) frequently arise in continuum\ndescriptions of physical processes relevant to science and engineering.\nMultilevel preconditioners represent a family of scalable techniques for\nsolving discrete PDEs of this type and thus are the method of choice for\nhigh-resolution simulations. The scalability and time-to-solution of massively\nparallel multilevel preconditioners can be adversely effected by using a\ncoarse-level solver with sub-optimal algorithmic complexity. To maintain\nscalability, agglomeration techniques applied to the coarse level have been\nshown to be necessary.\n  In this work, we present a new software component introduced within the\nPortable Extensible Toolkit for Scientific computation (PETSc) which permits\nagglomeration. We provide an overview of the design and implementation of this\nfunctionality, together with several use cases highlighting the benefits of\nagglomeration. Lastly, we demonstrate via numerical experiments employing\ngeometric multigrid with structured meshes, the flexibility and performance\ngains possible using our MPI-rank agglomeration implementation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 08:35:12 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["May", "Dave A.", ""], ["Sanan", "Patrick", ""], ["Rupp", "Karl", ""], ["Knepley", "Matthew G.", ""], ["Smith", "Barry F.", ""]]}, {"id": "1604.07242", "submitter": "Christoph Gersbacher", "authors": "Christoph Gersbacher", "title": "Implementation of $hp$-adaptive discontinuous finite element methods in\n  Dune-Fem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe generic algorithms and data structures for the\nimplementation of $hp$-adaptive discontinuous finite element methods in the\nDune-Fem library. Special attention is given to the often tedious and\nerror-prone task of transferring user data during adaptation. Simultaneously,\nwe generalize the approach to the restriction and prolongation of data\ncurrently implemented in Dune-Fem to the case of $p$- and $hp$-adaptation. The\ndune-fem-hpdg module described in this paper provides an extensible reference\nimplementation of $hp$-adaptive discontinuous discrete function spaces. We give\ndetails on its implementation and the extended adaptive interface. As proof of\nconcept we present the practical realization of an $hp$-adaptive interior\npenalty method for elliptic problems.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 13:22:16 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Gersbacher", "Christoph", ""]]}, {"id": "1604.08079", "submitter": "Paula Branco", "authors": "Paula Branco, Rita P. Ribeiro, Luis Torgo", "title": "UBL: an R package for Utility-based Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes the R package UBL that allows the use of several\nmethods for handling utility-based learning problems. Classification and\nregression problems that assume non-uniform costs and/or benefits pose serious\nchallenges to predictive analytic tasks. In the context of meteorology,\nfinance, medicine, ecology, among many other, specific domain information\nconcerning the preference bias of the users must be taken into account to\nenhance the models predictive performance. To deal with this problem, a large\nnumber of techniques was proposed by the research community for both\nclassification and regression tasks. The main goal of UBL package is to\nfacilitate the utility-based predictive analytic task by providing a set of\nmethods to deal with this type of problems in the R environment. It is a\nversatile tool that provides mechanisms to handle both regression and\nclassification (binary and multiclass) tasks. Moreover, UBL package allows the\nuser to specify his domain preferences, but it also provides some automatic\nmethods that try to infer those preference bias from the domain, considering\nsome common known settings.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 14:13:11 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 23:08:46 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Branco", "Paula", ""], ["Ribeiro", "Rita P.", ""], ["Torgo", "Luis", ""]]}]