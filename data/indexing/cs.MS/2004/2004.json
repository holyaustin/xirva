[{"id": "2004.00046", "submitter": "Alberto Paoluzzi", "authors": "Gianmaria DelMonte, Elia Onofri, Giorgio Scorzelli, Alberto Paoluzzi", "title": "Local congruence of chain complexes", "comments": "to submit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The object of this paper is to transform a set of local chain complexes to a\nsingle global complex using an equivalence relation of congruence of cells,\nsolving topologically the numerical inaccuracies of floating-point arithmetics.\nWhile computing the space arrangement generated by a collection of cellular\ncomplexes, one may start from independently and efficiently computing the\nintersection of each single input 2-cell with the others. The topology of these\nintersections is codified within a set of (0-2)-dimensional chain complexes.\nThe target of this paper is to merge the local chains by using the equivalence\nrelations of {\\epsilon}-congruence between 0-, 1-, and 2-cells (elementary\nchains). In particular, we reduce the block-diagonal coboundary matrices\n[\\Delta_0] and [\\Delta_1], used as matrix accumulators of the local coboundary\nchains, to the global matrices [\\delta_0] and [\\delta_1], representative of\ncongruence topology, i.e., of congruence quotients between all 0-,1-,2-cells,\nvia elementary algebraic operations on their columns. This algorithm is\ncodified using the Julia porting of the SuiteSparse:GraphBLAS implementation of\nthe GraphBLAS standard, conceived to efficiently compute algorithms on large\ngraphs using linear algebra and sparse matrices [1, 2].\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:15:32 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["DelMonte", "Gianmaria", ""], ["Onofri", "Elia", ""], ["Scorzelli", "Giorgio", ""], ["Paoluzzi", "Alberto", ""]]}, {"id": "2004.01463", "submitter": "Fabian Lange", "authors": "Jonas Klappert, Sven Yannick Klein, and Fabian Lange", "title": "Interpolation of Dense and Sparse Rational Functions and other\n  Improvements in $\\texttt{FireFly}$", "comments": "28 pages, 10 tables, 1 figure", "journal-ref": "Comput. Phys. Commun. 264 (2021) 107968", "doi": "10.1016/j.cpc.2021.107968", "report-no": "TTK-20-07, P3H-20-010", "categories": "cs.MS cs.SC hep-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the main improvements and new features in version $\\texttt{2.0}$\nof the open-source $\\texttt{C++}$ library $\\texttt{FireFly}$ for the\ninterpolation of rational functions. This includes algorithmic improvements,\ne.g. a hybrid algorithm for dense and sparse rational functions and an\nalgorithm to identify and remove univariate factors. The new version is applied\nto a Feynman-integral reduction to showcase the runtime improvements achieved.\nMoreover, $\\texttt{FireFly}$ now supports parallelization with $\\texttt{MPI}$\nand offers new tools like a parser for expressions or an executable for the\ninsertion of replacement tables.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 10:40:08 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 18:02:27 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Klappert", "Jonas", ""], ["Klein", "Sven Yannick", ""], ["Lange", "Fabian", ""]]}, {"id": "2004.03673", "submitter": "Robert Y. Lewis", "authors": "Floris van Doorn, Gabriel Ebner, and Robert Y. Lewis", "title": "Maintaining a Library of Formal Mathematics", "comments": "To appear in Proceedings of CICM 2020", "journal-ref": null, "doi": "10.1007/978-3-030-53518-6_16", "report-no": null, "categories": "cs.PL cs.MS math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lean mathematical library mathlib is developed by a community of users\nwith very different backgrounds and levels of experience. To lower the barrier\nof entry for contributors and to lessen the burden of reviewing contributions,\nwe have developed a number of tools for the library which check proof\ndevelopments for subtle mistakes in the code and generate documentation suited\nfor our varied audience.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 19:52:20 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 11:47:21 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["van Doorn", "Floris", ""], ["Ebner", "Gabriel", ""], ["Lewis", "Robert Y.", ""]]}, {"id": "2004.04435", "submitter": "Oksana Shadura", "authors": "Vassil Vassilev (1), Aleksandr Efremov (1) and Oksana Shadura (2) ((1)\n  Princeton University, (2) University of Nebraska Lincoln)", "title": "Automatic Differentiation in ROOT", "comments": "Submitted as a proceeding for CHEP 2019", "journal-ref": null, "doi": "10.1051/epjconf/202024502015", "report-no": null, "categories": "cs.MS cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mathematics and computer algebra, automatic differentiation (AD) is a set\nof techniques to evaluate the derivative of a function specified by a computer\nprogram. AD exploits the fact that every computer program, no matter how\ncomplicated, executes a sequence of elementary arithmetic operations (addition,\nsubtraction, multiplication, division, etc.), elementary functions (exp, log,\nsin, cos, etc.) and control flow statements. AD takes source code of a function\nas input and produces source code of the derived function. By applying the\nchain rule repeatedly to these operations, derivatives of arbitrary order can\nbe computed automatically, accurately to working precision, and using at most a\nsmall constant factor more arithmetic operations than the original program.\n  This paper presents AD techniques available in ROOT, supported by Cling, to\nproduce derivatives of arbitrary C/C++ functions through implementing source\ncode transformation and employing the chain rule of differential calculus in\nboth forward mode and reverse mode. We explain its current integration for\ngradient computation in TFormula. We demonstrate the correctness and\nperformance improvements in ROOT's fitting algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 09:18:50 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Vassilev", "Vassil", ""], ["Efremov", "Aleksandr", ""], ["Shadura", "Oksana", ""]]}, {"id": "2004.04667", "submitter": "Nina Miolane", "authors": "Nina Miolane, Alice Le Brigant, Johan Mathe, Benjamin Hou, Nicolas\n  Guigui, Yann Thanwerdas, Stefan Heyder, Olivier Peltre, Niklas Koep, Hadi\n  Zaatiti, Hatem Hajri, Yann Cabanes, Thomas Gerald, Paul Chauchat, Christian\n  Shewmake, Bernhard Kainz, Claire Donnat, Susan Holmes, Xavier Pennec", "title": "Geomstats: A Python Package for Riemannian Geometry in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Geomstats, an open-source Python toolbox for computations and\nstatistics on nonlinear manifolds, such as hyperbolic spaces, spaces of\nsymmetric positive definite matrices, Lie groups of transformations, and many\nmore. We provide object-oriented and extensively unit-tested implementations.\nAmong others, manifolds come equipped with families of Riemannian metrics, with\nassociated exponential and logarithmic maps, geodesics and parallel transport.\nStatistics and learning algorithms provide methods for estimation, clustering\nand dimension reduction on manifolds. All associated operations are vectorized\nfor batch computation and provide support for different execution backends,\nnamely NumPy, PyTorch and TensorFlow, enabling GPU acceleration. This paper\npresents the package, compares it with related libraries and provides relevant\ncode examples. We show that Geomstats provides reliable building blocks to\nfoster research in differential geometry and statistics, and to democratize the\nuse of Riemannian geometry in machine learning applications. The source code is\nfreely available under the MIT license at \\url{geomstats.ai}.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 20:41:50 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Miolane", "Nina", ""], ["Brigant", "Alice Le", ""], ["Mathe", "Johan", ""], ["Hou", "Benjamin", ""], ["Guigui", "Nicolas", ""], ["Thanwerdas", "Yann", ""], ["Heyder", "Stefan", ""], ["Peltre", "Olivier", ""], ["Koep", "Niklas", ""], ["Zaatiti", "Hadi", ""], ["Hajri", "Hatem", ""], ["Cabanes", "Yann", ""], ["Gerald", "Thomas", ""], ["Chauchat", "Paul", ""], ["Shewmake", "Christian", ""], ["Kainz", "Bernhard", ""], ["Donnat", "Claire", ""], ["Holmes", "Susan", ""], ["Pennec", "Xavier", ""]]}, {"id": "2004.08729", "submitter": "V\\'aclav Hapla", "authors": "Vaclav Hapla, Matthew G. Knepley, Michael Afanasiev, Christian Boehm,\n  Martin van Driel, Lion Krischer, Andreas Fichtner", "title": "Fully Parallel Mesh I/O using PETSc DMPlex with an Application to\n  Waveform Modeling", "comments": "23 pages, 11 figures", "journal-ref": "SIAM J. Sci. Comput. 43 (2021) C127-C153", "doi": "10.1137/20M1332748", "report-no": null, "categories": "cs.MS cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale PDE simulations using high-order finite-element methods on\nunstructured meshes are an indispensable tool in science and engineering. The\nwidely used open-source PETSc library offers an efficient representation of\ngeneric unstructured meshes within its DMPlex module. This paper details our\nrecent implementation of parallel mesh reading and topological interpolation\n(computation of edges and faces from a cell-vertex mesh) into DMPlex. We apply\nthese developments to seismic wave propagation scenarios on Mars as an example\napplication. The principal motivation is to overcome single-node memory limits\nand reach mesh sizes which were impossible before. Moreover, we demonstrate\nthat scalability of I/O and topological interpolation goes beyond 12'000 cores,\nand memory-imposed limits on mesh size vanish.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 23:26:04 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 11:48:01 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Hapla", "Vaclav", ""], ["Knepley", "Matthew G.", ""], ["Afanasiev", "Michael", ""], ["Boehm", "Christian", ""], ["van Driel", "Martin", ""], ["Krischer", "Lion", ""], ["Fichtner", "Andreas", ""]]}, {"id": "2004.08913", "submitter": "Dmitry Kulyabov", "authors": "Migran N. Gevorkyan and Dmitry S. Kulyabov and Anastasia V. Demidova\n  and Anna V. Korolkova", "title": "A practical approach to testing random number generators in computer\n  algebra systems", "comments": "in English, in Russian", "journal-ref": null, "doi": "10.1134/S096554252001008X", "report-no": null, "categories": "cs.MS cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has a practical aim. For a long time, implementations of\npseudorandom number generators in standard libraries of programming languages\nhad poor quality. The situation started to improve only recently. Up to now, a\nlarge number of libraries and weakly supported mathematical packages use\noutdated algorithms for random number generation. Four modern sets of\nstatistical tests that can be used for verifying random number generators are\ndescribed. It is proposed to use command line utilities, which makes it\npossible to avoid low-level programming in such languages as C or C++. Only\nfree open source systems are considered.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 17:19:19 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gevorkyan", "Migran N.", ""], ["Kulyabov", "Dmitry S.", ""], ["Demidova", "Anastasia V.", ""], ["Korolkova", "Anna V.", ""]]}, {"id": "2004.11765", "submitter": "Bo Li", "authors": "Bo Li and Viktor Larsson", "title": "GAPS: Generator for Automatic Polynomial Solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.MS cs.RO cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimal problems in computer vision raise the demand of generating efficient\nautomatic solvers for polynomial equation systems. Given a polynomial system\nrepeated with different coefficient instances, the traditional Gr\\\"obner basis\nor normal form based solution is very inefficient. Fortunately the Gr\\\"obner\nbasis of a same polynomial system with different coefficients is found to share\nconsistent inner structure. By precomputing such structures offline, Gr\\\"obner\nbasis as well as the polynomial system solutions can be solved automatically\nand efficiently online. In the past decade, several tools have been released to\ngenerate automatic solvers for a general minimal problems. The most recent tool\nautogen from Larsson et al. is a representative of these tools with\nstate-of-the-art performance in solver efficiency. GAPS wraps and improves\nautogen with more user-friendly interface, more functionality and better\nstability. We demonstrate in this report the main approach and enhancement\nfeatures of GAPS. A short tutorial of the software is also included.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:11:28 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Li", "Bo", ""], ["Larsson", "Viktor", ""]]}, {"id": "2004.13112", "submitter": "Isaac Ross", "authors": "I. M. Ross", "title": "Enhancements to the DIDO Optimal Control Toolbox", "comments": "17 pages, 16 figures. New figs explain cotangent barrier and\n  tunneling. Additional references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.MS cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2020, DIDO$^\\copyright$ turned 20! The software package emerged in 2001 as\na basic, user-friendly MATLAB$^\\circledR$ teaching-tool to illustrate the\nvarious nuances of Pontryagin's Principle but quickly rose to prominence in\n2007 after NASA announced it had executed a globally optimal maneuver using\nDIDO. Since then, the toolbox has grown in applications well beyond its\naerospace roots: from solving problems in quantum control to ushering rapid,\nnonlinear sensitivity-analysis in designing high-performance automobiles. Most\nrecently, it has been used to solve continuous-time traveling-salesman\nproblems. Over the last two decades, DIDO's algorithms have evolved from their\nsimple use of generic nonlinear programming solvers to a multifaceted\nengagement of fast spectral Hamiltonian programming techniques. A description\nof the internal enhancements to DIDO that define its mathematics and algorithms\nare described in this paper. A challenge example problem from robotics is\nincluded to showcase how the latest version of DIDO is capable of escaping the\ntrappings of a ``local minimum'' that ensnare many other trajectory\noptimization methods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 19:25:06 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 21:50:16 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ross", "I. M.", ""]]}, {"id": "2004.13283", "submitter": "EPTCS", "authors": "Marc Bouissou (EDF (\\'Electricit\\'e de France)), Shahid Khan (RWTH\n  Aachen University), Joost-Pieter Katoen (RWTH Aachen University), Pavel Krcal\n  (Lloyd's Register)", "title": "Various Ways to Quantify BDMPs", "comments": "In Proceedings MARS 2020, arXiv:2004.12403", "journal-ref": "EPTCS 316, 2020, pp. 1-14", "doi": "10.4204/EPTCS.316.1", "report-no": null, "categories": "cs.CE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Boolean logic driven Markov process (BDMP) is a dependability analysis\nmodel that defines a continuous-time Markov chain (CTMC). This formalism has\nhigh expressive power, yet it remains readable because its graphical\nrepresentation stays close to standard fault trees. The size of a BDMP is\nroughly speaking proportional to the size of the system it models, whereas the\nsize of the CTMC specified by this BDMP suffers from exponential growth. Thus\nquantifying large BDMPs can be a challenging task. The most general method to\nquantify them is Monte Carlo simulation, but this may be intractable for highly\nreliable systems. On the other hand, some subcategories of BDMPs can be\nprocessed with much more efficient methods. For example, BDMPs without repairs\ncan be translated into dynamic fault trees, a formalism accepted as an input of\nthe STORM model checker, that performs numerical calculations on sparse\nmatrices, or they can be processed with the tool FIGSEQ that explores paths\ngoing to a failure state and calculates their probabilities. BDMPs with repairs\ncan be quantified by FIGSEQ (BDMPs capturing quickly and completely repairable\nbehaviors are solved by a different algorithm), and by the I&AB (Initiator and\nAll Barriers) method, recently published and implemented in a prototype version\nof RISKSPECTRUM PSA. This tool, based exclusively on Boolean representations\nlooks for and quantifies minimal cut sets of the system, i.e., minimal\ncombinations of component failures that induce the loss of the system. This\nallows a quick quantification of large models with repairable components,\nstandby redundancies and some other types of dependencies between omponents.\nAll these quantification methods have been tried on a benchmark whose\ndefinition was published at the MARS 2017 workshop: the model of emergency\npower supplies of a nuclear power plant. In this paper, after a recall of the\ntheoretical principles of the various quantification methods, we compare their\nperformances on that benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 04:21:21 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Bouissou", "Marc", "", "EDF"], ["Khan", "Shahid", "", "RWTH\n  Aachen University"], ["Katoen", "Joost-Pieter", "", "RWTH Aachen University"], ["Krcal", "Pavel", "", "Lloyd's Register"]]}, {"id": "2004.13907", "submitter": "Santosh Nagarakatte", "authors": "Mohammadreza Soltaniyeh, Richard P. Martin, and Santosh Nagarakatte", "title": "Synergistic CPU-FPGA Acceleration of Sparse Linear Algebra", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": "Rutgers Computer Science Technical Report DCS-TR-750", "categories": "cs.DC cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes REAP, a software-hardware approach that enables high\nperformance sparse linear algebra computations on a cooperative CPU-FPGA\nplatform. REAP carefully separates the task of organizing the matrix elements\nfrom the computation phase. It uses the CPU to provide a first-pass\nre-organization of the matrix elements, allowing the FPGA to focus on the\ncomputation. We introduce a new intermediate representation that allows the CPU\nto communicate the sparse data and the scheduling decisions to the FPGA. The\ncomputation is optimized on the FPGA for effective resource utilization with\npipelining. REAP improves the performance of Sparse General Matrix\nMultiplication (SpGEMM) and Sparse Cholesky Factorization by 3.2X and 1.85X\ncompared to widely used sparse libraries for them on the CPU, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 01:06:52 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["Soltaniyeh", "Mohammadreza", ""], ["Martin", "Richard P.", ""], ["Nagarakatte", "Santosh", ""]]}]