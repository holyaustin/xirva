[{"id": "2005.00062", "submitter": "Yiding Hao", "authors": "Yiding Hao", "title": "Attribution Analysis of Grammatical Dependencies in LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTM language models have been shown to capture syntax-sensitive grammatical\ndependencies such as subject-verb agreement with a high degree of accuracy\n(Linzen et al., 2016, inter alia). However, questions remain regarding whether\nthey do so using spurious correlations, or whether they are truly able to match\nverbs with their subjects. This paper argues for the latter hypothesis. Using\nlayer-wise relevance propagation (Bach et al., 2015), a technique that\nquantifies the contributions of input features to model behavior, we show that\nLSTM performance on number agreement is directly correlated with the model's\nability to distinguish subjects from other nouns. Our results suggest that LSTM\nlanguage models are able to infer robust representations of syntactic\ndependencies.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 19:19:37 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Hao", "Yiding", ""]]}, {"id": "2005.00288", "submitter": "Saurabh Kumar", "authors": "Ravi Kumar Kushawaha, Saurabh Kumar, Biplab Banerjee, Rajbabu\n  Velmurugan", "title": "Distilling Spikes: Knowledge Distillation in Spiking Neural Networks", "comments": "Preprint: Manuscript under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNN) are energy-efficient computing architectures\nthat exchange spikes for processing information, unlike classical Artificial\nNeural Networks (ANN). Due to this, SNNs are better suited for real-life\ndeployments. However, similar to ANNs, SNNs also benefit from deeper\narchitectures to obtain improved performance. Furthermore, like the deep ANNs,\nthe memory, compute and power requirements of SNNs also increase with model\nsize, and model compression becomes a necessity. Knowledge distillation is a\nmodel compression technique that enables transferring the learning of a large\nmachine learning model to a smaller model with minimal loss in performance. In\nthis paper, we propose techniques for knowledge distillation in spiking neural\nnetworks for the task of image classification. We present ways to distill\nspikes from a larger SNN, also called the teacher network, to a smaller one,\nalso called the student network, while minimally impacting the classification\naccuracy. We demonstrate the effectiveness of the proposed method with detailed\nexperiments on three standard datasets while proposing novel distillation\nmethodologies and loss functions. We also present a multi-stage knowledge\ndistillation technique for SNNs using an intermediate network to obtain higher\nperformance from the student network. Our approach is expected to open up new\navenues for deploying high performing large SNN models on resource-constrained\nhardware platforms.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 09:36:32 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Kushawaha", "Ravi Kumar", ""], ["Kumar", "Saurabh", ""], ["Banerjee", "Biplab", ""], ["Velmurugan", "Rajbabu", ""]]}, {"id": "2005.00603", "submitter": "Gustavo Olague Dr.", "authors": "Francisco Fern\\'andez de Vega, Gustavo Olague, Francisco Ch\\'avez,\n  Daniel Lanza, Wolfgang Banzhaf, and Erik Goodman", "title": "It is Time for New Perspectives on How to Fight Bloat in GP", "comments": null, "journal-ref": "Genetic Programming Theory and Practice XVII, 8 May 2020", "doi": "10.1007/978-3-030-39958-0_2", "report-no": null, "categories": "cs.NE cs.AI cs.SC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The present and future of evolutionary algorithms depends on the proper use\nof modern parallel and distributed computing infrastructures. Although still\nsequential approaches dominate the landscape, available multi-core, many-core\nand distributed systems will make users and researchers to more frequently\ndeploy parallel version of the algorithms. In such a scenario, new\npossibilities arise regarding the time saved when parallel evaluation of\nindividuals are performed. And this time saving is particularly relevant in\nGenetic Programming. This paper studies how evaluation time influences not only\ntime to solution in parallel/distributed systems, but may also affect size\nevolution of individuals in the population, and eventually will reduce the\nbloat phenomenon GP features. This paper considers time and space as two sides\nof a single coin when devising a more natural method for fighting bloat. This\nnew perspective allows us to understand that new methods for bloat control can\nbe derived, and the first of such a method is described and tested.\nExperimental data confirms the strength of the approach: using computing time\nas a measure of individuals' complexity allows to control the growth in size of\ngenetic programming individuals.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 20:59:24 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["de Vega", "Francisco Fern\u00e1ndez", ""], ["Olague", "Gustavo", ""], ["Ch\u00e1vez", "Francisco", ""], ["Lanza", "Daniel", ""], ["Banzhaf", "Wolfgang", ""], ["Goodman", "Erik", ""]]}, {"id": "2005.00611", "submitter": "Ya-Chien Chang", "authors": "Ya-Chien Chang, Nima Roohi, Sicun Gao", "title": "Neural Lyapunov Control", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose new methods for learning control policies and neural network\nLyapunov functions for nonlinear control problems, with provable guarantee of\nstability. The framework consists of a learner that attempts to find the\ncontrol and Lyapunov functions, and a falsifier that finds counterexamples to\nquickly guide the learner towards solutions. The procedure terminates when no\ncounterexample is found by the falsifier, in which case the controlled\nnonlinear system is provably stable. The approach significantly simplifies the\nprocess of Lyapunov control design, provides end-to-end correctness guarantee,\nand can obtain much larger regions of attraction than existing methods such as\nLQR and SOS/SDP. We show experiments on how the new methods obtain high-quality\nsolutions for challenging control problems.\n", "versions": [{"version": "v1", "created": "Fri, 1 May 2020 21:18:39 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 20:41:39 GMT"}, {"version": "v3", "created": "Sat, 19 Dec 2020 21:35:49 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Chang", "Ya-Chien", ""], ["Roohi", "Nima", ""], ["Gao", "Sicun", ""]]}, {"id": "2005.00722", "submitter": "Nickolaos Koroniotis", "authors": "Nickolaos Koroniotis, Nour Moustafa", "title": "Enhancing network forensics with particle swarm and deep learning: The\n  particle deep framework", "comments": "2020/3", "journal-ref": "7th International Conference on Artificial Intelligence and\n  Applications (AIAP-2020), March 28 ~ 29, 2020, Sydney, Australia", "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of IoT smart things is rising, due to the automation they\nprovide and its effects on productivity. However, it has been proven that IoT\ndevices are vulnerable to both well established and new IoT-specific attack\nvectors. In this paper, we propose the Particle Deep Framework, a new network\nforensic framework for IoT networks that utilised Particle Swarm Optimisation\nto tune the hyperparameters of a deep MLP model and improve its performance.\nThe PDF is trained and validated using Bot-IoT dataset, a contemporary\nnetwork-traffic dataset that combines normal IoT and non-IoT traffic, with well\nknown botnet-related attacks. Through experimentation, we show that the\nperformance of a deep MLP model is vastly improved, achieving an accuracy of\n99.9% and false alarm rate of close to 0%.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 06:39:33 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Koroniotis", "Nickolaos", ""], ["Moustafa", "Nour", ""]]}, {"id": "2005.00723", "submitter": "Qiang Yu", "authors": "Qiang Yu, Shenglan Li, Huajin Tang, Longbiao Wang, Jianwu Dang, Kay\n  Chen Tan", "title": "Towards Efficient Processing and Learning with Spikes: New Approaches\n  for Multi-Spike Learning", "comments": "13 pages", "journal-ref": null, "doi": "10.1109/TCYB.2020.2984888", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spikes are the currency in central nervous systems for information\ntransmission and processing. They are also believed to play an essential role\nin low-power consumption of the biological systems, whose efficiency attracts\nincreasing attentions to the field of neuromorphic computing. However,\nefficient processing and learning of discrete spikes still remains as a\nchallenging problem. In this paper, we make our contributions towards this\ndirection. A simplified spiking neuron model is firstly introduced with effects\nof both synaptic input and firing output on membrane potential being modeled\nwith an impulse function. An event-driven scheme is then presented to further\nimprove the processing efficiency. Based on the neuron model, we propose two\nnew multi-spike learning rules which demonstrate better performance over other\nbaselines on various tasks including association, classification, feature\ndetection. In addition to efficiency, our learning rules demonstrate a high\nrobustness against strong noise of different types. They can also be\ngeneralized to different spike coding schemes for the classification task, and\nnotably single neuron is capable of solving multi-category classifications with\nour learning rules. In the feature detection task, we re-examine the ability of\nunsupervised STDP with its limitations being presented, and find a new\nphenomenon of losing selectivity. In contrast, our proposed learning rules can\nreliably solve the task over a wide range of conditions without specific\nconstraints being applied. Moreover, our rules can not only detect features but\nalso discriminate them. The improved performance of our methods would\ncontribute to neuromorphic computing as a preferable choice.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 06:41:20 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Yu", "Qiang", ""], ["Li", "Shenglan", ""], ["Tang", "Huajin", ""], ["Wang", "Longbiao", ""], ["Dang", "Jianwu", ""], ["Tan", "Kay Chen", ""]]}, {"id": "2005.00817", "submitter": "Andrea Apicella", "authors": "Andrea Apicella, Francesco Donnarumma, Francesco Isgr\\`o and Roberto\n  Prevete", "title": "A survey on modern trainable activation functions", "comments": "Published in \"Neural Networks\" journal (Elsevier)", "journal-ref": "Neural Networks Volume 138, June 2021, Pages 14-32", "doi": "10.1016/j.neunet.2021.01.026", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural networks literature, there is a strong interest in identifying and\ndefining activation functions which can improve neural network performance. In\nrecent years there has been a renovated interest of the scientific community in\ninvestigating activation functions which can be trained during the learning\nprocess, usually referred to as \"trainable\", \"learnable\" or \"adaptable\"\nactivation functions. They appear to lead to better network performance.\nDiverse and heterogeneous models of trainable activation function have been\nproposed in the literature. In this paper, we present a survey of these models.\nStarting from a discussion on the use of the term \"activation function\" in\nliterature, we propose a taxonomy of trainable activation functions, highlight\ncommon and distinctive proprieties of recent and past models, and discuss main\nadvantages and limitations of this type of approach. We show that many of the\nproposed approaches are equivalent to adding neuron layers which use fixed\n(non-trainable) activation functions and some simple local rule that\nconstraints the corresponding weight layers.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 12:38:43 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 22:11:55 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 12:55:51 GMT"}, {"version": "v4", "created": "Thu, 25 Feb 2021 21:34:34 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Apicella", "Andrea", ""], ["Donnarumma", "Francesco", ""], ["Isgr\u00f2", "Francesco", ""], ["Prevete", "Roberto", ""]]}, {"id": "2005.00853", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "Lower Bounds for Non-Elitist Evolutionary Algorithms via Negative\n  Multiplicative Drift", "comments": "Full version of a paper that appeared in the proceedings of PPSN\n  2020. Difference to the previous version: Added a section on standard bit\n  mutation with random mutation rate. Additional difference to the conference\n  version: All proofs are given since ArXiV does not have a page limit", "journal-ref": "Evolutionary Computation (2021) 29 (2): 305-329", "doi": "10.1162/evco_a_00283", "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decent number of lower bounds for non-elitist population-based evolutionary\nalgorithms has been shown by now. Most of them are technically demanding due to\nthe (hard to avoid) use of negative drift theorems -- general results which\ntranslate an expected progress away from the target into a high hitting time.\n  We propose a simple negative drift theorem for multiplicative drift scenarios\nand show that it can simplify existing analyses. We discuss in more detail\nLehre's (PPSN 2010) \\emph{negative drift in populations} method, one of the\nmost general tools to prove lower bounds on the runtime of non-elitist\nmutation-based evolutionary algorithms for discrete search spaces. Together\nwith other arguments, we obtain an alternative and simpler proof, which also\nstrengthens and simplifies this method. In particular, now only three of the\nfive technical conditions of the previous result have to be verified. The lower\nbounds we obtain are explicit instead of only asymptotic. This allows to\ncompute concrete lower bounds for concrete algorithms, but also enables us to\nshow that super-polynomial runtimes appear already when the reproduction rate\nis only a $(1 - \\omega(n^{-1/2}))$ factor below the threshold. For the special\ncase of algorithms using standard bit mutation with a random mutation rate\n(called uniform mixing in the language of hyper-heuristics), we prove the\nresult stated by Dang and Lehre (PPSN 2016) and extend it to mutation rates\nother than $\\Theta(1/n)$, which includes the heavy-tailed mutation operator\nproposed by Doerr, Le, Makhmara, and Nguyen (GECCO 2017). We finally apply our\nmethod and a novel domination argument to show an exponential lower bound for\nthe runtime of the mutation-only simple genetic algorithm on \\onemax for\narbitrary population size.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:10:09 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 14:18:07 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 16:17:34 GMT"}, {"version": "v4", "created": "Tue, 20 Oct 2020 09:04:46 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "2005.00863", "submitter": "Pranab K. Muhuri Dr.", "authors": "Zubair Ashraf, Pranab K. Muhuri, Q. M. Danish Lohani, and Mukul L. Roy", "title": "Type-2 fuzzy reliability redundancy allocation problem and its solution\n  using particle swarm optimization algorithm", "comments": null, "journal-ref": "Granular Computing, 4(2), 145-166 (2019)", "doi": "10.1007/s41066-018-0106-5", "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the fuzzy multi-objective reliability redundancy allocation\nproblem (FMORRAP) is proposed, which maximizes the system reliability while\nsimultaneously minimizing the system cost under the type 2 fuzzy uncertainty.\nIn the proposed formulation, the higher order uncertainties (such as\nparametric, manufacturing, environmental, and designers uncertainty) associated\nwith the system are modeled with interval type 2 fuzzy sets (IT2 FS). The\nfootprint of uncertainty of the interval type 2 membership functions (IT2 MFs)\naccommodates these uncertainties by capturing the multiple opinions from\nseveral system experts. We consider IT2 MFs to represent the subsystem\nreliability and cost, which are to be further aggregated using extension\nprinciple to evaluate the total system reliability and cost according to their\nconfigurations, i.e., series parallel and parallel series. We proposed a\nparticle swarm optimization (PSO) based novel solution approach to solve the\nFMORRAP. To demonstrate the applicability of two formulations, namely, series\nparallel FMORRAP and parallel series FMORRAP, we performed experimental\nsimulations on various numerical data sets. The decision makers/system experts\nassign different importance to the objectives (system reliability and cost),\nand these preferences are represented by sets of weights. The optimal results\nare obtained from our solution approach, and the Pareto optimal front is\nestablished using these different weight sets. The genetic algorithm (GA) was\nimplemented to compare the results obtained from our proposed solution\napproach. A statistical analysis was conducted between PSO and GA, and it was\nfound that the PSO based Pareto solution outperforms the GA.\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 15:39:54 GMT"}], "update_date": "2020-06-28", "authors_parsed": [["Ashraf", "Zubair", ""], ["Muhuri", "Pranab K.", ""], ["Lohani", "Q. M. Danish", ""], ["Roy", "Mukul L.", ""]]}, {"id": "2005.01113", "submitter": "Carl Troein", "authors": "Adriaan Merlevede and Carl Troein", "title": "Perfect Edge-Transmitting Recombination of Permutations", "comments": null, "journal-ref": null, "doi": null, "report-no": "LU TP 20-14", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crossover is the process of recombining the genetic features of two parents.\nFor many applications where crossover is applied to permutations, relevant\ngenetic features are pairs of adjacent elements, also called edges in the\npermutation order. Recombination of edges without errors is thought to be an\nNP-hard problem, typically approximated by heuristics that either introduce new\nedges or are only able to produce a small variety of offspring. Here, we derive\nan algorithm for crossover of permutations that achieves perfect transmission\nof edges and produces a uniform sampling of all possible offspring, in\nquadratic average computation time. The algorithm and its derivation reveal a\nlink between cycle crossover (CX) and edge assembly crossover (EAX), offering a\nnew perspective on these well-established algorithms. We also describe a\nmodification of the algorithm that generates the mathematically optimal\noffspring for the asymmetric travelling salesman problem.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 15:15:49 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Merlevede", "Adriaan", ""], ["Troein", "Carl", ""]]}, {"id": "2005.01186", "submitter": "Jason Kim", "authors": "Jason Z. Kim, Zhixin Lu, Erfan Nozari, George J. Pappas, Danielle S.\n  Bassett", "title": "Teaching Recurrent Neural Networks to Modify Chaotic Memories by Example", "comments": "7 main text figures, 3 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.NE nlin.CD", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The ability to store and manipulate information is a hallmark of\ncomputational systems. Whereas computers are carefully engineered to represent\nand perform mathematical operations on structured data, neurobiological systems\nperform analogous functions despite flexible organization and unstructured\nsensory input. Recent efforts have made progress in modeling the representation\nand recall of information in neural systems. However, precisely how neural\nsystems learn to modify these representations remains far from understood. Here\nwe demonstrate that a recurrent neural network (RNN) can learn to modify its\nrepresentation of complex information using only examples, and we explain the\nassociated learning mechanism with new theory. Specifically, we drive an RNN\nwith examples of translated, linearly transformed, or pre-bifurcated time\nseries from a chaotic Lorenz system, alongside an additional control signal\nthat changes value for each example. By training the network to replicate the\nLorenz inputs, it learns to autonomously evolve about a Lorenz-shaped manifold.\nAdditionally, it learns to continuously interpolate and extrapolate the\ntranslation, transformation, and bifurcation of this representation far beyond\nthe training data by changing the control signal. Finally, we provide a\nmechanism for how these computations are learned, and demonstrate that a single\nnetwork can simultaneously learn multiple computations. Together, our results\nprovide a simple but powerful mechanism by which an RNN can learn to manipulate\ninternal representations of complex information, allowing for the principled\nstudy and precise design of RNNs.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 20:51:46 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Kim", "Jason Z.", ""], ["Lu", "Zhixin", ""], ["Nozari", "Erfan", ""], ["Pappas", "George J.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "2005.01192", "submitter": "Patrik Christen", "authors": "Patrik Christen", "title": "Model Creation and Equivalence Proofs of Cellular Automata and\n  Artificial Neural Networks", "comments": "13 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computational methods and mathematical models have invaded arguably every\nscientific discipline forming its own field of research called computational\nscience. Mathematical models are the theoretical foundation of computational\nscience. Since Newton's time, differential equations in mathematical models\nhave been widely and successfully used to describe the macroscopic or global\nbehaviour of systems. With spatially inhomogeneous, time-varying, local\nelement-specific, and often non-linear interactions, the dynamics of complex\nsystems is in contrast more efficiently described by local rules and thus in an\nalgorithmic and local or microscopic manner. The theory of mathematical\nmodelling taking into account these characteristics of complex systems has to\nbe established still. We recently presented a so-called allagmatic method\nincluding a system metamodel to provide a framework for describing, modelling,\nsimulating, and interpreting complex systems. Implementations of cellular\nautomata and artificial neural networks were described and created with that\nmethod. Guidance from philosophy were helpful in these first studies focusing\non programming and feasibility. A rigorous mathematical formalism, however, is\nstill missing. This would not only more precisely describe and define the\nsystem metamodel, it would also further generalise it and with that extend its\nreach to formal treatment in applied mathematics and theoretical aspects of\ncomputational science as well as extend its applicability to other mathematical\nand computational models such as agent-based models. Here, a mathematical\ndefinition of the system metamodel is provided. Based on the presented\nformalism, model creation and equivalence of cellular automata and artificial\nneural networks are proved. It thus provides a formal approach for studying the\ncreation of mathematical models as well as their structural and operational\ncomparison.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 21:20:30 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 21:38:00 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 22:20:02 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Christen", "Patrik", ""]]}, {"id": "2005.01207", "submitter": "Jonatan Gomez", "authors": "Edwin Camilo Cubides and Jonatan Gomez", "title": "Obtaining Basic Algebra Formulas with Genetic Programming and Functional\n  Rewriting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a set of genetic programming operators and an\ninitialization population process based on concepts of functional programming\nrewriting for boosting inductive genetic programming. Such genetic operators\nare used within a hybrid adaptive evolutionary algorithm that evolves operator\nrates at the same time it evolves the solution. Solutions are represented using\nrecursive functions where genome is encoded as an ordered list of trees and\nphenotype is written in a simple functional programming language that uses\nrewriting as operational semantic (computational model). The fitness is the\nnumber of examples successfully deduced over the cardinal of the set of\nexamples. Parents are selected following a tournament selection mechanism and\nthe next population is obtained following a steady-state strategy. The\nevolutionary process can use some previous functions (programs) induced as\nbackground knowledge. We compare the performance of our technique in a set of\nhard problems (for classical genetic programming). In particular, we take as\ntest-bed the problem of obtaining equivalent algebraic expressions of some\nnotable products (such as square of a binomial, and cube of a binomial), and\nthe recursive formulas of sum of the first n and squares of the first n natural\nnumbers.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 23:32:36 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Cubides", "Edwin Camilo", ""], ["Gomez", "Jonatan", ""]]}, {"id": "2005.01467", "submitter": "Maxence Bouvier", "authors": "Maxence Bouvier, Alexandre Valentian, Thomas Mesquida, Fran\\c{c}ois\n  Rummens, Marina Reyboz, Elisa Vianello, Edith Beign\\'e", "title": "Spiking Neural Networks Hardware Implementations and Challenges: a\n  Survey", "comments": "Pre-print version of the file authorized for publication", "journal-ref": null, "doi": "10.1145/3304103", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic computing is henceforth a major research field for both academic\nand industrial actors. As opposed to Von Neumann machines, brain-inspired\nprocessors aim at bringing closer the memory and the computational elements to\nefficiently evaluate machine-learning algorithms. Recently, Spiking Neural\nNetworks, a generation of cognitive algorithms employing computational\nprimitives mimicking neuron and synapse operational principles, have become an\nimportant part of deep learning. They are expected to improve the computational\nperformance and efficiency of neural networks, but are best suited for hardware\nable to support their temporal dynamics. In this survey, we present the state\nof the art of hardware implementations of spiking neural networks and the\ncurrent trends in algorithm elaboration from model selection to training\nmechanisms. The scope of existing solutions is extensive; we thus present the\ngeneral framework and study on a case-by-case basis the relevant\nparticularities. We describe the strategies employed to leverage the\ncharacteristics of these event-driven algorithms at the hardware level and\ndiscuss their related advantages and challenges.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 13:24:00 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Bouvier", "Maxence", ""], ["Valentian", "Alexandre", ""], ["Mesquida", "Thomas", ""], ["Rummens", "Fran\u00e7ois", ""], ["Reyboz", "Marina", ""], ["Vianello", "Elisa", ""], ["Beign\u00e9", "Edith", ""]]}, {"id": "2005.01711", "submitter": "Karush Suri", "authors": "Karush Suri, Rinki Gupta", "title": "Dual Stage Classification of Hand Gestures using Surface Electromyogram", "comments": "arXiv admin note: text overlap with arXiv:2005.00410", "journal-ref": null, "doi": "10.1109/SPIN.2018.8474145", "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface electromyography (sEMG) is becoming exceeding useful in applications\ninvolving analysis of human motion such as in human-machine interface,\nassistive technology, healthcare and prosthetic development. The proposed work\npresents a novel dual stage classification approach for classification of\ngrasping gestures from sEMG signals. A statistical assessment of these\nactivities is presented to determine the similar characteristics between the\nconsidered activities. Similar activities are grouped together. In the first\nstage of classification, an activity is identified as belonging to a group,\nwhich is then further classified as one of the activities within the group in\nthe second stage of classification. The performance of the proposed approach is\ncompared to the conventional single stage classification approach in terms of\nclassification accuracies. The classification accuracies obtained using the\nproposed dual stage classification are significantly higher as compared to that\nfor single stage classification.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 01:11:38 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Suri", "Karush", ""], ["Gupta", "Rinki", ""]]}, {"id": "2005.01862", "submitter": "Zengyi Li", "authors": "Zengyi Li, Friedrich T. Sommer", "title": "Complex Amplitude-Phase Boltzmann Machines", "comments": "Short Technical Note", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the framework of Boltzmann machines to a network of complex-valued\nneurons with variable amplitudes, referred to as Complex Amplitude-Phase\nBoltzmann machine (CAP-BM). The model is capable of performing unsupervised\nlearning on the amplitude and relative phase distribution in complex data. The\nsampling rule of the Gibbs distribution and the learning rules of the model are\npresented. Learning in a Complex Amplitude-Phase restricted Boltzmann machine\n(CAP-RBM) is demonstrated on synthetic complex-valued images, and handwritten\nMNIST digits transformed by a complex wavelet transform. Specifically, we show\nthe necessity of a new amplitude-amplitude coupling term in our model. The\nproposed model is potentially valuable for machine learning tasks involving\ncomplex-valued data with amplitude variation, and for developing algorithms for\nnovel computation hardware, such as coupled oscillators and neuromorphic\nhardware, on which Boltzmann sampling can be executed in the complex domain.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 21:44:59 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Li", "Zengyi", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2005.02183", "submitter": "Weihua He", "authors": "Weihua He, YuJie Wu, Lei Deng, Guoqi Li, Haoyu Wang, Yang Tian, Wei\n  Ding, Wenhui Wang, Yuan Xie", "title": "Comparing SNNs and RNNs on Neuromorphic Vision Datasets: Similarities\n  and Differences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic data, recording frameless spike events, have attracted\nconsiderable attention for the spatiotemporal information components and the\nevent-driven processing fashion. Spiking neural networks (SNNs) represent a\nfamily of event-driven models with spatiotemporal dynamics for neuromorphic\ncomputing, which are widely benchmarked on neuromorphic data. Interestingly,\nresearchers in the machine learning community can argue that recurrent\n(artificial) neural networks (RNNs) also have the capability to extract\nspatiotemporal features although they are not event-driven. Thus, the question\nof \"what will happen if we benchmark these two kinds of models together on\nneuromorphic data\" comes out but remains unclear. In this work, we make a\nsystematic study to compare SNNs and RNNs on neuromorphic data, taking the\nvision datasets as a case study. First, we identify the similarities and\ndifferences between SNNs and RNNs (including the vanilla RNNs and LSTM) from\nthe modeling and learning perspectives. To improve comparability and fairness,\nwe unify the supervised learning algorithm based on backpropagation through\ntime (BPTT), the loss function exploiting the outputs at all timesteps, the\nnetwork structure with stacked fully-connected or convolutional layers, and the\nhyper-parameters during training. Especially, given the mainstream loss\nfunction used in RNNs, we modify it inspired by the rate coding scheme to\napproach that of SNNs. Furthermore, we tune the temporal resolution of datasets\nto test model robustness and generalization. At last, a series of contrast\nexperiments are conducted on two types of neuromorphic datasets: DVS-converted\n(N-MNIST) and DVS-captured (DVS Gesture).\n", "versions": [{"version": "v1", "created": "Sat, 2 May 2020 10:19:37 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["He", "Weihua", ""], ["Wu", "YuJie", ""], ["Deng", "Lei", ""], ["Li", "Guoqi", ""], ["Wang", "Haoyu", ""], ["Tian", "Yang", ""], ["Ding", "Wei", ""], ["Wang", "Wenhui", ""], ["Xie", "Yuan", ""]]}, {"id": "2005.02184", "submitter": "Filip Marcinek", "authors": "Filip Marcinek", "title": "Reproduction of Lateral Inhibition-Inspired Convolutional Neural Network\n  for Visual Attention and Saliency Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, neural networks have continued to flourish, achieving high\nefficiency in detecting relevant objects in photos or simply recognizing\n(classifying) these objects - mainly using CNN networks. Current solutions,\nhowever, are far from ideal, because it often turns out that network can be\neffectively confused with even natural images examples. I suspect that the\nclassification of an object is strongly influenced by the background pixels on\nwhich the object is located. In my work, I analyze the above problem using for\nthis purpose saliency maps created by the LICNN network. They are designed to\nsuppress the neurons surrounding the examined object and, consequently, reduce\nthe contribution of background pixels to the classifier predictions. My\nexperiments on the natural and adversarial images datasets show that, indeed,\nthere is a visible correlation between the background and the wrong-classified\nforeground object. This behavior of the network is not supported by human\nexperience, because, for example, we do not confuse the yellow school bus with\nthe snow plow just because it is on the snowy background.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 13:55:47 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Marcinek", "Filip", ""]]}, {"id": "2005.02211", "submitter": "Alessandro Salatiello", "authors": "Alessandro Salatiello and Martin A. Giese", "title": "Recurrent Neural Network Learning of Performance and Intrinsic\n  Population Dynamics from Sparse Neural Data", "comments": null, "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2020.\n  ICANN 2020. Lecture Notes in Computer Science, vol 12396. Springer,\n  Cham.:874-86", "doi": "10.1007/978-3-030-61609-0_69", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are popular models of brain function. The\ntypical training strategy is to adjust their input-output behavior so that it\nmatches that of the biological circuit of interest. Even though this strategy\nensures that the biological and artificial networks perform the same\ncomputational task, it does not guarantee that their internal activity dynamics\nmatch. This suggests that the trained RNNs might end up performing the task\nemploying a different internal computational mechanism, which would make them a\nsuboptimal model of the biological circuit. In this work, we introduce a novel\ntraining strategy that allows learning not only the input-output behavior of an\nRNN but also its internal network dynamics, based on sparse neural recordings.\nWe test the proposed method by training an RNN to simultaneously reproduce\ninternal dynamics and output signals of a physiologically-inspired neural\nmodel. Specifically, this model generates the multiphasic muscle-like activity\npatterns typically observed during the execution of reaching movements, based\non the oscillatory activation patterns concurrently observed in the motor\ncortex. Remarkably, we show that the reproduction of the internal dynamics is\nsuccessful even when the training algorithm relies on the activities of a small\nsubset of neurons sampled from the biological network. Furthermore, we show\nthat training the RNNs with this method significantly improves their\ngeneralization performance. Overall, our results suggest that the proposed\nmethod is suitable for building powerful functional RNN models, which\nautomatically capture important computational properties of the biological\ncircuit of interest from sparse neural recordings.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 14:16:54 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Salatiello", "Alessandro", ""], ["Giese", "Martin A.", ""]]}, {"id": "2005.02503", "submitter": "Semih Yagli", "authors": "Semih Yagli, Alex Dytso, H. Vincent Poor", "title": "Information-Theoretic Bounds on the Generalization Error and Privacy\n  Leakage in Federated Learning", "comments": "Accepted for publication in Proceedings of 21st IEEE International\n  Workshop on Signal Processing Advances in Wireless Communications (SPAWC),\n  2020. arXiv version is 10pt font, 6 Pages. This is the same document as the\n  SPAWC version, except that the conference version is written with 9pt font to\n  meet the strict page margin requirements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms operating on mobile networks can be characterized\ninto three different categories. First is the classical situation in which the\nend-user devices send their data to a central server where this data is used to\ntrain a model. Second is the distributed setting in which each device trains\nits own model and send its model parameters to a central server where these\nmodel parameters are aggregated to create one final model. Third is the\nfederated learning setting in which, at any given time $t$, a certain number of\nactive end users train with their own local data along with feedback provided\nby the central server and then send their newly estimated model parameters to\nthe central server. The server, then, aggregates these new parameters, updates\nits own model, and feeds the updated parameters back to all the end users,\ncontinuing this process until it converges.\n  The main objective of this work is to provide an information-theoretic\nframework for all of the aforementioned learning paradigms. Moreover, using the\nprovided framework, we develop upper and lower bounds on the generalization\nerror together with bounds on the privacy leakage in the classical, distributed\nand federated learning settings.\n  Keywords: Federated Learning, Distributed Learning, Machine Learning, Model\nAggregation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 21:23:45 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Yagli", "Semih", ""], ["Dytso", "Alex", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2005.02558", "submitter": "Desheng Wang", "authors": "Desheng Wang, Jiawei Liu, Xiang Qi, Baolin Sun, Peng Zhang", "title": "Revisiting Regex Generation for Modeling Industrial Applications by\n  Incorporating Byte Pair Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Regular expression is important for many natural language processing tasks\nespecially when used to deal with unstructured and semi-structured data. This\nwork focuses on automatically generating regular expressions and proposes a\nnovel genetic algorithm to deal with this problem. Different from the methods\nwhich generate regular expressions from character level, we first utilize byte\npair encoder (BPE) to extract some frequent items, which are then used to\nconstruct regular expressions. The fitness function of our genetic algorithm\ncontains multi objectives and is solved based on evolutionary procedure\nincluding crossover and mutation operation. In the fitness function, we take\nthe length of generated regular expression, the maximum matching characters and\nsamples for positive training samples, and the minimum matching characters and\nsamples for negative training samples into consideration. In addition, to\naccelerate the training process, we do exponential decay on the population size\nof the genetic algorithm. Our method together with a strong baseline is tested\non 13 kinds of challenging datasets. The results demonstrate the effectiveness\nof our method, which outperforms the baseline on 10 kinds of data and achieves\nnearly 50 percent improvement on average. By doing exponential decay, the\ntraining speed is approximately 100 times faster than the methods without using\nexponential decay. In summary, our method possesses both effectiveness and\nefficiency, and can be implemented for the industry application.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 02:09:10 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 07:52:25 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Wang", "Desheng", ""], ["Liu", "Jiawei", ""], ["Qi", "Xiang", ""], ["Sun", "Baolin", ""], ["Zhang", "Peng", ""]]}, {"id": "2005.02567", "submitter": "Friedrich Sommer", "authors": "Christopher Warner, Friedrich T. Sommer", "title": "A Model for Image Segmentation in Retina", "comments": "39 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While traditional feed-forward filter models can reproduce the rate responses\nof retinal ganglion neurons to simple stimuli, they cannot explain why\nsynchrony between spikes is much higher than expected by Poisson firing [6],\nand can be sometimes rhythmic [25, 16]. Here we investigate the hypothesis that\nsynchrony in periodic retinal spike trains could convey contextual information\nof the visual input, which is extracted by computations in the retinal network.\nWe propose a computational model for image segmentation consisting of a\nKuramoto model of coupled oscillators whose phases model the timing of\nindividual retinal spikes. The phase couplings between oscillators are shaped\nby the stimulus structure, causing cells to synchronize if the local contrast\nin their receptive fields is similar. In essence, relaxation in the oscillator\nnetwork solves a graph clustering problem with the graph representing feature\nsimilarity between different points in the image. We tested different model\nversions on the Berkeley Image Segmentation Data Set (BSDS). Networks with\nphase interactions set by standard representations of the feature graph\n(adjacency matrix, Graph Laplacian or modularity) failed to exhibit\nsegmentation performance significantly over the baseline, a model of\nindependent sensors. In contrast, a network with phase interactions that takes\ninto account not only feature similarities but also geometric distances between\nreceptive fields exhibited segmentation performance significantly above\nbaseline.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 02:58:18 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Warner", "Christopher", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2005.02602", "submitter": "Ji-Hoon Jeong", "authors": "Kyung-Hwan Shim, Ji-Hoon Jeong, Seong-Whan Lee", "title": "Gradual Relation Network: Decoding Intuitive Upper Extremity Movement\n  Imaginations Based on Few-Shot EEG Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interface (BCI) is a communication tool that connects users\nand external devices. In a real-time BCI environment, a calibration procedure\nis particularly necessary for each user and each session. This procedure\nconsumes a significant amount of time that hinders the application of a BCI\nsystem in a real-world scenario. To avoid this problem, we adopt the metric\nbased few-shot learning approach for decoding intuitive upper-extremity\nmovement imagination (MI) using a gradual relation network (GRN) that can\ngradually consider the combination of temporal and spectral groups. We acquired\nthe MI data of the upper-arm, forearm, and hand associated with intuitive\nupper-extremity movement from 25 subjects. The grand average multiclass\nclassification results under offline analysis were 42.57%, 55.60%, and 80.85%\nin 1-, 5-, and 25-shot settings, respectively. In addition, we could\ndemonstrate the feasibility of intuitive MI decoding using the few-shot\napproach in real-time robotic arm control scenarios. Five participants could\nachieve a success rate of 78% in the drinking task. Hence, we demonstrated the\nfeasibility of the online robotic arm control with shortened calibration time\nby focusing on human body parts but also the accommodation of various untrained\nintuitive MI decoding based on the proposed GRN.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:55:49 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Shim", "Kyung-Hwan", ""], ["Jeong", "Ji-Hoon", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2005.02618", "submitter": "Paul Diac", "authors": "Cosmin Pascaru, Paul Diac", "title": "Vehicle Routing and Scheduling for Regular Mobile Healthcare Services", "comments": "International Conference on Tools with Artificial Intelligence\n  (ICTAI) 8 pages 1 figure", "journal-ref": null, "doi": "10.1109/ICTAI.2018.00080", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose our solution to a particular practical problem in the domain of\nvehicle routing and scheduling. The generic task is finding the best allocation\nof the minimum number of \\emph{mobile resources} that can provide periodical\nservices in remote locations. These \\emph{mobile resources} are based at a\nsingle central location. Specifications have been defined initially for a\nreal-life application that is the starting point of an ongoing project.\nParticularly, the goal is to mitigate health problems in rural areas around a\ncity in Romania. Medically equipped vans are programmed to start daily routes\nfrom county capital, provide a given number of examinations in townships within\nthe county and return to the capital city in the same day. From the health care\nperspective, each van is equipped with an ultrasound scanner, and they are\nscheduled to investigate pregnant woman each trimester aiming to diagnose\npotential problems. The project is motivated by reports currently ranking\nRomania as the country with the highest infant mortality rate in the European\nUnion.\n  We developed our solution in two phases: modeling of the most relevant\nparameters and data available for our goal and then design and implement an\nalgorithm that provides an optimized solution. The most important metric of an\noutput scheduling is the number of vans that are necessary to provide a given\namount of examination time per township, followed by total travel time or fuel\nconsumption, number of different routes, and others. Our solution implements\ntwo probabilistic algorithms out of which we chose the one that performs the\nbest.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 07:06:28 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Pascaru", "Cosmin", ""], ["Diac", "Paul", ""]]}, {"id": "2005.02666", "submitter": "Lars Elend", "authors": "Tim Cofala, Lars Elend, Philip Mirbach, Jonas Prellberg, Thomas\n  Teusch, Oliver Kramer", "title": "Evolutionary Multi-Objective Design of SARS-CoV-2 Protease Inhibitor\n  Candidates", "comments": "15 pages, 7 figures, submitted to PPSN 2020", "journal-ref": "LNCS 12270 (2020) 357-371", "doi": "10.1007/978-3-030-58115-2_25", "report-no": null, "categories": "cs.NE cs.LG q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational drug design based on artificial intelligence is an emerging\nresearch area. At the time of writing this paper, the world suffers from an\noutbreak of the coronavirus SARS-CoV-2. A promising way to stop the virus\nreplication is via protease inhibition. We propose an evolutionary\nmulti-objective algorithm (EMOA) to design potential protease inhibitors for\nSARS-CoV-2's main protease. Based on the SELFIES representation the EMOA\nmaximizes the binding of candidate ligands to the protein using the docking\ntool QuickVina 2, while at the same time taking into account further objectives\nlike drug-likeliness or the fulfillment of filter constraints. The experimental\npart analyzes the evolutionary process and discusses the inhibitor candidates.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 09:15:20 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 13:35:31 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Cofala", "Tim", ""], ["Elend", "Lars", ""], ["Mirbach", "Philip", ""], ["Prellberg", "Jonas", ""], ["Teusch", "Thomas", ""], ["Kramer", "Oliver", ""]]}, {"id": "2005.02811", "submitter": "Romit Beed Mr", "authors": "Romit S Beed, Sunita Sarkar, Arindam Roy and Durba Bhattacharya", "title": "Hierarchical Bayesian Approach for Improving Weights for Solving\n  Multi-Objective Route Optimization Problem", "comments": "16 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weighted sum method is a simple and widely used technique that scalarizes\nmultiple conflicting objectives into a single objective function. It suffers\nfrom the problem of determining the appropriate weights corresponding to the\nobjectives. This paper proposes a novel Hierarchical Bayesian model based on\nMultinomial distribution and Dirichlet prior to refine the weights for solving\nsuch multi-objective route optimization problems. The model and methodologies\nrevolve around data obtained from a small scale pilot survey. The method aims\nat improving the existing methods of weight determination in the field of\nIntelligent Transport Systems as data driven choice of weights through\nappropriate probabilistic modelling ensures, on an average, much reliable\nresults than non-probabilistic techniques. Application of this model and\nmethodologies to simulated as well as real data sets revealed quite encouraging\nperformances with respect to stabilizing the estimates of weights.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 06:13:52 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Beed", "Romit S", ""], ["Sarkar", "Sunita", ""], ["Roy", "Arindam", ""], ["Bhattacharya", "Durba", ""]]}, {"id": "2005.03090", "submitter": "Thanh Pham Dinh", "authors": "Huynh Thi Thanh Binh, Pham Dinh Thanh, Tran Ba Trung, Le Cong Thanh,\n  Le Minh Hai Phong, Ananthram Swami, Bui Thu Lam", "title": "A Multifactorial Optimization Paradigm for Linkage Tree Genetic\n  Algorithm", "comments": null, "journal-ref": "InformationSciences. 540 (2020) 325-344", "doi": "10.1016/j.ins.2020.05.132", "report-no": "INS_15553", "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linkage Tree Genetic Algorithm (LTGA) is an effective Evolutionary Algorithm\n(EA) to solve complex problems using the linkage information between problem\nvariables. LTGA performs well in various kinds of single-task optimization and\nyields promising results in comparison with the canonical genetic algorithm.\nHowever, LTGA is an unsuitable method for dealing with multi-task optimization\nproblems. On the other hand, Multifactorial Optimization (MFO) can\nsimultaneously solve independent optimization problems, which are encoded in a\nunified representation to take advantage of the process of knowledge transfer.\nIn this paper, we introduce Multifactorial Linkage Tree Genetic Algorithm\n(MF-LTGA) by combining the main features of both LTGA and MFO. MF-LTGA is able\nto tackle multiple optimization tasks at the same time, each task learns the\ndependency between problem variables from the shared representation. This\nknowledge serves to determine the high-quality partial solutions for supporting\nother tasks in exploring the search space. Moreover, MF-LTGA speeds up\nconvergence because of knowledge transfer of relevant problems. We demonstrate\nthe effectiveness of the proposed algorithm on two benchmark problems:\nClustered Shortest-Path Tree Problem and Deceptive Trap Function. In comparison\nto LTGA and existing methods, MF-LTGA outperforms in quality of the solution or\nin computation time.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 19:28:39 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Binh", "Huynh Thi Thanh", ""], ["Thanh", "Pham Dinh", ""], ["Trung", "Tran Ba", ""], ["Thanh", "Le Cong", ""], ["Phong", "Le Minh Hai", ""], ["Swami", "Ananthram", ""], ["Lam", "Bui Thu", ""]]}, {"id": "2005.03181", "submitter": "Ravi Vadlamani", "authors": "Shaik Tanveer ul Huq, Vadlamani Ravi and Kalyanmoy Deb", "title": "Evolutionary Multi Objective Optimization Algorithm for Community\n  Detection in Complex Social Networks", "comments": "33 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Most optimization-based community detection approaches formulate the problem\nin a single or bi-objective framework. In this paper, we propose two variants\nof a three-objective formulation using a customized non-dominated sorting\ngenetic algorithm III (NSGA-III) to find community structures in a network. In\nthe first variant, named NSGA-III-KRM, we considered Kernel k means, Ratio cut,\nand Modularity, as the three objectives, whereas the second variant, named\nNSGA-III-CCM, considers Community score, Community fitness and Modularity, as\nthree objective functions. Experiments are conducted on four benchmark network\ndatasets. Comparison with state-of-the-art approaches along with\ndecomposition-based multi-objective evolutionary algorithm variants (MOEA/D-KRM\nand MOEA/D-CCM) indicates that the proposed variants yield comparable or better\nresults. This is particularly significant because the addition of the third\nobjective does not worsen the results of the other two objectives. We also\npropose a simple method to rank the Pareto solutions so obtained by proposing a\nnew measure, namely the ratio of the hyper-volume and inverted generational\ndistance (IGD). The higher the ratio, the better is the Pareto set. This\nstrategy is particularly useful in the absence of empirical attainment function\nin the multi-objective framework, where the number of objectives is more than\ntwo.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 00:13:31 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Huq", "Shaik Tanveer ul", ""], ["Ravi", "Vadlamani", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2005.03231", "submitter": "Qiang Yu", "authors": "Qiang Yu, Chenxiang Ma, Shiming Song, Gaoyan Zhang, Jianwu Dang, Kay\n  Chen Tan", "title": "Constructing Accurate and Efficient Deep Spiking Neural Networks with\n  Double-threshold and Augmented Schemes", "comments": "13 pages", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3043415", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are considered as a potential candidate to\novercome current challenges such as the high-power consumption encountered by\nartificial neural networks (ANNs), however there is still a gap between them\nwith respect to the recognition accuracy on practical tasks. A conversion\nstrategy was thus introduced recently to bridge this gap by mapping a trained\nANN to an SNN. However, it is still unclear that to what extent this obtained\nSNN can benefit both the accuracy advantage from ANN and high efficiency from\nthe spike-based paradigm of computation. In this paper, we propose two new\nconversion methods, namely TerMapping and AugMapping. The TerMapping is a\nstraightforward extension of a typical threshold-balancing method with a\ndouble-threshold scheme, while the AugMapping additionally incorporates a new\nscheme of augmented spike that employs a spike coefficient to carry the number\nof typical all-or-nothing spikes occurring at a time step. We examine the\nperformance of our methods based on MNIST, Fashion-MNIST and CIFAR10 datasets.\nThe results show that the proposed double-threshold scheme can effectively\nimprove accuracies of the converted SNNs. More importantly, the proposed\nAugMapping is more advantageous for constructing accurate, fast and efficient\ndeep SNNs as compared to other state-of-the-art approaches. Our study therefore\nprovides new approaches for further integration of advanced techniques in ANNs\nto improve the performance of SNNs, which could be of great merit to applied\ndevelopments with spike-based neuromorphic computing.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 06:44:05 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Yu", "Qiang", ""], ["Ma", "Chenxiang", ""], ["Song", "Shiming", ""], ["Zhang", "Gaoyan", ""], ["Dang", "Jianwu", ""], ["Tan", "Kay Chen", ""]]}, {"id": "2005.03382", "submitter": "Behrouz Bolourian Haghighi", "authors": "Behrouz Bolourian Haghighi, Amir Hossein Taherinia, Ahad Harati,\n  Modjtaba Rouhani", "title": "WSMN: An optimized multipurpose blind watermarking in Shearlet domain\n  using MLP and NSGA-II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital watermarking is a remarkable issue in the field of information\nsecurity to avoid the misuse of images in multimedia networks. Although access\nto unauthorized persons can be prevented through cryptography, it cannot be\nsimultaneously used for copyright protection or content authentication with the\npreservation of image integrity. Hence, this paper presents an optimized\nmultipurpose blind watermarking in Shearlet domain with the help of smart\nalgorithms including MLP and NSGA-II. In this method, four copies of the robust\ncopyright logo are embedded in the approximate coefficients of Shearlet by\nusing an effective quantization technique. Furthermore, an embedded random\nsequence as a semi-fragile authentication mark is effectively extracted from\ndetails by the neural network. Due to performing an effective optimization\nalgorithm for selecting optimum embedding thresholds, and also distinguishing\nthe texture of blocks, the imperceptibility and robustness have been preserved.\nThe experimental results reveal the superiority of the scheme with regard to\nthe quality of watermarked images and robustness against hybrid attacks over\nother state-of-the-art schemes. The average PSNR and SSIM of the dual\nwatermarked images are 38 dB and 0.95, respectively; Besides, it can\neffectively extract the copyright logo and locates forgery regions under severe\nattacks with satisfactory accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 11:14:46 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Haghighi", "Behrouz Bolourian", ""], ["Taherinia", "Amir Hossein", ""], ["Harati", "Ahad", ""], ["Rouhani", "Modjtaba", ""]]}, {"id": "2005.03476", "submitter": "Naresh Balaji Ravichandran", "authors": "Naresh Balaji Ravichandran, Anders Lansner, Pawel Herman", "title": "Brain-like approaches to unsupervised learning of hidden representations\n  -- a comparative study", "comments": "arXiv admin note: text overlap with arXiv:2003.12415", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Unsupervised learning of hidden representations has been one of the most\nvibrant research directions in machine learning in recent years. In this work\nwe study the brain-like Bayesian Confidence Propagating Neural Network (BCPNN)\nmodel, recently extended to extract sparse distributed high-dimensional\nrepresentations. The usefulness and class-dependent separability of the hidden\nrepresentations when trained on MNIST and Fashion-MNIST datasets is studied\nusing an external linear classifier and compared with other unsupervised\nlearning methods that include restricted Boltzmann machines and autoencoders.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 11:20:21 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 13:22:54 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Ravichandran", "Naresh Balaji", ""], ["Lansner", "Anders", ""], ["Herman", "Pawel", ""]]}, {"id": "2005.03675", "submitter": "Ines Chami", "authors": "Ines Chami, Sami Abu-El-Haija, Bryan Perozzi, Christopher R\\'e, Kevin\n  Murphy", "title": "Machine Learning on Graphs: A Model and Comprehensive Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a surge of recent interest in learning representations for\ngraph-structured data. Graph representation learning methods have generally\nfallen into three main categories, based on the availability of labeled data.\nThe first, network embedding (such as shallow graph embedding or graph\nauto-encoders), focuses on learning unsupervised representations of relational\nstructure. The second, graph regularized neural networks, leverages graphs to\naugment neural network losses with a regularization objective for\nsemi-supervised learning. The third, graph neural networks, aims to learn\ndifferentiable functions over discrete topologies with arbitrary structure.\nHowever, despite the popularity of these areas there has been surprisingly\nlittle work on unifying the three paradigms. Here, we aim to bridge the gap\nbetween graph neural networks, network embedding and graph regularization\nmodels. We propose a comprehensive taxonomy of representation learning methods\nfor graph-structured data, aiming to unify several disparate bodies of work.\nSpecifically, we propose a Graph Encoder Decoder Model (GRAPHEDM), which\ngeneralizes popular algorithms for semi-supervised learning on graphs (e.g.\nGraphSage, Graph Convolutional Networks, Graph Attention Networks), and\nunsupervised learning of graph representations (e.g. DeepWalk, node2vec, etc)\ninto a single consistent approach. To illustrate the generality of this\napproach, we fit over thirty existing methods into this framework. We believe\nthat this unifying view both provides a solid foundation for understanding the\nintuition behind these methods, and enables future research in the area.\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 18:00:02 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 15:41:03 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Chami", "Ines", ""], ["Abu-El-Haija", "Sami", ""], ["Perozzi", "Bryan", ""], ["R\u00e9", "Christopher", ""], ["Murphy", "Kevin", ""]]}, {"id": "2005.03898", "submitter": "Lenz Belzner", "authors": "Lenz Belzner and Martin Wirsing", "title": "Synthesizing Safe Policies under Probabilistic Constraints with\n  Reinforcement Learning and Bayesian Model Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to leverage epistemic uncertainty about constraint satisfaction of\na reinforcement learner in safety critical domains. We introduce a framework\nfor specification of requirements for reinforcement learners in constrained\nsettings, including confidence about results. We show that an agent's\nconfidence in constraint satisfaction provides a useful signal for balancing\noptimization and safety in the learning process.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 08:11:31 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 10:13:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Belzner", "Lenz", ""], ["Wirsing", "Martin", ""]]}, {"id": "2005.03947", "submitter": "Bao Trung Nguyen", "authors": "Trung B. Nguyen, Will N. Browne, Mengjie Zhang", "title": "Relatedness Measures to Aid the Transfer of Building Blocks among\n  Multiple Tasks", "comments": "accepted by The Genetic and Evolutionary Computation Conference\n  (GECCO 2020)", "journal-ref": null, "doi": "10.1145/3377930.3390169", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask Learning is a learning paradigm that deals with multiple different\ntasks in parallel and transfers knowledge among them. XOF, a Learning\nClassifier System using tree-based programs to encode building blocks\n(meta-features), constructs and collects features with rich discriminative\ninformation for classification tasks in an observed list. This paper seeks to\nfacilitate the automation of feature transferring in between tasks by utilising\nthe observed list. We hypothesise that the best discriminative features of a\nclassification task carry its characteristics. Therefore, the relatedness\nbetween any two tasks can be estimated by comparing their most appropriate\npatterns. We propose a multiple-XOF system, called mXOF, that can dynamically\nadapt feature transfer among XOFs. This system utilises the observed list to\nestimate the task relatedness. This method enables the automation of\ntransferring features. In terms of knowledge discovery, the resemblance\nestimation provides insightful relations among multiple data. We experimented\nmXOF on various scenarios, e.g. representative Hierarchical Boolean problems,\nclassification of distinct classes in the UCI Zoo dataset, and unrelated tasks,\nto validate its abilities of automatic knowledge-transfer and estimating task\nrelatedness. Results show that mXOF can estimate the relatedness reasonably\nbetween multiple tasks to aid the learning performance with the dynamic feature\ntransferring.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 10:26:59 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 14:20:48 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Nguyen", "Trung B.", ""], ["Browne", "Will N.", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2005.04091", "submitter": "Fatima Zohra Benhamida", "authors": "Riyadh Baghdadi, Abdelkader Nadir Debbagh, Kamel Abdous, Fatima Zohra\n  Benhamida, Alex Renda, Jonathan Elliott Frankle, Michael Carbin and Saman\n  Amarasinghe", "title": "TIRAMISU: A Polyhedral Compiler for Dense and Sparse Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we demonstrate a compiler that can optimize sparse and\nrecurrent neural networks, both of which are currently outside of the scope of\nexisting neural network compilers (sparse neural networks here stand for\nnetworks that can be accelerated with sparse tensor algebra techniques). Our\ndemonstration includes a mapping of sparse and recurrent neural networks to the\npolyhedral model along with an implementation of our approach in TIRAMISU, our\nstate-of-the-art polyhedral compiler. We evaluate our approach on a set of deep\nlearning benchmarks and compare our results with hand-optimized industrial\nlibraries. Our results show that our approach at least matches Intel MKL-DNN\nand in some cases outperforms it by 5x (on multicore-CPUs).\n", "versions": [{"version": "v1", "created": "Thu, 7 May 2020 07:27:08 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Baghdadi", "Riyadh", ""], ["Debbagh", "Abdelkader Nadir", ""], ["Abdous", "Kamel", ""], ["Benhamida", "Fatima Zohra", ""], ["Renda", "Alex", ""], ["Frankle", "Jonathan Elliott", ""], ["Carbin", "Michael", ""], ["Amarasinghe", "Saman", ""]]}, {"id": "2005.04136", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Jihwan Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Data-Free Network Quantization With Adversarial Knowledge Distillation", "comments": "CVPR 2020 Joint Workshop on Efficient Deep Learning in Computer\n  Vision (EDLCV)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization is an essential procedure in deep learning for\ndevelopment of efficient fixed-point inference models on mobile or edge\nplatforms. However, as datasets grow larger and privacy regulations become\nstricter, data sharing for model compression gets more difficult and\nrestricted. In this paper, we consider data-free network quantization with\nsynthetic data. The synthetic data are generated from a generator, while no\ndata are used in training the generator and in quantization. To this end, we\npropose data-free adversarial knowledge distillation, which minimizes the\nmaximum distance between the outputs of the teacher and the (quantized) student\nfor any adversarial samples from a generator. To generate adversarial samples\nsimilar to the original data, we additionally propose matching statistics from\nthe batch normalization layers for generated data and the original data in the\nteacher. Furthermore, we show the gain of producing diverse adversarial samples\nby using multiple generators and multiple students. Our experiments show the\nstate-of-the-art data-free model compression and quantization results for\n(wide) residual networks and MobileNet on SVHN, CIFAR-10, CIFAR-100, and\nTiny-ImageNet datasets. The accuracy losses compared to using the original\ndatasets are shown to be very minimal.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 16:24:55 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Choi", "Yoojin", ""], ["Choi", "Jihwan", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "2005.04151", "submitter": "Tapas Si", "authors": "Tapas Si", "title": "Swarm Programming Using Moth-Flame Optimization and Whale Optimization\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic programming (AP) is an important area of Machine Learning (ML)\nwhere computer programs are generated automatically. Swarm Programming (SP), a\nnewly emerging research area in AP, automatically generates the computer\nprograms using Swarm Intelligence (SI) algorithms. This paper presents two\ngrammar-based SP methods named as Grammatical Moth-Flame Optimizer (GMFO) and\nGrammatical Whale Optimizer (GWO). The Moth-Flame Optimizer and Whale\nOptimization algorithm are used as search engines or learning algorithms in\nGMFO and GWO respectively. The proposed methods are tested on Santa Fe Ant\nTrail, quartic symbolic regression, and 3-input multiplexer problems. The\nresults are compared with Grammatical Bee Colony (GBC) and Grammatical\nFireworks algorithm (GFWA). The experimental results demonstrate that the\nproposed SP methods can be used in automatic computer program generation.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 08:15:37 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Si", "Tapas", ""]]}, {"id": "2005.04153", "submitter": "Vasco Lopes Ferrinho", "authors": "Vasco Lopes, Paulo Fazendeiro", "title": "A Hybrid Method for Training Convolutional Neural Networks", "comments": "1 figure, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence algorithms have been steadily increasing in\npopularity and usage. Deep Learning, allows neural networks to be trained using\nhuge datasets and also removes the need for human extracted features, as it\nautomates the feature learning process. In the hearth of training deep neural\nnetworks, such as Convolutional Neural Networks, we find backpropagation, that\nby computing the gradient of the loss function with respect to the weights of\nthe network for a given input, it allows the weights of the network to be\nadjusted to better perform in the given task. In this paper, we propose a\nhybrid method that uses both backpropagation and evolutionary strategies to\ntrain Convolutional Neural Networks, where the evolutionary strategies are used\nto help to avoid local minimas and fine-tune the weights, so that the network\nachieves higher accuracy results. We show that the proposed hybrid method is\ncapable of improving upon regular training in the task of image classification\nin CIFAR-10, where a VGG16 model was used and the final test results increased\n0.61%, in average, when compared to using only backpropagation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 17:52:48 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lopes", "Vasco", ""], ["Fazendeiro", "Paulo", ""]]}, {"id": "2005.04155", "submitter": "Amir Mosavi Prof", "authors": "Saeed Nosratabadi, Felde Imre, Karoly Szell, Sina Ardabili, Bertalan\n  Beszedes, Amir Mosavi", "title": "Hybrid Machine Learning Models for Crop Yield Prediction", "comments": "5 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction of crop yield is essential for food security policymaking,\nplanning, and trade. The objective of the current study is to propose novel\ncrop yield prediction models based on hybrid machine learning methods. In this\nstudy, the performance of the artificial neural networks-imperialist\ncompetitive algorithm (ANN-ICA) and artificial neural networks-gray wolf\noptimizer (ANN-GWO) models for the crop yield prediction are evaluated.\nAccording to the results, ANN-GWO, with R of 0.48, RMSE of 3.19, and MEA of\n26.65, proved a better performance in the crop yield prediction compared to the\nANN-ICA model. The results can be used by either practitioners, researchers or\npolicymakers for food security.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 12:01:27 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Nosratabadi", "Saeed", ""], ["Imre", "Felde", ""], ["Szell", "Karoly", ""], ["Ardabili", "Sina", ""], ["Beszedes", "Bertalan", ""], ["Mosavi", "Amir", ""]]}, {"id": "2005.04156", "submitter": "Daniel Leite", "authors": "Leticia Decker, Daniel Leite, Fabio Viola, Daniele Bonacorsi", "title": "Comparison of Evolving Granular Classifiers applied to Anomaly Detection\n  for Predictive Maintenance in Computing Centers", "comments": "8 pages, 8 figures, IEEE Conference on Evolving and Adaptive\n  Intelligent Systems (EAIS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-based predictive maintenance of computing centers is a main concern\nregarding the worldwide computing grid that supports the CERN (European\nOrganization for Nuclear Research) physics experiments. A log, as\nevent-oriented adhoc information, is quite often given as unstructured big\ndata. Log data processing is a time-consuming computational task. The goal is\nto grab essential information from a continuously changeable grid environment\nto construct a classification model. Evolving granular classifiers are suited\nto learn from time-varying log streams and, therefore, perform online\nclassification of the severity of anomalies. We formulated a 4-class online\nanomaly classification problem, and employed time windows between landmarks and\ntwo granular computing methods, namely, Fuzzy-set-Based evolving Modeling\n(FBeM) and evolving Granular Neural Network (eGNN), to model and monitor\nlogging activity rate. The results of classification are of utmost importance\nfor predictive maintenance because priority can be given to specific time\nintervals in which the classifier indicates the existence of high or medium\nseverity anomalies.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:08:50 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Decker", "Leticia", ""], ["Leite", "Daniel", ""], ["Viola", "Fabio", ""], ["Bonacorsi", "Daniele", ""]]}, {"id": "2005.04157", "submitter": "Ivars Dzalbs Mr", "authors": "Ivars Dzalbs, Tatiana Kalganova", "title": "Hybrid 2-stage Imperialist Competitive Algorithm with Ant Colony\n  Optimization for Solving Multi-Depot Vehicle Routing Problem", "comments": "PPSN2020 Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Multi-Depot Vehicle Routing Problem (MDVRP) is a real-world model of the\nsimplistic Vehicle Routing Problem (VRP) that considers how to satisfy multiple\ncustomer demands from numerous depots. This paper introduces a hybrid 2-stage\napproach based on two population-based algorithms - Ant Colony Optimization\n(ACO) that mimics ant behaviour in nature and the Imperialist Competitive\nAlgorithm (ICA) that is based on geopolitical relationships between countries.\nIn the proposed hybrid algorithm, ICA is responsible for customer assignment to\nthe depots while ACO is routing and sequencing the customers. The algorithm is\ncompared to non-hybrid ACO and ICA as well as four other state-of-the-art\nmethods across 23 common Cordreaus benchmark instances. Results show clear\nimprovement over simple ACO and ICA and demonstrate very competitive results\nwhen compared to other rival algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:43:06 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Dzalbs", "Ivars", ""], ["Kalganova", "Tatiana", ""]]}, {"id": "2005.04165", "submitter": "Nathan Wycoff", "authors": "Nathan Wycoff, Prasanna Balaprakash, Fangfang Xia", "title": "Towards On-Chip Bayesian Neuromorphic Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If edge devices are to be deployed to critical applications where their\ndecisions could have serious financial, political, or public-health\nconsequences, they will need a way to signal when they are not sure how to\nreact to their environment. For instance, a lost delivery drone could make its\nway back to a distribution center or contact the client if it is confused about\nhow exactly to make its delivery, rather than taking the action which is \"most\nlikely\" correct. This issue is compounded for health care or military\napplications. However, the brain-realistic temporal credit assignment problem\nneuromorphic computing algorithms have to solve is difficult. The double role\nweights play in backpropagation-based-learning, dictating how the network\nreacts to both input and feedback, needs to be decoupled. e-prop 1 is a\npromising learning algorithm that tackles this with Broadcast Alignment (a\ntechnique where network weights are replaced with random weights during\nfeedback) and accumulated local information. We investigate under what\nconditions the Bayesian loss term can be expressed in a similar fashion,\nproposing an algorithm that can be computed with only local information as well\nand which is thus no more difficult to implement on hardware. This algorithm is\nexhibited on a store-recall problem, which suggests that it can learn good\nuncertainty on decisions to be made over time.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2020 18:45:03 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Wycoff", "Nathan", ""], ["Balaprakash", "Prasanna", ""], ["Xia", "Fangfang", ""]]}, {"id": "2005.04166", "submitter": "Gongjin Lan", "authors": "Gongjin Lan, Jakub M. Tomczak, Diederik M. Roijers, A.E. Eiben", "title": "Time Efficiency in Optimization with a Bayesian-Evolutionary Algorithm", "comments": "13 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all generate-and-test search algorithms are created equal. Bayesian\nOptimization (BO) invests a lot of computation time to generate the candidate\nsolution that best balances the predicted value and the uncertainty given all\nprevious data, taking increasingly more time as the number of evaluations\nperformed grows. Evolutionary Algorithms (EA) on the other hand rely on search\nheuristics that typically do not depend on all previous data and can be done in\nconstant time. Both the BO and EA community typically assess their performance\nas a function of the number of evaluations. However, this is unfair once we\nstart to compare the efficiency of these classes of algorithms, as the overhead\ntimes to generate candidate solutions are significantly different. We suggest\nto measure the efficiency of generate-and-test search algorithms as the\nexpected gain in the objective value per unit of computation time spent. We\nobserve that the preference of an algorithm to be used can change after a\nnumber of function evaluations. We therefore propose a new algorithm, a\ncombination of Bayesian optimization and an Evolutionary Algorithm, BEA for\nshort, that starts with BO, then transfers knowledge to an EA, and subsequently\nruns the EA. We compare the BEA with BO and the EA. The results show that BEA\noutperforms both BO and the EA in terms of time efficiency, and ultimately\nleads to better performance on well-known benchmark objective functions with\nmany local optima. Moreover, we test the three algorithms on nine test cases of\nrobot learning problems and here again we find that BEA outperforms the other\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 15:29:22 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Lan", "Gongjin", ""], ["Tomczak", "Jakub M.", ""], ["Roijers", "Diederik M.", ""], ["Eiben", "A. E.", ""]]}, {"id": "2005.04167", "submitter": "Ruthvik Vaila", "authors": "Ruthvik Vaila, John Chiasson, Vishal Saxena", "title": "Continuous Learning in a Single-Incremental-Task Scenario with Spike\n  Features", "comments": "Submitted to ICONS 2020", "journal-ref": "nternational Conference on Neuromorphic Systems 2020", "doi": "10.1145/3407197.3407213", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Neural Networks (DNNs) have two key deficiencies, their dependence on\nhigh precision computing and their inability to perform sequential learning,\nthat is, when a DNN is trained on a first task and the same DNN is trained on\nthe next task it forgets the first task. This phenomenon of forgetting previous\ntasks is also referred to as catastrophic forgetting. On the other hand a\nmammalian brain outperforms DNNs in terms of energy efficiency and the ability\nto learn sequentially without catastrophically forgetting. Here, we use\nbio-inspired Spike Timing Dependent Plasticity (STDP)in the feature extraction\nlayers of the network with instantaneous neurons to extract meaningful\nfeatures. In the classification sections of the network we use a modified\nsynaptic intelligence that we refer to as cost per synapse metric as a\nregularizer to immunize the network against catastrophic forgetting in a\nSingle-Incremental-Task scenario (SIT). In this study, we use MNIST handwritten\ndigits dataset that was divided into five sub-tasks.\n", "versions": [{"version": "v1", "created": "Sun, 3 May 2020 16:18:20 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Vaila", "Ruthvik", ""], ["Chiasson", "John", ""], ["Saxena", "Vishal", ""]]}, {"id": "2005.04168", "submitter": "Maxence Ernoult", "authors": "Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio,\n  Benjamin Scellier", "title": "Equilibrium Propagation with Continual Weight Updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a learning algorithm that bridges Machine\nLearning and Neuroscience, by computing gradients closely matching those of\nBackpropagation Through Time (BPTT), but with a learning rule local in space.\nGiven an input $x$ and associated target $y$, EP proceeds in two phases: in the\nfirst phase neurons evolve freely towards a first steady state; in the second\nphase output neurons are nudged towards $y$ until they reach a second steady\nstate. However, in existing implementations of EP, the learning rule is not\nlocal in time: the weight update is performed after the dynamics of the second\nphase have converged and requires information of the first phase that is no\nlonger available physically. In this work, we propose a version of EP named\nContinual Equilibrium Propagation (C-EP) where neuron and synapse dynamics\noccur simultaneously throughout the second phase, so that the weight update\nbecomes local in time. Such a learning rule local both in space and time opens\nthe possibility of an extremely energy efficient hardware implementation of EP.\nWe prove theoretically that, provided the learning rates are sufficiently\nsmall, at each time step of the second phase the dynamics of neurons and\nsynapses follow the gradients of the loss given by BPTT (Theorem 1). We\ndemonstrate training with C-EP on MNIST and generalize C-EP to neural networks\nwhere neurons are connected by asymmetric connections. We show through\nexperiments that the more the network updates follows the gradients of BPTT,\nthe best it performs in terms of training. These results bring EP a step closer\nto biology by better complying with hardware constraints while maintaining its\nintimate link with backpropagation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 14:54:30 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ernoult", "Maxence", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "2005.04169", "submitter": "Maxence Ernoult", "authors": "Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio,\n  Benjamin Scellier", "title": "Continual Weight Updates and Convolutional Architectures for Equilibrium\n  Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a biologically inspired alternative algorithm\nto backpropagation (BP) for training neural networks. It applies to RNNs fed by\na static input x that settle to a steady state, such as Hopfield networks. EP\nis similar to BP in that in the second phase of training, an error signal\npropagates backwards in the layers of the network, but contrary to BP, the\nlearning rule of EP is spatially local. Nonetheless, EP suffers from two major\nlimitations. On the one hand, due to its formulation in terms of real-time\ndynamics, EP entails long simulation times, which limits its applicability to\npractical tasks. On the other hand, the biological plausibility of EP is\nlimited by the fact that its learning rule is not local in time: the synapse\nupdate is performed after the dynamics of the second phase have converged and\nrequires information of the first phase that is no longer available physically.\nOur work addresses these two issues and aims at widening the spectrum of EP\nfrom standard machine learning models to more bio-realistic neural networks.\nFirst, we propose a discrete-time formulation of EP which enables to simplify\nequations, speed up training and extend EP to CNNs. Our CNN model achieves the\nbest performance ever reported on MNIST with EP. Using the same discrete-time\nformulation, we introduce Continual Equilibrium Propagation (C-EP): the weights\nof the network are adjusted continually in the second phase of training using\nlocal information in space and time. We show that in the limit of slow changes\nof synaptic strengths and small nudging, C-EP is equivalent to BPTT (Theorem\n1). We numerically demonstrate Theorem 1 and C-EP training on MNIST and\ngeneralize it to the bio-realistic situation of a neural network with\nasymmetric connections between neurons.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:14:06 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Ernoult", "Maxence", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "2005.04170", "submitter": "James Smith", "authors": "James E. Smith", "title": "A Neuromorphic Paradigm for Online Unsupervised Clustering", "comments": "Submitted to 53rd IEEE/ACM International Symposium on\n  Microarchitecture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational paradigm based on neuroscientific concepts is proposed and\nshown to be capable of online unsupervised clustering. Because it is an online\nmethod, it is readily amenable to streaming realtime applications and is\ncapable of dynamically adjusting to macro-level input changes. All operations,\nboth training and inference, are localized and efficient. The paradigm is\nimplemented as a cognitive column that incorporates five key elements: 1)\ntemporal coding, 2) an excitatory neuron model for inference, 3)\nwinner-take-all inhibition, 4) a column architecture that combines excitation\nand inhibition, 5) localized training via spike timing de-pendent plasticity\n(STDP). These elements are described and discussed, and a prototype column is\ngiven. The prototype column is simulated with a semi-synthetic benchmark and is\nshown to have performance characteristics on par with classic k-means.\nSimulations reveal the inner operation and capabilities of the column with\nemphasis on excitatory neuron response functions and STDP implementations.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2020 14:02:34 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Smith", "James E.", ""]]}, {"id": "2005.04171", "submitter": "Maryam Parsa", "authors": "Maryam Parsa, Catherine D. Schuman, Prasanna Date, Derek C. Rose, Bill\n  Kay, J. Parker Mitchell, Steven R. Young, Ryan Dellana, William Severa,\n  Thomas E. Potok, Kaushik Roy", "title": "Hyperparameter Optimization in Binary Communication Networks for\n  Neuromorphic Deployment", "comments": "9 pages, 3 figures, To appear in WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks for neuromorphic deployment is non-trivial. There\nhave been a variety of approaches proposed to adapt back-propagation or\nback-propagation-like algorithms appropriate for training. Considering that\nthese networks often have very different performance characteristics than\ntraditional neural networks, it is often unclear how to set either the network\ntopology or the hyperparameters to achieve optimal performance. In this work,\nwe introduce a Bayesian approach for optimizing the hyperparameters of an\nalgorithm for training binary communication networks that can be deployed to\nneuromorphic hardware. We show that by optimizing the hyperparameters on this\nalgorithm for each dataset, we can achieve improvements in accuracy over the\nprevious state-of-the-art for this algorithm on each dataset (by up to 15\npercent). This jump in performance continues to emphasize the potential when\nconverting traditional neural networks to binary communication applicable to\nneuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 01:15:45 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Parsa", "Maryam", ""], ["Schuman", "Catherine D.", ""], ["Date", "Prasanna", ""], ["Rose", "Derek C.", ""], ["Kay", "Bill", ""], ["Mitchell", "J. Parker", ""], ["Young", "Steven R.", ""], ["Dellana", "Ryan", ""], ["Severa", "William", ""], ["Potok", "Thomas E.", ""], ["Roy", "Kaushik", ""]]}, {"id": "2005.04210", "submitter": "Y Cooper", "authors": "Y. Cooper", "title": "The critical locus of overparameterized neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many aspects of the geometry of loss functions in deep learning remain\nmysterious. In this paper, we work toward a better understanding of the\ngeometry of the loss function $L$ of overparameterized feedforward neural\nnetworks. In this setting, we identify several components of the critical locus\nof $L$ and study their geometric properties. For networks of depth $\\ell \\geq\n4$, we identify a locus of critical points we call the star locus $S$. Within\n$S$ we identify a positive-dimensional sublocus $C$ with the property that for\n$p \\in C$, $p$ is a degenerate critical point, and no existing theoretical\nresult guarantees that gradient descent will not converge to $p$. For very wide\nnetworks, we build on earlier work and show that all critical points of $L$ are\ndegenerate, and give lower bounds on the number of zero eigenvalues of the\nHessian at each critical point. For networks that are both deep and very wide,\nwe compare the growth rates of the zero eigenspaces of the Hessian at all the\ndifferent families of critical points that we identify. The results in this\npaper provide a starting point to a more quantitative understanding of the\nproperties of various components of the critical locus of $L$.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 17:59:17 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 01:07:12 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cooper", "Y.", ""]]}, {"id": "2005.04319", "submitter": "Benjamin C.K. Tee", "authors": "Hian Hian See, Brian Lim, Si Li, Haicheng Yao, Wen Cheng, Harold Soh,\n  and Benjamin C.K. Tee", "title": "ST-MNIST -- The Spiking Tactile MNIST Neuromorphic Dataset", "comments": "Corresponding authors: Benjamin C.K. Tee and Harold Soh For dataset,\n  see http://www.benjamintee.com/stmnist 10 Pages, 4 Figures and 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.HC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile sensing is an essential modality for smart robots as it enables them\nto interact flexibly with physical objects in their environment. Recent\nadvancements in electronic skins have led to the development of data-driven\nmachine learning methods that exploit this important sensory modality. However,\ncurrent datasets used to train such algorithms are limited to standard\nsynchronous tactile sensors. There is a dearth of neuromorphic event-based\ntactile datasets, principally due to the scarcity of large-scale event-based\ntactile sensors. Having such datasets is crucial for the development and\nevaluation of new algorithms that process spatio-temporal event-based data. For\nexample, evaluating spiking neural networks on conventional frame-based\ndatasets is considered sub-optimal. Here, we debut a novel neuromorphic Spiking\nTactile MNIST (ST-MNIST) dataset, which comprises handwritten digits obtained\nby human participants writing on a neuromorphic tactile sensor array. We also\ndescribe an initial effort to evaluate our ST-MNIST dataset using existing\nartificial and spiking neural network models. The classification accuracies\nprovided herein can serve as performance benchmarks for future work. We\nanticipate that our ST-MNIST dataset will be of interest and useful to the\nneuromorphic and robotics research communities.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 23:44:14 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["See", "Hian Hian", ""], ["Lim", "Brian", ""], ["Li", "Si", ""], ["Yao", "Haicheng", ""], ["Cheng", "Wen", ""], ["Soh", "Harold", ""], ["Tee", "Benjamin C. K.", ""]]}, {"id": "2005.04347", "submitter": "Aavaas Gajurel", "authors": "Aavaas Gajurel, Sushil J. Louis, Frederick C Harris", "title": "GPU Acceleration of Sparse Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use graphics processing units(GPU) to accelerate sparse and\narbitrary structured neural networks. Sparse networks have nodes in the network\nthat are not fully connected with nodes in preceding and following layers, and\narbitrary structure neural networks have different number of nodes in each\nlayers. Sparse Neural networks with arbitrary structures are generally created\nin the processes like neural network pruning and evolutionary machine learning\nstrategies. We show that we can gain significant speedup for full activation of\nsuch neural networks using graphical processing units. We do a prepossessing\nstep to determine dependency groups for all the nodes in a network, and use\nthat information to guide the progression of activation in the neural network.\nThen we compute activation for each nodes in its own separate thread in the\nGPU, which allows for massive parallelization. We use CUDA framework to\nimplement our approach and compare the results of sequential and GPU\nimplementations. Our results show that the activation of sparse neural networks\nlends very well to GPU acceleration and can help speed up machine learning\nstrategies which generate such networks or other processes that have similar\nstructure.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 02:18:31 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gajurel", "Aavaas", ""], ["Louis", "Sushil J.", ""], ["Harris", "Frederick C", ""]]}, {"id": "2005.04364", "submitter": "Samson Tan", "authors": "Samson Tan, Shafiq Joty, Min-Yen Kan, Richard Socher", "title": "It's Morphin' Time! Combating Linguistic Discrimination with\n  Inflectional Perturbations", "comments": "To appear in the Proceedings of the 58th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2020)", "journal-ref": null, "doi": "10.18653/v1/2020.acl-main.263", "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training on only perfect Standard English corpora predisposes pre-trained\nneural networks to discriminate against minorities from non-standard linguistic\nbackgrounds (e.g., African American Vernacular English, Colloquial Singapore\nEnglish, etc.). We perturb the inflectional morphology of words to craft\nplausible and semantically similar adversarial examples that expose these\nbiases in popular NLP models, e.g., BERT and Transformer, and show that\nadversarially fine-tuning them for a single epoch significantly improves\nrobustness without sacrificing performance on clean data.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 04:01:43 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Tan", "Samson", ""], ["Joty", "Shafiq", ""], ["Kan", "Min-Yen", ""], ["Socher", "Richard", ""]]}, {"id": "2005.04473", "submitter": "Fabricio Breve", "authors": "Fabricio Breve, Carlos Norberto Fischer", "title": "Visually Impaired Aid using Convolutional Neural Networks, Transfer\n  Learning, and Particle Competition and Cooperation", "comments": "BREVE, Fabricio Aparecido; FISCHER, Carlos Norberto. Visually\n  Impaired Aid using Convolutional Neural Networks, Transfer Learning, and\n  Particle Competition and Cooperation In: 2020 International Joint Conference\n  on Neural Networks (IJCNN 2020), 2020, Glasgow, UK. Proceedings of 2020\n  International Joint Conference on Neural Networks (IJCNN 2020), 2020.\n  (accepted for publication)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigation and mobility are some of the major problems faced by visually\nimpaired people in their daily lives. Advances in computer vision led to the\nproposal of some navigation systems. However, most of them require expensive\nand/or heavy hardware. In this paper we propose the use of convolutional neural\nnetworks (CNN), transfer learning, and semi-supervised learning (SSL) to build\na framework aimed at the visually impaired aid. It has low computational costs\nand, therefore, may be implemented on current smartphones, without relying on\nany additional equipment. The smartphone camera can be used to automatically\ntake pictures of the path ahead. Then, they will be immediately classified,\nproviding almost instantaneous feedback to the user. We also propose a dataset\nto train the classifiers, including indoor and outdoor situations with\ndifferent types of light, floor, and obstacles. Many different CNN\narchitectures are evaluated as feature extractors and classifiers, by\nfine-tuning weights pre-trained on a much larger dataset. The graph-based SSL\nmethod, known as particle competition and cooperation, is also used for\nclassification, allowing feedback from the user to be incorporated without\nretraining the underlying network. 92\\% and 80\\% classification accuracy is\nachieved in the proposed dataset in the best supervised and SSL scenarios,\nrespectively.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2020 16:11:48 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Breve", "Fabricio", ""], ["Fischer", "Carlos Norberto", ""]]}, {"id": "2005.04536", "submitter": "Alexis Asseman", "authors": "Alexis Asseman, Nicolas Antoine and Ahmet S. Ozcan", "title": "Accelerating Deep Neuroevolution on Distributed FPGAs for Reinforcement\n  Learning Problems", "comments": "12 pages. Submitted to ACM Journal on Emerging Technologies in\n  Computing Systems: Special Issue on Hardware and Algorithms for Efficient\n  Machine Learning", "journal-ref": null, "doi": "10.1145/3425500", "report-no": null, "categories": "cs.NE cs.AI cs.AR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning augmented by the representational power of deep neural\nnetworks, has shown promising results on high-dimensional problems, such as\ngame playing and robotic control. However, the sequential nature of these\nproblems poses a fundamental challenge for computational efficiency. Recently,\nalternative approaches such as evolutionary strategies and deep neuroevolution\ndemonstrated competitive results with faster training time on distributed CPU\ncores. Here, we report record training times (running at about 1 million frames\nper second) for Atari 2600 games using deep neuroevolution implemented on\ndistributed FPGAs. Combined hardware implementation of the game console, image\npre-processing and the neural network in an optimized pipeline, multiplied with\nthe system level parallelism enabled the acceleration. These results are the\nfirst application demonstration on the IBM Neural Computer, which is a custom\ndesigned system that consists of 432 Xilinx FPGAs interconnected in a 3D mesh\nnetwork topology. In addition to high performance, experiments also showed\nimprovement in accuracy for all games compared to the CPU-implementation of the\nsame algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 00:41:39 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Asseman", "Alexis", ""], ["Antoine", "Nicolas", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "2005.04593", "submitter": "Ritam Guha Mr.", "authors": "Ritam Guha, Manosij Ghosh, Shyok Mutsuddi, Ram Sarkar, Seyedali\n  Mirjalili", "title": "Embedded Chaotic Whale Survival Algorithm for Filter-Wrapper Feature\n  Selection", "comments": "28 pages, 6 figures, submitted a minor revision to Soft Computing,\n  Springer", "journal-ref": null, "doi": "10.1007/s00500-020-05183-1", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification accuracy provided by a machine learning model depends a lot on\nthe feature set used in the learning process. Feature Selection (FS) is an\nimportant and challenging pre-processing technique which helps to identify only\nthe relevant features from a dataset thereby reducing the feature dimension as\nwell as improving the classification accuracy at the same time. The binary\nversion of Whale Optimization Algorithm (WOA) is a popular FS technique which\nis inspired from the foraging behavior of humpback whales. In this paper, an\nembedded version of WOA called Embedded Chaotic Whale Survival Algorithm\n(ECWSA) has been proposed which uses its wrapper process to achieve high\nclassification accuracy and a filter approach to further refine the selected\nsubset with low computation cost. Chaos has been introduced in the ECWSA to\nguide selection of the type of movement followed by the whales while searching\nfor prey. A fitness-dependent death mechanism has also been introduced in the\nsystem of whales which is inspired from the real-life scenario in which whales\ndie if they are unable to catch their prey. The proposed method has been\nevaluated on 18 well-known UCI datasets and compared with its predecessors as\nwell as some other popular FS methods.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:01:18 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Guha", "Ritam", ""], ["Ghosh", "Manosij", ""], ["Mutsuddi", "Shyok", ""], ["Sarkar", "Ram", ""], ["Mirjalili", "Seyedali", ""]]}, {"id": "2005.04596", "submitter": "Ritam Guha Mr.", "authors": "Ritam Guha, Manosij Ghosh, Pawan Kumar Singh, Ram Sarkar, Mita\n  Nasipuri", "title": "A Hybrid Swarm and Gravitation based feature selection algorithm for\n  Handwritten Indic Script Classification problem", "comments": "37 pages, 22 figures, submitted to Multimedia Tools and Applications,\n  Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In any multi-script environment, handwritten script classification is of\nparamount importance before the document images are fed to their respective\nOptical Character Recognition (OCR) engines. Over the years, this complex\npattern classification problem has been solved by researchers proposing various\nfeature vectors mostly having large dimension, thereby increasing the\ncomputation complexity of the whole classification model. Feature Selection\n(FS) can serve as an intermediate step to reduce the size of the feature\nvectors by restricting them only to the essential and relevant features. In our\npaper, we have addressed this issue by introducing a new FS algorithm, called\nHybrid Swarm and Gravitation based FS (HSGFS). This algorithm is made to run on\n3 feature vectors introduced in the literature recently - Distance-Hough\nTransform (DHT), Histogram of Oriented Gradients (HOG) and Modified log-Gabor\n(MLG) filter Transform. Three state-of-the-art classifiers namely, Multi-Layer\nPerceptron (MLP), K-Nearest Neighbour (KNN) and Support Vector Machine (SVM)\nare used for the handwritten script classification. Handwritten datasets,\nprepared at block, text-line and word level, consisting of officially\nrecognized 12 Indic scripts are used for the evaluation of our method. An\naverage improvement in the range of 2-5 % is achieved in the classification\naccuracies by utilizing only about 75-80 % of the original feature vectors on\nall three datasets. The proposed methodology also shows better performance when\ncompared to some popularly used FS models.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:27:55 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Guha", "Ritam", ""], ["Ghosh", "Manosij", ""], ["Singh", "Pawan Kumar", ""], ["Sarkar", "Ram", ""], ["Nasipuri", "Mita", ""]]}, {"id": "2005.04599", "submitter": "Ritam Guha Mr.", "authors": "Devroop Kar, Manosij Ghosh, Ritam Guha, Ram Sarkar, Laura\n  Garc\\'ia-Hern\\'andez, Ajith Abraham", "title": "Fuzzy Mutation Embedded Hybrids of Gravitational Search and Particle\n  Swarm Optimization Methods for Engineering Design Problems", "comments": "33 pages, 18 figures, submitted to Engineering Applications of\n  Artificial Intelligence, Elsevier", "journal-ref": null, "doi": "10.1016/j.engappai.2020.103847", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gravitational Search Algorithm (GSA) and Particle Swarm Optimization (PSO)\nare nature-inspired, swarm-based optimization algorithms respectively. Though\nthey have been widely used for single-objective optimization since their\ninception, they suffer from premature convergence. Even though the hybrids of\nGSA and PSO perform much better, the problem remains. Hence, to solve this\nissue we have proposed a fuzzy mutation model for two hybrid versions of PSO\nand GSA - Gravitational Particle Swarm (GPS) and PSOGSA. The developed\nalgorithms are called Mutation based GPS (MGPS) and Mutation based PSOGSA\n(MPSOGSA). The mutation operator is based on a fuzzy model where the\nprobability of mutation has been calculated based on the closeness of particle\nto population centroid and improvement in the particle value. We have evaluated\nthese two new algorithms on 23 benchmark functions of three categories\n(unimodal, multi-modal and multi-modal with fixed dimension). The experimental\noutcome shows that our proposed model outperforms their corresponding\nancestors, MGPS outperforms GPS 13 out of 23 times (56.52%) and MPSOGSA\noutperforms PSOGSA 17 times out of 23 (73.91 %). We have also compared our\nresults against those of recent optimization algorithms such as Sine Cosine\nAlgorithm (SCA), Opposition-Based SCA, and Volleyball Premier League Algorithm\n(VPL). In addition, we have applied our proposed algorithms on some classic\nengineering design problems and the outcomes are satisfactory. The related\ncodes of the proposed algorithms can be found in this link:\nFuzzy-Mutation-Embedded-Hybrids-of-GSA-and-PSO.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:42:36 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Kar", "Devroop", ""], ["Ghosh", "Manosij", ""], ["Guha", "Ritam", ""], ["Sarkar", "Ram", ""], ["Garc\u00eda-Hern\u00e1ndez", "Laura", ""], ["Abraham", "Ajith", ""]]}, {"id": "2005.04820", "submitter": "Qiang Yu", "authors": "Qiang Yu, Shiming Song, Chenxiang Ma, Linqiang Pan, Kay Chen Tan", "title": "Synaptic Learning with Augmented Spikes", "comments": "13 pages", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3040969", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional neuron models use analog values for information representation\nand computation, while all-or-nothing spikes are employed in the spiking ones.\nWith a more brain-like processing paradigm, spiking neurons are more promising\nfor improvements on efficiency and computational capability. They extend the\ncomputation of traditional neurons with an additional dimension of time carried\nby all-or-nothing spikes. Could one benefit from both the accuracy of analog\nvalues and the time-processing capability of spikes? In this paper, we\nintroduce a concept of augmented spikes to carry complementary information with\nspike coefficients in addition to spike latencies. New augmented spiking neuron\nmodel and synaptic learning rules are proposed to process and learn patterns of\naugmented spikes. We provide systematic insight into the properties and\ncharacteristics of our methods, including classification of augmented spike\npatterns, learning capacity, construction of causality, feature detection,\nrobustness and applicability to practical tasks such as acoustic and visual\npattern recognition. The remarkable results highlight the effectiveness and\npotential merits of our methods. Importantly, our augmented approaches are\nversatile and can be easily generalized to other spike-based systems,\ncontributing to a potential development for them including neuromorphic\ncomputing.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 01:00:23 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Yu", "Qiang", ""], ["Song", "Shiming", ""], ["Ma", "Chenxiang", ""], ["Pan", "Linqiang", ""], ["Tan", "Kay Chen", ""]]}, {"id": "2005.05053", "submitter": "Melikasadat Emami", "authors": "Melikasadat Emami, Mojtaba Sahraee-Ardakan, Parthe Pandit, Alyson K.\n  Fletcher, Sundeep Rangan, Michael Trumpis, Brinnae Bent, Chia-Han Chiang,\n  Jonathan Viventi", "title": "Low-Rank Nonlinear Decoding of $\\mu$-ECoG from the Primary Auditory\n  Cortex", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of neural decoding from parallel neural\nmeasurements systems such as micro-electrocorticography ($\\mu$-ECoG). In\nsystems with large numbers of array elements at very high sampling rates, the\ndimension of the raw measurement data may be large. Learning neural decoders\nfor this high-dimensional data can be challenging, particularly when the number\nof training samples is limited. To address this challenge, this work presents a\nnovel neural network decoder with a low-rank structure in the first hidden\nlayer. The low-rank constraints dramatically reduce the number of parameters in\nthe decoder while still enabling a rich class of nonlinear decoder maps. The\nlow-rank decoder is illustrated on $\\mu$-ECoG data from the primary auditory\ncortex (A1) of awake rats. This decoding problem is particularly challenging\ndue to the complexity of neural responses in the auditory cortex and the\npresence of confounding signals in awake animals. It is shown that the proposed\nlow-rank decoder significantly outperforms models using standard dimensionality\nreduction techniques such as principal component analysis (PCA).\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 05:51:08 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Emami", "Melikasadat", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Pandit", "Parthe", ""], ["Fletcher", "Alyson K.", ""], ["Rangan", "Sundeep", ""], ["Trumpis", "Michael", ""], ["Bent", "Brinnae", ""], ["Chiang", "Chia-Han", ""], ["Viventi", "Jonathan", ""]]}, {"id": "2005.05061", "submitter": "J\\'anos V\\'egh", "authors": "J\\'anos V\\'egh and \\'Ad\\'am J. Berki", "title": "Do we know the operating principles of our computers better than those\n  of our brain?", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing interest in understanding the behavior of the biological\nneural networks, and the increasing utilization of artificial neural networks\nin different fields and scales, both require a thorough understanding of how\nneuromorphic computing works. On the one side, the need to program those\nartificial neuron-like elements, and, on the other side, the necessity for a\nlarge number of such elements to cooperate, communicate and compute during\ntasks, need to be scrutinized to determine how efficiently conventional\ncomputing can assist in implementing such systems. Some electronic components\nbear a surprising resemblance to some biological structures. However, combining\nthem with components that work using different principles can result in systems\nwith very poor efficacy. The paper discusses how the conventional principles,\ncomponents and thinking about computing limit mimicking the biological systems.\nWe describe what changes will be necessary in the computing paradigms to get\ncloser to the marvelously efficient operation of biological neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2020 20:41:23 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["V\u00e9gh", "J\u00e1nos", ""], ["Berki", "\u00c1d\u00e1m J.", ""]]}, {"id": "2005.05066", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Aritz D. Martinez, Jesus L. Lobo, Ibai La\\~na and Javier\n  Del Ser", "title": "On the Transferability of Knowledge among Vehicle Routing Problems by\n  using Cellular Evolutionary Multitasking", "comments": "8 pages, 1 figure, paper accepted for presentation in the 23rd IEEE\n  International Conference on Intelligent Transportation Systems 2020 (IEEE\n  ITSC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitasking optimization is a recently introduced paradigm, focused on the\nsimultaneous solving of multiple optimization problem instances (tasks). The\ngoal of multitasking environments is to dynamically exploit existing\ncomplementarities and synergies among tasks, helping each other through the\ntransfer of genetic material. More concretely, Evolutionary Multitasking (EM)\nregards to the resolution of multitasking scenarios using concepts inherited\nfrom Evolutionary Computation. EM approaches such as the well-known\nMultifactorial Evolutionary Algorithm (MFEA) are lately gaining a notable\nresearch momentum when facing with multiple optimization problems. This work is\nfocused on the application of the recently proposed Multifactorial Cellular\nGenetic Algorithm (MFCGA) to the well-known Capacitated Vehicle Routing Problem\n(CVRP). In overall, 11 different multitasking setups have been built using 12\ndatasets. The contribution of this research is twofold. On the one hand, it is\nthe first application of the MFCGA to the Vehicle Routing Problem family of\nproblems. On the other hand, equally interesting is the second contribution,\nwhich is focused on the quantitative analysis of the positive genetic\ntransferability among the problem instances. To do that, we provide an\nempirical demonstration of the synergies arisen between the different\noptimization tasks.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 12:58:00 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 08:09:31 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Osaba", "Eneko", ""], ["Martinez", "Aritz D.", ""], ["Lobo", "Jesus L.", ""], ["La\u00f1a", "Ibai", ""], ["Del Ser", "Javier", ""]]}, {"id": "2005.05151", "submitter": "Louis Annabi", "authors": "Louis Annabi (ETIS), Alexandre Pitti (ETIS), Mathias Quoy (ETIS)", "title": "Autonomous learning and chaining of motor primitives using the Free\n  Energy Principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we apply the Free-Energy Principle to the question of motor\nprimitives learning. An echo-state network is used to generate motor\ntrajectories. We combine this network with a perception module and a controller\nthat can influence its dynamics. This new compound network permits the\nautonomous learning of a repertoire of motor trajectories. To evaluate the\nrepertoires built with our method, we exploit them in a handwriting task where\nprimitives are chained to produce long-range sequences.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 14:43:55 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Annabi", "Louis", "", "ETIS"], ["Pitti", "Alexandre", "", "ETIS"], ["Quoy", "Mathias", "", "ETIS"]]}, {"id": "2005.05268", "submitter": "Uzay \\c{C}etin", "authors": "Uzay Cetin and Yunus Emre Gundogmus", "title": "Feature Selection with Evolving, Fast and Slow Using Two Parallel\n  Genetic Algorithms", "comments": null, "journal-ref": "Conference: 2019 4th International Conference on Computer Science\n  and Engineering (UBMK)", "doi": "10.1109/UBMK.2019.8907165", "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection is one of the most challenging issues in machine learning,\nespecially while working with high dimensional data. In this paper, we address\nthe problem of feature selection and propose a new approach called Evolving\nFast and Slow. This new approach is based on using two parallel genetic\nalgorithms having high and low mutation rates, respectively. Evolving Fast and\nSlow requires a new parallel architecture combining an automatic system that\nevolves fast and an effortful system that evolves slow. With this architecture,\nexploration and exploitation can be done simultaneously and in unison. Evolving\nfast, with high mutation rate, can be useful to explore new unknown places in\nthe search space with long jumps; and Evolving Slow, with low mutation rate,\ncan be useful to exploit previously known places in the search space with short\nmovements. Our experiments show that Evolving Fast and Slow achieves very good\nresults in terms of both accuracy and feature elimination.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:10:39 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Cetin", "Uzay", ""], ["Gundogmus", "Yunus Emre", ""]]}, {"id": "2005.05294", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio and Alessio Micheli", "title": "Ring Reservoir Neural Networks for Graphs", "comments": "Accepted for IJCNN/WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning for graphs is nowadays a research topic of consolidated\nrelevance. Common approaches in the field typically resort to complex deep\nneural network architectures and demanding training algorithms, highlighting\nthe need for more efficient solutions. The class of Reservoir Computing (RC)\nmodels can play an important role in this context, enabling to develop fruitful\ngraph embeddings through untrained recursive architectures. In this paper, we\nstudy progressive simplifications to the design strategy of RC neural networks\nfor graphs. Our core proposal is based on shaping the organization of the\nhidden neurons to follow a ring topology. Experimental results on graph\nclassification tasks indicate that ring-reservoirs architectures enable\nparticularly effective network configurations, showing consistent advantages in\nterms of predictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2020 17:51:40 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "2005.05572", "submitter": "Michael Kummer", "authors": "Michael Kummer, Arunava Banerjee", "title": "Spike-Triggered Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characterization of neural responses to sensory stimuli is a central\nproblem in neuroscience. Spike-triggered average (STA), an influential\ntechnique, has been used to extract optimal linear kernels in a variety of\nanimal subjects. However, when the model assumptions are not met, it can lead\nto misleading and imprecise results. We introduce a technique, called\nspike-triggered descent (STD), which can be used alone or in conjunction with\nSTA to increase precision and yield success in scenarios where STA fails. STD\nworks by simulating a model neuron that learns to reproduce the observed spike\ntrain. Learning is achieved via parameter optimization that relies on a metric\ninduced on the space of spike trains modeled as a novel inner product space.\nThis technique can precisely learn higher order kernels using limited data.\nKernels extracted from a Locusta migratoria tympanal nerve dataset demonstrate\nthe strength of this approach.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 06:48:04 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Kummer", "Michael", ""], ["Banerjee", "Arunava", ""]]}, {"id": "2005.05613", "submitter": "Mudita Sharma Afhea", "authors": "Mudita Sharma, Manuel Lopez-Ibanez and Dimitar Kazakov", "title": "Unified Framework for the Adaptive Operator Selection of Discrete\n  Parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct an exhaustive survey of adaptive selection of operators (AOS) in\nEvolutionary Algorithms (EAs). We simplified the AOS structure by adding more\ncomponents to the framework to built upon the existing categorisation of AOS\nmethods. In addition to simplifying, we looked at the commonality among AOS\nmethods from literature to generalise them. Each component is presented with a\nnumber of alternative choices, each represented with a formula. We make three\nsets of comparisons. First, the methods from literature are tested on the BBOB\ntest bed with their default hyper parameters. Second, the hyper parameters of\nthese methods are tuned using an offline configurator known as IRACE. Third,\nfor a given set of problems, we use IRACE to select the best combination of\ncomponents and tune their hyper parameters.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 08:41:31 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Sharma", "Mudita", ""], ["Lopez-Ibanez", "Manuel", ""], ["Kazakov", "Dimitar", ""]]}, {"id": "2005.05704", "submitter": "Dania Humaidan", "authors": "Dania Humaidan, Sebastian Otte, Martin V. Butz", "title": "Fostering Event Compression using Gated Surprise", "comments": "submitted to ICANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our brain receives a dynamically changing stream of sensorimotor data. Yet,\nwe perceive a rather organized world, which we segment into and perceive as\nevents. Computational theories of cognitive science on event-predictive\ncognition suggest that our brain forms generative, event-predictive models by\nsegmenting sensorimotor data into suitable chunks of contextual experiences.\nHere, we introduce a hierarchical, surprise-gated recurrent neural network\narchitecture, which models this process and develops compact compressions of\ndistinct event-like contexts. The architecture contains a contextual LSTM\nlayer, which develops generative compressions of ongoing and subsequent\ncontexts. These compressions are passed into a GRU-like layer, which uses\nsurprise signals to update its recurrent latent state. The latent state is\npassed forward into another LSTM layer, which processes actual dynamic sensory\nflow in the light of the provided latent, contextual compression signals. Our\nmodel shows to develop distinct event compressions and achieves the best\nperformance on multiple event processing tasks. The architecture may be very\nuseful for the further development of resource-efficient learning, hierarchical\nmodel-based reinforcement learning, as well as the development of artificial\nevent-predictive cognition and intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 11:57:46 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Humaidan", "Dania", ""], ["Otte", "Sebastian", ""], ["Butz", "Martin V.", ""]]}, {"id": "2005.05744", "submitter": "Juergen Schmidhuber", "authors": "Juergen Schmidhuber", "title": "Deep Learning: Our Miraculous Year 1990-1991", "comments": "26 pages, 236 references, based on work of 4 Oct 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2020-2021, we are celebrating that many of the basic ideas behind the deep\nlearning revolution were published three decades ago within fewer than 12\nmonths in our \"Annus Mirabilis\" or \"Miraculous Year\" 1990-1991 at TU Munich.\nBack then, few people were interested, but a quarter century later, neural\nnetworks based on these ideas were on over 3 billion devices such as\nsmartphones, and used many billions of times per day, consuming a significant\nfraction of the world's compute.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 13:16:30 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 08:26:01 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Schmidhuber", "Juergen", ""]]}, {"id": "2005.05854", "submitter": "Preslav Nakov", "authors": "Giovanni Da San Martino, Shaden Shaar, Yifan Zhang, Seunghak Yu,\n  Alberto Barr\\'on-Cede\\~no, Preslav Nakov", "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "comments": "propaganda, disinformation, fake news, media bias, COVID-19", "journal-ref": "ACL-2020", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:20:55 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Martino", "Giovanni Da San", ""], ["Shaar", "Shaden", ""], ["Zhang", "Yifan", ""], ["Yu", "Seunghak", ""], ["Barr\u00f3n-Cede\u00f1o", "Alberto", ""], ["Nakov", "Preslav", ""]]}, {"id": "2005.05859", "submitter": "Vishnu Naresh Boddeti", "authors": "Zhichao Lu, Gautam Sreekumar, Erik Goodman, Wolfgang Banzhaf,\n  Kalyanmoy Deb, and Vishnu Naresh Boddeti", "title": "Neural Architecture Transfer", "comments": "Code is available at\n  https://github.com/human-analysis/neural-architecture-transfer", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2021", "doi": "10.1109/TPAMI.2021.3052758", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has emerged as a promising avenue for\nautomatically designing task-specific neural networks. Existing NAS approaches\nrequire one complete search for each deployment specification of hardware or\nobjective. This is a computationally impractical endeavor given the potentially\nlarge number of application scenarios. In this paper, we propose Neural\nArchitecture Transfer (NAT) to overcome this limitation. NAT is designed to\nefficiently generate task-specific custom models that are competitive under\nmultiple conflicting objectives. To realize this goal we learn task-specific\nsupernets from which specialized subnets can be sampled without any additional\ntraining. The key to our approach is an integrated online transfer learning and\nmany-objective evolutionary search procedure. A pre-trained supernet is\niteratively adapted while simultaneously searching for task-specific subnets.\nWe demonstrate the efficacy of NAT on 11 benchmark image classification tasks\nranging from large-scale multi-class to small-scale fine-grained datasets. In\nall cases, including ImageNet, NATNets improve upon the state-of-the-art under\nmobile settings ($\\leq$ 600M Multiply-Adds). Surprisingly, small-scale\nfine-grained datasets benefit the most from NAT. At the same time, the\narchitecture search and transfer is orders of magnitude more efficient than\nexisting NAS methods. Overall, the experimental evaluation indicates that,\nacross diverse image classification tasks and computational objectives, NAT is\nan appreciably more effective alternative to conventional transfer learning of\nfine-tuning weights of an existing network architecture learned on standard\ndatasets. Code is available at\nhttps://github.com/human-analysis/neural-architecture-transfer\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 15:30:36 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 00:32:53 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Lu", "Zhichao", ""], ["Sreekumar", "Gautam", ""], ["Goodman", "Erik", ""], ["Banzhaf", "Wolfgang", ""], ["Deb", "Kalyanmoy", ""], ["Boddeti", "Vishnu Naresh", ""]]}, {"id": "2005.05930", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Arnas Uselis, Mantas Luko\\v{s}evi\\v{c}ius, Lukas Stasytis", "title": "Localized convolutional neural networks for geospatial wind forecasting", "comments": null, "journal-ref": "Energies, 13 (13), pp. 3440, 2020", "doi": "10.3390/en13133440", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) possess many positive qualities when it\ncomes to spatial raster data. Translation invariance enables CNNs to detect\nfeatures regardless of their position in the scene. However, in some domains,\nlike geospatial, not all locations are exactly equal. In this work, we propose\nlocalized convolutional neural networks that enable convolutional architectures\nto learn local features in addition to the global ones. We investigate their\ninstantiations in the form of learnable inputs, local weights, and a more\ngeneral form. They can be added to any convolutional layers, easily end-to-end\ntrained, introduce minimal additional complexity, and let CNNs retain most of\ntheir benefits to the extent that they are needed. In this work we address\nspatio-temporal prediction: test the effectiveness of our methods on a\nsynthetic benchmark dataset and tackle three real-world wind prediction\ndatasets. For one of them, we propose a method to spatially order the unordered\ndata. We compare the recent state-of-the-art spatio-temporal prediction models\non the same data. Models that use convolutional layers can be and are extended\nwith our localizations. In all these cases our extensions improve the results,\nand thus often the state-of-the-art. We share all the code at a public\nrepository.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:14:49 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 14:56:21 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 16:13:17 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Uselis", "Arnas", ""], ["Luko\u0161evi\u010dius", "Mantas", ""], ["Stasytis", "Lukas", ""]]}, {"id": "2005.05941", "submitter": "Sneha Aenugu", "authors": "Sneha Aenugu", "title": "Training spiking neural networks using reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the brain communicate with each other through discrete action\nspikes as opposed to continuous signal transmission in artificial neural\nnetworks. Therefore, the traditional techniques for optimization of parameters\nin neural networks which rely on the assumption of differentiability of\nactivation functions are no longer applicable to modeling the learning\nprocesses in the brain. In this project, we propose biologically-plausible\nalternatives to backpropagation to facilitate the training of spiking neural\nnetworks. We primarily focus on investigating the candidacy of reinforcement\nlearning (RL) rules in solving the spatial and temporal credit assignment\nproblems to enable decision-making in complex tasks. In one approach, we\nconsider each neuron in a multi-layer neural network as an independent RL agent\nforming a different representation of the feature space while the network as a\nwhole forms the representation of the complex policy to solve the task at hand.\nIn other approach, we apply the reparameterization trick to enable\ndifferentiation through stochastic transformations in spiking neural networks.\nWe compare and contrast the two approaches by applying them to traditional RL\ndomains such as gridworld, cartpole and mountain car. Further we also suggest\nvariations and enhancements to enable future research in this area.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:40:36 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Aenugu", "Sneha", ""]]}, {"id": "2005.05960", "submitter": "Deepak Pathak", "authors": "Ramanan Sekar, Oleh Rybkin, Kostas Daniilidis, Pieter Abbeel, Danijar\n  Hafner, Deepak Pathak", "title": "Planning to Explore via Self-Supervised World Models", "comments": "Accepted at ICML 2020. Videos and code at\n  https://ramanans1.github.io/plan2explore/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning allows solving complex tasks, however, the learning\ntends to be task-specific and the sample efficiency remains a challenge. We\npresent Plan2Explore, a self-supervised reinforcement learning agent that\ntackles both these challenges through a new approach to self-supervised\nexploration and fast adaptation to new tasks, which need not be known during\nexploration. During exploration, unlike prior methods which retrospectively\ncompute the novelty of observations after the agent has already reached them,\nour agent acts efficiently by leveraging planning to seek out expected future\nnovelty. After exploration, the agent quickly adapts to multiple downstream\ntasks in a zero or a few-shot manner. We evaluate on challenging control tasks\nfrom high-dimensional image inputs. Without any training supervision or\ntask-specific interaction, Plan2Explore outperforms prior self-supervised\nexploration methods, and in fact, almost matches the performances oracle which\nhas access to rewards. Videos and code at\nhttps://ramanans1.github.io/plan2explore/\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2020 17:59:45 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 23:05:50 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Sekar", "Ramanan", ""], ["Rybkin", "Oleh", ""], ["Daniilidis", "Kostas", ""], ["Abbeel", "Pieter", ""], ["Hafner", "Danijar", ""], ["Pathak", "Deepak", ""]]}, {"id": "2005.06142", "submitter": "Karan Nayak Mr.", "authors": "Karan Nayak", "title": "Using Genetic Algorithm To Evolve Cellular Automata In Performing Edge\n  Detection", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cellular automata are discrete and computational models thatcan be shown as\ngeneral models of complexity. They are used in varied applications to derive\nthe generalized behavior of the presented model. In this paper we have took one\nsuch application. We have made an effort to perform edge detection on an image\nusing genetic algorithm. The purpose and the intention here is to analyze the\ncapability and performance of the suggested genetic algorithm. Genetic\nalgorithms are used to depict or obtain a general solution of given problem.\nUsing this feature of GA we have tried to evolve the cellular automata and\nshown that how with time it converges to the desired results.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 04:07:43 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Nayak", "Karan", ""]]}, {"id": "2005.06148", "submitter": "Jialin Liu Ph.D", "authors": "Tianye Shu, Ziqi Wang, Jialin Liu, Xin Yao", "title": "A Novel CNet-assisted Evolutionary Level Repairer and Its Applications\n  to Super Mario Bros", "comments": "Accepted at IEEE CEC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying latent variable evolution to game level design has become more and\nmore popular as little human expert knowledge is required. However, defective\nlevels with illegal patterns may be generated due to the violation of\nconstraints for level design. A traditional way of repairing the defective\nlevels is programming specific rule-based repairers to patch the flaw. However,\nprogramming these constraints is sometimes complex and not straightforward. An\nautonomous level repairer which is capable of learning the constraints is\nneeded. In this paper, we propose a novel approach, CNet, to learn the\nprobability distribution of tiles giving its surrounding tiles on a set of real\nlevels, and then detect the illegal tiles in generated new levels. Then, an\nevolutionary repairer is designed to search for optimal replacement schemes\nequipped with a novel search space being constructed with the help of CNet and\na novel heuristic function. The proposed approaches are proved to be effective\nin our case study of repairing GAN-generated and artificially destroyed levels\nof Super Mario Bros. game. Our CNet-assisted evolutionary repairer can also be\neasily applied to other games of which the levels can be represented by a\nmatrix of objects or tiles.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 04:27:18 GMT"}, {"version": "v2", "created": "Thu, 14 May 2020 16:17:39 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Shu", "Tianye", ""], ["Wang", "Ziqi", ""], ["Liu", "Jialin", ""], ["Yao", "Xin", ""]]}, {"id": "2005.06223", "submitter": "Stephane Doncieux", "authors": "Stephane Doncieux (ISIR), Nicolas Bredeche (ISIR), L\\'eni Le Goff\n  (ISIR), Beno\\^it Girard (ISIR), Alexandre Coninx (ISIR), Olivier Sigaud\n  (ISIR), Mehdi Khamassi (ISIR), Natalia D\\'iaz-Rodr\\'iguez (U2IS), David\n  Filliat (U2IS), Timothy Hospedales (ICSA), A. Eiben (VU), Richard Duro", "title": "DREAM Architecture: a Developmental Approach to Open-Ended Learning in\n  Robotics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots are still limited to controlled conditions, that the robot designer\nknows with enough details to endow the robot with the appropriate models or\nbehaviors. Learning algorithms add some flexibility with the ability to\ndiscover the appropriate behavior given either some demonstrations or a reward\nto guide its exploration with a reinforcement learning algorithm. Reinforcement\nlearning algorithms rely on the definition of state and action spaces that\ndefine reachable behaviors. Their adaptation capability critically depends on\nthe representations of these spaces: small and discrete spaces result in fast\nlearning while large and continuous spaces are challenging and either require a\nlong training period or prevent the robot from converging to an appropriate\nbehavior. Beside the operational cycle of policy execution and the learning\ncycle, which works at a slower time scale to acquire new policies, we introduce\nthe redescription cycle, a third cycle working at an even slower time scale to\ngenerate or adapt the required representations to the robot, its environment\nand the task. We introduce the challenges raised by this cycle and we present\nDREAM (Deferred Restructuring of Experience in Autonomous Machines), a\ndevelopmental cognitive architecture to bootstrap this redescription process\nstage by stage, build new state representations with appropriate motivations,\nand transfer the acquired knowledge across domains or tasks or even across\nrobots. We describe results obtained so far with this approach and end up with\na discussion of the questions it raises in Neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 09:29:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Doncieux", "Stephane", "", "ISIR"], ["Bredeche", "Nicolas", "", "ISIR"], ["Goff", "L\u00e9ni Le", "", "ISIR"], ["Girard", "Beno\u00eet", "", "ISIR"], ["Coninx", "Alexandre", "", "ISIR"], ["Sigaud", "Olivier", "", "ISIR"], ["Khamassi", "Mehdi", "", "ISIR"], ["D\u00edaz-Rodr\u00edguez", "Natalia", "", "U2IS"], ["Filliat", "David", "", "U2IS"], ["Hospedales", "Timothy", "", "ICSA"], ["Eiben", "A.", "", "VU"], ["Duro", "Richard", ""]]}, {"id": "2005.06224", "submitter": "Stephane Doncieux", "authors": "Stephane Doncieux (ISIR), Giuseppe Paolo (ISIR), Alban Laflaqui\\`ere,\n  Alexandre Coninx (ISIR)", "title": "Novelty Search makes Evolvability Inevitable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolvability is an important feature that impacts the ability of evolutionary\nprocesses to find interesting novel solutions and to deal with changing\nconditions of the problem to solve. The estimation of evolvability is not\nstraightforward and is generally too expensive to be directly used as selective\npressure in the evolutionary process. Indirectly promoting evolvability as a\nside effect of other easier and faster to compute selection pressures would\nthus be advantageous. In an unbounded behavior space, it has already been shown\nthat evolvable individuals naturally appear and tend to be selected as they are\nmore likely to invade empty behavior niches. Evolvability is thus a natural\nbyproduct of the search in this context. However, practical agents and\nenvironments often impose limits on the reach-able behavior space. How do these\nboundaries impact evolvability? In this context, can evolvability still be\npromoted without explicitly rewarding it? We show that Novelty Search\nimplicitly creates a pressure for high evolvability even in bounded behavior\nspaces, and explore the reasons for such a behavior. More precisely we show\nthat, throughout the search, the dynamic evaluation of novelty rewards\nindividuals which are very mobile in the behavior space, which in turn promotes\nevolvability.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 09:32:07 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Doncieux", "Stephane", "", "ISIR"], ["Paolo", "Giuseppe", "", "ISIR"], ["Laflaqui\u00e8re", "Alban", "", "ISIR"], ["Coninx", "Alexandre", "", "ISIR"]]}, {"id": "2005.06284", "submitter": "Evgeny Mirkes", "authors": "Evgeny M Mirkes", "title": "Artificial Neural Network Pruning to Extract Knowledge", "comments": "IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Neural Networks (NN) are widely used for solving complex problems\nfrom medical diagnostics to face recognition. Despite notable successes, the\nmain disadvantages of NN are also well known: the risk of overfitting, lack of\nexplainability (inability to extract algorithms from trained NN), and high\nconsumption of computing resources. Determining the appropriate specific NN\nstructure for each problem can help overcome these difficulties: Too poor NN\ncannot be successfully trained, but too rich NN gives unexplainable results and\nmay have a high chance of overfitting. Reducing precision of NN parameters\nsimplifies the implementation of these NN, saves computing resources, and makes\nthe NN skills more transparent. This paper lists the basic NN simplification\nproblems and controlled pruning procedures to solve these problems. All the\ndescribed pruning procedures can be implemented in one framework. The developed\nprocedures, in particular, find the optimal structure of NN for each task,\nmeasure the influence of each input signal and NN parameter, and provide a\ndetailed verbal description of the algorithms and skills of NN. The described\nmethods are illustrated by a simple example: the generation of explicit\nalgorithms for predicting the results of the US presidential election.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 12:24:40 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Mirkes", "Evgeny M", ""]]}, {"id": "2005.06305", "submitter": "Hai Phan", "authors": "Hai Phan, Zechun Liu, Dang Huynh, Marios Savvides, Kwang-Ting Cheng,\n  Zhiqiang Shen", "title": "Binarizing MobileNet via Evolution-based Searching", "comments": "Accepted by CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binary Neural Networks (BNNs), known to be one among the effectively compact\nnetwork architectures, have achieved great outcomes in the visual tasks.\nDesigning efficient binary architectures is not trivial due to the binary\nnature of the network. In this paper, we propose a use of evolutionary search\nto facilitate the construction and training scheme when binarizing MobileNet, a\ncompact network with separable depth-wise convolution. Inspired by one-shot\narchitecture search frameworks, we manipulate the idea of group convolution to\ndesign efficient 1-Bit Convolutional Neural Networks (CNNs), assuming an\napproximately optimal trade-off between computational cost and model accuracy.\nOur objective is to come up with a tiny yet efficient binary neural\narchitecture by exploring the best candidates of the group convolution while\noptimizing the model performance in terms of complexity and latency. The\napproach is threefold. First, we train strong baseline binary networks with a\nwide range of random group combinations at each convolutional layer. This\nset-up gives the binary neural networks a capability of preserving essential\ninformation through layers. Second, to find a good set of hyperparameters for\ngroup convolutions we make use of the evolutionary search which leverages the\nexploration of efficient 1-bit models. Lastly, these binary models are trained\nfrom scratch in a usual manner to achieve the final binary model. Various\nexperiments on ImageNet are conducted to show that following our construction\nguideline, the final model achieves 60.09% Top-1 accuracy and outperforms the\nstate-of-the-art CI-BCNN with the same computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:25:51 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 15:48:58 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Phan", "Hai", ""], ["Liu", "Zechun", ""], ["Huynh", "Dang", ""], ["Savvides", "Marios", ""], ["Cheng", "Kwang-Ting", ""], ["Shen", "Zhiqiang", ""]]}, {"id": "2005.06318", "submitter": "Charlotte Frenkel", "authors": "Charlotte Frenkel, Jean-Didier Legat, David Bol", "title": "A 28-nm Convolutional Neuromorphic Processor Enabling Online Learning\n  with Spike-Based Retinas", "comments": "Accepted for presentation at the IEEE International Symposium on\n  Circuits and Systems (ISCAS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an attempt to follow biological information representation and\norganization principles, the field of neuromorphic engineering is usually\napproached bottom-up, from the biophysical models to large-scale integration in\nsilico. While ideal as experimentation platforms for cognitive computing and\nneuroscience, bottom-up neuromorphic processors have yet to demonstrate an\nefficiency advantage compared to specialized neural network accelerators for\nreal-world problems. Top-down approaches aim at answering this difficulty by\n(i) starting from the applicative problem and (ii) investigating how to make\nthe associated algorithms hardware-efficient and biologically-plausible. In\norder to leverage the data sparsity of spike-based neuromorphic retinas for\nadaptive edge computing and vision applications, we follow a top-down approach\nand propose SPOON, a 28-nm event-driven CNN (eCNN). It embeds online learning\nwith only 16.8-% power and 11.8-% area overheads with the\nbiologically-plausible direct random target projection (DRTP) algorithm. With\nan energy per classification of 313nJ at 0.6V and a 0.32-mm$^2$ area for\naccuracies of 95.3% (on-chip training) and 97.5% (off-chip training) on MNIST,\nwe demonstrate that SPOON reaches the efficiency of conventional machine\nlearning accelerators while embedding on-chip learning and being compatible\nwith event-based sensors, a point that we further emphasize with N-MNIST\nbenchmarking.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 13:47:44 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Frenkel", "Charlotte", ""], ["Legat", "Jean-Didier", ""], ["Bol", "David", ""]]}, {"id": "2005.06398", "submitter": "Noam Razin", "authors": "Noam Razin, Nadav Cohen", "title": "Implicit Regularization in Deep Learning May Not Be Explainable by Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematically characterizing the implicit regularization induced by\ngradient-based optimization is a longstanding pursuit in the theory of deep\nlearning. A widespread hope is that a characterization based on minimization of\nnorms may apply, and a standard test-bed for studying this prospect is matrix\nfactorization (matrix completion via linear neural networks). It is an open\nquestion whether norms can explain the implicit regularization in matrix\nfactorization. The current paper resolves this open question in the negative,\nby proving that there exist natural matrix factorization problems on which the\nimplicit regularization drives all norms (and quasi-norms) towards infinity.\nOur results suggest that, rather than perceiving the implicit regularization\nvia norms, a potentially more useful interpretation is minimization of rank. We\ndemonstrate empirically that this interpretation extends to a certain class of\nnon-linear neural networks, and hypothesize that it may be key to explaining\ngeneralization in deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2020 16:13:30 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2020 16:47:36 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Razin", "Noam", ""], ["Cohen", "Nadav", ""]]}, {"id": "2005.06678", "submitter": "Chichun Zhou", "authors": "Chi-Chun Zhou, Hai-Long Tu, Yi Liu, and Jian Hua", "title": "Activation functions are not needed: the ratio net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The function approximator that finds the function mapping the feature to the\nlabel is an important component in a deep neural network for classification\ntasks. To overcome nonlinearity, which is the main difficulty in designing the\nfunction approximator, one usually uses the method based on the nonlinear\nactivation function or the nonlinear kernel function and yields classical\nnetworks such as the feed-forward neural network (MLP) and the radial basis\nfunction network (RBF). Although, classical networks such as the MLP are robust\nin most of the classification task, they are not the most efficient. E.g., they\nuse large amount of parameters and take long times to train. Additionally, the\nchoice of activation functions has a non-negligible influence on the\neffectiveness and efficiency of the network. In this paper, we propose a new\nnetwork that is efficient in finding the function that maps the feature to the\nlabel. Instead of using the nonlinear activation function, the new proposed\nnetwork uses the fractional form to overcome the nonlinearity, thus for the\nsake of convenience, we name the network the ratio net. We compare the\neffectiveness and efficiency of the ratio net and the classical networks such\nas the MLP and the RBF in the classification task on the mnist database of\nhandwritten digits and the IMDb dataset which is a binary sentiment analysis\ndataset. The result shows that the ratio net outperforms both the MLP and the\nRBF.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 01:07:56 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zhou", "Chi-Chun", ""], ["Tu", "Hai-Long", ""], ["Liu", "Yi", ""], ["Hua", "Jian", ""]]}, {"id": "2005.06728", "submitter": "Yemao Xu Mr", "authors": "Yemao Xu and Dezun Dong and Weixia Xu and Xiangke Liao", "title": "OD-SGD: One-step Delay Stochastic Gradient Descent for Distributed\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of modern deep learning neural network calls for large amounts\nof computation, which is often provided by GPUs or other specific accelerators.\nTo scale out to achieve faster training speed, two update algorithms are mainly\napplied in the distributed training process, i.e. the Synchronous SGD algorithm\n(SSGD) and Asynchronous SGD algorithm (ASGD). SSGD obtains good convergence\npoint while the training speed is slowed down by the synchronous barrier. ASGD\nhas faster training speed but the convergence point is lower when compared to\nSSGD. To sufficiently utilize the advantages of SSGD and ASGD, we propose a\nnovel technology named One-step Delay SGD (OD-SGD) to combine their strengths\nin the training process. Therefore, we can achieve similar convergence point\nand training speed as SSGD and ASGD separately. To the best of our knowledge,\nwe make the first attempt to combine the features of SSGD and ASGD to improve\ndistributed training performance. Each iteration of OD-SGD contains a global\nupdate in the parameter server node and local updates in the worker nodes, the\nlocal update is introduced to update and compensate the delayed local weights.\nWe evaluate our proposed algorithm on MNIST, CIFAR-10 and ImageNet datasets.\nExperimental results show that OD-SGD can obtain similar or even slightly\nbetter accuracy than SSGD, while its training speed is much faster, which even\nexceeds the training speed of ASGD.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 05:33:36 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Xu", "Yemao", ""], ["Dong", "Dezun", ""], ["Xu", "Weixia", ""], ["Liao", "Xiangke", ""]]}, {"id": "2005.06764", "submitter": "Diego Perez Liebana Dr.", "authors": "Diego Perez-Liebana, Muhammad Sajid Alam, Raluca D. Gaina", "title": "Rolling Horizon NEAT for General Video Game Playing", "comments": "8 pages, 5 figures, accepted for publication in IEEE Conference on\n  Games (CoG) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new Statistical Forward Planning (SFP) method, Rolling\nHorizon NeuroEvolution of Augmenting Topologies (rhNEAT). Unlike traditional\nRolling Horizon Evolution, where an evolutionary algorithm is in charge of\nevolving a sequence of actions, rhNEAT evolves weights and connections of a\nneural network in real-time, planning several steps ahead before returning an\naction to execute in the game. Different versions of the algorithm are explored\nin a collection of 20 GVGAI games, and compared with other SFP methods and\nstate of the art results. Although results are overall not better than other\nSFP methods, the nature of rhNEAT to adapt to changing game features has\nallowed to establish new state of the art records in games that other methods\nhave traditionally struggled with. The algorithm proposed here is general and\nintroduces a new way of representing information within rolling horizon\nevolution techniques.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 07:25:23 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Perez-Liebana", "Diego", ""], ["Alam", "Muhammad Sajid", ""], ["Gaina", "Raluca D.", ""]]}, {"id": "2005.07229", "submitter": "Iam Palatnik de Sousa", "authors": "Iam Palatnik de Sousa, Marley Maria Bernardes Rebuzzi Vellasco,\n  Eduardo Costa da Silva", "title": "Evolved Explainable Classifications for Lymph Node Metastases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel evolutionary approach for Explainable Artificial Intelligence is\npresented: the \"Evolved Explanations\" model (EvEx). This methodology consists\nin combining Local Interpretable Model Agnostic Explanations (LIME) with\nMulti-Objective Genetic Algorithms to allow for automated segmentation\nparameter tuning in image classification tasks. In this case, the dataset\nstudied is Patch-Camelyon, comprised of patches from pathology whole slide\nimages. A publicly available Convolutional Neural Network (CNN) was trained on\nthis dataset to provide a binary classification for presence/absence of lymph\nnode metastatic tissue. In turn, the classifications are explained by means of\nevolving segmentations, seeking to optimize three evaluation goals\nsimultaneously. The final explanation is computed as the mean of all\nexplanations generated by Pareto front individuals, evolved by the developed\ngenetic algorithm. To enhance reproducibility and traceability of the\nexplanations, each of them was generated from several different seeds, randomly\nchosen. The observed results show remarkable agreement between different seeds.\nDespite the stochastic nature of LIME explanations, regions of high explanation\nweights proved to have good agreement in the heat maps, as computed by\npixel-wise relative standard deviations. The found heat maps coincide with\nexpert medical segmentations, which demonstrates that this methodology can find\nhigh quality explanations (according to the evaluation metrics), with the novel\nadvantage of automated parameter fine tuning. These results give additional\ninsight into the inner workings of neural network black box decision making for\nmedical data.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 19:27:24 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["de Sousa", "Iam Palatnik", ""], ["Vellasco", "Marley Maria Bernardes Rebuzzi", ""], ["da Silva", "Eduardo Costa", ""]]}, {"id": "2005.07235", "submitter": "Antonio Mora Dr.", "authors": "A.M. Mora, A.I. Esparcia-Alc\\'azar", "title": "Evo* 2020 -- Late-Breaking Abstracts Volume", "comments": "LBAs accepted in Evo* 2020. Part of the Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the Late-Breaking Abstracts submitted to the Evo* 2020\nConference, that took place online, from 15 to 17 of April 2020. These papers\nwhere presented as short talks and also at the poster session of the conference\ntogether with other regular submissions. All of them present ongoing research\nand preliminary results investigating on the application of different\napproaches of Bioinspired Methods (mainly Evolutionary Computation) to\ndifferent problems, most of them real world ones.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2020 19:37:34 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mora", "A. M.", ""], ["Esparcia-Alc\u00e1zar", "A. I.", ""]]}, {"id": "2005.07360", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran", "title": "Learning Rate Annealing Can Provably Help Generalization, Even for\n  Convex Problems", "comments": "4 pages plus appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rate schedule can significantly affect generalization performance in\nmodern neural networks, but the reasons for this are not yet understood.\nLi-Wei-Ma (2019) recently proved this behavior can exist in a simplified\nnon-convex neural-network setting. In this note, we show that this phenomenon\ncan exist even for convex learning problems -- in particular, linear regression\nin 2 dimensions.\n  We give a toy convex problem where learning rate annealing (large initial\nlearning rate, followed by small learning rate) can lead gradient descent to\nminima with provably better generalization than using a small learning rate\nthroughout. In our case, this occurs due to a combination of the mismatch\nbetween the test and train loss landscapes, and early-stopping.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 05:16:32 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Nakkiran", "Preetum", ""]]}, {"id": "2005.07376", "submitter": "Zimeng Lyu", "authors": "Zimeng Lyu, Joshua Karns, AbdElRahman ElSaid, Travis Desell", "title": "Improving Neuroevolution Using Island Extinction and Repopulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroevolution commonly uses speciation strategies to better explore the\nsearch space of neural network architectures. One such speciation strategy is\nthrough the use of islands, which are also popular in improving performance and\nconvergence of distributed evolutionary algorithms. However, in this approach\nsome islands can become stagnant and not find new best solutions. In this\npaper, we propose utilizing extinction events and island repopulation to avoid\npremature convergence. We explore this with the Evolutionary eXploration of\nAugmenting Memory Models (EXAMM) neuro-evolution algorithm. In this strategy,\nall members of the worst performing island are killed of periodically and\nrepopulated with mutated versions of the global best genome. This island based\nstrategy is additionally compared to NEAT's (NeuroEvolution of Augmenting\nTopologies) speciation strategy. Experiments were performed using two different\nreal world time series datasets (coal-fired power plant and aviation flight\ndata). The results show that with statistical significance, this island\nextinction and repopulation strategy evolves better global best genomes than\nboth EXAMM's original island based strategy and NEAT's speciation strategy.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 06:47:41 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Lyu", "Zimeng", ""], ["Karns", "Joshua", ""], ["ElSaid", "AbdElRahman", ""], ["Desell", "Travis", ""]]}, {"id": "2005.07478", "submitter": "Sean Walton", "authors": "Sean P. Walton and Alma A. M. Rahat and James Stovold", "title": "Evaluating Mixed-Initiative Procedural Level Design Tools using a\n  Triple-Blind Mixed-Method User Study", "comments": "Accepted to be Published in: IEEE Transactions on Games", "journal-ref": null, "doi": "10.1109/TG.2021.3086215", "report-no": null, "categories": "cs.NE cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Results from a triple-blind mixed-method user study into the effectiveness of\nmixed-initiative tools for the procedural generation of game levels are\npresented. A tool which generates levels using interactive evolutionary\noptimisation was designed for this study which (a) is focused on supporting the\ndesigner to explore the design space and (b) only requires the designer to\ninteract with it by designing levels. The tool identifies level design patterns\nin an initial hand-designed map and uses that information to drive an\ninteractive optimisation algorithm. A rigorous user study was designed which\ncompared the experiences of designers using the mixed-initiative tool to\ndesigners who were given a tool which provided completely random level\nsuggestions. The designers using the mixed-initiative tool showed an increased\nengagement in the level design task, reporting that it was effective in\ninspiring new ideas and design directions. This provides significant evidence\nthat procedural content generation can be used as a powerful tool to support\nthe human design process.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 11:40:53 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 08:46:49 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Walton", "Sean P.", ""], ["Rahat", "Alma A. M.", ""], ["Stovold", "James", ""]]}, {"id": "2005.07669", "submitter": "Jeovane Hon\\'orio Alves", "authors": "Jeovane Honorio Alves, Lucas Ferrari de Oliveira", "title": "Optimizing Neural Architecture Search using Limited GPU Time in a\n  Dynamic Search Space: A Gene Expression Programming Approach", "comments": "Accepted for presentation at the IEEE Congress on Evolutionary\n  Computation (IEEE CEC) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient identification of people and objects, segmentation of regions of\ninterest and extraction of relevant data in images, texts, audios and videos\nare evolving considerably in these past years, which deep learning methods,\ncombined with recent improvements in computational resources, contributed\ngreatly for this achievement. Although its outstanding potential, development\nof efficient architectures and modules requires expert knowledge and amount of\nresource time available. In this paper, we propose an evolutionary-based neural\narchitecture search approach for efficient discovery of convolutional models in\na dynamic search space, within only 24 GPU hours. With its efficient search\nenvironment and phenotype representation, Gene Expression Programming is\nadapted for network's cell generation. Despite having limited GPU resource time\nand broad search space, our proposal achieved similar state-of-the-art to\nmanually-designed convolutional networks and also NAS-generated ones, even\nbeating similar constrained evolutionary-based NAS works. The best cells in\ndifferent runs achieved stable results, with a mean error of 2.82% in CIFAR-10\ndataset (which the best model achieved an error of 2.67%) and 18.83% for\nCIFAR-100 (best model with 18.16%). For ImageNet in the mobile setting, our\nbest model achieved top-1 and top-5 errors of 29.51% and 10.37%, respectively.\nAlthough evolutionary-based NAS works were reported to require a considerable\namount of GPU time for architecture search, our approach obtained promising\nresults in little time, encouraging further experiments in evolutionary-based\nNAS, for search and network representation improvements.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 17:32:30 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Alves", "Jeovane Honorio", ""], ["de Oliveira", "Lucas Ferrari", ""]]}, {"id": "2005.07772", "submitter": "Julie Rolla", "authors": "Julie Rolla, Amy Connolly, Kai Staats, Stephanie Wissel, Dean Arakaki,\n  Ian Best, Adam Blenk, Brian Clark, Maximillian Clowdus, Suren Gourapura,\n  Corey Harris, Hannah Hasan, Luke Letwin, David Liu, Carl Pfendner, Jordan\n  Potter, Cade Sbrocco, Tom Sinha and Jacob Trevithick", "title": "Evolving Antennas for Ultra-High Energy Neutrino Detection", "comments": "8 pages including references, 6 figures, presented at 36th\n  International Cosmic Ray Conference (ICRC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.NE physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms borrow from biology the concepts of mutation and\nselection in order to evolve optimized solutions to known problems. The GENETIS\ncollaboration is developing genetic algorithms for designing antennas that are\nmore sensitive to ultra-high energy neutrino induced radio pulses than current\ndesigns. There are three aspects of this investigation. The first is to evolve\nsimple wire antennas to test the concept and different algorithms. Second,\noptimized antenna response patterns are evolved for a given array geometry.\nFinally, antennas themselves are evolved using neutrino sensitivity as a\nmeasure of fitness. This is achieved by integrating the XFdtd finite-difference\ntime-domain modeling program with simulations of neutrino experiments.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 20:25:37 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Rolla", "Julie", ""], ["Connolly", "Amy", ""], ["Staats", "Kai", ""], ["Wissel", "Stephanie", ""], ["Arakaki", "Dean", ""], ["Best", "Ian", ""], ["Blenk", "Adam", ""], ["Clark", "Brian", ""], ["Clowdus", "Maximillian", ""], ["Gourapura", "Suren", ""], ["Harris", "Corey", ""], ["Hasan", "Hannah", ""], ["Letwin", "Luke", ""], ["Liu", "David", ""], ["Pfendner", "Carl", ""], ["Potter", "Jordan", ""], ["Sbrocco", "Cade", ""], ["Sinha", "Tom", ""], ["Trevithick", "Jacob", ""]]}, {"id": "2005.07786", "submitter": "Yerlan Idelbayev", "authors": "Yerlan Idelbayev and Miguel \\'A. Carreira-Perpi\\~n\\'an", "title": "A flexible, extensible software framework for model compression based on\n  the LC algorithm", "comments": "15 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a software framework based on the ideas of the\nLearning-Compression (LC) algorithm, that allows a user to compress a neural\nnetwork or other machine learning model using different compression schemes\nwith minimal effort. Currently, the supported compressions include pruning,\nquantization, low-rank methods (including automatically learning the layer\nranks), and combinations of those, and the user can choose different\ncompression types for different parts of a neural network.\n  The LC algorithm alternates two types of steps until convergence: a learning\n(L) step, which trains a model on a dataset (using an algorithm such as SGD);\nand a compression (C) step, which compresses the model parameters (using a\ncompression scheme such as low-rank or quantization). This decoupling of the\n\"machine learning\" aspect from the \"signal compression\" aspect means that\nchanging the model or the compression type amounts to calling the corresponding\nsubroutine in the L or C step, respectively. The library fully supports this by\ndesign, which makes it flexible and extensible. This does not come at the\nexpense of performance: the runtime needed to compress a model is comparable to\nthat of training the model in the first place; and the compressed model is\ncompetitive in terms of prediction accuracy and compression ratio with other\nalgorithms (which are often specialized for specific models or compression\nschemes). The library is written in Python and PyTorch and available in Github.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 21:14:48 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Idelbayev", "Yerlan", ""], ["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""]]}, {"id": "2005.07916", "submitter": "Dongxiao Zhang", "authors": "Hao Xu, Dongxiao Zhang, and Junsheng Zeng", "title": "Deep-learning of Parametric Partial Differential Equations from Sparse\n  and Noisy Data", "comments": "30 pages, 6 figures, and 7 tables", "journal-ref": "Phys. Fluids, 33, 037132, 10.1063/5.0042868, 2021", "doi": "10.1063/5.0042868", "report-no": null, "categories": "physics.comp-ph cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven methods have recently made great progress in the discovery of\npartial differential equations (PDEs) from spatial-temporal data. However,\nseveral challenges remain to be solved, including sparse noisy data, incomplete\ncandidate library, and spatially- or temporally-varying coefficients. In this\nwork, a new framework, which combines neural network, genetic algorithm and\nadaptive methods, is put forward to address all of these challenges\nsimultaneously. In the framework, a trained neural network is utilized to\ncalculate derivatives and generate a large amount of meta-data, which solves\nthe problem of sparse noisy data. Next, genetic algorithm is utilized to\ndiscover the form of PDEs and corresponding coefficients with an incomplete\ncandidate library. Finally, a two-step adaptive method is introduced to\ndiscover parametric PDEs with spatially- or temporally-varying coefficients. In\nthis method, the structure of a parametric PDE is first discovered, and then\nthe general form of varying coefficients is identified. The proposed algorithm\nis tested on the Burgers equation, the convection-diffusion equation, the wave\nequation, and the KdV equation. The results demonstrate that this method is\nrobust to sparse and noisy data, and is able to discover parametric PDEs with\nan incomplete candidate library.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 09:09:57 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Xu", "Hao", ""], ["Zhang", "Dongxiao", ""], ["Zeng", "Junsheng", ""]]}, {"id": "2005.08083", "submitter": "Alex De Sa'", "authors": "Alex G. C. de S\\'a, Cristiano G. Pimenta, Gisele L. Pappa and Alex A.\n  Freitas", "title": "A Robust Experimental Evaluation of Automated Multi-Label Classification\n  Methods", "comments": "GECCO'2020 paper: Submitted and accepted", "journal-ref": null, "doi": "10.1145/3377930.3390231", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Machine Learning (AutoML) has emerged to deal with the selection\nand configuration of algorithms for a given learning task. With the progression\nof AutoML, several effective methods were introduced, especially for\ntraditional classification and regression problems. Apart from the AutoML\nsuccess, several issues remain open. One issue, in particular, is the lack of\nability of AutoML methods to deal with different types of data. Based on this\nscenario, this paper approaches AutoML for multi-label classification (MLC)\nproblems. In MLC, each example can be simultaneously associated to several\nclass labels, unlike the standard classification task, where an example is\nassociated to just one class label. In this work, we provide a general\ncomparison of five automated multi-label classification methods -- two\nevolutionary methods, one Bayesian optimization method, one random search and\none greedy search -- on 14 datasets and three designed search spaces. Overall,\nwe observe that the most prominent method is the one based on a canonical\ngrammar-based genetic programming (GGP) search method, namely\nAuto-MEKA$_{GGP}$. Auto-MEKA$_{GGP}$ presented the best average results in our\ncomparison and was statistically better than all the other methods in different\nsearch spaces and evaluated measures, except when compared to the greedy search\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 20:08:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 16:48:27 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["de S\u00e1", "Alex G. C.", ""], ["Pimenta", "Cristiano G.", ""], ["Pappa", "Gisele L.", ""], ["Freitas", "Alex A.", ""]]}, {"id": "2005.08350", "submitter": "Mahboobeh Parsapoor", "authors": "M.Parsapoor, U.Bilstrup, B.Svensson", "title": "Forecasting Solar Activity with Two Computational Intelligence Models (A\n  Comparative Study)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solar activity It is vital to accurately predict solar activity, in order to\ndecrease the plausible damage of electronic equipment in the event of a large\nhigh-intensity solar eruption. Recently, we have proposed BELFIS (Brain\nEmotional Learning-based Fuzzy Inference System) as a tool for the forecasting\nof chaotic systems. The structure of BELFIS is designed based on the neural\nstructure of fear conditioning. The function of BELFIS is implemented by\nassigning adaptive networks to the components of the BELFIS structure. This\npaper especially focuses on performance evaluation of BELFIS as a predictor by\nforecasting solar cycles 16 to 24. The performance of BELFIS is compared with\nother computational models used for this purpose, and in particular with\nadaptive neuro-fuzzy inference system (ANFIS).\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 19:29:15 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Parsapoor", "M.", ""], ["Bilstrup", "U.", ""], ["Svensson", "B.", ""]]}, {"id": "2005.08368", "submitter": "Ahmed Khalifa", "authors": "Ahmed Khalifa and Julian Togelius", "title": "Multi-Objective level generator generation with Marahel", "comments": "Published at the PCGWorkshop 2020, 8pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new system to design constructive level generators by\nsearching the space of constructive level generators defined by Marahel\nlanguage. We use NSGA-II, a multi-objective optimization algorithm, to search\nfor generators for three different problems (Binary, Zelda, and Sokoban). We\nrestrict the representation to a subset of Marahel language to push the\nevolution to find more efficient generators. The results show that the\ngenerated generators were able to achieve good performance on most of the\nfitness functions over these three problems. However, on Zelda and Sokoban,\nthey tend to depend on the initial state than modifying the map.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 20:56:33 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 00:03:10 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Togelius", "Julian", ""]]}, {"id": "2005.08603", "submitter": "Leendert Remmelzwaal", "authors": "Leendert A Remmelzwaal, Amit K Mishra, George F R Ellis", "title": "Brain-inspired Distributed Cognitive Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper we present a brain-inspired cognitive architecture that\nincorporates sensory processing, classification, contextual prediction, and\nemotional tagging. The cognitive architecture is implemented as three modular\nweb-servers, meaning that it can be deployed centrally or across a network for\nservers. The experiments reveal two distinct operations of behaviour, namely\nhigh- and low-salience modes of operations, which closely model attention in\nthe brain. In addition to modelling the cortex, we have demonstrated that a\nbio-inspired architecture introduced processing efficiencies. The software has\nbeen published as an open source platform, and can be easily extended by future\nresearch teams. This research lays the foundations for bio-realistic attention\ndirection and sensory selection, and we believe that it is a key step towards\nachieving a bio-realistic artificial intelligent system.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 11:38:32 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Remmelzwaal", "Leendert A", ""], ["Mishra", "Amit K", ""], ["Ellis", "George F R", ""]]}, {"id": "2005.08620", "submitter": "Gi-Hwan Shin", "authors": "Gi-Hwan Shin, Minji Lee, Seong-Whan Lee", "title": "Assessment of Unconsciousness for Memory Consolidation Using EEG Signals", "comments": "Submitted to IEEE International Conference on System, Man, and\n  Cybernetics (IEEE SMC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The assessment of consciousness and unconsciousness is a challenging issue in\nmodern neuroscience. Consciousness is closely related to memory consolidation\nin that memory is a critical component of conscious experience. So far, many\nstudies have been reported on memory consolidation during consciousness, but\nthere is little research on memory consolidation during unconsciousness.\nTherefore, we aim to assess the unconsciousness in terms of memory\nconsolidation using electroencephalogram signals. In particular, we used\nunconscious state during a nap; because sleep is the only state in which\nconsciousness disappears under normal physiological conditions. Seven\nparticipants performed two memory tasks (word-pairs and visuo-spatial) before\nand after the nap to assess the memory consolidation during unconsciousness. As\na result, spindle power in central, parietal, occipital regions during\nunconsciousness was positively correlated with the performance of location\nmemory. With the memory performance, there was also a negative correlation\nbetween delta connectivity and word-pairs memory, alpha connectivity and\nlocation memory, and spindle connectivity and word-pairs memory. We\nadditionally observed the significant relationship between unconsciousness and\nbrain changes during memory recall before and after the nap. These findings\ncould help present new insights into the assessment of unconsciousness by\nexploring the relationship with memory consolidation.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 06:49:42 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Shin", "Gi-Hwan", ""], ["Lee", "Minji", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2005.08642", "submitter": "Ritam Guha Mr.", "authors": "Kushal Kanti Ghosh, Ritam Guha, Soulib Ghosh, Suman Kumar Bera, Ram\n  Sarkar", "title": "Atom Search Optimization with Simulated Annealing -- a Hybrid\n  Metaheuristic Approach for Feature Selection", "comments": "39 pages, submitted to Expert Systems with Applications, Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'Hybrid meta-heuristics' is one of the most interesting recent trends in the\nfield of optimization and feature selection (FS). In this paper, we have\nproposed a binary variant of Atom Search Optimization (ASO) and its hybrid with\nSimulated Annealing called ASO-SA techniques for FS. In order to map the real\nvalues used by ASO to the binary domain of FS, we have used two different\ntransfer functions: S-shaped and V-shaped. We have hybridized this technique\nwith a local search technique called, SA We have applied the proposed feature\nselection methods on 25 datasets from 4 different categories: UCI, Handwritten\ndigit recognition, Text, non-text separation, and Facial emotion recognition.\nWe have used 3 different classifiers (K-Nearest Neighbor, Multi-Layer\nPerceptron and Random Forest) for evaluating the strength of the selected\nfeatured by the binary ASO, ASO-SA and compared the results with some recent\nwrapper-based algorithms. The experimental results confirm the superiority of\nthe proposed method both in terms of classification accuracy and number of\nselected features.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2020 07:56:58 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ghosh", "Kushal Kanti", ""], ["Guha", "Ritam", ""], ["Ghosh", "Soulib", ""], ["Bera", "Suman Kumar", ""], ["Sarkar", "Ram", ""]]}, {"id": "2005.08768", "submitter": "Benoit Brummer", "authors": "Benoit Brummer, Christophe De Vleeschouwer", "title": "Adapting JPEG XS gains and priorities to tasks and contents", "comments": "CLIC at CVPR 2020", "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR) Workshops, 2020, pp. 164-165", "doi": "10.1109/CVPRW50498.2020.00090", "report-no": null, "categories": "eess.IV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most current research in the domain of image compression focuses solely on\nachieving state of the art compression ratio, but that is not always usable in\ntoday's workflow due to the constraints on computing resources.\n  Constant market requirements for a low-complexity image codec have led to the\nrecent development and standardization of a lightweight image codec named JPEG\nXS.\n  In this work we show that JPEG XS compression can be adapted to a specific\ngiven task and content, such as preserving visual quality on desktop content or\nmaintaining high accuracy in neural network segmentation tasks, by optimizing\nits gain and priority parameters using the covariance matrix adaptation\nevolution strategy.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 14:33:25 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 20:31:35 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 09:34:40 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Brummer", "Benoit", ""], ["De Vleeschouwer", "Christophe", ""]]}, {"id": "2005.08874", "submitter": "Tobias Huber", "authors": "Tobias Huber, Katharina Weitz, Elisabeth Andr\\'e, Ofra Amir", "title": "Local and Global Explanations of Agent Behavior: Integrating Strategy\n  Summaries with Saliency Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With advances in reinforcement learning (RL), agents are now being developed\nin high-stakes application domains such as healthcare and transportation.\nExplaining the behavior of these agents is challenging, as the environments in\nwhich they act have large state spaces, and their decision-making can be\naffected by delayed rewards, making it difficult to analyze their behavior. To\naddress this problem, several approaches have been developed. Some approaches\nattempt to convey the $\\textit{global}$ behavior of the agent, describing the\nactions it takes in different states. Other approaches devised $\\textit{local}$\nexplanations which provide information regarding the agent's decision-making in\na particular state. In this paper, we combine global and local explanation\nmethods, and evaluate their joint and separate contributions, providing (to the\nbest of our knowledge) the first user study of combined local and global\nexplanations for RL agents. Specifically, we augment strategy summaries that\nextract important trajectories of states from simulations of the agent with\nsaliency maps which show what information the agent attends to. Our results\nshow that the choice of what states to include in the summary (global\ninformation) strongly affects people's understanding of agents: participants\nshown summaries that included important states significantly outperformed\nparticipants who were presented with agent behavior in a randomly set of chosen\nworld-states. We find mixed results with respect to augmenting demonstrations\nwith saliency maps (local information), as the addition of saliency maps did\nnot significantly improve performance in most cases. However, we do find some\nevidence that saliency maps can help users better understand what information\nthe agent relies on in its decision making, suggesting avenues for future work\nthat can further improve explanations of RL agents.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:44:55 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 17:34:10 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 17:54:59 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Huber", "Tobias", ""], ["Weitz", "Katharina", ""], ["Andr\u00e9", "Elisabeth", ""], ["Amir", "Ofra", ""]]}, {"id": "2005.08879", "submitter": "Byoung-Hee Kwon", "authors": "Byoung-Hee Kwon, Ji-Hoon Jeong, Jeong-Hyun Cho, and Seong-Whan Lee", "title": "Decoding of Intuitive Visual Motion Imagery Using Convolutional Neural\n  Network under 3D-BCI Training Environment", "comments": "Submitted to IEEE International Conference on System, Man, and\n  Cybernetics (IEEE SMC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we adopted visual motion imagery, which is a more intuitive\nbrain-computer interface (BCI) paradigm, for decoding the intuitive user\nintention. We developed a 3-dimensional BCI training platform and applied it to\nassist the user in performing more intuitive imagination in the visual motion\nimagery experiment. The experimental tasks were selected based on the movements\nthat we commonly used in daily life, such as picking up a phone, opening a\ndoor, eating food, and pouring water. Nine subjects participated in our\nexperiment. We presented statistical evidence that visual motion imagery has a\nhigh correlation from the prefrontal and occipital lobes. In addition, we\nselected the most appropriate electroencephalography channels using a\nfunctional connectivity approach for visual motion imagery decoding and\nproposed a convolutional neural network architecture for classification. As a\nresult, the averaged classification performance of the proposed architecture\nfor 4 classes from 16 channels was 67.50 % across all subjects. This result is\nencouraging, and it shows the possibility of developing a BCI-based device\ncontrol system for practical applications such as neuroprosthesis and a robotic\narm.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 06:14:40 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Kwon", "Byoung-Hee", ""], ["Jeong", "Ji-Hoon", ""], ["Cho", "Jeong-Hyun", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2005.09165", "submitter": "Minhyeok Lee", "authors": "Minhyeok Lee, Junhee Seok", "title": "Regularization Methods for Generative Adversarial Networks: An Overview\n  of Recent Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its short history, Generative Adversarial Network (GAN) has been\nextensively studied and used for various tasks, including its original purpose,\ni.e., synthetic sample generation. However, applying GAN to different data\ntypes with diverse neural network architectures has been hindered by its\nlimitation in training, where the model easily diverges. Such a notorious\ntraining of GANs is well known and has been addressed in numerous studies.\nConsequently, in order to make the training of GAN stable, numerous\nregularization methods have been proposed in recent years. This paper reviews\nthe regularization methods that have been recently introduced, most of which\nhave been published in the last three years. Specifically, we focus on general\nmethods that can be commonly used regardless of neural network architectures.\nTo explore the latest research trends in the regularization for GANs, the\nmethods are classified into several groups by their operation principles, and\nthe differences between the methods are analyzed. Furthermore, to provide\npractical knowledge of using these methods, we investigate popular methods that\nhave been frequently employed in state-of-the-art GANs. In addition, we discuss\nthe limitations in existing methods and propose future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 01:59:24 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Lee", "Minhyeok", ""], ["Seok", "Junhee", ""]]}, {"id": "2005.09319", "submitter": "Albert Zeyer", "authors": "Albert Zeyer, Andr\\'e Merboldt, Ralf Schl\\\"uter, Hermann Ney", "title": "A New Training Pipeline for an Improved Neural Transducer", "comments": "published at Interspeech 2020", "journal-ref": null, "doi": "10.21437/Interspeech.2020-1855", "report-no": null, "categories": "eess.AS cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The RNN transducer is a promising end-to-end model candidate. We compare the\noriginal training criterion with the full marginalization over all alignments,\nto the commonly used maximum approximation, which simplifies, improves and\nspeeds up our training. We also generalize from the original neural network\nmodel and study more powerful models, made possible due to the maximum\napproximation. We further generalize the output label topology to cover RNN-T,\nRNA and CTC. We perform several studies among all these aspects, including a\nstudy on the effect of external alignments. We find that the transducer model\ngeneralizes much better on longer sequences than the attention model. Our final\ntransducer model outperforms our attention model on Switchboard 300h by over 6%\nrelative WER.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:35:38 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 22:13:01 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Zeyer", "Albert", ""], ["Merboldt", "Andr\u00e9", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.09330", "submitter": "Zhixin Liu", "authors": "Mingxiang Chen, Lei Gao, Qichang Chen, Zhixin Liu", "title": "Dynamic Partial Removal: A Neural Network Heuristic for Large\n  Neighborhood Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel neural network design that learns the heuristic\nfor Large Neighborhood Search (LNS). LNS consists of a destroy operator and a\nrepair operator that specify a way to carry out the neighborhood search to\nsolve the Combinatorial Optimization problems. The proposed approach in this\npaper applies a Hierarchical Recurrent Graph Convolutional Network (HRGCN) as a\nLNS heuristic, namely Dynamic Partial Removal, with the advantage of adaptive\ndestruction and the potential to search across a large scale, as well as the\ncontext-awareness in both spatial and temporal perspective. This model is\ngeneralized as an efficient heuristic approach to different combinatorial\noptimization problems, especially to the problems with relatively tight\nconstraints. We apply this model to vehicle routing problem (VRP) in this paper\nas an example. The experimental results show that this approach outperforms the\ntraditional LNS heuristics on the same problem as well. The source code is\navailable at\n\\href{https://github.com/water-mirror/DPR}{https://github.com/water-mirror/DPR}.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:50:35 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Chen", "Mingxiang", ""], ["Gao", "Lei", ""], ["Chen", "Qichang", ""], ["Liu", "Zhixin", ""]]}, {"id": "2005.09336", "submitter": "Albert Zeyer", "authors": "Mohammad Zeineldeen, Albert Zeyer, Wei Zhou, Thomas Ng, Ralf\n  Schl\\\"uter, Hermann Ney", "title": "A systematic comparison of grapheme-based vs. phoneme-based label units\n  for encoder-decoder-attention models", "comments": "5 pages, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the rationale of end-to-end modeling, CTC, RNN-T or\nencoder-decoder-attention models for automatic speech recognition (ASR) use\ngraphemes or grapheme-based subword units based on e.g. byte-pair encoding\n(BPE). The mapping from pronunciation to spelling is learned completely from\ndata. In contrast to this, classical approaches to ASR employ secondary\nknowledge sources in the form of phoneme lists to define phonetic output labels\nand pronunciation lexica. In this work, we do a systematic comparison between\ngrapheme- and phoneme-based output labels for an encoder-decoder-attention ASR\nmodel. We investigate the use of single phonemes as well as BPE-based phoneme\ngroups as output labels of our model. To preserve a simplified and efficient\ndecoder design, we also extend the phoneme set by auxiliary units to be able to\ndistinguish homophones. Experiments performed on the Switchboard 300h and\nLibriSpeech benchmarks show that phoneme-based modeling is competitive to\ngrapheme-based encoder-decoder-attention modeling.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 09:54:17 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 22:05:17 GMT"}, {"version": "v3", "created": "Thu, 15 Apr 2021 16:59:10 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Zeineldeen", "Mohammad", ""], ["Zeyer", "Albert", ""], ["Zhou", "Wei", ""], ["Ng", "Thomas", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2005.09380", "submitter": "J{\\o}rgen Nordmoen", "authors": "J{\\o}rgen Nordmoen, T{\\o}nnes Frostad Nygaard, Eivind Samuelsen and\n  Kyrre Glette", "title": "On Restricting Real-Valued Genotypes in Evolutionary Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-valued genotypes together with the variation operators, mutation and\ncrossover, constitute some of the fundamental building blocks of Evolutionary\nAlgorithms. Real-valued genotypes are utilized in a broad range of contexts,\nfrom weights in Artificial Neural Networks to parameters in robot control\nsystems. Shared between most uses of real-valued genomes is the need for\nlimiting the range of individual parameters to allowable bounds. In this paper\nwe will illustrate the challenge of limiting the parameters of real-valued\ngenomes and analyse the most promising method to properly limit these values.\nWe utilize both empirical as well as benchmark examples to demonstrate the\nutility of the proposed method and through a literature review show how the\ninsight of this paper could impact other research within the field. The\nproposed method requires minimal intervention from Evolutionary Algorithm\npractitioners and behaves well under repeated application of variation\noperators, leading to better theoretical properties as well as significant\ndifferences in well-known benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 11:58:40 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Nordmoen", "J\u00f8rgen", ""], ["Nygaard", "T\u00f8nnes Frostad", ""], ["Samuelsen", "Eivind", ""], ["Glette", "Kyrre", ""]]}, {"id": "2005.09512", "submitter": "Frederico Gadelha Guimaraes", "authors": "Leonardo Augusto Ferreira and Frederico Gadelha Guimar\\~aes and\n  Rodrigo Silva", "title": "Applying Genetic Programming to Improve Interpretability in Machine\n  Learning Models", "comments": "8 pages, 8 figures, submitted and accepted to 2020 IEEE Congress on\n  Evolutionary Computation (IEEE CEC 2020). Copyright 2020 IEEE. Personal use\n  of this material is permitted. Permission from IEEE must be obtained for all\n  other uses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable Artificial Intelligence (or xAI) has become an important research\ntopic in the fields of Machine Learning and Deep Learning. In this paper, we\npropose a Genetic Programming (GP) based approach, named Genetic Programming\nExplainer (GPX), to the problem of explaining decisions computed by AI systems.\nThe method generates a noise set located in the neighborhood of the point of\ninterest, whose prediction should be explained, and fits a local explanation\nmodel for the analyzed sample. The tree structure generated by GPX provides a\ncomprehensible analytical, possibly non-linear, symbolic expression which\nreflects the local behavior of the complex model. We considered three machine\nlearning techniques that can be recognized as complex black-box models: Random\nForest, Deep Neural Network and Support Vector Machine in twenty data sets for\nregression and classifications problems. Our results indicate that the GPX is\nable to produce more accurate understanding of complex models than the state of\nthe art. The results validate the proposed approach as a novel way to deploy GP\nto improve interpretability.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2020 16:09:49 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ferreira", "Leonardo Augusto", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""], ["Silva", "Rodrigo", ""]]}, {"id": "2005.09526", "submitter": "Jawar Singh Dr.", "authors": "Abhash Kumar, Jawar Singh, Sai Manohar Beeraka, and Bharat Gupta", "title": "In-memory Implementation of On-chip Trainable and Scalable ANN for AI/ML\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional von Neumann architecture based processors become inefficient in\nterms of energy and throughput as they involve separate processing and memory\nunits, also known as~\\textit{memory wall}. The memory wall problem is further\nexacerbated when massive parallelism and frequent data movement are required\nbetween processing and memory units for real-time implementation of artificial\nneural network (ANN) that enables many intelligent applications. One of the\nmost promising approach to address the memory wall problem is to carry out\ncomputations inside the memory core itself that enhances the memory bandwidth\nand energy efficiency for extensive computations. This paper presents an\nin-memory computing architecture for ANN enabling artificial intelligence (AI)\nand machine learning (ML) applications. The proposed architecture utilizes deep\nin-memory architecture based on standard six transistor (6T) static random\naccess memory (SRAM) core for the implementation of a multi-layered perceptron.\nOur novel on-chip training and inference in-memory architecture reduces energy\ncost and enhances throughput by simultaneously accessing the multiple rows of\nSRAM array per precharge cycle and eliminating the frequent access of data. The\nproposed architecture realizes backpropagation which is the keystone during the\nnetwork training using newly proposed different building blocks such as weight\nupdation, analog multiplication, error calculation, signed analog to digital\nconversion, and other necessary signal control units. The proposed architecture\nwas trained and tested on the IRIS dataset which exhibits $\\approx46\\times$\nmore energy efficient per MAC (multiply and accumulate) operation compared to\nearlier classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 15:36:39 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Kumar", "Abhash", ""], ["Singh", "Jawar", ""], ["Beeraka", "Sai Manohar", ""], ["Gupta", "Bharat", ""]]}, {"id": "2005.09551", "submitter": "Zahid Iqbal", "authors": "Zahid Iqbal, Waseem Shahzad", "title": "A Diverse Clustering Particle Swarm Optimizer for Dynamic Environment:\n  To Locate and Track Multiple Optima", "comments": "2018 IEEE Conference on Industrial Electronics and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real life, mostly problems are dynamic. Many algorithms have been proposed\nto handle the static problems, but these algorithms do not handle or poorly\nhandle the dynamic environment problems. Although, many algorithms have been\nproposed to handle dynamic problems but still, there are some limitations or\ndrawbacks in every algorithm regarding diversity of particles and tracking of\nalready found optima. To overcome these limitations/drawbacks, we have proposed\na new efficient algorithm to handle the dynamic environment effectively by\ntracking and locating multiple optima and by improving the diversity and\nconvergence speed of algorithm. In this algorithm, a new method has been\nproposed which explore the undiscovered areas of search space to increase the\ndiversity of algorithm. This algorithm also uses a method to effectively handle\nthe overlapped and overcrowded particles. Branke has proposed moving peak\nbenchmark which is commonly used MBP in literature. We also have performed\ndifferent experiments on Moving Peak Benchmark. After comparing the\nexperimental results with different state of art algorithms, it was seen that\nour algorithm performed more efficiently.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 16:12:40 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Iqbal", "Zahid", ""], ["Shahzad", "Waseem", ""]]}, {"id": "2005.10190", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Feature Purification: How Adversarial Training Performs Robust Deep\n  Learning", "comments": "v2 and V3 polish writing and experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the empirical success of using Adversarial Training to defend deep\nlearning models against adversarial perturbations, so far, it still remains\nrather unclear what the principles are behind the existence of adversarial\nperturbations, and what adversarial training does to the neural network to\nremove them.\n  In this paper, we present a principle that we call Feature Purification,\nwhere we show one of the causes of the existence of adversarial examples is the\naccumulation of certain small dense mixtures in the hidden weights during the\ntraining process of a neural network; and more importantly, one of the goals of\nadversarial training is to remove such mixtures to purify hidden weights. We\npresent both experiments on the CIFAR-10 dataset to illustrate this principle,\nand a theoretical result proving that for certain natural classification tasks,\ntraining a two-layer neural network with ReLU activation using randomly\ninitialized gradient descent indeed satisfies this principle.\n  Technically, we give, to the best of our knowledge, the first result proving\nthat the following two can hold simultaneously for training a neural network\nwith ReLU activation. (1) Training over the original data is indeed non-robust\nto small adversarial perturbations of some radius. (2) Adversarial training,\neven with an empirical perturbation algorithm such as FGM, can in fact be\nprovably robust against ANY perturbations of the same radius. Finally, we also\nprove a complexity lower bound, showing that low complexity models such as\nlinear classifiers, low-degree polynomials, or even the neural tangent kernel\nfor this network, CANNOT defend against perturbations of this same radius, no\nmatter what algorithms are used to train them.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2020 16:56:08 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 08:09:49 GMT"}, {"version": "v3", "created": "Sat, 3 Jul 2021 19:10:04 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2005.10851", "submitter": "Yinghan Long", "authors": "Yinghan Long, Indranil Chakraborty, Kaushik Roy", "title": "Conditionally Deep Hybrid Neural Networks Across Edge and Cloud", "comments": "6 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasiveness of \"Internet-of-Things\" in our daily life has led to a\nrecent surge in fog computing, encompassing a collaboration of cloud computing\nand edge intelligence. To that effect, deep learning has been a major driving\nforce towards enabling such intelligent systems. However, growing model sizes\nin deep learning pose a significant challenge towards deployment in\nresource-constrained edge devices. Moreover, in a distributed intelligence\nenvironment, efficient workload distribution is necessary between edge and\ncloud systems. To address these challenges, we propose a conditionally deep\nhybrid neural network for enabling AI-based fog computing. The proposed network\ncan be deployed in a distributed manner, consisting of quantized layers and\nearly exits at the edge and full-precision layers on the cloud. During\ninference, if an early exit has high confidence in the classification results,\nit would allow samples to exit at the edge, and the deeper layers on the cloud\nare activated conditionally, which can lead to improved energy efficiency and\ninference latency. We perform an extensive design space exploration with the\ngoal of minimizing energy consumption at the edge while achieving\nstate-of-the-art classification accuracies on image classification tasks. We\nshow that with binarized layers at the edge, the proposed conditional hybrid\nnetwork can process 65% of inferences at the edge, leading to 5.5x\ncomputational energy reduction with minimal accuracy degradation on CIFAR-10\ndataset. For the more complex dataset CIFAR-100, we observe that the proposed\nnetwork with 4-bit quantization at the edge achieves 52% early classification\nat the edge with 4.8x energy reduction. The analysis gives us insights on\ndesigning efficient hybrid networks which achieve significantly higher energy\nefficiency than full-precision networks for edge-cloud based distributed\nintelligence systems.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 18:18:43 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Long", "Yinghan", ""], ["Chakraborty", "Indranil", ""], ["Roy", "Kaushik", ""]]}, {"id": "2005.10904", "submitter": "James Aimone", "authors": "J. Darby Smith, William Severa, Aaron J. Hill, Leah Reeder, Brian\n  Franke, Richard B. Lehoucq, Ojas D. Parekh, and James B. Aimone", "title": "Solving a steady-state PDE using spiking networks and neuromorphic\n  hardware", "comments": "Submitted to 2020 International Conference on Neuromorphic Systems\n  (2020 ICONS)", "journal-ref": null, "doi": null, "report-no": "SAND2020-5296 O", "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widely parallel, spiking neural networks of neuromorphic processors can\nenable computationally powerful formulations. While recent interest has focused\non primarily machine learning tasks, the space of appropriate applications is\nwide and continually expanding. Here, we leverage the parallel and event-driven\nstructure to solve a steady state heat equation using a random walk method. The\nrandom walk can be executed fully within a spiking neural network using\nstochastic neuron behavior, and we provide results from both IBM TrueNorth and\nIntel Loihi implementations. Additionally, we position this algorithm as a\npotential scalable benchmark for neuromorphic systems.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2020 21:06:19 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Smith", "J. Darby", ""], ["Severa", "William", ""], ["Hill", "Aaron J.", ""], ["Reeder", "Leah", ""], ["Franke", "Brian", ""], ["Lehoucq", "Richard B.", ""], ["Parekh", "Ojas D.", ""], ["Aimone", "James B.", ""]]}, {"id": "2005.11074", "submitter": "George Kyriakides", "authors": "George Kyriakides and Konstantinos Margaritis", "title": "An Introduction to Neural Architecture Search for Convolutional Networks", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) is a research field concerned with utilizing\noptimization algorithms to design optimal neural network architectures. There\nare many approaches concerning the architectural search spaces, optimization\nalgorithms, as well as candidate architecture evaluation methods. As the field\nis growing at a continuously increasing pace, it is difficult for a beginner to\ndiscern between major, as well as emerging directions the field has followed.\nIn this work, we provide an introduction to the basic concepts of NAS for\nconvolutional networks, along with the major advances in search spaces,\nalgorithms and evaluation techniques.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:33:22 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Kyriakides", "George", ""], ["Margaritis", "Konstantinos", ""]]}, {"id": "2005.11106", "submitter": "Mostafa Kiani", "authors": "M. Kiani", "title": "On the suitability of generalized regression neural networks for GNSS\n  position time series prediction for geodetic applications in geodesy and\n  geophysics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, the generalized regression neural network is used to predict\nthe GNSS position time series. Using the IGS 24-hour final solution data for\nBad Hamburg permanent GNSS station in Germany, it is shown that the larger the\ntraining of the network, the higher the accuracy is, regardless of the time\nspan of the time series. In order to analyze the performance of the neural\nnetwork in various conditions, 14 permanent stations are used in different\ncountries, namely, Spain, France, Romania, Poland, Russian Federation, United\nKingdom, Czech Republic, Sweden, Ukraine, Italy, Finland, Slovak Republic,\nCyprus, and Greece. The performance analysis is divided into two parts,\ncontinuous data-without gaps-and discontinuous ones-having intervals of gaps\nwith no data available. Three measure of error are presented, namely, symmetric\nmean absolute percentage error, standard deviation, and mean of absolute\nerrors. It is shown that for discontinuous data the position can be predicted\nwith an accuracy of up to 6 centimeters, while the continuous data positions\npresent a higher prediction accuracy, as high as 3 centimeters. In order to\ncompare the results of this machine learning algorithm with the traditional\nstatistical approaches, the Theta method is used, which is well-established for\nhigh-accuracy time series prediction. The comparison shows that the generalized\nregression neural network machine learning algorithm presents better accuracy\nthan the Theta method, possibly up to 250 times. In addition, it is\napproximately 4.6 times faster.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 11:04:46 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Kiani", "M.", ""]]}, {"id": "2005.11203", "submitter": "Alex Pitti Dr", "authors": "Alexandre Pitti, Mathias Quoy, Catherine Lavandier, Sofiane Boucenna", "title": "Digital Neural Networks in the Brain: From Mechanisms for Extracting\n  Structure in the World To Self-Structuring the Brain Itself", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to keep trace of information, the brain has to resolve the problem\nwhere information is and how to index new ones. We propose that the neural\nmechanism used by the prefrontal cortex (PFC) to detect structure in temporal\nsequences, based on the temporal order of incoming information, has served as\nsecond purpose to the spatial ordering and indexing of brain networks. We call\nthis process, apparent to the manipulation of neural 'addresses' to organize\nthe brain's own network, the 'digitalization' of information. Such tool is\nimportant for information processing and preservation, but also for memory\nformation and retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 14:29:51 GMT"}], "update_date": "2020-05-25", "authors_parsed": [["Pitti", "Alexandre", ""], ["Quoy", "Mathias", ""], ["Lavandier", "Catherine", ""], ["Boucenna", "Sofiane", ""]]}, {"id": "2005.11387", "submitter": "Aydogan Ozcan", "authors": "Jingxi Li, Deniz Mengu, Nezih T. Yardimci, Yi Luo, Xurong Li, Muhammed\n  Veli, Yair Rivenson, Mona Jarrahi, Aydogan Ozcan", "title": "Spectrally-Encoded Single-Pixel Machine Vision Using Diffractive\n  Networks", "comments": "21 pages, 5 figures, 1 table", "journal-ref": "Science Advances (2021)", "doi": "10.1126/sciadv.abd7690", "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D engineering of matter has opened up new avenues for designing systems that\ncan perform various computational tasks through light-matter interaction. Here,\nwe demonstrate the design of optical networks in the form of multiple\ndiffractive layers that are trained using deep learning to transform and encode\nthe spatial information of objects into the power spectrum of the diffracted\nlight, which are used to perform optical classification of objects with a\nsingle-pixel spectroscopic detector. Using a time-domain spectroscopy setup\nwith a plasmonic nanoantenna-based detector, we experimentally validated this\nmachine vision framework at terahertz spectrum to optically classify the images\nof handwritten digits by detecting the spectral power of the diffracted light\nat ten distinct wavelengths, each representing one class/digit. We also report\nthe coupling of this spectral encoding achieved through a diffractive optical\nnetwork with a shallow electronic neural network, separately trained to\nreconstruct the images of handwritten digits based on solely the spectral\ninformation encoded in these ten distinct wavelengths within the diffracted\nlight. These reconstructed images demonstrate task-specific image decompression\nand can also be cycled back as new inputs to the same diffractive network to\nimprove its optical object classification. This unique machine vision framework\nmerges the power of deep learning with the spatial and spectral processing\ncapabilities of diffractive networks, and can also be extended to other\nspectral-domain measurement systems to enable new 3D imaging and sensing\nmodalities integrated with spectrally encoded classification tasks performed\nthrough diffractive optical networks.\n", "versions": [{"version": "v1", "created": "Fri, 15 May 2020 09:18:21 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2021 04:48:42 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Li", "Jingxi", ""], ["Mengu", "Deniz", ""], ["Yardimci", "Nezih T.", ""], ["Luo", "Yi", ""], ["Li", "Xurong", ""], ["Veli", "Muhammed", ""], ["Rivenson", "Yair", ""], ["Jarrahi", "Mona", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2005.11464", "submitter": "Aydogan Ozcan", "authors": "Deniz Mengu, Yifan Zhao, Nezih T. Yardimci, Yair Rivenson, Mona\n  Jarrahi, Aydogan Ozcan", "title": "Misalignment Resilient Diffractive Optical Networks", "comments": "15 Pages, 6 Figures", "journal-ref": "Nanophotonics (2020)", "doi": "10.1515/nanoph-2020-0291", "report-no": null, "categories": "eess.IV cs.NE physics.comp-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an optical machine learning framework, Diffractive Deep Neural Networks\n(D2NN) take advantage of data-driven training methods used in deep learning to\ndevise light-matter interaction in 3D for performing a desired statistical\ninference task. Multi-layer optical object recognition platforms designed with\nthis diffractive framework have been shown to generalize to unseen image data\nachieving e.g., >98% blind inference accuracy for hand-written digit\nclassification. The multi-layer structure of diffractive networks offers\nsignificant advantages in terms of their diffraction efficiency, inference\ncapability and optical signal contrast. However, the use of multiple\ndiffractive layers also brings practical challenges for the fabrication and\nalignment of these diffractive systems for accurate optical inference. Here, we\nintroduce and experimentally demonstrate a new training scheme that\nsignificantly increases the robustness of diffractive networks against 3D\nmisalignments and fabrication tolerances in the physical implementation of a\ntrained diffractive network. By modeling the undesired layer-to-layer\nmisalignments in 3D as continuous random variables in the optical forward\nmodel, diffractive networks are trained to maintain their inference accuracy\nover a large range of misalignments; we term this diffractive network design as\nvaccinated D2NN (v-D2NN). We further extend this vaccination strategy to the\ntraining of diffractive networks that use differential detectors at the output\nplane as well as to jointly-trained hybrid (optical-electronic) networks to\nreveal that all of these diffractive designs improve their resilience to\nmisalignments by taking into account possible 3D fabrication variations and\ndisplacements during their training phase.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 04:22:48 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Mengu", "Deniz", ""], ["Zhao", "Yifan", ""], ["Yardimci", "Nezih T.", ""], ["Rivenson", "Yair", ""], ["Jarrahi", "Mona", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2005.11580", "submitter": "Honglin Bao", "authors": "Honglin Bao and Wolfgang Banzhaf", "title": "Evolution of Cooperative Hunting in Artificial Multi-layered Societies", "comments": "Conflict of interest with our previous collaborators. Thus, we\n  retract the preprint. We retract all earlier versions of the paper as well,\n  but due to the arXiv policy, previous versions cannot be removed. We ask that\n  you ignore the abstract, earlier versions and do not refer to or distribute\n  them further, and we apologize for any inconvenience caused. Thanks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.NE nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of cooperative behavior is a crucial issue in multiagent-based\nsocial simulation. In this paper, an agent-based model is proposed to study the\nevolution of cooperative hunting behaviors in an artificial society. In this\nmodel, the standard hunting game of stag is modified into a new situation with\nsocial hierarchy and penalty. The agent society is divided into multiple layers\nwith supervisors and subordinates. In each layer, the society is divided into\nmultiple clusters. A supervisor controls all subordinates in a cluster locally.\nSubordinates interact with rivals through reinforcement learning, and report\nlearning information to their corresponding supervisor. Supervisors process the\nreported information through repeated affiliation-based aggregation and by\ninformation exchange with other supervisors, then pass down the reprocessed\ninformation to subordinates as guidance. Subordinates, in turn, update learning\ninformation according to guidance, following the \"win stay, lose shift\"\nstrategy. Experiments are carried out to test the evolution of cooperation in\nthis closed-loop semi-supervised emergent system with different parameters. We\nalso study the variations and phase transitions in this game setting.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 18:23:04 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 14:08:15 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 17:14:40 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 18:51:05 GMT"}, {"version": "v5", "created": "Fri, 15 Jan 2021 19:43:23 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Bao", "Honglin", ""], ["Banzhaf", "Wolfgang", ""]]}, {"id": "2005.11600", "submitter": "Ke Li Kl", "authors": "Ke Li, Haifeng Nie, Huifu Gao, Xin Yao", "title": "Knee Point Identification Based on Trade-Off Utility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knee points, characterised as their smallest trade-off loss at all\nobjectives, are attractive to decision makers in multi-criterion\ndecision-making. In contrast, other Pareto-optimal solutions are less\nattractive since a small improvement on one objective can lead to a significant\ndegradation on at least one of the other objectives. In this paper, we propose\na simple and effective knee point identification method based on trade-off\nutility, dubbed KPITU, to help decision makers identify knee points from a\ngiven set of trade-off solutions. The basic idea of KPITU is to sequentially\nvalidate whether a solution is a knee point or not by comparing its trade-off\nutility with others within its neighbourhood. In particular, a solution is a\nknee point if and only if it has the best trade-off utility among its\nneighbours. Moreover, we implement a GPU version of KPITU that carries out the\nknee point identification in a parallel manner. This GPU version reduces the\nworst-case complexity from quadratic to linear. To validate the effectiveness\nof KPITU, we compare its performance with five state-of-the-art knee point\nidentification methods on 134 test problem instances. Empirical results fully\ndemonstrate the outstanding performance of KPITU especially on problems with\nmany local knee points. At the end, we further validate the usefulness of KPITU\nfor guiding EMO algorithms to search for knee points on the fly during the\nevolutionary process.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 21:05:00 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Li", "Ke", ""], ["Nie", "Haifeng", ""], ["Gao", "Huifu", ""], ["Yao", "Xin", ""]]}, {"id": "2005.11603", "submitter": "Guruprasad Raghavan", "authors": "Guruprasad Raghavan, Jiayi Li, Matt Thomson", "title": "Geometric algorithms for predicting resilience and recovering damage in\n  neural networks", "comments": "10 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological neural networks have evolved to maintain performance despite\nsignificant circuit damage. To survive damage, biological network architectures\nhave both intrinsic resilience to component loss and also activate recovery\nprograms that adjust network weights through plasticity to stabilize\nperformance. Despite the importance of resilience in technology applications,\nthe resilience of artificial neural networks is poorly understood, and\nautonomous recovery algorithms have yet to be developed. In this paper, we\nestablish a mathematical framework to analyze the resilience of artificial\nneural networks through the lens of differential geometry. Our geometric\nlanguage provides natural algorithms that identify local vulnerabilities in\ntrained networks as well as recovery algorithms that dynamically adjust\nnetworks to compensate for damage. We reveal striking vulnerabilities in\ncommonly used image analysis networks, like MLP's and CNN's trained on MNIST\nand CIFAR10 respectively. We also uncover high-performance recovery paths that\nenable the same networks to dynamically re-adjust their parameters to\ncompensate for damage. Broadly, our work provides procedures that endow\nartificial systems with resilience and rapid-recovery routines to enhance their\nintegration with IoT devices as well as enable their deployment for critical\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2020 21:13:26 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 19:20:49 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Raghavan", "Guruprasad", ""], ["Li", "Jiayi", ""], ["Thomson", "Matt", ""]]}, {"id": "2005.11633", "submitter": "Bojian Yin", "authors": "Bojian Yin, Federico Corradi, Sander M. Boht\\'e", "title": "Effective and Efficient Computation with Multiple-timescale Spiking\n  Recurrent Neural Networks", "comments": "11 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of brain-inspired neuromorphic computing as a paradigm for edge\nAI is motivating the search for high-performance and efficient spiking neural\nnetworks to run on this hardware. However, compared to classical neural\nnetworks in deep learning, current spiking neural networks lack competitive\nperformance in compelling areas. Here, for sequential and streaming tasks, we\ndemonstrate how a novel type of adaptive spiking recurrent neural network\n(SRNN) is able to achieve state-of-the-art performance compared to other\nspiking neural networks and almost reach or exceed the performance of classical\nrecurrent neural networks (RNNs) while exhibiting sparse activity. From this,\nwe calculate a $>$100x energy improvement for our SRNNs over classical RNNs on\nthe harder tasks. To achieve this, we model standard and adaptive\nmultiple-timescale spiking neurons as self-recurrent neural units, and leverage\nsurrogate gradients and auto-differentiation in the PyTorch Deep Learning\nframework to efficiently implement backpropagation-through-time, including\nlearning of the important spiking neuron parameters to adapt our spiking\nneurons to the tasks.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 01:04:53 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:12:49 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Yin", "Bojian", ""], ["Corradi", "Federico", ""], ["Boht\u00e9", "Sander M.", ""]]}, {"id": "2005.11689", "submitter": "Ralf M\\\"oller", "authors": "Ralf M\\\"oller", "title": "Derivation of Symmetric PCA Learning Rules from a Novel Objective\n  Function", "comments": "Added a paragraph to section 'Conclusion' describing a disadvantage\n  of the novel learning rules", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural learning rules for principal component / subspace analysis (PCA / PSA)\ncan be derived by maximizing an objective function (summed variance of the\nprojection on the subspace axes) under an orthonormality constraint. For a\nsubspace with a single axis, the optimization produces the principal\neigenvector of the data covariance matrix. Hierarchical learning rules with\ndeflation procedures can then be used to extract multiple eigenvectors.\nHowever, for a subspace with multiple axes, the optimization leads to PSA\nlearning rules which only converge to axes spanning the principal subspace but\nnot to the principal eigenvectors. A modified objective function with distinct\nweight factors had to be introduced produce PCA learning rules. Optimization of\nthe objective function for multiple axes leads to symmetric learning rules\nwhich do not require deflation procedures. For the PCA case, the estimated\nprincipal eigenvectors are ordered (w.r.t. the corresponding eigenvalues)\ndepending on the order of the weight factors.\n  Here we introduce an alternative objective function where it is not necessary\nto introduce fixed weight factors; instead, the alternative objective function\nuses squared summands. Optimization leads to symmetric PCA learning rules which\nconverge to the principal eigenvectors, but without imposing an order. In place\nof the diagonal matrices with fixed weight factors, variable diagonal matrices\nappear in the learning rules. We analyze this alternative approach by\ndetermining the fixed points of the constrained optimization. The behavior of\nthe constrained objective function at the fixed points is analyzed which\nconfirms both the PCA behavior and the fact that no order is imposed. Different\nways to derive learning rules from the optimization of the objective function\nare presented. The role of the terms in the learning rules obtained from these\nderivations is explored.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 08:57:54 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 06:22:43 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["M\u00f6ller", "Ralf", ""]]}, {"id": "2005.11699", "submitter": "Andrei Ivanov", "authors": "Andrei Ivanov, Uwe Iben, Anna Golovkina", "title": "Physics-based polynomial neural networks for one-shot learning of\n  dynamical systems from one or a few samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.DS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an approach for incorporating prior physical knowledge\ninto the neural network to improve data efficiency and the generalization of\npredictive models. If the dynamics of a system approximately follows a given\ndifferential equation, the Taylor mapping method can be used to initialize the\nweights of a polynomial neural network. This allows the fine-tuning of the\nmodel from one training sample of real system dynamics. The paper describes\npractical results on real experiments with both a simple pendulum and one of\nthe largest worldwide X-ray source. It is demonstrated in practice that the\nproposed approach allows recovering complex physics from noisy, limited, and\npartial observations and provides meaningful predictions for previously unseen\ninputs. The approach mainly targets the learning of physical systems when\nstate-of-the-art models are difficult to apply given the lack of training data.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 09:27:10 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 07:44:33 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Ivanov", "Andrei", ""], ["Iben", "Uwe", ""], ["Golovkina", "Anna", ""]]}, {"id": "2005.12270", "submitter": "Miad Zandavi Mr", "authors": "Seid Miad Zandavi, Taha Hossein Rashidi, Fatemeh Vafaee", "title": "Forecasting the Spread of Covid-19 Under Control Scenarios Using LSTM\n  and Dynamic Behavioral Models", "comments": "As requested by the dear moderator, to assess the statistical\n  significance of the reduction in RMSE in hybrid models compared to LSTM, each\n  module was evaluated 500 times after hype-parameter tuning, and the\n  corresponding RMSE distribution was used to estimate 95% confidence interval\n  (CI) and t-test p-values comparing significant differences between different\n  stages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accurately predict the regional spread of Covid-19 infection, this study\nproposes a novel hybrid model which combines a Long short-term memory (LSTM)\nartificial recurrent neural network with dynamic behavioral models. Several\nfactors and control strategies affect the virus spread, and the uncertainty\narisen from confounding variables underlying the spread of the Covid-19\ninfection is substantial. The proposed model considers the effect of multiple\nfactors to enhance the accuracy in predicting the number of cases and deaths\nacross the top ten most-affected countries and Australia. The results show that\nthe proposed model closely replicates test data. It not only provides accurate\npredictions but also estimates the daily behavior of the system under\nuncertainty. The hybrid model outperforms the LSTM model accounting for limited\navailable data. The parameters of the hybrid models were optimized using a\ngenetic algorithm for each country to improve the prediction power while\nconsidering regional properties. Since the proposed model can accurately\npredict Covid-19 spread under consideration of containment policies, is capable\nof being used for policy assessment, planning and decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 10:43:55 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Zandavi", "Seid Miad", ""], ["Rashidi", "Taha Hossein", ""], ["Vafaee", "Fatemeh", ""]]}, {"id": "2005.12330", "submitter": "Alessandro Ingrosso", "authors": "Alessandro Ingrosso", "title": "Optimal Learning with Excitatory and Inhibitory synapses", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1008536", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the relation between weight structure and input/output\nstatistics is fundamental for understanding the computational capabilities of\nneural circuits. In this work, I study the problem of storing associations\nbetween analog signals in the presence of correlations, using methods from\nstatistical mechanics. I characterize the typical learning performance in terms\nof the power spectrum of random input and output processes. I show that optimal\nsynaptic weight configurations reach a capacity of 0.5 for any fraction of\nexcitatory to inhibitory weights and have a peculiar synaptic distribution with\na finite fraction of silent synapses. I further provide a link between typical\nlearning performance and principal components analysis in single cases. These\nresults may shed light on the synaptic profile of brain circuits, such as\ncerebellar structures, that are thought to engage in processing time-dependent\nsignals and performing on-line prediction.\n", "versions": [{"version": "v1", "created": "Mon, 25 May 2020 18:25:54 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Ingrosso", "Alessandro", ""]]}, {"id": "2005.12553", "submitter": "Chang Wang", "authors": "Hao Chen, Chang Wang, Jian Huang, Jianxing Gong", "title": "Efficient Use of heuristics for accelerating XCS-based Policy Learning\n  in Markov Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Markov games, playing against non-stationary opponents with learning\nability is still challenging for reinforcement learning (RL) agents, because\nthe opponents can evolve their policies concurrently. This increases the\ncomplexity of the learning task and slows down the learning speed of the RL\nagents. This paper proposes efficient use of rough heuristics to speed up\npolicy learning when playing against concurrent learners. Specifically, we\npropose an algorithm that can efficiently learn explainable and generalized\naction selection rules by taking advantages of the representation of\nquantitative heuristics and an opponent model with an eXtended classifier\nsystem (XCS) in zero-sum Markov games. A neural network is used to model the\nopponent from their behaviors and the corresponding policy is inferred for\naction selection and rule evolution. In cases of multiple heuristic policies,\nwe introduce the concept of Pareto optimality for action selection. Besides,\ntaking advantages of the condition representation and matching mechanism of\nXCS, the heuristic policies and the opponent model can provide guidance for\nsituations with similar feature representation. Furthermore, we introduce an\naccuracy-based eligibility trace mechanism to speed up rule evolution, i.e.,\nclassifiers that can match the historical traces are reinforced according to\ntheir accuracy. We demonstrate the advantages of the proposed algorithm over\nseveral benchmark algorithms in a soccer and a thief-and-hunter scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 07:47:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Chen", "Hao", ""], ["Wang", "Chang", ""], ["Huang", "Jian", ""], ["Gong", "Jianxing", ""]]}, {"id": "2005.12557", "submitter": "Stuart Watt", "authors": "Stuart Watt and Mikhail Kostylev", "title": "Spoken digit classification using a spin-wave delay-line active-ring\n  reservoir computing", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a test of general applicability, we use the recently proposed spin-wave\ndelay line active-ring reservoir computer to perform the spoken digit\nrecognition task. On this, classification accuracies of up to 93% are achieved.\nThe tested device prototype employs improved spin wave transducers (antennas).\nTherefore, in addition, we also let the computer complete the short-term memory\n(STM) task and the parity check (PC) tasks, because the fading memory and\nnonlinearity are essential to reservoir computing performance. The resulting\nSTM and PC capacities reach maximum values of 4.77 and 1.47 respectively.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 07:53:15 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Watt", "Stuart", ""], ["Kostylev", "Mikhail", ""]]}, {"id": "2005.12826", "submitter": "Tao Liu", "authors": "Tao Liu", "title": "BHN: A Brain-like Heterogeneous Network", "comments": "Improve the readability, and add an image experiment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain works in an unsupervised way, and more than one brain region\nis essential for lighting up intelligence. Inspired by this, we propose a\nbrain-like heterogeneous network (BHN), which can cooperatively learn a lot of\ndistributed representations and one global attention representation. By\noptimizing distributed, self-supervised, and gradient-isolated objective\nfunctions in a minimax fashion, our model improves its representations, which\nare generated from patches of pictures or frames of videos in experiments.\n", "versions": [{"version": "v1", "created": "Tue, 26 May 2020 16:02:38 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 09:07:15 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Liu", "Tao", ""]]}, {"id": "2005.12833", "submitter": "Laila Rasmy", "authors": "Laila Rasmy, Yang Xiang, Ziqian Xie, Cui Tao and Degui Zhi", "title": "Med-BERT: pre-trained contextualized embeddings on large-scale\n  structured electronic health records for disease prediction", "comments": "L.R., X.Y., and Z.X. share first authorship of this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) based predictive models from electronic health records\n(EHR) deliver impressive performance in many clinical tasks. Large training\ncohorts, however, are often required to achieve high accuracy, hindering the\nadoption of DL-based models in scenarios with limited training data size.\nRecently, bidirectional encoder representations from transformers (BERT) and\nrelated models have achieved tremendous successes in the natural language\nprocessing domain. The pre-training of BERT on a very large training corpus\ngenerates contextualized embeddings that can boost the performance of models\ntrained on smaller datasets. We propose Med-BERT, which adapts the BERT\nframework for pre-training contextualized embedding models on structured\ndiagnosis data from 28,490,650 patients EHR dataset. Fine-tuning experiments\nare conducted on two disease-prediction tasks: (1) prediction of heart failure\nin patients with diabetes and (2) prediction of pancreatic cancer from two\nclinical databases. Med-BERT substantially improves prediction accuracy,\nboosting the area under receiver operating characteristics curve (AUC) by\n2.02-7.12%. In particular, pre-trained Med-BERT substantially improves the\nperformance of tasks with very small fine-tuning training sets (300-500\nsamples) boosting the AUC by more than 20% or equivalent to the AUC of 10 times\nlarger training set. We believe that Med-BERT will benefit disease-prediction\nstudies with small local training datasets, reduce data collection expenses,\nand accelerate the pace of artificial intelligence aided healthcare.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 05:07:17 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Rasmy", "Laila", ""], ["Xiang", "Yang", ""], ["Xie", "Ziqian", ""], ["Tao", "Cui", ""], ["Zhi", "Degui", ""]]}, {"id": "2005.12841", "submitter": "Antonio Prestes Garcia", "authors": "Antonio Prestes Garc\\'ia and Alfonso Rodr\\'iguez-Pat\\'on", "title": "Applying Evolutionary Metaheuristics for Parameter Estimation of\n  Individual-Based Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual-based models are complex and they have usually an elevated number\nof input parameters which must be tuned for reproducing the observed population\ndata or the experimental results as accurately as possible. Thus, one of the\nweakest points of this modelling approach lies on the fact that rarely the\nmodeler has the enough information about the correct values or even the\nacceptable range for the input parameters. Consequently, several parameter\ncombinations must be tried to find an acceptable set of input factors\nminimizing the deviations of simulated and the reference dataset. In practice,\nmost of times, it is computationally unfeasible to traverse the complete search\nspace trying all every possible combination to find the best of set of\nparameters. That is precisely an instance of a combinatorial problem which is\nsuitable for being solved by metaheuristics and evolutionary computation\ntechniques. In this work, we introduce EvoPER, an R package for simplifying the\nparameter estimation using evolutionary computation methods.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2020 07:48:27 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Garc\u00eda", "Antonio Prestes", ""], ["Rodr\u00edguez-Pat\u00f3n", "Alfonso", ""]]}, {"id": "2005.13095", "submitter": "Nilufer Tuptuk", "authors": "Nilufer Tuptuk and Stephen Hailes", "title": "Identifying Vulnerabilities of Industrial Control Systems using\n  Evolutionary Multiobjective Optimisation", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel methodology to assist in identifying\nvulnerabilities in a real-world complex heterogeneous industrial control\nsystems (ICS) using two evolutionary multiobjective optimisation (EMO)\nalgorithms, NSGA-II and SPEA2. Our approach is evaluated on a well known\nbenchmark chemical plant simulator, the Tennessee Eastman (TE) process model.\nWe identified vulnerabilities in individual components of the TE model and then\nmade use of these to generate combinatorial attacks to damage the safety of the\nsystem, and to cause economic loss. Results were compared against random\nattacks, and the performance of the EMO algorithms were evaluated using\nhypervolume, spread and inverted generational distance (IGD) metrics. A defence\nagainst these attacks in the form of a novel intrusion detection system was\ndeveloped, using a number of machine learning algorithms. Designed approach was\nfurther tested against the developed detection methods. Results demonstrate\nthat EMO algorithms are a promising tool in the identification of the most\nvulnerable components of ICS, and weaknesses of any existing detection systems\nin place to protect the system. The proposed approach can be used by control\nand security engineers to design security aware control, and test the\neffectiveness of security mechanisms, both during design, and later during\nsystem operation.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:22:48 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Tuptuk", "Nilufer", ""], ["Hailes", "Stephen", ""]]}, {"id": "2005.13105", "submitter": "Mee Seong Im", "authors": "Mee Seong Im, Venkat R. Dasari", "title": "Genetic optimization algorithms applied toward mission computability\n  models", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic algorithms are modeled after the biological evolutionary processes\nthat use natural selection to select the best species to survive. They are\nheuristics based and low cost to compute. Genetic algorithms use selection,\ncrossover, and mutation to obtain a feasible solution to computational\nproblems. In this paper, we describe our genetic optimization algorithms to a\nmission-critical and constraints-aware computation problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 00:45:24 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Im", "Mee Seong", ""], ["Dasari", "Venkat R.", ""]]}, {"id": "2005.13110", "submitter": "Clifford Broni-Bediako", "authors": "Clifford Broni-Bediako, Yuki Murata, Luiz Henrique Mormille and\n  Masayasu Atsumi", "title": "Evolutionary NAS with Gene Expression Programming of Cellular Encoding", "comments": "Accepted at IEEE SSCI 2020 (7 pages, 3 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The renaissance of neural architecture search (NAS) has seen classical\nmethods such as genetic algorithms (GA) and genetic programming (GP) being\nexploited for convolutional neural network (CNN) architectures. While recent\nwork have achieved promising performance on visual perception tasks, the direct\nencoding scheme of both GA and GP has functional complexity deficiency and does\nnot scale well on large architectures like CNN. To address this, we present a\nnew generative encoding scheme -- $symbolic\\ linear\\ generative\\ encoding$\n(SLGE) -- simple, yet powerful scheme which embeds local graph transformations\nin chromosomes of linear fixed-length string to develop CNN architectures of\nvariant shapes and sizes via evolutionary process of gene expression\nprogramming. In experiments, the effectiveness of SLGE is shown in discovering\narchitectures that improve the performance of the state-of-the-art handcrafted\nCNN architectures on CIFAR-10 and CIFAR-100 image classification tasks; and\nachieves a competitive classification error rate with the existing NAS methods\nusing less GPU resources.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 01:19:32 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 15:41:20 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Broni-Bediako", "Clifford", ""], ["Murata", "Yuki", ""], ["Mormille", "Luiz Henrique", ""], ["Atsumi", "Masayasu", ""]]}, {"id": "2005.13594", "submitter": "Ahmad Hoorfar", "authors": "Vahraz Jamnejad and Ahmad Hoorfar", "title": "Antenna Optimization Using a New Evolutionary Algorithm Based on\n  Tukey-Lambda Probability Distribution", "comments": "5 pages, to be submitted to IEEE ACCESS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.SP physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new evolutionary optimization algorithm based\non Tukey's symmetric lambda distribution. Tukey distribution is defined by 3\nparameters, the shape parameter, the scale parameter, and the location\nparameter or average value. Various other distributions can be approximated by\nchanging the shape parameter, and as a result can encompass a large class of\nprobability distributions. In addition, Because of these attributes, an\nEvolutionary Programming (EP) algorithm with Tukey mutation operator may\nperform well in a large class of optimization problems. Various schemes in\nimplementation of EP with Tukey distribution are discussed, and the resulting\nalgorithms are applied to selected test functions and antenna design problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2020 19:00:35 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 22:47:37 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Jamnejad", "Vahraz", ""], ["Hoorfar", "Ahmad", ""]]}, {"id": "2005.13766", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Olivier Francon, Elliot Meyerson, Xin Qiu, Elisa\n  Canzani, and Babak Hodjat", "title": "From Prediction to Prescription: Evolutionary Optimization of\n  Non-Pharmaceutical Interventions in the COVID-19 Pandemic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several models have been developed to predict how the COVID-19 pandemic\nspreads, and how it could be contained with non-pharmaceutical interventions\n(NPIs) such as social distancing restrictions and school and business closures.\nThis paper demonstrates how evolutionary AI could be used to facilitate the\nnext step, i.e. determining most effective intervention strategies\nautomatically. Through evolutionary surrogate-assisted prescription (ESP), it\nis possible to generate a large number of candidate strategies and evaluate\nthem with predictive models. In principle, strategies can be customized for\ndifferent countries and locales, and balance the need to contain the pandemic\nand the need to minimize their economic impact. While still limited by\navailable data, early experiments suggest that workplace and school\nrestrictions are the most important and need to be designed carefully. It also\ndemonstrates that results of lifting restrictions can be unreliable, and\nsuggests creative ways in which restrictions can be implemented softly, e.g. by\nalternating them over time. As more data becomes available, the approach can be\nincreasingly useful in dealing with COVID-19 as well as possible future\npandemics.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 03:43:31 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 23:12:48 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 23:02:52 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Francon", "Olivier", ""], ["Meyerson", "Elliot", ""], ["Qiu", "Xin", ""], ["Canzani", "Elisa", ""], ["Hodjat", "Babak", ""]]}, {"id": "2005.13780", "submitter": "Dharani Punithan", "authors": "Dharani Punithan and Byoung-Tak Zhang", "title": "Pattern Denoising in Molecular Associative Memory using Pairwise Markov\n  Random Field Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an in silico molecular associative memory model for pattern\nlearning, storage and denoising using Pairwise Markov Random Field (PMRF)\nmodel. Our PMRF-based molecular associative memory model extracts locally\ndistributed features from the exposed examples, learns and stores the patterns\nin the molecular associative memory and denoises the given noisy patterns via\nDNA computation based operations. Thus, our computational molecular model\ndemonstrates the functionalities of content-addressability of human memory. Our\nmolecular simulation results show that the averaged mean squared error between\nthe learned and denoised patterns are low (< 0.014) up to 30% of noise.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 05:14:08 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 13:23:16 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 10:40:18 GMT"}, {"version": "v4", "created": "Wed, 17 Jun 2020 06:09:51 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Punithan", "Dharani", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "2005.13823", "submitter": "Behnam Pourghassemi", "authors": "Behnam Pourghassemi (1), Chenghao Zhang (1), Joo Hwan Lee (2), Aparna\n  Chandramowlishwaran (1) ((1) University of California, Irvine, (2) Samsung\n  Semiconductor)", "title": "Brief Announcement: On the Limits of Parallelizing Convolutional Neural\n  Networks on GPUs", "comments": "3 pages, 1 figure, to be published in Proceedings of the 32nd ACM\n  Symposium on Parallelism in Algorithms and Architectures (SPAA '20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs are currently the platform of choice for training neural networks.\nHowever, training a deep neural network (DNN) is a time-consuming process even\non GPUs because of the massive number of parameters that have to be learned. As\na result, accelerating DNN training has been an area of significant research in\nthe last couple of years.\n  While earlier networks such as AlexNet had a linear dependency between layers\nand operations, state-of-the-art networks such as ResNet, PathNet, and\nGoogleNet have a non-linear structure that exhibits a higher level of\ninter-operation parallelism. However, popular deep learning (DL) frameworks\nsuch as TensorFlow and PyTorch launch the majority of neural network\noperations, especially convolutions, serially on GPUs and do not exploit this\ninter-op parallelism. In this brief announcement, we make a case for the need\nand potential benefit of exploiting this rich parallelism in state-of-the-art\nnon-linear networks for reducing the training time. We identify the challenges\nand limitations in enabling concurrent layer execution on GPU backends (such as\ncuDNN) of DL frameworks and propose potential solutions.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:51:22 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Pourghassemi", "Behnam", ""], ["Zhang", "Chenghao", ""], ["Lee", "Joo Hwan", ""], ["Chandramowlishwaran", "Aparna", ""]]}, {"id": "2005.13825", "submitter": "Jakob Bossek", "authors": "Jakob Bossek, Frank Neumann, Pan Peng, Dirk Sudholt", "title": "More Effective Randomized Search Heuristics for Graph Coloring Through\n  Dynamic Optimization", "comments": "To be presented at GECCO2020", "journal-ref": null, "doi": "10.1145/3377930.3390174", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic optimization problems have gained significant attention in\nevolutionary computation as evolutionary algorithms (EAs) can easily adapt to\nchanging environments. We show that EAs can solve the graph coloring problem\nfor bipartite graphs more efficiently by using dynamic optimization. In our\napproach the graph instance is given incrementally such that the EA can\nreoptimize its coloring when a new edge introduces a conflict. We show that,\nwhen edges are inserted in a way that preserves graph connectivity, Randomized\nLocal Search (RLS) efficiently finds a proper 2-coloring for all bipartite\ngraphs. This includes graphs for which RLS and other EAs need exponential\nexpected time in a static optimization scenario. We investigate different ways\nof building up the graph by popular graph traversals such as\nbreadth-first-search and depth-first-search and analyse the resulting runtime\nbehavior. We further show that offspring populations (e. g. a (1+$\\lambda$)\nRLS) lead to an exponential speedup in $\\lambda$. Finally, an island model\nusing 3 islands succeeds in an optimal time of $\\Theta(m)$ on every $m$-edge\nbipartite graph, outperforming offspring populations. This is the first example\nwhere an island model guarantees a speedup that is not bounded in the number of\nislands.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 07:55:12 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Bossek", "Jakob", ""], ["Neumann", "Frank", ""], ["Peng", "Pan", ""], ["Sudholt", "Dirk", ""]]}, {"id": "2005.13865", "submitter": "Jakob Bossek", "authors": "Jakob Bossek, Christian Grimme, G\\\"unter Rudolph, Heike Trautmann", "title": "Towards Decision Support in Dynamic Bi-Objective Vehicle Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a dynamic bi-objective vehicle routing problem, where a subset of\ncustomers ask for service over time. Therein, the distance traveled by a single\nvehicle and the number of unserved dynamic requests is minimized by a dynamic\nevolutionary multi-objective algorithm (DEMOA), which operates on discrete time\nwindows (eras). A decision is made at each era by a decision-maker, thus any\ndecision depends on irreversible decisions made in foregoing eras. To\nunderstand effects of sequences of decision-making and\ninteractions/dependencies between decisions made, we conduct a series of\nexperiments. More precisely, we fix a set of decision-maker preferences $D$ and\nthe number of eras $n_t$ and analyze all $|D|^{n_t}$ combinations of\ndecision-maker options. We find that for random uniform instances (a) the final\nselected solutions mainly depend on the final decision and not on the decision\nhistory, (b) solutions are quite robust with respect to the number of unvisited\ndynamic customers, and (c) solutions of the dynamic approach can even dominate\nsolutions obtained by a clairvoyant EMOA. In contrast, for instances with\nclustered customers, we observe a strong dependency on decision-making history\nas well as more variance in solution diversity.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 09:29:05 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Bossek", "Jakob", ""], ["Grimme", "Christian", ""], ["Rudolph", "G\u00fcnter", ""], ["Trautmann", "Heike", ""]]}, {"id": "2005.13867", "submitter": "Mao Ye", "authors": "Chenpeng Zhang (1), Shuai Li (2), Mao Ye (1), Ce Zhu (2), Xue Li (3)\n  ((1) School of Computer Science and Engineering, University of Electronic\n  Science and Technology of China, (2) School of Information and Communication\n  Engineering, University of Electronic Science and Technology of China, (3)\n  School of Information Technology and Electronic Engineering, The University\n  of Queensland)", "title": "Learning Various Length Dependence by Dual Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are widely used as a memory model for\nsequence-related problems. Many variants of RNN have been proposed to solve the\ngradient problems of training RNNs and process long sequences. Although some\nclassical models have been proposed, capturing long-term dependence while\nresponding to short-term changes remains a challenge. To this problem, we\npropose a new model named Dual Recurrent Neural Networks (DuRNN). The DuRNN\nconsists of two parts to learn the short-term dependence and progressively\nlearn the long-term dependence. The first part is a recurrent neural network\nwith constrained full recurrent connections to deal with short-term dependence\nin sequence and generate short-term memory. Another part is a recurrent neural\nnetwork with independent recurrent connections which helps to learn long-term\ndependence and generate long-term memory. A selection mechanism is added\nbetween two parts to help the needed long-term information transfer to the\nindependent neurons. Multiple modules can be stacked to form a multi-layer\nmodel for better performance. Our contributions are: 1) a new recurrent model\ndeveloped based on the divide-and-conquer strategy to learn long and short-term\ndependence separately, and 2) a selection mechanism to enhance the separating\nand learning of different temporal scales of dependence. Both theoretical\nanalysis and extensive experiments are conducted to validate the performance of\nour model, and we also conduct simple visualization experiments and ablation\nanalyses for the model interpretability. Experimental results indicate that the\nproposed DuRNN model can handle not only very long sequences (over 5000 time\nsteps), but also short sequences very well. Compared with many state-of-the-art\nRNN models, our model has demonstrated efficient and better performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 09:30:01 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Zhang", "Chenpeng", ""], ["Li", "Shuai", ""], ["Ye", "Mao", ""], ["Zhu", "Ce", ""], ["Li", "Xue", ""]]}, {"id": "2005.13872", "submitter": "Jakob Bossek", "authors": "Jakob Bossek, Christian Grimme, Heike Trautmann", "title": "Dynamic Bi-Objective Routing of Multiple Vehicles", "comments": null, "journal-ref": null, "doi": "10.1145/3377930.3390146", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, e.g. in delivery and service scenarios, Vehicle-Routing-Problems\n(VRPs) often imply repeated decision making on dynamic customer requests. As in\nclassical VRPs, tours have to be planned short while the number of serviced\ncustomers has to be maximized at the same time resulting in a multi-objective\nproblem. Beyond that, however, dynamic requests lead to the need for\nre-planning of not yet realized tour parts, while already realized tour parts\nare irreversible. In this paper we study this type of bi-objective dynamic VRP\nincluding sequential decision making and concurrent realization of decisions.\nWe adopt a recently proposed Dynamic Evolutionary Multi-Objective Algorithm\n(DEMOA) for a related VRP problem and extend it to the more realistic (here\nconsidered) scenario of multiple vehicles. We empirically show that our DEMOA\nis competitive with a multi-vehicle offline and clairvoyant variant of the\nproposed DEMOA as well as with the dynamic single-vehicle approach proposed\nearlier.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 09:35:45 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Bossek", "Jakob", ""], ["Grimme", "Christian", ""], ["Trautmann", "Heike", ""]]}, {"id": "2005.13971", "submitter": "Christian Oliva", "authors": "Christian Oliva and Luis F. Lago-Fern\\'andez", "title": "Separation of Memory and Processing in Dual Recurrent Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.FL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a neural network architecture that stacks a recurrent layer and a\nfeedforward layer that is also connected to the input, and compare it to\nstandard Elman and LSTM architectures in terms of accuracy and\ninterpretability. When noise is introduced into the activation function of the\nrecurrent units, these neurons are forced into a binary activation regime that\nmakes the networks behave much as finite automata. The resulting models are\nsimpler, easier to interpret and get higher accuracy on different sample\nproblems, including the recognition of regular languages, the computation of\nadditions in different bases and the generation of arithmetic expressions.\n", "versions": [{"version": "v1", "created": "Sun, 17 May 2020 11:38:42 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Oliva", "Christian", ""], ["Lago-Fern\u00e1ndez", "Luis F.", ""]]}, {"id": "2005.14105", "submitter": "Christoph Hertrich", "authors": "Christoph Hertrich and Martin Skutella", "title": "Provably Good Solutions to the Knapsack Problem via Neural Networks of\n  Bounded Size", "comments": "A short version of this paper appears in the proceedings of AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DM cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of a satisfying and rigorous mathematical understanding of\nthe performance of neural networks is a major challenge in artificial\nintelligence. Against this background, we study the expressive power of neural\nnetworks through the example of the classical NP-hard Knapsack Problem. Our\nmain contribution is a class of recurrent neural networks (RNNs) with rectified\nlinear units that are iteratively applied to each item of a Knapsack instance\nand thereby compute optimal or provably good solution values. We show that an\nRNN of depth four and width depending quadratically on the profit of an optimum\nKnapsack solution is sufficient to find optimum Knapsack solutions. We also\nprove the following tradeoff between the size of an RNN and the quality of the\ncomputed Knapsack solution: for Knapsack instances consisting of $n$ items, an\nRNN of depth five and width $w$ computes a solution of value at least\n$1-\\mathcal{O}(n^2/\\sqrt{w})$ times the optimum solution value. Our results\nbuild upon a classical dynamic programming formulation of the Knapsack Problem\nas well as a careful rounding of profit values that are also at the core of the\nwell-known fully polynomial-time approximation scheme for the Knapsack Problem.\nA carefully conducted computational study qualitatively supports our\ntheoretical size bounds. Finally, we point out that our results can be\ngeneralized to many other combinatorial optimization problems that admit\ndynamic programming solution methods, such as various Shortest Path Problems,\nthe Longest Common Subsequence Problem, and the Traveling Salesperson Problem.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 15:55:37 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 10:26:12 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Hertrich", "Christoph", ""], ["Skutella", "Martin", ""]]}, {"id": "2005.14187", "submitter": "Hanrui Wang", "authors": "Hanrui Wang, Zhanghao Wu, Zhijian Liu, Han Cai, Ligeng Zhu, Chuang\n  Gan, Song Han", "title": "HAT: Hardware-Aware Transformers for Efficient Natural Language\n  Processing", "comments": "Accepted to ACL 2020. 14 pages, 12 figures. Code available at\n  http://github.com/mit-han-lab/hardware-aware-transformers.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but\nthey are difficult to be deployed on hardware due to the intensive computation.\nTo enable low-latency inference on resource-constrained hardware platforms, we\npropose to design Hardware-Aware Transformers (HAT) with neural architecture\nsearch. We first construct a large design space with $\\textit{arbitrary\nencoder-decoder attention}$ and $\\textit{heterogeneous layers}$. Then we train\na $\\textit{SuperTransformer}$ that covers all candidates in the design space,\nand efficiently produces many $\\textit{SubTransformers}$ with weight sharing.\nFinally, we perform an evolutionary search with a hardware latency constraint\nto find a specialized $\\textit{SubTransformer}$ dedicated to run fast on the\ntarget hardware. Extensive experiments on four machine translation tasks\ndemonstrate that HAT can discover efficient models for different hardware (CPU,\nGPU, IoT device). When running WMT'14 translation task on Raspberry Pi-4, HAT\ncan achieve $\\textbf{3}\\times$ speedup, $\\textbf{3.7}\\times$ smaller size over\nbaseline Transformer; $\\textbf{2.7}\\times$ speedup, $\\textbf{3.6}\\times$\nsmaller size over Evolved Transformer with $\\textbf{12,041}\\times$ less search\ncost and no performance loss. HAT code is\nhttps://github.com/mit-han-lab/hardware-aware-transformers.git\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 17:58:56 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Wang", "Hanrui", ""], ["Wu", "Zhanghao", ""], ["Liu", "Zhijian", ""], ["Cai", "Han", ""], ["Zhu", "Ligeng", ""], ["Gan", "Chuang", ""], ["Han", "Song", ""]]}, {"id": "2005.14261", "submitter": "Adonis Bogris", "authors": "Adonis Bogris, Charis Mesaritakis, Stavros Deligiannidis, Pu Li", "title": "Fabry-Perot Lasers as Enablers for Parallel Reservoir Computing", "comments": null, "journal-ref": null, "doi": "10.1109/JSTQE.2020.3011879", "report-no": null, "categories": "physics.app-ph cs.NE eess.SP nlin.CD physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of Fabry-Perot (FP) lasers as potential neuromorphic\ncomputing machines with parallel processing capabilities. With the use of\noptical injection between a master FP laser and a slave FP laser under feedback\nwe demonstrate the potential for scaling up the processing power at\nlongitudinal mode granularity and perform real-time processing for signal\nequalization in 25 Gbaud intensity modulation direct detection optical\ncommunication systems. We demonstrate the improvement of classification\nperformance as the number of nodes increases and the capability of simultaneous\nprocessing of arbitrary data streams. Extensive numerical simulations show that\nup to 8 longitudinal modes in typical Fabry-Perot lasers can be leveraged so as\nto enhance classification performance.\n", "versions": [{"version": "v1", "created": "Mon, 4 May 2020 05:45:35 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 14:00:13 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Bogris", "Adonis", ""], ["Mesaritakis", "Charis", ""], ["Deligiannidis", "Stavros", ""], ["Li", "Pu", ""]]}, {"id": "2005.14664", "submitter": "Josef Urban", "authors": "Josef Urban and Jan Jakub\\r{u}v", "title": "First Neural Conjecturing Datasets and Experiments", "comments": "Accepted to CICM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe several datasets and first experiments with creating conjectures\nby neural methods. The datasets are based on the Mizar Mathematical Library\nprocessed in several forms and the problems extracted from it by the MPTP\nsystem and proved by the E prover using the ENIGMA guidance. The conjecturing\nexperiments use the Transformer architecture and in particular its GPT-2\nimplementation.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2020 16:46:25 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Urban", "Josef", ""], ["Jakub\u016fv", "Jan", ""]]}]