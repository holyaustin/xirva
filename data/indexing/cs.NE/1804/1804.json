[{"id": "1804.00149", "submitter": "Gianluca Susi PhD", "authors": "Simone Acciarito, Gian Carlo Cardarilli, Alessandro Cristini, Luca Di\n  Nunzio, Rocco Fazzolari, Gaurav Mani Khanal, Marco Re, Gianluca Susi", "title": "Hardware design of LIF with Latency neuron model with memristive STDP\n  synapses", "comments": null, "journal-ref": "Integration, the VLSI Journal - Volume 59, September 2017, Pages\n  81-89", "doi": "10.1016/j.vlsi.2017.05.006", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the hardware implementation of a neuromorphic system is\npresented. This system is composed of a Leaky Integrate-and-Fire with Latency\n(LIFL) neuron and a Spike-Timing Dependent Plasticity (STDP) synapse. LIFL\nneuron model allows to encode more information than the common\nIntegrate-and-Fire models, typically considered for neuromorphic\nimplementations. In our system LIFL neuron is implemented using CMOS circuits\nwhile memristor is used for the implementation of the STDP synapse. A\ndescription of the entire circuit is provided. Finally, the capabilities of the\nproposed architecture have been evaluated by simulating a motif composed of\nthree neurons and two synapses. The simulation results confirm the validity of\nthe proposed system and its suitability for the design of more complex spiking\nneural networks\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 10:34:11 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Acciarito", "Simone", ""], ["Cardarilli", "Gian Carlo", ""], ["Cristini", "Alessandro", ""], ["Di Nunzio", "Luca", ""], ["Fazzolari", "Rocco", ""], ["Khanal", "Gaurav Mani", ""], ["Re", "Marco", ""], ["Susi", "Gianluca", ""]]}, {"id": "1804.00222", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, Brian Cheung, Jascha Sohl-Dickstein", "title": "Meta-Learning Update Rules for Unsupervised Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major goal of unsupervised learning is to discover data representations\nthat are useful for subsequent tasks, without access to supervised labels\nduring training. Typically, this involves minimizing a surrogate objective,\nsuch as the negative log likelihood of a generative model, with the hope that\nrepresentations useful for subsequent tasks will arise as a side effect. In\nthis work, we propose instead to directly target later desired tasks by\nmeta-learning an unsupervised learning rule which leads to representations\nuseful for those tasks. Specifically, we target semi-supervised classification\nperformance, and we meta-learn an algorithm -- an unsupervised weight update\nrule -- that produces representations useful for this task. Additionally, we\nconstrain our unsupervised update rule to a be a biologically-motivated,\nneuron-local function, which enables it to generalize to different neural\nnetwork architectures, datasets, and data modalities. We show that the\nmeta-learned update rule produces useful features and sometimes outperforms\nexisting unsupervised learning techniques. We further show that the\nmeta-learned unsupervised update rule generalizes to train networks with\ndifferent widths, depths, and nonlinearities. It also generalizes to train on\ndata with randomly permuted input dimensions and even generalizes from image\ndatasets to a text task.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 22:44:28 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 01:41:23 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 05:26:00 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Cheung", "Brian", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1804.00497", "submitter": "Alexander Wong", "authors": "Alexander Wong, Mohammad Javad Shafiee, and Michael St. Jules", "title": "MicronNet: A Highly Compact Deep Convolutional Neural Network\n  Architecture for Real-time Embedded Traffic Sign Classification", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic sign recognition is a very important computer vision task for a\nnumber of real-world applications such as intelligent transportation\nsurveillance and analysis. While deep neural networks have been demonstrated in\nrecent years to provide state-of-the-art performance traffic sign recognition,\na key challenge for enabling the widespread deployment of deep neural networks\nfor embedded traffic sign recognition is the high computational and memory\nrequirements of such networks. As a consequence, there are significant benefits\nin investigating compact deep neural network architectures for traffic sign\nrecognition that are better suited for embedded devices. In this paper, we\nintroduce MicronNet, a highly compact deep convolutional neural network for\nreal-time embedded traffic sign recognition designed based on macroarchitecture\ndesign principles (e.g., spectral macroarchitecture augmentation, parameter\nprecision optimization, etc.) as well as numerical microarchitecture\noptimization strategies. The resulting overall architecture of MicronNet is\nthus designed with as few parameters and computations as possible while\nmaintaining recognition performance, leading to optimized information density\nof the proposed network. The resulting MicronNet possesses a model size of just\n~1MB and ~510,000 parameters (~27x fewer parameters than state-of-the-art)\nwhile still achieving a human performance level top-1 accuracy of 98.9% on the\nGerman traffic sign recognition benchmark. Furthermore, MicronNet requires just\n~10 million multiply-accumulate operations to perform inference, and has a\ntime-to-compute of just 32.19 ms on a Cortex-A53 high efficiency processor.\nThese experimental results show that highly compact, optimized deep neural\nnetwork architectures can be designed for real-time traffic sign recognition\nthat are well-suited for embedded scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 01:32:59 GMT"}, {"version": "v2", "created": "Sat, 7 Apr 2018 00:43:55 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 16:11:25 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Wong", "Alexander", ""], ["Shafiee", "Mohammad Javad", ""], ["Jules", "Michael St.", ""]]}, {"id": "1804.00656", "submitter": "Claudio Sanhueza", "authors": "Claudio Sanhueza, Francia Jim\\'enez, Regina Berretta and Pablo Moscato", "title": "mQAPViz: A divide-and-conquer multi-objective optimization algorithm to\n  compute large data visualizations", "comments": "Proceeding GECCO 18 Proceedings of the Genetic and Evolutionary\n  Computation Conference. Pages 737-744 Kyoto, Japan - July 15 - 19, 2018", "journal-ref": null, "doi": "10.1145/3205455.3205457", "report-no": null, "categories": "cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for data visualizations are essential tools for transforming data\ninto useful narratives. Unfortunately, very few visualization algorithms can\nhandle the large datasets of many real-world scenarios. In this study, we\naddress the visualization of these datasets as a Multi-Objective Optimization\nProblem. We propose mQAPViz, a divide-and-conquer multi-objective optimization\nalgorithm to compute large-scale data visualizations. Our method employs the\nMulti-Objective Quadratic Assignment Problem (mQAP) as the mathematical\nfoundation to solve the visualization task at hand. The algorithm applies\nadvanced sampling techniques originating from the field of machine learning and\nefficient data structures to scale to millions of data objects. The algorithm\nallocates objects onto a 2D grid layout. Experimental results on real-world and\nlarge datasets demonstrate that mQAPViz is a competitive alternative to\nexisting techniques.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 09:55:10 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 07:01:14 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 03:10:30 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Sanhueza", "Claudio", ""], ["Jim\u00e9nez", "Francia", ""], ["Berretta", "Regina", ""], ["Moscato", "Pablo", ""]]}, {"id": "1804.00768", "submitter": "Mohammad Hasanzadeh Mofrad", "authors": "Mohammad Hasanzadeh Mofrad and S. K. Chang", "title": "A Bi-population Particle Swarm Optimizer for Learning Automata based\n  Slow Intelligent System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle Swarm Optimization (PSO) is an Evolutionary Algorithm (EA) that\nutilizes a swarm of particles to solve an optimization problem. Slow\nIntelligence System (SIS) is a learning framework which slowly learns the\nsolution to a problem performing a series of operations. Moreover, Learning\nAutomata (LA) are minuscule but effective decision making entities which are\nbest suited to act as a controller component. In this paper, we combine two\nisolate populations of PSO to forge the Adaptive Intelligence Optimizer (AIO)\nwhich harnesses the advantages of a bi-population PSO to escape from the local\nminimum and avoid premature convergence. Furthermore, using the rich framework\nof SIS and the nifty control theory that LA derived from, we find the perfect\nmatching between SIS and LA where acting slowly is the pillar of both of them.\nBoth SIS and LA need time to converge to the optimal decision where this\nenables AIO to outperform standard PSO having an incomparable performance on\nevolutionary optimization benchmark functions.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 00:12:07 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Mofrad", "Mohammad Hasanzadeh", ""], ["Chang", "S. K.", ""]]}, {"id": "1804.00815", "submitter": "Shamak Dutta", "authors": "Shamak Dutta, Bryan Tripp, Graham Taylor", "title": "Convolutional Neural Networks Regularized by Correlated Noise", "comments": "Accepted at CRV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the visual cortex are correlated in their variability. The\npresence of correlation impacts cortical processing because noise cannot be\naveraged out over many neurons. In an effort to understand the functional\npurpose of correlated variability, we implement and evaluate correlated noise\nmodels in deep convolutional neural networks. Inspired by the cortex,\ncorrelation is defined as a function of the distance between neurons and their\nselectivity. We show how to sample from high-dimensional correlated\ndistributions while keeping the procedure differentiable, so that\nback-propagation can proceed as usual. The impact of correlated variability is\nevaluated on the classification of occluded and non-occluded images with and\nwithout the presence of other regularization techniques, such as dropout. More\nwork is needed to understand the effects of correlations in various conditions,\nhowever in 10/12 of the cases we studied, the best performance on occluded\nimages was obtained from a model with correlated noise.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 04:05:00 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Dutta", "Shamak", ""], ["Tripp", "Bryan", ""], ["Taylor", "Graham", ""]]}, {"id": "1804.00831", "submitter": "Yanghoon Kim", "authors": "Yanghoon Kim and Hwanhee Lee and Kyomin Jung", "title": "AttnConvnet at SemEval-2018 Task 1: Attention-based Convolutional Neural\n  Networks for Multi-label Emotion Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an attention-based classifier that predicts\nmultiple emotions of a given sentence. Our model imitates human's two-step\nprocedure of sentence understanding and it can effectively represent and\nclassify sentences. With emoji-to-meaning preprocessing and extra lexicon\nutilization, we further improve the model performance. We train and evaluate\nour model with data provided by SemEval-2018 task 1-5, each sentence of which\nhas several labels among 11 given sentiments. Our model achieves 5-th/1-th rank\nin English/Spanish respectively.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 05:31:35 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 00:21:43 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Kim", "Yanghoon", ""], ["Lee", "Hwanhee", ""], ["Jung", "Kyomin", ""]]}, {"id": "1804.01144", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson, Vito Trianni, Justin Werfel, and Hiroki Sayama", "title": "Self-Organization and Artificial Life: A Review", "comments": "8 pages, submitted to ALife 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.AI cs.MA cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-organization has been an important concept within a number of\ndisciplines, which Artificial Life (ALife) also has heavily utilized since its\ninception. The term and its implications, however, are often confusing or\nmisinterpreted. In this work, we provide a mini-review of self-organization and\nits relationship with ALife, aiming at initiating discussions on this important\ntopic with the interested audience. We first articulate some fundamental\naspects of self-organization, outline its usage, and review its applications to\nALife within its soft, hard, and wet domains. We also provide perspectives for\nfurther research.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:44:09 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Gershenson", "Carlos", ""], ["Trianni", "Vito", ""], ["Werfel", "Justin", ""], ["Sayama", "Hiroki", ""]]}, {"id": "1804.01314", "submitter": "Donya Yazdani", "authors": "Dogan Corus, Pietro S. Oliveto, Donya Yazdani", "title": "When Hypermutations and Ageing Enable Artificial Immune Systems to\n  Outperform Evolutionary Algorithms", "comments": "An extended abstract of this paper has been published at the 2017\n  Genetic and Evolutionary Computation Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a time complexity analysis of the Opt-IA artificial immune system\n(AIS). We first highlight the power and limitations of its distinguishing\noperators (i.e., hypermutations with mutation potential and ageing) by\nanalysing them in isolation. Recent work has shown that ageing combined with\nlocal mutations can help escape local optima on a dynamic optimisation\nbenchmark function. We generalise this result by rigorously proving that,\ncompared to evolutionary algorithms (EAs), ageing leads to impressive speed-ups\non the standard Cliff benchmark function both when using local and global\nmutations. Unless the stop at first constructive mutation (FCM) mechanism is\napplied, we show that hypermutations require exponential expected runtime to\noptimise any function with a polynomial number of optima. If instead FCM is\nused, the expected runtime is at most a linear factor larger than the upper\nbound achieved for any random local search algorithm using the artificial\nfitness levels method. Nevertheless, we prove that algorithms using\nhypermutations can be considerably faster than EAs at escaping local optima. An\nanalysis of the complete Opt-IA reveals that it is efficient on the previously\nconsidered functions and highlights problems where the use of the full\nalgorithm is crucial. We complete the picture by presenting a class of\nfunctions for which Opt-IA fails with overwhelming probability while standard\nEAs are efficient.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 09:22:57 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2019 14:41:30 GMT"}], "update_date": "2019-03-18", "authors_parsed": [["Corus", "Dogan", ""], ["Oliveto", "Pietro S.", ""], ["Yazdani", "Donya", ""]]}, {"id": "1804.01653", "submitter": "Rong Zhang", "authors": "Rong Zhang, Weiping Li, Tong Mo", "title": "Review of Deep Learning", "comments": "In Chinese. Have been published in the journal \"Information and\n  Control\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, China, the United States and other countries, Google and\nother high-tech companies have increased investment in artificial intelligence.\nDeep learning is one of the current artificial intelligence research's key\nareas. This paper analyzes and summarizes the latest progress and future\nresearch directions of deep learning. Firstly, three basic models of deep\nlearning are outlined, including multilayer perceptrons, convolutional neural\nnetworks, and recurrent neural networks. On this basis, we further analyze the\nemerging new models of convolution neural networks and recurrent neural\nnetworks. This paper then summarizes deep learning's applications in many areas\nof artificial intelligence, including speech processing, computer vision,\nnatural language processing and so on. Finally, this paper discusses the\nexisting problems of deep learning and gives the corresponding possible\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 02:23:59 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 15:34:03 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Zhang", "Rong", ""], ["Li", "Weiping", ""], ["Mo", "Tong", ""]]}, {"id": "1804.01660", "submitter": "Christoph Adami", "authors": "Arend Hintze, Douglas Kirkpatrick, and Christoph Adami (Michigan State\n  University)", "title": "The structure of evolved representations across different substrates for\n  artificial intelligence", "comments": "8 pages, 13 figures. Submitted to Artificial Life Conference (Tokyo,\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs), while exceptionally useful for\nclassification, are vulnerable to misdirection. Small amounts of noise can\nsignificantly affect their ability to correctly complete a task. Instead of\ngeneralizing concepts, ANNs seem to focus on surface statistical regularities\nin a given task. Here we compare how recurrent artificial neural networks, long\nshort-term memory units, and Markov Brains sense and remember their\nenvironments. We show that information in Markov Brains is localized and\nsparsely distributed, while the other neural network substrates \"smear\"\ninformation about the environment across all nodes, which makes them vulnerable\nto noise.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 03:10:37 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Hintze", "Arend", "", "Michigan State\n  University"], ["Kirkpatrick", "Douglas", "", "Michigan State\n  University"], ["Adami", "Christoph", "", "Michigan State\n  University"]]}, {"id": "1804.01694", "submitter": "Anvita Gupta", "authors": "Anvita Gupta and James Zou", "title": "Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for\n  Optimizing Protein Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) represent an attractive and novel\napproach to generate realistic data, such as genes, proteins, or drugs, in\nsynthetic biology. Here, we apply GANs to generate synthetic DNA sequences\nencoding for proteins of variable length. We propose a novel feedback-loop\narchitecture, called Feedback GAN (FBGAN), to optimize the synthetic gene\nsequences for desired properties using an external function analyzer. The\nproposed architecture also has the advantage that the analyzer need not be\ndifferentiable. We apply the feedback-loop mechanism to two examples: 1)\ngenerating synthetic genes coding for antimicrobial peptides, and 2) optimizing\nsynthetic genes for the secondary structure of their resulting peptides. A\nsuite of metrics demonstrate that the GAN generated proteins have desirable\nbiophysical properties. The FBGAN architecture can also be used to optimize\nGAN-generated datapoints for useful properties in domains beyond genomics.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 07:17:42 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Gupta", "Anvita", ""], ["Zou", "James", ""]]}, {"id": "1804.01712", "submitter": "Aditya Grover", "authors": "Aditya Grover, Ramki Gummadi, Miguel Lazaro-Gredilla, Dale Schuurmans,\n  Stefano Ermon", "title": "Variational Rejection Sampling", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning latent variable models with stochastic variational inference is\nchallenging when the approximate posterior is far from the true posterior, due\nto high variance in the gradient estimates. We propose a novel rejection\nsampling step that discards samples from the variational posterior which are\nassigned low likelihoods by the model. Our approach provides an arbitrarily\naccurate approximation of the true posterior at the expense of extra\ncomputation. Using a new gradient estimator for the resulting unnormalized\nproposal distribution, we achieve average improvements of 3.71 nats and 0.21\nnats over state-of-the-art single-sample and multi-sample alternatives\nrespectively for estimating marginal log-likelihoods using sigmoid belief\nnetworks on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 07:53:41 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Grover", "Aditya", ""], ["Gummadi", "Ramki", ""], ["Lazaro-Gredilla", "Miguel", ""], ["Schuurmans", "Dale", ""], ["Ermon", "Stefano", ""]]}, {"id": "1804.01756", "submitter": "Yan Wu", "authors": "Yan Wu, Greg Wayne, Alex Graves, Timothy Lillicrap", "title": "The Kanerva Machine: A Generative Distributed Memory", "comments": "Published as a conference paper at ICLR 2018 (corrected typos in\n  revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end trained memory system that quickly adapts to new\ndata and generates samples like them. Inspired by Kanerva's sparse distributed\nmemory, it has a robust distributed reading and writing mechanism. The memory\nis analytically tractable, which enables optimal on-line compression via a\nBayesian update-rule. We formulate it as a hierarchical conditional generative\nmodel, where memory provides a rich data-dependent prior distribution.\nConsequently, the top-down memory and bottom-up perception are combined to\nproduce the code representing an observation. Empirically, we demonstrate that\nthe adaptive memory significantly improves generative models trained on both\nthe Omniglot and CIFAR datasets. Compared with the Differentiable Neural\nComputer (DNC) and its variants, our memory model has greater capacity and is\nsignificantly easier to train.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 10:07:05 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 12:23:40 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 09:52:40 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Wu", "Yan", ""], ["Wayne", "Greg", ""], ["Graves", "Alex", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1804.01963", "submitter": "Emmanuel Dufourq Mr", "authors": "Emmanuel Dufourq, Bruce A. Bassett", "title": "Automated Classification of Text Sentiment", "comments": "In \"2017 Annual Conference of the South African Institute of Computer\n  Scientists and Information\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to identify sentiment in text, referred to as sentiment analysis,\nis one which is natural to adult humans. This task is, however, not one which a\ncomputer can perform by default. Identifying sentiments in an automated,\nalgorithmic manner will be a useful capability for business and research in\ntheir search to understand what consumers think about their products or\nservices and to understand human sociology. Here we propose two new Genetic\nAlgorithms (GAs) for the task of automated text sentiment analysis. The GAs\nlearn whether words occurring in a text corpus are either sentiment or\namplifier words, and their corresponding magnitude. Sentiment words, such as\n'horrible', add linearly to the final sentiment. Amplifier words in contrast,\nwhich are typically adjectives/adverbs like 'very', multiply the sentiment of\nthe following word. This increases, decreases or negates the sentiment of the\nfollowing word. The sentiment of the full text is then the sum of these terms.\nThis approach grows both a sentiment and amplifier dictionary which can be\nreused for other purposes and fed into other machine learning algorithms. We\nreport the results of multiple experiments conducted on large Amazon data sets.\nThe results reveal that our proposed approach was able to outperform several\npublic and/or commercial sentiment analysis algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 17:21:48 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "1804.02257", "submitter": "Sam Kriegman", "authors": "Sam Kriegman, Nick Cheney, Francesco Corucci, and Josh C. Bongard", "title": "Interoceptive robustness through environment-mediated morphological\n  development", "comments": null, "journal-ref": null, "doi": "10.1145/3205455.3205529", "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typically, AI researchers and roboticists try to realize intelligent behavior\nin machines by tuning parameters of a predefined structure (body plan and/or\nneural network architecture) using evolutionary or learning algorithms. Another\nbut not unrelated longstanding property of these systems is their brittleness\nto slight aberrations, as highlighted by the growing deep learning literature\non adversarial examples. Here we show robustness can be achieved by evolving\nthe geometry of soft robots, their control systems, and how their material\nproperties develop in response to one particular interoceptive stimulus\n(engineering stress) during their lifetimes. By doing so we realized robots\nthat were equally fit but more robust to extreme material defects (such as\nmight occur during fabrication or by damage thereafter) than robots that did\nnot develop during their lifetimes, or developed in response to a different\ninteroceptive stimulus (pressure). This suggests that the interplay between\nchanges in the containing systems of agents (body plan and/or neural\narchitecture) at different temporal scales (evolutionary and developmental)\nalong different modalities (geometry, material properties, synaptic weights)\nand in response to different signals (interoceptive and external perception)\nall dictate those agents' abilities to evolve or learn capable and robust\nstrategies.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:33:37 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 01:39:25 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Kriegman", "Sam", ""], ["Cheney", "Nick", ""], ["Corucci", "Francesco", ""], ["Bongard", "Josh C.", ""]]}, {"id": "1804.02341", "submitter": "Edward Choi", "authors": "Edward Choi, Angeliki Lazaridou, Nando de Freitas", "title": "Compositional Obverter Communication Learning From Raw Visual Input", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the distinguishing aspects of human language is its compositionality,\nwhich allows us to describe complex environments with limited vocabulary.\nPreviously, it has been shown that neural network agents can learn to\ncommunicate in a highly structured, possibly compositional language based on\ndisentangled input (e.g. hand- engineered features). Humans, however, do not\nlearn to communicate based on well-summarized features. In this work, we train\nneural agents to simultaneously develop visual perception from raw image\npixels, and learn to communicate with a sequence of discrete symbols. The\nagents play an image description game where the image contains factors such as\ncolors and shapes. We train the agents using the obverter technique where an\nagent introspects to generate messages that maximize its own understanding.\nThrough qualitative analysis, visualization and a zero-shot test, we show that\nthe agents can develop, out of raw image pixels, a language with compositional\nproperties, given a proper pressure from the environment.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 16:12:51 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Choi", "Edward", ""], ["Lazaridou", "Angeliki", ""], ["de Freitas", "Nando", ""]]}, {"id": "1804.02464", "submitter": "Thomas Miconi", "authors": "Thomas Miconi, Jeff Clune, Kenneth O. Stanley", "title": "Differentiable plasticity: training plastic neural networks with\n  backpropagation", "comments": "Presented at ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML2018), Stockholm, Sweden, PMLR 80, 2018", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we build agents that keep learning from experience, quickly and\nefficiently, after their initial training? Here we take inspiration from the\nmain mechanism of learning in biological brains: synaptic plasticity, carefully\ntuned by evolution to produce efficient lifelong learning. We show that\nplasticity, just like connection weights, can be optimized by gradient descent\nin large (millions of parameters) recurrent networks with Hebbian plastic\nconnections. First, recurrent plastic networks with more than two million\nparameters can be trained to memorize and reconstruct sets of novel,\nhigh-dimensional 1000+ pixels natural images not seen during training.\nCrucially, traditional non-plastic recurrent networks fail to solve this task.\nFurthermore, trained plastic networks can also solve generic meta-learning\ntasks such as the Omniglot task, with competitive results and little parameter\noverhead. Finally, in reinforcement learning settings, plastic networks\noutperform a non-plastic equivalent in a maze exploration task. We conclude\nthat differentiable plasticity may provide a powerful novel approach to the\nlearning-to-learn problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 21:43:13 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 00:50:53 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 16:55:11 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Miconi", "Thomas", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1804.02476", "submitter": "Alex Graves", "authors": "Alex Graves, Jacob Menick, Aaron van den Oord", "title": "Associative Compression Networks for Representation Learning", "comments": "Revised to clarify difference between ACN and IID loss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Associative Compression Networks (ACNs), a new\nframework for variational autoencoding with neural networks. The system differs\nfrom existing variational autoencoders (VAEs) in that the prior distribution\nused to model each code is conditioned on a similar code from the dataset. In\ncompression terms this equates to sequentially transmitting the dataset using\nan ordering determined by proximity in latent space. Since the prior need only\naccount for local, rather than global variations in the latent space, the\ncoding cost is greatly reduced, leading to rich, informative codes. Crucially,\nthe codes remain informative when powerful, autoregressive decoders are used,\nwhich we argue is fundamentally difficult with normal VAEs. Experimental\nresults on MNIST, CIFAR-10, ImageNet and CelebA show that ACNs discover\nhigh-level latent features such as object class, writing style, pose and facial\nexpression, which can be used to cluster and classify the data, as well as to\ngenerate diverse and convincing samples. We conclude that ACNs are a promising\nnew direction for representation learning: one that steps away from IID\nmodelling, and towards learning a structured description of the dataset as a\nwhole.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 22:17:04 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 16:20:25 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Graves", "Alex", ""], ["Menick", "Jacob", ""], ["Oord", "Aaron van den", ""]]}, {"id": "1804.02491", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy, Ethem Alpayd{\\i}n", "title": "Continuously Constructive Deep Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, deep learning algorithms update the network weights whereas\nthe network architecture is chosen manually, using a process of trial and\nerror. In this work, we propose two novel approaches that automatically update\nthe network structure while also learning its weights. The novelty of our\napproach lies in our parameterization where the depth, or additional\ncomplexity, is encapsulated continuously in the parameter space through control\nparameters that add additional complexity. We propose two methods: In tunnel\nnetworks, this selection is done at the level of a hidden unit, and in budding\nperceptrons, this is done at the level of a network layer; updating this\ncontrol parameter introduces either another hidden unit or another hidden\nlayer. We show the effectiveness of our methods on the synthetic two-spirals\ndata and on two real data sets of MNIST and MIRFLICKR, where we see that our\nproposed methods, with the same set of hyperparameters, can correctly adjust\nthe network complexity to the task complexity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 02:09:16 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["\u0130rsoy", "Ozan", ""], ["Alpayd\u0131n", "Ethem", ""]]}, {"id": "1804.02508", "submitter": "Christoph Adami", "authors": "Ali Tehrani-Saleh, Thomas LaBar and Christoph Adami (Michigan State\n  University)", "title": "Evolution leads to a diversity of motion-detection neuronal circuits", "comments": "8 pages, 8 figures, Artificial Life Conference (2018), to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.CV cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central goal of evolutionary biology is to explain the origins and\ndistribution of diversity across life. Beyond species or genetic diversity, we\nalso observe diversity in the circuits (genetic or otherwise) underlying\ncomplex functional traits. However, while the theory behind the origins and\nmaintenance of genetic and species diversity has been studied for decades,\ntheory concerning the origin of diverse functional circuits is still in its\ninfancy. It is not known how many different circuit structures can implement\nany given function, which evolutionary factors lead to different circuits, and\nwhether the evolution of a particular circuit was due to adaptive or\nnon-adaptive processes. Here, we use digital experimental evolution to study\nthe diversity of neural circuits that encode motion detection in digital\n(artificial) brains. We find that evolution leads to an enormous diversity of\npotential neural architectures encoding motion detection circuits, even for\ncircuits encoding the exact same function. Evolved circuits vary in both\nredundancy and complexity (as previously found in genetic circuits) suggesting\nthat similar evolutionary principles underlie circuit formation using any\nsubstrate. We also show that a simple (designed) motion detection circuit that\nis optimally-adapted gains in complexity when evolved further, and that\nselection for mutational robustness led this gain in complexity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 04:26:21 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 14:06:08 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Tehrani-Saleh", "Ali", "", "Michigan State\n  University"], ["LaBar", "Thomas", "", "Michigan State\n  University"], ["Adami", "Christoph", "", "Michigan State\n  University"]]}, {"id": "1804.02620", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura and Takashi Yamaguchi", "title": "A Proposal of Interactive Growing Hierarchical SOM", "comments": "6 pages, 11 figures, Proc. of 2011 IEEE International Conference on\n  Systems, Man, and Cybernetics (IEEE SMC 2011). arXiv admin note: text overlap\n  with arXiv:cs/0405030 by other authors", "journal-ref": null, "doi": "10.1109/ICSMC.2011.6084144", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self Organizing Map is trained using unsupervised learning to produce a\ntwo-dimensional discretized representation of input space of the training\ncases. Growing Hierarchical SOM is an architecture which grows both in a\nhierarchical way representing the structure of data distribution and in a\nhorizontal way representation the size of each individual maps. The control\nmethod of the growing degree of GHSOM by pruning off the redundant branch of\nhierarchy in SOM is proposed in this paper. Moreover, the interface tool for\nthe proposed method called interactive GHSOM is developed. We discuss the\ncomputation results of Iris data by using the developed tool.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 03:37:36 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Ichimura", "Takumi", ""], ["Yamaguchi", "Takashi", ""]]}, {"id": "1804.02628", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Shin Kamada", "title": "Clustering and Retrieval Method of Immunological Memory Cell in Clonal\n  Selection Algorithm", "comments": "6 pages, 9 figures, Proc. of the 6th International conference on Soft\n  Computing and Intelligent Systems and The 13th International Symposium on\n  Advanced Intelligent Systems(SCIS-ISIS 2012)", "journal-ref": null, "doi": "10.1109/SCIS-ISIS.2012.6505049", "report-no": null, "categories": "cs.NE cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clonal selection principle explains the basic features of an adaptive\nimmune response to a antigenic stimulus. It established the idea that only\nthose cells that recognize the antigens are selected to proliferate and\ndifferentiate. This paper explains a computational implementation of the clonal\nselection principle that explicitly takes into account the affinity maturation\nof the immune response. Antibodies generated by the clonal selection algorithm\nare clustered in some categories according to the affinity maturation, so that\nimmunological memory cells which respond to the specified pathogen are created.\nExperimental results to classify the medical database of Coronary Heart Disease\ndatabases are reported. For the dataset, our proposed method shows the 99.6\\%\nclassification capability of training data.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 04:27:09 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Kamada", "Shin", ""]]}, {"id": "1804.02702", "submitter": "Ashwani Kumar", "authors": "Ashwani Kumar", "title": "Ordinal Pooling Networks: For Preserving Information over Shrinking\n  Feature Maps", "comments": "9 pages with 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the framework of convolutional neural networks that lie at the heart of\ndeep learning, downsampling is often performed with a max-pooling operation\nthat only retains the element with maximum activation, while completely\ndiscarding the information contained in other elements in a pooling region. To\naddress this issue, a novel pooling scheme, Ordinal Pooling Network (OPN), is\nintroduced in this work. OPN rearranges all the elements of a pooling region in\na sequence and assigns different weights to these elements based upon their\norders in the sequence, where the weights are learned via the gradient-based\noptimisation. The results of our small-scale experiments on image\nclassification task demonstrate that this scheme leads to a consistent\nimprovement in the accuracy over max-pooling operation. This improvement is\nexpected to increase in deeper networks, where several layers of pooling become\nnecessary.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 15:00:46 GMT"}, {"version": "v2", "created": "Sun, 15 Apr 2018 18:02:14 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Kumar", "Ashwani", ""]]}, {"id": "1804.02813", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Kosuke Tanabe, Toshiyuki Yamashita", "title": "An Adaptive Learning Method of Personality Trait Based Mood in Mental\n  State Transition Network by Recurrent Neural Network", "comments": "6 pages, 9 figures, Proc. of IEEE 7th International Workshop on\n  Computational Intelligence and Applications (IWCIA2014)", "journal-ref": null, "doi": "10.1109/IWCIA.2014.6988081", "report-no": null, "categories": "cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental State Transition Network (MSTN) is a basic concept of approximating to\nhuman psychological and mental responses. A stimulus calculated by Emotion\nGenerating Calculations (EGC) method can cause the transition of mood from an\nemotional state to others. In this paper, the agent can interact with human to\nrealize smooth communication by an adaptive learning method of the user's\npersonality trait based mood. The learning method consists of the profit\nsharing (PS) method and the recurrent neural network (RNN). An emotion for\nsensor inputs to MSTN is calculated by EGC and the variance of emotion leads to\nthe change of mental state, and then the sequence of states forms an episode.\nIn order to learn the tendency of personality trait effectively, the\nineffective rules should be removed from the episode. PS method finds out a\ndetour in episode and should be deleted. Furthermore, RNN works to realize the\nvariance of user's mood. Some experimental results were shown the success of\nrepresenting a various human's delicate emotion.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:41:27 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Tanabe", "Kosuke", ""], ["Yamashita", "Toshiyuki", ""]]}, {"id": "1804.02816", "submitter": "Takumi Ichimura", "authors": "Shin Kamada, Takumi Ichimura", "title": "A Generation Method of Immunological Memory in Clonal Selection\n  Algorithm by using Restricted Boltzmann Machines", "comments": "6 pages, 10 figures, Proc. of 2015 IEEE International Conference on\n  Systems, Man, and Cybernetics(IEEE SMC 2015)", "journal-ref": null, "doi": "10.1109/SMC.2015.465", "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a high technique of image processing is required to extract the\nimage features in real time. In our research, the tourist subject data are\ncollected from the Mobile Phone based Participatory Sensing (MPPS) system. Each\nrecord consists of image files with GPS, geographic location name, user's\nnumerical evaluation, and comments written in natural language at sightseeing\nspots where a user really visits. In our previous research, the famous\nlandmarks in sightseeing spot can be detected by Clonal Selection Algorithm\nwith Immunological Memory Cell (CSAIM). However, some landmarks was not\ndetected correctly by the previous method because they didn't have enough\namount of information for the feature extraction. In order to improve the\nweakness, we propose the generation method of immunological memory by\nRestricted Boltzmann Machines. To verify the effectiveness of the method, some\nexperiments for classification of the subjective data are executed by using\nmachine learning tools for Deep Learning.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 05:14:26 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Kamada", "Shin", ""], ["Ichimura", "Takumi", ""]]}, {"id": "1804.02827", "submitter": "Yaodong He", "authors": "Yaodong He, Jianfeng Zhou and Shiu Yin Yuen", "title": "Composing photomosaic images using clustering based evolutionary\n  programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photomosaic images are a type of images consisting of various tiny images. A\ncomplete form can be seen clearly by viewing it from a long distance. Small\ntiny images which replace blocks of the original image can be seen clearly by\nviewing it from a short distance. In the past, many algorithms have been\nproposed trying to automatically compose photomosaic images. Most of these\nalgorithms are designed with greedy algorithms to match the blocks with the\ntiny images. To obtain a better visual sense and satisfy some commercial\nrequirements, a constraint that a tiny image should not be repeatedly used many\ntimes is usually added. With the constraint, the photomosaic problem becomes a\ncombinatorial optimization problem. Evolutionary algorithms imitating the\nprocess of natural selection are popular and powerful in combinatorial\noptimization problems. However, little work has been done on applying\nevolutionary algorithms to photomosaic problem. In this paper, we present an\nalgorithm called clustering based evolutionary programming to deal with the\nproblem. We give prior knowledge to the optimization algorithm which makes the\noptimization process converges faster. In our experiment, the proposed\nalgorithm is compared with the state of the art algorithms and software. The\nresults indicate that our algorithm performs the best.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 05:57:24 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["He", "Yaodong", ""], ["Zhou", "Jianfeng", ""], ["Yuen", "Shiu Yin", ""]]}, {"id": "1804.02851", "submitter": "Bing Zeng", "authors": "Bing Zeng, Xinyu Li, Liang Gao, Yuyan Zhang, Haozhen Dong", "title": "Whale swarm algorithm with the mechanism of identifying and escaping\n  from extreme points for multimodal function optimization", "comments": "28 pages, 11 figures, 9 tables, 39 references", "journal-ref": null, "doi": "10.1007/s00521-018-3949-4", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real-world optimization problems often come with multiple global optima\nor local optima. Therefore, increasing niching metaheuristic algorithms, which\ndevote to finding multiple optima in a single run, are developed to solve these\nmultimodal optimization problems. However, there are two difficulties urgently\nto be solved for most existing niching metaheuristic algorithms: how to set the\noptimal values of niching parameters for different optimization problems, and\nhow to jump out of the local optima efficiently. These two difficulties limited\ntheir practicality largely. Based on Whale Swarm Algorithm (WSA) we proposed\npreviously, this paper presents a new multimodal optimizer named WSA with\nIterative Counter (WSA-IC) to address these two difficulties. In the one hand,\nWSA-IC improves the iteration rule of the original WSA for multimodal\noptimization, which removes the need of specifying different values of\nattenuation coefficient for different problems to form multiple subpopulations,\nwithout introducing any niching parameter. In the other hand, WSA-IC enables\nthe identification of extreme point during iterations relying on two new\nparameters (i.e., stability threshold Ts and fitness threshold Tf), to jump out\nof the located extreme point. Moreover, the convergence of WSA-IC is proved.\nFinally, the proposed WSA-IC is compared with several niching metaheuristic\nalgorithms on CEC2015 niching benchmark test functions and five additional\nclassical multimodal functions with high dimensions. The experimental results\ndemonstrate that WSA-IC statistically outperforms other niching metaheuristic\nalgorithms on most test functions.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 07:29:33 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 00:44:46 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 04:59:24 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Zeng", "Bing", ""], ["Li", "Xinyu", ""], ["Gao", "Liang", ""], ["Zhang", "Yuyan", ""], ["Dong", "Haozhen", ""]]}, {"id": "1804.02884", "submitter": "Duc Thien Nguyen", "authors": "Duc Thien Nguyen and Akshat Kumar and Hoong Chuin Lau", "title": "Policy Gradient With Value Function Approximation For Collective\n  Multiagent Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized (PO)MDPs provide an expressive framework for sequential\ndecision making in a multiagent system. Given their computational complexity,\nrecent research has focused on tractable yet practical subclasses of\nDec-POMDPs. We address such a subclass called CDEC-POMDP where the collective\nbehavior of a population of agents affects the joint-reward and environment\ndynamics. Our main contribution is an actor-critic (AC) reinforcement learning\nmethod for optimizing CDEC-POMDP policies. Vanilla AC has slow convergence for\nlarger problems. To address this, we show how a particular decomposition of the\napproximate action-value function over agents leads to effective updates, and\nalso derive a new way to train the critic based on local reward signals.\nComparisons on a synthetic benchmark and a real-world taxi fleet optimization\nproblem show that our new AC approach provides better quality solutions than\nprevious best approaches.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 09:45:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Nguyen", "Duc Thien", ""], ["Kumar", "Akshat", ""], ["Lau", "Hoong Chuin", ""]]}, {"id": "1804.03294", "submitter": "Tianyun Zhang", "authors": "Tianyun Zhang, Shaokai Ye, Kaiqi Zhang, Jian Tang, Wujie Wen, Makan\n  Fardad, Yanzhi Wang", "title": "A Systematic DNN Weight Pruning Framework using Alternating Direction\n  Method of Multipliers", "comments": null, "journal-ref": "ECCV 2018, pp 191-207", "doi": "10.1007/978-3-030-01237-3_12", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning methods for deep neural networks (DNNs) have been investigated\nrecently, but prior work in this area is mainly heuristic, iterative pruning,\nthereby lacking guarantees on the weight reduction ratio and convergence time.\nTo mitigate these limitations, we present a systematic weight pruning framework\nof DNNs using the alternating direction method of multipliers (ADMM). We first\nformulate the weight pruning problem of DNNs as a nonconvex optimization\nproblem with combinatorial constraints specifying the sparsity requirements,\nand then adopt the ADMM framework for systematic weight pruning. By using ADMM,\nthe original nonconvex optimization problem is decomposed into two subproblems\nthat are solved iteratively. One of these subproblems can be solved using\nstochastic gradient descent, the other can be solved analytically. Besides, our\nmethod achieves a fast convergence rate.\n  The weight pruning results are very promising and consistently outperform the\nprior work. On the LeNet-5 model for the MNIST data set, we achieve 71.2 times\nweight reduction without accuracy loss. On the AlexNet model for the ImageNet\ndata set, we achieve 21 times weight reduction without accuracy loss. When we\nfocus on the convolutional layer pruning for computation reductions, we can\nreduce the total computation by five times compared with the prior work\n(achieving a total of 13.4 times weight reduction in convolutional layers). Our\nmodels and codes are released at https://github.com/KaiqiZhang/admm-pruning\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 01:14:51 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 02:19:16 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 16:52:02 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Zhang", "Tianyun", ""], ["Ye", "Shaokai", ""], ["Zhang", "Kaiqi", ""], ["Tang", "Jian", ""], ["Wen", "Wujie", ""], ["Fardad", "Makan", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1804.03304", "submitter": "Hiroki Sayama", "authors": "Hiroki Sayama", "title": "Seeking Open-Ended Evolution in Swarm Chemistry II: Analyzing Long-Term\n  Dynamics via Automated Object Harvesting", "comments": "8 pages, 9 figures, to be published in the ALIFE 2018 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We studied the long-term dynamics of evolutionary Swarm Chemistry by\nextending the simulation length ten-fold compared to earlier work and by\ndeveloping and using a new automated object harvesting method. Both macroscopic\ndynamics and microscopic object features were characterized and tracked using\nseveral measures. Results showed that the evolutionary dynamics tended to\nsettle down into a stable state after the initial transient period, and that\nthe extent of environmental perturbations also affected the evolutionary trends\nsubstantially. In the meantime, the automated harvesting method successfully\nproduced a huge collection of spontaneously evolved objects, revealing the\nsystem's autonomous creativity at an unprecedented scale.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 01:34:38 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 01:24:49 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Sayama", "Hiroki", ""]]}, {"id": "1804.03313", "submitter": "Liyao Gao Mr.", "authors": "Liyao Gao", "title": "Cortex Neural Network: learning with Neural Network groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Network has been successfully applied to many real-world problems,\nsuch as image recognition and machine translation. However, for the current\narchitecture of neural networks, it is hard to perform complex cognitive tasks,\nfor example, to process the image and audio inputs together. Cortex, as an\nimportant architecture in the brain, is important for animals to perform the\ncomplex cognitive task. We view the architecture of Cortex in the brain as a\nmissing part in the design of the current artificial neural network. In this\npaper, we purpose Cortex Neural Network (CrtxNN). The Cortex Neural Network is\nan upper architecture of neural networks which motivated from cerebral cortex\nin the brain to handle different tasks in the same learning system. It is able\nto identify different tasks and solve them with different methods. In our\nimplementation, the Cortex Neural Network is able to process different\ncognitive tasks and perform reflection to get a higher accuracy. We provide a\nseries of experiments to examine the capability of the cortex architecture on\ntraditional neural networks. Our experiments proved its ability on the Cortex\nNeural Network can reach accuracy by 98.32% on MNIST and 62% on CIFAR10 at the\nsame time, which can promisingly reduce the loss by 40%.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 02:33:47 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gao", "Liyao", ""]]}, {"id": "1804.03395", "submitter": "Andrei Velichko", "authors": "Andrei Velichko, Vadim Putrolaynen, Maksim Belyaev", "title": "Higher Order and Long-Range Synchronization Effects for Classification\n  and Computing in Oscillator-Based Spiking Neural Networks", "comments": "25 pages, 13 figures", "journal-ref": "Neural Comput. Appl. 2020", "doi": "10.1007/s00521-020-05177-y", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the circuit of two thermally coupled VO2 oscillators, we studied a higher\norder synchronization effect, which can be used in object classification\ntechniques to increase the number of possible synchronous states of the\noscillator system. We developed the phase-locking estimation method to\ndetermine the values of subharmonic ratio and synchronization effectiveness. In\nour experiment, the number of possible synchronous states of the oscillator\nsystem was twelve, and subharmonic ratio distributions were shaped as Arnold's\ntongues. In the model, the number of states may reach the maximum value of 150\nat certain levels of coupling strength and noise. The long-range\nsynchronization effect in a one-dimensional chain of oscillators occurs even at\nlow values of synchronization effectiveness for intermediate links. We\ndemonstrate a technique for storing and recognizing vector images, which can\nused for reservoir computing. In addition, we present the implementation of\nanalog operation of multiplication, the synchronization based logic for binary\ncomputations, and the possibility to develop the interface between spike neural\nnetwork and a computer. Based on the universal physical effects, the high order\nsynchronization can be applied to any spiking oscillators with any coupling\ntype, enhancing the practical value of the presented results to expand spike\nneural network capabilities.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 08:30:48 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 04:23:51 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Velichko", "Andrei", ""], ["Putrolaynen", "Vadim", ""], ["Belyaev", "Maksim", ""]]}, {"id": "1804.03441", "submitter": "Andrea Biagioni", "authors": "Roberto Ammendola, Andrea Biagioni, Fabrizio Capuani, Paolo Cretaro,\n  Giulia De Bonis, Francesca Lo Cicero, Alessandro Lonardo, Michele Martinelli,\n  Pier Stanislao Paolucci, Elena Pastorelli, Luca Pontisso, Francesco Simula,\n  Piero Vicini", "title": "The Brain on Low Power Architectures - Efficient Simulation of Cortical\n  Slow Waves and Asynchronous States", "comments": null, "journal-ref": "(2018) Advances in Parallel Computing, 32, pp. 760-769", "doi": "10.3233/978-1-61499-843-3-760", "report-no": null, "categories": "cs.DC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient brain simulation is a scientific grand challenge, a\nparallel/distributed coding challenge and a source of requirements and\nsuggestions for future computing architectures. Indeed, the human brain\nincludes about 10^15 synapses and 10^11 neurons activated at a mean rate of\nseveral Hz. Full brain simulation poses Exascale challenges even if simulated\nat the highest abstraction level. The WaveScalES experiment in the Human Brain\nProject (HBP) has the goal of matching experimental measures and simulations of\nslow waves during deep-sleep and anesthesia and the transition to other brain\nstates. The focus is the development of dedicated large-scale\nparallel/distributed simulation technologies. The ExaNeSt project designs an\nARM-based, low-power HPC architecture scalable to million of cores, developing\na dedicated scalable interconnect system, and SWA/AW simulations are included\namong the driving benchmarks. At the joint between both projects is the INFN\nproprietary Distributed and Plastic Spiking Neural Networks (DPSNN) simulation\nengine. DPSNN can be configured to stress either the networking or the\ncomputation features available on the execution platforms. The simulation\nstresses the networking component when the neural net - composed by a\nrelatively low number of neurons, each one projecting thousands of synapses -\nis distributed over a large number of hardware cores. When growing the number\nof neurons per core, the computation starts to be the dominating component for\nshort range connections. This paper reports about preliminary performance\nresults obtained on an ARM-based HPC prototype developed in the framework of\nthe ExaNeSt project. Furthermore, a comparison is given of instantaneous power,\ntotal energy consumption, execution time and energetic cost per synaptic event\nof SWA/AW DPSNN simulations when executed on either ARM- or Intel-based server\nplatforms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:39:25 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Ammendola", "Roberto", ""], ["Biagioni", "Andrea", ""], ["Capuani", "Fabrizio", ""], ["Cretaro", "Paolo", ""], ["De Bonis", "Giulia", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Martinelli", "Michele", ""], ["Paolucci", "Pier Stanislao", ""], ["Pastorelli", "Elena", ""], ["Pontisso", "Luca", ""], ["Simula", "Francesco", ""], ["Vicini", "Piero", ""]]}, {"id": "1804.03826", "submitter": "Junpei Zhong", "authors": "Junpei Zhong and Angelo Cangelosi and Xinzheng Zhang and Tetsuya Ogata", "title": "AFA-PredNet: The action modulation within predictive coding", "comments": "Accepted: International Joint Conference on Neural Networks (IJCNN\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictive processing (PP) hypothesizes that the predictive inference of\nour sensorimotor system is encoded implicitly in the regularities between\nperception and action. We propose a neural architecture in which such\nregularities of active inference are encoded hierarchically. We further suggest\nthat this encoding emerges during the embodied learning process when the\nappropriate action is selected to minimize the prediction error in perception.\nTherefore, this predictive stream in the sensorimotor loop is generated in a\ntop-down manner. Specifically, it is constantly modulated by the motor actions\nand is updated by the bottom-up prediction error signals. In this way, the\ntop-down prediction originally comes from the prior experience from both\nperception and action representing the higher levels of this hierarchical\ncognition. In our proposed embodied model, we extend the PredNet Network, a\nhierarchical predictive coding network, with the motor action units implemented\nby a multi-layer perceptron network (MLP) to modulate the network top-down\nprediction. Two experiments, a minimalistic world experiment, and a mobile\nrobot experiment are conducted to evaluate the proposed model in a qualitative\nway. In the neural representation, it can be observed that the causal inference\nof predictive percept from motor actions can be also observed while the agent\nis interacting with the environment.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 06:14:22 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Zhong", "Junpei", ""], ["Cangelosi", "Angelo", ""], ["Zhang", "Xinzheng", ""], ["Ogata", "Tetsuya", ""]]}, {"id": "1804.03906", "submitter": "Vassilis Vassiliades", "authors": "Vassilis Vassiliades and Jean-Baptiste Mouret", "title": "Discovering the Elite Hypervolume by Leveraging Interspecies Correlation", "comments": "In GECCO 2018", "journal-ref": null, "doi": "10.1145/3205455.3205602", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution has produced an astonishing diversity of species, each filling a\ndifferent niche. Algorithms like MAP-Elites mimic this divergent evolutionary\nprocess to find a set of behaviorally diverse but high-performing solutions,\ncalled the elites. Our key insight is that species in nature often share a\nsurprisingly large part of their genome, in spite of occupying very different\nniches; similarly, the elites are likely to be concentrated in a specific\n\"elite hypervolume\" whose shape is defined by their common features. In this\npaper, we first introduce the elite hypervolume concept and propose two metrics\nto characterize it: the genotypic spread and the genotypic similarity. We then\nintroduce a new variation operator, called \"directional variation\", that\nexploits interspecies (or inter-elites) correlations to accelerate the\nMAP-Elites algorithm. We demonstrate the effectiveness of this operator in\nthree problems (a toy function, a redundant robotic arm, and a hexapod robot).\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 09:53:05 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Vassiliades", "Vassilis", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1804.04177", "submitter": "Amir Rubin", "authors": "Danny Hendler, Shay Kels, Amir Rubin", "title": "Detecting Malicious PowerShell Commands using Deep Neural Networks", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microsoft's PowerShell is a command-line shell and scripting language that is\ninstalled by default on Windows machines. While PowerShell can be configured by\nadministrators for restricting access and reducing vulnerabilities, these\nrestrictions can be bypassed. Moreover, PowerShell commands can be easily\ngenerated dynamically, executed from memory, encoded and obfuscated, thus\nmaking the logging and forensic analysis of code executed by PowerShell\nchallenging.For all these reasons, PowerShell is increasingly used by\ncybercriminals as part of their attacks' tool chain, mainly for downloading\nmalicious contents and for lateral movement. Indeed, a recent comprehensive\ntechnical report by Symantec dedicated to PowerShell's abuse by cybercrimials\nreported on a sharp increase in the number of malicious PowerShell samples they\nreceived and in the number of penetration tools and frameworks that use\nPowerShell. This highlights the urgent need of developing effective methods for\ndetecting malicious PowerShell commands.In this work, we address this challenge\nby implementing several novel detectors of malicious PowerShell commands and\nevaluating their performance. We implemented both \"traditional\" natural\nlanguage processing (NLP) based detectors and detectors based on\ncharacter-level convolutional neural networks (CNNs). Detectors' performance\nwas evaluated using a large real-world dataset.Our evaluation results show\nthat, although our detectors individually yield high performance, an ensemble\ndetector that combines an NLP-based classifier with a CNN-based classifier\nprovides the best performance, since the latter classifier is able to detect\nmalicious commands that succeed in evading the former. Our analysis of these\nevasive commands reveals that some obfuscation patterns automatically detected\nby the CNN classifier are intrinsically difficult to detect using the NLP\ntechniques we applied.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 19:16:03 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 10:01:48 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Hendler", "Danny", ""], ["Kels", "Shay", ""], ["Rubin", "Amir", ""]]}, {"id": "1804.04187", "submitter": "Nick Moran", "authors": "Nick Moran and Jordan Pollack", "title": "Coevolutionary Neural Population Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We present a method for using neural networks to model evolutionary\npopulation dynamics, and draw parallels to recent deep learning advancements in\nwhich adversarially-trained neural networks engage in coevolutionary\ninteractions. We conduct experiments which demonstrate that models from\nevolutionary game theory are capable of describing the behavior of these neural\npopulation systems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 19:57:06 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Moran", "Nick", ""], ["Pollack", "Jordan", ""]]}, {"id": "1804.04286", "submitter": "Sam Kriegman", "authors": "Shawn L.E. Beaulieu, Sam Kriegman, Josh C. Bongard", "title": "Combating catastrophic forgetting with developmental compression", "comments": null, "journal-ref": null, "doi": "10.1145/3205455.3205615", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generally intelligent agents exhibit successful behavior across problems in\nseveral settings. Endemic in approaches to realize such intelligence in\nmachines is catastrophic forgetting: sequential learning corrupts knowledge\nobtained earlier in the sequence, or tasks antagonistically compete for system\nresources. Methods for obviating catastrophic forgetting have sought to\nidentify and preserve features of the system necessary to solve one problem\nwhen learning to solve another, or to enforce modularity such that minimally\noverlapping sub-functions contain task specific knowledge. While successful,\nboth approaches scale poorly because they require larger architectures as the\nnumber of training instances grows, causing different parts of the system to\nspecialize for separate subsets of the data. Here we present a method for\naddressing catastrophic forgetting called developmental compression. It\nexploits the mild impacts of developmental mutations to lessen adverse changes\nto previously-evolved capabilities and `compresses' specialized neural networks\ninto a generalized one. In the absence of domain knowledge, developmental\ncompression produces systems that avoid overt specialization, alleviating the\nneed to engineer a bespoke system for every task permutation and suggesting\nbetter scalability than existing approaches. We validate this method on a robot\ncontrol problem and hope to extend this approach to other machine learning\ndomains in the future.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 02:20:47 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Beaulieu", "Shawn L. E.", ""], ["Kriegman", "Sam", ""], ["Bongard", "Josh C.", ""]]}, {"id": "1804.04612", "submitter": "Saksham Kukreja", "authors": "Saksham Kukreja", "title": "A Comprehensive Study on the Applications of Machine Learning for the\n  Medical Diagnosis and Prognosis of Asthma", "comments": "27 pages. arXiv admin note: text overlap with arXiv:1505.01345 by\n  other authors without attribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An estimated 300 million people worldwide suffer from asthma, and this number\nis expected to increase to 400 million by 2025. Approximately 250,000 people\ndie prematurely each year from asthma out of which, almost all deaths are\navoidable. Most of these deaths occur because the patients are unaware of their\nasthmatic morbidity. If detected early, asthmatic mortality rate can be reduced\nby 78%, provided that the patients carry appropriate medication for the same\nand/or are in lose vicinity to medical equipment like nebulizers. This study\nfocuses on the development and valuation of algorithms to diagnose asthma\nthrough symptom intensive questionary, clinical data and medical reports.\nMachine Learning Algorithms like Back-propagation model, Context Sensitive\nAuto-Associative Memory Neural Network Model, C4.5 Algorithm, Bayesian Network\nand Particle Swarm Optimization have been employed for the diagnosis of asthma\nand later a comparison is made between their respective prospects. All\nalgorithms received an accuracy of over 80%. However, the use of Auto\nAssociative Memory Model (on a layered Artificial Neural Network) displayed\nmuch better results. It reached to an accuracy of over 90% and an inconclusive\ndiagnosis rate of less than 1% when trained with adequate data. In the end,\nna\\\"ive mobile based applications were developed on Android and iOS that made\nuse of the self-training auto associative memory model to achieve an accuracy\nof nearly 94.2%.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 13:21:51 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Kukreja", "Saksham", ""]]}, {"id": "1804.04749", "submitter": "Christoph Treude", "authors": "Christoph Treude and Markus Wagner", "title": "Predicting Good Configurations for GitHub and Stack Overflow Topic\n  Models", "comments": "to appear as full paper at MSR 2019, the 16th International\n  Conference on Mining Software Repositories", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software repositories contain large amounts of textual data, ranging from\nsource code comments and issue descriptions to questions, answers, and comments\non Stack Overflow. To make sense of this textual data, topic modelling is\nfrequently used as a text-mining tool for the discovery of hidden semantic\nstructures in text bodies. Latent Dirichlet allocation (LDA) is a commonly used\ntopic model that aims to explain the structure of a corpus by grouping texts.\nLDA requires multiple parameters to work well, and there are only rough and\nsometimes conflicting guidelines available on how these parameters should be\nset. In this paper, we contribute (i) a broad study of parameters to arrive at\ngood local optima for GitHub and Stack Overflow text corpora, (ii) an\na-posteriori characterisation of text corpora related to eight programming\nlanguages, and (iii) an analysis of corpus feature importance via per-corpus\nLDA configuration. We find that (1) popular rules of thumb for topic modelling\nparameter configuration are not applicable to the corpora used in our\nexperiments, (2) corpora sampled from GitHub and Stack Overflow have different\ncharacteristics and require different configurations to achieve good model fit,\nand (3) we can predict good configurations for unseen corpora reliably. These\nfindings support researchers and practitioners in efficiently determining\nsuitable configurations for topic modelling when analysing textual data\ncontained in software repositories.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 00:09:48 GMT"}, {"version": "v2", "created": "Sat, 23 Jun 2018 11:30:52 GMT"}, {"version": "v3", "created": "Sun, 10 Mar 2019 07:38:41 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Treude", "Christoph", ""], ["Wagner", "Markus", ""]]}, {"id": "1804.04806", "submitter": "Yosuke Oyama", "authors": "Yosuke Oyama, Tal Ben-Nun, Torsten Hoefler, Satoshi Matsuoka", "title": "{\\mu}-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching", "comments": "11 pages, 14 figures. Part of the content have been published in IPSJ\n  SIG Technical Report, Vol. 2017-HPC-162, No. 22, pp. 1-9, 2017. (DOI:\n  http://id.nii.ac.jp/1001/00184814)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used\nin deep learning. Specifically, cuDNN implements several equivalent convolution\nalgorithms, whose performance and memory footprint may vary considerably,\ndepending on the layer dimensions. When an algorithm is automatically selected\nby cuDNN, the decision is performed on a per-layer basis, and thus it often\nresorts to slower algorithms that fit the workspace size constraints. We\npresent {\\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides\nlayers' mini-batch computation into several micro-batches. Based on Dynamic\nProgramming and Integer Linear Programming, {\\mu}-cuDNN enables faster\nalgorithms by decreasing the workspace requirements. At the same time,\n{\\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples\nstatistical efficiency from the hardware efficiency safely. We demonstrate the\neffectiveness of {\\mu}-cuDNN over two frameworks, Caffe and TensorFlow,\nachieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2\nGPU. These results indicate that using micro-batches can seamlessly increase\nthe performance of deep learning, while maintaining the same memory footprint.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 07:20:44 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Oyama", "Yosuke", ""], ["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""], ["Matsuoka", "Satoshi", ""]]}, {"id": "1804.04849", "submitter": "Jos van der Westhuizen", "authors": "Jos van der Westhuizen and Joan Lasenby", "title": "The unreasonable effectiveness of the forget gate", "comments": "Corrected LSTM gradient derivations. Added link to code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the success of the gated recurrent unit, a natural question is whether\nall the gates of the long short-term memory (LSTM) network are necessary.\nPrevious research has shown that the forget gate is one of the most important\ngates in the LSTM. Here we show that a forget-gate-only version of the LSTM\nwith chrono-initialized biases, not only provides computational savings but\noutperforms the standard LSTM on multiple benchmark datasets and competes with\nsome of the best contemporary models. Our proposed network, the JANET, achieves\naccuracies of 99% and 92.5% on the MNIST and pMNIST datasets, outperforming the\nstandard LSTM which yields accuracies of 98.5% and 91%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 09:18:17 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 17:23:40 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 10:55:56 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["van der Westhuizen", "Jos", ""], ["Lasenby", "Joan", ""]]}, {"id": "1804.04890", "submitter": "Osamu Shouno", "authors": "Kristof B. Charbonneau and Osamu Shouno", "title": "Neural Trajectory Analysis of Recurrent Neural Network In Handwriting\n  Synthesis", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are capable of learning to generate highly\nrealistic, online handwritings in a wide variety of styles from a given text\nsequence. Furthermore, the networks can generate handwritings in the style of a\nparticular writer when the network states are primed with a real sequence of\npen movements from the writer. However, how populations of neurons in the RNN\ncollectively achieve such performance still remains poorly understood. To\ntackle this problem, we investigated learned representations in RNNs by\nextracting low-dimensional, neural trajectories that summarize the activity of\na population of neurons in the network during individual syntheses of\nhandwritings. The neural trajectories show that different writing styles are\nencoded in different subspaces inside an internal space of the network. Within\neach subspace, different characters of the same style are represented as\ndifferent state dynamics. These results demonstrate the effectiveness of\nanalyzing the neural trajectory for intuitive understanding of how the RNNs\nwork.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 11:31:06 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Charbonneau", "Kristof B.", ""], ["Shouno", "Osamu", ""]]}, {"id": "1804.05012", "submitter": "Phil Long", "authors": "Peter L. Bartlett, Steven N. Evans and Philip M. Long", "title": "Representing smooth functions as compositions of near-identity functions\n  with implications for deep network optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any smooth bi-Lipschitz $h$ can be represented exactly as a\ncomposition $h_m \\circ ... \\circ h_1$ of functions $h_1,...,h_m$ that are close\nto the identity in the sense that each $\\left(h_i-\\mathrm{Id}\\right)$ is\nLipschitz, and the Lipschitz constant decreases inversely with the number $m$\nof functions composed. This implies that $h$ can be represented to any accuracy\nby a deep residual network whose nonlinear layers compute functions with a\nsmall Lipschitz constant. Next, we consider nonlinear regression with a\ncomposition of near-identity nonlinear maps. We show that, regarding Fr\\'echet\nderivatives with respect to the $h_1,...,h_m$, any critical point of a\nquadratic criterion in this near-identity region must be a global minimizer. In\ncontrast, if we consider derivatives with respect to parameters of a fixed-size\nresidual network with sigmoid activation functions, we show that there are\nnear-identity critical points that are suboptimal, even in the realizable case.\nInformally, this means that functional gradient methods for residual networks\ncannot get stuck at suboptimal critical points corresponding to near-identity\nlayers, whereas parametric gradient methods for sigmoidal residual networks\nsuffer from suboptimal critical points in the near-identity region.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:24:17 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 17:07:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Evans", "Steven N.", ""], ["Long", "Philip M.", ""]]}, {"id": "1804.05093", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Serkan Kiranyaz, Moncef Gabbouj and Alexandros\n  Iosifidis", "title": "Heterogeneous Multilayer Generalized Operational Perceptron", "comments": "Accepted in IEEE Transaction on Neural Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2019.2914082", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional Multilayer Perceptron (MLP) using McCulloch-Pitts neuron\nmodel is inherently limited to a set of neuronal activities, i.e., linear\nweighted sum followed by nonlinear thresholding step. Previously, Generalized\nOperational Perceptron (GOP) was proposed to extend conventional perceptron\nmodel by defining a diverse set of neuronal activities to imitate a generalized\nmodel of biological neurons. Together with GOP, Progressive Operational\nPerceptron (POP) algorithm was proposed to optimize a pre-defined template of\nmultiple homogeneous layers in a layerwise manner. In this paper, we propose an\nefficient algorithm to learn a compact, fully heterogeneous multilayer network\nthat allows each individual neuron, regardless of the layer, to have distinct\ncharacteristics. Based on the complexity of the problem, the proposed algorithm\noperates in a progressive manner on a neuronal level, searching for a compact\ntopology, not only in terms of depth but also width, i.e., the number of\nneurons in each layer. The proposed algorithm is shown to outperform other\nrelated learning methods in extensive experiments on several classification\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 19:37:39 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 18:46:18 GMT"}, {"version": "v3", "created": "Sat, 27 Apr 2019 12:15:51 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Kiranyaz", "Serkan", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1804.05208", "submitter": "Maxim Buzdalov", "authors": "Ilya Yakupov and Maxim Buzdalov", "title": "On Asynchronous Non-Dominated Sorting for Steady-State Multiobjective\n  Evolutionary Algorithms", "comments": "An extended abstract of this work will appear in proceedings of GECCO\n  2018", "journal-ref": null, "doi": "10.1145/3205651.3205802", "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In parallel and distributed environments, generational evolutionary\nalgorithms often do not exploit the full potential of the computation system\nsince they have to wait until the entire population is evaluated before\nstarting selection procedures. Steady-state algorithms are often seen as a\nsolution to this problem, since fitness evaluation can be done by multiple\nthreads in an asynchronous way. However, if the algorithm updates its state in\na complicated way, the threads will eventually have to wait until this update\nfinishes. State update procedures that are computationally expensive are common\nin multiobjective evolutionary algorithms.\n  We have implemented an asynchronous steady-state version of the NSGA-II\nalgorithm. Its most expensive part, non-dominated sorting, determines the time\nneeded to update the state. We turned the existing incremental non-dominated\nsorting algorithm into an asynchronous one using several concurrency\ntechniques: a single entry-level lock, finer-grained locks working with\nnon-domination levels, and a non-blocking approach using compare-and-set\noperations. Our experimental results reveal the trade-off between the\nwork-efficiency of the algorithm and the achieved amount of parallelism.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 12:03:25 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Yakupov", "Ilya", ""], ["Buzdalov", "Maxim", ""]]}, {"id": "1804.05267", "submitter": "Marc Ortiz", "authors": "Marc Ortiz, Adri\\'an Cristal, Eduard Ayguad\\'e and Marc Casas", "title": "Low-Precision Floating-Point Schemes for Neural Network Training", "comments": "16 pages, 9 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of low-precision fixed-point arithmetic along with stochastic\nrounding has been proposed as a promising alternative to the commonly used\n32-bit floating point arithmetic to enhance training neural networks training\nin terms of performance and energy efficiency. In the first part of this paper,\nthe behaviour of the 12-bit fixed-point arithmetic when training a\nconvolutional neural network with the CIFAR-10 dataset is analysed, showing\nthat such arithmetic is not the most appropriate for the training phase. After\nthat, the paper presents and evaluates, under the same conditions, alternative\nlow-precision arithmetics, starting with the 12-bit floating-point arithmetic.\nThese two representations are then leveraged using local scaling in order to\nincrease accuracy and get closer to the baseline 32-bit floating-point\narithmetic. Finally, the paper introduces a simplified model in which both the\noutputs and the gradients of the neural networks are constrained to\npower-of-two values, just using 7 bits for their representation. The evaluation\ndemonstrates a minimal loss in accuracy for the proposed Power-of-Two neural\nnetwork, avoiding the use of multiplications and divisions and thereby,\nsignificantly reducing the training time as well as the energy consumption and\nmemory requirements during the training and inference phases.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 19:10:07 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ortiz", "Marc", ""], ["Cristal", "Adri\u00e1n", ""], ["Ayguad\u00e9", "Eduard", ""], ["Casas", "Marc", ""]]}, {"id": "1804.05319", "submitter": "Saptarshi Sengupta", "authors": "Saptarshi Sengupta, Sanchita Basak, Richard Alan Peters II", "title": "Particle Swarm Optimization: A survey of historical and recent\n  developments with hybridization perspectives", "comments": "34 pages, 7 tables", "journal-ref": "Mach. Learn. Knowl. Extr. 2018, 1(1), 157-191", "doi": "10.3390/make1010010", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle Swarm Optimization (PSO) is a metaheuristic global optimization\nparadigm that has gained prominence in the last two decades due to its ease of\napplication in unsupervised, complex multidimensional problems which cannot be\nsolved using traditional deterministic algorithms. The canonical particle swarm\noptimizer is based on the flocking behavior and social co-operation of birds\nand fish schools and draws heavily from the evolutionary behavior of these\norganisms. This paper serves to provide a thorough survey of the PSO algorithm\nwith special emphasis on the development, deployment and improvements of its\nmost basic as well as some of the state-of-the-art implementations. Concepts\nand directions on choosing the inertia weight, constriction factor, cognition\nand social weights and perspectives on convergence, parallelization, elitism,\nniching and discrete optimization as well as neighborhood topologies are\noutlined. Hybridization attempts with other evolutionary and swarm paradigms in\nselected applications are covered and an up-to-date review is put forward for\nthe interested reader.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 08:26:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 17:16:35 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Sengupta", "Saptarshi", ""], ["Basak", "Sanchita", ""], ["Peters", "Richard Alan", "II"]]}, {"id": "1804.05364", "submitter": "Adam Gaier", "authors": "Adam Gaier, Alexander Asteroth, Jean-Baptiste Mouret", "title": "Data-efficient Neuroevolution with Kernel-Based Surrogate Models", "comments": "In GECCO 2018", "journal-ref": null, "doi": "10.1145/3205455.3205510", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate-assistance approaches have long been used in computationally\nexpensive domains to improve the data-efficiency of optimization algorithms.\nNeuroevolution, however, has so far resisted the application of these\ntechniques because it requires the surrogate model to make fitness predictions\nbased on variable topologies, instead of a vector of parameters. Our main\ninsight is that we can sidestep this problem by using kernel-based surrogate\nmodels, which require only the definition of a distance measure between\nindividuals. Our second insight is that the well-established Neuroevolution of\nAugmenting Topologies (NEAT) algorithm provides a computationally efficient\ndistance measure between dissimilar networks in the form of \"compatibility\ndistance\", initially designed to maintain topological diversity. Combining\nthese two ideas, we introduce a surrogate-assisted neuroevolution algorithm\nthat combines NEAT and a surrogate model built using a compatibility distance\nkernel. We demonstrate the data-efficiency of this new algorithm on the low\ndimensional cart-pole swing-up problem, as well as the higher dimensional\nhalf-cheetah running task. In both tasks the surrogate-assisted variant\nachieves the same or better results with several times fewer function\nevaluations as the original NEAT.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 14:54:49 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 13:40:00 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Gaier", "Adam", ""], ["Asteroth", "Alexander", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1804.05374", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Dmitriy Serdyuk, Yoshua Bengio", "title": "Twin Regularization for online speech recognition", "comments": "Accepted at INTESPEECH 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online speech recognition is crucial for developing natural human-machine\ninterfaces. This modality, however, is significantly more challenging than\noff-line ASR, since real-time/low-latency constraints inevitably hinder the use\nof future information, that is known to be very helpful to perform robust\npredictions. A popular solution to mitigate this issue consists of feeding\nneural acoustic models with context windows that gather some future frames.\nThis introduces a latency which depends on the number of employed look-ahead\nfeatures. This paper explores a different approach, based on estimating the\nfuture rather than waiting for it. Our technique encourages the hidden\nrepresentations of a unidirectional recurrent network to embed some useful\ninformation about the future. Inspired by a recently proposed technique called\nTwin Networks, we add a regularization term that forces forward hidden states\nto be as close as possible to cotemporal backward ones, computed by a \"twin\"\nneural network running backwards in time. The experiments, conducted on a\nnumber of datasets, recurrent architectures, input features, and acoustic\nconditions, have shown the effectiveness of this approach. One important\nadvantage is that our method does not introduce any additional computation at\ntest time if compared to standard unidirectional recurrent networks.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 15:52:16 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 01:00:03 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Serdyuk", "Dmitriy", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.05429", "submitter": "James Bevins", "authors": "James Bevins and Rachel Slaybaugh", "title": "Gnowee: A Hybrid Metaheuristic Optimization Algorithm for Constrained,\n  Black Box, Combinatorial Mixed-Integer Design", "comments": "43 pages, 7 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Gnowee, a modular, Python-based, open-source hybrid\nmetaheuristic optimization algorithm (Available from\nhttps://github.com/SlaybaughLab/Gnowee). Gnowee is designed for rapid\nconvergence to nearly globally optimum solutions for complex, constrained\nnuclear engineering problems with mixed-integer and combinatorial design\nvectors and high-cost, noisy, discontinuous, black box objective function\nevaluations. Gnowee's hybrid metaheuristic framework is a new combination of a\nset of diverse, robust heuristics that appropriately balance diversification\nand intensification strategies across a wide range of optimization problems.\n  This novel algorithm was specifically developed to optimize complex nuclear\ndesign problems; the motivating research problem was the design of material\nstack-ups to modify neutron energy spectra to specific targeted spectra for\napplications in nuclear medicine, technical nuclear forensics, nuclear physics,\netc. However, there are a wider range of potential applications for this\nalgorithm both within the nuclear community and beyond. To demonstrate Gnowee's\nbehavior for a variety of problem types, comparisons between Gnowee and several\nwell-established metaheuristic algorithms are made for a set of eighteen\ncontinuous, mixed-integer, and combinatorial benchmarks. These results\ndemonstrate Gnoweee to have superior flexibility and convergence\ncharacteristics over a wide range of design spaces. We anticipate this wide\nrange of applicability will make this algorithm desirable for many complex\nengineering applications.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 21:16:17 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bevins", "James", ""], ["Slaybaugh", "Rachel", ""]]}, {"id": "1804.05443", "submitter": "Maxim Buzdalov", "authors": "Nina Bulanova and Maxim Buzdalov", "title": "Better Fixed-Arity Unbiased Black-Box Algorithms", "comments": "An extended abstract will appear at GECCO'18", "journal-ref": null, "doi": "10.1145/3205651.3205762", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their GECCO'12 paper, Doerr and Doerr proved that the $k$-ary unbiased\nblack-box complexity of OneMax on $n$ bits is $O(n/k)$ for $2\\le k\\le O(\\log\nn)$. We propose an alternative strategy for achieving this unbiased black-box\ncomplexity when $3\\le k\\le\\log_2 n$. While it is based on the same idea of\nblock-wise optimization, it uses $k$-ary unbiased operators in a different way.\n  For each block of size $2^{k-1}-1$ we set up, in $O(k)$ queries, a virtual\ncoordinate system, which enables us to use an arbitrary unrestricted algorithm\nto optimize this block. This is possible because this coordinate system\nintroduces a bijection between unrestricted queries and a subset of $k$-ary\nunbiased operators. We note that this technique does not depend on OneMax being\nsolved and can be used in more general contexts.\n  This together constitutes an algorithm which is conceptually simpler than the\none by Doerr and Doerr, and at the same time achieves better constant factors\nin the asymptotic notation. Our algorithm works in $(2+o(1))\\cdot n/(k-1)$,\nwhere $o(1)$ relates to $k$. Our experimental evaluation of this algorithm\nshows its efficiency already for $3\\le k\\le6$.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 22:40:42 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 14:44:23 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Bulanova", "Nina", ""], ["Buzdalov", "Maxim", ""]]}, {"id": "1804.05445", "submitter": "Alexander Lalejini", "authors": "Alexander Lalejini and Charles Ofria", "title": "Evolving Event-driven Programs with SignalGP", "comments": null, "journal-ref": null, "doi": "10.1145/3205455.3205523", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SignalGP, a new genetic programming (GP) technique designed to\nincorporate the event-driven programming paradigm into computational\nevolution's toolbox. Event-driven programming is a software design philosophy\nthat simplifies the development of reactive programs by automatically\ntriggering program modules (event-handlers) in response to external events,\nsuch as signals from the environment or messages from other programs. SignalGP\nincorporates these concepts by extending existing tag-based referencing\ntechniques into an event-driven context. Both events and functions are labeled\nwith evolvable tags; when an event occurs, the function with the closest\nmatching tag is triggered. In this work, we apply SignalGP in the context of\nlinear GP. We demonstrate the value of the event-driven paradigm using two\ndistinct test problems (an environment coordination problem and a distributed\nleader election problem) by comparing SignalGP to variants that are otherwise\nidentical, but must actively use sensors to process events or messages. In each\nof these problems, rapid interaction with the environment or other agents is\ncritical for maximizing fitness. We also discuss ways in which SignalGP can be\ngeneralized beyond our linear GP implementation.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 22:47:41 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Lalejini", "Alexander", ""], ["Ofria", "Charles", ""]]}, {"id": "1804.05554", "submitter": "Bert Moons", "authors": "Bert Moons, Daniel Bankman, Lita Yang, Boris Murmann, Marian Verhelst", "title": "BinarEye: An Always-On Energy-Accuracy-Scalable Binary CNN Processor\n  With All Memory On Chip in 28nm CMOS", "comments": "Presented at the 2018 IEEE Custom Integrated Circuits Conference\n  (CICC). Presentation is available here:\n  https://www.researchgate.net/publication/324452819_Presentation_on_Binareye_at_CICC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces BinarEye: a digital processor for always-on Binary\nConvolutional Neural Networks. The chip maximizes data reuse through a Neuron\nArray exploiting local weight Flip-Flops. It stores full network models and\nfeature maps and hence requires no off-chip bandwidth, which leads to a 230\n1b-TOPS/W peak efficiency. Its 3 levels of flexibility - (a) weight\nreconfiguration, (b) a programmable network depth and (c) a programmable\nnetwork width - allow trading energy for accuracy depending on the task's\nrequirements. BinarEye's full system input-to-label energy consumption ranges\nfrom 14.4uJ/f for 86% CIFAR-10 and 98% owner recognition down to 0.92uJ/f for\n94% face detection at up to 1700 frames per second. This is 3-12-70x more\nefficient than the state-of-the-art at on-par accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 08:51:29 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Moons", "Bert", ""], ["Bankman", "Daniel", ""], ["Yang", "Lita", ""], ["Murmann", "Boris", ""], ["Verhelst", "Marian", ""]]}, {"id": "1804.05650", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr and Carola Doerr", "title": "Theory of Parameter Control for Discrete Black-Box Optimization:\n  Provable Performance Gains Through Dynamic Parameter Choices", "comments": null, "journal-ref": "In Benjamin Doerr and Frank Neumann, Theory of Evolutionary\n  Computation: Recent Developments in Discrete Optimization, pages 271-321,\n  Springer, 2020", "doi": "10.1007/978-3-030-29414-4_6", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter control aims at realizing performance gains through a dynamic\nchoice of the parameters which determine the behavior of the underlying\noptimization algorithm. In the context of evolutionary algorithms this research\nline has for a long time been dominated by empirical approaches. With the\nsignificant advances in running time analysis achieved in the last ten years,\nthe parameter control question has become accessible to theoretical\ninvestigations. A number of running time results for a broad range of different\nparameter control mechanisms have been obtained in recent years. This book\nchapter surveys these works, and puts them into context, by proposing an\nupdated classification scheme for parameter control.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 13:07:05 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 21:33:40 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 23:36:53 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Doerr", "Benjamin", ""], ["Doerr", "Carola", ""]]}, {"id": "1804.05978", "submitter": "Martin Pil\\'at", "authors": "Martin Pil\\'at", "title": "Controlling the Charging of Electric Vehicles with Neural Networks", "comments": "8 pages, 3 figures, accepted for IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489027", "report-no": null, "categories": "cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and evaluate controllers for the coordination of the charging of\nelectric vehicles. The controllers are based on neural networks and are\ncompletely de-centralized, in the sense that the charging current is completely\ndecided by the controller itself. One of the versions of the controllers does\nnot require any outside communication at all.\n  We test controllers based on two different architectures of neural networks -\nthe feed-forward networks and the echo state networks. The networks are\noptimized by either an evolutionary algorithm (CMA-ES) or by a gradient-based\nmethod. The results of the different architectures and the different\noptimization algorithms are compared in a realistic scenario. We show that the\ncontrollers are able to charge the cars while keeping the peak consumptions\nalmost the same as when no charging is performed. Moreover, the controllers\nfill the valleys of the consumption thus reducing the difference between the\nmaximum and minimum consumption in the grid.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 23:20:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Pil\u00e1t", "Martin", ""]]}, {"id": "1804.06173", "submitter": "Phan Trung Hai Nguyen", "authors": "Phan Trung Hai Nguyen and Dirk Sudholt", "title": "Memetic Algorithms Beat Evolutionary Algorithms on the Class of Hurdle\n  Problems", "comments": "21 pages, 03 figures", "journal-ref": "Proceedings of the 2018 Genetic and Evolutionary Computation\n  Conference", "doi": "10.1145/3205455.3205456", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memetic algorithms are popular hybrid search heuristics that integrate local\nsearch into the search process of an evolutionary algorithm in order to combine\nthe advantages of rapid exploitation and global optimisation. However, these\nalgorithms are not well understood and the field is lacking a solid theoretical\nfoundation that explains when and why memetic algorithms are effective.\n  We provide a rigorous runtime analysis of a simple memetic algorithm, the\n$(1+1)$ MA, on the Hurdle problem class, a landscape class of tuneable\ndifficulty that shows a \"big valley structure\", a characteristic feature of\nmany hard problems from combinatorial optimisation. The only parameter of this\nclass is the hurdle width w, which describes the length of fitness valleys that\nhave to be overcome. We show that the $(1+1)$ EA requires $\\Theta(n^w)$\nexpected function evaluations to find the optimum, whereas the $(1+1)$ MA with\nbest-improvement and first-improvement local search can find the optimum in\n$\\Theta(n^2+n^3/w^2)$ and $\\Theta(n^3/w^2)$ function evaluations, respectively.\nSurprisingly, while increasing the hurdle width makes the problem harder for\nevolutionary algorithms, the problem becomes easier for memetic algorithms. We\ndiscuss how these findings can explain and illustrate the success of memetic\nalgorithms for problems with big valley structures.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 11:35:21 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Nguyen", "Phan Trung Hai", ""], ["Sudholt", "Dirk", ""]]}, {"id": "1804.06318", "submitter": "Misha Denil", "authors": "Brandon Amos, Laurent Dinh, Serkan Cabi, Thomas Roth\\\"orl, Sergio\n  G\\'omez Colmenarejo, Alistair Muldal, Tom Erez, Yuval Tassa, Nando de\n  Freitas, Misha Denil", "title": "Learning Awareness Models", "comments": "Accepted to ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of an agent with a fixed body interacting with an\nunknown and uncertain external world. We show that models trained to predict\nproprioceptive information about the agent's body come to represent objects in\nthe external world. In spite of being trained with only internally available\nsignals, these dynamic body models come to represent external objects through\nthe necessity of predicting their effects on the agent's own body. That is, the\nmodel learns holistic persistent representations of objects in the world, even\nthough the only training signals are body signals. Our dynamics model is able\nto successfully predict distributions over 132 sensor readings over 100 steps\ninto the future and we demonstrate that even when the body is no longer in\ncontact with an object, the latent variables of the dynamics model continue to\nrepresent its shape. We show that active data collection by maximizing the\nentropy of predictions about the body---touch sensors, proprioception and\nvestibular information---leads to learning of dynamic models that show superior\nperformance when used for control. We also collect data from a real robotic\nhand and show that the same models can be used to answer questions about\nproperties of objects in the real world. Videos with qualitative results of our\nmodels are available at https://goo.gl/mZuqAV.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:28:01 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Amos", "Brandon", ""], ["Dinh", "Laurent", ""], ["Cabi", "Serkan", ""], ["Roth\u00f6rl", "Thomas", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Muldal", "Alistair", ""], ["Erez", "Tom", ""], ["Tassa", "Yuval", ""], ["de Freitas", "Nando", ""], ["Denil", "Misha", ""]]}, {"id": "1804.06508", "submitter": "Kartik Hegde", "authors": "Kartik Hegde, Jiyong Yu, Rohit Agrawal, Mengjia Yan, Michael Pellauer,\n  Christopher W. Fletcher", "title": "UCNN: Exploiting Computational Reuse in Deep Neural Networks via Weight\n  Repetition", "comments": "Appears in the proceedings of the 45th International Symposium on\n  Computer Architecture~(ISCA), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have begun to permeate all corners of\nelectronic society (from voice recognition to scene generation) due to their\nhigh accuracy and machine efficiency per operation. At their core, CNN\ncomputations are made up of multi-dimensional dot products between weight and\ninput vectors. This paper studies how weight repetition ---when the same weight\noccurs multiple times in or across weight vectors--- can be exploited to save\nenergy and improve performance during CNN inference. This generalizes a popular\nline of work to improve efficiency from CNN weight sparsity, as reducing\ncomputation due to repeated zero weights is a special case of reducing\ncomputation due to repeated weights.\n  To exploit weight repetition, this paper proposes a new CNN accelerator\ncalled the Unique Weight CNN Accelerator (UCNN). UCNN uses weight repetition to\nreuse CNN sub-computations (e.g., dot products) and to reduce CNN model size\nwhen stored in off-chip DRAM ---both of which save energy. UCNN further\nimproves performance by exploiting sparsity in weights. We evaluate UCNN with\nan accelerator-level cycle and energy model and with an RTL implementation of\nthe UCNN processing element. On three contemporary CNNs, UCNN improves\nthroughput-normalized energy consumption by 1.2x - 4x, relative to a similarly\nprovisioned baseline accelerator that uses Eyeriss-style sparsity\noptimizations. At the same time, the UCNN processing element adds only 17-24%\narea overhead relative to the same baseline.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 00:11:38 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Hegde", "Kartik", ""], ["Yu", "Jiyong", ""], ["Agrawal", "Rohit", ""], ["Yan", "Mengjia", ""], ["Pellauer", "Michael", ""], ["Fletcher", "Christopher W.", ""]]}, {"id": "1804.06511", "submitter": "Thomas Keller", "authors": "T. Anderson Keller, Sharath Nittur Sridhar, Xin Wang", "title": "Fast Weight Long Short-Term Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Associative memory using fast weights is a short-term memory mechanism that\nsubstantially improves the memory capacity and time scale of recurrent neural\nnetworks (RNNs). As recent studies introduced fast weights only to regular\nRNNs, it is unknown whether fast weight memory is beneficial to gated RNNs. In\nthis work, we report a significant synergy between long short-term memory\n(LSTM) networks and fast weight associative memories. We show that this\ncombination, in learning associative retrieval tasks, results in much faster\ntraining and lower test error, a performance boost most prominent at high\nmemory task difficulties.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 00:20:28 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Keller", "T. Anderson", ""], ["Sridhar", "Sharath Nittur", ""], ["Wang", "Xin", ""]]}, {"id": "1804.06660", "submitter": "Iosif Szeidert PhD", "authors": "Cristian Vasar, Iosif Szeidert, Ioan Filip, Gabriela Prostean", "title": "Short Term Electric Load Forecast with Artificial Neural Networks", "comments": "7 pages, 13 figures, IFAC MCPL 2007 The 4th International Federation\n  of Automatic Control Conference on Management and Control of Production and\n  Logistics, September 27-30, Sibiu - Romania, pp.443-449", "journal-ref": "IFAC MCPL 2007 The 4th International Federation of Automatic\n  Control Conference on Management and Control of Production and Logistics,\n  September 27-30, Sibiu - Romania, ISBN: 978-973-739-481-1", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents issues regarding short term electric load forecasting\nusing feedforward and Elman recurrent neural networks. The study cases were\ndeveloped using measured data representing electrical energy consume from Banat\narea. There were considered 35 different types of structure for both\nfeedforward and recurrent network cases. For each type of neural network\nstructure were performed many trainings and best solution was selected. The\nissue of forecasting the load on short term is essential in the effective\nenergetic consume management in an open market environment.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 11:36:51 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Vasar", "Cristian", ""], ["Szeidert", "Iosif", ""], ["Filip", "Ioan", ""], ["Prostean", "Gabriela", ""]]}, {"id": "1804.06682", "submitter": "Mostafa Wahby", "authors": "Mostafa Wahby, Mary Katherine Heinrich, Daniel Nicolas Hofstadler,\n  Payam Zahadat, Sebastian Risi, Phil Ayres, Thomas Schmickl and Heiko Hamann", "title": "A Robot to Shape your Natural Plant: The Machine Learning Approach to\n  Model and Control Bio-Hybrid Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3205455.3205516", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-hybrid systems---close couplings of natural organisms with\ntechnology---are high potential and still underexplored. In existing work,\nrobots have mostly influenced group behaviors of animals. We explore the\npossibilities of mixing robots with natural plants, merging useful attributes.\nSignificant synergies arise by combining the plants' ability to efficiently\nproduce shaped material and the robots' ability to extend sensing and\ndecision-making behaviors. However, programming robots to control plant motion\nand shape requires good knowledge of complex plant behaviors. Therefore, we use\nmachine learning to create a holistic plant model and evolve robot controllers.\nAs a benchmark task we choose obstacle avoidance. We use computer vision to\nconstruct a model of plant stem stiffening and motion dynamics by training an\nLSTM network. The LSTM network acts as a forward model predicting change in the\nplant, driving the evolution of neural network robot controllers. The evolved\ncontrollers augment the plants' natural light-finding and tissue-stiffening\nbehaviors to avoid obstacles and grow desired shapes. We successfully verify\nthe robot controllers and bio-hybrid behavior in reality, with a physical setup\nand actual plants.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 12:30:18 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 09:26:34 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Wahby", "Mostafa", ""], ["Heinrich", "Mary Katherine", ""], ["Hofstadler", "Daniel Nicolas", ""], ["Zahadat", "Payam", ""], ["Risi", "Sebastian", ""], ["Ayres", "Phil", ""], ["Schmickl", "Thomas", ""], ["Hamann", "Heiko", ""]]}, {"id": "1804.06732", "submitter": "Alberto Delm\\'as", "authors": "Alberto Delmas, Sayeh Sharify, Patrick Judd, Kevin Siu, Milos Nikolic,\n  Andreas Moshovos", "title": "DPRed: Making Typical Activation and Weight Values Matter In Deep\n  Learning Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that selecting a single data type (precision) for all values in Deep\nNeural Networks, even if that data type is different per layer, amounts to\nworst case design. Much shorter data types can be used if we target the common\ncase by adjusting the precision at a much finer granularity. We propose Dynamic\nPrecision Reduction (DPRed), where we group weights and activations and encode\nthem using a precision specific to each group. The per group precisions are\nselected statically for the weights and dynamically by hardware for the\nactivations. We exploit these precisions to reduce: 1) off-chip storage and\noff- and on-chip communication, and 2) execution time. DPRed compression\nreduces off-chip traffic to nearly 35% and 33% on average compared to no\ncompression respectively for 16b and 8b models. This makes it possible to\nsustain higher performance for a given off-chip memory interface while also\nboosting energy efficiency. We also demonstrate designs where the time required\nto process each group of activations and/or weights scales proportionally to\nthe precision they use for convolutional and fully-connected layers. This\nimproves execution time and energy efficiency for both dense and sparse\nnetworks. We show the techniques work with 8-bit networks, where 1.82x and\n2.81x speedups are achieved for two different hardware variants that take\nadvantage of dynamic precision variability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 00:35:04 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 22:54:15 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2018 07:12:36 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Delmas", "Alberto", ""], ["Sharify", "Sayeh", ""], ["Judd", "Patrick", ""], ["Siu", "Kevin", ""], ["Nikolic", "Milos", ""], ["Moshovos", "Andreas", ""]]}, {"id": "1804.06739", "submitter": "Ohad Shamir", "authors": "Ohad Shamir", "title": "Are ResNets Provably Better than Linear Predictors?", "comments": "Comparison to previous arXiv version: Minor changes to incorporate\n  comments of NIPS 2018 reviewers (main results are unaffected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A residual network (or ResNet) is a standard deep neural net architecture,\nwith state-of-the-art performance across numerous applications. The main\npremise of ResNets is that they allow the training of each layer to focus on\nfitting just the residual of the previous layer's output and the target output.\nThus, we should expect that the trained network is no worse than what we can\nobtain if we remove the residual layers and train a shallower network instead.\nHowever, due to the non-convexity of the optimization problem, it is not at all\nclear that ResNets indeed achieve this behavior, rather than getting stuck at\nsome arbitrarily poor local minimum. In this paper, we rigorously prove that\narbitrarily deep, nonlinear residual units indeed exhibit this behavior, in the\nsense that the optimization landscape contains no local minima with value above\nwhat can be obtained with a linear predictor (namely a 1-layer network).\nNotably, we show this under minimal or no assumptions on the precise network\narchitecture, data distribution, or loss function used. We also provide a\nquantitative analysis of approximate stationary points for this problem.\nFinally, we show that with a certain tweak to the architecture, training the\nnetwork with standard stochastic gradient descent achieves an objective value\nclose or better than any linear predictor.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:06:15 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 16:10:51 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 10:58:10 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2018 10:30:26 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Shamir", "Ohad", ""]]}, {"id": "1804.06774", "submitter": "Junpei Zhong", "authors": "Junpei Zhong and Tetsuya Ogata and Angelo Cangelosi", "title": "Encoding Longer-term Contextual Multi-modal Information in a Predictive\n  Coding Model", "comments": "Submitted to ICDL/EpiRob 2018 (8th Joint IEEE International\n  Conference on Development and Learning and on Epigenetic Robotics )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies suggest that within the hierarchical architecture, the topological\nhigher level possibly represents a conscious category of the current sensory\nevents with slower changing activities. They attempt to predict the activities\non the lower level by relaying the predicted information. On the other hand,\nthe incoming sensory information corrects such prediction of the events on the\nhigher level by the novel or surprising signal. We propose a predictive\nhierarchical artificial neural network model that examines this hypothesis on\nneurorobotic platforms, based on the AFA-PredNet model. In this neural network\nmodel, there are different temporal scales of predictions exist on different\nlevels of the hierarchical predictive coding, which are defined in the temporal\nparameters in the neurons. Also, both the fast and the slow-changing neural\nactivities are modulated by the active motor activities. A neurorobotic\nexperiment based on the architecture was also conducted based on the data\ncollected from the VRep simulator.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 07:47:33 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Zhong", "Junpei", ""], ["Ogata", "Tetsuya", ""], ["Cangelosi", "Angelo", ""]]}, {"id": "1804.06808", "submitter": "Jo\\~ao Francisco Barreto Da Silva Martins", "authors": "Joao Francisco B. S. Martins, Luiz Otavio V. B. Oliveira, Luis F.\n  Miranda, Felipe Casadei, Gisele L. Pappa", "title": "Solving the Exponential Growth of Symbolic Regression Trees in Geometric\n  Semantic Genetic Programming", "comments": "8 pages, In proceedings of Genetic and Evolutionary Computation\n  Conference (GECCO 2018), Kyoto, Japan", "journal-ref": null, "doi": "10.1145/3205455.3205593", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Geometric Semantic Genetic Programming (GSGP) have shown that\nthis variant of Genetic Programming (GP) reaches better results than its\npredecessor for supervised machine learning problems, particularly in the task\nof symbolic regression. However, by construction, the geometric semantic\ncrossover operator generates individuals that grow exponentially with the\nnumber of generations, resulting in solutions with limited use. This paper\npresents a new method for individual simplification named GSGP with Reduced\ntrees (GSGP-Red). GSGP-Red works by expanding the functions generated by the\ngeometric semantic operators. The resulting expanded function is guaranteed to\nbe a linear combination that, in a second step, has its repeated structures and\nrespective coefficients aggregated. Experiments in 12 real-world datasets show\nthat it is not only possible to create smaller and completely equivalent\nindividuals in competitive computational time, but also to reduce the number of\nnodes composing them by 58 orders of magnitude, on average.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 16:45:16 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Martins", "Joao Francisco B. S.", ""], ["Oliveira", "Luiz Otavio V. B.", ""], ["Miranda", "Luis F.", ""], ["Casadei", "Felipe", ""], ["Pappa", "Gisele L.", ""]]}, {"id": "1804.06964", "submitter": "Siyu Huang", "authors": "Siyu Huang, Xi Li, Zhi-Qi Cheng, Zhongfei Zhang, Alexander Hauptmann", "title": "GNAS: A Greedy Neural Architecture Search Method for Multi-Attribute\n  Learning", "comments": "ACM MM 2018 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in deep multi-attribute learning is to effectively discover the\ninter-attribute correlation structures. Typically, the conventional deep\nmulti-attribute learning approaches follow the pipeline of manually designing\nthe network architectures based on task-specific expertise prior knowledge and\ncareful network tunings, leading to the inflexibility for various complicated\nscenarios in practice. Motivated by addressing this problem, we propose an\nefficient greedy neural architecture search approach (GNAS) to automatically\ndiscover the optimal tree-like deep architecture for multi-attribute learning.\nIn a greedy manner, GNAS divides the optimization of global architecture into\nthe optimizations of individual connections step by step. By iteratively\nupdating the local architectures, the global tree-like architecture gets\nconverged where the bottom layers are shared across relevant attributes and the\nbranches in top layers more encode attribute-specific features. Experiments on\nthree benchmark multi-attribute datasets show the effectiveness and compactness\nof neural architectures derived by GNAS, and also demonstrate the efficiency of\nGNAS in searching neural architectures.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 01:29:00 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2018 21:45:17 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Huang", "Siyu", ""], ["Li", "Xi", ""], ["Cheng", "Zhi-Qi", ""], ["Zhang", "Zhongfei", ""], ["Hauptmann", "Alexander", ""]]}, {"id": "1804.07127", "submitter": "Antoine Cully", "authors": "Antoine Cully and Yiannis Demiris", "title": "Hierarchical Behavioral Repertoires with Unsupervised Descriptors", "comments": "GECCO 2018", "journal-ref": "Genetic and Evolutionary Computation Conference 2018", "doi": "10.1145/3205455.3205571", "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enabling artificial agents to automatically learn complex, versatile and\nhigh-performing behaviors is a long-lasting challenge. This paper presents a\nstep in this direction with hierarchical behavioral repertoires that stack\nseveral behavioral repertoires to generate sophisticated behaviors. Each\nrepertoire of this architecture uses the lower repertoires to create complex\nbehaviors as sequences of simpler ones, while only the lowest repertoire\ndirectly controls the agent's movements. This paper also introduces a novel\napproach to automatically define behavioral descriptors thanks to an\nunsupervised neural network that organizes the produced high-level behaviors.\nThe experiments show that the proposed architecture enables a robot to learn\nhow to draw digits in an unsupervised manner after having learned to draw lines\nand arcs. Compared to traditional behavioral repertoires, the proposed\narchitecture reduces the dimensionality of the optimization problems by orders\nof magnitude and provides behaviors with a twice better fitness. More\nimportantly, it enables the transfer of knowledge between robots: a\nhierarchical repertoire evolved for a robotic arm to draw digits can be\ntransferred to a humanoid robot by simply changing the lowest layer of the\nhierarchy. This enables the humanoid to draw digits although it has never been\ntrained for this task.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 12:53:39 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Cully", "Antoine", ""], ["Demiris", "Yiannis", ""]]}, {"id": "1804.07144", "submitter": "Deepika Singh", "authors": "Deepika Singh, Erinc Merdivan, Ismini Psychoula, Johannes Kropf, Sten\n  Hanke, Matthieu Geist and Andreas Holzinger", "title": "Human Activity Recognition using Recurrent Neural Networks", "comments": null, "journal-ref": "International Cross-Domain Conference for Machine Learning and\n  Knowledge Extraction: CD-MAKE 2017", "doi": "10.1007/978-3-319-66808-6_18", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition using smart home sensors is one of the bases of\nubiquitous computing in smart environments and a topic undergoing intense\nresearch in the field of ambient assisted living. The increasingly large amount\nof data sets calls for machine learning methods. In this paper, we introduce a\ndeep learning model that learns to classify human activities without using any\nprior knowledge. For this purpose, a Long Short Term Memory (LSTM) Recurrent\nNeural Network was applied to three real world smart home datasets. The results\nof these experiments show that the proposed approach outperforms the existing\nones in terms of accuracy and performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:20:09 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Singh", "Deepika", ""], ["Merdivan", "Erinc", ""], ["Psychoula", "Ismini", ""], ["Kropf", "Johannes", ""], ["Hanke", "Sten", ""], ["Geist", "Matthieu", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1804.07145", "submitter": "Thomas Schmitz Ir", "authors": "Thomas Schmitz, Jean-Jacques Embrechts", "title": "Real Time Emulation of Parametric Guitar Tube Amplifier With Long Short\n  Term Memory Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous audio systems for musicians are expensive and bulky. Therefore, it\ncould be advantageous to model them and to replace them by computer emulation.\nIn guitar players' world, audio systems could have a desirable nonlinear\nbehavior (distortion effects). It is thus difficult to find a simple model to\nemulate them in real time. Volterra series model and its subclass are usual\nways to model nonlinear systems. Unfortunately, these systems are difficult to\nidentify in an analytic way. In this paper we propose to take advantage of the\nnew progress made in neural networks to emulate them in real time. We show that\nan accurate emulation can be reached with less than 1% of root mean square\nerror between the signal coming from a tube amplifier and the output of the\nneural network. Moreover, the research has been extended to model the Gain\nparameter of the amplifier.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:20:44 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Schmitz", "Thomas", ""], ["Embrechts", "Jean-Jacques", ""]]}, {"id": "1804.07179", "submitter": "Naoki Hamada", "authors": "Naoki Hamada and Keisuke Goto", "title": "Data-Driven Analysis of Pareto Set Topology", "comments": "8 pages, accepted at GECCO'18 as a full paper", "journal-ref": null, "doi": "10.1145/3205455.3205613", "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When and why can evolutionary multi-objective optimization (EMO) algorithms\ncover the entire Pareto set? That is a major concern for EMO researchers and\npractitioners. A recent theoretical study revealed that (roughly speaking) if\nthe Pareto set forms a topological simplex (a curved line, a curved triangle, a\ncurved tetrahedron, etc.), then decomposition-based EMO algorithms can cover\nthe entire Pareto set. Usually, we cannot know the true Pareto set and have to\nestimate its topology by using the population of EMO algorithms during or after\nthe runtime. This paper presents a data-driven approach to analyze the topology\nof the Pareto set. We give a theory of how to recognize the topology of the\nPareto set from data and implement an algorithm to judge whether the true\nPareto set may form a topological simplex or not. Numerical experiments show\nthat the proposed method correctly recognizes the topology of high-dimensional\nPareto sets within reasonable population size.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 14:03:00 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Hamada", "Naoki", ""], ["Goto", "Keisuke", ""]]}, {"id": "1804.07209", "submitter": "Marco Ciccone", "authors": "Marco Ciccone, Marco Gallieri, Jonathan Masci, Christian Osendorfer,\n  Faustino Gomez", "title": "NAIS-Net: Stable Deep Networks from Non-Autonomous Differential\n  Equations", "comments": "NeurIPS 2018 (updated version): new results and proof on incremental\n  stability for ReLU case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Non-Autonomous Input-Output Stable Network(NAIS-Net), a\nvery deep architecture where each stacked processing block is derived from a\ntime-invariant non-autonomous dynamical system. Non-autonomy is implemented by\nskip connections from the block input to each of the unrolled processing stages\nand allows stability to be enforced so that blocks can be unrolled adaptively\nto a pattern-dependent processing depth. NAIS-Net induces non-trivial,\nLipschitz input-output maps, even for an infinite unroll length. We prove that\nthe network is globally asymptotically stable so that for every initial\ncondition there is exactly one input-dependent equilibrium assuming $tanh$\nunits, and incrementally stable for ReL units. An efficient implementation that\nenforces the stability under derived conditions for both fully-connected and\nconvolutional layers is also presented. Experimental results show how NAIS-Net\nexhibits stability in practice, yielding a significant reduction in\ngeneralization gap compared to ResNets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:07:14 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 10:34:05 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 03:59:39 GMT"}, {"version": "v4", "created": "Fri, 21 May 2021 16:03:38 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ciccone", "Marco", ""], ["Gallieri", "Marco", ""], ["Masci", "Jonathan", ""], ["Osendorfer", "Christian", ""], ["Gomez", "Faustino", ""]]}, {"id": "1804.07234", "submitter": "Anil Yaman", "authors": "Anil Yaman, Decebal Constantin Mocanu, Giovanni Iacca, George\n  Fletcher, Mykola Pechenizkiy", "title": "Limited Evaluation Cooperative Co-evolutionary Differential Evolution\n  for Large-scale Neuroevolution", "comments": null, "journal-ref": null, "doi": "10.1145/3205455.3205555", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world control and classification tasks involve a large number of\nfeatures. When artificial neural networks (ANNs) are used for modeling these\ntasks, the network architectures tend to be large. Neuroevolution is an\neffective approach for optimizing ANNs; however, there are two bottlenecks that\nmake their application challenging in case of high-dimensional networks using\ndirect encoding. First, classic evolutionary algorithms tend not to scale well\nfor searching large parameter spaces; second, the network evaluation over a\nlarge number of training instances is in general time-consuming. In this work,\nwe propose an approach called the Limited Evaluation Cooperative\nCo-evolutionary Differential Evolution algorithm (LECCDE) to optimize\nhigh-dimensional ANNs.\n  The proposed method aims to optimize the pre-synaptic weights of each\npost-synaptic neuron in different subpopulations using a Cooperative\nCo-evolutionary Differential Evolution algorithm, and employs a limited\nevaluation scheme where fitness evaluation is performed on a relatively small\nnumber of training instances based on fitness inheritance. We test LECCDE on\nthree datasets with various sizes, and our results show that cooperative\nco-evolution significantly improves the test error comparing to standard\nDifferential Evolution, while the limited evaluation scheme facilitates a\nsignificant reduction in computing time.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:34:39 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 20:07:24 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Yaman", "Anil", ""], ["Mocanu", "Decebal Constantin", ""], ["Iacca", "Giovanni", ""], ["Fletcher", "George", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1804.07284", "submitter": "Cem C. Tutum", "authors": "Cem C. Tutum, Supawit Chockchowwat, Etienne Vouga, Risto Miikkulainen", "title": "Functional Generative Design: An Evolutionary Approach to 3D-Printing", "comments": "8 pages, 12 figures, GECCO'18", "journal-ref": null, "doi": "10.1145/3205455.3205635", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumer-grade printers are widely available, but their ability to print\ncomplex objects is limited. Therefore, new designs need to be discovered that\nserve the same function, but are printable. A representative such problem is to\nproduce a working, reliable mechanical spring. The proposed methodology for\ndiscovering solutions to this problem consists of three components: First, an\neffective search space is learned through a variational autoencoder (VAE);\nsecond, a surrogate model for functional designs is built; and third, a genetic\nalgorithm is used to simultaneously update the hyperparameters of the surrogate\nand to optimize the designs using the updated surrogate. Using a car-launcher\nmechanism as a test domain, spring designs were 3D-printed and evaluated to\nupdate the surrogate model. Two experiments were then performed: First, the\ninitial set of designs for the surrogate-based optimizer was selected randomly\nfrom the training set that was used for training the VAE model, which resulted\nin an exploitative search behavior. On the other hand, in the second\nexperiment, the initial set was composed of more uniformly selected designs\nfrom the same training set and a more explorative search behavior was observed.\nBoth of the experiments showed that the methodology generates interesting,\nsuccessful, and reliable spring geometries robust to the noise inherent in the\n3D printing process. The methodology can be generalized to other functional\ndesign problems, thus making consumer-grade 3D printing more versatile.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 17:35:50 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Tutum", "Cem C.", ""], ["Chockchowwat", "Supawit", ""], ["Vouga", "Etienne", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1804.07370", "submitter": "Jae-sun Seo", "authors": "Shihui Yin, Gaurav Srivastava, Shreyas K. Venkataramanaiah, Chaitali\n  Chakrabarti, Visar Berisha, Jae-sun Seo", "title": "Minimizing Area and Energy of Deep Learning Hardware Design Using\n  Collective Low Precision and Structured Compression", "comments": "2017 Asilomar Conference on Signals, Systems and Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have shown tremendous success in many recognition\ntasks; however, these algorithms typically include a deep neural network (DNN)\nstructure and a large number of parameters, which makes it challenging to\nimplement them on power/area-constrained embedded platforms. To reduce the\nnetwork size, several studies investigated compression by introducing\nelement-wise or row-/column-/block-wise sparsity via pruning and\nregularization. In addition, many recent works have focused on reducing\nprecision of activations and weights with some reducing down to a single bit.\nHowever, combining various sparsity structures with binarized or\nvery-low-precision (2-3 bit) neural networks have not been comprehensively\nexplored. In this work, we present design techniques for minimum-area/-energy\nDNN hardware with minimal degradation in accuracy. During training, both\nbinarization/low-precision and structured sparsity are applied as constraints\nto find the smallest memory footprint for a given deep learning algorithm. The\nDNN model for CIFAR-10 dataset with weight memory reduction of 50X exhibits\naccuracy comparable to that of the floating-point counterpart. Area,\nperformance and energy results of DNN hardware in 40nm CMOS are reported for\nthe MNIST dataset. The optimized DNN that combines 8X structured compression\nand 3-bit weight precision showed 98.4% accuracy at 20nJ per classification.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 20:32:04 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Yin", "Shihui", ""], ["Srivastava", "Gaurav", ""], ["Venkataramanaiah", "Shreyas K.", ""], ["Chakrabarti", "Chaitali", ""], ["Berisha", "Visar", ""], ["Seo", "Jae-sun", ""]]}, {"id": "1804.07633", "submitter": "Ammar Daskin", "authors": "Ammar Daskin", "title": "A Simple Quantum Neural Net with a Periodic Activation Function", "comments": "a discussion session is added. 5 pages, conference paper. To appear\n  in The 2018 IEEE International Conference on Systems, Man, and Cybernetics\n  (SMC2018)", "journal-ref": null, "doi": "10.1109/SMC.2018.00491", "report-no": null, "categories": "quant-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a simple neural net that requires only $O(nlog_2k)$\nnumber of qubits and $O(nk)$ quantum gates: Here, $n$ is the number of input\nparameters, and $k$ is the number of weights applied to these parameters in the\nproposed neural net. We describe the network in terms of a quantum circuit, and\nthen draw its equivalent classical neural net which involves $O(k^n)$ nodes in\nthe hidden layer. Then, we show that the network uses a periodic activation\nfunction of cosine values of the linear combinations of the inputs and weights.\nThe backpropagation is described through the gradient descent, and then iris\nand breast cancer datasets are used for the simulations. The numerical results\nindicate the network can be used in machine learning problems and it may\nprovide exponential speedup over the same structured classical neural net.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 14:16:49 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 14:44:02 GMT"}, {"version": "v3", "created": "Tue, 17 Jul 2018 08:55:39 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Daskin", "Ammar", ""]]}, {"id": "1804.07655", "submitter": "Andreas Steyven", "authors": "Emma Hart, Andreas S.W. Steyven, Ben Paechter", "title": "Evolution of a Functionally Diverse Swarm via a Novel Decentralised\n  Quality-Diversity Algorithm", "comments": "In GECCO 2018", "journal-ref": null, "doi": "10.1145/3205455.3205481", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of functional diversity within a group has been demonstrated to\nlead to greater robustness, higher performance and increased problem-solving\nability in a broad range of studies that includes insect groups, human groups\nand swarm robotics. Evolving group diversity however has proved challenging\nwithin Evolutionary Robotics, requiring reproductive isolation and careful\nattention to population size and selection mechanisms. To tackle this issue, we\nintroduce a novel, decentralised, variant of the MAP-Elites illumination\nalgorithm which is hybridised with a well-known distributed evolutionary\nalgorithm (mEDEA). The algorithm simultaneously evolves multiple diverse\nbehaviours for multiple robots, with respect to a simple token-gathering task.\nEach robot in the swarm maintains a local archive defined by two pre-specified\nfunctional traits which is shared with robots it come into contact with. We\ninvestigate four different strategies for sharing, exploiting and combining\nlocal archives and compare results to mEDEA. Experimental results show that in\ncontrast to previous claims, it is possible to evolve a functionally diverse\nswarm without geographical isolation, and that the new method outperforms mEDEA\nin terms of the diversity, coverage and precision of the evolved swarm.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 14:57:26 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Hart", "Emma", ""], ["Steyven", "Andreas S. W.", ""], ["Paechter", "Ben", ""]]}, {"id": "1804.07663", "submitter": "Andreas Steyven", "authors": "Andreas Steyven, Emma Hart, Ben Paechter", "title": "An Investigation of Environmental Influence on the Benefits of\n  Adaptation Mechanisms in Evolutionary Swarm Robotics", "comments": "In GECCO 2017", "journal-ref": null, "doi": "10.1145/3071178.3071232", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A robotic swarm that is required to operate for long periods in a potentially\nunknown environment can use both evolution and individual learning methods in\norder to adapt. However, the role played by the environment in influencing the\neffectiveness of each type of learning is not well understood. In this paper,\nwe address this question by analysing the performance of a swarm in a range of\nsimulated, dynamic environments where a distributed evolutionary algorithm for\nevolving a controller is augmented with a number of different individual\nlearning mechanisms. The learning mechanisms themselves are defined by\nparameters which can be either fixed or inherited. We conduct experiments in a\nrange of dynamic environments whose characteristics are varied so as to present\ndifferent opportunities for learning. Results enable us to map environmental\ncharacteristics to the most effective learning algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:13:47 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Steyven", "Andreas", ""], ["Hart", "Emma", ""], ["Paechter", "Ben", ""]]}, {"id": "1804.07802", "submitter": "Eunhyeok Park", "authors": "Eunhyeok Park, Sungjoo Yoo, Peter Vajda", "title": "Value-aware Quantization for Training and Inference of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel value-aware quantization which applies aggressively\nreduced precision to the majority of data while separately handling a small\namount of large data in high precision, which reduces total quantization errors\nunder very low precision. We present new techniques to apply the proposed\nquantization to training and inference. The experiments show that our method\nwith 3-bit activations (with 2% of large ones) can give the same training\naccuracy as full-precision one while offering significant (41.6% and 53.7%)\nreductions in the memory cost of activations in ResNet-152 and Inception-v3\ncompared with the state-of-the-art method. Our experiments also show that deep\nnetworks such as Inception-v3, ResNet-101 and DenseNet-121 can be quantized for\ninference with 4-bit weights and activations (with 1% 16-bit data) within 1%\ntop-1 accuracy drop.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 19:13:37 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Park", "Eunhyeok", ""], ["Yoo", "Sungjoo", ""], ["Vajda", "Peter", ""]]}, {"id": "1804.07824", "submitter": "Yan Xu", "authors": "Patrick Koch, Oleg Golovidov, Steven Gardner, Brett Wujek, Joshua\n  Griffin, Yan Xu", "title": "Autotune: A Derivative-free Optimization Framework for Hyperparameter\n  Tuning", "comments": "10 Pages, 9 figures, accept by KDD 2018", "journal-ref": null, "doi": "10.1145/3219819.3219837", "report-no": null, "categories": "cs.LG cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications often require hyperparameter tuning. The\nhyperparameters usually drive both the efficiency of the model training process\nand the resulting model quality. For hyperparameter tuning, machine learning\nalgorithms are complex black-boxes. This creates a class of challenging\noptimization problems, whose objective functions tend to be nonsmooth,\ndiscontinuous, unpredictably varying in computational expense, and include\ncontinuous, categorical, and/or integer variables. Further, function\nevaluations can fail for a variety of reasons including numerical difficulties\nor hardware failures. Additionally, not all hyperparameter value combinations\nare compatible, which creates so called hidden constraints. Robust and\nefficient optimization algorithms are needed for hyperparameter tuning. In this\npaper we present an automated parallel derivative-free optimization framework\ncalled \\textbf{Autotune}, which combines a number of specialized sampling and\nsearch methods that are very effective in tuning machine learning models\ndespite these challenges. Autotune provides significantly improved models over\nusing default hyperparameter settings with minimal user interaction on\nreal-world applications. Given the inherent expense of training numerous\ncandidate models, we demonstrate the effectiveness of Autotune's search methods\nand the efficient distributed and parallel paradigms for training and tuning\nmodels, and also discuss the resource trade-offs associated with the ability to\nboth distribute the training process and parallelize the tuning process.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 20:56:33 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 18:20:17 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Koch", "Patrick", ""], ["Golovidov", "Oleg", ""], ["Gardner", "Steven", ""], ["Wujek", "Brett", ""], ["Griffin", "Joshua", ""], ["Xu", "Yan", ""]]}, {"id": "1804.07887", "submitter": "Bradley Alexander", "authors": "Bradley Alexander and Yang Heng Lee", "title": "A Cell-Division Search Technique for Inversion with Application to\n  Picture-Discovery and Magnetotellurics", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving inverse problems in natural sciences often requires a search pro-\ncess to find explanatory models that match collected field data. Inverse\nproblems are often under-determined meaning that there are many poten- tial\nexplanatory models for the same data. In such cases using stochastic search,\nthrough providing multiple solutions, can help characterise which model\nfeatures that are most persistent and therefore likely to be real.\nUnfortunately, in some fields, large parameter spaces can make stochas- tic\nsearch intractable. In this work we improve upon previous work by defining a\ncompact and expressive representation and search process able to describe and\ndiscover two and three dimensional spatial models. The search process takes\nplace in stages starting with greedy search, followed by alternating stages of\nevolutionary search and a novel model-splitting process inspired by\ncell-division. We apply this framework to two prob- lems - magnetotellurics and\npicture discovery. We show that our improved representation and search process\nis able to produce detailed models with low error residuals.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 04:23:43 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Alexander", "Bradley", ""], ["Lee", "Yang Heng", ""]]}, {"id": "1804.07999", "submitter": "Xin-She Yang", "authors": "Xin-She Yang, Suash Deb, Yuxin Zhao, Simon Fong, Xingshi He", "title": "Swarm Intelligence: Past, Present and Future", "comments": "Soft Computing, 2017", "journal-ref": null, "doi": "10.1007/s00500-017-2810-5", "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many optimization problems in science and engineering are challenging to\nsolve, and the current trend is to use swarm intelligence (SI) and SI-based\nalgorithms to tackle such challenging problems. Some significant developments\nhave been made in recent years, though there are still many open problems in\nthis area. This paper provides a short but timely analysis about SI-based\nalgorithms and their links with self-organization. Different characteristics\nand properties are analyzed here from both mathematical and qualitative\nperspectives. Future research directions are outlined and open questions are\nalso highlighted.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 17:15:11 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Yang", "Xin-She", ""], ["Deb", "Suash", ""], ["Zhao", "Yuxin", ""], ["Fong", "Simon", ""], ["He", "Xingshi", ""]]}, {"id": "1804.08042", "submitter": "Najeeb Khan", "authors": "Najeeb Khan, Jawad Shah and Ian Stavness", "title": "Bridgeout: stochastic bridge regularization for deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in training deep neural networks is overfitting, i.e.\ninferior performance on unseen test examples compared to performance on\ntraining examples. To reduce overfitting, stochastic regularization methods\nhave shown superior performance compared to deterministic weight penalties on a\nnumber of image recognition tasks. Stochastic methods such as Dropout and\nShakeout, in expectation, are equivalent to imposing a ridge and elastic-net\npenalty on the model parameters, respectively. However, the choice of the norm\nof weight penalty is problem dependent and is not restricted to $\\{L_1,L_2\\}$.\nTherefore, in this paper we propose the Bridgeout stochastic regularization\ntechnique and prove that it is equivalent to an $L_q$ penalty on the weights,\nwhere the norm $q$ can be learned as a hyperparameter from data. Experimental\nresults show that Bridgeout results in sparse model weights, improved gradients\nand superior classification performance compared to Dropout and Shakeout on\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 23:27:24 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Khan", "Najeeb", ""], ["Shah", "Jawad", ""], ["Stavness", "Ian", ""]]}, {"id": "1804.08150", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei, Masoud Ghodrati, Saeed Reza Kheradpisheh,\n  Timothee Masquelier, Anthony S. Maida", "title": "Deep Learning in Spiking Neural Networks", "comments": null, "journal-ref": "Neural Networks (2018)", "doi": "10.1016/j.neunet.2018.12.002", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning has been a revolution in the field of machine\nlearning, for computer vision in particular. In this approach, a deep\n(multilayer) artificial neural network (ANN) is trained in a supervised manner\nusing backpropagation. Huge amounts of labeled examples are required, but the\nresulting classification accuracy is truly impressive, sometimes outperforming\nhumans. Neurons in an ANN are characterized by a single, static,\ncontinuous-valued activation. Yet biological neurons use discrete spikes to\ncompute and transmit information, and the spike times, in addition to the spike\nrates, matter. Spiking neural networks (SNNs) are thus more biologically\nrealistic than ANNs, and arguably the only viable option if one wants to\nunderstand how the brain computes. SNNs are also more hardware friendly and\nenergy-efficient than ANNs, and are thus appealing for technology, especially\nfor portable devices. However, training deep SNNs remains a challenge. Spiking\nneurons' transfer function is usually non-differentiable, which prevents using\nbackpropagation. Here we review recent supervised and unsupervised methods to\ntrain deep SNNs, and compare them in terms of accuracy, but also computational\ncost and hardware friendliness. The emerging picture is that SNNs still lag\nbehind ANNs in terms of accuracy, but the gap is decreasing, and can even\nvanish on some tasks, while the SNNs typically require much fewer operations.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 18:27:34 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 02:48:45 GMT"}, {"version": "v3", "created": "Sat, 1 Sep 2018 14:43:38 GMT"}, {"version": "v4", "created": "Sun, 20 Jan 2019 14:30:40 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Ghodrati", "Masoud", ""], ["Kheradpisheh", "Saeed Reza", ""], ["Masquelier", "Timothee", ""], ["Maida", "Anthony S.", ""]]}, {"id": "1804.08328", "submitter": "Amir Zamir", "authors": "Amir Zamir, Alexander Sax, William Shen, Leonidas Guibas, Jitendra\n  Malik, Silvio Savarese", "title": "Taskonomy: Disentangling Task Transfer Learning", "comments": "CVPR 2018 (Oral). See project website and live demos at\n  http://taskonomy.vision/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Do visual tasks have a relationship, or are they unrelated? For instance,\ncould having surface normals simplify estimating the depth of an image?\nIntuition answers these questions positively, implying existence of a structure\namong visual tasks. Knowing this structure has notable values; it is the\nconcept underlying transfer learning and provides a principled way for\nidentifying redundancies across tasks, e.g., to seamlessly reuse supervision\namong related tasks or solve many tasks in one system without piling up the\ncomplexity.\n  We proposes a fully computational approach for modeling the structure of\nspace of visual tasks. This is done via finding (first and higher-order)\ntransfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D,\nand semantic tasks in a latent space. The product is a computational taxonomic\nmap for task transfer learning. We study the consequences of this structure,\ne.g. nontrivial emerged relationships, and exploit them to reduce the demand\nfor labeled data. For example, we show that the total number of labeled\ndatapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3\n(compared to training independently) while keeping the performance nearly the\nsame. We provide a set of tools for computing and probing this taxonomical\nstructure including a solver that users can employ to devise efficient\nsupervision policies for their use cases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 10:46:28 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Zamir", "Amir", ""], ["Sax", "Alexander", ""], ["Shen", "William", ""], ["Guibas", "Leonidas", ""], ["Malik", "Jitendra", ""], ["Savarese", "Silvio", ""]]}, {"id": "1804.08378", "submitter": "Nicolas Weber", "authors": "Nicolas Weber, Florian Schmidt, Mathias Niepert, Felipe Huici", "title": "BrainSlug: Transparent Acceleration of Deep Learning Through Depth-First\n  Parallelism", "comments": "Technical Report, 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CV cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network frameworks such as PyTorch and TensorFlow are the workhorses\nof numerous machine learning applications ranging from object recognition to\nmachine translation. While these frameworks are versatile and straightforward\nto use, the training of and inference in deep neural networks is resource\n(energy, compute, and memory) intensive. In contrast to recent works focusing\non algorithmic enhancements, we introduce BrainSlug, a framework that\ntransparently accelerates neural network workloads by changing the default\nlayer-by-layer processing to a depth-first approach, reducing the amount of\ndata required by the computations and thus improving the performance of the\navailable hardware caches. BrainSlug achieves performance improvements of up to\n41.1% on CPUs and 35.7% on GPUs. These optimizations come at zero cost to the\nuser as they do not require hardware changes and only need tiny adjustments to\nthe software.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 12:49:04 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Weber", "Nicolas", ""], ["Schmidt", "Florian", ""], ["Niepert", "Mathias", ""], ["Huici", "Felipe", ""]]}, {"id": "1804.08711", "submitter": "Aydogan Ozcan", "authors": "Xing Lin, Yair Rivenson, Nezih T. Yardimci, Muhammed Veli, Mona\n  Jarrahi and Aydogan Ozcan", "title": "All-Optical Machine Learning Using Diffractive Deep Neural Networks", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": "10.1126/science.aat8084", "report-no": null, "categories": "cs.NE cs.LG physics.comp-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an all-optical Diffractive Deep Neural Network (D2NN)\narchitecture that can learn to implement various functions after deep\nlearning-based design of passive diffractive layers that work collectively. We\nexperimentally demonstrated the success of this framework by creating\n3D-printed D2NNs that learned to implement handwritten digit classification and\nthe function of an imaging lens at terahertz spectrum. With the existing\nplethora of 3D-printing and other lithographic fabrication methods as well as\nspatial-light-modulators, this all-optical deep learning framework can perform,\nat the speed of light, various complex functions that computer-based neural\nnetworks can implement, and will find applications in all-optical image\nanalysis, feature detection and object classification, also enabling new camera\ndesigns and optical components that can learn to perform unique tasks using\nD2NNs.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 05:27:34 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 06:44:08 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Lin", "Xing", ""], ["Rivenson", "Yair", ""], ["Yardimci", "Nezih T.", ""], ["Veli", "Muhammed", ""], ["Jarrahi", "Mona", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1804.08838", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Heerad Farkhoor, Rosanne Liu, Jason Yosinski", "title": "Measuring the Intrinsic Dimension of Objective Landscapes", "comments": "Published in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recently trained neural networks employ large numbers of parameters to\nachieve good performance. One may intuitively use the number of parameters\nrequired as a rough gauge of the difficulty of a problem. But how accurate are\nsuch notions? How many parameters are really needed? In this paper we attempt\nto answer this question by training networks not in their native parameter\nspace, but instead in a smaller, randomly oriented subspace. We slowly increase\nthe dimension of this subspace, note at which dimension solutions first appear,\nand define this to be the intrinsic dimension of the objective landscape. The\napproach is simple to implement, computationally tractable, and produces\nseveral suggestive conclusions. Many problems have smaller intrinsic dimensions\nthan one might suspect, and the intrinsic dimension for a given dataset varies\nlittle across a family of models with vastly different sizes. This latter\nresult has the profound implication that once a parameter space is large enough\nto solve a problem, extra parameters serve directly to increase the\ndimensionality of the solution manifold. Intrinsic dimension allows some\nquantitative comparison of problem difficulty across supervised, reinforcement,\nand other types of learning where we conclude, for example, that solving the\ninverted pendulum problem is 100 times easier than classifying digits from\nMNIST, and playing Atari Pong from pixels is about as hard as classifying\nCIFAR-10. In addition to providing new cartography of the objective landscapes\nwandered by parameterized models, the method is a simple technique for\nconstructively obtaining an upper bound on the minimum description length of a\nsolution. A byproduct of this construction is a simple approach for compressing\nnetworks, in some cases by more than 100 times.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 04:29:10 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Li", "Chunyuan", ""], ["Farkhoor", "Heerad", ""], ["Liu", "Rosanne", ""], ["Yosinski", "Jason", ""]]}, {"id": "1804.08940", "submitter": "Dominik Fischer", "authors": "Dominik Fischer, Sanaz Mostaghim, Larissa Albantakis", "title": "How swarm size during evolution impacts the behavior, generalizability,\n  and brain complexity of animats performing a spatial navigation task", "comments": "10 pages, 14 figures, GECCO 2018, July 15-19, 2018, Kyoto, Japan", "journal-ref": null, "doi": "10.1145/3205455.3205646", "report-no": null, "categories": "cs.NE nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While it is relatively easy to imitate and evolve natural swarm behavior in\nsimulations, less is known about the social characteristics of simulated,\nevolved swarms, such as the optimal (evolutionary) group size, why individuals\nin a swarm perform certain actions, and how behavior would change in swarms of\ndifferent sizes. To address these questions, we used a genetic algorithm to\nevolve animats equipped with Markov Brains in a spatial navigation task that\nfacilitates swarm behavior. The animats' goal was to frequently cross between\ntwo rooms without colliding with other animats. Animats were evolved in swarms\nof various sizes. We then evaluated the task performance and social behavior of\nthe final generation from each evolution when placed with swarms of different\nsizes in order to evaluate their generalizability across conditions. According\nto our experiments, we find that swarm size during evolution matters: animats\nevolved in a balanced swarm developed more flexible behavior, higher fitness\nacross conditions, and, in addition, higher brain complexity.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 10:07:34 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Fischer", "Dominik", ""], ["Mostaghim", "Sanaz", ""], ["Albantakis", "Larissa", ""]]}, {"id": "1804.08996", "submitter": "Naima Chouikhi", "authors": "Naima Chouikhi and Boudour Ammar and Adel M. Alimi", "title": "Genesis of Basic and Multi-Layer Echo State Network Recurrent\n  Autoencoders for Efficient Data Representations", "comments": "13 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a widely accepted fact that data representations intervene noticeably\nin machine learning tools. The more they are well defined the better the\nperformance results are. Feature extraction-based methods such as autoencoders\nare conceived for finding more accurate data representations from the original\nones. They efficiently perform on a specific task in terms of 1) high accuracy,\n2) large short term memory and 3) low execution time. Echo State Network (ESN)\nis a recent specific kind of Recurrent Neural Network which presents very rich\ndynamics thanks to its reservoir-based hidden layer. It is widely used in\ndealing with complex non-linear problems and it has outperformed classical\napproaches in a number of tasks including regression, classification, etc. In\nthis paper, the noticeable dynamism and the large memory provided by ESN and\nthe strength of Autoencoders in feature extraction are gathered within an ESN\nRecurrent Autoencoder (ESN-RAE). In order to bring up sturdier alternative to\nconventional reservoir-based networks, not only single layer basic ESN is used\nas an autoencoder, but also Multi-Layer ESN (ML-ESN-RAE). The new features,\nonce extracted from ESN's hidden layer, are applied to classification tasks.\nThe classification rates rise considerably compared to those obtained when\napplying the original data features. An accuracy-based comparison is performed\nbetween the proposed recurrent AEs and two variants of an ELM feed-forward AEs\n(Basic and ML) in both of noise free and noisy environments. The empirical\nstudy reveals the main contribution of recurrent connections in improving the\nclassification performance results.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 12:49:54 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 23:48:03 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Chouikhi", "Naima", ""], ["Ammar", "Boudour", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1804.09299", "submitter": "Alexander M. Rush", "authors": "Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer,\n  Hanspeter Pfister, Alexander M. Rush", "title": "Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models", "comments": "VAST - IEEE VIS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Sequence-to-Sequence models have proven to be accurate and robust for\nmany sequence prediction tasks, and have become the standard approach for\nautomatic translation of text. The models work in a five stage blackbox process\nthat involves encoding a source sequence to a vector space and then decoding\nout to a new target sequence. This process is now standard, but like many deep\nlearning methods remains quite difficult to understand or debug. In this work,\nwe present a visual analysis tool that allows interaction with a trained\nsequence-to-sequence model through each stage of the translation process. The\naim is to identify which patterns have been learned and to detect model errors.\nWe demonstrate the utility of our tool through several real-world large-scale\nsequence-to-sequence use cases.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 00:32:45 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 15:59:38 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Strobelt", "Hendrik", ""], ["Gehrmann", "Sebastian", ""], ["Behrisch", "Michael", ""], ["Perer", "Adam", ""], ["Pfister", "Hanspeter", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1804.09331", "submitter": "William La Cava", "authors": "Patryk Orzechowski, William La Cava, Jason H. Moore", "title": "Where are we now? A large benchmark study of recent symbolic regression\n  methods", "comments": "8 pages, 4 figures. GECCO 2018", "journal-ref": null, "doi": "10.1145/3205455.3205539", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a broad benchmarking of recent genetic programming\napproaches to symbolic regression in the context of state of the art machine\nlearning approaches. We use a set of nearly 100 regression benchmark problems\nculled from open source repositories across the web. We conduct a rigorous\nbenchmarking of four recent symbolic regression approaches as well as nine\nmachine learning approaches from scikit-learn. The results suggest that\nsymbolic regression performs strongly compared to state-of-the-art gradient\nboosting algorithms, although in terms of running times is among the slowest of\nthe available methodologies. We discuss the results in detail and point to\nfuture research directions that may allow symbolic regression to gain wider\nadoption in the machine learning community.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 02:58:13 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 15:32:40 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Orzechowski", "Patryk", ""], ["La Cava", "William", ""], ["Moore", "Jason H.", ""]]}, {"id": "1804.09558", "submitter": "Raquel P\\'erez-Arnal", "authors": "Raquel P\\'erez-Arnal, Armand Vilalta, Dario Garcia-Gasulla, Ulises\n  Cort\\'es, Eduard Ayguad\\'e, Jesus Labarta", "title": "A Visual Distance for WordNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the distance between concepts is an important field of study of\nNatural Language Processing, as it can be used to improve tasks related to the\ninterpretation of those same concepts. WordNet, which includes a wide variety\nof concepts associated with words (i.e., synsets), is often used as a source\nfor computing those distances. In this paper, we explore a distance for WordNet\nsynsets based on visual features, instead of lexical ones. For this purpose, we\nextract the graphic features generated within a deep convolutional neural\nnetworks trained with ImageNet and use those features to generate a\nrepresentative of each synset. Based on those representatives, we define a\ndistance measure of synsets, which complements the traditional lexical\ndistances. Finally, we propose some experiments to evaluate its performance and\ncompare it with the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:34:33 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 09:17:36 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["P\u00e9rez-Arnal", "Raquel", ""], ["Vilalta", "Armand", ""], ["Garcia-Gasulla", "Dario", ""], ["Cort\u00e9s", "Ulises", ""], ["Ayguad\u00e9", "Eduard", ""], ["Labarta", "Jesus", ""]]}, {"id": "1804.09859", "submitter": "Takashi Shinozaki", "authors": "Takashi Shinozaki", "title": "Competitive Learning Enriches Learning Representation and Accelerates\n  the Fine-tuning of CNNs", "comments": "Appeared at NIPS 2017 Workshop: Deep Learning: Bridging Theory and\n  Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose the integration of competitive learning into\nconvolutional neural networks (CNNs) to improve the representation learning and\nefficiency of fine-tuning. Conventional CNNs use back propagation learning, and\nit enables powerful representation learning by a discrimination task. However,\nit requires huge amount of labeled data, and acquisition of labeled data is\nmuch harder than that of unlabeled data. Thus, efficient use of unlabeled data\nis getting crucial for DNNs. To address the problem, we introduce unsupervised\ncompetitive learning into the convolutional layer, and utilize unlabeled data\nfor effective representation learning. The results of validation experiments\nusing a toy model demonstrated that strong representation learning effectively\nextracted bases of images into convolutional filters using unlabeled data, and\naccelerated the speed of the fine-tuning of subsequent supervised back\npropagation learning. The leverage was more apparent when the number of filters\nwas sufficiently large, and, in such a case, the error rate steeply decreased\nin the initial phase of fine-tuning. Thus, the proposed method enlarged the\nnumber of filters in CNNs, and enabled a more detailed and generalized\nrepresentation. It could provide a possibility of not only deep but broad\nneural networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 02:28:48 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Shinozaki", "Takashi", ""]]}, {"id": "1804.09862", "submitter": "Hyeong-Ju Kang", "authors": "Hyeong-Ju Kang", "title": "Accelerator-Aware Pruning for Convolutional Neural Networks", "comments": "11 pages, 9 figures", "journal-ref": "IEEE Transactions on Circuits and Systems for Video Technology,\n  vol. 30, no. 7, pp. 2093-2103, Jul. 2020", "doi": "10.1109/TCSVT.2019.2911674", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have shown tremendous performance capabilities\nin computer vision tasks, but their excessive amounts of weight storage and\narithmetic operations prevent them from being adopted in embedded environments.\nOne of the solutions involves pruning, where certain unimportant weights are\nforced to have a value of zero. Many pruning schemes have been proposed, but\nthese have mainly focused on the number of pruned weights. Previous pruning\nschemes scarcely considered ASIC or FPGA accelerator architectures. When these\npruned networks are run on accelerators, the lack of consideration of the\narchitecture causes some inefficiency problems, including internal buffer\nmisalignments and load imbalances. This paper proposes a new pruning scheme\nthat reflects accelerator architectures. In the proposed scheme, pruning is\nperformed so that the same number of weights remain for each weight group\ncorresponding to activations fetched simultaneously. In this way, the pruning\nscheme resolves the inefficiency problems, doubling the accelerator\nperformance. Even with this constraint, the proposed pruning scheme reached a\npruning ratio similar to that of previous unconstrained pruning schemes, not\nonly on AlexNet and VGG16 but also on state-of-the-art very deep networks such\nas ResNet. Furthermore, the proposed scheme demonstrated a comparable pruning\nratio on compact networks such as MobileNet and on slimmed networks that were\nalready pruned in a channel-wise manner. In addition to improving the\nefficiency of previous sparse accelerators, it will be also shown that the\nproposed pruning scheme can be used to reduce the logic complexity of sparse\naccelerators.The pruned models are publicly available at\nhttps://github.com/HyeongjuKang/accelerator-aware-pruning.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 02:35:04 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 12:49:00 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 07:22:14 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Kang", "Hyeong-Ju", ""]]}, {"id": "1804.09882", "submitter": "Guillaume Jourjon", "authors": "Jathushan Rajasegaran and Suranga Seneviratne and Guillaume Jourjon", "title": "A Neural Embeddings Approach for Detecting Mobile Counterfeit Apps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfeit apps impersonate existing popular apps in attempts to misguide\nusers to install them for various reasons such as collecting personal\ninformation, spreading malware, or simply to increase their advertisement\nrevenue. Many counterfeits can be identified once installed, however even a\ntech-savvy user may struggle to detect them before installation as app icons\nand descriptions can be quite similar to the original app. To this end, this\npaper proposes to use neural embeddings generated by state-of-the-art\nconvolutional neural networks (CNNs) to measure the similarity between images.\nOur results show that for the problem of counterfeit detection a novel approach\nof using style embeddings given by the Gram matrix of CNN filter responses\noutperforms baseline methods such as content embeddings and SIFT features. We\nshow that further performance increases can be achieved by combining style\nembeddings with content embeddings. We present an analysis of approximately 1.2\nmillion apps from Google Play Store and identify a set of potential\ncounterfeits for top-1,000 apps. Under a conservative assumption, we were able\nto find 139 apps that contain malware in a set of 6,880 apps that showed high\nvisual similarity to one of the top-1,000 apps in Google Play Store.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 03:58:50 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Rajasegaran", "Jathushan", ""], ["Seneviratne", "Suranga", ""], ["Jourjon", "Guillaume", ""]]}, {"id": "1804.09891", "submitter": "Reza Bonyadi", "authors": "Mohammad Reza Bonyadi, David C. Reutens", "title": "Optimal-margin evolutionary classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach for discriminative classification using\nevolutionary algorithms. We first propose an algorithm to optimize the total\nloss value using a modified 0-1 loss function in a one-dimensional space for\nclassification. We then extend this algorithm for multi-dimensional\nclassification using an evolutionary algorithm. The proposed evolutionary\nalgorithm aims to find a hyperplane which best classifies instances while\nminimizes the classification risk. We test particle swarm optimization,\nevolutionary strategy, and covariance matrix adaptation evolutionary strategy\nfor optimization purpose. Finally, we compare our results with well-established\nand state-of-the-art classification algorithms, for both binary and multi-class\nclassification, on 19 benchmark classification problems, with and without noise\nand outliers. Results show that the performance of the proposed algorithm is\nsignificantly (t-test) better than all other methods in almost all problems\ntested. We also show that the proposed algorithm is significantly more robust\nagainst noise and outliers comparing to other methods. The running time of the\nalgorithm is within a reasonable range for the solution of real-world\nclassification problems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 05:29:45 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Bonyadi", "Mohammad Reza", ""], ["Reutens", "David C.", ""]]}, {"id": "1804.10123", "submitter": "Sam Leroux", "authors": "Sam Leroux, Pavlo Molchanov, Pieter Simoens, Bart Dhoedt, Thomas\n  Breuel, Jan Kautz", "title": "IamNN: Iterative and Adaptive Mobile Neural Network for Efficient Image\n  Classification", "comments": "ICLR 2018 Workshop track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep residual networks (ResNets) made a recent breakthrough in deep learning.\nThe core idea of ResNets is to have shortcut connections between layers that\nallow the network to be much deeper while still being easy to optimize avoiding\nvanishing gradients. These shortcut connections have interesting side-effects\nthat make ResNets behave differently from other typical network architectures.\nIn this work we use these properties to design a network based on a ResNet but\nwith parameter sharing and with adaptive computation time. The resulting\nnetwork is much smaller than the original network and can adapt the\ncomputational cost to the complexity of the input image.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 15:57:00 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Leroux", "Sam", ""], ["Molchanov", "Pavlo", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""], ["Breuel", "Thomas", ""], ["Kautz", "Jan", ""]]}, {"id": "1804.10200", "submitter": "Y Cooper", "authors": "Y Cooper", "title": "The loss landscape of overparameterized neural networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore some mathematical features of the loss landscape of\noverparameterized neural networks. A priori one might imagine that the loss\nfunction looks like a typical function from $\\mathbb{R}^n$ to $\\mathbb{R}$ - in\nparticular, nonconvex, with discrete global minima. In this paper, we prove\nthat in at least one important way, the loss function of an overparameterized\nneural network does not look like a typical function. If a neural net has $n$\nparameters and is trained on $d$ data points, with $n>d$, we show that the\nlocus $M$ of global minima of $L$ is usually not discrete, but rather an $n-d$\ndimensional submanifold of $\\mathbb{R}^n$. In practice, neural nets commonly\nhave orders of magnitude more parameters than data points, so this observation\nimplies that $M$ is typically a very high-dimensional subset of $\\mathbb{R}^n$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:58:45 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Cooper", "Y", ""]]}, {"id": "1804.10223", "submitter": "Jeff Pool", "authors": "Feiwen Zhu, Jeff Pool, Michael Andersch, Jeremy Appleyard, Fung Xie", "title": "Sparse Persistent RNNs: Squeezing Large Recurrent Networks On-Chip", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are powerful tools for solving\nsequence-based problems, but their efficacy and execution time are dependent on\nthe size of the network. Following recent work in simplifying these networks\nwith model pruning and a novel mapping of work onto GPUs, we design an\nefficient implementation for sparse RNNs. We investigate several optimizations\nand tradeoffs: Lamport timestamps, wide memory loads, and a bank-aware weight\nlayout. With these optimizations, we achieve speedups of over 6x over the next\nbest algorithm for a hidden layer of size 2304, batch size of 4, and a density\nof 30%. Further, our technique allows for models of over 5x the size to fit on\na GPU for a speedup of 2x, enabling larger networks to help advance the\nstate-of-the-art. We perform case studies on NMT and speech recognition tasks\nin the appendix, accelerating their recurrent layers by up to 3x.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 18:18:57 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Zhu", "Feiwen", ""], ["Pool", "Jeff", ""], ["Andersch", "Michael", ""], ["Appleyard", "Jeremy", ""], ["Xie", "Fung", ""]]}, {"id": "1804.10306", "submitter": "Dmitry Yarotsky", "authors": "Dmitry Yarotsky", "title": "Universal approximations of invariant maps by neural networks", "comments": "64 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe generalizations of the universal approximation theorem for neural\nnetworks to maps invariant or equivariant with respect to linear\nrepresentations of groups. Our goal is to establish network-like computational\nmodels that are both invariant/equivariant and provably complete in the sense\nof their ability to approximate any continuous invariant/equivariant map. Our\ncontribution is three-fold. First, in the general case of compact groups we\npropose a construction of a complete invariant/equivariant network using an\nintermediate polynomial layer. We invoke classical theorems of Hilbert and Weyl\nto justify and simplify this construction; in particular, we describe an\nexplicit complete ansatz for approximation of permutation-invariant maps.\nSecond, we consider groups of translations and prove several versions of the\nuniversal approximation theorem for convolutional networks in the limit of\ncontinuous signals on euclidean spaces. Finally, we consider 2D signal\ntransformations equivariant with respect to the group SE(2) of rigid euclidean\nmotions. In this case we introduce the \"charge--conserving convnet\" -- a\nconvnet-like computational model based on the decomposition of the feature\nspace into isotypic representations of SO(2). We prove this model to be a\nuniversal approximator for continuous SE(2)--equivariant signal\ntransformations.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 23:03:35 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Yarotsky", "Dmitry", ""]]}, {"id": "1804.10316", "submitter": "Jun Lu", "authors": "Jun Lu, Wei Ma, Boi Faltings", "title": "CompNet: Neural networks growing via the compact network morphism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often the case that the performance of a neural network can be improved\nby adding layers. In real-world practices, we always train dozens of neural\nnetwork architectures in parallel which is a wasteful process. We explored\n$CompNet$, in which case we morph a well-trained neural network to a deeper one\nwhere network function can be preserved and the added layer is compact. The\nwork of the paper makes two contributions: a). The modified network can\nconverge fast and keep the same functionality so that we do not need to train\nfrom scratch again; b). The layer size of the added layer in the neural network\nis controlled by removing the redundant parameters with sparse optimization.\nThis differs from previous network morphism approaches which tend to add more\nneurons or channels beyond the actual requirements and result in redundance of\nthe model. The method is illustrated using several neural network structures on\ndifferent data sets including MNIST and CIFAR10.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 01:20:26 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Lu", "Jun", ""], ["Ma", "Wei", ""], ["Faltings", "Boi", ""]]}, {"id": "1804.10322", "submitter": "Eric Plourde", "authors": "Marc-Antoine Moinnereau, Thomas Brienne, Simon Brodeur, Jean Rouat,\n  Kevin Whittingstall and Eric Plourde", "title": "Classification of auditory stimuli from EEG signals with a regulated\n  recurrent neural network reservoir", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of electroencephalogram (EEG) as the main input signal in\nbrain-machine interfaces has been widely proposed due to the non-invasive\nnature of the EEG. Here we are specifically interested in interfaces that\nextract information from the auditory system and more specifically in the task\nof classifying heard speech from EEGs. To do so, we propose to limit the\npreprocessing of the EEGs and use machine learning approaches to automatically\nextract their meaningful characteristics. More specifically, we use a regulated\nrecurrent neural network (RNN) reservoir, which has been shown to outperform\nclassic machine learning approaches when applied to several different\nbio-signals, and we compare it with a deep neural network approach. Moreover,\nwe also investigate the classification performance as a function of the number\nof EEG electrodes. A set of 8 subjects were presented randomly with 3 different\nauditory stimuli (English vowels a, i and u). We obtained an excellent\nclassification rate of 83.2% with the RNN when considering all 64 electrodes. A\nrate of 81.7% was achieved with only 10 electrodes.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 02:10:29 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Moinnereau", "Marc-Antoine", ""], ["Brienne", "Thomas", ""], ["Brodeur", "Simon", ""], ["Rouat", "Jean", ""], ["Whittingstall", "Kevin", ""], ["Plourde", "Eric", ""]]}, {"id": "1804.10343", "submitter": "Sohil Shah", "authors": "Sohil Shah, Pallabi Ghosh, Larry S Davis and Tom Goldstein", "title": "Stacked U-Nets: A No-Frills Approach to Natural Image Segmentation", "comments": "The code is available at https://github.com/shahsohil/sunets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many imaging tasks require global information about all pixels in an image.\nConventional bottom-up classification networks globalize information by\ndecreasing resolution; features are pooled and downsampled into a single\noutput. But for semantic segmentation and object detection tasks, a network\nmust provide higher-resolution pixel-level outputs. To globalize information\nwhile preserving resolution, many researchers propose the inclusion of\nsophisticated auxiliary blocks, but these come at the cost of a considerable\nincrease in network size and computational cost. This paper proposes stacked\nu-nets (SUNets), which iteratively combine features from different resolution\nscales while maintaining resolution. SUNets leverage the information\nglobalization power of u-nets in a deeper network architectures that is capable\nof handling the complexity of natural images. SUNets perform extremely well on\nsemantic segmentation tasks using a small number of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 05:03:32 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Shah", "Sohil", ""], ["Ghosh", "Pallabi", ""], ["Davis", "Larry S", ""], ["Goldstein", "Tom", ""]]}, {"id": "1804.10662", "submitter": "Raphael Vivacqua Carneiro", "authors": "Raphael V. Carneiro, Rafael C. Nascimento, R\\^anik Guidolini, Vinicius\n  B. Cardoso, Thiago Oliveira-Santos, Claudine Badue and Alberto F. De Souza", "title": "Mapping Road Lanes Using Laser Remission and Deep Neural Networks", "comments": "Accepted by IEEE 2018 International Joint Conference on Neural\n  Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of deep neural networks (DNN) for solving the problem of\ninferring the position and relevant properties of lanes of urban roads with\npoor or absent horizontal signalization, in order to allow the operation of\nautonomous cars in such situations. We take a segmentation approach to the\nproblem and use the Efficient Neural Network (ENet) DNN for segmenting LiDAR\nremission grid maps into road maps. We represent road maps using what we called\nroad grid maps. Road grid maps are square matrixes and each element of these\nmatrixes represents a small square region of real-world space. The value of\neach element is a code associated with the semantics of the road map. Our road\ngrid maps contain all information about the roads' lanes required for building\nthe Road Definition Data Files (RDDFs) that are necessary for the operation of\nour autonomous car, IARA (Intelligent Autonomous Robotic Automobile). We have\nbuilt a dataset of tens of kilometers of manually marked road lanes and used\npart of it to train ENet to segment road grid maps from remission grid maps.\nAfter being trained, ENet achieved an average segmentation accuracy of 83.7%.\nWe have tested the use of inferred road grid maps in the real world using IARA\non a stretch of 3.7 km of urban roads and it has shown performance equivalent\nto that of the previous IARA's subsystem that uses a manually generated RDDF.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 19:45:54 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Carneiro", "Raphael V.", ""], ["Nascimento", "Rafael C.", ""], ["Guidolini", "R\u00e2nik", ""], ["Cardoso", "Vinicius B.", ""], ["Oliveira-Santos", "Thiago", ""], ["Badue", "Claudine", ""], ["De Souza", "Alberto F.", ""]]}, {"id": "1804.10694", "submitter": "R. Baghdadi", "authors": "Riyadh Baghdadi, Jessica Ray, Malek Ben Romdhane, Emanuele Del Sozzo,\n  Abdurrahman Akkas, Yunming Zhang, Patricia Suriana, Shoaib Kamil, Saman\n  Amarasinghe", "title": "Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.00419", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.MS cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Tiramisu, a polyhedral framework designed to generate\nhigh performance code for multiple platforms including multicores, GPUs, and\ndistributed machines. Tiramisu introduces a scheduling language with novel\nextensions to explicitly manage the complexities that arise when targeting\nthese systems. The framework is designed for the areas of image processing,\nstencils, linear algebra and deep learning. Tiramisu has two main features: it\nrelies on a flexible representation based on the polyhedral model and it has a\nrich scheduling language allowing fine-grained control of optimizations.\nTiramisu uses a four-level intermediate representation that allows full\nseparation between the algorithms, loop transformations, data layouts, and\ncommunication. This separation simplifies targeting multiple hardware\narchitectures with the same algorithm. We evaluate Tiramisu by writing a set of\nimage processing, deep learning, and linear algebra benchmarks and compare them\nwith state-of-the-art compilers and hand-tuned libraries. We show that Tiramisu\nmatches or outperforms existing compilers and libraries on different hardware\narchitectures, including multicore CPUs, GPUs, and distributed machines.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 21:28:44 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 19:58:57 GMT"}, {"version": "v3", "created": "Wed, 26 Sep 2018 21:24:44 GMT"}, {"version": "v4", "created": "Tue, 18 Dec 2018 02:41:00 GMT"}, {"version": "v5", "created": "Thu, 20 Dec 2018 16:25:40 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Baghdadi", "Riyadh", ""], ["Ray", "Jessica", ""], ["Romdhane", "Malek Ben", ""], ["Del Sozzo", "Emanuele", ""], ["Akkas", "Abdurrahman", ""], ["Zhang", "Yunming", ""], ["Suriana", "Patricia", ""], ["Kamil", "Shoaib", ""], ["Amarasinghe", "Saman", ""]]}, {"id": "1804.10727", "submitter": "Jonathan Binas", "authors": "Jonathan Binas, Yoshua Bengio", "title": "Low-memory convolutional neural networks through incremental depth-first\n  processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an incremental processing scheme for convolutional neural\nnetwork (CNN) inference, targeted at embedded applications with limited memory\nbudgets. Instead of processing layers one by one, individual input pixels are\npropagated through all parts of the network they can influence under the given\nstructural constraints. This depth-first updating scheme comes with hard bounds\non the memory footprint: the memory required is constant in the case of 1D\ninput and proportional to the square root of the input dimension in the case of\n2D input.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 03:03:45 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 21:06:44 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Binas", "Jonathan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.11127", "submitter": "Michael Wand", "authors": "Michael Wand and Ngoc Thang Vu and Juergen Schmidhuber", "title": "Investigations on End-to-End Audiovisual Fusion", "comments": "Published at ICASSP 2018", "journal-ref": "Proceedings of the 2018 IEEE International Conference on\n  Acoustics, Speech and Signal Processing, pages 3041 - 3045", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audiovisual speech recognition (AVSR) is a method to alleviate the adverse\neffect of noise in the acoustic signal. Leveraging recent developments in deep\nneural network-based speech recognition, we present an AVSR neural network\narchitecture which is trained end-to-end, without the need to separately model\nthe process of decision fusion as in conventional (e.g. HMM-based) systems. The\nfusion system outperforms single-modality recognition under all noise\nconditions. Investigation of the saliency of the input features shows that the\nneural network automatically adapts to different noise levels in the acoustic\nsignal.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 11:27:26 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Wand", "Michael", ""], ["Vu", "Ngoc Thang", ""], ["Schmidhuber", "Juergen", ""]]}, {"id": "1804.11129", "submitter": "Eurico Covas", "authors": "Eurico Covas and Emmanouil Benetos", "title": "Optimal Neural Network Feature Selection for Spatial-Temporal\n  Forecasting", "comments": "11 pages", "journal-ref": null, "doi": "10.1063/1.5095060", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show empirical evidence on how to construct the optimal\nfeature selection or input representation used by the input layer of a\nfeedforward neural network for the propose of forecasting spatial-temporal\nsignals. The approach is based on results from dynamical systems theory, namely\nthe non-linear embedding theorems. We demonstrate it for a variety of\nspatial-temporal signals, with one spatial and one temporal dimensions, and\nshow that the optimal input layer representation consists of a grid, with\nspatial/temporal lags determined by the minimum of the mutual information of\nthe spatial/temporal signals and the number of points taken in space/time\ndecided by the embedding dimension of the signal. We present evidence of this\nproposal by running a Monte Carlo simulation of several combinations of input\nlayer feature designs and show that the one predicted by the non-linear\nembedding theorems seems to be optimal or close of optimal. In total we show\nevidence in four unrelated systems: a series of coupled Henon maps; a series of\ncouple Ordinary Differential Equations (Lorenz-96) phenomenologically modelling\natmospheric dynamics; the Kuramoto-Sivashinsky equation, a partial differential\nequation used in studies of instabilities in laminar flame fronts and finally\nreal physical data from sunspot areas in the Sun (in latitude and time) from\n1874 to 2015.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 11:29:59 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Covas", "Eurico", ""], ["Benetos", "Emmanouil", ""]]}, {"id": "1804.11188", "submitter": "Corentin Tallec", "authors": "Corentin Tallec, Yann Ollivier", "title": "Can recurrent neural networks warp time?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful recurrent models such as long short-term memories (LSTMs) and\ngated recurrent units (GRUs) use ad hoc gating mechanisms. Empirically these\nmodels have been found to improve the learning of medium to long term temporal\ndependencies and to help with vanishing gradient issues. We prove that\nlearnable gates in a recurrent model formally provide quasi- invariance to\ngeneral time transformations in the input data. We recover part of the LSTM\narchitecture from a simple axiomatic approach. This result leads to a new way\nof initializing gate biases in LSTMs and GRUs. Ex- perimentally, this new\nchrono initialization is shown to greatly improve learning of long term\ndependencies, with minimal implementation effort.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 09:17:35 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Tallec", "Corentin", ""], ["Ollivier", "Yann", ""]]}, {"id": "1804.11237", "submitter": "Gardave Bhumbra", "authors": "Gardave S Bhumbra", "title": "Deep learning improved by biological activation functions", "comments": "11 pages, 4 figures. 18/05/2018: 9 pages, 5 figures. Eq. 1 corrected.\n  Changed name of biological activation functions. Weight initialisation\n  simplified: experiments repeated, all figures changed, overall results\n  unchanged, Methods shortened, Appendix removed. Added new Results section for\n  new experiments on CIFAR 10/100 data. Extended arguments in Discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  `Biologically inspired' activation functions, such as the logistic sigmoid,\nhave been instrumental in the historical advancement of machine learning.\nHowever in the field of deep learning, they have been largely displaced by\nrectified linear units (ReLU) or similar functions, such as its exponential\nlinear unit (ELU) variant, to mitigate the effects of vanishing gradients\nassociated with error back-propagation. The logistic sigmoid however does not\nrepresent the true input-output relation in neuronal cells under physiological\nconditions. Here, bionodal root unit (BRU) activation functions are introduced,\nexhibiting input-output non-linearities that are substantially more\nbiologically plausible since their functional form is based on known\nbiophysical properties of neuronal cells.\n  In order to evaluate the learning performance of BRU activations, deep\nnetworks are constructed with identical architectures except differing in their\ntransfer functions (ReLU, ELU, and BRU). Multilayer perceptrons, stacked\nauto-encoders, and convolutional networks are used to test supervised and\nunsupervised learning based on the MNIST and CIFAR-10/100 datasets. Comparisons\nof learning performance, quantified using loss and error measurements,\ndemonstrate that bionodal networks both train faster than their ReLU and ELU\ncounterparts and result in the best generalised models even in the absence of\nformal regularisation. These results therefore suggest that revisiting the\ndetailed properties of biological neurones and their circuitry might prove\ninvaluable in the field of deep learning for the future.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 10:20:28 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 08:59:48 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Bhumbra", "Gardave S", ""]]}, {"id": "1804.11239", "submitter": "Caiwen Ding", "authors": "Caiwen Ding, Ao Ren, Geng Yuan, Xiaolong Ma, Jiayu Li, Ning Liu, Bo\n  Yuan, Yanzhi Wang", "title": "Structured Weight Matrices-Based Hardware Accelerators in Deep Neural\n  Networks: FPGAs and ASICs", "comments": "6 pages, 7 figures, GLSVLSI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both industry and academia have extensively investigated hardware\naccelerations. In this work, to address the increasing demands in computational\ncapability and memory requirement, we propose structured weight matrices\n(SWM)-based compression techniques for both \\emph{field programmable gate\narray} (FPGA) and \\emph{application-specific integrated circuit} (ASIC)\nimplementations. In algorithm part, SWM-based framework adopts block-circulant\nmatrices to achieve a fine-grained tradeoff between accuracy and compression\nratio. The SWM-based technique can reduce computational complexity from\nO($n^2$) to O($n\\log n$) and storage complexity from O($n^2$) to O($n$) for\neach layer and both training and inference phases. For FPGA implementations on\ndeep convolutional neural networks (DCNNs), we achieve at least 152X and 72X\nimprovement in performance and energy efficiency, respectively using the\nSWM-based framework, compared with the baseline of IBM TrueNorth processor\nunder same accuracy constraints using the data set of MNIST, SVHN, and\nCIFAR-10. For FPGA implementations on long short term memory (LSTM) networks,\nthe proposed SWM-based LSTM can achieve up to 21X enhancement in performance\nand 33.5X gains in energy efficiency compared with the baseline accelerator.\nFor ASIC implementations, the SWM-based ASIC design exhibits impressive\nadvantages in terms of power, throughput, and energy efficiency. Experimental\nresults indicate that this method is greatly suitable for applying DNNs onto\nboth FPGAs and mobile/IoT devices.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 19:57:54 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Ding", "Caiwen", ""], ["Ren", "Ao", ""], ["Yuan", "Geng", ""], ["Ma", "Xiaolong", ""], ["Li", "Jiayu", ""], ["Liu", "Ning", ""], ["Yuan", "Bo", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1804.11285", "submitter": "Ludwig Schmidt", "authors": "Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar and\n  Aleksander M\\k{a}dry", "title": "Adversarially Robust Generalization Requires More Data", "comments": "Small changes for biblatex compatibility", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are often susceptible to adversarial perturbations of\ntheir inputs. Even small perturbations can cause state-of-the-art classifiers\nwith high \"standard\" accuracy to produce an incorrect prediction with high\nconfidence. To better understand this phenomenon, we study adversarially robust\nlearning from the viewpoint of generalization. We show that already in a simple\nnatural data model, the sample complexity of robust learning can be\nsignificantly larger than that of \"standard\" learning. This gap is information\ntheoretic and holds irrespective of the training algorithm or the model family.\nWe complement our theoretical results with experiments on popular image\nclassification datasets and show that a similar gap exists here as well. We\npostulate that the difficulty of training robust classifiers stems, at least\npartially, from this inherently larger sample complexity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:55:59 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 05:24:33 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Schmidt", "Ludwig", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Talwar", "Kunal", ""], ["M\u0105dry", "Aleksander", ""]]}, {"id": "1804.11313", "submitter": "Biswa Sengupta", "authors": "Biswa Sengupta and Karl J. Friston", "title": "How Robust are Deep Neural Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional and Recurrent, deep neural networks have been successful in\nmachine learning systems for computer vision, reinforcement learning, and other\nallied fields. However, the robustness of such neural networks is seldom\napprised, especially after high classification accuracy has been attained. In\nthis paper, we evaluate the robustness of three recurrent neural networks to\ntiny perturbations, on three widely used datasets, to argue that high accuracy\ndoes not always mean a stable and a robust (to bounded perturbations,\nadversarial attacks, etc.) system. Especially, normalizing the spectrum of the\ndiscrete recurrent network to bound the spectrum (using power method, Rayleigh\nquotient, etc.) on a unit disk produces stable, albeit highly non-robust neural\nnetworks. Furthermore, using the $\\epsilon$-pseudo-spectrum, we show that\ntraining of recurrent networks, say using gradient-based methods, often result\nin non-normal matrices that may or may not be diagonalizable. Therefore, the\nopen problem lies in constructing methods that optimize not only for accuracy\nbut also for the stability and the robustness of the underlying neural network,\na criterion that is distinct from the other.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 16:39:31 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Sengupta", "Biswa", ""], ["Friston", "Karl J.", ""]]}]