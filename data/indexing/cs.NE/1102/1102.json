[{"id": "1102.0183", "submitter": "Dan Ciresan", "authors": "Dan C. Cire\\c{s}an, Ueli Meier, Jonathan Masci, Luca M. Gambardella\n  and J\\\"urgen Schmidhuber", "title": "High-Performance Neural Networks for Visual Object Classification", "comments": "12 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": "IDSIA 1-11", "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a fast, fully parameterizable GPU implementation of Convolutional\nNeural Network variants. Our feature extractors are neither carefully designed\nnor pre-wired, but rather learned in a supervised way. Our deep hierarchical\narchitectures achieve the best published results on benchmarks for object\nclassification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with\nerror rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple\nback-propagation perform better than more shallow ones. Learning is\nsurprisingly rapid. NORB is completely trained within five epochs. Test error\nrates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 15:34:43 GMT"}], "update_date": "2011-02-02", "authors_parsed": [["Cire\u015fan", "Dan C.", ""], ["Meier", "Ueli", ""], ["Masci", "Jonathan", ""], ["Gambardella", "Luca M.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1102.1140", "submitter": "Carola Winzen", "authors": "Benjamin Doerr, Carola Winzen", "title": "Ranking-Based Black-Box Complexity", "comments": "This is an extended version of our CSR 2011 paper. 31 pages. The\n  journal version is to appear in Algorithmica, DOI: 10.1007/s00453-012-9684-9", "journal-ref": null, "doi": "10.1007/s00453-012-9684-9", "report-no": null, "categories": "cs.NE cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized search heuristics such as evolutionary algorithms, simulated\nannealing, and ant colony optimization are a broadly used class of\ngeneral-purpose algorithms. Analyzing them via classical methods of theoretical\ncomputer science is a growing field. While several strong runtime analysis\nresults have appeared in the last 20 years, a powerful complexity theory for\nsuch algorithms is yet to be developed. We enrich the existing notions of\nblack-box complexity by the additional restriction that not the actual\nobjective values, but only the relative quality of the previously evaluated\nsolutions may be taken into account by the black-box algorithm. Many randomized\nsearch heuristics belong to this class of algorithms.\n  We show that the new ranking-based model gives more realistic complexity\nestimates for some problems. For example, the class of all binary-value\nfunctions has a black-box complexity of $O(\\log n)$ in the previous black-box\nmodels, but has a ranking-based complexity of $\\Theta(n)$.\n  For the class of all OneMax functions, we present a ranking-based black-box\nalgorithm that has a runtime of $\\Theta(n / \\log n)$, which shows that the\nOneMax problem does not become harder with the additional ranking-basedness\nrestriction.\n", "versions": [{"version": "v1", "created": "Sun, 6 Feb 2011 11:13:25 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2011 22:14:26 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2012 08:10:26 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Doerr", "Benjamin", ""], ["Winzen", "Carola", ""]]}, {"id": "1102.1407", "submitter": "Muralidhar Ravuri", "authors": "Muralidhar Ravuri", "title": "Stable Parallel Looped Systems -- A New Theoretical Framework for the\n  Evolution of Order", "comments": "21 pages, 9 figures; simplified text and figures for clarity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the paper is to identify laws and mechanisms that allow the\ncreation of more order from disorder using natural means i.e., without the help\nof conscious beings. While this is not possible for the collection of all\ndynamical systems as it violates the second law of thermodynamics, I show that\nthis is possible within a special subset called stable parallel looped (SPL)\ndynamical systems. I identify a new infinite family of physical and chemical\ndynamical SPL systems, which are (a) easy to create naturally and (b) easy to\nmerge, link and combine to create dynamical systems of any specified\ncomplexity. Within SPL systems, I propose a special collection of designs\ncalled active material-energy looped systems using which it is possible to\ngenerate large-scale ordered chemical networks, like the metabolic networks, in\na reliable, repeatable, iterative and natural manner. The resulting SPL systems\nprovide a new theoretical framework for the problem of origin of life.\n", "versions": [{"version": "v1", "created": "Mon, 7 Feb 2011 20:27:13 GMT"}, {"version": "v2", "created": "Mon, 14 Feb 2011 20:54:06 GMT"}, {"version": "v3", "created": "Tue, 17 May 2011 19:50:20 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["Ravuri", "Muralidhar", ""]]}, {"id": "1102.1691", "submitter": "Manuel Marques-Pita PhD", "authors": "Manuel Marques-Pita and Luis M. Rocha", "title": "Schema Redescription in Cellular Automata: Revisiting Emergence in\n  Complex Systems", "comments": "paper submitted to the 2011 IEEE Symposium on Artificial Life", "journal-ref": "The 2011 IEEE Symposium on Artificial Life, at the IEEE Symposium\n  Series on Computational Intelligence 2011. April 11 - 15, 201, Paris, France,\n  pp: 233-240", "doi": null, "report-no": null, "categories": "nlin.CG cs.AI cs.FL cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to eliminate redundancy in the transition tables of\nBoolean automata: schema redescription with two symbols. One symbol is used to\ncapture redundancy of individual input variables, and another to capture\npermutability in sets of input variables: fully characterizing the canalization\npresent in Boolean functions. Two-symbol schemata explain aspects of the\nbehaviour of automata networks that the characterization of their emergent\npatterns does not capture. We use our method to compare two well-known cellular\nautomata for the density classification task: the human engineered CA GKL, and\nanother obtained via genetic programming (GP). We show that despite having very\ndifferent collective behaviour, these rules are very similar. Indeed, GKL is a\nspecial case of GP. Therefore, we demonstrate that it is more feasible to\ncompare cellular automata via schema redescriptions of their rules, than by\nlooking at their emergent behaviour, leading us to question the tendency in\ncomplexity research to pay much more attention to emergent patterns than to\nlocal interactions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Feb 2011 19:13:53 GMT"}, {"version": "v2", "created": "Wed, 9 Feb 2011 15:44:38 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Marques-Pita", "Manuel", ""], ["Rocha", "Luis M.", ""]]}, {"id": "1102.2559", "submitter": "Mike Stimpson", "authors": "Mike Stimpson", "title": "Toward Measuring the Scaling of Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several genetic programming systems are created, each solving a different\nproblem. In these systems, the median number of generations G needed to evolve\na working program is measured. The behavior of G is observed as the difficulty\nof the problem is increased. In these systems, the density D of working\nprograms in the universe of all possible programs is measured. The relationship\nG ~ 1/sqrt(D) is observed to approximately hold for two program-like systems.\nFor parallel systems (systems that look like several independent programs\nevolving in parallel), the relationship G ~ 1/(n ln n) is observed to\napproximately hold. Finally, systems that are anti-parallel are considered.\n", "versions": [{"version": "v1", "created": "Sun, 13 Feb 2011 05:09:32 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Stimpson", "Mike", ""]]}, {"id": "1102.2739", "submitter": "Sergey Tarasenko", "authors": "Sergey S. Tarasenko", "title": "A General Framework for Development of the Cortex-like Visual Object\n  Recognition System: Waves of Spikes, Predictive Coding and Universal\n  Dictionary of Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study is focused on the development of the cortex-like visual object\nrecognition system. We propose a general framework, which consists of three\nhierarchical levels (modules). These modules functionally correspond to the V1,\nV4 and IT areas. Both bottom-up and top-down connections between the\nhierarchical levels V4 and IT are employed. The higher the degree of matching\nbetween the input and the preferred stimulus, the shorter the response time of\nthe neuron. Therefore information about a single stimulus is distributed in\ntime and is transmitted by the waves of spikes. The reciprocal connections and\nwaves of spikes implement predictive coding: an initial hypothesis is generated\non the basis of information delivered by the first wave of spikes and is tested\nwith the information carried by the consecutive waves. The development is\nconsidered as extraction and accumulation of features in V4 and objects in IT.\nOnce stored a feature can be disposed, if rarely activated. This cause update\nof feature repository. Consequently, objects in IT are also updated. This\nillustrates the growing process and dynamical change of topological structures\nof V4, IT and connections between these areas.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 11:40:08 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Tarasenko", "Sergey S.", ""]]}, {"id": "1102.3868", "submitter": "Valmir Barbosa", "authors": "Luis O. Rigo Jr, Valmir C. Barbosa", "title": "Evolved preambles for MAX-SAT heuristics", "comments": null, "journal-ref": "Proceedings of the International Conference on Evolutionary\n  Computation Theory and Applications, 23-31, 2011", "doi": "10.5220/0003660400230031", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MAX-SAT heuristics normally operate from random initial truth assignments to\nthe variables. We consider the use of what we call preambles, which are\nsequences of variables with corresponding single-variable assignment actions\nintended to be used to determine a more suitable initial truth assignment for a\ngiven problem instance and a given heuristic. For a number of well established\nMAX-SAT heuristics and benchmark instances, we demonstrate that preambles can\nbe evolved by a genetic algorithm such that the heuristics are outperformed in\na significant fraction of the cases.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 16:37:59 GMT"}], "update_date": "2012-01-05", "authors_parsed": [["Rigo", "Luis O.", "Jr"], ["Barbosa", "Valmir C.", ""]]}, {"id": "1102.5757", "submitter": "Amit Choudhary", "authors": "Amit Choudhary and Rahul Rishi", "title": "Improving the character recognition efficiency of feed forward BP neural\n  network", "comments": "12 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is focused on improving the character recognition capability of\nfeed-forward back-propagation neural network by using one, two and three hidden\nlayers and the modified additional momentum term. 182 English letters were\ncollected for this work and the equivalent binary matrix form of these\ncharacters was applied to the neural network as training patterns. While the\nnetwork was getting trained, the connection weights were modified at each epoch\nof learning. For each training sample, the error surface was examined for\nminima by computing the gradient descent. We started the experiment by using\none hidden layer and the number of hidden layers was increased up to three and\nit has been observed that accuracy of the network was increased with low mean\nsquare error but at the cost of training time. The recognition accuracy was\nimproved further when modified additional momentum term was used.\n", "versions": [{"version": "v1", "created": "Mon, 28 Feb 2011 19:58:20 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Choudhary", "Amit", ""], ["Rishi", "Rahul", ""]]}]