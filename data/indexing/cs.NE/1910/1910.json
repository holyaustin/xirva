[{"id": "1910.00122", "submitter": "Katarzyna Kozdon Mx", "authors": "Katarzyna Kozdon and Peter Bentley", "title": "Normalisation of Weights and Firing Rates in Spiking Neural Networks\n  with Spike-Timing-Dependent Plasticity", "comments": "Developmental Neural Networks Workshop, The 2019 Conference on\n  Artificial Life (ALife 2019). Newcastle, United Kingdom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining the ability to fire sparsely is crucial for information encoding\nin neural networks. Additionally, spiking homeostasis is vital for spiking\nneural networks with changing numbers of weights and neurons. We discuss a\nrange of network stabilisation approaches, inspired by homeostatic synaptic\nplasticity mechanisms reported in the brain. These include weight scaling, and\nweight change as a function of the network's spiking activity. We tested\nnormalisation of the sum of weights for all neurons, and by neuron type. We\nexamined how this approach affects firing rate and performance on clustering of\ntime-series data in the form of moving geometric shapes. We found that neuron\ntype-specific normalisation is a promising approach for preventing weight drift\nin spiking neural networks, thus enabling longer training cycles. It can be\nadapted for networks with architectural plasticity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 21:44:55 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kozdon", "Katarzyna", ""], ["Bentley", "Peter", ""]]}, {"id": "1910.00230", "submitter": "Leo Cazenille", "authors": "Leo Cazenille and Nicolas Bredeche and Nathanael Aubert-Kato", "title": "Exploring Self-Assembling Behaviors in a Swarm of Bio-micro-robots using\n  Surrogate-Assisted MAP-Elites", "comments": "In IEEE Symposium Series on Computational Intelligence (SSCI) 2019.\n  Accepted to the IEEE ALIFE Conference 2019. 8 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarms of molecular robots are a promising approach to create specific shapes\nat the microscopic scale through self-assembly. However, controlling their\nbehavior is a challenging problem as it involves complex non-linear dynamics\nand high experimental variability. Hand-crafting a molecular controller will\noften be time-consuming and give sub-optimal results. Optimization methods,\nlike the bioNEAT algorithm, were previously employed to partially overcome\nthese difficulties, but they still had to cope with deceptive high-dimensional\nsearch spaces and computationally expensive simulations. Here, we describe a\nnovel approach to solve this problem by using MAP-Elites, an algorithm that\nsearches for both high-performing and diverse solutions. We then apply it to a\nmolecular robotic framework we recently introduced that allows sensing,\nsignaling and self-assembly at the micro-scale and show that MAP-Elites\noutperforms previous approaches. Additionally, we propose a surrogate model of\nmicro-robots physics and chemical reaction dynamics to reduce the computational\ncosts of simulation. We show that the resulting methodology is capable of\noptimizing controllers with similar accuracy as when using only a full-fledged\nrealistic model, with half the computational budget.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 07:24:05 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Cazenille", "Leo", ""], ["Bredeche", "Nicolas", ""], ["Aubert-Kato", "Nathanael", ""]]}, {"id": "1910.00370", "submitter": "Yijun Bian", "authors": "Yijun Bian, Qingquan Song, Mengnan Du, Jun Yao, Huanhuan Chen, Xia Hu", "title": "Sub-Architecture Ensemble Pruning in Neural Architecture Search", "comments": "Accepted by TNNLS. This work was done when the first author was a\n  visiting research scholar at Texas A&M University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is gaining more and more attention in recent\nyears due to its flexibility and remarkable capability to reduce the burden of\nneural network design. To achieve better performance, however, the searching\nprocess usually costs massive computations that might not be affordable for\nresearchers and practitioners. While recent attempts have employed ensemble\nlearning methods to mitigate the enormous computational cost, however, they\nneglect a key property of ensemble methods, namely diversity, which leads to\ncollecting more similar sub-architectures with potential redundancy in the\nfinal design. To tackle this problem, we propose a pruning method for NAS\nensembles called \"Sub-Architecture Ensemble Pruning in Neural Architecture\nSearch (SAEP).\" It targets to leverage diversity and to achieve sub-ensemble\narchitectures at a smaller size with comparable performance to ensemble\narchitectures that are not pruned. Three possible solutions are proposed to\ndecide which sub-architectures to prune during the searching process.\nExperimental results exhibit the effectiveness of the proposed method by\nlargely reducing the number of sub-architectures without degrading the\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:26:54 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 03:37:48 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Bian", "Yijun", ""], ["Song", "Qingquan", ""], ["Du", "Mengnan", ""], ["Yao", "Jun", ""], ["Chen", "Huanhuan", ""], ["Hu", "Xia", ""]]}, {"id": "1910.00945", "submitter": "Michael Lones", "authors": "Michael Lones", "title": "Optimising Optimisers with Push GP", "comments": null, "journal-ref": "In: Hu T., Louren\\c{c}o N., Medvet E., Divina F. (eds) Genetic\n  Programming. EuroGP 2020. Lecture Notes in Computer Science, vol 12101.\n  Springer, Cham", "doi": "10.1007/978-3-030-44094-7_7", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work uses Push GP to automatically design both local and\npopulation-based optimisers for continuous-valued problems. The optimisers are\ntrained on a single function optimisation landscape, using random\ntransformations to discourage overfitting. They are then tested for generality\non larger versions of the same problem, and on other continuous-valued\nproblems. In most cases, the optimisers generalise well to the larger problems.\nSurprisingly, some of them also generalise very well to previously unseen\nproblems, outperforming existing general purpose optimisers such as CMA-ES.\nAnalysis of the behaviour of the evolved optimisers indicates a range of\ninteresting optimisation strategies that are not found within conventional\noptimisers, suggesting that this approach could be useful for discovering novel\nand effective forms of optimisation in an automated manner.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 13:38:55 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Lones", "Michael", ""]]}, {"id": "1910.00998", "submitter": "Peter J Liu", "authors": "Peter J. Liu, Yu-An Chung, Jie Ren", "title": "SummAE: Zero-Shot Abstractive Text Summarization using Length-Agnostic\n  Auto-Encoders", "comments": "first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end neural model for zero-shot abstractive text\nsummarization of paragraphs, and introduce a benchmark task, ROCSumm, based on\nROCStories, a subset for which we collected human summaries. In this task,\nfive-sentence stories (paragraphs) are summarized with one sentence, using\nhuman summaries only for evaluation. We show results for extractive and human\nbaselines to demonstrate a large abstractive gap in performance. Our model,\nSummAE, consists of a denoising auto-encoder that embeds sentences and\nparagraphs in a common space, from which either can be decoded. Summaries for\nparagraphs are generated by decoding a sentence from the paragraph\nrepresentations. We find that traditional sequence-to-sequence auto-encoders\nfail to produce good summaries and describe how specific architectural choices\nand pre-training techniques can significantly improve performance,\noutperforming extractive baselines. The data, training, evaluation code, and\nbest model weights are open-sourced.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 14:57:55 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Liu", "Peter J.", ""], ["Chung", "Yu-An", ""], ["Ren", "Jie", ""]]}, {"id": "1910.01010", "submitter": "Benoit Miramond Pr.", "authors": "Nassim Abderrahmane and Edgar Lemaire and Beno\\^it Miramond", "title": "Design Space Exploration of Hardware Spiking Neurons for Embedded\n  Artificial Intelligence", "comments": null, "journal-ref": "Elsevier journal on Neural Networks, 2019", "doi": "10.1016/j.neunet.2019.09.024", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is yielding unprecedented interest in research and industry,\ndue to recent success in many applied contexts such as image classification and\nobject recognition. However, the deployment of these systems requires huge\ncomputing capabilities, thus making them unsuitable for embedded systems. To\ndeal with this limitation, many researchers are investigating brain-inspired\ncomputing, which would be a perfect alternative to the conventional Von Neumann\narchitecture based computers (CPU/GPU) that meet the requirements for computing\nperformance, but not for energy-efficiency. Therefore, neuromorphic hardware\ncircuits that are adaptable for both parallel and distributed computations need\nto be designed. In this paper, we focus on Spiking Neural Networks (SNNs) with\na comprehensive study of information coding methods and hardware exploration.\nIn this context, we propose a framework for neuromorphic hardware design space\nexploration, which allows to define a suitable architecture based on\napplication-specific constraints and starting from a wide variety of possible\narchitectural choices. For this framework, we have developed a behavioral level\nsimulator for neuromorphic hardware architectural exploration named NAXT.\nMoreover, we propose modified versions of the standard Rate Coding technique to\nmake trade-offs with the Time Coding paradigm, which is characterized by the\nlow number of spikes propagating in the network. Thus, we are able to reduce\nthe number of spikes while keeping the same neuron's model, which results in an\nSNN with fewer events to process. By doing so, we seek to reduce the amount of\npower consumed by the hardware. Furthermore, we present three neuromorphic\nhardware architectures in order to quantitatively study the implementation of\nSNNs. These architectures are derived from a novel funnel-like Design Space\nExploration framework for neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 16:20:03 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Abderrahmane", "Nassim", ""], ["Lemaire", "Edgar", ""], ["Miramond", "Beno\u00eet", ""]]}, {"id": "1910.01059", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, Osvaldo Simeone, Brian Gardner, and Andr\\'e Gr\\\"uning", "title": "An Introduction to Probabilistic Spiking Neural Networks: Probabilistic\n  Models, Learning Rules, and Applications", "comments": "Published in IEEE Signal Processing Magazine, Vol. 36, No. 6, pp.\n  64-77 (subsumes arXiv:1812.03929), Author's Accepted Manuscript", "journal-ref": null, "doi": "10.1109/MSP.2019.2935234", "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are distributed trainable systems whose\ncomputing elements, or neurons, are characterized by internal analog dynamics\nand by digital and sparse synaptic communications. The sparsity of the synaptic\nspiking inputs and the corresponding event-driven nature of neural processing\ncan be leveraged by energy-efficient hardware implementations, which can offer\nsignificant energy reductions as compared to conventional artificial neural\nnetworks (ANNs). The design of training algorithms lags behind the hardware\nimplementations. Most existing training algorithms for SNNs have been designed\neither for biological plausibility or through conversion from pretrained ANNs\nvia rate encoding. This article provides an introduction to SNNs by focusing on\na probabilistic signal processing methodology that enables the direct\nderivation of learning rules by leveraging the unique time-encoding\ncapabilities of SNNs. We adopt discrete-time probabilistic models for networked\nspiking neurons and derive supervised and unsupervised learning rules from\nfirst principles via variational inference. Examples and open research problems\nare also provided.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 16:28:34 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 18:14:03 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""], ["Gardner", "Brian", ""], ["Gr\u00fcning", "Andr\u00e9", ""]]}, {"id": "1910.01178", "submitter": "Arnaud Mignan", "authors": "Arnaud Mignan, Marco Broccardo", "title": "Neural Network Applications in Earthquake Prediction (1994-2019):\n  Meta-Analytic Insight on their Limitations", "comments": "25 pages, 7 figures", "journal-ref": "Seismological Research Letters, 2020", "doi": "10.1785/0220200021", "report-no": null, "categories": "cs.NE cs.LG physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, deep learning has solved seemingly intractable\nproblems, boosting the hope to find approximate solutions to problems that now\nare considered unsolvable. Earthquake prediction, the Grail of Seismology, is,\nin this context of continuous exciting discoveries, an obvious choice for deep\nlearning exploration. We review the entire literature of artificial neural\nnetwork (ANN) applications for earthquake prediction (77 articles, 1994-2019\nperiod) and find two emerging trends: an increasing interest in this domain,\nand a complexification of ANN models over time, towards deep learning. Despite\napparent positive results observed in this corpus, we demonstrate that simpler\nmodels seem to offer similar predictive powers, if not better ones. Due to the\nstructured, tabulated nature of earthquake catalogues, and the limited number\nof features so far considered, simpler and more transparent machine learning\nmodels seem preferable at the present stage of research. Those baseline models\nfollow first physical principles and are consistent with the known empirical\nlaws of Statistical Seismology, which have minimal abilities to predict large\nearthquakes.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 19:28:34 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Mignan", "Arnaud", ""], ["Broccardo", "Marco", ""]]}, {"id": "1910.01215", "submitter": "Xingyou Song", "authors": "Xingyou Song, Wenbo Gao, Yuxiang Yang, Krzysztof Choromanski, Aldo\n  Pacchiano, Yunhao Tang", "title": "ES-MAML: Simple Hessian-Free Meta Learning", "comments": "Published as a conference paper in ICLR 2020. Code can be found in\n  http://github.com/google-research/google-research/tree/master/es_maml", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce ES-MAML, a new framework for solving the model agnostic meta\nlearning (MAML) problem based on Evolution Strategies (ES). Existing algorithms\nfor MAML are based on policy gradients, and incur significant difficulties when\nattempting to estimate second derivatives using backpropagation on stochastic\npolicies. We show how ES can be applied to MAML to obtain an algorithm which\navoids the problem of estimating second derivatives, and is also conceptually\nsimple and easy to implement. Moreover, ES-MAML can handle new types of\nnonsmooth adaptation operators, and other techniques for improving performance\nand estimation of ES methods become applicable. We show empirically that\nES-MAML is competitive with existing methods and often yields better adaptation\nwith fewer queries.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 19:28:33 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 20:39:22 GMT"}, {"version": "v3", "created": "Sat, 11 Jan 2020 15:30:11 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 15:49:16 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Song", "Xingyou", ""], ["Gao", "Wenbo", ""], ["Yang", "Yuxiang", ""], ["Choromanski", "Krzysztof", ""], ["Pacchiano", "Aldo", ""], ["Tang", "Yunhao", ""]]}, {"id": "1910.01271", "submitter": "Alexander Wong", "authors": "Alexander Wong, Mahmoud Famuori, Mohammad Javad Shafiee, Francis Li,\n  Brendan Chwyl, and Jonathan Chung", "title": "YOLO Nano: a Highly Compact You Only Look Once Convolutional Neural\n  Network for Object Detection", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection remains an active area of research in the field of computer\nvision, and considerable advances and successes has been achieved in this area\nthrough the design of deep convolutional neural networks for tackling object\ndetection. Despite these successes, one of the biggest challenges to widespread\ndeployment of such object detection networks on edge and mobile scenarios is\nthe high computational and memory requirements. As such, there has been growing\nresearch interest in the design of efficient deep neural network architectures\ncatered for edge and mobile usage. In this study, we introduce YOLO Nano, a\nhighly compact deep convolutional neural network for the task of object\ndetection. A human-machine collaborative design strategy is leveraged to create\nYOLO Nano, where principled network design prototyping, based on design\nprinciples from the YOLO family of single-shot object detection network\narchitectures, is coupled with machine-driven design exploration to create a\ncompact network with highly customized module-level macroarchitecture and\nmicroarchitecture designs tailored for the task of embedded object detection.\nThe proposed YOLO Nano possesses a model size of ~4.0MB (>15.1x and >8.3x\nsmaller than Tiny YOLOv2 and Tiny YOLOv3, respectively) and requires 4.57B\noperations for inference (>34% and ~17% lower than Tiny YOLOv2 and Tiny YOLOv3,\nrespectively) while still achieving an mAP of ~69.1% on the VOC 2007 dataset\n(~12% and ~10.7% higher than Tiny YOLOv2 and Tiny YOLOv3, respectively).\nExperiments on inference speed and power efficiency on a Jetson AGX Xavier\nembedded module at different power budgets further demonstrate the efficacy of\nYOLO Nano for embedded scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 01:29:26 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Wong", "Alexander", ""], ["Famuori", "Mahmoud", ""], ["Shafiee", "Mohammad Javad", ""], ["Li", "Francis", ""], ["Chwyl", "Brendan", ""], ["Chung", "Jonathan", ""]]}, {"id": "1910.01274", "submitter": "Isar Nejadgholi", "authors": "Kathleen C. Fraser, Isar Nejadgholi, Berry De Bruijn, Muqun Li, Astha\n  LaPlante, Khaldoun Zine El Abidine", "title": "Extracting UMLS Concepts from Medical Text Using General and\n  Domain-Specific Deep Learning Models", "comments": "11 pages, accepted at LOUHI2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity recognition is a critical first step to a number of clinical NLP\napplications, such as entity linking and relation extraction. We present the\nfirst attempt to apply state-of-the-art entity recognition approaches on a\nnewly released dataset, MedMentions. This dataset contains over 4000 biomedical\nabstracts, annotated for UMLS semantic types. In comparison to existing\ndatasets, MedMentions contains a far greater number of entity types, and thus\nrepresents a more challenging but realistic scenario in a real-world setting.\nWe explore a number of relevant dimensions, including the use of contextual\nversus non-contextual word embeddings, general versus domain-specific\nunsupervised pre-training, and different deep learning architectures. We\ncontrast our results against the well-known i2b2 2010 entity recognition\ndataset, and propose a new method to combine general and domain-specific\ninformation. While producing a state-of-the-art result for the i2b2 2010 task\n(F1 = 0.90), our results on MedMentions are significantly lower (F1 = 0.63),\nsuggesting there is still plenty of opportunity for improvement on this new\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 01:51:17 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Fraser", "Kathleen C.", ""], ["Nejadgholi", "Isar", ""], ["De Bruijn", "Berry", ""], ["Li", "Muqun", ""], ["LaPlante", "Astha", ""], ["Abidine", "Khaldoun Zine El", ""]]}, {"id": "1910.01280", "submitter": "Mehdi Neshat", "authors": "Mehdi Neshat, Bradley Alexander, Markus Wagner", "title": "A Hybrid Cooperative Co-evolution Algorithm Framework for Optimising\n  Power Take Off and Placements of Wave Energy Converters", "comments": "Information Sciences (2020)", "journal-ref": "INFORM SCIENCES 534 (2020) 218-244", "doi": "10.1016/j.ins.2020.03.112", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wave energy technologies have the potential to play a significant role in the\nsupply of renewable energy on a world scale. One of the most promising designs\nfor wave energy converters (WECs) are fully submerged buoys. In this work, we\nexplore the optimisation of WEC arrays consisting of a three-tether buoy model\ncalled CETO. Such arrays can be optimised for total energy output by adjusting\nboth the relative positions of buoys in farms and also the power-take-off (PTO)\nparameters for each buoy. The search space for these parameters is complex and\nmulti-modal. Moreover, the evaluation of each parameter setting is\ncomputationally expensive -- limiting the number of full model evaluations that\ncan be made. To handle this problem, we propose a new hybrid cooperative\nco-evolution algorithm (HCCA). HCCA consists of a symmetric local search plus\nNelder-Mead and a cooperative co-evolution algorithm (CC) with a backtracking\nstrategy for optimising the positions and PTO settings of WECs, respectively.\nMoreover, a new adaptive scenario is proposed for tuning grey wolf optimiser\n(AGWO) hyper-parameter. AGWO participates notably with other applied optimisers\nin HCCA. For assessing the effectiveness of the proposed approach five popular\nEvolutionary Algorithms (EAs), four alternating optimisation methods and two\nmodern hybrid ideas (LS-NM and SLS-NM-B) are carefully compared in four real\nwave situations (Adelaide, Tasmania, Sydney and Perth) with two wave farm sizes\n(4 and 16). According to the experimental outcomes, the hybrid cooperative\nframework exhibits better performance in terms of both runtime and quality of\nobtained solutions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 02:16:01 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Neshat", "Mehdi", ""], ["Alexander", "Bradley", ""], ["Wagner", "Markus", ""]]}, {"id": "1910.01473", "submitter": "Behrooz Mamandipoor", "authors": "Behrooz Mamandipoor, Mahshid Majd, Monica Moz, Venet Osmani", "title": "Blood lactate concentration prediction in critical care patients:\n  handling missing values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blood lactate concentration is a strong indicator of mortality risk in\ncritically ill patients. While frequent lactate measurements are necessary to\nassess patient's health state, the measurement is an invasive procedure that\ncan increase risk of hospital-acquired infections. For this reason we formally\ndefine the problem of lactate prediction as a clinically relevant benchmark\nproblem for machine learning community so as to assist clinical decision making\nin blood lactate testing. Accordingly, we demonstrate the relevant challenges\nof the problem and its data in addition to the adopted solutions. Also, we\nevaluate the performance of different prediction algorithms on a large dataset\nof ICU patients from the multi-centre eICU database. More specifically, we\nfocus on investigating the impact of missing value imputation methods in\nlactate prediction for each algorithm. The experimental analysis shows\npromising prediction results that encourages further investigation of this\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 13:56:50 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Mamandipoor", "Behrooz", ""], ["Majd", "Mahshid", ""], ["Moz", "Monica", ""], ["Osmani", "Venet", ""]]}, {"id": "1910.01523", "submitter": "Yixing Xu", "authors": "Yixing Xu, Yunhe Wang, Kai Han, Yehui Tang, Shangling Jui, Chunjing\n  Xu, Chang Xu", "title": "ReNAS:Relativistic Evaluation of Neural Architecture Search", "comments": "CVPR 2021, Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective and efficient architecture performance evaluation scheme is\nessential for the success of Neural Architecture Search (NAS). To save\ncomputational cost, most of existing NAS algorithms often train and evaluate\nintermediate neural architectures on a small proxy dataset with limited\ntraining epochs. But it is difficult to expect an accurate performance\nestimation of an architecture in such a coarse evaluation way. This paper\nadvocates a new neural architecture evaluation scheme, which aims to determine\nwhich architecture would perform better instead of accurately predict the\nabsolute architecture performance. Therefore, we propose a\n\\textbf{relativistic} architecture performance predictor in NAS (ReNAS). We\nencode neural architectures into feature tensors, and further refining the\nrepresentations with the predictor. The proposed relativistic performance\npredictor can be deployed in discrete searching methods to search for the\ndesired architectures without additional evaluation. Experimental results on\nNAS-Bench-101 dataset suggests that, sampling 424 ($0.1\\%$ of the entire search\nspace) neural architectures and their corresponding validation performance is\nalready enough for learning an accurate architecture performance predictor. The\naccuracies of our searched neural architectures on NAS-Bench-101 and\nNAS-Bench-201 datasets are higher than that of the state-of-the-art methods and\nshow the priority of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 02:21:12 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 03:24:46 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 11:36:49 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2019 08:02:22 GMT"}, {"version": "v5", "created": "Wed, 10 Mar 2021 07:27:53 GMT"}, {"version": "v6", "created": "Mon, 22 Mar 2021 09:02:22 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Xu", "Yixing", ""], ["Wang", "Yunhe", ""], ["Han", "Kai", ""], ["Tang", "Yehui", ""], ["Jui", "Shangling", ""], ["Xu", "Chunjing", ""], ["Xu", "Chang", ""]]}, {"id": "1910.01603", "submitter": "Ruben Rodriguez Torrado", "authors": "Ruben Rodriguez Torrado, Ahmed Khalifa, Michael Cerny Green, Niels\n  Justesen, Sebastian Risi and Julian Togelius", "title": "Bootstrapping Conditional GANs for Video Game Level Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown im-pressive results for\nimage generation. However, GANs facechallenges in generating contents with\ncertain types of con-straints, such as game levels. Specifically, it is\ndifficult togenerate levels that have aesthetic appeal and are playable atthe\nsame time. Additionally, because training data usually islimited, it is\nchallenging to generate unique levels with cur-rent GANs. In this paper, we\npropose a new GAN architec-ture namedConditional Embedding Self-Attention\nGenera-tive Adversarial Network(CESAGAN) and a new bootstrap-ping training\nprocedure. The CESAGAN is a modification ofthe self-attention GAN that\nincorporates an embedding fea-ture vector input to condition the training of\nthe discriminatorand generator. This allows the network to model\nnon-localdependency between game objects, and to count objects. Ad-ditionally,\nto reduce the number of levels necessary to trainthe GAN, we propose a\nbootstrapping mechanism in whichplayable generated levels are added to the\ntraining set. Theresults demonstrate that the new approach does not only\ngen-erate a larger number of levels that are playable but also gen-erates fewer\nduplicate levels compared to a standard GAN.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:09:47 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Torrado", "Ruben Rodriguez", ""], ["Khalifa", "Ahmed", ""], ["Green", "Michael Cerny", ""], ["Justesen", "Niels", ""], ["Risi", "Sebastian", ""], ["Togelius", "Julian", ""]]}, {"id": "1910.01748", "submitter": "Guillermo A. Castillo", "authors": "Guillermo A. Castillo, Bowen Weng, Wei Zhang, Ayonga Hereid", "title": "Hybrid Zero Dynamics Inspired Feedback Control Policy Design for 3D\n  Bipedal Locomotion using Reinforcement Learning", "comments": "Supplemental video: https://youtu.be/GOT6bnxqwuU", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel model-free reinforcement learning (RL) framework\nto design feedback control policies for 3D bipedal walking. Existing RL\nalgorithms are often trained in an end-to-end manner or rely on prior knowledge\nof some reference joint trajectories. Different from these studies, we propose\na novel policy structure that appropriately incorporates physical insights\ngained from the hybrid nature of the walking dynamics and the well-established\nhybrid zero dynamics approach for 3D bipedal walking. As a result, the overall\nRL framework has several key advantages, including lightweight network\nstructure, short training time, and less dependence on prior knowledge. We\ndemonstrate the effectiveness of the proposed method on Cassie, a challenging\n3D bipedal robot. The proposed solution produces stable limit walking cycles\nthat can track various walking speed in different directions. Surprisingly,\nwithout specifically trained with disturbances to achieve robustness, it also\nperforms robustly against various adversarial forces applied to the torso\ntowards both the forward and the backward directions.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 22:20:04 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Castillo", "Guillermo A.", ""], ["Weng", "Bowen", ""], ["Zhang", "Wei", ""], ["Hereid", "Ayonga", ""]]}, {"id": "1910.01763", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Andriy Myronenko, Ziyue Xu, Wenqi Li, Holger Roth, Yufang\n  Huang, Fausto Milletari, Daguang Xu", "title": "NeurReg: Neural Registration and Its Application to Image Segmentation", "comments": "WACV 2020 first round early accept; supplementary\n  https://drive.google.com/file/d/1kzTLQn8cpoQNAYWUDJMtN5HcqhbWbl7G/view?usp=sharing;\n  code will be released soon under NVIDIA open source; demos\n  https://www.youtube.com/watch?v=GYLD7t7dSAg&t=3s", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Registration is a fundamental task in medical image analysis which can be\napplied to several tasks including image segmentation, intra-operative\ntracking, multi-modal image alignment, and motion analysis. Popular\nregistration tools such as ANTs and NiftyReg optimize an objective function for\neach pair of images from scratch which is time-consuming for large images with\ncomplicated deformation. Facilitated by the rapid progress of deep learning,\nlearning-based approaches such as VoxelMorph have been emerging for image\nregistration. These approaches can achieve competitive performance in a\nfraction of a second on advanced GPUs. In this work, we construct a neural\nregistration framework, called NeurReg, with a hybrid loss of displacement\nfields and data similarity, which substantially improves the current\nstate-of-the-art of registrations. Within the framework, we simulate various\ntransformations by a registration simulator which generates fixed image and\ndisplacement field ground truth for training. Furthermore, we design three\nsegmentation frameworks based on the proposed registration framework: 1)\natlas-based segmentation, 2) joint learning of both segmentation and\nregistration tasks, and 3) multi-task learning with atlas-based segmentation as\nan intermediate feature. Extensive experimental results validate the\neffectiveness of the proposed NeurReg framework based on various metrics: the\nendpoint error (EPE) of the predicted displacement field, mean square error\n(MSE), normalized local cross-correlation (NLCC), mutual information (MI), Dice\ncoefficient, uncertainty estimation, and the interpretability of the\nsegmentation. The proposed NeurReg improves registration accuracy with fast\ninference speed, which can greatly accelerate related medical image analysis\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 00:07:22 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Zhu", "Wentao", ""], ["Myronenko", "Andriy", ""], ["Xu", "Ziyue", ""], ["Li", "Wenqi", ""], ["Roth", "Holger", ""], ["Huang", "Yufang", ""], ["Milletari", "Fausto", ""], ["Xu", "Daguang", ""]]}, {"id": "1910.01858", "submitter": "Rakesh Katuwal Mr.", "authors": "Rakesh Katuwal, P.N. Suganthan", "title": "Stacked Autoencoder Based Deep Random Vector Functional Link Neural\n  Network for Classification", "comments": "29 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme learning machine (ELM), which can be viewed as a variant of Random\nVector Functional Link (RVFL) network without the input-output direct\nconnections, has been extensively used to create multi-layer (deep) neural\nnetworks. Such networks employ randomization based autoencoders (AE) for\nunsupervised feature extraction followed by an ELM classifier for final\ndecision making. Each randomization based AE acts as an independent feature\nextractor and a deep network is obtained by stacking several such AEs. Inspired\nby the better performance of RVFL over ELM, in this paper, we propose several\ndeep RVFL variants by utilizing the framework of stacked autoencoders.\nSpecifically, we introduce direct connections (feature reuse) from preceding\nlayers to the fore layers of the network as in the original RVFL network. Such\nconnections help to regularize the randomization and also reduce the model\ncomplexity. Furthermore, we also introduce denoising criterion, recovering\nclean inputs from their corrupted versions, in the autoencoders to achieve\nbetter higher level representations than the ordinary autoencoders. Extensive\nexperiments on several classification datasets show that our proposed deep\nnetworks achieve overall better and faster generalization than the other\nrelevant state-of-the-art deep neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 10:25:24 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:15:43 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 09:33:35 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 05:25:33 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Katuwal", "Rakesh", ""], ["Suganthan", "P. N.", ""]]}, {"id": "1910.01875", "submitter": "Pooria Hadikhani", "authors": "Parham Hadikhani, Pooria Hadikhani", "title": "An adaptive hybrid algorithm for social networks to choose groups with\n  independent members", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Choosing a committee with independent members in social networks can be named\nas a problem in group selection and independence in the committee is considered\nas the main criterion of this selection. Independence is calculated based on\nthe social distance between group members. Although there are many solutions to\nsolve the problem of group selection in social networks, such as selection of\nthe target set or community detection, just one solution has been proposed to\nchoose committee members based on their independence as a measure of group\nperformance. In this paper, a new adaptive hybrid algorithm is proposed to\nselect the best committee members to maximize the independence of the\ncommittees. This algorithm is a combination of particle swarm optimization\n(PSO) algorithm with two local search algorithms. The goal of this work is to\ncombine exploration and exploitation to improve the efficiency of the proposed\nalgorithm and obtain the optimal solution. Additionally, to combine local\nsearch algorithms with particle swarm optimization, an effective selection\nmechanism is used to select a suitable local search algorithm to combine with\nparticle swarm optimization during the search process. The results of\nexperimental simulation are compared with the well-known and successful\nmetaheuristic algorithms. This comparison shows that the proposed method\nimproves the group independence by at least 21%.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 11:14:34 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Hadikhani", "Parham", ""], ["Hadikhani", "Pooria", ""]]}, {"id": "1910.01888", "submitter": "Andreas Madsen", "authors": "Andreas Madsen, Alexander Rosenberg Johansen", "title": "Measuring Arithmetic Extrapolation Performance", "comments": "Published at Science meets Engineering of Deep Learning at 33rd\n  Conference on Neural Information Processing Systems (NeurIPS 2019),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Neural Arithmetic Logic Unit (NALU) is a neural network layer that can\nlearn exact arithmetic operations between the elements of a hidden state. The\ngoal of NALU is to learn perfect extrapolation, which requires learning the\nexact underlying logic of an unknown arithmetic problem. Evaluating the\nperformance of the NALU is non-trivial as one arithmetic problem might have\nmany solutions. As a consequence, single-instance MSE has been used to evaluate\nand compare performance between models. However, it can be hard to interpret\nwhat magnitude of MSE represents a correct solution and models sensitivity to\ninitialization. We propose using a success-criterion to measure if and when a\nmodel converges. Using a success-criterion we can summarize success-rate over\nmany initialization seeds and calculate confidence intervals. We contribute a\ngeneralized version of the previous arithmetic benchmark to measure models\nsensitivity under different conditions. This is, to our knowledge, the first\nextensive evaluation with respect to convergence of the NALU and its sub-units.\nUsing a success-criterion to summarize 4800 experiments we find that\nconsistently learning arithmetic extrapolation is challenging, in particular\nfor multiplication.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 12:00:36 GMT"}, {"version": "v2", "created": "Thu, 7 Nov 2019 09:31:54 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Madsen", "Andreas", ""], ["Johansen", "Alexander Rosenberg", ""]]}, {"id": "1910.01982", "submitter": "Lei He", "authors": "Lei He, Arthur Guijt, Mathijs de Weerdt, Lining Xing, Neil Yorke-Smith", "title": "Order Acceptance and Scheduling with Sequence-dependent Setup Times: a\n  New Memetic Algorithm and Benchmark of the State of the Art", "comments": null, "journal-ref": "Computers & Industrial Engineering, volume 138, article 106102,\n  2019", "doi": "10.1016/j.cie.2019.106102", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Order Acceptance and Scheduling (OAS) problem describes a class of\nreal-world problems such as in smart manufacturing and satellite scheduling.\nThis problem consists of simultaneously selecting a subset of orders to be\nprocessed as well as determining the associated schedule. A common\ngeneralization includes sequence-dependent setup times and time windows. A\nnovel memetic algorithm for this problem, called Sparrow, comprises a\nhybridization of biased random key genetic algorithm (BRKGA) and adaptive large\nneighbourhood search (ALNS). Sparrow integrates the exploration ability of\nBRKGA and the exploitation ability of ALNS. On a set of standard benchmark\ninstances, this algorithm obtains better-quality solutions with runtimes\ncomparable to state-of-the-art algorithms. To further understand the strengths\nand weaknesses of these algorithms, their performance is also compared on a set\nof new benchmark instances with more realistic properties. We conclude that\nSparrow is distinguished by its ability to solve difficult instances from the\nOAS literature, and that the hybrid steady-state genetic algorithm (HSSGA)\nperforms well on large instances in terms of optimality gap, although taking\nmore time than Sparrow.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 14:55:41 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["He", "Lei", ""], ["Guijt", "Arthur", ""], ["de Weerdt", "Mathijs", ""], ["Xing", "Lining", ""], ["Yorke-Smith", "Neil", ""]]}, {"id": "1910.02219", "submitter": "Abiodun Ayodeji", "authors": "Abiodun Ayodeji, Yong-kuo Liu", "title": "Recurrent neural network based decision support system", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision Support Systems (DSS) in complex installations play a crucial role\nin assisting operators in decision making during abnormal transients and\nprocess disturbances, by actively displaying the status of the system and\nrecording events, time of occurrence and suggesting relevant actions. The\ncomplexity and dynamics of complex systems require a careful selection of\nsuitable neural network architecture, so as to improve diagnostic accuracy. In\nthis work, we present a technique to develop a fault diagnostic decision\nsupport using recurrent neural network and Principal Component Analysis (PCA).\nWe utilized the PCA method for noise filtering in the pre-diagnostic stage, and\nevaluate the predictive capability of radial basis recurrent network on a\nrepresentative data derived from the simulation of a pressurized nuclear\nreactor. The process was validated using data from different fault scenarios,\nand the fault signatures were used as the input. The predictive outputs\nrequired are the location and sizes of the faults. The result shows that the\nradial basis network gives accurate predictions. Selected hyperparameters and\ndiagnostic results are also presented in this paper.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 06:30:57 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ayodeji", "Abiodun", ""], ["Liu", "Yong-kuo", ""]]}, {"id": "1910.02244", "submitter": "Laurent Meunier", "authors": "Laurent Meunier, Jamal Atif, Olivier Teytaud", "title": "Yet another but more efficient black-box adversarial attack: tiling and\n  evolution strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new black-box attack achieving state of the art performances.\nOur approach is based on a new objective function, borrowing ideas from\n$\\ell_\\infty$-white box attacks, and particularly designed to fit\nderivative-free optimization requirements. It only requires to have access to\nthe logits of the classifier without any other information which is a more\nrealistic scenario. Not only we introduce a new objective function, we extend\nprevious works on black box adversarial attacks to a larger spectrum of\nevolution strategies and other derivative-free optimization methods. We also\nhighlight a new intriguing property that deep neural networks are not robust to\nsingle shot tiled attacks. Our models achieve, with a budget limited to\n$10,000$ queries, results up to $99.2\\%$ of success rate against InceptionV3\nclassifier with $630$ queries to the network on average in the untargeted\nattacks setting, which is an improvement by $90$ queries of the current state\nof the art. In the targeted setting, we are able to reach, with a limited\nbudget of $100,000$, $100\\%$ of success rate with a budget of $6,662$ queries\non average, i.e. we need $800$ queries less than the current state of the art.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2019 10:36:47 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 10:48:51 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Meunier", "Laurent", ""], ["Atif", "Jamal", ""], ["Teytaud", "Olivier", ""]]}, {"id": "1910.02366", "submitter": "Dilin Wang", "authors": "Qiang Liu, Lemeng Wu, Dilin Wang", "title": "Splitting Steepest Descent for Growing Neural Architectures", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a progressive training approach for neural networks which\nadaptively grows the network structure by splitting existing neurons to\nmultiple off-springs. By leveraging a functional steepest descent idea, we\nderive a simple criterion for deciding the best subset of neurons to split and\na splitting gradient for optimally updating the off-springs. Theoretically, our\nsplitting strategy is a second-order functional steepest descent for escaping\nsaddle points in an $\\infty$-Wasserstein metric space, on which the standard\nparametric gradient descent is a first-order steepest descent. Our method\nprovides a new computationally efficient approach for optimizing neural network\nstructures, especially for learning lightweight neural architectures in\nresource-constrained settings.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 04:15:23 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:17:16 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 22:25:12 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Liu", "Qiang", ""], ["Wu", "Lemeng", ""], ["Wang", "Dilin", ""]]}, {"id": "1910.02509", "submitter": "Tyler Hayes", "authors": "Tyler L. Hayes, Kushal Kafle, Robik Shrestha, Manoj Acharya,\n  Christopher Kanan", "title": "REMIND Your Neural Network to Prevent Catastrophic Forgetting", "comments": "To appear in the European Conference on Computer Vision (ECCV-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People learn throughout life. However, incrementally updating conventional\nneural networks leads to catastrophic forgetting. A common remedy is replay,\nwhich is inspired by how the brain consolidates memory. Replay involves\nfine-tuning a network on a mixture of new and old instances. While there is\nneuroscientific evidence that the brain replays compressed memories, existing\nmethods for convolutional networks replay raw images. Here, we propose REMIND,\na brain-inspired approach that enables efficient replay with compressed\nrepresentations. REMIND is trained in an online manner, meaning it learns one\nexample at a time, which is closer to how humans learn. Under the same\nconstraints, REMIND outperforms other methods for incremental class learning on\nthe ImageNet ILSVRC-2012 dataset. We probe REMIND's robustness to data ordering\nschemes known to induce catastrophic forgetting. We demonstrate REMIND's\ngenerality by pioneering online learning for Visual Question Answering (VQA).\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 19:48:23 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 16:58:09 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 17:10:44 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Hayes", "Tyler L.", ""], ["Kafle", "Kushal", ""], ["Shrestha", "Robik", ""], ["Acharya", "Manoj", ""], ["Kanan", "Christopher", ""]]}, {"id": "1910.02600", "submitter": "Alexander Amini", "authors": "Alexander Amini, Wilko Schwarting, Ava Soleimany, Daniela Rus", "title": "Deep Evidential Regression", "comments": "Code available on: https://github.com/aamini/evidential-deep-learning", "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deterministic neural networks (NNs) are increasingly being deployed in safety\ncritical domains, where calibrated, robust, and efficient measures of\nuncertainty are crucial. In this paper, we propose a novel method for training\nnon-Bayesian NNs to estimate a continuous target as well as its associated\nevidence in order to learn both aleatoric and epistemic uncertainty. We\naccomplish this by placing evidential priors over the original Gaussian\nlikelihood function and training the NN to infer the hyperparameters of the\nevidential distribution. We additionally impose priors during training such\nthat the model is regularized when its predicted evidence is not aligned with\nthe correct output. Our method does not rely on sampling during inference or on\nout-of-distribution (OOD) examples for training, thus enabling efficient and\nscalable uncertainty learning. We demonstrate learning well-calibrated measures\nof uncertainty on various benchmarks, scaling to complex computer vision tasks,\nas well as robustness to adversarial and OOD test samples.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 04:11:34 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 16:37:04 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Amini", "Alexander", ""], ["Schwarting", "Wilko", ""], ["Soleimany", "Ava", ""], ["Rus", "Daniela", ""]]}, {"id": "1910.02720", "submitter": "Sergey Bartunov", "authors": "Sergey Bartunov, Jack W Rae, Simon Osindero, Timothy P Lillicrap", "title": "Meta-Learning Deep Energy-Based Memory Models", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning associative memory -- a system which is able\nto retrieve a remembered pattern based on its distorted or incomplete version.\nAttractor networks provide a sound model of associative memory: patterns are\nstored as attractors of the network dynamics and associative retrieval is\nperformed by running the dynamics starting from a query pattern until it\nconverges to an attractor. In such models the dynamics are often implemented as\nan optimization procedure that minimizes an energy function, such as in the\nclassical Hopfield network. In general it is difficult to derive a writing rule\nfor a given dynamics and energy that is both compressive and fast. Thus, most\nresearch in energy-based memory has been limited either to tractable energy\nmodels not expressive enough to handle complex high-dimensional objects such as\nnatural images, or to models that do not offer fast writing. We present a novel\nmeta-learning approach to energy-based memory models (EBMM) that allows one to\nuse an arbitrary neural architecture as an energy model and quickly store\npatterns in its weights. We demonstrate experimentally that our EBMM approach\ncan build compressed memories for synthetic and natural data, and is capable of\nassociative retrieval that outperforms existing memory systems in terms of the\nreconstruction error and compression rate.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 10:58:08 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 08:34:53 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Bartunov", "Sergey", ""], ["Rae", "Jack W", ""], ["Osindero", "Simon", ""], ["Lillicrap", "Timothy P", ""]]}, {"id": "1910.02749", "submitter": "Jonas Schmitt", "authors": "Jonas Schmitt, Sebastian Kuckuk, Harald K\\\"ostler", "title": "Optimizing Geometric Multigrid Methods with Evolutionary Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.MS cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many linear and nonlinear systems that arise from the discretization of\npartial differential equations the construction of an efficient multigrid\nsolver is a challenging task. Here we present a novel approach for the\noptimization of geometric multigrid methods that is based on evolutionary\ncomputation, a generic program optimization technique inspired by the principle\nof natural evolution. A multigrid solver is represented as a tree of\nmathematical expressions which we generate based on a tailored grammar. The\nquality of each solver is evaluated in terms of convergence and compute\nperformance using automated local Fourier analysis (LFA) and roofline\nperformance modeling, respectively. Based on these objectives a multi-objective\noptimization is performed using strongly typed genetic programming with a\nnon-dominated sorting based selection. To evaluate the model-based prediction\nand to target concrete applications, scalable implementations of an evolved\nsolver can be automatically generated with the ExaStencils framework. We\ndemonstrate our approach by constructing multigrid solvers for the steady-state\nheat equation with constant and variable coefficients that consistently perform\nbetter than common V- and W-cycles.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 12:23:28 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 08:44:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Schmitt", "Jonas", ""], ["Kuckuk", "Sebastian", ""], ["K\u00f6stler", "Harald", ""]]}, {"id": "1910.02776", "submitter": "Maciej Wo{\\l}czyk", "authors": "Maciej Wo{\\l}czyk, Jacek Tabor, Marek \\'Smieja, Szymon Maszke", "title": "Biologically-Inspired Spatial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce bio-inspired artificial neural networks consisting of neurons\nthat are additionally characterized by spatial positions. To simulate\nproperties of biological systems we add the costs penalizing long connections\nand the proximity of neurons in a two-dimensional space. Our experiments show\nthat in the case where the network performs two different tasks, the neurons\nnaturally split into clusters, where each cluster is responsible for processing\na different task. This behavior not only corresponds to the biological systems,\nbut also allows for further insight into interpretability or continual\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 13:22:13 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Wo\u0142czyk", "Maciej", ""], ["Tabor", "Jacek", ""], ["\u015amieja", "Marek", ""], ["Maszke", "Szymon", ""]]}, {"id": "1910.02875", "submitter": "Arthur Jacot", "authors": "Arthur Jacot and Franck Gabriel and Cl\\'ement Hongler", "title": "The asymptotic spectrum of the Hessian of DNN throughout training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of DNNs during gradient descent is described by the so-called\nNeural Tangent Kernel (NTK). In this article, we show that the NTK allows one\nto gain precise insight into the Hessian of the cost of DNNs. When the NTK is\nfixed during training, we obtain a full characterization of the asymptotics of\nthe spectrum of the Hessian, at initialization and during training. In the\nso-called mean-field limit, where the NTK is not fixed during training, we\ndescribe the first two moments of the Hessian at initialization.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2019 13:04:14 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 07:57:49 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Jacot", "Arthur", ""], ["Gabriel", "Franck", ""], ["Hongler", "Cl\u00e9ment", ""]]}, {"id": "1910.03268", "submitter": "Lorenzo Federici Mr.", "authors": "Lorenzo Federici, Alessandro Zavoli, Guido Colasurdo, Lucandrea\n  Mancini, Agostino Neri", "title": "Integrated Optimization of Ascent Trajectory and SRM Design of\n  Multistage Launch Vehicles", "comments": "29th AAS/AIAA Space Flight Mechanics Meeting, Ka'anapali, Maui, HI", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology for the concurrent first-stage preliminary\ndesign and ascent trajectory optimization, with application to a Vega-derived\nLight Launch Vehicle. The reuse as first stage of an existing upper-stage\n(Zefiro 40) requires a propellant grain geometry redesign, in order to account\nfor the mutated operating conditions. An optimization code based on the\nparallel running of several Differential Evolution algorithms is used to find\nthe optimal internal pressure law during Z40 operation, together with the\noptimal thrust direction and other relevant flight parameters of the entire\nascent trajectory. Payload injected into a target orbit is maximized, while\nrespecting multiple design constraints, either involving the alone solid rocket\nmotor or dependent on the actual flight trajectory. Numerical results for SSO\ninjection are presented.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 08:30:27 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Federici", "Lorenzo", ""], ["Zavoli", "Alessandro", ""], ["Colasurdo", "Guido", ""], ["Mancini", "Lucandrea", ""], ["Neri", "Agostino", ""]]}, {"id": "1910.03354", "submitter": "Gideon Gbenga Oladipupo", "authors": "Gideon Gbenga Oladipupo", "title": "Research on the Concept of Liquid State Machine", "comments": "12 pages, 7 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liquid State Machine (LSM) is a neural model with real time computations\nwhich transforms the time varying inputs stream to a higher dimensional space.\nThe concept of LSM is a novel field of research in biological inspired\ncomputation with most research effort on training the model as well as finding\nthe optimum learning method. In this review, the performance of LSM model was\ninvestigated using two learning method, online learning and offline (batch)\nlearning methods. The review revealed that optimal performance of LSM was\nrecorded through online method as computational space and other complexities\nassociated with batch learning is eliminated.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 12:15:46 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Oladipupo", "Gideon Gbenga", ""]]}, {"id": "1910.03437", "submitter": "Mahardhika Pratama Dr", "authors": "Mahardhika Pratama, Choiru Za'in, Andri Ashfahani, Yew Soon Ong and\n  Weiping Ding", "title": "Automatic Construction of Multi-layer Perceptron Network from Streaming\n  Examples", "comments": "This paper has been accepted for publication in CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous construction of deep neural network (DNNs) is desired for data\nstreams because it potentially offers two advantages: proper model's capacity\nand quick reaction to drift and shift. While the self-organizing mechanism of\nDNNs remains an open issue, this task is even more challenging to be developed\nfor standard multi-layer DNNs than that using the different-depth structures,\nbecause the addition of a new layer results in information loss of previously\ntrained knowledge. A Neural Network with Dynamically Evolved Capacity (NADINE)\nis proposed in this paper. NADINE features a fully open structure where its\nnetwork structure, depth and width, can be automatically evolved from scratch\nin an online manner and without the use of problem-specific thresholds. NADINE\nis structured under a standard MLP architecture and the catastrophic forgetting\nissue during the hidden layer addition phase is resolved using the proposal of\nsoft-forgetting and adaptive memory methods. The advantage of NADINE, namely\nelastic structure and online learning trait, is numerically validated using\nnine data stream classification and regression problems where it demonstrates\nperformance improvement over prominent algorithms in all problems. In addition,\nit is capable of dealing with data stream regression and classification\nproblems equally well.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 14:55:28 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 12:31:01 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Pratama", "Mahardhika", ""], ["Za'in", "Choiru", ""], ["Ashfahani", "Andri", ""], ["Ong", "Yew Soon", ""], ["Ding", "Weiping", ""]]}, {"id": "1910.03492", "submitter": "Dan Busbridge", "authors": "Joseph Enguehard, Dan Busbridge, Vitalii Zhelezniak, Nils Hammerla", "title": "Neural Language Priors", "comments": "4 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of sentence encoder architecture reflects assumptions about how a\nsentence's meaning is composed from its constituent words. We examine the\ncontribution of these architectures by holding them randomly initialised and\nfixed, effectively treating them as as hand-crafted language priors, and\nevaluating the resulting sentence encoders on downstream language tasks. We\nfind that even when encoders are presented with additional information that can\nbe used to solve tasks, the corresponding priors do not leverage this\ninformation, except in an isolated case. We also find that apparently\nuninformative priors are just as good as seemingly informative priors on almost\nall tasks, indicating that learning is a necessary component to leverage\ninformation provided by architecture choice.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 16:44:33 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Enguehard", "Joseph", ""], ["Busbridge", "Dan", ""], ["Zhelezniak", "Vitalii", ""], ["Hammerla", "Nils", ""]]}, {"id": "1910.03799", "submitter": "Gutha Jaya Krishna", "authors": "Gutha Jaya Krishna, Vadlamani Ravi", "title": "Large Scale Global Optimization by Hybrid Evolutionary Computation", "comments": "29 Pages, 8 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In management, business, economics, science, engineering, and research\ndomains, Large Scale Global Optimization (LSGO) plays a predominant and vital\nrole. Though LSGO is applied in many of the application domains, it is a very\ntroublesome and a perverse task. The Congress on Evolutionary Computation (CEC)\nbegan an LSGO competition to come up with algorithms with a bunch of standard\nbenchmark unconstrained LSGO functions. Therefore, in this paper, we propose a\nhybrid meta-heuristic algorithm, which combines an Improved and Modified\nHarmony Search (IMHS), along with a Modified Differential Evolution (MDE) with\nan alternate selection strategy. Harmony Search (HS) does the job of\nexploration and exploitation, and Differential Evolution does the job of giving\na perturbation to the exploration of IMHS, as harmony search suffers from being\nstuck at the basin of local optimal. To judge the performance of the suggested\nalgorithm, we compare the proposed algorithm with ten excellent meta-heuristic\nalgorithms on fifteen LSGO benchmark functions, which have 1000 continuous\ndecision variables, of the CEC 2013 LSGO special session. The experimental\nresults consistently show that our proposed hybrid meta-heuristic performs\nstatistically on par with some algorithms in a few problems, while it turned\nout to be the best in a couple of problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 05:41:58 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Krishna", "Gutha Jaya", ""], ["Ravi", "Vadlamani", ""]]}, {"id": "1910.03804", "submitter": "Mahesh Pal Dr.", "authors": "Mahesh Pal", "title": "Deep neural network for pier scour prediction", "comments": "7 pages, 2 figure, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement in computing power over last decades, deep neural\nnetworks (DNN), consisting of two or more hidden layers with large number of\nnodes, are being suggested as an alternate to commonly used single-hidden-layer\nneural networks (ANN). DNN are found to be flexible models with a very large\nnumber of parameters, thus making them capable of modelling very complex and\nhighly nonlinear relationships existing between inputs and outputs. This paper\ninvestigates the potential of a DNN consisting of 3 hidden layers (100, 80 and\n50 nodes) to predict the local scour around bridge piers using field data. To\nupdate the weights and bias of DNN, an adaptive learning rate optimization\nalgorithm was used. The dataset consists of 232 pier scour measurements, out of\nwhich a total of 154 data were used to train whereas remaining 78 data to test\nthe created model. A correlation coefficient value of 0.957 (root mean square\nerror = 0.306m) was achieved by DNN in comparison to 0.938 (0.388m) by ANN,\nindicating an improved performance by DNN for scour depth perdition.\nEncouraging performance on the used dataset in the work suggests the need of\nmore studies on the use of DNN for various civil engineering applications.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 06:18:59 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Pal", "Mahesh", ""]]}, {"id": "1910.03879", "submitter": "Haakon Robinson", "authors": "Haakon Robinson, Adil Rasheed, Omer San", "title": "Dissecting Deep Neural Networks", "comments": "12 pages, 10 figures (not including bio pics), submitted to IEEE\n  Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In exchange for large quantities of data and processing power, deep neural\nnetworks have yielded models that provide state of the art predication\ncapabilities in many fields. However, a lack of strong guarantees on their\nbehaviour have raised concerns over their use in safety-critical applications.\nA first step to understanding these networks is to develop alternate\nrepresentations that allow for further analysis. It has been shown that neural\nnetworks with piecewise affine activation functions are themselves piecewise\naffine, with their domains consisting of a vast number of linear regions. So\nfar, the research on this topic has focused on counting the number of linear\nregions, rather than obtaining explicit piecewise affine representations. This\nwork presents a novel algorithm that can compute the piecewise affine form of\nany fully connected neural network with rectified linear unit activations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 10:05:23 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 12:33:32 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Robinson", "Haakon", ""], ["Rasheed", "Adil", ""], ["San", "Omer", ""]]}, {"id": "1910.03912", "submitter": "Evgeny Matusov", "authors": "Patrick Wilken and Evgeny Matusov", "title": "Novel Applications of Factored Neural Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore the usefulness of target factors in neural machine\ntranslation (NMT) beyond their original purpose of predicting word lemmas and\ntheir inflections, as proposed by Garc\\`ia-Mart\\`inez et al., 2016. For this,\nwe introduce three novel applications of the factored output architecture: In\nthe first one, we use a factor to explicitly predict the word case separately\nfrom the target word itself. This allows for information to be shared between\ndifferent casing variants of a word. In a second task, we use a factor to\npredict when two consecutive subwords have to be joined, eliminating the need\nfor target subword joining markers. The third task is the prediction of special\ntokens of the operation sequence NMT model (OSNMT) of Stahlberg et al., 2018.\nAutomatic evaluation on English-to-German and English-to-Turkish tasks showed\nthat integration of such auxiliary prediction tasks into NMT is at least as\ngood as the standard NMT approach. For the OSNMT, we observed a significant\nimprovement in BLEU over the baseline OSNMT implementation due to a reduced\noutput sequence length that resulted from the introduction of the target\nfactors.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 11:45:07 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Wilken", "Patrick", ""], ["Matusov", "Evgeny", ""]]}, {"id": "1910.04098", "submitter": "Louis Kirsch", "authors": "Louis Kirsch, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "Improving Generalization in Meta Reinforcement Learning using Learned\n  Objectives", "comments": "Accepted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological evolution has distilled the experiences of many learners into the\ngeneral learning algorithms of humans. Our novel meta reinforcement learning\nalgorithm MetaGenRL is inspired by this process. MetaGenRL distills the\nexperiences of many complex agents to meta-learn a low-complexity neural\nobjective function that decides how future individuals will learn. Unlike\nrecent meta-RL algorithms, MetaGenRL can generalize to new environments that\nare entirely different from those used for meta-training. In some cases, it\neven outperforms human-engineered RL algorithms. MetaGenRL uses off-policy\nsecond-order gradients during meta-training that greatly increase its sample\nefficiency.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:20:48 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 16:56:33 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Kirsch", "Louis", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1910.04112", "submitter": "Honglin Li", "authors": "HongLin Li, Payam Barnaghi, Shirin Enshaeifar, Frieder Ganz", "title": "Continual Learning Using Bayesian Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual learning models allow to learn and adapt to new changes and tasks\nover time. However, in continual and sequential learning scenarios in which the\nmodels are trained using different data with various distributions, neural\nnetworks tend to forget the previously learned knowledge. This phenomenon is\noften referred to as catastrophic forgetting. The catastrophic forgetting is an\ninevitable problem in continual learning models for dynamic environments. To\naddress this issue, we propose a method, called Continual Bayesian Learning\nNetworks (CBLN), which enables the networks to allocate additional resources to\nadapt to new tasks without forgetting the previously learned tasks. Using a\nBayesian Neural Network, CBLN maintains a mixture of Gaussian posterior\ndistributions that are associated with different tasks. The proposed method\ntries to optimise the number of resources that are needed to learn each task\nand avoids an exponential increase in the number of resources that are involved\nin learning multiple tasks. The proposed method does not need to access the\npast training data and can choose suitable weights to classify the data points\nduring the test time automatically based on an uncertainty criterion. We have\nevaluated our method on the MNIST and UCR time-series datasets. The evaluation\nresults show that our method can address the catastrophic forgetting problem at\na promising rate compared to the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 16:50:20 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 10:37:37 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Li", "HongLin", ""], ["Barnaghi", "Payam", ""], ["Enshaeifar", "Shirin", ""], ["Ganz", "Frieder", ""]]}, {"id": "1910.04142", "submitter": "Arunkumar Byravan", "authors": "Arunkumar Byravan, Jost Tobias Springenberg, Abbas Abdolmaleki, Roland\n  Hafner, Michael Neunert, Thomas Lampe, Noah Siegel, Nicolas Heess, Martin\n  Riedmiller", "title": "Imagined Value Gradients: Model-Based Policy Optimization with\n  Transferable Latent Dynamics Models", "comments": "To appear at the 3rd annual Conference on Robot Learning, Osaka,\n  Japan (CoRL 2019). 24 pages including appendix (main paper - 8 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are masters at quickly learning many complex tasks, relying on an\napproximate understanding of the dynamics of their environments. In much the\nsame way, we would like our learning agents to quickly adapt to new tasks. In\nthis paper, we explore how model-based Reinforcement Learning (RL) can\nfacilitate transfer to new tasks. We develop an algorithm that learns an\naction-conditional, predictive model of expected future observations, rewards\nand values from which a policy can be derived by following the gradient of the\nestimated value along imagined trajectories. We show how robust policy\noptimization can be achieved in robot manipulation tasks even with approximate\nmodels that are learned directly from vision and proprioception. We evaluate\nthe efficacy of our approach in a transfer learning scenario, re-using\npreviously learned models on tasks with different reward structures and visual\ndistractors, and show a significant improvement in learning speed compared to\nstrong off-policy baselines. Videos with results can be found at\nhttps://sites.google.com/view/ivg-corl19\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 17:37:52 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Byravan", "Arunkumar", ""], ["Springenberg", "Jost Tobias", ""], ["Abdolmaleki", "Abbas", ""], ["Hafner", "Roland", ""], ["Neunert", "Michael", ""], ["Lampe", "Thomas", ""], ["Siegel", "Noah", ""], ["Heess", "Nicolas", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1910.04209", "submitter": "Jerry Ma", "authors": "Jerry Ma, Denis Yarats", "title": "On the adequacy of untuned warmup for adaptive optimization", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adaptive optimization algorithms such as Adam are widely used in deep\nlearning. The stability of such algorithms is often improved with a warmup\nschedule for the learning rate. Motivated by the difficulty of choosing and\ntuning warmup schedules, recent work proposes automatic variance rectification\nof Adam's adaptive learning rate, claiming that this rectified approach\n(\"RAdam\") surpasses the vanilla Adam algorithm and reduces the need for\nexpensive tuning of Adam with warmup. In this work, we refute this analysis and\nprovide an alternative explanation for the necessity of warmup based on the\nmagnitude of the update term, which is of greater relevance to training\nstability. We then provide some \"rule-of-thumb\" warmup schedules, and we\ndemonstrate that simple untuned warmup of Adam performs more-or-less\nidentically to RAdam in typical practical settings. We conclude by suggesting\nthat practitioners stick to linear warmup with Adam, with a sensible default\nbeing linear warmup over $2 / (1 - \\beta_2)$ training iterations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 19:25:03 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 01:58:24 GMT"}, {"version": "v3", "created": "Sat, 20 Mar 2021 03:43:16 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Ma", "Jerry", ""], ["Yarats", "Denis", ""]]}, {"id": "1910.04233", "submitter": "Kevin Liang", "authors": "Kevin J Liang, Guoyin Wang, Yitong Li, Ricardo Henao, Lawrence Carin", "title": "Kernel-Based Approaches for Sequence Modeling: Connections to Neural\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate time-dependent data analysis from the perspective of recurrent\nkernel machines, from which models with hidden units and gated memory cells\narise naturally. By considering dynamic gating of the memory cell, a model\nclosely related to the long short-term memory (LSTM) recurrent neural network\nis derived. Extending this setup to $n$-gram filters, the convolutional neural\nnetwork (CNN), Gated CNN, and recurrent additive network (RAN) are also\nrecovered as special cases. Our analysis provides a new perspective on the\nLSTM, while also extending it to $n$-gram convolutional filters. Experiments\nare performed on natural language processing tasks and on analysis of local\nfield potentials (neuroscience). We demonstrate that the variants we derive\nfrom kernels perform on par or even better than traditional neural methods. For\nthe neuroscience application, the new models demonstrate significant\nimprovements relative to the prior state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 20:15:53 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Liang", "Kevin J", ""], ["Wang", "Guoyin", ""], ["Li", "Yitong", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1910.04650", "submitter": "Yuwen Xiong", "authors": "Yuwen Xiong, Mengye Ren, Raquel Urtasun", "title": "Learning to Remember from a Multi-Task Teacher", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on catastrophic forgetting during sequential learning\ntypically focus on fixing the accuracy of the predictions for a previously\nlearned task. In this paper we argue that the outputs of neural networks are\nsubject to rapid changes when learning a new data distribution, and networks\nthat appear to \"forget\" everything still contain useful representation towards\nprevious tasks. Instead of enforcing the output accuracy to stay the same, we\npropose to reduce the effect of catastrophic forgetting on the representation\nlevel, as the output layer can be quickly recovered later with a small number\nof examples. Towards this goal, we propose an experimental setup that measures\nthe amount of representational forgetting, and develop a novel meta-learning\nalgorithm to overcome this issue. The proposed meta-learner produces weight\nupdates of a sequential learning network, mimicking a multi-task teacher\nnetwork's representation. We show that our meta-learner can improve its learned\nrepresentations on new tasks, while maintaining a good representation for old\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 15:33:19 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 07:27:07 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Xiong", "Yuwen", ""], ["Ren", "Mengye", ""], ["Urtasun", "Raquel", ""]]}, {"id": "1910.04903", "submitter": "Arturo Pardo", "authors": "Arturo Pardo, Jos\\'e A. Guti\\'errez-Guti\\'errez, Jos\\'e Miguel\n  L\\'opez-Higuera, Brian W. Pogue, and Olga M. Conde", "title": "Coloring the Black Box: Visualizing neural network behavior with a\n  self-introspective model", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following work presents how autoencoding all the possible hidden\nactivations of a network for a given problem can provide insight about its\nstructure, behavior, and vulnerabilities. The method, termed\nself-introspection, can show that a trained model showcases similar activation\npatterns (albeit randomly distributed due to initialization) when shown data\nbelonging to the same category, and classification errors occur in fringe areas\nwhere the activations are not as clearly defined, suggesting some form of\nrandom, slowly varying, implicit encoding occurring within deep networks, that\ncan be observed with this representation. Additionally, obtaining a\nlow-dimensional representation of all the activations allows for (1) real-time\nmodel evaluation in the context of a multiclass classification problem, (2) the\nrearrangement of all hidden layers by their relevance in obtaining a specific\noutput, and (3) the obtainment of a framework where studying possible\ncounter-measures to noise and adversarial attacks is possible.\nSelf-introspection can show how damaged input data can modify the hidden\nactivations, producing an erroneous response. A few illustrative are\nimplemented for feedforward and convolutional models and the MNIST and CIFAR-10\ndatasets, showcasing its capabilities as a model evaluation framework.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 23:02:12 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 10:41:04 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Pardo", "Arturo", ""], ["Guti\u00e9rrez-Guti\u00e9rrez", "Jos\u00e9 A.", ""], ["L\u00f3pez-Higuera", "Jos\u00e9 Miguel", ""], ["Pogue", "Brian W.", ""], ["Conde", "Olga M.", ""]]}, {"id": "1910.04909", "submitter": "Hamda Ajmal", "authors": "Hamda Ajmal, Michael Madden, Catherine Enright", "title": "Dealing with Stochasticity in Biological ODE Models", "comments": "5 pages. In Workshop on Computational Biology (WCB) 2017, co-located\n  with the 34th International Conference on Machine Learning (ICML). arXiv\n  admin note: text overlap with arXiv:1910.04895", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical modeling with Ordinary Differential Equations (ODEs) has proven\nto be extremely successful in a variety of fields, including biology. However,\nthese models are completely deterministic given a certain set of initial\nconditions. We convert mathematical ODE models of three benchmark biological\nsystems to Dynamic Bayesian Networks (DBNs). The DBN model can handle model\nuncertainty and data uncertainty in a principled manner. They can be used for\ntemporal data mining for noisy and missing variables. We apply Particle\nFiltering algorithm to infer the model variables by re-estimating the models\nparameters of various biological ODE models. The model parameters are\nautomatically re-estimated using temporal evidence in the form of data streams.\nThe results show that DBNs are capable of inferring the model variables of the\nODE model with high accuracy in situations where data is missing, incomplete,\nsparse and irregular and true values of model parameters are not known.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 23:20:19 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:57:03 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Ajmal", "Hamda", ""], ["Madden", "Michael", ""], ["Enright", "Catherine", ""]]}, {"id": "1910.04958", "submitter": "Cengiz Pehlevan", "authors": "Dina Obeid, Hugo Ramambason and Cengiz Pehlevan", "title": "Structured and Deep Similarity Matching via Structured and Deep Hebbian\n  Networks", "comments": "Accepted for publication in NeurIPS 2019; Minor typos fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic plasticity is widely accepted to be the mechanism behind learning in\nthe brain's neural networks. A central question is how synapses, with access to\nonly local information about the network, can still organize collectively and\nperform circuit-wide learning in an efficient manner. In single-layered and\nall-to-all connected neural networks, local plasticity has been shown to\nimplement gradient-based learning on a class of cost functions that contain a\nterm that aligns the similarity of outputs to the similarity of inputs. Whether\nsuch cost functions exist for networks with other architectures is not known.\nIn this paper, we introduce structured and deep similarity matching cost\nfunctions, and show how they can be optimized in a gradient-based manner by\nneural networks with local learning rules. These networks extend F\\\"oldiak's\nHebbian/Anti-Hebbian network to deep architectures and structured feedforward,\nlateral and feedback connections. Credit assignment problem is solved elegantly\nby a factorization of the dual learning objective to synapse specific local\nobjectives. Simulations show that our networks learn meaningful features.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 03:44:00 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 22:16:34 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Obeid", "Dina", ""], ["Ramambason", "Hugo", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "1910.04966", "submitter": "Cheng He", "authors": "Cheng He, Shihua Huang, Ran Cheng, Kay Chen Tan, and Yaochu Jin", "title": "Evolutionary Multiobjective Optimization Driven by Generative\n  Adversarial Networks (GANs)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, increasing works have proposed to drive evolutionary algorithms\nusing machine learning models. Usually, the performance of such model based\nevolutionary algorithms is highly dependent on the training qualities of the\nadopted models. Since it usually requires a certain amount of data (i.e. the\ncandidate solutions generated by the algorithms) for model training, the\nperformance deteriorates rapidly with the increase of the problem scales, due\nto the curse of dimensionality. To address this issue, we propose a\nmulti-objective evolutionary algorithm driven by the generative adversarial\nnetworks (GANs). At each generation of the proposed algorithm, the parent\nsolutions are first classified into real and fake samples to train the GANs;\nthen the offspring solutions are sampled by the trained GANs. Thanks to the\npowerful generative ability of the GANs, our proposed algorithm is capable of\ngenerating promising offspring solutions in high-dimensional decision space\nwith limited training data. The proposed algorithm is tested on 10 benchmark\nproblems with up to 200 decision variables. Experimental results on these test\nproblems demonstrate the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:28:41 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 06:19:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["He", "Cheng", ""], ["Huang", "Shihua", ""], ["Cheng", "Ran", ""], ["Tan", "Kay Chen", ""], ["Jin", "Yaochu", ""]]}, {"id": "1910.04970", "submitter": "Gege Zhang", "authors": "Gege Zhang, Gangwei Li, Ningwei Shen and Weidong Zhang", "title": "The Expressivity and Training of Deep Neural Networks: toward the Edge\n  of Chaos?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressivity is one of the most significant issues in assessing neural\nnetworks. In this paper, we provide a quantitative analysis of the expressivity\nfor the deep neural network (DNN) from its dynamic model, where the Hilbert\nspace is employed to analyze the convergence and criticality. We study the\nfeature mapping of several widely used activation functions obtained by Hermite\npolynomials, and find sharp declines or even saddle points in the feature\nspace, which stagnate the information transfer in DNNs. We then present a new\nactivation function design based on the Hermite polynomials for better\nutilization of spatial representation. Moreover, we analyze the information\ntransfer of DNNs, emphasizing the convergence problem caused by the mismatch\nbetween input and topological structure. We also study the effects of input\nperturbations and regularization operators on critical expressivity. Our\ntheoretical analysis reveals that DNNs use spatial domains for information\nrepresentation and evolve to the edge of chaos as depth increases. In actual\ntraining, whether a particular network can ultimately arrive the edge of chaos\ndepends on its ability to overcome convergence and pass information to the\nrequired network depth. Finally, we demonstrate the empirical performance of\nthe proposed hypothesis via multivariate time series prediction and image\nclassification examples.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:44:10 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 13:33:24 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Zhang", "Gege", ""], ["Li", "Gangwei", ""], ["Shen", "Ningwei", ""], ["Zhang", "Weidong", ""]]}, {"id": "1910.04972", "submitter": "Kenneth Stewart", "authors": "Kenneth Stewart, Garrick Orchard, Sumit Bam Shrestha, Emre Neftci", "title": "On-chip Few-shot Learning with Surrogate Gradient Descent on a\n  Neuromorphic Processor", "comments": "Preprint, work in progress. Submitted to AICAS 2020 for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work suggests that synaptic plasticity dynamics in biological models\nof neurons and neuromorphic hardware are compatible with gradient-based\nlearning (Neftci et al., 2019). Gradient-based learning requires iterating\nseveral times over a dataset, which is both time-consuming and constrains the\ntraining samples to be independently and identically distributed. This is\nincompatible with learning systems that do not have boundaries between training\nand inference, such as in neuromorphic hardware. One approach to overcome these\nconstraints is transfer learning, where a portion of the network is pre-trained\nand mapped into hardware and the remaining portion is trained online. Transfer\nlearning has the advantage that pre-training can be accelerated offline if the\ntask domain is known, and few samples of each class are sufficient for learning\nthe target task at reasonable accuracies. Here, we demonstrate on-line\nsurrogate gradient few-shot learning on Intel's Loihi neuromorphic research\nprocessor using features pre-trained with spike-based gradient\nbackpropagation-through-time. Our experimental results show that the Loihi chip\ncan learn gestures online using a small number of shots and achieve results\nthat are comparable to the models simulated on a conventional processor.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 04:57:44 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 12:39:57 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 06:37:40 GMT"}, {"version": "v4", "created": "Wed, 16 Oct 2019 11:48:07 GMT"}, {"version": "v5", "created": "Mon, 21 Oct 2019 18:38:03 GMT"}, {"version": "v6", "created": "Tue, 5 Nov 2019 17:41:12 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Stewart", "Kenneth", ""], ["Orchard", "Garrick", ""], ["Shrestha", "Sumit Bam", ""], ["Neftci", "Emre", ""]]}, {"id": "1910.05018", "submitter": "Nathana\\\"el Fijalkow", "authors": "Nathana\\\"el Fijalkow, Mohit Kumar Gupta", "title": "Verification of Neural Networks: Specifying Global Robustness using\n  Generative Models", "comments": "A preliminary version was presented at the VNN Symposium\n  (Verification of Neural Networks) in Stanford, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of neural networks across most machine learning tasks and the\npersistence of adversarial examples have made the verification of such models\nan important quest. Several techniques have been successfully developed to\nverify robustness, and are now able to evaluate neural networks with thousands\nof nodes. The main weakness of this approach is in the specification:\nrobustness is asserted on a validation set consisting of a finite set of\nexamples, i.e. locally.\n  We propose a notion of global robustness based on generative models, which\nasserts the robustness on a very large and representative set of examples. We\nshow how this can be used for verifying neural networks. In this paper we\nexperimentally explore the merits of this approach, and show how it can be used\nto construct realistic adversarial examples.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 08:05:54 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Fijalkow", "Nathana\u00ebl", ""], ["Gupta", "Mohit Kumar", ""]]}, {"id": "1910.05065", "submitter": "Leonidas Doumas", "authors": "Leonidas A. A. Doumas, Guillermo Puebla, Andrea E. Martin, John E.\n  Hummel", "title": "Relation learning in a neurocomputational architecture supports\n  cross-domain transfer", "comments": "Includes supplemental material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  People readily generalise prior knowledge to novel situations and stimuli.\nAdvances in machine learning and artificial intelligence have begun to\napproximate and even surpass human performance in specific domains, but machine\nlearning systems struggle to generalise information to untrained situations. We\npresent and model that demonstrates human-like extrapolatory generalisation by\nlearning and explicitly representing an open-ended set of relations\ncharacterising regularities within the domains it is exposed to. First, when\ntrained to play one video game (e.g., Breakout). the model generalises to a new\ngame (e.g., Pong) with different rules, dimensions, and characteristics in a\nsingle shot. Second, the model can learn representations from a different\ndomain (e.g., 3D shape images) that support learning a video game and\ngeneralising to a new game in one shot. By exploiting well-established\nprinciples from cognitive psychology and neuroscience, the model learns\nstructured representations without feedback, and without requiring knowledge of\nthe relevant relations to be given a priori. We present additional simulations\nshowing that the representations that the model learns support cross-domain\ngeneralisation. The model's ability to generalise between different games\ndemonstrates the flexible generalisation afforded by a capacity to learn not\nonly statistical relations, but also other relations that are useful for\ncharacterising the domain to be learned. In turn, this kind of flexible,\nrelational generalisation is only possible because the model is capable of\nrepresenting relations explicitly, a capacity that is notably absent in extant\nstatistical machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 10:21:06 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Doumas", "Leonidas A. A.", ""], ["Puebla", "Guillermo", ""], ["Martin", "Andrea E.", ""], ["Hummel", "John E.", ""]]}, {"id": "1910.05091", "submitter": "Mirko Trisolini", "authors": "Mirko Trisolini, Hugh G. Lewis, Camilla Colombo", "title": "Spacecraft design optimisation for demise and survivability", "comments": "Paper accepted for publication in Aerospace Science and Technology", "journal-ref": null, "doi": "10.1016/j.ast.2018.04.006", "report-no": null, "categories": "cs.NE astro-ph.EP cs.CE math.OC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the mitigation measures introduced to cope with the space debris issue\nthere is the de-orbiting of decommissioned satellites. Guidelines for\nre-entering objects call for a ground casualty risk no higher than 0.0001. To\ncomply with this requirement, satellites can be designed through a\ndesign-for-demise philosophy. Still, a spacecraft designed to demise has to\nsurvive the debris-populated space environment for many years. The demisability\nand the survivability of a satellite can both be influenced by a set of common\ndesign choices such as the material selection, the geometry definition, and the\nposition of the components. Within this context, two models have been developed\nto analyse the demise and the survivability of satellites. Given the competing\nnature of the demisability and the survivability, a multi-objective\noptimisation framework was developed, with the aim to identify trade-off\nsolutions for the preliminary design of satellites. As the problem is nonlinear\nand involves the combination of continuous and discrete variables, classical\nderivative based approaches are unsuited and a genetic algorithm was selected\ninstead. The genetic algorithm uses the developed demisability and\nsurvivability criteria as the fitness functions of the multi-objective\nalgorithm. The paper presents a test case, which considers the preliminary\noptimisation of tanks in terms of material, geometry, location, and number of\ntanks for a representative Earth observation mission. The configuration of the\nexternal structure of the spacecraft is fixed. Tanks were selected because they\nare sensitive to both design requirements: they represent critical components\nin the demise process and impact damage can cause the loss of the mission\nbecause of leaking and ruptures. The results present the possible trade off\nsolutions, constituting the Pareto front obtained from the multi-objective\noptimisation.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 11:39:22 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Trisolini", "Mirko", ""], ["Lewis", "Hugh G.", ""], ["Colombo", "Camilla", ""]]}, {"id": "1910.05245", "submitter": "Asier Mujika", "authors": "Asier Mujika and Felix Weissenberger and Angelika Steger", "title": "Decoupling Hierarchical Recurrent Neural Networks With Locally\n  Computable Losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-term dependencies is a key long-standing challenge of recurrent\nneural networks (RNNs). Hierarchical recurrent neural networks (HRNNs) have\nbeen considered a promising approach as long-term dependencies are resolved\nthrough shortcuts up and down the hierarchy. Yet, the memory requirements of\nTruncated Backpropagation Through Time (TBPTT) still prevent training them on\nvery long sequences. In this paper, we empirically show that in (deep) HRNNs,\npropagating gradients back from higher to lower levels can be replaced by\nlocally computable losses, without harming the learning capability of the\nnetwork, over a wide range of tasks. This decoupling by local losses reduces\nthe memory requirements of training by a factor exponential in the depth of the\nhierarchy in comparison to standard TBPTT.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 15:25:28 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Mujika", "Asier", ""], ["Weissenberger", "Felix", ""], ["Steger", "Angelika", ""]]}, {"id": "1910.05268", "submitter": "Asier Mujika", "authors": "Florian Meier and Asier Mujika and Marcelo Matheus Gauy and Angelika\n  Steger", "title": "Improving Gradient Estimation in Evolutionary Strategies With Past\n  Descent Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary Strategies (ES) are known to be an effective black-box\noptimization technique for deep neural networks when the true gradients cannot\nbe computed, such as in Reinforcement Learning. We continue a recent line of\nresearch that uses surrogate gradients to improve the gradient estimation of\nES. We propose a novel method to optimally incorporate surrogate gradient\ninformation. Our approach, unlike previous work, needs no information about the\nquality of the surrogate gradients and is always guaranteed to find a descent\ndirection that is better than the surrogate gradient. This allows to\niteratively use the previous gradient estimate as surrogate gradient for the\ncurrent search point. We theoretically prove that this yields fast convergence\nto the true gradient for linear functions and show under simplifying\nassumptions that it significantly improves gradient estimates for general\nfunctions. Finally, we evaluate our approach empirically on MNIST and\nreinforcement learning tasks and show that it considerably improves the\ngradient estimation of ES at no extra computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 16:00:39 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Meier", "Florian", ""], ["Mujika", "Asier", ""], ["Gauy", "Marcelo Matheus", ""], ["Steger", "Angelika", ""]]}, {"id": "1910.05378", "submitter": "Amir Dehsarvi", "authors": "Amir Dehsarvi, Stephen L. Smith", "title": "Classification of Resting-State fMRI using Evolutionary Algorithms:\n  Towards a Brain Imaging Biomarker for Parkinson's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate early diagnosis and monitoring of neurodegenerative conditions is\nessential for effective disease management and delivery of medication and\ntreatment. This research develops automatic methods for detecting brain imaging\npreclinical biomarkers for Parkinson's disease (PD) by considering the novel\napplication of evolutionary algorithms. A fundamental novel element of this\nwork is the use of evolutionary algorithms to both map and predict the\nfunctional connectivity in patients using resting state functional MRI data\ntaken from the PPMI to identify PD progression biomarkers. Specifically,\nCartesian Genetic Programming was used to classify DCM data as well as\ntime-series data. The findings were validated using two other commonly used\nclassification methods (Artificial Neural Networks and Support Vector Machines)\nand by employing k-fold cross-validation. Across DCM and time-series analyses,\nfindings revealed maximum accuracies of 75.21% for early stage (prodromal) PD\npatients versus healthy controls, 85.87% for PD patients versus prodromal PD\npatients, and 92.09% for PD patients versus healthy controls. Prodromal PD\npatients were classified from healthy controls with high accuracy - this is\nnotable and represents the key finding of this research since current methods\nof diagnosing prodromal PD have both low reliability and low accuracy.\nFurthermore, Cartesian Genetic Programming provided comparable performance\naccuracy relative to ANN and SVM. Evolutionary algorithms enable us to decode\nthe classifier in terms of understanding the data inputs that are used, more\neasily than in ANN and SVM. Hence, these findings underscore the relevance of\nboth DCM analyses for classification and CGP as a novel classification tool for\nbrain imaging data with medical implications for disease diagnosis,\nparticularly in early and asymptomatic stages.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 19:12:34 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Dehsarvi", "Amir", ""], ["Smith", "Stephen L.", ""]]}, {"id": "1910.05448", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Simon Denman, David Ahmedt-Aristizabal, Sridha\n  Sridharan, Kristin Laurens, Patrick Johnston, and Clinton Fookes", "title": "Neural Memory Plasticity for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of machine learning, Neural Memory Networks (NMNs) have\nrecently achieved impressive results in a variety of application areas\nincluding visual question answering, trajectory prediction, object tracking,\nand language modelling. However, we observe that the attention based knowledge\nretrieval mechanisms used in current NMNs restricts them from achieving their\nfull potential as the attention process retrieves information based on a set of\nstatic connection weights. This is suboptimal in a setting where there are vast\ndifferences among samples in the data domain; such as anomaly detection where\nthere is no consistent criteria for what constitutes an anomaly. In this paper,\nwe propose a plastic neural memory access mechanism which exploits both static\nand dynamic connection weights in the memory read, write and output generation\nprocedures. We demonstrate the effectiveness and flexibility of the proposed\nmemory model in three challenging anomaly detection tasks in the medical\ndomain: abnormal EEG identification, MRI tumour type classification and\nschizophrenia risk detection in children. In all settings, the proposed\napproach outperforms the current state-of-the-art. Furthermore, we perform an\nin-depth analysis demonstrating the utility of neural plasticity for the\nknowledge retrieval process and provide evidence on how the proposed memory\nmodel generates sparse yet informative memory outputs.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 00:32:56 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["Ahmedt-Aristizabal", "David", ""], ["Sridharan", "Sridha", ""], ["Laurens", "Kristin", ""], ["Johnston", "Patrick", ""], ["Fookes", "Clinton", ""]]}, {"id": "1910.05492", "submitter": "Chao Qian", "authors": "Chao Qian", "title": "Multi-objective Evolutionary Algorithms are Still Good: Maximizing\n  Monotone Approximately Submodular Minus Modular Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As evolutionary algorithms (EAs) are general-purpose optimization algorithms,\nrecent theoretical studies have tried to analyze their performance for solving\ngeneral problem classes, with the goal of providing a general theoretical\nexplanation of the behavior of EAs. Particularly, a simple multi-objective EA,\ni.e., GSEMO, has been shown to be able to achieve good polynomial-time\napproximation guarantees for submodular optimization, where the objective\nfunction is only required to satisfy some properties but without explicit\nformulation. Submodular optimization has wide applications in diverse areas,\nand previous studies have considered the cases where the objective functions\nare monotone submodular, monotone non-submodular, or non-monotone submodular.\nTo complement this line of research, this paper studies the problem class of\nmaximizing monotone approximately submodular minus modular functions (i.e.,\n$f=g-c$) with a size constraint, where $g$ is a non-negative monotone\napproximately submodular function and $c$ is a non-negative modular function,\nresulting in the objective function $f$ being non-monotone non-submodular. We\nprove that the GSEMO can achieve the best-known polynomial-time approximation\nguarantee. Empirical studies on the applications of Bayesian experimental\ndesign and directed vertex cover show the excellent performance of the GSEMO.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 04:56:37 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Qian", "Chao", ""]]}, {"id": "1910.05493", "submitter": "Yasir Hussain", "authors": "Yasir Hussain, Zhiqiu Huang, Yu Zhou and Senzhang Wang", "title": "Deep Transfer Learning for Source Code Modeling", "comments": null, "journal-ref": "International Journal of Software Engineering and Knowledge\n  Engineering. Vol. 30, No. 05, pp. 649-668 (2020)", "doi": "10.1142/S0218194020500230", "report-no": null, "categories": "cs.LG cs.NE cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning models have shown great potential in source\ncode modeling and analysis. Generally, deep learning-based approaches are\nproblem-specific and data-hungry. A challenging issue of these approaches is\nthat they require training from starch for a different related problem. In this\nwork, we propose a transfer learning-based approach that significantly improves\nthe performance of deep learning-based source code models. In contrast to\ntraditional learning paradigms, transfer learning can transfer the knowledge\nlearned in solving one problem into another related problem. First, we present\ntwo recurrent neural network-based models RNN and GRU for the purpose of\ntransfer learning in the domain of source code modeling. Next, via transfer\nlearning, these pre-trained (RNN and GRU) models are used as feature\nextractors. Then, these extracted features are combined into attention learner\nfor different downstream tasks. The attention learner leverages from the\nlearned knowledge of pre-trained models and fine-tunes them for a specific\ndownstream task. We evaluate the performance of the proposed approach with\nextensive experiments with the source code suggestion task. The results\nindicate that the proposed approach outperforms the state-of-the-art models in\nterms of accuracy, precision, recall, and F-measure without training the models\nfrom scratch.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 04:59:17 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 12:08:39 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hussain", "Yasir", ""], ["Huang", "Zhiqiu", ""], ["Zhou", "Yu", ""], ["Wang", "Senzhang", ""]]}, {"id": "1910.05836", "submitter": "Yasir Noori", "authors": "Yasir J Noori, C H de Groot", "title": "Modelling Resistive and Phase Change Memory with Passive Selector Arrays\n  -- A Matlab Tool", "comments": "9 pages, 16 figures, open-access code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memristor devices are crucial for developing neuromorphic computers and\nnext-generation memory technologies. In this work, we provide a comprehensive\nmodelling tool for simulating static DC reading operations of memristor\ncrossbar arrays that use passive selectors with matrix algebra in MATLAB. The\nsoftware tool was parallel coded and optimized to run with personal computers\nand distributed computer clusters with minimized CPU and memory consumption.\nUsing the tool, we demonstrate the effect of changing the line resistance,\narray size, voltage selection scheme, selector diode's ideality factor, reverse\nsaturation current, temperature and sense resistance on the electrical behavior\nand expected sense margin of one-diode-one-resistor crossbar arrays. We then\ninvestigate the effect of single and dual side array biasing and grounding on\nthe dissipated current throughout the array cells. The tool we offer to the\nmemristor community and the studies we present enables the design of larger and\nmore practical memristor arrays for application in data storage and\nneuromorphic computing.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 21:28:58 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Noori", "Yasir J", ""], ["de Groot", "C H", ""]]}, {"id": "1910.05920", "submitter": "Corey Lammie", "authors": "Corey Lammie, Olga Krestinskaya, Alex James, Mostafa Rahimi Azghadi", "title": "Variation-aware Binarized Memristive Networks", "comments": "4 pages, 3 figures, 3 tables", "journal-ref": "2019 IEEE International Conference on Electronics Circuits and\n  Systems (ICECS)", "doi": "10.1109/ICECS46596.2019.8964998", "report-no": null, "categories": "cs.ET cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The quantization of weights to binary states in Deep Neural Networks (DNNs)\ncan replace resource-hungry multiply accumulate operations with simple\naccumulations. Such Binarized Neural Networks (BNNs) exhibit greatly reduced\nresource and power requirements. In addition, memristors have been shown as\npromising synaptic weight elements in DNNs. In this paper, we propose and\nsimulate novel Binarized Memristive Convolutional Neural Network (BMCNN)\narchitectures employing hybrid weight and parameter representations. We train\nthe proposed architectures offline and then map the trained parameters to our\nbinarized memristive devices for inference. To take into account the variations\nin memristive devices, and to study their effect on the performance, we\nintroduce variations in $R_{ON}$ and $R_{OFF}$. Moreover, we introduce means to\nmitigate the adverse effect of memristive variations in our proposed networks.\nFinally, we benchmark our BMCNNs and variation-aware BMCNNs using the MNIST\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 05:46:12 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lammie", "Corey", ""], ["Krestinskaya", "Olga", ""], ["James", "Alex", ""], ["Azghadi", "Mostafa Rahimi", ""]]}, {"id": "1910.05929", "submitter": "Stanislav Fort", "authors": "Stanislav Fort, Surya Ganguli", "title": "Emergent properties of the local geometry of neural loss landscapes", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local geometry of high dimensional neural network loss landscapes can\nboth challenge our cherished theoretical intuitions as well as dramatically\nimpact the practical success of neural network training. Indeed recent works\nhave observed 4 striking local properties of neural loss landscapes on\nclassification tasks: (1) the landscape exhibits exactly $C$ directions of high\npositive curvature, where $C$ is the number of classes; (2) gradient directions\nare largely confined to this extremely low dimensional subspace of positive\nHessian curvature, leaving the vast majority of directions in weight space\nunexplored; (3) gradient descent transiently explores intermediate regions of\nhigher positive curvature before eventually finding flatter minima; (4)\ntraining can be successful even when confined to low dimensional {\\it random}\naffine hyperplanes, as long as these hyperplanes intersect a Goldilocks zone of\nhigher than average curvature. We develop a simple theoretical model of\ngradients and Hessians, justified by numerical experiments on architectures and\ndatasets used in practice, that {\\it simultaneously} accounts for all $4$ of\nthese surprising and seemingly unrelated properties. Our unified model provides\nconceptual insights into the emergence of these properties and makes\nconnections with diverse topics in neural networks, random matrix theory, and\nspin glasses, including the neural tangent kernel, BBP phase transitions, and\nDerrida's random energy model.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 06:23:38 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Fort", "Stanislav", ""], ["Ganguli", "Surya", ""]]}, {"id": "1910.06062", "submitter": "Maryam Hasani-Shoreh", "authors": "Maryam Hasani-Shoreh, Frank Neumann", "title": "On the Use of Diversity Mechanisms in Dynamic Constrained Continuous\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population diversity plays a key role in evolutionary algorithms that enables\nglobal exploration and avoids premature convergence. This is especially more\ncrucial in dynamic optimization in which diversity can ensure that the\npopulation keeps track of the global optimum by adapting to the changing\nenvironment. Dynamic constrained optimization problems (DCOPs) have been the\ntarget for many researchers in recent years as they comprehend many of the\ncurrent real-world problems. Regardless of the importance of diversity in\ndynamic optimization, there is not an extensive study investigating the effects\nof diversity promotion techniques in DCOPs so far. To address this gap, this\npaper aims to investigate how the use of different diversity mechanisms may\ninfluence the behavior of algorithms in DCOPs. To achieve this goal, we apply\nand adapt the most common diversity promotion mechanisms for dynamic\nenvironments using differential evolution (DE) as our base algorithm. The\nresults show that applying diversity techniques to solve DCOPs in most test\ncases lead to significant enhancement in the baseline algorithm in terms of\nmodified offline error values.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 23:59:01 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Hasani-Shoreh", "Maryam", ""], ["Neumann", "Frank", ""]]}, {"id": "1910.06250", "submitter": "Christian Lins", "authors": "Christian Lins, Bj\\\"orn Friedrich, Andreas Hein, Sebastian Fudickar", "title": "An evolutionary approach to continuously estimate CPR quality parameters\n  from a wrist-worn inertial sensor", "comments": "26 pages. arXiv admin note: text overlap with arXiv:1809.07692", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cardiopulmonary resuscitation (CPR) is one of the most critical emergency\ninterventions for sudden cardiac arrest. In this paper, a robust sinusoidal\nmodel-fitting method based on a Evolution Strategy inspired algorithm for CPR\nquality parameters -- naming chest compression frequency and depth -- as\nmeasured by an inertial measurement unit (IMU) attached to the wrist is\npresented. The proposed approach will allow bystanders to improve CPR as part\nof a continuous closed-loop support system once integrated into a smartphone or\nsmartwatch application. By evaluating the model's precision with data recorded\nby a training mannequin as reference standard, a variance for the compression\nfrequency of $\\pm 2.22$ compressions per minute (cpm) has been found for the\nIMU attached to the wrist. It was found that this previously unconsidered\nposition and thus, the use of smartwatches is a suitable alternative to the\ntypical placement of phones in hand for CPR training.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 08:13:30 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 05:58:30 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 10:05:00 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lins", "Christian", ""], ["Friedrich", "Bj\u00f6rn", ""], ["Hein", "Andreas", ""], ["Fudickar", "Sebastian", ""]]}, {"id": "1910.06283", "submitter": "Moustafa Zein", "authors": "Moustafa Zein, Aboul Ella Hassanien, Ammar Adl, and Adam Slowik", "title": "Monkey Optimization System with Active Membranes: A New Meta-heuristic\n  Optimization System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Optimization techniques, used to get the optimal solution in search spaces,\nhave not solved the time-consuming problem. The objective of this study is to\ntackle the sequential processing problem in Monkey Algorithm and simulating the\nnatural parallel behavior of monkeys. Therefore, a P system with active\nmembranes is constructed by providing a codification for Monkey Algorithm\nwithin the context of a cell-like P system, defining accordingly the elements\nof the model - membrane structure, objects, rules and the behavior of it. The\nproposed algorithm has modeled the natural behavior of climb process using\nseparate membranes, rather than the original algorithm. Moreover, it introduced\nthe membrane migration process to select the best solution and the time stamp\nwas added as an additional stopping criterion to control the timing of the\nalgorithm. The results indicate a substantial solution for the time consumption\nproblem, significant representation of the natural behavior of monkeys, and\nconsiderable chance to reach the best solution in the context of\nmeta-heuristics purpose. In addition, experiments use the commonly used\nbenchmark functions to test the performance of the algorithm as well as the\nexpected time of the proposed P Monkey optimization algorithm and the\ntraditional Monkey Algorithm running on population size. The unit times are\ncalculated based on the complexity of algorithms, where P Monkey takes a time\nunit to fire rule(s) over a population size n; as soon as, Monkey Algorithm\ntakes a time unit to run a step every mathematical equation over a population\nsize.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 14:43:49 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zein", "Moustafa", ""], ["Hassanien", "Aboul Ella", ""], ["Adl", "Ammar", ""], ["Slowik", "Adam", ""]]}, {"id": "1910.06458", "submitter": "Ali Mirzaeian", "authors": "Ali Mirzaeian, Houman Homayoun, Avesta Sasan", "title": "TCD-NPE: A Re-configurable and Efficient Neural Processing Engine,\n  Powered by Novel Temporal-Carry-deferring MACs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we first propose the design of Temporal-Carry-deferring MAC\n(TCD-MAC) and illustrate how our proposed solution can gain significant energy\nand performance benefit when utilized to process a stream of input data. We\nthen propose using the TCD-MAC to build a reconfigurable, high speed, and low\npower Neural Processing Engine (TCD-NPE). We, further, propose a novel\nscheduler that lists the sequence of needed processing events to process an MLP\nmodel in the least number of computational rounds in our proposed TCD-NPE. We\nillustrate that our proposed TCD-NPE significantly outperform similar neural\nprocessing solutions that use conventional MACs in terms of both energy\nconsumption and execution time.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 23:05:34 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Mirzaeian", "Ali", ""], ["Homayoun", "Houman", ""], ["Sasan", "Avesta", ""]]}, {"id": "1910.06466", "submitter": "Alexander Wong", "authors": "Mohammad Javad Shafiee, Andrew Hryniowski, Francis Li, Zhong Qiu Lin,\n  and Alexander Wong", "title": "State of Compact Architecture Search For Deep Neural Networks", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of compact deep neural networks is a crucial task to enable\nwidespread adoption of deep neural networks in the real-world, particularly for\nedge and mobile scenarios. Due to the time-consuming and challenging nature of\nmanually designing compact deep neural networks, there has been significant\nrecent research interest into algorithms that automatically search for compact\nnetwork architectures. A particularly interesting class of compact architecture\nsearch algorithms are those that are guided by baseline network architectures.\nSuch algorithms have been shown to be significantly more computationally\nefficient than unguided methods. In this study, we explore the current state of\ncompact architecture search for deep neural networks through both theoretical\nand empirical analysis of four different state-of-the-art compact architecture\nsearch algorithms: i) group lasso regularization, ii) variational dropout, iii)\nMorphNet, and iv) Generative Synthesis. We examine these methods in detail\nbased on a number of different factors such as efficiency, effectiveness, and\nscalability. Furthermore, empirical evaluations are conducted to compare the\nefficacy of these compact architecture search algorithms across three\nwell-known benchmark datasets. While by no means an exhaustive exploration, we\nhope that this study helps provide insights into the interesting state of this\nrelatively new area of research in terms of diversity and real, tangible gains\nalready achieved in architecture design improvements. Furthermore, the hope is\nthat this study would help in pushing the conversation forward towards a deeper\ntheoretical and empirical understanding where the research community currently\nstands in the landscape of compact architecture search for deep neural\nnetworks, and the practical challenges and considerations in leveraging such\napproaches for operational usage.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 00:16:52 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Hryniowski", "Andrew", ""], ["Li", "Francis", ""], ["Lin", "Zhong Qiu", ""], ["Wong", "Alexander", ""]]}, {"id": "1910.06500", "submitter": "Yasir Hussain", "authors": "Yasir Hussain, Zhiqiu Huang, Yu Zhou and Senzhang Wang", "title": "DeepVS: An Efficient and Generic Approach for Source Code Modeling Usage", "comments": null, "journal-ref": "Electronics Letters ( Volume: 56 , Issue: 12 , 6 11 2020 )\n  Page(s): 604 - 607", "doi": "10.1049/el.2020.0500", "report-no": null, "categories": "cs.NE cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The source code suggestions provided by current IDEs are mostly dependent on\nstatic type learning. These suggestions often end up proposing irrelevant\nsuggestions for a peculiar context. Recently, deep learning-based approaches\nhave shown great potential in the modeling of source code for various software\nengineering tasks. However, these techniques lack adequate generalization and\nresistance to acclimate the use of such models in a real-world software\ndevelopment environment. This letter presents \\textit{DeepVS}, an end-to-end\ndeep neural code completion tool that learns from existing codebases by\nexploiting the bidirectional Gated Recurrent Unit (BiGRU) neural net. The\nproposed tool is capable of providing source code suggestions instantly in an\nIDE by using pre-trained BiGRU neural net. The evaluation of this work is\ntwo-fold, quantitative and qualitative. Through extensive evaluation on ten\nreal-world open-source software systems, the proposed method shows significant\nperformance enhancement and its practicality. Moreover, the results also\nsuggest that \\textit{DeepVS} tool is capable of suggesting zero-day (unseen)\ncode tokens by learning coding patterns from real-world software systems.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 02:59:52 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 12:01:26 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hussain", "Yasir", ""], ["Huang", "Zhiqiu", ""], ["Zhou", "Yu", ""], ["Wang", "Senzhang", ""]]}, {"id": "1910.06610", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Analyzing symmetry and symmetry breaking by computational aesthetic\n  measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study creating and analyzing symmetry and broken symmetry in digital art.\nOur focus is not so much on computer-generating artistic images, but rather on\nanalyzing concepts and templates for incorporating symmetry and symmetry\nbreaking into the creation process. Taking as a starting point patterns\ngenerated algorithmically by emulating the collective feeding behavior of\nsand-bubbler crabs, all four types of two-dimensional symmetry are used as\nisometric maps. Apart from a geometric interpretation of symmetry, we also\nconsider color as an object of symmetric transformations. Color symmetry is\nrealized as a color permutation consistent with the isometries. Moreover, we\nanalyze the abilities of computational aesthetic measures to serve as a metric\nthat reflects design parameters, i.e. the type of symmetry and the degree of\nsymmetry breaking.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 09:17:38 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "1910.06854", "submitter": "Lukas Sekanina", "authors": "Filip Badan, Lukas Sekanina", "title": "Optimizing Convolutional Neural Networks for Embedded Systems by Means\n  of Neuroevolution", "comments": "TPNC 2019, LNCS 11934, pp. 1-13, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-34500-6_7", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated design methods for convolutional neural networks (CNNs) have\nrecently been developed in order to increase the design productivity. We\npropose a neuroevolution method capable of evolving and optimizing CNNs with\nrespect to the classification error and CNN complexity (expressed as the number\nof tunable CNN parameters), in which the inference phase can partly be executed\nusing fixed point operations to further reduce power consumption. Experimental\nresults are obtained with TinyDNN framework and presented using two common\nimage classification benchmark problems -- MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 15:15:39 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Badan", "Filip", ""], ["Sekanina", "Lukas", ""]]}, {"id": "1910.06948", "submitter": "Kailiang Wu", "authors": "Kailiang Wu, Dongbin Xiu", "title": "Data-Driven Deep Learning of Partial Differential Equations in Modal\n  Space", "comments": "Minor notational changes", "journal-ref": "Journal of Computational Physics, 408: 109307, 2020", "doi": "10.1016/j.jcp.2020.109307", "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for recovering/approximating unknown time-dependent\npartial differential equation (PDE) using its solution data. Instead of\nidentifying the terms in the underlying PDE, we seek to approximate the\nevolution operator of the underlying PDE numerically. The evolution operator of\nthe PDE, defined in infinite-dimensional space, maps the solution from a\ncurrent time to a future time and completely characterizes the solution\nevolution of the underlying unknown PDE. Our recovery strategy relies on\napproximation of the evolution operator in a properly defined modal space,\ni.e., generalized Fourier space, in order to reduce the problem to finite\ndimensions. The finite dimensional approximation is then accomplished by\ntraining a deep neural network structure, which is based on residual network\n(ResNet), using the given data. Error analysis is provided to illustrate the\npredictive accuracy of the proposed method. A set of examples of different\ntypes of PDEs, including inviscid Burgers' equation that develops discontinuity\nin its solution, are presented to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:43:32 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 23:59:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1910.07012", "submitter": "Gean Pereira", "authors": "Gean Trindade Pereira, Mois\\'es dos Santos, Edesio Alcoba\\c{c}a,\n  Rafael Mantovani and Andr\\'e Carvalho", "title": "Transfer Learning for Algorithm Recommendation", "comments": "Short-paper accepted in LXAI Research Workshop co-located with\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-Learning is a subarea of Machine Learning that aims to take advantage of\nprior knowledge to learn faster and with fewer data [1]. There are different\nscenarios where meta-learning can be applied, and one of the most common is\nalgorithm recommendation, where previous experience on applying machine\nlearning algorithms for several datasets can be used to learn which algorithm,\nfrom a set of options, would be more suitable for a new dataset [2]. Perhaps\nthe most popular form of meta-learning is transfer learning, which consists of\ntransferring knowledge acquired by a machine learning algorithm in a previous\nlearning task to increase its performance faster in another and similar task\n[3]. Transfer Learning has been widely applied in a variety of complex tasks\nsuch as image classification, machine translation and, speech recognition,\nachieving remarkable results [4,5,6,7,8]. Although transfer learning is very\nused in traditional or base-learning, it is still unknown if it is useful in a\nmeta-learning setup. For that purpose, in this paper, we investigate the\neffects of transferring knowledge in the meta-level instead of base-level.\nThus, we train a neural network on meta-datasets related to algorithm\nrecommendation, and then using transfer learning, we reuse the knowledge\nlearned by the neural network in other similar datasets from the same domain,\nto verify how transferable is the acquired meta-knowledge.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 19:26:31 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Pereira", "Gean Trindade", ""], ["Santos", "Mois\u00e9s dos", ""], ["Alcoba\u00e7a", "Edesio", ""], ["Mantovani", "Rafael", ""], ["Carvalho", "Andr\u00e9", ""]]}, {"id": "1910.07070", "submitter": "Wenqian Ronny Huang", "authors": "W. Ronny Huang, Yike Qi, Qianqian Li, Jonathan Degange", "title": "DeepErase: Weakly Supervised Ink Artifact Removal in Document Text\n  Images", "comments": "Conference paper at WACV 2020. First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper-intensive industries like insurance, law, and government have long\nleveraged optical character recognition (OCR) to automatically transcribe\nhordes of scanned documents into text strings for downstream processing. Even\nin 2019, there are still many scanned documents and mail that come into\nbusinesses in non-digital format. Text to be extracted from real world\ndocuments is often nestled inside rich formatting, such as tabular structures\nor forms with fill-in-the-blank boxes or underlines whose ink often touches or\neven strikes through the ink of the text itself. Further, the text region could\nhave random ink smudges or spurious strokes. Such ink artifacts can severely\ninterfere with the performance of recognition algorithms or other downstream\nprocessing tasks. In this work, we propose DeepErase, a neural-based\npreprocessor to erase ink artifacts from text images. We devise a method to\nprogrammatically assemble real text images and real artifacts into\nrealistic-looking \"dirty\" text images, and use them to train an artifact\nsegmentation network in a weakly supervised manner, since pixel-level\nannotations are automatically obtained during the assembly process. In addition\nto high segmentation accuracy, we show that our cleansed images achieve a\nsignificant boost in recognition accuracy by popular OCR software such as\nTesseract 4.0. Finally, we test DeepErase on out-of-distribution datasets (NIST\nSDB) of scanned IRS tax return forms and achieve double-digit improvements in\naccuracy. All experiments are performed on both printed and handwritten text.\nCode for all experiments is available at https://github.com/yikeqicn/DeepErase\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 21:57:04 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 00:50:27 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 05:35:49 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Huang", "W. Ronny", ""], ["Qi", "Yike", ""], ["Li", "Qianqian", ""], ["Degange", "Jonathan", ""]]}, {"id": "1910.07151", "submitter": "Peng Yang", "authors": "Peng Yang and Qi Yang and Ke Tang and Xin Yao", "title": "Parallel Exploration via Negatively Correlated Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective exploration is a key to successful search. The recently proposed\nNegatively Correlated Search (NCS) tries to achieve this by parallel\nexploration, where a set of search processes are driven to be negatively\ncorrelated so that different promising areas of the search space can be visited\nsimultaneously. Various applications have verified the advantages of such novel\nsearch behaviors. Nevertheless, the mathematical understandings are still\nlacking as the previous NCS was mostly devised by intuition. In this paper, a\nmore principled NCS is presented, explaining that the parallel exploration is\nequivalent to the explicit maximization of both the population diversity and\nthe population solution qualities, and can be optimally obtained by partially\ngradient descending both models with respect to each search process. For\nempirical assessments, the reinforcement learning tasks that largely demand\nexploration ability is considered. The new NCS is applied to the popular\nreinforcement learning problems, i.e., playing Atari games, to directly train a\ndeep convolution network with 1.7 million connection weights in the\nenvironments with uncertain and delayed rewards. Empirical results show that\nthe significant advantages of NCS over the compared state-of-the-art methods\ncan be highly owed to the effective parallel exploration ability.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 03:30:29 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 07:44:06 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Yang", "Peng", ""], ["Yang", "Qi", ""], ["Tang", "Ke", ""], ["Yao", "Xin", ""]]}, {"id": "1910.07225", "submitter": "Julian Stier", "authors": "Julian Stier and Michael Granitzer", "title": "Structural Analysis of Sparse Neural Networks", "comments": "23rd International Conference on Knowledge-Based and Intelligent\n  Information & Engineering Systems", "journal-ref": null, "doi": "10.1016/j.procs.2019.09.165", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Neural Networks regained attention due to their potential for\nmathematical and computational advantages. We give motivation to study\nArtificial Neural Networks (ANNs) from a network science perspective, provide a\ntechnique to embed arbitrary Directed Acyclic Graphs into ANNs and report study\nresults on predicting the performance of image classifiers based on the\nstructural properties of the networks' underlying graph. Results could further\nprogress neuroevolution and add explanations for the success of distinct\narchitectures from a structural perspective.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:08:42 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Stier", "Julian", ""], ["Granitzer", "Michael", ""]]}, {"id": "1910.07234", "submitter": "Anis Koubaa", "authors": "Adel Ammar, Anis Koubaa, Mohanned Ahmed, Abdulrahman Saad", "title": "Aerial Images Processing for Car Detection using Convolutional Neural\n  Networks: Comparison between Faster R-CNN and YoloV3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we address the problem of car detection from aerial images\nusing Convolutional Neural Networks (CNN). This problem presents additional\nchallenges as compared to car (or any object) detection from ground images\nbecause features of vehicles from aerial images are more difficult to discern.\nTo investigate this issue, we assess the performance of two state-of-the-art\nCNN algorithms, namely Faster R-CNN, which is the most popular region-based\nalgorithm, and YOLOv3, which is known to be the fastest detection algorithm. We\nanalyze two datasets with different characteristics to check the impact of\nvarious factors, such as UAV's altitude, camera resolution, and object size. A\ntotal of 39 training experiments were conducted to account for the effect of\ndifferent hyperparameter values. The objective of this work is to conduct the\nmost robust and exhaustive comparison between these two cutting-edge algorithms\non the specific domain of aerial images. By using a variety of metrics, we show\nthat YOLOv3 yields better performance in most configurations, except that it\nexhibits a lower recall and less confident detections when object sizes and\nscales in the testing dataset differ largely from those in the training\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 09:25:35 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 20:11:47 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Ammar", "Adel", ""], ["Koubaa", "Anis", ""], ["Ahmed", "Mohanned", ""], ["Saad", "Abdulrahman", ""]]}, {"id": "1910.07268", "submitter": "Sebastian Schmitt", "authors": "Jakub Kmec and Sebastian Schmitt", "title": "Exploring the fitness landscape of a realistic turbofan rotor blade\n  optimization", "comments": null, "journal-ref": "In: Rodrigues H. et al. (eds) EngOpt 2018 Proceedings of the 6th\n  International Conference on Engineering Optimization. EngOpt 2018", "doi": "10.1007/978-3-319-97773-7_46", "report-no": null, "categories": "cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aerodynamic shape optimization has established itself as a valuable tool in\nthe engineering design process to achieve highly efficient results. A central\naspect for such approaches is the mapping from the design parameters which\nencode the geometry of the shape to be improved to the quality criteria which\ndescribe its performance. The choices to be made in the setup of the\noptimization process strongly influence this mapping and thus are expected to\nhave a profound influence on the achievable result. In this work we explore the\ninfluence of such choices on the effects on the shape optimization of a\nturbofan rotor blade as it can be realized within an aircraft engine design\nprocess. The blade quality is assessed by realistic three dimensional\ncomputational fluid dynamics (CFD) simulations.\n  We investigate the outcomes of several optimization runs which differ in\nvarious configuration options, such as optimization algorithm, initialization,\nnumber of degrees of freedom for the parametrization. For all such variations,\nwe generally find that the achievable improvement of the blade quality is\ncomparable for most settings and thus rather insensitive to the details of the\nsetup.\n  On the other hand, even supposedly minor changes in the settings, such as\nusing a different random seed for the initialization of the optimizer\nalgorithm, lead to very different shapes. Optimized shapes which show\ncomparable performance usually differ quite strongly in their geometries over\nthe complete blade.\n  Our analyses indicate that the fitness landscape for such a realistic\nturbofan rotor blade optimization is highly multi-modal with many local optima,\nwhere very different shapes show similar performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 10:38:58 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kmec", "Jakub", ""], ["Schmitt", "Sebastian", ""]]}, {"id": "1910.07387", "submitter": "Alexander Wong", "authors": "Zhong Qiu Lin, Mohammad Javad Shafiee, Stanislav Bochkarev, Michael\n  St. Jules, Xiao Yu Wang, and Alexander Wong", "title": "Do Explanations Reflect Decisions? A Machine-centric Strategy to\n  Quantify the Performance of Explainability Algorithms", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a significant surge of interest recently around the concept of\nexplainable artificial intelligence (XAI), where the goal is to produce an\ninterpretation for a decision made by a machine learning algorithm. Of\nparticular interest is the interpretation of how deep neural networks make\ndecisions, given the complexity and `black box' nature of such networks. Given\nthe infancy of the field, there has been very limited exploration into the\nassessment of the performance of explainability methods, with most evaluations\ncentered around subjective visual interpretation of the produced\ninterpretations. In this study, we explore a more machine-centric strategy for\nquantifying the performance of explainability methods on deep neural networks\nvia the notion of decision-making impact analysis. We introduce two\nquantitative performance metrics: i) Impact Score, which assesses the\npercentage of critical factors with either strong confidence reduction impact\nor decision changing impact, and ii) Impact Coverage, which assesses the\npercentage coverage of adversarially impacted factors in the input. A\ncomprehensive analysis using this approach was conducted on several\nstate-of-the-art explainability methods (LIME, SHAP, Expected Gradients,\nGSInquire) on a ResNet-50 deep convolutional neural network using a subset of\nImageNet for the task of image classification. Experimental results show that\nthe critical regions identified by LIME within the tested images had the lowest\nimpact on the decision-making process of the network (~38%), with progressive\nincrease in decision-making impact for SHAP (~44%), Expected Gradients (~51%),\nand GSInquire (~76%). While by no means perfect, the hope is that the proposed\nmachine-centric strategy helps push the conversation forward towards better\nmetrics for evaluating explainability methods and improve trust in deep neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 14:52:51 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 21:14:22 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Lin", "Zhong Qiu", ""], ["Shafiee", "Mohammad Javad", ""], ["Bochkarev", "Stanislav", ""], ["Jules", "Michael St.", ""], ["Wang", "Xiao Yu", ""], ["Wong", "Alexander", ""]]}, {"id": "1910.07407", "submitter": "Benjamin Cramer", "authors": "Benjamin Cramer, Yannik Stradmann, Johannes Schemmel and Friedemann\n  Zenke", "title": "The Heidelberg spiking datasets for the systematic evaluation of spiking\n  neural networks", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3044364", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking neural networks are the basis of versatile and power-efficient\ninformation processing in the brain. Although we currently lack a detailed\nunderstanding of how these networks compute, recently developed optimization\ntechniques allow us to instantiate increasingly complex functional spiking\nneural networks in-silico. These methods hold the promise to build more\nefficient non-von-Neumann computing hardware and will offer new vistas in the\nquest of unraveling brain circuit function. To accelerate the development of\nsuch methods, objective ways to compare their performance are indispensable.\nPresently, however, there are no widely accepted means for comparing the\ncomputational performance of spiking neural networks. To address this issue, we\nintroduce two spike-based classification datasets, broadly applicable to\nbenchmark both software and neuromorphic hardware implementations of spiking\nneural networks. To accomplish this, we developed a general audio-to-spiking\nconversion procedure inspired by neurophysiology. Further, we applied this\nconversion to an existing and a novel speech dataset. The latter is the free,\nhigh-fidelity, and word-level aligned Heidelberg digit dataset that we created\nspecifically for this study. By training a range of conventional and spiking\nclassifiers, we show that leveraging spike timing information within these\ndatasets is essential for good classification accuracy. These results serve as\nthe first reference for future performance comparisons of spiking neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:22:01 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 10:23:34 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:30:24 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cramer", "Benjamin", ""], ["Stradmann", "Yannik", ""], ["Schemmel", "Johannes", ""], ["Zenke", "Friedemann", ""]]}, {"id": "1910.07482", "submitter": "Ozan Caglayan", "authors": "Ozan Caglayan, Zixiu Wu, Pranava Madhyastha, Josiah Wang, Lucia Specia", "title": "Imperial College London Submission to VATEX Video Captioning Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the Imperial College London team's submission to the\n2019' VATEX video captioning challenge, where we first explore two\nsequence-to-sequence models, namely a recurrent (GRU) model and a transformer\nmodel, which generate captions from the I3D action features. We then\ninvestigate the effect of dropping the encoder and the attention mechanism and\ninstead conditioning the GRU decoder over two different vectorial\nrepresentations: (i) a max-pooled action feature vector and (ii) the output of\na multi-label classifier trained to predict visual entities from the action\nfeatures. Our baselines achieved scores comparable to the official baseline.\nConditioning over entity predictions performed substantially better than\nconditioning on the max-pooled feature vector, and only marginally worse than\nthe GRU-based sequence-to-sequence baseline.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 17:22:25 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Caglayan", "Ozan", ""], ["Wu", "Zixiu", ""], ["Madhyastha", "Pranava", ""], ["Wang", "Josiah", ""], ["Specia", "Lucia", ""]]}, {"id": "1910.07491", "submitter": "Shouyong Jiang", "authors": "Shouyong Jiang, Hongru Li, Jinglei Guo, Mingjun Zhong, Shengxiang\n  Yang, Marcus Kaiser, Natalio Krasnogor", "title": "AREA: Adaptive Reference-set Based Evolutionary Algorithm for\n  Multiobjective Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population-based evolutionary algorithms have great potential to handle\nmultiobjective optimisation problems. However, these algorithms depends largely\non problem characteristics, and there is a need to improve their performance\nfor a wider range of problems. References, which are often specified by the\ndecision maker's preference in different forms, are a very effective method to\nimprove the performance of algorithms but have not been fully explored in\nliterature. This paper proposes a novel framework for effective use of\nreferences to strengthen algorithms. This framework considers references as\nsearch targets which can be adjusted based on the information collected during\nthe search. The proposed framework is combined with new strategies, such as\nreference adaptation and adaptive local mating, to solve different types of\nproblems. The proposed algorithm is compared with state of the arts on a wide\nrange of problems with diverse characteristics. The comparison and extensive\nsensitivity analysis demonstrate that the proposed algorithm is competitive and\nrobust across different types of problems studied in this paper.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 16:58:47 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Jiang", "Shouyong", ""], ["Li", "Hongru", ""], ["Guo", "Jinglei", ""], ["Zhong", "Mingjun", ""], ["Yang", "Shengxiang", ""], ["Kaiser", "Marcus", ""], ["Krasnogor", "Natalio", ""]]}, {"id": "1910.07724", "submitter": "Sagar Verma", "authors": "Sagar Verma and Prince Patel and Angshul Majumdar", "title": "Collaborative Filtering with Label Consistent Restricted Boltzmann\n  Machine", "comments": "6 pages, ICAPR 2017, Code: https://github.com/sagarverma/LC-CFRBM", "journal-ref": null, "doi": "10.1109/ICAPR.2017.8593079", "report-no": null, "categories": "cs.LG cs.IR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The possibility of employing restricted Boltzmann machine (RBM) for\ncollaborative filtering has been known for about a decade. However, there has\nbeen hardly any work on this topic since 2007. This work revisits the\napplication of RBM in recommender systems. RBM based collaborative filtering\nonly used the rating information; this is an unsupervised architecture. This\nwork adds supervision by exploiting user demographic information and item\nmetadata. A network is learned from the representation layer to the labels\n(metadata). The proposed label consistent RBM formulation improves\nsignificantly on the existing RBM based approach and yield results at par with\nthe state-of-the-art latent factor based models.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 05:58:56 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Verma", "Sagar", ""], ["Patel", "Prince", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1910.07960", "submitter": "Giacomo Indiveri", "authors": "Llewyn Salt, David Howard, Giacomo Indiveri, Yulia Sandamirskaya", "title": "Parameter Optimization and Learning in a Spiking Neural Network for UAV\n  Obstacle Avoidance targeting Neuromorphic Processors", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2941506", "report-no": null, "categories": "cs.NE cs.ET nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lobula Giant Movement Detector (LGMD) is an identified neuron of the\nlocust that detects looming objects and triggers the insect's escape responses.\nUnderstanding the neural principles and network structure that lead to these\nfast and robust responses can facilitate the design of efficient obstacle\navoidance strategies for robotic applications. Here we present a neuromorphic\nspiking neural network model of the LGMD driven by the output of a neuromorphic\nDynamic Vision Sensor (DVS), which incorporates spiking frequency adaptation\nand synaptic plasticity mechanisms, and which can be mapped onto existing\nneuromorphic processor chips. However, as the model has a wide range of\nparameters, and the mixed signal analogue-digital circuits used to implement\nthe model are affected by variability and noise, it is necessary to optimise\nthe parameters to produce robust and reliable responses. Here we propose to use\nDifferential Evolution (DE) and Bayesian Optimisation (BO) techniques to\noptimise the parameter space and investigate the use of Self-Adaptive\nDifferential Evolution (SADE) to ameliorate the difficulties of finding\nappropriate input parameters for the DE technique. We quantify the performance\nof the methods proposed with a comprehensive comparison of different optimisers\napplied to the model, and demonstrate the validity of the approach proposed\nusing recordings made from a DVS sensor mounted on a UAV.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 15:06:27 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Salt", "Llewyn", ""], ["Howard", "David", ""], ["Indiveri", "Giacomo", ""], ["Sandamirskaya", "Yulia", ""]]}, {"id": "1910.08149", "submitter": "Sagar Verma", "authors": "Sagar Verma and Shikha Singh and Angshul Majumdar", "title": "Multi Label Restricted Boltzmann Machine for Non-Intrusive Load\n  Monitoring", "comments": "5 pages, ICASSP2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Increasing population indicates that energy demands need to be managed in the\nresidential sector. Prior studies have reflected that the customers tend to\nreduce a significant amount of energy consumption if they are provided with\nappliance-level feedback. This observation has increased the relevance of load\nmonitoring in today's tech-savvy world. Most of the previously proposed\nsolutions claim to perform load monitoring without intrusion, but they are not\ncompletely non-intrusive. These methods require historical appliance-level data\nfor training the model for each of the devices. This data is gathered by\nputting a sensor on each of the appliances present in the home which causes\nintrusion in the building. Some recent studies have proposed that if we frame\nNon-Intrusive Load Monitoring (NILM) as a multi-label classification problem,\nthe need for appliance-level data can be avoided. In this paper, we propose\nMulti-label Restricted Boltzmann Machine(ML-RBM) for NILM and report an\nexperimental evaluation of proposed and state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 20:31:15 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Verma", "Sagar", ""], ["Singh", "Shikha", ""], ["Majumdar", "Angshul", ""]]}, {"id": "1910.08413", "submitter": "Alexander Ra{\\ss}", "authors": "Faramarz Khosravi, Alexander Ra{\\ss}, J\\\"urgen Teich", "title": "Efficient Computation of Probabilistic Dominance in Robust\n  Multi-Objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world problems typically require the simultaneous optimization of\nseveral, often conflicting objectives. Many of these multi-objective\noptimization problems are characterized by wide ranges of uncertainties in\ntheir decision variables or objective functions, which further increases the\ncomplexity of optimization. To cope with such uncertainties, robust\noptimization is widely studied aiming to distinguish candidate solutions with\nuncertain objectives specified by confidence intervals, probability\ndistributions or sampled data. However, existing techniques mostly either fail\nto consider the actual distributions or assume uncertainty as instances of\nuniform or Gaussian distributions. This paper introduces an empirical approach\nthat enables an efficient comparison of candidate solutions with uncertain\nobjectives that can follow arbitrary distributions. Given two candidate\nsolutions under comparison, this operator calculates the probability that one\nsolution dominates the other in terms of each uncertain objective. It can\nsubstitute for the standard comparison operator of existing optimization\ntechniques such as evolutionary algorithms to enable discovering robust\nsolutions to problems with multiple uncertain objectives. This paper also\nproposes to incorporate various uncertainties in well-known multi-objective\nproblems to provide a benchmark for evaluating uncertainty-aware optimization\ntechniques. The proposed comparison operator and benchmark suite are integrated\ninto an existing optimization tool that features a selection of multi-objective\noptimization problems and algorithms. Experiments show that in comparison with\nexisting techniques, the proposed approach achieves higher optimization quality\nat lower overheads.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 13:33:55 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Khosravi", "Faramarz", ""], ["Ra\u00df", "Alexander", ""], ["Teich", "J\u00fcrgen", ""]]}, {"id": "1910.08475", "submitter": "Jordan Ash", "authors": "Jordan T. Ash and Ryan P. Adams", "title": "On Warm-Starting Neural Network Training", "comments": null, "journal-ref": "2020 Advances in Neural Information Processing Systems", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world deployments of machine learning systems, data arrive\npiecemeal. These learning scenarios may be passive, where data arrive\nincrementally due to structural properties of the problem (e.g., daily\nfinancial data) or active, where samples are selected according to a measure of\ntheir quality (e.g., experimental design). In both of these cases, we are\nbuilding a sequence of models that incorporate an increasing amount of data. We\nwould like each of these models in the sequence to be performant and take\nadvantage of all the data that are available to that point. Conventional\nintuition suggests that when solving a sequence of related optimization\nproblems of this form, it should be possible to initialize using the solution\nof the previous iterate -- to \"warm start\" the optimization rather than\ninitialize from scratch -- and see reductions in wall-clock time. However, in\npractice this warm-starting seems to yield poorer generalization performance\nthan models that have fresh random initializations, even though the final\ntraining losses are similar. While it appears that some hyperparameter settings\nallow a practitioner to close this generalization gap, they seem to only do so\nin regimes that damage the wall-clock gains of the warm start. Nevertheless, it\nis highly desirable to be able to warm-start neural network training, as it\nwould dramatically reduce the resource usage associated with the construction\nof performant deep learning systems. In this work, we take a closer look at\nthis empirical phenomenon and try to understand when and how it occurs. We also\nprovide a surprisingly simple trick that overcomes this pathology in several\nimportant situations, and present experiments that elucidate some of its\nproperties.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 15:35:59 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 18:09:19 GMT"}, {"version": "v3", "created": "Thu, 31 Dec 2020 07:58:30 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Ash", "Jordan T.", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1910.08581", "submitter": "Shaeke Salman", "authors": "Shaeke Salman, Canlin Zhang, Xiuwen Liu, Washington Mio", "title": "Towards Quantifying Intrinsic Generalization of Deep ReLU Networks", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the underlying mechanisms that enable the empirical successes\nof deep neural networks is essential for further improving their performance\nand explaining such networks. Towards this goal, a specific question is how to\nexplain the \"surprising\" behavior of the same over-parametrized deep neural\nnetworks that can generalize well on real datasets and at the same time\n\"memorize\" training samples when the labels are randomized. In this paper, we\ndemonstrate that deep ReLU networks generalize from training samples to new\npoints via piece-wise linear interpolation. We provide a quantified analysis on\nthe generalization ability of a deep ReLU network: Given a fixed point\n$\\mathbf{x}$ and a fixed direction in the input space $\\mathcal{S}$, there is\nalways a segment such that any point on the segment will be classified the same\nas the fixed point $\\mathbf{x}$. We call this segment the $generalization \\\ninterval$. We show that the generalization intervals of a ReLU network behave\nsimilarly along pairwise directions between samples of the same label in both\nreal and random cases on the MNIST and CIFAR-10 datasets. This result suggests\nthat the same interpolation mechanism is used in both cases. Additionally, for\ndatasets using real labels, such networks provide a good approximation of the\nunderlying manifold in the data, where the changes are much smaller along\ntangent directions than along normal directions. On the other hand, however,\nfor datasets with random labels, generalization intervals along mid-lines of\ntriangles with the same label are much smaller than those on the datasets with\nreal labels, suggesting different behaviors along other directions. Our\nsystematic experiments demonstrate for the first time that such deep neural\nnetworks generalize through the same interpolation and explain the differences\nbetween their performance on datasets with real and random labels.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 18:38:22 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Salman", "Shaeke", ""], ["Zhang", "Canlin", ""], ["Liu", "Xiuwen", ""], ["Mio", "Washington", ""]]}, {"id": "1910.08629", "submitter": "Yongfeng Zhang", "authors": "Shaoyun Shi, Hanxiong Chen, Min Zhang, Yongfeng Zhang", "title": "Neural Logic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the great success of deep neural networks in many\nresearch areas. The fundamental idea behind the design of most neural networks\nis to learn similarity patterns from data for prediction and inference, which\nlacks the ability of logical reasoning. However, the concrete ability of\nlogical reasoning is critical to many theoretical and practical problems. In\nthis paper, we propose Neural Logic Network (NLN), which is a dynamic neural\narchitecture that builds the computational graph according to input logical\nexpressions. It learns basic logical operations as neural modules, and conducts\npropositional logical reasoning through the network for inference. Experiments\non simulated data show that NLN achieves significant performance on solving\nlogical equations. Further experiments on real-world data show that NLN\nsignificantly outperforms state-of-the-art models on collaborative filtering\nand personalized recommendation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 01:53:37 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Shi", "Shaoyun", ""], ["Chen", "Hanxiong", ""], ["Zhang", "Min", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "1910.08747", "submitter": "Hu Weizhen", "authors": "Min Jiang, Weizhen Hu, Liming Qiu, Minghui Shi, Kay Chen Tan", "title": "Solving dynamic multi-objective optimization problems via support vector\n  machine", "comments": null, "journal-ref": null, "doi": "10.1109/ICACI.2018.8377567", "report-no": null, "categories": "cs.AI cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Multi-objective Optimization Problems (DMOPs) refer to optimization\nproblems that objective functions will change with time. Solving DMOPs implies\nthat the Pareto Optimal Set (POS) at different moments can be accurately found,\nand this is a very difficult job due to the dynamics of the optimization\nproblems. The POS that have been obtained in the past can help us to find the\nPOS of the next time more quickly and accurately. Therefore, in this paper we\npresent a Support Vector Machine (SVM) based Dynamic Multi-Objective\nEvolutionary optimization Algorithm, called SVM-DMOEA. The algorithm uses the\nPOS that has been obtained to train a SVM and then take the trained SVM to\nclassify the solutions of the dynamic optimization problem at the next moment,\nand thus it is able to generate an initial population which consists of\ndifferent individuals recognized by the trained SVM. The initial populuation\ncan be fed into any population based optimization algorithm, e.g., the\nNondominated Sorting Genetic Algorithm II (NSGA-II), to get the POS at that\nmoment. The experimental results show the validity of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 11:06:33 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jiang", "Min", ""], ["Hu", "Weizhen", ""], ["Qiu", "Liming", ""], ["Shi", "Minghui", ""], ["Tan", "Kay Chen", ""]]}, {"id": "1910.08751", "submitter": "Hu Weizhen", "authors": "Weizhen Hu, Min Jiang, Xing Gao, Kay Chen Tan, Yiu-ming Cheung", "title": "Solving Dynamic Multi-objective Optimization Problems Using Incremental\n  Support Vector Machine", "comments": "6 pages", "journal-ref": null, "doi": "10.1109/CEC.2019.8790005", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main feature of the Dynamic Multi-objective Optimization Problems (DMOPs)\nis that optimization objective functions will change with times or\nenvironments. One of the promising approaches for solving the DMOPs is reusing\nthe obtained Pareto optimal set (POS) to train prediction models via machine\nlearning approaches. In this paper, we train an Incremental Support Vector\nMachine (ISVM) classifier with the past POS, and then the solutions of the DMOP\nwe want to solve at the next moment are filtered through the trained ISVM\nclassifier. A high-quality initial population will be generated by the ISVM\nclassifier, and a variety of different types of population-based dynamic\nmulti-objective optimization algorithms can benefit from the population. To\nverify this idea, we incorporate the proposed approach into three evolutionary\nalgorithms, the multi-objective particle swarm optimization(MOPSO),\nNondominated Sorting Genetic Algorithm II (NSGA-II), and the Regularity\nModel-based multi-objective estimation of distribution algorithm(RE-MEDA). We\nemploy experiments to test these algorithms, and experimental results show the\neffectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 11:15:53 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Hu", "Weizhen", ""], ["Jiang", "Min", ""], ["Gao", "Xing", ""], ["Tan", "Kay Chen", ""], ["Cheung", "Yiu-ming", ""]]}, {"id": "1910.08753", "submitter": "Zhenzhong Wang", "authors": "Zhenzhong Wang, Min Jiang, Xing Gao, Liang Feng, Weizhen Hu, Kay Chen\n  Tan", "title": "Evolutionary Dynamic Multi-objective Optimization Via Regression\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic multi-objective optimization problems (DMOPs) remain a challenge to\nbe settled, because of conflicting objective functions change over time. In\nrecent years, transfer learning has been proven to be a kind of effective\napproach in solving DMOPs. In this paper, a novel transfer learning based\ndynamic multi-objective optimization algorithm (DMOA) is proposed called\nregression transfer learning prediction based DMOA (RTLP-DMOA). The algorithm\naims to generate an excellent initial population to accelerate the evolutionary\nprocess and improve the evolutionary performance in solving DMOPs. When an\nenvironmental change is detected, a regression transfer learning prediction\nmodel is constructed by reusing the historical population, which can predict\nobjective values. Then, with the assistance of this prediction model, some\nhigh-quality solutions with better predicted objective values are selected as\nthe initial population, which can improve the performance of the evolutionary\nprocess. We compare the proposed algorithm with three state-of-the-art\nalgorithms on benchmark functions. Experimental results indicate that the\nproposed algorithm can significantly enhance the performance of static\nmulti-objective optimization algorithms and is competitive in convergence and\ndiversity.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 11:29:52 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 04:35:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Wang", "Zhenzhong", ""], ["Jiang", "Min", ""], ["Gao", "Xing", ""], ["Feng", "Liang", ""], ["Hu", "Weizhen", ""], ["Tan", "Kay Chen", ""]]}, {"id": "1910.09308", "submitter": "Dominik M\\\"uller", "authors": "Dominik M\\\"uller and Frank Kramer", "title": "MIScnn: A Framework for Medical Image Segmentation with Convolutional\n  Neural Networks and Deep Learning", "comments": "Open-source Python framework available on GitHub\n  (https://github.com/frankkramer-lab/MIScnn) and PyPI (miscnn). 11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increased availability and usage of modern medical imaging induced a\nstrong need for automatic medical image segmentation. Still, current image\nsegmentation platforms do not provide the required functionalities for plain\nsetup of medical image segmentation pipelines. Already implemented pipelines\nare commonly standalone software, optimized on a specific public data set.\nTherefore, this paper introduces the open-source Python library MIScnn. The aim\nof MIScnn is to provide an intuitive API allowing fast building of medical\nimage segmentation pipelines including data I/O, preprocessing, data\naugmentation, patch-wise analysis, metrics, a library with state-of-the-art\ndeep learning models and model utilization like training, prediction, as well\nas fully automatic evaluation (e.g. cross-validation). Similarly, high\nconfigurability and multiple open interfaces allow full pipeline customization.\nRunning a cross-validation with MIScnn on the Kidney Tumor Segmentation\nChallenge 2019 data set (multi-class semantic segmentation with 300 CT scans)\nresulted into a powerful predictor based on the standard 3D U-Net model. With\nthis experiment, we could show that the MIScnn framework enables researchers to\nrapidly set up a complete medical image segmentation pipeline by using just a\nfew lines of code. The source code for MIScnn is available in the Git\nrepository: https://github.com/frankkramer-lab/MIScnn.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 12:43:25 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["M\u00fcller", "Dominik", ""], ["Kramer", "Frank", ""]]}, {"id": "1910.09312", "submitter": "Kayode Adetunji", "authors": "Kayode Adetunji, Ivan Hofsajer, Ling Cheng", "title": "Trends in the optimal location and sizing of electrical units in smart\n  grids using meta-heuristic algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY eess.SP math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of smart grids has effectively transformed the traditional\ngrid system. This promises numerous advantages for economic values and\nautonomous control of energy sources. In smart grids development, there are\nvarious objectives such as voltage stability, minimized power loss, minimized\neconomic cost and voltage profile improvement. Thus, researchers have\ninvestigated several approaches based on meta-heuristic optimization algorithms\nfor the optimal location and sizing of electrical units in a distribution\nsystem. Meta-heuristic algorithms have been applied to solve different problems\nin power systems and they have been successfully used in distribution systems.\nThis paper presents a comprehensive review on existing methods for the optimal\nlocation and sizing of electrical units in distribution networks while\nconsidering the improvement of major objective functions. Techniques such as\nvoltage stability index, power loss index, and loss sensitivity factors have\nbeen implemented alongside the meta-heuristic optimization algorithms to reduce\nthe search space of solutions for objective functions. However, these\ntechniques can cause a loss of optimality. Another perceived problem is the\ninappropriate handling of multiple objectives, which can also affect the\noptimality of results. Hence, a recent method such as Pareto fronts generation\nhas been developed to produce non-dominating solutions. This review shows a\nneed for more research on (i) the effective handling of multiple objective\nfunctions, (ii) more efficient meta-heuristic optimization algorithms and/or\n(iii) better supporting techniques.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 07:45:43 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Adetunji", "Kayode", ""], ["Hofsajer", "Ivan", ""], ["Cheng", "Ling", ""]]}, {"id": "1910.09402", "submitter": "Juanping Zhu", "authors": "Juanping Zhu, Qi Meng, Wei Chen, Zhi-ming Ma", "title": "Interpreting Basis Path Set in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on basis path set, G-SGD algorithm significantly outperforms\nconventional SGD algorithm in optimizing neural networks. However, how the\ninner mechanism of basis paths work remains mysterious. From the aspect of\ngraph theory, this paper defines basis path, investigates structure properties\nof basis paths in regular fully connected neural network and interprets the\ngraph representation of basis path set. Moreover, we propose hierarchical\nalgorithm HBPS to find basis path set B in fully connected neural network by\ndecomposing the network into several independent and parallel substructures.\nAlgorithm HBPS demands that there doesn't exist shared edges between any two\nindependent substructure paths.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 08:54:28 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Zhu", "Juanping", ""], ["Meng", "Qi", ""], ["Chen", "Wei", ""], ["Ma", "Zhi-ming", ""]]}, {"id": "1910.09495", "submitter": "Saeed Reza Kheradpisheh", "authors": "Saeed Reza Kheradpisheh and Timoth\\'ee Masquelier", "title": "S4NN: temporal backpropagation for spiking neural networks with one\n  spike per neuron", "comments": null, "journal-ref": "International Journal of Neural Systems 2020", "doi": "10.1142/S0129065720500276", "report-no": null, "categories": "cs.NE cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new supervised learning rule for multilayer spiking neural\nnetworks (SNNs) that use a form of temporal coding known as rank-order-coding.\nWith this coding scheme, all neurons fire exactly one spike per stimulus, but\nthe firing order carries information. In particular, in the readout layer, the\nfirst neuron to fire determines the class of the stimulus. We derive a new\nlearning rule for this sort of network, named S4NN, akin to traditional error\nbackpropagation, yet based on latencies. We show how approximated error\ngradients can be computed backward in a feedforward network with any number of\nlayers. This approach reaches state-of-the-art performance with supervised\nmulti fully-connected layer SNNs: test accuracy of 97.4% for the MNIST dataset,\nand 99.2% for the Caltech Face/Motorbike dataset. Yet, the neuron model that we\nuse, non-leaky integrate-and-fire, is much simpler than the one used in all\nprevious works. The source codes of the proposed S4NN are publicly available at\nhttps://github.com/SRKH/S4NN.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:39:42 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 15:43:30 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 09:23:11 GMT"}, {"version": "v4", "created": "Sat, 13 Jun 2020 10:33:19 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kheradpisheh", "Saeed Reza", ""], ["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "1910.09594", "submitter": "Nicolas Skatchkovsky", "authors": "Nicolas Skatchkovsky, Hyeryung Jang, and Osvaldo Simeone", "title": "Federated Neuromorphic Learning of Spiking Neural Networks for Low-Power\n  Edge Intelligence", "comments": "submitted for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) offer a promising alternative to conventional\nArtificial Neural Networks (ANNs) for the implementation of on-device low-power\nonline learning and inference. On-device training is, however, constrained by\nthe limited amount of data available at each device. In this paper, we propose\nto mitigate this problem via cooperative training through Federated Learning\n(FL). To this end, we introduce an online FL-based learning rule for networked\non-device SNNs, which we refer to as FL-SNN. FL-SNN leverages local feedback\nsignals within each SNN, in lieu of backpropagation, and global feedback\nthrough communication via a base station. The scheme demonstrates significant\nadvantages over separate training and features a flexible trade-off between\ncommunication load and accuracy via the selective exchange of synaptic weights.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:36:17 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Skatchkovsky", "Nicolas", ""], ["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1910.09599", "submitter": "Johannes M\\\"uller", "authors": "Johannes M\\\"uller", "title": "On the space-time expressivity of ResNets", "comments": "Extended abstract of master's thesis; presented at the ICLR 2020\n  Workshop on Integration of Deep Neural Models and Differential Equations;\n  full version of the thesis available under\n  https://freidok.uni-freiburg.de/data/151788", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual networks (ResNets) are a deep learning architecture that\nsubstantially improved the state of the art performance in certain supervised\nlearning tasks. Since then, they have received continuously growing attention.\nResNets have a recursive structure $x_{k+1} = x_k + R_k(x_k)$ where $R_k$ is a\nneural network called a residual block. This structure can be seen as the Euler\ndiscretisation of an associated ordinary differential equation (ODE) which is\ncalled a neural ODE. Recently, ResNets were proposed as the space-time\napproximation of ODEs which are not of this neural type. To elaborate this\nconnection we show that by increasing the number of residual blocks as well as\ntheir expressivity the solution of an arbitrary ODE can be approximated in\nspace and time simultaneously by deep ReLU ResNets. Further, we derive\nestimates on the complexity of the residual blocks required to obtain a\nprescribed accuracy under certain regularity assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 18:43:50 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 18:55:45 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 18:06:36 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 20:58:33 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["M\u00fcller", "Johannes", ""]]}, {"id": "1910.09694", "submitter": "Arthur Rattew", "authors": "Arthur G. Rattew, Shaohan Hu, Marco Pistoia, Richard Chen and Steve\n  Wood", "title": "A Domain-agnostic, Noise-resistant, Hardware-efficient Evolutionary\n  Variational Quantum Eigensolver", "comments": "14 pages, 10 figures; references added; minor additions and edits\n  made; affiliations corrected;", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational quantum algorithms have shown promise in numerous fields due to\ntheir versatility in solving problems of scientific and commercial interest.\nHowever, leading algorithms for Hamiltonian simulation, such as the Variational\nQuantum Eigensolver (VQE), use fixed preconstructed ansatzes, limiting their\ngeneral applicability and accuracy. Thus, variational forms---the quantum\ncircuits that implement ansatzes ---are either crafted heuristically or by\nencoding domain-specific knowledge. In this paper, we present an Evolutionary\nVariational Quantum Eigensolver (EVQE), a novel variational algorithm that uses\nevolutionary programming techniques to minimize the expectation value of a\ngiven Hamiltonian by dynamically generating and optimizing an ansatz. The\nalgorithm is equally applicable to optimization problems in all domains,\nobtaining accurate energy evaluations with hardware-efficient ansatzes. In\nmolecular simulations, the variational forms generated by EVQE are up to\n$18.6\\times$ shallower and use up to $12\\times$ fewer CX gates than those\nobtained by VQE with a unitary coupled cluster ansatz. EVQE demonstrates\nsignificant noise-resistance properties, obtaining results in noisy simulation\nwith at least $3.6\\times$ less error than VQE using any tested ansatz\nconfiguration. We successfully evaluated EVQE on a real 5-qubit IBMQ quantum\ncomputer. The experimental results, which we obtained both via simulation and\non real quantum hardware, demonstrate the effectiveness of EVQE for\ngeneral-purpose optimization on the quantum computers of the present and near\nfuture.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 23:42:19 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 13:49:13 GMT"}, {"version": "v3", "created": "Mon, 18 Nov 2019 23:12:26 GMT"}, {"version": "v4", "created": "Thu, 23 Jan 2020 20:09:35 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Rattew", "Arthur G.", ""], ["Hu", "Shaohan", ""], ["Pistoia", "Marco", ""], ["Chen", "Richard", ""], ["Wood", "Steve", ""]]}, {"id": "1910.09745", "submitter": "Wen-Yu Chang", "authors": "Wen-Yu Chang, Tsung-Nan Lin", "title": "Vanishing Nodes: Another Phenomenon That Makes Training Deep Neural\n  Networks Difficult", "comments": "16 pages, 9 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the problem of vanishing/exploding gradients is a\nchallenge when training deep networks. In this paper, we describe another\nphenomenon, called vanishing nodes, that also increases the difficulty of\ntraining deep neural networks. As the depth of a neural network increases, the\nnetwork's hidden nodes have more highly correlated behavior. This results in\ngreat similarities between these nodes. The redundancy of hidden nodes thus\nincreases as the network becomes deeper. We call this problem vanishing nodes,\nand we propose the metric vanishing node indicator (VNI) for quantitatively\nmeasuring the degree of vanishing nodes. The VNI can be characterized by the\nnetwork parameters, which is shown analytically to be proportional to the depth\nof the network and inversely proportional to the network width. The theoretical\nresults show that the effective number of nodes vanishes to one when the VNI\nincreases to one (its maximal value), and that vanishing/exploding gradients\nand vanishing nodes are two different challenges that increase the difficulty\nof training deep neural networks. The numerical results from the experiments\nsuggest that the degree of vanishing nodes will become more evident during\nback-propagation training, and that when the VNI is equal to 1, the network\ncannot learn simple tasks (e.g. the XOR problem) even when the gradients are\nneither vanishing nor exploding. We refer to this kind of gradients as the\nwalking dead gradients, which cannot help the network converge when having a\nrelatively large enough scale. Finally, the experiments show that the\nlikelihood of failed training increases as the depth of the network increases.\nThe training will become much more difficult due to the lack of network\nrepresentation capability.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 03:11:26 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Chang", "Wen-Yu", ""], ["Lin", "Tsung-Nan", ""]]}, {"id": "1910.09763", "submitter": "Thomas Merkh", "authors": "Thomas Merkh and Guido Mont\\'ufar", "title": "Stochastic Feedforward Neural Networks: Universal Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter we take a look at the universal approximation question for\nstochastic feedforward neural networks. In contrast to deterministic networks,\nwhich represent mappings from a set of inputs to a set of outputs, stochastic\nnetworks represent mappings from a set of inputs to a set of probability\ndistributions over the set of outputs. In particular, even if the sets of\ninputs and outputs are finite, the class of stochastic mappings in question is\nnot finite. Moreover, while for a deterministic function the values of all\noutput variables can be computed independently of each other given the values\nof the inputs, in the stochastic setting the values of the output variables may\nneed to be correlated, which requires that their values are computed jointly. A\nprominent class of stochastic feedforward networks which has played a key role\nin the resurgence of deep learning are deep belief networks. The\nrepresentational power of these networks has been studied mainly in the\ngenerative setting, as models of probability distributions without an input, or\nin the discriminative setting for the special case of deterministic mappings.\nWe study the representational power of deep sigmoid belief networks in terms of\ncompositions of linear transformations of probability distributions, Markov\nkernels, that can be expressed by the layers of the network. We investigate\ndifferent types of shallow and deep architectures, and the minimal number of\nlayers and units per layer that are sufficient and necessary in order for the\nnetwork to be able to approximate any given stochastic mapping from the set of\ninputs to the set of outputs arbitrarily well.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 04:49:43 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Merkh", "Thomas", ""], ["Mont\u00fafar", "Guido", ""]]}, {"id": "1910.09768", "submitter": "Qiulei Dong", "authors": "Qiulei Dong and Jiayin Sun and Zhanyi Hu", "title": "Face representation by deep learning: a linear encoding in a parameter\n  space?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Convolutional Neural Networks (CNNs) have achieved tremendous\nperformances on face recognition, and one popular perspective regarding CNNs'\nsuccess is that CNNs could learn discriminative face representations from face\nimages with complex image feature encoding. However, it is still unclear what\nis the intrinsic mechanism of face representation in CNNs. In this work, we\ninvestigate this problem by formulating face images as points in a\nshape-appearance parameter space, and our results demonstrate that: (i) The\nencoding and decoding of the neuron responses (representations) to face images\nin CNNs could be achieved under a linear model in the parameter space, in\nagreement with the recent discovery in primate IT face neurons, but different\nfrom the aforementioned perspective on CNNs' face representation with complex\nimage feature encoding; (ii) The linear model for face encoding and decoding in\nthe parameter space could achieve close or even better performances on face\nrecognition and verification than state-of-the-art CNNs, which might provide\nnew lights on the design strategies for face recognition systems; (iii) The\nneuron responses to face images in CNNs could not be adequately modelled by the\naxis model, a model recently proposed on face modelling in primate IT cortex.\nAll these results might shed some lights on the often complained blackbox\nnature behind CNNs' tremendous performances on face recognition.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 05:01:28 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Dong", "Qiulei", ""], ["Sun", "Jiayin", ""], ["Hu", "Zhanyi", ""]]}, {"id": "1910.09890", "submitter": "Albert Gu", "authors": "Albert Gu, Caglar Gulcehre, Tom Le Paine, Matt Hoffman, Razvan Pascanu", "title": "Improving the Gating Mechanism of Recurrent Neural Networks", "comments": "International Conference on Machine Learning 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gating mechanisms are widely used in neural network models, where they allow\ngradients to backpropagate more easily through depth or time. However, their\nsaturation property introduces problems of its own. For example, in recurrent\nmodels these gates need to have outputs near 1 to propagate information over\nlong time-delays, which requires them to operate in their saturation regime and\nhinders gradient-based learning of the gate mechanism. We address this problem\nby deriving two synergistic modifications to the standard gating mechanism that\nare easy to implement, introduce no additional hyperparameters, and improve\nlearnability of the gates when they are close to saturation. We show how these\nchanges are related to and improve on alternative recently proposed gating\nmechanisms such as chrono initialization and Ordered Neurons. Empirically, our\nsimple gating mechanisms robustly improve the performance of recurrent models\non a range of applications, including synthetic memorization tasks, sequential\nimage classification, language modeling, and reinforcement learning,\nparticularly when long-term dependencies are involved.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 11:03:00 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 20:20:55 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Gu", "Albert", ""], ["Gulcehre", "Caglar", ""], ["Paine", "Tom Le", ""], ["Hoffman", "Matt", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1910.09993", "submitter": "Flavio Martinelli", "authors": "Flavio Martinelli, Giorgia Dellaferrera, Pablo Mainar, Milos Cernak", "title": "Spiking neural networks trained with backpropagation for low power\n  neuromorphic implementation of voice activity detection", "comments": "5 pages, 2 figures, 2 tables", "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), Barcelona, Spain, 2020, pp. 8544-8548", "doi": "10.1109/ICASSP40776.2020.9053412", "report-no": null, "categories": "eess.AS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Voice Activity Detection (VAD) are driven by artificial\nand Recurrent Neural Networks (RNNs), however, using a VAD system in\nbattery-operated devices requires further power efficiency. This can be\nachieved by neuromorphic hardware, which enables Spiking Neural Networks (SNNs)\nto perform inference at very low energy consumption. Spiking networks are\ncharacterized by their ability to process information efficiently, in a sparse\ncascade of binary events in time called spikes. However, a big performance gap\nseparates artificial from spiking networks, mostly due to a lack of powerful\nSNN training algorithms. To overcome this problem we exploit an SNN model that\ncan be recast into an RNN-like model and trained with known deep learning\ntechniques. We describe an SNN training procedure that achieves low spiking\nactivity and pruning algorithms to remove 85% of the network connections with\nno performance loss. The model achieves state-of-the-art performance with a\nfraction of power consumption comparing to other methods.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 14:10:56 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 16:46:12 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Martinelli", "Flavio", ""], ["Dellaferrera", "Giorgia", ""], ["Mainar", "Pablo", ""], ["Cernak", "Milos", ""]]}, {"id": "1910.10021", "submitter": "Thibaut Vidal", "authors": "Jordana Mecler, Anand Subramanian, Thibaut Vidal", "title": "A simple and effective hybrid genetic search for the job sequencing and\n  tool switching problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The job sequencing and tool switching problem (SSP) has been extensively\nstudied in the field of operations research, due to its practical relevance and\nmethodological interest. Given a machine that can load a limited amount of\ntools simultaneously and a number of jobs that require a subset of the\navailable tools, the SSP seeks a job sequence that minimizes the number of tool\nswitches in the machine. To solve this problem, we propose a simple and\nefficient hybrid genetic search based on a generic solution representation, a\ntailored decoding operator, efficient local searches and diversity management\ntechniques. To guide the search, we introduce a secondary objective designed to\nbreak ties. These techniques allow to explore structurally different solutions\nand escape local optima. As shown in our computational experiments on classical\nbenchmark instances, our algorithm significantly outperforms all previous\napproaches while remaining simple to apprehend and easy to implement. We\nfinally report results on a new set of larger instances to stimulate future\nresearch and comparative analyses.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 21:41:06 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Mecler", "Jordana", ""], ["Subramanian", "Anand", ""], ["Vidal", "Thibaut", ""]]}, {"id": "1910.10045", "submitter": "Javier Del Ser Dr.", "authors": "Alejandro Barredo Arrieta, Natalia D\\'iaz-Rodr\\'iguez, Javier Del Ser,\n  Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garc\\'ia, Sergio\n  Gil-L\\'opez, Daniel Molina, Richard Benjamins, Raja Chatila, Francisco\n  Herrera", "title": "Explainable Artificial Intelligence (XAI): Concepts, Taxonomies,\n  Opportunities and Challenges toward Responsible AI", "comments": "67 pages, 13 figures, accepted for its publication in Information\n  Fusion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, Artificial Intelligence (AI) has achieved a notable\nmomentum that may deliver the best of expectations over many application\nsectors across the field. For this to occur, the entire community stands in\nfront of the barrier of explainability, an inherent problem of AI techniques\nbrought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not\npresent in the last hype of AI. Paradigms underlying this problem fall within\nthe so-called eXplainable AI (XAI) field, which is acknowledged as a crucial\nfeature for the practical deployment of AI models. This overview examines the\nexisting literature in the field of XAI, including a prospect toward what is\nyet to be reached. We summarize previous efforts to define explainability in\nMachine Learning, establishing a novel definition that covers prior conceptual\npropositions with a major focus on the audience for which explainability is\nsought. We then propose and discuss about a taxonomy of recent contributions\nrelated to the explainability of different Machine Learning models, including\nthose aimed at Deep Learning methods for which a second taxonomy is built. This\nliterature analysis serves as the background for a series of challenges faced\nby XAI, such as the crossroads between data fusion and explainability. Our\nprospects lead toward the concept of Responsible Artificial Intelligence,\nnamely, a methodology for the large-scale implementation of AI methods in real\norganizations with fairness, model explainability and accountability at its\ncore. Our ultimate goal is to provide newcomers to XAI with a reference\nmaterial in order to stimulate future research advances, but also to encourage\nexperts and professionals from other disciplines to embrace the benefits of AI\nin their activity sectors, without any prior bias for its lack of\ninterpretability.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 15:27:30 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 08:09:25 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Arrieta", "Alejandro Barredo", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Del Ser", "Javier", ""], ["Bennetot", "Adrien", ""], ["Tabik", "Siham", ""], ["Barbado", "Alberto", ""], ["Garc\u00eda", "Salvador", ""], ["Gil-L\u00f3pez", "Sergio", ""], ["Molina", "Daniel", ""], ["Benjamins", "Richard", ""], ["Chatila", "Raja", ""], ["Herrera", "Francisco", ""]]}, {"id": "1910.10231", "submitter": "Sahar Voghoei", "authors": "Sahar Voghoei, Navid Hashemi Tonekaboni, Jason G. Wallace, Hamid R.\n  Arabnia", "title": "Deep Learning at the Edge", "comments": "7 Pages, 79 References, CSCI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing number of Internet of Things (IoT) devices has created a\nnew computing paradigm, called edge computing, where most of the computations\nare performed at the edge devices, rather than on centralized servers. An edge\ndevice is an electronic device that provides connections to service providers\nand other edge devices; typically, such devices have limited resources. Since\nedge devices are resource-constrained, the task of launching algorithms,\nmethods, and applications onto edge devices is considered to be a significant\nchallenge. In this paper, we discuss one of the most widely used machine\nlearning methods, namely, Deep Learning (DL) and offer a short survey on the\nrecent approaches used to map DL onto the edge computing paradigm. We also\nprovide relevant discussions about selected applications that would greatly\nbenefit from DL at the edge.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 21:08:09 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Voghoei", "Sahar", ""], ["Tonekaboni", "Navid Hashemi", ""], ["Wallace", "Jason G.", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1910.10264", "submitter": "Andrew Lensen", "authors": "Andrew Lensen, Bing Xue, Mengjie Zhang", "title": "Genetic Programming for Evolving Similarity Functions for Clustering:\n  Representations and Analysis", "comments": "29 pages, accepted by Evolutionary Computation (Journal), MIT Press", "journal-ref": null, "doi": "10.1162/evco_a_00264", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a difficult and widely-studied data mining task, with many\nvarieties of clustering algorithms proposed in the literature. Nearly all\nalgorithms use a similarity measure such as a distance metric (e.g. Euclidean\ndistance) to decide which instances to assign to the same cluster. These\nsimilarity measures are generally pre-defined and cannot be easily tailored to\nthe properties of a particular dataset, which leads to limitations in the\nquality and the interpretability of the clusters produced. In this paper, we\npropose a new approach to automatically evolving similarity functions for a\ngiven clustering algorithm by using genetic programming. We introduce a new\ngenetic programming-based method which automatically selects a small subset of\nfeatures (feature selection) and then combines them using a variety of\nfunctions (feature construction) to produce dynamic and flexible similarity\nfunctions that are specifically designed for a given dataset. We demonstrate\nhow the evolved similarity functions can be used to perform clustering using a\ngraph-based representation. The results of a variety of experiments across a\nrange of large, high-dimensional datasets show that the proposed approach can\nachieve higher and more consistent performance than the benchmark methods. We\nfurther extend the proposed approach to automatically produce multiple\ncomplementary similarity functions by using a multi-tree approach, which gives\nfurther performance improvements. We also analyse the interpretability and\nstructure of the automatically evolved similarity functions to provide insight\ninto how and why they are superior to standard distance metrics.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 22:45:19 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Lensen", "Andrew", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1910.10461", "submitter": "Wei-Chang Yeh", "authors": "Wei-Chang Yeh", "title": "A Novel Generalized Artificial Neural Network for Mining Two-Class\n  Datasets", "comments": "14pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel general neural network (GNN) is proposed for two-class data mining in\nthis study. In a GNN, each attribute in the dataset is treated as a node, with\neach pair of nodes being connected by an arc. The reliability is of each arc,\nwhich is similar to the weight in artificial neural network and must be solved\nusing simplified swarm optimization (SSO), is constant. After the node\nreliability is made the transformed value of the related attribute, the\napproximate reliability of each GNN instance is calculated based on the\nproposed intelligent Monte Carlo simulation (iMCS). This approximate GNN\nreliability is then compared with a given threshold to predict each instance.\nThe proposed iMCS-SSO is used to repeat the procedure and train the GNN, such\nthat the predicted class values match the actual class values as much as\npossible. To evaluate the classification performance of the proposed GNN,\nexperiments were performed on five well-known benchmark datasets. The\ncomputational results compared favorably with those obtained using support\nvector machines.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 11:18:49 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Yeh", "Wei-Chang", ""]]}, {"id": "1910.10559", "submitter": "Roman Pogodin", "authors": "Roman Pogodin, Dane Corneil, Alexander Seeholzer, Joseph Heng, Wulfram\n  Gerstner", "title": "Working memory facilitates reward-modulated Hebbian learning in\n  recurrent neural networks", "comments": "NeurIPS 2019 workshop \"Real Neurons & Hidden Units: Future directions\n  at the intersection of neuroscience and artificial intelligence\", Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is a powerful tool to explain how the brain learns\ntemporal sequences, such as movements, but existing learning schemes are either\nbiologically implausible or too inefficient to explain animal performance. We\nshow that a network can learn complicated sequences with a reward-modulated\nHebbian learning rule if the network of reservoir neurons is combined with a\nsecond network that serves as a dynamic working memory and provides a\nspatio-temporal backbone signal to the reservoir. In combination with the\nworking memory, reward-modulated Hebbian learning of the readout neurons\nperforms as well as FORCE learning, but with the advantage of a biologically\nplausible interpretation of both the learning rule and the learning paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 13:42:53 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Pogodin", "Roman", ""], ["Corneil", "Dane", ""], ["Seeholzer", "Alexander", ""], ["Heng", "Joseph", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1910.10576", "submitter": "Tien Cuong Phi", "authors": "Tien Cuong Phi, Alexandre Muzy and Patricia Reynaud-Bouret", "title": "Event-scheduling algorithms with Kalikow decomposition for simulating\n  potentially infinite neuronal networks", "comments": null, "journal-ref": "Springer Nature Computer Science, 2020", "doi": "10.1007/s42979-019-0039-3", "report-no": null, "categories": "stat.CO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-scheduling algorithms can compute in continuous time the next\noccurrence of points (as events) of a counting process based on their current\nconditional intensity. In particular event-scheduling algorithms can be adapted\nto perform the simulation of finite neuronal networks activity. These\nalgorithms are based on Ogata's thinning strategy \\cite{Oga81}, which always\nneeds to simulate the whole network to access the behaviour of one particular\nneuron of the network. On the other hand, for discrete time models, theoretical\nalgorithms based on Kalikow decomposition can pick at random influencing\nneurons and perform a perfect simulation (meaning without approximations) of\nthe behaviour of one given neuron embedded in an infinite network, at every\ntime step. These algorithms are currently not computationally tractable in\ncontinuous time. To solve this problem, an event-scheduling algorithm with\nKalikow decomposition is proposed here for the sequential simulation of point\nprocesses neuronal models satisfying this decomposition. This new algorithm is\napplied to infinite neuronal networks whose finite time simulation is a\nprerequisite to realistic brain modeling.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:23:16 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Phi", "Tien Cuong", ""], ["Muzy", "Alexandre", ""], ["Reynaud-Bouret", "Patricia", ""]]}, {"id": "1910.10579", "submitter": "Richard Preen", "authors": "Richard J. Preen and Stewart W. Wilson and Larry Bull", "title": "Autoencoding with a Classifier System", "comments": null, "journal-ref": "IEEE Transactions on Evolutionary Computation (2021)", "doi": "10.1109/TEVC.2021.3079320", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoders are data-specific compression algorithms learned automatically\nfrom examples. The predominant approach has been to construct single large\nglobal models that cover the domain. However, training and evaluating models of\nincreasing size comes at the price of additional time and computational cost.\nConditional computation, sparsity, and model pruning techniques can reduce\nthese costs while maintaining performance. Learning classifier systems (LCS)\nare a framework for adaptively subdividing input spaces into an ensemble of\nsimpler local approximations that together cover the domain. LCS perform\nconditional computation through the use of a population of individual\ngating/guarding components, each associated with a local approximation. This\narticle explores the use of an LCS to adaptively decompose the input domain\ninto a collection of small autoencoders where local solutions of different\ncomplexity may emerge. In addition to benefits in convergence time and\ncomputational cost, it is shown possible to reduce code size as well as the\nresulting decoder computational cost when compared with the global model\nequivalent.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 14:27:29 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 17:51:44 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 10:09:48 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 14:32:16 GMT"}, {"version": "v5", "created": "Tue, 27 Oct 2020 17:55:15 GMT"}, {"version": "v6", "created": "Mon, 2 Nov 2020 09:59:31 GMT"}, {"version": "v7", "created": "Thu, 25 Feb 2021 16:14:08 GMT"}, {"version": "v8", "created": "Wed, 12 May 2021 13:20:17 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Preen", "Richard J.", ""], ["Wilson", "Stewart W.", ""], ["Bull", "Larry", ""]]}, {"id": "1910.10806", "submitter": "Vishwa Karia", "authors": "Vishwa Karia, Wenhao Zhang, Arash Naeim, Ramin Ramezani", "title": "GenSample: A Genetic Algorithm for Oversampling in Imbalanced Datasets", "comments": "7 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imbalanced datasets are ubiquitous. Classification performance on imbalanced\ndatasets is generally poor for the minority class as the classifier cannot\nlearn decision boundaries well. However, in sensitive applications like fraud\ndetection, medical diagnosis, and spam identification, it is extremely\nimportant to classify the minority instances correctly. In this paper, we\npresent a novel technique based on genetic algorithms, GenSample, for\noversampling the minority class in imbalanced datasets. GenSample decides the\nrate of oversampling a minority example by taking into account the difficulty\nin learning that example, along with the performance improvement achieved by\noversampling it. This technique terminates the oversampling process when the\nperformance of the classifier begins to deteriorate. Consequently, it produces\nsynthetic data only as long as a performance boost is obtained. The algorithm\nwas tested on 9 real-world imbalanced datasets of varying sizes and imbalance\nratios. It achieved the highest F-Score on 8 out of 9 datasets, confirming its\nability to better handle imbalanced data compared to other existing\nmethodologies.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 20:48:54 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Karia", "Vishwa", ""], ["Zhang", "Wenhao", ""], ["Naeim", "Arash", ""], ["Ramezani", "Ramin", ""]]}, {"id": "1910.10942", "submitter": "Simon Leglaive", "authors": "Simon Leglaive (IETR), Xavier Alameda-Pineda (PERCEPTION), Laurent\n  Girin (GIPSA-CRISSP, PERCEPTION), Radu Horaud (PERCEPTION)", "title": "A Recurrent Variational Autoencoder for Speech Enhancement", "comments": null, "journal-ref": "ICASSP 2020 - 2020 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), May 2020, Barcelona, Spain", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a generative approach to speech enhancement based on a\nrecurrent variational autoencoder (RVAE). The deep generative speech model is\ntrained using clean speech signals only, and it is combined with a nonnegative\nmatrix factorization noise model for speech enhancement. We propose a\nvariational expectation-maximization algorithm where the encoder of the RVAE is\nfine-tuned at test time, to approximate the distribution of the latent\nvariables given the noisy speech observations. Compared with previous\napproaches based on feed-forward fully-connected architectures, the proposed\nrecurrent deep generative speech model induces a posterior temporal dynamic\nover the latent variables, which is shown to improve the speech enhancement\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 06:54:36 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 09:36:23 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Leglaive", "Simon", "", "IETR"], ["Alameda-Pineda", "Xavier", "", "PERCEPTION"], ["Girin", "Laurent", "", "GIPSA-CRISSP, PERCEPTION"], ["Horaud", "Radu", "", "PERCEPTION"]]}, {"id": "1910.10949", "submitter": "M\\'arton Szemenyei", "authors": "Marton Szemenyei and Vladimir Estivill-Castro", "title": "ROBO: Robust, Fully Neural Object Detection for Robot Soccer", "comments": "Presented at the 2019 RoboCup Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has become exceptionally popular in the last few years due to\nits success in computer vision and other fields of AI. However, deep neural\nnetworks are computationally expensive, which limits their application in low\npower embedded systems, such as mobile robots. In this paper, an efficient\nneural network architecture is proposed for the problem of detecting relevant\nobjects in robot soccer environments. The ROBO model's increase in efficiency\nis achieved by exploiting the peculiarities of the environment. Compared to the\nstate-of-the-art Tiny YOLO model, the proposed network provides approximately\n35 times decrease in run time, while achieving superior average precision,\nalthough at the cost of slightly worse localization accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 07:24:58 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Szemenyei", "Marton", ""], ["Estivill-Castro", "Vladimir", ""]]}, {"id": "1910.11006", "submitter": "Dongxu Li", "authors": "Dongxu Li, Cristian Rodriguez Opazo, Xin Yu, Hongdong Li", "title": "Word-level Deep Sign Language Recognition from Video: A New Large-scale\n  Dataset and Methods Comparison", "comments": "Accepted by WACV2020, First Round, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based sign language recognition aims at helping deaf people to\ncommunicate with others. However, most existing sign language datasets are\nlimited to a small number of words. Due to the limited vocabulary size, models\nlearned from those datasets cannot be applied in practice. In this paper, we\nintroduce a new large-scale Word-Level American Sign Language (WLASL) video\ndataset, containing more than 2000 words performed by over 100 signers. This\ndataset will be made publicly available to the research community. To our\nknowledge, it is by far the largest public ASL dataset to facilitate word-level\nsign recognition research.\n  Based on this new large-scale dataset, we are able to experiment with several\ndeep learning methods for word-level sign recognition and evaluate their\nperformances in large scale scenarios. Specifically we implement and compare\ntwo different models,i.e., (i) holistic visual appearance-based approach, and\n(ii) 2D human pose based approach. Both models are valuable baselines that will\nbenefit the community for method benchmarking. Moreover, we also propose a\nnovel pose-based temporal graph convolution networks (Pose-TGCN) that models\nspatial and temporal dependencies in human pose trajectories simultaneously,\nwhich has further boosted the performance of the pose-based method. Our results\nshow that pose-based and appearance-based models achieve comparable\nperformances up to 66% at top-10 accuracy on 2,000 words/glosses, demonstrating\nthe validity and challenges of our dataset. Our dataset and baseline deep\nmodels are available at \\url{https://dxli94.github.io/WLASL/}.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 10:04:29 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 00:24:44 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Li", "Dongxu", ""], ["Opazo", "Cristian Rodriguez", ""], ["Yu", "Xin", ""], ["Li", "Hongdong", ""]]}, {"id": "1910.11306", "submitter": "Joao Carreira", "authors": "Jean-Baptiste Alayrac, Jo\\~ao Carreira, Relja Arandjelovi\\'c and\n  Andrew Zisserman", "title": "Controllable Attention for Structured Layered Video Decomposition", "comments": "In ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to be able to separate a video into its\nnatural layers, and to control which of the separated layers to attend to. For\nexample, to be able to separate reflections, transparency or object motion. We\nmake the following three contributions: (i) we introduce a new structured\nneural network architecture that explicitly incorporates layers (as spatial\nmasks) into its design. This improves separation performance over previous\ngeneral purpose networks for this task; (ii) we demonstrate that we can augment\nthe architecture to leverage external cues such as audio for controllability\nand to help disambiguation; and (iii) we experimentally demonstrate the\neffectiveness of our approach and training procedure with controlled\nexperiments while also showing that the proposed model can be successfully\napplied to real-word applications such as reflection removal and action\nrecognition in cluttered scenes.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 17:36:40 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Alayrac", "Jean-Baptiste", ""], ["Carreira", "Jo\u00e3o", ""], ["Arandjelovi\u0107", "Relja", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1910.11380", "submitter": "Sahar Hojjatinia", "authors": "Sahar Hojjatinia, Mahdi Aliyari Shoorehdeli, Zahra Fatahi, Zeinab\n  Hojjatinia, Abbas Haghparast", "title": "Improving the Izhikevich Model Based on Rat Basolateral Amygdala and\n  Hippocampus Neurons, and Recognizing Their Possible Firing Patterns", "comments": "29 pages, 3 figures, 2 supplemental figures, 2 tables", "journal-ref": "Basic and Clinical Neuroscience 11.1 (2020): 79", "doi": "10.32598/bcn.9.10.435", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction- Identifying the potential firing patterns following different\nbrain regions under normal and abnormal conditions increases our understanding\nof events at the level of neural interactions in the brain. The Izhikevich\nmodel is one of the simplest biologically plausible models, i.e. capable of\ncapturing the most recognized firing patterns of neurons. This property makes\nthe model efficient in simulating the large-scale networks of neurons.\nImproving the Izhikevich model for adapting to the neuronal activity of the rat\nbrain with great accuracy would make the model effective for future neural\nnetwork implementations. Methods- Data sampling from two brain regions, the HIP\nand BLA, was performed by the extracellular recordings of male rats, and spike\nsorting was conducted by Plexon offline sorter. Further analyses were performed\nthrough NeuroExplorer and MATLAB. To optimize the Izhikevich model parameters,\na genetic algorithm was used. The process of comparison in each iteration leads\nto the survival of better populations until achieving the optimum solution.\nResults- In the present study, the possible firing patterns of the real single\nneurons of the HIP and BLA were identified. Additionally, an improved\nIzhikevich model was achieved. Accordingly, the real neuronal spiking pattern\nof these regions neurons and the corresponding cases of the Izhikevich neuron\nspiking pattern were adjusted with great accuracy. Conclusion- This study was\nconducted to elevate our knowledge of neural interactions in different\nstructures of the brain and accelerate the quality of future large-scale neural\nnetwork simulations, as well as reducing the modeling complexity. This aim was\nachievable by performing the improved Izhikevich model, and inserting only the\nplausible firing patterns, and eliminating unrealistic ones.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 19:04:36 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 00:02:16 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 05:22:10 GMT"}, {"version": "v4", "created": "Sat, 6 Mar 2021 20:36:40 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Hojjatinia", "Sahar", ""], ["Shoorehdeli", "Mahdi Aliyari", ""], ["Fatahi", "Zahra", ""], ["Hojjatinia", "Zeinab", ""], ["Haghparast", "Abbas", ""]]}, {"id": "1910.11858", "submitter": "Colin White", "authors": "Colin White, Willie Neiswanger, Yash Savani", "title": "BANANAS: Bayesian Optimization with Neural Architectures for Neural\n  Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past half-decade, many methods have been considered for neural\narchitecture search (NAS). Bayesian optimization (BO), which has long had\nsuccess in hyperparameter optimization, has recently emerged as a very\npromising strategy for NAS when it is coupled with a neural predictor. Recent\nwork has proposed different instantiations of this framework, for example,\nusing Bayesian neural networks or graph convolutional networks as the\npredictive model within BO. However, the analyses in these papers often focus\non the full-fledged NAS algorithm, so it is difficult to tell which individual\ncomponents of the framework lead to the best performance.\n  In this work, we give a thorough analysis of the \"BO + neural predictor\"\nframework by identifying five main components: the architecture encoding,\nneural predictor, uncertainty calibration method, acquisition function, and\nacquisition optimization strategy. We test several different methods for each\ncomponent and also develop a novel path-based encoding scheme for neural\narchitectures, which we show theoretically and empirically scales better than\nother encodings. Using all of our analyses, we develop a final algorithm called\nBANANAS, which achieves state-of-the-art performance on NAS search spaces. We\nadhere to the NAS research checklist (Lindauer and Hutter 2019) to facilitate\nbest practices, and our code is available at\nhttps://github.com/naszilla/naszilla.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:35:49 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 08:39:44 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 15:28:47 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["White", "Colin", ""], ["Neiswanger", "Willie", ""], ["Savani", "Yash", ""]]}, {"id": "1910.12151", "submitter": "Jeff Orchard", "authors": "Jeff Orchard, Wei Sun", "title": "Making Predictive Coding Networks Generative", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive coding (PC) networks are a biologically interesting class of\nneural networks. Their layered hierarchy mimics the reciprocal connectivity\npattern observed in the mammalian cortex, and they can be trained using local\nlearning rules that approximate backpropagation [Bogacz, 2017]. However,\ndespite having feedback connections that enable information to flow down the\nnetwork hierarchy, discriminative PC networks are not generative. Clamping the\noutput class and running the network to equilibrium yields an input sample that\ntypically does not resemble the training input. This paper studies this\nphenomenon, and proposes a simple solution that promotes the generation of\ninput samples that resemble the training inputs. Simple decay, a technique\nalready in wide use in neural networks, pushes the PC network toward a unique\nminimum 2-norm solution, and that unique solution provably (for linear\nnetworks) matches the training inputs. The method also vastly improves the\nsamples generated for nonlinear networks, as we demonstrate on MNIST.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2019 21:57:52 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Orchard", "Jeff", ""], ["Sun", "Wei", ""]]}, {"id": "1910.12396", "submitter": "Guy Katz", "authors": "Sumathi Gokulanathan, Alexander Feldsher, Adi Malca, Clark Barrett,\n  Guy Katz", "title": "Simplifying Neural Networks using Formal Verification", "comments": "This paper appeared at NFM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) verification is an emerging field, with diverse\nverification engines quickly becoming available. Demonstrating the\neffectiveness of these engines on real-world DNNs is an important step towards\ntheir wider adoption. We present a tool that can leverage existing verification\nengines in performing a novel application: neural network simplification,\nthrough the reduction of the size of a DNN without harming its accuracy. We\nreport on the work-flow of the simplification process, and demonstrate its\npotential significance and applicability on a family of real-world DNNs for\naircraft collision avoidance, whose sizes we were able to reduce by as much as\n10%.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 17:29:53 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 12:00:56 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gokulanathan", "Sumathi", ""], ["Feldsher", "Alexander", ""], ["Malca", "Adi", ""], ["Barrett", "Clark", ""], ["Katz", "Guy", ""]]}, {"id": "1910.12401", "submitter": "Caine Ardayfio Mr.", "authors": "Caine Ardayfio", "title": "Computational design of organic solar cell active layer through genetic\n  algorithm", "comments": "13 pages, 7 figures, International Science and Engineering Fair\n  Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.mtrl-sci", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The active layer microstructure of organic solar cells is critical to\nefficiency. By studying the photovoltaic properties of organic solar cell's\nmicrostructure, it is possible to increase the efficiency of the solar cell. A\ngraph-based microstructure model was employed to approximate the efficiency,\nmeasured as short circuit current, of a solar cell given a microstructure.\nThrough probabilistic graph-based optimization, a class of microstructures were\nfound with an efficiency surpassing that of more conventional morphologies.\nThese optimized solar cells surpass the efficiency of more conventional\nphotovoltaic devices as they better facilitate charge transport, generation,\nand dissociation. A device was designed with a 40.29% increase in short circuit\ncurrent from the solar cells with the currently believed optimal morphology.\nThe designed morphologies feature two dendritic clusters of the donor material\npoly(3-hexylthiophene-2,5-diyl) (P3HT) and the acceptor material\nphenyl-C61-Butyric-Acid-Methyl Ester (PCBM). The designed microstructure's\nincrease in performance contrasts with more conventional structures featuring\ninterdigitated or bilayer strands of P3HT and PCBM. The change of\nmicrostructure morphology through graph-based evolution obtains an organic\nsolar cell with an efficiency significantly greater than conventional organic\nsolar cells, proves the validity of graph-based microstructure models for\nsimulation in materials science, and advances the vision of an inexpensive,\nefficient form of renewable energy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 01:32:20 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Ardayfio", "Caine", ""]]}, {"id": "1910.12412", "submitter": "Phillip Smith Mr", "authors": "Phillip Smith, Robert Hunjet, Aldeida Aleti, Asad Khan", "title": "Swarm Behaviour Evolution via Rule Sharing and Novelty Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper an exertion of our previous work by increasing the\nrobustness and coverage of the evolution search via hybridisation with a\nstate-of-the-art novelty search and accelerate the individual agent behaviour\nsearches via a novel behaviour-component sharing technique. Via these\nimprovements, we present Swarm Learning Classifier System 2.0 (SLCS2), a\nbehaviour evolving algorithm which is robust to complex environments, and seen\nto out-perform a human behaviour designer in challenging cases of the\ndata-transfer task in a range of environmental conditions. Additionally, we\nexamine the impact of tailoring the SLCS2 rule generator for specific\nenvironmental conditions. We find this leads to over-fitting, as might be\nexpected, and thus conclude that for greatest environment flexibility a general\nrule generator should be utilised.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 02:53:44 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Smith", "Phillip", ""], ["Hunjet", "Robert", ""], ["Aleti", "Aldeida", ""], ["Khan", "Asad", ""]]}, {"id": "1910.12478", "submitter": "Greg Yang", "authors": "Greg Yang", "title": "Tensor Programs I: Wide Feedforward or Recurrent Neural Networks of Any\n  Architecture are Gaussian Processes", "comments": "Appearing in NeurIPS 2019; 10 pages of main text; 12 figures, 11\n  programs; 73 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide neural networks with random weights and biases are Gaussian processes,\nas originally observed by Neal (1995) and more recently by Lee et al. (2018)\nand Matthews et al. (2018) for deep fully-connected networks, as well as by\nNovak et al. (2019) and Garriga-Alonso et al. (2019) for deep convolutional\nnetworks. We show that this Neural Network-Gaussian Process correspondence\nsurprisingly extends to all modern feedforward or recurrent neural networks\ncomposed of multilayer perceptron, RNNs (e.g. LSTMs, GRUs), (nD or graph)\nconvolution, pooling, skip connection, attention, batch normalization, and/or\nlayer normalization. More generally, we introduce a language for expressing\nneural network computations, and our result encompasses all such expressible\nneural networks. This work serves as a tutorial on the *tensor programs*\ntechnique formulated in Yang (2019) and elucidates the Gaussian Process results\nobtained there. We provide open-source implementations of the Gaussian Process\nkernels of simple RNN, GRU, transformer, and batchnorm+ReLU network at\ngithub.com/thegregyang/GP4A.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 07:31:59 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 08:48:14 GMT"}, {"version": "v3", "created": "Sat, 8 May 2021 12:45:18 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yang", "Greg", ""]]}, {"id": "1910.12492", "submitter": "Leendert Remmelzwaal", "authors": "Leendert A Remmelzwaal, Amit K Mishra, George F R Ellis", "title": "CTNN: Corticothalamic-inspired neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sensory predictions by the brain in all modalities take place as a result of\nbottom-up and top-down connections both in the neocortex and between the\nneocortex and the thalamus. The bottom-up connections in the cortex are\nresponsible for learning, pattern recognition, and object classification, and\nhave been widely modelled using artificial neural networks (ANNs). Here, we\npresent a neural network architecture modelled on the top-down corticothalamic\nconnections and the behaviour of the thalamus: a corticothalamic neural network\n(CTNN), consisting of an auto-encoder connected to a difference engine with a\nthreshold. We demonstrate that the CTNN is input agnostic, multi-modal, robust\nduring partial occlusion of one or more sensory inputs, and has significantly\nhigher processing efficiency than other predictive coding models, proportional\nto the number of sequentially similar inputs in a sequence. This increased\nefficiency could be highly significant in more complex implementations of this\narchitecture, where the predictive nature of the cortex will allow most of the\nincoming data to be discarded.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 08:15:25 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 10:07:08 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 08:10:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Remmelzwaal", "Leendert A", ""], ["Mishra", "Amit K", ""], ["Ellis", "George F R", ""]]}, {"id": "1910.12620", "submitter": "Sherif Abdulatif", "authors": "Sherif Abdulatif, Karim Armanious, Karim Guirguis, Jayasankar T.\n  Sajeev, Bin Yang", "title": "AeGAN: Time-Frequency Speech Denoising via Generative Adversarial\n  Networks", "comments": "5 pages, 4 figures and 2 Tables. Accepted in EUSIPCO 2020", "journal-ref": null, "doi": "10.23919/Eusipco47968.2020.9287606", "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic speech recognition (ASR) systems are of vital importance nowadays\nin commonplace tasks such as speech-to-text processing and language\ntranslation. This created the need for an ASR system that can operate in\nrealistic crowded environments. Thus, speech enhancement is a valuable building\nblock in ASR systems and other applications such as hearing aids, smartphones\nand teleconferencing systems. In this paper, a generative adversarial network\n(GAN) based framework is investigated for the task of speech enhancement, more\nspecifically speech denoising of audio tracks. A new architecture based on\nCasNet generator and an additional feature-based loss are incorporated to get\nrealistically denoised speech phonetics. Finally, the proposed framework is\nshown to outperform other learning and traditional model-based speech\nenhancement approaches.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 13:27:22 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 19:55:22 GMT"}, {"version": "v3", "created": "Sat, 6 Jun 2020 00:10:35 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Abdulatif", "Sherif", ""], ["Armanious", "Karim", ""], ["Guirguis", "Karim", ""], ["Sajeev", "Jayasankar T.", ""], ["Yang", "Bin", ""]]}, {"id": "1910.12781", "submitter": "Malte Ludewig", "authors": "Malte Ludewig, Noemi Mauro, Sara Latifi, Dietmar Jannach", "title": "Empirical Analysis of Session-Based Recommendation Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/s11257-020-09277-1", "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are tools that support online users by pointing them to\npotential items of interest in situations of information overload. In recent\nyears, the class of session-based recommendation algorithms received more\nattention in the research literature. These algorithms base their\nrecommendations solely on the observed interactions with the user in an ongoing\nsession and do not require the existence of long-term preference profiles. Most\nrecently, a number of deep learning based (\"neural\") approaches to\nsession-based recommendations were proposed. However, previous research\nindicates that today's complex neural recommendation methods are not always\nbetter than comparably simple algorithms in terms of prediction accuracy.\n  With this work, our goal is to shed light on the state-of-the-art in the area\nof session-based recommendation and on the progress that is made with neural\napproaches. For this purpose, we compare twelve algorithmic approaches, among\nthem six recent neural methods, under identical conditions on various datasets.\nWe find that the progress in terms of prediction accuracy that is achieved with\nneural methods is still limited. In most cases, our experiments show that\nsimple heuristic methods based on nearest-neighbors schemes are preferable over\nconceptually and computationally more complex methods. Observations from a user\nstudy furthermore indicate that recommendations based on heuristic methods were\nalso well accepted by the study participants. To support future progress and\nreproducibility in this area, we publicly share the session-rec evaluation\nframework that was used in our research.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 16:08:58 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 15:36:15 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Ludewig", "Malte", ""], ["Mauro", "Noemi", ""], ["Latifi", "Sara", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1910.12824", "submitter": "J\\\"org Franke", "authors": "J\\\"org K.H. Franke, Gregor K\\\"ohler, Noor Awad, Frank Hutter", "title": "Neural Architecture Evolution in Deep Reinforcement Learning for\n  Continuous Control", "comments": "NeurIPS 2019 MetaLearn Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Deep Reinforcement Learning algorithms still heavily rely on\nhandcrafted neural network architectures. We propose a novel approach to\nautomatically find strong topologies for continuous control tasks while only\nadding a minor overhead in terms of interactions in the environment. To achieve\nthis, we combine Neuroevolution techniques with off-policy training and propose\na novel architecture mutation operator. Experiments on five continuous control\nbenchmarks show that the proposed Actor-Critic Neuroevolution algorithm often\noutperforms the strong Actor-Critic baseline and is capable of automatically\nfinding topologies in a sample-efficient manner which would otherwise have to\nbe found by expensive architecture search.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:33:26 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 21:38:04 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 11:54:44 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Franke", "J\u00f6rg K. H.", ""], ["K\u00f6hler", "Gregor", ""], ["Awad", "Noor", ""], ["Hutter", "Frank", ""]]}, {"id": "1910.12827", "submitter": "Michael Chang", "authors": "Rishi Veerapaneni, John D. Co-Reyes, Michael Chang, Michael Janner,\n  Chelsea Finn, Jiajun Wu, Joshua B. Tenenbaum, Sergey Levine", "title": "Entity Abstraction in Visual Model-Based Reinforcement Learning", "comments": "Accepted at CoRL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tests the hypothesis that modeling a scene in terms of entities\nand their local interactions, as opposed to modeling the scene globally,\nprovides a significant benefit in generalizing to physical tasks in a\ncombinatorial space the learner has not encountered before. We present\nobject-centric perception, prediction, and planning (OP3), which to the best of\nour knowledge is the first fully probabilistic entity-centric dynamic latent\nvariable framework for model-based reinforcement learning that acquires entity\nrepresentations from raw visual observations without supervision and uses them\nto predict and plan. OP3 enforces entity-abstraction -- symmetric processing of\neach entity representation with the same locally-scoped function -- which\nenables it to scale to model different numbers and configurations of objects\nfrom those in training. Our approach to solving the key technical challenge of\ngrounding these entity representations to actual objects in the environment is\nto frame this variable binding problem as an inference problem, and we develop\nan interactive inference algorithm that uses temporal continuity and\ninteractive feedback to bind information about object properties to the entity\nvariables. On block-stacking tasks, OP3 generalizes to novel block\nconfigurations and more objects than observed during training, outperforming an\noracle model that assumes access to object supervision and achieving two to\nthree times better accuracy than a state-of-the-art video prediction model that\ndoes not exhibit entity abstraction.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 17:37:46 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 12:57:33 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 23:16:31 GMT"}, {"version": "v4", "created": "Sat, 11 Apr 2020 19:50:41 GMT"}, {"version": "v5", "created": "Wed, 6 May 2020 14:51:15 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Veerapaneni", "Rishi", ""], ["Co-Reyes", "John D.", ""], ["Chang", "Michael", ""], ["Janner", "Michael", ""], ["Finn", "Chelsea", ""], ["Wu", "Jiajun", ""], ["Tenenbaum", "Joshua B.", ""], ["Levine", "Sergey", ""]]}, {"id": "1910.12919", "submitter": "Debanjan Bhowmik", "authors": "Divya Kaushik, Utkarsh Singh, Upasana Sahu, Indu Sreedevi and Debanjan\n  Bhowmik", "title": "Comparing domain wall synapse with other Non Volatile Memory devices for\n  on-chip learning in Analog Hardware Neural Network", "comments": "The following article has been submitted to AIP Advances. When it is\n  published, it will be found at https://aip.scitation.org/journal/adv", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph cond-mat.mtrl-sci cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resistive Random Access Memory (RRAM) and Phase Change Memory (PCM) devices\nhave been popularly used as synapses in crossbar array based analog Neural\nNetwork (NN) circuit to achieve more energy and time efficient data\nclassification compared to conventional computers. Here we demonstrate the\nadvantages of recently proposed spin orbit torque driven Domain Wall (DW)\ndevice as synapse compared to the RRAM and PCM devices with respect to on-chip\nlearning (training in hardware) in such NN. Synaptic characteristic of DW\nsynapse, obtained by us from micromagnetic modeling, turns out to be much more\nlinear and symmetric (between positive and negative update) than that of RRAM\nand PCM synapse. This makes design of peripheral analog circuits for on-chip\nlearning much easier in DW synapse based NN compared to that for RRAM and PCM\nsynapses. We next incorporate the DW synapse as a Verilog-A model in the\ncrossbar array based NN circuit we design on SPICE circuit simulator.\nSuccessful on-chip learning is demonstrated through SPICE simulations on the\npopular Fisher's Iris dataset. Time and energy required for learning turn out\nto be orders of magnitude lower for DW synapse based NN circuit compared to\nthat for RRAM and PCM synapse based NN circuits.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 19:25:21 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Kaushik", "Divya", ""], ["Singh", "Utkarsh", ""], ["Sahu", "Upasana", ""], ["Sreedevi", "Indu", ""], ["Bhowmik", "Debanjan", ""]]}, {"id": "1910.12948", "submitter": "Gilles Vandewiele", "authors": "Gilles Vandewiele and Femke Ongenae and Filip De Turck", "title": "GENDIS: GENetic DIscovery of Shapelets", "comments": null, "journal-ref": null, "doi": "10.3390/s21041059", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the time series classification domain, shapelets are small time series\nthat are discriminative for a certain class. It has been shown that classifiers\nare able to achieve state-of-the-art results on a plethora of datasets by\ntaking as input distances from the input time series to different\ndiscriminative shapelets. Additionally, these shapelets can easily be\nvisualized and thus possess an interpretable characteristic, making them very\nappealing in critical domains, such as the health care domain, where\nlongitudinal data is ubiquitous. In this study, a new paradigm for shapelet\ndiscovery is proposed, which is based upon evolutionary computation. The\nadvantages of the proposed approach are that (i) it is gradient-free, which\ncould allow to escape from local optima more easily and to find suited\ncandidates more easily and supports non-differentiable objectives, (ii) no\nbrute-force search is required, which drastically reduces the computational\ncomplexity by several orders of magnitude, (iii) the total amount of shapelets\nand length of each of these shapelets are evolved jointly with the shapelets\nthemselves, alleviating the need to specify this beforehand, (iv) entire sets\nare evaluated at once as opposed to single shapelets, which results in smaller\nfinal sets with less similar shapelets that result in similar predictive\nperformances, and (v) discovered shapelets do not need to be a subsequence of\nthe input time series. We present the results of experiments which validate the\nenumerated advantages.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 08:51:35 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 12:23:35 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Vandewiele", "Gilles", ""], ["Ongenae", "Femke", ""], ["De Turck", "Filip", ""]]}, {"id": "1910.12952", "submitter": "Rajabi Masoumi Mina", "authors": "Mina Rajabi, Hajar Sadeghizadeh, Zahra Mola-Amini, Niloofar Ahmadyrad", "title": "Hybrid Adaptive Neuro-Fuzzy Inference System for Diagnosing the Liver\n  Disorders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, a hybrid method based on an Adaptive Neuro-Fuzzy Inference\nSystem (ANFIS) and Particle Swarm Optimization (PSO) for diagnosing Liver\ndisorders (ANFIS-PSO) is introduced. This smart diagnosis method deals with a\ncombination of making an inference system and optimization process which tries\nto tune the hyper-parameters of ANFIS based on the data-set. The Liver diseases\ncharacteristics are taken from the UCI Repository of Machine Learning\nDatabases. The number of these characteristic attributes are 7, and the sample\nnumber is 354. The right diagnosis performance of the ANFIS-PSO intelligent\nmedical system for liver disease is evaluated by using classification accuracy,\nsensitivity and specificity analysis, respectively. According to the\nexperimental results, the performance of ANFIS-PSO can be more considerable\nthan traditional FIS and ANFIS without optimization phase.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 05:53:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Rajabi", "Mina", ""], ["Sadeghizadeh", "Hajar", ""], ["Mola-Amini", "Zahra", ""], ["Ahmadyrad", "Niloofar", ""]]}, {"id": "1910.13038", "submitter": "David Ha", "authors": "C. Daniel Freeman, Luke Metz, David Ha", "title": "Learning to Predict Without Looking Ahead: World Models Without Forward\n  Prediction", "comments": "To appear at the Thirty-third Conference on Neural Information\n  Processing Systems (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Much of model-based reinforcement learning involves learning a model of an\nagent's world, and training an agent to leverage this model to perform a task\nmore efficiently. While these models are demonstrably useful for agents, every\nnaturally occurring model of the world of which we are aware---e.g., a\nbrain---arose as the byproduct of competing evolutionary pressures for\nsurvival, not minimization of a supervised forward-predictive loss via gradient\ndescent. That useful models can arise out of the messy and slow optimization\nprocess of evolution suggests that forward-predictive modeling can arise as a\nside-effect of optimization under the right circumstances. Crucially, this\noptimization process need not explicitly be a forward-predictive loss. In this\nwork, we introduce a modification to traditional reinforcement learning which\nwe call observational dropout, whereby we limit the agents ability to observe\nthe real environment at each timestep. In doing so, we can coerce an agent into\nlearning a world model to fill in the observation gaps during reinforcement\nlearning. We show that the emerged world model, while not explicitly trained to\npredict the future, can help the agent learn key skills required to perform\nwell in its environment. Videos of our results available at\nhttps://learningtopredict.github.io/\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 02:17:27 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 00:30:18 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Freeman", "C. Daniel", ""], ["Metz", "Luke", ""], ["Ha", "David", ""]]}, {"id": "1910.13063", "submitter": "Anuj Dubey", "authors": "Anuj Dubey, Rosario Cammarota and Aydin Aysu", "title": "MaskedNet: The First Hardware Inference Engine Aiming Power Side-Channel\n  Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Power Analysis (DPA) has been an active area of research for the\npast two decades to study the attacks for extracting secret information from\ncryptographic implementations through power measurements and their defenses.\nUnfortunately, the research on power side-channels have so far predominantly\nfocused on analyzing implementations of ciphers such as AES, DES, RSA, and\nrecently post-quantum cryptography primitives (e.g., lattices). Meanwhile,\nmachine-learning, and in particular deep-learning applications are becoming\nubiquitous with several scenarios where the Machine Learning Models are\nIntellectual Properties requiring confidentiality. Expanding side-channel\nanalysis to Machine Learning Model extraction, however, is largely unexplored.\n  This paper expands the DPA framework to neural-network classifiers. First, it\nshows DPA attacks during inference to extract the secret model parameters such\nas weights and biases of a neural network. Second, it proposes the\n$\\textit{first countermeasures}$ against these attacks by augmenting\n$\\textit{masking}$. The resulting design uses novel masked components such as\nmasked adder trees for fully-connected layers and masked Rectifier Linear Units\nfor activation functions. On a SAKURA-X FPGA board, experiments show that the\nfirst-order DPA attacks on the unprotected implementation can succeed with only\n200 traces and our protection respectively increases the latency and area-cost\nby 2.8x and 2.3x.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 03:19:16 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 18:42:02 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 19:05:59 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Dubey", "Anuj", ""], ["Cammarota", "Rosario", ""], ["Aysu", "Aydin", ""]]}, {"id": "1910.13321", "submitter": "Tobias Hinz", "authors": "Tobias Hinz, Stefan Heinrich, Stefan Wermter", "title": "Semantic Object Accuracy for Generative Text-to-Image Synthesis", "comments": "Added a user study to verify results. Code available at\n  https://github.com/tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis", "journal-ref": "TPAMI (Early Access), 2020", "doi": "10.1109/TPAMI.2020.3021209", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks conditioned on textual image descriptions are\ncapable of generating realistic-looking images. However, current methods still\nstruggle to generate images based on complex image captions from a\nheterogeneous domain. Furthermore, quantitatively evaluating these\ntext-to-image models is challenging, as most evaluation metrics only judge\nimage quality but not the conformity between the image and its caption. To\naddress these challenges we introduce a new model that explicitly models\nindividual objects within an image and a new evaluation metric called Semantic\nObject Accuracy (SOA) that specifically evaluates images given an image\ncaption. The SOA uses a pre-trained object detector to evaluate if a generated\nimage contains objects that are mentioned in the image caption, e.g. whether an\nimage generated from \"a car driving down the street\" contains a car. We perform\na user study comparing several text-to-image models and show that our SOA\nmetric ranks the models the same way as humans, whereas other metrics such as\nthe Inception Score do not. Our evaluation also shows that models which\nexplicitly model objects outperform models which only model global image\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 15:35:52 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 12:25:16 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Hinz", "Tobias", ""], ["Heinrich", "Stefan", ""], ["Wermter", "Stefan", ""]]}, {"id": "1910.13332", "submitter": "Matthias Freiberger", "authors": "Matthias Freiberger, Peter Bienstman and Joni Dambre", "title": "Towards Deep Physical Reservoir Computing Through Automatic Task\n  Decomposition And Mapping", "comments": "Submitted to the IEEE International Conference on Rebooting Computing\n  2019; accepted as a poster, will not be presented though", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photonic reservoir computing is a promising candidate for low-energy\ncomputing at high bandwidths. Despite recent successes, there are bounds to\nwhat one can achieve simply by making photonic reservoirs larger. Therefore, a\nswitch from single-reservoir computing to multi-reservoir and even deep\nphysical reservoir computing is desirable. Given that backpropagation can not\nbe used directly to train multi-reservoir systems in our targeted setting, we\npropose an alternative approach that still uses its power to derive\nintermediate targets. In this work we report our findings on a conducted\nexperiment to evaluate the general feasibility of our approach by training a\nnetwork of 3 Echo State Networks to perform the well-known NARMA-10 task using\ntargets derived through backpropagation. Our results indicate that our proposed\nmethod is well-suited to train multi-reservoir systems in a efficient way.\n", "versions": [{"version": "v1", "created": "Fri, 25 Oct 2019 09:46:54 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Freiberger", "Matthias", ""], ["Bienstman", "Peter", ""], ["Dambre", "Joni", ""]]}, {"id": "1910.13351", "submitter": "Donald Wunsch", "authors": "Donald C. Wunsch", "title": "Admiring the Great Mountain: A Celebration Special Issue in Honor of\n  Stephen Grossbergs 80th Birthday", "comments": "Editorial for Special Issue of Neural Networks in honor of\n  Grossberg's 80th birthday", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This editorial summarizes selected key contributions of Prof. Stephen\nGrossberg and describes the papers in this 80th birthday special issue in his\nhonor. His productivity, creativity, and vision would each be enough to mark a\nscientist of the first caliber. In combination, they have resulted in\ncontributions that have changed the entire discipline of neural networks.\nGrossberg has been tremendously influential in engineering, dynamical systems,\nand artificial intelligence as well. Indeed, he has been one of the most\nimportant mentors and role models in my career, and has done so with\nextraordinary generosity and encouragement. All authors in this special issue\nhave taken great pleasure in hereby commemorating his extraordinary career and\ncontributions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 09:17:01 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Wunsch", "Donald C.", ""]]}, {"id": "1910.13931", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, Aparna Aketi, and Kaushik Roy", "title": "Towards Scalable, Efficient and Accurate Deep Spiking Neural Networks\n  with Backward Residual Connections, Stochastic Softmax and Hybridization", "comments": "14 pages, 7 figures, 17 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) may offer an energy-efficient alternative for\nimplementing deep learning applications. In recent years, there have been\nseveral proposals focused on supervised (conversion, spike-based gradient\ndescent) and unsupervised (spike timing dependent plasticity) training methods\nto improve the accuracy of SNNs on large-scale tasks. However, each of these\nmethods suffer from scalability, latency and accuracy limitations. In this\npaper, we propose novel algorithmic techniques of modifying the SNN\nconfiguration with backward residual connections, stochastic softmax and hybrid\nartificial-and-spiking neuronal activations to improve the learning ability of\nthe training methodologies to yield competitive accuracy, while, yielding large\nefficiency gains over their artificial counterparts. Note, artificial\ncounterparts refer to conventional deep learning/artificial neural networks.\nOur techniques apply to VGG/Residual architectures, and are compatible with all\nforms of training methodologies. Our analysis reveals that the proposed\nsolutions yield near state-of-the-art accuracy with significant\nenergy-efficiency and reduced parameter overhead translating to hardware\nimprovements on complex visual recognition tasks, such as, CIFAR10, Imagenet\ndatatsets.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2019 15:31:15 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Aketi", "Aparna", ""], ["Roy", "Kaushik", ""]]}, {"id": "1910.14021", "submitter": "Majid Masoumi", "authors": "Majid Masoumi, Mina Rajabi", "title": "Adaptive Neuro Particle Swarm Optimization applied for diagnosing\n  disorders", "comments": "arXiv admin note: substantial text overlap with arXiv:1910.12952", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new Adaptive Neuro Particle Swarm Optimization (ANPSO) combined with a\nfuzzy inference system for diagnosing disorders is presented in this paper. The\nmain contributions of the novel proposed method can be a global search across\nthe whole search space with faster convergence rate. Moreover, it shows a\nbetter exploration and exploitation by applying the adaptive control\nparameters, automatic control of inertia weight and coefficient of personal and\nsocial behaviours. Utilizing such attributes lead to a fast and smart diagnosis\nmechanism which is able to diagnosis the diseases by the high accuracy. The\nANPSO is associated with tuning the characteristics of the inference system to\nachieve the minimum diagnosis error as far as the optimized model is obtained.\nAs a case study, we use liver disorders dataset called Bupa. According to the\npreliminary ramifications, the suggested adaptive PSO performance can overcome\nthe traditional inference system and combined with other optimization methods\nsubstantially.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 00:40:15 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Masoumi", "Majid", ""], ["Rajabi", "Mina", ""]]}, {"id": "1910.14215", "submitter": "Rebecca Russell", "authors": "Rebecca L. Russell and Christopher Reale", "title": "Multivariate Uncertainty in Deep Learning", "comments": "To be published in IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has the potential to dramatically impact navigation and\ntracking state estimation problems critical to autonomous vehicles and\nrobotics. Measurement uncertainties in state estimation systems based on Kalman\nand other Bayes filters are typically assumed to be a fixed covariance matrix.\nThis assumption is risky, particularly for \"black box\" deep learning models, in\nwhich uncertainty can vary dramatically and unexpectedly. Accurate\nquantification of multivariate uncertainty will allow for the full potential of\ndeep learning to be used more safely and reliably in these applications. We\nshow how to model multivariate uncertainty for regression problems with neural\nnetworks, incorporating both aleatoric and epistemic sources of heteroscedastic\nuncertainty. We train a deep uncertainty covariance matrix model in two ways:\ndirectly using a multivariate Gaussian density loss function, and indirectly\nusing end-to-end training through a Kalman filter. We experimentally show in a\nvisual tracking problem the large impact that accurate multivariate uncertainty\nquantification can have on Kalman filter performance for both in-domain and\nout-of-domain evaluation data. We additionally show in a challenging visual\nodometry problem how end-to-end filter training can allow uncertainty\npredictions to compensate for filter weaknesses.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:25:16 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 22:54:51 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Russell", "Rebecca L.", ""], ["Reale", "Christopher", ""]]}, {"id": "1910.14220", "submitter": "Xiaobiao Huang", "authors": "Faya Wang, Minghao Song, Auralee Edelen, Xiaobiao Huang", "title": "Machine learning for design optimization of storage ring nonlinear\n  dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.acc-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach to expedite design optimization of nonlinear beam dynamics\nin storage rings is proposed and demonstrated in this study. At each iteration,\na neural network surrogate model is used to suggest new trial solutions in a\nmulti-objective optimization task. The surrogate model is then updated with the\nnew solutions, and this process is repeated until the final optimized solution\nis obtained. We apply this approach to optimize the nonlinear beam dynamics of\nthe SPEAR3 storage ring, where sextupole knobs are adjusted to simultaneously\nimprove the dynamic aperture and the momentum aperture. The approach is shown\nto converge to the Pareto front considerably faster than the genetic and\nparticle swarm algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 02:36:50 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Wang", "Faya", ""], ["Song", "Minghao", ""], ["Edelen", "Auralee", ""], ["Huang", "Xiaobiao", ""]]}, {"id": "1910.14389", "submitter": "Weijie Zheng", "authors": "Benjamin Doerr, Weijie Zheng", "title": "Sharp Bounds for Genetic Drift in EDAs", "comments": null, "journal-ref": null, "doi": "10.1109/TEVC.2020.2987361", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of Distribution Algorithms (EDAs) are one branch of Evolutionary\nAlgorithms (EAs) in the broad sense that they evolve a probabilistic model\ninstead of a population. Many existing algorithms fall into this category.\nAnalogous to genetic drift in EAs, EDAs also encounter the phenomenon that\nupdates of the probabilistic model not justified by the fitness move the\nsampling frequencies to the boundary values. This can result in a considerable\nperformance loss.\n  This paper proves the first sharp estimates of the boundary hitting time of\nthe sampling frequency of a neutral bit for several univariate EDAs. For the\nUMDA that selects $\\mu$ best individuals from $\\lambda$ offspring each\ngeneration, we prove that the expected first iteration when the frequency of\nthe neutral bit leaves the middle range $[\\tfrac 14, \\tfrac 34]$ and the\nexpected first time it is absorbed in 0 or 1 are both $\\Theta(\\mu)$. The\ncorresponding hitting times are $\\Theta(K^2)$ for the cGA with hypothetical\npopulation size $K$. This paper further proves that for PBIL with parameters\n$\\mu$, $\\lambda$, and $\\rho$, in an expected number of $\\Theta(\\mu/\\rho^2)$\niterations the sampling frequency of a neutral bit leaves the interval\n$[\\Theta(\\rho/\\mu),1-\\Theta(\\rho/\\mu)]$ and then always the same value is\nsampled for this bit, that is, the frequency approaches the corresponding\nboundary value with maximum speed.\n  For the lower bounds implicit in these statements, we also show exponential\ntail bounds. If a bit is not neutral, but neutral or has a preference for ones,\nthen the lower bounds on the times to reach a low frequency value still hold.\nAn analogous statement holds for bits that are neutral or prefer the value\nzero.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 11:38:33 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Doerr", "Benjamin", ""], ["Zheng", "Weijie", ""]]}, {"id": "1910.14594", "submitter": "Vladimir Golkov", "authors": "Luca Della Libera, Vladimir Golkov, Yue Zhu, Arman Mielke, Daniel\n  Cremers", "title": "Deep Learning for 2D and 3D Rotatable Data: An Overview of Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the reasons for the success of convolutional networks is their\nequivariance/invariance under translations. However, rotatable data such as\nmolecules, living cells, everyday objects, or galaxies require processing with\nequivariance/invariance under rotations in cases where the rotation of the\ncoordinate system does not affect the meaning of the data (e.g. object\nclassification). On the other hand, estimation/processing of rotations is\nnecessary in cases where rotations are important (e.g. motion estimation).\nThere has been recent progress in methods and theory in all these regards. Here\nwe provide an overview of existing methods, both for 2D and 3D rotations (and\ntranslations), and identify commonalities and links between them, in the hope\nthat our insights will be useful for choosing and perfecting the methods.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 16:47:46 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Della Libera", "Luca", ""], ["Golkov", "Vladimir", ""], ["Zhu", "Yue", ""], ["Mielke", "Arman", ""], ["Cremers", "Daniel", ""]]}, {"id": "1910.14627", "submitter": "Zhaojun Wang", "authors": "Zhun Fan, Zhaojun Wang, Xiaomin Zhu, Bingliang Hu, Anmin Zou, and\n  Dongwei Bao", "title": "An Automatic Design Framework of Swarm Pattern Formation based on\n  Multi-objective Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing swarm pattern formation methods depend on a predefined gene\nregulatory network (GRN) structure that requires designers' priori knowledge,\nwhich is difficult to adapt to complex and changeable environments. To\ndynamically adapt to the complex and changeable environments, we propose an\nautomatic design framework of swarm pattern formation based on multi-objective\ngenetic programming. The proposed framework does not need to define the\nstructure of the GRN-based model in advance, and it applies some basic network\nmotifs to automatically structure the GRN-based model. In addition, a\nmulti-objective genetic programming (MOGP) combines with NSGA-II, namely\nMOGP-NSGA-II, to balance the complexity and accuracy of the GRN-based model. In\nevolutionary process, an MOGP-NSGA-II and differential evolution (DE) are\napplied to optimize the structures and parameters of the GRN-based model in\nparallel. Simulation results demonstrate that the proposed framework can\neffectively evolve some novel GRN-based models, and these GRN-based models not\nonly have a simpler structure and a better performance, but also are robust to\nthe complex and changeable environments.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 17:12:36 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 17:08:45 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Fan", "Zhun", ""], ["Wang", "Zhaojun", ""], ["Zhu", "Xiaomin", ""], ["Hu", "Bingliang", ""], ["Zou", "Anmin", ""], ["Bao", "Dongwei", ""]]}]