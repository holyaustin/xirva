[{"id": "1006.0448", "submitter": "Karol Gregor", "authors": "Karo Gregor, Yann LeCun", "title": "Emergence of Complex-Like Cells in a Temporal Product Network with Local\n  Receptive Fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new neural architecture and an unsupervised algorithm for\nlearning invariant representations from temporal sequence of images. The system\nuses two groups of complex cells whose outputs are combined multiplicatively:\none that represents the content of the image, constrained to be constant over\nseveral consecutive frames, and one that represents the precise location of\nfeatures, which is allowed to vary over time but constrained to be sparse. The\narchitecture uses an encoder to extract features, and a decoder to reconstruct\nthe input from the features. The method was applied to patches extracted from\nconsecutive movie frames and produces orientation and frequency selective units\nanalogous to the complex cells in V1. An extension of the method is proposed to\ntrain a network composed of units with local receptive field spread over a\nlarge image of arbitrary size. A layer of complex cells, subject to sparsity\nconstraints, pool feature units over overlapping local neighborhoods, which\ncauses the feature units to organize themselves into pinwheel patterns of\norientation-selective receptive fields, similar to those observed in the\nmammalian visual cortex. A feed-forward encoder efficiently computes the\nfeature representation of full images.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2010 17:08:29 GMT"}], "update_date": "2010-06-03", "authors_parsed": [["Gregor", "Karo", ""], ["LeCun", "Yann", ""]]}, {"id": "1006.1434", "submitter": "EPTCS", "authors": "A. Steven Younger (Missouri State University), Emmett Redd (Missouri\n  State University)", "title": "Computing by Means of Physics-Based Optical Neural Networks", "comments": null, "journal-ref": "EPTCS 26, 2010, pp. 159-167", "doi": "10.4204/EPTCS.26.15", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report recent research on computing with biology-based neural network\nmodels by means of physics-based opto-electronic hardware. New technology\nprovides opportunities for very-high-speed computation and uncovers problems\nobstructing the wide-spread use of this new capability. The Computation\nModeling community may be able to offer solutions to these cross-boundary\nresearch problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 01:17:00 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Younger", "A. Steven", "", "Missouri State University"], ["Redd", "Emmett", "", "Missouri\n  State University"]]}, {"id": "1006.1512", "submitter": "Uwe Aickelin", "authors": "Julie Greensmith, Uwe Aickelin", "title": "The Deterministic Dendritic Cell Algorithm", "comments": "12 pages, 1 algorithm, 1 figure, 2 tables, 7th International\n  Conference on Artificial Immune Systems (ICARIS 2008)", "journal-ref": "Proceedings of the 7th International Conference on Artificial\n  Immune Systems (ICARIS 2008), Phuket, Thailand, p 291-303", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dendritic Cell Algorithm is an immune-inspired algorithm orig- inally\nbased on the function of natural dendritic cells. The original instantiation of\nthe algorithm is a highly stochastic algorithm. While the performance of the\nalgorithm is good when applied to large real-time datasets, it is difficult to\nanal- yse due to the number of random-based elements. In this paper a\ndeterministic version of the algorithm is proposed, implemented and tested\nusing a port scan dataset to provide a controllable system. This version\nconsists of a controllable amount of parameters, which are experimented with in\nthis paper. In addition the effects are examined of the use of time windows and\nvariation on the number of cells, both which are shown to influence the\nalgorithm. Finally a novel metric for the assessment of the algorithms output\nis introduced and proves to be a more sensitive metric than the metric used\nwith the original Dendritic Cell Algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 10:07:34 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Greensmith", "Julie", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1006.1518", "submitter": "Uwe Aickelin", "authors": "Julie Greensmith, Jan Feyereisl, Uwe Aickelin", "title": "The DCA:SOMe Comparison A comparative study between two\n  biologically-inspired algorithms", "comments": "38 pages, 29 figures, 10 tables, Evolutionary Intelligence", "journal-ref": "Evolutionary Intelligence, 1 (2), p 85-112, 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dendritic Cell Algorithm (DCA) is an immune-inspired algorithm, developed\nfor the purpose of anomaly detection. The algorithm performs multi-sensor data\nfusion and correlation which results in a 'context aware' detection system.\nPrevious applications of the DCA have included the detection of potentially\nmalicious port scanning activity, where it has produced high rates of true\npositives and low rates of false positives. In this work we aim to compare the\nperformance of the DCA and of a Self-Organizing Map (SOM) when applied to the\ndetection of SYN port scans, through experimental analysis. A SOM is an ideal\ncandidate for comparison as it shares similarities with the DCA in terms of the\ndata fusion method employed. It is shown that the results of the two systems\nare comparable, and both produce false positives for the same processes. This\nshows that the DCA can produce anomaly detection results to the same standard\nas an established technique.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 10:41:56 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Greensmith", "Julie", ""], ["Feyereisl", "Jan", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1006.1526", "submitter": "Uwe Aickelin", "authors": "William Wilson, Philip Birkin, Uwe Aickelin", "title": "The Motif Tracking Algorithm", "comments": "13 pages, 10 figures, International Journal of Automation and\n  Computing", "journal-ref": "International Journal of Automation and Computing, 5 (1), p32-44,\n  2008", "doi": "10.1007/s11633.008.0032.0", "report-no": null, "categories": "cs.AI cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for patterns or motifs in data represents a problem area of key\ninterest to finance and economic researchers. In this paper we introduce the\nMotif Tracking Algorithm, a novel immune inspired pattern identification tool\nthat is able to identify unknown motifs of a non specified length which repeat\nwithin time series data. The power of the algorithm comes from the fact that it\nuses a small number of parameters with minimal assumptions regarding the data\nbeing examined or the underlying motifs. Our interest lies in applying the\nalgorithm to financial time series data to identify unknown patterns that\nexist. The algorithm is tested using three separate data sets. Particular\nsuitability to financial data is shown by applying it to oil price data. In all\ncases the algorithm identifies the presence of a motif population in a fast and\nefficient manner due to the utilisation of an intuitive symbolic\nrepresentation. The resulting population of motifs is shown to have\nconsiderable potential value for other applications such as forecasting and\nalgorithm seeding.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 11:08:25 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Wilson", "William", ""], ["Birkin", "Philip", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1006.1543", "submitter": "Raajay Viswanathan", "authors": "Raajay Viswanathan and P. S. Sastry and K.P. Unnikrishnan", "title": "Efficient Discovery of Large Synchronous Events in Neural Spike Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding patterns from multi-neuronal spike trains\nthat give us insights into the multi-neuronal codes used in the brain and help\nus design better brain computer interfaces. We focus on the synchronous firings\nof groups of neurons as these have been shown to play a major role in coding\nand communication. With large electrode arrays, it is now possible to\nsimultaneously record the spiking activity of hundreds of neurons over large\nperiods of time. Recently, techniques have been developed to efficiently count\nthe frequency of synchronous firing patterns. However, when the number of\nneurons being observed grows they suffer from the combinatorial explosion in\nthe number of possible patterns and do not scale well. In this paper, we\npresent a temporal data mining scheme that overcomes many of these problems. It\ngenerates a set of candidate patterns from frequent patterns of smaller size;\nall possible patterns are not counted. Also we count only a certain well\ndefined subset of occurrences and this makes the process more efficient. We\nhighlight the computational advantage that this approach offers over the\nexisting methods through simulations.\n  We also propose methods for assessing the statistical significance of the\ndiscovered patterns. We detect only those patterns that repeat often enough to\nbe significant and thus be able to automatically fix the threshold for the\ndata-mining application. Finally we discuss the usefulness of these methods for\nbrain computer interfaces.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 13:03:45 GMT"}], "update_date": "2010-06-09", "authors_parsed": [["Viswanathan", "Raajay", ""], ["Sastry", "P. S.", ""], ["Unnikrishnan", "K. P.", ""]]}, {"id": "1006.1563", "submitter": "Uwe Aickelin", "authors": "Jan Feyereisl, Uwe Aickelin", "title": "ToLeRating UR-STD", "comments": "7 pages, 4 figures, 1 table, 2nd International Conference on Emerging\n  Security Information, Systems and Technologies,", "journal-ref": "Proceedings of the 2nd International Conference on Emerging\n  Security Information, Systems and Technologies, Cap Esterel, France, p\n  287-293, 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new emerging paradigm of Uncertain Risk of Suspicion, Threat and Danger,\nobserved across the field of information security, is described. Based on this\nparadigm a novel approach to anomaly detection is presented. Our approach is\nbased on a simple yet powerful analogy from the innate part of the human immune\nsystem, the Toll-Like Receptors. We argue that such receptors incorporated as\npart of an anomaly detector enhance the detector's ability to distinguish\nnormal and anomalous behaviour. In addition we propose that Toll-Like Receptors\nenable the classification of detected anomalies based on the types of attacks\nthat perpetrate the anomalous behaviour. Classification of such type is either\nmissing in existing literature or is not fit for the purpose of reducing the\nburden of an administrator of an intrusion detection system. For our model to\nwork, we propose the creation of a taxonomy of the digital Acytota, based on\nwhich our receptors are created.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 14:12:08 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Feyereisl", "Jan", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1006.1568", "submitter": "Uwe Aickelin", "authors": "Jamie Twycross, Uwe Aickelin", "title": "Towards a Conceptual Framework for Innate Immunity", "comments": "14 pages, 5 figures, 2 tables, 4th International Conference on\n  Artificial Immune Systems (ICARIS 2005)", "journal-ref": "Proceedings of the 4th International Conference on Artificial\n  Immune Systems (ICARIS 2005), Lecture Notes in Computer Science 3627, Banff,\n  Canada, p 112-125", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Innate immunity now occupies a central role in immunology. However,\nartificial immune system models have largely been inspired by adaptive not\ninnate immunity. This paper reviews the biological principles and properties of\ninnate immunity and, adopting a conceptual framework, asks how these can be\nincorporated into artificial models. The aim is to outline a meta-framework for\nmodels of innate immunity.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2010 14:25:23 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Twycross", "Jamie", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1006.1681", "submitter": "EPTCS", "authors": "German Terrazas (University of Nottingham), Dario Landa-Silva\n  (University of Nottingham), Natalio Krasnogor (University of Nottingham)", "title": "Towards the Design of Heuristics by Means of Self-Assembly", "comments": null, "journal-ref": "EPTCS 26, 2010, pp. 135-146", "doi": "10.4204/EPTCS.26.13", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current investigations on hyper-heuristics design have sprung up in two\ndifferent flavours: heuristics that choose heuristics and heuristics that\ngenerate heuristics. In the latter, the goal is to develop a problem-domain\nindependent strategy to automatically generate a good performing heuristic for\nthe problem at hand. This can be done, for example, by automatically selecting\nand combining different low-level heuristics into a problem specific and\neffective strategy. Hyper-heuristics raise the level of generality on automated\nproblem solving by attempting to select and/or generate tailored heuristics for\nthe problem at hand. Some approaches like genetic programming have been\nproposed for this. In this paper, we explore an elegant nature-inspired\nalternative based on self-assembly construction processes, in which structures\nemerge out of local interactions between autonomous components. This idea\narises from previous works in which computational models of self-assembly were\nsubject to evolutionary design in order to perform the automatic construction\nof user-defined structures. Then, the aim of this paper is to present a novel\nmethodology for the automated design of heuristics by means of self-assembly.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2010 02:03:41 GMT"}], "update_date": "2010-06-10", "authors_parsed": [["Terrazas", "German", "", "University of Nottingham"], ["Landa-Silva", "Dario", "", "University of Nottingham"], ["Krasnogor", "Natalio", "", "University of Nottingham"]]}, {"id": "1006.1918", "submitter": "Carlos Sarraute", "authors": "Carlos Sarraute (Core Security Technologies and Instituto Tecnologico\n  Buenos Aires), Javier Burroni (Core Security Technologies)", "title": "Using Neural Networks to improve classical Operating System\n  Fingerprinting techniques", "comments": null, "journal-ref": "Electronic Journal of SADIO, Vol. 8, no. 1, pp. 35-47 (2008)", "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present remote Operating System detection as an inference problem: given a\nset of observations (the target host responses to a set of tests), we want to\ninfer the OS type which most probably generated these observations. Classical\ntechniques used to perform this analysis present several limitations. To\nimprove the analysis, we have developed tools using neural networks and\nStatistics tools. We present two working modules: one which uses DCE-RPC\nendpoints to distinguish Windows versions, and another which uses Nmap\nsignatures to distinguish different version of Windows, Linux, Solaris,\nOpenBSD, FreeBSD and NetBSD systems. We explain the details of the topology and\ninner workings of the neural networks used, and the fine tuning of their\nparameters. Finally we show positive experimental results.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2010 22:22:47 GMT"}], "update_date": "2010-06-11", "authors_parsed": [["Sarraute", "Carlos", "", "Core Security Technologies and Instituto Tecnologico\n  Buenos Aires"], ["Burroni", "Javier", "", "Core Security Technologies"]]}, {"id": "1006.2844", "submitter": "Carlos Sarraute", "authors": "Javier Burroni, Carlos Sarraute (CoreLabs, Core Security Technologies)", "title": "Outrepasser les limites des techniques classiques de Prise d'Empreintes\n  grace aux Reseaux de Neurones", "comments": "16 pages, 3 figures. Symposium sur la S\\'ecurit\\'e des Technologies\n  de l'Information et des Communications (SSTIC), Rennes, France, May 31-June\n  2, 2006", "journal-ref": "Actes du symposium SSTIC (2006)", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present an application of Artificial Intelligence techniques to the field\nof Information Security. The problem of remote Operating System (OS) Detection,\nalso called OS Fingerprinting, is a crucial step of the penetration testing\nprocess, since the attacker (hacker or security professional) needs to know the\nOS of the target host in order to choose the exploits that he will use. OS\nDetection is accomplished by passively sniffing network packets and actively\nsending test packets to the target host, to study specific variations in the\nhost responses revealing information about its operating system.\n  The first fingerprinting implementations were based on the analysis of\ndifferences between TCP/IP stack implementations. The next generation focused\nthe analysis on application layer data such as the DCE RPC endpoint\ninformation. Even though more information was analyzed, some variation of the\n\"best fit\" algorithm was still used to interpret this new information. Our new\napproach involves an analysis of the composition of the information collected\nduring the OS identification process to identify key elements and their\nrelations. To implement this approach, we have developed tools using Neural\nNetworks and techniques from the field of Statistics. These tools have been\nsuccessfully integrated in a commercial software (Core Impact).\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2010 20:52:44 GMT"}], "update_date": "2010-06-16", "authors_parsed": [["Burroni", "Javier", "", "CoreLabs, Core Security Technologies"], ["Sarraute", "Carlos", "", "CoreLabs, Core Security Technologies"]]}, {"id": "1006.2945", "submitter": "Uwe Aickelin", "authors": "Amanda Whitbrook, Uwe Aickelin, Jonathan M. Garibaldi", "title": "Two-Timescale Learning Using Idiotypic Behaviour Mediation For A\n  Navigating Mobile Robot", "comments": "40 pages, 12 tables, Journal of Applied Soft Computing", "journal-ref": "Journal of Applied Soft Computing, 10, p 876-887, 2010", "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A combined Short-Term Learning (STL) and Long-Term Learning (LTL) approach to\nsolving mobile-robot navigation problems is presented and tested in both the\nreal and virtual domains. The LTL phase consists of rapid simulations that use\na Genetic Algorithm to derive diverse sets of behaviours, encoded as variable\nsets of attributes, and the STL phase is an idiotypic Artificial Immune System.\nResults from the LTL phase show that sets of behaviours develop very rapidly,\nand significantly greater diversity is obtained when multiple autonomous\npopulations are used, rather than a single one. The architecture is assessed\nunder various scenarios, including removal of the LTL phase and switching off\nthe idiotypic mechanism in the STL phase. The comparisons provide substantial\nevidence that the best option is the inclusion of both the LTL phase and the\nidiotypic system. In addition, this paper shows that structurally different\nenvironments can be used for the two phases without compromising\ntransferability.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2010 10:17:21 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Whitbrook", "Amanda", ""], ["Aickelin", "Uwe", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "1006.3650", "submitter": "Uwe Aickelin", "authors": "Amanda Whitbrook, Uwe Aickelin, Jonathan M. Garibaldi", "title": "The Use of Probabilistic Systems to Mimic the Behaviour of Idiotypic AIS\n  Robot Controllers", "comments": "8 pages, 6 tables, 2 figures, Journal of Systemics, Cybernetics and\n  Informatics", "journal-ref": "Journal of Systemics, Cybernetics and Informatics, 2009, 7(6),\n  p72-79", "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has shown that robot navigation systems that employ an\narchitecture based upon the idiotypic network theory of the immune system have\nan advantage over control techniques that rely on reinforcement learning only.\nThis is thought to be a result of intelligent behaviour selection on the part\nof the idiotypic robot. In this paper an attempt is made to imitate idiotypic\ndynamics by creating controllers that use reinforcement with a number of\ndifferent probabilistic schemes to select robot behaviour. The aims are to show\nthat the idiotypic system is not merely performing some kind of periodic random\nbehaviour selection, and to try to gain further insight into the processes that\ngovern the idiotypic mechanism. Trials are carried out using simulated Pioneer\nrobots that undertake navigation exercises. Results show that a scheme that\nboosts the probability of selecting highly-ranked alternative behaviours to 50%\nduring stall conditions comes closest to achieving the properties of the\nidiotypic system, but remains unable to match it in terms of all round\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 09:38:51 GMT"}], "update_date": "2013-05-30", "authors_parsed": [["Whitbrook", "Amanda", ""], ["Aickelin", "Uwe", ""], ["Garibaldi", "Jonathan M.", ""]]}, {"id": "1006.3654", "submitter": "Uwe Aickelin", "authors": "Jamie Twycross, Uwe Aickelin, Amanda Whitbrook", "title": "Detecting Anomalous Process Behaviour using Second Generation Artificial\n  Immune Systems", "comments": "26 pages, 4 tables, 2 figures, International Journal of\n  Unconventional Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Immune Systems have been successfully applied to a number of\nproblem domains including fault tolerance and data mining, but have been shown\nto scale poorly when applied to computer intrusion detec- tion despite the fact\nthat the biological immune system is a very effective anomaly detector. This\nmay be because AIS algorithms have previously been based on the adaptive immune\nsystem and biologically-naive mod- els. This paper focuses on describing and\ntesting a more complex and biologically-authentic AIS model, inspired by the\ninteractions between the innate and adaptive immune systems. Its performance on\na realistic process anomaly detection problem is shown to be better than\nstandard AIS methods (negative-selection), policy-based anomaly detection\nmethods (systrace), and an alternative innate AIS approach (the DCA). In\naddition, it is shown that runtime information can be used in combination with\nsystem call information to enhance detection capability.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2010 09:55:04 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Twycross", "Jamie", ""], ["Aickelin", "Uwe", ""], ["Whitbrook", "Amanda", ""]]}, {"id": "1006.4540", "submitter": "William Jackson", "authors": "N. Suguna and K. Thanushkodi", "title": "A Novel Rough Set Reduct Algorithm for Medical Domain Based on Bee\n  Colony Optimization", "comments": "IEEE Publication Format,\n  https://sites.google.com/site/journalofcomputing/", "journal-ref": "Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN\n  2151-9617", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature selection refers to the problem of selecting relevant features which\nproduce the most predictive outcome. In particular, feature selection task is\ninvolved in datasets containing huge number of features. Rough set theory has\nbeen one of the most successful methods used for feature selection. However,\nthis method is still not able to find optimal subsets. This paper proposes a\nnew feature selection method based on Rough set theory hybrid with Bee Colony\nOptimization (BCO) in an attempt to combat this. This proposed work is applied\nin the medical domain to find the minimal reducts and experimentally compared\nwith the Quick Reduct, Entropy Based Reduct, and other hybrid Rough Set methods\nsuch as Genetic Algorithm (GA), Ant Colony Optimization (ACO) and Particle\nSwarm Optimization (PSO).\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 14:53:33 GMT"}], "update_date": "2010-06-24", "authors_parsed": [["Suguna", "N.", ""], ["Thanushkodi", "K.", ""]]}, {"id": "1006.4645", "submitter": "Thomas Bartz-Beielstein", "authors": "Thomas Bartz-Beielstein", "title": "SPOT: An R Package For Automatic and Interactive Tuning of Optimization\n  Algorithms by Sequential Parameter Optimization", "comments": "Related software can be downloaded from\n  http://cran.r-project.org/web/packages/SPOT/index.html", "journal-ref": null, "doi": null, "report-no": "CIOP Technical Report 05/10. Cologne University of Applied Sciences", "categories": "cs.NE cs.AI math.OC stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The sequential parameter optimization (SPOT) package for R is a toolbox for\ntuning and understanding simulation and optimization algorithms. Model-based\ninvestigations are common approaches in simulation and optimization. Sequential\nparameter optimization has been developed, because there is a strong need for\nsound statistical analysis of simulation and optimization algorithms. SPOT\nincludes methods for tuning based on classical regression and analysis of\nvariance techniques; tree-based models such as CART and random forest; Gaussian\nprocess models (Kriging), and combinations of different meta-modeling\napproaches. This article exemplifies how SPOT can be used for automatic and\ninteractive tuning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2010 21:18:36 GMT"}], "update_date": "2010-06-25", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""]]}, {"id": "1006.4754", "submitter": "Krishna Lingashetty", "authors": "Krishna Chaithanya Lingashetty", "title": "Active Sites model for the B-Matrix Approach", "comments": "11 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper continues on the work of the B-Matrix approach in hebbian learning\nproposed by Dr. Kak. It reports the results on methods of improving the memory\nretrieval capacity of the hebbian neural network which implements the B-Matrix\napproach. Previously, the approach to retrieving the memories from the network\nwas to clamp all the individual neurons separately and verify the integrity of\nthese memories. Here we present a network with the capability to identify the\n\"active sites\" in the network during the training phase and use these \"active\nsites\" to generate the memories retrieved from these neurons. Three methods are\nproposed for obtaining the update order of the network from the proximity\nmatrix when multiple neurons are to be clamped. We then present a comparison\nbetween the new methods to the classical case and also among the methods\nthemselves.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jun 2010 11:28:30 GMT"}], "update_date": "2010-06-25", "authors_parsed": [["Lingashetty", "Krishna Chaithanya", ""]]}, {"id": "1006.4949", "submitter": "Uwe Aickelin", "authors": "Julie Greensmith, Amanda Whitbrook, Uwe Aickelin", "title": "Artificial Immune Systems (2010)", "comments": "29 pages, 1 algorithm, 3 figures, Handbook of Metaheuristics, 2nd\n  Edition, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human immune system has numerous properties that make it ripe for\nexploitation in the computational domain, such as robustness and fault\ntolerance, and many different algorithms, collectively termed Artificial Immune\nSystems (AIS), have been inspired by it. Two generations of AIS are currently\nin use, with the first generation relying on simplified immune models and the\nsecond generation utilising interdisciplinary collaboration to develop a deeper\nunderstanding of the immune system and hence produce more complex models. Both\ngenerations of algorithms have been successfully applied to a variety of\nproblems, including anomaly detection, pattern recognition, optimisation and\nrobotics. In this chapter an overview of AIS is presented, its evolution is\ndiscussed, and it is shown that the diversification of the field is linked to\nthe diversity of the immune system itself, leading to a number of algorithms as\nopposed to one archetypal system. Two case studies are also presented to help\nprovide insight into the mechanisms of AIS; these are the idiotypic network\napproach and the Dendritic Cell Algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2010 09:55:30 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Greensmith", "Julie", ""], ["Whitbrook", "Amanda", ""], ["Aickelin", "Uwe", ""]]}, {"id": "1006.5008", "submitter": "Uwe Aickelin", "authors": "Julie Greensmith, Uwe Aickelin, Steve Cayzer", "title": "Detecting Danger: The Dendritic Cell Algorithm", "comments": "27 pages, 8 figures, Robust Intelligent Systems", "journal-ref": "Robust Intelligent Systems, 12, p 89-112, 2008", "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dendritic Cell Algorithm (DCA) is inspired by the function of the\ndendritic cells of the human immune system. In nature, dendritic cells are the\nintrusion detection agents of the human body, policing the tissue and organs\nfor potential invaders in the form of pathogens. In this research, and abstract\nmodel of DC behaviour is developed and subsequently used to form an algorithm,\nthe DCA. The abstraction process was facilitated through close collaboration\nwith laboratory- based immunologists, who performed bespoke experiments, the\nresults of which are used as an integral part of this algorithm. The DCA is a\npopulation based algorithm, with each agent in the system represented as an\n'artificial DC'. Each DC has the ability to combine multiple data streams and\ncan add context to data suspected as anomalous. In this chapter the abstraction\nprocess and details of the resultant algorithm are given. The algorithm is\napplied to numerous intrusion detection problems in computer security including\nthe detection of port scans and botnets, where it has produced impressive\nresults with relatively low rates of false positives.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2010 15:30:45 GMT"}], "update_date": "2010-07-05", "authors_parsed": [["Greensmith", "Julie", ""], ["Aickelin", "Uwe", ""], ["Cayzer", "Steve", ""]]}, {"id": "1006.5745", "submitter": "Poonam Garg", "authors": "Poonam Garg", "title": "Evolutionary Computation Algorithms for Cryptanalysis: A Study", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The cryptanalysis of various cipher problems can be formulated as NP-Hard\ncombinatorial problem. Solving such problems requires time and/or memory\nrequirement which increases with the size of the problem. Techniques for\nsolving combinatorial problems fall into two broad groups - exact algorithms\nand Evolutionary Computation algorithms. An exact algorithms guarantees that\nthe optimal solution to the problem will be found. The exact algorithms like\nbranch and bound, simplex method, brute force etc methodology is very\ninefficient for solving combinatorial problem because of their prohibitive\ncomplexity (time and memory requirement). The Evolutionary Computation\nalgorithms are employed in an attempt to find an adequate solution to the\nproblem. A Evolutionary Computation algorithm - Genetic algorithm, simulated\nannealing and tabu search were developed to provide a robust and efficient\nmethodology for cryptanalysis. The aim of these techniques to find sufficient\n\"good\" solution efficiently with the characteristics of the problem, instead of\nthe global optimum solution, and thus it also provides attractive alternative\nfor the large scale applications. This paper focuses on the methodology of\nEvolutionary Computation algorithms .\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2010 00:07:44 GMT"}], "update_date": "2010-07-01", "authors_parsed": [["Garg", "Poonam", ""]]}]