[{"id": "1812.00045", "submitter": "Bilal Kartal", "authors": "Bilal Kartal, Pablo Hernandez-Leal, Matthew E. Taylor", "title": "Using Monte Carlo Tree Search as a Demonstrator within Asynchronous Deep\n  RL", "comments": "9 pages, 6 figures, To appear at AAAI-19 Workshop on Reinforcement\n  Learning in Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved great successes in recent\nyears with the help of novel methods and higher compute power. However, there\nare still several challenges to be addressed such as convergence to locally\noptimal policies and long training times. In this paper, firstly, we augment\nAsynchronous Advantage Actor-Critic (A3C) method with a novel self-supervised\nauxiliary task, i.e. \\emph{Terminal Prediction}, measuring temporal closeness\nto terminal states, namely A3C-TP. Secondly, we propose a new framework where\nplanning algorithms such as Monte Carlo tree search or other sources of\n(simulated) demonstrators can be integrated to asynchronous distributed DRL\nmethods. Compared to vanilla A3C, our proposed methods both learn faster and\nconverge to better policies on a two-player mini version of the Pommerman game.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 20:37:17 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1812.00271", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Yoshua Bengio", "title": "Learning Speaker Representations with Mutual Information", "comments": "Submitted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning good representations is of crucial importance in deep learning.\nMutual Information (MI) or similar measures of statistical dependence are\npromising tools for learning these representations in an unsupervised way. Even\nthough the mutual information between two random variables is hard to measure\ndirectly in high dimensional spaces, some recent studies have shown that an\nimplicit optimization of MI can be achieved with an encoder-discriminator\narchitecture similar to that of Generative Adversarial Networks (GANs). In this\nwork, we learn representations that capture speaker identities by maximizing\nthe mutual information between the encoded representations of chunks of speech\nrandomly sampled from the same sentence. The proposed encoder relies on the\nSincNet architecture and transforms raw speech waveform into a compact feature\nvector. The discriminator is fed by either positive samples (of the joint\ndistribution of encoded chunks) or negative samples (from the product of the\nmarginals) and is trained to separate them. We report experiments showing that\nthis approach effectively learns useful speaker representations, leading to\npromising results on speaker identification and verification tasks. Our\nexperiments consider both unsupervised and semi-supervised settings and compare\nthe performance achieved with different objective functions.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 21:48:28 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 22:49:01 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1812.00289", "submitter": "Cheikh Toure", "authors": "Cheikh Toure, Anne Auger, Dimo Brockhoff, Nikolaus Hansen", "title": "On Bi-Objective convex-quadratic problems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze theoretical properties of bi-objective\nconvex-quadratic problems. We give a complete description of their Pareto set\nand prove the convexity of their Pareto front. We show that the Pareto set is a\nline segment when both Hessian matrices are proportional. We then propose a\nnovel set of convex-quadratic test problems, describe their theoretical\nproperties and the algorithm abilities required by those test problems. This\nincludes in particular testing the sensitivity with respect to separability,\nill-conditioned problems, rotational invariance, and whether the Pareto set is\naligned with the coordinate axis.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 23:32:43 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Toure", "Cheikh", ""], ["Auger", "Anne", ""], ["Brockhoff", "Dimo", ""], ["Hansen", "Nikolaus", ""]]}, {"id": "1812.00493", "submitter": "Carola Doerr", "authors": "Eduardo Carvalho Pinto and Carola Doerr", "title": "Towards a More Practice-Aware Runtime Analysis of Evolutionary\n  Algorithms", "comments": "Internship report as of July 2017. Some references are outdated.\n  Please get in touch if you are interested in a specific result and we will be\n  happy to discuss the latest version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theory of evolutionary computation (EC) aims at providing mathematically\nfounded statements about the performance of evolutionary algorithms (EAs). The\npredominant topic in this research domain is runtime analysis, which studies\nthe time it takes a given EA to solve a given optimization problem. Runtime\nanalysis has witnessed significant advances in the last couple of years,\nallowing us to compute precise runtime estimates for several EAs and several\nproblems. Runtime analysis is, however (and unfortunately!), often judged by\npractitioners to be of little relevance for real applications of EAs. Several\nreasons for this claim exist. We address two of them in this present work:\n  (1) EA implementations often differ from their vanilla pseudocode\ndescription, which, in turn, typically form the basis for runtime analysis. To\nclose the resulting gap between empirically observed and theoretically derived\nperformance estimates, we therefore suggest to take this discrepancy into\naccount in the mathematical analysis and to adjust, for example, the cost\nassigned to the evaluation of search points that equal one of their direct\nparents (provided that this is easy to verify as is the case in almost all\nstandard EAs).\n  (2) Most runtime analysis results make statements about the expected time to\nreach an optimal solution (and possibly the distribution of this optimization\ntime) only, thus explicitly or implicitly neglecting the importance of\nunderstanding how the function values evolve over time. We suggest to extend\nruntime statements to runtime profiles, covering the expected time needed to\nreach points of intermediate fitness values.\n  As a direct consequence, we obtain a result showing that the greedy (2+1) GA\nof Sudholt [GECCO 2012] outperforms any unary unbiased black-box algorithm on\nOneMax.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 00:13:34 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Pinto", "Eduardo Carvalho", ""], ["Doerr", "Carola", ""]]}, {"id": "1812.00622", "submitter": "Jean-Philippe Fauvelle", "authors": "Jean-Philippe Fauvelle, Alexandre Dey, Sylvain Navers", "title": "Protection of an information system by artificial intelligence: a\n  three-phase approach based on behaviour analysis to detect a hostile scenario", "comments": "in French. European Cyber Week - C\\&ESAR Conference - Artificial\n  Intelligence and Cybersecurity, Nov 2018, Rennes, France. 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the behaviour of individuals and entities (UEBA) is an area\nof artificial intelligence that detects hostile actions (e.g. attacks, fraud,\ninfluence, poisoning) due to the unusual nature of observed events, by affixing\nto a signature-based operation. A UEBA process usually involves two phases,\nlearning and inference. Intrusion detection systems (IDS) available still\nsuffer from bias, including over-simplification of problems, underexploitation\nof the AI potential, insufficient consideration of the temporality of events,\nand perfectible management of the memory cycle of behaviours. In addition,\nwhile an alert generated by a signature-based IDS can refer to the signature on\nwhich the detection is based, the IDS in the UEBA domain produce results, often\nassociated with a score, whose explainable character is less obvious. Our\nunsupervised approach is to enrich this process by adding a third phase to\ncorrelate events (incongruities, weak signals) that are presumed to be linked\ntogether, with the benefit of a reduction of false positives and negatives. We\nalso seek to avoid a so-called \"boiled frog\" bias inherent in continuous\nlearning. Our first results are interesting and have an explainable character,\nboth on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 09:29:03 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Fauvelle", "Jean-Philippe", ""], ["Dey", "Alexandre", ""], ["Navers", "Sylvain", ""]]}, {"id": "1812.00768", "submitter": "Aleksey Zakharov", "authors": "Aleksey O. Zakharov, Yulia V. Kovalenko", "title": "Construction and reduction of the Pareto set in asymmetric travelling\n  salesman problem with two criteria", "comments": "Vestnik of Saint Petersburg University. Applied Mathematics. Computer\n  Science. Control Processes, 2018, vol. 14, iss. 4. arXiv admin note:\n  substantial text overlap with arXiv:1805.10606", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the bicriteria asymmetric travelling salesman problem (bi-ATSP).\nOptimal solution to a multicriteria problem is usually supposed to be the\nPareto set, which is rather wide in real-world problems. For the first time we\napply to the bi-ATSP the axiomatic approach of the Pareto set reduction\nproposed by V. Noghin. We identify series of 'quanta of information' that\nguarantee the reduction of the Pareto set for particular cases of the bi-ATSP.\nAn approximation of the Pareto set to the bi-ATSP is constructed by a new\nmulti-objective genetic algorithm. The experimental evaluation carried out in\nthis paper shows the degree of reduction of the Pareto set approximation for\nvarious 'quanta of information' and various structures of the bi-ATSP instances\ngenerated randomly or from TSPLIB problems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 21:05:07 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Zakharov", "Aleksey O.", ""], ["Kovalenko", "Yulia V.", ""]]}, {"id": "1812.00966", "submitter": "Dirk Sudholt", "authors": "Dirk Sudholt", "title": "Analysing the Robustness of Evolutionary Algorithms to Noise: Refined\n  Runtime Bounds and an Example Where Noise is Beneficial", "comments": "This is an extended version of a paper that appeared in the\n  Proceedings of the Genetic and Evolutionary Computation Conference (GECCO\n  2018), https://doi.org/10.1145/3205455.3205595", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the performance of well-known evolutionary algorithms (1+1)EA and\n(1+$\\lambda$)EA in the prior noise model, where in each fitness evaluation the\nsearch point is altered before evaluation with probability $p$. We present\nrefined results for the expected optimisation time of the (1+1)EA and the\n(1+$\\lambda$)EA on the function LeadingOnes, where bits have to be optimised in\nsequence. Previous work showed that the (1+1)EA on LeadingOnes runs in\npolynomial expected time if $p = O((\\log n)/n^2)$ and needs superpolynomial\nexpected time if $p = \\omega((\\log n)/n)$, leaving a huge gap for which no\nresults were known. We close this gap by showing that the expected optimisation\ntime is $\\Theta(n^2) \\cdot \\exp(\\Theta(\\min\\{pn^2, n\\}))$ for all $p \\le 1/2$,\nallowing for the first time to locate the threshold between polynomial and\nsuperpolynomial expected times at $p = \\Theta((\\log n)/n^2)$. Hence the (1+1)EA\non LeadingOnes is much more sensitive to noise than previously thought. We also\nshow that offspring populations of size $\\lambda \\ge 3.42\\log n$ can\neffectively deal with much higher noise than known before.\n  Finally, we present an example of a rugged landscape where prior noise can\nhelp to escape from local optima by blurring the landscape and allowing a hill\nclimber to see the underlying gradient. We prove that in this particular\nsetting noise can have a highly beneficial effect on performance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 18:41:38 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Sudholt", "Dirk", ""]]}, {"id": "1812.01032", "submitter": "Paul Knott PhD MPhys BSc", "authors": "Rosanna Nichols, Lana Mineh, Jes\\'us Rubio, Jonathan C. F. Matthews\n  and Paul A. Knott", "title": "Designing quantum experiments with a genetic algorithm", "comments": "11 pages + Appendix, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a genetic algorithm that designs quantum optics experiments for\nengineering quantum states with specific properties. Our algorithm is powerful\nand flexible, and can easily be modified to find methods of engineering states\nfor a range of applications. Here we focus on quantum metrology. First, we\nconsider the noise-free case, and use the algorithm to find quantum states with\na large quantum Fisher information (QFI). We find methods, which only involve\nexperimental elements that are available with current or near-future\ntechnology, for engineering quantum states with up to a 100-fold improvement\nover the best classical state, and a 20-fold improvement over the optimal\nGaussian state. Such states are a superposition of the vacuum with a large\nnumber of photons (around $80$), and can hence be seen as\nSchr\\\"odinger-cat-like states. We then apply the two most dominant noise\nsources in our setting -- photon loss and imperfect heralding -- and use the\nalgorithm to find quantum states that still improve over the optimal Gaussian\nstate with realistic levels of noise. This will open up experimental and\ntechnological work in using exotic non-Gaussian states for quantum-enhanced\nphase measurements. Finally, we use the Bayesian mean square error to look\nbeyond the regime of validity of the QFI, finding quantum states with precision\nenhancements over the alternatives even when the experiment operates in the\nregime of limited data.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 19:06:33 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 15:54:09 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Nichols", "Rosanna", ""], ["Mineh", "Lana", ""], ["Rubio", "Jes\u00fas", ""], ["Matthews", "Jonathan C. F.", ""], ["Knott", "Paul A.", ""]]}, {"id": "1812.01054", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag, Pablo G. Moreno, Neil D. Lawrence, Andreas\n  Damianou", "title": "Transferring Knowledge across Learning Processes", "comments": "Published as a conference paper at ICLR 2019; 23 pages, 8 figures, 6\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In complex transfer learning scenarios new tasks might not be tightly linked\nto previous tasks. Approaches that transfer information contained only in the\nfinal parameters of a source model will therefore struggle. Instead, transfer\nlearning at a higher level of abstraction is needed. We propose Leap, a\nframework that achieves this by transferring knowledge across learning\nprocesses. We associate each task with a manifold on which the training process\ntravels from initialization to final parameters and construct a meta-learning\nobjective that minimizes the expected length of this path. Our framework\nleverages only information obtained during training and can be computed on the\nfly at negligible cost. We demonstrate that our framework outperforms competing\nmethods, both in meta-learning and transfer learning, on a set of computer\nvision tasks. Finally, we demonstrate that Leap can transfer knowledge across\nlearning processes in demanding reinforcement learning environments (Atari)\nthat involve millions of gradient steps.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 19:43:16 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 16:28:01 GMT"}, {"version": "v3", "created": "Fri, 22 Mar 2019 13:44:59 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Moreno", "Pablo G.", ""], ["Lawrence", "Neil D.", ""], ["Damianou", "Andreas", ""]]}, {"id": "1812.01070", "submitter": "Wengong Jin", "authors": "Wengong Jin, Kevin Yang, Regina Barzilay, Tommi Jaakkola", "title": "Learning Multimodal Graph-to-Graph Translation for Molecular\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view molecular optimization as a graph-to-graph translation problem. The\ngoal is to learn to map from one molecular graph to another with better\nproperties based on an available corpus of paired molecules. Since molecules\ncan be optimized in different ways, there are multiple viable translations for\neach input graph. A key challenge is therefore to model diverse translation\noutputs. Our primary contributions include a junction tree encoder-decoder for\nlearning diverse graph translations along with a novel adversarial training\nmethod for aligning distributions of molecules. Diverse output distributions in\nour model are explicitly realized by low-dimensional latent vectors that\nmodulate the translation process. We evaluate our model on multiple molecular\noptimization tasks and show that our model outperforms previous\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 20:28:09 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 22:19:13 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 19:38:39 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Jin", "Wengong", ""], ["Yang", "Kevin", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1812.01717", "submitter": "Sjoerd van Steenkiste", "authors": "Thomas Unterthiner, Sjoerd van Steenkiste, Karol Kurach, Raphael\n  Marinier, Marcin Michalski, Sylvain Gelly", "title": "Towards Accurate Generative Models of Video: A New Metric & Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in deep generative models have lead to remarkable progress in\nsynthesizing high quality images. Following their successful application in\nimage processing and representation learning, an important next step is to\nconsider videos. Learning generative models of video is a much harder task,\nrequiring a model to capture the temporal dynamics of a scene, in addition to\nthe visual presentation of objects. While recent attempts at formulating\ngenerative models of video have had some success, current progress is hampered\nby (1) the lack of qualitative metrics that consider visual quality, temporal\ncoherence, and diversity of samples, and (2) the wide gap between purely\nsynthetic video data sets and challenging real-world data sets in terms of\ncomplexity. To this extent we propose Fr\\'{e}chet Video Distance (FVD), a new\nmetric for generative models of video, and StarCraft 2 Videos (SCV), a\nbenchmark of game play from custom starcraft 2 scenarios that challenge the\ncurrent capabilities of generative models of video. We contribute a large-scale\nhuman study, which confirms that FVD correlates well with qualitative human\njudgment of generated videos, and provide initial benchmark results on SCV.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 03:57:42 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 16:43:17 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Unterthiner", "Thomas", ""], ["van Steenkiste", "Sjoerd", ""], ["Kurach", "Karol", ""], ["Marinier", "Raphael", ""], ["Michalski", "Marcin", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1812.01762", "submitter": "Zachariah Carmichael", "authors": "Zachariah Carmichael, Hamed F. Langroudi, Char Khazanov, Jeffrey\n  Lillie, John L. Gustafson, Dhireesha Kudithipudi", "title": "Deep Positron: A Deep Neural Network Using the Posit Number System", "comments": "6 pages, Design, Automation and Test in Europe 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent surge of interest in Deep Neural Networks (DNNs) has led to\nincreasingly complex networks that tax computational and memory resources. Many\nDNNs presently use 16-bit or 32-bit floating point operations. Significant\nperformance and power gains can be obtained when DNN accelerators support\nlow-precision numerical formats. Despite considerable research, there is still\na knowledge gap on how low-precision operations can be realized for both DNN\ntraining and inference. In this work, we propose a DNN architecture, Deep\nPositron, with posit numerical format operating successfully at $\\leq$8 bits\nfor inference. We propose a precision-adaptable FPGA soft core for exact\nmultiply-and-accumulate for uniform comparison across three numerical formats,\nfixed, floating-point and posit. Preliminary results demonstrate that 8-bit\nposit has better accuracy than 8-bit fixed or floating-point for three\ndifferent low-dimensional datasets. Moreover, the accuracy is comparable to\n32-bit floating-point on a Xilinx Virtex-7 FPGA device. The trade-offs between\nDNN performance and hardware resources, i.e. latency, power, and resource\nutilization, show that posit outperforms in accuracy and latency at 8-bit and\nbelow.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 00:36:53 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 00:03:16 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Carmichael", "Zachariah", ""], ["Langroudi", "Hamed F.", ""], ["Khazanov", "Char", ""], ["Lillie", "Jeffrey", ""], ["Gustafson", "John L.", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1812.01895", "submitter": "Arttu Lamsa", "authors": "Niko Reunanen, Ville K\\\"on\\\"onen, Hermanni H\\\"alv\\\"a, Jani\n  M\\\"antyj\\\"arvi, Arttu L\\\"ams\\\"a and Jussi Liikka", "title": "Computational Graph Approach for Detection of Composite Human Activities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing work in human activity detection classifies physical activities\nusing a single fixed-length subset of a sensor signal. However, temporally\nconsecutive subsets of a sensor signal are not utilized. This is not optimal\nfor classifying physical activities (composite activities) that are composed of\na temporal series of simpler activities (atomic activities). A sport consists\nof physical activities combined in a fashion unique to that sport. The\nconstituent physical activities and the sport are not fundamentally different.\nWe propose a computational graph architecture for human activity detection\nbased on the readings of a triaxial accelerometer. The resulting model learns\n1) a representation of the atomic activities of a sport and 2) to classify\nphysical activities as compositions of the atomic activities. The proposed\nmodel, alongside with a set of baseline models, was tested for a simultaneous\nclassification of eight physical activities (walking, nordic walking, running,\nsoccer, rowing, bicycling, exercise bicycling and lying down). The proposed\nmodel obtained an overall mean accuracy of 77.91% (population) and 95.28%\n(personalized). The corresponding accuracies of the best baseline model were\n73.52% and 90.03%. However, without combining consecutive atomic activities,\nthe corresponding accuracies of the proposed model were 71.52% and 91.22%. The\nresults show that our proposed model is accurate, outperforms the baseline\nmodels and learns to combine simple activities into complex activities.\nComposite activities can be classified as combinations of atomic activities.\nOur proposed architecture is a basis for accurate models in human activity\ndetection.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 10:16:43 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Reunanen", "Niko", ""], ["K\u00f6n\u00f6nen", "Ville", ""], ["H\u00e4lv\u00e4", "Hermanni", ""], ["M\u00e4ntyj\u00e4rvi", "Jani", ""], ["L\u00e4ms\u00e4", "Arttu", ""], ["Liikka", "Jussi", ""]]}, {"id": "1812.02500", "submitter": "Peng Yang", "authors": "Peng Yang, Ke Tang, Xin Yao", "title": "A Parallel Divide-and-Conquer based Evolutionary Algorithm for\n  Large-scale Optimization", "comments": "12 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale optimization problems that involve thousands of decision\nvariables have extensively arisen from various industrial areas. As a powerful\noptimization tool for many real-world applications, evolutionary algorithms\n(EAs) fail to solve the emerging large-scale problems both effectively and\nefficiently. In this paper, we propose a novel Divide-and-Conquer (DC) based EA\nthat can not only produce high-quality solution by solving sub-problems\nseparately, but also highly utilizes the power of parallel computing by solving\nthe sub-problems simultaneously. Existing DC-based EAs that were deemed to\nenjoy the same advantages of the proposed algorithm, are shown to be\npractically incompatible with the parallel computing scheme, unless some\ntrade-offs are made by compromising the solution quality.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 12:45:48 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Yang", "Peng", ""], ["Tang", "Ke", ""], ["Yao", "Xin", ""]]}, {"id": "1812.02504", "submitter": "Alberto Bartoli", "authors": "Eric Medvet, Alberto Bartoli, Alessio Ansuini, Fabiano Tarlao", "title": "Observing the Population Dynamics in GE by means of the Intrinsic\n  Dimension", "comments": "Evolutionary Machine Learning workshop at International Conference on\n  Parallel Problem Solving from Nature (EML@PPSN), 2018, Coimbra (Portugal)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We explore the use of Intrinsic Dimension (ID) for gaining insights in how\npopulations evolve in Evolutionary Algorithms. ID measures the minimum number\nof dimensions needed to accurately describe a dataset and its estimators are\nbeing used more and more in Machine Learning to cope with large datasets. We\npostulate that ID can provide information about population which is\ncomplimentary w.r.t.\\ what (a simple measure of) diversity tells. We\nexperimented with the application of ID to populations evolved with a recent\nvariant of Grammatical Evolution. The preliminary results suggest that\ndiversity and ID constitute two different points of view on the population\ndynamics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 12:55:05 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Medvet", "Eric", ""], ["Bartoli", "Alberto", ""], ["Ansuini", "Alessio", ""], ["Tarlao", "Fabiano", ""]]}, {"id": "1812.02532", "submitter": "Dario  Izzo", "authors": "Dario Izzo, Dharmesh Tailor and Thomas Vasileiou", "title": "On the stability analysis of deep neural network representations of an\n  optimal state-feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work have shown how the optimal state-feedback, obtained as the\nsolution to the Hamilton-Jacobi-Bellman equations, can be approximated for\nseveral nonlinear, deterministic systems by deep neural networks. When\nimitation (supervised) learning is used to train the neural network on optimal\nstate-action pairs, for instance as derived by applying Pontryagin's theory of\noptimal processes, the resulting model is referred here as the guidance and\ncontrol network. In this work, we analyze the stability of nonlinear and\ndeterministic systems controlled by such networks. We then propose a method\nutilising differential algebraic techniques and high-order Taylor maps to gain\ninformation on the stability of the neurocontrolled state trajectories. We\nexemplify the proposed methods in the case of the two-dimensional dynamics of a\nquadcopter controlled to reach the origin and we study how different\narchitectures of the guidance and control network affect the stability of the\ntarget equilibrium point and the stability margins to time delay. Moreover, we\nshow how to study the robustness to initial conditions of a nominal trajectory,\nusing a Taylor representation of the neurocontrolled neighbouring trajectories.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 14:07:31 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 08:01:30 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 12:27:45 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Izzo", "Dario", ""], ["Tailor", "Dharmesh", ""], ["Vasileiou", "Thomas", ""]]}, {"id": "1812.02637", "submitter": "Gavin Weiguang Ding", "authors": "Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, and Ruitong Huang", "title": "MMA Training: Direct Input Space Margin Maximization through Adversarial\n  Training", "comments": "Published at the Eighth International Conference on Learning\n  Representations (ICLR 2020), https://openreview.net/forum?id=HkeryxBtPB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversarial robustness of neural networks from a margin maximization\nperspective, where margins are defined as the distances from inputs to a\nclassifier's decision boundary. Our study shows that maximizing margins can be\nachieved by minimizing the adversarial loss on the decision boundary at the\n\"shortest successful perturbation\", demonstrating a close connection between\nadversarial losses and the margins. We propose Max-Margin Adversarial (MMA)\ntraining to directly maximize the margins to achieve adversarial robustness.\nInstead of adversarial training with a fixed $\\epsilon$, MMA offers an\nimprovement by enabling adaptive selection of the \"correct\" $\\epsilon$ as the\nmargin individually for each datapoint. In addition, we rigorously analyze\nadversarial training with the perspective of margin maximization, and provide\nan alternative interpretation for adversarial training, maximizing either a\nlower or an upper bound of the margins. Our experiments empirically confirm our\ntheory and demonstrate MMA training's efficacy on the MNIST and CIFAR10\ndatasets w.r.t. $\\ell_\\infty$ and $\\ell_2$ robustness. Code and models are\navailable at https://github.com/BorealisAI/mma_training.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 16:15:52 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 21:51:13 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 14:07:17 GMT"}, {"version": "v4", "created": "Wed, 4 Mar 2020 19:58:33 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ding", "Gavin Weiguang", ""], ["Sharma", "Yash", ""], ["Lui", "Kry Yik Chau", ""], ["Huang", "Ruitong", ""]]}, {"id": "1812.02711", "submitter": "Cees Ferdinand Verdier", "authors": "Cees F. Verdier, Manuel Mazo Jr", "title": "Formal Synthesis of Analytic Controllers for Sampled-Data Systems via\n  Genetic Programming", "comments": "The original version of this article has been accepted to CDC 2018.\n  This version contains minor corrections. Supported by NWO Domain TTW under\n  the CADUSY project \\#13852", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an automatic formal controller synthesis method for\nnonlinear sampled-data systems with safety and reachability specifications.\nFundamentally, the presented method is not restricted to polynomial systems and\ncontrollers. We consider periodically switched controllers based on a Control\nLyapunov Barrier-like functions. The proposed method utilizes genetic\nprogramming to synthesize these functions as well as the controller modes.\nCorrectness of the controller are subsequently verified by means of a\nSatisfiability Modulo Theories solver. Effectiveness of the proposed\nmethodology is demonstrated on multiple systems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 18:45:17 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Verdier", "Cees F.", ""], ["Mazo", "Manuel", "Jr"]]}, {"id": "1812.02831", "submitter": "Shumeet Baluja", "authors": "Shumeet Baluja, Dave Marwood, Nick Johnston, Michele Covell", "title": "Neural Image Decompression: Learning to Render Better Image Previews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rapidly increasing portion of Internet traffic is dominated by requests\nfrom mobile devices with limited- and metered-bandwidth constraints. To satisfy\nthese requests, it has become standard practice for websites to transmit small\nand extremely compressed image previews as part of the initial page-load\nprocess. Recent work, based on an adaptive triangulation of the target image,\nhas shown the ability to generate thumbnails of full images at extreme\ncompression rates: 200 bytes or less with impressive gains (in terms of PSNR\nand SSIM) over both JPEG and WebP standards. However, qualitative assessments\nand preservation of semantic content can be less favorable. We present a novel\nmethod to significantly improve the reconstruction quality of the original\nimage with no changes to the encoded information. Our neural-based decoding not\nonly achieves higher PSNR and SSIM scores than the original methods, but also\nyields a substantial increase in semantic-level content preservation. In\naddition, by keeping the same encoding stream, our solution is completely\ninter-operable with the original decoder. The end result is suitable for a\nrange of small-device deployments, as it involves only a single forward-pass\nthrough a small, scalable network.\n", "versions": [{"version": "v1", "created": "Thu, 6 Dec 2018 22:12:39 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Baluja", "Shumeet", ""], ["Marwood", "Dave", ""], ["Johnston", "Nick", ""], ["Covell", "Michele", ""]]}, {"id": "1812.02948", "submitter": "Dario  Izzo", "authors": "Dario Izzo and Marcus M\\\"artens and Binfeng Pan", "title": "A Survey on Artificial Intelligence Trends in Spacecraft Guidance\n  Dynamics and Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid developments of Artificial Intelligence in the last decade are\ninfluencing Aerospace Engineering to a great extent and research in this\ncontext is proliferating. We share our observations on the recent developments\nin the area of Spacecraft Guidance Dynamics and Control, giving selected\nexamples on success stories that have been motivated by mission designs. Our\nfocus is on evolutionary optimisation, tree searches and machine learning,\nincluding deep learning and reinforcement learning as the key technologies and\ndrivers for current and future research in the field. From a high-level\nperspective, we survey various scenarios for which these approaches have been\nsuccessfully applied or are under strong scientific investigation. Whenever\npossible, we highlight the relations and synergies that can be obtained by\ncombining different techniques and projects towards future domains for which\nnewly emerging artificial intelligence techniques are expected to become game\nchangers.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 08:46:09 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Izzo", "Dario", ""], ["M\u00e4rtens", "Marcus", ""], ["Pan", "Binfeng", ""]]}, {"id": "1812.02956", "submitter": "Piotr Szyma\\'nski", "authors": "Piotr Szyma\\'nski, Tomasz Kajdanowicz, Nitesh Chawla", "title": "LNEMLC: Label Network Embeddings for Multi-Label Classification", "comments": "submitted to TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multi-label classification aims to classify instances with discrete\nnon-exclusive labels. Most approaches on multi-label classification focus on\neffective adaptation or transformation of existing binary and multi-class\nlearning approaches but fail in modelling the joint probability of labels or do\nnot preserve generalization abilities for unseen label combinations. To address\nthese issues we propose a new multi-label classification scheme, LNEMLC - Label\nNetwork Embedding for Multi-Label Classification, that embeds the label network\nand uses it to extend input space in learning and inference of any base\nmulti-label classifier. The approach allows capturing of labels' joint\nprobability at low computational complexity providing results comparable to the\nbest methods reported in the literature. We demonstrate how the method reveals\nstatistically significant improvements over the simple kNN baseline classifier.\nWe also provide hints for selecting the robust configuration that works\nsatisfactorily across data domains.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 09:30:18 GMT"}, {"version": "v2", "created": "Tue, 1 Jan 2019 21:11:09 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Szyma\u0144ski", "Piotr", ""], ["Kajdanowicz", "Tomasz", ""], ["Chawla", "Nitesh", ""]]}, {"id": "1812.03183", "submitter": "Paul Knott PhD MPhys BSc", "authors": "L. O'Driscoll, R. Nichols, P. A. Knott", "title": "A hybrid machine-learning algorithm for designing quantum experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hybrid machine-learning algorithm for designing quantum optics\nexperiments that produce specific quantum states. Our algorithm successfully\nfound experimental schemes to produce all 5 states we asked it to, including\nSchr\\\"odinger cat states and cubic phase states, all to a fidelity of over\n$96\\%$. Here we specifically focus on designing realistic experiments, and\nhence all of the algorithm's designs only contain experimental elements that\nare available with current technology. The core of our algorithm is a genetic\nalgorithm that searches for optimal arrangements of the experimental elements,\nbut to speed up the initial search we incorporate a neural network that\nclassifies quantum states. The latter is of independent interest, as it quickly\nlearned to accurately classify quantum states given their photon-number\ndistributions.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2018 19:01:38 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 14:08:37 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["O'Driscoll", "L.", ""], ["Nichols", "R.", ""], ["Knott", "P. A.", ""]]}, {"id": "1812.03365", "submitter": "Dennis George Wilson", "authors": "Dennis G Wilson, Sylvain Cussat-Blanc, Herv\\'e Luga, Kyle Harrington", "title": "Neuromodulated Learning in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the brain, learning signals change over time and synaptic location, and\nare applied based on the learning history at the synapse, in the complex\nprocess of neuromodulation. Learning in artificial neural networks, on the\nother hand, is shaped by hyper-parameters set before learning starts, which\nremain static throughout learning, and which are uniform for the entire\nnetwork. In this work, we propose a method of deep artificial neuromodulation\nwhich applies the concepts of biological neuromodulation to stochastic gradient\ndescent. Evolved neuromodulatory dynamics modify learning parameters at each\nlayer in a deep neural network over the course of the network's training. We\nshow that the same neuromodulatory dynamics can be applied to different models\nand can scale to new problems not encountered during evolution. Finally, we\nexamine the evolved neuromodulation, showing that evolution found dynamic,\nlocation-specific learning strategies.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2018 22:10:34 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Wilson", "Dennis G", ""], ["Cussat-Blanc", "Sylvain", ""], ["Luga", "Herv\u00e9", ""], ["Harrington", "Kyle", ""]]}, {"id": "1812.03381", "submitter": "Tim Salimans", "authors": "Tim Salimans and Richard Chen", "title": "Learning Montezuma's Revenge from a Single Demonstration", "comments": "Deep RL Workshop, NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for learning from a single demonstration to solve\nhard exploration tasks like the Atari game Montezuma's Revenge. Instead of\nimitating human demonstrations, as proposed in other recent works, our approach\nis to maximize rewards directly. Our agent is trained using off-the-shelf\nreinforcement learning, but starts every episode by resetting to a state from a\ndemonstration. By starting from such demonstration states, the agent requires\nmuch less exploration to learn a game compared to when it starts from the\nbeginning of the game at every episode. We analyze reinforcement learning for\ntasks with sparse rewards in a simple toy environment, where we show that the\nrun-time of standard RL methods scales exponentially in the number of states\nbetween rewards. Our method reduces this to quadratic scaling, opening up many\ntasks that were previously infeasible. We then apply our method to Montezuma's\nRevenge, for which we present a trained agent achieving a high-score of 74,500,\nbetter than any previously published result.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2018 20:16:16 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Salimans", "Tim", ""], ["Chen", "Richard", ""]]}, {"id": "1812.03444", "submitter": "Muhammad Marwan Muhammad Fuad", "authors": "Muhammad Marwan Muhammad Fuad", "title": "Applying Nature-Inspired Optimization Algorithms for Selecting Important\n  Timestamps to Reduce Time Series Dimensionality", "comments": "13 pages, Evolving Systems (2017).\n  https://link.springer.com/article/10.1007/s12530-017-9207-7#citeas", "journal-ref": null, "doi": "10.1007/s12530-017-9207-7", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series data account for a major part of data supply available today.\nTime series mining handles several tasks such as classification, clustering,\nquery-by-content, prediction, and others. Performing data mining tasks on raw\ntime series is inefficient as these data are high-dimensional by nature.\nInstead, time series are first pre-processed using several techniques before\ndifferent data mining tasks can be performed on them. In general, there are two\nmain approaches to reduce time series dimensionality, the first is what we call\nlandmark methods. These methods are based on finding characteristic features in\nthe target time series. The second is based on data transformations. These\nmethods transform the time series from the original space into a reduced space,\nwhere they can be managed more efficiently. The method we present in this paper\napplies a third approach, as it projects a time series onto a lower-dimensional\nspace by selecting important points in the time series. The novelty of our\nmethod is that these points are not chosen according to a geometric criterion,\nwhich is subjective in most cases, but through an optimization process. The\nother important characteristic of our method is that these important points are\nselected on a dataset-level and not on a single time series-level. The direct\nadvantage of this strategy is that the distance defined on the low-dimensional\nspace lower bounds the original distance applied to raw data. This enables us\nto apply the popular GEMINI algorithm. The promising results of our experiments\non a wide variety of time series datasets, using different optimizers, and\napplied to the two major data mining tasks, validate our new method.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 08:26:35 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Fuad", "Muhammad Marwan Muhammad", ""]]}, {"id": "1812.03457", "submitter": "Xiaopeng Luo Dr.", "authors": "Xiaopeng Luo", "title": "Minima distribution for global optimization", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper establishes a strict mathematical relationship between an\narbitrary continuous function on a compact set and its global minima, like the\nwell-known first order optimality condition for convex and differentiable\nfunctions. By introducing a class of nascent minima distribution functions that\nis only related to the target function and the given compact set, we construct\na sequence that monotonically converges to the global minima on that given\ncompact set. Then, we further consider some various sequences of sets where\neach sequence monotonically shrinks from the original compact set to the set of\nall global minimizers, and the shrink rate can be determined for continuously\ndifferentiable functions. Finally, we provide a different way of constructing\nthe nascent minima distribution functions.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 10:37:28 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 06:06:30 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 08:02:15 GMT"}, {"version": "v4", "created": "Fri, 24 May 2019 02:52:13 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Luo", "Xiaopeng", ""]]}, {"id": "1812.03513", "submitter": "Weijie Zheng", "authors": "Benjamin Doerr, Weijie Zheng", "title": "Working Principles of Binary Differential Evolution", "comments": null, "journal-ref": null, "doi": "10.1016/j.tcs.2019.08.025", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a first fundamental analysis of the working principles of binary\ndifferential evolution (BDE), an optimization heuristic for binary decision\nvariables that was derived by Gong and Tuson (2007) from the very successful\nclassic differential evolution (DE) for continuous optimization. We show that\nunlike most other optimization paradigms, it is stable in the sense that\nneutral bit values are sampled with probability close to $1/2$ for a long time.\nThis is generally a desirable property, however, it makes it harder to find the\noptima for decision variables with small influence on the objective function.\nThis can result in an optimization time exponential in the dimension when\noptimizing simple symmetric functions like OneMax. On the positive side, BDE\nquickly detects and optimizes the most important decision variables. For\nexample, dominant bits converge to the optimal value in time logarithmic in the\npopulation size. This enables BDE to optimize the most important bits very\nfast. Overall, our results indicate that BDE is an interesting optimization\nparadigm having characteristics significantly different from classic\nevolutionary algorithms or estimation-of-distribution algorithms (EDAs).\n  On the technical side, we observe that the strong stochastic dependencies in\nthe random experiment describing a run of BDE prevent us from proving all\ndesired results with the mathematical rigor that was successfully used in the\nanalysis of other evolutionary algorithms. Inspired by mean-field approaches in\nstatistical physics we propose a more independent variant of BDE, show\nexperimentally its similarity to BDE, and prove some statements rigorously only\nfor the independent variant. Such a semi-rigorous approach might be interesting\nfor other problems in evolutionary computation where purely mathematical\nmethods failed so far.\n", "versions": [{"version": "v1", "created": "Sun, 9 Dec 2018 16:29:14 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Doerr", "Benjamin", ""], ["Zheng", "Weijie", ""]]}, {"id": "1812.03608", "submitter": "Liqiang Zhu", "authors": "Wei Wang and Liqiang Zhu", "title": "Reliable Identification of Redundant Kernels for Convolutional Neural\n  Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To compress deep convolutional neural networks (CNNs) with large memory\nfootprint and long inference time, this paper proposes a novel pruning\ncriterion using layer-wised Ln-norm of feature maps. Different from existing\npruning criteria, which are mainly based on L1-norm of convolution kernels, the\nproposed method utilizes Ln-norm of output feature maps after non-linear\nactivations, where n is a variable, increasing from 1 at the first convolution\nlayer to inf at the last convolution layer. With the ability of accurately\nidentifying unimportant convolution kernels, the proposed method achieves a\ngood balance between model size and inference accuracy. The experiments on\nImageNet and the successful application in railway surveillance system show\nthat the proposed method outperforms existing kernel-norm-based methods and is\ngenerally applicable to any deep neural network with convolution operations.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 03:28:15 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Wang", "Wei", ""], ["Zhu", "Liqiang", ""]]}, {"id": "1812.03929", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, Osvaldo Simeone, Brian Gardner, and Andr\\'e Gr\\\"uning", "title": "An Introduction to Spiking Neural Networks: Probabilistic Models,\n  Learning Rules, and Applications", "comments": "This article is now superseded by arXiv:1910.01059. To appear on IEEE\n  Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) are distributed trainable systems whose\ncomputing elements, or neurons, are characterized by internal analog dynamics\nand by digital and sparse synaptic communications. The sparsity of the synaptic\nspiking inputs and the corresponding event-driven nature of neural processing\ncan be leveraged by hardware implementations that have demonstrated significant\nenergy reductions as compared to conventional Artificial Neural Networks\n(ANNs). Most existing training algorithms for SNNs have been designed either\nfor biological plausibility or through conversion from pre-trained ANNs via\nrate encoding. This paper aims at providing an introduction to SNNs by focusing\non a probabilistic signal processing methodology that enables the direct\nderivation of learning rules leveraging the unique time encoding capabilities\nof SNNs. To this end, the paper adopts discrete-time probabilistic models for\nnetworked spiking neurons, and it derives supervised and unsupervised learning\nrules from first principles by using variational inference. Examples and open\nresearch problems are also provided.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 17:29:12 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 11:39:43 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 16:21:34 GMT"}, {"version": "v4", "created": "Fri, 19 Jul 2019 18:10:12 GMT"}, {"version": "v5", "created": "Sun, 20 Oct 2019 12:43:05 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""], ["Gardner", "Brian", ""], ["Gr\u00fcning", "Andr\u00e9", ""]]}, {"id": "1812.03955", "submitter": "Norman Di Palo", "authors": "Norman Di Palo, Harri Valpola", "title": "Improving Model-Based Control and Active Exploration with Reconstruction\n  Uncertainty Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model based predictions of future trajectories of a dynamical system often\nsuffer from inaccuracies, forcing model based control algorithms to re-plan\noften, thus being computationally expensive, suboptimal and not reliable. In\nthis work, we propose a model agnostic method for estimating the uncertainty of\na model?s predictions based on reconstruction error, using it in control and\nexploration. As our experiments show, this uncertainty estimation can be used\nto improve control performance on a wide variety of environments by choosing\npredictions of which the model is confident. It can also be used for active\nlearning to explore more efficiently the environment by planning for\ntrajectories with high uncertainty, allowing faster model learning.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2018 18:09:10 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Di Palo", "Norman", ""], ["Valpola", "Harri", ""]]}, {"id": "1812.04458", "submitter": "Alan Reynolds", "authors": "V\\'aclav Poto\\v{c}ek, Alan P. Reynolds, Alessandro Fedrizzi, David W.\n  Corne", "title": "Multi-objective evolutionary algorithms for quantum circuit discovery", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum hardware continues to advance, yet finding new quantum algorithms -\nquantum software - remains a challenge, with classically trained computer\nprogrammers having little intuition of how computational tasks may be performed\nin the quantum realm. As such, the idea of developing automated tools for\nalgorithm development is even more appealing for quantum computing than for\nclassical. Here we develop a robust, multi-objective evolutionary search\nstrategy to design quantum circuits 'from scratch', by combining and\nparameterizing a task-generic library of quantum circuit elements. When applied\nto 'ab initio' design of quantum circuits for the input/output mapping\nrequirements of the quantum Fourier transform and Grover's search algorithm, it\nfinds textbook circuit designs, along with alternative structures that achieve\nthe same functionality. Exploiting its multi-objective nature, the discovery\nalgorithm can trade off performance measures such as accuracy, circuit width or\ndepth, gate count, or implementability - a crucial requirement for\nfirst-generation quantum processors and applications.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 15:19:19 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Poto\u010dek", "V\u00e1clav", ""], ["Reynolds", "Alan P.", ""], ["Fedrizzi", "Alessandro", ""], ["Corne", "David W.", ""]]}, {"id": "1812.04818", "submitter": "Matin Hashemi", "authors": "Saeed Saadatnejad, Mohammadhosein Oveisi, Matin Hashemi", "title": "LSTM-Based ECG Classification for Continuous Monitoring on Personal\n  Wearable Devices", "comments": "Accepted for publication in IEEE Journal of Biomedical and Health\n  Informatics (J-BHI)", "journal-ref": "IEEE Journal of Biomedical and Health Informatics (JBHI), Vol. 24,\n  No. 2, February 2020", "doi": "10.1109/JBHI.2019.2911367", "report-no": null, "categories": "eess.SP cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A novel ECG classification algorithm is proposed for continuous\ncardiac monitoring on wearable devices with limited processing capacity.\nMethods: The proposed solution employs a novel architecture consisting of\nwavelet transform and multiple LSTM recurrent neural networks. Results:\nExperimental evaluations show superior ECG classification performance compared\nto previous works. Measurements on different hardware platforms show the\nproposed algorithm meets timing requirements for continuous and real-time\nexecution on wearable devices. Conclusion: In contrast to many\ncompute-intensive deep-learning based approaches, the proposed algorithm is\nlightweight, and therefore, brings continuous monitoring with accurate\nLSTM-based ECG classification to wearable devices. Significance: The proposed\nalgorithm is both accurate and lightweight. The source code is available online\n[1].\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 06:04:44 GMT"}, {"version": "v2", "created": "Sat, 13 Apr 2019 10:39:43 GMT"}, {"version": "v3", "created": "Sat, 11 May 2019 22:53:26 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Saadatnejad", "Saeed", ""], ["Oveisi", "Mohammadhosein", ""], ["Hashemi", "Matin", ""]]}, {"id": "1812.04948", "submitter": "Samuli Laine", "authors": "Tero Karras, Samuli Laine, Timo Aila", "title": "A Style-Based Generator Architecture for Generative Adversarial Networks", "comments": "CVPR 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an alternative generator architecture for generative adversarial\nnetworks, borrowing from style transfer literature. The new architecture leads\nto an automatically learned, unsupervised separation of high-level attributes\n(e.g., pose and identity when trained on human faces) and stochastic variation\nin the generated images (e.g., freckles, hair), and it enables intuitive,\nscale-specific control of the synthesis. The new generator improves the\nstate-of-the-art in terms of traditional distribution quality metrics, leads to\ndemonstrably better interpolation properties, and also better disentangles the\nlatent factors of variation. To quantify interpolation quality and\ndisentanglement, we propose two new, automated methods that are applicable to\nany generator architecture. Finally, we introduce a new, highly varied and\nhigh-quality dataset of human faces.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 13:59:43 GMT"}, {"version": "v2", "created": "Wed, 6 Feb 2019 14:58:00 GMT"}, {"version": "v3", "created": "Fri, 29 Mar 2019 11:08:46 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Karras", "Tero", ""], ["Laine", "Samuli", ""], ["Aila", "Timo", ""]]}, {"id": "1812.04974", "submitter": "Elena Pastorelli", "authors": "Francesco Simula, Elena Pastorelli, Pier Stanislao Paolucci, Michele\n  Martinelli, Alessandro Lonardo, Andrea Biagioni, Cristiano Capone, Fabrizio\n  Capuani, Paolo Cretaro, Giulia De Bonis, Francesca Lo Cicero, Luca Pontisso,\n  Piero Vicini, Roberto Ammendola", "title": "Real-time cortical simulations: energy and interconnect scaling on\n  distributed systems", "comments": "8 pages, 8 figures, 4 tables, submitted after final publication on\n  PDP2019 proceedings, corrected final DOI. arXiv admin note: text overlap with\n  arXiv:1812.04974, arXiv:1804.03441", "journal-ref": "27th Euromicro International Conference on Parallel, Distributed\n  and Network-based Processing (PDP), Pavia, Italy, February 13-15, 2019, pp.\n  283-290", "doi": "10.1109/EMPDP.2019.8671627", "report-no": null, "categories": "cs.DC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We profile the impact of computation and inter-processor communication on the\nenergy consumption and on the scaling of cortical simulations approaching the\nreal-time regime on distributed computing platforms. Also, the speed and energy\nconsumption of processor architectures typical of standard HPC and embedded\nplatforms are compared. We demonstrate the importance of the design of\nlow-latency interconnect for speed and energy consumption. The cost of cortical\nsimulations is quantified using the Joule per synaptic event metric on both\narchitectures. Reaching efficient real-time on large scale cortical simulations\nis of increasing relevance for both future bio-inspired artificial intelligence\napplications and for understanding the cognitive functions of the brain, a\nscientific quest that will require to embed large scale simulations into highly\ncomplex virtual or real worlds. This work stands at the crossroads between the\nWaveScalES experiment in the Human Brain Project (HBP), which includes the\nobjective of large scale thalamo-cortical simulations of brain states and their\ntransitions, and the ExaNeSt and EuroExa projects, that investigate the design\nof an ARM-based, low-power High Performance Computing (HPC) architecture with a\ndedicated interconnect scalable to million of cores; simulation of deep sleep\nSlow Wave Activity (SWA) and Asynchronous aWake (AW) regimes expressed by\nthalamo-cortical models are among their benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 14:42:10 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2018 13:16:02 GMT"}, {"version": "v3", "created": "Tue, 19 Feb 2019 15:33:39 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2019 11:18:26 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Simula", "Francesco", ""], ["Pastorelli", "Elena", ""], ["Paolucci", "Pier Stanislao", ""], ["Martinelli", "Michele", ""], ["Lonardo", "Alessandro", ""], ["Biagioni", "Andrea", ""], ["Capone", "Cristiano", ""], ["Capuani", "Fabrizio", ""], ["Cretaro", "Paolo", ""], ["De Bonis", "Giulia", ""], ["Cicero", "Francesca Lo", ""], ["Pontisso", "Luca", ""], ["Vicini", "Piero", ""], ["Ammendola", "Roberto", ""]]}, {"id": "1812.04998", "submitter": "Seyed Mostafa Kia", "authors": "Seyed Mostafa Kia, Andre F. Marquand", "title": "Neural Processes Mixed-Effect Models for Deep Normative Modeling of\n  Clinical Neuroimaging Data", "comments": "Medical Imaging with Deep Learning (MIDL 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Normative modeling has recently been introduced as a promising approach for\nmodeling variation of neuroimaging measures across individuals in order to\nderive biomarkers of psychiatric disorders. Current implementations rely on\nGaussian process regression, which provides coherent estimates of uncertainty\nneeded for the method but also suffers from drawbacks including poor scaling to\nlarge datasets and a reliance on fixed parametric kernels. In this paper, we\npropose a deep normative modeling framework based on neural processes (NPs) to\nsolve these problems. To achieve this, we define a stochastic process\nformulation for mixed-effect models and show how NPs can be adopted for\nspatially structured mixed-effect modeling of neuroimaging data. This enables\nus to learn optimal feature representations and covariance structure for the\nrandom-effect and noise via global latent variables. In this scheme, predictive\nuncertainty can be approximated by sampling from the distribution of these\nglobal latent variables. On a publicly available clinical fMRI dataset, we\ncompare the novelty detection performance of multivariate normative models\nestimated by the proposed NP approach to a baseline multi-task Gaussian process\nregression approach and show substantial improvements for certain diagnostic\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 16:02:06 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 13:18:47 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kia", "Seyed Mostafa", ""], ["Marquand", "Andre F.", ""]]}, {"id": "1812.05058", "submitter": "Mucong Ding", "authors": "Mucong Ding, Kwok Yip Szeto", "title": "Selection of Random Walkers that Optimizes the Global Mean First-Passage\n  Time for Search in Complex Networks", "comments": "5 pages, 2 figures, accepted at ICCS'17", "journal-ref": "In Procedia Computer Science 108 (2017): 2423-2427", "doi": null, "report-no": null, "categories": "physics.soc-ph cs.NE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a method to optimize the global mean first-passage time (GMFPT) of\nmultiple random walkers searching in complex networks for a general target,\nwithout specifying the property of the target node. According to the Laplace\ntransformed formula of the GMFPT, we can equivalently minimize the overlap\nbetween the probability distribution of sites visited by the random walkers. We\nemploy a mutation only genetic algorithm to solve this optimization problem\nusing a population of walkers with different starting positions and a\ncorresponding mutation matrix to modify them. The numerical experiments on two\nkinds of random networks (WS and BA) show satisfactory results in selecting the\norigins for the walkers to achieve minimum overlap. Our method thus provides\nguidance for setting up the search process by multiple random walkers on\ncomplex networks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 17:55:56 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Ding", "Mucong", ""], ["Szeto", "Kwok Yip", ""]]}, {"id": "1812.05433", "submitter": "Bert Wang-Chak Chan", "authors": "Bert Wang-Chak Chan", "title": "Lenia - Biology of Artificial Life", "comments": "49 pages, 20 figures, 7 tables; accepted by Complex Systems", "journal-ref": "Complex Systems, 2019, 28(3), 251-286", "doi": "10.25088/ComplexSystems.28.3.251", "report-no": null, "categories": "nlin.CG cs.NE nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a new system of artificial life called Lenia (from Latin lenis\n\"smooth\"), a two-dimensional cellular automaton with continuous\nspace-time-state and generalized local rule. Computer simulations show that\nLenia supports a great diversity of complex autonomous patterns or \"lifeforms\"\nbearing resemblance to real-world microscopic organisms. More than 400 species\nin 18 families have been identified, many discovered via interactive\nevolutionary computation. They differ from other cellular automata patterns in\nbeing geometric, metameric, fuzzy, resilient, adaptive, and rule-generic.\n  We present basic observations of the system regarding the properties of\nspace-time and basic settings. We provide a broad survey of the lifeforms,\ncategorize them into a hierarchical taxonomy, and map their distribution in the\nparameter hyperspace. We describe their morphological structures and behavioral\ndynamics, propose possible mechanisms of their self-propulsion,\nself-organization and plasticity. Finally, we discuss how the study of Lenia\nwould be related to biology, artificial life, and artificial intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 13:58:24 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 16:57:29 GMT"}, {"version": "v3", "created": "Sat, 4 May 2019 11:20:44 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Chan", "Bert Wang-Chak", ""]]}, {"id": "1812.05687", "submitter": "Peter Lillian", "authors": "Peter E. Lillian, Richard Meyes, Tobias Meisen", "title": "Ablation of a Robot's Brain: Neural Networks Under a Knife", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is still not fully understood exactly how neural networks are able to\nsolve the complex tasks that have recently pushed AI research forward. We\npresent a novel method for determining how information is structured inside a\nneural network. Using ablation (a neuroscience technique for cutting away parts\nof a brain to determine their function), we approach several neural network\narchitectures from a biological perspective. Through an analysis of this\nmethod's results, we examine important similarities between biological and\nartificial neural networks to search for the implicit knowledge locked away in\nthe network's weights.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2018 20:58:37 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 07:57:22 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Lillian", "Peter E.", ""], ["Meyes", "Richard", ""], ["Meisen", "Tobias", ""]]}, {"id": "1812.05815", "submitter": "Anna Bosman", "authors": "Kevin Louis de Jong and Anna Sergeevna Bosman", "title": "Unsupervised Change Detection in Satellite Images Using Convolutional\n  Neural Networks", "comments": "Paper accepted to IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an efficient unsupervised method for detecting relevant\nchanges between two temporally different images of the same scene. A\nconvolutional neural network (CNN) for semantic segmentation is implemented to\nextract compressed image features, as well as to classify the detected changes\ninto the correct semantic classes. A difference image is created using the\nfeature map information generated by the CNN, without explicitly training on\ntarget difference images. Thus, the proposed change detection method is\nunsupervised, and can be performed using any CNN model pre-trained for semantic\nsegmentation.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 08:15:15 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 10:37:16 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["de Jong", "Kevin Louis", ""], ["Bosman", "Anna Sergeevna", ""]]}, {"id": "1812.05866", "submitter": "Gerard Van Wyk", "authors": "Gerard Jacques van Wyk and Anna Sergeevna Bosman", "title": "Evolutionary Neural Architecture Search for Image Restoration", "comments": "Paper accepted to IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) architectures have traditionally been\nexplored by human experts in a manual search process that is time-consuming and\nineffectively explores the massive space of potential solutions. Neural\narchitecture search (NAS) methods automatically search the space of neural\nnetwork hyperparameters in order to find optimal task-specific architectures.\nNAS methods have discovered CNN architectures that achieve state-of-the-art\nperformance in image classification among other tasks, however the application\nof NAS to image-to-image regression problems such as image restoration is\nsparse. This paper proposes a NAS method that performs computationally\nefficient evolutionary search of a minimally constrained network architecture\nsearch space. The performance of architectures discovered by the proposed\nmethod is evaluated on a variety of image restoration tasks applied to the\nImageNet64x64 dataset, and compared with human-engineered CNN architectures.\nThe best neural architectures discovered using only 2 GPU-hours of evolutionary\nsearch exhibit comparable performance to the human-engineered baseline\narchitecture.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 11:36:09 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 12:45:12 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["van Wyk", "Gerard Jacques", ""], ["Bosman", "Anna Sergeevna", ""]]}, {"id": "1812.05979", "submitter": "Jan Leike", "authors": "Miljan Martic and Jan Leike and Andrew Trask and Matteo Hessel and\n  Shane Legg and Pushmeet Kohli", "title": "Scaling shared model governance via model splitting", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently the only techniques for sharing governance of a deep learning model\nare homomorphic encryption and secure multiparty computation. Unfortunately,\nneither of these techniques is applicable to the training of large neural\nnetworks due to their large computational and communication overheads. As a\nscalable technique for shared model governance, we propose splitting deep\nlearning model between multiple parties. This paper empirically investigates\nthe security guarantee of this technique, which is introduced as the problem of\nmodel completion: Given the entire training data set or an environment\nsimulator, and a subset of the parameters of a trained deep learning model, how\nmuch training is required to recover the model's original performance? We\ndefine a metric for evaluating the hardness of the model completion problem and\nstudy it empirically in both supervised learning on ImageNet and reinforcement\nlearning on Atari and DeepMind~Lab. Our experiments show that (1) the model\ncompletion problem is harder in reinforcement learning than in supervised\nlearning because of the unavailability of the trained agent's trajectories, and\n(2) its hardness depends not primarily on the number of parameters of the\nmissing part, but more so on their type and location. Our results suggest that\nmodel splitting might be a feasible technique for shared model governance in\nsome settings where training is very expensive.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 15:29:21 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Martic", "Miljan", ""], ["Leike", "Jan", ""], ["Trask", "Andrew", ""], ["Hessel", "Matteo", ""], ["Legg", "Shane", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1812.06247", "submitter": "Hock Hung Chieng", "authors": "Hock Hung Chieng, Noorhaniza Wahid, Pauline Ong and Sai Raj Kishore\n  Perla", "title": "Flatten-T Swish: a thresholded ReLU-Swish-like activation function for\n  deep learning", "comments": null, "journal-ref": "International Journal of Advances in Intelligent Informatics,\n  4(2), 76-86", "doi": "10.26555/ijain.v4i2.249", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Activation functions are essential for deep learning methods to learn and\nperform complex tasks such as image classification. Rectified Linear Unit\n(ReLU) has been widely used and become the default activation function across\nthe deep learning community since 2012. Although ReLU has been popular,\nhowever, the hard zero property of the ReLU has heavily hindered the negative\nvalues from propagating through the network. Consequently, the deep neural\nnetwork has not been benefited from the negative representations. In this work,\nan activation function called Flatten-T Swish (FTS) that leverage the benefit\nof the negative values is proposed. To verify its performance, this study\nevaluates FTS with ReLU and several recent activation functions. Each\nactivation function is trained using MNIST dataset on five different deep fully\nconnected neural networks (DFNNs) with depth vary from five to eight layers.\nFor a fair evaluation, all DFNNs are using the same configuration settings.\nBased on the experimental results, FTS with a threshold value, T=-0.20 has the\nbest overall performance. As compared with ReLU, FTS (T=-0.20) improves MNIST\nclassification accuracy by 0.13%, 0.70%, 0.67%, 1.07% and 1.15% on wider 5\nlayers, slimmer 5 layers, 6 layers, 7 layers and 8 layers DFNNs respectively.\nApart from this, the study also noticed that FTS converges twice as fast as\nReLU. Although there are other existing activation functions are also\nevaluated, this study elects ReLU as the baseline activation function.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 07:02:44 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Chieng", "Hock Hung", ""], ["Wahid", "Noorhaniza", ""], ["Ong", "Pauline", ""], ["Perla", "Sai Raj Kishore", ""]]}, {"id": "1812.06300", "submitter": "Patrick Spettel", "authors": "Patrick Spettel and Hans-Georg Beyer", "title": "Analysis of the $(\\mu/\\mu_I,\\lambda)$-$\\sigma$-Self-Adaptation Evolution\n  Strategy with Repair by Projection Applied to a Conically Constrained Problem", "comments": "This is a PREPRINT of an article submitted to IEEE Transactions On\n  Evolutionary Computation. It is currently under review. Due to size\n  limitations, this manuscript comprises figures with reduced resolution. 10\n  pages + supplementary material. Copyright 2018 IEEE. The work was supported\n  by the Austrian Science Fund FWF under grant P29651-N32", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A theoretical performance analysis of the\n$(\\mu/\\mu_I,\\lambda)$-$\\sigma$-Self-Adaptation Evolution Strategy\n($\\sigma$SA-ES) is presented considering a conically constrained problem.\nInfeasible offspring are repaired using projection onto the boundary of the\nfeasibility region. Closed-form approximations are used for the one-generation\nprogress of the evolution strategy. Approximate deterministic evolution\nequations are formulated for analyzing the strategy's dynamics. By iterating\nthe evolution equations with the approximate one-generation expressions, the\nevolution strategy's dynamics can be predicted. The derived theoretical results\nare compared to experiments for assessing the approximation quality. It is\nshown that in the steady state the $(\\mu/\\mu_I,\\lambda)$-$\\sigma$SA-ES exhibits\na performance as if the ES were optimizing a sphere model. Unlike the\nnon-recombinative $(1,\\lambda)$-ES, the parental steady state behavior does not\nevolve on the cone boundary but stays away from the boundary to a certain\nextent.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 14:48:40 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Spettel", "Patrick", ""], ["Beyer", "Hans-Georg", ""]]}, {"id": "1812.06303", "submitter": "Dongrui Wu", "authors": "Dongrui Wu and Xianfeng Tan", "title": "Multi-Tasking Genetic Algorithm (MTGA) for Fuzzy System Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning uses auxiliary data or knowledge from relevant tasks to\nfacilitate the learning in a new task. Multi-task optimization applies\nmulti-task learning to optimization to study how to effectively and efficiently\ntackle multiple optimization problems simultaneously. Evolutionary\nmulti-tasking, or multi-factorial optimization, is an emerging subfield of\nmulti-task optimization, which integrates evolutionary computation and\nmulti-task learning. This paper proposes a novel and easy-to-implement\nmulti-tasking genetic algorithm (MTGA), which copes well with significantly\ndifferent optimization tasks by estimating and using the bias among them.\nComparative studies with eight state-of-the-art single- and multi-task\napproaches in the literature on nine benchmarks demonstrated that on average\nthe MTGA outperformed all of them, and had lower computational cost than six of\nthem. Based on the MTGA, a simultaneous optimization strategy for fuzzy system\ndesign is also proposed. Experiments on simultaneous optimization of type-1 and\ninterval type-2 fuzzy logic controllers for couple-tank water level control\ndemonstrated that the MTGA can find better fuzzy logic controllers than other\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 15:07:55 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 11:30:15 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Wu", "Dongrui", ""], ["Tan", "Xianfeng", ""]]}, {"id": "1812.06381", "submitter": "Wenji Li", "authors": "Zhun Fan, Wenji Li, Zhaojun Wang, Yutong Yuan, Fuzan Sun, Zhi Yang,\n  Jie Ruan, Zhaocheng Li and Erik Goodman", "title": "Embedding Push and Pull Search in the Framework of Differential\n  Evolution for Solving Constrained Single-objective Optimization Problems", "comments": "11 pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a push and pull search method in the framework of\ndifferential evolution (PPS-DE) to solve constrained single-objective\noptimization problems (CSOPs). More specifically, two sub-populations,\nincluding the top and bottom sub-populations, are collaborated with each other\nto search global optimal solutions efficiently. The top sub-population adopts\nthe pull and pull search (PPS) mechanism to deal with constraints, while the\nbottom sub-population use the superiority of feasible solutions (SF) technique\nto deal with constraints. In the top sub-population, the search process is\ndivided into two different stages --- push and pull stages.An adaptive DE\nvariant with three trial vector generation strategies is employed in the\nproposed PPS-DE. In the top sub-population, all the three trial vector\ngeneration strategies are used to generate offsprings, just like in CoDE. In\nthe bottom sub-population, a strategy adaptation, in which the trial vector\ngeneration strategies are periodically self-adapted by learning from their\nexperiences in generating promising solutions in the top sub-population, is\nused to choose a suitable trial vector generation strategy to generate one\noffspring. Furthermore, a parameter adaptation strategy from LSHADE44 is\nemployed in both sup-populations to generate scale factor $F$ and crossover\nrate $CR$ for each trial vector generation strategy. Twenty-eight CSOPs with\n10-, 30-, and 50-dimensional decision variables provided in the CEC2018\ncompetition on real parameter single objective optimization are optimized by\nthe proposed PPS-DE. The experimental results demonstrate that the proposed\nPPS-DE has the best performance compared with the other seven state-of-the-art\nalgorithms, including AGA-PPS, LSHADE44, LSHADE44+IDE, UDE, IUDE,\n$\\epsilon$MAg-ES and C$^2$oDE.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 02:52:31 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Fan", "Zhun", ""], ["Li", "Wenji", ""], ["Wang", "Zhaojun", ""], ["Yuan", "Yutong", ""], ["Sun", "Fuzan", ""], ["Yang", "Zhi", ""], ["Ruan", "Jie", ""], ["Li", "Zhaocheng", ""], ["Goodman", "Erik", ""]]}, {"id": "1812.06426", "submitter": "Guangli Li", "authors": "Guangli Li, Lei Liu, Xueying Wang, Xiao Dong, Peng Zhao, Xiaobing Feng", "title": "Auto-tuning Neural Network Quantization Framework for Collaborative\n  Inference Between the Cloud and Edge", "comments": "Published at ICANN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks (DNNs) have been widely applied in mobile\nintelligent applications. The inference for the DNNs is usually performed in\nthe cloud. However, it leads to a large overhead of transmitting data via\nwireless network. In this paper, we demonstrate the advantages of the\ncloud-edge collaborative inference with quantization. By analyzing the\ncharacteristics of layers in DNNs, an auto-tuning neural network quantization\nframework for collaborative inference is proposed. We study the effectiveness\nof mixed-precision collaborative inference of state-of-the-art DNNs by using\nImageNet dataset. The experimental results show that our framework can generate\nreasonable network partitions and reduce the storage on mobile devices with\ntrivial loss of accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 09:05:44 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Li", "Guangli", ""], ["Liu", "Lei", ""], ["Wang", "Xueying", ""], ["Dong", "Xiao", ""], ["Zhao", "Peng", ""], ["Feng", "Xiaobing", ""]]}, {"id": "1812.06474", "submitter": "Victor Sanchez-Anguix Dr.", "authors": "Victor Sanchez-Anguix, Rithin Chalumuri, Reyhan Aydogan, Vicente\n  Julian", "title": "A near Pareto optimal approach to student-supervisor allocation with two\n  sided preferences and workload balance", "comments": null, "journal-ref": "Applied Soft Computing, 2018", "doi": "10.1016/j.asoc.2018.11.049", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of allocating students to supervisors for the development of a\npersonal project or a dissertation is a crucial activity in the higher\neducation environment, as it enables students to get feedback on their work\nfrom an expert and improve their personal, academic, and professional\nabilities. In this article, we propose a multi-objective and near Pareto\noptimal genetic algorithm for the allocation of students to supervisors. The\nallocation takes into consideration the students and supervisors' preferences\non research/project topics, the lower and upper supervision quotas of\nsupervisors, as well as the workload balance amongst supervisors. We introduce\nnovel mutation and crossover operators for the student-supervisor allocation\nproblem. The experiments carried out show that the components of the genetic\nalgorithm are more apt for the problem than classic components, and that the\ngenetic algorithm is capable of producing allocations that are near Pareto\noptimal in a reasonable time.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2018 15:01:55 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Sanchez-Anguix", "Victor", ""], ["Chalumuri", "Rithin", ""], ["Aydogan", "Reyhan", ""], ["Julian", "Vicente", ""]]}, {"id": "1812.06488", "submitter": "Theodore Moskovitz", "authors": "Theodore H. Moskovitz, Ashok Litwin-Kumar, L.F. Abbott", "title": "Feedback alignment in deep convolutional networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ongoing studies have identified similarities between neural representations\nin biological networks and in deep artificial neural networks. This has led to\nrenewed interest in developing analogies between the backpropagation learning\nalgorithm used to train artificial networks and the synaptic plasticity rules\noperative in the brain. These efforts are challenged by biologically\nimplausible features of backpropagation, one of which is a reliance on\nsymmetric forward and backward synaptic weights. A number of methods have been\nproposed that do not rely on weight symmetry but, thus far, these have failed\nto scale to deep convolutional networks and complex data. We identify principal\nobstacles to the scalability of such algorithms and introduce several\ntechniques to mitigate them. We demonstrate that a modification of the feedback\nalignment method that enforces a weaker form of weight symmetry, one that\nrequires agreement of weight sign but not magnitude, can achieve performance\ncompetitive with backpropagation. Our results complement those of Bartunov et\nal. (2018) and Xiao et al. (2018b) and suggest that mechanisms that promote\nalignment of feedforward and feedback weights are critical for learning in deep\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 22:12:53 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 04:19:00 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Moskovitz", "Theodore H.", ""], ["Litwin-Kumar", "Ashok", ""], ["Abbott", "L. F.", ""]]}, {"id": "1812.06574", "submitter": "Yunzhe Hao", "authors": "Yunzhe Hao, Xuhui Huang, Meng Dong, Bo Xu", "title": "A Biologically Plausible Supervised Learning Method for Spiking Neural\n  Networks Using the Symmetric STDP Rule", "comments": "29 pages, 6 figures", "journal-ref": "Neural Networks 121C (2020) pp. 387-395", "doi": "10.1016/j.neunet.2019.09.007", "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) possess energy-efficient potential due to\nevent-based computation. However, supervised training of SNNs remains a\nchallenge as spike activities are non-differentiable. Previous SNNs training\nmethods can be generally categorized into two basic classes, i.e.,\nbackpropagation-like training methods and plasticity-based learning methods.\nThe former methods are dependent on energy-inefficient real-valued computation\nand non-local transmission, as also required in artificial neural networks\n(ANNs), whereas the latter are either considered to be biologically implausible\nor exhibit poor performance. Hence, biologically plausible (bio-plausible)\nhigh-performance supervised learning (SL) methods for SNNs remain deficient. In\nthis paper, we proposed a novel bio-plausible SNN model for SL based on the\nsymmetric spike-timing dependent plasticity (sym-STDP) rule found in\nneuroscience. By combining the sym-STDP rule with bio-plausible synaptic\nscaling and intrinsic plasticity of the dynamic threshold, our SNN model\nimplemented SL well and achieved good performance in the benchmark recognition\ntask (MNIST dataset). To reveal the underlying mechanism of our SL model, we\nvisualized both layer-based activities and synaptic weights using the\nt-distributed stochastic neighbor embedding (t-SNE) method after training and\nfound that they were well clustered, thereby demonstrating excellent\nclassification ability. Furthermore, to verify the robustness of our model, we\ntrained it on another more realistic dataset (Fashion-MNIST), which also showed\ngood performance. As the learning rules were bio-plausible and based purely on\nlocal spike events, our model could be easily applied to neuromorphic hardware\nfor online training and may be helpful for understanding SL information\nprocessing at the synaptic level in biological neural systems.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 01:38:14 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 03:33:43 GMT"}, {"version": "v3", "created": "Sun, 6 Oct 2019 09:27:27 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Hao", "Yunzhe", ""], ["Huang", "Xuhui", ""], ["Dong", "Meng", ""], ["Xu", "Bo", ""]]}, {"id": "1812.06585", "submitter": "Mingde Zhao", "authors": "Mingde Zhao and Hongwei Ge and Yi Lian and Kai Zhang", "title": "Generalizable Meta-Heuristic based on Temporal Estimation of Rewards for\n  Large Scale Blackbox Optimization", "comments": "7 pages of contents, 1 page of references, 2 pages for appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization abilities of heuristic optimizers may deteriorate with the\nincrement of the search space dimensionality. To achieve generalized\nperformance across Large Scale Blackbox Optimization (LSBO) tasks, it\nispossible to ensemble several heuristics and devise a meta-heuristic to\ncontrol their initiation. This paper first proposes a methodology of\ntransforming LSBO problems into online decision processes to maximize\nefficiency of resource utilization. Then, using the perspective of multi-armed\nbandits with non-stationary reward distributions, we propose a meta-heuristic\nbased on Temporal Estimation of Rewards (TER) to address such decision process.\nTER uses a window for temporal credit assignment and Boltzmann exploration to\nbalance the exploration-exploitation tradeoff. The prior-free TER generalizes\nacross LSBO tasks with flexibility for different types of limited computational\nresources (e.g. time, money, etc.) and is easy to be adapted to new tasks for\nits simplicity and easy interface for heuristic articulation. Tests on the\nbenchmarks validate the problem formulation and suggest significant\neffectiveness: when TER is articulated with three heuristics, competitive\nperformance is reported across different sets of benchmark problems with search\ndimensions up to 10000.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 02:36:26 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 16:03:08 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Zhao", "Mingde", ""], ["Ge", "Hongwei", ""], ["Lian", "Yi", ""], ["Zhang", "Kai", ""]]}, {"id": "1812.07019", "submitter": "Joel Leibo", "authors": "Joel Z. Leibo, Julien Perolat, Edward Hughes, Steven Wheelwright, Adam\n  H. Marblestone, Edgar Du\\'e\\~nez-Guzm\\'an, Peter Sunehag, Iain Dunning, Thore\n  Graepel", "title": "Malthusian Reinforcement Learning", "comments": "9 pages, 2 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we explore a new algorithmic framework for multi-agent reinforcement\nlearning, called Malthusian reinforcement learning, which extends self-play to\ninclude fitness-linked population size dynamics that drive ongoing innovation.\nIn Malthusian RL, increases in a subpopulation's average return drive\nsubsequent increases in its size, just as Thomas Malthus argued in 1798 was the\nrelationship between preindustrial income levels and population growth.\nMalthusian reinforcement learning harnesses the competitive pressures arising\nfrom growing and shrinking population size to drive agents to explore regions\nof state and policy spaces that they could not otherwise reach. Furthermore, in\nenvironments where there are potential gains from specialization and division\nof labor, we show that Malthusian reinforcement learning is better positioned\nto take advantage of such synergies than algorithms based on self-play.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 19:36:14 GMT"}, {"version": "v2", "created": "Sun, 3 Mar 2019 14:58:43 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Leibo", "Joel Z.", ""], ["Perolat", "Julien", ""], ["Hughes", "Edward", ""], ["Wheelwright", "Steven", ""], ["Marblestone", "Adam H.", ""], ["Du\u00e9\u00f1ez-Guzm\u00e1n", "Edgar", ""], ["Sunehag", "Peter", ""], ["Dunning", "Iain", ""], ["Graepel", "Thore", ""]]}, {"id": "1812.07040", "submitter": "Stanis{\\l}aw Wo\\'zniak", "authors": "Stanis{\\l}aw Wo\\'zniak, Angeliki Pantazi, Thomas Bohnstingl, Evangelos\n  Eleftheriou", "title": "Deep learning incorporating biologically-inspired neural dynamics", "comments": null, "journal-ref": "Nat Mach Intell 2, 325-336 (2020)", "doi": "10.1038/s42256-020-0187-0", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become the key technology of artificial intelligence and\nhave contributed to breakthroughs in several machine learning tasks, primarily\nowing to advances in deep learning applied to Artificial Neural Networks\n(ANNs). Simultaneously, Spiking Neural Networks (SNNs) incorporating\nbiologically-feasible spiking neurons have held great promise because of their\nrich temporal dynamics and high-power efficiency. However, the developments in\nSNNs were proceeding separately from those in ANNs, effectively limiting the\nadoption of deep learning research insights. Here we show an alternative\nperspective on the spiking neuron that casts it as a particular ANN construct\ncalled Spiking Neural Unit (SNU), and a soft SNU (sSNU) variant that\ngeneralizes its dynamics to a novel recurrent ANN unit. SNUs bridge the\nbiologically-inspired SNNs with ANNs and provide a methodology for seamless\ninclusion of spiking neurons in deep learning architectures. Furthermore, SNU\nenables highly-efficient in-memory acceleration of SNNs trained with\nbackpropagation through time, implemented with the hardware in-the-loop. We\napply SNUs to tasks ranging from hand-written digit recognition, language\nmodelling, to music prediction. We obtain accuracy comparable to, or better\nthan, that of state-of-the-art ANNs, and we experimentally verify the efficacy\nof the in-memory-based SNN realization for the music-prediction task using\n52,800 phase-change memory devices. The new generation of neural units\nintroduced in this paper incorporate biologically-inspired neural dynamics in\ndeep learning. In addition, they provide a systematic methodology for training\nneuromorphic computing hardware. Thus, they open a new avenue for a widespread\nadoption of SNNs in practical applications.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 20:32:06 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 08:16:52 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Wo\u017aniak", "Stanis\u0142aw", ""], ["Pantazi", "Angeliki", ""], ["Bohnstingl", "Thomas", ""], ["Eleftheriou", "Evangelos", ""]]}, {"id": "1812.07069", "submitter": "Joel Lehman", "authors": "Felipe Petroski Such, Vashisht Madhavan, Rosanne Liu, Rui Wang, Pablo\n  Samuel Castro, Yulun Li, Jiale Zhi, Ludwig Schubert, Marc G. Bellemare, Jeff\n  Clune, Joel Lehman", "title": "An Atari Model Zoo for Analyzing, Visualizing, and Comparing Deep\n  Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much human and computational effort has aimed to improve how deep\nreinforcement learning algorithms perform on benchmarks such as the Atari\nLearning Environment. Comparatively less effort has focused on understanding\nwhat has been learned by such methods, and investigating and comparing the\nrepresentations learned by different families of reinforcement learning (RL)\nalgorithms. Sources of friction include the onerous computational requirements,\nand general logistical and architectural complications for running Deep RL\nalgorithms at scale. We lessen this friction, by (1) training several\nalgorithms at scale and releasing trained models, (2) integrating with a\nprevious Deep RL model release, and (3) releasing code that makes it easy for\nanyone to load, visualize, and analyze such models. This paper introduces the\nAtari Zoo framework, which contains models trained across benchmark Atari\ngames, in an easy-to-use format, as well as code that implements common modes\nof analysis and connects such models to a popular neural network visualization\nlibrary. Further, to demonstrate the potential of this dataset and software\npackage, we show initial quantitative and qualitative comparisons between the\nperformance and representations of several deep RL algorithms, highlighting\ninteresting and previously unknown distinctions between them.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 21:53:38 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 20:45:27 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Such", "Felipe Petroski", ""], ["Madhavan", "Vashisht", ""], ["Liu", "Rosanne", ""], ["Wang", "Rui", ""], ["Castro", "Pablo Samuel", ""], ["Li", "Yulun", ""], ["Zhi", "Jiale", ""], ["Schubert", "Ludwig", ""], ["Bellemare", "Marc G.", ""], ["Clune", "Jeff", ""], ["Lehman", "Joel", ""]]}, {"id": "1812.07248", "submitter": "Rasmus Berg Palm", "authors": "Rasmus Berg Palm, Florian Laws, Ole Winther", "title": "Attend, Copy, Parse -- End-to-end information extraction from documents", "comments": null, "journal-ref": "ICDAR 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document information extraction tasks performed by humans create data\nconsisting of a PDF or document image input, and extracted string outputs. This\nend-to-end data is naturally consumed and produced when performing the task\nbecause it is valuable in and of itself. It is naturally available, at no\nadditional cost. Unfortunately, state-of-the-art word classification methods\nfor information extraction cannot use this data, instead requiring word-level\nlabels which are expensive to create and consequently not available for many\nreal life tasks. In this paper we propose the Attend, Copy, Parse architecture,\na deep neural network model that can be trained directly on end-to-end data,\nbypassing the need for word-level labels. We evaluate the proposed architecture\non a large diverse set of invoices, and outperform a state-of-the-art\nproduction system based on word classification. We believe our proposed\narchitecture can be used on many real life information extraction tasks where\nword classification cannot be used due to a lack of the required word-level\nlabels.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 09:05:53 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 13:40:42 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 07:03:05 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Palm", "Rasmus Berg", ""], ["Laws", "Florian", ""], ["Winther", "Ole", ""]]}, {"id": "1812.07520", "submitter": "Wojciech Samek", "authors": "Simon Wiedemann, Arturo Marban, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Entropy-Constrained Training of Deep Neural Networks", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for neural network compression that is\nmotivated by the Minimum Description Length (MDL) principle. For that we first\nderive an expression for the entropy of a neural network, which measures its\ncomplexity explicitly in terms of its bit-size. Then, we formalize the problem\nof neural network compression as an entropy-constrained optimization objective.\nThis objective generalizes many of the compression techniques proposed in the\nliterature, in that pruning or reducing the cardinality of the weight elements\nof the network can be seen special cases of entropy-minimization techniques.\nFurthermore, we derive a continuous relaxation of the objective, which allows\nus to minimize it using gradient based optimization techniques. Finally, we\nshow that we can reach state-of-the-art compression results on different\nnetwork architectures and data sets, e.g. achieving x71 compression gains on a\nVGG-like architecture.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 17:36:22 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 13:14:50 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Wiedemann", "Simon", ""], ["Marban", "Arturo", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1812.07608", "submitter": "Haozhen Dong", "authors": "Haozhen Dong, Liang Gao, Xinyu Li, Haoran Zhong, Bing Zeng", "title": "Differential Evolution with Better and Nearest Option for Function\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential evolution(DE) is a conventional algorithm with fast convergence\nspeed. However, DE may be trapped in local optimal solution easily. Many\nresearchers devote themselves to improving DE. In our previously work, whale\nswarm algorithm have shown its strong searching performance due to its niching\nbased mutation strategy. Based on this fact, we propose a new DE algorithm\ncalled DE with Better and Nearest option (NbDE). In order to evaluate the\nperformance of NbDE, NbDE is compared with several meta-heuristic algorithms on\nnine classical benchmark test functions with different dimensions. The results\nshow that NbDE outperforms other algorithms in convergence speed and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 02:52:02 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 00:47:46 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Dong", "Haozhen", ""], ["Gao", "Liang", ""], ["Li", "Xinyu", ""], ["Zhong", "Haoran", ""], ["Zeng", "Bing", ""]]}, {"id": "1812.07609", "submitter": "Mohammad Samavatian", "authors": "Mohammad Hossein Samavatian, Anys Bacha, Li Zhou, Radu Teodorescu", "title": "RNNFast: An Accelerator for Recurrent Neural Networks Using Domain Wall\n  Memory", "comments": "26 pages", "journal-ref": "JETC January 2020 Volume 1 26 pages", "doi": "10.1145/3399670", "report-no": null, "categories": "cs.NE cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are an important class of neural networks\ndesigned to retain and incorporate context into current decisions. RNNs are\nparticularly well suited for machine learning problems in which context is\nimportant, such as speech recognition and language translation. This work\npresents RNNFast, a hardware accelerator for RNNs that leverages an emerging\nclass of non-volatile memory called domain-wall memory (DWM). We show that DWM\nis very well suited for RNN acceleration due to its very high density and low\nread/write energy. At the same time, the sequential nature of input/weight\nprocessing of RNNs mitigates one of the downsides of DWM, which is the linear\n(rather than constant) data access time.RNNFast is very efficient and highly\nscalable, with flexible mapping of logical neurons to RNN hardware blocks. The\nbasic hardware primitive, the RNN processing element (PE) includes custom\nDWM-based multiplication, sigmoid and tanh units for high density and\nlow-energy. The accelerator is designed to minimize data movement by closely\ninterleaving DWM storage and computation. We compare our design with a\nstate-of-the-art GPGPU and find21.8x higher performance with70x lower energy\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 18:14:50 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 01:04:04 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Samavatian", "Mohammad Hossein", ""], ["Bacha", "Anys", ""], ["Zhou", "Li", ""], ["Teodorescu", "Radu", ""]]}, {"id": "1812.07611", "submitter": "Yiheng Zhu", "authors": "Yiheng Zhu, Yichen Yao, Zili Wu, Yujie Chen, Guozheng Li, Haoyuan Hu,\n  Yinghui Xu", "title": "GP-CNAS: Convolutional Neural Network Architecture Search with Genetic\n  Programming", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are effective at solving difficult\nproblems like visual recognition, speech recognition and natural language\nprocessing. However, performance gain comes at the cost of laborious\ntrial-and-error in designing deeper CNN architectures. In this paper, a genetic\nprogramming (GP) framework for convolutional neural network architecture\nsearch, abbreviated as GP-CNAS, is proposed to automatically search for optimal\nCNN architectures. GP-CNAS encodes CNNs as trees where leaf nodes (GP\nterminals) are selected residual blocks and non-leaf nodes (GP functions)\nspecify the block assembling procedure. Our tree-based representation enables\neasy design and flexible implementation of genetic operators. Specifically, we\ndesign a dynamic crossover operator that strikes a balance between exploration\nand exploitation, which emphasizes CNN complexity at early stage and CNN\ndiversity at later stage. Therefore, the desired CNN architecture with balanced\ndepth and width can be found within limited trials. Moreover, our GP-CNAS\nframework is highly compatible with other manually-designed and NAS-generated\nblock types as well. Experimental results on the CIFAR-10 dataset show that\nGP-CNAS is competitive among the state-of-the-art automatic and semi-automatic\nNAS algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:44:15 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Zhu", "Yiheng", ""], ["Yao", "Yichen", ""], ["Wu", "Zili", ""], ["Chen", "Yujie", ""], ["Li", "Guozheng", ""], ["Hu", "Haoyuan", ""], ["Xu", "Yinghui", ""]]}, {"id": "1812.07965", "submitter": "Yali Amit", "authors": "Yali Amit", "title": "Deep learning with asymmetric connections and Hebbian updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that deep networks can be trained using Hebbian updates yielding\nsimilar performance to ordinary back-propagation on challenging image datasets.\nTo overcome the unrealistic symmetry in connections between layers, implicit in\nback-propagation, the feedback weights are separate from the feedforward\nweights. The feedback weights are also updated with a local rule, the same as\nthe feedforward weights - a weight is updated solely based on the product of\nactivity of the units it connects. With fixed feedback weights as proposed in\nLillicrap et. al (2016) performance degrades quickly as the depth of the\nnetwork increases. If the feedforward and feedback weights are initialized with\nthe same values, as proposed in Zipser and Rumelhart (1990), they remain the\nsame throughout training thus precisely implementing back-propagation. We show\nthat even when the weights are initialized differently and at random, and the\nalgorithm is no longer performing back-propagation, performance is comparable\non challenging datasets. We also propose a cost function whose derivative can\nbe represented as a local Hebbian update on the last layer. Convolutional\nlayers are updated with tied weights across space, which is not biologically\nplausible. We show that similar performance is achieved with untied layers,\nalso known as locally connected layers, corresponding to the connectivity\nimplied by the convolutional layers, but where weights are untied and updated\nseparately. In the linear case we show theoretically that the convergence of\nthe error to zero is accelerated by the update of the feedback weights.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 20:40:29 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 21:05:57 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Amit", "Yali", ""]]}, {"id": "1812.08252", "submitter": "Richard Preen", "authors": "Richard J. Preen, Larry Bull, Andrew Adamatzky", "title": "Towards an Evolvable Cancer Treatment Simulator", "comments": null, "journal-ref": "BioSystems (2019), 182:1-7", "doi": "10.1016/j.biosystems.2019.05.005", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of high-fidelity computational simulations promises to enable\nhigh-throughput hypothesis testing and optimisation of cancer therapies.\nHowever, increasing realism comes at the cost of increasing computational\nrequirements. This article explores the use of surrogate-assisted evolutionary\nalgorithms to optimise the targeted delivery of a therapeutic compound to\ncancerous tumour cells with the multicellular simulator, PhysiCell. The use of\nboth Gaussian process models and multi-layer perceptron neural network\nsurrogate models are investigated. We find that evolutionary algorithms are\nable to effectively explore the parameter space of biophysical properties\nwithin the agent-based simulations, minimising the resulting number of\ncancerous cells after a period of simulated treatment. Both model-assisted\nalgorithms are found to outperform a standard evolutionary algorithm,\ndemonstrating their ability to perform a more effective search within the very\nsmall evaluation budget. This represents the first use of efficient\nevolutionary algorithms within a high-throughput multicellular computing\napproach to find therapeutic design optima that maximise tumour regression.\n", "versions": [{"version": "v1", "created": "Wed, 19 Dec 2018 21:28:15 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 15:05:02 GMT"}, {"version": "v3", "created": "Tue, 14 May 2019 16:06:46 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""], ["Adamatzky", "Andrew", ""]]}, {"id": "1812.08338", "submitter": "Torsten Asselmeyer-Maluga", "authors": "Torsten Asselmeyer-Maluga", "title": "Quantum computing and the brain: quantum nets, dessins d'enfants and\n  neural networks", "comments": "17 pages, 3 Figures, accepted for the proceedings of the QTech 2018\n  conference (September 2018, Paris)", "journal-ref": null, "doi": "10.1051/epjconf/201919800014", "report-no": null, "categories": "quant-ph cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we will discuss a formal link between neural networks and\nquantum computing. For that purpose we will present a simple model for the\ndescription of the neural network by forming sub-graphs of the whole network\nwith the same or a similar state. We will describe the interaction between\nthese areas by closed loops, the feedback loops. The change of the graph is\ngiven by the deformations of the loops. This fact can be mathematically\nformalized by the fundamental group of the graph. Furthermore the neuron has\ntwo basic states $|0\\rangle$ (ground state) and $|1\\rangle$ (excited state).\nThe whole state of an area of neurons is the linear combination of the two\nbasic state with complex coefficients representing the signals (with 3\nParameters: amplitude, frequency and phase) along the neurons. Then it can be\nshown that the set of all signals forms a manifold (character variety) and all\nproperties of the network must be encoded in this manifold. In the paper, we\nwill discuss how to interpret learning and intuition in this model. Using the\nMorgan-Shalen compactification, the limit for signals with large amplitude can\nbe analyzed by using quasi-Fuchsian groups as represented by dessins d'enfants\n(graphs to analyze Riemannian surfaces). As shown by Planat and collaborators,\nthese dessins d'enfants are a direct bridge to (topological) quantum computing\nwith permutation groups. The normalization of the signal reduces to the group\n$SU(2)$ and the whole model to a quantum network. Then we have a direct\nconnection to quantum circuits. This network can be transformed into operations\non tensor networks. Formally we will obtain a link between machine learning and\nQuantum computing.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 14:11:24 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Asselmeyer-Maluga", "Torsten", ""]]}, {"id": "1812.08480", "submitter": "Carola Doerr", "authors": "Peyman Afshani, Manindra Agrawal, Benjamin Doerr, Carola Doerr, Kasper\n  Green Larsen, Kurt Mehlhorn", "title": "The Query Complexity of a Permutation-Based Variant of Mastermind", "comments": "Full version of a result previously announced in 2013. Accepted\n  subject to minor revision at Discrete Applied Mathematics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the query complexity of a permutation-based variant of the guessing\ngame Mastermind. In this variant, the secret is a pair $(z,\\pi)$ which consists\nof a binary string $z \\in \\{0,1\\}^n$ and a permutation $\\pi$ of $[n]$. The\nsecret must be unveiled by asking queries of the form $x \\in \\{0,1\\}^n$. For\neach such query, we are returned the score \\[ f_{z,\\pi}(x):= \\max \\{ i \\in\n[0..n]\\mid \\forall j \\leq i: z_{\\pi(j)} = x_{\\pi(j)}\\}\\,;\\] i.e., the score of\n$x$ is the length of the longest common prefix of $x$ and $z$ with respect to\nthe order imposed by $\\pi$. The goal is to minimize the number of queries\nneeded to identify $(z,\\pi)$. This problem originates from the study of\nblack-box optimization heuristics, where it is known as the\n\\textsc{LeadingOnes} problem.\n  In this work, we prove matching upper and lower bounds for the deterministic\nand randomized query complexity of this game, which are $\\Theta(n \\log n)$ and\n$\\Theta(n \\log \\log n)$, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 11:00:59 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Afshani", "Peyman", ""], ["Agrawal", "Manindra", ""], ["Doerr", "Benjamin", ""], ["Doerr", "Carola", ""], ["Larsen", "Kasper Green", ""], ["Mehlhorn", "Kurt", ""]]}, {"id": "1812.08655", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Danial Azam, Arpit Kapoor, R. Dietmar M\\\"uller", "title": "Surrogate-assisted Bayesian inversion for landscape and basin evolution\n  models", "comments": "Geoscientific Model Development", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NE physics.geo-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The complex and computationally expensive nature of landscape evolution\nmodels pose significant challenges in the inference and optimisation of unknown\nparameters. Bayesian inference provides a methodology for estimation and\nuncertainty quantification of unknown model parameters. In our previous work,\nwe developed parallel tempering Bayeslands as a framework for parameter\nestimation and uncertainty quantification for the Badlands landscape evolution\nmodel. Parallel tempering Bayeslands features high-performance computing with\ndozens of processing cores running in parallel to enhance computational\nefficiency. Although we use parallel computing, the procedure remains\ncomputationally challenging since thousands of samples need to be drawn and\nevaluated. \\textcolor{black}{In large-scale landscape and basin evolution\nproblems, a single model evaluation can take from several minutes to hours, and\nin some instances, even days. Surrogate-assisted optimisation has been used for\nseveral computationally expensive engineering problems which motivate its use\nin optimisation and inference of complex geoscientific models.} The use of\nsurrogate models can speed up parallel tempering Bayeslands by developing\ncomputationally inexpensive models to mimic expensive ones. In this paper, we\napply surrogate-assisted parallel tempering where that surrogate mimics a\nlandscape evolution model by estimating the likelihood function from the model.\n\\textcolor{black}{We employ a neural network-based surrogate model that learns\nfrom the history of samples generated. } The entire framework is developed in a\nparallel computing infrastructure to take advantage of parallelism. The results\nshow that the proposed methodology is effective in lowering the overall\ncomputational cost significantly while retaining the quality of solutions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 03:56:20 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 09:51:22 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 13:05:43 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Chandra", "Rohitash", ""], ["Azam", "Danial", ""], ["Kapoor", "Arpit", ""], ["M\u00fcller", "R. Dietmar", ""]]}, {"id": "1812.08934", "submitter": "Xiaoliang Dai", "authors": "Xiaoliang Dai, Peizhao Zhang, Bichen Wu, Hongxu Yin, Fei Sun, Yanghan\n  Wang, Marat Dukhan, Yunqing Hu, Yiming Wu, Yangqing Jia, Peter Vajda, Matt\n  Uyttendaele, Niraj K. Jha", "title": "ChamNet: Towards Efficient Network Design through Platform-Aware Model\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an efficient neural network (NN) architecture design\nmethodology called Chameleon that honors given resource constraints. Instead of\ndeveloping new building blocks or using computationally-intensive reinforcement\nlearning algorithms, our approach leverages existing efficient network building\nblocks and focuses on exploiting hardware traits and adapting computation\nresources to fit target latency and/or energy constraints. We formulate\nplatform-aware NN architecture search in an optimization framework and propose\na novel algorithm to search for optimal architectures aided by efficient\naccuracy and resource (latency and/or energy) predictors. At the core of our\nalgorithm lies an accuracy predictor built atop Gaussian Process with Bayesian\noptimization for iterative sampling. With a one-time building cost for the\npredictors, our algorithm produces state-of-the-art model architectures on\ndifferent platforms under given constraints in just minutes. Our results show\nthat adapting computation resources to building blocks is critical to model\nperformance. Without the addition of any bells and whistles, our models achieve\nsignificant accuracy improvements against state-of-the-art hand-crafted and\nautomatically designed architectures. We achieve 73.8% and 75.3% top-1 accuracy\non ImageNet at 20ms latency on a mobile CPU and DSP. At reduced latency, our\nmodels achieve up to 8.5% (4.8%) and 6.6% (9.3%) absolute top-1 accuracy\nimprovements compared to MobileNetV2 and MnasNet, respectively, on a mobile CPU\n(DSP), and 2.7% (4.6%) and 5.6% (2.6%) accuracy gains over ResNet-101 and\nResNet-152, respectively, on an Nvidia GPU (Intel CPU).\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 03:59:34 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Dai", "Xiaoliang", ""], ["Zhang", "Peizhao", ""], ["Wu", "Bichen", ""], ["Yin", "Hongxu", ""], ["Sun", "Fei", ""], ["Wang", "Yanghan", ""], ["Dukhan", "Marat", ""], ["Hu", "Yunqing", ""], ["Wu", "Yiming", ""], ["Jia", "Yangqing", ""], ["Vajda", "Peter", ""], ["Uyttendaele", "Matt", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1812.08951", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, James Glass", "title": "Analysis Methods in Neural Language Processing: A Survey", "comments": "Version including the supplementary materials (3 tables), also\n  available at https://boknilev.github.io/nlp-analysis-methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of natural language processing has seen impressive progress in\nrecent years, with neural network models replacing many of the traditional\nsystems. A plethora of new models have been proposed, many of which are thought\nto be opaque compared to their feature-rich counterparts. This has led\nresearchers to analyze, interpret, and evaluate neural networks in novel and\nmore fine-grained ways. In this survey paper, we review analysis methods in\nneural language processing, categorize them according to prominent research\ntrends, highlight existing limitations, and point to potential directions for\nfuture work.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 05:13:03 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:38:50 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Glass", "James", ""]]}, {"id": "1812.09113", "submitter": "Nicolas Vecoven", "authors": "Nicolas Vecoven, Damien Ernst, Antoine Wehenkel, Guillaume Drion", "title": "Introducing Neuromodulation in Deep Neural Networks to Learn Adaptive\n  Behaviours", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals excel at adapting their intentions, attention, and actions to the\nenvironment, making them remarkably efficient at interacting with a rich,\nunpredictable and ever-changing external world, a property that intelligent\nmachines currently lack. Such an adaptation property relies heavily on cellular\nneuromodulation, the biological mechanism that dynamically controls intrinsic\nproperties of neurons and their response to external stimuli in a\ncontext-dependent manner. In this paper, we take inspiration from cellular\nneuromodulation to construct a new deep neural network architecture that is\nspecifically designed to learn adaptive behaviours. The network adaptation\ncapabilities are tested on navigation benchmarks in a meta-reinforcement\nlearning context and compared with state-of-the-art approaches. Results show\nthat neuromodulation is capable of adapting an agent to different tasks and\nthat neuromodulation-based approaches provide a promising way of improving\nadaptation of artificial systems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 13:43:32 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 15:19:20 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2019 09:57:58 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Vecoven", "Nicolas", ""], ["Ernst", "Damien", ""], ["Wehenkel", "Antoine", ""], ["Drion", "Guillaume", ""]]}, {"id": "1812.09441", "submitter": "Truyen Tran", "authors": "Kien Do, Truyen Tran, Svetha Venkatesh", "title": "Graph Transformation Policy Network for Chemical Reaction Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a fundamental problem in chemistry known as chemical reaction\nproduct prediction. Our main insight is that the input reactant and reagent\nmolecules can be jointly represented as a graph, and the process of generating\nproduct molecules from reactant molecules can be formulated as a sequence of\ngraph transformations. To this end, we propose Graph Transformation Policy\nNetwork (GTPN) -- a novel generic method that combines the strengths of graph\nneural networks and reinforcement learning to learn the reactions directly from\ndata with minimal chemical knowledge. Compared to previous methods, GTPN has\nsome appealing properties such as: end-to-end learning, and making no\nassumption about the length or the order of graph transformations. In order to\nguide model search through the complex discrete space of sets of bond changes\neffectively, we extend the standard policy gradient loss by adding useful\nconstraints. Evaluation results show that GTPN improves the top-1 accuracy over\nthe current state-of-the-art method by about 3% on the large USPTO dataset. Our\nmodel's performances and prediction errors are also analyzed carefully in the\npaper.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 03:11:10 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1812.09569", "submitter": "Sergey Belim", "authors": "S.V. Belim, S.B. Larionov", "title": "The algorithm of formation of a training set for an artificial neural\n  network for image segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article suggests an algorithm of formation a training set for artificial\nneural network in case of image segmentation. The distinctive feature of this\nalgorithm is that it using only one image for segmentation. The segmentation\nperforms using three-layer perceptron. The main method of the segmentation is a\nmethod of region growing. Neural network is using for get a decision to include\npixel into an area or not. Impulse noise is using for generation of a training\nset. Pixels damaged by noise are not related to the same region. Suggested\nmethod has been tested with help of computer experiment in automatic and\ninteractive modes.\n", "versions": [{"version": "v1", "created": "Sat, 22 Dec 2018 17:21:59 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Belim", "S. V.", ""], ["Larionov", "S. B.", ""]]}, {"id": "1812.09968", "submitter": "Qi Wang", "authors": "Xingxing Liang, Qi Wang, Yanghe Feng, Zhong Liu, Jincai Huang", "title": "VMAV-C: A Deep Attention-based Reinforcement Learning Algorithm for\n  Model-based Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent breakthroughs in Go play and strategic games have witnessed the great\npotential of reinforcement learning in intelligently scheduling in uncertain\nenvironment, but some bottlenecks are also encountered when we generalize this\nparadigm to universal complex tasks. Among them, the low efficiency of data\nutilization in model-free reinforcement algorithms is of great concern. In\ncontrast, the model-based reinforcement learning algorithms can reveal\nunderlying dynamics in learning environments and seldom suffer the data\nutilization problem. To address the problem, a model-based reinforcement\nlearning algorithm with attention mechanism embedded is proposed as an\nextension of World Models in this paper. We learn the environment model through\nMixture Density Network Recurrent Network(MDN-RNN) for agents to interact, with\ncombinations of variational auto-encoder(VAE) and attention incorporated in\nstate value estimates during the process of learning policy. In this way, agent\ncan learn optimal policies through less interactions with actual environment,\nand final experiments demonstrate the effectiveness of our model in control\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2018 19:25:23 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Liang", "Xingxing", ""], ["Wang", "Qi", ""], ["Feng", "Yanghe", ""], ["Liu", "Zhong", ""], ["Huang", "Jincai", ""]]}, {"id": "1812.10098", "submitter": "Sergey Belim", "authors": "S.V. Belim, S.B. Larionov", "title": "The algorithm of the impulse noise filtration in images based on an\n  algorithm of community detection in graphs", "comments": null, "journal-ref": "2017 Dynamics of Systems, Mechanisms and Machines (Dynamics),\n  Omsk, Russia, pp. 1-5", "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article suggests an algorithm of impulse noise filtration, based on the\ncommunity detection in graphs. The image is representing as non-oriented\nweighted graph. Each pixel of an image is corresponding to a vertex of the\ngraph. Community detection algorithm is running on the given graph. Assumed\nthat communities that contain only one pixel are corresponding to noised pixels\nof an image. Suggested method was tested with help of computer experiment. This\nexperiment was conducted on grayscale, and on colored images, on artificial\nimages and on photos. It is shown that the suggested method is better than\nmedian filter by 20% regardless of noise percent. Higher efficiency is\njustified by the fact that most of filters are changing all of image pixels,\nbut suggested method is finding and restoring only noised pixels. The\ndependence of the effectiveness of the proposed method on the percentage of\nnoise in the image is shown.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 12:40:12 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Belim", "S. V.", ""], ["Larionov", "S. B.", ""]]}, {"id": "1812.10240", "submitter": "Deepak Mittal", "authors": "Deepak Mittal, Shweta Bhardwaj, Mitesh M. Khapra, Balaraman Ravindran", "title": "Studying the Plasticity in Deep Convolutional Neural Networks using\n  Random Pruning", "comments": "To appear in the Journal of Machine Vision and Applications,\n  Springer. This work is an extended version of our previous work\n  arXiv:1801.10447, \"Recovering from Random Pruning: On the Plasticity of Deep\n  Convolutional Neural Networks\", accepted at WACV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a lot of work on pruning filters from deep\nconvolutional neural networks (CNNs) with the intention of reducing\ncomputations.The key idea is to rank the filters based on a certain criterion\n(say, l1-norm) and retain only the top ranked filters. Once the low scoring\nfilters are pruned away the remainder of the network is fine tuned and is shown\nto give performance comparable to the original unpruned network. In this work,\nwe report experiments which suggest that the comparable performance of the\npruned network is not due to the specific criterion chosen but due to the\ninherent plasticity of deep neural networks which allows them to recover from\nthe loss of pruned filters once the rest of the filters are fine-tuned.\nSpecifically we show counter-intuitive results wherein by randomly pruning\n25-50% filters from deep CNNs we are able to obtain the same performance as\nobtained by using state-of-the-art pruning methods. We empirically validate our\nclaims by doing an exhaustive evaluation with VGG-16 and ResNet-50. We also\nevaluate a real world scenario where a CNN trained on all 1000 ImageNet classes\nneeds to be tested on only a small set of classes at test time (say, only\nanimals). We create a new benchmark dataset from ImageNet to evaluate such\nclass specific pruning and show that even here a random pruning strategy gives\nclose to state-of-the-art performance. Unlike existing approaches which mainly\nfocus on the task of image classification, in this work we also report results\non object detection and image segmentation. We show that using a simple random\npruning strategy we can achieve significant speed up in object detection (74%\nimprovement in fps) while retaining the same accuracy as that of the original\nFaster RCNN model. Similarly we show that the performance of a pruned\nSegmentation Network (SegNet) is actually very similar to that of the original\nunpruned SegNet.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 06:26:06 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Mittal", "Deepak", ""], ["Bhardwaj", "Shweta", ""], ["Khapra", "Mitesh M.", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1812.10247", "submitter": "Vladimir Puzyrev", "authors": "Vladimir Puzyrev", "title": "Deep learning electromagnetic inversion with convolutional neural\n  networks", "comments": "27 pages, 14 figures", "journal-ref": null, "doi": "10.1093/gji/ggz204", "report-no": null, "categories": "physics.geo-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geophysical inversion attempts to estimate the distribution of physical\nproperties in the Earth's interior from observations collected at or above the\nsurface. Inverse problems are commonly posed as least-squares optimization\nproblems in high-dimensional parameter spaces. Existing approaches are largely\nbased on deterministic gradient-based methods, which are limited by\nnonlinearity and nonuniqueness of the inverse problem. Probabilistic inversion\nmethods, despite their great potential in uncertainty quantification, still\nremain a formidable computational task. In this paper, I explore the potential\nof deep learning methods for electromagnetic inversion. This approach does not\nrequire calculation of the gradient and provides results instantaneously. Deep\nneural networks based on fully convolutional architecture are trained on large\nsynthetic datasets obtained by full 3-D simulations. The performance of the\nmethod is demonstrated on models of strong practical relevance representing an\nonshore controlled source electromagnetic CO2 monitoring scenario. The\npre-trained networks can reliably estimate the position and lateral dimensions\nof the anomalies, as well as their resistivity properties. Several fully\nconvolutional network architectures are compared in terms of their accuracy,\ngeneralization, and cost of training. Examples with different survey geometry\nand noise levels confirm the feasibility of the deep learning inversion,\nopening the possibility to estimate the subsurface resistivity distribution in\nreal time.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 07:00:23 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Puzyrev", "Vladimir", ""]]}, {"id": "1812.10308", "submitter": "Harshavardhan Kamarthi", "authors": "Harshavardhan Kamarthi, Kousik Krishnan", "title": "Hierarchical Genetic Algorithms with evolving objective functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework of genetic algorithms which use multi-level\nhierarchies to solve an optimization problem by searching over the space of\nsimpler objective functions. We solve a variant of Travelling Salesman Problem\ncalled \\texttt{soft-TSP} and show that when the constraints on the overall\nobjective function are changed the algorithm adapts to churn out solutions for\nthe changed objective. We use this idea to speed up learning by systematically\naltering the constraints to find a more globally optimal solution. We also use\nthis framework to solve polynomial regression where the actual objective\nfunction is unknown but searching over space of available objective functions\nyields a good approximate solution.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 16:38:45 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 14:06:51 GMT"}, {"version": "v3", "created": "Mon, 5 Aug 2019 10:44:39 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kamarthi", "Harshavardhan", ""], ["Krishnan", "Kousik", ""]]}, {"id": "1812.10539", "submitter": "Aditya Grover", "authors": "Aditya Grover, Stefano Ermon", "title": "Uncertainty Autoencoders: Learning Compressed Representations via\n  Variational Information Maximization", "comments": "AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing techniques enable efficient acquisition and recovery of\nsparse, high-dimensional data signals via low-dimensional projections. In this\nwork, we propose Uncertainty Autoencoders, a learning framework for\nunsupervised representation learning inspired by compressed sensing. We treat\nthe low-dimensional projections as noisy latent representations of an\nautoencoder and directly learn both the acquisition (i.e., encoding) and\namortized recovery (i.e., decoding) procedures. Our learning objective\noptimizes for a tractable variational lower bound to the mutual information\nbetween the datapoints and the latent representations. We show how our\nframework provides a unified treatment to several lines of research in\ndimensionality reduction, compressed sensing, and generative modeling.\nEmpirically, we demonstrate a 32% improvement on average over competing\napproaches for the task of statistical compressed sensing of high-dimensional\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2018 21:14:06 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 06:45:27 GMT"}, {"version": "v3", "created": "Thu, 11 Apr 2019 22:16:32 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Grover", "Aditya", ""], ["Ermon", "Stefano", ""]]}, {"id": "1812.10549", "submitter": "Marc Johnson", "authors": "Marc Everett Johnson", "title": "Automatic Summarization of Natural Language", "comments": "6 pages, 1 literature synthesis matrix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic summarization of natural language is a current topic in computer\nscience research and industry, studied for decades because of its usefulness\nacross multiple domains. For example, summarization is necessary to create\nreviews such as this one. Research and applications have achieved some success\nin extractive summarization (where key sentences are curated), however,\nabstractive summarization (synthesis and re-stating) is a hard problem and\ngenerally unsolved in computer science. This literature review contrasts\nhistorical progress up through current state of the art, comparing dimensions\nsuch as: extractive vs. abstractive, supervised vs. unsupervised, NLP (Natural\nLanguage Processing) vs Knowledge-based, deep learning vs algorithms,\nstructured vs. unstructured sources, and measurement metrics such as Rouge and\nBLEU. Multiple dimensions are contrasted since current research uses\ncombinations of approaches as seen in the review matrix. Throughout this\nsummary, synthesis and critique is provided. This review concludes with\ninsights for improved abstractive summarization measurement, with surprising\nimplications for detecting understanding and comprehension in general.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 14:17:56 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Johnson", "Marc Everett", ""]]}, {"id": "1812.10775", "submitter": "Tolga Birdal", "authors": "Yongheng Zhao and Tolga Birdal and Haowen Deng and Federico Tombari", "title": "3D Point Capsule Networks", "comments": "As published in CVPR 2019 (camera ready version), with supplementary\n  material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose 3D point-capsule networks, an auto-encoder designed\nto process sparse 3D point clouds while preserving spatial arrangements of the\ninput data. 3D capsule networks arise as a direct consequence of our novel\nunified 3D auto-encoder formulation. Their dynamic routing scheme and the\npeculiar 2D latent space deployed by our approach bring in improvements for\nseveral common point cloud-related tasks, such as object classification, object\nreconstruction and part segmentation as substantiated by our extensive\nevaluations. Moreover, it enables new applications such as part interpolation\nand replacement.\n", "versions": [{"version": "v1", "created": "Thu, 27 Dec 2018 17:16:48 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 23:39:55 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Zhao", "Yongheng", ""], ["Birdal", "Tolga", ""], ["Deng", "Haowen", ""], ["Tombari", "Federico", ""]]}, {"id": "1812.11061", "submitter": "Denis Antipov", "authors": "Denis Antipov, Benjamin Doerr", "title": "A Tight Runtime Analysis for the $(\\mu + \\lambda)$ EA", "comments": "50 pages, extended version of the conference paper Denis Antipov,\n  Benjamin Doerr, Jiefeng Fang, and Tangi Hetet Runtime analysis for the ({\\mu}\n  + {\\lambda}) EA optimizing OneMax. In Genetic and Evolutionary Computation\n  Conference, GECCO 2018, pages 1459-1466. ACM, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant progress in the theory of evolutionary algorithms, the\ntheoretical understanding of evolutionary algorithms which use non-trivial\npopulations remains challenging and only few rigorous results exist. Already\nfor the most basic problem, the determination of the asymptotic runtime of the\n$(\\mu+\\lambda)$ evolutionary algorithm on the simple OneMax benchmark function,\nonly the special cases $\\mu=1$ and $\\lambda=1$ have been solved.\n  In this work, we analyze this long-standing problem and show the\nasymptotically tight result that the runtime $T$, the number of iterations\nuntil the optimum is found, satisfies \\[E[T] = \\Theta\\bigg(\\frac{n\\log\nn}{\\lambda}+\\frac{n}{\\lambda / \\mu} + \\frac{n\\log^+\\log^+ \\lambda/ \\mu}{\\log^+\n\\lambda / \\mu}\\bigg),\\] where $\\log^+ x := \\max\\{1, \\log x\\}$ for all $x > 0$.\n  The same methods allow to improve the previous-best $O(\\frac{n \\log\nn}{\\lambda} + n \\log \\lambda)$ runtime guarantee for the $(\\lambda+\\lambda)$~EA\nwith fair parent selection to a tight $\\Theta(\\frac{n \\log n}{\\lambda} + n)$\nruntime result.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 15:51:59 GMT"}, {"version": "v2", "created": "Tue, 21 Jan 2020 11:52:34 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Antipov", "Denis", ""], ["Doerr", "Benjamin", ""]]}, {"id": "1812.11202", "submitter": "Louis Annabi", "authors": "Louis Annabi and Michael Garcia Ortiz", "title": "State representation learning with recurrent capsule networks", "comments": "4 pages, 4 figures, NIPS Workshop on Modeling the Physical World:\n  Perception, Learning, and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of compact and relevant state representations has been\nproved very useful at solving complex reinforcement learning tasks. In this\npaper, we propose a recurrent capsule network that learns such representations\nby trying to predict the future observations in an agent's trajectory.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 19:31:26 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 21:03:15 GMT"}, {"version": "v3", "created": "Mon, 18 Feb 2019 14:23:17 GMT"}, {"version": "v4", "created": "Fri, 22 Feb 2019 17:15:44 GMT"}], "update_date": "2019-02-25", "authors_parsed": [["Annabi", "Louis", ""], ["Ortiz", "Michael Garcia", ""]]}, {"id": "1812.11240", "submitter": "Norman Tasfi", "authors": "Norman Tasfi and Miriam Capretz", "title": "Dynamic Planning Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Dynamic Planning Networks (DPN), a novel architecture for deep\nreinforcement learning, that combines model-based and model-free aspects for\nonline planning. Our architecture learns to dynamically construct plans using a\nlearned state-transition model by selecting and traversing between simulated\nstates and actions to maximize information before acting. In contrast to\nmodel-free methods, model-based planning lets the agent efficiently test action\nhypotheses without performing costly trial-and-error in the environment. DPN\nlearns to efficiently form plans by expanding a single action-conditional state\ntransition at a time instead of exhaustively evaluating each action, reducing\nthe required number of state-transitions during planning by up to 96%. We\nobserve various emergent planning patterns used to solve environments,\nincluding classical search methods such as breadth-first and depth-first\nsearch. DPN shows improved data efficiency, performance, and generalization to\nnew and unseen domains in comparison to several baselines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2018 22:37:30 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 15:15:44 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Tasfi", "Norman", ""], ["Capretz", "Miriam", ""]]}, {"id": "1812.11337", "submitter": "Ghouthi Boukli Hacene", "authors": "Ghouthi Boukli Hacene (ELEC), Vincent Gripon, Matthieu Arzel (ELEC),\n  Nicolas Farrugia (ELEC), Yoshua Bengio (DIRO)", "title": "Quantized Guided Pruning for Efficient Hardware Implementations of\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are state-of-the-art in numerous\ncomputer vision tasks such as object classification and detection. However, the\nlarge amount of parameters they contain leads to a high computational\ncomplexity and strongly limits their usability in budget-constrained devices\nsuch as embedded devices. In this paper, we propose a combination of a new\npruning technique and a quantization scheme that effectively reduce the\ncomplexity and memory usage of convolutional layers of CNNs, and replace the\ncomplex convolutional operation by a low-cost multiplexer. We perform\nexperiments on the CIFAR10, CIFAR100 and SVHN and show that the proposed method\nachieves almost state-of-the-art accuracy, while drastically reducing the\ncomputational and memory footprints. We also propose an efficient hardware\narchitecture to accelerate CNN operations. The proposed hardware architecture\nis a pipeline and accommodates multiple layers working at the same time to\nspeed up the inference process.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 11:06:39 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Hacene", "Ghouthi Boukli", "", "ELEC"], ["Gripon", "Vincent", "", "ELEC"], ["Arzel", "Matthieu", "", "ELEC"], ["Farrugia", "Nicolas", "", "ELEC"], ["Bengio", "Yoshua", "", "DIRO"]]}, {"id": "1812.11391", "submitter": "Fathi Salem", "authors": "Fathi M. Salem", "title": "SLIM LSTMs", "comments": "7 pages, no figures. conference manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory (LSTM) Recurrent Neural networks (RNNs) rely on gating\nsignals, each driven by a function of a weighted sum of at least 3 components:\n(i) one of an adaptive weight matrix multiplied by the incoming external input\nvector sequence, (ii) one adaptive weight matrix multiplied by the previous\nmemory/state vector, and (iii) one adaptive bias vector. In effect, they\naugment the simple Recurrent Neural Networks (sRNNs) structure with the\naddition of a \"memory cell\" and the incorporation of at most 3 gating signals.\n  The standard LSTM structure and components encompass redundancy and overly\nincreased parameterization. In this paper, we systemically introduce variants\nof the LSTM RNNs, referred to as SLIM LSTMs. These variants express\naggressively reduced parameterizations to achieve computational saving and/or\nspeedup in (training) performance---while necessarily retaining (validation\naccuracy) performance comparable to the standard LSTM RNN.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 16:11:01 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Salem", "Fathi M.", ""]]}, {"id": "1812.11424", "submitter": "Alessandro Ingrosso", "authors": "Alessandro Ingrosso and L.F. Abbott", "title": "Training dynamically balanced excitatory-inhibitory networks", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0220547", "report-no": null, "categories": "cond-mat.dis-nn cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of biologically plausible models of neural circuits is\ncrucial for understanding the computational properties of the nervous system.\nConstructing functional networks composed of separate excitatory and inhibitory\nneurons obeying Dale's law presents a number of challenges. We show how a\ntarget-based approach, when combined with a fast online constrained\noptimization technique, is capable of building functional models of rate and\nspiking recurrent neural networks in which excitation and inhibition are\nbalanced. Balanced networks can be trained to produce complicated temporal\npatterns and to solve input-output tasks while retaining biologically desirable\nfeatures such as Dale's law and response variability.\n", "versions": [{"version": "v1", "created": "Sat, 29 Dec 2018 18:58:52 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ingrosso", "Alessandro", ""], ["Abbott", "L. F.", ""]]}, {"id": "1812.11467", "submitter": "Saurabh Bagchi", "authors": "Mustafa Abdallah, Ashraf Mahgoub, Saurabh Bagchi and Somali Chaterji", "title": "ATHENA: Automated Tuning of Genomic Error Correction Algorithms using\n  Language Models", "comments": "10 main pages, 7 references and appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of most error-correction algorithms that operate on genomic\nsequencer reads is dependent on the proper choice of its configuration\nparameters, such as the value of k in k-mer based techniques. In this work, we\ntarget the problem of finding the best values of these configuration parameters\nto optimize error correction. We perform this in a data-driven manner, due to\nthe observation that different configuration parameters are optimal for\ndifferent datasets, i.e., from different instruments and organisms. We use\nlanguage modeling techniques from the Natural Language Processing (NLP) domain\nin our algorithmic suite, Athena, to automatically tune the\nperformance-sensitive configuration parameters. Through the use of N-Gram and\nRecurrent Neural Network (RNN) language modeling, we validate the intuition\nthat the EC performance can be computed quantitatively and efficiently using\nthe perplexity metric, prevalent in NLP. After training the language model, we\nshow that the perplexity metric calculated for runtime data has a strong\nnegative correlation with the correction of the erroneous NGS reads. Therefore,\nwe use the perplexity metric to guide a hill climbing-based search, converging\ntoward the best $k$-value. Our approach is suitable for both de novo and\ncomparative sequencing (resequencing), eliminating the need for a reference\ngenome to serve as the ground truth. This is important because the use of a\nreference genome often carries forward the biases along the stages of the\npipeline.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 04:15:29 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Abdallah", "Mustafa", ""], ["Mahgoub", "Ashraf", ""], ["Bagchi", "Saurabh", ""], ["Chaterji", "Somali", ""]]}, {"id": "1812.11485", "submitter": "Naoya Taguchi", "authors": "Naoya Taguchi and Yoshimasa Tsuruoka", "title": "Partially Non-Recurrent Controllers for Memory-Augmented Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory-Augmented Neural Networks (MANNs) are a class of neural networks\nequipped with an external memory, and are reported to be effective for tasks\nrequiring a large long-term memory and its selective use. The core module of a\nMANN is called a controller, which is usually implemented as a recurrent neural\nnetwork (RNN) (e.g., LSTM) to enable the use of contextual information in\ncontrolling the other modules. However, such an RNN-based controller often\nallows a MANN to directly solve the given task by using the (small) internal\nmemory of the controller, and prevents the MANN from making the best use of the\nexternal memory, thereby resulting in a suboptimally trained model. To address\nthis problem, we present a novel type of RNN-based controller that is partially\nnon-recurrent and avoids the direct use of its internal memory for solving the\ntask, while keeping the ability of using contextual information in controlling\nthe other modules. Our empirical experiments using Neural Turing Machines and\nDifferentiable Neural Computers on the Toy and bAbI tasks demonstrate that the\nproposed controllers give substantially better results than standard RNN-based\ncontrollers.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 07:59:04 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Taguchi", "Naoya", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "1812.11527", "submitter": "Luca Pedrelli", "authors": "Claudio Gallicchio, Alessio Micheli, Luca Pedrelli", "title": "Comparison between DeepESNs and gated RNNs on multivariate time-series\n  prediction", "comments": "Preprint version of Claudio Gallicchio, Alessio Micheli and Luca\n  Pedrelli (2019) Comparison between DeepESNs and gated RNNs on multivariate\n  time-series prediction. In: ESANN 2019 proceedings, European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning.\n  Bruges (Belgium), 24-26 April 2019, i6doc.com publ., ISBN 978-287-587-065-0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an experimental comparison between Deep Echo State Networks\n(DeepESNs) and gated Recurrent Neural Networks (RNNs) on multivariate\ntime-series prediction tasks. In particular, we compare reservoir and\nfully-trained RNNs able to represent signals featured by multiple time-scales\ndynamics. The analysis is performed in terms of efficiency and prediction\naccuracy on 4 polyphonic music tasks. Our results show that DeepESN is able to\noutperform ESN in terms of prediction accuracy and efficiency. Whereas, between\nfully-trained approaches, Gated Recurrent Units (GRU) outperforms Long\nShort-Term Memory (LSTM) and simple RNN models in most cases. Overall, DeepESN\nturned out to be extremely more efficient than others RNN approaches and the\nbest solution in terms of prediction accuracy on 3 out of 4 tasks.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 13:13:16 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 15:49:23 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""], ["Pedrelli", "Luca", ""]]}, {"id": "1812.11581", "submitter": "H. Sebastian Seung", "authors": "H. Sebastian Seung", "title": "Unsupervised learning by a nonlinear network with Hebbian excitatory and\n  anti-Hebbian inhibitory neurons", "comments": "10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a rate-based nonlinear neural network in which\nexcitatory (E) neurons receive feedforward excitation from sensory (S) neurons,\nand inhibit each other through disynaptic pathways mediated by inhibitory (I)\ninterneurons. Correlation-based plasticity of disynaptic inhibition serves to\nincompletely decorrelate E neuron activity, pushing the E neurons to learn\ndistinct sensory features. The plasticity equations additionally contain\n\"extra\" terms fostering competition between excitatory synapses converging onto\nthe same postsynaptic neuron and inhibitory synapses diverging from the same\npresynaptic neuron. The parameters of competition between S$\\to$E connections\ncan be adjusted to make learned features look more like \"parts\" or \"wholes.\"\nThe parameters of competition between I-E connections can be adjusted to set\nthe typical decorrelatedness and sparsity of E neuron activity. Numerical\nsimulations of unsupervised learning show that relatively few I neurons can be\nsufficient for achieving good decorrelation, and increasing the number of I\nneurons makes decorrelation more complete. Excitatory and inhibitory inputs to\nactive E neurons are approximately balanced as a result of learning.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 18:19:23 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Seung", "H. Sebastian", ""]]}, {"id": "1812.11610", "submitter": "Mahamad Alam", "authors": "Mahamad Nabab Alam", "title": "State-of-the-Art Economic Load Dispatch of Power Systems Using Particle\n  Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Metaheuristic particle swarm optimization (PSO) algorithm has emerged as one\nof the most promising optimization techniques in solving highly constrained\nnon-linear and non-convex optimization problems in different areas of\nelectrical engineering. Economic operation of the power system is one of the\nmost important areas of electrical engineering where PSO has been used\nefficiently in solving various issues of practical systems. In this paper, a\ncomprehensive survey of research works in solving various aspects of economic\nload dispatch (ELD) problems of power system engineering using different types\nof PSO algorithms is presented. Five important areas of ELD problems have been\nidentified, and the papers published in the general area of ELD using PSO have\nbeen classified into these five sections. These five areas are (i) single\nobjective economic load dispatch, (ii) dynamic economic load dispatch, (iii)\neconomic load dispatch with non-conventional sources, (iv) multi-objective\nenvironmental/economic dispatch, and (v) economic load dispatch of microgrids.\nAt the end of each category, a table is provided which describes the main\nfeatures of the papers in brief. The promising future works are given at the\nconclusion of the review.\n", "versions": [{"version": "v1", "created": "Sun, 30 Dec 2018 20:47:38 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Alam", "Mahamad Nabab", ""]]}, {"id": "1812.11792", "submitter": "Naoki Takeuchi", "authors": "N. Takeuchi, M. Aono, Y. Hara-Azumi, C. L. Ayala", "title": "A Circuit-Level Amoeba-Inspired SAT Solver", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": "10.1109/TCSII.2019.2951181", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AmbSAT (or AmoebaSAT) is a biologically-inspired stochastic local search\n(SLS) solver to explore solutions to the Boolean satisfiability problem (SAT).\nAmbSAT updates multiple variables in parallel at every iteration step, and thus\nAmbSAT can find solutions with a fewer number of iteration steps than some\nother conventional SLS solvers for a specific set of SAT instances. However,\nthe parallelism of AmbSAT is not compatible with general-purpose\nmicroprocessors in that many clock cycles are required to execute each\niteration; thus, AmbSAT requires special hardware that can exploit the\nparallelism of AmbSAT to quickly find solutions. In this paper, we propose a\ncircuit model (hardware-friendly algorithm) that explores solutions to SAT in a\nsimilar way to AmbSAT, which we call circuit-level AmbSAT (CL-AmbSAT). We\nconducted numerical simulation to evaluate the search performance of CL-AmbSAT\nfor a set of randomly generated SAT instances that was designed to estimate the\nscalability of our approach. Simulation results showed that CL-AmbSAT finds\nsolutions with a fewer iteration number than a powerful SLS solver, ProbSAT,\nand outperforms even AmbSAT. Since CL-AmbSAT uses simple combinational logic to\nupdate variables, CL-AmbSAT can be easily implemented in various hardware.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2018 07:02:15 GMT"}, {"version": "v2", "created": "Sun, 24 Feb 2019 04:37:51 GMT"}, {"version": "v3", "created": "Wed, 6 Nov 2019 02:31:50 GMT"}], "update_date": "2019-11-07", "authors_parsed": [["Takeuchi", "N.", ""], ["Aono", "M.", ""], ["Hara-Azumi", "Y.", ""], ["Ayala", "C. L.", ""]]}, {"id": "1812.11937", "submitter": "H. Sebastian Seung", "authors": "H. Sebastian Seung", "title": "Two \"correlation games\" for a nonlinear network with Hebbian excitatory\n  neurons and anti-Hebbian inhibitory neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A companion paper introduces a nonlinear network with Hebbian excitatory (E)\nneurons that are reciprocally coupled with anti-Hebbian inhibitory (I) neurons\nand also receive Hebbian feedforward excitation from sensory (S) afferents. The\npresent paper derives the network from two normative principles that are\nmathematically equivalent but conceptually different. The first principle\nformulates unsupervised learning as a constrained optimization problem:\nmaximization of S-E correlations subject to a copositivity constraint on E-E\ncorrelations. A combination of Legendre and Lagrangian duality yields a\nzero-sum continuous game between excitatory and inhibitory connections that is\nsolved by the neural network. The second principle defines a zero-sum game\nbetween E and I cells. E cells want to maximize S-E correlations and minimize\nE-I correlations, while I cells want to maximize I-E correlations and minimize\npower. The conflict between I and E objectives effectively forces the E cells\nto decorrelate from each other, although only incompletely. Legendre duality\nyields the neural network.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:18:46 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Seung", "H. Sebastian", ""]]}, {"id": "1812.11971", "submitter": "Alexander Sax", "authors": "Alexander Sax, Bradley Emi, Amir R. Zamir, Leonidas Guibas, Silvio\n  Savarese, Jitendra Malik", "title": "Mid-Level Visual Representations Improve Generalization and Sample\n  Efficiency for Learning Visuomotor Policies", "comments": "See project website, demos, and code at http://perceptual.actor", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much does having visual priors about the world (e.g. the fact that the\nworld is 3D) assist in learning to perform downstream motor tasks (e.g.\ndelivering a package)? We study this question by integrating a generic\nperceptual skill set (e.g. a distance estimator, an edge detector, etc.) within\na reinforcement learning framework--see Figure 1. This skill set (hereafter\nmid-level perception) provides the policy with a more processed state of the\nworld compared to raw images.\n  We find that using a mid-level perception confers significant advantages over\ntraining end-to-end from scratch (i.e. not leveraging priors) in\nnavigation-oriented tasks. Agents are able to generalize to situations where\nthe from-scratch approach fails and training becomes significantly more sample\nefficient. However, we show that realizing these gains requires careful\nselection of the mid-level perceptual skills. Therefore, we refine our findings\ninto an efficient max-coverage feature set that can be adopted in lieu of raw\nimages. We perform our study in completely separate buildings for training and\ntesting and compare against visually blind baseline policies and\nstate-of-the-art feature learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2018 18:59:25 GMT"}, {"version": "v2", "created": "Fri, 19 Apr 2019 17:58:50 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2019 07:12:34 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Sax", "Alexander", ""], ["Emi", "Bradley", ""], ["Zamir", "Amir R.", ""], ["Guibas", "Leonidas", ""], ["Savarese", "Silvio", ""], ["Malik", "Jitendra", ""]]}]