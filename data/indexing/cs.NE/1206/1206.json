[{"id": "1206.0285", "submitter": "Jyotsna  Kumar Prof.", "authors": "J. K. Mandal and Somnath Mukhopadhyay", "title": "Image Filtering using All Neighbor Directional Weighted Pixels:\n  Optimization using Particle Swarm Optimization", "comments": "14 pages", "journal-ref": "Signal & Image Processing : An International Journal (SIPIJ)\n  Vol.2, No.4 (2011)", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel approach for de noising images corrupted by random\nvalued impulses has been proposed. Noise suppression is done in two steps. The\ndetection of noisy pixels is done using all neighbor directional weighted\npixels (ANDWP) in the 5 x 5 window. The filtering scheme is based on minimum\nvariance of the four directional pixels. In this approach, relatively recent\ncategory of stochastic global optimization technique i.e., particle swarm\noptimization (PSO) has also been used for searching the parameters of detection\nand filtering operators required for optimal performance. Results obtained\nshows better de noising and preservation of fine details for highly corrupted\nimages.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 10:36:25 GMT"}], "update_date": "2012-06-04", "authors_parsed": [["Mandal", "J. K.", ""], ["Mukhopadhyay", "Somnath", ""]]}, {"id": "1206.0730", "submitter": "Youhei Akimoto", "authors": "Youhei Akimoto, Yuichi Nagata, Isao Ono, Shigenobu Kobayashi", "title": "Theoretical foundation for CMA-ES from information geometric perspective", "comments": "Algorithmica (special issue on evolutionary computation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the theoretical basis of the covariance matrix adaptation\nevolution strategy (CMA-ES) from the information geometry viewpoint.\n  To establish a theoretical foundation for the CMA-ES, we focus on a geometric\nstructure of a Riemannian manifold of probability distributions equipped with\nthe Fisher metric. We define a function on the manifold which is the\nexpectation of fitness over the sampling distribution, and regard the goal of\nupdate of the parameters of sampling distribution in the CMA-ES as maximization\nof the expected fitness. We investigate the steepest ascent learning for the\nexpected fitness maximization, where the steepest ascent direction is given by\nthe natural gradient, which is the product of the inverse of the Fisher\ninformation matrix and the conventional gradient of the function.\n  Our first result is that we can obtain under some types of parameterization\nof multivariate normal distribution the natural gradient of the expected\nfitness without the need for inversion of the Fisher information matrix. We\nfind that the update of the distribution parameters in the CMA-ES is the same\nas natural gradient learning for expected fitness maximization. Our second\nresult is that we derive the range of learning rates such that a step in the\ndirection of the exact natural gradient improves the parameters in the expected\nfitness. We see from the close relation between the CMA-ES and natural gradient\nlearning that the default setting of learning rates in the CMA-ES seems\nsuitable in terms of monotone improvement in expected fitness. Then, we discuss\nthe relation to the expectation-maximization framework and provide an\ninformation geometric interpretation of the CMA-ES.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 17:20:58 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Akimoto", "Youhei", ""], ["Nagata", "Yuichi", ""], ["Ono", "Isao", ""], ["Kobayashi", "Shigenobu", ""]]}, {"id": "1206.0974", "submitter": "Loshchilov Ilya", "authors": "Ilya Loshchilov (INRIA Saclay - Ile de France), Marc Schoenauer (INRIA\n  Saclay - Ile de France, MSR - INRIA), Mich\\`ele Sebag (INRIA Saclay - Ile de\n  France, LRI)", "title": "Black-box optimization benchmarking of IPOP-saACM-ES on the BBOB-2012\n  noisy testbed", "comments": "Genetic and Evolutionary Computation Conference (GECCO 2012) (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the performance of IPOP-saACM-ES, recently proposed\nself-adaptive surrogate-assisted Covariance Matrix Adaptation Evolution\nStrategy. The algorithm was tested using restarts till a total number of\nfunction evaluations of $10^6D$ was reached, where $D$ is the dimension of the\nfunction search space. The experiments show that the surrogate model control\nallows IPOP-saACM-ES to be as robust as the original IPOP-aCMA-ES and\noutperforms the latter by a factor from 2 to 3 on 6 benchmark problems with\nmoderate noise. On 15 out of 30 benchmark problems in dimension 20,\nIPOP-saACM-ES exceeds the records observed during BBOB-2009 and BBOB-2010.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 06:22:19 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Loshchilov", "Ilya", "", "INRIA Saclay - Ile de France"], ["Schoenauer", "Marc", "", "INRIA\n  Saclay - Ile de France, MSR - INRIA"], ["Sebag", "Mich\u00e8le", "", "INRIA Saclay - Ile de\n  France, LRI"]]}, {"id": "1206.1012", "submitter": "Iztok Fister", "authors": "Iztok Fister Jr., Iztok Fister, Janez Brest", "title": "A Hybrid Artificial Bee Colony Algorithm for Graph 3-Coloring", "comments": null, "journal-ref": "I. JR.,Fister, I., Fister and J., Brest. A Hybrid Artificial Bee\n  Colony Algorithm for Graph 3-Coloring. In Swarm and Evolutionary Computation,\n  Lecture Notes in Computer Science, 7269, Springer Berlin / Heidelberg, 66-74\n  (2012)", "doi": "10.1007/978-3-642-29353-5_8", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Artificial Bee Colony (ABC) is the name of an optimization algorithm that\nwas inspired by the intelligent behavior of a honey bee swarm. It is widely\nrecognized as a quick, reliable, and efficient methods for solving optimization\nproblems. This paper proposes a hybrid ABC (HABC) algorithm for graph\n3-coloring, which is a well-known discrete optimization problem. The results of\nHABC are compared with results of the well-known graph coloring algorithms of\ntoday, i.e. the Tabucol and Hybrid Evolutionary algorithm (HEA) and results of\nthe traditional evolutionary algorithm with SAW method (EA-SAW). Extensive\nexperimentations has shown that the HABC matched the competitive results of the\nbest graph coloring algorithms, and did better than the traditional heuristics\nEA-SAW when solving equi-partite, flat, and random generated medium-sized\ngraphs.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2012 18:44:15 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Fister", "Iztok", "Jr."], ["Fister", "Iztok", ""], ["Brest", "Janez", ""]]}, {"id": "1206.1074", "submitter": "Iztok Fister", "authors": "Iztok Fister, Iztok Fister Jr., Janez Brest, Viljem \\v{Z}umer", "title": "Memetic Artificial Bee Colony Algorithm for Large-Scale Global\n  Optimization", "comments": "CONFERENCE: IEEE Congress on Evolutionary Computation, Brisbane,\n  Australia, 2012", "journal-ref": null, "doi": "10.1109/CEC.2012.6252938", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memetic computation (MC) has emerged recently as a new paradigm of efficient\nalgorithms for solving the hardest optimization problems. On the other hand,\nartificial bees colony (ABC) algorithms demonstrate good performances when\nsolving continuous and combinatorial optimization problems. This study tries to\nuse these technologies under the same roof. As a result, a memetic ABC (MABC)\nalgorithm has been developed that is hybridized with two local search\nheuristics: the Nelder-Mead algorithm (NMA) and the random walk with direction\nexploitation (RWDE). The former is attended more towards exploration, while the\nlatter more towards exploitation of the search space. The stochastic adaptation\nrule was employed in order to control the balancing between exploration and\nexploitation. This MABC algorithm was applied to a Special suite on Large Scale\nContinuous Global Optimization at the 2012 IEEE Congress on Evolutionary\nComputation. The obtained results the MABC are comparable with the results of\nDECC-G, DECC-G*, and MLCC.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 21:04:10 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Fister", "Iztok", ""], ["Fister", "Iztok", "Jr."], ["Brest", "Janez", ""], ["\u017dumer", "Viljem", ""]]}, {"id": "1206.1305", "submitter": "Massimiliano Vasile", "authors": "Massimiliano Vasile, Federico Zuiani", "title": "MACS: An Agent-Based Memetic Multiobjective Optimization Algorithm\n  Applied to Space Trajectory Design", "comments": null, "journal-ref": "Proceedings of the Institution of Mechanical Engineers, Part G:\n  Journal of Aerospace Engineering September 5, 2011 0954410011410274", "doi": "10.1177/0954410011410274", "report-no": null, "categories": "cs.CE cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an algorithm for multiobjective optimization that blends\ntogether a number of heuristics. A population of agents combines heuristics\nthat aim at exploring the search space both globally and in a neighborhood of\neach agent. These heuristics are complemented with a combination of a local and\nglobal archive. The novel agent- based algorithm is tested at first on a set of\nstandard problems and then on three specific problems in space trajectory\ndesign. Its performance is compared against a number of state-of-the-art\nmultiobjective optimisation algorithms that use the Pareto dominance as\nselection criterion: NSGA-II, PAES, MOPSO, MTS. The results demonstrate that\nthe agent-based search can identify parts of the Pareto set that the other\nalgorithms were not able to capture. Furthermore, convergence is statistically\nbetter although the variance of the results is in some cases higher.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 19:21:22 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Vasile", "Massimiliano", ""], ["Zuiani", "Federico", ""]]}, {"id": "1206.1309", "submitter": "Massimiliano Vasile", "authors": "Federico Zuiani, Massimiliano Vasile, Alison Gibbings", "title": "Evidence-Based Robust Design of Deflection Actions for Near Earth\n  Objects", "comments": "Celestial Mechanics and Dynamical Astronomy, 2012", "journal-ref": null, "doi": "10.1007/s10569-012-9423-1", "report-no": null, "categories": "cs.CE cs.NE math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to the robust design of deflection\nactions for Near Earth Objects (NEO). In particular, the case of deflection by\nmeans of Solar-pumped Laser ablation is studied here in detail. The basic idea\nbehind Laser ablation is that of inducing a sublimation of the NEO surface,\nwhich produces a low thrust thereby slowly deviating the asteroid from its\ninitial Earth threatening trajectory. This work investigates the integrated\ndesign of the Space-based Laser system and the deflection action generated by\nlaser ablation under uncertainty. The integrated design is formulated as a\nmulti-objective optimisation problem in which the deviation is maximised and\nthe total system mass is minimised. Both the model for the estimation of the\nthrust produced by surface laser ablation and the spacecraft system model are\nassumed to be affected by epistemic uncertainties (partial or complete lack of\nknowledge). Evidence Theory is used to quantify these uncertainties and\nintroduce them in the optimisation process. The propagation of the trajectory\nof the NEO under the laser-ablation action is performed with a novel approach\nbased on an approximated analytical solution of Gauss' Variational Equations.\nAn example of design of the deflection of asteroid Apophis with a swarm of\nspacecraft is presented.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 19:31:17 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Zuiani", "Federico", ""], ["Vasile", "Massimiliano", ""], ["Gibbings", "Alison", ""]]}, {"id": "1206.1443", "submitter": "Asif Perwej", "authors": "Asif Perwej", "title": "On applying Neuro - Computing in E-com Domain", "comments": "5 Pages, 1 Figure, ISSN No. 2250 - 2297", "journal-ref": "International Journal of Arts Commerce &\n  Management(IJACM),November 2011, Volume 01, Number 01, Pages 1-5", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior studies have generally suggested that Artificial Neural Networks (ANNs)\nare superior to conventional statistical models in predicting consumer buying\nbehavior. There are, however, contradicting findings which raise question over\nusefulness of ANNs. This paper discusses development of three neural networks\nfor modeling consumer e-commerce behavior and compares the findings to\nequivalent logistic regression models. The results showed that ANNs predict\ne-commerce adoption slightly more accurately than logistic models but this is\nhardly justifiable given the added complexity. Further, ANNs seem to be highly\nadaptive, particularly when a small sample is coupled with a large number of\nnodes in hidden layers which, in turn, limits the neural networks'\ngeneralisability.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 10:48:48 GMT"}], "update_date": "2012-06-08", "authors_parsed": [["Perwej", "Asif", ""]]}, {"id": "1206.1953", "submitter": "Sohrab MIrsaeidi", "authors": "Mojtaba Nouri, Mahdi Bayat Mokhtari, Sohrab Mirsaeidi, Mohammad Reza\n  Miveh", "title": "Improvement of Loadability in Distribution System Using Genetic\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generally during recent decades due to development of power systems, the\nmethods for delivering electrical energy to consumers, and because of voltage\nvariations is a very important problem, the power plants follow this criteria.\nThe good solution for improving transfer and distribution of electrical power\nthe majority of consumers prefer to use energy near the loads .So small units\nthat are connected to distribution system named \"Decentralized Generation\" or\n\"Dispersed Generation\". Deregulated in power industry and development of\nrenewable energies are the most important factors in developing this type of\nelectricity generation. Today DG has a key role in electrical distribution\nsystems. For example we can refer to improving reliability indices, improvement\nof stability and reduction of losses in power system. One of the key problems\nin using DG's, is allocation of these sources in distribution networks. Load\nability in distribution systems and its improvement has an effective role in\nthe operation of power systems. However, placement of distributed generation\nsources in order to improve the distribution system load ability index was not\nconsidered, we show DG placement and allocation with genetic algorithm\noptimization method maximize load ability of power systems .This method\nimplemented on the IEEE Standard bench marks. The results show the\neffectiveness of the proposed algorithm .Another benefits of DG in selected\npositions are also studied and compared.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 16:23:34 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Nouri", "Mojtaba", ""], ["Mokhtari", "Mahdi Bayat", ""], ["Mirsaeidi", "Sohrab", ""], ["Miveh", "Mohammad Reza", ""]]}, {"id": "1206.1971", "submitter": "Sugata Sanyal", "authors": "Siby Abraham, Sugata Sanyal, Mukund Sanglikar", "title": "A Connectionist Network Approach to Find Numerical Solutions of\n  Diophantine Equations", "comments": "7 pages, 2 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces a connectionist network approach to find numerical\nsolutions of Diophantine equations as an attempt to address the famous\nHilbert's tenth problem. The proposed methodology uses a three layer feed\nforward neural network with back propagation as sequential learning procedure\nto find numerical solutions of a class of Diophantine equations. It uses a\ndynamically constructed network architecture where number of nodes in the input\nlayer is chosen based on the number of variables in the equation. The powers of\nthe given Diophantine equation are taken as input to the input layer. The\ntraining of the network starts with initial random integral weights. The\nweights are updated based on the back propagation of the error values at the\noutput layer. The optimization of weights is augmented by adding a momentum\nfactor into the network. The optimized weights of the connection between the\ninput layer and the hidden layer are taken as numerical solution of the given\nDiophantine equation. The procedure is validated using different Diophantine\nEquations of different number of variables and different powers.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 20:24:09 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2012 19:00:24 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Abraham", "Siby", ""], ["Sanyal", "Sugata", ""], ["Sanglikar", "Mukund", ""]]}, {"id": "1206.2587", "submitter": "Imtiez Fliss", "authors": "Imtiez Fliss and Moncef Tagina", "title": "Exploiting Particle Swarm Optimization in Multiple Faults Fuzzy\n  Detection", "comments": "Extended version of : Fliss I. and Tagina M., Multiple faults fuzzy\n  detection approach improved by Particle Swarm Optimization, published in The\n  8th International Conference of Modelling and Simulation - MOSIM'10,\n  Hammamet, Tunisia, May 10-12, 2010; Journal of Computing, Volume 4, Issue 2,\n  February 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper an on-line multiple faults detection approach is first of all\nproposed. For efficiency, an optimal design of membership functions is\nrequired. Thus, the proposed approach is improved using Particle Swarm\nOptimization (PSO) technique. The inputs of the proposed approaches are\nresiduals representing the numerical evaluation of Analytical Redundancy\nRelations. These residuals are generated due to the use of bond graph modeling.\nThe results of the fuzzy detection modules are displayed as a colored causal\ngraph. A comparison between the results obtained by using PSO and those given\nby the use of Genetic Algorithms (GA) is finally made. The experiments focus on\na simulation of the three-tank hydraulic system, a benchmark in the diagnosis\ndomain.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 19:38:53 GMT"}], "update_date": "2012-06-13", "authors_parsed": [["Fliss", "Imtiez", ""], ["Tagina", "Moncef", ""]]}, {"id": "1206.3522", "submitter": "Dirk Sudholt", "authors": "J\\\"org L\\\"assig and Dirk Sudholt", "title": "General Upper Bounds on the Running Time of Parallel Evolutionary\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for analyzing the running time of parallel\nevolutionary algorithms with spatially structured populations. Based on the\nfitness-level method, it yields upper bounds on the expected parallel running\ntime. This allows to rigorously estimate the speedup gained by parallelization.\nTailored results are given for common migration topologies: ring graphs, torus\ngraphs, hypercubes, and the complete graph. Example applications for\npseudo-Boolean optimization show that our method is easy to apply and that it\ngives powerful results. In our examples the possible speedup increases with the\ndensity of the topology. Surprisingly, even sparse topologies like ring graphs\nlead to a significant speedup for many functions while not increasing the total\nnumber of function evaluations by more than a constant factor. We also identify\nwhich number of processors yield asymptotically optimal speedups, thus giving\nhints on how to parametrize parallel evolutionary algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 17:28:51 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["L\u00e4ssig", "J\u00f6rg", ""], ["Sudholt", "Dirk", ""]]}, {"id": "1206.3777", "submitter": "Mahjabeen Mirza Beg", "authors": "Mahjabeen Mirza Beg and Monika Jain", "title": "An Analysis of the Methods Employed for Breast Cancer Diagnosis", "comments": "5 pages, 6 figures", "journal-ref": "International Journal of Research in Computer Science 2 (2012)\n  25-29", "doi": null, "report-no": null, "categories": "cs.NE q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer research over the last decade has been tremendous. The ground\nbreaking innovations and novel methods help in the early detection, in setting\nthe stages of the therapy and in assessing the response of the patient to the\ntreatment. The prediction of the recurrent cancer is also crucial for the\nsurvival of the patient. This paper studies various techniques used for the\ndiagnosis of breast cancer. Different methods are explored for their merits and\nde-merits for the diagnosis of breast lesion. Some of the methods are yet\nunproven but the studies look very encouraging. It was found that the recent\nuse of the combination of Artificial Neural Networks in most of the instances\ngives accurate results for the diagnosis of breast cancer and their use can\nalso be extended to other diseases.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 18:02:57 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Beg", "Mahjabeen Mirza", ""], ["Jain", "Monika", ""]]}, {"id": "1206.4588", "submitter": "Avishek Ghosh", "authors": "Avishek Ghosh, Arnab Ghosh, Arkabandhu Chowdhury, Jubin Hazra", "title": "An Evolutionary Approach to Drug-Design Using Quantam Binary Particle\n  Swarm Optimization Algorithm", "comments": "4 pages, 6 figures (Published in IEEE SCEECS 2012). arXiv admin note:\n  substantial text overlap with arXiv:1205.6412", "journal-ref": null, "doi": "10.1109/SCEECS.2012.6184776", "report-no": null, "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work provides a new approach to evolve ligand structures which\nrepresent possible drug to be docked to the active site of the target protein.\nThe structure is represented as a tree where each non-empty node represents a\nfunctional group. It is assumed that the active site configuration of the\ntarget protein is known with position of the essential residues. In this paper\nthe interaction energy of the ligands with the protein target is minimized.\nMoreover, the size of the tree is difficult to obtain and it will be different\nfor different active sites. To overcome the difficulty, a variable tree size\nconfiguration is used for designing ligands. The optimization is done using a\nquantum discrete PSO. The result using fixed length and variable length\nconfiguration are compared.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 05:06:26 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Ghosh", "Avishek", ""], ["Ghosh", "Arnab", ""], ["Chowdhury", "Arkabandhu", ""], ["Hazra", "Jubin", ""]]}, {"id": "1206.4812", "submitter": "Gilles Wainrib", "authors": "Mathieu Galtier, Gilles Wainrib", "title": "A biological gradient descent for prediction through a combination of\n  STDP and homeostatic plasticity", "comments": "36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying, formalizing and combining biological mechanisms which implement\nknown brain functions, such as prediction, is a main aspect of current research\nin theoretical neuroscience. In this letter, the mechanisms of Spike Timing\nDependent Plasticity (STDP) and homeostatic plasticity, combined in an original\nmathematical formalism, are shown to shape recurrent neural networks into\npredictors. Following a rigorous mathematical treatment, we prove that they\nimplement the online gradient descent of a distance between the network\nactivity and its stimuli. The convergence to an equilibrium, where the network\ncan spontaneously reproduce or predict its stimuli, does not suffer from\nbifurcation issues usually encountered in learning in recurrent neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 09:13:39 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2013 16:11:01 GMT"}], "update_date": "2013-06-12", "authors_parsed": [["Galtier", "Mathieu", ""], ["Wainrib", "Gilles", ""]]}, {"id": "1206.4968", "submitter": "Youhei Akimoto", "authors": "Youhei Akimoto (INRIA Saclay - Ile de France), Anne Auger (INRIA\n  Saclay - Ile de France), Nikolaus Hansen (INRIA Saclay - Ile de France)", "title": "Convergence of the Continuous Time Trajectories of Isotropic Evolution\n  Strategies on Monotonic C^2-composite Functions", "comments": "PPSN - 12th International Conference on Parallel Problem Solving from\n  Nature - 2012 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information-Geometric Optimization (IGO) has been introduced as a unified\nframework for stochastic search algorithms. Given a parametrized family of\nprobability distributions on the search space, the IGO turns an arbitrary\noptimization problem on the search space into an optimization problem on the\nparameter space of the probability distribution family and defines a natural\ngradient ascent on this space. From the natural gradients defined over the\nentire parameter space we obtain continuous time trajectories which are the\nsolutions of an ordinary differential equation (ODE). Via discretization, the\nIGO naturally defines an iterated gradient ascent algorithm. Depending on the\nchosen distribution family, the IGO recovers several known algorithms such as\nthe pure rank-\\mu update CMA-ES. Consequently, the continuous time\nIGO-trajectory can be viewed as an idealization of the original algorithm. In\nthis paper we study the continuous time trajectories of the IGO given the\nfamily of isotropic Gaussian distributions. These trajectories are a\ndeterministic continuous time model of the underlying evolution strategy in the\nlimit for population size to infinity and change rates to zero. On functions\nthat are the composite of a monotone and a convex-quadratic function, we prove\nthe global convergence of the solution of the ODE towards the global optimum.\nWe extend this result to composites of monotone and twice continuously\ndifferentiable functions and prove local convergence towards local optima.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 18:54:00 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Akimoto", "Youhei", "", "INRIA Saclay - Ile de France"], ["Auger", "Anne", "", "INRIA\n  Saclay - Ile de France"], ["Hansen", "Nikolaus", "", "INRIA Saclay - Ile de France"]]}, {"id": "1206.5170", "submitter": "Avishek Ghosh", "authors": "Arnab Ghosh, Avishek Ghosh, Arkabandhu Chowdhury, Amit Konar, R.\n  Janarthanan", "title": "Multi-robot Cooperative Box-pushing problem using Multi-objective\n  Particle Swarm Optimization Technique", "comments": "6 Pages, 4 Figures (Accepted at MNCAPPS 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work provides a new approach to solve the well-known multi-robot\nco-operative box pushing problem as a multi objective optimization problem\nusing modified Multi-objective Particle Swarm Optimization. The method proposed\nhere allows both turning and translation of the box, during shift to a desired\ngoal position. We have employed local planning scheme to determine the\nmagnitude of the forces applied by the two mobile robots perpendicularly at\nspecific locations on the box to align and translate it in each distinct step\nof motion of the box, for minimization of both time and energy. Finally the\nresults are compared with the results obtained by solving the same problem\nusing Non-dominated Sorting Genetic Algorithm-II (NSGA-II). The proposed scheme\nis found to give better results compared to NSGA-II.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 05:07:44 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Ghosh", "Arnab", ""], ["Ghosh", "Avishek", ""], ["Chowdhury", "Arkabandhu", ""], ["Konar", "Amit", ""], ["Janarthanan", "R.", ""]]}, {"id": "1206.5360", "submitter": "Sudarshan Nandy", "authors": "Sudarshan Nandy, Partha Pratim Sarkar and Achintya Das", "title": "Analysis of a Nature Inspired Firefly Algorithm based Back-propagation\n  Neural Network Training", "comments": "9 pages, 10 figures, Published with International Journal of Computer\n  Applications (IJCA)", "journal-ref": "International Journal of Computer Applications 43(22):8-16, April\n  2012. Published by Foundation of Computer Science, New York, USA", "doi": "10.5120/6401-8339", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization algorithms are normally influenced by meta-heuristic approach.\nIn recent years several hybrid methods for optimization are developed to find\nout a better solution. The proposed work using meta-heuristic Nature Inspired\nalgorithm is applied with back-propagation method to train a feed-forward\nneural network. Firefly algorithm is a nature inspired meta-heuristic\nalgorithm, and it is incorporated into back-propagation algorithm to achieve\nfast and improved convergence rate in training feed-forward neural network. The\nproposed technique is tested over some standard data set. It is found that\nproposed method produces an improved convergence within very few iteration.\nThis performance is also analyzed and compared to genetic algorithm based\nback-propagation. It is observed that proposed method consumes less time to\nconverge and providing improved convergence rate with minimum feed-forward\nneural network design.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 05:37:37 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Nandy", "Sudarshan", ""], ["Sarkar", "Partha Pratim", ""], ["Das", "Achintya", ""]]}, {"id": "1206.5559", "submitter": "Susan Khor", "authors": "Susan Khor", "title": "Speeding up the construction of slow adaptive walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm (bliss) is proposed to speed up the construction of slow\nadaptive walks. Slow adaptive walks are adaptive walks biased towards closer\npoints or smaller move steps. They were previously introduced to explore a\nsearch space, e.g. to detect potential local optima or to assess the ruggedness\nof a fitness landscape. To avoid the quadratic cost of computing Hamming\ndistance (HD) for all-pairs of strings in a set in order to find the set of\nclosest strings for each string, strings are sorted and clustered by bliss such\nthat similar strings are more likely to get paired off for HD computation. To\nefficiently arrange the strings by similarity, bliss employs the idea of shared\nnon-overlapping position specific subsequences between strings which is\ninspired by an alignment-free protein sequence comparison algorithm. Tests are\nperformed to evaluate the quality of b-walks, i.e. slow adaptive walks\nconstructed from the output of bliss, on enumerated search spaces. Finally,\nb-walks are applied to explore larger search spaces with the help of\nWang-Landau sampling.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 02:16:01 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Khor", "Susan", ""]]}, {"id": "1206.5651", "submitter": "B Nischal", "authors": "Garimella Ramamurthy, Bondalapati Nischal", "title": "Optimization of Real, Hermitian Quadratic Forms: Real, Complex\n  Hopfield-Amari Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research paper, the problem of optimization of quadratic forms\nassociated with the dynamics of Hopfield-Amari neural network is considered. An\nelegant (and short) proof of the states at which local/global minima of\nquadratic form are attained is provided. A theorem associated with local/global\nminimization of quadratic energy function using the Hopfield-Amari neural\nnetwork is discussed. The results are generalized to a \"Complex Hopfield neural\nnetwork\" dynamics over the complex hypercube (using a \"complex signum\nfunction\"). It is also reasoned through two theorems that there is no loss of\ngenerality in assuming the threshold vector to be a zero vector in the case of\nreal as well as a \"Complex Hopfield neural network\". Some structured quadratic\nforms like Toeplitz form and Complex Toeplitz form are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 11:30:44 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2012 17:47:48 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Ramamurthy", "Garimella", ""], ["Nischal", "Bondalapati", ""]]}, {"id": "1206.5771", "submitter": "Christoph Adami", "authors": "Lars Marstaller, Arend Hintze, and Christoph Adami", "title": "The evolution of representation in simple cognitive networks", "comments": "36 pages, 10 figures, one Table", "journal-ref": "Neural Computation 25 (2013) 2079-2107", "doi": "10.1162/NECO_a_00475", "report-no": null, "categories": "q-bio.NC cs.NE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations are internal models of the environment that can provide\nguidance to a behaving agent, even in the absence of sensory information. It is\nnot clear how representations are developed and whether or not they are\nnecessary or even essential for intelligent behavior. We argue here that the\nability to represent relevant features of the environment is the expected\nconsequence of an adaptive process, give a formal definition of representation\nbased on information theory, and quantify it with a measure R. To measure how R\nchanges over time, we evolve two types of networks---an artificial neural\nnetwork and a network of hidden Markov gates---to solve a categorization task\nusing a genetic algorithm. We find that the capacity to represent increases\nduring evolutionary adaptation, and that agents form representations of their\nenvironment during their lifetime. This ability allows the agents to act on\nsensorial inputs in the context of their acquired representations and enables\ncomplex and context-dependent behavior. We examine which concepts (features of\nthe environment) our networks are representing, how the representations are\nlogically encoded in the networks, and how they form as an agent behaves to\nsolve a task. We conclude that R should be able to quantify the representations\nwithin any cognitive system, and should be predictive of an agent's long-term\nadaptive success.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 19:03:04 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2013 17:27:01 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Marstaller", "Lars", ""], ["Hintze", "Arend", ""], ["Adami", "Christoph", ""]]}, {"id": "1206.5780", "submitter": "Loshchilov Ilya", "authors": "Ilya Loshchilov (INRIA Saclay - Ile de France), Marc Schoenauer (INRIA\n  Saclay - Ile de France, MSR - INRIA), Mich\\`ele Sebag (INRIA Saclay - Ile de\n  France, LRI)", "title": "Black-box optimization benchmarking of IPOP-saACM-ES and BIPOP-saACM-ES\n  on the BBOB-2012 noiseless testbed", "comments": "arXiv admin note: substantial text overlap with arXiv:1206.0974", "journal-ref": "Genetic and Evolutionary Computation Conference (GECCO 2012)\n  (2012)", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the performance of IPOP-saACM-ES and BIPOP-saACM-ES,\nrecently proposed self-adaptive surrogate-assisted Covariance Matrix Adaptation\nEvolution Strategies. Both algorithms were tested using restarts till a total\nnumber of function evaluations of $10^6D$ was reached, where $D$ is the\ndimension of the function search space. We compared surrogate-assisted\nalgorithms with their surrogate-less versions IPOP-saACM-ES and BIPOP-saACM-ES,\ntwo algorithms with one of the best overall performance observed during the\nBBOB-2009 and BBOB-2010. The comparison shows that the surrogate-assisted\nversions outperform the original CMA-ES algorithms by a factor from 2 to 4 on 8\nout of 24 noiseless benchmark problems, showing the best results among all\nalgorithms of the BBOB-2009 and BBOB-2010 on Ellipsoid, Discus, Bent Cigar,\nSharp Ridge and Sum of different powers functions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 06:23:46 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Loshchilov", "Ilya", "", "INRIA Saclay - Ile de France"], ["Schoenauer", "Marc", "", "INRIA\n  Saclay - Ile de France, MSR - INRIA"], ["Sebag", "Mich\u00e8le", "", "INRIA Saclay - Ile de\n  France, LRI"]]}, {"id": "1206.6466", "submitter": "Lawrence McAfee", "authors": "Lawrence McAfee (Stanford University), Kunle Olukotun (Stanford\n  University)", "title": "Utilizing Static Analysis and Code Generation to Accelerate Neural\n  Networks", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As datasets continue to grow, neural network (NN) applications are becoming\nincreasingly limited by both the amount of available computational power and\nthe ease of developing high-performance applications. Researchers often must\nhave expert systems knowledge to make their algorithms run efficiently.\nAlthough available computing power increases rapidly each year, algorithm\nefficiency is not able to keep pace due to the use of general purpose\ncompilers, which are not able to fully optimize specialized application\ndomains. Within the domain of NNs, we have the added knowledge that network\narchitecture remains constant during training, meaning the architecture's data\nstructure can be statically optimized by a compiler. In this paper, we present\nSONNC, a compiler for NNs that utilizes static analysis to generate optimized\nparallel code. We show that SONNC's use of static optimizations make it able to\noutperform hand-optimized C++ code by up to 7.8X, and MATLAB code by up to 24X.\nAdditionally, we show that use of SONNC significantly reduces code complexity\nwhen using structurally sparse networks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["McAfee", "Lawrence", "", "Stanford University"], ["Olukotun", "Kunle", "", "Stanford\n  University"]]}, {"id": "1206.6722", "submitter": "Andrew Clark", "authors": "Andrew Clark", "title": "Piecewise Linear Topology, Evolutionary Algorithms, and Optimization\n  Problems", "comments": "PDF from Word docx, 11 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.GN math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Schemata theory, Markov chains, and statistical mechanics have been used to\nexplain how evolutionary algorithms (EAs) work. Incremental success has been\nachieved with all of these methods, but each has been stymied by limitations\nrelated to its less-than-global view. We show that moving the investigation\ninto topological space improves our understanding of why EAs work.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 15:13:37 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Clark", "Andrew", ""]]}]