[{"id": "2106.00014", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "Diffusion Self-Organizing Map on the Hypersphere", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a diffusion based implementation of the self-organizing map on the\nunit hypersphere. We show that this approach can be efficiently implemented\nusing just linear algebra methods, we give a python numpy implementation, and\nwe illustrate the approach using the well known MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 16:27:50 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "2106.00613", "submitter": "Jian Cui", "authors": "Jian Cui, Zirui Lan, Yisi Liu, Ruilin Li, Fan Li, Olga Sourina, and\n  Wolfgang Mueller-Wittig", "title": "A Compact and Interpretable Convolutional Neural Network for\n  Cross-Subject Driver Drowsiness Detection from Single-Channel EEG", "comments": null, "journal-ref": null, "doi": "10.1016/j.ymeth.2021.04.017", "report-no": null, "categories": "eess.SP cs.HC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Driver drowsiness is one of main factors leading to road fatalities and\nhazards in the transportation industry. Electroencephalography (EEG) has been\nconsidered as one of the best physiological signals to detect drivers drowsy\nstates, since it directly measures neurophysiological activities in the brain.\nHowever, designing a calibration-free system for driver drowsiness detection\nwith EEG is still a challenging task, as EEG suffers from serious mental and\nphysical drifts across different subjects. In this paper, we propose a compact\nand interpretable Convolutional Neural Network (CNN) to discover shared EEG\nfeatures across different subjects for driver drowsiness detection. We\nincorporate the Global Average Pooling (GAP) layer in the model structure,\nallowing the Class Activation Map (CAM) method to be used for localizing\nregions of the input signal that contribute most for classification. Results\nshow that the proposed model can achieve an average accuracy of 73.22% on 11\nsubjects for 2-class cross-subject EEG signal classification, which is higher\nthan conventional machine learning methods and other state-of-art deep learning\nmethods. It is revealed by the visualization technique that the model has\nlearned biologically explainable features, e.g., Alpha spindles and Theta\nburst, as evidence for the drowsy state. It is also interesting to see that the\nmodel uses artifacts that usually dominate the wakeful EEG, e.g., muscle\nartifacts and sensor drifts, to recognize the alert state. The proposed model\nillustrates a potential direction to use CNN models as a powerful tool to\ndiscover shared features related to different mental states across different\nsubjects from EEG signals.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 14:36:34 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Cui", "Jian", ""], ["Lan", "Zirui", ""], ["Liu", "Yisi", ""], ["Li", "Ruilin", ""], ["Li", "Fan", ""], ["Sourina", "Olga", ""], ["Mueller-Wittig", "Wolfgang", ""]]}, {"id": "2106.00672", "submitter": "Marcin Andrychowicz", "authors": "Manu Orsini, Anton Raichuk, L\\'eonard Hussenot, Damien Vincent, Robert\n  Dadashi, Sertan Girgin, Matthieu Geist, Olivier Bachem, Olivier Pietquin,\n  Marcin Andrychowicz", "title": "What Matters for Adversarial Imitation Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial imitation learning has become a popular framework for imitation\nin continuous control. Over the years, several variations of its components\nwere proposed to enhance the performance of the learned policies as well as the\nsample complexity of the algorithm. In practice, these choices are rarely\ntested all together in rigorous empirical studies. It is therefore difficult to\ndiscuss and understand what choices, among the high-level algorithmic options\nas well as low-level implementation details, matter. To tackle this issue, we\nimplement more than 50 of these choices in a generic adversarial imitation\nlearning framework and investigate their impacts in a large-scale study (>500k\ntrained agents) with both synthetic and human-generated demonstrations. While\nmany of our findings confirm common practices, some of them are surprising or\neven contradict prior work. In particular, our results suggest that artificial\ndemonstrations are not a good proxy for human data and that the very common\npractice of evaluating imitation algorithms only with synthetic demonstrations\nmay lead to algorithms which perform poorly in the more realistic scenarios\nwith human demonstrations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 17:58:08 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Orsini", "Manu", ""], ["Raichuk", "Anton", ""], ["Hussenot", "L\u00e9onard", ""], ["Vincent", "Damien", ""], ["Dadashi", "Robert", ""], ["Girgin", "Sertan", ""], ["Geist", "Matthieu", ""], ["Bachem", "Olivier", ""], ["Pietquin", "Olivier", ""], ["Andrychowicz", "Marcin", ""]]}, {"id": "2106.00687", "submitter": "Nik Dennler", "authors": "Nik Dennler, Germain Haessig, Matteo Cartiglia, Giacomo Indiveri", "title": "Online Detection of Vibration Anomalies Using Balanced Spiking Neural\n  Networks", "comments": "This work is presented at the 2021 IEEE AICAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vibration patterns yield valuable information about the health state of a\nrunning machine, which is commonly exploited in predictive maintenance tasks\nfor large industrial systems. However, the overhead, in terms of size,\ncomplexity and power budget, required by classical methods to exploit this\ninformation is often prohibitive for smaller-scale applications such as\nautonomous cars, drones or robotics. Here we propose a neuromorphic approach to\nperform vibration analysis using spiking neural networks that can be applied to\na wide range of scenarios. We present a spike-based end-to-end pipeline able to\ndetect system anomalies from vibration data, using building blocks that are\ncompatible with analog-digital neuromorphic circuits. This pipeline operates in\nan online unsupervised fashion, and relies on a cochlea model, on feedback\nadaptation and on a balanced spiking neural network. We show that the proposed\nmethod achieves state-of-the-art performance or better against two publicly\navailable data sets. Further, we demonstrate a working proof-of-concept\nimplemented on an asynchronous neuromorphic processor device. This work\nrepresents a significant step towards the design and implementation of\nautonomous low-power edge-computing devices for online vibration monitoring.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 18:00:02 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Dennler", "Nik", ""], ["Haessig", "Germain", ""], ["Cartiglia", "Matteo", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2106.00884", "submitter": "Brian Kidd", "authors": "Mohammadreza Armandpour, Brian Kidd, Yu Du, Jianhua Z. Huang", "title": "Deep Personalized Glucose Level Forecasting Using Attention-based\n  Recurrent Neural Networks", "comments": "8 pages, submitted to IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we study the problem of blood glucose forecasting and provide\na deep personalized solution. Predicting blood glucose level in people with\ndiabetes has significant value because health complications of abnormal glucose\nlevel are serious, sometimes even leading to death. Therefore, having a model\nthat can accurately and quickly warn patients of potential problems is\nessential. To develop a better deep model for blood glucose forecasting, we\nanalyze the data and detect important patterns. These observations helped us to\npropose a method that has several key advantages over existing methods: 1- it\nlearns a personalized model for each patient as well as a global model; 2- it\nuses an attention mechanism and extracted time features to better learn\nlong-term dependencies in the data; 3- it introduces a new, robust training\nprocedure for time series data. We empirically show the efficacy of our model\non a real dataset.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 01:36:53 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Armandpour", "Mohammadreza", ""], ["Kidd", "Brian", ""], ["Du", "Yu", ""], ["Huang", "Jianhua Z.", ""]]}, {"id": "2106.00901", "submitter": "Hiroshi Kajino", "authors": "Hiroshi Kajino", "title": "A Differentiable Point Process with Its Application to Spiking Neural\n  Networks", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is concerned about a learning algorithm for a probabilistic model\nof spiking neural networks (SNNs). Jimenez Rezende & Gerstner (2014) proposed a\nstochastic variational inference algorithm to train SNNs with hidden neurons.\nThe algorithm updates the variational distribution using the score function\ngradient estimator, whose high variance often impedes the whole learning\nalgorithm. This paper presents an alternative gradient estimator for SNNs based\non the path-wise gradient estimator. The main technical difficulty is a lack of\na general method to differentiate a realization of an arbitrary point process,\nwhich is necessary to derive the path-wise gradient estimator. We develop a\ndifferentiable point process, which is the technical highlight of this paper,\nand apply it to derive the path-wise gradient estimator for SNNs. We\ninvestigate the effectiveness of our gradient estimator through numerical\nsimulation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:40:17 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 07:15:32 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Kajino", "Hiroshi", ""]]}, {"id": "2106.00958", "submitter": "Diogo Almeida", "authors": "Diogo Almeida, Clemens Winter, Jie Tang, Wojciech Zaremba", "title": "A Generalizable Approach to Learning Optimizers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core issue with learning to optimize neural networks has been the lack of\ngeneralization to real world problems. To address this, we describe a system\ndesigned from a generalization-first perspective, learning to update optimizer\nhyperparameters instead of model parameters directly using novel features,\nactions, and a reward function. This system outperforms Adam at all neural\nnetwork tasks including on modalities not seen during training. We achieve 2x\nspeedups on ImageNet, and a 2.5x speedup on a language modeling task using over\n5 orders of magnitude more compute than the training tasks.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 06:03:18 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 19:36:13 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Almeida", "Diogo", ""], ["Winter", "Clemens", ""], ["Tang", "Jie", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "2106.01100", "submitter": "Michel Pohl", "authors": "Michel Pohl, Mitsuru Uesaka, Hiroyuki Takahashi, Kazuyuki Demachi and\n  Ritu Bhusal Chhatkuli", "title": "Prediction of the Position of External Markers Using a Recurrent Neural\n  Network Trained With Unbiased Online Recurrent Optimization for Safe Lung\n  Cancer Radiotherapy", "comments": "20 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During lung cancer radiotherapy, the position of infrared reflective objects\non the chest can be recorded to estimate the tumor location. However,\nradiotherapy systems usually have a latency inherent to robot control\nlimitations that impedes the radiation delivery precision. Not taking this\nphenomenon into account may cause unwanted damage to healthy tissues and lead\nto side effects such as radiation pneumonitis. In this research, we use nine\nobservation records of the three-dimensional position of three external markers\non the chest and abdomen of healthy individuals breathing during intervals from\n73s to 222s. The sampling frequency is equal to 10Hz and the amplitudes of the\nrecorded trajectories range from 6mm to 40mm in the superior-inferior\ndirection. We forecast the location of each marker simultaneously with a\nhorizon value (the time interval in advance for which the prediction is made)\nbetween 0.1s and 2.0s, using a recurrent neural network (RNN) trained with\nunbiased online recurrent optimization (UORO). We compare its performance with\nan RNN trained with real-time recurrent learning, least mean squares (LMS), and\noffline linear regression. Training and cross-validation are performed during\nthe first minute of each sequence. On average, UORO achieves the lowest\nroot-mean-square (RMS) and maximum error, equal respectively to 1.3mm and\n8.8mm, with a prediction time per time step lower than 2.8ms (Dell Intel core\ni9-9900K 3.60Ghz). Linear regression has the lowest RMS error for the horizon\nvalues 0.1s and 0.2s, followed by LMS for horizon values between 0.3s and 0.5s,\nand UORO for horizon values greater than 0.6s.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:07:31 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Pohl", "Michel", ""], ["Uesaka", "Mitsuru", ""], ["Takahashi", "Hiroyuki", ""], ["Demachi", "Kazuyuki", ""], ["Chhatkuli", "Ritu Bhusal", ""]]}, {"id": "2106.01101", "submitter": "Gilad Yehudai", "authors": "Gal Vardi, Gilad Yehudai, Ohad Shamir", "title": "Learning a Single Neuron with Bias Using Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We theoretically study the fundamental problem of learning a single neuron\nwith a bias term ($\\mathbf{x} \\mapsto \\sigma(<\\mathbf{w},\\mathbf{x}> + b)$) in\nthe realizable setting with the ReLU activation, using gradient descent.\nPerhaps surprisingly, we show that this is a significantly different and more\nchallenging problem than the bias-less case (which was the focus of previous\nworks on single neurons), both in terms of the optimization geometry as well as\nthe ability of gradient methods to succeed in some scenarios. We provide a\ndetailed study of this problem, characterizing the critical points of the\nobjective, demonstrating failure cases, and providing positive convergence\nguarantees under different sets of assumptions. To prove our results, we\ndevelop some tools which may be of independent interest, and improve previous\nresults on learning single neurons.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 12:09:55 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Vardi", "Gal", ""], ["Yehudai", "Gilad", ""], ["Shamir", "Ohad", ""]]}, {"id": "2106.01146", "submitter": "Ajitabh Kumar", "authors": "Ajitabh Kumar", "title": "Multi-stage, multi-swarm PSO for joint optimization of well placement\n  and control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evolutionary optimization algorithms, including particle swarm optimization\n(PSO), have been successfully applied in oil industry for production planning\nand control. Such optimization studies are quite challenging due to large\nnumber of decision variables, production scenarios, and subsurface\nuncertainties. In this work, a multi-stage, multi-swarm PSO (MS2PSO) is\nproposed to fix certain issues with canonical PSO algorithm such as premature\nconvergence, excessive influence of global best solution, and oscillation.\n  Multiple experiments are conducted using Olympus benchmark to compare the\nefficacy of algorithms. Canonical PSO hyperparameters are first tuned to\nprioritize exploration in early phase and exploitation in late phase. Next, a\ntwo-stage multi-swarm PSO (2SPSO) is used where multiple-swarms of the first\nstage collapse into a single swarm in the second stage. Finally, MS2PSO with\nmultiple stages and multiple swarms is used in which swarms recursively\ncollapse after each stage. Multiple swarm strategy ensures that diversity is\nretained within the population and multiple modes are explored. Staging ensures\nthat local optima found during initial stage does not lead to premature\nconvergence. Optimization test case comprises of 90 control variables and a\ntwenty year period of flow simulation. It is observed that different algorithm\ndesigns have their own benefits and drawbacks. Multiple swarms and stages help\nalgorithm to move away from local optima, but at the same time they may also\nnecessitate larger number of iterations for convergence. Both 2SPSO and MS2PSO\nare found to be helpful for problems with high dimensions and multiple modes\nwhere greater degree of exploration is desired.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 13:34:50 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kumar", "Ajitabh", ""]]}, {"id": "2106.01176", "submitter": "Hossein Monshizadeh Naeen", "authors": "Maliheh Roknizadeh, Hossein Monshizadeh Naeen", "title": "Hybrid Ensemble optimized algorithm based on Genetic Programming for\n  imbalanced data classification", "comments": "11 pages, 4 Tables, 7 Figures Accepted in Twelfth International\n  Conference on Information Technology, Computer and Telecommunications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most significant current discussions in the field of data mining\nis classifying imbalanced data. In recent years, several ways are proposed such\nas algorithm level (internal) approaches, data level (external) techniques, and\ncost-sensitive methods. Although extensive research has been carried out on\nimbalanced data classification, however, several unsolved challenges remain\nsuch as no attention to the importance of samples to balance, determine the\nappropriate number of classifiers, and no optimization of classifiers in the\ncombination of classifiers. The purpose of this paper is to improve the\nefficiency of the ensemble method in the sampling of training data sets,\nespecially in the minority class, and to determine better basic classifiers for\ncombining classifiers than existing methods. We proposed a hybrid ensemble\nalgorithm based on Genetic Programming (GP) for two classes of imbalanced data\nclassification. In this study uses historical data from UCI Machine Learning\nRepository to assess minority classes in imbalanced datasets. The performance\nof our proposed algorithm is evaluated by Rapid-miner studio v.7.5.\nExperimental results show the performance of the proposed method on the\nspecified data sets in the size of the training set shows 40% and 50% better\naccuracy than other dimensions of the minority class prediction.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:14:38 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Roknizadeh", "Maliheh", ""], ["Naeen", "Hossein Monshizadeh", ""]]}, {"id": "2106.01177", "submitter": "Nicolas Skatchkovsky", "authors": "Nicolas Skatchkovsky, Osvaldo Simeone, Hyeryung Jang", "title": "Learning to Time-Decode in Spiking Neural Networks Through the\n  Information Bottleneck", "comments": "Under review for conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the key challenges in training Spiking Neural Networks (SNNs) is that\ntarget outputs typically come in the form of natural signals, such as labels\nfor classification or images for generative models, and need to be encoded into\nspikes. This is done by handcrafting target spiking signals, which in turn\nimplicitly fixes the mechanisms used to decode spikes into natural signals,\ne.g., rate decoding. The arbitrary choice of target signals and decoding rule\ngenerally impairs the capacity of the SNN to encode and process information in\nthe timing of spikes. To address this problem, this work introduces a hybrid\nvariational autoencoder architecture, consisting of an encoding SNN and a\ndecoding Artificial Neural Network (ANN). The role of the decoding ANN is to\nlearn how to best convert the spiking signals output by the SNN into the target\nnatural signal. A novel end-to-end learning rule is introduced that optimizes a\ndirected information bottleneck training criterion via surrogate gradients. We\ndemonstrate the applicability of the technique in an experimental settings on\nvarious tasks, including real-life datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:14:47 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Skatchkovsky", "Nicolas", ""], ["Simeone", "Osvaldo", ""], ["Jang", "Hyeryung", ""]]}, {"id": "2106.01182", "submitter": "Matthias Gro{\\ss}", "authors": "Matthias Gro{\\ss}, Dietlind Z\\\"uhlke, Boris Naujoks", "title": "Automating Speedrun Routing: Overview and Vision", "comments": "8 pages, submitted to IEEE Conference on Games 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Speedrunning in general means to play a video game fast, i.e. using all means\nat one's disposal to achieve a given goal in the least amount of time possible.\nTo do so, a speedrun must be planned in advance, or routed, as it is referred\nto by the community. This paper focuses on discovering challenges and defining\nmodels needed when trying to approach the problem of routing algorithmically.\nIt provides an overview of relevant speedrunning literature, extracting vital\ninformation and formulating criticism. Important categorizations are pointed\nout and a nomenclature is build to support professional discussion. Different\nconcepts of graph representations are presented and their potential is\ndiscussed with regard to solving the speedrun routing optimization problem.\nVisions both for problem modeling as well as solving are presented and assessed\nregarding suitability and expected challenges. This results in a vision of\npotential solutions and what will be addressed in the future.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 14:26:26 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Gro\u00df", "Matthias", ""], ["Z\u00fchlke", "Dietlind", ""], ["Naujoks", "Boris", ""]]}, {"id": "2106.01288", "submitter": "Charlotte Frenkel", "authors": "Charlotte Frenkel, David Bol, Giacomo Indiveri", "title": "Bottom-Up and Top-Down Neural Processing Systems Design: Neuromorphic\n  Intelligence as the Convergence of Natural and Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Moore's law has driven exponential computing power expectations, its\nnearing end calls for new avenues for improving the overall system performance.\nOne of these avenues is the exploration of new alternative brain-inspired\ncomputing architectures that promise to achieve the flexibility and\ncomputational efficiency of biological neural processing systems. Within this\ncontext, neuromorphic intelligence represents a paradigm shift in computing\nbased on the implementation of spiking neural network architectures tightly\nco-locating processing and memory. In this paper, we provide a comprehensive\noverview of the field, highlighting the different levels of granularity present\nin existing silicon implementations, comparing approaches that aim at\nreplicating natural intelligence (bottom-up) versus those that aim at solving\npractical artificial intelligence applications (top-down), and assessing the\nbenefits of the different circuit design styles used to achieve these goals.\nFirst, we present the analog, mixed-signal and digital circuit design styles,\nidentifying the boundary between processing and memory through time\nmultiplexing, in-memory computation and novel devices. Next, we highlight the\nkey tradeoffs for each of the bottom-up and top-down approaches, survey their\nsilicon implementations, and carry out detailed comparative analyses to extract\ndesign guidelines. Finally, we identify both necessary synergies and missing\nelements required to achieve a competitive advantage for neuromorphic edge\ncomputing over conventional machine-learning accelerators, and outline the key\nelements for a framework toward neuromorphic intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:51:45 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Frenkel", "Charlotte", ""], ["Bol", "David", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2106.01329", "submitter": "Giacomo Indiveri", "authors": "Giacomo Indiveri", "title": "Introducing \"Neuromorphic Computing and Engineering\"", "comments": "NCE Editorial", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CE cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard nature of computing is currently being challenged by a range of\nproblems that start to hinder technological progress. One of the strategies\nbeing proposed to address some of these problems is to develop novel\nbrain-inspired processing methods and technologies, and apply them to a wide\nrange of application scenarios. This is an extremely challenging endeavor that\nrequires researchers in multiple disciplines to combine their efforts and\nco-design at the same time the processing methods, the supporting computing\narchitectures, and their underlying technologies. The journal ``Neuromorphic\nComputing and Engineering'' (NCE) has been launched to support this new\ncommunity in this effort and provide a forum and repository for presenting and\ndiscussing its latest advances. Through close collaboration with our colleagues\non the editorial team, the scope and characteristics of NCE have been designed\nto ensure it serves a growing transdisciplinary and dynamic community across\nacademia and industry.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 20:12:27 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Indiveri", "Giacomo", ""]]}, {"id": "2106.01435", "submitter": "Tarik A. Rashid", "authors": "Hu Tianqing, Mohammad Khishe, Mokhtar Mohammadi, Gholam-Reza Parvizi,\n  Sarkhel H. Taher Karim, Tarik A. Rashid", "title": "Real-Time COVID-19 Diagnosis from X-Ray Images Using Deep CNN and\n  Extreme Learning Machines Stabilized by Chimp Optimization Algorithm", "comments": "17 pages. arXiv admin note: text overlap with arXiv:2105.14192", "journal-ref": "Biomedical Signal Processing and Control, 2021", "doi": "10.1016/j.bspc.2021.102764", "report-no": null, "categories": "eess.IV cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Real-time detection of COVID-19 using radiological images has gained priority\ndue to the increasing demand for fast diagnosis of COVID-19 cases. This paper\nintroduces a novel two-phase approach for classifying chest X-ray images. Deep\nLearning (DL) methods fail to cover these aspects since training and\nfine-tuning the model's parameters consume much time. In this approach, the\nfirst phase comes to train a deep CNN working as a feature extractor, and the\nsecond phase comes to use Extreme Learning Machines (ELMs) for real-time\ndetection. The main drawback of ELMs is to meet the need of a large number of\nhidden-layer nodes to gain a reliable and accurate detector in applying image\nprocessing since the detective performance remarkably depends on the setting of\ninitial weights and biases. Therefore, this paper uses Chimp Optimization\nAlgorithm (ChOA) to improve results and increase the reliability of the network\nwhile maintaining real-time capability. The designed detector is to be\nbenchmarked on the COVID-Xray-5k and COVIDetectioNet datasets, and the results\nare verified by comparing it with the classic DCNN, Genetic Algorithm optimized\nELM (GA-ELM), Cuckoo Search optimized ELM (CS-ELM), and Whale Optimization\nAlgorithm optimized ELM (WOA-ELM). The proposed approach outperforms other\ncomparative benchmarks with 98.25% and 99.11% as ultimate accuracy on the\nCOVID-Xray-5k and COVIDetectioNet datasets, respectively, and it led relative\nerror to reduce as the amount of 1.75% and 1.01% as compared to a convolutional\nCNN. More importantly, the time needed for training deep ChOA-ELM is only\n0.9474 milliseconds, and the overall testing time for 3100 images is 2.937\nseconds.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 20:04:04 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Tianqing", "Hu", ""], ["Khishe", "Mohammad", ""], ["Mohammadi", "Mokhtar", ""], ["Parvizi", "Gholam-Reza", ""], ["Karim", "Sarkhel H. Taher", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2106.01683", "submitter": "Udaya B Rongala", "authors": "Udaya B. Rongala and Henrik J\\\"orntell", "title": "Rich dynamics caused by known biological brain network features\n  resulting in stateful networks", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The mammalian brain could contain dense and sparse network connectivity\nstructures, including both excitatory and inhibitory neurons, but is without\nany clearly defined output layer. The neurons have time constants, which mean\nthat the integrated network structure has state memory. The network structure\ncontains complex mutual interactions between the neurons under different\nconditions, which depend on the internal state of the network. The internal\nstate can be defined as the distribution of activity across all individual\nneurons across the network. Therefore, the state of a neuron/network becomes a\ndefining factor for how information is represented within the network. Towards\nthis study, we constructed a fully connected (with dense/sparse coding\nstrategies) recurrent network comprising of both excitatory and inhibitory\nneurons, driven by pseudo-random inputs of varying frequencies. In this study\nwe assessed the impact of varying specific intrinsic parameters of the neurons\nthat enriched network state dynamics, such as initial neuron activity, amount\nof inhibition in combination with thresholded neurons and conduction delays.\nThe impact was assessed by quantifying the changes in mutual interactions\nbetween the neurons within the network for each given input. We found such\neffects were more profound in sparsely connected networks than in densely\nconnected networks. However, also densely connected networks could make use of\nsuch dynamic changes in the mutual interactions between neurons, as a given\ninput could induce multiple different network states.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 08:32:43 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Rongala", "Udaya B.", ""], ["J\u00f6rntell", "Henrik", ""]]}, {"id": "2106.01741", "submitter": "David Mark Bossens", "authors": "David M. Bossens and Adam J. Sobey", "title": "Lifetime policy reuse and the importance of task capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing challenge in artificial intelligence is lifelong learning. In\nlifelong learning, many tasks are presented in sequence and learners must\nefficiently transfer knowledge between tasks while avoiding catastrophic\nforgetting over long lifetimes. On these problems, policy reuse and other\nmulti-policy reinforcement learning techniques can learn many tasks. However,\nthey can generate many temporary or permanent policies, resulting in memory\nissues. Consequently, there is a need for lifetime-scalable methods that\ncontinually refine a policy library of a pre-defined size. This paper presents\na first approach to lifetime-scalable policy reuse. To pre-select the number of\npolicies, a notion of task capacity, the maximal number of tasks that a policy\ncan accurately solve, is proposed. To evaluate lifetime policy reuse using this\nmethod, two state-of-the-art single-actor base-learners are compared: 1) a\nvalue-based reinforcement learner, Deep Q-Network (DQN) or Deep Recurrent\nQ-Network (DRQN); and 2) an actor-critic reinforcement learner, Proximal Policy\nOptimisation (PPO) with or without Long Short-Term Memory layer. By selecting\nthe number of policies based on task capacity, D(R)QN achieves near-optimal\nperformance with 6 policies in a 27-task MDP domain and 9 policies in an\n18-task POMDP domain; with fewer policies, catastrophic forgetting and negative\ntransfer are observed. Due to slow, monotonic improvement, PPO requires fewer\npolicies, 1 policy for the 27-task domain and 4 policies for the 18-task\ndomain, but it learns the tasks with lower accuracy than D(R)QN. These findings\nvalidate lifetime-scalable policy reuse and suggest using D(R)QN for larger and\nPPO for smaller library sizes.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 10:42:49 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bossens", "David M.", ""], ["Sobey", "Adam J.", ""]]}, {"id": "2106.01900", "submitter": "Luca Mariot", "authors": "Mauro Castelli, Luca Manzoni, Luca Mariot, Marco S. Nobile, Andrea\n  Tangherloni", "title": "Salp Swarm Optimization: a Critical Review", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the crowded environment of bio-inspired population-based meta-heuristics,\nthe Salp Swarm Optimization (SSO) algorithm recently appeared and immediately\ngained a lot of momentum. Inspired by the peculiar spatial arrangement of salp\ncolonies, which are displaced in long chains following a leader, this algorithm\nseems to provide interesting optimization performances. However, the original\nwork was characterized by some conceptual and mathematical flaws, which\ninfluenced all ensuing papers on the subject. In this manuscript, we perform a\ncritical review of SSO, highlighting all the issues present in the literature\nand their negative effects on the optimization process carried out by the\nalgorithm. We also propose a mathematically correct version of SSO, named\nAmended Salp Swarm Optimizer (ASSO) that fixes all the discussed problems.\nFinally, we benchmark the performance of ASSO on a set of tailored experiments,\nshowing it achieves better results than the original SSO.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 14:43:37 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Castelli", "Mauro", ""], ["Manzoni", "Luca", ""], ["Mariot", "Luca", ""], ["Nobile", "Marco S.", ""], ["Tangherloni", "Andrea", ""]]}, {"id": "2106.01920", "submitter": "Kunal Bhardwaj", "authors": "Kunal Bhardwaj", "title": "Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement\n  Prediction", "comments": "19 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With technological advancements and the exponential growth of data, we have\nbeen unfolding different capabilities of neural networks in different sectors.\nIn this paper, I have tried to use a specific type of Neural Network known as\nConvolutional Neural Network(CNN/ConvNet) in the stock market. In other words,\nI have tried to construct and train a convolutional neural network on past\nstock prices data and then tried to predict the movement of stock price i.e.\nwhether the stock price would rise or fall, in the coming time.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 15:14:46 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Bhardwaj", "Kunal", ""]]}, {"id": "2106.01958", "submitter": "Abhishek Ramdas Nair", "authors": "Abhishek Ramdas Nair, Pallab Kumar Nath, Shantanu Chakrabartty, Chetan\n  Singh Thakur", "title": "Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel framework for designing multiplierless kernel machines\nthat can be used on resource-constrained platforms like intelligent edge\ndevices. The framework uses a piecewise linear (PWL) approximation based on a\nmargin propagation (MP) technique and uses only addition/subtraction, shift,\ncomparison, and register underflow/overflow operations. We propose a\nhardware-friendly MP-based inference and online training algorithm that has\nbeen optimized for a Field Programmable Gate Array (FPGA) platform. Our FPGA\nimplementation eliminates the need for DSP units and reduces the number of\nLUTs. By reusing the same hardware for inference and training, we show that the\nplatform can overcome classification errors and local minima artifacts that\nresult from the MP approximation. Using the FPGA platform, we also show that\nthe proposed multiplierless MP-kernel machine demonstrates superior performance\nin terms of power, performance, and area compared to other comparable\nimplementations.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jun 2021 16:06:08 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Nair", "Abhishek Ramdas", ""], ["Nath", "Pallab Kumar", ""], ["Chakrabartty", "Shantanu", ""], ["Thakur", "Chetan Singh", ""]]}, {"id": "2106.02328", "submitter": "Torsten Sch\\\"on", "authors": "Thangapavithraa Balaji, Patrick Blies, Georg G\\\"ori, Raphael Mitsch,\n  Marcel Wasserer, Torsten Sch\\\"on", "title": "Temporally coherent video anonymization through GAN inpainting", "comments": "Preprint of our FG2021 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work tackles the problem of temporally coherent face anonymization in\nnatural video streams.We propose JaGAN, a two-stage system starting with\ndetecting and masking out faces with black image patches in all individual\nframes of the video. The second stage leverages a privacy-preserving Video\nGenerative Adversarial Network designed to inpaint the missing image patches\nwith artificially generated faces. Our initial experiments reveal that image\nbased generative models are not capable of inpainting patches showing temporal\ncoherent appearance across neighboring video frames. To address this issue we\nintroduce a newly curated video collection, which is made publicly available\nfor the research community along with this paper. We also introduce the\nIdentity Invariance Score IdI as a means to quantify temporal coherency between\nneighboring frames.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 08:19:44 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Balaji", "Thangapavithraa", ""], ["Blies", "Patrick", ""], ["G\u00f6ri", "Georg", ""], ["Mitsch", "Raphael", ""], ["Wasserer", "Marcel", ""], ["Sch\u00f6n", "Torsten", ""]]}, {"id": "2106.02479", "submitter": "Leon Bungert", "authors": "Leon Bungert, Tim Roith, Daniel Tenbrinck, Martin Burger", "title": "Neural Architecture Search via Bregman Iterations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel strategy for Neural Architecture Search (NAS) based on\nBregman iterations. Starting from a sparse neural network our gradient-based\none-shot algorithm gradually adds relevant parameters in an inverse scale space\nmanner. This allows the network to choose the best architecture in the search\nspace which makes it well-designed for a given task, e.g., by adding neurons or\nskip connections. We demonstrate that using our approach one can unveil, for\ninstance, residual autoencoders for denoising, deblurring, and classification\ntasks. Code is available at https://github.com/TimRoith/BregmanLearning.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 13:37:47 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Bungert", "Leon", ""], ["Roith", "Tim", ""], ["Tenbrinck", "Daniel", ""], ["Burger", "Martin", ""]]}, {"id": "2106.02490", "submitter": "Thomas Conley", "authors": "Thomas Conley and Jugal Kalita", "title": "Language Model Metrics and Procrustes Analysis for Improved Vector\n  Transformation of NLP Embeddings", "comments": null, "journal-ref": "Proceedings of the 17th International Conference on Natural\n  Language Processing, pages 170-174, Patna, India, December 18-21, 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Neural networks are mathematical models at their core. This\ntruismpresents some fundamental difficulty when networks are tasked with\nNatural Language Processing. A key problem lies in measuring the similarity or\ndistance among vectors in NLP embedding space, since the mathematical concept\nof distance does not always agree with the linguistic concept. We suggest that\nthe best way to measure linguistic distance among vectors is by employing the\nLanguage Model (LM) that created them. We introduce Language Model Distance\n(LMD) for measuring accuracy of vector transformations based on the\nDistributional Hypothesis ( LMD Accuracy ). We show the efficacy of this metric\nby applying it to a simple neural network learning the Procrustes algorithm for\nbilingual word mapping.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 13:56:10 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Conley", "Thomas", ""], ["Kalita", "Jugal", ""]]}, {"id": "2106.02568", "submitter": "Seongsik Park", "authors": "Seongsik Park, Sungroh Yoon", "title": "Training Energy-Efficient Deep Spiking Neural Networks with\n  Time-to-First-Spike Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous energy consumption of deep neural networks (DNNs) has become a\nserious problem in deep learning. Spiking neural networks (SNNs), which mimic\nthe operations in the human brain, have been studied as prominent\nenergy-efficient neural networks. Due to their event-driven and\nspatiotemporally sparse operations, SNNs show possibilities for\nenergy-efficient processing. To unlock their potential, deep SNNs have adopted\ntemporal coding such as time-to-first-spike (TTFS)coding, which represents the\ninformation between neurons by the first spike time. With TTFS coding, each\nneuron generates one spike at most, which leads to a significant improvement in\nenergy efficiency. Several studies have successfully introduced TTFS coding in\ndeep SNNs, but they showed restricted efficiency improvement owing to the lack\nof consideration for efficiency during training. To address the aforementioned\nissue, this paper presents training methods for energy-efficient deep SNNs with\nTTFS coding. We introduce a surrogate DNN model to train the deep SNN in a\nfeasible time and analyze the effect of the temporal kernel on training\nperformance and efficiency. Based on the investigation, we propose\nstochastically relaxed activation and initial value-based regularization for\nthe temporal kernel parameters. In addition, to reduce the number of spikes\neven further, we present temporal kernel-aware batch normalization. With the\nproposed methods, we could achieve comparable training results with\nsignificantly reduced spikes, which could lead to energy-efficient deep SNNs.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 16:02:27 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Park", "Seongsik", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2106.02619", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Forward Super-Resolution: How Can GANs Learn Hierarchical Generative\n  Models for Real-World Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are among the most successful models\nfor learning high-complexity, real-world distributions. However, in theory, due\nto the highly non-convex, non-concave landscape of the minmax training\nobjective, GAN remains one of the least understood deep learning models. In\nthis work, we formally study how GANs can efficiently learn certain\nhierarchically generated distributions that are close to the distribution of\nimages in practice. We prove that when a distribution has a structure that we\nrefer to as Forward Super-Resolution, then simply training generative\nadversarial networks using gradient descent ascent (GDA) can indeed learn this\ndistribution efficiently, both in terms of sample and time complexities. We\nalso provide concrete empirical evidence that not only our assumption \"forward\nsuper-resolution\" is very natural in practice, but also the underlying learning\nmechanisms that we study in this paper (to allow us efficiently train GAN via\nGDA in theory) simulates the actual learning process of GANs in practice on\nreal-world problems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:33:29 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2106.02626", "submitter": "Gabriel B\\'ena", "authors": "Gabriel B\\'ena, Dan F. M. Goodman", "title": "Extreme sparsity gives rise to functional specialization", "comments": "12 pages, 4 figures, Preprint (submitted to Neurips 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modularity of neural networks -- both biological and artificial -- can be\nthought of either structurally or functionally, and the relationship between\nthese is an open question. We show that enforcing structural modularity via\nsparse connectivity between two dense sub-networks which need to communicate to\nsolve the task leads to functional specialization of the sub-networks, but only\nat extreme levels of sparsity. With even a moderate number of interconnections,\nthe sub-networks become functionally entangled. Defining functional\nspecialization is in itself a challenging problem without a universally agreed\nsolution. To address this, we designed three different measures of\nspecialization (based on weight masks, retraining and correlation) and found\nthem to qualitatively agree. Our results have implications in both neuroscience\nand machine learning. For neuroscience, it shows that we cannot conclude that\nthere is functional modularity simply by observing moderate levels of\nstructural modularity: knowing the brain's connectome is not sufficient for\nunderstanding how it breaks down into functional modules. For machine learning,\nusing structure to promote functional modularity -- which may be important for\nrobustness and generalization -- may require extremely narrow bottlenecks\nbetween modules.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 17:39:36 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["B\u00e9na", "Gabriel", ""], ["Goodman", "Dan F. M.", ""]]}, {"id": "2106.02681", "submitter": "Samuel Schmidgall", "authors": "Samuel Schmidgall, Julia Ashkanazy, Wallace Lawson, Joe Hays", "title": "SpikePropamine: Differentiable Plasticity in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The adaptive changes in synaptic efficacy that occur between spiking neurons\nhave been demonstrated to play a critical role in learning for biological\nneural networks. Despite this source of inspiration, many learning focused\napplications using Spiking Neural Networks (SNNs) retain static synaptic\nconnections, preventing additional learning after the initial training period.\nHere, we introduce a framework for simultaneously learning the underlying\nfixed-weights and the rules governing the dynamics of synaptic plasticity and\nneuromodulated synaptic plasticity in SNNs through gradient descent. We further\ndemonstrate the capabilities of this framework on a series of challenging\nbenchmarks, learning the parameters of several plasticity rules including BCM,\nOja's, and their respective set of neuromodulatory variants. The experimental\nresults display that SNNs augmented with differentiable plasticity are\nsufficient for solving a set of challenging temporal learning tasks that a\ntraditional SNN fails to solve, even in the presence of significant noise.\nThese networks are also shown to be capable of producing locomotion on a\nhigh-dimensional robotic learning task, where near-minimal degradation in\nperformance is observed in the presence of novel conditions not seen during the\ninitial training period.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:29:07 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Schmidgall", "Samuel", ""], ["Ashkanazy", "Julia", ""], ["Lawson", "Wallace", ""], ["Hays", "Joe", ""]]}, {"id": "2106.02894", "submitter": "Xun Jiao", "authors": "Dongning Ma, Xun Jiao", "title": "MoleHD: Automated Drug Discovery using Brain-Inspired Hyperdimensional\n  Computing", "comments": "Under review for NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern drug discovery is often time-consuming, complex and cost-ineffective\ndue to the large volume of molecular data and complicated molecular properties.\nRecently, machine learning algorithms have shown promising results in virtual\nscreening of automated drug discovery by predicting molecular properties. While\nemerging learning methods such as graph neural networks and recurrent neural\nnetworks exhibit high accuracy, they are also notoriously computation-intensive\nand memory-intensive with operations such as feature embeddings or deep\nconvolutions. In this paper, we propose a viable alternative to neural network\nclassifiers. We present MoleHD, a method based on brain-inspired\nhyperdimensional computing (HDC) for molecular property prediction. We first\ntransform the SMILES presentation of molecules into feature vectors by SMILE-PE\ntokenizers pretrained on the ChEMBL database. Then, we develop HDC encoders to\nproject such features into high-dimensional vectors that are used for training\nand inference. We perform an extensive evaluation using 30 classification tasks\nfrom 3 widely-used molecule datasets and compare MoleHD with 10 baseline\nmethods including 6 SOTA neural network classifiers. Results show that MoleHD\nis able to outperform all the baseline methods on average across 30\nclassification tasks with significantly reduced computing cost. To the best of\nour knowledge, we develop the first HDC-based method for drug discovery. The\npromising results presented in this paper can potentially lead to a novel path\nin drug discovery research.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 13:33:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ma", "Dongning", ""], ["Jiao", "Xun", ""]]}, {"id": "2106.02926", "submitter": "Won-Yong Shin", "authors": "Cong Tran, Won-Yong Shin, Andreas Spitz", "title": "IM-META: Influence Maximization Using Node Metadata in Networks With\n  Unknown Topology", "comments": "14 pages, 12 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.IT cs.LG cs.NE math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real-world applications of influence maximization (IM), the network\nstructure is often unknown. In this case, we may identify the most influential\nseed nodes by exploring only a part of the underlying network given a small\nbudget for node queries. Motivated by the fact that collecting node metadata is\nmore cost-effective than investigating the relationship between nodes via\nqueried nodes, we develop IM-META, an end-to-end solution to IM in networks\nwith unknown topology by retrieving information from both queries and node\nmetadata. However, using such metadata to aid the IM process is not without\nrisk due to the noisy nature of metadata and uncertainties in connectivity\ninference. To tackle these challenges, we formulate an IM problem that aims to\nfind two sets, i.e., seed nodes and queried nodes. We propose an effective\nmethod that iteratively performs three steps: 1) we learn the relationship\nbetween collected metadata and edges via a Siamese neural network model, 2) we\nselect a number of inferred influential edges to construct a reinforced graph\nused for discovering an optimal seed set, and 3) we identify the next node to\nquery by maximizing the inferred influence spread using a topology-aware\nranking strategy. By querying only 5% of nodes, IM-META reaches 93% of the\nupper bound performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jun 2021 16:11:02 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Tran", "Cong", ""], ["Shin", "Won-Yong", ""], ["Spitz", "Andreas", ""]]}, {"id": "2106.03007", "submitter": "Shohei Ohsawa", "authors": "Shohei Ohsawa", "title": "Unbiased Self-Play", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE econ.EM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a general optimization framework for emergent belief-state\nrepresentation without any supervision. We employed the common configuration of\nmultiagent reinforcement learning and communication to improve exploration\ncoverage over an environment by leveraging the knowledge of each agent. In this\npaper, we obtained that recurrent neural nets (RNNs) with shared weights are\nhighly biased in partially observable environments because of their\nnoncooperativity. To address this, we designated an unbiased version of\nself-play via mechanism design, also known as reverse game theory, to clarify\nunbiased knowledge at the Bayesian Nash equilibrium. The key idea is to add\nimaginary rewards using the peer prediction mechanism, i.e., a mechanism for\nmutually criticizing information in a decentralized environment. Numerical\nanalyses, including StarCraft exploration tasks with up to 20 agents and\noff-the-shelf RNNs, demonstrate the state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 02:16:45 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ohsawa", "Shohei", ""]]}, {"id": "2106.03275", "submitter": "Richard Allmendinger", "authors": "Richard Allmendinger, Andrzej Jaszkiewicz, Arnaud Liefooghe,\n  Christiane Tammer", "title": "What if we Increase the Number of Objectives? Theoretical and Empirical\n  Implications for Many-objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The difficulty of solving a multi-objective optimization problem is impacted\nby the number of objectives to be optimized. The presence of many objectives\ntypically introduces a number of challenges that affect the choice/design of\noptimization algorithms. This paper investigates the drivers of these\nchallenges from two angles: (i) the influence of the number of objectives on\nproblem characteristics and (ii) the practical behavior of commonly used\nprocedures and algorithms for coping with many objectives. In addition to\nreviewing various drivers, the paper makes theoretical contributions by\nquantifying some drivers and/or verifying these drivers empirically by carrying\nout experiments on multi-objective NK landscapes and other typical benchmarks.\nWe then make use of our theoretical and empirical findings to derive practical\nrecommendations to support algorithm design. Finally, we discuss remaining\ntheoretical gaps and opportunities for future research in the area of multi-\nand many-objective optimization.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 23:25:35 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Allmendinger", "Richard", ""], ["Jaszkiewicz", "Andrzej", ""], ["Liefooghe", "Arnaud", ""], ["Tammer", "Christiane", ""]]}, {"id": "2106.03394", "submitter": "Dai Hai Nguyen", "authors": "Dai Hai Nguyen and Koji Tsuda", "title": "A generative model for molecule generation based on chemical reaction\n  trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have been shown powerful in generating novel molecules\nwith desired chemical properties via their representations such as strings,\ntrees or graphs. However, these models are limited in recommending synthetic\nroutes for the generated molecules in practice. We propose a generative model\nto generate molecules via multi-step chemical reaction trees. Specifically, our\nmodel first propose a chemical reaction tree with predicted reaction templates\nand commercially available molecules (starting molecules), and then perform\nforward synthetic steps to obtain product molecules. Experiments show that our\nmodel can generate chemical reactions whose product molecules are with desired\nchemical properties. Also, the complete synthetic routes for these product\nmolecules are provided.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 07:47:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nguyen", "Dai Hai", ""], ["Tsuda", "Koji", ""]]}, {"id": "2106.03461", "submitter": "Arjun Beniwal", "authors": "Arjun, Aniket Singh Rajpoot, Mahesh Raveendranatha Panicker", "title": "Subject Independent Emotion Recognition using EEG Signals Employing\n  Attention Driven Neural Networks", "comments": "Under Review in IEEE Journal of Biomedical and Health Informatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Electroencephalogram (EEG) based emotional analysis has been employed in\nmedical science, security and human-computer interaction with good success. In\nthe recent past, deep learning-based approaches have significantly improved the\nclassification accuracy when compared to classical signal processing and\nmachine learning based frameworks. But most of them were subject-dependent\nstudies which were not able to generalize on the subject-independent tasks due\nto the inter-subject variability in EEG. In this work, a novel deep learning\nframework capable of doing subject-independent emotion recognition is\npresented, consisting of two parts. First, an unsupervised Long Short-Term\nMemory (LSTM) with channel-attention autoencoder is proposed for getting a\ncorrelated lower dimensional latent space representation of the EEG data for\neach subject. Secondly, a convolutional neural network (CNN) with attention\nframework, which takes the first component as input, is presented for\nperforming the task of subject-independent emotion recognition. With the\nattention mechanism, the proposed approach could highlight the channel of\ninterest as well as the temporal localization of the EEG signal, which\ncontributes to the emotion under consideration as validated by the results. The\nproposed approach has been validated using various widely employed datasets for\nEEG signals including DEAP dataset, SEED dataset and CHB-MIT dataset. With\nproposed methodology, average subject independent accuracies of 65.9%, 69.5%\nfor valence and arousal classification in the DEAP dataset, 76.7% for\npositive-negative classification in SEED dataset is obtained and further for\nthe CHB-MIT dataset average subject independent accuracies of 69.1%, 67.6%,\n72.3% for Pre-Ictal Vs Ictal, Inter-Ictal Vs Ictal, Pre-Ictal Vs Inter-Ictal\nclassification is obtained.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 09:41:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Arjun", "", ""], ["Rajpoot", "Aniket Singh", ""], ["Panicker", "Mahesh Raveendranatha", ""]]}, {"id": "2106.03580", "submitter": "M Ganesh Kumar", "authors": "M Ganesh Kumar, Cheston Tan, Camilo Libedinsky, Shih-Cheng Yen, Andrew\n  Yong-Yi Tan", "title": "One-shot learning of paired associations by a reservoir computing model\n  with Hebbian plasticity", "comments": "16 pages, 6 figures. Code can be accessed at\n  https://github.com/mgkumar138/Oneshot_Reservoir", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-shot learning can be achieved by algorithms and animals, but how the\nlatter do it is poorly understood as most of the algorithms are not\nbiologically plausible. Experiments studying one-shot learning in rodents have\nshown that after initial gradual learning of associations between cues and\nlocations, new associations can be learned with just a single exposure to each\nnew cue-location pair. Foster, Morris and Dayan (2000) developed a hybrid\ntemporal difference - symbolic model that exhibited one-shot learning for dead\nreckoning to displaced single locations. While the temporal difference rule for\nlearning the agent's actual coordinates was biologically plausible, the model's\nsymbolic mechanism for learning target coordinates was not, and one-shot\nlearning for multiple target locations was not addressed. Here we extend the\nmodel by replacing the symbolic mechanism with a reservoir of recurrently\nconnected neurons resembling cortical microcircuitry. Biologically plausible\nlearning of target coordinates was achieved by subjecting the reservoir's\noutput weights to synaptic plasticity governed by a novel 4-factor variant of\nthe exploratory Hebbian (EH) rule. As with rodents, the reservoir model\nexhibited one-shot learning for multiple paired associations.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:03:51 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kumar", "M Ganesh", ""], ["Tan", "Cheston", ""], ["Libedinsky", "Camilo", ""], ["Yen", "Shih-Cheng", ""], ["Tan", "Andrew Yong-Yi", ""]]}, {"id": "2106.03748", "submitter": "William Guss", "authors": "William Hebgen Guss, Stephanie Milani, Nicholay Topin, Brandon\n  Houghton, Sharada Mohanty, Andrew Melnik, Augustin Harter, Benoit Buschmaas,\n  Bjarne Jaster, Christoph Berganski, Dennis Heitkamp, Marko Henning, Helge\n  Ritter, Chengjie Wu, Xiaotian Hao, Yiming Lu, Hangyu Mao, Yihuan Mao, Chao\n  Wang, Michal Opanowicz, Anssi Kanervisto, Yanick Schraner, Christian\n  Scheller, Xiren Zhou, Lu Liu, Daichi Nishio, Toi Tsuneda, Karolis\n  Ramanauskas, Gabija Juceviciute", "title": "Towards robust and domain agnostic reinforcement learning competitions", "comments": "20 pages, several figures, published PMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning competitions have formed the basis for standard\nresearch benchmarks, galvanized advances in the state-of-the-art, and shaped\nthe direction of the field. Despite this, a majority of challenges suffer from\nthe same fundamental problems: participant solutions to the posed challenge are\nusually domain-specific, biased to maximally exploit compute resources, and not\nguaranteed to be reproducible. In this paper, we present a new framework of\ncompetition design that promotes the development of algorithms that overcome\nthese barriers. We propose four central mechanisms for achieving this end:\nsubmission retraining, domain randomization, desemantization through domain\nobfuscation, and the limitation of competition compute and environment-sample\nbudget. To demonstrate the efficacy of this design, we proposed, organized, and\nran the MineRL 2020 Competition on Sample-Efficient Reinforcement Learning. In\nthis work, we describe the organizational outcomes of the competition and show\nthat the resulting participant submissions are reproducible, non-specific to\nthe competition environment, and sample/resource efficient, despite the\ndifficult competition task.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:15:46 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Guss", "William Hebgen", ""], ["Milani", "Stephanie", ""], ["Topin", "Nicholay", ""], ["Houghton", "Brandon", ""], ["Mohanty", "Sharada", ""], ["Melnik", "Andrew", ""], ["Harter", "Augustin", ""], ["Buschmaas", "Benoit", ""], ["Jaster", "Bjarne", ""], ["Berganski", "Christoph", ""], ["Heitkamp", "Dennis", ""], ["Henning", "Marko", ""], ["Ritter", "Helge", ""], ["Wu", "Chengjie", ""], ["Hao", "Xiaotian", ""], ["Lu", "Yiming", ""], ["Mao", "Hangyu", ""], ["Mao", "Yihuan", ""], ["Wang", "Chao", ""], ["Opanowicz", "Michal", ""], ["Kanervisto", "Anssi", ""], ["Schraner", "Yanick", ""], ["Scheller", "Christian", ""], ["Zhou", "Xiren", ""], ["Liu", "Lu", ""], ["Nishio", "Daichi", ""], ["Tsuneda", "Toi", ""], ["Ramanauskas", "Karolis", ""], ["Juceviciute", "Gabija", ""]]}, {"id": "2106.03847", "submitter": "Omri Avrahami", "authors": "Omri Avrahami, Dani Lischinski, Ohad Fried", "title": "GAN Cocktail: mixing GANs without dataset access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.GR cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Today's generative models are capable of synthesizing high-fidelity images,\nbut each model specializes on a specific target domain. This raises the need\nfor model merging: combining two or more pretrained generative models into a\nsingle unified one. In this work we tackle the problem of model merging, given\ntwo constraints that often come up in the real world: (1) no access to the\noriginal training data, and (2) without increasing the size of the neural\nnetwork. To the best of our knowledge, model merging under these constraints\nhas not been studied thus far. We propose a novel, two-stage solution. In the\nfirst stage, we transform the weights of all the models to the same parameter\nspace by a technique we term model rooting. In the second stage, we merge the\nrooted models by averaging their weights and fine-tuning them for each specific\ndomain, using only data generated by the original trained models. We\ndemonstrate that our approach is superior to baseline methods and to existing\ntransfer learning techniques, and investigate several applications.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 17:59:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Avrahami", "Omri", ""], ["Lischinski", "Dani", ""], ["Fried", "Ohad", ""]]}, {"id": "2106.04011", "submitter": "AkshatKumar Nigam Mr", "authors": "AkshatKumar Nigam, Robert Pollice, Alan Aspuru-Guzik", "title": "JANUS: Parallel Tempered Genetic Algorithm Guided by Deep Neural\n  Networks for Inverse Molecular Design", "comments": "20 pages, 12 figures, 4 tables. Comments are welcome! (code will be\n  uploaded when paper is formally published)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse molecular design, i.e., designing molecules with specific target\nproperties, can be posed as an optimization problem. High-dimensional\noptimization tasks in the natural sciences are commonly tackled via\npopulation-based metaheuristic optimization algorithms such as evolutionary\nalgorithms. However, expensive property evaluation, which is often required,\ncan limit the widespread use of such approaches as the associated cost can\nbecome prohibitive. Herein, we present JANUS, a genetic algorithm that is\ninspired by parallel tempering. It propagates two populations, one for\nexploration and another for exploitation, improving optimization by reducing\nexpensive property evaluations. Additionally, JANUS is augmented by a deep\nneural network that approximates molecular properties via active learning for\nenhanced sampling of the chemical space. Our method uses the SELFIES molecular\nrepresentation and the STONED algorithm for the efficient generation of\nstructures, and outperforms other generative models in common inverse molecular\ndesign tasks achieving state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 23:41:34 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Nigam", "AkshatKumar", ""], ["Pollice", "Robert", ""], ["Aspuru-Guzik", "Alan", ""]]}, {"id": "2106.04034", "submitter": "Leonardo Trujillo Dr", "authors": "Leonardo Trujillo, Jose Manuel Mu\\~noz Contreras, Daniel E Hernandez,\n  Mauro Castelli and Juan J Tapia", "title": "GSGP-CUDA -- a CUDA framework for Geometric Semantic Genetic Programming", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Geometric Semantic Genetic Programming (GSGP) is a state-of-the-art machine\nlearning method based on evolutionary computation. GSGP performs search\noperations directly at the level of program semantics, which can be done more\nefficiently then operating at the syntax level like most GP systems. Efficient\nimplementations of GSGP in C++ exploit this fact, but not to its full\npotential. This paper presents GSGP-CUDA, the first CUDA implementation of GSGP\nand the most efficient, which exploits the intrinsic parallelism of GSGP using\nGPUs. Results show speedups greater than 1,000X relative to the\nstate-of-the-art sequential implementation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 00:58:39 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Trujillo", "Leonardo", ""], ["Contreras", "Jose Manuel Mu\u00f1oz", ""], ["Hernandez", "Daniel E", ""], ["Castelli", "Mauro", ""], ["Tapia", "Juan J", ""]]}, {"id": "2106.04089", "submitter": "David Clark", "authors": "David G. Clark, L. F. Abbott, SueYeon Chung", "title": "Credit Assignment Through Broadcasting a Global Error Vector", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation (BP) uses detailed, unit-specific feedback to train deep\nneural networks (DNNs) with remarkable success. That biological neural circuits\nappear to perform credit assignment, but cannot implement BP, implies the\nexistence of other powerful learning algorithms. Here, we explore the extent to\nwhich a globally broadcast learning signal, coupled with local weight updates,\nenables training of DNNs. We present both a learning rule, called global\nerror-vector broadcasting (GEVB), and a class of DNNs, called vectorized\nnonnegative networks (VNNs), in which this learning rule operates. VNNs have\nvector-valued units and nonnegative weights past the first layer. The GEVB\nlearning rule generalizes three-factor Hebbian learning, updating each weight\nby an amount proportional to the inner product of the presynaptic activation\nand a globally broadcast error vector when the postsynaptic unit is active. We\nprove that these weight updates are matched in sign to the gradient, enabling\naccurate credit assignment. Moreover, at initialization, these updates are\nexactly proportional to the gradient in the limit of infinite network width.\nGEVB matches the performance of BP in VNNs, and in some cases outperforms\ndirect feedback alignment (DFA) applied in conventional networks. Unlike DFA,\nGEVB successfully trains convolutional layers. Altogether, our theoretical and\nempirical results point to a surprisingly powerful role for a global learning\nsignal in training DNNs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 04:08:46 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Clark", "David G.", ""], ["Abbott", "L. F.", ""], ["Chung", "SueYeon", ""]]}, {"id": "2106.04165", "submitter": "Stefano Massaroli", "authors": "Michael Poli, Stefano Massaroli, Luca Scimeca, Seong Joon Oh, Sanghyuk\n  Chun, Atsushi Yamashita, Hajime Asama, Jinkyoo Park, Animesh Garg", "title": "Neural Hybrid Automata: Learning Dynamics with Multiple Modes and\n  Stochastic Transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective control and prediction of dynamical systems often require\nappropriate handling of continuous-time and discrete, event-triggered\nprocesses. Stochastic hybrid systems (SHSs), common across engineering domains,\nprovide a formalism for dynamical systems subject to discrete, possibly\nstochastic, state jumps and multi-modal continuous-time flows. Despite the\nversatility and importance of SHSs across applications, a general procedure for\nthe explicit learning of both discrete events and multi-mode continuous\ndynamics remains an open problem. This work introduces Neural Hybrid Automata\n(NHAs), a recipe for learning SHS dynamics without a priori knowledge on the\nnumber of modes and inter-modal transition dynamics. NHAs provide a systematic\ninference method based on normalizing flows, neural differential equations and\nself-supervision. We showcase NHAs on several tasks, including mode recovery\nand flow learning in systems with stochastic transitions, and end-to-end\nlearning of hierarchical robot controllers.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 08:04:39 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Poli", "Michael", ""], ["Massaroli", "Stefano", ""], ["Scimeca", "Luca", ""], ["Oh", "Seong Joon", ""], ["Chun", "Sanghyuk", ""], ["Yamashita", "Atsushi", ""], ["Asama", "Hajime", ""], ["Park", "Jinkyoo", ""], ["Garg", "Animesh", ""]]}, {"id": "2106.04181", "submitter": "Martin Briesch", "authors": "Martin Briesch, Dominik Sobania and Franz Rothlauf", "title": "The Randomness of Input Data Spaces is an A Priori Predictor for\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over-parameterized models can perfectly learn various types of data\ndistributions, however, generalization error is usually lower for real data in\ncomparison to artificial data. This suggests that the properties of data\ndistributions have an impact on generalization capability. This work focuses on\nthe search space defined by the input data and assumes that the correlation\nbetween labels of neighboring input values influences generalization. If\ncorrelation is low, the randomness of the input data space is high leading to\nhigh generalization error. We suggest to measure the randomness of an input\ndata space using Maurer's universal. Results for synthetic classification tasks\nand common image classification benchmarks (MNIST, CIFAR10, and Microsoft's\ncats vs. dogs data set) find a high correlation between the randomness of input\ndata spaces and the generalization error of deep neural networks for binary\nclassification problems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 08:44:03 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Briesch", "Martin", ""], ["Sobania", "Dominik", ""], ["Rothlauf", "Franz", ""]]}, {"id": "2106.04540", "submitter": "Jordan Lei", "authors": "Jordan Lei, Ari S. Benjamin, Konrad P. Kording", "title": "Object Based Attention Through Internal Gating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Object-based attention is a key component of the visual system, relevant for\nperception, learning, and memory. Neurons tuned to features of attended objects\ntend to be more active than those associated with non-attended objects. There\nis a rich set of models of this phenomenon in computational neuroscience.\nHowever, there is currently a divide between models that successfully match\nphysiological data but can only deal with extremely simple problems and models\nof attention used in computer vision. For example, attention in the brain is\nknown to depend on top-down processing, whereas self-attention in deep learning\ndoes not. Here, we propose an artificial neural network model of object-based\nattention that captures the way in which attention is both top-down and\nrecurrent. Our attention model works well both on simple test stimuli, such as\nthose using images of handwritten digits, and on more complex stimuli, such as\nnatural images drawn from the COCO dataset. We find that our model replicates a\nrange of findings from neuroscience, including attention-invariant tuning,\ninhibition of return, and attention-mediated scaling of activity. Understanding\nobject based attention is both computationally interesting and a key problem\nfor computational neuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 17:20:50 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Lei", "Jordan", ""], ["Benjamin", "Ari S.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "2106.04618", "submitter": "Laurens Bliek", "authors": "Laurens Bliek, Arthur Guijt, Rickard Karlsson, Sicco Verwer, Mathijs\n  de Weerdt", "title": "EXPObench: Benchmarking Surrogate-based Optimisation Algorithms on\n  Expensive Black-box Functions", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Surrogate algorithms such as Bayesian optimisation are especially designed\nfor black-box optimisation problems with expensive objectives, such as\nhyperparameter tuning or simulation-based optimisation. In the literature,\nthese algorithms are usually evaluated with synthetic benchmarks which are well\nestablished but have no expensive objective, and only on one or two real-life\napplications which vary wildly between papers. There is a clear lack of\nstandardisation when it comes to benchmarking surrogate algorithms on\nreal-life, expensive, black-box objective functions. This makes it very\ndifficult to draw conclusions on the effect of algorithmic contributions. A new\nbenchmark library, EXPObench, provides first steps towards such a\nstandardisation. The library is used to provide an extensive comparison of six\ndifferent surrogate algorithms on four expensive optimisation problems from\ndifferent real-life applications. This has led to new insights regarding the\nrelative importance of exploration, the evaluation time of the objective, and\nthe used model. A further contribution is that we make the algorithms and\nbenchmark problem instances publicly available, contributing to more uniform\nanalysis of surrogate algorithms. Most importantly, we include the performance\nof the six algorithms on all evaluated problem instances. This results in a\nunique new dataset that lowers the bar for researching new methods as the\nnumber of expensive evaluations required for comparison is significantly\nreduced.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 18:17:42 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Bliek", "Laurens", ""], ["Guijt", "Arthur", ""], ["Karlsson", "Rickard", ""], ["Verwer", "Sicco", ""], ["de Weerdt", "Mathijs", ""]]}, {"id": "2106.04656", "submitter": "Farzad Karami", "authors": "Farzad Karami, Nasser Kehtarnavaz, Mario Rotea", "title": "Probabilistic Neural Network to Quantify Uncertainty of Wind Power\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Each year a growing number of wind farms are being added to power grids to\ngenerate electricity. The power curve of a wind turbine, which exhibits the\nrelationship between generated power and wind speed, plays a major role in\nassessing the performance of a wind farm. Neural networks have been used for\npower curve estimation. However, they do not produce a confidence measure for\ntheir output, unless computationally prohibitive Bayesian methods are used. In\nthis paper, a probabilistic neural network with Monte Carlo dropout is\nconsidered to quantify the model (epistemic) uncertainty of the power curve\nestimation. This approach offers a minimal increase in computational complexity\nover deterministic approaches. Furthermore, by incorporating a probabilistic\nloss function, the noise or aleatoric uncertainty in the data is estimated. The\ndeveloped network captures both model and noise uncertainty which is found to\nbe useful tools in assessing performance. Also, the developed network is\ncompared with existing ones across a public domain dataset showing superior\nperformance in terms of prediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jun 2021 19:15:53 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Karami", "Farzad", ""], ["Kehtarnavaz", "Nasser", ""], ["Rotea", "Mario", ""]]}, {"id": "2106.04693", "submitter": "Sakib Mostafa", "authors": "Sakib Mostafa, Debajyoti Mondal", "title": "On the Evolution of Neuron Communities in a Deep Learning Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques are increasingly being adopted for classification\ntasks over the past decade, yet explaining how deep learning architectures can\nachieve state-of-the-art performance is still an elusive goal. While all the\ntraining information is embedded deeply in a trained model, we still do not\nunderstand much about its performance by only analyzing the model. This paper\nexamines the neuron activation patterns of deep learning-based classification\nmodels and explores whether the models' performances can be explained through\nneurons' activation behavior. We propose two approaches: one that models\nneurons' activation behavior as a graph and examines whether the neurons form\nmeaningful communities, and the other examines the predictability of neurons'\nbehavior using entropy. Our comprehensive experimental study reveals that both\nthe community quality (modularity) and entropy are closely related to the deep\nlearning models' performances, thus paves a novel way of explaining deep\nlearning models directly from the neurons' activation pattern.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jun 2021 21:09:55 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Mostafa", "Sakib", ""], ["Mondal", "Debajyoti", ""]]}, {"id": "2106.04775", "submitter": "Luis Torres-Trevi\\~no PhD", "authors": "Luis Torres-Trevi\\~no", "title": "A 2020 taxonomy of algorithms inspired on living beings behavior", "comments": "a collection of algorithms names, 24 pages, two figures, 9 tables, a\n  recompilation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Taking the role of a computer naturalist, a journey is taken through bio\ninspired algorithms taking account on algorithms which are inspired on living\nbeing behaviors. A compilation of algorithms is made considering several\nreviews or surveys of bio-inspired heuristics and swarm intelligence until 2020\nyear. A classification is made considering kingdoms as used by biologists\ngenerating several branches for animalia, bacteria, plants, fungi and protista\nto develop a taxonomy.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 02:37:46 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Torres-Trevi\u00f1o", "Luis", ""]]}, {"id": "2106.04777", "submitter": "Everton Lira", "authors": "Everton R. Lira, Heverton B. de Mac\\^edo, Danielli A. Lima, Leonardo\n  Alt, Gina M. B. Oliveira", "title": "A reversible system based on hybrid toggle radius-4 cellular automata\n  and its application as a block cipher", "comments": "34 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dynamical system described herein uses a hybrid cellular automata (CA)\nmechanism to attain reversibility, and this approach is adapted to create a\nnovel block cipher algorithm called HCA. CA are widely used for modeling\ncomplex systems and employ an inherently parallel model. Therefore,\napplications derived from CA have a tendency to fit very well in the current\ncomputational paradigm where scalability and multi-threading potential are\nquite desirable characteristics. HCA model has recently received a patent by\nthe Brazilian agency INPI. Several evaluations and analyses performed on the\nmodel are presented here, such as theoretical discussions related to its\nreversibility and an analysis based on graph theory, which reduces HCA security\nto the well-known Hamiltonian cycle problem that belongs to the NP-complete\nclass. Finally, the cryptographic robustness of HCA is empirically evaluated\nthrough several tests, including avalanche property compliance and the NIST\nrandomness suite.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 02:52:05 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Lira", "Everton R.", ""], ["de Mac\u00eado", "Heverton B.", ""], ["Lima", "Danielli A.", ""], ["Alt", "Leonardo", ""], ["Oliveira", "Gina M. B.", ""]]}, {"id": "2106.04854", "submitter": "Burak Ta\\u{g}tekin", "authors": "Burak Ta\\u{g}tekin, Mahiye Uluya\\u{g}mur \\\"Ozt\\\"urk, Mert Kutay Sezer", "title": "A Case Study: Using Genetic Algorithm for Job Scheduling Problem", "comments": "5 pages, 2 algorithm, Case study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, DevOps pipelines of huge projects are getting more and more\ncomplex. Each job in the pipeline might need different requirements including\nspecific hardware specifications and dependencies. To achieve minimal makespan,\ndevelopers always apply as much machines as possible. Consequently, others may\nbe stalled for waiting resource released. Minimizing the makespan of each job\nusing a few resource is a challenging problem. In this study, it is aimed to 1)\nautomatically determine the priority of jobs to reduce the waiting time in the\nline, 2) automatically allocate the machine resource to each job. In this work,\nthe problem is formulated as a multi-objective optimization problem. We use GA\nalgorithm to automatically determine job priorities and resource demand for\nminimizing individual makespan and resource usage. Finally, the experimental\nresults show that our proposed priority list generation algorithm is more\neffective than current priority list producing method in the aspects of\nmakespan and allocated machine count.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 07:26:21 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ta\u011ftekin", "Burak", ""], ["\u00d6zt\u00fcrk", "Mahiye Uluya\u011fmur", ""], ["Sezer", "Mert Kutay", ""]]}, {"id": "2106.04985", "submitter": "Tomek Korbak", "authors": "Tomasz Korbak and Hady Elsahar and Marc Dymetman and Germ\\'an\n  Kruszewski", "title": "Energy-Based Models for Code Generation under Compilability Constraints", "comments": "Accepted for the First Workshop on Natural Language Processing for\n  Programming, ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE cs.SE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural language models can be successfully trained on source code, leading to\napplications such as code completion. However, their versatile autoregressive\nself-supervision objective overlooks important global sequence-level features\nthat are present in the data such as syntactic correctness or compilability. In\nthis work, we pose the problem of learning to generate compilable code as\nconstraint satisfaction. We define an Energy-Based Model (EBM) representing a\npre-trained generative model with an imposed constraint of generating only\ncompilable sequences. We then use the KL-Adaptive Distributional Policy\nGradient algorithm (Khalifa et al., 2021) to train a generative model\napproximating the EBM. We conduct experiments showing that our proposed\napproach is able to improve compilability rates without sacrificing diversity\nand complexity of the generated samples.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 11:06:32 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Korbak", "Tomasz", ""], ["Elsahar", "Hady", ""], ["Dymetman", "Marc", ""], ["Kruszewski", "Germ\u00e1n", ""]]}, {"id": "2106.04986", "submitter": "Tai-Yu Ma", "authors": "Tai-Yu Ma and S\\'ebastien Faye", "title": "Multistep Electric Vehicle Charging Station Occupancy Prediction using\n  Mixed LSTM Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public charging station occupancy prediction plays key importance in\ndeveloping a smart charging strategy to reduce electric vehicle (EV) operator\nand user inconvenience. However, existing studies are mainly based on\nconventional econometric or time series methodologies with limited accuracy. We\npropose a new mixed long short-term memory neural network incorporating both\nhistorical charging state sequences and time-related features for multistep\ndiscrete charging occupancy state prediction. Unlike the existing LSTM\nnetworks, the proposed model separates different types of features and handles\nthem differently with mixed neural network architecture. The model is compared\nto a number of state-of-the-art machine learning and deep learning approaches\nbased on the EV charging data obtained from the open data portal of the city of\nDundee, UK. The results show that the proposed method produces very accurate\npredictions (99.99% and 81.87% for 1 step (10 minutes) and 6 step (1 hour)\nahead, respectively, and outperforms the benchmark approaches significantly\n(+22.4% for one-step-ahead prediction and +6.2% for 6 steps ahead). A\nsensitivity analysis is conducted to evaluate the impact of the model\nparameters on prediction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 11:10:14 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ma", "Tai-Yu", ""], ["Faye", "S\u00e9bastien", ""]]}, {"id": "2106.05096", "submitter": "Eric Fraga", "authors": "Eric S. Fraga", "title": "Multiple simultaneous solution representations in a population based\n  evolutionary algorithm", "comments": "17 pages, 4 figures. Ancillary file written in org mode in Emacs\n  contains all data for figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The representation used for solutions in optimization can have a significant\nimpact on the performance of the optimization method. Traditional population\nbased evolutionary methods have homogeneous populations where all solutions use\nthe same representation. If different representations are to be considered,\ndifferent runs are required to investigate the relative performance. In this\npaper, we illustrate the use of a population based evolutionary method, Fresa,\ninspired by the propagation of Strawberry plants, which allows for multiple\nrepresentations to co-exist in the population.\n  Fresa is implemented in the Julia language. Julia provides dynamic typing and\nmultiple dispatch. In multiple dispatch, the function invoked is determined,\ndynamically at run time, by the types of the arguments passed to it. This\nenables a generic implementation of key steps in the plant propagation\nalgorithm which allows for a heterogeneous population. The search procedure\nthen leads to a competition between representations automatically.\n  A simple case study from the design of operating conditions for a batch\nreactor system is used to illustrate heterogeneous population based search.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 14:22:28 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Fraga", "Eric S.", ""]]}, {"id": "2106.05181", "submitter": "Cheng Qian", "authors": "Cheng Qian", "title": "Condition Integration Memory Network: An Interpretation of the Meaning\n  of the Neuronal Design", "comments": "39 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This document introduces a hypothesized framework on the functional nature of\nprimitive neural network. It discusses such an idea that the activity of\nneurons and synapses can symbolically reenact the dynamic changes in the world\nand enable an adaptive system of behavior. More specifically, the network\nachieves these without participating in an algorithmic structure. When a\nneuron's activation represents some symbolic element in the environment, each\nof its synapses can indicate a potential change to the element and its future\nstate. The efficacy of a synaptic connection further specifies the element's\nparticular probability for, or contribution to, such a change. A neuron's\nactivation is transformed to its postsynaptic targets as it fires, resulting in\na chronological shift of the represented elements. As the inherent function of\nsummation in a neuron integrates the various presynaptic contributions, the\nneural network mimics the collective causal relationship of events in the\nobserved environment.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 05:59:27 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Qian", "Cheng", ""]]}, {"id": "2106.05186", "submitter": "Madhavun Candadai", "authors": "Madhavun Candadai", "title": "Information theoretic analysis of computational models as a tool to\n  understand the neural basis of behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT cs.NE math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the greatest research challenges of this century is to understand the\nneural basis for how behavior emerges in brain-body-environment systems. To\nthis end, research has flourished along several directions but have\npredominantly focused on the brain. While there is in an increasing acceptance\nand focus on including the body and environment in studying the neural basis of\nbehavior, animal researchers are often limited by technology or tools.\nComputational models provide an alternative framework within which one can\nstudy model systems where ground-truth can be measured and interfered with.\nThese models act as a hypothesis generation framework that would in turn guide\nexperimentation. Furthermore, the ability to intervene as we please, allows us\nto conduct in-depth analysis of these models in a way that cannot be performed\nin natural systems. For this purpose, information theory is emerging as a\npowerful tool that can provide insights into the operation of these\nbrain-body-environment models. In this work, I provide an introduction, a\nreview and discussion to make a case for how information theoretic analysis of\ncomputational models is a potent research methodology to help us better\nunderstand the neural basis of behavior.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 02:08:18 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Candadai", "Madhavun", ""]]}, {"id": "2106.05373", "submitter": "Steven W. D. Chien", "authors": "Artur Podobas, Martin Svedin, Steven W. D. Chien, Ivy B. Peng, Naresh\n  Balaji Ravichandran, Pawel Herman, Anders Lansner, Stefano Markidis", "title": "StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs,\n  GPUs and FPGAs", "comments": "Accepted for publication at the International Symposium on Highly\n  Efficient Accelerators and Reconfigurable Technologies (HEART 2021)", "journal-ref": null, "doi": "10.1145/3468044.3468052", "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modern deep learning method based on backpropagation has surged in\npopularity and has been used in multiple domains and application areas. At the\nsame time, there are other -- less-known -- machine learning algorithms with a\nmature and solid theoretical foundation whose performance remains unexplored.\nOne such example is the brain-like Bayesian Confidence Propagation Neural\nNetwork (BCPNN). In this paper, we introduce StreamBrain -- a framework that\nallows neural networks based on BCPNN to be practically deployed in\nHigh-Performance Computing systems. StreamBrain is a domain-specific language\n(DSL), similar in concept to existing machine learning (ML) frameworks, and\nsupports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate\nthat StreamBrain can train the well-known ML benchmark dataset MNIST within\nseconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We\nalso show how StreamBrain can be used to train with custom floating-point\nformats and illustrate the impact of using different bfloat variations on BCPNN\nusing FPGAs.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 20:28:18 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Podobas", "Artur", ""], ["Svedin", "Martin", ""], ["Chien", "Steven W. D.", ""], ["Peng", "Ivy B.", ""], ["Ravichandran", "Naresh Balaji", ""], ["Herman", "Pawel", ""], ["Lansner", "Anders", ""], ["Markidis", "Stefano", ""]]}, {"id": "2106.05521", "submitter": "Michael Thrun PhD", "authors": "Michael C. Thrun and Alfred Ultsch", "title": "Swarm Intelligence for Self-Organized Clustering", "comments": "54 pages, 21 figures", "journal-ref": "Artificial intelligence, Vol. 290, pp. 103237. 2021", "doi": "10.1016/j.artint.2020.103237", "report-no": null, "categories": "cs.NE cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms implementing populations of agents which interact with one another\nand sense their environment may exhibit emergent behavior such as\nself-organization and swarm intelligence. Here a swarm system, called\nDatabionic swarm (DBS), is introduced which is able to adapt itself to\nstructures of high-dimensional data characterized by distance and/or\ndensity-based structures in the data space. By exploiting the interrelations of\nswarm intelligence, self-organization and emergence, DBS serves as an\nalternative approach to the optimization of a global objective function in the\ntask of clustering. The swarm omits the usage of a global objective function\nand is parameter-free because it searches for the Nash equilibrium during its\nannealing process. To our knowledge, DBS is the first swarm combining these\napproaches. Its clustering can outperform common clustering methods such as\nK-means, PAM, single linkage, spectral clustering, model-based clustering, and\nWard, if no prior knowledge about the data is available. A central problem in\nclustering is the correct estimation of the number of clusters. This is\naddressed by a DBS visualization called topographic map which allows assessing\nthe number of clusters. It is known that all clustering algorithms construct\nclusters, irrespective of the data set contains clusters or not. In contrast to\nmost other clustering algorithms, the topographic map identifies, that\nclustering of the data is meaningless if the data contains no (natural)\nclusters. The performance of DBS is demonstrated on a set of benchmark data,\nwhich are constructed to pose difficult clustering problems and in two\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 06:21:48 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Thrun", "Michael C.", ""], ["Ultsch", "Alfred", ""]]}, {"id": "2106.05566", "submitter": "Jean-Yves Franceschi", "authors": "Jean-Yves Franceschi (MLIA), Emmanuel de B\\'ezenac (MLIA), Ibrahim\n  Ayed (MLIA), Micka\\\"el Chen, Sylvain Lamprier (MLIA), Patrick Gallinari\n  (MLIA)", "title": "A Neural Tangent Kernel Perspective of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical analyses for Generative Adversarial Networks (GANs) generally\nassume an arbitrarily large family of discriminators and do not consider the\ncharacteristics of the architectures used in practice. We show that this\nframework of analysis is too simplistic to properly analyze GAN training. To\ntackle this issue, we leverage the theory of infinite-width neural networks to\nmodel neural discriminator training for a wide range of adversarial losses via\nits Neural Tangent Kernel (NTK). Our analytical results show that GAN\ntrainability primarily depends on the discriminator's architecture. We further\nstudy the discriminator for specific architectures and losses, and highlight\nproperties providing a new understanding of GAN training. For example, we find\nthat GANs trained with the integral probability metric loss minimize the\nmaximum mean discrepancy with the NTK as kernel. Our conclusions demonstrate\nthe analysis opportunities provided by the proposed framework, which paves the\nway for better and more principled GAN models. We release a generic GAN\nanalysis toolkit based on our framework that supports the empirical part of our\nstudy.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 07:46:02 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Franceschi", "Jean-Yves", "", "MLIA"], ["de B\u00e9zenac", "Emmanuel", "", "MLIA"], ["Ayed", "Ibrahim", "", "MLIA"], ["Chen", "Micka\u00ebl", "", "MLIA"], ["Lamprier", "Sylvain", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2106.05569", "submitter": "Anjana Arunkumar", "authors": "Swaroop Mishra, Anjana Arunkumar", "title": "Front Contribution instead of Back Propagation", "comments": "NeurIPS 2020 - Beyond Backpropagation Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning's outstanding track record across several domains has stemmed\nfrom the use of error backpropagation (BP). Several studies, however, have\nshown that it is impossible to execute BP in a real brain. Also, BP still\nserves as an important and unsolved bottleneck for memory usage and speed. We\npropose a simple, novel algorithm, the Front-Contribution algorithm, as a\ncompact alternative to BP. The contributions of all weights with respect to the\nfinal layer weights are calculated before training commences and all the\ncontributions are appended to weights of the final layer, i.e., the effective\nfinal layer weights are a non-linear function of themselves. Our algorithm then\nessentially collapses the network, precluding the necessity for weight updation\nof all weights not in the final layer. This reduction in parameters results in\nlower memory usage and higher training speed. We show that our algorithm\nproduces the exact same output as BP, in contrast to several recently proposed\nalgorithms approximating BP. Our preliminary experiments demonstrate the\nefficacy of the proposed algorithm. Our work provides a foundation to\neffectively utilize these presently under-explored \"front contributions\", and\nserves to inspire the next generation of training algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 07:47:53 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Mishra", "Swaroop", ""], ["Arunkumar", "Anjana", ""]]}, {"id": "2106.05648", "submitter": "Luca Grillotti", "authors": "Luca Grillotti and Antoine Cully", "title": "Unsupervised Behaviour Discovery with Quality-Diversity Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-Diversity algorithms refer to a class of evolutionary algorithms\ndesigned to find a collection of diverse and high-performing solutions to a\ngiven problem. In robotics, such algorithms can be used for generating a\ncollection of controllers covering most of the possible behaviours of a robot.\nTo do so, these algorithms associate a behavioural descriptor to each of these\nbehaviours. Each behavioural descriptor is used for estimating the novelty of\none behaviour compared to the others. In most existing algorithms, the\nbehavioural descriptor needs to be hand-coded, thus requiring prior knowledge\nabout the task to solve. In this paper, we introduce: Autonomous Robots\nRealising their Abilities, an algorithm that uses a dimensionality reduction\ntechnique to automatically learn behavioural descriptors based on raw sensory\ndata. The performance of this algorithm is assessed on three robotic tasks in\nsimulation. The experimental results show that it performs similarly to\ntraditional hand-coded approaches without the requirement to provide any\nhand-coded behavioural descriptor. In the collection of diverse and\nhigh-performing solutions, it also manages to find behaviours that are novel\nwith respect to more features than its hand-coded baselines. Finally, we\nintroduce a variant of the algorithm which is robust to the dimensionality of\nthe behavioural descriptor space.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 10:40:18 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Grillotti", "Luca", ""], ["Cully", "Antoine", ""]]}, {"id": "2106.05686", "submitter": "Mattias Nilsson", "authors": "Mattias Nilsson, Foteini Liwicki, and Fredrik Sandin", "title": "Spatiotemporal Spike-Pattern Selectivity in Single Mixed-Signal Neurons\n  with Balanced Synapses", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Realizing the potential of mixed-signal neuromorphic processors for\nultra-low-power inference and learning requires efficient use of their\ninhomogeneous analog circuitry as well as sparse, time-based information\nencoding and processing. Here, we investigate spike-timing-based spatiotemporal\nreceptive fields of output-neurons in the Spatiotemporal Correlator (STC)\nnetwork, for which we used excitatory-inhibitory balanced disynaptic inputs\ninstead of dedicated axonal or neuronal delays. We present hardware-in-the-loop\nexperiments with a mixed-signal DYNAP-SE neuromorphic processor, in which\nfive-dimensional receptive fields of hardware neurons were mapped by randomly\nsampling input spike-patterns from a uniform distribution. We find that, when\nthe balanced disynaptic elements are randomly programmed, some of the neurons\ndisplay distinct receptive fields. Furthermore, we demonstrate how a neuron was\ntuned to detect a particular spatiotemporal feature, to which it initially was\nnon-selective, by activating a different subset of the inhomogeneous analog\nsynaptic circuits. The energy dissipation of the balanced synaptic elements is\none order of magnitude lower per lateral connection (0.65 nJ vs 9.3 nJ per\nspike) than former delay-based neuromorphic hardware implementations. Thus, we\nshow how the inhomogeneous synaptic circuits could be utilized for\nresource-efficient implementation of STC network layers, in a way that enables\nsynapse-address reprogramming as a discrete mechanism for feature tuning.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 12:04:03 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Nilsson", "Mattias", ""], ["Liwicki", "Foteini", ""], ["Sandin", "Fredrik", ""]]}, {"id": "2106.05814", "submitter": "Song Tan", "authors": "Song Tan, Xia He", "title": "A concise method for feature selection via normalized frequencies", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature selection is an important part of building a machine learning model.\nBy eliminating redundant or misleading features from data, the machine learning\nmodel can achieve better performance while reducing the demand on com-puting\nresources. Metaheuristic algorithms are mostly used to implement feature\nselection such as swarm intelligence algorithms and evolutionary algorithms.\nHowever, they suffer from the disadvantage of relative complexity and slowness.\nIn this paper, a concise method is proposed for universal feature selection.\nThe proposed method uses a fusion of the filter method and the wrapper method,\nrather than a combination of them. In the method, one-hoting encoding is used\nto preprocess the dataset, and random forest is utilized as the classifier. The\nproposed method uses normalized frequencies to assign a value to each feature,\nwhich will be used to find the optimal feature subset. Furthermore, we propose\na novel approach to exploit the outputs of mutual information, which allows for\na better starting point for the experiments. Two real-world dataset in the\nfield of intrusion detection were used to evaluate the proposed method. The\nevaluation results show that the proposed method outperformed several\nstate-of-the-art related works in terms of accuracy, precision, recall, F-score\nand AUC.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:29:54 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Tan", "Song", ""], ["He", "Xia", ""]]}, {"id": "2106.06061", "submitter": "Daniel Harrold", "authors": "Daniel J. B. Harrold, Jun Cao, and Zhong Fan", "title": "Data-driven battery operation for energy arbitrage using rainbow deep\n  reinforcement learning", "comments": "13 pages, 9 figures (17 counting each subfigure)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the world seeks to become more sustainable, intelligent solutions are\nneeded to increase the penetration of renewable energy. In this paper, the\nmodel-free deep reinforcement learning algorithm Rainbow Deep Q-Networks is\nused to control a battery in a small microgrid to perform energy arbitrage and\nmore efficiently utilise solar and wind energy sources. The grid operates with\nits own demand and renewable generation based on a dataset collected at Keele\nUniversity, as well as using dynamic energy pricing from a real wholesale\nenergy market. Four scenarios are tested including using demand and price\nforecasting produced with local weather data. The algorithm and its\nsubcomponents are evaluated against two continuous control benchmarks with\nRainbow able to outperform all other method. This research shows the importance\nof using the distributional approach for reinforcement learning when working\nwith complex environments and reward functions, as well as how it can be used\nto visualise and contextualise the agent's behaviour for real-world\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 21:27:35 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Harrold", "Daniel J. B.", ""], ["Cao", "Jun", ""], ["Fan", "Zhong", ""]]}, {"id": "2106.06085", "submitter": "Thomas Helmuth", "authors": "Thomas Helmuth and Lee Spector", "title": "Problem-solving benefits of down-sampled lexicase selection", "comments": "to be published in Artificial Life Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In genetic programming, an evolutionary method for producing computer\nprograms that solve specified computational problems, parent selection is\nordinarily based on aggregate measures of performance across an entire training\nset. Lexicase selection, by contrast, selects on the basis of performance on\nrandom sequences of training cases; this has been shown to enhance\nproblem-solving power in many circumstances. Lexicase selection can also be\nseen as better reflecting biological evolution, by modeling sequences of\nchallenges that organisms face over their lifetimes. Recent work has\ndemonstrated that the advantages of lexicase selection can be amplified by\ndown-sampling, meaning that only a random subsample of the training cases is\nused each generation. This can be seen as modeling the fact that individual\norganisms encounter only subsets of the possible environments, and that\nenvironments change over time. Here we provide the most extensive benchmarking\nof down-sampled lexicase selection to date, showing that its benefits hold up\nto increased scrutiny. The reasons that down-sampling helps, however, are not\nyet fully understood. Hypotheses include that down-sampling allows for more\ngenerations to be processed with the same budget of program evaluations; that\nthe variation of training data across generations acts as a changing\nenvironment, encouraging adaptation; or that it reduces overfitting, leading to\nmore general solutions. We systematically evaluate these hypotheses, finding\nevidence against all three, and instead draw the conclusion that down-sampled\nlexicase selection's main benefit stems from the fact that it allows the\nevolutionary process to examine more individuals within the same computational\nbudget, even though each individual is examined less completely.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 23:42:09 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Helmuth", "Thomas", ""], ["Spector", "Lee", ""]]}, {"id": "2106.06086", "submitter": "Thomas Helmuth", "authors": "Thomas Helmuth and Peter Kelly", "title": "PSB2: The Second Program Synthesis Benchmark Suite", "comments": "To be published in GECCO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  For the past six years, researchers in genetic programming and other program\nsynthesis disciplines have used the General Program Synthesis Benchmark Suite\nto benchmark many aspects of automatic program synthesis systems. These\nproblems have been used to make notable progress toward the goal of general\nprogram synthesis: automatically creating the types of software that human\nprogrammers code. Many of the systems that have attempted the problems in the\noriginal benchmark suite have used it to demonstrate performance improvements\ngranted through new techniques. Over time, the suite has gradually become\noutdated, hindering the accurate measurement of further improvements. The field\nneeds a new set of more difficult benchmark problems to move beyond what was\npreviously possible.\n  In this paper, we describe the 25 new general program synthesis benchmark\nproblems that make up PSB2, a new benchmark suite. These problems are curated\nfrom a variety of sources, including programming katas and college courses. We\nselected these problems to be more difficult than those in the original suite,\nand give results using PushGP showing this increase in difficulty. These new\nproblems give plenty of room for improvement, pointing the way for the next six\nor more years of general program synthesis research.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 23:44:05 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Helmuth", "Thomas", ""], ["Kelly", "Peter", ""]]}, {"id": "2106.06158", "submitter": "Ahmed Gad", "authors": "Ahmed Fawzy Gad", "title": "PyGAD: An Intuitive Genetic Algorithm Python Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces PyGAD, an open-source easy-to-use Python library for\nbuilding the genetic algorithm. PyGAD supports a wide range of parameters to\ngive the user control over everything in its life cycle. This includes, but is\nnot limited to, population, gene value range, gene data type, parent selection,\ncrossover, and mutation. PyGAD is designed as a general-purpose optimization\nlibrary that allows the user to customize the fitness function. Its usage\nconsists of 3 main steps: build the fitness function, create an instance of the\npygad.GA class, and calling the pygad.GA.run() method. The library supports\ntraining deep learning models created either with PyGAD itself or with\nframeworks like Keras and PyTorch. Given its stable state, PyGAD is also in\nactive development to respond to the user's requested features and enhancement\nreceived on GitHub https://github.com/ahmedfgad/GeneticAlgorithmPython. PyGAD\ncomes with documentation https://pygad.readthedocs.io for further details and\nexamples.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 04:08:30 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Gad", "Ahmed Fawzy", ""]]}, {"id": "2106.06174", "submitter": "Danial Yazdani", "authors": "Danial Yazdani (1), Juergen Branke (2), Mohammad Nabi Omidvar (3),\n  Changhe Li (4), Michalis Mavrovouniotis (5), Trung Thanh Nguyen (6),\n  Shengxiang Yang (7), Xin Yao (1 and 8) ((1) Guangdong Provincial Key\n  Laboratory of Brain-inspired Intelligent Computation, Department of Computer\n  Science and Engineering, Southern University of Science and Technology, (2)\n  Operational Research and Management Sciences Group, Warwick Business school,\n  University of Warwick, (3) School of Computing, University of Leeds, and\n  Leeds University Business School, (4) School of Automation, China University\n  of Geosciences, (5) KIOS Research and Innovation Center of Excellence,\n  Department of Electrical and Computer Engineering, (6) Liverpool Logistics,\n  Offshore and Marine (LOOM) Research Institute, Faculty of Engineering and\n  Technology, School of Engineering, Liverpool John Moores University, (7)\n  Center for Computational Intelligence (CCI), School of Computer Science and\n  Informatics, De Montfort University, (8) Center of Excellence for Research in\n  Computational Intelligence and Applications (CERCIA), School of Computer\n  Science, University of Birmingham)", "title": "Generalized Moving Peaks Benchmark", "comments": "This document forms the basis for a range of competitions on\n  Evolutionary Continuous Dynamic Optimization in the upcoming well-known\n  conferences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This document describes the Generalized Moving Peaks Benchmark (GMPB) that\ngenerates continuous dynamic optimization problem instances. The landscapes\ngenerated by GMPB are constructed by assembling several components with a\nvariety of controllable characteristics ranging from unimodal to highly\nmultimodal, symmetric to highly asymmetric, smooth to highly irregular, and\nvarious degrees of variable interaction and ill-conditioning. In this document,\nwe explain how these characteristics can be generated by different parameter\nsettings of GMPB. The MATLAB source code of GMPB is also explained. This\ndocument forms the basis for a range of competitions on Evolutionary Continuous\nDynamic Optimization in the upcoming well-known conferences.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 05:31:01 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Yazdani", "Danial", "", "1 and 8"], ["Branke", "Juergen", "", "1 and 8"], ["Omidvar", "Mohammad Nabi", "", "1 and 8"], ["Li", "Changhe", "", "1 and 8"], ["Mavrovouniotis", "Michalis", "", "1 and 8"], ["Nguyen", "Trung Thanh", "", "1 and 8"], ["Yang", "Shengxiang", "", "1 and 8"], ["Yao", "Xin", "", "1 and 8"]]}, {"id": "2106.06216", "submitter": "Luca Mazzola", "authors": "Andreas Waldis and Luca Mazzola", "title": "Nested and Balanced Entity Recognition using Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity Recognition (ER) within a text is a fundamental exercise in Natural\nLanguage Processing, enabling further depending tasks such as Knowledge\nExtraction, Text Summarisation, or Keyphrase Extraction. An entity consists of\nsingle words or of a consecutive sequence of terms, constituting the basic\nbuilding blocks for communication. Mainstream ER approaches are mainly limited\nto flat structures, concentrating on the outermost entities while ignoring the\ninner ones. This paper introduces a partly-layered network architecture that\ndeals with the complexity of overlapping and nested cases. The proposed\narchitecture consists of two parts: (1) a shared Sequence Layer and (2) a\nstacked component with multiple Tagging Layers. The adoption of such an\narchitecture has the advantage of preventing overfit to a specific word-length,\nthus maintaining performance for longer entities despite their lower frequency.\nTo verify the proposed architecture's effectiveness, we train and evaluate this\narchitecture to recognise two kinds of entities - Concepts (CR) and Named\nEntities (NER). Our approach achieves state-of-the-art NER performances, while\nit outperforms previous CR approaches. Considering these promising results, we\nsee the possibility to evolve the architecture for other cases such as the\nextraction of events or the detection of argumentative components.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 07:52:32 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Waldis", "Andreas", ""], ["Mazzola", "Luca", ""]]}, {"id": "2106.06232", "submitter": "Jiajun Fan", "authors": "Jiajun Fan, Changnan Xiao, Yue Huang", "title": "GDI: Rethinking What Makes Reinforcement Learning Different From\n  Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Q Network (DQN) firstly kicked the door of deep reinforcement learning\n(DRL) via combining deep learning (DL) with reinforcement learning (RL), which\nhas noticed that the distribution of the acquired data would change during the\ntraining process. DQN found this property might cause instability for training,\nso it proposed effective methods to handle the downside of the property.\nInstead of focusing on the unfavourable aspects, we find it critical for RL to\nease the gap between the estimated data distribution and the ground truth data\ndistribution while supervised learning (SL) fails to do so. From this new\nperspective, we extend the basic paradigm of RL called the Generalized Policy\nIteration (GPI) into a more generalized version, which is called the\nGeneralized Data Distribution Iteration (GDI). We see massive RL algorithms and\ntechniques can be unified into the GDI paradigm, which can be considered as one\nof the special cases of GDI. We provide theoretical proof of why GDI is better\nthan GPI and how it works. Several practical algorithms based on GDI have been\nproposed to verify the effectiveness and extensiveness of it. Empirical\nexperiments prove our state-of-the-art (SOTA) performance on Arcade Learning\nEnvironment (ALE), wherein our algorithm has achieved 9620.98% mean human\nnormalized score (HNS), 1146.39% median HNS and 22 human world record\nbreakthroughs (HWRB) using only 200M training frames. Our work aims to lead the\nRL research to step into the journey of conquering the human world records and\nseek real superhuman agents on both performance and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 08:31:12 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 04:44:24 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 07:17:36 GMT"}, {"version": "v4", "created": "Mon, 26 Jul 2021 09:35:35 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 07:11:02 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Fan", "Jiajun", ""], ["Xiao", "Changnan", ""], ["Huang", "Yue", ""]]}, {"id": "2106.06304", "submitter": "Furong Ye", "authors": "Furong Ye and Carola Doerr and Hao Wang and Thomas B\\\"ack", "title": "Automated Configuration of Genetic Algorithms by Tuning for Anytime\n  Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the best configuration of algorithms' hyperparameters for a given\noptimization problem is an important task in evolutionary computation. We\ncompare in this work the results of four different hyperparameter tuning\napproaches for a family of genetic algorithms on 25 diverse pseudo-Boolean\noptimization problems. More precisely, we compare previously obtained results\nfrom a grid search with those obtained from three automated configuration\ntechniques: iterated racing, mixed-integer parallel efficient global\noptimization, and mixed-integer evolutionary strategies.\n  Using two different cost metrics, expected running time and the area under\nthe empirical cumulative distribution function curve, we find that in several\ncases the best configurations with respect to expected running time are\nobtained when using the area under the empirical cumulative distribution\nfunction curve as the cost metric during the configuration process. Our results\nsuggest that even when interested in expected running time performance, it\nmight be preferable to use anytime performance measures for the configuration\ntask. We also observe that tuning for expected running time is much more\nsensitive with respect to the budget that is allocated to the target\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 10:44:51 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Ye", "Furong", ""], ["Doerr", "Carola", ""], ["Wang", "Hao", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2106.06579", "submitter": "Yeshwanth Venkatesha", "authors": "Yeshwanth Venkatesha, Youngeun Kim, Leandros Tassiulas, Priyadarshini\n  Panda", "title": "Federated Learning with Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks get widespread adoption in resource-constrained embedded\ndevices, there is a growing need for low-power neural systems. Spiking Neural\nNetworks (SNNs)are emerging to be an energy-efficient alternative to the\ntraditional Artificial Neural Networks (ANNs) which are known to be\ncomputationally intensive. From an application perspective, as federated\nlearning involves multiple energy-constrained devices, there is a huge scope to\nleverage energy efficiency provided by SNNs. Despite its importance, there has\nbeen little attention on training SNNs on a large-scale distributed system like\nfederated learning. In this paper, we bring SNNs to a more realistic federated\nlearning scenario. Specifically, we propose a federated learning framework for\ndecentralized and privacy-preserving training of SNNs. To validate the proposed\nfederated learning framework, we experimentally evaluate the advantages of SNNs\non various aspects of federated learning with CIFAR10 and CIFAR100 benchmarks.\nWe observe that SNNs outperform ANNs in terms of overall accuracy by over 15%\nwhen the data is distributed across a large number of clients in the federation\nwhile providing up to5.3x energy efficiency. In addition to efficiency, we also\nanalyze the sensitivity of the proposed federated SNN framework to data\ndistribution among the clients, stragglers, and gradient noise and perform a\ncomprehensive comparison with ANNs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 19:00:58 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Venkatesha", "Yeshwanth", ""], ["Kim", "Youngeun", ""], ["Tassiulas", "Leandros", ""], ["Panda", "Priyadarshini", ""]]}, {"id": "2106.06876", "submitter": "Arnaud Berny", "authors": "Arnaud Berny", "title": "Affine OneMax", "comments": "An extended two-page abstract of this work will appear in 2021\n  Genetic and Evolutionary Computation Conference Companion (GECCO '21\n  Companion)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of test functions for black box optimization is introduced.\nAffine OneMax (AOM) functions are defined as compositions of OneMax and\ninvertible affine maps on bit vectors. The black box complexity of the class is\nupper bounded by a polynomial of large degree in the dimension. The proof\nrelies on discrete Fourier analysis and the Kushilevitz-Mansour algorithm.\nTunable complexity is achieved by expressing invertible linear maps as finite\nproducts of transvections. The black box complexity of sub-classes of AOM\nfunctions is studied. Finally, experimental results are given to illustrate the\nperformance of search algorithms on AOM functions.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jun 2021 22:41:18 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Berny", "Arnaud", ""]]}, {"id": "2106.06927", "submitter": "Renan Rojas-Gomez", "authors": "Renan A. Rojas-Gomez, Raymond A. Yeh, Minh N. Do, Anh Nguyen", "title": "Inverting Adversarially Robust Networks for Image Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent research in adversarially robust classifiers suggests their\nrepresentations tend to be aligned with human perception, which makes them\nattractive for image synthesis and restoration applications. Despite favorable\nempirical results on a few downstream tasks, their advantages are limited to\nslow and sensitive optimization-based techniques. Moreover, their use on\ngenerative models remains unexplored. This work proposes the use of robust\nrepresentations as a perceptual primitive for feature inversion models, and\nshow its benefits with respect to standard non-robust image features. We\nempirically show that adopting robust representations as an image prior\nsignificantly improves the reconstruction accuracy of CNN-based feature\ninversion models. Furthermore, it allows reconstructing images at multiple\nscales out-of-the-box. Following these findings, we propose an\nencoding-decoding network based on robust representations and show its\nadvantages for applications such as anomaly detection, style transfer and image\ndenoising.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 05:51:00 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rojas-Gomez", "Renan A.", ""], ["Yeh", "Raymond A.", ""], ["Do", "Minh N.", ""], ["Nguyen", "Anh", ""]]}, {"id": "2106.07030", "submitter": "Alpha Renner", "authors": "Alpha Renner, Forrest Sheldon, Anatoly Zlotnik, Louis Tao, Andrew\n  Sornborger", "title": "The Backpropagation Algorithm Implemented on Spiking Neuromorphic\n  Hardware", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-21-24457", "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capabilities of natural neural systems have inspired new generations of\nmachine learning algorithms as well as neuromorphic very large-scale integrated\n(VLSI) circuits capable of fast, low-power information processing. However,\nmost modern machine learning algorithms are not neurophysiologically plausible\nand thus are not directly implementable in neuromorphic hardware. In\nparticular, the workhorse of modern deep learning, the backpropagation\nalgorithm, has proven difficult to translate to neuromorphic hardware. In this\nstudy, we present a neuromorphic, spiking backpropagation algorithm based on\npulse-gated dynamical information coordination and processing, implemented on\nIntel's Loihi neuromorphic research processor. We demonstrate a\nproof-of-principle three-layer circuit that learns to classify digits from the\nMNIST dataset. This implementation shows a path for using massively parallel,\nlow-power, low-latency neuromorphic processors in modern deep learning\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 15:56:40 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Renner", "Alpha", ""], ["Sheldon", "Forrest", ""], ["Zlotnik", "Anatoly", ""], ["Tao", "Louis", ""], ["Sornborger", "Andrew", ""]]}, {"id": "2106.07091", "submitter": "Ramin Hasani", "authors": "Zahra Babaiee, Ramin Hasani, Mathias Lechner, Daniela Rus, Radu Grosu", "title": "On-Off Center-Surround Receptive Fields for Accurate and Robust Image\n  Classification", "comments": "21 Pages. Accepted for publication in the proceedings of the 38th\n  International Conference on Machine Learning (ICML) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robustness to variations in lighting conditions is a key objective for any\ndeep vision system. To this end, our paper extends the receptive field of\nconvolutional neural networks with two residual components, ubiquitous in the\nvisual processing system of vertebrates: On-center and off-center pathways,\nwith excitatory center and inhibitory surround; OOCS for short. The on-center\npathway is excited by the presence of a light stimulus in its center but not in\nits surround, whereas the off-center one is excited by the absence of a light\nstimulus in its center but not in its surround. We design OOCS pathways via a\ndifference of Gaussians, with their variance computed analytically from the\nsize of the receptive fields. OOCS pathways complement each other in their\nresponse to light stimuli, ensuring this way a strong edge-detection\ncapability, and as a result, an accurate and robust inference under challenging\nlighting conditions. We provide extensive empirical evidence showing that\nnetworks supplied with the OOCS edge representation gain accuracy and\nillumination-robustness compared to standard deep models.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 20:55:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Babaiee", "Zahra", ""], ["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Rus", "Daniela", ""], ["Grosu", "Radu", ""]]}, {"id": "2106.07095", "submitter": "Arnaud Berny", "authors": "Arnaud Berny", "title": "Linear representation of categorical values", "comments": "An extended two-page abstract of this work will appear in 2021\n  Genetic and Evolutionary Computation Conference Companion (GECCO '21\n  Companion)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a binary representation of categorical values using a linear map.\nThis linear representation preserves the neighborhood structure of categorical\nvalues. In the context of evolutionary algorithms, it means that every\ncategorical value can be reached in a single mutation. The linear\nrepresentation is embedded into standard metaheuristics, applied to the problem\nof Sudoku puzzles, and compared to the more traditional direct binary encoding.\nIt shows promising results in fixed-budget experiments and empirical cumulative\ndistribution functions with high dimension instances, and also in fixed-target\nexperiments with small dimension instances.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jun 2021 21:28:03 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Berny", "Arnaud", ""]]}, {"id": "2106.07172", "submitter": "Dongjin Lee", "authors": "Dongjin Lee, Seongsik Park, Jongwan Kim, Wuhyeong Doh, Sungroh Yoon", "title": "Energy-efficient Knowledge Distillation for Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking neural networks (SNNs) have been gaining interest as energy-efficient\nalternatives of conventional artificial neural networks (ANNs) due to their\nevent-driven computation. Considering the future deployment of SNN models to\nconstrained neuromorphic devices, many studies have applied techniques\noriginally used for ANN model compression, such as network quantization,\npruning, and knowledge distillation, to SNNs. Among them, existing works on\nknowledge distillation reported accuracy improvements of student SNN model.\nHowever, analysis on energy efficiency, which is also an important feature of\nSNN, was absent. In this paper, we thoroughly analyze the performance of the\ndistilled SNN model in terms of accuracy and energy efficiency. In the process,\nwe observe a substantial increase in the number of spikes, leading to energy\ninefficiency, when using the conventional knowledge distillation methods. Based\non this analysis, to achieve energy efficiency, we propose a novel knowledge\ndistillation method with heterogeneous temperature parameters. We evaluate our\nmethod on two different datasets and show that the resulting SNN student\nsatisfies both accuracy improvement and reduction of the number of spikes. On\nMNIST dataset, our proposed student SNN achieves up to 0.09% higher accuracy\nand produces 65% less spikes compared to the student SNN trained with\nconventional knowledge distillation method. We also compare the results with\nother SNN compression techniques and training methods.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 05:42:05 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lee", "Dongjin", ""], ["Park", "Seongsik", ""], ["Kim", "Jongwan", ""], ["Doh", "Wuhyeong", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2106.07252", "submitter": "Qi Zhao", "authors": "Qi Zhao, Bai Yan, Yuhui Shi", "title": "Evolutionary Robust Clustering Over Time for Temporal Data", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many clustering scenes, data samples' attribute values change over time.\nFor such data, we are often interested in obtaining a partition for each time\nstep and tracking the dynamic change of partitions. Normally, a smooth change\nis assumed for data to have a temporal smooth nature. Existing algorithms\nconsider the temporal smoothness as an a priori preference and bias the search\ntowards the preferred direction. This a priori manner leads to a risk of\nconverging to an unexpected region because it is not always the case that a\nreasonable preference can be elicited given the little prior knowledge about\nthe data. To address this issue, this paper proposes a new clustering framework\ncalled evolutionary robust clustering over time. One significant innovation of\nthe proposed framework is processing the temporal smoothness in an a posteriori\nmanner, which avoids unexpected convergence that occurs in existing algorithms.\nFurthermore, the proposed framework automatically tunes the weight of\nsmoothness without data's affinity matrix and predefined parameters, which\nholds better applicability and scalability. The effectiveness and efficiency of\nthe proposed framework are confirmed by comparing with state-of-the-art\nalgorithms on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 09:07:42 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhao", "Qi", ""], ["Yan", "Bai", ""], ["Shi", "Yuhui", ""]]}, {"id": "2106.07318", "submitter": "Qi Zhao", "authors": "Bai Yan, Qi Zhao, Jin Zhang, J. Andrew Zhang, Xin Yao", "title": "Multiobjective Bilevel Evolutionary Approach for Off-Grid\n  Direction-of-Arrival Estimation", "comments": "This paper has been submitted to an Elsevier journal for peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The source number identification is an essential step in direction-of-arrival\n(DOA) estimation. Existing methods may provide a wrong source number due to\ninferior statistical properties (in low SNR or limited snapshots) or modeling\nerrors (caused by relaxing sparse penalties), especially in impulsive noise. To\naddress this issue, we propose a novel idea of simultaneous source number\nidentification and DOA estimation. We formulate a multiobjective off-grid DOA\nestimation model to realize this idea, by which the source number can be\nautomatically identified together with DOA estimation. In particular, the\nsource number is properly exploited by the $l_0$ norm of impinging signals\nwithout relaxations, guaranteeing accuracy. Furthermore, we design a\nmultiobjective bilevel evolutionary algorithm to solve the proposed model. The\nsource number identification and sparse recovery are simultaneously optimized\nat the on-grid (lower) level. A forward search strategy is developed to further\nrefine the grid at the off-grid (upper) level. This strategy does not need\nlinear approximations and can eliminate the off-grid gap with low computational\ncomplexity. Simulation results demonstrate the outperformance of our method in\nterms of source number and root mean square error.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 11:44:03 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yan", "Bai", ""], ["Zhao", "Qi", ""], ["Zhang", "Jin", ""], ["Zhang", "J. Andrew", ""], ["Yao", "Xin", ""]]}, {"id": "2106.07323", "submitter": "Qi Zhao", "authors": "Bai Yan, Qi Zhao, Jin Zhang, J. Andrew Zhang, Xin Yao", "title": "Gridless Evolutionary Approach for Line Spectral Estimation with Unknown\n  Model Order", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gridless methods show great superiority in line spectral estimation. These\nmethods need to solve an atomic $l_0$ norm (i.e., the continuous analog of\n$l_0$ norm) minimization problem to estimate frequencies and model order. Since\nthis problem is NP-hard to compute, relaxations of atomic $l_0$ norm, such as\nnuclear norm and reweighted atomic norm, have been employed for promoting\nsparsity. However, the relaxations give rise to a resolution limit,\nsubsequently leading to biased model order and convergence error. To overcome\nthe above shortcomings of relaxation, we propose a novel idea of simultaneously\nestimating the frequencies and model order by means of the atomic $l_0$ norm.\nTo accomplish this idea, we build a multiobjective optimization model. The\nmeasurment error and the atomic $l_0$ norm are taken as the two optimization\nobjectives. The proposed model directly exploits the model order via the atomic\n$l_0$ norm, thus breaking the resolution limit. We further design a\nvariable-length evolutionary algorithm to solve the proposed model, which\nincludes two innovations. One is a variable-length coding and search strategy.\nIt flexibly codes and interactively searches diverse solutions with different\nmodel orders. These solutions act as steppingstones that help fully exploring\nthe variable and open-ended frequency search space and provide extensive\npotentials towards the optima. Another innovation is a model order pruning\nmechanism, which heuristically prunes less contributive frequencies within the\nsolutions, thus significantly enhancing convergence and diversity. Simulation\nresults confirm the superiority of our approach in both frequency estimation\nand model order selection.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 11:54:37 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Yan", "Bai", ""], ["Zhao", "Qi", ""], ["Zhang", "Jin", ""], ["Zhang", "J. Andrew", ""], ["Yao", "Xin", ""]]}, {"id": "2106.07611", "submitter": "Santiago Miret", "authors": "Santiago Miret, Vui Seng Chua, Mattias Marder, Mariano Phielipp,\n  Nilesh Jain, Somdeb Majumdar", "title": "Neuroevolution-Enhanced Multi-Objective Optimization for Mixed-Precision\n  Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mixed-precision quantization is a powerful tool to enable memory and compute\nsavings of neural network workloads by deploying different sets of bit-width\nprecisions on separate compute operations. Recent research has shown\nsignificant progress in applying mixed-precision quantization techniques to\nreduce the memory footprint of various workloads, while also preserving task\nperformance. Prior work, however, has often ignored additional objectives, such\nas bit-operations, that are important for deployment of workloads on hardware.\nHere we present a flexible and scalable framework for automated mixed-precision\nquantization that optimizes multiple objectives. Our framework relies on\nNeuroevolution-Enhanced Multi-Objective Optimization (NEMO), a novel search\nmethod, to find Pareto optimal mixed-precision configurations for memory and\nbit-operations objectives. Within NEMO, a population is divided into\nstructurally distinct sub-populations (species) which jointly form the Pareto\nfrontier of solutions for the multi-objective problem. At each generation,\nspecies are re-sized in proportion to the goodness of their contribution to the\nPareto frontier. This allows NEMO to leverage established search techniques and\nneuroevolution methods to continually improve the goodness of the Pareto\nfrontier. In our experiments we apply a graph-based representation to describe\nthe underlying workload, enabling us to deploy graph neural networks trained by\nNEMO to find Pareto optimal configurations for various workloads trained on\nImageNet. Compared to the state-of-the-art, we achieve competitive results on\nmemory compression and superior results for compute compression for\nMobileNet-V2, ResNet50 and ResNeXt-101-32x8d. A deeper analysis of the results\nobtained by NEMO also shows that both the graph representation and the\nspecies-based approach are critical in finding effective configurations for all\nworkloads.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jun 2021 17:15:15 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Miret", "Santiago", ""], ["Chua", "Vui Seng", ""], ["Marder", "Mattias", ""], ["Phielipp", "Mariano", ""], ["Jain", "Nilesh", ""], ["Majumdar", "Somdeb", ""]]}, {"id": "2106.08314", "submitter": "Ramin Hasani", "authors": "Charles Vorbach, Ramin Hasani, Alexander Amini, Mathias Lechner,\n  Daniela Rus", "title": "Causal Navigation by Continuous-time Neural Networks", "comments": "23 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Imitation learning enables high-fidelity, vision-based learning of policies\nwithin rich, photorealistic environments. However, such techniques often rely\non traditional discrete-time neural models and face difficulties in\ngeneralizing to domain shifts by failing to account for the causal\nrelationships between the agent and the environment. In this paper, we propose\na theoretical and experimental framework for learning causal representations\nusing continuous-time neural networks, specifically over their discrete-time\ncounterparts. We evaluate our method in the context of visual-control learning\nof drones over a series of complex tasks, ranging from short- and long-term\nnavigation, to chasing static and dynamic objects through photorealistic\nenvironments. Our results demonstrate that causal continuous-time deep models\ncan perform robust navigation tasks, where advanced recurrent models fail.\nThese models learn complex causal control representations directly from raw\nvisual inputs and scale to solve a variety of tasks using imitation learning.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 17:45:32 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Vorbach", "Charles", ""], ["Hasani", "Ramin", ""], ["Amini", "Alexander", ""], ["Lechner", "Mathias", ""], ["Rus", "Daniela", ""]]}, {"id": "2106.08747", "submitter": "Luis Marti", "authors": "Taco de Wolff (CIRIC), Hugo Carrillo (CIRIC), Luis Mart\\'i (CIRIC),\n  Nayat Sanchez-Pi (CIRIC)", "title": "Towards Optimally Weighted Physics-Informed Neural Networks in Ocean\n  Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The carbon pump of the world's ocean plays a vital role in the biosphere and\nclimate of the earth, urging improved understanding of the functions and\ninfluences of the ocean for climate change analyses. State-of-the-art\ntechniques are required to develop models that can capture the complexity of\nocean currents and temperature flows. This work explores the benefits of using\nphysics-informed neural networks (PINNs) for solving partial differential\nequations related to ocean modeling; such as the Burgers, wave, and\nadvection-diffusion equations. We explore the trade-offs of using data vs.\nphysical models in PINNs for solving partial differential equations. PINNs\naccount for the deviation from physical laws in order to improve learning and\ngeneralization. We observed how the relative weight between the data and\nphysical model in the loss function influence training results, where small\ndata sets benefit more from the added physics information.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 12:48:13 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["de Wolff", "Taco", "", "CIRIC"], ["Carrillo", "Hugo", "", "CIRIC"], ["Mart\u00ed", "Luis", "", "CIRIC"], ["Sanchez-Pi", "Nayat", "", "CIRIC"]]}, {"id": "2106.08748", "submitter": "Suman Sapkota", "authors": "Suman Sapkota and Binod Bhattarai", "title": "Input Invex Neural Network", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel method to constrain invexity on Neural\nNetworks (NN). Invex functions ensure every stationary point is global minima.\nHence, gradient descent commenced from any point will lead to the global\nminima. Another advantage of invexity on NN is to divide data space locally\ninto two connected sets with a highly non-linear decision boundary by simply\nthresholding the output. To this end, we formulate a universal invex function\napproximator and employ it to enforce invexity in NN. We call it Input Invex\nNeural Networks (II-NN). We first fit data with a known invex function,\nfollowed by modification with a NN, compare the direction of the gradient and\npenalize the direction of gradient on NN if it contradicts with the direction\nof reference invex function. In order to penalize the direction of the gradient\nwe perform Gradient Clipped Gradient Penalty (GC-GP). We applied our method to\nthe existing NNs for both image classification and regression tasks. From the\nextensive empirical and qualitative experiments, we observe that our method\ngives the performance similar to ordinary NN yet having invexity. Our method\noutperforms linear NN and Input Convex Neural Network (ICNN) with a large\nmargin. We publish our code and implementation details at github.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 12:48:55 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Sapkota", "Suman", ""], ["Bhattarai", "Binod", ""]]}, {"id": "2106.08918", "submitter": "Jake Grigsby", "authors": "Jake Grigsby, Jin Yong Yoo, Yanjun Qi", "title": "Towards Automatic Actor-Critic Solutions to Continuous Control", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Model-free off-policy actor-critic methods are an efficient solution to\ncomplex continuous control tasks. However, these algorithms rely on a number of\ndesign tricks and many hyperparameters, making their applications to new\ndomains difficult and computationally expensive. This paper creates an\nevolutionary approach that automatically tunes these design decisions and\neliminates the RL-specific hyperparameters from the Soft Actor-Critic\nalgorithm. Our design is sample efficient and provides practical advantages\nover baseline approaches, including improved exploration, generalization over\nmultiple control frequencies, and a robust ensemble of high-performance\npolicies. Empirically, we show that our agent outperforms well-tuned\nhyperparameter settings in popular benchmarks from the DeepMind Control Suite.\nWe then apply it to new control tasks to find high-performance solutions with\nminimal compute and research effort.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 16:18:20 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Grigsby", "Jake", ""], ["Yoo", "Jin Yong", ""], ["Qi", "Yanjun", ""]]}, {"id": "2106.08921", "submitter": "Kinjal Pravinbhai Patel Ms", "authors": "Kinjal Patel, Eric Hunsberger, Sean Batir, and Chris Eliasmith", "title": "A Spiking Neural Network for Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to investigate the scalability of neuromorphic computing for computer\nvision, with the objective of replicating non-neuromorphic performance on\ncomputer vision tasks while reducing power consumption. We convert the deep\nArtificial Neural Network (ANN) architecture U-Net to a Spiking Neural Network\n(SNN) architecture using the Nengo framework. Both rate-based and spike-based\nmodels are trained and optimized for benchmarking performance and power, using\na modified version of the ISBI 2D EM Segmentation dataset consisting of\nmicroscope images of cells. We propose a partitioning method to optimize\ninter-chip communication to improve speed and energy efficiency when deploying\nmulti-chip networks on the Loihi neuromorphic chip. We explore the advantages\nof regularizing firing rates of Loihi neurons for converting ANN to SNN with\nminimum accuracy loss and optimized energy consumption. We propose a percentile\nbased regularization loss function to limit the spiking rate of the neuron\nbetween a desired range. The SNN is converted directly from the corresponding\nANN, and demonstrates similar semantic segmentation as the ANN using the same\nnumber of neurons and weights. However, the neuromorphic implementation on the\nIntel Loihi neuromorphic chip is over 2x more energy-efficient than\nconventional hardware (CPU, GPU) when running online (one image at a time).\nThese power improvements are achieved without sacrificing the task performance\naccuracy of the network, and when all weights (Loihi, CPU, and GPU networks)\nare quantized to 8 bits.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 16:23:18 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Patel", "Kinjal", ""], ["Hunsberger", "Eric", ""], ["Batir", "Sean", ""], ["Eliasmith", "Chris", ""]]}, {"id": "2106.08937", "submitter": "Louis Annabi", "authors": "Louis Annabi, Alexandre Pitti and Mathias Quoy", "title": "A Predictive Coding Account for Chaotic Itinerancy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG nlin.CD", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  As a phenomenon in dynamical systems allowing autonomous switching between\nstable behaviors, chaotic itinerancy has gained interest in neurorobotics\nresearch. In this study, we draw a connection between this phenomenon and the\npredictive coding theory by showing how a recurrent neural network implementing\npredictive coding can generate neural trajectories similar to chaotic\nitinerancy in the presence of input noise. We propose two scenarios generating\nrandom and past-independent attractor switching trajectories using our model.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 16:48:14 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Annabi", "Louis", ""], ["Pitti", "Alexandre", ""], ["Quoy", "Mathias", ""]]}, {"id": "2106.08972", "submitter": "Unai Garciarena", "authors": "Unai Garciarena, Roberto Santana, Alexander Mendiburu", "title": "Redefining Neural Architecture Search of Heterogeneous Multi-Network\n  Models by Characterizing Variation Operators and Model Components", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With neural architecture search methods gaining ground on manually designed\ndeep neural networks -even more rapidly as model sophistication escalates-, the\nresearch trend shifts towards arranging different and often increasingly\ncomplex neural architecture search spaces. In this conjuncture, delineating\nalgorithms which can efficiently explore these search spaces can result in a\nsignificant improvement over currently used methods, which, in general,\nrandomly select the structural variation operator, hoping for a performance\ngain. In this paper, we investigate the effect of different variation operators\nin a complex domain, that of multi-network heterogeneous neural models. These\nmodels have an extensive and complex search space of structures as they require\nmultiple sub-networks within the general model in order to answer to different\noutput types. From that investigation, we extract a set of general guidelines,\nwhose application is not limited to that particular type of model, and are\nuseful to determine the direction in which an architecture optimization method\ncould find the largest improvement. To deduce the set of guidelines, we\ncharacterize both the variation operators, according to their effect on the\ncomplexity and performance of the model; and the models, relying on diverse\nmetrics which estimate the quality of the different parts composing it.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:12:26 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Garciarena", "Unai", ""], ["Santana", "Roberto", ""], ["Mendiburu", "Alexander", ""]]}, {"id": "2106.09011", "submitter": "Paola Cascante-Bonilla", "authors": "Paola Cascante-Bonilla, Arshdeep Sekhon, Yanjun Qi, Vicente Ordonez", "title": "Evolving Image Compositions for Feature Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional neural networks for visual recognition require large amounts of\ntraining samples and usually benefit from data augmentation. This paper\nproposes PatchMix, a data augmentation method that creates new samples by\ncomposing patches from pairs of images in a grid-like pattern. These new\nsamples' ground truth labels are set as proportional to the number of patches\nfrom each image. We then add a set of additional losses at the patch-level to\nregularize and to encourage good representations at both the patch and image\nlevels. A ResNet-50 model trained on ImageNet using PatchMix exhibits superior\ntransfer learning capabilities across a wide array of benchmarks. Although\nPatchMix can rely on random pairings and random grid-like patterns for mixing,\nwe explore evolutionary search as a guiding strategy to discover optimal\ngrid-like patterns and image pairing jointly. For this purpose, we conceive a\nfitness function that bypasses the need to re-train a model to evaluate each\nchoice. In this way, PatchMix outperforms a base model on CIFAR-10 (+1.91),\nCIFAR-100 (+5.31), Tiny Imagenet (+3.52), and ImageNet (+1.16) by significant\nmargins, also outperforming previous state-of-the-art pairwise augmentation\nstrategies.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 17:57:18 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Cascante-Bonilla", "Paola", ""], ["Sekhon", "Arshdeep", ""], ["Qi", "Yanjun", ""], ["Ordonez", "Vicente", ""]]}, {"id": "2106.09104", "submitter": "Anup Das", "authors": "Shihao Song, Twisha Titirsha, Anup Das", "title": "Improving Inference Lifetime of Neuromorphic Systems via Intelligent\n  Synapse Mapping", "comments": "Accepted for publication at ASAP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-Volatile Memories (NVMs) such as Resistive RAM (RRAM) are used in\nneuromorphic systems to implement high-density and low-power analog synaptic\nweights. Unfortunately, an RRAM cell can switch its state after reading its\ncontent a certain number of times. Such behavior challenges the integrity and\nprogram-once-read-many-times philosophy of implementing machine learning\ninference on neuromorphic systems, impacting the Quality-of-Service (QoS).\nElevated temperatures and frequent usage can significantly shorten the number\nof times an RRAM cell can be reliably read before it becomes absolutely\nnecessary to reprogram. We propose an architectural solution to extend the read\nendurance of RRAM-based neuromorphic systems. We make two key contributions.\nFirst, we formulate the read endurance of an RRAM cell as a function of the\nprogrammed synaptic weight and its activation within a machine learning\nworkload. Second, we propose an intelligent workload mapping strategy\nincorporating the endurance formulation to place the synapses of a machine\nlearning model onto the RRAM cells of the hardware. The objective is to extend\nthe inference lifetime, defined as the number of times the model can be used to\ngenerate output (inference) before the trained weights need to be reprogrammed\non the RRAM cells of the system. We evaluate our architectural solution with\nmachine learning workloads on a cycle-accurate simulator of an RRAM-based\nneuromorphic system. Our results demonstrate a significant increase in\ninference lifetime with only a minimal performance impact.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 20:12:47 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Song", "Shihao", ""], ["Titirsha", "Twisha", ""], ["Das", "Anup", ""]]}, {"id": "2106.09153", "submitter": "Kevin Frans", "authors": "Kevin Frans, L.B. Soros, Olaf Witkowski", "title": "Selecting for Selection: Learning To Balance Adaptive and Diversifying\n  Pressures in Evolutionary Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by natural evolution, evolutionary search algorithms have proven\nremarkably capable due to their dual abilities to radiantly explore through\ndiverse populations and to converge to adaptive pressures. A large part of this\nbehavior comes from the selection function of an evolutionary algorithm, which\nis a metric for deciding which individuals survive to the next generation. In\ndeceptive or hard-to-search fitness landscapes, greedy selection often fails,\nthus it is critical that selection functions strike the correct balance between\ngradient-exploiting adaptation and exploratory diversification. This paper\nintroduces Sel4Sel, or Selecting for Selection, an algorithm that searches for\nhigh-performing neural-network-based selection functions through a\nmeta-evolutionary loop. Results on three distinct bitstring domains indicate\nthat Sel4Sel networks consistently match or exceed the performance of both\nfitness-based selection and benchmarks explicitly designed to encourage\ndiversity. Analysis of the strongest Sel4Sel networks reveals a general\ntendency to favor highly novel individuals early on, with a gradual shift\ntowards fitness-based selection as deceptive local optima are bypassed.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 22:11:27 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Frans", "Kevin", ""], ["Soros", "L. B.", ""], ["Witkowski", "Olaf", ""]]}, {"id": "2106.09180", "submitter": "Yash Akhauri", "authors": "Yash Akhauri, Adithya Niranjan, J. Pablo Mu\\~noz, Suvadeep Banerjee,\n  Abhijit Davare, Pasquale Cocchini, Anton A. Sorokin, Ravi Iyer, Nilesh Jain", "title": "RHNAS: Realizable Hardware and Neural Architecture Search", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapidly evolving field of Artificial Intelligence necessitates automated\napproaches to co-design neural network architecture and neural accelerators to\nmaximize system efficiency and address productivity challenges. To enable joint\noptimization of this vast space, there has been growing interest in\ndifferentiable NN-HW co-design. Fully differentiable co-design has reduced the\nresource requirements for discovering optimized NN-HW configurations, but fail\nto adapt to general hardware accelerator search spaces. This is due to the\nexistence of non-synthesizable (invalid) designs in the search space of many\nhardware accelerators. To enable efficient and realizable co-design of\nconfigurable hardware accelerators with arbitrary neural network search spaces,\nwe introduce RHNAS. RHNAS is a method that combines reinforcement learning for\nhardware optimization with differentiable neural architecture search. RHNAS\ndiscovers realizable NN-HW designs with 1.84x lower latency and 1.86x lower\nenergy-delay product (EDP) on ImageNet and 2.81x lower latency and 3.30x lower\nEDP on CIFAR-10 over the default hardware accelerator design.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 00:15:42 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Akhauri", "Yash", ""], ["Niranjan", "Adithya", ""], ["Mu\u00f1oz", "J. Pablo", ""], ["Banerjee", "Suvadeep", ""], ["Davare", "Abhijit", ""], ["Cocchini", "Pasquale", ""], ["Sorokin", "Anton A.", ""], ["Iyer", "Ravi", ""], ["Jain", "Nilesh", ""]]}, {"id": "2106.09269", "submitter": "Daiki Chijiwa", "authors": "Daiki Chijiwa, Shin'ya Yamaguchi, Yasutoshi Ida, Kenji Umakoshi,\n  Tomohiro Inoue", "title": "Pruning Randomly Initialized Neural Networks with Iterative\n  Randomization", "comments": "Code will be available at https://github.com/dchiji-ntt/iterand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning the weights of randomly initialized neural networks plays an\nimportant role in the context of lottery ticket hypothesis. Ramanujan et al.\n(2020) empirically showed that only pruning the weights can achieve remarkable\nperformance instead of optimizing the weight values. However, to achieve the\nsame level of performance as the weight optimization, the pruning approach\nrequires more parameters in the networks before pruning and thus more memory\nspace. To overcome this parameter inefficiency, we introduce a novel framework\nto prune randomly initialized neural networks with iteratively randomizing\nweight values (IteRand). Theoretically, we prove an approximation theorem in\nour framework, which indicates that the randomizing operations are provably\neffective to reduce the required number of the parameters. We also empirically\ndemonstrate the parameter efficiency in multiple experiments on CIFAR-10 and\nImageNet.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 06:32:57 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Chijiwa", "Daiki", ""], ["Yamaguchi", "Shin'ya", ""], ["Ida", "Yasutoshi", ""], ["Umakoshi", "Kenji", ""], ["Inoue", "Tomohiro", ""]]}, {"id": "2106.09296", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Yun-Yun Tsai, Pin-Yu Chen", "title": "Voice2Series: Reprogramming Acoustic Models for Time Series\n  Classification", "comments": "Accepted to ICML 2021, 16 Pages", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning 2021", "doi": null, "report-no": "11808--11819", "categories": "cs.LG cs.AI cs.NE cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning to classify time series with limited data is a practical yet\nchallenging problem. Current methods are primarily based on hand-designed\nfeature extraction rules or domain-specific data augmentation. Motivated by the\nadvances in deep speech processing models and the fact that voice data are\nunivariate temporal signals, in this paper, we propose Voice2Series (V2S), a\nnovel end-to-end approach that reprograms acoustic models for time series\nclassification, through input transformation learning and output label mapping.\nLeveraging the representation learning power of a large-scale pre-trained\nspeech processing model, on 30 different time series tasks we show that V2S\neither outperforms or is tied with state-of-the-art methods on 20 tasks, and\nimproves their average accuracy by 1.84%. We further provide a theoretical\njustification of V2S by proving its population risk is upper bounded by the\nsource risk and a Wasserstein distance accounting for feature alignment via\nreprogramming. Our results offer new and effective means to time series\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 07:59:15 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Tsai", "Yun-Yun", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2106.09330", "submitter": "Daniel Nissani", "authors": "Daniel N. Nissani (Nissensohn)", "title": "A Simple Generative Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative neural networks are able to mimic intricate probability\ndistributions such as those of handwritten text, natural images, etc. Since\ntheir inception several models were proposed. The most successful of these were\nbased on adversarial (GAN), auto-encoding (VAE) and maximum mean discrepancy\n(MMD) relatively complex architectures and schemes. Surprisingly, a very simple\narchitecture (a single feed-forward neural network) in conjunction with an\nobvious optimization goal (Kullback_Leibler divergence) was apparently\noverlooked. This paper demonstrates that such a model (denoted SGN for its\nsimplicity) is able to generate samples visually and quantitatively competitive\nas compared with the fore-mentioned state of the art methods.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 08:49:17 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 14:05:07 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 05:17:26 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Nissani", "Daniel N.", "", "Nissensohn"]]}, {"id": "2106.09693", "submitter": "Koushik Biswas", "authors": "Koushik Biswas, Shilpak Banerjee, Ashish Kumar Pandey", "title": "Orthogonal-Pad\\'e Activation Functions: Trainable Activation functions\n  for smooth and faster convergence in deep networks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have proposed orthogonal-Pad\\'e activation functions, which are trainable\nactivation functions and show that they have faster learning capability and\nimproves the accuracy in standard deep learning datasets and models. Based on\nour experiments, we have found two best candidates out of six orthogonal-Pad\\'e\nactivations, which we call safe Hermite-Pade (HP) activation functions, namely\nHP-1 and HP-2. When compared to ReLU, HP-1 and HP-2 has an increment in top-1\naccuracy by 5.06% and 4.63% respectively in PreActResNet-34, by 3.02% and 2.75%\nrespectively in MobileNet V2 model on CIFAR100 dataset while on CIFAR10 dataset\ntop-1 accuracy increases by 2.02% and 1.78% respectively in PreActResNet-34, by\n2.24% and 2.06% respectively in LeNet, by 2.15% and 2.03% respectively in\nEfficientnet B0.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 17:47:01 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Biswas", "Koushik", ""], ["Banerjee", "Shilpak", ""], ["Pandey", "Ashish Kumar", ""]]}, {"id": "2106.09835", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Dual-Teacher Class-Incremental Learning With Data-Free Generative Replay", "comments": "CVPR 2021 Workshop on Continual Learning in Computer Vision\n  (CLVision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes two novel knowledge transfer techniques for\nclass-incremental learning (CIL). First, we propose data-free generative replay\n(DF-GR) to mitigate catastrophic forgetting in CIL by using synthetic samples\nfrom a generative model. In the conventional generative replay, the generative\nmodel is pre-trained for old data and shared in extra memory for later\nincremental learning. In our proposed DF-GR, we train a generative model from\nscratch without using any training data, based on the pre-trained\nclassification model from the past, so we curtail the cost of sharing\npre-trained generative models. Second, we introduce dual-teacher information\ndistillation (DT-ID) for knowledge distillation from two teachers to one\nstudent. In CIL, we use DT-ID to learn new classes incrementally based on the\npre-trained model for old classes and another model (pre-)trained on the new\ndata for new classes. We implemented the proposed schemes on top of one of the\nstate-of-the-art CIL methods and showed the performance improvement on\nCIFAR-100 and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 22:13:15 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Choi", "Yoojin", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "2106.09857", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Minghai Qin, Fei Sun, Zejiang Hou, Kun Yuan, Yi Xu,\n  Yanzhi Wang, Yen-Kuang Chen, Rong Jin, Yuan Xie", "title": "Effective Model Sparsification by Scheduled Grow-and-Prune Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) are effective in solving many real-world\nproblems. Larger DNN models usually exhibit better quality (e.g., accuracy) but\ntheir excessive computation results in long training and inference time. Model\nsparsification can reduce the computation and memory cost while maintaining\nmodel quality. Most existing sparsification algorithms unidirectionally remove\nweights, while others randomly or greedily explore a small subset of weights in\neach layer. The inefficiency of the algorithms reduces the achievable sparsity\nlevel. In addition, many algorithms still require pre-trained dense models and\nthus suffer from large memory footprint and long training time. In this paper,\nwe propose a novel scheduled grow-and-prune (GaP) methodology without\npre-training the dense models. It addresses the shortcomings of the previous\nworks by repeatedly growing a subset of layers to dense and then pruning back\nto sparse after some training. Experiments have shown that such models can\nmatch or beat the quality of highly optimized dense models at 80% sparsity on a\nvariety of tasks, such as image classification, objective detection, 3D object\npart segmentation, and translation. They also outperform other state-of-the-art\n(SOTA) pruning methods, including pruning from pre-trained dense models. As an\nexample, a 90% sparse ResNet-50 obtained via GaP achieves 77.9% top-1 accuracy\non ImageNet, improving the SOTA results by 1.5%.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 01:03:13 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Ma", "Xiaolong", ""], ["Qin", "Minghai", ""], ["Sun", "Fei", ""], ["Hou", "Zejiang", ""], ["Yuan", "Kun", ""], ["Xu", "Yi", ""], ["Wang", "Yanzhi", ""], ["Chen", "Yen-Kuang", ""], ["Jin", "Rong", ""], ["Xie", "Yuan", ""]]}, {"id": "2106.09922", "submitter": "Tomohiro Harada", "authors": "Tomohiro Harada and Enrique Alba and Gabriel Luque", "title": "A Fresh Approach to Evaluate Performance in Distributed Parallel Genetic\n  Algorithms", "comments": "22 pages, submitted to Applied Soft Computing and under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work proposes a novel approach to evaluate and analyze the behavior of\nmulti-population parallel genetic algorithms (PGAs) when running on a cluster\nof multi-core processors. In particular, we deeply study their numerical and\ncomputational behavior by proposing a mathematical model representing the\nobserved performance curves. In them, we discuss the emerging mathematical\ndescriptions of PGA performance instead of, e.g., individual isolated results\nsubject to visual inspection, for a better understanding of the effects of the\nnumber of cores used (scalability), their migration policy (the migration gap,\nin this paper), and the features of the solved problem (type of encoding and\nproblem size). The conclusions based on the real figures and the numerical\nmodels fitting them represent a fresh way of understanding their speed-up,\nrunning time, and numerical effort, allowing a comparison based on a few\nmeaningful numeric parameters. This represents a set of conclusions beyond the\nusual textual lessons found in past works on PGAs. It can be used as an\nestimation tool for the future performance of the algorithms and a way of\nfinding out their limitations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 05:07:14 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Harada", "Tomohiro", ""], ["Alba", "Enrique", ""], ["Luque", "Gabriel", ""]]}, {"id": "2106.10015", "submitter": "Anil Yaman", "authors": "Anil Yaman, Nicolas Bredeche, Onur \\c{C}aylak, Joel Z. Leibo, Sang Wan\n  Lee", "title": "Meta-control of social learning strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social learning, copying other's behavior without actual experience, offers a\ncost-effective means of knowledge acquisition. However, it raises the\nfundamental question of which individuals have reliable information: successful\nindividuals versus the majority. The former and the latter are known\nrespectively as success-based and conformist social learning strategies. We\nshow here that while the success-based strategy fully exploits the benign\nenvironment of low uncertainly, it fails in uncertain environments. On the\nother hand, the conformist strategy can effectively mitigate this adverse\neffect. Based on these findings, we hypothesized that meta-control of\nindividual and social learning strategies provides effective and\nsample-efficient learning in volatile and uncertain environments. Simulations\non a set of environments with various levels of volatility and uncertainty\nconfirmed our hypothesis. The results imply that meta-control of social\nlearning affords agents the leverage to resolve environmental uncertainty with\nminimal exploration cost, by exploiting others' learning as an external\nknowledge base.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 09:17:21 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Yaman", "Anil", ""], ["Bredeche", "Nicolas", ""], ["\u00c7aylak", "Onur", ""], ["Leibo", "Joel Z.", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2106.10155", "submitter": "Frederik Schubert", "authors": "Maren Awiszus, Frederik Schubert, Bodo Rosenhahn", "title": "World-GAN: a Generative Model for Minecraft Worlds", "comments": "8 pages, 8 figures, IEEE Conference on Games (CoG) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces World-GAN, the first method to perform data-driven\nProcedural Content Generation via Machine Learning in Minecraft from a single\nexample. Based on a 3D Generative Adversarial Network (GAN) architecture, we\nare able to create arbitrarily sized world snippets from a given sample. We\nevaluate our approach on creations from the community as well as structures\ngenerated with the Minecraft World Generator. Our method is motivated by the\ndense representations used in Natural Language Processing (NLP) introduced with\nword2vec [1]. The proposed block2vec representations make World-GAN independent\nfrom the number of different blocks, which can vary a lot in Minecraft, and\nenable the generation of larger levels. Finally, we demonstrate that changing\nthis new representation space allows us to change the generated style of an\nalready trained generator. World-GAN enables its users to generate Minecraft\nworlds based on parts of their creations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 14:45:39 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Awiszus", "Maren", ""], ["Schubert", "Frederik", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "2106.10382", "submitter": "Yusuke Sakemi Ph.D.", "authors": "Yusuke Sakemi, Takashi Morie, Takeo Hosomi, Kazuyuki Aihara", "title": "Effects of VLSI Circuit Constraints on Temporal-Coding Multilayer\n  Spiking Neural Networks", "comments": "corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spiking neural network (SNN) has been attracting considerable attention\nnot only as a mathematical model for the brain, but also as an energy-efficient\ninformation processing model for real-world applications. In particular, SNNs\nbased on temporal coding are expected to be much more efficient than those\nbased on rate coding, because the former requires substantially fewer spikes to\ncarry out tasks. As SNNs are continuous-state and continuous-time models, it is\nfavorable to implement them with analog VLSI circuits. However, the\nconstruction of the entire system with continuous-time analog circuits would be\ninfeasible when the system size is very large. Therefore, mixed-signal circuits\nmust be employed, and the time discretization and quantization of the synaptic\nweights are necessary. Moreover, the analog VLSI implementation of SNNs\nexhibits non-idealities, such as the effects of noise and device mismatches, as\nwell as other constraints arising from the analog circuit operation. In this\nstudy, we investigated the effects of the time discretization and/or weight\nquantization on the performance of SNNs. Furthermore, we elucidated the effects\nthe lower bound of the membrane potentials and the temporal fluctuation of the\nfiring threshold. Finally, we propose an optimal approach for the mapping of\nmathematical SNN models to analog circuits with discretized time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 22:51:58 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 01:27:25 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Sakemi", "Yusuke", ""], ["Morie", "Takashi", ""], ["Hosomi", "Takeo", ""], ["Aihara", "Kazuyuki", ""]]}, {"id": "2106.10575", "submitter": "Ondrej Bohdal", "authors": "Ondrej Bohdal, Yongxin Yang, Timothy Hospedales", "title": "EvoGrad: Efficient Gradient-Based Meta-Learning and Hyperparameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based meta-learning and hyperparameter optimization have seen\nsignificant progress recently, enabling practical end-to-end training of neural\nnetworks together with many hyperparameters. Nevertheless, existing approaches\nare relatively expensive as they need to compute second-order derivatives and\nstore a longer computational graph. This cost prevents scaling them to larger\nnetwork architectures. We present EvoGrad, a new approach to meta-learning that\ndraws upon evolutionary techniques to more efficiently compute hypergradients.\nEvoGrad estimates hypergradient with respect to hyperparameters without\ncalculating second-order gradients, or storing a longer computational graph,\nleading to significant improvements in efficiency. We evaluate EvoGrad on two\nsubstantial recent meta-learning applications, namely cross-domain few-shot\nlearning with feature-wise transformations and noisy label learning with\nMetaWeightNet. The results show that EvoGrad significantly improves efficiency\nand enables scaling meta-learning to bigger CNN architectures such as from\nResNet18 to ResNet34.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jun 2021 21:51:39 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Bohdal", "Ondrej", ""], ["Yang", "Yongxin", ""], ["Hospedales", "Timothy", ""]]}, {"id": "2106.10944", "submitter": "Bartosz W\\'ojcik", "authors": "Bartosz W\\'ojcik, Mateusz \\.Zarski, Kamil Ksi\\k{a}\\.zek, Jaros{\\l}aw\n  Adam Miszczak, Miros{\\l}aw Jan Skibniewski", "title": "Hard hat wearing detection based on head keypoint localization", "comments": "15 pages, 9 figures and 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, a lot of attention is paid to deep learning methods in the\ncontext of vision-based construction site safety systems, especially regarding\npersonal protective equipment. However, despite all this attention, there is\nstill no reliable way to establish the relationship between workers and their\nhard hats. To answer this problem a combination of deep learning, object\ndetection and head keypoint localization, with simple rule-based reasoning is\nproposed in this article. In tests, this solution surpassed the previous\nmethods based on the relative bounding box position of different instances, as\nwell as direct detection of hard hat wearers and non-wearers. The results show\nthat the conjunction of novel deep learning methods with humanly-interpretable\nrule-based systems can result in a solution that is both reliable and can\nsuccessfully mimic manual, on-site supervision. This work is the next step in\nthe development of fully autonomous construction site safety systems and shows\nthat there is still room for improvement in this area.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 09:31:33 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["W\u00f3jcik", "Bartosz", ""], ["\u017barski", "Mateusz", ""], ["Ksi\u0105\u017cek", "Kamil", ""], ["Miszczak", "Jaros\u0142aw Adam", ""], ["Skibniewski", "Miros\u0142aw Jan", ""]]}, {"id": "2106.11135", "submitter": "Appalabathula Venkatesh", "authors": "Appalabathula Venkatesh, Pradeepa H, Chidanandappa R, Shankar\n  Nalinakshan, Jayasankar V N", "title": "Brushless Motor Performance Optimization by Eagle Strategy with Firefly\n  and PSO", "comments": "International Journal of Engineering Trends and Technology (IJETT)\n  Journal Volume-68 Issue-9,Year of Publication 2020 8Pages,5 Figures", "journal-ref": null, "doi": "10.14445/22315381/IJETT-V68I9P220", "report-no": null, "categories": "eess.SY cs.NE cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brushless motors has special place though different motors are available\nbecause of its special features like absence in commutation, reduced noise and\nlonger lifetime etc., The experimental parameter tracking of BLDC Motor can be\nachieved by developing a Reference system and their stability is guaranteed by\nadopting Lyapunov Stability theorems. But the stability is guaranteed only if\nthe adaptive system is incorporated with the powerful and efficient\noptimization techniques. In this paper the powerful eagle strategy with\nParticle Swarm optimization and Firefly algorithms are applied to evaluate the\nperformance of brushless motor Where, Eagle Strategy(ES) with the use of Levys\nwalk distribution function performs diversified global search and the Particle\nSwarm Optimization (PSO) and Firefly Algorithm(FFA) performs the efficient\nintensive local search. The combined operation makes the overall optimization\ntechnique as much convenient The simulation results are obtained by using\nMATLAB Simulink software\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 05:47:47 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Venkatesh", "Appalabathula", ""], ["H", "Pradeepa", ""], ["R", "Chidanandappa", ""], ["Nalinakshan", "Shankar", ""], ["N", "Jayasankar V", ""]]}, {"id": "2106.11151", "submitter": "Awni Hannun", "authors": "Awni Hannun", "title": "The Role of Evolution in Machine Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine intelligence can develop either directly from experience or by\ninheriting experience through evolution. The bulk of current research efforts\nfocus on algorithms which learn directly from experience. I argue that the\nalternative, evolution, is important to the development of machine intelligence\nand underinvested in terms of research allocation. The primary aim of this work\nis to assess where along the spectrum of evolutionary algorithms to invest in\nresearch. My first-order suggestion is to diversify research across a broader\nspectrum of evolutionary approaches. I also define meta-evolutionary algorithms\nand argue that they may yield an optimal trade-off between the many factors\ninfluencing the development of machine intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 14:46:18 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Hannun", "Awni", ""]]}, {"id": "2106.11463", "submitter": "Gang Wang", "authors": "Gang Wang", "title": "A Logical Neural Network Structure With More Direct Mapping From Logical\n  Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical relations widely exist in human activities. Human use them for making\njudgement and decision according to various conditions, which are embodied in\nthe form of \\emph{if-then} rules. As an important kind of cognitive\nintelligence, it is prerequisite of representing and storing logical relations\nrightly into computer systems so as to make automatic judgement and decision,\nespecially for high-risk domains like medical diagnosis. However, current\nnumeric ANN (Artificial Neural Network) models are good at perceptual\nintelligence such as image recognition while they are not good at cognitive\nintelligence such as logical representation, blocking the further application\nof ANN. To solve it, researchers have tried to design logical ANN models to\nrepresent and store logical relations. Although there are some advances in this\nresearch area, recent works still have disadvantages because the structures of\nthese logical ANN models still don't map more directly with logical relations\nwhich will cause the corresponding logical relations cannot be read out from\ntheir network structures. Therefore, in order to represent logical relations\nmore clearly by the neural network structure and to read out logical relations\nfrom it, this paper proposes a novel logical ANN model by designing the new\nlogical neurons and links in demand of logical representation. Compared with\nthe recent works on logical ANN models, this logical ANN model has more clear\ncorresponding with logical relations using the more direct mapping method\nherein, thus logical relations can be read out following the connection\npatterns of the network structure. Additionally, less neurons are used.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 00:53:08 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wang", "Gang", ""]]}, {"id": "2106.11578", "submitter": "Yu Du", "authors": "Yu Du", "title": "Online Ordering Platform City Distribution Based on Genetic Algorithm", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Since the rising of the takeaway ordering platform, the M platform has taken\nthe lead in the industry with its high-quality service. The increasing order\nvolume leads the competition between platforms to reduce the distribution cost,\nwhich increases rapidly because of the unreasonable distribution route. By\nanalyzing platform distribution's current situation, we study the vehicle\nrouting problem of urban distribution on the M platform and minimize the\ndistribution cost. Considering the constraints of the customer's expected\ndelivery time and vehicle condition, we combine the different arrival times of\nthe vehicle routing problem model using three soft time windows and solve the\nproblem using a genetic algorithm (GA). The results show that our model and\nalgorithm can design the vehicle path superior to the original model in terms\nof distribution cost and delivery time, thus providing decision support for the\nM platform to save distribution cost in urban distribution in the future.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 07:24:46 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Du", "Yu", ""]]}, {"id": "2106.11804", "submitter": "Antonio Mora Dr.", "authors": "A.M. Mora and A.I. Esparcia-Alc\\'azar", "title": "Evo* 2021 -- Late-Breaking Abstracts Volume", "comments": "LBAs accepted in Evo* 2021. Part of the Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Volume with the Late-Breaking Abstracts submitted to the Evo* 2021\nConference, held online from 7 to 9 of April 2021. These papers present ongoing\nresearch and preliminary results investigating on the application of different\napproaches of Bioinspired Methods (mainly Evolutionary Computation) to\ndifferent problems, most of them real world ones.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jun 2021 22:21:46 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Mora", "A. M.", ""], ["Esparcia-Alc\u00e1zar", "A. I.", ""]]}, {"id": "2106.11872", "submitter": "Donglin Zhuang", "authors": "Donglin Zhuang, Xingyao Zhang, Shuaiwen Leon Song, Sara Hooker", "title": "Randomness In Neural Network Training: Characterizing The Impact of\n  Tooling", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The quest for determinism in machine learning has disproportionately focused\non characterizing the impact of noise introduced by algorithmic design choices.\nIn this work, we address a less well understood and studied question: how does\nour choice of tooling introduce randomness to deep neural network training. We\nconduct large scale experiments across different types of hardware,\naccelerators, state of art networks, and open-source datasets, to characterize\nhow tooling choices contribute to the level of non-determinism in a system, the\nimpact of said non-determinism, and the cost of eliminating different sources\nof noise.\n  Our findings are surprising, and suggest that the impact of non-determinism\nin nuanced. While top-line metrics such as top-1 accuracy are not noticeably\nimpacted, model performance on certain parts of the data distribution is far\nmore sensitive to the introduction of randomness. Our results suggest that\ndeterministic tooling is critical for AI safety. However, we also find that the\ncost of ensuring determinism varies dramatically between neural network\narchitectures and hardware types, e.g., with overhead up to $746\\%$, $241\\%$,\nand $196\\%$ on a spectrum of widely used GPU accelerator architectures,\nrelative to non-deterministic training. The source code used in this paper is\navailable at https://github.com/usyd-fsalab/NeuralNetworkRandomness.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 15:42:15 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Zhuang", "Donglin", ""], ["Zhang", "Xingyao", ""], ["Song", "Shuaiwen Leon", ""], ["Hooker", "Sara", ""]]}, {"id": "2106.11908", "submitter": "Wilkie Olin-Ammentorp", "authors": "Wilkie Olin-Ammentorp, Maxim Bazhenov", "title": "Deep Phasor Networks: Connecting Conventional and Spiking Neural\n  Networks", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we extend standard neural networks by building upon an\nassumption that neuronal activations correspond to the angle of a complex\nnumber lying on the unit circle, or 'phasor.' Each layer in such a network\nproduces new activations by taking a weighted superposition of the previous\nlayer's phases and calculating the new phase value. This generalized\narchitecture allows models to reach high accuracy and carries the singular\nadvantage that mathematically equivalent versions of the network can be\nexecuted with or without regard to a temporal variable. Importantly, the value\nof a phase angle in the temporal domain can be sparsely represented by a\nperiodically repeating series of delta functions or 'spikes'. We demonstrate\nthe atemporal training of a phasor network on standard deep learning tasks and\nshow that these networks can then be executed in either the traditional\natemporal domain or spiking temporal domain with no conversion step needed.\nThis provides a novel basis for constructing deep networkswhich operate via\ntemporal, spike-based calculations suitable for neuromorphic computing\nhardware.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jun 2021 21:37:08 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Olin-Ammentorp", "Wilkie", ""], ["Bazhenov", "Maxim", ""]]}, {"id": "2106.11914", "submitter": "Daniel Dimanov", "authors": "Daniel Dimanov, Emili Balaguer-Ballester, Colin Singleton and Shahin\n  Rostami", "title": "MONCAE: Multi-Objective Neuroevolution of Convolutional Autoencoders", "comments": "Published as a Poster paper in ICLR 2021 Neural Architecture Search\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present a novel neuroevolutionary method to identify the\narchitecture and hyperparameters of convolutional autoencoders. Remarkably, we\nused a hypervolume indicator in the context of neural architecture search for\nautoencoders, for the first time to our current knowledge. Results show that\nimages were compressed by a factor of more than 10, while still retaining\nenough information to achieve image classification for the majority of the\ntasks. Thus, this new approach can be used to speed up the AutoML pipeline for\nimage compression.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 13:24:08 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Dimanov", "Daniel", ""], ["Balaguer-Ballester", "Emili", ""], ["Singleton", "Colin", ""], ["Rostami", "Shahin", ""]]}, {"id": "2106.11916", "submitter": "Akram Alofi", "authors": "Akram Alofi, Mahmoud A. Bokhari, Robert Hendley, Rami Bahsoon", "title": "Selecting Miners within Blockchain-based Systems Using Evolutionary\n  Algorithms for Energy Optimisation", "comments": "To appear in 2021 Genetic and Evolutionary Computation Conference\n  Companion (GECCO '21 Companion), July 10--14, 2021, Lille, France", "journal-ref": null, "doi": "10.1145/3449726.3459558", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we represent the problem of selecting miners within a\nblockchain-based system as a subset selection problem. We formulate the problem\nof minimising blockchain energy consumption as an optimisation problem with two\nconflicting objectives: energy consumption and trust. The proposed model is\ncompared across different algorithms to demonstrate its performance.\n", "versions": [{"version": "v1", "created": "Sun, 6 Jun 2021 00:00:41 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Alofi", "Akram", ""], ["Bokhari", "Mahmoud A.", ""], ["Hendley", "Robert", ""], ["Bahsoon", "Rami", ""]]}, {"id": "2106.11919", "submitter": "Francisco Baeta", "authors": "Francisco Baeta, Jo\\~ao Correia, Tiago Martins, Penousal Machado", "title": "Speed Benchmarking of Genetic Programming Frameworks", "comments": null, "journal-ref": null, "doi": "10.1145/3449639.3459335", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic Programming (GP) is known to suffer from the burden of being\ncomputationally expensive by design. While, over the years, many techniques\nhave been developed to mitigate this issue, data vectorization, in particular,\nis arguably still the most attractive strategy due to the parallel nature of\nGP. In this work, we employ a series of benchmarks meant to compare both the\nperformance and evolution capabilities of different vectorized and iterative\nimplementation approaches across several existing frameworks. Namely, TensorGP,\na novel open-source engine written in Python, is shown to greatly benefit from\nthe TensorFlow library to accelerate the domain evaluation phase in GP. The\npresented performance benchmarks demonstrate that the TensorGP engine manages\nto pull ahead, with relative speedups above two orders of magnitude for\nproblems with a higher number of fitness cases. Additionally, as a consequence\nof being able to compute larger domains, we argue that TensorGP performance\ngains aid the discovery of more accurate candidate solutions.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 22:06:42 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Baeta", "Francisco", ""], ["Correia", "Jo\u00e3o", ""], ["Martins", "Tiago", ""], ["Machado", "Penousal", ""]]}, {"id": "2106.11927", "submitter": "Dongxiao Zhang", "authors": "Yuntian Chen, Yingtao Luo, Qiang Liu, Hao Xu, and Dongxiao Zhang", "title": "Any equation is a forest: Symbolic genetic algorithm for discovering\n  open-form partial differential equations (SGA-PDE)", "comments": "24 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations (PDEs) are concise and understandable\nrepresentations of domain knowledge, which are essential for deepening our\nunderstanding of physical processes and predicting future responses. However,\nthe PDEs of many real-world problems are uncertain, which calls for PDE\ndiscovery. We propose the symbolic genetic algorithm (SGA-PDE) to discover\nopen-form PDEs directly from data without prior knowledge about the equation\nstructure. SGA-PDE focuses on the representation and optimization of PDE.\nFirstly, SGA-PDE uses symbolic mathematics to realize the flexible\nrepresentation of any given PDE, transforms a PDE into a forest, and converts\neach function term into a binary tree. Secondly, SGA-PDE adopts a specially\ndesigned genetic algorithm to efficiently optimize the binary trees by\niteratively updating the tree topology and node attributes. The SGA-PDE is\ngradient-free, which is a desirable characteristic in PDE discovery since it is\ndifficult to obtain the gradient between the PDE loss and the PDE structure. In\nthe experiment, SGA-PDE not only successfully discovered nonlinear Burgers'\nequation, Korteweg-de Vries (KdV) equation, and Chafee-Infante equation, but\nalso handled PDEs with fractional structure and compound functions that cannot\nbe solved by conventional PDE discovery methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jun 2021 06:46:13 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chen", "Yuntian", ""], ["Luo", "Yingtao", ""], ["Liu", "Qiang", ""], ["Xu", "Hao", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2106.12042", "submitter": "Mert Saritac", "authors": "Akbal Rain, Mert Emre Saritac", "title": "HydroPower Plant Planning for Resilience Improvement of Power Systems\n  using Fuzzy-Neural based Genetic Algorithm", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will propose a novel technique for optimize hydropower plant in\nsmall scale based on load frequency control (LFC) which use self-tuning fuzzy\nProportional- Derivative (PD) method for estimation and prediction of planning.\nDue to frequency is not controlled by any dump load or something else, so this\npower plant is under dynamic frequency variations that will use PD controller\nwhich optimize by fuzzy rules and then with neural deep learning techniques and\nGenetic Algorithm optimization. The main purpose of this work is because to\nmaintain frequency in small-hydropower plant at nominal value. So, proposed\ncontroller means Fuzzy PD optimization with Genetic Algorithm will be used for\nLFC in small scale of hydropower system. The proposed schema can be used in\ndifferent designation of both diesel generator and mini-hydropower system at\nlow stream flow. It is also possible to use diesel generator at the hydropower\nsystem which can be turn off when Consumer demand is higher than electricity\ngeneration. The simulation will be done in MATLAB/Simulink to represent and\nevaluate the performance of this control schema under dynamic frequency\nvariations. Spiking Neural Network (SNN) used as the main deep learning\ntechniques to optimizing this load frequency control which turns into Deep\nSpiking Neural Network (DSNN). Obtained results represented that the proposed\nschema has robust and high-performance frequency control in comparison to other\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 21:08:01 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Rain", "Akbal", ""], ["Saritac", "Mert Emre", ""]]}, {"id": "2106.12086", "submitter": "Jinjin Xu", "authors": "Jinjin Xu, Yaochu Jin, Wenli Du", "title": "A Federated Data-Driven Evolutionary Algorithm for Expensive\n  Multi/Many-objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven optimization has found many successful applications in the real\nworld and received increased attention in the field of evolutionary\noptimization. Most existing algorithms assume that the data used for\noptimization is always available on a central server for construction of\nsurrogates. This assumption, however, may fail to hold when the data must be\ncollected in a distributed way and is subject to privacy restrictions. This\npaper aims to propose a federated data-driven evolutionary\nmulti-/many-objective optimization algorithm. To this end, we leverage\nfederated learning for surrogate construction so that multiple clients\ncollaboratively train a radial-basis-function-network as the global surrogate.\nThen a new federated acquisition function is proposed for the central server to\napproximate the objective values using the global surrogate and estimate the\nuncertainty level of the approximated objective values based on the local\nmodels. The performance of the proposed algorithm is verified on a series of\nmulti/many-objective benchmark problems by comparing it with two\nstate-of-the-art surrogate-assisted multi-objective evolutionary algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 22:33:24 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Xu", "Jinjin", ""], ["Jin", "Yaochu", ""], ["Du", "Wenli", ""]]}, {"id": "2106.12307", "submitter": "Mats Richter", "authors": "Mats L. Richter, Julius Sch\\\"oning, Ulf Krumnack", "title": "Should You Go Deeper? Optimizing Convolutional Neural Network\n  Architectures without Training by Receptive Field Analysis", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Applying artificial neural networks (ANN) to specific tasks, researchers,\nprogrammers, and other specialists usually overshot the number of convolutional\nlayers in their designs. By implication, these ANNs hold too many parameters,\nwhich needed unnecessarily trained without impacting the result. The features,\na convolutional layer can process, are strictly limited by its receptive field.\nBy layer-wise analyzing the expansion of the receptive fields, we can reliably\npredict sequences of layers that will not contribute qualitatively to the\ninference in thegiven ANN architecture. Based on these analyses, we propose\ndesign strategies to resolve these inefficiencies, optimizing the\nexplainability and the computational performance of ANNs. Since neither the\nstrategies nor the analysis requires training of the actual model, these\ninsights allow for a very efficient design process of ANNs architectures which\nmight be automated in the future.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 11:04:16 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Richter", "Mats L.", ""], ["Sch\u00f6ning", "Julius", ""], ["Krumnack", "Ulf", ""]]}, {"id": "2106.12423", "submitter": "Samuli Laine", "authors": "Tero Karras, Miika Aittala, Samuli Laine, Erik H\\\"ark\\\"onen, Janne\n  Hellsten, Jaakko Lehtinen, Timo Aila", "title": "Alias-Free Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We observe that despite their hierarchical convolutional nature, the\nsynthesis process of typical generative adversarial networks depends on\nabsolute pixel coordinates in an unhealthy manner. This manifests itself as,\ne.g., detail appearing to be glued to image coordinates instead of the surfaces\nof depicted objects. We trace the root cause to careless signal processing that\ncauses aliasing in the generator network. Interpreting all signals in the\nnetwork as continuous, we derive generally applicable, small architectural\nchanges that guarantee that unwanted information cannot leak into the\nhierarchical synthesis process. The resulting networks match the FID of\nStyleGAN2 but differ dramatically in their internal representations, and they\nare fully equivariant to translation and rotation even at subpixel scales. Our\nresults pave the way for generative models better suited for video and\nanimation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:20:01 GMT"}, {"version": "v2", "created": "Thu, 15 Jul 2021 14:43:18 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Karras", "Tero", ""], ["Aittala", "Miika", ""], ["Laine", "Samuli", ""], ["H\u00e4rk\u00f6nen", "Erik", ""], ["Hellsten", "Janne", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "2106.12444", "submitter": "Arindam Basu", "authors": "Shih-Chii Liu, John Paul Strachan, Arindam Basu", "title": "Prospects for Analog Circuits in Deep Networks", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Operations typically used in machine learning al-gorithms (e.g. adds and soft\nmax) can be implemented bycompact analog circuits. Analog Application-Specific\nIntegrated Circuit (ASIC) designs that implement these algorithms using\ntechniques such as charge sharing circuits and subthreshold transistors,\nachieve very high power efficiencies. With the recent advances in deep learning\nalgorithms, focus has shifted to hardware digital accelerator designs that\nimplement the prevalent matrix-vector multiplication operations. Power in these\ndesigns is usually dominated by the memory access power of off-chip DRAM needed\nfor storing the network weights and activations. Emerging dense non-volatile\nmemory technologies can help to provide on-chip memory and analog circuits can\nbe well suited to implement the needed multiplication-vector operations coupled\nwith in-computing memory approaches. This paper presents abrief review of\nanalog designs that implement various machine learning algorithms. It then\npresents an outlook for the use ofanalog circuits in low-power deep network\naccelerators suitable for edge or tiny machine learning applications.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:49:21 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Liu", "Shih-Chii", ""], ["Strachan", "John Paul", ""], ["Basu", "Arindam", ""]]}, {"id": "2106.12499", "submitter": "Xiaofeng Liu", "authors": "Xiaofeng Liu, Fangxu Xing, Maureen Stone, Jiachen Zhuo, Reese Timothy,\n  Jerry L. Prince, Georges El Fakhri, Jonghye Woo", "title": "Generative Self-training for Cross-domain Unsupervised Tagged-to-Cine\n  MRI Synthesis", "comments": "MICCAI 2021 (early accept <13%)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-training based unsupervised domain adaptation (UDA) has shown great\npotential to address the problem of domain shift, when applying a trained deep\nlearning model in a source domain to unlabeled target domains. However, while\nthe self-training UDA has demonstrated its effectiveness on discriminative\ntasks, such as classification and segmentation, via the reliable pseudo-label\nselection based on the softmax discrete histogram, the self-training UDA for\ngenerative tasks, such as image synthesis, is not fully investigated. In this\nwork, we propose a novel generative self-training (GST) UDA framework with\ncontinuous value prediction and regression objective for cross-domain image\nsynthesis. Specifically, we propose to filter the pseudo-label with an\nuncertainty mask, and quantify the predictive confidence of generated images\nwith practical variational Bayes learning. The fast test-time adaptation is\nachieved by a round-based alternative optimization scheme. We validated our\nframework on the tagged-to-cine magnetic resonance imaging (MRI) synthesis\nproblem, where datasets in the source and target domains were acquired from\ndifferent scanners or centers. Extensive validations were carried out to verify\nour framework against popular adversarial training UDA methods. Results show\nthat our GST, with tagged MRI of test subjects in new target domains, improved\nthe synthesis quality by a large margin, compared with the adversarial training\nUDA methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:19:00 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Liu", "Xiaofeng", ""], ["Xing", "Fangxu", ""], ["Stone", "Maureen", ""], ["Zhuo", "Jiachen", ""], ["Timothy", "Reese", ""], ["Prince", "Jerry L.", ""], ["Fakhri", "Georges El", ""], ["Woo", "Jonghye", ""]]}, {"id": "2106.12549", "submitter": "Behnam Zeinali Mr", "authors": "Behnam Zeinali, Di Zhuang, J. Morris Chang", "title": "ESAI: Efficient Split Artificial Intelligence via Early Exiting Using\n  Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have been outperforming conventional machine\nlearning algorithms in many computer vision-related tasks. However, it is not\ncomputationally acceptable to implement these models on mobile and IoT devices\nand the majority of devices are harnessing the cloud computing methodology in\nwhich outstanding deep learning models are responsible for analyzing the data\non the server. This can bring the communication cost for the devices and make\nthe whole system useless in those times where the communication is not\navailable. In this paper, a new framework for deploying on IoT devices has been\nproposed which can take advantage of both the cloud and the on-device models by\nextracting the meta-information from each sample's classification result and\nevaluating the classification's performance for the necessity of sending the\nsample to the server. Experimental results show that only 40 percent of the\ntest data should be sent to the server using this technique and the overall\naccuracy of the framework is 92 percent which improves the accuracy of both\nclient and server models.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jun 2021 04:47:53 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Zeinali", "Behnam", ""], ["Zhuang", "Di", ""], ["Chang", "J. Morris", ""]]}, {"id": "2106.12659", "submitter": "Stephen Kelly", "authors": "Stephen Kelly, Tatiana Voegerl, Wolfgang Banzhaf, Cedric Gondro", "title": "Evolving Hierarchical Memory-Prediction Machines in Multi-Task\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A fundamental aspect of behaviour is the ability to encode salient features\nof experience in memory and use these memories, in combination with current\nsensory information, to predict the best action for each situation such that\nlong-term objectives are maximized. The world is highly dynamic, and\nbehavioural agents must generalize across a variety of environments and\nobjectives over time. This scenario can be modeled as a partially-observable\nmulti-task reinforcement learning problem. We use genetic programming to evolve\nhighly-generalized agents capable of operating in six unique environments from\nthe control literature, including OpenAI's entire Classic Control suite. This\nrequires the agent to support discrete and continuous actions simultaneously.\nNo task-identification sensor inputs are provided, thus agents must identify\ntasks from the dynamics of state variables alone and define control policies\nfor each task. We show that emergent hierarchical structure in the evolving\nprograms leads to multi-task agents that succeed by performing a temporal\ndecomposition and encoding of the problem environments in memory. The resulting\nagents are competitive with task-specific agents in all six environments.\nFurthermore, the hierarchical structure of programs allows for dynamic run-time\ncomplexity, which results in relatively efficient operation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 21:34:32 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Kelly", "Stephen", ""], ["Voegerl", "Tatiana", ""], ["Banzhaf", "Wolfgang", ""], ["Gondro", "Cedric", ""]]}, {"id": "2106.12891", "submitter": "Anwesh Bhattacharya", "authors": "Anwesh Bhattacharya, Marios Mattheakis, Pavlos Protopapas", "title": "Encoding Involutory Invariance in Neural Networks", "comments": "19 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In certain situations, Neural Networks (NN) are trained upon data that obey\nunderlying physical symmetries. However, it is not guaranteed that NNs will\nobey the underlying symmetry unless embedded in the network structure. In this\nwork, we explore a special kind of symmetry where functions are invariant with\nrespect to involutory linear/affine transformations up to parity $p=\\pm 1$. We\ndevelop mathematical theorems and propose NN architectures that ensure\ninvariance and universal approximation properties. Numerical experiments\nindicate that the proposed models outperform baseline networks while respecting\nthe imposed symmetry. An adaption of our technique to convolutional NN\nclassification tasks for datasets with inherent horizontal/vertical reflection\nsymmetry has also been proposed.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 16:07:15 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Bhattacharya", "Anwesh", ""], ["Mattheakis", "Marios", ""], ["Protopapas", "Pavlos", ""]]}, {"id": "2106.12901", "submitter": "Haowei Jiang", "authors": "Haowei Jiang, Feiwei Qin, Jin Cao, Yong Peng, Yanli Shao", "title": "Recurrent Neural Network from Adder's Perspective: Carry-lookahead RNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recurrent network architecture is a widely used model in sequence\nmodeling, but its serial dependency hinders the computation parallelization,\nwhich makes the operation inefficient. The same problem was encountered in\nserial adder at the early stage of digital electronics. In this paper, we\ndiscuss the similarities between recurrent neural network (RNN) and serial\nadder. Inspired by carry-lookahead adder, we introduce carry-lookahead module\nto RNN, which makes it possible for RNN to run in parallel. Then, we design the\nmethod of parallel RNN computation, and finally Carry-lookahead RNN (CL-RNN) is\nproposed. CL-RNN takes advantages in parallelism and flexible receptive field.\nThrough a comprehensive set of tests, we verify that CL-RNN can perform better\nthan existing typical RNNs in sequence modeling tasks which are specially\ndesigned for RNNs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 12:28:33 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Jiang", "Haowei", ""], ["Qin", "Feiwei", ""], ["Cao", "Jin", ""], ["Peng", "Yong", ""], ["Shao", "Yanli", ""]]}, {"id": "2106.13031", "submitter": "Roman Pogodin", "authors": "Roman Pogodin, Yash Mehta, Timothy P. Lillicrap, Peter E. Latham", "title": "Towards Biologically Plausible Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional networks are ubiquitous in deep learning. They are particularly\nuseful for images, as they reduce the number of parameters, reduce training\ntime, and increase accuracy. However, as a model of the brain they are\nseriously problematic, since they require weight sharing - something real\nneurons simply cannot do. Consequently, while neurons in the brain can be\nlocally connected (one of the features of convolutional networks), they cannot\nbe convolutional. Locally connected but non-convolutional networks, however,\nsignificantly underperform convolutional ones. This is troublesome for studies\nthat use convolutional networks to explain activity in the visual system. Here\nwe study plausible alternatives to weight sharing that aim at the same\nregularization principle, which is to make each neuron within a pool react\nsimilarly to identical inputs. The most natural way to do that is by showing\nthe network multiple translations of the same image, akin to saccades in animal\nvision. However, this approach requires many translations, and doesn't remove\nthe performance gap. We propose instead to add lateral connectivity to a\nlocally connected network, and allow learning via Hebbian plasticity. This\nrequires the network to pause occasionally for a sleep-like phase of \"weight\nsharing\". This method enables locally connected networks to achieve nearly\nconvolutional performance on ImageNet, thus supporting convolutional networks\nas a model of the visual stream.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:01:58 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Pogodin", "Roman", ""], ["Mehta", "Yash", ""], ["Lillicrap", "Timothy P.", ""], ["Latham", "Peter E.", ""]]}, {"id": "2106.13082", "submitter": "Robert Rosenbaum", "authors": "Robert Rosenbaum", "title": "On the relationship between predictive coding and backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial neural networks are often interpreted as abstract models of\nbiological neuronal networks, but they are typically trained using the\nbiologically unrealistic backpropagation algorithm and its variants. Predictive\ncoding has been offered as a potentially more biologically realistic\nalternative to backpropagation for training neural networks. In this\nmanuscript, I review and extend recent work on the mathematical relationship\nbetween predictive coding and backpropagation for training feedforward\nartificial neural networks on supervised learning tasks. I discuss some\nimplications of these results for the interpretation of predictive coding and\ndeep neural networks as models of biological learning and I describe a\nrepository of functions, Torch2PC, for performing predictive coding with\nPyTorch neural network models.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jun 2021 18:22:50 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 11:13:15 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Rosenbaum", "Robert", ""]]}, {"id": "2106.13541", "submitter": "M Ganesh Kumar", "authors": "M Ganesh Kumar, Cheston Tan, Camilo Libedinsky, Shih-Cheng Yen, Andrew\n  Yong-Yi Tan", "title": "A nonlinear hidden layer enables actor-critic agents to learn multiple\n  paired association navigation", "comments": "31 pages, 8 figures. Acknowledgements revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Navigation to multiple cued reward locations has been increasingly used to\nstudy rodent learning. Though deep reinforcement learning agents have been\nshown to be able to learn the task, they are not biologically plausible.\nBiologically plausible classic actor-critic agents have been shown to learn to\nnavigate to single reward locations, but which biologically plausible agents\nare able to learn multiple cue-reward location tasks has remained unclear. In\nthis computational study, we show versions of classic agents that learn to\nnavigate to a single reward location, and adapt to reward location\ndisplacement, but are not able to learn multiple paired association navigation.\nThe limitation is overcome by an agent in which place cell and cue information\nare first processed by a feedforward nonlinear hidden layer with synapses to\nthe actor and critic subject to temporal difference error-modulated plasticity.\nFaster learning is obtained when the feedforward layer is replaced by a\nrecurrent reservoir network.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 10:23:05 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 03:30:13 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Kumar", "M Ganesh", ""], ["Tan", "Cheston", ""], ["Libedinsky", "Camilo", ""], ["Yen", "Shih-Cheng", ""], ["Tan", "Andrew Yong-Yi", ""]]}, {"id": "2106.13585", "submitter": "Nico Potyka", "authors": "Jonathan Spieler, Nico Potyka, Steffen Staab", "title": "Learning Gradual Argumentation Frameworks using Genetic Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradual argumentation frameworks represent arguments and their relationships\nin a weighted graph. Their graphical structure and intuitive semantics makes\nthem a potentially interesting tool for interpretable machine learning. It has\nbeen noted recently that their mechanics are closely related to neural\nnetworks, which allows learning their weights from data by standard deep\nlearning frameworks. As a first proof of concept, we propose a genetic\nalgorithm to simultaneously learn the structure of argumentative classification\nmodels. To obtain a well interpretable model, the fitness function balances\nsparseness and accuracy of the classifier. We discuss our algorithm and present\nfirst experimental results on standard benchmarks from the UCI machine learning\nrepository. Our prototype learns argumentative classification models that are\ncomparable to decision trees in terms of learning performance and\ninterpretability.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 12:33:31 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Spieler", "Jonathan", ""], ["Potyka", "Nico", ""], ["Staab", "Steffen", ""]]}, {"id": "2106.13834", "submitter": "Ruiyuan Gu", "authors": "Li-Ping Liu, Ruiyuan Gu, Xiaozhe Hu", "title": "Ladder Polynomial Neural Networks", "comments": "The work has been first submitted to ICLR 2019 (submission link).\n  Unfortunately the contribution was not sufficiently appreciated by reviewers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Polynomial functions have plenty of useful analytical properties, but they\nare rarely used as learning models because their function class is considered\nto be restricted. This work shows that when trained properly polynomial\nfunctions can be strong learning models. Particularly this work constructs\npolynomial feedforward neural networks using the product activation, a new\nactivation function constructed from multiplications. The new neural network is\na polynomial function and provides accurate control of its polynomial order. It\ncan be trained by standard training techniques such as batch normalization and\ndropout. This new feedforward network covers several previous polynomial models\nas special cases. Compared with common feedforward neural networks, the\npolynomial feedforward network has closed-form calculations of a few\ninteresting quantities, which are very useful in Bayesian learning. In a series\nof regression and classification tasks in the empirical study, the proposed\nmodel outperforms previous polynomial models.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 18:16:48 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 04:57:17 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Liu", "Li-Ping", ""], ["Gu", "Ruiyuan", ""], ["Hu", "Xiaozhe", ""]]}, {"id": "2106.13898", "submitter": "Ramin Hasani", "authors": "Ramin Hasani, Mathias Lechner, Alexander Amini, Lucas Liebenwein, Max\n  Tschaikowski, Gerald Teschl, Daniela Rus", "title": "Closed-form Continuous-Depth Models", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO math.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Continuous-depth neural models, where the derivative of the model's hidden\nstate is defined by a neural network, have enabled strong sequential data\nprocessing capabilities. However, these models rely on advanced numerical\ndifferential equation (DE) solvers resulting in a significant overhead both in\nterms of computational cost and model complexity. In this paper, we present a\nnew family of models, termed Closed-form Continuous-depth (CfC) networks, that\nare simple to describe and at least one order of magnitude faster while\nexhibiting equally strong modeling abilities compared to their ODE-based\ncounterparts. The models are hereby derived from the analytical closed-form\nsolution of an expressive subset of time-continuous models, thus alleviating\nthe need for complex DE solvers all together. In our experimental evaluations,\nwe demonstrate that CfC networks outperform advanced, recurrent models over a\ndiverse set of time-series prediction tasks, including those with long-term\ndependencies and irregularly sampled data. We believe our findings open new\nopportunities to train and deploy rich, continuous neural models in\nresource-constrained settings, which demand both performance and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jun 2021 22:08:51 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Amini", "Alexander", ""], ["Liebenwein", "Lucas", ""], ["Tschaikowski", "Max", ""], ["Teschl", "Gerald", ""], ["Rus", "Daniela", ""]]}, {"id": "2106.13927", "submitter": "Peng Wang", "authors": "Peng Wang and Gang Xin and Yuwei Jiao", "title": "Quantum Dynamics Interpretation of Black-box Optimization", "comments": "The paper may provide a new quantum perspective for studying the\n  basic search behavior of the intelligence algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent decades, with the emergence of numerous novel intelligent\noptimization algorithms, many optimization researchers have begun to look for a\nbasic search mechanism for their schemes that provides a more essential\nexplanation of their studies. This paper aims to study the basic mechanism of\nan algorithm for black-box optimization with quantum theory. To achieve this\ngoal, the Schroedinger equation is employed to establish the relationship\nbetween the optimization problem and the quantum system, which makes it\npossible to study the dynamic search behaviors in the evolution process with\nquantum theory. Moreover, to explore the basic behavior of the optimization\nsystem, the optimization problem is assumed to be decomposed and approximated.\nThen, a multilevel approximation quantum dynamics model of the optimization\nalgorithm is established, which provides a mathematical and physical framework\nfor the analysis of the optimization algorithm. Correspondingly, the basic\nsearch behavior based on this model is derived, which is governed by quantum\ntheory. Comparison experiments and analysis between different bare-bones\nalgorithms confirm the existence of the quantum mechanic based basic search\nmechanism of the algorithm on black-box optimization.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 02:30:44 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wang", "Peng", ""], ["Xin", "Gang", ""], ["Jiao", "Yuwei", ""]]}, {"id": "2106.13956", "submitter": "Raghuveer Chimata Dr", "authors": "V. Gunasekaran, K.K. Kovi, S. Arja and R. Chimata", "title": "Solar Irradiation Forecasting using Genetic Algorithms", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Renewable energy forecasting is attaining greater importance due to its\nconstant increase in contribution to the electrical power grids. Solar energy\nis one of the most significant contributors to renewable energy and is\ndependent on solar irradiation. For the effective management of electrical\npower grids, forecasting models that predict solar irradiation, with high\naccuracy, are needed. In the current study, Machine Learning techniques such as\nLinear Regression, Extreme Gradient Boosting and Genetic Algorithm Optimization\nare used to forecast solar irradiation. The data used for training and\nvalidation is recorded from across three different geographical stations in the\nUnited States that are part of the SURFRAD network. A Global Horizontal Index\n(GHI) is predicted for the models built and compared. Genetic Algorithm\nOptimization is applied to XGB to further improve the accuracy of solar\nirradiation prediction.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 06:48:20 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gunasekaran", "V.", ""], ["Kovi", "K. K.", ""], ["Arja", "S.", ""], ["Chimata", "R.", ""]]}, {"id": "2106.14007", "submitter": "Ravi Vadlamani", "authors": "Yelleti Vivek, Vadlamani Ravi and Pisipati Radhakrishna", "title": "Scalable Feature Subset Selection for Big Data using Parallel Hybrid\n  Evolutionary Algorithm based Wrapper in Apache Spark", "comments": "27 pages, 11 Tables and 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a wrapper for feature subset selection (FSS) based\non parallel and distributed hybrid evolutionary algorithms viz., parallel\nbinary differential evolution and threshold accepting (PB-DETA), parallel\nbinary threshold accepting and differential evolution (PB-TADE) under the\nApache Spark environment. Here, the FSS is formulated as a combinatorial\noptimization problem. PB-TADE comprises invoking two optimization algorithms\ni.e., TA and BDE in tandem in every iteration, while in PB-DETA, BDE is invoked\nfirst before TA takes over in tandem in every iteration. In addition to these\nhybrids, parallel binary differential evolution (P-BDE), is also developed to\ninvestigate the role played by TA and for baseline comparison. For all the\nthree proposed approaches, logistic regression (LR) is used to compute the\nfitness function namely, the area under ROC curve (AUC) score. The\neffectiveness of the parallel and distributed wrappers is assessed over five\nlarge datasets of varying feature space dimension pertaining to the cyber\nsecurity and biology domains. It is noteworthy that the PB-TADE turned out to\nbe statistically significant compared to P-BDE and PB-DETA. The speed up is\nreported with respect to the sequential version of the three wrappers. Average\nAUC score obtained, most repeated feature subsets, feature subsets with least\ncardinality having best AUC score are also reported. Further, our proposed\nmethods outperformed the state-of-the-art results, wherever the results were\nreported.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 11:59:02 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 05:43:32 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Vivek", "Yelleti", ""], ["Ravi", "Vadlamani", ""], ["Radhakrishna", "Pisipati", ""]]}, {"id": "2106.14406", "submitter": "Nayan Saxena", "authors": "Robert Wu, Nayan Saxena, Rohan Jain", "title": "Poisoning the Search Space in Neural Architecture Search", "comments": "All authors contributed equally. Appears in AdvML Workshop @\n  ICML2021: A Blessing in Disguise: The Prospects and Perils of Adversarial\n  Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has proven to be a highly effective problem-solving tool for\nobject detection and image segmentation across various domains such as\nhealthcare and autonomous driving. At the heart of this performance lies neural\narchitecture design which relies heavily on domain knowledge and prior\nexperience on the researchers' behalf. More recently, this process of finding\nthe most optimal architectures, given an initial search space of possible\noperations, was automated by Neural Architecture Search (NAS). In this paper,\nwe evaluate the robustness of one such algorithm known as Efficient NAS (ENAS)\nagainst data agnostic poisoning attacks on the original search space with\ncarefully designed ineffective operations. By evaluating algorithm performance\non the CIFAR-10 dataset, we empirically demonstrate how our novel search space\npoisoning (SSP) approach and multiple-instance poisoning attacks exploit design\nflaws in the ENAS controller to result in inflated prediction error rates for\nchild networks. Our results provide insights into the challenges to surmount in\nusing NAS for more adversarially robust architecture search.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 05:45:57 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wu", "Robert", ""], ["Saxena", "Nayan", ""], ["Jain", "Rohan", ""]]}, {"id": "2106.14417", "submitter": "Dickson Owuor Dr.", "authors": "Dickson Odhiambo Owuor", "title": "Capturing the temporal constraints of gradual patterns", "comments": "155 pagesm Doctoral thesis, Montpellier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradual pattern mining allows for extraction of attribute correlations\nthrough gradual rules such as: \"the more X, the more Y\". Such correlations are\nuseful in identifying and isolating relationships among the attributes that may\nnot be obvious through quick scans on a data set. For instance, a researcher\nmay apply gradual pattern mining to determine which attributes of a data set\nexhibit unfamiliar correlations in order to isolate them for deeper exploration\nor analysis. In this work, we propose an ant colony optimization technique\nwhich uses a popular probabilistic approach that mimics the behavior biological\nants as they search for the shortest path to find food in order to solve\ncombinatorial problems. In our second contribution, we extend an existing\ngradual pattern mining technique to allow for extraction of gradual patterns\ntogether with an approximated temporal lag between the affected gradual item\nsets. Such a pattern is referred to as a fuzzy-temporal gradual pattern and it\nmay take the form: \"the more X, the more Y, almost 3 months later\". In our\nthird contribution, we propose a data crossing model that allows for\nintegration of mostly gradual pattern mining algorithm implementations into a\nCloud platform. This contribution is motivated by the proliferation of IoT\napplications in almost every area of our society and this comes with provision\nof large-scale time-series data from different sources.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 06:45:48 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Owuor", "Dickson Odhiambo", ""]]}, {"id": "2106.14487", "submitter": "Patrick Kenekayoro", "authors": "Patrick Kenekayoro", "title": "A Meta-Heuristic Search Algorithm based on Infrasonic Mating Displays in\n  Peafowls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Meta-heuristic techniques are important as they are used to find solutions to\ncomputationally intractable problems. Simplistic methods such as exhaustive\nsearch become computationally expensive and unreliable as the solution space\nfor search algorithms increase. As no method is guaranteed to perform better\nthan all others in all classes of optimization search problems, there is a need\nto constantly find new and/or adapt old search algorithms. This research\nproposes an Infrasonic Search Algorithm, inspired from the Gravitational Search\nAlgorithm and the mating behaviour in peafowls. The Infrasonic Search Algorithm\nidentified competitive solutions to 23 benchmark unimodal and multimodal test\nfunctions compared to the Genetic Algorithm, Particle Swarm Optimization\nAlgorithm and the Gravitational Search Algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 09:04:51 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Kenekayoro", "Patrick", ""]]}, {"id": "2106.14773", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Designing color symmetry in stigmergic art", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Color symmetry is an extension of symmetry imposed by isometric\ntransformations and means that the colors of geometrical objects are assigned\naccording to the symmetry properties of the objects. A color symmetry permutes\nthe coloring of the objects consistently with their symmetry group. We apply\nthis concept to bio-inspired generative art. Therefore, we interpret the\ngeometrical objects as motifs that may repeat themselves with a\nsymmetry-consistent coloring. The motifs are obtained by design principles from\nstigmergy. We discuss a design procedure and present visual results.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:47:15 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "2106.14776", "submitter": "Martin Trefzer", "authors": "Ziwei Wang, Martin A. Trefzer, Simon J. Bale, Andy M. Tyrrell", "title": "Multi-objective Evolutionary Approach for Efficient Kernel Size and\n  Shape for CNN", "comments": "13 pages paper, plus 17 papers supplementary materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While state-of-the-art development in CNN topology, such as VGGNet and\nResNet, have become increasingly accurate, these networks are computationally\nexpensive involving billions of arithmetic operations and parameters. To\nimprove the classification accuracy, state-of-the-art CNNs usually involve\nlarge and complex convolutional layers. However, for certain applications, e.g.\nInternet of Things (IoT), where such CNNs are to be implemented on\nresource-constrained platforms, the CNN architectures have to be small and\nefficient. To deal with this problem, reducing the resource consumption in\nconvolutional layers has become one of the most significant solutions. In this\nwork, a multi-objective optimisation approach is proposed to trade-off between\nthe amount of computation and network accuracy by using Multi-Objective\nEvolutionary Algorithms (MOEAs). The number of convolution kernels and the size\nof these kernels are proportional to computational resource consumption of\nCNNs. Therefore, this paper considers optimising the computational resource\nconsumption by reducing the size and number of kernels in convolutional layers.\nAdditionally, the use of unconventional kernel shapes has been investigated and\nresults show these clearly outperform the commonly used square convolution\nkernels. The main contributions of this paper are therefore a methodology to\nsignificantly reduce computational cost of CNNs, based on unconventional kernel\nshapes, and provide different trade-offs for specific use cases. The\nexperimental results further demonstrate that the proposed method achieves\nlarge improvements in resource consumption with no significant reduction in\nnetwork performance. Compared with the benchmark CNN, the best trade-off\narchitecture shows a reduction in multiplications of up to 6X and with slight\nincrease in classification accuracy on CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 14:47:29 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Wang", "Ziwei", ""], ["Trefzer", "Martin A.", ""], ["Bale", "Simon J.", ""], ["Tyrrell", "Andy M.", ""]]}, {"id": "2106.14993", "submitter": "Michael Chang", "authors": "Michael Chang, Sidhant Kaushik, Sergey Levine, Thomas L. Griffiths", "title": "Modularity in Reinforcement Learning via Algorithmic Independence in\n  Credit Assignment", "comments": "Long Presentation at the Thirty-eighth International Conference on\n  Machine Learning (ICML) 2021. 21 pages, 11 figures. v2: updated\n  acknowledgments. v3: clarified that the internal function nodes of the credit\n  assignment mechanism are not considered O(1)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many transfer problems require re-using previously optimal decisions for\nsolving new tasks, which suggests the need for learning algorithms that can\nmodify the mechanisms for choosing certain actions independently of those for\nchoosing others. However, there is currently no formalism nor theory for how to\nachieve this kind of modular credit assignment. To answer this question, we\ndefine modular credit assignment as a constraint on minimizing the algorithmic\nmutual information among feedback signals for different decisions. We introduce\nwhat we call the modularity criterion for testing whether a learning algorithm\nsatisfies this constraint by performing causal analysis on the algorithm\nitself. We generalize the recently proposed societal decision-making framework\nas a more granular formalism than the Markov decision process to prove that for\ndecision sequences that do not contain cycles, certain single-step temporal\ndifference action-value methods meet this criterion while all policy-gradient\nmethods do not. Empirical evidence suggests that such action-value methods are\nmore sample efficient than policy-gradient methods on transfer problems that\nrequire only sparse changes to a sequence of previously optimal decisions.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 21:29:13 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 21:42:55 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 17:07:10 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chang", "Michael", ""], ["Kaushik", "Sidhant", ""], ["Levine", "Sergey", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2106.15240", "submitter": "Alexandre Variengien", "authors": "Alexandre Variengien, Stefano Nichele, Tom Glover and Sidney\n  Pontes-Filho", "title": "Towards self-organized control: Using neural cellular automata to\n  robustly control a cart-pole agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural cellular automata (Neural CA) are a recent framework used to model\nbiological phenomena emerging from multicellular organisms. In these systems,\nartificial neural networks are used as update rules for cellular automata.\nNeural CA are end-to-end differentiable systems where the parameters of the\nneural network can be learned to achieve a particular task. In this work, we\nused neural CA to control a cart-pole agent. The observations of the\nenvironment are transmitted in input cells, while the values of output cells\nare used as a readout of the system. We trained the model using deep-Q\nlearning, where the states of the output cells were used as the Q-value\nestimates to be optimized. We found that the computing abilities of the\ncellular automata were maintained over several hundreds of thousands of\niterations, producing an emergent stable behavior in the environment it\ncontrols for thousands of steps. Moreover, the system demonstrated life-like\nphenomena such as a developmental phase, regeneration after damage, stability\ndespite a noisy environment, and robustness to unseen disruption such as input\ndeletion.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 10:49:42 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 08:40:56 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Variengien", "Alexandre", ""], ["Nichele", "Stefano", ""], ["Glover", "Tom", ""], ["Pontes-Filho", "Sidney", ""]]}, {"id": "2106.15295", "submitter": "Andr\\'es Camero", "authors": "Andr\\'es Camero and Jamal Toutouh and Enrique Alba", "title": "Reliable and Fast Recurrent Neural Network Architecture Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces Random Error Sampling-based Neuroevolution (RESN), a\nnovel automatic method to optimize recurrent neural network architectures. RESN\ncombines an evolutionary algorithm with a training-free evaluation approach.\nThe results show that RESN achieves state-of-the-art error performance while\nreducing by half the computational time.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 12:16:19 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Camero", "Andr\u00e9s", ""], ["Toutouh", "Jamal", ""], ["Alba", "Enrique", ""]]}, {"id": "2106.15392", "submitter": "Seyed Jalaleddin Mousavirad", "authors": "Seyed Jalaleddin Mousavirad, Diego Oliva, Salvador Hinojosa and Gerald\n  Schaefer", "title": "Differential Evolution-based Neural Network Training Incorporating a\n  Centroid-based Strategy and Dynamic Opposition-based Learning", "comments": "IEEE Congress on Evolutionary Computation 2021 (CEC2021), 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training multi-layer neural networks (MLNNs), a challenging task, involves\nfinding appropriate weights and biases. MLNN training is important since the\nperformance of MLNNs is mainly dependent on these network parameters. However,\nconventional algorithms such as gradient-based methods, while extensively used\nfor MLNN training, suffer from drawbacks such as a tendency to getting stuck in\nlocal optima. Population-based metaheuristic algorithms can be used to overcome\nthese problems. In this paper, we propose a novel MLNN training algorithm,\nCenDE-DOBL, that is based on differential evolution (DE), a centroid-based\nstrategy (Cen-S), and dynamic opposition-based learning (DOBL). The Cen-S\napproach employs the centroid of the best individuals as a member of\npopulation, while other members are updated using standard crossover and\nmutation operators. This improves exploitation since the new member is obtained\nbased on the best individuals, while the employed DOBL strategy, which uses the\nopposite of an individual, leads to enhanced exploration. Our extensive\nexperiments compare CenDE-DOBL to 26 conventional and population-based\nalgorithms and confirm it to provide excellent MLNN training performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 13:27:12 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Mousavirad", "Seyed Jalaleddin", ""], ["Oliva", "Diego", ""], ["Hinojosa", "Salvador", ""], ["Schaefer", "Gerald", ""]]}, {"id": "2106.15420", "submitter": "Vineet Kotariya", "authors": "Vineet Kotariya, Udayan Ganguly", "title": "Spiking-GAN: A Spiking Generative Adversarial Network Using\n  Time-To-First-Spike Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) have shown great potential in solving deep\nlearning problems in an energy-efficient manner. However, they are still\nlimited to simple classification tasks. In this paper, we propose Spiking-GAN,\nthe first spike-based Generative Adversarial Network (GAN). It employs a kind\nof temporal coding scheme called time-to-first-spike coding. We train it using\napproximate backpropagation in the temporal domain. We use simple\nintegrate-and-fire (IF) neurons with very high refractory period for our\nnetwork which ensures a maximum of one spike per neuron. This makes the model\nmuch sparser than a spike rate-based system. Our modified temporal loss\nfunction called 'Aggressive TTFS' improves the inference time of the network by\nover 33% and reduces the number of spikes in the network by more than 11%\ncompared to previous works. Our experiments show that on training the network\non the MNIST dataset using this approach, we can generate high quality samples.\nThereby demonstrating the potential of this framework for solving such problems\nin the spiking domain.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 13:43:07 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Kotariya", "Vineet", ""], ["Ganguly", "Udayan", ""]]}, {"id": "2106.15546", "submitter": "Naresh Balaji Ravichandran", "authors": "Naresh Balaji Ravichandran, Anders Lansner, Pawel Herman", "title": "Semi-supervised learning with Bayesian Confidence Propagation Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Learning internal representations from data using no or few labels is useful\nfor machine learning research, as it allows using massive amounts of unlabeled\ndata. In this work, we use the Bayesian Confidence Propagation Neural Network\n(BCPNN) model developed as a biologically plausible model of the cortex. Recent\nwork has demonstrated that these networks can learn useful internal\nrepresentations from data using local Bayesian-Hebbian learning rules. In this\nwork, we show how such representations can be leveraged in a semi-supervised\nsetting by introducing and comparing different classifiers. We also evaluate\nand compare such networks with other popular semi-supervised classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 16:29:17 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Ravichandran", "Naresh Balaji", ""], ["Lansner", "Anders", ""], ["Herman", "Pawel", ""]]}, {"id": "2106.15577", "submitter": "Fiorella Wever", "authors": "Fiorella Wever, T. Anderson Keller, Victor Garcia, Laura Symul", "title": "As easy as APC: Leveraging self-supervised learning in the context of\n  time series classification with varying levels of sparsity and severe class\n  imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High levels of sparsity and strong class imbalance are ubiquitous challenges\nthat are often presented simultaneously in real-world time series data. While\nmost methods tackle each problem separately, our proposed approach handles both\nin conjunction, while imposing fewer assumptions on the data. In this work, we\npropose leveraging a self-supervised learning method, specifically\nAutoregressive Predictive Coding (APC), to learn relevant hidden\nrepresentations of time series data in the context of both missing data and\nclass imbalance. We apply APC using either a GRU or GRU-D encoder on two\nreal-world datasets, and show that applying one-step-ahead prediction with APC\nimproves the classification results in all settings. In fact, by applying GRU-D\n- APC, we achieve state-of-the-art AUPRC results on the Physionet benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:11:36 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Wever", "Fiorella", ""], ["Keller", "T. Anderson", ""], ["Garcia", "Victor", ""], ["Symul", "Laura", ""]]}, {"id": "2106.15609", "submitter": "Nirmalya Thakur", "authors": "Nirmalya Thakur and Chia Y. Han", "title": "An Ambient Intelligence-Based Human Behavior Monitoring Framework for\n  Ubiquitous Environments", "comments": null, "journal-ref": "Journal of Information, Volume 12, Issue 2, 2021, Article 81", "doi": "10.3390/info12020081", "report-no": null, "categories": "cs.HC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This framework for human behavior monitoring aims to take a holistic approach\nto study, track, monitor, and analyze human behavior during activities of daily\nliving (ADLs). The framework consists of two novel functionalities. First, it\ncan perform the semantic analysis of user interactions on the diverse\ncontextual parameters during ADLs to identify a list of distinct behavioral\npatterns associated with different complex activities. Second, it consists of\nan intelligent decision-making algorithm that can analyze these behavioral\npatterns and their relationships with the dynamic contextual and spatial\nfeatures of the environment to detect any anomalies in user behavior that could\nconstitute an emergency. These functionalities of this interdisciplinary\nframework were developed by integrating the latest advancements and\ntechnologies in human-computer interaction, machine learning, Internet of\nThings, pattern recognition, and ubiquitous computing. The framework was\nevaluated on a dataset of ADLs, and the performance accuracies of these two\nfunctionalities were found to be 76.71% and 83.87%, respectively. The presented\nand discussed results uphold the relevance and immense potential of this\nframework to contribute towards improving the quality of life and assisted\nliving of the aging population in the future of Internet of Things (IoT)-based\nubiquitous living environments, e.g., smart homes.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 17:50:54 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Thakur", "Nirmalya", ""], ["Han", "Chia Y.", ""]]}, {"id": "2106.15691", "submitter": "Annie Wong", "authors": "Annie Wong, Thomas B\\\"ack, Anna V. Kononova, Aske Plaat", "title": "Multiagent Deep Reinforcement Learning: Challenges and Directions\n  Towards Human-Like Approaches", "comments": "37 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper surveys the field of multiagent deep reinforcement learning. The\ncombination of deep neural networks with reinforcement learning has gained\nincreased traction in recent years and is slowly shifting the focus from\nsingle-agent to multiagent environments. Dealing with multiple agents is\ninherently more complex as (a) the future rewards depend on the joint actions\nof multiple players and (b) the computational complexity of functions\nincreases. We present the most common multiagent problem representations and\ntheir main challenges, and identify five research areas that address one or\nmore of these challenges: centralised training and decentralised execution,\nopponent modelling, communication, efficient coordination, and reward shaping.\nWe find that many computational studies rely on unrealistic assumptions or are\nnot generalisable to other settings; they struggle to overcome the curse of\ndimensionality or nonstationarity. Approaches from psychology and sociology\ncapture promising relevant behaviours such as communication and coordination.\nWe suggest that, for multiagent reinforcement learning to be successful, future\nresearch addresses these challenges with an interdisciplinary approach to open\nup new possibilities for more human-oriented solutions in multiagent\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 19:53:15 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Wong", "Annie", ""], ["B\u00e4ck", "Thomas", ""], ["Kononova", "Anna V.", ""], ["Plaat", "Aske", ""]]}, {"id": "2106.16215", "submitter": "Jayesh Choudhary", "authors": "Jayesh Choudhary, Vivek Saraswat, Udayan Ganguly", "title": "Algorithm For 3D-Chemotaxis Using Spiking Neural Network", "comments": "12 pages, 8 figures, accepted for the '30th International Conference\n  on Artificial Neural Networks, ICANN2021'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we aim to devise an end-to-end spiking implementation for\ncontour tracking in 3D media inspired by chemotaxis, where the worm reaches the\nregion which has the given set concentration. For a planer medium, efficient\ncontour tracking algorithms have already been devised, but a new degree of\nfreedom has quite a few challenges. Here we devise an algorithm based on\nklinokinesis - where the motion of the worm is in response to the stimuli but\nnot proportional to it. Thus the path followed is not the shortest, but we can\ntrack the set concentration successfully. We are using simple LIF neurons for\nthe neural network implementation, considering the feasibility of its\nimplementation in the neuromorphic computing hardware.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:11:00 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Choudhary", "Jayesh", ""], ["Saraswat", "Vivek", ""], ["Ganguly", "Udayan", ""]]}, {"id": "2106.16225", "submitter": "Sidak Pal Singh", "authors": "Sidak Pal Singh, Gregor Bachmann, Thomas Hofmann", "title": "Analytic Insights into Structure and Rank of Neural Network Hessian Maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Hessian of a neural network captures parameter interactions through\nsecond-order derivatives of the loss. It is a fundamental object of study,\nclosely tied to various problems in deep learning, including model design,\noptimization, and generalization. Most prior work has been empirical, typically\nfocusing on low-rank approximations and heuristics that are blind to the\nnetwork structure. In contrast, we develop theoretical tools to analyze the\nrange of the Hessian map, providing us with a precise understanding of its rank\ndeficiency as well as the structural reasons behind it. This yields exact\nformulas and tight upper bounds for the Hessian rank of deep linear networks,\nallowing for an elegant interpretation in terms of rank deficiency. Moreover,\nwe demonstrate that our bounds remain faithful as an estimate of the numerical\nHessian rank, for a larger class of models such as rectified and hyperbolic\ntangent networks. Further, we also investigate the implications of model\narchitecture (e.g.~width, depth, bias) on the rank deficiency. Overall, our\nwork provides novel insights into the source and extent of redundancy in\noverparameterized networks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 17:29:58 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 17:57:50 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Singh", "Sidak Pal", ""], ["Bachmann", "Gregor", ""], ["Hofmann", "Thomas", ""]]}]