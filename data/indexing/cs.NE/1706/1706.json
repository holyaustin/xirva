[{"id": "1706.00074", "submitter": "Daniel Crawford", "authors": "Anna Levit, Daniel Crawford, Navid Ghadermarzy, Jaspreet S. Oberoi,\n  Ehsan Zahedinejad, Pooya Ronagh", "title": "Free energy-based reinforcement learning using a quantum processor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.OC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent theoretical and experimental results suggest the possibility of using\ncurrent and near-future quantum hardware in challenging sampling tasks. In this\npaper, we introduce free energy-based reinforcement learning (FERL) as an\napplication of quantum hardware. We propose a method for processing a quantum\nannealer's measured qubit spin configurations in approximating the free energy\nof a quantum Boltzmann machine (QBM). We then apply this method to perform\nreinforcement learning on the grid-world problem using the D-Wave 2000Q quantum\nannealer. The experimental results show that our technique is a promising\nmethod for harnessing the power of quantum sampling in reinforcement learning\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 18:57:42 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Levit", "Anna", ""], ["Crawford", "Daniel", ""], ["Ghadermarzy", "Navid", ""], ["Oberoi", "Jaspreet S.", ""], ["Zahedinejad", "Ehsan", ""], ["Ronagh", "Pooya", ""]]}, {"id": "1706.00280", "submitter": "Denis Kleyko", "authors": "Denis Kleyko, E. Paxon Frady, Mansour Kheffache, Evgeny Osipov", "title": "Integer Echo State Networks: Efficient Reservoir Computing for Digital\n  Hardware", "comments": "13 pages, 11 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approximation of Echo State Networks (ESN) that can be\nefficiently implemented on digital hardware based on the mathematics of\nhyperdimensional computing. The reservoir of the proposed integer Echo State\nNetwork (intESN) is a vector containing only n-bits integers (where n<8 is\nnormally sufficient for a satisfactory performance). The recurrent matrix\nmultiplication is replaced with an efficient cyclic shift operation. The\nproposed intESN approach is verified with typical tasks in reservoir computing:\nmemorizing of a sequence of inputs; classifying time-series; learning dynamic\nprocesses. Such architecture results in dramatic improvements in memory\nfootprint and computational efficiency, with minimal performance loss. The\nexperiments on a field-programmable gate array confirm that the proposed intESN\napproach is much more energy efficient than the conventional ESN.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 12:57:11 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 08:31:56 GMT"}, {"version": "v3", "created": "Fri, 9 Oct 2020 05:20:19 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Kleyko", "Denis", ""], ["Frady", "E. Paxon", ""], ["Kheffache", "Mansour", ""], ["Osipov", "Evgeny", ""]]}, {"id": "1706.00290", "submitter": "Julius Kunze", "authors": "Julius Kunze, Louis Kirsch, Ilia Kurenkov, Andreas Krug, Jens\n  Johannsmeier and Sebastian Stober", "title": "Transfer Learning for Speech Recognition on a Budget", "comments": "Accepted for 2nd ACL Workshop on Representation Learning for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end training of automated speech recognition (ASR) systems requires\nmassive data and compute resources. We explore transfer learning based on model\nadaptation as an approach for training ASR models under constrained GPU memory,\nthroughput and training data. We conduct several systematic experiments\nadapting a Wav2Letter convolutional neural network originally trained for\nEnglish ASR to the German language. We show that this technique allows faster\ntraining on consumer-grade resources while requiring less training data in\norder to achieve the same accuracy, thereby lowering the cost of training ASR\nmodels in other languages. Model introspection revealed that small adaptations\nto the network's weights were sufficient for good performance, especially for\ninner layers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 13:33:54 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Kunze", "Julius", ""], ["Kirsch", "Louis", ""], ["Kurenkov", "Ilia", ""], ["Krug", "Andreas", ""], ["Johannsmeier", "Jens", ""], ["Stober", "Sebastian", ""]]}, {"id": "1706.00382", "submitter": "Cengiz Pehlevan", "authors": "Cengiz Pehlevan, Sreyas Mohan, Dmitri B. Chklovskii", "title": "Blind nonnegative source separation using biological neural networks", "comments": "Accepted for publication in Neural Computation", "journal-ref": null, "doi": "10.1162/neco_a_01007", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blind source separation, i.e. extraction of independent sources from a\nmixture, is an important problem for both artificial and natural signal\nprocessing. Here, we address a special case of this problem when sources (but\nnot the mixing matrix) are known to be nonnegative, for example, due to the\nphysical nature of the sources. We search for the solution to this problem that\ncan be implemented using biologically plausible neural networks. Specifically,\nwe consider the online setting where the dataset is streamed to a neural\nnetwork. The novelty of our approach is that we formulate blind nonnegative\nsource separation as a similarity matching problem and derive neural networks\nfrom the similarity matching objective. Importantly, synaptic weights in our\nnetworks are updated according to biologically plausible local learning rules.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 16:50:09 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Pehlevan", "Cengiz", ""], ["Mohan", "Sreyas", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1706.00504", "submitter": "Patrick Judd", "authors": "Alberto Delmas, Patrick Judd, Sayeh Sharify, Andreas Moshovos", "title": "Dynamic Stripes: Exploiting the Dynamic Precision Requirements of\n  Activation Values in Neural Networks", "comments": "3 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stripes is a Deep Neural Network (DNN) accelerator that uses bit-serial\ncomputation to offer performance that is proportional to the fixed-point\nprecision of the activation values. The fixed-point precisions are determined a\npriori using profiling and are selected at a per layer granularity. This paper\npresents Dynamic Stripes, an extension to Stripes that detects precision\nvariance at runtime and at a finer granularity. This extra level of precision\nreduction increases performance by 41% over Stripes.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 21:57:32 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Delmas", "Alberto", ""], ["Judd", "Patrick", ""], ["Sharify", "Sayeh", ""], ["Moshovos", "Andreas", ""]]}, {"id": "1706.00517", "submitter": "Ardavan Pedram", "authors": "Yuanfang Li and Ardavan Pedram", "title": "CATERPILLAR: Coarse Grain Reconfigurable Architecture for Accelerating\n  the Training of Deep Neural Networks", "comments": "ASAP 2017: The 28th Annual IEEE International Conference on\n  Application-specific Systems, Architectures and Processors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating the inference of a trained DNN is a well studied subject. In\nthis paper we switch the focus to the training of DNNs. The training phase is\ncompute intensive, demands complicated data communication, and contains\nmultiple levels of data dependencies and parallelism. This paper presents an\nalgorithm/architecture space exploration of efficient accelerators to achieve\nbetter network convergence rates and higher energy efficiency for training\nDNNs. We further demonstrate that an architecture with hierarchical support for\ncollective communication semantics provides flexibility in training various\nnetworks performing both stochastic and batched gradient descent based\ntechniques. Our results suggest that smaller networks favor non-batched\ntechniques while performance for larger networks is higher using batched\noperations. At 45nm technology, CATERPILLAR achieves performance efficiencies\nof 177 GFLOPS/W at over 80% utilization for SGD training on small networks and\n211 GFLOPS/W at over 90% utilization for pipelined SGD/CP training on larger\nnetworks using a total area of 103.2 mm$^2$ and 178.9 mm$^2$ respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 22:58:37 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 15:30:54 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Li", "Yuanfang", ""], ["Pedram", "Ardavan", ""]]}, {"id": "1706.00648", "submitter": "Michael Bukatin", "authors": "Michael Bukatin, Jon Anthony", "title": "Dataflow Matrix Machines as a Model of Computations with Linear Streams", "comments": "6 pages, accepted for presentation at LearnAut 2017: Learning and\n  Automata workshop at LICS (Logic in Computer Science) 2017 conference.\n  Preprint original version: April 9, 2017; minor correction: May 1, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We overview dataflow matrix machines as a Turing complete generalization of\nrecurrent neural networks and as a programming platform. We describe vector\nspace of finite prefix trees with numerical leaves which allows us to combine\nexpressive power of dataflow matrix machines with simplicity of traditional\nrecurrent neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 13:46:05 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Bukatin", "Michael", ""], ["Anthony", "Jon", ""]]}, {"id": "1706.00878", "submitter": "Qingqing Cao", "authors": "Qingqing Cao, Niranjan Balasubramanian, Aruna Balasubramanian", "title": "MobiRNN: Efficient Recurrent Neural Network Execution on Mobile GPU", "comments": "Published at 1st International Workshop on Embedded and Mobile Deep\n  Learning colocated with MobiSys 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we explore optimizations to run Recurrent Neural Network (RNN)\nmodels locally on mobile devices. RNN models are widely used for Natural\nLanguage Processing, Machine Translation, and other tasks. However, existing\nmobile applications that use RNN models do so on the cloud. To address privacy\nand efficiency concerns, we show how RNN models can be run locally on mobile\ndevices. Existing work on porting deep learning models to mobile devices focus\non Convolution Neural Networks (CNNs) and cannot be applied directly to RNN\nmodels. In response, we present MobiRNN, a mobile-specific optimization\nframework that implements GPU offloading specifically for mobile GPUs.\nEvaluations using an RNN model for activity recognition shows that MobiRNN does\nsignificantly decrease the latency of running RNN models on phones.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jun 2017 00:48:12 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Cao", "Qingqing", ""], ["Balasubramanian", "Niranjan", ""], ["Balasubramanian", "Aruna", ""]]}, {"id": "1706.01215", "submitter": "Shuochao Yao", "authors": "Shuochao Yao, Yiran Zhao, Aston Zhang, Lu Su, Tarek Abdelzaher", "title": "DeepIoT: Compressing Deep Neural Network Structures for Sensing Systems\n  with a Compressor-Critic Framework", "comments": "Published in SenSys2017. Code is available on\n  https://github.com/yscacaca/DeepIoT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning motivate the use of deep neutral networks in\nsensing applications, but their excessive resource needs on constrained\nembedded devices remain an important impediment. A recently explored solution\nspace lies in compressing (approximating or simplifying) deep neural networks\nin some manner before use on the device. We propose a new compression solution,\ncalled DeepIoT, that makes two key contributions in that space. First, unlike\ncurrent solutions geared for compressing specific types of neural networks,\nDeepIoT presents a unified approach that compresses all commonly used deep\nlearning structures for sensing applications, including fully-connected,\nconvolutional, and recurrent neural networks, as well as their combinations.\nSecond, unlike solutions that either sparsify weight matrices or assume linear\nstructure within weight matrices, DeepIoT compresses neural network structures\ninto smaller dense matrices by finding the minimum number of non-redundant\nhidden elements, such as filters and dimensions required by each layer, while\nkeeping the performance of sensing applications the same. Importantly, it does\nso using an approach that obtains a global view of parameter redundancies,\nwhich is shown to produce superior compression. We conduct experiments with\nfive different sensing-related tasks on Intel Edison devices. DeepIoT\noutperforms all compared baseline algorithms with respect to execution time and\nenergy consumption by a significant margin. It reduces the size of deep neural\nnetworks by 90% to 98.9%. It is thus able to shorten execution time by 71.4% to\n94.5%, and decrease energy consumption by 72.2% to 95.7%. These improvements\nare achieved without loss of accuracy. The results underscore the potential of\nDeepIoT for advancing the exploitation of deep neural networks on\nresource-constrained embedded devices.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 06:55:44 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 14:48:44 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 23:27:25 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Yao", "Shuochao", ""], ["Zhao", "Yiran", ""], ["Zhang", "Aston", ""], ["Su", "Lu", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "1706.01307", "submitter": "Benjamin Graham", "authors": "Benjamin Graham, Laurens van der Maaten", "title": "Submanifold Sparse Convolutional Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional network are the de-facto standard for analysing spatio-temporal\ndata such as images, videos, 3D shapes, etc. Whilst some of this data is\nnaturally dense (for instance, photos), many other data sources are inherently\nsparse. Examples include pen-strokes forming on a piece of paper, or (colored)\n3D point clouds that were obtained using a LiDAR scanner or RGB-D camera.\nStandard \"dense\" implementations of convolutional networks are very inefficient\nwhen applied on such sparse data. We introduce a sparse convolutional operation\ntailored to processing sparse data that differs from prior work on sparse\nconvolutional networks in that it operates strictly on submanifolds, rather\nthan \"dilating\" the observation with every layer in the network. Our empirical\nanalysis of the resulting submanifold sparse convolutional networks shows that\nthey perform on par with state-of-the-art methods whilst requiring\nsubstantially less computation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 13:25:24 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Graham", "Benjamin", ""], ["van der Maaten", "Laurens", ""]]}, {"id": "1706.01330", "submitter": "Filip Matzner", "authors": "Filip Matzner", "title": "Neuroevolution on the Edge of Chaos", "comments": "To appear in Proceedings of the Genetic and Evolutionary Computation\n  Conference 2017 (GECCO '17)", "journal-ref": null, "doi": "10.1145/3071178.3071292", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo state networks represent a special type of recurrent neural networks.\nRecent papers stated that the echo state networks maximize their computational\nperformance on the transition between order and chaos, the so-called edge of\nchaos. This work confirms this statement in a comprehensive set of experiments.\nFurthermore, the echo state networks are compared to networks evolved via\nneuroevolution. The evolved networks outperform the echo state networks,\nhowever, the evolution consumes significant computational resources. It is\ndemonstrated that echo state networks with local connections combine the best\nof both worlds, the simplicity of random echo state networks and the\nperformance of evolved networks. Finally, it is shown that evolution tends to\nstay close to the ordered side of the edge of chaos.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 14:04:16 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Matzner", "Filip", ""]]}, {"id": "1706.01331", "submitter": "Mark Riedl", "authors": "Lara J. Martin, Prithviraj Ammanabrolu, Xinyu Wang, William Hancock,\n  Shruti Singh, Brent Harrison, Mark O. Riedl", "title": "Event Representations for Automated Story Generation with Deep Neural\n  Nets", "comments": "Submitted to AAAI'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated story generation is the problem of automatically selecting a\nsequence of events, actions, or words that can be told as a story. We seek to\ndevelop a system that can generate stories by learning everything it needs to\nknow from textual story corpora. To date, recurrent neural networks that learn\nlanguage models at character, word, or sentence levels have had little success\ngenerating coherent stories. We explore the question of event representations\nthat provide a mid-level of abstraction between words and sentences in order to\nretain the semantic information of the original data while minimizing event\nsparsity. We present a technique for preprocessing textual story data into\nevent sequences. We then present a technique for automated story generation\nwhereby we decompose the problem into the generation of successive events\n(event2event) and the generation of natural language sentences from events\n(event2sentence). We give empirical results comparing different event\nrepresentations and their effects on event successor generation and the\ntranslation of events to natural language.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 14:04:48 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 18:14:02 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 14:45:22 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Martin", "Lara J.", ""], ["Ammanabrolu", "Prithviraj", ""], ["Wang", "Xinyu", ""], ["Hancock", "William", ""], ["Singh", "Shruti", ""], ["Harrison", "Brent", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1706.01382", "submitter": "Cameron Musco", "authors": "Nancy Lynch, Cameron Musco, Merav Parter", "title": "Neuro-RAM Unit with Applications to Similarity Testing and Compression\n  in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed algorithms implemented in a simplified biologically\ninspired model for stochastic spiking neural networks. We focus on tradeoffs\nbetween computation time and network complexity, along with the role of\nrandomness in efficient neural computation.\n  It is widely accepted that neural computation is inherently stochastic. In\nrecent work, we explored how this stochasticity could be leveraged to solve the\n`winner-take-all' leader election task. Here, we focus on using randomness in\nneural algorithms for similarity testing and compression. In the most basic\nsetting, given two $n$-length patterns of firing neurons, we wish to\ndistinguish if the patterns are equal or $\\epsilon$-far from equal.\n  Randomization allows us to solve this task with a very compact network, using\n$O \\left (\\frac{\\sqrt{n}\\log n}{\\epsilon}\\right)$ auxiliary neurons, which is\nsublinear in the input size. At the heart of our solution is the design of a\n$t$-round neural random access memory, or indexing network, which we call a\nneuro-RAM. This module can be implemented with $O(n/t)$ auxiliary neurons and\nis useful in many applications beyond similarity testing.\n  Using a VC dimension-based argument, we show that the tradeoff between\nruntime and network size in our neuro-RAM is nearly optimal. Our result has\nseveral implications -- since our neuro-RAM can be implemented with\ndeterministic threshold gates, it shows that, in contrast to similarity\ntesting, randomness does not provide significant computational advantages for\nthis problem. It also establishes a separation between feedforward networks\nwhose gates spike with sigmoidal probability functions, and well-studied\ndeterministic sigmoidal networks, whose gates output real number sigmoidal\nvalues, and which can implement a neuro-RAM much more efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 15:43:40 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 17:34:32 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Lynch", "Nancy", ""], ["Musco", "Cameron", ""], ["Parter", "Merav", ""]]}, {"id": "1706.01406", "submitter": "Alessandro Aimar", "authors": "Alessandro Aimar, Hesham Mostafa, Enrico Calabrese, Antonio\n  Rios-Navarro, Ricardo Tapiador-Morales, Iulia-Alexandra Lungu, Moritz B.\n  Milde, Federico Corradi, Alejandro Linares-Barranco, Shih-Chii Liu, Tobi\n  Delbruck", "title": "NullHop: A Flexible Convolutional Neural Network Accelerator Based on\n  Sparse Representations of Feature Maps", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2018.2852335", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have become the dominant neural network\narchitecture for solving many state-of-the-art (SOA) visual processing tasks.\nEven though Graphical Processing Units (GPUs) are most often used in training\nand deploying CNNs, their power efficiency is less than 10 GOp/s/W for\nsingle-frame runtime inference. We propose a flexible and efficient CNN\naccelerator architecture called NullHop that implements SOA CNNs useful for\nlow-power and low-latency application scenarios. NullHop exploits the sparsity\nof neuron activations in CNNs to accelerate the computation and reduce memory\nrequirements. The flexible architecture allows high utilization of available\ncomputing resources across kernel sizes ranging from 1x1 to 7x7. NullHop can\nprocess up to 128 input and 128 output feature maps per layer in a single pass.\nWe implemented the proposed architecture on a Xilinx Zynq FPGA platform and\npresent results showing how our implementation reduces external memory\ntransfers and compute time in five different CNNs ranging from small ones up to\nthe widely known large VGG16 and VGG19 CNNs. Post-synthesis simulations using\nMentor Modelsim in a 28nm process with a clock frequency of 500 MHz show that\nthe VGG19 network achieves over 450 GOp/s. By exploiting sparsity, NullHop\nachieves an efficiency of 368%, maintains over 98% utilization of the MAC\nunits, and achieves a power efficiency of over 3TOp/s/W in a core area of\n6.3mm$^2$. As further proof of NullHop's usability, we interfaced its FPGA\nimplementation with a neuromorphic event camera for real time interactive\ndemonstrations.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 16:20:24 GMT"}, {"version": "v2", "created": "Tue, 6 Mar 2018 10:05:33 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Aimar", "Alessandro", ""], ["Mostafa", "Hesham", ""], ["Calabrese", "Enrico", ""], ["Rios-Navarro", "Antonio", ""], ["Tapiador-Morales", "Ricardo", ""], ["Lungu", "Iulia-Alexandra", ""], ["Milde", "Moritz B.", ""], ["Corradi", "Federico", ""], ["Linares-Barranco", "Alejandro", ""], ["Liu", "Shih-Chii", ""], ["Delbruck", "Tobi", ""]]}, {"id": "1706.01450", "submitter": "Tong Wang", "authors": "Tong Wang and Xingdi Yuan and Adam Trischler", "title": "A Joint Model for Question Answering and Question Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a generative machine comprehension model that learns jointly to\nask and answer questions based on documents. The proposed model uses a\nsequence-to-sequence framework that encodes the document and generates a\nquestion (answer) given an answer (question). Significant improvement in model\nperformance is observed empirically on the SQuAD corpus, confirming our\nhypothesis that the model benefits from jointly learning to perform both tasks.\nWe believe the joint model's novelty offers a new perspective on machine\ncomprehension beyond architectural engineering, and serves as a first step\ntowards autonomous information seeking.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 17:58:52 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Wang", "Tong", ""], ["Yuan", "Xingdi", ""], ["Trischler", "Adam", ""]]}, {"id": "1706.01831", "submitter": "Madhavun Candadai Vasu", "authors": "Madhavun Candadai Vasu, Eduardo Izquierdo", "title": "Information Bottleneck in Control Tasks with Recurrent Spiking Neural\n  Networks", "comments": "Accepted at ICANN'17 to appear in Springer Lecture Notes in Computer\n  Science", "journal-ref": "ICANN 2017. Lecture Notes in Computer Science, vol 10613.\n  Springer, Cham", "doi": "10.1007/978-3-319-68600-4_28", "report-no": null, "categories": "cs.NE cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nervous system encodes continuous information from the environment in the\nform of discrete spikes, and then decodes these to produce smooth motor\nactions. Understanding how spikes integrate, represent, and process information\nto produce behavior is one of the greatest challenges in neuroscience.\nInformation theory has the potential to help us address this challenge.\nInformational analyses of deep and feed-forward artificial neural networks\nsolving static input-output tasks, have led to the proposal of the\n\\emph{Information Bottleneck} principle, which states that deeper layers encode\nmore relevant yet minimal information about the inputs. Such an analyses on\nnetworks that are recurrent, spiking, and perform control tasks is relatively\nunexplored. Here, we present results from a Mutual Information analysis of a\nrecurrent spiking neural network that was evolved to perform the classic\npole-balancing task. Our results show that these networks deviate from the\n\\emph{Information Bottleneck} principle prescribed for feed-forward networks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 16:08:18 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Vasu", "Madhavun Candadai", ""], ["Izquierdo", "Eduardo", ""]]}, {"id": "1706.01905", "submitter": "Matthias Plappert", "authors": "Matthias Plappert, Rein Houthooft, Prafulla Dhariwal, Szymon Sidor,\n  Richard Y. Chen, Xi Chen, Tamim Asfour, Pieter Abbeel, Marcin Andrychowicz", "title": "Parameter Space Noise for Exploration", "comments": "Updated to camera-ready ICLR submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) methods generally engage in exploratory\nbehavior through noise injection in the action space. An alternative is to add\nnoise directly to the agent's parameters, which can lead to more consistent\nexploration and a richer set of behaviors. Methods such as evolutionary\nstrategies use parameter perturbations, but discard all temporal structure in\nthe process and require significantly more samples. Combining parameter noise\nwith traditional RL methods allows to combine the best of both worlds. We\ndemonstrate that both off- and on-policy methods benefit from this approach\nthrough experimental comparison of DQN, DDPG, and TRPO on high-dimensional\ndiscrete action environments as well as continuous control tasks. Our results\nshow that RL with parameter noise learns more efficiently than traditional RL\nwith action space noise and evolutionary strategies individually.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 18:09:29 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 09:05:10 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Plappert", "Matthias", ""], ["Houthooft", "Rein", ""], ["Dhariwal", "Prafulla", ""], ["Sidor", "Szymon", ""], ["Chen", "Richard Y.", ""], ["Chen", "Xi", ""], ["Asfour", "Tamim", ""], ["Abbeel", "Pieter", ""], ["Andrychowicz", "Marcin", ""]]}, {"id": "1706.02021", "submitter": "Anbang Yao", "authors": "Yiwen Guo, Anbang Yao, Hao Zhao, Yurong Chen", "title": "Network Sketching: Exploiting Binary Structure in Deep CNNs", "comments": "To appear in CVPR2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) with deep architectures have\nsubstantially advanced the state-of-the-art in computer vision tasks. However,\ndeep networks are typically resource-intensive and thus difficult to be\ndeployed on mobile devices. Recently, CNNs with binary weights have shown\ncompelling efficiency to the community, whereas the accuracy of such models is\nusually unsatisfactory in practice. In this paper, we introduce network\nsketching as a novel technique of pursuing binary-weight CNNs, targeting at\nmore faithful inference and better trade-off for practical applications. Our\nbasic idea is to exploit binary structure directly in pre-trained filter banks\nand produce binary-weight models via tensor expansion. The whole process can be\ntreated as a coarse-to-fine model approximation, akin to the pencil drawing\nsteps of outlining and shading. To further speedup the generated models, namely\nthe sketches, we also propose an associative implementation of binary tensor\nconvolutions. Experimental results demonstrate that a proper sketch of AlexNet\n(or ResNet) outperforms the existing binary-weight models by large margins on\nthe ImageNet large scale classification task, while the committed memory for\nnetwork parameters only exceeds a little.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 01:53:44 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Guo", "Yiwen", ""], ["Yao", "Anbang", ""], ["Zhao", "Hao", ""], ["Chen", "Yurong", ""]]}, {"id": "1706.02052", "submitter": "Ravi Adepu Sankar", "authors": "Adepu Ravi Sankar, Vineeth N Balasubramanian", "title": "Are Saddles Good Enough for Deep Learning?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen a growing interest in understanding deep neural\nnetworks from an optimization perspective. It is understood now that converging\nto low-cost local minima is sufficient for such models to become effective in\npractice. However, in this work, we propose a new hypothesis based on recent\ntheoretical findings and empirical studies that deep neural network models\nactually converge to saddle points with high degeneracy. Our findings from this\nwork are new, and can have a significant impact on the development of gradient\ndescent based methods for training deep networks. We validated our hypotheses\nusing an extensive experimental evaluation on standard datasets such as MNIST\nand CIFAR-10, and also showed that recent efforts that attempt to escape\nsaddles finally converge to saddles with high degeneracy, which we define as\n`good saddles'. We also verified the famous Wigner's Semicircle Law in our\nexperimental results.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 05:44:07 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Sankar", "Adepu Ravi", ""], ["Balasubramanian", "Vineeth N", ""]]}, {"id": "1706.02124", "submitter": "Marian Tietz", "authors": "Marian Tietz, Tayfun Alpay, Johannes Twiefel, Stefan Wermter", "title": "Semi-Supervised Phoneme Recognition with Recurrent Ladder Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-68600-4_1", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ladder networks are a notable new concept in the field of semi-supervised\nlearning by showing state-of-the-art results in image recognition tasks while\nbeing compatible with many existing neural architectures. We present the\nrecurrent ladder network, a novel modification of the ladder network, for\nsemi-supervised learning of recurrent neural networks which we evaluate with a\nphoneme recognition task on the TIMIT corpus. Our results show that the model\nis able to consistently outperform the baseline and achieve fully-supervised\nbaseline performance with only 75% of all labels which demonstrates that the\nmodel is capable of using unsupervised data as an effective regulariser.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 10:50:47 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 18:49:26 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Tietz", "Marian", ""], ["Alpay", "Tayfun", ""], ["Twiefel", "Johannes", ""], ["Wermter", "Stefan", ""]]}, {"id": "1706.02257", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Eric Martinson, Vijay Chintalapudi, Rui Guo", "title": "Driver Action Prediction Using Deep (Bidirectional) Recurrent Neural\n  Network", "comments": "ITSC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced driver assistance systems (ADAS) can be significantly improved with\neffective driver action prediction (DAP). Predicting driver actions early and\naccurately can help mitigate the effects of potentially unsafe driving\nbehaviors and avoid possible accidents. In this paper, we formulate driver\naction prediction as a timeseries anomaly prediction problem. While the anomaly\n(driver actions of interest) detection might be trivial in this context,\nfinding patterns that consistently precede an anomaly requires searching for or\nextracting features across multi-modal sensory inputs. We present such a driver\naction prediction system, including a real-time data acquisition, processing\nand learning framework for predicting future or impending driver action. The\nproposed system incorporates camera-based knowledge of the driving environment\nand the driver themselves, in addition to traditional vehicle dynamics. It then\nuses a deep bidirectional recurrent neural network (DBRNN) to learn the\ncorrelation between sensory inputs and impending driver behavior achieving\naccurate and high horizon action prediction. The proposed system performs\nbetter than other existing systems on driver action prediction tasks and can\naccurately predict key driver actions including acceleration, braking, lane\nchange and turning at durations of 5sec before the action is executed by the\ndriver.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 17:00:08 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Martinson", "Eric", ""], ["Chintalapudi", "Vijay", ""], ["Guo", "Rui", ""]]}, {"id": "1706.02275", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe, Yi Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, Igor Mordatch", "title": "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore deep reinforcement learning methods for multi-agent domains. We\nbegin by analyzing the difficulty of traditional algorithms in the multi-agent\ncase: Q-learning is challenged by an inherent non-stationarity of the\nenvironment, while policy gradient suffers from a variance that increases as\nthe number of agents grows. We then present an adaptation of actor-critic\nmethods that considers action policies of other agents and is able to\nsuccessfully learn policies that require complex multi-agent coordination.\nAdditionally, we introduce a training regimen utilizing an ensemble of policies\nfor each agent that leads to more robust multi-agent policies. We show the\nstrength of our approach compared to existing methods in cooperative as well as\ncompetitive scenarios, where agent populations are able to discover various\nphysical and informational coordination strategies.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 17:35:00 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 22:18:54 GMT"}, {"version": "v3", "created": "Tue, 16 Jan 2018 23:37:25 GMT"}, {"version": "v4", "created": "Sat, 14 Mar 2020 20:33:00 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Lowe", "Ryan", ""], ["Wu", "Yi", ""], ["Tamar", "Aviv", ""], ["Harb", "Jean", ""], ["Abbeel", "Pieter", ""], ["Mordatch", "Igor", ""]]}, {"id": "1706.02393", "submitter": "Denis Gudovskiy", "authors": "Denis A. Gudovskiy, Luca Rigazio", "title": "ShiftCNN: Generalized Low-Precision Architecture for Inference of\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce ShiftCNN, a generalized low-precision architecture\nfor inference of multiplierless convolutional neural networks (CNNs). ShiftCNN\nis based on a power-of-two weight representation and, as a result, performs\nonly shift and addition operations. Furthermore, ShiftCNN substantially reduces\ncomputational cost of convolutional layers by precomputing convolution terms.\nSuch an optimization can be applied to any CNN architecture with a relatively\nsmall codebook of weights and allows to decrease the number of product\noperations by at least two orders of magnitude. The proposed architecture\ntargets custom inference accelerators and can be realized on FPGAs or ASICs.\nExtensive evaluation on ImageNet shows that the state-of-the-art CNNs can be\nconverted without retraining into ShiftCNN with less than 1% drop in accuracy\nwhen the proposed quantization algorithm is employed. RTL simulations,\ntargeting modern FPGAs, show that power consumption of convolutional layers is\nreduced by a factor of 4 compared to conventional 8-bit fixed-point\narchitectures.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 22:00:25 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Gudovskiy", "Denis A.", ""], ["Rigazio", "Luca", ""]]}, {"id": "1706.02490", "submitter": "Matej Hoffmann", "authors": "Karla Stepanova and Matej Hoffmann and Zdenek Straka and Frederico B.\n  Klein and Angelo Cangelosi and Michal Vavrecka", "title": "Where is my forearm? Clustering of body parts from simultaneous tactile\n  and linguistic input using sequential mapping", "comments": "pp. 155-162", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and animals are constantly exposed to a continuous stream of sensory\ninformation from different modalities. At the same time, they form more\ncompressed representations like concepts or symbols. In species that use\nlanguage, this process is further structured by this interaction, where a\nmapping between the sensorimotor concepts and linguistic elements needs to be\nestablished. There is evidence that children might be learning language by\nsimply disambiguating potential meanings based on multiple exposures to\nutterances in different contexts (cross-situational learning). In existing\nmodels, the mapping between modalities is usually found in a single step by\ndirectly using frequencies of referent and meaning co-occurrences. In this\npaper, we present an extension of this one-step mapping and introduce a newly\nproposed sequential mapping algorithm together with a publicly available Matlab\nimplementation. For demonstration, we have chosen a less typical scenario:\ninstead of learning to associate objects with their names, we focus on body\nrepresentations. A humanoid robot is receiving tactile stimulations on its\nbody, while at the same time listening to utterances of the body part names\n(e.g., hand, forearm and torso). With the goal at arriving at the correct \"body\ncategories\", we demonstrate how a sequential mapping algorithm outperforms\none-step mapping. In addition, the effect of data set size and noise in the\nlinguistic input are studied.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 09:31:42 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Stepanova", "Karla", ""], ["Hoffmann", "Matej", ""], ["Straka", "Zdenek", ""], ["Klein", "Frederico B.", ""], ["Cangelosi", "Angelo", ""], ["Vavrecka", "Michal", ""]]}, {"id": "1706.02556", "submitter": "Daniele Gravina", "authors": "Daniele Gravina, Antonios Liapis and Georgios N. Yannakakis", "title": "Surprise Search for Evolutionary Divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the notion of surprise for unconventional discovery we introduce\na general search algorithm we name surprise search as a new method of\nevolutionary divergent search. Surprise search is grounded in the divergent\nsearch paradigm and is fabricated within the principles of evolutionary search.\nThe algorithm mimics the self-surprise cognitive process and equips\nevolutionary search with the ability to seek for solutions that deviate from\nthe algorithm's expected behaviour. The predictive model of expected solutions\nis based on historical trails of where the search has been and local\ninformation about the search space. Surprise search is tested extensively in a\nrobot maze navigation task: experiments are held in four authored deceptive\nmazes and in 60 generated mazes and compared against objective-based\nevolutionary search and novelty search. The key findings of this study reveal\nthat surprise search is advantageous compared to the other two search\nprocesses. In particular, it outperforms objective search and it is as\nefficient as novelty search in all tasks examined. Most importantly, surprise\nsearch is faster, on average, and more robust in solving the navigation problem\ncompared to any other algorithm examined. Finally, our analysis reveals that\nsurprise search explores the behavioural space more extensively and yields\nhigher population diversity compared to novelty search. What distinguishes\nsurprise search from other forms of divergent search, such as the search for\nnovelty, is its ability to diverge not from earlier and seen solutions but\nrather from predicted and unseen points in the domain considered.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 12:55:26 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Gravina", "Daniele", ""], ["Liapis", "Antonios", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "1706.02596", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Chris Dyer", "title": "Dynamic Integration of Background Knowledge in Neural NLU Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common-sense and background knowledge is required to understand natural\nlanguage, but in most neural natural language understanding (NLU) systems, this\nknowledge must be acquired from training corpora during learning, and then it\nis static at test time. We introduce a new architecture for the dynamic\nintegration of explicit background knowledge in NLU models. A general-purpose\nreading module reads background knowledge in the form of free-text statements\n(together with task-specific text inputs) and yields refined word\nrepresentations to a task-specific NLU architecture that reprocesses the task\ninputs with these representations. Experiments on document question answering\n(DQA) and recognizing textual entailment (RTE) demonstrate the effectiveness\nand flexibility of the approach. Analysis shows that our model learns to\nexploit knowledge in a semantically appropriate way.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 14:10:22 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 14:54:53 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 08:57:43 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Weissenborn", "Dirk", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Dyer", "Chris", ""]]}, {"id": "1706.02609", "submitter": "Yujie Wu", "authors": "Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, Luping Shi", "title": "Spatio-Temporal Backpropagation for Training High-performance Spiking\n  Neural Networks", "comments": null, "journal-ref": "Frontiers in neuroscience, 2018, 12", "doi": "10.3389/fnins.2018.00331", "report-no": null, "categories": "cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compared with artificial neural networks (ANNs), spiking neural networks\n(SNNs) are promising to explore the brain-like behaviors since the spikes could\nencode more spatio-temporal information. Although pre-training from ANN or\ndirect training based on backpropagation (BP) makes the supervised training of\nSNNs possible, these methods only exploit the networks' spatial domain\ninformation which leads to the performance bottleneck and requires many\ncomplicated training skills. Another fundamental issue is that the spike\nactivity is naturally non-differentiable which causes great difficulties in\ntraining SNNs. To this end, we build an iterative LIF model that is more\nfriendly for gradient descent training. By simultaneously considering the\nlayer-by-layer spatial domain (SD) and the timing-dependent temporal domain\n(TD) in the training phase, as well as an approximated derivative for the spike\nactivity, we propose a spatio-temporal backpropagation (STBP) training\nframework without using any complicated technology. We achieve the best\nperformance of multi-layered perceptron (MLP) compared with existing\nstate-of-the-art algorithms over the static MNIST and the dynamic N-MNIST\ndataset as well as a custom object detection dataset. This work provides a new\nperspective to explore the high-performance SNNs for future brain-like\ncomputing paradigm with rich spatio-temporal dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 14:33:55 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 02:40:45 GMT"}, {"version": "v3", "created": "Tue, 12 Sep 2017 10:50:05 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wu", "Yujie", ""], ["Deng", "Lei", ""], ["Li", "Guoqi", ""], ["Zhu", "Jun", ""], ["Shi", "Luping", ""]]}, {"id": "1706.02684", "submitter": "Jean-Charles Vialatte", "authors": "Jean-Charles Vialatte, Vincent Gripon, Gilles Coppin", "title": "Learning Local Receptive Fields and their Weight Sharing Scheme on\n  Graphs", "comments": "To appear in 2017, 5th IEEE Global Conference on Signal and\n  Information Processing, 5 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple and generic layer formulation that extends the properties\nof convolutional layers to any domain that can be described by a graph. Namely,\nwe use the support of its adjacency matrix to design learnable weight sharing\nfilters able to exploit the underlying structure of signals in the same fashion\nas for images. The proposed formulation makes it possible to learn the weights\nof the filter as well as a scheme that controls how they are shared across the\ngraph. We perform validation experiments with image datasets and show that\nthese filters offer performances comparable with convolutional ones.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 17:03:34 GMT"}, {"version": "v2", "created": "Wed, 20 Sep 2017 14:56:59 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 16:32:20 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Vialatte", "Jean-Charles", ""], ["Gripon", "Vincent", ""], ["Coppin", "Gilles", ""]]}, {"id": "1706.02761", "submitter": "Li Jing", "authors": "Li Jing, Caglar Gulcehre, John Peurifoy, Yichen Shen, Max Tegmark,\n  Marin Solja\\v{c}i\\'c, Yoshua Bengio", "title": "Gated Orthogonal Recurrent Units: On Learning to Forget", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel recurrent neural network (RNN) based model that combines\nthe remembering ability of unitary RNNs with the ability of gated RNNs to\neffectively forget redundant/irrelevant information in its memory. We achieve\nthis by extending unitary RNNs with a gating mechanism. Our model is able to\noutperform LSTMs, GRUs and Unitary RNNs on several long-term dependency\nbenchmark tasks. We empirically both show the orthogonal/unitary RNNs lack the\nability to forget and also the ability of GORU to simultaneously remember long\nterm dependencies while forgetting irrelevant information. This plays an\nimportant role in recurrent neural networks. We provide competitive results\nalong with an analysis of our model on many natural sequential tasks including\nthe bAbI Question Answering, TIMIT speech spectrum prediction, Penn TreeBank,\nand synthetic tasks that involve long-term dependencies such as algorithmic,\nparenthesis, denoising and copying tasks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 20:40:32 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 13:47:17 GMT"}, {"version": "v3", "created": "Wed, 25 Oct 2017 15:17:03 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Jing", "Li", ""], ["Gulcehre", "Caglar", ""], ["Peurifoy", "John", ""], ["Shen", "Yichen", ""], ["Tegmark", "Max", ""], ["Solja\u010di\u0107", "Marin", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1706.02766", "submitter": "Yuan Yuan", "authors": "Yuan Yuan, Yew-Soon Ong, Liang Feng, A.K. Qin, Abhishek Gupta,\n  Bingshui Da, Qingfu Zhang, Kay Chen Tan, Yaochu Jin, and Hisao Ishibuchi", "title": "Evolutionary Multitasking for Multiobjective Continuous Optimization:\n  Benchmark Problems, Performance Metrics and Baseline Results", "comments": "11 pages, 5 pages, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this report, we suggest nine test problems for multi-task multi-objective\noptimization (MTMOO), each of which consists of two multiobjective optimization\ntasks that need to be solved simultaneously. The relationship between tasks\nvaries between different test problems, which would be helpful to have a\ncomprehensive evaluation of the MO-MFO algorithms. It is expected that the\nproposed test problems will germinate progress the field of the MTMOO research.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 20:49:34 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Yuan", "Yuan", ""], ["Ong", "Yew-Soon", ""], ["Feng", "Liang", ""], ["Qin", "A. K.", ""], ["Gupta", "Abhishek", ""], ["Da", "Bingshui", ""], ["Zhang", "Qingfu", ""], ["Tan", "Kay Chen", ""], ["Jin", "Yaochu", ""], ["Ishibuchi", "Hisao", ""]]}, {"id": "1706.02776", "submitter": "Matt Shannon", "authors": "Matt Shannon", "title": "Optimizing expected word error rate via sampling for speech recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-level minimum Bayes risk (sMBR) training has become the de facto\nstandard for sequence-level training of speech recognition acoustic models. It\nhas an elegant formulation using the expectation semiring, and gives large\nimprovements in word error rate (WER) over models trained solely using\ncross-entropy (CE) or connectionist temporal classification (CTC). sMBR\ntraining optimizes the expected number of frames at which the reference and\nhypothesized acoustic states differ. It may be preferable to optimize the\nexpected WER, but WER does not interact well with the expectation semiring, and\nprevious approaches based on computing expected WER exactly involve expanding\nthe lattices used during training. In this paper we show how to perform\noptimization of the expected WER by sampling paths from the lattices used\nduring conventional sMBR training. The gradient of the expected WER is itself\nan expectation, and so may be approximated using Monte Carlo sampling. We show\nexperimentally that optimizing WER during acoustic model training gives 5%\nrelative improvement in WER over a well-tuned sMBR baseline on a 2-channel\nquery recognition task (Google Home).\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 21:14:48 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Shannon", "Matt", ""]]}, {"id": "1706.02850", "submitter": "Alessandro Corbetta", "authors": "Alessandro Corbetta, Vlado Menkovski, Federico Toschi", "title": "Weakly supervised training of deep convolutional neural networks for\n  overhead pedestrian localization in depth fields", "comments": null, "journal-ref": "Advanced Video and Signal Based Surveillance (AVSS), 2017 14th\n  IEEE International Conference on", "doi": "10.1109/AVSS.2017.8078490", "report-no": null, "categories": "cs.CV cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overhead depth map measurements capture sufficient amount of information to\nenable human experts to track pedestrians accurately. However, fully automating\nthis process using image analysis algorithms can be challenging. Even though\nhand-crafted image analysis algorithms are successful in many common cases,\nthey fail frequently when there are complex interactions of multiple objects in\nthe image. Many of the assumptions underpinning the hand-crafted solutions do\nnot hold in these cases and the multitude of exceptions are hard to model\nprecisely. Deep Learning (DL) algorithms, on the other hand, do not require\nhand crafted solutions and are the current state-of-the-art in object\nlocalization in images. However, they require exceeding amount of annotations\nto produce successful models. In the case of object localization these\nannotations are difficult and time consuming to produce. In this work we\npresent an approach for developing pedestrian localization models using DL\nalgorithms with efficient weak supervision from an expert. We circumvent the\nneed for annotation of large corpus of data by annotating only small amount of\npatches and relying on synthetic data augmentation as a vehicle for injecting\nexpert knowledge in the model training. This approach of weak supervision\nthrough expert selection of representative patches, suitable transformations\nand synthetic data augmentations enables us to successfully develop DL models\nfor pedestrian localization efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 07:14:08 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Corbetta", "Alessandro", ""], ["Menkovski", "Vlado", ""], ["Toschi", "Federico", ""]]}, {"id": "1706.02887", "submitter": "Tobias Glasmachers", "authors": "Tobias Glasmachers", "title": "Global Convergence of the (1+1) Evolution Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish global convergence of the (1+1) evolution strategy, i.e.,\nconvergence to a critical point independent of the initial state. More\nprecisely, we show the existence of a critical limit point, using a suitable\nextension of the notion of a critical point to measurable functions. At its\ncore, the analysis is based on a novel progress guarantee for elitist,\nrank-based evolutionary algorithms. By applying it to the (1+1) evolution\nstrategy we are able to provide an accurate characterization of whether global\nconvergence is guaranteed with full probability, or whether premature\nconvergence is possible. We illustrate our results on a number of example\napplications ranging from smooth (non-convex) cases over different types of\nsaddle points and ridge functions to discontinuous and extremely rugged\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 10:39:04 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 07:41:46 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 16:03:51 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Glasmachers", "Tobias", ""]]}, {"id": "1706.03041", "submitter": "Andreas S{\\o}gaard", "authors": "Andreas S{\\o}gaard", "title": "Learning optimal wavelet bases using a neural network approach", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method for learning optimal, orthonormal wavelet bases for\nrepresenting 1- and 2D signals, based on parallels between the wavelet\ntransform and fully connected artificial neural networks, is described. The\nstructural similarities between these two concepts are reviewed and combined to\na \"wavenet\", allowing for the direct learning of optimal wavelet filter\ncoefficient through stochastic gradient descent with back-propagation over\nensembles of training inputs, where conditions on the filter coefficients for\nconstituting orthonormal wavelet bases are cast as quadratic regularisations\nterms. We describe the practical implementation of this method, and study its\nperformance for high-energy physics collision events for QCD $2 \\to 2$\nprocesses. It is shown that an optimal solution is found, even in a\nhigh-dimensional search space, and the implications of the result are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 15:46:01 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 10:31:57 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["S\u00f8gaard", "Andreas", ""]]}, {"id": "1706.03146", "submitter": "Shuai Tang", "authors": "Shuai Tang, Hailin Jin, Chen Fang, Zhaowen Wang, Virginia R. de Sa", "title": "Rethinking Skip-thought: A Neighborhood based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the skip-thought model with neighborhood information as weak\nsupervision. More specifically, we propose a skip-thought neighbor model to\nconsider the adjacent sentences as a neighborhood. We train our skip-thought\nneighbor model on a large corpus with continuous sentences, and then evaluate\nthe trained model on 7 tasks, which include semantic relatedness, paraphrase\ndetection, and classification benchmarks. Both quantitative comparison and\nqualitative investigation are conducted. We empirically show that, our\nskip-thought neighbor model performs as well as the skip-thought model on\nevaluation tasks. In addition, we found that, incorporating an autoencoder path\nin our model didn't aid our model to perform better, while it hurts the\nperformance of the skip-thought model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 22:39:31 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Tang", "Shuai", ""], ["Jin", "Hailin", ""], ["Fang", "Chen", ""], ["Wang", "Zhaowen", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1706.03170", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei and Anthony Maida", "title": "Bio-Inspired Multi-Layer Spiking Neural Network Extracts Discriminative\n  Features from Speech Signals", "comments": null, "journal-ref": "Neural Information Processing. ICONIP 2017. Lecture Notes in\n  Computer Science, vol 10639", "doi": "10.1007/978-3-319-70136-3_95", "report-no": null, "categories": "cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) enable power-efficient implementations due to\ntheir sparse, spike-based coding scheme. This paper develops a bio-inspired SNN\nthat uses unsupervised learning to extract discriminative features from speech\nsignals, which can subsequently be used in a classifier. The architecture\nconsists of a spiking convolutional/pooling layer followed by a fully connected\nspiking layer for feature discovery. The convolutional layer of leaky,\nintegrate-and-fire (LIF) neurons represents primary acoustic features. The\nfully connected layer is equipped with a probabilistic spike-timing-dependent\nplasticity learning rule. This layer represents the discriminative features\nthrough probabilistic, LIF neurons. To assess the discriminative power of the\nlearned features, they are used in a hidden Markov model (HMM) for spoken digit\nrecognition. The experimental results show performance above 96% that compares\nfavorably with popular statistical feature extraction methods. Our results\nprovide a novel demonstration of unsupervised feature acquisition in an SNN.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 02:14:42 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Maida", "Anthony", ""]]}, {"id": "1706.03301", "submitter": "Matus Telgarsky", "authors": "Matus Telgarsky", "title": "Neural networks and rational functions", "comments": "To appear, ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks and rational functions efficiently approximate each other. In\nmore detail, it is shown here that for any ReLU network, there exists a\nrational function of degree $O(\\text{polylog}(1/\\epsilon))$ which is\n$\\epsilon$-close, and similarly for any rational function there exists a ReLU\nnetwork of size $O(\\text{polylog}(1/\\epsilon))$ which is $\\epsilon$-close. By\ncontrast, polynomials need degree $\\Omega(\\text{poly}(1/\\epsilon))$ to\napproximate even a single ReLU. When converting a ReLU network to a rational\nfunction as above, the hidden constants depend exponentially on the number of\nlayers, which is shown to be tight; in other words, a compositional\nrepresentation can be beneficial even for rational functions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 03:07:42 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Telgarsky", "Matus", ""]]}, {"id": "1706.03470", "submitter": "Bingshui Da", "authors": "Bingshui Da, Yew-Soon Ong, Liang Feng, A.K. Qin, Abhishek Gupta,\n  Zexuan Zhu, Chuan-Kang Ting, Ke Tang, and Xin Yao", "title": "Evolutionary Multitasking for Single-objective Continuous Optimization:\n  Benchmark Problems, Performance Metric, and Baseline Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we suggest nine test problems for multi-task single-objective\noptimization (MTSOO), each of which consists of two single-objective\noptimization tasks that need to be solved simultaneously. The relationship\nbetween tasks varies between different test problems, which would be helpful to\nhave a comprehensive evaluation of the MFO algorithms. It is expected that the\nproposed test problems will germinate progress the field of the MTSOO research.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 05:25:40 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Da", "Bingshui", ""], ["Ong", "Yew-Soon", ""], ["Feng", "Liang", ""], ["Qin", "A. K.", ""], ["Gupta", "Abhishek", ""], ["Zhu", "Zexuan", ""], ["Ting", "Chuan-Kang", ""], ["Tang", "Ke", ""], ["Yao", "Xin", ""]]}, {"id": "1706.03608", "submitter": "Hasan Ali Aky\\\"urek", "authors": "Hasan Ali Aky\\\"urek, \\\"Omer Kaan Baykan, Bar{\\i}\\c{s} Ko\\c{c}er", "title": "Improving Gravitational Search Algorithm Performance with Artificial Bee\n  Colony Algorithm for Constrained Numerical Optimization", "comments": "13 pages in The Journal of MacroTrends in Applied Science, Vol 4.\n  Issue 1. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose an improved gravitational search algorithm named\nGSABC. The algorithm improves gravitational search algorithm (GSA) results\nimproved by using artificial bee colony algorithm (ABC) to solve constrained\nnumerical optimization problems. In GSA, solutions are attracted towards each\nother by applying gravitational forces, which depending on the masses assigned\nto the solutions, to each other. The heaviest mass will move slower than other\nmasses and gravitate others. Due to nature of gravitation, GSA may pass global\nminimum if some solutions stuck to local minimum. ABC updates the positions of\nthe best solutions that has obtained from GSA, preventing the GSA from sticking\nto the local minimum by its strong searching ability. The proposed algorithm\nimproves the performance of GSA. The proposed method tested on 23 well-known\nunimodal, multimodal and fixed-point multimodal benchmark test functions.\nExperimental results show that GSABC outperforms or performs similarly to five\nstate-of-the-art optimization approaches.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2017 18:21:05 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Aky\u00fcrek", "Hasan Ali", ""], ["Baykan", "\u00d6mer Kaan", ""], ["Ko\u00e7er", "Bar\u0131\u015f", ""]]}, {"id": "1706.03609", "submitter": "Qian Liu", "authors": "Qian Liu, Yunhua Chen and Steve Furber", "title": "Noisy Softplus: an activation function that enables SNNs to be trained\n  as ANNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extended the work of proposed activation function, Noisy Softplus, to fit\ninto training of layered up spiking neural networks (SNNs). Thus, any ANN\nemploying Noisy Softplus neurons, even of deep architecture, can be trained\nsimply by the traditional algorithm, for example Back Propagation (BP), and the\ntrained weights can be directly used in the spiking version of the same network\nwithout any conversion. Furthermore, the training method can be generalised to\nother activation units, for instance Rectified Linear Units (ReLU), to train\ndeep SNNs off-line. This research is crucial to provide an effective approach\nfor SNN training, and to increase the classification accuracy of SNNs with\nbiological characteristics and to close the gap between the performance of SNNs\nand ANNs.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 11:49:48 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Liu", "Qian", ""], ["Chen", "Yunhua", ""], ["Furber", "Steve", ""]]}, {"id": "1706.03610", "submitter": "Georg Wiese", "authors": "Georg Wiese, Dirk Weissenborn, Mariana Neves", "title": "Neural Domain Adaptation for Biomedical Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factoid question answering (QA) has recently benefited from the development\nof deep learning (DL) systems. Neural network models outperform traditional\napproaches in domains where large datasets exist, such as SQuAD (ca. 100,000\nquestions) for Wikipedia articles. However, these systems have not yet been\napplied to QA in more specific domains, such as biomedicine, because datasets\nare generally too small to train a DL system from scratch. For example, the\nBioASQ dataset for biomedical QA comprises less then 900 factoid (single\nanswer) and list (multiple answers) QA instances. In this work, we adapt a\nneural QA system trained on a large open-domain dataset (SQuAD, source) to a\nbiomedical dataset (BioASQ, target) by employing various transfer learning\ntechniques. Our network architecture is based on a state-of-the-art QA system,\nextended with biomedical word embeddings and a novel mechanism to answer list\nquestions. In contrast to existing biomedical QA systems, our system does not\nrely on domain-specific ontologies, parsers or entity taggers, which are\nexpensive to create. Despite this fact, our systems achieve state-of-the-art\nresults on factoid questions and competitive results on list questions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 13:08:21 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 15:16:18 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Wiese", "Georg", ""], ["Weissenborn", "Dirk", ""], ["Neves", "Mariana", ""]]}, {"id": "1706.03946", "submitter": "Isabelle Augenstein", "authors": "Ed Collins and Isabelle Augenstein and Sebastian Riedel", "title": "A Supervised Approach to Extractive Summarisation of Scientific Papers", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic summarisation is a popular approach to reduce a document to its\nmain arguments. Recent research in the area has focused on neural approaches to\nsummarisation, which can be very data-hungry. However, few large datasets exist\nand none for the traditionally popular domain of scientific publications, which\nopens up challenging research avenues centered on encoding large, complex\ndocuments. In this paper, we introduce a new dataset for summarisation of\ncomputer science publications by exploiting a large resource of author provided\nsummaries and show straightforward ways of extending it further. We develop\nmodels on the dataset making use of both neural sentence encoding and\ntraditionally used summarisation features and show that models which encode\nsentences as well as their local and global context perform best, significantly\noutperforming well-established baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 08:15:25 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Collins", "Ed", ""], ["Augenstein", "Isabelle", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1706.03993", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a and Alexandros Karatzoglou", "title": "Getting deep recommenders fit: Bloom embeddings for sparse binary\n  input/output networks", "comments": "Accepted for publication at ACM RecSys 2017; previous version\n  submitted to ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation algorithms that incorporate techniques from deep learning are\nbecoming increasingly popular. Due to the structure of the data coming from\nrecommendation domains (i.e., one-hot-encoded vectors of item preferences),\nthese algorithms tend to have large input and output dimensionalities that\ndominate their overall size. This makes them difficult to train, due to the\nlimited memory of graphical processing units, and difficult to deploy on mobile\ndevices with limited hardware. To address these difficulties, we propose Bloom\nembeddings, a compression technique that can be applied to the input and output\nof neural network models dealing with sparse high-dimensional binary-coded\ninstances. Bloom embeddings are computationally efficient, and do not seriously\ncompromise the accuracy of the model up to 1/5 compression ratios. In some\ncases, they even improve over the original accuracy, with relative increases up\nto 12%. We evaluate Bloom embeddings on 7 data sets and compare it against 4\nalternative methods, obtaining favorable results. We also discuss a number of\nfurther advantages of Bloom embeddings, such as 'on-the-fly' constant-time\noperation, zero or marginal space requirements, training time speedups, or the\nfact that they do not require any change to the core model architecture or\ntraining configuration.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 10:50:25 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "1706.04008", "submitter": "Patrick Putzky", "authors": "Patrick Putzky, Max Welling", "title": "Recurrent Inference Machines for Solving Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the recent research on solving iterative inference problems focuses\non moving away from hand-chosen inference algorithms and towards learned\ninference. In the latter, the inference process is unrolled in time and\ninterpreted as a recurrent neural network (RNN) which allows for joint learning\nof model and inference parameters with back-propagation through time. In this\nframework, the RNN architecture is directly derived from a hand-chosen\ninference algorithm, effectively limiting its capabilities. We propose a\nlearning framework, called Recurrent Inference Machines (RIM), in which we turn\nalgorithm construction the other way round: Given data and a task, train an RNN\nto learn an inference algorithm. Because RNNs are Turing complete [1, 2] they\nare capable to implement any inference algorithm. The framework allows for an\nabstraction which removes the need for domain knowledge. We demonstrate in\nseveral image restoration experiments that this abstraction is effective,\nallowing us to achieve state-of-the-art performance on image denoising and\nsuper-resolution tasks and superior across-task generalization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 11:24:41 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Putzky", "Patrick", ""], ["Welling", "Max", ""]]}, {"id": "1706.04052", "submitter": "Jinzhuo Wang", "authors": "Jinzhuo Wang, Wenmin Wang, Ronggang Wang, Wen Gao", "title": "Beyond Monte Carlo Tree Search: Playing Go with Deep Alternative Neural\n  Network and Long-Term Evaluation", "comments": "AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo tree search (MCTS) is extremely popular in computer Go which\ndetermines each action by enormous simulations in a broad and deep search tree.\nHowever, human experts select most actions by pattern analysis and careful\nevaluation rather than brute search of millions of future nteractions. In this\npaper, we propose a computer Go system that follows experts way of thinking and\nplaying. Our system consists of two parts. The first part is a novel deep\nalternative neural network (DANN) used to generate candidates of next move.\nCompared with existing deep convolutional neural network (DCNN), DANN inserts\nrecurrent layer after each convolutional layer and stacks them in an\nalternative manner. We show such setting can preserve more contexts of local\nfeatures and its evolutions which are beneficial for move prediction. The\nsecond part is a long-term evaluation (LTE) module used to provide a reliable\nevaluation of candidates rather than a single probability from move predictor.\nThis is consistent with human experts nature of playing since they can foresee\ntens of steps to give an accurate estimation of candidates. In our system, for\neach candidate, LTE calculates a cumulative reward after several future\ninteractions when local variations are settled. Combining criteria from the two\nparts, our system determines the optimal choice of next move. For more\ncomprehensive experiments, we introduce a new professional Go dataset (PGD),\nconsisting of 253233 professional records. Experiments on GoGoD and PGD\ndatasets show the DANN can substantially improve performance of move prediction\nover pure DCNN. When combining LTE, our system outperforms most relevant\napproaches and open engines based on MCTS.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 13:30:04 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Wang", "Jinzhuo", ""], ["Wang", "Wenmin", ""], ["Wang", "Ronggang", ""], ["Gao", "Wen", ""]]}, {"id": "1706.04119", "submitter": "Moshe Sipper", "authors": "Moshe Sipper, Weixuan Fu, Karuna Ahuja, Jason H. Moore", "title": "Investigating the Parameter Space of Evolutionary Algorithms", "comments": null, "journal-ref": "BioData Mining, 2018, 11:2", "doi": "10.1186/s13040-018-0164-x", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practice of evolutionary algorithms involves the tuning of many\nparameters. How big should the population be? How many generations should the\nalgorithm run? What is the (tournament selection) tournament size? What\nprobabilities should one assign to crossover and mutation? Through an extensive\nseries of experiments over multiple evolutionary algorithm implementations and\nproblems we show that parameter space tends to be rife with viable parameters,\nat least for 25 the problems studied herein. We discuss the implications of\nthis finding in practice.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 15:22:38 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 12:14:32 GMT"}, {"version": "v3", "created": "Tue, 10 Oct 2017 15:35:12 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Sipper", "Moshe", ""], ["Fu", "Weixuan", ""], ["Ahuja", "Karuna", ""], ["Moore", "Jason H.", ""]]}, {"id": "1706.04145", "submitter": "Najeeb Khan", "authors": "Najeeb Khan and Ian Stavness", "title": "Prediction of Muscle Activations for Reaching Movements using Deep\n  Neural Networks", "comments": "To be presented at the Annual meeting of American Society of\n  Biomechanics 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The motor control problem involves determining the time-varying muscle\nactivation trajectories required to accomplish a given movement. Muscle\nredundancy makes motor control a challenging task: there are many possible\nactivation trajectories that accomplish the same movement. Despite this\nredundancy, most movements are accomplished in highly stereotypical ways. For\nexample, point-to-point reaching movements are almost universally performed\nwith very similar smooth trajectories. Optimization methods are commonly used\nto predict muscle forces for measured movements. However, these approaches\nrequire computationally expensive simulations and are sensitive to the chosen\noptimality criteria and regularization. In this work, we investigate deep\nautoencoders for the prediction of muscle activation trajectories for\npoint-to-point reaching movements. We evaluate our DNN predictions with\nsimulated reaches and two methods to generate the muscle activations: inverse\ndynamics (ID) and optimal control (OC) criteria. We also investigate optimal\nnetwork parameters and training criteria to improve the accuracy of the\npredictions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 16:14:44 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Khan", "Najeeb", ""], ["Stavness", "Ian", ""]]}, {"id": "1706.04159", "submitter": "Peter O'Connor", "authors": "Peter O'Connor, Efstratios Gavves, Max Welling", "title": "Temporally Efficient Deep Learning with Spikes", "comments": "8 pages + references and appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of natural sensory data is temporally redundant. Video\nframes or audio samples which are sampled at nearby points in time tend to have\nsimilar values. Typically, deep learning algorithms take no advantage of this\nredundancy to reduce computation. This can be an obscene waste of energy. We\npresent a variant on backpropagation for neural networks in which computation\nscales with the rate of change of the data - not the rate at which we process\nthe data. We do this by having neurons communicate a combination of their\nstate, and their temporal change in state. Intriguingly, this simple\ncommunication rule give rise to units that resemble biologically-inspired leaky\nintegrate-and-fire neurons, and to a weight-update rule that is equivalent to a\nform of Spike-Timing Dependent Plasticity (STDP), a synaptic learning rule\nobserved in the brain. We demonstrate that on MNIST and a temporal variant of\nMNIST, our algorithm performs about as well as a Multilayer Perceptron trained\nwith backpropagation, despite only communicating discrete values between\nlayers.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 16:56:27 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["O'Connor", "Peter", ""], ["Gavves", "Efstratios", ""], ["Welling", "Max", ""]]}, {"id": "1706.04215", "submitter": "Ashwinkumar Ganesan", "authors": "Mandar Haldekar, Ashwinkumar Ganesan, Tim Oates", "title": "Identifying Spatial Relations in Images using Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches to building a large scale knowledge graph have usually\nrelied on extracting information (entities, their properties, and relations\nbetween them) from unstructured text (e.g. Dbpedia). Recent advances in\nConvolutional Neural Networks (CNN) allow us to shift our focus to learning\nentities and relations from images, as they build robust models that require\nlittle or no pre-processing of the images. In this paper, we present an\napproach to identify and extract spatial relations (e.g., The girl is standing\nbehind the table) from images using CNNs. Our research addresses two specific\nchallenges: providing insight into how spatial relations are learned by the\nnetwork and which parts of the image are used to predict these relations. We\nuse the pre-trained network VGGNet to extract features from an image and train\na Multi-layer Perceptron (MLP) on a set of synthetic images and the sun09\ndataset to extract spatial relations. The MLP predicts spatial relations\nwithout a bounding box around the objects or the space in the image depicting\nthe relation. To understand how the spatial relations are represented in the\nnetwork, a heatmap is overlayed on the image to show the regions that are\ndeemed important by the network. Also, we analyze the MLP to show the\nrelationship between the activation of consistent groups of nodes and the\nprediction of a spatial relation. We show how the loss of these groups affects\nthe networks ability to identify relations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 18:24:11 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Haldekar", "Mandar", ""], ["Ganesan", "Ashwinkumar", ""], ["Oates", "Tim", ""]]}, {"id": "1706.04223", "submitter": "Junbo Zhao", "authors": "Jake Zhao (Junbo), Yoon Kim, Kelly Zhang, Alexander M. Rush and Yann\n  LeCun", "title": "Adversarially Regularized Autoencoders", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models, trained using variational autoencoders or\ngenerative adversarial networks, are now a key technique for representation\nlearning of continuous structures. However, applying similar methods to\ndiscrete structures, such as text sequences or discretized images, has proven\nto be more challenging. In this work, we propose a flexible method for training\ndeep latent variable models of discrete structures. Our approach is based on\nthe recently-proposed Wasserstein autoencoder (WAE) which formalizes the\nadversarial autoencoder (AAE) as an optimal transport problem. We first extend\nthis framework to model discrete sequences, and then further explore different\nlearned priors targeting a controllable representation. This adversarially\nregularized autoencoder (ARAE) allows us to generate natural textual outputs as\nwell as perform manipulations in the latent space to induce change in the\noutput space. Finally we show that the latent representation can be trained to\nperform unaligned textual style transfer, giving improvements both in\nautomatic/human evaluation compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 19:00:53 GMT"}, {"version": "v2", "created": "Wed, 15 Nov 2017 05:41:04 GMT"}, {"version": "v3", "created": "Fri, 29 Jun 2018 00:07:16 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Zhao", "Jake", "", "Junbo"], ["Kim", "Yoon", ""], ["Zhang", "Kelly", ""], ["Rush", "Alexander M.", ""], ["LeCun", "Yann", ""]]}, {"id": "1706.04265", "submitter": "Sebastian Herzog", "authors": "Sebastian Herzog, Christian Tetzlaff and Florentin W\\\"org\\\"otter", "title": "Transfer entropy-based feedback improves performance in artificial\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure of the majority of modern deep neural networks is characterized\nby uni- directional feed-forward connectivity across a very large number of\nlayers. By contrast, the architecture of the cortex of vertebrates contains\nfewer hierarchical levels but many recurrent and feedback connections. Here we\nshow that a small, few-layer artificial neural network that employs feedback\nwill reach top level performance on a standard benchmark task, otherwise only\nobtained by large feed-forward structures. To achieve this we use feed-forward\ntransfer entropy between neurons to structure feedback connectivity. Transfer\nentropy can here intuitively be understood as a measure for the relevance of\ncertain pathways in the network, which are then amplified by feedback. Feedback\nmay therefore be key for high network performance in small brain-like\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 21:57:53 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 09:50:41 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Herzog", "Sebastian", ""], ["Tetzlaff", "Christian", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "1706.04332", "submitter": "Sung Kim", "authors": "Sung Kim, Patrick Howe, Thierry Moreau, Armin Alaghi, Luis Ceze,\n  Visvesh Sathe", "title": "MATIC: Learning Around Errors for Efficient Low-Voltage Neural Network\n  Accelerators", "comments": "6 pages, 12 figures, 3 tables. Published at Design, Automation and\n  Test in Europe Conference and Exhibition (DATE) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of the increasing demand for deep neural network (DNN)-based\nservices, efforts to develop dedicated hardware accelerators for DNNs are\ngrowing rapidly. However,while accelerators with high performance and\nefficiency on convolutional deep neural networks (Conv-DNNs) have been\ndeveloped, less progress has been made with regards to fully-connected DNNs\n(FC-DNNs). In this paper, we propose MATIC (Memory Adaptive Training with\nIn-situ Canaries), a methodology that enables aggressive voltage scaling of\naccelerator weight memories to improve the energy-efficiency of DNN\naccelerators. To enable accurate operation with voltage overscaling, MATIC\ncombines the characteristics of destructive SRAM reads with the error\nresilience of neural networks in a memory-adaptive training process.\nFurthermore, PVT-related voltage margins are eliminated using bit-cells from\nsynaptic weights as in-situ canaries to track runtime environmental variation.\nDemonstrated on a low-power DNN accelerator that we fabricate in 65 nm CMOS,\nMATIC enables up to 60-80 mV of voltage overscaling (3.3x total energy\nreduction versus the nominal voltage), or 18.6x application error reduction.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 06:36:02 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 06:59:08 GMT"}, {"version": "v3", "created": "Fri, 23 Mar 2018 11:24:35 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Kim", "Sung", ""], ["Howe", "Patrick", ""], ["Moreau", "Thierry", ""], ["Alaghi", "Armin", ""], ["Ceze", "Luis", ""], ["Sathe", "Visvesh", ""]]}, {"id": "1706.04560", "submitter": "Tong Wang", "authors": "Sandeep Subramanian, Tong Wang, Xingdi Yuan, Saizheng Zhang, Yoshua\n  Bengio, Adam Trischler", "title": "Neural Models for Key Phrase Detection and Question Generation", "comments": "Machine Reading for Question Answering workshop at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a two-stage neural model to tackle question generation from\ndocuments. First, our model estimates the probability that word sequences in a\ndocument are ones that a human would pick when selecting candidate answers by\ntraining a neural key-phrase extractor on the answers in a question-answering\ncorpus. Predicted key phrases then act as target answers and condition a\nsequence-to-sequence question-generation model with a copy mechanism.\nEmpirically, our key-phrase extraction model significantly outperforms an\nentity-tagging baseline and existing rule-based approaches. We further\ndemonstrate that our question generation system formulates fluent, answerable\nquestions from key phrases. This two-stage system could be used to augment or\ngenerate reading comprehension datasets, which may be leveraged to improve\nmachine reading systems or in educational settings.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 16:06:18 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 17:43:48 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 17:57:41 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Subramanian", "Sandeep", ""], ["Wang", "Tong", ""], ["Yuan", "Xingdi", ""], ["Zhang", "Saizheng", ""], ["Bengio", "Yoshua", ""], ["Trischler", "Adam", ""]]}, {"id": "1706.04568", "submitter": "Lex Fridman", "authors": "Lex Fridman, Benedikt Jenik, Shaiyan Keshvari, Bryan Reimer, Christoph\n  Zetzsche, Ruth Rosenholtz", "title": "SideEye: A Generative Neural Network Based Simulator of Human Peripheral\n  Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foveal vision makes up less than 1% of the visual field. The other 99% is\nperipheral vision. Precisely what human beings see in the periphery is both\nobvious and mysterious in that we see it with our own eyes but can't visualize\nwhat we see, except in controlled lab experiments. Degradation of information\nin the periphery is far more complex than what might be mimicked with a radial\nblur. Rather, behaviorally-validated models hypothesize that peripheral vision\nmeasures a large number of local texture statistics in pooling regions that\noverlap and grow with eccentricity. In this work, we develop a new method for\nperipheral vision simulation by training a generative neural network on a\nbehaviorally-validated full-field synthesis model. By achieving a 21,000 fold\nreduction in running time, our approach is the first to combine realism and\nspeed of peripheral vision simulation to a degree that provides a whole new way\nto approach visual design: through peripheral visualization.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 16:18:20 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 03:40:03 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Fridman", "Lex", ""], ["Jenik", "Benedikt", ""], ["Keshvari", "Shaiyan", ""], ["Reimer", "Bryan", ""], ["Zetzsche", "Christoph", ""], ["Rosenholtz", "Ruth", ""]]}, {"id": "1706.04698", "submitter": "Dongsung Huh", "authors": "Dongsung Huh, Terrence J. Sejnowski", "title": "Gradient Descent for Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of studies on neural computation are based on network models of static\nneurons that produce analog output, despite the fact that information\nprocessing in the brain is predominantly carried out by dynamic neurons that\nproduce discrete pulses called spikes. Research in spike-based computation has\nbeen impeded by the lack of efficient supervised learning algorithm for spiking\nnetworks. Here, we present a gradient descent method for optimizing spiking\nnetwork models by introducing a differentiable formulation of spiking networks\nand deriving the exact gradient calculation. For demonstration, we trained\nrecurrent spiking networks on two dynamic tasks: one that requires optimizing\nfast (~millisecond) spike-based interactions for efficient encoding of\ninformation, and a delayed memory XOR task over extended duration (~second).\nThe results show that our method indeed optimizes the spiking network dynamics\non the time scale of individual spikes as well as behavioral time scales. In\nconclusion, our result offers a general purpose supervised learning algorithm\nfor spiking neural networks, thus advancing further investigations on\nspike-based computation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 23:56:57 GMT"}, {"version": "v2", "created": "Mon, 19 Jun 2017 22:11:20 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Huh", "Dongsung", ""], ["Sejnowski", "Terrence J.", ""]]}, {"id": "1706.04702", "submitter": "Arnulf Jentzen", "authors": "Weinan E and Jiequn Han and Arnulf Jentzen", "title": "Deep learning-based numerical methods for high-dimensional parabolic\n  partial differential equations and backward stochastic differential equations", "comments": "39 pages, 15 figures", "journal-ref": "Commun. Math. Stat. 5, 349-380 (2017)", "doi": "10.1007/s40304-017-0117-6", "report-no": null, "categories": "math.NA cs.LG cs.NE math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm for solving parabolic partial differential\nequations (PDEs) and backward stochastic differential equations (BSDEs) in high\ndimension, by making an analogy between the BSDE and reinforcement learning\nwith the gradient of the solution playing the role of the policy function, and\nthe loss function given by the error between the prescribed terminal condition\nand the solution of the BSDE. The policy function is then approximated by a\nneural network, as is done in deep reinforcement learning. Numerical results\nusing TensorFlow illustrate the efficiency and accuracy of the proposed\nalgorithms for several 100-dimensional nonlinear PDEs from physics and finance\nsuch as the Allen-Cahn equation, the Hamilton-Jacobi-Bellman equation, and a\nnonlinear pricing model for financial derivatives.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 00:28:58 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["E", "Weinan", ""], ["Han", "Jiequn", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1706.05086", "submitter": "Jialin Liu Ph.D", "authors": "Simon M. Lucas, Jialin Liu, Diego P\\'erez-Li\\'ebana", "title": "Evaluating Noisy Optimisation Algorithms: First Hitting Time is\n  Problematic", "comments": "4 pages, 4 figurs, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key part of any evolutionary algorithm is fitness evaluation. When fitness\nevaluations are corrupted by noise, as happens in many real-world problems as a\nconsequence of various types of uncertainty, a strategy is needed in order to\ncope with this. Resampling is one of the most common strategies, whereby each\nsolution is evaluated many times in order to reduce the variance of the fitness\nestimates. When evaluating the performance of a noisy optimisation algorithm, a\nkey consideration is the stopping condition for the algorithm. A frequently\nused stopping condition in runtime analysis, known as \"First Hitting Time\", is\nto stop the algorithm as soon as it encounters the optimal solution. However,\nthis is unrealistic for real-world problems, as if the optimal solution were\nalready known, there would be no need to search for it. This paper argues that\nthe use of First Hitting Time, despite being a commonly used approach, is\nsignificantly flawed and overestimates the quality of many algorithms in\nreal-world cases, where the optimum is not known in advance and has to be\ngenuinely searched for. A better alternative is to measure the quality of the\nsolution an algorithm returns after a fixed evaluation budget, i.e., to focus\non final solution quality. This paper argues that focussing on final solution\nquality is more realistic and demonstrates cases where the results produced by\neach algorithm evaluation method lead to very different conclusions regarding\nthe quality of each noisy optimisation algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 09:44:34 GMT"}, {"version": "v2", "created": "Wed, 12 Jul 2017 11:20:05 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Lucas", "Simon M.", ""], ["Liu", "Jialin", ""], ["P\u00e9rez-Li\u00e9bana", "Diego", ""]]}, {"id": "1706.05087", "submitter": "\\c{C}a\\u{g}lar G\\\"ul\\c{c}ehre", "authors": "Caglar Gulcehre, Francis Dutil, Adam Trischler, Yoshua Bengio", "title": "Plan, Attend, Generate: Character-level Neural Machine Translation with\n  Planning in the Decoder", "comments": "Accepted to Rep4NLP 2017 Workshop at ACL 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the integration of a planning mechanism into an\nencoder-decoder architecture with an explicit alignment for character-level\nmachine translation. We develop a model that plans ahead when it computes\nalignments between the source and target sequences, constructing a matrix of\nproposed future alignments and a commitment vector that governs whether to\nfollow or recompute the plan. This mechanism is inspired by the strategic\nattentive reader and writer (STRAW) model. Our proposed model is end-to-end\ntrainable with fully differentiable operations. We show that it outperforms a\nstrong baseline on three character-level decoder neural machine translation on\nWMT'15 corpus. Our analysis demonstrates that our model can compute\nqualitatively intuitive alignments and achieves superior performance with fewer\nparameters.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 23:11:04 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 06:31:05 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Gulcehre", "Caglar", ""], ["Dutil", "Francis", ""], ["Trischler", "Adam", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1706.05283", "submitter": "Myoung Hoon Ha", "authors": "Myoung Hoon Ha and Byung-Ro Moon", "title": "The Evolution of Neural Network-Based Chart Patterns: A Preliminary\n  Study", "comments": "8 pages, In proceedings of Genetic and Evolutionary Computation\n  Conference (GECCO 2017), Berlin, Germany", "journal-ref": null, "doi": "10.1145/3071178.3071192", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural network-based chart pattern represents adaptive parametric features,\nincluding non-linear transformations, and a template that can be applied in the\nfeature space. The search of neural network-based chart patterns has been\nunexplored despite its potential expressiveness. In this paper, we formulate a\ngeneral chart pattern search problem to enable cross-representational\nquantitative comparison of various search schemes. We suggest a HyperNEAT\nframework applying state-of-the-art deep neural network techniques to find\nattractive neural network-based chart patterns; These techniques enable a fast\nevaluation and search of robust patterns, as well as bringing a performance\ngain. The proposed framework successfully found attractive patterns on the\nKorean stock market. We compared newly found patterns with those found by\ndifferent search schemes, showing the proposed approach has potential.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 01:53:52 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Ha", "Myoung Hoon", ""], ["Moon", "Byung-Ro", ""]]}, {"id": "1706.05507", "submitter": "Mahesh Chandra Mukkamala", "authors": "Mahesh Chandra Mukkamala, Matthias Hein", "title": "Variants of RMSProp and Adagrad with Logarithmic Regret Bounds", "comments": "ICML 2017, 16 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods have become recently very popular, in particular as\nthey have been shown to be useful in the training of deep neural networks. In\nthis paper we have analyzed RMSProp, originally proposed for the training of\ndeep neural networks, in the context of online convex optimization and show\n$\\sqrt{T}$-type regret bounds. Moreover, we propose two variants SC-Adagrad and\nSC-RMSProp for which we show logarithmic regret bounds for strongly convex\nfunctions. Finally, we demonstrate in the experiments that these new variants\noutperform other adaptive gradient techniques or stochastic gradient descent in\nthe optimization of strongly convex functions as well as in training of deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 09:48:55 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 18:47:37 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Mukkamala", "Mahesh Chandra", ""], ["Hein", "Matthias", ""]]}, {"id": "1706.05563", "submitter": "Timoleon Moraitis", "authors": "Timoleon Moraitis, Abu Sebastian, Irem Boybat, Manuel Le Gallo, Tomas\n  Tuma, Evangelos Eleftheriou", "title": "Fatiguing STDP: Learning from Spike-Timing Codes in the Presence of Rate\n  Codes", "comments": "8 pages, 8 figures, presented at IJCNN in May 2017", "journal-ref": "2017 International Joint Conference on Neural Networks (IJCNN),\n  Anchorage, AK, 2017, pp. 1823-1830", "doi": "10.1109/IJCNN.2017.7966072", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) could play a key role in unsupervised machine\nlearning applications, by virtue of strengths related to learning from the fine\ntemporal structure of event-based signals. However, some spike-timing-related\nstrengths of SNNs are hindered by the sensitivity of spike-timing-dependent\nplasticity (STDP) rules to input spike rates, as fine temporal correlations may\nbe obstructed by coarser correlations between firing rates. In this article, we\npropose a spike-timing-dependent learning rule that allows a neuron to learn\nfrom the temporally-coded information despite the presence of rate codes. Our\nlong-term plasticity rule makes use of short-term synaptic fatigue dynamics. We\nshow analytically that, in contrast to conventional STDP rules, our fatiguing\nSTDP (FSTDP) helps learn the temporal code, and we derive the necessary\nconditions to optimize the learning process. We showcase the effectiveness of\nFSTDP in learning spike-timing correlations among processes of different rates\nin synthetic data. Finally, we use FSTDP to detect correlations in real-world\nweather data from the United States in an experimental realization of the\nalgorithm that uses a neuromorphic hardware platform comprising phase-change\nmemristive devices. Taken together, our analyses and demonstrations suggest\nthat FSTDP paves the way for the exploitation of the spike-based strengths of\nSNNs in real-world applications.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jun 2017 17:11:27 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Moraitis", "Timoleon", ""], ["Sebastian", "Abu", ""], ["Boybat", "Irem", ""], ["Gallo", "Manuel Le", ""], ["Tuma", "Tomas", ""], ["Eleftheriou", "Evangelos", ""]]}, {"id": "1706.05683", "submitter": "Alfred Bourely", "authors": "Alfred Bourely, John Patrick Boueri, Krzysztof Choromonski", "title": "Sparse Neural Networks Topologies", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Sparse Neural Network architectures that are based on random or\nstructured bipartite graph topologies. Sparse architectures provide compression\nof the models learned and speed-ups of computations, they can also surpass\ntheir unstructured or fully connected counterparts. As we show, even more\ncompact topologies of the so-called SNN (Sparse Neural Network) can be achieved\nwith the use of structured graphs of connections between consecutive layers of\nneurons. In this paper, we investigate how the accuracy and training speed of\nthe models depend on the topology and sparsity of the neural network. Previous\napproaches using sparcity are all based on fully connected neural network\nmodels and create sparcity during training phase, instead we explicitly define\na sparse architectures of connections before the training. Building compact\nneural network models is coherent with empirical observations showing that\nthere is much redundancy in learned neural network models. We show\nexperimentally that the accuracy of the models learned with neural networks\ndepends on expander-like properties of the underlying topologies such as the\nspectral gap and algebraic connectivity rather than the density of the graphs\nof connections.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 16:30:25 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Bourely", "Alfred", ""], ["Boueri", "John Patrick", ""], ["Choromonski", "Krzysztof", ""]]}, {"id": "1706.06083", "submitter": "Dimitris Tsipras", "authors": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris\n  Tsipras, Adrian Vladu", "title": "Towards Deep Learning Models Resistant to Adversarial Attacks", "comments": "ICLR'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has demonstrated that deep neural networks are vulnerable to\nadversarial examples---inputs that are almost indistinguishable from natural\ndata and yet classified incorrectly by the network. In fact, some of the latest\nfindings suggest that the existence of adversarial attacks may be an inherent\nweakness of deep learning models. To address this problem, we study the\nadversarial robustness of neural networks through the lens of robust\noptimization. This approach provides us with a broad and unifying view on much\nof the prior work on this topic. Its principled nature also enables us to\nidentify methods for both training and attacking neural networks that are\nreliable and, in a certain sense, universal. In particular, they specify a\nconcrete security guarantee that would protect against any adversary. These\nmethods let us train networks with significantly improved resistance to a wide\nrange of adversarial attacks. They also suggest the notion of security against\na first-order adversary as a natural and broad security guarantee. We believe\nthat robustness against such well-defined classes of adversaries is an\nimportant stepping stone towards fully resistant deep learning models. Code and\npre-trained models are available at https://github.com/MadryLab/mnist_challenge\nand https://github.com/MadryLab/cifar10_challenge.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 17:53:11 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 17:34:00 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 01:16:40 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 18:53:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Madry", "Aleksander", ""], ["Makelov", "Aleksandar", ""], ["Schmidt", "Ludwig", ""], ["Tsipras", "Dimitris", ""], ["Vladu", "Adrian", ""]]}, {"id": "1706.06195", "submitter": "Ivo Gon\\c{c}alves", "authors": "Ivo Gon\\c{c}alves, Sara Silva, Carlos M. Fonseca, Mauro Castelli", "title": "Unsure When to Stop? Ask Your Semantic Neighbors", "comments": null, "journal-ref": null, "doi": "10.1145/3071178.3071328", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In iterative supervised learning algorithms it is common to reach a point in\nthe search where no further induction seems to be possible with the available\ndata. If the search is continued beyond this point, the risk of overfitting\nincreases significantly. Following the recent developments in inductive\nsemantic stochastic methods, this paper studies the feasibility of using\ninformation gathered from the semantic neighborhood to decide when to stop the\nsearch. Two semantic stopping criteria are proposed and experimentally assessed\nin Geometric Semantic Genetic Programming (GSGP) and in the Semantic Learning\nMachine (SLM) algorithm (the equivalent algorithm for neural networks). The\nexperiments are performed on real-world high-dimensional regression datasets.\nThe results show that the proposed semantic stopping criteria are able to\ndetect stopping points that result in a competitive generalization for both\nGSGP and SLM. This approach also yields computationally efficient algorithms as\nit allows the evolution of neural networks in less than 3 seconds on average,\nand of GP trees in at most 10 seconds. The usage of the proposed semantic\nstopping criteria in conjunction with the computation of optimal\nmutation/learning steps also results in small trees and neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 22:29:08 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Gon\u00e7alves", "Ivo", ""], ["Silva", "Sara", ""], ["Fonseca", "Carlos M.", ""], ["Castelli", "Mauro", ""]]}, {"id": "1706.06383", "submitter": "Misha Denil", "authors": "Misha Denil, Sergio G\\'omez Colmenarejo, Serkan Cabi, David Saxton,\n  Nando de Freitas", "title": "Programmable Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build deep RL agents that execute declarative programs expressed in formal\nlanguage. The agents learn to ground the terms in this language in their\nenvironment, and can generalize their behavior at test time to execute new\nprograms that refer to objects that were not referenced during training. The\nagents develop disentangled interpretable representations that allow them to\ngeneralize to a wide variety of zero-shot semantic tasks.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 12:19:34 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Denil", "Misha", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Cabi", "Serkan", ""], ["Saxton", "David", ""], ["de Freitas", "Nando", ""]]}, {"id": "1706.06511", "submitter": "Nathaniel Rodriguez", "authors": "Nathaniel Rodriguez, Eduardo Izquierdo, Yong-Yeol Ahn", "title": "Optimal modularity and memory capacity of neural reservoirs", "comments": null, "journal-ref": null, "doi": "10.1162/netn_a_00082", "report-no": null, "categories": "cs.NE cs.AI physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural network is a powerful computing framework that has been exploited\nby biological evolution and by humans for solving diverse problems. Although\nthe computational capabilities of neural networks are determined by their\nstructure, the current understanding of the relationships between a neural\nnetwork's architecture and function is still primitive. Here we reveal that\nneural network's modular architecture plays a vital role in determining the\nneural dynamics and memory performance of the network of threshold neurons. In\nparticular, we demonstrate that there exists an optimal modularity for memory\nperformance, where a balance between local cohesion and global connectivity is\nestablished, allowing optimally modular networks to remember longer. Our\nresults suggest that insights from dynamical analysis of neural networks and\ninformation spreading processes can be leveraged to better design neural\nnetworks and may shed light on the brain's modular organization.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 15:17:37 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 22:45:53 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 01:57:17 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Rodriguez", "Nathaniel", ""], ["Izquierdo", "Eduardo", ""], ["Ahn", "Yong-Yeol", ""]]}, {"id": "1706.06699", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei, Timothee Masquelier, Anthony Maida", "title": "Representation Learning using Event-based STDP", "comments": null, "journal-ref": "Neural Networks, vol. 105, pp. 294-303, 2018", "doi": "10.1016/j.neunet.2018.05.018", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although representation learning methods developed within the framework of\ntraditional neural networks are relatively mature, developing a spiking\nrepresentation model remains a challenging problem. This paper proposes an\nevent-based method to train a feedforward spiking neural network (SNN) layer\nfor extracting visual features. The method introduces a novel\nspike-timing-dependent plasticity (STDP) learning rule and a threshold\nadjustment rule both derived from a vector quantization-like objective function\nsubject to a sparsity constraint. The STDP rule is obtained by the gradient of\na vector quantization criterion that is converted to spike-based,\nspatio-temporally local update rules in a spiking network of leaky,\nintegrate-and-fire (LIF) neurons. Independence and sparsity of the model are\nachieved by the threshold adjustment rule and by a softmax function\nimplementing inhibition in the representation layer consisting of\nWTA-thresholded spiking neurons. Together, these mechanisms implement a form of\nspike-based, competitive learning. Two sets of experiments are performed on the\nMNIST and natural image datasets. The results demonstrate a sparse spiking\nvisual representation model with low reconstruction loss comparable with\nstate-of-the-art visual coding approaches, yet our rule is local in both time\nand space, thus biologically plausible and hardware friendly.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 23:13:31 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 01:26:09 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 17:24:56 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Masquelier", "Timothee", ""], ["Maida", "Anthony", ""]]}, {"id": "1706.06720", "submitter": "Mohamed Loey", "authors": "Mohamed Loey, Ahmed El-Sawy, Hazem EL-Bakry", "title": "Deep Learning Autoencoder Approach for Handwritten Arabic Digits\n  Recognition", "comments": "6 pages", "journal-ref": null, "doi": "10.1007/978-3-319-48308-5_54", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new unsupervised learning approach with stacked\nautoencoder (SAE) for Arabic handwritten digits categorization. Recently,\nArabic handwritten digits recognition has been an important area due to its\napplications in several fields. This work is focusing on the recognition part\nof handwritten Arabic digits recognition that face several challenges,\nincluding the unlimited variation in human handwriting and the large public\ndatabases. Arabic digits contains ten numbers that were descended from the\nIndian digits system. Stacked autoencoder (SAE) tested and trained the MADBase\ndatabase (Arabic handwritten digits images) that contain 10000 testing images\nand 60000 training images. We show that the use of SAE leads to significant\nimprovements across different machine-learning classification algorithms. SAE\nis giving an average accuracy of 98.5%.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 02:02:31 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Loey", "Mohamed", ""], ["El-Sawy", "Ahmed", ""], ["EL-Bakry", "Hazem", ""]]}, {"id": "1706.06920", "submitter": "Anton Eremeev", "authors": "A.V. Eremeev, Yu.V. Kovalenko", "title": "Genetic Algorithm with Optimal Recombination for the Asymmetric\n  Travelling Salesman Problem", "comments": "Proc. of The 11th International Conference on Large-Scale Scientific\n  Computations (LSSC-17), June 5 - 9, 2017, Sozopol, Bulgaria", "journal-ref": null, "doi": "10.1007/978-3-319-73441-5_36", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new genetic algorithm with optimal recombination for the\nasymmetric instances of travelling salesman problem. The algorithm incorporates\nseveral new features that contribute to its effectiveness: (i) Optimal\nrecombination problem is solved within crossover operator. (ii) A new mutation\noperator performs a random jump within 3-opt or 4-opt neighborhood. (iii)\nGreedy constructive heuristic of W.Zhang and 3-opt local search heuristic are\nused to generate the initial population. A computational experiment on TSPLIB\ninstances shows that the proposed algorithm yields competitive results to other\nwell-known memetic algorithms for asymmetric travelling salesman problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 14:14:13 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 04:44:07 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Eremeev", "A. V.", ""], ["Kovalenko", "Yu. V.", ""]]}, {"id": "1706.06931", "submitter": "Rasmus Ibsen-Jensen", "authors": "Krishnendu Chatterjee, Rasmus Ibsen-Jensen, Martin A. Nowak", "title": "Faster Monte-Carlo Algorithms for Fixation Probability of the Moran\n  Process on Undirected Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary graph theory studies the evolutionary dynamics in a population\nstructure given as a connected graph. Each node of the graph represents an\nindividual of the population, and edges determine how offspring are placed. We\nconsider the classical birth-death Moran process where there are two types of\nindividuals, namely, the residents with fitness 1 and mutants with fitness r.\nThe fitness indicates the reproductive strength. The evolutionary dynamics\nhappens as follows: in the initial step, in a population of all resident\nindividuals a mutant is introduced, and then at each step, an individual is\nchosen proportional to the fitness of its type to reproduce, and the offspring\nreplaces a neighbor uniformly at random. The process stops when all individuals\nare either residents or mutants. The probability that all individuals in the\nend are mutants is called the fixation probability. We present faster\npolynomial-time Monte-Carlo algorithms for finidng the fixation probability on\nundirected graphs. Our algorithms are always at least a factor O(n^2/log n)\nfaster as compared to the previous algorithms, where n is the number of nodes,\nand is polynomial even if r is given in binary. We also present lower bounds\nshowing that the upper bound on the expected number of effective steps we\npresent is asymptotically tight for undirected graphs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 14:35:24 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Chatterjee", "Krishnendu", ""], ["Ibsen-Jensen", "Rasmus", ""], ["Nowak", "Martin A.", ""]]}, {"id": "1706.07043", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Elad Marciano, Loren Lugosch, Warren J. Gross, David\n  Burshtein, Yair Beery", "title": "Deep Learning Methods for Improved Decoding of Linear Codes", "comments": "Accepted To IEEE Journal Of Selected Topics In Signal Processing", "journal-ref": null, "doi": "10.1109/JSTSP.2017.2788405", "report-no": null, "categories": "cs.IT cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of low complexity, close to optimal, channel decoding of linear\ncodes with short to moderate block length is considered. It is shown that deep\nlearning methods can be used to improve a standard belief propagation decoder,\ndespite the large example space. Similar improvements are obtained for the\nmin-sum algorithm. It is also shown that tying the parameters of the decoders\nacross iterations, so as to form a recurrent neural network architecture, can\nbe implemented with comparable results. The advantage is that significantly\nless parameters are required. We also introduce a recurrent neural decoder\narchitecture based on the method of successive relaxation. Improvements over\nstandard belief propagation are also observed on sparser Tanner graph\nrepresentations of the codes. Furthermore, we demonstrate that the neural\nbelief propagation decoder can be used to improve the performance, or\nalternatively reduce the computational complexity, of a close to optimal\ndecoder of short BCH codes.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 06:46:14 GMT"}, {"version": "v2", "created": "Mon, 1 Jan 2018 20:13:24 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Nachmani", "Eliya", ""], ["Marciano", "Elad", ""], ["Lugosch", "Loren", ""], ["Gross", "Warren J.", ""], ["Burshtein", "David", ""], ["Beery", "Yair", ""]]}, {"id": "1706.07206", "submitter": "Wojciech Samek", "authors": "Leila Arras, Gr\\'egoire Montavon, Klaus-Robert M\\\"uller, Wojciech\n  Samek", "title": "Explaining Recurrent Neural Network Predictions in Sentiment Analysis", "comments": "9 pages, 4 figures, accepted for EMNLP'17 Workshop on Computational\n  Approaches to Subjectivity, Sentiment & Social Media Analysis (WASSA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown\nto deliver insightful explanations in the form of input space relevances for\nunderstanding feed-forward neural network classification decisions. In the\npresent work, we extend the usage of LRP to recurrent neural networks. We\npropose a specific propagation rule applicable to multiplicative connections as\nthey arise in recurrent network architectures such as LSTMs and GRUs. We apply\nour technique to a word-based bi-directional LSTM model on a five-class\nsentiment prediction task, and evaluate the resulting LRP relevances both\nqualitatively and quantitatively, obtaining better results than a\ngradient-based related method which was used in previous work.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 08:24:59 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 20:01:33 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Arras", "Leila", ""], ["Montavon", "Gr\u00e9goire", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1706.07296", "submitter": "Sam Kriegman", "authors": "Sam Kriegman, Nick Cheney, Francesco Corucci, and Josh C. Bongard", "title": "A Minimal Developmental Model Can Increase Evolvability in Soft Robots", "comments": null, "journal-ref": null, "doi": "10.1145/3071178.3071296", "report-no": null, "categories": "cs.NE cs.RO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different subsystems of organisms adapt over many time scales, such as rapid\nchanges in the nervous system (learning), slower morphological and neurological\nchange over the lifetime of the organism (postnatal development), and change\nover many generations (evolution). Much work has focused on instantiating\nlearning or evolution in robots, but relatively little on development. Although\nmany theories have been forwarded as to how development can aid evolution, it\nis difficult to isolate each such proposed mechanism. Thus, here we introduce a\nminimal yet embodied model of development: the body of the robot changes over\nits lifetime, yet growth is not influenced by the environment. We show that\neven this simple developmental model confers evolvability because it allows\nevolution to sweep over a larger range of body plans than an equivalent\nnon-developmental system, and subsequent heterochronic mutations 'lock in' this\nbody plan in more morphologically-static descendants. Future work will involve\ngradually complexifying the developmental model to determine when and how such\nadded complexity increases evolvability.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 12:56:14 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Kriegman", "Sam", ""], ["Cheney", "Nick", ""], ["Corucci", "Francesco", ""], ["Bongard", "Josh C.", ""]]}, {"id": "1706.07446", "submitter": "Daniel George", "authors": "Daniel George, Hongyu Shen, E. A. Huerta", "title": "Deep Transfer Learning: A new deep learning glitch classification method\n  for advanced LIGO", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevD.97.101501", "report-no": null, "categories": "gr-qc astro-ph.IM cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exquisite sensitivity of the advanced LIGO detectors has enabled the\ndetection of multiple gravitational wave signals. The sophisticated design of\nthese detectors mitigates the effect of most types of noise. However, advanced\nLIGO data streams are contaminated by numerous artifacts known as glitches:\nnon-Gaussian noise transients with complex morphologies. Given their high rate\nof occurrence, glitches can lead to false coincident detections, obscure and\neven mimic gravitational wave signals. Therefore, successfully characterizing\nand removing glitches from advanced LIGO data is of utmost importance. Here, we\npresent the first application of Deep Transfer Learning for glitch\nclassification, showing that knowledge from deep learning algorithms trained\nfor real-world object recognition can be transferred for classifying glitches\nin time-series based on their spectrogram images. Using the Gravity Spy\ndataset, containing hand-labeled, multi-duration spectrograms obtained from\nreal LIGO data, we demonstrate that this method enables optimal use of very\ndeep convolutional neural networks for classification given small training\ndatasets, significantly reduces the time for training the networks, and\nachieves state-of-the-art accuracy above 98.8%, with perfect precision-recall\non 8 out of 22 classes. Furthermore, new types of glitches can be classified\naccurately given few labeled examples with this technique. Once trained via\ntransfer learning, we show that the convolutional neural networks can be\ntruncated and used as excellent feature extractors for unsupervised clustering\nmethods to identify new classes based on their morphology, without any labeled\nexamples. Therefore, this provides a new framework for dynamic glitch\nclassification for gravitational wave detectors, which are expected to\nencounter new types of noise as they undergo gradual improvements to attain\ndesign sensitivity.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 18:11:13 GMT"}], "update_date": "2018-07-15", "authors_parsed": [["George", "Daniel", ""], ["Shen", "Hongyu", ""], ["Huerta", "E. A.", ""]]}, {"id": "1706.07888", "submitter": "Sam Kriegman", "authors": "Sam Kriegman, Marcin Szubert, Josh C. Bongard, Christian Skalka", "title": "Evolving Spatially Aggregated Features from Satellite Imagery for\n  Regional Modeling", "comments": null, "journal-ref": "Parallel Problem Solving from Nature - PPSN XIV. PPSN 2016.\n  Lecture Notes in Computer Science, vol 9921. Springer, Cham", "doi": "10.1007/978-3-319-45823-6_66", "report-no": null, "categories": "stat.ML cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Satellite imagery and remote sensing provide explanatory variables at\nrelatively high resolutions for modeling geospatial phenomena, yet regional\nsummaries are often desirable for analysis and actionable insight. In this\npaper, we propose a novel method of inducing spatial aggregations as a\ncomponent of the machine learning process, yielding regional model features\nwhose construction is driven by model prediction performance rather than prior\nassumptions. Our results demonstrate that Genetic Programming is particularly\nwell suited to this type of feature construction because it can automatically\nsynthesize appropriate aggregations, as well as better incorporate them into\npredictive models compared to other regression methods we tested. In our\nexperiments we consider a specific problem instance and real-world dataset\nrelevant to predicting snow properties in high-mountain Asia.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 01:25:12 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 17:42:18 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Kriegman", "Sam", ""], ["Szubert", "Marcin", ""], ["Bongard", "Josh C.", ""], ["Skalka", "Christian", ""]]}, {"id": "1706.08231", "submitter": "Li Su", "authors": "Li Su", "title": "Between Homomorphic Signal Processing and Deep Neural Networks:\n  Constructing Deep Algorithms for Polyphonic Music Transcription", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach in understanding how deep neural networks\n(DNNs) work by applying homomorphic signal processing techniques. Focusing on\nthe task of multi-pitch estimation (MPE), this paper demonstrates the\nequivalence relation between a generalized cepstrum and a DNN in terms of their\nstructures and functionality. Such an equivalence relation, together with pitch\nperception theories and the recently established\nrectified-correlations-on-a-sphere (RECOS) filter analysis, provide an\nalternative way in explaining the role of the nonlinear activation function and\nthe multi-layer structure, both of which exist in a cepstrum and a DNN. To\nvalidate the efficacy of this new approach, a new feature designed in the same\nfashion is proposed for pitch salience function. The new feature outperforms\nthe one-layer spectrum in the MPE task and, as predicted, it addresses the\nissue of the missing fundamental effect and also achieves better robustness to\nnoise.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 04:57:06 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Su", "Li", ""]]}, {"id": "1706.08493", "submitter": "Filipe Assun\\c{c}\\~ao", "authors": "Filipe Assun\\c{c}\\~ao, Nuno Louren\\c{c}o, Penousal Machado, Bernardete\n  Ribeiro", "title": "Towards the Evolution of Multi-Layered Neural Networks: A Dynamic\n  Structured Grammatical Evolution Approach", "comments": null, "journal-ref": null, "doi": "10.1145/3071178.3071286", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current grammar-based NeuroEvolution approaches have several shortcomings. On\nthe one hand, they do not allow the generation of Artificial Neural Networks\n(ANNs composed of more than one hidden-layer. On the other, there is no way to\nevolve networks with more than one output neuron. To properly evolve ANNs with\nmore than one hidden-layer and multiple output nodes there is the need to know\nthe number of neurons available in previous layers. In this paper we introduce\nDynamic Structured Grammatical Evolution (DSGE): a new genotypic representation\nthat overcomes the aforementioned limitations. By enabling the creation of\ndynamic rules that specify the connection possibilities of each neuron, the\nmethodology enables the evolution of multi-layered ANNs with more than one\noutput neuron. Results in different classification problems show that DSGE\nevolves effective single and multi-layered ANNs, with a varying number of\noutput neurons.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:34:14 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Assun\u00e7\u00e3o", "Filipe", ""], ["Louren\u00e7o", "Nuno", ""], ["Machado", "Penousal", ""], ["Ribeiro", "Bernardete", ""]]}, {"id": "1706.08498", "submitter": "Matus Telgarsky", "authors": "Peter Bartlett, Dylan J. Foster, Matus Telgarsky", "title": "Spectrally-normalized margin bounds for neural networks", "comments": "Comparison to arXiv v1: 1-norm in main bound refined to\n  (2,1)-group-norm. Comparison to NIPS camera ready: typo fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a margin-based multiclass generalization bound for neural\nnetworks that scales with their margin-normalized \"spectral complexity\": their\nLipschitz constant, meaning the product of the spectral norms of the weight\nmatrices, times a certain correction factor. This bound is empirically\ninvestigated for a standard AlexNet network trained with SGD on the mnist and\ncifar10 datasets, with both original and random labels; the bound, the\nLipschitz constants, and the excess risks are all in direct correlation,\nsuggesting both that SGD selects predictors whose complexity scales with the\ndifficulty of the learning task, and secondly that the presented bound is\nsensitive to this complexity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 17:43:48 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 06:08:38 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Bartlett", "Peter", ""], ["Foster", "Dylan J.", ""], ["Telgarsky", "Matus", ""]]}, {"id": "1706.08568", "submitter": "Georg Wiese", "authors": "Georg Wiese, Dirk Weissenborn, Mariana Neves", "title": "Neural Question Answering at BioASQ 5B", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our submission to the 2017 BioASQ challenge. We\nparticipated in Task B, Phase B which is concerned with biomedical question\nanswering (QA). We focus on factoid and list question, using an extractive QA\nmodel, that is, we restrict our system to output substrings of the provided\ntext snippets. At the core of our system, we use FastQA, a state-of-the-art\nneural QA system. We extended it with biomedical word embeddings and changed\nits answer layer to be able to answer list questions in addition to factoid\nquestions. We pre-trained the model on a large-scale open-domain QA dataset,\nSQuAD, and then fine-tuned the parameters on the BioASQ training set. With our\napproach, we achieve state-of-the-art results on factoid questions and\ncompetitive results on list questions.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 19:14:10 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Wiese", "Georg", ""], ["Weissenborn", "Dirk", ""], ["Neves", "Mariana", ""]]}, {"id": "1706.08675", "submitter": "Dorien Herremans", "authors": "Dorien Herremans, Ching-Hua Chuan", "title": "Proceedings of the First International Workshop on Deep Learning and\n  Music", "comments": null, "journal-ref": "Proceedings of the First International Workshop on Deep Learning\n  and Music, joint with IJCNN, Anchorage, US, May 17-18, 2017", "doi": "10.13140/RG.2.2.22227.99364/1", "report-no": null, "categories": "cs.NE cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proceedings of the First International Workshop on Deep Learning and Music,\njoint with IJCNN, Anchorage, US, May 17-18, 2017\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 05:28:06 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Herremans", "Dorien", ""], ["Chuan", "Ching-Hua", ""]]}, {"id": "1706.08700", "submitter": "Claudio Sanhueza", "authors": "Claudio Sanhueza, Francia Jimenez, Regina Berretta, and Pablo Moscato", "title": "PasMoQAP: A Parallel Asynchronous Memetic Algorithm for solving the\n  Multi-Objective Quadratic Assignment Problem", "comments": "8 pages, 3 figures, 2 tables. Accepted at Conference on Evolutionary\n  Computation 2017 (CEC 2017)", "journal-ref": null, "doi": "10.1109/CEC.2017.7969430", "report-no": null, "categories": "cs.NE cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-Objective Optimization Problems (MOPs) have attracted growing attention\nduring the last decades. Multi-Objective Evolutionary Algorithms (MOEAs) have\nbeen extensively used to address MOPs because are able to approximate a set of\nnon-dominated high-quality solutions. The Multi-Objective Quadratic Assignment\nProblem (mQAP) is a MOP. The mQAP is a generalization of the classical QAP\nwhich has been extensively studied, and used in several real-life applications.\nThe mQAP is defined as having as input several flows between the facilities\nwhich generate multiple cost functions that must be optimized simultaneously.\nIn this study, we propose PasMoQAP, a parallel asynchronous memetic algorithm\nto solve the Multi-Objective Quadratic Assignment Problem. PasMoQAP is based on\nan island model that structures the population by creating sub-populations. The\nmemetic algorithm on each island individually evolve a reduced population of\nsolutions, and they asynchronously cooperate by sending selected solutions to\nthe neighboring islands. The experimental results show that our approach\nsignificatively outperforms all the island-based variants of the\nmulti-objective evolutionary algorithm NSGA-II. We show that PasMoQAP is a\nsuitable alternative to solve the Multi-Objective Quadratic Assignment Problem.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 07:42:31 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Sanhueza", "Claudio", ""], ["Jimenez", "Francia", ""], ["Berretta", "Regina", ""], ["Moscato", "Pablo", ""]]}, {"id": "1706.08884", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi and Rachid Guerraoui", "title": "When Neurons Fail", "comments": "2017 IEEE International Parallel and Distributed Processing\n  Symposium, Orlando, Florida", "journal-ref": null, "doi": "10.1109/IPDPS.2017.66", "report-no": null, "categories": "stat.ML cs.DC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view a neural network as a distributed system of which neurons can fail\nindependently, and we evaluate its robustness in the absence of any (recovery)\nlearning phase. We give tight bounds on the number of neurons that can fail\nwithout harming the result of a computation. To determine our bounds, we\nleverage the fact that neural activation functions are Lipschitz-continuous.\nOur bound is on a quantity, we call the \\textit{Forward Error Propagation},\ncapturing how much error is propagated by a neural network when a given number\nof components is failing, computing this quantity only requires looking at the\ntopology of the network, while experimentally assessing the robustness of a\nnetwork requires the costly experiment of looking at all the possible inputs\nand testing all the possible configurations of the network corresponding to\ndifferent failure situations, facing a discouraging combinatorial explosion.\n  We distinguish the case of neurons that can fail and stop their activity\n(crashed neurons) from the case of neurons that can fail by transmitting\narbitrary values (Byzantine neurons). Interestingly, as we show in the paper,\nour bound can easily be extended to the case where synapses can fail.\n  We show how our bound can be leveraged to quantify the effect of memory cost\nreduction on the accuracy of a neural network, to estimate the amount of\ninformation any neuron needs from its preceding layer, enabling thereby a\nboosting scheme that prevents neurons from waiting for unnecessary signals. We\nfinally discuss the trade-off between neural networks robustness and learning\ncost.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 14:31:09 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""]]}, {"id": "1706.08915", "submitter": "Daniele Bellutta", "authors": "Daniele Bellutta", "title": "The Fog of War: A Machine Learning Approach to Forecasting Weather on\n  Mars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For over a decade, scientists at NASA's Jet Propulsion Laboratory (JPL) have\nbeen recording measurements from the Martian surface as a part of the Mars\nExploration Rovers mission. One quantity of interest has been the opacity of\nMars's atmosphere for its importance in day-to-day estimations of the amount of\npower available to the rover from its solar arrays. This paper proposes the use\nof neural networks as a method for forecasting Martian atmospheric opacity that\nis more effective than the current empirical model. The more accurate\nprediction provided by these networks would allow operators at JPL to make more\naccurate predictions of the amount of energy available to the rover when they\nplan activities for coming sols.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 05:05:00 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Bellutta", "Daniele", ""]]}, {"id": "1706.08921", "submitter": "Giuseppe Pica", "authors": "Giuseppe Pica, Eugenio Piasini, Daniel Chicharro, Stefano Panzeri", "title": "Invariant components of synergy, redundancy, and unique information\n  among three variables", "comments": null, "journal-ref": "Entropy 2017, 19(9), 451", "doi": "10.3390/e19090451", "report-no": null, "categories": "cs.IT cs.NE math.IT math.ST physics.bio-ph physics.data-an stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a system of three stochastic variables, the Partial Information\nDecomposition (PID) of Williams and Beer dissects the information that two\nvariables (sources) carry about a third variable (target) into nonnegative\ninformation atoms that describe redundant, unique, and synergistic modes of\ndependencies among the variables. However, the classification of the three\nvariables into two sources and one target limits the dependency modes that can\nbe quantitatively resolved, and does not naturally suit all systems. Here, we\nextend the PID to describe trivariate modes of dependencies in full generality,\nwithout introducing additional decomposition axioms or making assumptions about\nthe target/source nature of the variables. By comparing different PID lattices\nof the same system, we unveil a finer PID structure made of seven nonnegative\ninformation subatoms that are invariant to different target/source\nclassifications and that are sufficient to construct any PID lattice. This\nfiner structure naturally splits redundant information into two nonnegative\ncomponents: the source redundancy, which arises from the pairwise correlations\nbetween the source variables, and the non-source redundancy, which does not,\nand relates to the synergistic information the sources carry about the target.\nThe invariant structure is also sufficient to construct the system's entropy,\nhence it characterizes completely all the interdependencies in the system.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 16:09:37 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Pica", "Giuseppe", ""], ["Piasini", "Eugenio", ""], ["Chicharro", "Daniel", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1706.09088", "submitter": "Dorien Herremans", "authors": "Dorien Herremans, Ching-Hua Chuan", "title": "Modeling Musical Context with Word2vec", "comments": "Proceedings of the First International Conference on Deep Learning\n  and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])", "journal-ref": "Proceedings of the First International Workshop on Deep Learning\n  and Music joint with IJCNN. Anchorage, US. 1(1). pp 11-18 (2017)", "doi": null, "report-no": "DLM/2017/1", "categories": "cs.SD cs.IR cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a semantic vector space model for capturing complex polyphonic\nmusical context. A word2vec model based on a skip-gram representation with\nnegative sampling was used to model slices of music from a dataset of\nBeethoven's piano sonatas. A visualization of the reduced vector space using\nt-distributed stochastic neighbor embedding shows that the resulting embedded\nvector space captures tonal relationships, even without any explicit\ninformation about the musical contents of the slices. Secondly, an excerpt of\nthe Moonlight Sonata from Beethoven was altered by replacing slices based on\ncontext similarity. The resulting music shows that the selected slice based on\nsimilar word2vec context also has a relatively short tonal distance from the\noriginal slice.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 00:46:50 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 02:33:06 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Herremans", "Dorien", ""], ["Chuan", "Ching-Hua", ""]]}, {"id": "1706.09262", "submitter": "Adam Kosiorek", "authors": "Adam R. Kosiorek, Alex Bewley, Ingmar Posner", "title": "Hierarchical Attentive Recurrent Tracking", "comments": "Published as a conference paper at NIPS 2017. Code is available at\n  https://github.com/akosiorek/hart and qualitative results are available at\n  https://youtu.be/Vvkjm0FRGSs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-agnostic object tracking is particularly difficult in cluttered\nenvironments as target specific discriminative models cannot be learned a\npriori. Inspired by how the human visual cortex employs spatial attention and\nseparate \"where\" and \"what\" processing pathways to actively suppress irrelevant\nvisual features, this work develops a hierarchical attentive recurrent model\nfor single object tracking in videos. The first layer of attention discards the\nmajority of background by selecting a region containing the object of interest,\nwhile the subsequent layers tune in on visual features particular to the\ntracked object. This framework is fully differentiable and can be trained in a\npurely data driven fashion by gradient methods. To improve training\nconvergence, we augment the loss function with terms for a number of auxiliary\ntasks relevant for tracking. Evaluation of the proposed model is performed on\ntwo datasets: pedestrian tracking on the KTH activity recognition dataset and\nthe more difficult KITTI object tracking dataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 13:00:14 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 14:35:08 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Kosiorek", "Adam R.", ""], ["Bewley", "Alex", ""], ["Posner", "Ingmar", ""]]}, {"id": "1706.09551", "submitter": "Andrew Pfalz", "authors": "A. Pfalz, E. Berdahl", "title": "Toward Inverse Control of Physics-Based Sound Synthesis", "comments": "Proceedings of the First International Conference on Deep Learning\n  and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])", "journal-ref": "Proceedings of the First International Workshop on Deep Learning\n  and Music joint with IJCNN, 1(1). pp 56-61 (2017)", "doi": null, "report-no": "DLM/2017/7", "categories": "cs.SD cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long Short-Term Memory networks (LSTMs) can be trained to realize inverse\ncontrol of physics-based sound synthesizers. Physics-based sound synthesizers\nsimulate the laws of physics to produce output sound according to input gesture\nsignals. When a user's gestures are measured in real time, she or he can use\nthem to control physics-based sound synthesizers, thereby creating simulated\nvirtual instruments. An intriguing question is how to program a computer to\nlearn to play such physics-based models. This work demonstrates that LSTMs can\nbe trained to accomplish this inverse control task with four physics-based\nsound synthesizers.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 02:33:56 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Pfalz", "A.", ""], ["Berdahl", "E.", ""]]}, {"id": "1706.09552", "submitter": "Hendrik Vincent Koops", "authors": "H.V. Koops, W.B. de Haas, J. Bransen, A. Volk", "title": "Chord Label Personalization through Deep Learning of Integrated Harmonic\n  Interval-based Representations", "comments": "Proceedings of the First International Conference on Deep Learning\n  and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])", "journal-ref": "Proc. of the Int. Workshop on Deep Learning and Music. Anchorage,\n  US. 1(1). pp19-25 (2017)", "doi": null, "report-no": "DLM/2017/2", "categories": "cs.SD cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing accuracy of automatic chord estimation systems, the\navailability of vast amounts of heterogeneous reference annotations, and\ninsights from annotator subjectivity research make chord label personalization\nincreasingly important. Nevertheless, automatic chord estimation systems are\nhistorically exclusively trained and evaluated on a single reference\nannotation. We introduce a first approach to automatic chord label\npersonalization by modeling subjectivity through deep learning of a harmonic\ninterval-based chord label representation. After integrating these\nrepresentations from multiple annotators, we can accurately personalize chord\nlabels for individual annotators from a single model and the annotators' chord\nlabel vocabulary. Furthermore, we show that chord personalization using\nmultiple reference annotations outperforms using a single reference annotation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 02:38:02 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Koops", "H. V.", ""], ["de Haas", "W. B.", ""], ["Bransen", "J.", ""], ["Volk", "A.", ""]]}, {"id": "1706.09553", "submitter": "Shija Geng", "authors": "S. Geng, G. Ren, M. Ogihara", "title": "Transforming Musical Signals through a Genre Classifying Convolutional\n  Neural Network", "comments": "Proceedings of the First International Conference on Deep Learning\n  and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])", "journal-ref": "Proc. of the First Int. Workshop on Deep Learning and Music joint\n  with IJCNN. Anchorage, US. 1(1). pp 48-49 (2017)", "doi": null, "report-no": "DLM/2017/4", "categories": "cs.SD cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have been successfully applied on both\ndiscriminative and generative modeling for music-related tasks. For a\nparticular task, the trained CNN contains information representing the decision\nmaking or the abstracting process. One can hope to manipulate existing music\nbased on this 'informed' network and create music with new features\ncorresponding to the knowledge obtained by the network. In this paper, we\npropose a method to utilize the stored information from a CNN trained on\nmusical genre classification task. The network was composed of three\nconvolutional layers, and was trained to classify five-second song clips into\nfive different genres. After training, randomly selected clips were modified by\nmaximizing the sum of outputs from the network layers. In addition to the\npotential of such CNNs to produce interesting audio transformation, more\ninformation about the network and the original music could be obtained from the\nanalysis of the generated features since these features indicate how the\nnetwork 'understands' the music.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 02:39:00 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Geng", "S.", ""], ["Ren", "G.", ""], ["Ogihara", "M.", ""]]}, {"id": "1706.09555", "submitter": "Zhe-Cheng Fan", "authors": "Z.C. Fan, T.S. Chan, Y.H. Yang, and J.S. R. Jang", "title": "Music Signal Processing Using Vector Product Neural Networks", "comments": "Proceedings of the First International Conference on Deep Learning\n  and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])", "journal-ref": "Proc. of the First Int. Workshop on Deep Learning and Music joint\n  with IJCNN. Anchorage, US. 1(1). pp 36-30 (2017)", "doi": null, "report-no": "DLM/2017/5", "categories": "cs.SD cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural network model for music signal processing using\nvector product neurons and dimensionality transformations. Here, the inputs are\nfirst mapped from real values into three-dimensional vectors then fed into a\nthree-dimensional vector product neural network where the inputs, outputs, and\nweights are all three-dimensional values. Next, the final outputs are mapped\nback to the reals. Two methods for dimensionality transformation are proposed,\none via context windows and the other via spectral coloring. Experimental\nresults on the iKala dataset for blind singing voice separation confirm the\nefficacy of our model.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 02:41:30 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Fan", "Z. C.", ""], ["Chan", "T. S.", ""], ["Yang", "Y. H.", ""], ["Jang", "J. S. R.", ""]]}, {"id": "1706.09556", "submitter": "Alessio Bazzica", "authors": "A. Bazzica, J.C. van Gemert, C.C.S. Liem, A. Hanjalic", "title": "Vision-based Detection of Acoustic Timed Events: a Case Study on\n  Clarinet Note Onsets", "comments": "Proceedings of the First International Conference on Deep Learning\n  and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])", "journal-ref": "Proc of the First Int Workshop on Deep Learning and Music.\n  Anchorage, US. 1(1). pp 31-36 (2017)", "doi": null, "report-no": "DLM/2017/8", "categories": "cs.NE cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acoustic events often have a visual counterpart. Knowledge of visual\ninformation can aid the understanding of complex auditory scenes, even when\nonly a stereo mixdown is available in the audio domain, \\eg identifying which\nmusicians are playing in large musical ensembles. In this paper, we consider a\nvision-based approach to note onset detection. As a case study we focus on\nchallenging, real-world clarinetist videos and carry out preliminary\nexperiments on a 3D convolutional neural network based on multiple streams and\npurposely avoiding temporal pooling. We release an audiovisual dataset with 4.5\nhours of clarinetist videos together with cleaned annotations which include\nabout 36,000 onsets and the coordinates for a number of salient points and\nregions of interest. By performing several training trials on our dataset, we\nlearned that the problem is challenging. We found that the CNN model is highly\nsensitive to the optimization algorithm and hyper-parameters, and that treating\nthe problem as binary classification may prevent the joint optimization of\nprecision and recall. To encourage further research, we publicly share our\ndataset, annotations and all models and detail which issues we came across\nduring our preliminary experiments.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 02:43:37 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Bazzica", "A.", ""], ["van Gemert", "J. C.", ""], ["Liem", "C. C. S.", ""], ["Hanjalic", "A.", ""]]}, {"id": "1706.09558", "submitter": "Patrick Hutchings", "authors": "P. Hutchings", "title": "Talking Drums: Generating drum grooves with neural networks", "comments": "Proceedings of the First International Conference on Deep Learning\n  and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])", "journal-ref": "Proceedings of the First International Workshop on Deep Learning\n  and Music joint with IJCNN. Anchorage, US. 1(1). pp 43-47 (2017)", "doi": null, "report-no": "DLM/2017/3", "categories": "cs.SD cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presented is a method of generating a full drum kit part for a provided\nkick-drum sequence. A sequence to sequence neural network model used in natural\nlanguage translation was adopted to encode multiple musical styles and an\nonline survey was developed to test different techniques for sampling the\noutput of the softmax function. The strongest results were found using a\nsampling technique that drew from the three most probable outputs at each\nsubdivision of the drum pattern but the consistency of output was found to be\nheavily dependent on style.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 03:03:35 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Hutchings", "P.", ""]]}, {"id": "1706.09559", "submitter": "Lonce Wyse", "authors": "L. Wyse", "title": "Audio Spectrogram Representations for Processing with Convolutional\n  Neural Networks", "comments": "Proceedings of the First International Conference on Deep Learning\n  and Music, Anchorage, US, May, 2017 (arXiv:1706.08675v1 [cs.NE])", "journal-ref": "Proceedings of the First International Workshop on Deep Learning\n  and Music joint with IJCNN. Anchorage, US. 1(1). pp 37-41 (2017)", "doi": null, "report-no": "DLM/2017/9", "categories": "cs.SD cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the decisions that arise when designing a neural network for any\napplication is how the data should be represented in order to be presented to,\nand possibly generated by, a neural network. For audio, the choice is less\nobvious than it seems to be for visual images, and a variety of representations\nhave been used for different applications including the raw digitized sample\nstream, hand-crafted features, machine discovered features, MFCCs and variants\nthat include deltas, and a variety of spectral representations. This paper\nreviews some of these representations and issues that arise, focusing\nparticularly on spectrograms for generating audio using neural networks for\nstyle transfer.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 03:04:06 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Wyse", "L.", ""]]}, {"id": "1706.09648", "submitter": "Riccardo Bonettor Ph.D.", "authors": "Riccardo Bonetto, Michele Rossi", "title": "Machine Learning Approaches to Energy Consumption Forecasting in\n  Households", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of power demand forecasting in residential\nmicro-grids. Several approaches using ARMA models, support vector machines, and\nrecurrent neural networks that perform one-step ahead predictions have been\nproposed in the literature. Here, we extend them to perform multi-step ahead\nforecasting and we compare their performance. Toward this end, we implement a\nparallel and efficient training framework, using power demand traces from real\ndeployments to gauge the accuracy of the considered techniques. Our results\nindicate that machine learning schemes achieve smaller prediction errors in the\nmean and the variance with respect to ARMA, but there is no clear algorithm of\nchoice among them. Pros and cons of these approaches are discussed and the\nsolution of choice is found to depend on the specific use case requirements. A\nhybrid approach, that is driven by the prediction interval, the target error,\nand its uncertainty, is then recommended.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 09:36:45 GMT"}], "update_date": "2017-06-30", "authors_parsed": [["Bonetto", "Riccardo", ""], ["Rossi", "Michele", ""]]}, {"id": "1706.09667", "submitter": "Maxinder S. Kanwal", "authors": "Maxinder S. Kanwal, Joshua A. Grochow, Nihat Ay", "title": "Comparing Information-Theoretic Measures of Complexity in Boltzmann\n  Machines", "comments": "16 pages, 7 figures; Appears in Entropy, Special Issue \"Information\n  Geometry II\"", "journal-ref": "Entropy (2017), 19(7), 310", "doi": "10.3390/e19070310", "report-no": null, "categories": "cs.IT cs.NE math.IT q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past three decades, many theoretical measures of complexity have been\nproposed to help understand complex systems. In this work, for the first time,\nwe place these measures on a level playing field, to explore the qualitative\nsimilarities and differences between them, and their shortcomings.\nSpecifically, using the Boltzmann machine architecture (a fully connected\nrecurrent neural network) with uniformly distributed weights as our model of\nstudy, we numerically measure how complexity changes as a function of network\ndynamics and network parameters. We apply an extension of one such\ninformation-theoretic measure of complexity to understand incremental Hebbian\nlearning in Hopfield networks, a fully recurrent architecture model of\nautoassociative memory. In the course of Hebbian learning, the total\ninformation flow reflects a natural upward trend in complexity as the network\nattempts to learn more and more patterns.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 10:39:15 GMT"}, {"version": "v2", "created": "Sun, 30 Jul 2017 01:01:49 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Kanwal", "Maxinder S.", ""], ["Grochow", "Joshua A.", ""], ["Ay", "Nihat", ""]]}]