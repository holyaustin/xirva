[{"id": "1103.0087", "submitter": "Ephzibah  Ep", "authors": "E.P.Ephzibah", "title": "Cost effective approach on feature selection using genetic algorithms\n  and fuzzy logic for diabetes diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A way to enhance the performance of a model that combines genetic algorithms\nand fuzzy logic for feature selection and classification is proposed. Early\ndiagnosis of any disease with less cost is preferable. Diabetes is one such\ndisease. Diabetes has become the fourth leading cause of death in developed\ncountries and there is substantial evidence that it is reaching epidemic\nproportions in many developing and newly industrialized nations. In medical\ndiagnosis, patterns consist of observable symptoms along with the results of\ndiagnostic tests. These tests have various associated costs and risks. In the\nautomated design of pattern classification, the proposed system solves the\nfeature subset selection problem. It is a task of identifying and selecting a\nuseful subset of pattern-representing features from a larger set of features.\nUsing fuzzy rule-based classification system, the proposed system proves to\nimprove the classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2011 06:10:18 GMT"}], "update_date": "2011-03-02", "authors_parsed": [["Ephzibah", "E. P.", ""]]}, {"id": "1103.0365", "submitter": "Pradeep", "authors": "J. Pradeep, E. Srinivasan and S. Himavathi", "title": "Diagonal Based Feature Extraction for Handwritten Alphabets Recognition\n  System using Neural Network", "comments": null, "journal-ref": null, "doi": "10.5121/ijcsit.2011.3103", "report-no": null, "categories": "stat.CO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An off-line handwritten alphabetical character recognition system using\nmultilayer feed forward neural network is described in the paper. A new method,\ncalled, diagonal based feature extraction is introduced for extracting the\nfeatures of the handwritten alphabets. Fifty data sets, each containing 26\nalphabets written by various people, are used for training the neural network\nand 570 different handwritten alphabetical characters are used for testing. The\nproposed recognition system performs quite well yielding higher levels of\nrecognition accuracy compared to the systems employing the conventional\nhorizontal and vertical methods of feature extraction. This system will be\nsuitable for converting handwritten documents into structural text form and\nrecognizing handwritten names.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2011 08:48:21 GMT"}], "update_date": "2011-03-03", "authors_parsed": [["Pradeep", "J.", ""], ["Srinivasan", "E.", ""], ["Himavathi", "S.", ""]]}, {"id": "1103.1156", "submitter": "Farnood Merrikh-Bayat", "authors": "Farnood Merrikh-Bayat and Saeed Bagheri-Shouraki", "title": "Efficient neuro-fuzzy system and its Memristor Crossbar-based Hardware\n  Implementation", "comments": "34 pages, 14 figures, Submitted to IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a novel neuro-fuzzy system is proposed where its learning is\nbased on the creation of fuzzy relations by using new implication method\nwithout utilizing any exact mathematical techniques. Then, a simple memristor\ncrossbar-based analog circuit is designed to implement this neuro-fuzzy system\nwhich offers very interesting properties. In addition to high connectivity\nbetween neurons and being fault-tolerant, all synaptic weights in our proposed\nmethod are always non-negative and there is no need to precisely adjust them.\nFinally, this structure is hierarchically expandable and can compute operations\nin real time since it is implemented through analog circuits. Simulation\nresults show the efficiency and applicability of our neuro-fuzzy computing\nsystem. They also indicate that this system can be a good candidate to be used\nfor creating artificial brain.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2011 18:52:05 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Merrikh-Bayat", "Farnood", ""], ["Bagheri-Shouraki", "Saeed", ""]]}, {"id": "1103.2110", "submitter": "Martin Aruldoss Mr", "authors": "A.Martin, V.Gayathri, G.Saranya, P.Gayathri, Prasanna Venkatesan", "title": "A hybrid model for bankruptcy prediction using genetic algorithm, fuzzy\n  c-means and mars", "comments": "Bankruptcy prediction, financial ratio models, Genetic Algorithm,\n  Fuzzy c-means Clustering, MARS", "journal-ref": "International Journal on Soft Computing (IJSC), Vol.2, No.1,\n  February 2011", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bankruptcy prediction is very important for all the organization since it\naffects the economy and rise many social problems with high costs. There are\nlarge number of techniques have been developed to predict the bankruptcy, which\nhelps the decision makers such as investors and financial analysts. One of the\nbankruptcy prediction models is the hybrid model using Fuzzy C-means clustering\nand MARS, which uses static ratios taken from the bank financial statements for\nprediction, which has its own theoretical advantages. The performance of\nexisting bankruptcy model can be improved by selecting the best features\ndynamically depend on the nature of the firm. This dynamic selection can be\naccomplished by Genetic Algorithm and it improves the performance of prediction\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2011 09:57:25 GMT"}], "update_date": "2011-03-11", "authors_parsed": [["Martin", "A.", ""], ["Gayathri", "V.", ""], ["Saranya", "G.", ""], ["Gayathri", "P.", ""], ["Venkatesan", "Prasanna", ""]]}, {"id": "1103.2741", "submitter": "Prerana Laddha", "authors": "Prerana Laddha", "title": "Memory Retrieval in the B-Matrix Neural Network", "comments": "8 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an extension to the memory retrieval procedure of the B-Matrix\napproach [6],[17] to neural network learning. The B-Matrix is a part of the\ninterconnection matrix generated from the Hebbian neural network, and in memory\nretrieval, the B-matrix is clamped with a small fragment of the memory. The\nfragment gradually enlarges by means of feedback, until the entire vector is\nobtained. In this paper, we propose the use of delta learning to enhance the\nretrieval rate of the stored memories.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2011 18:58:59 GMT"}], "update_date": "2011-03-15", "authors_parsed": [["Laddha", "Prerana", ""]]}, {"id": "1103.4487", "submitter": "Dan Ciresan", "authors": "Dan C. Cire\\c{s}an, Ueli Meier, Luca M. Gambardella and J\\\"urgen\n  Schmidhuber", "title": "Handwritten Digit Recognition with a Committee of Deep Neural Nets on\n  GPUs", "comments": "9 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "IDSIA-03-11", "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The competitive MNIST handwritten digit recognition benchmark has a long\nhistory of broken records since 1998. The most recent substantial improvement\nby others dates back 7 years (error rate 0.4%) . Recently we were able to\nsignificantly improve this result, using graphics cards to greatly speed up\ntraining of simple but deep MLPs, which achieved 0.35%, outperforming all the\nprevious more complex methods. Here we report another substantial improvement:\n0.31% obtained using a committee of MLPs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2011 10:38:50 GMT"}], "update_date": "2011-03-24", "authors_parsed": [["Cire\u015fan", "Dan C.", ""], ["Meier", "Ueli", ""], ["Gambardella", "Luca M.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1103.4820", "submitter": "Alexandru-Adrian Tantar", "authors": "Alexandru-Adrian Tantar, Emilia Tantar, Pascal Bouvry", "title": "Design and classification of dynamic multi-objective optimization\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we provide a formal model for the different time-dependent\ncomponents that can appear in dynamic multi-objective optimization problems,\nalong with a classification of these components. Four main classes are\nidentified, corresponding to the influence of the parameters, objective\nfunctions, previous states of the dynamic system and, last, environment\nchanges, which in turn lead to online optimization problems. For illustration\npurposes, examples are provided for each class identified - by no means\nstanding as the most representative ones or exhaustive in scope.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2011 17:59:10 GMT"}], "update_date": "2011-03-25", "authors_parsed": [["Tantar", "Alexandru-Adrian", ""], ["Tantar", "Emilia", ""], ["Bouvry", "Pascal", ""]]}, {"id": "1103.4904", "submitter": "Vitaly Feldman", "authors": "Vitaly Feldman", "title": "Distribution-Independent Evolvability of Linear Threshold Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Valiant's (2007) model of evolvability models the evolutionary process of\nacquiring useful functionality as a restricted form of learning from random\nexamples. Linear threshold functions and their various subclasses, such as\nconjunctions and decision lists, play a fundamental role in learning theory and\nhence their evolvability has been the primary focus of research on Valiant's\nframework (2007). One of the main open problems regarding the model is whether\nconjunctions are evolvable distribution-independently (Feldman and Valiant,\n2008). We show that the answer is negative. Our proof is based on a new\ncombinatorial parameter of a concept class that lower-bounds the complexity of\nlearning from correlations.\n  We contrast the lower bound with a proof that linear threshold functions\nhaving a non-negligible margin on the data points are evolvable\ndistribution-independently via a simple mutation algorithm. Our algorithm\nrelies on a non-linear loss function being used to select the hypotheses\ninstead of 0-1 loss in Valiant's (2007) original definition. The proof of\nevolvability requires that the loss function satisfies several mild conditions\nthat are, for example, satisfied by the quadratic loss function studied in\nseveral other works (Michael, 2007; Feldman, 2009; Valiant, 2010). An important\nproperty of our evolution algorithm is monotonicity, that is the algorithm\nguarantees evolvability without any decreases in performance. Previously,\nmonotone evolvability was only shown for conjunctions with quadratic loss\n(Feldman, 2009) or when the distribution on the domain is severely restricted\n(Michael, 2007; Feldman, 2009; Kanade et al., 2010)\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 04:34:42 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Feldman", "Vitaly", ""]]}, {"id": "1103.5081", "submitter": "Praveen Kuruvada", "authors": "Praveen Kuruvada", "title": "Using Variable Threshold to Increase Capacity in a Feedback Neural\n  Network", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents new results on the use of variable thresholds to\nincrease the capacity of a feedback neural network. Non-binary networks are\nalso considered in this analysis.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 20:59:13 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2011 21:32:26 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Kuruvada", "Praveen", ""]]}, {"id": "1103.5797", "submitter": "Markus Wagner", "authors": "Markus Wagner, Frank Neumann", "title": "Computational Complexity Results for Genetic Programming and the Sorting\n  Problem", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic Programming (GP) has found various applications. Understanding this\ntype of algorithm from a theoretical point of view is a challenging task. The\nfirst results on the computational complexity of GP have been obtained for\nproblems with isolated program semantics. With this paper, we push forward the\ncomputational complexity analysis of GP on a problem with dependent program\nsemantics. We study the well-known sorting problem in this context and analyze\nrigorously how GP can deal with different measures of sortedness.\n", "versions": [{"version": "v1", "created": "Tue, 29 Mar 2011 23:52:30 GMT"}, {"version": "v2", "created": "Fri, 6 May 2011 06:07:01 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Wagner", "Markus", ""], ["Neumann", "Frank", ""]]}]