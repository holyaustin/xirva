[{"id": "1612.00155", "submitter": "Pedro Tabacof", "authors": "Pedro Tabacof, Julia Tavares, Eduardo Valle", "title": "Adversarial Images for Variational Autoencoders", "comments": "Workshop on Adversarial Training, NIPS 2016, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate adversarial attacks for autoencoders. We propose a procedure\nthat distorts the input image to mislead the autoencoder in reconstructing a\ncompletely different target image. We attack the internal latent\nrepresentations, attempting to make the adversarial input produce an internal\nrepresentation as similar as possible as the target's. We find that\nautoencoders are much more robust to the attack than classifiers: while some\nexamples have tolerably small input distortion, and reasonable similarity to\nthe target image, there is a quasi-linear trade-off between those aims. We\nreport results on MNIST and SVHN datasets, and also test regular deterministic\nautoencoders, reaching similar conclusions in all cases. Finally, we show that\nthe usual adversarial attack for classifiers, while being much easier, also\npresents a direct proportion between distortion on the input, and misdirection\non the output. That proportionality however is hidden by the normalization of\nthe output, which maps a linear layer into non-linear probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 05:59:57 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Tabacof", "Pedro", ""], ["Tavares", "Julia", ""], ["Valle", "Eduardo", ""]]}, {"id": "1612.00369", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "New Ideas for Brain Modelling 3", "comments": null, "journal-ref": "Cognitive Systems Research, Vol. 55, pp. 1-13, 2019, Elsevier", "doi": "10.1016/j.cogsys.2018.12.016.", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a process for the creation and subsequent firing of\nsequences of neuronal patterns, as might be found in the human brain. The scale\nis one of larger patterns emerging from an ensemble mass, possibly through some\ntype of energy equation and a reduction procedure. The links between the\npatterns can be formed naturally, as a residual effect of the pattern creation\nitself. This paper follows-on closely from the earlier research, including two\nearlier papers in the series and uses the ideas of entropy and cohesion. With a\nsmall addition, it is possible to show how the inter-pattern links can be\ndetermined. A compact Grid form of an earlier Counting Mechanism is also\ndemonstrated and may be a new clustering technique. It is possible to explain\nhow a very basic repeating structure can form the arbitrary patterns and\nactivation sequences between them, and a key question of how nodes synchronise\nmay even be answerable.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 09:01:16 GMT"}, {"version": "v2", "created": "Sun, 29 Jan 2017 10:42:59 GMT"}, {"version": "v3", "created": "Tue, 14 Feb 2017 15:03:26 GMT"}, {"version": "v4", "created": "Thu, 23 Mar 2017 12:39:28 GMT"}, {"version": "v5", "created": "Fri, 16 Jun 2017 08:09:52 GMT"}, {"version": "v6", "created": "Thu, 7 Dec 2017 13:34:35 GMT"}, {"version": "v7", "created": "Thu, 1 Mar 2018 08:04:53 GMT"}, {"version": "v8", "created": "Mon, 17 Sep 2018 10:58:59 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1612.00377", "submitter": "Iulian Vlad Serban", "authors": "Iulian V. Serban, Alexander G. Ororbia II, Joelle Pineau, Aaron\n  Courville", "title": "Piecewise Latent Variables for Neural Variational Text Processing", "comments": "19 pages, 2 figures, 8 tables; EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in neural variational inference have facilitated the learning of\npowerful directed graphical models with continuous latent variables, such as\nvariational autoencoders. The hope is that such models will learn to represent\nrich, multi-modal latent factors in real-world data, such as natural language\ntext. However, current models often assume simplistic priors on the latent\nvariables - such as the uni-modal Gaussian distribution - which are incapable\nof representing complex latent factors efficiently. To overcome this\nrestriction, we propose the simple, but highly flexible, piecewise constant\ndistribution. This distribution has the capacity to represent an exponential\nnumber of modes of a latent target distribution, while remaining mathematically\ntractable. Our results demonstrate that incorporating this new latent\ndistribution into different models yields substantial improvements in natural\nlanguage processing tasks such as document modeling and natural language\ngeneration for dialogue.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 18:49:23 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 03:18:54 GMT"}, {"version": "v3", "created": "Thu, 13 Jul 2017 19:25:58 GMT"}, {"version": "v4", "created": "Sat, 23 Sep 2017 13:33:55 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Serban", "Iulian V.", ""], ["Ororbia", "Alexander G.", "II"], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""]]}, {"id": "1612.00472", "submitter": "Andrew Jaegle", "authors": "Andrew Jaegle, Stephen Phillips, Daphne Ippolito, Kostas Daniilidis", "title": "Understanding image motion with group representations", "comments": "Published as a conference paper at ICLR 2018; 14 pages, including\n  references and supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion is an important signal for agents in dynamic environments, but\nlearning to represent motion from unlabeled video is a difficult and\nunderconstrained problem. We propose a model of motion based on elementary\ngroup properties of transformations and use it to train a representation of\nimage motion. While most methods of estimating motion are based on pixel-level\nconstraints, we use these group properties to constrain the abstract\nrepresentation of motion itself. We demonstrate that a deep neural network\ntrained using this method captures motion in both synthetic 2D sequences and\nreal-world sequences of vehicle motion, without requiring any labels. Networks\ntrained to respect these constraints implicitly identify the image\ncharacteristic of motion in different sequence types. In the context of vehicle\nmotion, this method extracts information useful for localization, tracking, and\nodometry. Our results demonstrate that this representation is useful for\nlearning motion in the general setting where explicit labels are difficult to\nobtain.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2016 21:18:45 GMT"}, {"version": "v2", "created": "Mon, 26 Feb 2018 17:33:45 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jaegle", "Andrew", ""], ["Phillips", "Stephen", ""], ["Ippolito", "Daphne", ""], ["Daniilidis", "Kostas", ""]]}, {"id": "1612.00671", "submitter": "Tirtharaj Dash", "authors": "Siddharth Dinesh, Tirtharaj Dash", "title": "Reliable Evaluation of Neural Network for Multiclass Classification of\n  Real-world Data", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-2016-STUDY-1", "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a systematic evaluation of Neural Network (NN) for\nclassification of real-world data. In the field of machine learning, it is\noften seen that a single parameter that is 'predictive accuracy' is being used\nfor evaluating the performance of a classifier model. However, this parameter\nmight not be considered reliable given a dataset with very high level of\nskewness. To demonstrate such behavior, seven different types of datasets have\nbeen used to evaluate a Multilayer Perceptron (MLP) using twelve(12) different\nparameters which include micro- and macro-level estimation. In the present\nstudy, the most common problem of prediction called 'multiclass' classification\nhas been considered. The results that are obtained for different parameters for\neach of the dataset could demonstrate interesting findings to support the\nusability of these set of performance evaluation parameters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 19:58:44 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Dinesh", "Siddharth", ""], ["Dash", "Tirtharaj", ""]]}, {"id": "1612.00712", "submitter": "Jayant Krishnamurthy", "authors": "Kenton W. Murray and Jayant Krishnamurthy", "title": "Probabilistic Neural Programs", "comments": "Appears in NAMPI workshop at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present probabilistic neural programs, a framework for program induction\nthat permits flexible specification of both a computational model and inference\nalgorithm while simultaneously enabling the use of deep neural networks.\nProbabilistic neural programs combine a computation graph for specifying a\nneural network with an operator for weighted nondeterministic choice. Thus, a\nprogram describes both a collection of decisions as well as the neural network\narchitecture used to make each one. We evaluate our approach on a challenging\ndiagram question answering task where probabilistic neural programs correctly\nexecute nearly twice as many programs as a baseline model.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 15:46:09 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Murray", "Kenton W.", ""], ["Krishnamurthy", "Jayant", ""]]}, {"id": "1612.00745", "submitter": "Andras Lorincz", "authors": "Andr\\'as L\\H{o}rincz, M\\'at\\'e Cs\\'akv\\'ari, \\'Aron F\\'othi, Zolt\\'an\n  \\'Ad\\'am Milacski, Andr\\'as S\\'ark\\'any, Zolt\\'an T\\H{o}s\\'er", "title": "Cognitive Deep Machine Can Train Itself", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is making substantial progress in diverse applications. The\nsuccess is mostly due to advances in deep learning. However, deep learning can\nmake mistakes and its generalization abilities to new tasks are questionable.\nWe ask when and how one can combine network outputs, when (i) details of the\nobservations are evaluated by learned deep components and (ii) facts and\nconfirmation rules are available in knowledge based systems. We show that in\nlimited contexts the required number of training samples can be low and\nself-improvement of pre-trained networks in more general context is possible.\nWe argue that the combination of sparse outlier detection with deep components\nthat can support each other diminish the fragility of deep methods, an\nimportant requirement for engineering applications. We argue that supervised\nlearning of labels may be fully eliminated under certain conditions: a\ncomponent based architecture together with a knowledge based system can train\nitself and provide high quality answers. We demonstrate these concepts on the\nState Farm Distracted Driver Detection benchmark. We argue that the view of the\nStudy Panel (2016) may overestimate the requirements on `years of focused\nresearch' and `careful, unique construction' for `AI systems'.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 16:49:07 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["L\u0151rincz", "Andr\u00e1s", ""], ["Cs\u00e1kv\u00e1ri", "M\u00e1t\u00e9", ""], ["F\u00f3thi", "\u00c1ron", ""], ["Milacski", "Zolt\u00e1n \u00c1d\u00e1m", ""], ["S\u00e1rk\u00e1ny", "Andr\u00e1s", ""], ["T\u0151s\u00e9r", "Zolt\u00e1n", ""]]}, {"id": "1612.00817", "submitter": "Alexander Gaunt", "authors": "Alexander L. Gaunt, Marc Brockschmidt, Rishabh Singh, Nate Kushman,\n  Pushmeet Kohli, Jonathan Taylor, Daniel Tarlow", "title": "Summary - TerpreT: A Probabilistic Programming Language for Program\n  Induction", "comments": "7 pages, 2 figures, 4 tables in 1st Workshop on Neural Abstract\n  Machines & Program Induction (NAMPI), @NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study machine learning formulations of inductive program synthesis; that\nis, given input-output examples, synthesize source code that maps inputs to\ncorresponding outputs. Our key contribution is TerpreT, a domain-specific\nlanguage for expressing program synthesis problems. A TerpreT model is composed\nof a specification of a program representation and an interpreter that\ndescribes how programs map inputs to outputs. The inference task is to observe\na set of input-output examples and infer the underlying program. From a TerpreT\nmodel we automatically perform inference using four different back-ends:\ngradient descent (thus each TerpreT model can be seen as defining a\ndifferentiable interpreter), linear program (LP) relaxations for graphical\nmodels, discrete satisfiability solving, and the Sketch program synthesis\nsystem. TerpreT has two main benefits. First, it enables rapid exploration of a\nrange of domains, program representations, and interpreter models. Second, it\nseparates the model specification from the inference algorithm, allowing proper\ncomparisons between different approaches to inference.\n  We illustrate the value of TerpreT by developing several interpreter models\nand performing an extensive empirical comparison between alternative inference\nalgorithms on a variety of program models. To our knowledge, this is the first\nwork to compare gradient-based search over program space to traditional\nsearch-based alternatives. Our key empirical finding is that constraint solvers\ndominate the gradient descent and LP-based formulations.\n  This is a workshop summary of a longer report at arXiv:1608.04428\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 20:08:22 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Gaunt", "Alexander L.", ""], ["Brockschmidt", "Marc", ""], ["Singh", "Rishabh", ""], ["Kushman", "Nate", ""], ["Kohli", "Pushmeet", ""], ["Taylor", "Jonathan", ""], ["Tarlow", "Daniel", ""]]}, {"id": "1612.00891", "submitter": "Jonathan Cox", "authors": "Jonathan A. Cox", "title": "Parameter Compression of Recurrent Neural Networks and Degradation of\n  Short-term Memory", "comments": "Accepted to IJCNN 2017. Final camera ready paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significant computational costs of deploying neural networks in\nlarge-scale or resource constrained environments, such as data centers and\nmobile devices, has spurred interest in model compression, which can achieve a\nreduction in both arithmetic operations and storage memory. Several techniques\nhave been proposed for reducing or compressing the parameters for feed-forward\nand convolutional neural networks, but less is understood about the effect of\nparameter compression on recurrent neural networks (RNN). In particular, the\nextent to which the recurrent parameters can be compressed and the impact on\nshort-term memory performance, is not well understood. In this paper, we study\nthe effect of complexity reduction, through singular value decomposition rank\nreduction, on RNN and minimal gated recurrent unit (MGRU) networks for several\ntasks. We show that considerable rank reduction is possible when compressing\nrecurrent weights, even without fine tuning. Furthermore, we propose a\nperturbation model for the effect of general perturbations, such as a\ncompression, on the recurrent parameters of RNNs. The model is tested against a\nnoiseless memorization experiment that elucidates the short-term memory\nperformance. In this way, we demonstrate that the effect of compression of\nrecurrent parameters is dependent on the degree of temporal coherence present\nin the data and task. This work can guide on-the-fly RNN compression for novel\nenvironments or tasks, and provides insight for applying RNN compression in\nlow-power devices, such as hearing aids.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 23:11:10 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 18:22:30 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Cox", "Jonathan A.", ""]]}, {"id": "1612.00962", "submitter": "Leen De Baets", "authors": "Leen De Baets, Joeri Ruyssinck, Thomas Peiffer, Johan Decruyenaere,\n  Filip De Turck, Femke Ongenae, Tom Dhaene", "title": "Positive blood culture detection in time series data using a BiLSTM\n  network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presence of bacteria or fungi in the bloodstream of patients is abnormal\nand can lead to life-threatening conditions. A computational model based on a\nbidirectional long short-term memory artificial neural network, is explored to\nassist doctors in the intensive care unit to predict whether examination of\nblood cultures of patients will return positive. As input it uses nine\nmonitored clinical parameters, presented as time series data, collected from\n2177 ICU admissions at the Ghent University Hospital. Our main goal is to\ndetermine if general machine learning methods and more specific, temporal\nmodels, can be used to create an early detection system. This preliminary\nresearch obtains an area of 71.95% under the precision recall curve, proving\nthe potential of temporal neural networks in this context.\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2016 12:16:21 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["De Baets", "Leen", ""], ["Ruyssinck", "Joeri", ""], ["Peiffer", "Thomas", ""], ["Decruyenaere", "Johan", ""], ["De Turck", "Filip", ""], ["Ongenae", "Femke", ""], ["Dhaene", "Tom", ""]]}, {"id": "1612.00979", "submitter": "Stepan Tulyakov", "authors": "Stepan Tulyakov and Anton Ivanov and Francois Fleuret", "title": "Semi-supervised learning of deep metrics for stereo reconstruction", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-learning metrics have recently demonstrated extremely good performance\nto match image patches for stereo reconstruction. However, training such\nmetrics requires large amount of labeled stereo images, which can be difficult\nor costly to collect for certain applications. The main contribution of our\nwork is a new semi-supervised method for learning deep metrics from unlabeled\nstereo images, given coarse information about the scenes and the optical\nsystem. Our method alternatively optimizes the metric with a standard\nstochastic gradient descent, and applies stereo constraints to regularize its\nprediction. Experiments on reference data-sets show that, for a given network\narchitecture, training with this new method without ground-truth produces a\nmetric with performance as good as state-of-the-art baselines trained with the\nsaid ground-truth. This work has three practical implications. Firstly, it\nhelps to overcome limitations of training sets, in particular noisy ground\ntruth. Secondly it allows to use much more training data during learning.\nThirdly, it allows to tune deep metric for a particular stereo system, even if\nground truth is not available.\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2016 16:09:32 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Tulyakov", "Stepan", ""], ["Ivanov", "Anton", ""], ["Fleuret", "Francois", ""]]}, {"id": "1612.01251", "submitter": "Pedro Tabacof", "authors": "Ramon Oliveira, Pedro Tabacof, Eduardo Valle", "title": "Known Unknowns: Uncertainty Quality in Bayesian Neural Networks", "comments": "Workshop on Bayesian Deep Learning, NIPS 2016, Barcelona, Spain;\n  EDIT: Changed analysis from Logit-AUC space to AUC (with changes to Figs. 2\n  and 3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the uncertainty quality in neural networks using anomaly\ndetection. We extract uncertainty measures (e.g. entropy) from the predictions\nof candidate models, use those measures as features for an anomaly detector,\nand gauge how well the detector differentiates known from unknown classes. We\nassign higher uncertainty quality to candidate models that lead to better\ndetectors. We also propose a novel method for sampling a variational\napproximation of a Bayesian neural network, called One-Sample Bayesian\nApproximation (OSBA). We experiment on two datasets, MNIST and CIFAR10. We\ncompare the following candidate neural network models: Maximum Likelihood,\nBayesian Dropout, OSBA, and --- for MNIST --- the standard variational\napproximation. We show that Bayesian Dropout and OSBA provide better\nuncertainty information than Maximum Likelihood, and are essentially equivalent\nto the standard variational approximation, but much faster.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 05:21:42 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 00:24:27 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Oliveira", "Ramon", ""], ["Tabacof", "Pedro", ""], ["Valle", "Eduardo", ""]]}, {"id": "1612.01294", "submitter": "Arnab Ghosh", "authors": "Arnab Ghosh and Viveka Kulharia and Vinay Namboodiri", "title": "Message Passing Multi-Agent GANs", "comments": "The first 2 authors contributed equally for this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communicating and sharing intelligence among agents is an important facet of\nachieving Artificial General Intelligence. As a first step towards this\nchallenge, we introduce a novel framework for image generation: Message Passing\nMulti-Agent Generative Adversarial Networks (MPM GANs). While GANs have\nrecently been shown to be very effective for image generation and other tasks,\nthese networks have been limited to mostly single generator-discriminator\nnetworks. We show that we can obtain multi-agent GANs that communicate through\nmessage passing to achieve better image generation. The objectives of the\nindividual agents in this framework are two fold: a co-operation objective and\na competing objective. The co-operation objective ensures that the message\nsharing mechanism guides the other generator to generate better than itself\nwhile the competing objective encourages each generator to generate better than\nits counterpart. We analyze and visualize the messages that these GANs share\namong themselves in various scenarios. We quantitatively show that the message\nsharing formulation serves as a regularizer for the adversarial training.\nQualitatively, we show that the different generators capture different traits\nof the underlying data distribution.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 10:10:13 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Ghosh", "Arnab", ""], ["Kulharia", "Viveka", ""], ["Namboodiri", "Vinay", ""]]}, {"id": "1612.01491", "submitter": "Xinyu Wu", "authors": "Xinyu Wu and Vishal Saxena", "title": "Enabling Bio-Plausible Multi-level STDP using CMOS Neurons with\n  Dendrites and Bistable RRAMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale integration of emerging nanoscale non-volatile memory devices,\ne.g. resistive random-access memory (RRAM), can enable a new generation of\nneuromorphic computers that can solve a wide range of machine learning\nproblems. Such hybrid CMOS-RRAM neuromorphic architectures will result in\nseveral orders of magnitude reduction in energy consumption at a very small\nform factor, and herald autonomous learning machines capable of self-adapting\nto their environment. However, the progress in this area has been impeded from\nthe realization that the actual memory devices fall well short of their\nexpected behavior. In this work, we discuss the challenges associated with\nthese memory devices and their use in neuromorphic computing circuits, and\npropose pathways to overcome these limitations by introducing 'dendritic\nlearning'.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 19:30:25 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2016 01:54:34 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Wu", "Xinyu", ""], ["Saxena", "Vishal", ""]]}, {"id": "1612.01501", "submitter": "Georgios Smaragdos", "authors": "Georgios Smaragdos, Georgios Chatzikonstantis, Rahul Kukreja, Harry\n  Sidiropoulos, Dimitrios Rodopoulos, Ioannis Sourdis, Zaid Al-Ars,\n  Christoforos Kachris, Dimitrios Soudris, Chris I. De Zeeuw, Christos Strydis", "title": "BrainFrame: A node-level heterogeneous accelerator platform for neuron\n  simulations", "comments": "16 pages, 18 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The advent of High-Performance Computing (HPC) in recent years has\nled to its increasing use in brain study through computational models. The\nscale and complexity of such models are constantly increasing, leading to\nchallenging computational requirements. Even though modern HPC platforms can\noften deal with such challenges, the vast diversity of the modeling field does\nnot permit for a single acceleration (or homogeneous) platform to effectively\naddress the complete array of modeling requirements. Approach: In this paper we\npropose and build BrainFrame, a heterogeneous acceleration platform,\nincorporating three distinct acceleration technologies, a Dataflow Engine, a\nXeon Phi and a GP-GPU. The PyNN framework is also integrated into the platform.\nAs a challenging proof of concept, we analyze the performance of BrainFrame on\ndifferent instances of a state-of-the-art neuron model, modeling the Inferior-\nOlivary Nucleus using a biophysically-meaningful, extended Hodgkin-Huxley\nrepresentation. The model instances take into account not only the neuronal-\nnetwork dimensions but also different network-connectivity circumstances that\ncan drastically change application workload characteristics. Main results: The\nsynthetic approach of three HPC technologies demonstrated that BrainFrame is\nbetter able to cope with the modeling diversity encountered. Our performance\nanalysis shows clearly that the model directly affect performance and all three\ntechnologies are required to cope with all the model use cases.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 20:18:30 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2016 13:54:49 GMT"}, {"version": "v3", "created": "Tue, 27 Dec 2016 13:48:46 GMT"}, {"version": "v4", "created": "Tue, 15 Aug 2017 16:26:43 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Smaragdos", "Georgios", ""], ["Chatzikonstantis", "Georgios", ""], ["Kukreja", "Rahul", ""], ["Sidiropoulos", "Harry", ""], ["Rodopoulos", "Dimitrios", ""], ["Sourdis", "Ioannis", ""], ["Al-Ars", "Zaid", ""], ["Kachris", "Christoforos", ""], ["Soudris", "Dimitrios", ""], ["De Zeeuw", "Chris I.", ""], ["Strydis", "Christos", ""]]}, {"id": "1612.01543", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Mostafa El-Khamy, and Jungwon Lee", "title": "Towards the Limit of Network Quantization", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network quantization is one of network compression techniques to reduce the\nredundancy of deep neural networks. It reduces the number of distinct network\nparameter values by quantization in order to save the storage for them. In this\npaper, we design network quantization schemes that minimize the performance\nloss due to quantization given a compression ratio constraint. We analyze the\nquantitative relation of quantization errors to the neural network loss\nfunction and identify that the Hessian-weighted distortion measure is locally\nthe right objective function for the optimization of network quantization. As a\nresult, Hessian-weighted k-means clustering is proposed for clustering network\nparameters to quantize. When optimal variable-length binary codes, e.g.,\nHuffman codes, are employed for further compression, we derive that the network\nquantization problem can be related to the entropy-constrained scalar\nquantization (ECSQ) problem in information theory and consequently propose two\nsolutions of ECSQ for network quantization, i.e., uniform quantization and an\niterative solution similar to Lloyd's algorithm. Finally, using the simple\nuniform quantization followed by Huffman coding, we show from our experiments\nthat the compression ratios of 51.25, 22.17 and 40.65 are achievable for LeNet,\n32-layer ResNet and AlexNet, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 21:04:17 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 19:44:32 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Choi", "Yoojin", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1612.01589", "submitter": "Konrad \\.Zo{\\l}na", "authors": "Konrad Zolna", "title": "Improving the Performance of Neural Networks in Regression Tasks Using\n  Drawering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method presented extends a given regression neural network to make its\nperformance improve. The modification affects the learning procedure only,\nhence the extension may be easily omitted during evaluation without any change\nin prediction. It means that the modified model may be evaluated as quickly as\nthe original one but tends to perform better.\n  This improvement is possible because the modification gives better expressive\npower, provides better behaved gradients and works as a regularization. The\nknowledge gained by the temporarily extended neural network is contained in the\nparameters shared with the original neural network.\n  The only cost is an increase in learning time.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 23:28:54 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Zolna", "Konrad", ""]]}, {"id": "1612.01717", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Statistical mechanics of unsupervised feature learning in a restricted\n  Boltzmann machine with binary synapses", "comments": "24 pages, 9 figures, results added", "journal-ref": "J. Stat. Mech. (2017) 053302", "doi": "10.1088/1742-5468/aa6ddc", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revealing hidden features in unlabeled data is called unsupervised feature\nlearning, which plays an important role in pretraining a deep neural network.\nHere we provide a statistical mechanics analysis of the unsupervised learning\nin a restricted Boltzmann machine with binary synapses. A message passing\nequation to infer the hidden feature is derived, and furthermore, variants of\nthis equation are analyzed. A statistical analysis by replica theory describes\nthe thermodynamic properties of the model. Our analysis confirms an entropy\ncrisis preceding the non-convergence of the message passing equation,\nsuggesting a discontinuous phase transition as a key characteristic of the\nrestricted Boltzmann machine. Continuous phase transition is also confirmed\ndepending on the embedded feature strength in the data. The mean-field result\nunder the replica symmetric assumption agrees with that obtained by running\nmessage passing algorithms on single instances of finite sizes. Interestingly,\nin an approximate Hopfield model, the entropy crisis is absent, and a\ncontinuous phase transition is observed instead. We also develop an iterative\nequation to infer the hyper-parameter (temperature) hidden in the data, which\nin physics corresponds to iteratively imposing Nishimori condition. Our study\nprovides insights towards understanding the thermodynamic properties of the\nrestricted Boltzmann machine learning, and moreover important theoretical basis\nto build simplified deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 09:17:14 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 04:47:07 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1612.01936", "submitter": "Tan Nguyen", "authors": "Ankit B. Patel, Tan Nguyen, Richard G. Baraniuk", "title": "A Probabilistic Framework for Deep Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1504.00641", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a probabilistic framework for deep learning based on the Deep\nRendering Mixture Model (DRMM), a new generative probabilistic model that\nexplicitly capture variations in data due to latent task nuisance variables. We\ndemonstrate that max-sum inference in the DRMM yields an algorithm that exactly\nreproduces the operations in deep convolutional neural networks (DCNs),\nproviding a first principles derivation. Our framework provides new insights\ninto the successes and shortcomings of DCNs as well as a principled route to\ntheir improvement. DRMM training via the Expectation-Maximization (EM)\nalgorithm is a powerful alternative to DCN back-propagation, and initial\ntraining results are promising. Classification based on the DRMM and other\nvariants outperforms DCNs in supervised digit classification, training 2-3x\nfaster while achieving similar accuracy. Moreover, the DRMM is applicable to\nsemi-supervised and unsupervised learning tasks, achieving results that are\nstate-of-the-art in several categories on the MNIST benchmark and comparable to\nstate of the art on the CIFAR10 benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 18:15:40 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Patel", "Ankit B.", ""], ["Nguyen", "Tan", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1612.01939", "submitter": "Baochen Sun", "authors": "Baochen Sun, Jiashi Feng, Kate Saenko", "title": "Correlation Alignment for Unsupervised Domain Adaptation", "comments": "Introduction to CORAL, CORAL-LDA, and Deep CORAL. arXiv admin note:\n  text overlap with arXiv:1511.05547", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we present CORrelation ALignment (CORAL), a simple yet\neffective method for unsupervised domain adaptation. CORAL minimizes domain\nshift by aligning the second-order statistics of source and target\ndistributions, without requiring any target labels. In contrast to subspace\nmanifold methods, it aligns the original feature distributions of the source\nand target domains, rather than the bases of lower-dimensional subspaces. It is\nalso much simpler than other distribution matching methods. CORAL performs\nremarkably well in extensive evaluations on standard benchmark datasets. We\nfirst describe a solution that applies a linear transformation to source\nfeatures to align them with target features before classifier training. For\nlinear classifiers, we propose to equivalently apply CORAL to the classifier\nweights, leading to added efficiency when the number of classifiers is small\nbut the number and dimensionality of target examples are very high. The\nresulting CORAL Linear Discriminant Analysis (CORAL-LDA) outperforms LDA by a\nlarge margin on standard domain adaptation benchmarks. Finally, we extend CORAL\nto learn a nonlinear transformation that aligns correlations of layer\nactivations in deep neural networks (DNNs). The resulting Deep CORAL approach\nworks seamlessly with DNNs and achieves state-of-the-art performance on\nstandard benchmark datasets. Our code is available\nat:~\\url{https://github.com/VisionLearningGroup/CORAL}\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 18:31:57 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Sun", "Baochen", ""], ["Feng", "Jiashi", ""], ["Saenko", "Kate", ""]]}, {"id": "1612.01942", "submitter": "Tan Nguyen", "authors": "Tan Nguyen, Wanjia Liu, Ethan Perez, Richard G. Baraniuk, Ankit B.\n  Patel", "title": "Semi-Supervised Learning with the Deep Rendering Mixture Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning algorithms reduce the high cost of acquiring labeled\ntraining data by using both labeled and unlabeled data during learning. Deep\nConvolutional Networks (DCNs) have achieved great success in supervised tasks\nand as such have been widely employed in the semi-supervised learning. In this\npaper we leverage the recently developed Deep Rendering Mixture Model (DRMM), a\nprobabilistic generative model that models latent nuisance variation, and whose\ninference algorithm yields DCNs. We develop an EM algorithm for the DRMM to\nlearn from both labeled and unlabeled data. Guided by the theory of the DRMM,\nwe introduce a novel non-negativity constraint and a variational inference\nterm. We report state-of-the-art performance on MNIST and SVHN and competitive\nresults on CIFAR10. We also probe deeper into how a DRMM trained in a\nsemi-supervised setting represents latent nuisance variation using\nsynthetically rendered images. Taken together, our work provides a unified\nframework for supervised, unsupervised, and semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 18:32:53 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Nguyen", "Tan", ""], ["Liu", "Wanjia", ""], ["Perez", "Ethan", ""], ["Baraniuk", "Richard G.", ""], ["Patel", "Ankit B.", ""]]}, {"id": "1612.02130", "submitter": "Niek Tax", "authors": "Niek Tax, Ilya Verenich, Marcello La Rosa, Marlon Dumas", "title": "Predictive Business Process Monitoring with LSTM Neural Networks", "comments": "Accepted at the International Conference on Advanced Information\n  Systems Engineering (CAiSE) 2017", "journal-ref": "Lecture Notes in Computer Science, 10253 (2017) 477-492", "doi": "10.1007/978-3-319-59536-8_30", "report-no": null, "categories": "stat.AP cs.DB cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive business process monitoring methods exploit logs of completed\ncases of a process in order to make predictions about running cases thereof.\nExisting methods in this space are tailor-made for specific prediction tasks.\nMoreover, their relative accuracy is highly sensitive to the dataset at hand,\nthus requiring users to engage in trial-and-error and tuning when applying them\nin a specific setting. This paper investigates Long Short-Term Memory (LSTM)\nneural networks as an approach to build consistently accurate models for a wide\nrange of predictive process monitoring tasks. First, we show that LSTMs\noutperform existing techniques to predict the next event of a running case and\nits timestamp. Next, we show how to use models for predicting the next task in\norder to predict the full continuation of a running case. Finally, we apply the\nsame approach to predict the remaining time, and show that this approach\noutperforms existing tailor-made methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 07:04:17 GMT"}, {"version": "v2", "created": "Tue, 16 May 2017 18:51:41 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Tax", "Niek", ""], ["Verenich", "Ilya", ""], ["La Rosa", "Marcello", ""], ["Dumas", "Marlon", ""]]}, {"id": "1612.02136", "submitter": "Yanran Li", "authors": "Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, Wenjie Li", "title": "Mode Regularized Generative Adversarial Networks", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Generative Adversarial Networks achieve state-of-the-art results on\na variety of generative tasks, they are regarded as highly unstable and prone\nto miss modes. We argue that these bad behaviors of GANs are due to the very\nparticular functional shape of the trained discriminators in high dimensional\nspaces, which can easily make training stuck or push probability mass in the\nwrong direction, towards that of higher concentration than that of the data\ngenerating distribution. We introduce several ways of regularizing the\nobjective, which can dramatically stabilize the training of GAN models. We also\nshow that our regularizers can help the fair distribution of probability mass\nacross the modes of the data generating distribution, during the early phases\nof training and thus providing a unified solution to the missing modes problem.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 07:45:38 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 06:08:37 GMT"}, {"version": "v3", "created": "Sun, 18 Dec 2016 05:55:22 GMT"}, {"version": "v4", "created": "Mon, 20 Feb 2017 05:01:27 GMT"}, {"version": "v5", "created": "Thu, 2 Mar 2017 06:28:13 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Che", "Tong", ""], ["Li", "Yanran", ""], ["Jacob", "Athul Paul", ""], ["Bengio", "Yoshua", ""], ["Li", "Wenjie", ""]]}, {"id": "1612.02233", "submitter": "Sidharth Prasad", "authors": "Anmol Biswas, Sidharth Prasad, Sandip Lashkare and Udayan Ganguly", "title": "A simple and efficient SNN and its performance & robustness evaluation\n  method to enable hardware implementation", "comments": "9 page conference paper submitted at IJCNN 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNN) are more closely related to brain-like\ncomputation and inspire hardware implementation. This is enabled by small\nnetworks that give high performance on standard classification problems. In\nliterature, typical SNNs are deep and complex in terms of network structure,\nweight update rules and learning algorithms. This makes it difficult to\ntranslate them into hardware. In this paper, we first develop a simple\n2-layered network in software which compares with the state of the art on four\ndifferent standard data-sets within SNNs and has improved efficiency. For\nexample, it uses lower number of neurons (3 x), synapses (3.5 x) and epochs for\ntraining (30 x) for the Fisher Iris classification problem. The efficient\nnetwork is based on effective population coding and synapse-neuron co-design.\nSecond, we develop a computationally efficient (15000 x) and accurate\n(correlation of 0.98) method to evaluate the performance of the network without\nstandard recognition tests. Third, we show that the method produces a\nrobustness metric that can be used to evaluate noise tolerance.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 13:11:27 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Biswas", "Anmol", ""], ["Prasad", "Sidharth", ""], ["Lashkare", "Sandip", ""], ["Ganguly", "Udayan", ""]]}, {"id": "1612.02336", "submitter": "Janez Ales Dr", "authors": "Janez Ale\\v{s}", "title": "Neural Turing Machines: Convergence of Copy Tasks", "comments": "Predictor weights can be provided upon request", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The architecture of neural Turing machines is differentiable end to end and\nis trainable with gradient descent methods. Due to their large unfolded depth\nNeural Turing Machines are hard to train and because of their linear access of\ncomplete memory they do not scale. Other architectures have been studied to\novercome these difficulties. In this report we focus on improving the quality\nof prediction of the original linear memory architecture on copy and repeat\ncopy tasks. Copy task predictions on sequences of length six times larger than\nthose the neural Turing machine was trained on prove to be highly accurate and\nso do predictions of repeat copy tasks for sequences with twice the repetition\nnumber and twice the sequence length neural Turing machine was trained on.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 17:23:26 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Ale\u0161", "Janez", ""]]}, {"id": "1612.02482", "submitter": "Krupakar Hans", "authors": "Krupakar Hans, R S Milton", "title": "Improving the Performance of Neural Machine Translation Involving\n  Morphologically Rich Languages", "comments": "21 pages, 11 figures, 2 tables, Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of the attention mechanism in neural machine translation models\nhas improved the performance of machine translation systems by enabling\nselective lookup into the source sentence. In this paper, the efficiencies of\ntranslation using bidirectional encoder attention decoder models were studied\nwith respect to translation involving morphologically rich languages. The\nEnglish - Tamil language pair was selected for this analysis. First, the use of\nWord2Vec embedding for both the English and Tamil words improved the\ntranslation results by 0.73 BLEU points over the baseline RNNSearch model with\n4.84 BLEU score. The use of morphological segmentation before word\nvectorization to split the morphologically rich Tamil words into their\nrespective morphemes before the translation, caused a reduction in the target\nvocabulary size by a factor of 8. Also, this model (RNNMorph) improved the\nperformance of neural machine translation by 7.05 BLEU points over the\nRNNSearch model used over the same corpus. Since the BLEU evaluation of the\nRNNMorph model might be unreliable due to an increase in the number of matching\ntokens per sentence, the performances of the translations were also compared by\nmeans of human evaluation metrics of adequacy, fluency and relative ranking.\nFurther, the use of morphological segmentation also improved the efficacy of\nthe attention mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 23:20:53 GMT"}, {"version": "v2", "created": "Sun, 8 Jan 2017 06:04:50 GMT"}], "update_date": "2017-01-10", "authors_parsed": [["Hans", "Krupakar", ""], ["Milton", "R S", ""]]}, {"id": "1612.02522", "submitter": "Sven Cattell", "authors": "Sven Cattell", "title": "Geometric Decomposition of Feed Forward Neural Networks", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There have been several attempts to mathematically understand neural networks\nand many more from biological and computational perspectives. The field has\nexploded in the last decade, yet neural networks are still treated much like a\nblack box. In this work we describe a structure that is inherent to a feed\nforward neural network. This will provide a framework for future work on neural\nnetworks to improve training algorithms, compute the homology of the network,\nand other applications. Our approach takes a more geometric point of view and\nis unlike other attempts to mathematically understand neural networks that rely\non a functional perspective.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 03:28:10 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Cattell", "Sven", ""]]}, {"id": "1612.02695", "submitter": "Jan Chorowski", "authors": "Jan Chorowski and Navdeep Jaitly", "title": "Towards better decoding and language model integration in sequence to\n  sequence models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed Sequence-to-Sequence (seq2seq) framework advocates\nreplacing complex data processing pipelines, such as an entire automatic speech\nrecognition system, with a single neural network trained in an end-to-end\nfashion. In this contribution, we analyse an attention-based seq2seq speech\nrecognition system that directly transcribes recordings into characters. We\nobserve two shortcomings: overconfidence in its predictions and a tendency to\nproduce incomplete transcriptions when language models are used. We propose\npractical solutions to both problems achieving competitive speaker independent\nword error rates on the Wall Street Journal dataset: without separate language\nmodels we reach 10.6% WER, while together with a trigram language model, we\nreach 6.7% WER.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 15:23:44 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Chorowski", "Jan", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1612.02734", "submitter": "Peter Sadowski", "authors": "Pierre Baldi, Peter Sadowski, Zhiqin Lu", "title": "Learning in the Machine: Random Backpropagation and the Deep Learning\n  Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random backpropagation (RBP) is a variant of the backpropagation algorithm\nfor training neural networks, where the transpose of the forward matrices are\nreplaced by fixed random matrices in the calculation of the weight updates. It\nis remarkable both because of its effectiveness, in spite of using random\nmatrices to communicate error information, and because it completely removes\nthe taxing requirement of maintaining symmetric weights in a physical neural\nsystem. To better understand random backpropagation, we first connect it to the\nnotions of local learning and learning channels. Through this connection, we\nderive several alternatives to RBP, including skipped RBP (SRPB), adaptive RBP\n(ARBP), sparse RBP, and their combinations (e.g. ASRBP) and analyze their\ncomputational complexity. We then study their behavior through simulations\nusing the MNIST and CIFAR-10 bechnmark datasets. These simulations show that\nmost of these variants work robustly, almost as well as backpropagation, and\nthat multiplication by the derivatives of the activation functions is\nimportant. As a follow-up, we study also the low-end of the number of bits\nrequired to communicate error information over the learning channel. We then\nprovide partial intuitive explanations for some of the remarkable properties of\nRBP and its variations. Finally, we prove several mathematical results,\nincluding the convergence to fixed points of linear chains of arbitrary length,\nthe convergence to fixed points of linear autoencoders with decorrelated data,\nthe long-term existence of solutions for linear systems with a single hidden\nlayer and convergence in special cases, and the convergence to fixed points of\nnon-linear chains, when the derivative of the activation functions is included.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 17:15:45 GMT"}, {"version": "v2", "created": "Fri, 22 Dec 2017 17:29:20 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Baldi", "Pierre", ""], ["Sadowski", "Peter", ""], ["Lu", "Zhiqin", ""]]}, {"id": "1612.02741", "submitter": "Lili Mou", "authors": "Lili Mou, Zhengdong Lu, Hang Li, Zhi Jin", "title": "Coupling Distributed and Symbolic Execution for Natural Language Queries", "comments": "Accepted by ICML-17; also presented at ICLR-17 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building neural networks to query a knowledge base (a table) with natural\nlanguage is an emerging research topic in deep learning. An executor for table\nquerying typically requires multiple steps of execution because queries may\nhave complicated structures. In previous studies, researchers have developed\neither fully distributed executors or symbolic executors for table querying. A\ndistributed executor can be trained in an end-to-end fashion, but is weak in\nterms of execution efficiency and explicit interpretability. A symbolic\nexecutor is efficient in execution, but is very difficult to train especially\nat initial stages. In this paper, we propose to couple distributed and symbolic\nexecution for natural language queries, where the symbolic executor is\npretrained with the distributed executor's intermediate execution results in a\nstep-by-step fashion. Experiments show that our approach significantly\noutperforms both distributed and symbolic executors, exhibiting high accuracy,\nhigh learning efficiency, high execution efficiency, and high interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 17:45:16 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 11:37:44 GMT"}, {"version": "v3", "created": "Tue, 25 Apr 2017 20:39:57 GMT"}, {"version": "v4", "created": "Fri, 16 Jun 2017 14:33:31 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Mou", "Lili", ""], ["Lu", "Zhengdong", ""], ["Li", "Hang", ""], ["Jin", "Zhi", ""]]}, {"id": "1612.02893", "submitter": "Krupakar Hans", "authors": "Hans Krupakar, Akshay Jayakumar, Dhivya G", "title": "A Review of Intelligent Practices for Irrigation Prediction", "comments": "18 pages, 3 figures, 1 table, In National Conference on Computational\n  Intelligence and High-Performance Computing (NCCIHPC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population growth and increasing droughts are creating unprecedented strain\non the continued availability of water resources. Since irrigation is a major\nconsumer of fresh water, wastage of resources in this sector could have strong\nconsequences. To address this issue, irrigation water management and prediction\ntechniques need to be employed effectively and should be able to account for\nthe variabilities present in the environment. The different techniques surveyed\nin this paper can be classified into two categories: computational and\nstatistical. Computational methods deal with scientific correlations between\nphysical parameters whereas statistical methods involve specific prediction\nalgorithms that can be used to automate the process of irrigation water\nprediction. These algorithms interpret semantic relationships between the\nvarious parameters of temperature, pressure, evapotranspiration etc. and store\nthem as numerical precomputed entities specific to the conditions and the area\nused as the data for the training corpus used to train it. We focus on\nreviewing the computational methods used to determine Evapotranspiration and\nits implications. We compare the efficiencies of different data mining and\nmachine learning methods implemented in this area, such as Logistic Regression,\nDecision Tress Classifier, SysFor, Support Vector Machine(SVM), Fuzzy Logic\ntechniques, Artifical Neural Networks(ANNs) and various hybrids of Genetic\nAlgorithms (GA) applied to irrigation prediction. We also recommend a possible\ntechnique for the same based on its superior results in other such time series\nanalysis tasks.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 22:52:05 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Krupakar", "Hans", ""], ["Jayakumar", "Akshay", ""], ["G", "Dhivya", ""]]}, {"id": "1612.02913", "submitter": "Mohammed Zidan", "authors": "Mohammed A. Zidan, YeonJoo Jeong, Jong Hong Shin, Chao Du, Zhengya\n  Zhang, Wei D. Lu", "title": "Field-Programmable Crossbar Array (FPCA) for Reconfigurable Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, advances in electronics were directly driven by the scaling of\nCMOS transistors according to Moore's law. However, both the CMOS scaling and\nthe classical computer architecture are approaching fundamental and practical\nlimits, and new computing architectures based on emerging devices, such as\nresistive random-access memory (RRAM) devices, are expected to sustain the\nexponential growth of computing capability. Here we propose a novel\nmemory-centric, reconfigurable, general purpose computing platform that is\ncapable of handling the explosive amount of data in a fast and energy-efficient\nmanner. The proposed computing architecture is based on a uniform, physical,\nresistive, memory-centric fabric that can be optimally reconfigured and\nutilized to perform different computing and data storage tasks in a massively\nparallel approach. The system can be tailored to achieve maximal energy\nefficiency based on the data flow by dynamically allocating the basic computing\nfabric for storage, arithmetic, and analog computing including neuromorphic\ncomputing tasks.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 04:41:25 GMT"}, {"version": "v2", "created": "Sun, 18 Dec 2016 05:57:43 GMT"}, {"version": "v3", "created": "Mon, 3 Jul 2017 14:45:28 GMT"}, {"version": "v4", "created": "Thu, 20 Jul 2017 14:55:45 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Zidan", "Mohammed A.", ""], ["Jeong", "YeonJoo", ""], ["Shin", "Jong Hong", ""], ["Du", "Chao", ""], ["Zhang", "Zhengya", ""], ["Lu", "Wei D.", ""]]}, {"id": "1612.03214", "submitter": "Thomas Mesnard", "authors": "Thomas Mesnard, Wulfram Gerstner, Johanni Brea", "title": "Towards deep learning with spiking neurons in energy based models with\n  contrastive Hebbian plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, error back-propagation in multi-layer neural networks\n(deep learning) has been impressively successful in supervised and\nreinforcement learning tasks. As a model for learning in the brain, however,\ndeep learning has long been regarded as implausible, since it relies in its\nbasic form on a non-local plasticity rule. To overcome this problem,\nenergy-based models with local contrastive Hebbian learning were proposed and\ntested on a classification task with networks of rate neurons. We extended this\nwork by implementing and testing such a model with networks of leaky\nintegrate-and-fire neurons. Preliminary results indicate that it is possible to\nlearn a non-linear regression task with hidden layers, spiking neurons and a\nlocal synaptic plasticity rule.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 23:17:11 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Mesnard", "Thomas", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1612.03268", "submitter": "Venkataraman Santhanam", "authors": "Venkataraman Santhanam, Vlad I. Morariu, Larry S. Davis", "title": "Generalized Deep Image to Image Regression", "comments": "Submitted to CVPR on November 15th, 2016. Code will be made available\n  soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Deep Convolutional Neural Network architecture which serves as a\ngeneric image-to-image regressor that can be trained end-to-end without any\nfurther machinery. Our proposed architecture: the Recursively Branched\nDeconvolutional Network (RBDN) develops a cheap multi-context image\nrepresentation very early on using an efficient recursive branching scheme with\nextensive parameter sharing and learnable upsampling. This multi-context\nrepresentation is subjected to a highly non-linear locality preserving\ntransformation by the remainder of our network comprising of a series of\nconvolutions/deconvolutions without any spatial downsampling. The RBDN\narchitecture is fully convolutional and can handle variable sized images during\ninference. We provide qualitative/quantitative results on $3$ diverse tasks:\nrelighting, denoising and colorization and show that our proposed RBDN\narchitecture obtains comparable results to the state-of-the-art on each of\nthese tasks when used off-the-shelf without any post processing or\ntask-specific architectural modifications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 08:22:27 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Santhanam", "Venkataraman", ""], ["Morariu", "Vlad I.", ""], ["Davis", "Larry S.", ""]]}, {"id": "1612.03402", "submitter": "Andrzej Jaszkiewicz", "authors": "Andrzej Jaszkiewicz", "title": "Improved Quick Hypervolume Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a significant improvement of Quick Hypervolume\nalgorithm, one of the state-of-the-art algorithms for calculating exact\nhypervolume of the space dominated by a set of d-dimensional points. This value\nis often used as a quality indicator in multiobjective evolutionary algorithms\nand other multiobjective metaheuristics and the efficiency of calculating this\nindicator is of crucial importance especially in the case of large sets or many\ndimensional objective spaces. We use a similar divide and conquer scheme as in\nthe original Quick Hypervolume algorithm, but in our algorithm we split the\nproblem into smaller sub-problems in a different way. Through both theoretical\nanalysis and computational study we show that our approach improves\ncomputational complexity of the algorithm and practical running times.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2016 12:10:52 GMT"}, {"version": "v2", "created": "Thu, 5 Jan 2017 11:33:46 GMT"}, {"version": "v3", "created": "Mon, 22 May 2017 11:17:53 GMT"}, {"version": "v4", "created": "Fri, 11 Aug 2017 07:50:20 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Jaszkiewicz", "Andrzej", ""]]}, {"id": "1612.03480", "submitter": "Cengiz Pehlevan", "authors": "Yuansi Chen, Cengiz Pehlevan, Dmitri B. Chklovskii", "title": "Self-calibrating Neural Networks for Dimensionality Reduction", "comments": "2016 Asilomar Conference on Signals, Systems and Computers", "journal-ref": null, "doi": "10.1109/ACSSC.2016.7869625", "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a novel family of biologically plausible online algorithms for\nreducing the dimensionality of streaming data has been derived from the\nsimilarity matching principle. In these algorithms, the number of output\ndimensions can be determined adaptively by thresholding the singular values of\nthe input data matrix. However, setting such threshold requires knowing the\nmagnitude of the desired singular values in advance. Here we propose online\nalgorithms where the threshold is self-calibrating based on the singular values\ncomputed from the existing observations. To derive these algorithms from the\nsimilarity matching cost function we propose novel regularizers. As before,\nthese online algorithms can be implemented by Hebbian/anti-Hebbian neural\nnetworks in which the learning rule depends on the chosen regularizer. We\ndemonstrate both mathematically and via simulation the effectiveness of these\nonline algorithms in various settings.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2016 21:15:05 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Chen", "Yuansi", ""], ["Pehlevan", "Cengiz", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1612.03707", "submitter": "Yuzhen Lu", "authors": "Yuzhen Lu", "title": "Empirical Evaluation of A New Approach to Simplifying Long Short-term\n  Memory (LSTM)", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard LSTM, although it succeeds in the modeling long-range\ndependences, suffers from a highly complex structure that can be simplified\nthrough modifications to its gate units. This paper was to perform an empirical\ncomparison between the standard LSTM and three new simplified variants that\nwere obtained by eliminating input signal, bias and hidden unit signal from\nindividual gates, on the tasks of modeling two sequence datasets. The\nexperiments show that the three variants, with reduced parameters, can achieve\ncomparable performance with the standard LSTM. Due attention should be paid to\nturning the learning rate to achieve high accuracies\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 14:36:22 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Lu", "Yuzhen", ""]]}, {"id": "1612.03770", "submitter": "James Aimone", "authors": "Timothy J. Draelos, Nadine E. Miner, Christopher C. Lamb, Jonathan A.\n  Cox, Craig M. Vineyard, Kristofor D. Carlson, William M. Severa, Conrad D.\n  James, and James B. Aimone", "title": "Neurogenesis Deep Learning", "comments": "8 pages, 8 figures, Accepted to 2017 International Joint Conference\n  on Neural Networks (IJCNN 2017)", "journal-ref": null, "doi": "10.1109/IJCNN.2017.7965898", "report-no": "SAND2017-2174 C", "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine learning methods, such as deep neural networks (DNN), have\nachieved remarkable success in a number of complex data processing tasks. These\nmethods have arguably had their strongest impact on tasks such as image and\naudio processing - data processing domains in which humans have long held clear\nadvantages over conventional algorithms. In contrast to biological neural\nsystems, which are capable of learning continuously, deep artificial networks\nhave a limited ability for incorporating new information in an already trained\nnetwork. As a result, methods for continuous learning are potentially highly\nimpactful in enabling the application of deep networks to dynamic data sets.\nHere, inspired by the process of adult neurogenesis in the hippocampus, we\nexplore the potential for adding new neurons to deep layers of artificial\nneural networks in order to facilitate their acquisition of novel information\nwhile preserving previously trained data representations. Our results on the\nMNIST handwritten digit dataset and the NIST SD 19 dataset, which includes\nlower and upper case letters and digits, demonstrate that neurogenesis is well\nsuited for addressing the stability-plasticity dilemma that has long challenged\nadaptive machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 16:25:23 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 16:45:11 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Draelos", "Timothy J.", ""], ["Miner", "Nadine E.", ""], ["Lamb", "Christopher C.", ""], ["Cox", "Jonathan A.", ""], ["Vineyard", "Craig M.", ""], ["Carlson", "Kristofor D.", ""], ["Severa", "William M.", ""], ["James", "Conrad D.", ""], ["Aimone", "James B.", ""]]}, {"id": "1612.03929", "submitter": "Nabiha Asghar", "authors": "Nabiha Asghar, Pascal Poupart, Xin Jiang, Hang Li", "title": "Deep Active Learning for Dialogue Generation", "comments": "Accepted at 6th Joint Conference on Lexical and Computational\n  Semantics (*SEM) 2017 (Previously titled \"Online Sequence-to-Sequence Active\n  Learning for Open-Domain Dialogue Generation\" on ArXiv)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online, end-to-end, neural generative conversational model for\nopen-domain dialogue. It is trained using a unique combination of offline\ntwo-phase supervised learning and online human-in-the-loop active learning.\nWhile most existing research proposes offline supervision or hand-crafted\nreward functions for online reinforcement, we devise a novel interactive\nlearning mechanism based on hamming-diverse beam search for response generation\nand one-character user-feedback at each step. Experiments show that our model\ninherently promotes the generation of semantically relevant and interesting\nresponses, and can be used to train agents with customized personas, moods and\nconversational styles.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 21:19:51 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 01:58:21 GMT"}, {"version": "v3", "created": "Fri, 16 Dec 2016 20:44:43 GMT"}, {"version": "v4", "created": "Wed, 1 Feb 2017 18:19:50 GMT"}, {"version": "v5", "created": "Fri, 16 Jun 2017 14:08:31 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Asghar", "Nabiha", ""], ["Poupart", "Pascal", ""], ["Jiang", "Xin", ""], ["Li", "Hang", ""]]}, {"id": "1612.03940", "submitter": "Soheil Hashemi", "authors": "Soheil Hashemi, Nicholas Anthony, Hokchhay Tann, R. Iris Bahar,\n  Sherief Reda", "title": "Understanding the Impact of Precision Quantization on the Accuracy and\n  Energy of Neural Networks", "comments": "Accepted for conference proceedings in DATE17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are gaining in popularity as they are used to generate\nstate-of-the-art results for a variety of computer vision and machine learning\napplications. At the same time, these networks have grown in depth and\ncomplexity in order to solve harder problems. Given the limitations in power\nbudgets dedicated to these networks, the importance of low-power, low-memory\nsolutions has been stressed in recent years. While a large number of dedicated\nhardware using different precisions has recently been proposed, there exists no\ncomprehensive study of different bit precisions and arithmetic in both inputs\nand network parameters. In this work, we address this issue and perform a study\nof different bit-precisions in neural networks (from floating-point to\nfixed-point, powers of two, and binary). In our evaluation, we consider and\nanalyze the effect of precision scaling on both network accuracy and hardware\nmetrics including memory footprint, power and energy consumption, and design\narea. We also investigate training-time methodologies to compensate for the\nreduction in accuracy due to limited bit precision and demonstrate that in most\ncases, precision scaling can deliver significant benefits in design metrics at\nthe cost of very modest decreases in network accuracy. In addition, we propose\nthat a small portion of the benefits achieved when using lower precisions can\nbe forfeited to increase the network size and therefore the accuracy. We\nevaluate our experiments, using three well-recognized networks and datasets to\nshow its generality. We investigate the trade-offs and highlight the benefits\nof using lower precisions in terms of energy and memory footprint.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 21:36:48 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Hashemi", "Soheil", ""], ["Anthony", "Nicholas", ""], ["Tann", "Hokchhay", ""], ["Bahar", "R. Iris", ""], ["Reda", "Sherief", ""]]}, {"id": "1612.04052", "submitter": "Bodo Rueckauer", "authors": "Bodo Rueckauer, Iulia-Alexandra Lungu, Yuhuang Hu, Michael Pfeiffer", "title": "Theory and Tools for the Conversion of Analog to Spiking Convolutional\n  Neural Networks", "comments": "9 pages, 2 figures, presented at the workshop \"Computing with Spikes\"\n  at NIPS 2016, Barcelona, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) have shown great potential for\nnumerous real-world machine learning applications, but performing inference in\nlarge CNNs in real-time remains a challenge. We have previously demonstrated\nthat traditional CNNs can be converted into deep spiking neural networks\n(SNNs), which exhibit similar accuracy while reducing both latency and\ncomputational load as a consequence of their data-driven, event-based style of\ncomputing. Here we provide a novel theory that explains why this conversion is\nsuccessful, and derive from it several new tools to convert a larger and more\npowerful class of deep networks into SNNs. We identify the main sources of\napproximation errors in previous conversion methods, and propose simple\nmechanisms to fix these issues. Furthermore, we develop spiking implementations\nof common CNN operations such as max-pooling, softmax, and batch-normalization,\nwhich allow almost loss-less conversion of arbitrary CNN architectures into the\nspiking domain. Empirical evaluation of different network architectures on the\nMNIST and CIFAR10 benchmarks leads to the best SNN results reported to date.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 07:58:34 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Rueckauer", "Bodo", ""], ["Lungu", "Iulia-Alexandra", ""], ["Hu", "Yuhuang", ""], ["Pfeiffer", "Michael", ""]]}, {"id": "1612.04197", "submitter": "Sandeep Aswath Narayana", "authors": "Sandeep Aswath Narayana", "title": "An Artificial Neural Networks based Temperature Prediction Framework for\n  Network-on-Chip based Multicore Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous improvement in silicon process technologies has made possible the\nintegration of hundreds of cores on a single chip. However, power and heat have\nbecome dominant constraints in designing these massive multicore chips causing\nissues with reliability, timing variations and reduced lifetime of the chips.\nDynamic Thermal Management (DTM) is a solution to avoid high temperatures on\nthe die. Typical DTM schemes only address core level thermal issues. However,\nthe Network-on-chip (NoC) paradigm, which has emerged as an enabling\nmethodology for integrating hundreds to thousands of cores on the same die can\ncontribute significantly to the thermal issues. Moreover, the typical DTM is\ntriggered reactively based on temperature measurements from on-chip thermal\nsensor requiring long reaction times whereas predictive DTM method estimates\nfuture temperature in advance, eliminating the chance of temperature overshoot.\nArtificial Neural Networks (ANNs) have been used in various domains for\nmodeling and prediction with high accuracy due to its ability to learn and\nadapt. This thesis concentrates on designing an ANN prediction engine to\npredict the thermal profile of the cores and Network-on-Chip elements of the\nchip. This thermal profile of the chip is then used by the predictive DTM that\ncombines both core level and network level DTM techniques. On-chip wireless\ninterconnect which is recently envisioned to enable energy-efficient data\nexchange between cores in a multicore environment, will be used to provide a\nbroadcast-capable medium to efficiently distribute thermal control messages to\ntrigger and manage the DTM schemes.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 09:11:13 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Narayana", "Sandeep Aswath", ""]]}, {"id": "1612.04316", "submitter": "Haik Manukian", "authors": "Haik Manukian, Fabio L. Traversa, Massimiliano Di Ventra", "title": "Memcomputing Numerical Inversion with Self-Organizing Logic Gates", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2017.2697386", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to use Digital Memcomputing Machines (DMMs), implemented with\nself-organizing logic gates (SOLGs), to solve the problem of numerical\ninversion. Starting from fixed-point scalar inversion we describe the\ngeneralization to solving linear systems and matrix inversion. This method,\nwhen realized in hardware, will output the result in only one computational\nstep. As an example, we perform simulations of the scalar case using a 5-bit\nlogic circuit made of SOLGs, and show that the circuit successfully performs\nthe inversion. Our method can be extended efficiently to any level of\nprecision, since we prove that producing n-bit precision in the output requires\nextending the circuit by at most n bits. This type of numerical inversion can\nbe implemented by DMM units in hardware, it is scalable, and thus of great\nbenefit to any real-time computing application.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 18:51:32 GMT"}, {"version": "v2", "created": "Wed, 4 Jan 2017 20:19:22 GMT"}, {"version": "v3", "created": "Sat, 8 Apr 2017 21:35:06 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Manukian", "Haik", ""], ["Traversa", "Fabio L.", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "1612.04357", "submitter": "Xun Huang", "authors": "Xun Huang, Yixuan Li, Omid Poursaeed, John Hopcroft, Serge Belongie", "title": "Stacked Generative Adversarial Networks", "comments": "CVPR 2017, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel generative model named Stacked Generative\nAdversarial Networks (SGAN), which is trained to invert the hierarchical\nrepresentations of a bottom-up discriminative network. Our model consists of a\ntop-down stack of GANs, each learned to generate lower-level representations\nconditioned on higher-level representations. A representation discriminator is\nintroduced at each feature hierarchy to encourage the representation manifold\nof the generator to align with that of the bottom-up discriminative network,\nleveraging the powerful discriminative representations to guide the generative\nmodel. In addition, we introduce a conditional loss that encourages the use of\nconditional information from the layer above, and a novel entropy loss that\nmaximizes a variational lower bound on the conditional entropy of generator\noutputs. We first train each stack independently, and then train the whole\nmodel end-to-end. Unlike the original GAN that uses a single noise vector to\nrepresent all the variations, our SGAN decomposes variations into multiple\nlevels and gradually resolves uncertainties in the top-down generative process.\nBased on visual inspection, Inception scores and visual Turing test, we\ndemonstrate that SGAN is able to generate images of much higher quality than\nGANs without stacking.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 20:48:58 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 01:21:55 GMT"}, {"version": "v3", "created": "Tue, 7 Mar 2017 07:50:27 GMT"}, {"version": "v4", "created": "Wed, 12 Apr 2017 15:04:01 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Huang", "Xun", ""], ["Li", "Yixuan", ""], ["Poursaeed", "Omid", ""], ["Hopcroft", "John", ""], ["Belongie", "Serge", ""]]}, {"id": "1612.04659", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Zhi Wang, Liwei Wang", "title": "Stable Memory Allocation in the Hippocampus: Fundamental Limits and\n  Neural Realization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is believed that hippocampus functions as a memory allocator in brain, the\nmechanism of which remains unrevealed. In Valiant's neuroidal model, the\nhippocampus was described as a randomly connected graph, the computation on\nwhich maps input to a set of activated neuroids with stable size. Valiant\nproposed three requirements for the hippocampal circuit to become a stable\nmemory allocator (SMA): stability, continuity and orthogonality. The\nfunctionality of SMA in hippocampus is essential in further computation within\ncortex, according to Valiant's model.\n  In this paper, we put these requirements for memorization functions into\nrigorous mathematical formulation and introduce the concept of capacity, based\non the probability of erroneous allocation. We prove fundamental limits for the\ncapacity and error probability of SMA, in both data-independent and\ndata-dependent settings. We also establish an example of stable memory\nallocator that can be implemented via neuroidal circuits. Both theoretical\nbounds and simulation results show that the neural SMA functions well.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 14:26:05 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Mou", "Wenlong", ""], ["Wang", "Zhi", ""], ["Wang", "Liwei", ""]]}, {"id": "1612.04742", "submitter": "Stefan Lattner", "authors": "Stefan Lattner, Maarten Grachten, Gerhard Widmer", "title": "Imposing higher-level Structure in Polyphonic Music Generation using\n  Convolutional Restricted Boltzmann Machines and Constraints", "comments": "31 pages, 11 figures", "journal-ref": "Journal of Creative Music Systems, Volume 2, Issue 1, March 2018", "doi": "10.5920/jcms.2018.01", "report-no": null, "categories": "cs.SD cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method for imposing higher-level structure on generated,\npolyphonic music. A Convolutional Restricted Boltzmann Machine (C-RBM) as a\ngenerative model is combined with gradient descent constraint optimisation to\nprovide further control over the generation process. Among other things, this\nallows for the use of a \"template\" piece, from which some structural properties\ncan be extracted, and transferred as constraints to the newly generated\nmaterial. The sampling process is guided with Simulated Annealing to avoid\nlocal optima, and to find solutions that both satisfy the constraints, and are\nrelatively stable with respect to the C-RBM. Results show that with this\napproach it is possible to control the higher-level self-similarity structure,\nthe meter, and the tonal properties of the resulting musical piece, while\npreserving its local musical coherence.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 17:33:38 GMT"}, {"version": "v2", "created": "Thu, 15 Dec 2016 01:48:52 GMT"}, {"version": "v3", "created": "Thu, 17 Aug 2017 15:21:05 GMT"}, {"version": "v4", "created": "Sat, 14 Apr 2018 12:43:15 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Lattner", "Stefan", ""], ["Grachten", "Maarten", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1612.04897", "submitter": "Takayuki Osogami Ph.D.", "authors": "Takayuki Osogami", "title": "Learning binary or real-valued time-series via spike-timing dependent\n  plasticity", "comments": "This paper was accepted and presented at Computing with Spikes NIPS\n  2016 Workshop, Barcelona, Spain, December 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dynamic Boltzmann machine (DyBM) has been proposed as a model of a spiking\nneural network, and its learning rule of maximizing the log-likelihood of given\ntime-series has been shown to exhibit key properties of spike-timing dependent\nplasticity (STDP), which had been postulated and experimentally confirmed in\nthe field of neuroscience as a learning rule that refines the Hebbian rule.\nHere, we relax some of the constraints in the DyBM in a way that it becomes\nmore suitable for computation and learning. We show that learning the DyBM can\nbe considered as logistic regression for binary-valued time-series. We also\nshow how the DyBM can learn real-valued data in the form of a Gaussian DyBM and\ndiscuss its relation to the vector autoregressive (VAR) model. The Gaussian\nDyBM extends the VAR by using additional explanatory variables, which\ncorrespond to the eligibility traces of the DyBM and capture long term\ndependency of the time-series. Numerical experiments show that the Gaussian\nDyBM significantly improves the predictive accuracy over VAR.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 00:57:51 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Osogami", "Takayuki", ""]]}, {"id": "1612.04970", "submitter": "Tomas Maul", "authors": "Kien Tuong Phan, Tomas Henrique Maul, Tuong Thuy Vu, Lai Weng Kin", "title": "Improving Neural Network Generalization by Combining Parallel Circuits\n  with Dropout", "comments": "Pre-print. The final publication is available at Springer via\n  http://dx.doi.org/10.1007/978-3-319-46675-0_63", "journal-ref": null, "doi": "10.1007/978-3-319-46675-0_63", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an attempt to solve the lengthy training times of neural networks, we\nproposed Parallel Circuits (PCs), a biologically inspired architecture.\nPrevious work has shown that this approach fails to maintain generalization\nperformance in spite of achieving sharp speed gains. To address this issue, and\nmotivated by the way Dropout prevents node co-adaption, in this paper, we\nsuggest an improvement by extending Dropout to the PC architecture. The paper\nprovides multiple insights into this combination, including a variety of fusion\napproaches. Experiments show promising results in which improved error rates\nare achieved in most cases, whilst maintaining the speed advantage of the PC\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 08:38:58 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Phan", "Kien Tuong", ""], ["Maul", "Tomas Henrique", ""], ["Vu", "Tuong Thuy", ""], ["Kin", "Lai Weng", ""]]}, {"id": "1612.05054", "submitter": "Ashish Bora", "authors": "Ashish Bora, Sugato Basu, Joydeep Ghosh", "title": "Graphical RNN Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many time series are generated by a set of entities that interact with one\nanother over time. This paper introduces a broad, flexible framework to learn\nfrom multiple inter-dependent time series generated by such entities. Our\nframework explicitly models the entities and their interactions through time.\nIt achieves this by building on the capabilities of Recurrent Neural Networks,\nwhile also offering several ways to incorporate domain knowledge/constraints\ninto the model architecture. The capabilities of our approach are showcased\nthrough an application to weather prediction, which shows gains over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 13:24:41 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Bora", "Ashish", ""], ["Basu", "Sugato", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1612.05231", "submitter": "Li Jing", "authors": "Li Jing, Yichen Shen, Tena Dub\\v{c}ek, John Peurifoy, Scott Skirlo,\n  Yann LeCun, Max Tegmark, Marin Solja\\v{c}i\\'c", "title": "Tunable Efficient Unitary Neural Networks (EUNN) and their application\n  to RNNs", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using unitary (instead of general) matrices in artificial neural networks\n(ANNs) is a promising way to solve the gradient explosion/vanishing problem, as\nwell as to enable ANNs to learn long-term correlations in the data. This\napproach appears particularly promising for Recurrent Neural Networks (RNNs).\nIn this work, we present a new architecture for implementing an Efficient\nUnitary Neural Network (EUNNs); its main advantages can be summarized as\nfollows. Firstly, the representation capacity of the unitary space in an EUNN\nis fully tunable, ranging from a subspace of SU(N) to the entire unitary space.\nSecondly, the computational complexity for training an EUNN is merely\n$\\mathcal{O}(1)$ per parameter. Finally, we test the performance of EUNNs on\nthe standard copying task, the pixel-permuted MNIST digit recognition benchmark\nas well as the Speech Prediction Test (TIMIT). We find that our architecture\nsignificantly outperforms both other state-of-the-art unitary RNNs and the LSTM\narchitecture, in terms of the final performance and/or the wall-clock training\nspeed. EUNNs are thus promising alternatives to RNNs and LSTMs for a wide\nvariety of applications.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 20:39:15 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 19:00:50 GMT"}, {"version": "v3", "created": "Mon, 3 Apr 2017 17:13:38 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Jing", "Li", ""], ["Shen", "Yichen", ""], ["Dub\u010dek", "Tena", ""], ["Peurifoy", "John", ""], ["Skirlo", "Scott", ""], ["LeCun", "Yann", ""], ["Tegmark", "Max", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "1612.05251", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee, Peter Szolovits", "title": "Neural Networks for Joint Sentence Classification in Medical Paper\n  Abstracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing models based on artificial neural networks (ANNs) for sentence\nclassification often do not incorporate the context in which sentences appear,\nand classify sentences individually. However, traditional sentence\nclassification approaches have been shown to greatly benefit from jointly\nclassifying subsequent sentences, such as with conditional random fields. In\nthis work, we present an ANN architecture that combines the effectiveness of\ntypical ANN models to classify sentences in isolation, with the strength of\nstructured prediction. Our model achieves state-of-the-art results on two\ndifferent datasets for sequential sentence classification in medical abstracts.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 20:57:56 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""], ["Szolovits", "Peter", ""]]}, {"id": "1612.05536", "submitter": "Menouar Boulif", "authors": "Boulif Menouar", "title": "A new cut-based genetic algorithm for graph partitioning applied to cell\n  formation", "comments": "12 pages, 4 figures, unpublished work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cell formation is a critical step in the design of cellular manufacturing\nsystems. Recently, it was tackled using a cut-based-graph-partitioning model.\nThis model meets real-life production systems requirements as it uses the\nactual amount of product flows, it looks for the suitable number of cells, and\nit takes into account the natural constraints such as operation sequences,\nmaximum cell size, cohabitation and non-cohabitation constraints. Based on this\nmodel, we propose an original encoding representation to solve the problem by\nusing a genetic algorithm. We discuss the performance of this new GA in\ncomparison to some approaches taken from the literature on a set of medium\nsized instances. Given the results we obtained, it is reasonable to assume that\nthe new GA will provide similar results for large real-life problems. Keywords:\nGroup Technology, Manufacturing Cell Formation, Graph Partitioning, Graph Cuts,\nGenetic Algorithm, Encoding representation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 16:16:54 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Menouar", "Boulif", ""]]}, {"id": "1612.05571", "submitter": "Daniel Neil", "authors": "Daniel Neil, Jun Haeng Lee, Tobi Delbruck, Shih-Chii Liu", "title": "Delta Networks for Optimized Recurrent Network Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many neural networks exhibit stability in their activation patterns over time\nin response to inputs from sensors operating under real-world conditions. By\ncapitalizing on this property of natural signals, we propose a Recurrent Neural\nNetwork (RNN) architecture called a delta network in which each neuron\ntransmits its value only when the change in its activation exceeds a threshold.\nThe execution of RNNs as delta networks is attractive because their states must\nbe stored and fetched at every timestep, unlike in convolutional neural\nnetworks (CNNs). We show that a naive run-time delta network implementation\noffers modest improvements on the number of memory accesses and computes, but\noptimized training techniques confer higher accuracy at higher speedup. With\nthese optimizations, we demonstrate a 9X reduction in cost with negligible loss\nof accuracy for the TIDIGITS audio digit recognition benchmark. Similarly, on\nthe large Wall Street Journal speech recognition benchmark even existing\nnetworks can be greatly accelerated as delta networks, and a 5.7x improvement\nwith negligible loss of accuracy can be obtained through training. Finally, on\nan end-to-end CNN trained for steering angle prediction in a driving dataset,\nthe RNN cost can be reduced by a substantial 100X.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 17:57:15 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Neil", "Daniel", ""], ["Lee", "Jun Haeng", ""], ["Delbruck", "Tobi", ""], ["Liu", "Shih-Chii", ""]]}, {"id": "1612.05596", "submitter": "Emre Neftci", "authors": "Emre Neftci, Charles Augustine, Somnath Paul, Georgios Detorakis", "title": "Neuromorphic Deep Learning Machines", "comments": null, "journal-ref": null, "doi": "10.3389/fnins.2017.00324", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ongoing challenge in neuromorphic computing is to devise general and\ncomputationally efficient models of inference and learning which are compatible\nwith the spatial and temporal constraints of the brain. One increasingly\npopular and successful approach is to take inspiration from inference and\nlearning algorithms used in deep neural networks. However, the workhorse of\ndeep learning, the gradient descent Back Propagation (BP) rule, often relies on\nthe immediate availability of network-wide information stored with\nhigh-precision memory, and precise operations that are difficult to realize in\nneuromorphic hardware. Remarkably, recent work showed that exact backpropagated\nweights are not essential for learning deep representations. Random BP replaces\nfeedback weights with random ones and encourages the network to adjust its\nfeed-forward weights to learn pseudo-inverses of the (random) feedback weights.\nBuilding on these results, we demonstrate an event-driven random BP (eRBP) rule\nthat uses an error-modulated synaptic plasticity for learning deep\nrepresentations in neuromorphic computing hardware. The rule requires only one\naddition and two comparisons for each synaptic weight using a two-compartment\nleaky Integrate & Fire (I&F) neuron, making it very suitable for implementation\nin digital or mixed-signal neuromorphic hardware. Our results show that using\neRBP, deep representations are rapidly learned, achieving nearly identical\nclassification accuracies compared to artificial neural network simulations on\nGPUs, while being robust to neural and synaptic state quantizations during\nlearning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 19:06:35 GMT"}, {"version": "v2", "created": "Sat, 21 Jan 2017 07:45:32 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Neftci", "Emre", ""], ["Augustine", "Charles", ""], ["Paul", "Somnath", ""], ["Detorakis", "Georgios", ""]]}, {"id": "1612.05695", "submitter": "Pooya Ronagh", "authors": "Daniel Crawford, Anna Levit, Navid Ghadermarzy, Jaspreet S. Oberoi,\n  Pooya Ronagh", "title": "Reinforcement Learning Using Quantum Boltzmann Machines", "comments": null, "journal-ref": "Quantum Information & Computation, Volume 18 (1-2), pp. 0051-0074\n  (2018)", "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate whether quantum annealers with select chip layouts can\noutperform classical computers in reinforcement learning tasks. We associate a\ntransverse field Ising spin Hamiltonian with a layout of qubits similar to that\nof a deep Boltzmann machine (DBM) and use simulated quantum annealing (SQA) to\nnumerically simulate quantum sampling from this system. We design a\nreinforcement learning algorithm in which the set of visible nodes representing\nthe states and actions of an optimal policy are the first and last layers of\nthe deep network. In absence of a transverse field, our simulations show that\nDBMs are trained more effectively than restricted Boltzmann machines (RBM) with\nthe same number of nodes. We then develop a framework for training the network\nas a quantum Boltzmann machine (QBM) in the presence of a significant\ntransverse field for reinforcement learning. This method also outperforms the\nreinforcement learning method that uses RBMs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Dec 2016 02:33:41 GMT"}, {"version": "v2", "created": "Sun, 25 Dec 2016 08:18:19 GMT"}, {"version": "v3", "created": "Thu, 3 Jan 2019 20:49:47 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Crawford", "Daniel", ""], ["Levit", "Anna", ""], ["Ghadermarzy", "Navid", ""], ["Oberoi", "Jaspreet S.", ""], ["Ronagh", "Pooya", ""]]}, {"id": "1612.05836", "submitter": "Shervin Ardeshir", "authors": "Shervin Ardeshir, Krishna Regmi, and Ali Borji", "title": "EgoTransfer: Transferring Motion Across Egocentric and Exocentric\n  Domains using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mirror neurons have been observed in the primary motor cortex of primate\nspecies, in particular in humans and monkeys. A mirror neuron fires when a\nperson performs a certain action, and also when he observes the same action\nbeing performed by another person. A crucial step towards building fully\nautonomous intelligent systems with human-like learning abilities is the\ncapability in modeling the mirror neuron. On one hand, the abundance of\negocentric cameras in the past few years has offered the opportunity to study a\nlot of vision problems from the first-person perspective. A great deal of\ninteresting research has been done during the past few years, trying to explore\nvarious computer vision tasks from the perspective of the self. On the other\nhand, videos recorded by traditional static cameras, capture humans performing\ndifferent actions from an exocentric third-person perspective. In this work, we\ntake the first step towards relating motion information across these two\nperspectives. We train models that predict motion in an egocentric view, by\nobserving it from an exocentric view, and vice versa. This allows models to\npredict how an egocentric motion would look like from outside. To do so, we\ntrain linear and nonlinear models and evaluate their performance in terms of\nretrieving the egocentric (exocentric) motion features, while having access to\nan exocentric (egocentric) motion feature. Our experimental results demonstrate\nthat motion information can be successfully transferred across the two views.\n", "versions": [{"version": "v1", "created": "Sat, 17 Dec 2016 23:33:37 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Ardeshir", "Shervin", ""], ["Regmi", "Krishna", ""], ["Borji", "Ali", ""]]}, {"id": "1612.05974", "submitter": "Francesco Conti", "authors": "Francesco Conti, Robert Schilling, Pasquale Davide Schiavone, Antonio\n  Pullini, Davide Rossi, Frank Kagan G\\\"urkaynak, Michael Muehlberghuber,\n  Michael Gautschi, Igor Loi, Germain Haugou, Stefan Mangard, Luca Benini", "title": "An IoT Endpoint System-on-Chip for Secure and Energy-Efficient\n  Near-Sensor Analytics", "comments": "15 pages, 12 figures, accepted for publication to the IEEE\n  Transactions on Circuits and Systems - I: Regular Papers", "journal-ref": null, "doi": "10.1109/TCSI.2017.2698019", "report-no": null, "categories": "cs.AR cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-sensor data analytics is a promising direction for IoT endpoints, as it\nminimizes energy spent on communication and reduces network load - but it also\nposes security concerns, as valuable data is stored or sent over the network at\nvarious stages of the analytics pipeline. Using encryption to protect sensitive\ndata at the boundary of the on-chip analytics engine is a way to address data\nsecurity issues. To cope with the combined workload of analytics and encryption\nin a tight power envelope, we propose Fulmine, a System-on-Chip based on a\ntightly-coupled multi-core cluster augmented with specialized blocks for\ncompute-intensive data processing and encryption functions, supporting software\nprogrammability for regular computing tasks. The Fulmine SoC, fabricated in\n65nm technology, consumes less than 20mW on average at 0.8V achieving an\nefficiency of up to 70pJ/B in encryption, 50pJ/px in convolution, or up to\n25MIPS/mW in software. As a strong argument for real-life flexible application\nof our platform, we show experimental results for three secure analytics use\ncases: secure autonomous aerial surveillance with a state-of-the-art deep CNN\nconsuming 3.16pJ per equivalent RISC op; local CNN-based face detection with\nsecured remote recognition in 5.74pJ/op; and seizure detection with encrypted\ndata collection from EEG within 12.7pJ/op.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 19:20:42 GMT"}, {"version": "v2", "created": "Sun, 2 Apr 2017 22:55:15 GMT"}, {"version": "v3", "created": "Sun, 23 Apr 2017 17:39:09 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Conti", "Francesco", ""], ["Schilling", "Robert", ""], ["Schiavone", "Pasquale Davide", ""], ["Pullini", "Antonio", ""], ["Rossi", "Davide", ""], ["G\u00fcrkaynak", "Frank Kagan", ""], ["Muehlberghuber", "Michael", ""], ["Gautschi", "Michael", ""], ["Loi", "Igor", ""], ["Haugou", "Germain", ""], ["Mangard", "Stefan", ""], ["Benini", "Luca", ""]]}, {"id": "1612.06093", "submitter": "Min Jiang", "authors": "Min Jiang, Zhongqiang Huang, Liming Qiu, Wenzhen Huang and Gary G. Yen", "title": "Transfer Learning based Dynamic Multiobjective Optimization Algorithms", "comments": null, "journal-ref": null, "doi": "10.1109/TEVC.2017.2771451", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major distinguishing features of the dynamic multiobjective\noptimization problems (DMOPs) is the optimization objectives will change over\ntime, thus tracking the varying Pareto-optimal front becomes a challenge. One\nof the promising solutions is reusing the \"experiences\" to construct a\nprediction model via statistical machine learning approaches. However most of\nthe existing methods ignore the non-independent and identically distributed\nnature of data used to construct the prediction model. In this paper, we\npropose an algorithmic framework, called Tr-DMOEA, which integrates transfer\nlearning and population-based evolutionary algorithm for solving the DMOPs.\nThis approach takes the transfer learning method as a tool to help reuse the\npast experience for speeding up the evolutionary process, and at the same time,\nany population based multiobjective algorithms can benefit from this\nintegration without any extensive modifications. To verify this, we incorporate\nthe proposed approach into the development of three well-known algorithms,\nnondominated sorting genetic algorithm II (NSGA-II), multiobjective particle\nswarm optimization (MOPSO), and the regularity model-based multiobjective\nestimation of distribution algorithm (RM-MEDA), and then employ twelve\nbenchmark functions to test these algorithms as well as compare with some\nchosen state-of-the-art designs. The experimental results confirm the\neffectiveness of the proposed method through exploiting machine learning\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 09:49:28 GMT"}, {"version": "v2", "created": "Sat, 18 Nov 2017 13:04:02 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Jiang", "Min", ""], ["Huang", "Zhongqiang", ""], ["Qiu", "Liming", ""], ["Huang", "Wenzhen", ""], ["Yen", "Gary G.", ""]]}, {"id": "1612.06212", "submitter": "Thomas Laurent", "authors": "Thomas Laurent and James von Brecht", "title": "A recurrent neural network without chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an exceptionally simple gated recurrent neural network (RNN)\nthat achieves performance comparable to well-known gated architectures, such as\nLSTMs and GRUs, on the word-level language modeling task. We prove that our\nmodel has simple, predicable and non-chaotic dynamics. This stands in stark\ncontrast to more standard gated architectures, whose underlying dynamical\nsystems exhibit chaotic behavior.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 14:59:14 GMT"}], "update_date": "2016-12-20", "authors_parsed": [["Laurent", "Thomas", ""], ["von Brecht", "James", ""]]}, {"id": "1612.06370", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Ross Girshick, Piotr Doll\\'ar, Trevor Darrell, Bharath\n  Hariharan", "title": "Learning Features by Watching Objects Move", "comments": "CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel yet intuitive approach to unsupervised feature\nlearning. Inspired by the human visual system, we explore whether low-level\nmotion-based grouping cues can be used to learn an effective visual\nrepresentation. Specifically, we use unsupervised motion-based segmentation on\nvideos to obtain segments, which we use as 'pseudo ground truth' to train a\nconvolutional network to segment objects from a single frame. Given the\nextensive evidence that motion plays a key role in the development of the human\nvisual system, we hope that this straightforward approach to unsupervised\nlearning will be more effective than cleverly designed 'pretext' tasks studied\nin the literature. Indeed, our extensive experiments show that this is the\ncase. When used for transfer learning on object detection, our representation\nsignificantly outperforms previous unsupervised approaches across multiple\nsettings, especially when training data for the target task is scarce.\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2016 20:56:04 GMT"}, {"version": "v2", "created": "Wed, 12 Apr 2017 04:28:47 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Pathak", "Deepak", ""], ["Girshick", "Ross", ""], ["Doll\u00e1r", "Piotr", ""], ["Darrell", "Trevor", ""], ["Hariharan", "Bharath", ""]]}, {"id": "1612.06519", "submitter": "Forrest Iandola", "authors": "Forrest Iandola", "title": "Exploring the Design Space of Deep Convolutional Neural Networks at\n  Large Scale", "comments": "thesis, UC Berkeley (2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the research community has discovered that deep neural\nnetworks (DNNs) and convolutional neural networks (CNNs) can yield higher\naccuracy than all previous solutions to a broad array of machine learning\nproblems. To our knowledge, there is no single CNN/DNN architecture that solves\nall problems optimally. Instead, the \"right\" CNN/DNN architecture varies\ndepending on the application at hand. CNN/DNNs comprise an enormous design\nspace. Quantitatively, we find that a small region of the CNN design space\ncontains 30 billion different CNN architectures.\n  In this dissertation, we develop a methodology that enables systematic\nexploration of the design space of CNNs. Our methodology is comprised of the\nfollowing four themes.\n  1. Judiciously choosing benchmarks and metrics.\n  2. Rapidly training CNN models.\n  3. Defining and describing the CNN design space.\n  4. Exploring the design space of CNN architectures.\n  Taken together, these four themes comprise an effective methodology for\ndiscovering the \"right\" CNN architectures to meet the needs of practical\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 06:20:43 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Iandola", "Forrest", ""]]}, {"id": "1612.06962", "submitter": "Zijun Wu", "authors": "Zijun Wu, Rolf Moehring, Jianhui Lai", "title": "Stochastic Runtime Analysis of a Cross Entropy Algorithm for Traveling\n  Salesman Problems", "comments": "40 pages, 7 figures", "journal-ref": "Theoretical Computer Science, 2017", "doi": "10.1016/j.tcs.2017.10.012", "report-no": null, "categories": "cs.DS cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article analyzes the stochastic runtime of a Cross-Entropy Algorithm on\ntwo classes of traveling salesman problems. The algorithm shares main features\nof the famous Max-Min Ant System with iteration-best reinforcement.\n  For simple instances that have a $\\{1,n\\}$-valued distance function and a\nunique optimal solution, we prove a stochastic runtime of $O(n^{6+\\epsilon})$\nwith the vertex-based random solution generation, and a stochastic runtime of\n$O(n^{3+\\epsilon}\\ln n)$ with the edge-based random solution generation for an\narbitrary $\\epsilon\\in (0,1)$. These runtimes are very close to the known\nexpected runtime for variants of Max-Min Ant System with best-so-far\nreinforcement. They are obtained for the stronger notion of stochastic runtime,\nwhich means that an optimal solution is obtained in that time with an\noverwhelming probability, i.e., a probability tending exponentially fast to one\nwith growing problem size.\n  We also inspect more complex instances with $n$ vertices positioned on an\n$m\\times m$ grid. When the $n$ vertices span a convex polygon, we obtain a\nstochastic runtime of $O(n^{3}m^{5+\\epsilon})$ with the vertex-based random\nsolution generation, and a stochastic runtime of $O(n^{2}m^{5+\\epsilon})$ for\nthe edge-based random solution generation. When there are $k = O(1)$ many\nvertices inside a convex polygon spanned by the other $n-k$ vertices, we obtain\na stochastic runtime of $O(n^{4}m^{5+\\epsilon}+n^{6k-1}m^{\\epsilon})$ with the\nvertex-based random solution generation, and a stochastic runtime of\n$O(n^{3}m^{5+\\epsilon}+n^{3k}m^{\\epsilon})$ with the edge-based random solution\ngeneration. These runtimes are better than the expected runtime for the\nso-called $(\\mu\\!+\\!\\lambda)$ EA reported in a recent article, and again\nobtained for the stronger notion of stochastic runtime.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 03:24:26 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 03:24:57 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Wu", "Zijun", ""], ["Moehring", "Rolf", ""], ["Lai", "Jianhui", ""]]}, {"id": "1612.07029", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Scale-invariance of ruggedness measures in fractal fitness landscapes", "comments": null, "journal-ref": "International Journal of Parallel, Emergent and Distributed\n  Systems (2017)", "doi": null, "report-no": null, "categories": "nlin.CD cs.NE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with using chaos to direct trajectories to targets and\nanalyzes ruggedness and fractality of the resulting fitness landscapes. The\ntargeting problem is formulated as a dynamic fitness landscape and four\ndifferent chaotic maps generating such a landscape are studied. By using a\ncomputational approach, we analyze properties of the landscapes and quantify\ntheir fractal and rugged characteristics. In particular, it is shown that\nruggedness measures such as correlation length and information content are\nscale-invariant and self-similar.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 09:45:36 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 08:26:32 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "1612.07603", "submitter": "Wenji Li", "authors": "Zhun Fan, Wenji Li, Xinye Cai, Hui Li, Caimin Wei, Qingfu Zhang,\n  Kalyanmoy Deb and Erik D. Goodman", "title": "Difficulty Adjustable and Scalable Constrained Multi-objective Test\n  Problem Toolkit", "comments": "28 pages,8 figures, 7 tables", "journal-ref": null, "doi": "10.1162/evco_a_00259", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective evolutionary algorithms (MOEAs) have progressed significantly\nin recent decades, but most of them are designed to solve unconstrained\nmulti-objective optimization problems. In fact, many real-world multi-objective\nproblems contain a number of constraints. To promote research on constrained\nmulti-objective optimization, we first propose a problem classification scheme\nwith three primary types of difficulty, which reflect various types of\nchallenges presented by real-world optimization problems, in order to\ncharacterize the constraint functions in constrained multi-objective\noptimization problems (CMOPs). These are feasibility-hardness,\nconvergence-hardness and diversity-hardness. We then develop a general toolkit\nto construct difficulty-adjustable and scalable CMOPs (DAS-CMOPs, or DAS-CMaOPs\nwhen the number of objectives is greater than three) with three types of\nparameterized constraint functions developed to capture the three proposed\ntypes of difficulty. Based on this toolkit, we suggest nine\ndifficulty-adjustable and scalable CMOPs and nine CMaOPs. The experimental\nresults reveal that mechanisms in MOEA/D-CDP may be more effective in solving\nconvergence-hard DAS-CMOPs, while mechanisms of NSGA-II-CDP may be more\neffective in solving DAS-CMOPs with simultaneous diversity-, feasibility- and\nconvergence-hardness. Mechanisms in C-NSGA-III may be more effective in solving\nfeasibility-hard CMaOPs, while mechanisms of C-MOEA/DD may be more effective in\nsolving CMaOPs with convergence-hardness. In addition, none of them can solve\nthese problems efficiently, which stimulates us to continue to develop new\nCMOEAs and CMaOEAs to solve the suggested DAS-CMOPs and DAS-CMaOPs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 14:36:29 GMT"}, {"version": "v2", "created": "Sat, 16 Sep 2017 07:09:08 GMT"}, {"version": "v3", "created": "Tue, 28 May 2019 08:46:23 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Fan", "Zhun", ""], ["Li", "Wenji", ""], ["Cai", "Xinye", ""], ["Li", "Hui", ""], ["Wei", "Caimin", ""], ["Zhang", "Qingfu", ""], ["Deb", "Kalyanmoy", ""], ["Goodman", "Erik D.", ""]]}, {"id": "1612.07771", "submitter": "Klaus Greff", "authors": "Klaus Greff and Rupesh K. Srivastava and J\\\"urgen Schmidhuber", "title": "Highway and Residual Networks learn Unrolled Iterative Estimation", "comments": "10 + 4 pages, accepted for ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The past year saw the introduction of new architectures such as Highway\nnetworks and Residual networks which, for the first time, enabled the training\nof feedforward networks with dozens to hundreds of layers using simple gradient\ndescent. While depth of representation has been posited as a primary reason for\ntheir success, there are indications that these architectures defy a popular\nview of deep learning as a hierarchical computation of increasingly abstract\nfeatures at each layer.\n  In this report, we argue that this view is incomplete and does not adequately\nexplain several recent findings. We propose an alternative viewpoint based on\nunrolled iterative estimation -- a group of successive layers iteratively\nrefine their estimates of the same features instead of computing an entirely\nnew representation. We demonstrate that this viewpoint directly leads to the\nconstruction of Highway and Residual networks. Finally we provide preliminary\nexperiments to discuss the similarities and differences between the two\narchitectures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 19:57:35 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 19:52:47 GMT"}, {"version": "v3", "created": "Tue, 14 Mar 2017 21:27:03 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Greff", "Klaus", ""], ["Srivastava", "Rupesh K.", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1612.07828", "submitter": "Ashish Shrivastava", "authors": "Ashish Shrivastava, Tomas Pfister, Oncel Tuzel, Josh Susskind, Wenda\n  Wang, Russ Webb", "title": "Learning from Simulated and Unsupervised Images through Adversarial\n  Training", "comments": "Accepted at CVPR 2017 for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent progress in graphics, it has become more tractable to train\nmodels on synthetic images, potentially avoiding the need for expensive\nannotations. However, learning from synthetic images may not achieve the\ndesired performance due to a gap between synthetic and real image\ndistributions. To reduce this gap, we propose Simulated+Unsupervised (S+U)\nlearning, where the task is to learn a model to improve the realism of a\nsimulator's output using unlabeled real data, while preserving the annotation\ninformation from the simulator. We develop a method for S+U learning that uses\nan adversarial network similar to Generative Adversarial Networks (GANs), but\nwith synthetic images as inputs instead of random vectors. We make several key\nmodifications to the standard GAN algorithm to preserve annotations, avoid\nartifacts, and stabilize training: (i) a 'self-regularization' term, (ii) a\nlocal adversarial loss, and (iii) updating the discriminator using a history of\nrefined images. We show that this enables generation of highly realistic\nimages, which we demonstrate both qualitatively and with a user study. We\nquantitatively evaluate the generated images by training models for gaze\nestimation and hand pose estimation. We show a significant improvement over\nusing synthetic images, and achieve state-of-the-art results on the MPIIGaze\ndataset without any labeled real data.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 22:10:51 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 21:24:52 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Shrivastava", "Ashish", ""], ["Pfister", "Tomas", ""], ["Tuzel", "Oncel", ""], ["Susskind", "Josh", ""], ["Wang", "Wenda", ""], ["Webb", "Russ", ""]]}, {"id": "1612.07846", "submitter": "Daniel Durstewitz", "authors": "Daniel Durstewitz", "title": "A State Space Approach for Piecewise-Linear Recurrent Neural Networks\n  for Reconstructing Nonlinear Dynamics from Neural Measurements", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005542", "report-no": null, "categories": "q-bio.NC cs.NE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational properties of neural systems are often thought to be\nimplemented in terms of their network dynamics. Hence, recovering the system\ndynamics from experimentally observed neuronal time series, like multiple\nsingle-unit (MSU) recordings or neuroimaging data, is an important step toward\nunderstanding its computations. Ideally, one would not only seek a state space\nrepresentation of the dynamics, but would wish to have access to its governing\nequations for in-depth analysis. Recurrent neural networks (RNNs) are a\ncomputationally powerful and dynamically universal formal framework which has\nbeen extensively studied from both the computational and the dynamical systems\nperspective. Here we develop a semi-analytical maximum-likelihood estimation\nscheme for piecewise-linear RNNs (PLRNNs) within the statistical framework of\nstate space models, which accounts for noise in both the underlying latent\ndynamics and the observation process. The Expectation-Maximization algorithm is\nused to infer the latent state distribution, through a global Laplace\napproximation, and the PLRNN parameters iteratively. After validating the\nprocedure on toy examples, the approach is applied to MSU recordings from the\nrodent anterior cingulate cortex obtained during performance of a classical\nworking memory task, delayed alternation. A model with 5 states turned out to\nbe sufficient to capture the essential computational dynamics underlying task\nperformance, including stimulus-selective delay activity. The estimated models\nwere rarely multi-stable, but rather were tuned to exhibit slow dynamics in the\nvicinity of a bifurcation point. In summary, the present work advances a\nsemi-analytical (thus reasonably fast) maximum-likelihood estimation framework\nfor PLRNNs that may enable to recover the relevant dynamics underlying observed\nneuronal time series, and directly link them to computational properties.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 01:01:52 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Durstewitz", "Daniel", ""]]}, {"id": "1612.08109", "submitter": "Ashish Mani Dr.", "authors": "Nija Mani, Gursaran, and Ashish Mani", "title": "Solving Combinatorial Optimization problems with Quantum inspired\n  Evolutionary Algorithm Tuned using a Novel Heuristic Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum inspired Evolutionary Algorithms were proposed more than a decade ago\nand have been employed for solving a wide range of difficult search and\noptimization problems. A number of changes have been proposed to improve\nperformance of canonical QEA. However, canonical QEA is one of the few\nevolutionary algorithms, which uses a search operator with relatively large\nnumber of parameters. It is well known that performance of evolutionary\nalgorithms is dependent on specific value of parameters for a given problem.\nThe advantage of having large number of parameters in an operator is that the\nsearch process can be made more powerful even with a single operator without\nrequiring a combination of other operators for exploration and exploitation.\nHowever, the tuning of operators with large number of parameters is complex and\ncomputationally expensive. This paper proposes a novel heuristic method for\ntuning parameters of canonical QEA. The tuned QEA outperforms canonical QEA on\na class of discrete combinatorial optimization problems which, validates the\ndesign of the proposed parameter tuning framework. The proposed framework can\nbe used for tuning other algorithms with both large and small number of tunable\nparameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 22:51:09 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 07:05:42 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Mani", "Nija", ""], ["Gursaran", "", ""], ["Mani", "Ashish", ""]]}, {"id": "1612.08117", "submitter": "Michael Mozer", "authors": "Ronald T. Kneusel and Michael C. Mozer", "title": "Improving Human-Machine Cooperative Visual Search With Soft Highlighting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in machine learning have produced systems that attain human-level\nperformance on certain visual tasks, e.g., object identification. Nonetheless,\nother tasks requiring visual expertise are unlikely to be entrusted to machines\nfor some time, e.g., satellite and medical imagery analysis. We describe a\nhuman-machine cooperative approach to visual search, the aim of which is to\noutperform either human or machine acting alone. The traditional route to\naugmenting human performance with automatic classifiers is to draw boxes around\nregions of an image deemed likely to contain a target. Human experts typically\nreject this type of hard highlighting. We propose instead a soft highlighting\ntechnique in which the saliency of regions of the visual field is modulated in\na graded fashion based on classifier confidence level. We report on experiments\nwith both synthetic and natural images showing that soft highlighting achieves\na performance synergy surpassing that attained by hard highlighting.\n", "versions": [{"version": "v1", "created": "Sat, 24 Dec 2016 00:06:02 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Kneusel", "Ronald T.", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1612.08810", "submitter": "Hado van Hasselt", "authors": "David Silver, Hado van Hasselt, Matteo Hessel, Tom Schaul, Arthur\n  Guez, Tim Harley, Gabriel Dulac-Arnold, David Reichert, Neil Rabinowitz,\n  Andre Barreto, Thomas Degris", "title": "The Predictron: End-To-End Learning and Planning", "comments": "Camera-ready version, ICML 2017, with supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key challenges of artificial intelligence is to learn models that\nare effective in the context of planning. In this document we introduce the\npredictron architecture. The predictron consists of a fully abstract model,\nrepresented by a Markov reward process, that can be rolled forward multiple\n\"imagined\" planning steps. Each forward pass of the predictron accumulates\ninternal rewards and values over multiple planning depths. The predictron is\ntrained end-to-end so as to make these accumulated values accurately\napproximate the true value function. We applied the predictron to procedurally\ngenerated random mazes and a simulator for the game of pool. The predictron\nyielded significantly more accurate predictions than conventional deep neural\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 06:47:15 GMT"}, {"version": "v2", "created": "Fri, 20 Jan 2017 14:57:31 GMT"}, {"version": "v3", "created": "Thu, 20 Jul 2017 09:21:54 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Silver", "David", ""], ["van Hasselt", "Hado", ""], ["Hessel", "Matteo", ""], ["Schaul", "Tom", ""], ["Guez", "Arthur", ""], ["Harley", "Tim", ""], ["Dulac-Arnold", "Gabriel", ""], ["Reichert", "David", ""], ["Rabinowitz", "Neil", ""], ["Barreto", "Andre", ""], ["Degris", "Thomas", ""]]}, {"id": "1612.08813", "submitter": "Ahmed Mateen Mr.", "authors": "Ahmed Mateen, Marriam Nazir, Salman Afsar Awan", "title": "Optimization of Test Case Generation using Genetic Algorithm (GA)", "comments": "9 pages", "journal-ref": "International Journal of Computer Applications Foundation of\n  Computer Science (FCS), NY, USA Volume 151 - Number 7 Year of Publication:\n  2016", "doi": "10.5120/ijca2016911703", "report-no": null, "categories": "cs.SE cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Testing provides means pertaining to assuring software performance. The total\naim of software industry is actually to make a certain start associated with\nhigh quality software for the end user. However, associated with software\ntesting has quite a few underlying concerns, which are very important and need\nto pay attention on these issues. These issues are effectively generating,\nprioritization of test cases, etc. These issues can be overcome by paying\nattention and focus. Solitary of the greatest Problems in the software testing\narea is usually how to acquire a great proper set associated with cases to\nconfirm software. Some other strategies and also methodologies are proposed\npertaining to shipping care of most of these issues. Genetic Algorithm (GA)\nbelongs to evolutionary algorithms. Evolutionary algorithms have a significant\nrole in the automatic test generation and many researchers are focusing on it.\nIn this study explored software testing related issues by using the GA\napproach. In addition to right after applying some analysis, better solution\nproduced, that is feasible and reliable. The particular research presents the\nimplementation of GAs because of its generation of optimized test cases. Along\nthese lines, this paper gives proficient system for the optimization of test\ncase generation using genetic algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 06:55:53 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Mateen", "Ahmed", ""], ["Nazir", "Marriam", ""], ["Awan", "Salman Afsar", ""]]}, {"id": "1612.09022", "submitter": "Fathi Salem", "authors": "Fathi M. Salem", "title": "A Basic Recurrent Neural Network Model", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model of a basic recurrent neural network (or bRNN) that\nincludes a separate linear term with a slightly \"stable\" fixed matrix to\nguarantee bounded solutions and fast dynamic response. We formulate a state\nspace viewpoint and adapt the constrained optimization Lagrange Multiplier\n(CLM) technique and the vector Calculus of Variations (CoV) to derive the\n(stochastic) gradient descent. In this process, one avoids the commonly used\nre-application of the circular chain-rule and identifies the error\nback-propagation with the co-state backward dynamic equations. We assert that\nthis bRNN can successfully perform regression tracking of time-series.\nMoreover, the \"vanishing and exploding\" gradients are explicitly quantified and\nexplained through the co-state dynamics and the update laws. The adapted CoV\nframework, in addition, can correctly and principally integrate new loss\nfunctions in the network on any variable and for varied goals, e.g., for\nsupervised learning on the outputs and unsupervised learning on the internal\n(hidden) states.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 02:10:50 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Salem", "Fathi M.", ""]]}, {"id": "1612.09205", "submitter": "Tamas Madl", "authors": "Tamas Madl", "title": "Deep neural heart rate variability analysis", "comments": "6 pages in NIPS 2016 Workshop on Machine Learning for Health (ML4HC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite of the pain and limited accuracy of blood tests for early recognition\nof cardiovascular disease, they dominate risk screening and triage. On the\nother hand, heart rate variability is non-invasive and cheap, but not\nconsidered accurate enough for clinical practice. Here, we tackle heart beat\ninterval based classification with deep learning. We introduce an end to end\ndifferentiable hybrid architecture, consisting of a layer of biological neuron\nmodels of cardiac dynamics (modified FitzHugh Nagumo neurons) and several\nlayers of a standard feed-forward neural network. The proposed model is\nevaluated on ECGs from 474 stable at-risk (coronary artery disease) patients,\nand 1172 chest pain patients of an emergency department. We show that it can\nsignificantly outperform models based on traditional heart rate variability\npredictors, as well as approaching or in some cases outperforming clinical\nblood tests, based only on 60 seconds of inter-beat intervals.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2016 17:14:05 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Madl", "Tamas", ""]]}, {"id": "1612.09292", "submitter": "Stephen Russek", "authors": "S. E. Russek, C. A. Donnelly, M. L. Schneider, B. Baek, M. R. Pufall,\n  W. H. Rippard, P. F. Hopkins, P. D. Dresselhaus, S. P. Benz", "title": "Stochastic single flux quantum neuromorphic computing using magnetically\n  tunable Josephson junctions", "comments": "2016 IEEE International Conference on Rebooting Computing (ICRC)", "journal-ref": null, "doi": "10.1109/ICRC.2016.7738712", "report-no": null, "categories": "cond-mat.supr-con cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single flux quantum (SFQ) circuits form a natural neuromorphic technology\nwith SFQ pulses and superconducting transmission lines simulating action\npotentials and axons, respectively. Here we present a new component, magnetic\nJosephson junctions, that have a tunablility and re-configurability that was\nlacking from previous SFQ neuromorphic circuits. The nanoscale magnetic\nstructure acts as a tunable synaptic constituent that modifies the junction\ncritical current. These circuits can operate near the thermal limit where\nstochastic firing of the neurons is an essential component of the technology.\nThis technology has the ability to create complex neural systems with greater\nthan 10^21 neural firings per second with approximately 1 W dissipation.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 22:17:43 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Russek", "S. E.", ""], ["Donnelly", "C. A.", ""], ["Schneider", "M. L.", ""], ["Baek", "B.", ""], ["Pufall", "M. R.", ""], ["Rippard", "W. H.", ""], ["Hopkins", "P. F.", ""], ["Dresselhaus", "P. D.", ""], ["Benz", "S. P.", ""]]}, {"id": "1612.09506", "submitter": "Mundher Al-Shabi", "authors": "Tee Connie, Mundher Al-Shabi, Michael Goh", "title": "Smart Content Recognition from Images Using a Mixture of Convolutional\n  Neural Networks", "comments": "To be published in LNEE, Code: github.com/mundher/NSFW", "journal-ref": null, "doi": "10.1007/978-981-10-6451-7_2", "report-no": null, "categories": "stat.ML cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid development of the Internet, web contents become huge. Most of the\nwebsites are publicly available, and anyone can access the contents from\nanywhere such as workplace, home and even schools. Nevertheless, not all the\nweb contents are appropriate for all users, especially children. An example of\nthese contents is pornography images which should be restricted to certain age\ngroup. Besides, these images are not safe for work (NSFW) in which employees\nshould not be seen accessing such contents during work. Recently, convolutional\nneural networks have been successfully applied to many computer vision\nproblems. Inspired by these successes, we propose a mixture of convolutional\nneural networks for adult content recognition. Unlike other works, our method\nis formulated on a weighted sum of multiple deep neural network models. The\nweights of each CNN models are expressed as a linear regression problem learned\nusing Ordinary Least Squares (OLS). Experimental results demonstrate that the\nproposed model outperforms both single CNN model and the average sum of CNN\nmodels in adult content recognition.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 15:18:39 GMT"}, {"version": "v2", "created": "Fri, 14 Jul 2017 09:03:57 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Connie", "Tee", ""], ["Al-Shabi", "Mundher", ""], ["Goh", "Michael", ""]]}]