[{"id": "1805.00092", "submitter": "Jun He", "authors": "Jun He and Tao Xu", "title": "New Methods of Studying Valley Fitness Landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The word \"valley\" is a popular term used in intuitively describing fitness\nlandscapes. What is a valley on a fitness landscape? How to identify the\ndirection and location of a valley if it exists? However, such questions are\nseldom rigorously studied in evolutionary optimization especially when the\nsearch space is a high dimensional continuous space. This paper presents two\nmethods of studying valleys on a fitness landscape. The first method is based\non the topological homeomorphism. It establishes a rigorous definition of a\nvalley. A valley is regarded as a one-dimensional manifold. The second method\ntakes a different viewpoint from statistics. It provides an algorithm of\nidentifying the valley direction and location using principle component\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 20:51:20 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["He", "Jun", ""], ["Xu", "Tao", ""]]}, {"id": "1805.00254", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Benjamin Roth and Hinrich Sch\\\"utze", "title": "Joint Bootstrapping Machines for High Confidence Relation Extraction", "comments": "In Proceedings of the 16th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL-HLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised bootstrapping techniques for relationship extraction from\ntext iteratively expand a set of initial seed instances. Due to the lack of\nlabeled data, a key challenge in bootstrapping is semantic drift: if a false\npositive instance is added during an iteration, then all following iterations\nare contaminated. We introduce BREX, a new bootstrapping method that protects\nagainst such contamination by highly effective confidence assessment. This is\nachieved by using entity and template seeds jointly (as opposed to just one as\nin previous work), by expanding entities and templates in parallel and in a\nmutually constraining fashion in each iteration and by introducing\nhigherquality similarity measures for templates. Experimental results show that\nBREX achieves an F1 that is 0.13 (0.87 vs. 0.74) better than the state of the\nart for four relationships.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 09:39:19 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Roth", "Benjamin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1805.00272", "submitter": "Jun He Dr", "authors": "Wei Huang, Tao Xu, Kangshun Li and Jun He", "title": "Multiobjective Optimization Differential Evolution Enhanced with\n  Principle Component Analysis for Constrained Optimization", "comments": null, "journal-ref": "Swarm and Evolutionary Computation, 2019", "doi": "10.1016/j.swevo.2019.100571", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiobjective evolutionary algorithms (MOEAs) have been successfully applied\nto a number of constrained optimization problems. Many of them adopt mutation\nand crossover operators from differential evolution. However, these operators\ndo not explicitly utilise features of fitness landscapes. To improve the\nperformance of algorithms, this paper aims at designing a search operator\nadapting to fitness landscapes. Through an observation, we find that principle\ncomponent analysis (PCA) can be used to characterise fitness landscapes. Based\non this finding, a new search operator, called PCA-projection, is proposed. In\norder to verify the effectiveness of PCA-projection, we design two algorithms\nenhanced with PCA-projection for solving constrained optimization problems,\ncalled PMODE and HECO-PDE, respectively. Experiments have been conducted on the\nIEEE CEC 2017 competition benchmark suite in constrained optimisation. PMODE\nand HECO-PDE are compared with the algorithms from the IEEE CEC 2018\ncompetition and another recent MOEA for constrained optimisation. Experimental\nresults show that an algorithm enhanced with PCA-projection performs better\nthan its corresponding opponent without this operator. Furthermore, HECO-PDE is\nranked first on all dimensions according to the competition rules. This study\nreveals that decomposition-based MOEAs, such as HECO-PDE, are competitive with\nbest single-objective and multiobjective evolutionary algorithms for\nconstrained optimisation, but MOEAs based on non-dominance, such as PMODE, may\nnot.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 11:20:55 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 08:03:49 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Huang", "Wei", ""], ["Xu", "Tao", ""], ["Li", "Kangshun", ""], ["He", "Jun", ""]]}, {"id": "1805.00342", "submitter": "Hongxin Wang", "authors": "Hongxin Wang, Jigen Peng, and Shigang Yue", "title": "A Feedback Neural Network for Small Target Motion Detection in Cluttered\n  Backgrounds", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small target motion detection is critical for insects to search for and track\nmates or prey which always appear as small dim speckles in the visual field. A\nclass of specific neurons, called small target motion detectors (STMDs), has\nbeen characterized by exquisite sensitivity for small target motion.\nUnderstanding and analyzing visual pathway of STMD neurons are beneficial to\ndesign artificial visual systems for small target motion detection. Feedback\nloops have been widely identified in visual neural circuits and play an\nimportant role in target detection. However, if there exists a feedback loop in\nthe STMD visual pathway or if a feedback loop could significantly improve the\ndetection performance of STMD neurons, is unclear. In this paper, we propose a\nfeedback neural network for small target motion detection against naturally\ncluttered backgrounds. In order to form a feedback loop, model output is\ntemporally delayed and relayed to previous neural layer as feedback signal.\nExtensive experiments showed that the significant improvement of the proposed\nfeedback neural network over the existing STMD-based models for small target\nmotion detection.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 13:57:08 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 22:06:38 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Wang", "Hongxin", ""], ["Peng", "Jigen", ""], ["Yue", "Shigang", ""]]}, {"id": "1805.00509", "submitter": "William Severa", "authors": "William Severa, Rich Lehoucq, Ojas Parekh, James B. Aimone", "title": "Spiking Neural Algorithms for Markov Process Random Walk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random walk is a fundamental stochastic process that underlies many\nnumerical tasks in scientific computing applications. We consider here two\nneural algorithms that can be used to efficiently implement random walks on\nspiking neuromorphic hardware. The first method tracks the positions of\nindividual walkers independently by using a modular code inspired by the grid\ncell spatial representation in the brain. The second method tracks the\ndensities of random walkers at each spatial location directly. We analyze the\nscaling complexity of each of these methods and illustrate their ability to\nmodel random walkers under different probabilistic conditions.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 18:31:40 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Severa", "William", ""], ["Lehoucq", "Rich", ""], ["Parekh", "Ojas", ""], ["Aimone", "James B.", ""]]}, {"id": "1805.00728", "submitter": "Jialin Liu Ph.D", "authors": "Vanessa Volz, Jacob Schrum, Jialin Liu, Simon M. Lucas, Adam Smith,\n  Sebastian Risi", "title": "Evolving Mario Levels in the Latent Space of a Deep Convolutional\n  Generative Adversarial Network", "comments": "8 pages, GECCO2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a machine learning approach\ncapable of generating novel example outputs across a space of provided training\nexamples. Procedural Content Generation (PCG) of levels for video games could\nbenefit from such models, especially for games where there is a pre-existing\ncorpus of levels to emulate. This paper trains a GAN to generate levels for\nSuper Mario Bros using a level from the Video Game Level Corpus. The approach\nsuccessfully generates a variety of levels similar to one in the original\ncorpus, but is further improved by application of the Covariance Matrix\nAdaptation Evolution Strategy (CMA-ES). Specifically, various fitness functions\nare used to discover levels within the latent space of the GAN that maximize\ndesired properties. Simple static properties are optimized, such as a given\ndistribution of tile types. Additionally, the champion A* agent from the 2009\nMario AI competition is used to assess whether a level is playable, and how\nmany jumping actions are required to beat it. These fitness functions allow for\nthe discovery of levels that exist within the space of examples designed by\nexperts, and also guide the search towards levels that fulfill one or more\nspecified objectives.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 10:59:36 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Volz", "Vanessa", ""], ["Schrum", "Jacob", ""], ["Liu", "Jialin", ""], ["Lucas", "Simon M.", ""], ["Smith", "Adam", ""], ["Risi", "Sebastian", ""]]}, {"id": "1805.00987", "submitter": "Laurynas Karazija", "authors": "Laurynas Karazija, Petar Veli\\v{c}kovi\\'c, and Pietro Li\\`o", "title": "Automatic Inference of Cross-modal Connection Topologies for X-CNNs", "comments": "10 pages, 3 figures, 2 tables, to appear in ISNN 2018", "journal-ref": null, "doi": "10.1007/978-3-319-92537-0_7", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a way to learn cross-modal convolutional neural network\n(X-CNN) architectures from a base convolutional network (CNN) and the training\ndata to reduce the design cost and enable applying cross-modal networks in\nsparse data environments. Two approaches for building X-CNNs are presented. The\nbase approach learns the topology in a data-driven manner, by using\nmeasurements performed on the base CNN and supplied data. The iterative\napproach performs further optimisation of the topology through a combined\nlearning procedure, simultaneously learning the topology and training the\nnetwork. The approaches were evaluated agains examples of hand-designed X-CNNs\nand their base variants, showing superior performance and, in some cases,\ngaining an additional 9% of accuracy. From further considerations, we conclude\nthat the presented methodology takes less time than any manual approach would,\nwhilst also significantly reducing the design complexity. The application of\nthe methods is fully automated and implemented in Xsertion library.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 19:16:17 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Karazija", "Laurynas", ""], ["Veli\u010dkovi\u0107", "Petar", ""], ["Li\u00f2", "Pietro", ""]]}, {"id": "1805.01048", "submitter": "Baibhab Chatterjee", "authors": "Baibhab Chatterjee, Debayan Das and Shreyas Sen", "title": "RF-PUF: IoT Security Enhancement through Authentication of Wireless\n  Nodes using In-situ Machine Learning", "comments": "Presented in Hardware Oriented Security and Trust (HOST), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical unclonable functions (PUF) in silicon exploit die-to-die\nmanufacturing variations during fabrication for uniquely identifying each die.\nSince it is practically a hard problem to recreate exact silicon features\nacross dies, a PUFbased authentication system is robust, secure and\ncost-effective, as long as bias removal and error correction are taken into\naccount. In this work, we utilize the effects of inherent process variation on\nanalog and radio-frequency (RF) properties of multiple wireless transmitters\n(Tx) in a sensor network, and detect the features at the receiver (Rx) using a\ndeep neural network based framework. The proposed mechanism/framework, called\nRF-PUF, harnesses already existing RF communication hardware and does not\nrequire any additional PUF-generation circuitry in the Tx for practical\nimplementation. Simulation results indicate that the RF-PUF framework can\ndistinguish up to 10000 transmitters (with standard foundry defined variations\nfor a 65 nm process, leading to non-idealities such as LO offset and I-Q\nimbalance) under varying channel conditions, with a probability of false\ndetection < 10e-3\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 22:43:03 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Chatterjee", "Baibhab", ""], ["Das", "Debayan", ""], ["Sen", "Shreyas", ""]]}, {"id": "1805.01141", "submitter": "Rui Wang", "authors": "Rui Wang, Jeff Clune, and Kenneth O. Stanley", "title": "VINE: An Open Source Interactive Data Visualization Tool for\n  Neuroevolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep neuroevolution have demonstrated that evolutionary\nalgorithms, such as evolution strategies (ES) and genetic algorithms (GA), can\nscale to train deep neural networks to solve difficult reinforcement learning\n(RL) problems. However, it remains a challenge to analyze and interpret the\nunderlying process of neuroevolution in such high dimensions. To begin to\naddress this challenge, this paper presents an interactive data visualization\ntool called VINE (Visual Inspector for NeuroEvolution) aimed at helping\nneuroevolution researchers and end-users better understand and explore this\nfamily of algorithms. VINE works seamlessly with a breadth of neuroevolution\nalgorithms, including ES and GA, and addresses the difficulty of observing the\nunderlying dynamics of the learning process through an interactive\nvisualization of the evolving agent's behavior characterizations over\ngenerations. As neuroevolution scales to neural networks with millions or more\nconnections, visualization tools like VINE that offer fresh insight into the\nunderlying dynamics of evolution become increasingly valuable and important for\ninspiring new innovations and applications.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 07:21:43 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Wang", "Rui", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1805.01221", "submitter": "Edgar Covantes Osuna", "authors": "Edgar Covantes Osuna, Wanru Gao, Frank Neumann and Dirk Sudholt", "title": "Design and Analysis of Diversity-Based Parent Selection Schemes for\n  Speeding Up Evolutionary Multi-objective Optimisation", "comments": "To be published in Theoretical Computer Science journal", "journal-ref": null, "doi": "10.1016/j.tcs.2018.06.009", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parent selection in evolutionary algorithms for multi-objective optimisation\nis usually performed by dominance mechanisms or indicator functions that prefer\nnon-dominated points. We propose to refine the parent selection on evolutionary\nmulti-objective optimisation with diversity-based metrics. The aim is to focus\non individuals with a high diversity contribution located in poorly explored\nareas of the search space, so the chances of creating new non-dominated\nindividuals are better than in highly populated areas. We show by means of\nrigorous runtime analysis that the use of diversity-based parent selection\nmechanisms in the Simple Evolutionary Multi-objective Optimiser (SEMO) and\nGlobal SEMO for the well known bi-objective functions ${\\rm O{\\small\nNE}M{\\small IN}M{\\small AX}}$ and ${\\rm LOTZ}$ can significantly improve their\nperformance. Our theoretical results are accompanied by experimental studies\nthat show a correspondence between theory and empirical results and motivate\nfurther theoretical investigations in terms of stagnation. We show that\nstagnation might occur when favouring individuals with a high diversity\ncontribution in the parent selection step and provide a discussion on which\nscheme to use for more complex problems based on our theoretical and\nexperimental results.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 11:05:34 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 09:11:45 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Osuna", "Edgar Covantes", ""], ["Gao", "Wanru", ""], ["Neumann", "Frank", ""], ["Sudholt", "Dirk", ""]]}, {"id": "1805.01352", "submitter": "Yangfan Hu", "authors": "Yangfan Hu, Huajin Tang, Gang Pan", "title": "Spiking Deep Residual Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) have received significant attention for their\nbiological plausibility. SNNs theoretically have at least the same\ncomputational power as traditional artificial neural networks (ANNs). They\npossess potential of achieving energy-efficiency while keeping comparable\nperformance to deep neural networks (DNNs). However, it is still a big\nchallenge to train a very deep SNN. In this paper, we propose an efficient\napproach to build a spiking version of deep residual network (ResNet). ResNet\nis considered as a kind of the state-of-the-art convolutional neural networks\n(CNNs). We employ the idea of converting a trained ResNet to a network of\nspiking neurons, named Spiking ResNet (S-ResNet). We propose a shortcut\nconversion model to appropriately scale continuous-valued activations to match\nfiring rates in SNN, and a compensation mechanism to reduce the error caused by\ndiscretisation. Experimental results demonstrate that, compared with the\nstate-of-the-art SNN approaches, the proposed Spiking ResNet achieves the best\nperformance on CIFAR-10, CIFAR-100, and ImageNet 2012. Our work is the first\ntime to build a SNN deeper than 40, with comparable performance to ANNs on a\nlarge-scale dataset.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 06:44:13 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 16:55:37 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Hu", "Yangfan", ""], ["Tang", "Huajin", ""], ["Pan", "Gang", ""]]}, {"id": "1805.01374", "submitter": "Baibhab Chatterjee", "authors": "Baibhab Chatterjee, Debayan Das, Shovan Maity and Shreyas Sen", "title": "RF-PUF: Enhancing IoT Security through Authentication of Wireless Nodes\n  using In-situ Machine Learning", "comments": "Accepted: in the IEEE Internet of Things Journal (JIoT), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional authentication in radio-frequency (RF) systems enable secure data\ncommunication within a network through techniques such as digital signatures\nand hash-based message authentication codes (HMAC), which suffer from key\nrecovery attacks. State-of-the-art IoT networks such as Nest also use Open\nAuthentication (OAuth 2.0) protocols that are vulnerable to cross-site-recovery\nforgery (CSRF), which shows that these techniques may not prevent an adversary\nfrom copying or modeling the secret IDs or encryption keys using invasive, side\nchannel, learning or software attacks. Physical unclonable functions (PUF), on\nthe other hand, can exploit manufacturing process variations to uniquely\nidentify silicon chips which makes a PUF-based system extremely robust and\nsecure at low cost, as it is practically impossible to replicate the same\nsilicon characteristics across dies. Taking inspiration from human\ncommunication, which utilizes inherent variations in the voice signatures to\nidentify a certain speaker, we present RF- PUF: a deep neural network-based\nframework that allows real-time authentication of wireless nodes, using the\neffects of inherent process variation on RF properties of the wireless\ntransmitters (Tx), detected through in-situ machine learning at the receiver\n(Rx) end. The proposed method utilizes the already-existing asymmetric RF\ncommunication framework and does not require any additional circuitry for PUF\ngeneration or feature extraction. Simulation results involving the process\nvariations in a standard 65 nm technology node, and features such as LO offset\nand I-Q imbalance detected with a neural network having 50 neurons in the\nhidden layer indicate that the framework can distinguish up to 4800\ntransmitters with an accuracy of 99.9% (~ 99% for 10,000 transmitters) under\nvarying channel conditions, and without the need for traditional preambles.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:28:44 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 20:15:40 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 02:00:32 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Chatterjee", "Baibhab", ""], ["Das", "Debayan", ""], ["Maity", "Shovan", ""], ["Sen", "Shreyas", ""]]}, {"id": "1805.01385", "submitter": "Yang Liu Dr.", "authors": "Yang Liu", "title": "Research on the Brain-inspired Cross-modal Neural Cognitive Computing\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address modeling problems of brain-inspired intelligence, this thesis is\nfocused on researching in the semantic-oriented framework design for multimedia\nand multimodal information. The Multimedia Neural Cognitive Computing (MNCC)\nmodel was designed based on the nervous mechanism and cognitive architecture.\nFurthermore, the semantic-oriented hierarchical Cross-modal Neural Cognitive\nComputing (CNCC) framework was proposed based on MNCC model, and formal\ndescription and analysis for CNCC framework was given. It would effectively\nimprove the performance of semantic processing for multimedia and cross-modal\ninformation, and has far-reaching significance for exploration and realization\nbrain-inspired computing.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:51:51 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 13:01:02 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Liu", "Yang", ""]]}, {"id": "1805.01516", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, E.M. Mirkes, I.Y. Tyukin", "title": "How deep should be the depth of convolutional neural networks: a\n  backyard dog case study", "comments": "Edited and extended version with more detailed description of\n  numerical experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The work concerns the problem of reducing a pre-trained deep neuronal network\nto a smaller network, with just few layers, whilst retaining the network's\nfunctionality on a given task\n  The proposed approach is motivated by the observation that the aim to deliver\nthe highest accuracy possible in the broadest range of operational conditions,\nwhich many deep neural networks models strive to achieve, may not necessarily\nbe always needed, desired, or even achievable due to the lack of data or\ntechnical constraints. In relation to the face recognition problem, we\nformulated an example of such a usecase, the `backyard dog' problem. The\n`backyard dog', implemented by a lean network, should correctly identify\nmembers from a limited group of individuals, a `family', and should distinguish\nbetween them. At the same time, the network must produce an alarm to an image\nof an individual who is not in a member of the family. To produce such a\nnetwork, we propose a shallowing algorithm. The algorithm takes an existing\ndeep learning model on its input and outputs a shallowed version of it. The\nalgorithm is non-iterative and is based on the Advanced Supervised Principal\nComponent Analysis. Performance of the algorithm is assessed in exhaustive\nnumerical experiments. In the above usecase, the `backyard dog' problem, the\nmethod is capable of drastically reducing the depth of deep learning neural\nnetworks, albeit at the cost of mild performance deterioration.\n  We developed a simple non-iterative method for shallowing down pre-trained\ndeep networks. The method is generic in the sense that it applies to a broad\nclass of feed-forward networks, and is based on the Advanced Supervise\nPrincipal Component Analysis. The method enables generation of families of\nsmaller-size shallower specialized networks tuned for specific operational\nconditions and tasks from a single larger and more universal legacy network.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 19:37:54 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 06:06:19 GMT"}, {"version": "v3", "created": "Sun, 8 Dec 2019 17:43:12 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Gorban", "A. N.", ""], ["Mirkes", "E. M.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1805.01623", "submitter": "Yong-Hyuk Kim", "authors": "Hye-Jin Kim and Yong-Hyuk Kim", "title": "Recent Progress on Graph Partitioning Problems Using Evolutionary\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph partitioning problem (GPP) is a representative combinatorial\noptimization problem which is NP-hard. Currently, various approaches to solve\nGPP have been introduced. Among these, the GPP solution using evolutionary\ncomputation (EC) is an effective approach. There has not been any survey on the\nresearch applying EC to GPP since 2011. In this survey, we introduce various\nattempts to apply EC to GPP made in the recent seven years.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 06:37:43 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Kim", "Hye-Jin", ""], ["Kim", "Yong-Hyuk", ""]]}, {"id": "1805.01831", "submitter": "Francesco Conti", "authors": "Daniele Palossi, Antonio Loquercio, Francesco Conti, Eric Flamand,\n  Davide Scaramuzza, Luca Benini", "title": "A 64mW DNN-based Visual Navigation Engine for Autonomous Nano-Drones", "comments": "15 pages, 13 figures, 5 tables, 2 listings, accepted for publication\n  in the IEEE Internet of Things Journal (IEEE IOTJ)", "journal-ref": null, "doi": "10.1109/JIOT.2019.2917066", "report-no": null, "categories": "cs.RO cs.AI cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully-autonomous miniaturized robots (e.g., drones), with artificial\nintelligence (AI) based visual navigation capabilities are extremely\nchallenging drivers of Internet-of-Things edge intelligence capabilities.\nVisual navigation based on AI approaches, such as deep neural networks (DNNs)\nare becoming pervasive for standard-size drones, but are considered out of\nreach for nanodrones with size of a few cm${}^\\mathrm{2}$. In this work, we\npresent the first (to the best of our knowledge) demonstration of a navigation\nengine for autonomous nano-drones capable of closed-loop end-to-end DNN-based\nvisual navigation. To achieve this goal we developed a complete methodology for\nparallel execution of complex DNNs directly on-bard of resource-constrained\nmilliwatt-scale nodes. Our system is based on GAP8, a novel parallel\nultra-low-power computing platform, and a 27 g commercial, open-source\nCrazyFlie 2.0 nano-quadrotor. As part of our general methodology we discuss the\nsoftware mapping techniques that enable the state-of-the-art deep convolutional\nneural network presented in [1] to be fully executed on-board within a strict 6\nfps real-time constraint with no compromise in terms of flight results, while\nall processing is done with only 64 mW on average. Our navigation engine is\nflexible and can be used to span a wide performance range: at its peak\nperformance corner it achieves 18 fps while still consuming on average just\n3.5% of the power envelope of the deployed nano-aircraft.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 15:47:33 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 16:01:07 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 13:37:53 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 08:40:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Palossi", "Daniele", ""], ["Loquercio", "Antonio", ""], ["Conti", "Francesco", ""], ["Flamand", "Eric", ""], ["Scaramuzza", "Davide", ""], ["Benini", "Luca", ""]]}, {"id": "1805.01837", "submitter": "Mathias Niepert", "authors": "Mathias Niepert and Alberto Garcia-Duran", "title": "Towards a Spectrum of Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our ongoing work on understanding the limitations of graph\nconvolutional networks (GCNs) as well as our work on generalizations of graph\nconvolutions for representing more complex node attribute dependencies. Based\non an analysis of GCNs with the help of the corresponding computation graphs,\nwe propose a generalization of existing GCNs where the aggregation operations\nare (a) determined by structural properties of the local neighborhood graphs\nand (b) not restricted to weighted averages. We show that the proposed approach\nis strictly more expressive while requiring only a modest increase in the\nnumber of parameters and computations. We also show that the proposed\ngeneralization is identical to standard convolutional layers when applied to\nregular grid graphs.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 16:13:36 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Niepert", "Mathias", ""], ["Garcia-Duran", "Alberto", ""]]}, {"id": "1805.01890", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Mojtaba Heidarysafa, Donald E. Brown, Kiana Jafari\n  Meimandi, Laura E. Barnes", "title": "RMDL: Random Multimodel Deep Learning for Classification", "comments": "Best Paper award ACM ICISDM", "journal-ref": null, "doi": "10.1145/3206098.3206111", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continually increasing number of complex datasets each year necessitates\never improving machine learning methods for robust and accurate categorization\nof these data. This paper introduces Random Multimodel Deep Learning (RMDL): a\nnew ensemble, deep learning approach for classification. Deep learning models\nhave achieved state-of-the-art results across many domains. RMDL solves the\nproblem of finding the best deep learning structure and architecture while\nsimultaneously improving robustness and accuracy through ensembles of deep\nlearning architectures. RDML can accept as input a variety data to include\ntext, video, images, and symbolic. This paper describes RMDL and shows test\nresults for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,\nand 20newsgroup. These test results show that RDML produces consistently better\nperformance than standard methods over a broad range of data types and\nclassification problems.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 19:36:43 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 16:08:33 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Kowsari", "Kamran", ""], ["Heidarysafa", "Mojtaba", ""], ["Brown", "Donald E.", ""], ["Meimandi", "Kiana Jafari", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1805.01929", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline, Sonia M. Buckley, Adam N. McCaughan, Jeff\n  Chiles, Richard P. Mirin, and Sae Woo Nam", "title": "Superconducting Optoelectronic Neurons I: General Principles", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of neural hardware is informed by the prominence of differentiated\nprocessing and information integration in cognitive systems. The central role\nof communication leads to the principal assumption of the hardware platform:\nsignals between neurons should be optical to enable fanout and communication\nwith minimal delay. The requirement of energy efficiency leads to the\nutilization of superconducting detectors to receive single-photon signals. We\ndiscuss the potential of superconducting optoelectronic hardware to achieve the\nspatial and temporal information integration advantageous for cognitive\nprocessing, and we consider physical scaling limits based on light-speed\ncommunication. We introduce the superconducting optoelectronic neurons and\nnetworks that are the subject of the subsequent papers in this series.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 20:30:20 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 17:08:50 GMT"}, {"version": "v3", "created": "Thu, 24 May 2018 22:29:19 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Shainline", "Jeffrey M.", ""], ["Buckley", "Sonia M.", ""], ["McCaughan", "Adam N.", ""], ["Chiles", "Jeff", ""], ["Mirin", "Richard P.", ""], ["Nam", "Sae Woo", ""]]}, {"id": "1805.01937", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline, Adam N. McCaughan, Sonia M. Buckley, Christine\n  A. Donnelly, Manuel Castellanos-Beltran, Michael L. Schneider, Richard P.\n  Mirin, and Sae Woo Nam", "title": "Superconducting Optoelectronic Neurons III: Synaptic Plasticity", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a means of dynamically reconfiguring the synaptic weight of a\nsuperconducting optoelectronic loop neuron, a superconducting flux storage loop\nis inductively coupled to the synaptic current bias of the neuron. A standard\nflux memory cell is used to achieve a binary synapse, and loops capable of\nstoring many flux quanta are used to enact multi-stable synapses. Circuits are\ndesigned to implement supervised learning wherein current pulses add or remove\nflux from the loop to strengthen or weaken the synaptic weight. Designs are\npresented for circuits with hundreds of intermediate synaptic weights between\nminimum and maximum strengths. Circuits for implementing unsupervised learning\nare modeled using two photons to strengthen and two photons to weaken the\nsynaptic weight via Hebbian and anti-Hebbian learning rules, and techniques are\nproposed to control the learning rate. Implementation of short-term plasticity,\nhomeostatic plasticity, and metaplasticity in loop neurons is discussed.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 21:06:40 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 17:11:51 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 19:57:45 GMT"}, {"version": "v4", "created": "Tue, 3 Jul 2018 22:41:53 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Shainline", "Jeffrey M.", ""], ["McCaughan", "Adam N.", ""], ["Buckley", "Sonia M.", ""], ["Donnelly", "Christine A.", ""], ["Castellanos-Beltran", "Manuel", ""], ["Schneider", "Michael L.", ""], ["Mirin", "Richard P.", ""], ["Nam", "Sae Woo", ""]]}, {"id": "1805.01941", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline, Adam N. McCaughan, Sonia M. Buckley, Richard P.\n  Mirin, and Sae Woo Nam", "title": "Superconducting Optoelectronic Neurons IV: Transmitter Circuits", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A superconducting optoelectronic neuron will produce a small current pulse\nupon reaching threshold. We present an amplifier chain that converts this small\ncurrent pulse to a voltage pulse sufficient to produce light from a\nsemiconductor diode. This light is the signal used to communicate between\nneurons in the network. The amplifier chain comprises a thresholding Josephson\njunction, a relaxation oscillator Josephson junction, a superconducting\nthin-film current-gated current amplifier, and a superconducting thin-film\ncurrent-gated voltage amplifier. We analyze the performance of the elements in\nthe amplifier chain in the time domain to calculate the energy consumption per\nphoton created for several values of light-emitting diode capacitance and\nefficiency. The speed of the amplification sequence allows neuronal firing up\nto at least 20\\,MHz with power density low enough to be cooled easily with\nstandard $^4$He cryogenic systems operating at 4.2\\,K.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 21:32:38 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 17:13:17 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Shainline", "Jeffrey M.", ""], ["McCaughan", "Adam N.", ""], ["Buckley", "Sonia M.", ""], ["Mirin", "Richard P.", ""], ["Nam", "Sae Woo", ""]]}, {"id": "1805.01942", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline, Jeff Chiles, Sonia M. Buckley, Adam N.\n  McCaughan, Richard P. Mirin, and Sae Woo Nam", "title": "Superconducting Optoelectronic Neurons V: Networks and Scaling", "comments": "21 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of superconducting optoelectronic neurons are investigated for their\nnear-term technological potential and long-term physical limitations. Networks\nwith short average path length, high clustering coefficient, and power-law\ndegree distribution are designed using a growth model that assigns connections\nbetween new and existing nodes based on spatial distance as well as degree of\nexisting nodes. The network construction algorithm is scalable to arbitrary\nlevels of network hierarchy and achieves systems with fractal spatial\nproperties and efficient wiring. By modeling the physical size of\nsuperconducting optoelectronic neurons, we calculate the area of these\nnetworks. A system with 8100 neurons and 330,430 total synapses will fit on a\n1\\,cm $\\times$ 1\\,cm die. Systems of millions of neurons with hundreds of\nmillions of synapses will fit on a 300\\,mm wafer. For multi-wafer assemblies,\ncommunication at light speed enables a neuronal pool the size of a large data\ncenter comprising 100 trillion neurons with coherent oscillations at 1\\,MHz.\nAssuming a power law frequency distribution, as is necessary for self-organized\ncriticality, we calculate the power consumption of the networks. We find the\nuse of single photons for communication and superconducting circuits for\ncomputation leads to power density low enough to be cooled by liquid $^4$He for\nnetworks of any scale.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 21:35:43 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 17:15:02 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 19:59:58 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Shainline", "Jeffrey M.", ""], ["Chiles", "Jeff", ""], ["Buckley", "Sonia M.", ""], ["McCaughan", "Adam N.", ""], ["Mirin", "Richard P.", ""], ["Nam", "Sae Woo", ""]]}, {"id": "1805.01947", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline, Sonia M. Buckley, Adam N. McCaughan, Jeff\n  Chiles, Richard P. Mirin, and Sae Woo Nam", "title": "Circuit designs for superconducting optoelectronic loop neurons", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": "10.1063/1.5038031", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical communication achieves high fanout and short delay advantageous for\ninformation integration in neural systems. Superconducting detectors enable\nsignaling with single photons for maximal energy efficiency. We present designs\nof superconducting optoelectronic neurons based on superconducting\nsingle-photon detectors, Josephson junctions, semiconductor light sources, and\nmulti-planar dielectric waveguides. These circuits achieve complex synaptic and\nneuronal functions with high energy efficiency, leveraging the strengths of\nlight for communication and superconducting electronics for computation. The\nneurons send few-photon signals to synaptic connections. These signals\ncommunicate neuronal firing events as well as update synaptic weights.\nSpike-timing-dependent plasticity is implemented with a single photon\ntriggering each step of the process. Microscale light-emitting diodes and\nwaveguide networks enable connectivity from a neuron to thousands of synaptic\nconnections, and the use of light for communication enables synchronization of\nneurons across an area limited only by the distance light can travel within the\nperiod of a network oscillation. Experimentally, each of the requisite circuit\nelements has been demonstrated, yet a hardware platform combining them all has\nnot been attempted. Compared to digital logic or quantum computing, device\ntolerances are relaxed. For this neural application, optical sources providing\nincoherent pulses with 10,000 photons produced with efficiency of 10$^{-3}$\noperating at 20\\,MHz at 4.2\\,K are sufficient to enable a massively scalable\nneural computing platform with connectivity comparable to the brain and thirty\nthousand times higher speed.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 22:08:40 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 17:46:09 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Shainline", "Jeffrey M.", ""], ["Buckley", "Sonia M.", ""], ["McCaughan", "Adam N.", ""], ["Chiles", "Jeff", ""], ["Mirin", "Richard P.", ""], ["Nam", "Sae Woo", ""]]}, {"id": "1805.02214", "submitter": "Marek Rei", "authors": "Marek Rei, Anders S{\\o}gaard", "title": "Zero-shot Sequence Labeling: Transferring Knowledge from Sentences to\n  Tokens", "comments": "NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can attention- or gradient-based visualization techniques be used to infer\ntoken-level labels for binary sequence tagging problems, using networks trained\nonly on sentence-level labels? We construct a neural network architecture based\non soft attention, train it as a binary sentence classifier and evaluate\nagainst token-level annotation on four different datasets. Inferring token\nlabels from a network provides a method for quantitatively evaluating what the\nmodel is learning, along with generating useful feedback in assistance systems.\nOur results indicate that attention-based methods are able to predict\ntoken-level labels more accurately, compared to gradient-based methods,\nsometimes even rivaling the supervised oracle network.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 13:53:50 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Rei", "Marek", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1805.02599", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline, Sonia M. Buckley, Adam N. McCaughan, Manuel\n  Castellanos-Beltran, Christine A. Donnelly, Michael L. Schneider, Richard P.\n  Mirin, and Sae Woo Nam", "title": "Superconducting Optoelectronic Neurons II: Receiver Circuits", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circuits using superconducting single-photon detectors and Josephson\njunctions to perform signal reception, synaptic weighting, and integration are\ninvestigated. The circuits convert photon-detection events into flux quanta,\nthe number of which is determined by the synaptic weight. The current from many\nsynaptic connections is inductively coupled to a superconducting loop that\nimplements the neuronal threshold operation. Designs are presented for synapses\nand neurons that perform integration as well as detect coincidence events for\ntemporal coding. Both excitatory and inhibitory connections are demonstrated.\nIt is shown that a neuron with a single integration loop can receive input from\n1000 such synaptic connections, and neurons of similar design could employ many\nloops for dendritic processing.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 16:17:42 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 17:10:25 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 19:55:10 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Shainline", "Jeffrey M.", ""], ["Buckley", "Sonia M.", ""], ["McCaughan", "Adam N.", ""], ["Castellanos-Beltran", "Manuel", ""], ["Donnelly", "Christine A.", ""], ["Schneider", "Michael L.", ""], ["Mirin", "Richard P.", ""], ["Nam", "Sae Woo", ""]]}, {"id": "1805.03033", "submitter": "Bogdan Penkovsky", "authors": "Bogdan Penkovsky, Laurent Larger, Daniel Brunner", "title": "Efficient Design of Hardware-Enabled Reservoir Computing in FPGAs", "comments": null, "journal-ref": null, "doi": "10.1063/1.5039826", "report-no": null, "categories": "cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a new approach towards the efficient optimization\nand implementation of reservoir computing hardware reducing the required domain\nexpert knowledge and optimization effort. First, we adapt the reservoir input\nmask to the structure of the data via linear autoencoders. We therefore\nincorporate the advantages of dimensionality reduction and dimensionality\nexpansion achieved by conventional algorithmically efficient linear algebra\nprocedures of principal component analysis. Second, we employ\nevolutionary-inspired genetic algorithm techniques resulting in a highly\nefficient optimization of reservoir dynamics with dramatically reduced number\nof evaluations comparing to exhaustive search. We illustrate the method on the\nso-called single-node reservoir computing architecture, especially suitable for\nimplementation in ultrahigh-speed hardware. The combination of both methods and\nthe resulting reduction of time required for performance optimization of a\nhardware system establish a strategy towards machine learning hardware capable\nof self-adaption to optimally solve specific problems. We confirm the validity\nof those principles building reservoir computing hardware based on a\nfield-programmable gate array.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 07:40:59 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 16:59:14 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Penkovsky", "Bogdan", ""], ["Larger", "Laurent", ""], ["Brunner", "Daniel", ""]]}, {"id": "1805.03337", "submitter": "William Wilson", "authors": "William H. Wilson", "title": "Multi-scale metrics and self-organizing maps: a computational approach\n  to the structure of sensory maps", "comments": "36 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of a bi-scale metric for use in the\ncooperative phase of the self-organizing map (SOM) algorithm. Use of a bi-scale\nmetric allows segmentation of the map into a number of regions, corresponding\nto anticipated cluster structure in the data. Such a situation occurs, for\nexample, in the somatotopic maps which inspired the SOM algo- rithm, where\nclusters of data may correspond to body surface regions whose general structure\nis known. When a bi-scale metric is appropriately applied, issues with map\nneurons that are not activated by any point in the training data are reduced or\neliminated. The paper also presents results of simulation studies on the\nplasticity of bi-scale metric maps when they are retrained af- ter loss of\ngroups of map neurons or after changes in training data (such as would occur in\na somatotopic map when a body surface region like a finger is lost/removed).\nThe paper further considers situations where tri-scale met- rics may be useful,\nand an alternative approach suggested by neurobiology, where some map regions\nadapt more slowly to stimuli because they have a lower learning rate parameter.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 01:05:51 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Wilson", "William H.", ""]]}, {"id": "1805.03473", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Lorenzo Livi, Karl {\\O}yvind Mikalsen, Michael\n  Kampffmeyer, Robert Jenssen", "title": "Learning representations for multivariate time series with missing data\n  using Temporal Kernelized Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning compressed representations of multivariate time series (MTS)\nfacilitates data analysis in the presence of noise and redundant information,\nand for a large number of variates and time steps. However, classical\ndimensionality reduction approaches are designed for vectorial data and cannot\ndeal explicitly with missing values. In this work, we propose a novel\nautoencoder architecture based on recurrent neural networks to generate\ncompressed representations of MTS. The proposed model can process inputs\ncharacterized by variable lengths and it is specifically designed to handle\nmissing data. Our autoencoder learns fixed-length vectorial representations,\nwhose pairwise similarities are aligned to a kernel function that operates in\ninput space and that handles missing values. This allows to learn good\nrepresentations, even in the presence of a significant amount of missing data.\nTo show the effectiveness of the proposed approach, we evaluate the quality of\nthe learned representations in several classification tasks, including those\ninvolving medical data, and we compare to other methods for dimensionality\nreduction. Successively, we design two frameworks based on the proposed\narchitecture: one for imputing missing data and another for one-class\nclassification. Finally, we analyze under what circumstances an autoencoder\nwith recurrent layers can learn better compressed representations of MTS than\nfeed-forward architectures.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 12:18:54 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 15:57:11 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Livi", "Lorenzo", ""], ["Mikalsen", "Karl \u00d8yvind", ""], ["Kampffmeyer", "Michael", ""], ["Jenssen", "Robert", ""]]}, {"id": "1805.03615", "submitter": "Sandra Robles", "authors": "Steven Abel, David G. Cerdeno, Sandra Robles", "title": "The Power of Genetic Algorithms: what remains of the pMSSM?", "comments": "40 pages, 27 figures, 13 tables, 1 appendix", "journal-ref": null, "doi": null, "report-no": "IPPP/18/32", "categories": "hep-ph astro-ph.CO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic Algorithms (GAs) are explored as a tool for probing new physics with\nhigh dimensionality. We study the 19-dimensional pMSSM, including experimental\nconstraints from all sources and assessing the consistency of potential signals\nof new physics. We show that GAs excel at making a fast and accurate diagnosis\nof the cross-compatibility of a set of experimental constraints in such high\ndimensional models. In the case of the pMSSM, it is found that only ${\\cal\nO}(10^4)$ model evaluations are required to obtain a best fit point in\nagreement with much more costly MCMC scans. This efficiency allows higher\ndimensional models to be falsified, and patterns in the spectrum identified,\norders of magnitude more quickly. As examples of falsification, we consider the\nmuon anomalous magnetic moment, and the Galactic Centre gamma-ray excess\nobserved by Fermi-LAT, which could in principle be explained in terms of\nneutralino dark matter. We show that both observables cannot be explained\nwithin the pMSSM, and that they provide the leading contribution to the total\ngoodness of the fit, with $\\chi^2_{\\delta a_\\mu^{\\mathrm{SUSY}}}\\approx12$ and\n$\\chi^2_{\\rm GCE}\\approx 155$, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 16:54:26 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Abel", "Steven", ""], ["Cerdeno", "David G.", ""], ["Robles", "Sandra", ""]]}, {"id": "1805.03718", "submitter": "Xiaowei Wang", "authors": "Charles Eckert, Xiaowei Wang, Jingcheng Wang, Arun Subramaniyan, Ravi\n  Iyer, Dennis Sylvester, David Blaauw, Reetuparna Das", "title": "Neural Cache: Bit-Serial In-Cache Acceleration of Deep Neural Networks", "comments": "To appear in the 45th ACM/IEEE International Symposium on Computer\n  Architecture (ISCA 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Neural Cache architecture, which re-purposes cache\nstructures to transform them into massively parallel compute units capable of\nrunning inferences for Deep Neural Networks. Techniques to do in-situ\narithmetic in SRAM arrays, create efficient data mapping and reducing data\nmovement are proposed. The Neural Cache architecture is capable of fully\nexecuting convolutional, fully connected, and pooling layers in-cache. The\nproposed architecture also supports quantization in-cache. Our experimental\nresults show that the proposed architecture can improve inference latency by\n18.3x over state-of-art multi-core CPU (Xeon E5), 7.7x over server class GPU\n(Titan Xp), for Inception v3 model. Neural Cache improves inference throughput\nby 12.4x over CPU (2.2x over GPU), while reducing power consumption by 50% over\nCPU (53% over GPU).\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 20:16:37 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Eckert", "Charles", ""], ["Wang", "Xiaowei", ""], ["Wang", "Jingcheng", ""], ["Subramaniyan", "Arun", ""], ["Iyer", "Ravi", ""], ["Sylvester", "Dennis", ""], ["Blaauw", "David", ""], ["Das", "Reetuparna", ""]]}, {"id": "1805.03886", "submitter": "Giorgio Gosti", "authors": "Viola Folli, Giorgio Gosti, Marco Leonetti, Giancarlo Ruocco", "title": "Effect of dilution in asymmetric recurrent neural networks", "comments": "31 pages, 5 figures", "journal-ref": "Folli, V., Gosti, G., Leonetti, M., Ruocco, G., Effect of dilution\n  in asymmetric recurrent neural networks. Neural Networks (2018)", "doi": "10.1016/J.NEUNET.2018.04.003", "report-no": null, "categories": "cond-mat.dis-nn cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study with numerical simulation the possible limit behaviors of\nsynchronous discrete-time deterministic recurrent neural networks composed of N\nbinary neurons as a function of a network's level of dilution and asymmetry.\nThe network dilution measures the fraction of neuron couples that are\nconnected, and the network asymmetry measures to what extent the underlying\nconnectivity matrix is asymmetric. For each given neural network, we study the\ndynamical evolution of all the different initial conditions, thus\ncharacterizing the full dynamical landscape without imposing any learning rule.\nBecause of the deterministic dynamics, each trajectory converges to an\nattractor, that can be either a fixed point or a limit cycle. These attractors\nform the set of all the possible limit behaviors of the neural network. For\neach network, we then determine the convergence times, the limit cycles'\nlength, the number of attractors, and the sizes of the attractors' basin. We\nshow that there are two network structures that maximize the number of possible\nlimit behaviors. The first optimal network structure is fully-connected and\nsymmetric. On the contrary, the second optimal network structure is highly\nsparse and asymmetric. The latter optimal is similar to what observed in\ndifferent biological neuronal circuits. These observations lead us to\nhypothesize that independently from any given learning model, an efficient and\neffective biologic network that stores a number of limit behaviors close to its\nmaximum capacity tends to develop a connectivity structure similar to one of\nthe optimal networks we found.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 08:41:27 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Folli", "Viola", ""], ["Gosti", "Giorgio", ""], ["Leonetti", "Marco", ""], ["Ruocco", "Giancarlo", ""]]}, {"id": "1805.03908", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, Santiago Pascual, Alexandros Karatzoglou", "title": "Towards a universal neural network encoder for time series", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of a time series encoder to learn representations that are\nuseful on data set types with which it has not been trained on. The encoder is\nformed of a convolutional neural network whose temporal output is summarized by\na convolutional attention mechanism. This way, we obtain a compact,\nfixed-length representation from longer, variable-length time series. We\nevaluate the performance of the proposed approach on a well-known time series\nclassification benchmark, considering full adaptation, partial adaptation, and\nno adaptation of the encoder to the new data type. Results show that such\nstrategies are competitive with the state-of-the-art, often outperforming\nconceptually-matching approaches. Besides accuracy scores, the facility of\nadaptation and the efficiency of pre-trained encoders make them an appealing\noption for the processing of scarcely- or non-labeled time series.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 09:46:45 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Pascual", "Santiago", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "1805.03963", "submitter": "Veit Elser", "authors": "Veit Elser, Dan Schmidt, Jonathan Yedidia", "title": "Monotone Learning with Rectified Wire Networks", "comments": "41 pages, 21 figures, new experimental results, various improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new neural network model, together with a tractable and\nmonotone online learning algorithm. Our model describes feed-forward networks\nfor classification, with one output node for each class. The only nonlinear\noperation is rectification using a ReLU function with a bias. However, there is\na rectifier on every edge rather than at the nodes of the network. There are\nalso weights, but these are positive, static, and associated with the nodes.\nOur \"rectified wire\" networks are able to represent arbitrary Boolean\nfunctions. Only the bias parameters, on the edges of the network, are learned.\nAnother departure in our approach, from standard neural networks, is that the\nloss function is replaced by a constraint. This constraint is simply that the\nvalue of the output node associated with the correct class should be zero. Our\nmodel has the property that the exact norm-minimizing parameter update,\nrequired to correctly classify a training item, is the solution to a quadratic\nprogram that can be computed with a few passes through the network. We\ndemonstrate a training algorithm using this update, called sequential\ndeactivation (SDA), on MNIST and some synthetic datasets. Upon adopting a\nnatural choice for the nodal weights, SDA has no hyperparameters other than\nthose describing the network structure. Our experiments explore behavior with\nrespect to network size and depth in a family of sparse expander networks.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 13:24:34 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 20:49:16 GMT"}, {"version": "v3", "created": "Fri, 24 Aug 2018 17:09:49 GMT"}, {"version": "v4", "created": "Mon, 14 Jan 2019 01:08:30 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Elser", "Veit", ""], ["Schmidt", "Dan", ""], ["Yedidia", "Jonathan", ""]]}, {"id": "1805.04142", "submitter": "Zhe Li", "authors": "Zhe Li, Ji Li, Ao Ren, Caiwen Ding, Jeffrey Draper, Qinru Qiu, Bo\n  Yuan, Yanzhi Wang", "title": "Towards Budget-Driven Hardware Optimization for Deep Convolutional\n  Neural Networks using Stochastic Computing", "comments": "Accepted by IEEE Computer Society Annual Symposium on VLSI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Deep Convolutional Neural Network (DCNN) has achieved tremendous\nsuccess in many machine learning applications. Nevertheless, the deep structure\nhas brought significant increases in computation complexity. Largescale deep\nlearning systems mainly operate in high-performance server clusters, thus\nrestricting the application extensions to personal or mobile devices. Previous\nworks on GPU and/or FPGA acceleration for DCNNs show increasing speedup, but\nignore other constraints, such as area, power, and energy. Stochastic Computing\n(SC), as a unique data representation and processing technique, has the\npotential to enable the design of fully parallel and scalable hardware\nimplementations of large-scale deep learning systems. This paper proposed an\nautomatic design allocation algorithm driven by budget requirement considering\noverall accuracy performance. This systematic method enables the automatic\ndesign of a DCNN where all design parameters are jointly optimized.\nExperimental results demonstrate that proposed algorithm can achieve a joint\noptimization of all design parameters given the comprehensive budget of a DCNN.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 19:21:39 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Li", "Zhe", ""], ["Li", "Ji", ""], ["Ren", "Ao", ""], ["Ding", "Caiwen", ""], ["Draper", "Jeffrey", ""], ["Qiu", "Qinru", ""], ["Yuan", "Bo", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1805.04152", "submitter": "Hamid Khodabandehlou", "authors": "Hamid Khodabandehlou and M. Sami Fadali", "title": "Training Recurrent Neural Networks via Dynamical Trajectory-Based\n  Optimization", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.08.058", "report-no": null, "categories": "eess.SP cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces a new method to train recurrent neural networks using\ndynamical trajectory-based optimization. The optimization method utilizes a\nprojected gradient system (PGS) and a quotient gradient system (QGS) to\ndetermine the feasible regions of an optimization problem and search the\nfeasible regions for local minima. By exploring the feasible regions, local\nminima are identified and the local minimum with the lowest cost is chosen as\nthe global minimum of the optimization problem. Lyapunov theory is used to\nprove the stability of the local minima and their stability in the presence of\nmeasurement errors. Numerical examples show that the new approach provides\nbetter results than genetic algorithm and error backpropagation (EBP) trained\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 19:54:08 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Khodabandehlou", "Hamid", ""], ["Fadali", "M. Sami", ""]]}, {"id": "1805.04217", "submitter": "Yuan Fu", "authors": "Yuan Fu, Hu Wang, and Meng-Zhu Yang", "title": "An Adaptive Population Size Differential Evolution with Novel Mutation\n  Strategy for Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential evolution (DE) has competitive performance on constrained\noptimization problems (COPs), which targets at searching for global optimal\nsolution without violating the constraints. Generally, researchers pay more\nattention on avoiding violating the constraints than better objective function\nvalue. To achieve the aim of searching the feasible solutions accurately, an\nadaptive population size method and an adaptive mutation strategy are proposed\nin the paper. The adaptive population method is similar to a state switch which\ncontrols the exploring state and exploiting state according to the situation of\nfeasible solution search. The novel mutation strategy is designed to enhance\nthe effect of status switch based on adaptive population size, which is useful\nto reduce the constraint violations. Moreover, a mechanism based on\nmultipopulation competition and a more precise method of constraint control are\nadopted in the proposed algorithm. The proposed differential evolution\nalgorithm, APDE-NS, is evaluated on the benchmark problems from CEC2017\nconstrained real parameter optimization. The experimental results show the\neffectiveness of the proposed method is competitive compared to other\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 01:28:35 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Fu", "Yuan", ""], ["Wang", "Hu", ""], ["Yang", "Meng-Zhu", ""]]}, {"id": "1805.04258", "submitter": "Mahardhika Pratama Dr", "authors": "Md Meftahul Ferdaus, Mahardhika Pratama, Sreenatha G. Anavatti,\n  Matthew A. Garratt", "title": "PALM: An Incremental Construction of Hyperplanes for Data Stream\n  Regression", "comments": "This paper is currently under 2nd round review for publication by\n  IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data stream has been the underlying challenge in the age of big data because\nit calls for real-time data processing with the absence of a retraining process\nand/or an iterative learning approach. In realm of fuzzy system community, data\nstream is handled by algorithmic development of self-adaptive neurofuzzy\nsystems (SANFS) characterized by the single-pass learning mode and the open\nstructure property which enables effective handling of fast and rapidly\nchanging natures of data streams. The underlying bottleneck of SANFSs lies in\nits design principle which involves a high number of free parameters (rule\npremise and rule consequent) to be adapted in the training process. This figure\ncan even double in the case of type-2 fuzzy system. In this work, a novel\nSANFS, namely parsimonious learning machine (PALM), is proposed. PALM features\nutilization of a new type of fuzzy rule based on the concept of hyperplane\nclustering which significantly reduces the number of network parameters because\nit has no rule premise parameters. PALM is proposed in both type-1 and type-2\nfuzzy systems where all of which characterize a fully dynamic rule-based\nsystem. That is, it is capable of automatically generating, merging and tuning\nthe hyperplane-based fuzzy rule in the single pass manner. Moreover, an\nextension of PALM, namely recurrent PALM (rPALM), is proposed and adopts the\nconcept of teacher-forcing mechanism in the deep learning literature. The\nefficacy of PALM has been evaluated through numerical study with six real-world\nand synthetic data streams from public database and our own real-world project\nof autonomous vehicles. The proposed model showcases significant improvements\nin terms of computational complexity and number of required parameters against\nseveral renowned SANFSs, while attaining comparable and often better predictive\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 07:23:20 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 03:33:24 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Ferdaus", "Md Meftahul", ""], ["Pratama", "Mahardhika", ""], ["Anavatti", "Sreenatha G.", ""], ["Garratt", "Matthew A.", ""]]}, {"id": "1805.04264", "submitter": "Lyan Verwimp", "authors": "Lyan Verwimp, Hugo Van hamme, Vincent Renkens, Patrick Wambacq", "title": "State Gradients for RNN Memory Analysis", "comments": "Accepted for Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for analyzing what the state in RNNs remembers from\nits input embeddings. Our approach is inspired by backpropagation, in the sense\nthat we compute the gradients of the states with respect to the input\nembeddings. The gradient matrix is decomposed with Singular Value Decomposition\nto analyze which directions in the embedding space are best transferred to the\nhidden state space, characterized by the largest singular values. We apply our\napproach to LSTM language models and investigate to what extent and for how\nlong certain classes of words are remembered on average for a certain corpus.\nAdditionally, the extent to which a specific property or relationship is\nremembered by the RNN can be tracked by comparing a vector characterizing that\nproperty with the direction(s) in embedding space that are best preserved in\nhidden state space.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 07:51:28 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 09:05:30 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Verwimp", "Lyan", ""], ["Van hamme", "Hugo", ""], ["Renkens", "Vincent", ""], ["Wambacq", "Patrick", ""]]}, {"id": "1805.04513", "submitter": "Sayeh Sharify", "authors": "Sayeh Sharify, Mostafa Mahmoud, Alberto Delmas Lascorz, Milos Nikolic,\n  Andreas Moshovos", "title": "Laconic Deep Learning Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate a method for transparently identifying ineffectual computations\nin unmodified Deep Learning models and without affecting accuracy.\nSpecifically, we show that if we decompose multiplications down to the bit\nlevel the amount of work performed during inference for image classification\nmodels can be consistently reduced by two orders of magnitude. In the best case\nstudied of a sparse variant of AlexNet, this approach can ideally reduce\ncomputation work by more than 500x. We present Laconic a hardware accelerator\nthat implements this approach to improve execution time, and energy efficiency\nfor inference with Deep Learning Networks. Laconic judiciously gives up some of\nthe work reduction potential to yield a low-cost, simple, and energy efficient\ndesign that outperforms other state-of-the-art accelerators. For example, a\nLaconic configuration that uses a weight memory interface with just 128 wires\noutperforms a conventional accelerator with a 2K-wire weight memory interface\nby 2.3x on average while being 2.13x more energy efficient on average. A\nLaconic configuration that uses a 1K-wire weight memory interface, outperforms\nthe 2K-wire conventional accelerator by 15.4x and is 1.95x more energy\nefficient. Laconic does not require but rewards advances in model design such\nas a reduction in precision, the use of alternate numeric representations that\nreduce the number of bits that are \"1\", or an increase in weight or activation\nsparsity.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 18:14:08 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Sharify", "Sayeh", ""], ["Mahmoud", "Mostafa", ""], ["Lascorz", "Alberto Delmas", ""], ["Nikolic", "Milos", ""], ["Moshovos", "Andreas", ""]]}, {"id": "1805.04924", "submitter": "Payam Siyari", "authors": "Payam Siyari, Bistra Dilkina, Constantine Dovrolis", "title": "Emergence and Evolution of Hierarchical Structure in Complex Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SI stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that many complex systems, both in technology and nature,\nexhibit hierarchical modularity: smaller modules, each of them providing a\ncertain function, are used within larger modules that perform more complex\nfunctions. What is not well understood however is how this hierarchical\nstructure (which is fundamentally a network property) emerges, and how it\nevolves over time. We propose a modeling framework, referred to as Evo-Lexis,\nthat provides insight to some fundamental questions about evolving hierarchical\nsystems. Evo-Lexis models the most elementary modules of the system as symbols\n(\"sources\") and the modules at the highest level of the hierarchy as sequences\nof those symbols (\"targets\"). Evo-Lexis computes the optimized adjustment of a\ngiven hierarchy when the set of targets changes over time by additions and\nremovals (a process referred to as \"incremental design\"). In this paper we use\ncomputation modeling to show that:\n  - Low-cost and deep hierarchies emerge when the population of target\nsequences evolves through tinkering and mutation. - Strong selection on the\ncost of new candidate targets results in reuse of more complex (longer) nodes\nin an optimized hierarchy. - The bias towards reuse of complex nodes results in\nan \"hourglass architecture\" (i.e., few intermediate nodes that cover almost all\nsource-target paths). - With such bias, the core nodes are conserved for\nrelatively long time periods although still being vulnerable to major\ntransitions and punctuated equilibria. - Finally, we analyze the differences in\nterms of cost and structure between incrementally designed hierarchies and the\ncorresponding \"clean-slate\" hierarchies which result when the system is\ndesigned from scratch after a change.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 18:38:51 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 21:40:05 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Siyari", "Payam", ""], ["Dilkina", "Bistra", ""], ["Dovrolis", "Constantine", ""]]}, {"id": "1805.05047", "submitter": "Shreya Mishra", "authors": "Shreya Mishra, Swati Vipsita", "title": "Triclustering of Gene Expression Microarray data using Evolutionary\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Tri-clustering, a sub-matrix is being created, which exhibit highly\nsimilar behavior with respect to genes, conditions and time-points. In this\ntechnique, genes with same expression values are discovered across some\nfragment of time points, under certain conditions. In this paper, triclustering\nusing evolutionary algorithm is implemented using a new fitness function\nconsisting of 3D Mean Square residue (MSR) and Least Square approximation\n(LSL). The primary objective is to find triclusters with minimum overlapping,\nlow MSR, low LSL and covering almost every element of expression matrix, thus\nminimizing the overall fitness value. To improve the results of algorithm, new\nfitness function is introduced to find good quality triclusters. It is observed\nfrom experiments that, triclustering using EA yielded good quality triclusters.\nThe experiment was implemented on yeast Saccharomyces dataset. Index\nTerms-Tri-clustering, Genetic Algorithm, Mean squared residue, Volume, Weights,\nLeast square approximation.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 07:59:39 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Mishra", "Shreya", ""], ["Vipsita", "Swati", ""]]}, {"id": "1805.05225", "submitter": "Tamer Alkhouli", "authors": "Albert Zeyer, Tamer Alkhouli, and Hermann Ney", "title": "RETURNN as a Generic Flexible Neural Toolkit with Application to\n  Translation and Speech Recognition", "comments": "accepted as demo paper on ACL 2018", "journal-ref": null, "doi": "10.18653/v1/P18-4022", "report-no": null, "categories": "cs.NE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the fast training and decoding speed of RETURNN of attention\nmodels for translation, due to fast CUDA LSTM kernels, and a fast pure\nTensorFlow beam search decoder. We show that a layer-wise pretraining scheme\nfor recurrent attention models gives over 1% BLEU improvement absolute and it\nallows to train deeper recurrent encoder networks. Promising preliminary\nresults on max. expected BLEU training are presented. We are able to train\nstate-of-the-art models for translation and end-to-end models for speech\nrecognition and show results on WMT 2017 and Switchboard. The flexibility of\nRETURNN allows a fast research feedback loop to experiment with alternative\narchitectures, and its generality allows to use it on a wide range of\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 15:23:40 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 13:33:46 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zeyer", "Albert", ""], ["Alkhouli", "Tamer", ""], ["Ney", "Hermann", ""]]}, {"id": "1805.05373", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Yeeleng S. Vang, Yufang Huang, Xiaohui Xie", "title": "DeepEM: Deep 3D ConvNets With EM For Weakly Supervised Pulmonary Nodule\n  Detection", "comments": "MICCAI2018 Early Accept, Code\n  https://github.com/uci-cbcl/DeepEM-for-Weakly-Supervised-Detection.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep learning has been witnessing widespread adoption in various\nmedical image applications. However, training complex deep neural nets requires\nlarge-scale datasets labeled with ground truth, which are often unavailable in\nmany medical image domains. For instance, to train a deep neural net to detect\npulmonary nodules in lung computed tomography (CT) images, current practice is\nto manually label nodule locations and sizes in many CT images to construct a\nsufficiently large training dataset, which is costly and difficult to scale. On\nthe other hand, electronic medical records (EMR) contain plenty of partial\ninformation on the content of each medical image. In this work, we explore how\nto tap this vast, but currently unexplored data source to improve pulmonary\nnodule detection. We propose DeepEM, a novel deep 3D ConvNet framework\naugmented with expectation-maximization (EM), to mine weakly supervised labels\nin EMRs for pulmonary nodule detection. Experimental results show that DeepEM\ncan lead to 1.5\\% and 3.9\\% average improvement in free-response receiver\noperating characteristic (FROC) scores on LUNA16 and Tianchi datasets,\nrespectively, demonstrating the utility of incomplete information in EMRs for\nimproving deep learning\nalgorithms.\\footnote{https://github.com/uci-cbcl/DeepEM-for-Weakly-Supervised-Detection.git}\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:31:11 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 04:45:49 GMT"}, {"version": "v3", "created": "Sat, 26 May 2018 16:41:34 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zhu", "Wentao", ""], ["Vang", "Yeeleng S.", ""], ["Huang", "Yufang", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1805.05696", "submitter": "Luka Ribar", "authors": "Luka Ribar, Rodolphe Sepulchre", "title": "Neuromodulation of Neuromorphic Circuits", "comments": null, "journal-ref": "IEEE Transactions on Circuits and Systems I: Regular Papers, vol.\n  66, no. 8, pp. 3028-3040, Aug. 2019", "doi": "10.1109/TCSI.2019.2907113", "report-no": null, "categories": "q-bio.NC cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology to enable control of a neuromorphic circuit in\nclose analogy with the physiological neuromodulation of a single neuron. The\nmethodology is general in that it only relies on a parallel interconnection of\nelementary voltage-controlled current sources. In contrast to controlling a\nnonlinear circuit through the parameter tuning of a state-space model, our\napproach is purely input-output. The circuit elements are controlled and\ninterconnected to shape the current-voltage characteristics (I-V curves) of the\ncircuit in prescribed timescales. In turn, shaping those I-V curves determines\nthe excitability properties of the circuit. We show that this methodology\nenables both robust and accurate control of the circuit behavior and resembles\nthe biophysical mechanisms of neuromodulation. As a proof of concept, we\nsimulate a SPICE model composed of MOSFET transconductance amplifiers operating\nin the weak inversion regime.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 10:43:18 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 14:13:15 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 19:49:20 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ribar", "Luka", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1805.05854", "submitter": "Xin-She Yang", "authors": "Asma Chakri, Rabia Khelif, Mohamed Benouaret, Xin-She Yang", "title": "New directional bat algorithm for continuous optimization problems", "comments": null, "journal-ref": "Expert Systems with Applications, vol. 69, 159-175 (2017)", "doi": "10.1016/j.eswa.2016.10.050", "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bat algorithm (BA) is a recent optimization algorithm based on swarm\nintelligence and inspiration from the echolocation behavior of bats. One of the\nissues in the standard bat algorithm is the premature convergence that can\noccur due to the low exploration ability of the algorithm under some\nconditions. To overcome this deficiency, directional echolocation is introduced\nto the standard bat algorithm to enhance its exploration and exploitation\ncapabilities. In addition to such directional echolocation, three other\nimprovements have been embedded into the standard bat algorithm to enhance its\nperformance. The new proposed approach, namely the directional Bat Algorithm\n(dBA), has been then tested using several standard and non-standard benchmarks\nfrom the CEC2005 benchmark suite. The performance of dBA has been compared with\nten other algorithms and BA variants using non-parametric statistical tests.\nThe statistical test results show the superiority of the directional bat\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 10:36:56 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Chakri", "Asma", ""], ["Khelif", "Rabia", ""], ["Benouaret", "Mohamed", ""], ["Yang", "Xin-She", ""]]}, {"id": "1805.05855", "submitter": "Xin-She Yang", "authors": "Xin-She Yang", "title": "Social Algorithms", "comments": "Encyclopedia of Complexity and Systems Science, 2017", "journal-ref": null, "doi": "10.1007/978-3-642-27737-5_678-1", "report-no": null, "categories": "cs.NE cs.AI cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article concerns the review of a special class of swarm intelligence\nbased algorithms for solving optimization problems and these algorithms can be\nreferred to as social algorithms. Social algorithms use multiple agents and the\nsocial interactions to design rules for algorithms so as to mimic certain\nsuccessful characteristics of the social/biological systems such as ants, bees,\nbats, birds and animals.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 13:44:18 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Yang", "Xin-She", ""]]}, {"id": "1805.06242", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Sven Magg, Cornelius Weber and Stefan Wermter", "title": "Conversational Analysis using Utterance-level Attention-based\n  Bidirectional Recurrent Neural Networks", "comments": "Proceedings of INTERSPEECH 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-2527", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches for dialogue act recognition have shown that context from\npreceding utterances is important to classify the subsequent one. It was shown\nthat the performance improves rapidly when the context is taken into account.\nWe propose an utterance-level attention-based bidirectional recurrent neural\nnetwork (Utt-Att-BiRNN) model to analyze the importance of preceding utterances\nto classify the current one. In our setup, the BiRNN is given the input set of\ncurrent and preceding utterances. Our model outperforms previous models that\nuse only preceding utterances as context on the used corpus. Another\ncontribution of the article is to discover the amount of information in each\nutterance to classify the subsequent one and to show that context-based\nlearning not only improves the performance but also achieves higher confidence\nin the classification. We use character- and word-level features to represent\nthe utterances. The results are presented for character and word feature\nrepresentations and as an ensemble model of both representations. We found that\nwhen classifying short utterances, the closest preceding utterances contributes\nto a higher degree.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 10:51:56 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 12:11:59 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Magg", "Sven", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "1805.06280", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Cornelius Weber, Sven Magg, and Stefan Wermter", "title": "A Context-based Approach for Dialogue Act Recognition using Simple\n  Recurrent Neural Networks", "comments": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation (LREC 2018)", "journal-ref": null, "doi": null, "report-no": "id:525, pages:1952--1957", "categories": "cs.CL cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue act recognition is an important part of natural language\nunderstanding. We investigate the way dialogue act corpora are annotated and\nthe learning approaches used so far. We find that the dialogue act is\ncontext-sensitive within the conversation for most of the classes.\nNevertheless, previous models of dialogue act classification work on the\nutterance-level and only very few consider context. We propose a novel\ncontext-based learning method to classify dialogue acts using a character-level\nlanguage model utterance representation, and we notice significant improvement.\nWe evaluate this method on the Switchboard Dialogue Act corpus, and our results\nshow that the consideration of the preceding utterances as a context of the\ncurrent utterance improves dialogue act detection.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 12:58:18 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1805.06366", "submitter": "Lance Williams", "authors": "Lance R. Williams", "title": "Towards Complex Artificial Life", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An object-oriented combinator chemistry was used to construct an artificial\norganism with a system architecture possessing characteristics necessary for\norganisms to evolve into more complex forms. This architecture supports\nmodularity by providing a mechanism for the construction of executable modules\ncalled $methods$ that can be duplicated and specialized to increase complexity.\nAt the same time, its support for concurrency provides the flexibility in\nexecution order necessary for redundancy, degeneracy and parallelism to\nmitigate increased replication costs. The organism is a moving,\nself-replicating, spatially distributed assembly of elemental combinators\ncalled a $roving \\: pile.$ The pile hosts an asynchronous message passing\ncomputation implemented by parallel subprocesses encoded by genes distributed\nthrough out the pile like the plasmids of a bacterial cell.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 15:20:30 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Williams", "Lance R.", ""]]}, {"id": "1805.07249", "submitter": "Shrihari Vasudevan", "authors": "Shrihari Vasudevan", "title": "Dynamic learning rate using Mutual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates dynamic hyper-parameter setting, for deep neural\nnetwork training, using Mutual Information (MI). The specific hyper-parameter\nstudied in this paper is the learning rate. MI between the output layer and\ntrue outcomes is used to dynamically set the learning rate of the network\nthrough the training cycle; the idea is also extended to layer-wise setting of\nlearning rate. Two approaches are demonstrated - tracking relative change in\nmutual information and, additionally tracking its value relative to a reference\nmeasure. The paper does not attempt to recommend a specific learning rate\npolicy. Experiments demonstrate that mutual information may be effectively used\nto dynamically set learning rate and achieve competitive to better outcomes in\ncompetitive to better time.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 14:46:20 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 07:34:51 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Vasudevan", "Shrihari", ""]]}, {"id": "1805.07433", "submitter": "Nuri Cingillioglu", "authors": "Nuri Cingillioglu, Alessandra Russo", "title": "DeepLogic: Towards End-to-End Differentiable Logical Reasoning", "comments": "Camera-ready AAAI-MAKE19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining machine learning with logic-based expert systems in order to get\nthe best of both worlds are becoming increasingly popular. However, to what\nextent machine learning can already learn to reason over rule-based knowledge\nis still an open problem. In this paper, we explore how symbolic logic, defined\nas logic programs at a character level, is learned to be represented in a\nhigh-dimensional vector space using RNN-based iterative neural networks to\nperform reasoning. We create a new dataset that defines 12 classes of logic\nprograms exemplifying increased level of complexity of logical reasoning and\ntrain the networks in an end-to-end fashion to learn whether a logic program\nentails a given query. We analyse how learning the inference algorithm gives\nrise to representations of atoms, literals and rules within logic programs and\nevaluate against increasing lengths of predicate and constant symbols as well\nas increasing steps of multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:36:21 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 13:15:41 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 21:19:06 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Cingillioglu", "Nuri", ""], ["Russo", "Alessandra", ""]]}, {"id": "1805.07443", "submitter": "Shuai Tang", "authors": "Shuai Tang, Virginia R. de Sa", "title": "Multi-view Sentence Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning can provide self-supervision when different views are\navailable of the same data. The distributional hypothesis provides another form\nof useful self-supervision from adjacent sentences which are plentiful in large\nunlabelled corpora. Motivated by the asymmetry in the two hemispheres of the\nhuman brain as well as the observation that different learning architectures\ntend to emphasise different aspects of sentence meaning, we create a unified\nmulti-view sentence representation learning framework, in which, one view\nencodes the input sentence with a Recurrent Neural Network (RNN), and the other\nview encodes it with a simple linear model, and the training objective is to\nmaximise the agreement specified by the adjacent context information between\ntwo views. We show that, after training, the vectors produced from our\nmulti-view training provide improved representations over the single-view\ntraining, and the combination of different views gives further representational\nimprovement and demonstrates solid transferability on standard downstream\ntasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 21:04:08 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Tang", "Shuai", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1805.07475", "submitter": "Jacob Harer", "authors": "Jacob Harer, Onur Ozdemir, Tomo Lazovich, Christopher P. Reale,\n  Rebecca L. Russell, Louis Y. Kim, Peter Chin", "title": "Learning to Repair Software Vulnerabilities with Generative Adversarial\n  Networks", "comments": "Presented at 32nd Conference on Neural Information Processing Systems\n  (nips 2018), Montreal Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the problem of automated repair of software vulnerabilities, we\npropose an adversarial learning approach that maps from one discrete source\ndomain to another target domain without requiring paired labeled examples or\nsource and target domains to be bijections. We demonstrate that the proposed\nadversarial learning approach is an effective technique for repairing software\nvulnerabilities, performing close to seq2seq approaches that require labeled\npairs. The proposed Generative Adversarial Network approach is\napplication-agnostic in that it can be applied to other problems similar to\ncode repair, such as grammar correction or sentiment translation.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:31:03 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 16:09:33 GMT"}, {"version": "v3", "created": "Sun, 28 Oct 2018 18:22:18 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Harer", "Jacob", ""], ["Ozdemir", "Onur", ""], ["Lazovich", "Tomo", ""], ["Reale", "Christopher P.", ""], ["Russell", "Rebecca L.", ""], ["Kim", "Louis Y.", ""], ["Chin", "Peter", ""]]}, {"id": "1805.07494", "submitter": "Hyoungwook Nam", "authors": "Hyoungwook Nam, Segwang Kim, Kyomin Jung", "title": "Number Sequence Prediction Problems for Evaluating Computational Powers\n  of Neural Networks", "comments": "Accepted to 2019 AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by number series tests to measure human intelligence, we suggest\nnumber sequence prediction tasks to assess neural network models' computational\npowers for solving algorithmic problems. We define the complexity and\ndifficulty of a number sequence prediction task with the structure of the\nsmallest automaton that can generate the sequence. We suggest two types of\nnumber sequence prediction problems: the number-level and the digit-level\nproblems. The number-level problems format sequences as 2-dimensional grids of\ndigits and the digit-level problems provide a single digit input per a time\nstep. The complexity of a number-level sequence prediction can be defined with\nthe depth of an equivalent combinatorial logic, and the complexity of a\ndigit-level sequence prediction can be defined with an equivalent state\nautomaton for the generation rule. Experiments with number-level sequences\nsuggest that CNN models are capable of learning the compound operations of\nsequence generation rules, but the depths of the compound operations are\nlimited. For the digit-level problems, simple GRU and LSTM models can solve\nsome problems with the complexity of finite state automata. Memory augmented\nmodels such as Stack-RNN, Attention, and Neural Turing Machines can solve the\nreverse-order task which has the complexity of simple pushdown automaton.\nHowever, all of above cannot solve general Fibonacci, Arithmetic or Geometric\nsequence generation problems that represent the complexity of queue automata or\nTuring machines. The results show that our number sequence prediction problems\neffectively evaluate machine learning models' computational capabilities.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 02:36:13 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 09:43:26 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Nam", "Hyoungwook", ""], ["Kim", "Segwang", ""], ["Jung", "Kyomin", ""]]}, {"id": "1805.07500", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Fisher B. Gouza", "title": "GADAM: Genetic-Evolutionary ADAM for Deep Neural Network Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network learning can be formulated as a non-convex optimization\nproblem. Existing optimization algorithms, e.g., Adam, can learn the models\nfast, but may get stuck in local optima easily. In this paper, we introduce a\nnovel optimization algorithm, namely GADAM (Genetic-Evolutionary Adam). GADAM\nlearns deep neural network models based on a number of unit models generations\nby generations: it trains the unit models with Adam, and evolves them to the\nnew generations with genetic algorithm. We will show that GADAM can effectively\njump out of the local optima in the learning process to obtain better\nsolutions, and prove that GADAM can also achieve a very fast convergence.\nExtensive experiments have been done on various benchmark datasets, and the\nlearning results will demonstrate the effectiveness and efficiency of the GADAM\nalgorithm.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:16:44 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 03:37:14 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Zhang", "Jiawei", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.07502", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "On Deep Ensemble Learning from a Function Approximation Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to provide a general ensemble learning framework\nbased on deep learning models. Given a group of unit models, the proposed deep\nensemble learning framework will effectively combine their learning results via\na multilayered ensemble model. In the case when the unit model mathematical\nmappings are bounded, sigmoidal and discriminatory, we demonstrate that the\ndeep ensemble learning framework can achieve a universal approximation of any\nfunctions from the input space to the output space. Meanwhile, to achieve such\na performance, the deep ensemble learning framework also impose a strict\nconstraint on the number of involved unit models. According to the theoretic\nproof provided in this paper, given the input feature space of dimension d, the\nrequired unit model number will be 2d, if the ensemble model involves one\nsingle layer. Furthermore, as the ensemble component goes deeper, the number of\nrequired unit model is proved to be lowered down exponentially.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:25:30 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.07504", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Deep Loopy Neural Network Model for Graph Structured Data Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing deep learning models may encounter great challenges in handling\ngraph structured data. In this paper, we introduce a new deep learning model\nfor graph data specifically, namely the deep loopy neural network.\nSignificantly different from the previous deep models, inside the deep loopy\nneural network, there exist a large number of loops created by the extensive\nconnections among nodes in the input graph data, which makes model learning an\ninfeasible task. To resolve such a problem, in this paper, we will introduce a\nnew learning algorithm for the deep loopy neural network specifically. Instead\nof learning the model variables based on the original model, in the proposed\nlearning algorithm, errors will be back-propagated through the edges in a group\nof extracted spanning trees. Extensive numerical experiments have been done on\nseveral real-world graph datasets, and the experimental results demonstrate the\neffectiveness of both the proposed model and the learning algorithm in handling\ngraph data.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:33:20 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 17:45:22 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1805.07507", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "Reconciled Polynomial Machine: A Unified Representation of Shallow and\n  Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim at introducing a new machine learning model, namely\nreconciled polynomial machine, which can provide a unified representation of\nexisting shallow and deep machine learning models. Reconciled polynomial\nmachine predicts the output by computing the inner product of the feature\nkernel function and variable reconciling function. Analysis of several concrete\nmodels, including Linear Models, FM, MVM, Perceptron, MLP and Deep Neural\nNetworks, will be provided in this paper, which can all be reduced to the\nreconciled polynomial machine representations. Detailed analysis of the\nlearning error by these models will also be illustrated in this paper based on\ntheir reduced representations from the function approximation perspective.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:40:52 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.07508", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "GEN Model: An Alternative Approach to Deep Neural Network Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.08631", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an alternative approach, namely GEN (Genetic\nEvolution Network) Model, to the deep learning models. Instead of building one\nsingle deep model, GEN adopts a genetic-evolutionary learning strategy to build\na group of unit models generations by generations. Significantly different from\nthe wellknown representation learning models with extremely deep structures,\nthe unit models covered in GEN are of a much shallower architecture. In the\ntraining process, from each generation, a subset of unit models will be\nselected based on their performance to evolve and generate the child models in\nthe next generation. GEN has significant advantages compared with existing deep\nrepresentation learning models in terms of both learning effectiveness,\nefficiency and interpretability of the learning process and learned results.\nExtensive experiments have been done on diverse benchmark datasets, and the\nexperimental results have demonstrated the outstanding performance of GEN\ncompared with the state-of-the-art baseline methods in both effectiveness of\nefficiency.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:48:26 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.07531", "submitter": "Maxim Nazarov", "authors": "M. N. Nazarov", "title": "Neural networks with dynamical coefficients and adjustable connections\n  on the basis of integrated backpropagation", "comments": null, "journal-ref": "Bulletin of Udmurt University. Mathematics, Mechanics, Computer\n  Science, 2018, vol. 28, issue 2, pp. 260-274", "doi": "10.20537/vm180212", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider artificial neurons which will update their weight coefficients\nwith an internal rule based on backpropagation, rather than using it as an\nexternal training procedure. To achieve this we include the backpropagation\nerror estimate as a separate entity in all the neuron models and perform its\nexchange along the synaptic connections. In addition to this we add some\nspecial type of neurons with reference inputs, which will serve as a base\nsource of error estimates for the whole network. Finally, we introduce a\ntraining control signal for all the neurons, which can enable the correction of\nweights and the exchange of error estimates. For recurrent neural networks we\nalso demonstrate how to integrate backpropagation through time into their\nformalism with the help of some stack memory for reference inputs and external\ndata inputs of neurons. Also, for widely used neural networks, such as long\nshort-term memory, radial basis function networks, multilayer perceptrons and\nconvolutional neural networks, we demonstrate their alternative description\nwithin the framework of our new formalism.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 07:34:33 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 09:12:48 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Nazarov", "M. N.", ""]]}, {"id": "1805.07569", "submitter": "Hannes Rapp", "authors": "Hannes Rapp, Martin Paul Nawrot, Merav Stern", "title": "Reliable counting of weakly labeled concepts by a single spiking neuron\n  model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making an informed, correct and quick decision can be life-saving. It's\ncrucial for animals during an escape behaviour or for autonomous cars during\ndriving. The decision can be complex and may involve an assessment of the\namount of threats present and the nature of each threat. Thus, we should expect\nearly sensory processing to supply classification information fast and\naccurately, even before relying the information to higher brain areas or more\ncomplex system components downstream. Today, advanced convolutional artificial\nneural networks can successfully solve visual detection and classification\ntasks and are commonly used to build complex decision making systems. However,\nin order to perform well on these tasks they require increasingly complex,\n\"very deep\" model structure, which is costly in inference run-time, energy\nconsumption and number of training samples, only trainable on cloud-computing\nclusters. A single spiking neuron has been shown to be able to solve\nrecognition tasks for homogeneous Poisson input statistics, a commonly used\nmodel for spiking activity in the neocortex. When modeled as leaky integrate\nand fire with gradient decent learning algorithm it was shown to posses a\nvariety of complex computational capabilities. Here we improve its\nimplementation. We also account for more natural stimulus generated inputs that\ndeviate from this homogeneous Poisson spiking. The improved gradient-based\nlocal learning rule allows for significantly better and stable generalization.\nWe also show that with its improved capabilities it can count weakly labeled\nconcepts by applying our model to a problem of multiple instance learning (MIL)\nwith counting where labels are only available for collections of concepts. In\nthis counting MNIST task the neuron exploits the improved implementation and\noutperforms conventional ConvNet architecture under similar condtions.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 11:09:27 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2018 09:09:15 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Rapp", "Hannes", ""], ["Nawrot", "Martin Paul", ""], ["Stern", "Merav", ""]]}, {"id": "1805.07802", "submitter": "Dimche Kostadinov", "authors": "Dimche Kostadinov, Behrooz Razeghi, Sohrab Ferdowsi, Slava\n  Voloshynovskiy", "title": "Network Learning with Local Propagation", "comments": "preprint, a similar version submitted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a locally decoupled network parameter learning with local\npropagation. Three elements are taken into account: (i) sets of nonlinear\ntransforms that describe the representations at all nodes, (ii) a local\nobjective at each node related to the corresponding local representation goal,\nand (iii) a local propagation model that relates the nonlinear error vectors at\neach node with the goal error vectors from the directly connected nodes. The\nmodeling concepts (i), (ii) and (iii) offer several advantages, including (a) a\nunified learning principle for any network that is represented as a graph, (b)\nunderstanding and interpretation of the local and the global learning dynamics,\n(c) decoupled and parallel parameter learning, (d) a possibility for learning\nin infinitely long, multi-path and multi-goal networks. Numerical experiments\nvalidate the potential of the learning principle. The preliminary results show\nadvantages in comparison to the state-of-the-art methods, w.r.t. the learning\ntime and the network size while having comparable recognition accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:21:05 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kostadinov", "Dimche", ""], ["Razeghi", "Behrooz", ""], ["Ferdowsi", "Sohrab", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1805.07816", "submitter": "Jiefeng Chen", "authors": "Jiefeng Chen, Xi Wu, Vaibhav Rastogi, Yingyu Liang, Somesh Jha", "title": "Towards Understanding Limitations of Pixel Discretization Against\n  Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wide adoption of artificial neural networks in various domains has led to an\nincreasing interest in defending adversarial attacks against them.\nPreprocessing defense methods such as pixel discretization are particularly\nattractive in practice due to their simplicity, low computational overhead, and\napplicability to various systems. It is observed that such methods work well on\nsimple datasets like MNIST, but break on more complicated ones like ImageNet\nunder recently proposed strong white-box attacks. To understand the conditions\nfor success and potentials for improvement, we study the pixel discretization\ndefense method, including more sophisticated variants that take into account\nthe properties of the dataset being discretized. Our results again show poor\nresistance against the strong attacks. We analyze our results in a theoretical\nframework and offer strong evidence that pixel discretization is unlikely to\nwork on all but the simplest of the datasets. Furthermore, our arguments\npresent insights why some other preprocessing defenses may be insecure.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 19:37:54 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 02:46:43 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 18:30:38 GMT"}, {"version": "v4", "created": "Tue, 16 Apr 2019 02:02:16 GMT"}, {"version": "v5", "created": "Thu, 3 Oct 2019 15:43:21 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Chen", "Jiefeng", ""], ["Wu", "Xi", ""], ["Rastogi", "Vaibhav", ""], ["Liang", "Yingyu", ""], ["Jha", "Somesh", ""]]}, {"id": "1805.07866", "submitter": "Yingyezhe Jin", "authors": "Yingyezhe Jin, Wenrui Zhang and Peng Li", "title": "Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking\n  Neural Networks", "comments": "11 pages, 5 figures. Published at NeurIPS (Neural Information\n  Processing System) 2018. Code available:\n  https://github.com/jinyyy666/mm-bp-snn", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are positioned to enable spatio-temporal\ninformation processing and ultra-low power event-driven neuromorphic hardware.\nHowever, SNNs are yet to reach the same performances of conventional deep\nartificial neural networks (ANNs), a long-standing challenge due to complex\ndynamics and non-differentiable spike events encountered in training. The\nexisting SNN error backpropagation (BP) methods are limited in terms of\nscalability, lack of proper handling of spiking discontinuities, and/or\nmismatch between the rate-coded loss function and computed gradient. We present\na hybrid macro/micro level backpropagation (HM2-BP) algorithm for training\nmulti-layer SNNs. The temporal effects are precisely captured by the proposed\nspike-train level post-synaptic potential (S-PSP) at the microscopic level. The\nrate-coded errors are defined at the macroscopic level, computed and\nback-propagated across both macroscopic and microscopic levels. Different from\nexisting BP methods, HM2-BP directly computes the gradient of the rate-coded\nloss function w.r.t tunable parameters. We evaluate the proposed HM2-BP\nalgorithm by training deep fully connected and convolutional SNNs based on the\nstatic MNIST [14] and dynamic neuromorphic N-MNIST [26]. HM2-BP achieves an\naccuracy level of 99.49% and 98.88% for MNIST and N-MNIST, respectively,\noutperforming the best reported performances obtained from the existing SNN BP\nalgorithms. Furthermore, the HM2-BP produces the highest accuracies based on\nSNNs for the EMNIST [3] dataset, and leads to high recognition accuracy for the\n16-speaker spoken English letters of TI46 Corpus [16], a challenging\npatio-temporal speech recognition benchmark for which no prior success based on\nSNNs was reported. It also achieves competitive performances surpassing those\nof conventional deep learning models when dealing with asynchronous spiking\nstreams.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 02:04:30 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 05:32:05 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 06:34:07 GMT"}, {"version": "v4", "created": "Fri, 26 Oct 2018 03:47:02 GMT"}, {"version": "v5", "created": "Wed, 12 Dec 2018 04:44:45 GMT"}, {"version": "v6", "created": "Sat, 19 Jan 2019 16:43:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Jin", "Yingyezhe", ""], ["Zhang", "Wenrui", ""], ["Li", "Peng", ""]]}, {"id": "1805.07891", "submitter": "Liang Luo", "authors": "Liang Luo, Jacob Nelson, Luis Ceze, Amar Phanishayee, Arvind\n  Krishnamurthy", "title": "Parameter Hub: a Rack-Scale Parameter Server for Distributed Deep Neural\n  Network Training", "comments": null, "journal-ref": null, "doi": "10.1145/3267809.3267840", "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed deep neural network (DDNN) training constitutes an increasingly\nimportant workload that frequently runs in the cloud. Larger DNN models and\nfaster compute engines are shifting DDNN training bottlenecks from computation\nto communication. This paper characterizes DDNN training to precisely pinpoint\nthese bottlenecks. We found that timely training requires high performance\nparameter servers (PSs) with optimized network stacks and gradient processing\npipelines, as well as server and network hardware with balanced computation and\ncommunication resources. We therefore propose PHub, a high performance\nmulti-tenant, rack-scale PS design. PHub co-designs the PS software and\nhardware to accelerate rack-level and hierarchical cross-rack parameter\nexchange, with an API compatible with many DDNN training frameworks. PHub\nprovides a performance improvement of up to 2.7x compared to state-of-the-art\ndistributed training techniques for cloud-based ImageNet workloads, with 25%\nbetter throughput per dollar.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 04:55:04 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 21:18:51 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Luo", "Liang", ""], ["Nelson", "Jacob", ""], ["Ceze", "Luis", ""], ["Phanishayee", "Amar", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1805.07907", "submitter": "Joy Bose", "authors": "Kushal Singla, Joy Bose", "title": "IoT2Vec: Identification of Similar IoT Devices via Activity Footprints", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a smart home or smart office environment with a number of IoT\ndevices connected and passing data between one another. The footprints of the\ndata transferred can provide valuable information about the devices, which can\nbe used to (a) identify the IoT devices and (b) in case of failure, to identify\nthe correct replacements for these devices. In this paper, we generate the\nembeddings for IoT devices in a smart home using Word2Vec, and explore the\npossibility of having a similar concept for IoT devices, aka IoT2Vec. These\nembeddings can be used in a number of ways, such as to find similar devices in\nan IoT device store, or as a signature of each type of IoT device. We show\nresults of a feasibility study on the CASAS dataset of IoT device activity\nlogs, using our method to identify the patterns in embeddings of various types\nof IoT devices in a household.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 06:31:52 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Singla", "Kushal", ""], ["Bose", "Joy", ""]]}, {"id": "1805.07917", "submitter": "Shauharda Khadka", "authors": "Shauharda Khadka and Kagan Tumer", "title": "Evolution-Guided Policy Gradient in Reinforcement Learning", "comments": "32nd Conference on Neural Information Processing Systems (NIPS 2018),\n  Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (DRL) algorithms have been successfully applied\nto a range of challenging control tasks. However, these methods typically\nsuffer from three core difficulties: temporal credit assignment with sparse\nrewards, lack of effective exploration, and brittle convergence properties that\nare extremely sensitive to hyperparameters. Collectively, these challenges\nseverely limit the applicability of these approaches to real-world problems.\nEvolutionary Algorithms (EAs), a class of black box optimization techniques\ninspired by natural evolution, are well suited to address each of these three\nchallenges. However, EAs typically suffer from high sample complexity and\nstruggle to solve problems that require optimization of a large number of\nparameters. In this paper, we introduce Evolutionary Reinforcement Learning\n(ERL), a hybrid algorithm that leverages the population of an EA to provide\ndiversified data to train an RL agent, and reinserts the RL agent into the EA\npopulation periodically to inject gradient information into the EA. ERL\ninherits EA's ability of temporal credit assignment with a fitness metric,\neffective exploration with a diverse set of policies, and stability of a\npopulation-based approach and complements it with off-policy DRL's ability to\nleverage gradients for higher sample efficiency and faster learning.\nExperiments in a range of challenging continuous control benchmarks demonstrate\nthat ERL significantly outperforms prior DRL and EA methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 06:55:58 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 17:23:26 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Khadka", "Shauharda", ""], ["Tumer", "Kagan", ""]]}, {"id": "1805.08034", "submitter": "Lars Ruthotto", "authors": "Eldad Haber, Felix Lucka, Lars Ruthotto", "title": "Never look back - A modified EnKF method and its application to the\n  training of neural networks without back propagation", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a new derivative-free optimization method and\ninvestigate its use for training neural networks. Our method is motivated by\nthe Ensemble Kalman Filter (EnKF), which has been used successfully for solving\noptimization problems that involve large-scale, highly nonlinear dynamical\nsystems. A key benefit of the EnKF method is that it requires only the\nevaluation of the forward propagation but not its derivatives. Hence, in the\ncontext of neural networks, it alleviates the need for back propagation and\nreduces the memory consumption dramatically. However, the method is not a pure\n\"black-box\" global optimization heuristic as it efficiently utilizes the\nstructure of typical learning problems. Promising first results of the EnKF for\ntraining deep neural networks have been presented recently by Kovachki and\nStuart. We propose an important modification of the EnKF that enables us to\nprove convergence of our method to the minimizer of a strongly convex function.\nOur method also bears similarity with implicit filtering and we demonstrate its\npotential for minimizing highly oscillatory functions using a simple example.\nFurther, we provide numerical examples that demonstrate the potential of our\nmethod for training deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 13:08:31 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 13:07:07 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Haber", "Eldad", ""], ["Lucka", "Felix", ""], ["Ruthotto", "Lars", ""]]}, {"id": "1805.08060", "submitter": "Anil Yesilkaya", "authors": "Anil Yesilkaya, Onur Karatalay, Arif Selcuk Ogrenci, Erdal Panayirci", "title": "Channel Estimation for Visible Light Communications Using Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1109/IJCNN.2016.7727215", "report-no": null, "categories": "cs.NE cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visible light communications (VLC) is an emerging field in technology and\nresearch. Estimating the channel taps is a major requirement for designing\nreliable communication systems. Due to the nonlinear characteristics of the VLC\nchannel those parameters cannot be derived easily. They can be calculated by\nmeans of software simulation. In this work, a novel methodology is proposed for\nthe prediction of channel parameters using neural networks. Measurements\nconducted in a controlled experimental setup are used to train neural networks\nfor channel tap prediction. Our experiment results indicate that neural\nnetworks can be effectively trained to predict channel taps under different\nenvironmental conditions.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:02:03 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Yesilkaya", "Anil", ""], ["Karatalay", "Onur", ""], ["Ogrenci", "Arif Selcuk", ""], ["Panayirci", "Erdal", ""]]}, {"id": "1805.08079", "submitter": "Menachem Adelman", "authors": "Menachem Adelman, Kfir Y. Levy, Ido Hakimi, Mark Silberstein", "title": "Faster Neural Network Training with Approximate Tensor Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel technique for faster DNN training which systematically\napplies sample-based approximation to the constituent tensor operations, i.e.,\nmatrix multiplications and convolutions. We introduce new sampling techniques,\nstudy their theoretical properties, and prove that they provide the same\nconvergence guarantees when applied to SGD DNN training. We apply approximate\ntensor operations to single and multi-node training of MLP and CNN networks on\nMNIST, CIFAR-10 and ImageNet datasets. We demonstrate up to 66% reduction in\nthe amount of computations and communication, and up to 1.37x faster training\ntime while maintaining negligible or no impact on the final test accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:14:14 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 14:37:43 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Adelman", "Menachem", ""], ["Levy", "Kfir Y.", ""], ["Hakimi", "Ido", ""], ["Silberstein", "Mark", ""]]}, {"id": "1805.08154", "submitter": "Georgios Spithourakis", "authors": "Georgios P. Spithourakis and Sebastian Riedel", "title": "Numeracy for Language Models: Evaluating and Improving their Ability to\n  Predict Numbers", "comments": "accepted at ACL 2018", "journal-ref": null, "doi": "10.18653/v1/P18-1196", "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numeracy is the ability to understand and work with numbers. It is a\nnecessary skill for composing and understanding documents in clinical,\nscientific, and other technical domains. In this paper, we explore different\nstrategies for modelling numerals with language models, such as memorisation\nand digit-by-digit composition, and propose a novel neural architecture that\nuses a continuous probability density function to model numerals from an open\nvocabulary. Our evaluation on clinical and scientific datasets shows that using\nhierarchical models to distinguish numerals from words improves a perplexity\nmetric on the subset of numerals by 2 and 4 orders of magnitude, respectively,\nover non-hierarchical models. A combination of strategies can further improve\nperplexity. Our continuous probability density function model reduces mean\nabsolute percentage errors by 18% and 54% in comparison to the second best\nstrategy for each dataset, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 16:18:41 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Spithourakis", "Georgios P.", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1805.08180", "submitter": "Andrew Levy", "authors": "Andrew Levy, Robert Platt, Kate Saenko", "title": "Hierarchical Reinforcement Learning with Hindsight", "comments": "Duplicate. See arXiv:1712.00948 \"Learning Multi-Level Hierarchies\n  with Hindsight\" for latest version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms can suffer from poor sample efficiency\nwhen rewards are delayed and sparse. We introduce a solution that enables\nagents to learn temporally extended actions at multiple levels of abstraction\nin a sample efficient and automated fashion. Our approach combines universal\nvalue functions and hindsight learning, allowing agents to learn policies\nbelonging to different time scales in parallel. We show that our method\nsignificantly accelerates learning in a variety of discrete and continuous\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:02:53 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 17:52:47 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Levy", "Andrew", ""], ["Platt", "Robert", ""], ["Saenko", "Kate", ""]]}, {"id": "1805.08191", "submitter": "Zhe Gan", "authors": "Qiuyuan Huang, Zhe Gan, Asli Celikyilmaz, Dapeng Wu, Jianfeng Wang,\n  Xiaodong He", "title": "Hierarchically Structured Reinforcement Learning for Topically Coherent\n  Visual Story Generation", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hierarchically structured reinforcement learning approach to\naddress the challenges of planning for generating coherent multi-sentence\nstories for the visual storytelling task. Within our framework, the task of\ngenerating a story given a sequence of images is divided across a two-level\nhierarchical decoder. The high-level decoder constructs a plan by generating a\nsemantic concept (i.e., topic) for each image in sequence. The low-level\ndecoder generates a sentence for each image using a semantic compositional\nnetwork, which effectively grounds the sentence generation conditioned on the\ntopic. The two decoders are jointly trained end-to-end using reinforcement\nlearning. We evaluate our model on the visual storytelling (VIST) dataset.\nEmpirical results from both automatic and human evaluations demonstrate that\nthe proposed hierarchically structured reinforced training achieves\nsignificantly better performance compared to a strong flat deep reinforcement\nlearning baseline.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:23:31 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 20:11:56 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 07:58:43 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Huang", "Qiuyuan", ""], ["Gan", "Zhe", ""], ["Celikyilmaz", "Asli", ""], ["Wu", "Dapeng", ""], ["Wang", "Jianfeng", ""], ["He", "Xiaodong", ""]]}, {"id": "1805.08249", "submitter": "Konrad Zolna", "authors": "Konrad Zolna and Krzysztof J. Geras and Kyunghyun Cho", "title": "Classifier-agnostic saliency map extraction", "comments": null, "journal-ref": "Computer Vision and Image Understanding, Volume 196, 2020, 102969,\n  ISSN 1077-3142", "doi": "10.1016/j.cviu.2020.102969", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently available methods for extracting saliency maps identify parts of\nthe input which are the most important to a specific fixed classifier. We show\nthat this strong dependence on a given classifier hinders their performance. To\naddress this problem, we propose classifier-agnostic saliency map extraction,\nwhich finds all parts of the image that any classifier could use, not just one\ngiven in advance. We observe that the proposed approach extracts higher quality\nsaliency maps than prior work while being conceptually simple and easy to\nimplement. The method sets the new state of the art result for localization\ntask on the ImageNet data, outperforming all existing weakly-supervised\nlocalization techniques, despite not using the ground truth labels at the\ninference time. The code reproducing the results is available at\nhttps://github.com/kondiz/casme .\n  The final version of this manuscript is published in Computer Vision and\nImage Understanding and is available online at\nhttps://doi.org/10.1016/j.cviu.2020.102969 .\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:36:52 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 19:14:19 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 16:56:49 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zolna", "Konrad", ""], ["Geras", "Krzysztof J.", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1805.08289", "submitter": "Ari Benjamin", "authors": "Ari S. Benjamin, David Rolnick, Konrad Kording", "title": "Measuring and regularizing networks in function space", "comments": "Presented at ICLR 2019", "journal-ref": "International Conference on Learning Representations, 2019,\n  https://openreview.net/pdf?id=SkMwpiR9Y7", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To optimize a neural network one often thinks of optimizing its parameters,\nbut it is ultimately a matter of optimizing the function that maps inputs to\noutputs. Since a change in the parameters might serve as a poor proxy for the\nchange in the function, it is of some concern that primacy is given to\nparameters but that the correspondence has not been tested. Here, we show that\nit is simple and computationally feasible to calculate distances between\nfunctions in a $L^2$ Hilbert space. We examine how typical networks behave in\nthis space, and compare how parameter $\\ell^2$ distances compare to function\n$L^2$ distances between various points of an optimization trajectory. We find\nthat the two distances are nontrivially related. In particular, the\n$L^2/\\ell^2$ ratio decreases throughout optimization, reaching a steady value\naround when test error plateaus. We then investigate how the $L^2$ distance\ncould be applied directly to optimization. We first propose that in multitask\nlearning, one can avoid catastrophic forgetting by directly limiting how much\nthe input/output function changes between tasks. Secondly, we propose a new\nlearning rule that constrains the distance a network can travel through\n$L^2$-space in any one update. This allows new examples to be learned in a way\nthat minimally interferes with what has previously been learned. These\napplications demonstrate how one can measure and regularize function distances\ndirectly, without relying on parameters or local approximations like loss\ncurvature.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 21:03:21 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 22:17:51 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 19:04:34 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Benjamin", "Ari S.", ""], ["Rolnick", "David", ""], ["Kording", "Konrad", ""]]}, {"id": "1805.08303", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Compression of Deep Convolutional Neural Networks under Joint Sparsity\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the optimization of deep convolutional neural networks (CNNs)\nsuch that they provide good performance while having reduced complexity if\ndeployed on either conventional systems utilizing spatial-domain convolution or\nlower complexity systems designed for Winograd convolution. Furthermore, we\nexplore the universal quantization and compression of these networks. In\nparticular, the proposed framework produces one compressed model whose\nconvolutional filters can be made sparse either in the spatial domain or in the\nWinograd domain. Hence, one compressed model can be deployed universally on any\nplatform, without need for re-training on the deployed platform, and the\nsparsity of its convolutional filters can be exploited for further complexity\nreduction in either domain. To get a better compression ratio, the sparse model\nis compressed in the spatial domain which has a less number of parameters. From\nour experiments, we obtain $24.2\\times$, $47.7\\times$ and $35.4\\times$\ncompressed models for ResNet-18, AlexNet and CT-SRCNN, while their\ncomputational cost is also reduced by $4.5\\times$, $5.1\\times$ and\n$23.5\\times$, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:00:21 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 02:18:12 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Choi", "Yoojin", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1805.08311", "submitter": "Mohammad Ghasemzadeh", "authors": "Mohammad Ghasemzadeh, Fang Lin, Bita Darvish Rouhani, Farinaz\n  Koushanfar, Ke Huang", "title": "AgileNet: Lightweight Dictionary-based Few-shot Learning", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning models is heavily tied to the use of massive\namount of labeled data and excessively long training time. With the emergence\nof intelligent edge applications that use these models, the critical challenge\nis to obtain the same inference capability on a resource-constrained device\nwhile providing adaptability to cope with the dynamic changes in the data. We\npropose AgileNet, a novel lightweight dictionary-based few-shot learning\nmethodology which provides reduced complexity deep neural network for efficient\nexecution at the edge while enabling low-cost updates to capture the dynamics\nof the new data. Evaluations of state-of-the-art few-shot learning benchmarks\ndemonstrate the superior accuracy of AgileNet compared to prior arts.\nAdditionally, AgileNet is the first few-shot learning approach that prevents\nmodel updates by eliminating the knowledge obtained from the primary training.\nThis property is ensured through the dictionaries learned by our novel\nend-to-end structured decomposition, which also reduces the memory footprint\nand computation complexity to match the edge device constraints.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:36:11 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Ghasemzadeh", "Mohammad", ""], ["Lin", "Fang", ""], ["Rouhani", "Bita Darvish", ""], ["Koushanfar", "Farinaz", ""], ["Huang", "Ke", ""]]}, {"id": "1805.08340", "submitter": "Tong Qin", "authors": "Tong Qin and Ling Zhou and Dongbin Xiu", "title": "Reducing Parameter Space for Neural Network Training", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For neural networks (NNs) with rectified linear unit (ReLU) or binary\nactivation functions, we show that their training can be accomplished in a\nreduced parameter space. Specifically, the weights in each neuron can be\ntrained on the unit sphere, as opposed to the entire space, and the threshold\ncan be trained in a bounded interval, as opposed to the real line. We show that\nthe NNs in the reduced parameter space are mathematically equivalent to the\nstandard NNs with parameters in the whole space. The reduced parameter space\nshall facilitate the optimization procedure for the network training, as the\nsearch space becomes (much) smaller. We demonstrate the improved training\nperformance using numerical examples.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 01:08:40 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 17:13:01 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2020 18:10:43 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Qin", "Tong", ""], ["Zhou", "Ling", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1805.08394", "submitter": "Michael Mozer", "authors": "Michael C.Mozer, Denis Kazakov, Robert V. Lindsey", "title": "State-Denoised Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are difficult to train on sequence\nprocessing tasks, not only because input noise may be amplified through\nfeedback, but also because any inaccuracy in the weights has similar\nconsequences as input noise. We describe a method for denoising the hidden\nstate during training to achieve more robust representations thereby improving\ngeneralization performance. Attractor dynamics are incorporated into the hidden\nstate to `clean up' representations at each step of a sequence. The attractor\ndynamics are trained through an auxillary denoising loss to recover previously\nexperienced hidden states from noisy versions of those states. This\nstate-denoised recurrent neural network {SDRNN} performs multiple steps of\ninternal processing for each external sequence step. On a range of tasks, we\nshow that the SDRNN outperforms a generic RNN as well as a variant of the SDRNN\nwith attractor dynamics on the hidden state but without the auxillary loss. We\nargue that attractor dynamics---and corresponding connectivity\nconstraints---are an essential component of the deep learning arsenal and\nshould be invoked not only for recurrent networks but also for improving deep\nfeedforward nets and intertask transfer.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 05:10:13 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 17:16:24 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Mozer", "Michael C.", ""], ["Kazakov", "Denis", ""], ["Lindsey", "Robert V.", ""]]}, {"id": "1805.08522", "submitter": "Guillermo Valle-P\\'erez", "authors": "Guillermo Valle-P\\'erez, Chico Q. Camargo, Ard A. Louis", "title": "Deep learning generalizes because the parameter-function map is biased\n  towards simple functions", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) generalize remarkably well without explicit\nregularization even in the strongly over-parametrized regime where classical\nlearning theory would instead predict that they would severely overfit. While\nmany proposals for some kind of implicit regularization have been made to\nrationalise this success, there is no consensus for the fundamental reason why\nDNNs do not strongly overfit. In this paper, we provide a new explanation. By\napplying a very general probability-complexity bound recently derived from\nalgorithmic information theory (AIT), we argue that the parameter-function map\nof many DNNs should be exponentially biased towards simple functions. We then\nprovide clear evidence for this strong simplicity bias in a model DNN for\nBoolean functions, as well as in much larger fully connected and convolutional\nnetworks applied to CIFAR10 and MNIST. As the target functions in many real\nproblems are expected to be highly structured, this intrinsic simplicity bias\nhelps explain why deep networks generalize well on real world problems. This\npicture also facilitates a novel PAC-Bayes approach where the prior is taken\nover the DNN input-output function space, rather than the more conventional\nprior over parameter space. If we assume that the training algorithm samples\nparameters close to uniformly within the zero-error region then the PAC-Bayes\ntheorem can be used to guarantee good expected generalization for target\nfunctions producing high-likelihood training sets. By exploiting recently\ndiscovered connections between DNNs and Gaussian processes to estimate the\nmarginal likelihood, we produce relatively tight generalization PAC-Bayes error\nbounds which correlate well with the true error on realistic datasets such as\nMNIST and CIFAR10 and for architectures including convolutional and fully\nconnected networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 11:51:36 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 10:55:36 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 18:22:18 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2019 23:40:35 GMT"}, {"version": "v5", "created": "Sun, 21 Apr 2019 10:16:54 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Valle-P\u00e9rez", "Guillermo", ""], ["Camargo", "Chico Q.", ""], ["Louis", "Ard A.", ""]]}, {"id": "1805.08545", "submitter": "Arturo Marban", "authors": "Arturo Marban, Vignesh Srinivasan, Wojciech Samek, Josep Fern\\'andez,\n  Alicia Casals", "title": "A Recurrent Convolutional Neural Network Approach for Sensorless Force\n  Estimation in Robotic Surgery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing force feedback as relevant information in current Robot-Assisted\nMinimally Invasive Surgery systems constitutes a technological challenge due to\nthe constraints imposed by the surgical environment. In this context,\nSensorless Force Estimation techniques represent a potential solution, enabling\nto sense the interaction forces between the surgical instruments and\nsoft-tissues. Specifically, if visual feedback is available for observing\nsoft-tissues' deformation, this feedback can be used to estimate the forces\napplied to these tissues. To this end, a force estimation model, based on\nConvolutional Neural Networks and Long-Short Term Memory networks, is proposed\nin this work. This model is designed to process both, the spatiotemporal\ninformation present in video sequences and the temporal structure of tool data\n(the surgical tool-tip trajectory and its grasping status). A series of\nanalyses are carried out to reveal the advantages of the proposal and the\nchallenges that remain for real applications. This research work focuses on two\nsurgical task scenarios, referred to as pushing and pulling tissue. For these\ntwo scenarios, different input data modalities and their effect on the force\nestimation quality are investigated. These input data modalities are tool data,\nvideo sequences and a combination of both. The results suggest that the force\nestimation quality is better when both, the tool data and video sequences, are\nprocessed by the neural network model. Moreover, this study reveals the need\nfor a loss function, designed to promote the modeling of smooth and sharp\ndetails found in force signals. Finally, the results show that the modeling of\nforces due to pulling tasks is more challenging than for the simplest pushing\nactions.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:39:24 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Marban", "Arturo", ""], ["Srinivasan", "Vignesh", ""], ["Samek", "Wojciech", ""], ["Fern\u00e1ndez", "Josep", ""], ["Casals", "Alicia", ""]]}, {"id": "1805.08574", "submitter": "Sebastian Flennerhag", "authors": "Sebastian Flennerhag, Hujun Yin, John Keane, Mark Elliot", "title": "Breaking the Activation Function Bottleneck through Adaptive\n  Parameterization", "comments": "Published as a conference paper at NeurIPS (NIPS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard neural network architectures are non-linear only by virtue of a\nsimple element-wise activation function, making them both brittle and\nexcessively large. In this paper, we consider methods for making the\nfeed-forward layer more flexible while preserving its basic structure. We\ndevelop simple drop-in replacements that learn to adapt their parameterization\nconditional on the input, thereby increasing statistical efficiency\nsignificantly. We present an adaptive LSTM that advances the state of the art\nfor the Penn Treebank and WikiText-2 word-modeling tasks while using fewer\nparameters and converging in less than half as many iterations.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 13:35:08 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 06:37:30 GMT"}, {"version": "v3", "created": "Mon, 9 Jul 2018 10:13:09 GMT"}, {"version": "v4", "created": "Thu, 22 Nov 2018 13:57:14 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Flennerhag", "Sebastian", ""], ["Yin", "Hujun", ""], ["Keane", "John", ""], ["Elliot", "Mark", ""]]}, {"id": "1805.08594", "submitter": "Louis Faury", "authors": "Louis Faury and Flavian Vasile and Cl\\'ement Calauz\\`enes and Olivier\n  Fercoq", "title": "Neural Generative Models for Global Optimization with Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of global optimization is to find the global optimum of arbitrary\nclasses of functions, possibly highly multimodal ones. In this paper we focus\non the subproblem of global optimization for differentiable functions and we\npropose an Evolutionary Search-inspired solution where we model point search\ndistributions via Generative Neural Networks. This approach enables us to model\ndiverse and complex search distributions based on which we can efficiently\nexplore complicated objective landscapes. In our experiments we show the\npractical superiority of our algorithm versus classical Evolutionary Search and\ngradient-based solutions on a benchmark set of multimodal functions, and\ndemonstrate how it can be used to accelerate Bayesian Optimization with\nGaussian Processes.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 14:12:32 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 14:25:53 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 18:24:19 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Faury", "Louis", ""], ["Vasile", "Flavian", ""], ["Calauz\u00e8nes", "Cl\u00e9ment", ""], ["Fercoq", "Olivier", ""]]}, {"id": "1805.08654", "submitter": "Hongxiang Chen", "authors": "Hongxiang Chen, Leonard Wossnig, Simone Severini, Hartmut Neven, and\n  Masoud Mohseni", "title": "Universal discriminative quantum neural networks", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": "10.1007/s42484-020-00025-7", "report-no": null, "categories": "quant-ph cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum mechanics fundamentally forbids deterministic discrimination of\nquantum states and processes. However, the ability to optimally distinguish\nvarious classes of quantum data is an important primitive in quantum\ninformation science. In this work, we train near-term quantum circuits to\nclassify data represented by non-orthogonal quantum probability distributions\nusing the Adam stochastic optimization algorithm. This is achieved by iterative\ninteractions of a classical device with a quantum processor to discover the\nparameters of an unknown non-unitary quantum circuit. This circuit learns to\nsimulates the unknown structure of a generalized quantum measurement, or\nPositive-Operator-Value-Measure (POVM), that is required to optimally\ndistinguish possible distributions of quantum inputs. Notably we use universal\ncircuit topologies, with a theoretically motivated circuit design, which\nguarantees that our circuits can in principle learn to perform arbitrary\ninput-output mappings. Our numerical simulations show that shallow quantum\ncircuits could be trained to discriminate among various pure and mixed quantum\nstates exhibiting a trade-off between minimizing erroneous and inconclusive\noutcomes with comparable performance to theoretically optimal POVMs. We train\nthe circuit on different classes of quantum data and evaluate the\ngeneralization error on unseen mixed quantum states. This generalization power\nhence distinguishes our work from standard circuit optimization and provides an\nexample of quantum machine learning for a task that has inherently no classical\nanalogue.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:09:43 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Chen", "Hongxiang", ""], ["Wossnig", "Leonard", ""], ["Severini", "Simone", ""], ["Neven", "Hartmut", ""], ["Mohseni", "Masoud", ""]]}, {"id": "1805.08680", "submitter": "Fei Gao", "authors": "Binyan Lin, Fei Gao, Meng Wang, Yuyao Xiong, Ansheng Li", "title": "A Parameter Estimation of Fractional Order Grey Model Based on Adaptive\n  Dynamic Cat Swarm Algorithm", "comments": "6 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we utilize ADCSO (Adaptive Dynamic Cat Swarm Optimization) to\nestimate the parameters of Fractional Order Grey Model. The parameters of\nFractional Order Grey Model affect the prediction accuracy of the model. In\norder to solve the problem that general swarm intelligence algorithms easily\nfall into the local optimum and optimize the accuracy of the model, ADCSO is\nutilized to reduce the error of the model. Experimental results for the data of\ncontainer throughput of Wuhan Port and marine capture productions of Zhejiang\nProvince show that the different parameter values affect the prediction\nresults. The parameters estimated by ADCSO make the prediction error of the\nmodel smaller and the convergence speed higher, and it is not easy to fall into\nthe local convergence compared with PSO (Particle Swarm Optimization) and LSM\n(Least Square Method). The feasibility and advantage of ADCSO for the parameter\nestimation of Fractional Order Grey Model are verified.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:52:28 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 12:13:52 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Lin", "Binyan", ""], ["Gao", "Fei", ""], ["Wang", "Meng", ""], ["Xiong", "Yuyao", ""], ["Li", "Ansheng", ""]]}, {"id": "1805.08709", "submitter": "Emin Orhan", "authors": "A. Emin Orhan", "title": "A Simple Cache Model for Image Recognition", "comments": "Published as a conference paper at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training large-scale image recognition models is computationally expensive.\nThis raises the question of whether there might be simple ways to improve the\ntest performance of an already trained model without having to re-train or\nfine-tune it with new data. Here, we show that, surprisingly, this is indeed\npossible. The key observation we make is that the layers of a deep network\nclose to the output layer contain independent, easily extractable\nclass-relevant information that is not contained in the output layer itself. We\npropose to extract this extra class-relevant information using a simple\nkey-value cache memory to improve the classification performance of the model\nat test time. Our cache memory is directly inspired by a similar cache model\npreviously proposed for language modeling (Grave et al., 2017). This cache\ncomponent does not require any training or fine-tuning; it can be applied to\nany pre-trained model and, by properly setting only two hyper-parameters, leads\nto significant improvements in its classification performance. Improvements are\nobserved across several architectures and datasets. In the cache component,\nusing features extracted from layers close to the output (but not from the\noutput layer itself) as keys leads to the largest improvements. Concatenating\nfeatures from multiple layers to form keys can further improve performance over\nusing single-layer features as keys. The cache component also has a\nregularizing effect, a simple consequence of which is that it substantially\nincreases the robustness of models against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:50:14 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 18:24:18 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Orhan", "A. Emin", ""]]}, {"id": "1805.08747", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Limeng Cui, Fisher B. Gouza", "title": "EgoCoder: Intelligent Program Synthesis with Hierarchical Sequential\n  Neural Network Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming has been an important skill for researchers and practitioners in\ncomputer science and other related areas. To learn basic programing skills, a\nlong-time systematic training is usually required for beginners. According to a\nrecent market report, the computer software market is expected to continue\nexpanding at an accelerating speed, but the market supply of qualified software\ndevelopers can hardly meet such a huge demand. In recent years, the surge of\ntext generation research works provides the opportunities to address such a\ndilemma through automatic program synthesis. In this paper, we propose to make\nour try to solve the program synthesis problem from a data mining perspective.\nTo address the problem, a novel generative model, namely EgoCoder, will be\nintroduced in this paper. EgoCoder effectively parses program code into\nabstract syntax trees (ASTs), where the tree nodes will contain the program\ncode/comment content and the tree structure can capture the program logic\nflows. Based on a new unit model called Hsu, EgoCoder can effectively capture\nboth the hierarchical and sequential patterns in the program ASTs. Extensive\nexperiments will be done to compare EgoCoder with the state-of-the-art text\ngeneration methods, and the experimental results have demonstrated the\neffectiveness of EgoCoder in addressing the program synthesis problem.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:11:35 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.08751", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Bowen Dong, Philip S. Yu", "title": "FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural\n  Network", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, due to the booming development of online social networks,\nfake news for various commercial and political purposes has been appearing in\nlarge numbers and widespread in the online world. With deceptive words, online\nsocial network users can get infected by these online fake news easily, which\nhas brought about tremendous effects on the offline society already. An\nimportant goal in improving the trustworthiness of information in online social\nnetworks is to identify the fake news timely. This paper aims at investigating\nthe principles, methodologies and algorithms for detecting fake news articles,\ncreators and subjects from online social networks and evaluating the\ncorresponding performance. This paper addresses the challenges introduced by\nthe unknown characteristics of fake news and diverse connections among news\narticles, creators and subjects. This paper introduces a novel automatic fake\nnews credibility inference model, namely FAKEDETECTOR. Based on a set of\nexplicit and latent features extracted from the textual information,\nFAKEDETECTOR builds a deep diffusive network model to learn the representations\nof news articles, creators and subjects simultaneously. Extensive experiments\nhave been done on a real-world fake news dataset to compare FAKEDETECTOR with\nseveral state-of-the-art models, and the experimental results have demonstrated\nthe effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:23:32 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2019 11:40:16 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zhang", "Jiawei", ""], ["Dong", "Bowen", ""], ["Yu", "Philip S.", ""]]}, {"id": "1805.08786", "submitter": "Mirco Milletar\\`i", "authors": "Mirco Milletar\\'i, Thiparat Chotibut, Paolo E. Trevisanutto", "title": "Mean Field Theory of Activation Functions in Deep Neural Networks", "comments": "Presented at the ICML 2019 Workshop on Theoretical Physics forDeep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Statistical Mechanics (SM) model of deep neural networks,\nconnecting the energy-based and the feed forward networks (FFN) approach. We\ninfer that FFN can be understood as performing three basic steps: encoding,\nrepresentation validation and propagation. From the meanfield solution of the\nmodel, we obtain a set of natural activations -- such as Sigmoid, $\\tanh$ and\nReLu -- together with the state-of-the-art, Swish; this represents the expected\ninformation propagating through the network and tends to ReLu in the limit of\nzero noise.We study the spectrum of the Hessian on an associated classification\ntask, showing that Swish allows for more consistent performances over a wider\nrange of network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 18:00:02 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 03:33:45 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Milletar\u00ed", "Mirco", ""], ["Chotibut", "Thiparat", ""], ["Trevisanutto", "Paolo E.", ""]]}, {"id": "1805.08878", "submitter": "Narendra Patwardhan", "authors": "Narendra Patwardhan, Madhura Ingalhalikar, Rahee Walambe", "title": "ARiA: Utilizing Richard's Curve for Controlling the Non-monotonicity of\n  the Activation Function in Deep Neural Nets", "comments": "Modified version Submitted to ECCV '18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel activation unit that can be efficiently employed\nin deep neural nets (DNNs) and performs significantly better than the\ntraditional Rectified Linear Units (ReLU). The function developed is a two\nparameter version of the specialized Richard's Curve and we call it Adaptive\nRichard's Curve weighted Activation (ARiA). This function is non-monotonous,\nanalogous to the newly introduced Swish, however allows a precise control over\nits non-monotonous convexity by varying the hyper-parameters. We first\ndemonstrate the mathematical significance of the two parameter ARiA followed by\nits application to benchmark problems such as MNIST, CIFAR-10 and CIFAR-100,\nwhere we compare the performance with ReLU and Swish units. Our results\nillustrate a significantly superior performance on all these datasets, making\nARiA a potential replacement for ReLU and other activations in DNNs.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 21:46:08 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Patwardhan", "Narendra", ""], ["Ingalhalikar", "Madhura", ""], ["Walambe", "Rahee", ""]]}, {"id": "1805.08889", "submitter": "David Clark", "authors": "David G. Clark, Jesse A. Livezey, Edward F. Chang, Kristofer E.\n  Bouchard", "title": "Spiking Linear Dynamical Systems on Neuromorphic Hardware for Low-Power\n  Brain-Machine Interfaces", "comments": "23 pages, 8 figures; added reference, removed typo in Fig. 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic architectures achieve low-power operation by using many simple\nspiking neurons in lieu of traditional hardware. Here, we develop methods for\nprecise linear computations in spiking neural networks and use these methods to\nmap the evolution of a linear dynamical system (LDS) onto an existing\nneuromorphic chip: IBM's TrueNorth. We analytically characterize, and\nnumerically validate, the discrepancy between the spiking LDS state sequence\nand that of its non-spiking counterpart. These analytical results shed light on\nthe multiway tradeoff between time, space, energy, and accuracy in neuromorphic\ncomputation. To demonstrate the utility of our work, we implemented a\nneuromorphic Kalman filter (KF) and used it for offline decoding of human vocal\npitch from neural data. The neuromorphic KF could be used for low-power\nfiltering in domains beyond neuroscience, such as navigation or robotics.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 22:34:19 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 23:37:53 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Clark", "David G.", ""], ["Livezey", "Jesse A.", ""], ["Chang", "Edward F.", ""], ["Bouchard", "Kristofer E.", ""]]}, {"id": "1805.08932", "submitter": "Chetan Singh Thakur", "authors": "Chetan Singh Thakur, Jamal Molin, Gert Cauwenberghs, Giacomo Indiveri,\n  Kundan Kumar, Ning Qiao, Johannes Schemmel, Runchun Wang, Elisabetta Chicca,\n  Jennifer Olson Hasler, Jae-sun Seo, Shimeng Yu, Yu Cao, Andr\\'e van Schaik,\n  Ralph Etienne-Cummings", "title": "Large-Scale Neuromorphic Spiking Array Processors: A quest to mimic the\n  brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neuromorphic engineering (NE) encompasses a diverse range of approaches to\ninformation processing that are inspired by neurobiological systems, and this\nfeature distinguishes neuromorphic systems from conventional computing systems.\nThe brain has evolved over billions of years to solve difficult engineering\nproblems by using efficient, parallel, low-power computation. The goal of NE is\nto design systems capable of brain-like computation. Numerous large-scale\nneuromorphic projects have emerged recently. This interdisciplinary field was\nlisted among the top 10 technology breakthroughs of 2014 by the MIT Technology\nReview and among the top 10 emerging technologies of 2015 by the World Economic\nForum. NE has two-way goals: one, a scientific goal to understand the\ncomputational properties of biological neural systems by using models\nimplemented in integrated circuits (ICs); second, an engineering goal to\nexploit the known properties of biological systems to design and implement\nefficient devices for engineering applications. Building hardware neural\nemulators can be extremely useful for simulating large-scale neural models to\nexplain how intelligent behavior arises in the brain. The principle advantages\nof neuromorphic emulators are that they are highly energy efficient, parallel\nand distributed, and require a small silicon area. Thus, compared to\nconventional CPUs, these neuromorphic emulators are beneficial in many\nengineering applications such as for the porting of deep learning algorithms\nfor various recognitions tasks. In this review article, we describe some of the\nmost significant neuromorphic spiking emulators, compare the different\narchitectures and approaches used by them, illustrate their advantages and\ndrawbacks, and highlight the capabilities that each can deliver to neural\nmodelers.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 01:52:33 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Thakur", "Chetan Singh", ""], ["Molin", "Jamal", ""], ["Cauwenberghs", "Gert", ""], ["Indiveri", "Giacomo", ""], ["Kumar", "Kundan", ""], ["Qiao", "Ning", ""], ["Schemmel", "Johannes", ""], ["Wang", "Runchun", ""], ["Chicca", "Elisabetta", ""], ["Hasler", "Jennifer Olson", ""], ["Seo", "Jae-sun", ""], ["Yu", "Shimeng", ""], ["Cao", "Yu", ""], ["van Schaik", "Andr\u00e9", ""], ["Etienne-Cummings", "Ralph", ""]]}, {"id": "1805.09244", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Andrea Bongiorno", "title": "Concentric ESN: Assessing the Effect of Modularity in Cycle Reservoirs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces concentric Echo State Network, an approach to design\nreservoir topologies that tries to bridge the gap between deterministically\nconstructed simple cycle models and deep reservoir computing approaches. We\nshow how to modularize the reservoir into simple unidirectional and concentric\ncycles with pairwise bidirectional jump connections between adjacent loops. We\nprovide a preliminary experimental assessment showing how concentric reservoirs\nyield to superior predictive accuracy and memory capacity with respect to\nsingle cycle reservoirs and deep reservoir models.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:58:57 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bacciu", "Davide", ""], ["Bongiorno", "Andrea", ""]]}, {"id": "1805.09282", "submitter": "Mikhail Goykhman", "authors": "Mikhail Goykhman", "title": "On self-play computation of equilibrium in poker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare performance of the genetic algorithm and the counterfactual regret\nminimization algorithm in computing the near-equilibrium strategies in the\nsimplified poker games. We focus on the von Neumann poker and the simplified\nversion of the Texas Hold'Em poker, and test outputs of the considered\nalgorithms against analytical expressions defining the Nash equilibrium\nstrategies. We comment on the performance of the studied algorithms against\nopponents deviating from equilibrium.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 16:54:50 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Goykhman", "Mikhail", ""]]}, {"id": "1805.09355", "submitter": "Marek Rei", "authors": "Marek Rei, Daniela Gerz, Ivan Vuli\\'c", "title": "Scoring Lexical Entailment with a Supervised Directional Similarity\n  Network", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Supervised Directional Similarity Network (SDSN), a novel\nneural architecture for learning task-specific transformation functions on top\nof general-purpose word embeddings. Relying on only a limited amount of\nsupervision from task-specific scores on a subset of the vocabulary, our\narchitecture is able to generalise and transform a general-purpose\ndistributional vector space to model the relation of lexical entailment.\nExperiments show excellent performance on scoring graded lexical entailment,\nraising the state-of-the-art on the HyperLex dataset by approximately 25%.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 18:03:40 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Rei", "Marek", ""], ["Gerz", "Daniela", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.09415", "submitter": "Martin Krejca", "authors": "Timo K\\\"otzing and Martin S. Krejca", "title": "First-Hitting Times Under Additive Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For the last ten years, almost every theoretical result concerning the\nexpected run time of a randomized search heuristic used drift theory, making it\nthe arguably most important tool in this domain. Its success is due to its ease\nof use and its powerful result: drift theory allows the user to derive bounds\non the expected first-hitting time of a random process by bounding expected\nlocal changes of the process -- the drift. This is usually far easier than\nbounding the expected first-hitting time directly.\n  Due to the widespread use of drift theory, it is of utmost importance to have\nthe best drift theorems possible. We improve the fundamental additive,\nmultiplicative, and variable drift theorems by stating them in a form as\ngeneral as possible and providing examples of why the restrictions we keep are\nstill necessary. Our additive drift theorem for upper bounds only requires the\nprocess to be nonnegative, that is, we remove unnecessary restrictions like a\nfinite, discrete, or bounded search space. As corollaries, the same is true for\nour upper bounds in the case of variable and multiplicative drift.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:13:40 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["K\u00f6tzing", "Timo", ""], ["Krejca", "Martin S.", ""]]}, {"id": "1805.09545", "submitter": "Lenaic Chizat", "authors": "Lenaic Chizat (SIERRA), Francis Bach (SIERRA)", "title": "On the Global Convergence of Gradient Descent for Over-parameterized\n  Models using Optimal Transport", "comments": "Advances in Neural Information Processing Systems (NIPS), Dec 2018,\n  Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks in machine learning and signal processing can be solved by\nminimizing a convex function of a measure. This includes sparse spikes\ndeconvolution or training a neural network with a single hidden layer. For\nthese problems, we study a simple minimization method: the unknown measure is\ndiscretized into a mixture of particles and a continuous-time gradient descent\nis performed on their weights and positions. This is an idealization of the\nusual way to train neural networks with a large hidden layer. We show that,\nwhen initialized correctly and in the many-particle limit, this gradient flow,\nalthough non-convex, converges to global minimizers. The proof involves\nWasserstein gradient flows, a by-product of optimal transport theory. Numerical\nexperiments show that this asymptotic behavior is already at play for a\nreasonable number of particles, even in high dimension.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 08:28:01 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 09:27:29 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Chizat", "Lenaic", "", "SIERRA"], ["Bach", "Francis", "", "SIERRA"]]}, {"id": "1805.09692", "submitter": "Sam Ritter", "authors": "Samuel Ritter, Jane X. Wang, Zeb Kurth-Nelson, Siddhant M. Jayakumar,\n  Charles Blundell, Razvan Pascanu, Matthew Botvinick", "title": "Been There, Done That: Meta-Learning with Episodic Recall", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning agents excel at rapidly learning new tasks from open-ended task\ndistributions; yet, they forget what they learn about each task as soon as the\nnext begins. When tasks reoccur - as they do in natural environments -\nmetalearning agents must explore again instead of immediately exploiting\npreviously discovered solutions. We propose a formalism for generating\nopen-ended yet repetitious environments, then develop a meta-learning\narchitecture for solving these environments. This architecture melds the\nstandard LSTM working memory with a differentiable neural episodic memory. We\nexplore the capabilities of agents with this episodic LSTM in five\nmeta-learning environments with reoccurring tasks, ranging from bandits to\nnavigation and stochastic sequential decision problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 14:15:27 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 14:59:58 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Ritter", "Samuel", ""], ["Wang", "Jane X.", ""], ["Kurth-Nelson", "Zeb", ""], ["Jayakumar", "Siddhant M.", ""], ["Blundell", "Charles", ""], ["Pascanu", "Razvan", ""], ["Botvinick", "Matthew", ""]]}, {"id": "1805.09712", "submitter": "Burak Kakillioglu", "authors": "Burak Kakillioglu, Yantao Lu, and Senem Velipasalar", "title": "Autonomously and Simultaneously Refining Deep Neural Network Parameters\n  by Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of parameters, and the design of the network architecture are\nimportant factors affecting the performance of deep neural networks. However,\nthere has not been much work on developing an established and systematic way of\nbuilding the structure and choosing the parameters of a neural network, and\nthis task heavily depends on trial and error and empirical results. Considering\nthat there are many design and parameter choices, such as the number of neurons\nin each layer, the type of activation function, the choice of using drop out or\nnot, it is very hard to cover every configuration, and find the optimal\nstructure. In this paper, we propose a novel and systematic method that\nautonomously and simultaneously optimizes multiple parameters of any given deep\nneural network by using a generative adversarial network (GAN). In our proposed\napproach, two different models compete and improve each other progressively\nwith a GAN-based strategy. Our proposed approach can be used to autonomously\nrefine the parameters, and improve the accuracy of different deep neural\nnetwork architectures. Without loss of generality, the proposed method has been\ntested with three different neural network architectures, and three very\ndifferent datasets and applications. The results show that the presented\napproach can simultaneously and successfully optimize multiple neural network\nparameters, and achieve increased accuracy in all three scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 15:00:13 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Kakillioglu", "Burak", ""], ["Lu", "Yantao", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1805.09786", "submitter": "\\c{C}a\\u{g}lar G\\\"ul\\c{c}ehre", "authors": "Caglar Gulcehre, Misha Denil, Mateusz Malinowski, Ali Razavi, Razvan\n  Pascanu, Karl Moritz Hermann, Peter Battaglia, Victor Bapst, David Raposo,\n  Adam Santoro, Nando de Freitas", "title": "Hyperbolic Attention Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce hyperbolic attention networks to endow neural networks with\nenough capacity to match the complexity of data with hierarchical and power-law\nstructure. A few recent approaches have successfully demonstrated the benefits\nof imposing hyperbolic geometry on the parameters of shallow networks. We\nextend this line of work by imposing hyperbolic geometry on the activations of\nneural networks. This allows us to exploit hyperbolic geometry to reason about\nembeddings produced by deep networks. We achieve this by re-expressing the\nubiquitous mechanism of soft attention in terms of operations defined for\nhyperboloid and Klein models. Our method shows improvements in terms of\ngeneralization on neural machine translation, learning on graphs and visual\nquestion answering tasks while keeping the neural representations compact.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:11:35 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Gulcehre", "Caglar", ""], ["Denil", "Misha", ""], ["Malinowski", "Mateusz", ""], ["Razavi", "Ali", ""], ["Pascanu", "Razvan", ""], ["Hermann", "Karl Moritz", ""], ["Battaglia", "Peter", ""], ["Bapst", "Victor", ""], ["Raposo", "David", ""], ["Santoro", "Adam", ""], ["de Freitas", "Nando", ""]]}, {"id": "1805.09791", "submitter": "Xiaoxi He", "authors": "Xiaoxi He, Zimu Zhou, Lothar Thiele", "title": "Multi-Task Zipping via Layer-wise Neuron Sharing", "comments": "Published as a conference paper at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future mobile devices are anticipated to perceive, understand and react to\nthe world on their own by running multiple correlated deep neural networks\non-device. Yet the complexity of these neural networks needs to be trimmed down\nboth within-model and cross-model to fit in mobile storage and memory. Previous\nstudies focus on squeezing the redundancy within a single neural network. In\nthis work, we aim to reduce the redundancy across multiple models. We propose\nMulti-Task Zipping (MTZ), a framework to automatically merge correlated,\npre-trained deep neural networks for cross-model compression. Central in MTZ is\na layer-wise neuron sharing and incoming weight updating scheme that induces a\nminimal change in the error function. MTZ inherits information from each model\nand demands light retraining to re-boost the accuracy of individual tasks.\nEvaluations show that MTZ is able to fully merge the hidden layers of two\nVGG-16 networks with a 3.18% increase in the test error averaged on ImageNet\nand CelebA, or share 39.61% parameters between the two networks with <0.5%\nincrease in the test errors for both tasks. The number of iterations to retrain\nthe combined network is at least 17.8 times lower than that of training a\nsingle VGG-16 network. Moreover, experiments show that MTZ is also able to\neffectively merge multiple residual networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:33:38 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 09:05:31 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["He", "Xiaoxi", ""], ["Zhou", "Zimu", ""], ["Thiele", "Lothar", ""]]}, {"id": "1805.09874", "submitter": "Aleksandr Aravkin", "authors": "German Abrevaya, Irina Rish, Aleksandr Y. Aravkin, Guillermo Cecchi,\n  James Kozloski, Pablo Polosecki, Peng Zheng, Silvina Ponce Dawson, Juliana\n  Rhee, David Cox", "title": "Learning Nonlinear Brain Dynamics: van der Pol Meets LSTM", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world data sets, especially in biology, are produced by complex\nnonlinear dynamical systems. In this paper, we focus on brain calcium imaging\n(CaI) of different organisms (zebrafish and rat), aiming to build a model of\njoint activation dynamics in large neuronal populations, including the whole\nbrain of zebrafish. We propose a new approach for capturing dynamics of\ntemporal SVD components that uses the coupled (multivariate) van der Pol (VDP)\noscillator, a nonlinear ordinary differential equation (ODE) model describing\nneural activity, with a new parameter estimation technique that combines\nvariable projection optimization and stochastic search. We show that the\napproach successfully handles nonlinearities and hidden state variables in the\ncoupled VDP. The approach is accurate, achieving 0.82 to 0.94 correlation\nbetween the actual and model-generated components, and interpretable, as VDP's\ncoupling matrix reveals anatomically meaningful positive (excitatory) and\nnegative (inhibitory) interactions across different brain subsystems\ncorresponding to spatial SVD components. Moreover, VDP is comparable to (or\nsometimes better than) recurrent neural networks (LSTM) for (short-term)\nprediction of future brain activity; VDP needs less parameters to train, which\nwas a plus on our small training data. Finally, the overall best predictive\nmethod, greatly outperforming both VDP and LSTM in short- and long-term\npredictive settings on both datasets, was the new hybrid VDP-LSTM approach that\nused VDP to simulate large domain-specific dataset for LSTM pretraining; note\nthat simple LSTM data-augmentation via noisy versions of training data was much\nless effective.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 19:58:37 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2019 02:03:39 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Abrevaya", "German", ""], ["Rish", "Irina", ""], ["Aravkin", "Aleksandr Y.", ""], ["Cecchi", "Guillermo", ""], ["Kozloski", "James", ""], ["Polosecki", "Pablo", ""], ["Zheng", "Peng", ""], ["Dawson", "Silvina Ponce", ""], ["Rhee", "Juliana", ""], ["Cox", "David", ""]]}, {"id": "1805.09943", "submitter": "Tyler Hughes", "authors": "Tyler W. Hughes, Momchil Minkov, Yu Shi, Shanhui Fan", "title": "Training of photonic neural networks through in situ backpropagation", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": "10.1364/OPTICA.5.000864", "report-no": null, "categories": "physics.optics cs.LG cs.NE physics.app-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, integrated optics has gained interest as a hardware platform for\nimplementing machine learning algorithms. Of particular interest are artificial\nneural networks, since matrix-vector multi- plications, which are used heavily\nin artificial neural networks, can be done efficiently in photonic circuits.\nThe training of an artificial neural network is a crucial step in its\napplication. However, currently on the integrated photonics platform there is\nno efficient protocol for the training of these networks. In this work, we\nintroduce a method that enables highly efficient, in situ training of a\nphotonic neural network. We use adjoint variable methods to derive the photonic\nanalogue of the backpropagation algorithm, which is the standard method for\ncomputing gradients of conventional neural networks. We further show how these\ngradients may be obtained exactly by performing intensity measurements within\nthe device. As an application, we demonstrate the training of a numerically\nsimulated photonic artificial neural network. Beyond the training of photonic\nmachine learning implementations, our method may also be of broad interest to\nexperimental sensitivity analysis of photonic systems and the optimization of\nreconfigurable optics platforms.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 01:24:05 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Hughes", "Tyler W.", ""], ["Minkov", "Momchil", ""], ["Shi", "Yu", ""], ["Fan", "Shanhui", ""]]}, {"id": "1805.10002", "submitter": "Yanbin Liu", "authors": "Yanbin Liu, Juho Lee, Minseop Park, Saehoon Kim, Eunho Yang, Sung Ju\n  Hwang and Yi Yang", "title": "Learning to Propagate Labels: Transductive Propagation Network for\n  Few-shot Learning", "comments": "Accepted in ICLR 2019; code available at\n  https://github.com/csyanbin/TPN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of few-shot learning is to learn a classifier that generalizes well\neven when trained with a limited number of training instances per class. The\nrecently introduced meta-learning approaches tackle this problem by learning a\ngeneric classifier across a large number of multiclass classification tasks and\ngeneralizing the model to a new task. Yet, even with such meta-learning, the\nlow-data problem in the novel classification task still remains. In this paper,\nwe propose Transductive Propagation Network (TPN), a novel meta-learning\nframework for transductive inference that classifies the entire test set at\nonce to alleviate the low-data problem. Specifically, we propose to learn to\npropagate labels from labeled instances to unlabeled test instances, by\nlearning a graph construction module that exploits the manifold structure in\nthe data. TPN jointly learns both the parameters of feature embedding and the\ngraph construction in an end-to-end manner. We validate TPN on multiple\nbenchmark datasets, on which it largely outperforms existing few-shot learning\napproaches and achieves the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 07:00:31 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 06:31:47 GMT"}, {"version": "v3", "created": "Tue, 25 Dec 2018 04:31:05 GMT"}, {"version": "v4", "created": "Fri, 1 Feb 2019 04:36:54 GMT"}, {"version": "v5", "created": "Fri, 8 Feb 2019 09:30:53 GMT"}], "update_date": "2019-02-11", "authors_parsed": [["Liu", "Yanbin", ""], ["Lee", "Juho", ""], ["Park", "Minseop", ""], ["Kim", "Saehoon", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""], ["Yang", "Yi", ""]]}, {"id": "1805.10169", "submitter": "Anna Melnichenko", "authors": "Timo K\\\"otzing, J.A.Gregor Lagodzinski, Johannes Lengler, Anna\n  Melnichenko", "title": "Destructiveness of Lexicographic Parsimony Pressure and Alleviation by a\n  Concatenation Crossover in Genetic Programming", "comments": "to appear in PPSN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For theoretical analyses there are two specifics distinguishing GP from many\nother areas of evolutionary computation. First, the variable size\nrepresentations, in particular yielding a possible bloat (i.e. the growth of\nindividuals with redundant parts). Second, the role and realization of\ncrossover, which is particularly central in GP due to the tree-based\nrepresentation. Whereas some theoretical work on GP has studied the effects of\nbloat, crossover had a surprisingly little share in this work. We analyze a\nsimple crossover operator in combination with local search, where a preference\nfor small solutions minimizes bloat (lexicographic parsimony pressure); the\nresulting algorithm is denoted Concatenation Crossover GP. For this purpose\nthree variants of the well-studied MAJORITY test function with large plateaus\nare considered. We show that the Concatenation Crossover GP can efficiently\noptimize these test functions, while local search cannot be efficient for all\nthree variants independent of employing bloat control.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 14:18:25 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["K\u00f6tzing", "Timo", ""], ["Lagodzinski", "J. A. Gregor", ""], ["Lengler", "Johannes", ""], ["Melnichenko", "Anna", ""]]}, {"id": "1805.10190", "submitter": "Alice Coucke", "authors": "Alice Coucke, Alaa Saade, Adrien Ball, Th\\'eodore Bluche, Alexandre\n  Caulier, David Leroy, Cl\\'ement Doumouro, Thibault Gisselbrecht, Francesco\n  Caltagirone, Thibaut Lavril, Ma\\\"el Primet, Joseph Dureau", "title": "Snips Voice Platform: an embedded Spoken Language Understanding system\n  for private-by-design voice interfaces", "comments": "29 pages, 9 figures, 17 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the machine learning architecture of the Snips Voice\nPlatform, a software solution to perform Spoken Language Understanding on\nmicroprocessors typical of IoT devices. The embedded inference is fast and\naccurate while enforcing privacy by design, as no personal user data is ever\ncollected. Focusing on Automatic Speech Recognition and Natural Language\nUnderstanding, we detail our approach to training high-performance Machine\nLearning models that are small enough to run in real-time on small devices.\nAdditionally, we describe a data generation procedure that provides sufficient,\nhigh-quality training data without compromising user privacy.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 15:04:17 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 17:52:08 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 16:34:25 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Coucke", "Alice", ""], ["Saade", "Alaa", ""], ["Ball", "Adrien", ""], ["Bluche", "Th\u00e9odore", ""], ["Caulier", "Alexandre", ""], ["Leroy", "David", ""], ["Doumouro", "Cl\u00e9ment", ""], ["Gisselbrecht", "Thibault", ""], ["Caltagirone", "Francesco", ""], ["Lavril", "Thibaut", ""], ["Primet", "Ma\u00ebl", ""], ["Dureau", "Joseph", ""]]}, {"id": "1805.10255", "submitter": "Manoj Kumar", "authors": "Manoj Kumar, George E. Dahl, Vijay Vasudevan, Mohammad Norouzi", "title": "Parallel Architecture and Hyperparameter Search via Successive Halving\n  and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and powerful algorithm for parallel black box\noptimization called Successive Halving and Classification (SHAC). The algorithm\noperates in $K$ stages of parallel function evaluations and trains a cascade of\nbinary classifiers to iteratively cull the undesirable regions of the search\nspace. SHAC is easy to implement, requires no tuning of its own configuration\nparameters, is invariant to the scale of the objective function and can be\nbuilt using any choice of binary classifier. We adopt tree-based classifiers\nwithin SHAC and achieve competitive performance against several strong\nbaselines for optimizing synthetic functions, hyperparameters and\narchitectures.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:12:38 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Kumar", "Manoj", ""], ["Dahl", "George E.", ""], ["Vasudevan", "Vijay", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1805.10307", "submitter": "Hossein Sabzian", "authors": "Hossein Sabzian, Hossein Gharib, Javad Noori, Mohammad Ali Shafia,\n  Mohammad Javad Sheikh", "title": "Forecasting the successful execution of horizontal strategy in a\n  diversified corporation via a DEMATEL-supported artificial neural network - A\n  case study", "comments": "35 pages, 16 figures, 7 tables, 34 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, competition is getting tougher as market shrinks because of\nfinancial crisis of the late 2000s. Organizations are tensely forced to\nleverage their core competencies to survive through attracting more customers\nand gaining more efficacious operations. In such a situation, diversified\ncorporations which run multiple businesses have opportunities to get\ncompetitive advantage and differentiate themselves by executing horizontal\nstrategy. Since this strategy completely engages a number of business units of\na diversified corporation through resource sharing among them, any effort to\nimplement it will fail if being not supported by enough information. However,\nfor successful execution of horizontal strategy, managers should have reliable\ninformation concerning its success probability in advance. To provide such a\nprecious information, a three-step framework has been developed. In the first\nstep, major influencers on successful execution of horizontal strategy have\nbeen captured through literature study and interviewing subject matter experts.\nIn the second step through the decision making trial and evaluation laboratory\n(DEMATEL) methodology, critical success factors (CSFs) have been extracted from\nmajor influencers and a success probability assessment index system (SPAIS) has\nbeen formed. In the third step, due to the statistical nature (multivariate and\ndistribution free) of SPAIS, an artificial neural network has been designed for\nenabling organizational managers to forecast the success probability of\nhorizontal strategy execution in a multi-business corporation far better than\nother classical models.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 18:14:26 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Sabzian", "Hossein", ""], ["Gharib", "Hossein", ""], ["Noori", "Javad", ""], ["Shafia", "Mohammad Ali", ""], ["Sheikh", "Mohammad Javad", ""]]}, {"id": "1805.10338", "submitter": "Lierni Sestorain", "authors": "Lierni Sestorain and Massimiliano Ciaramita and Christian Buck and\n  Thomas Hofmann", "title": "Zero-Shot Dual Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) systems rely on large amounts of parallel\ndata. This is a major challenge for low-resource languages. Building on recent\nwork on unsupervised and semi-supervised methods, we present an approach that\ncombines zero-shot and dual learning. The latter relies on reinforcement\nlearning, to exploit the duality of the machine translation task, and requires\nonly monolingual data for the target language pair. Experiments show that a\nzero-shot dual system, trained on English-French and English-Spanish,\noutperforms by large margins a standard NMT system in zero-shot translation\nperformance on Spanish-French (both directions). The zero-shot dual method\napproaches the performance, within 2.2 BLEU points, of a comparable supervised\nsetting. Our method can obtain improvements also on the setting where a small\namount of parallel data for the zero-shot language pair is available. Adding\nRussian, to extend our experiments to jointly modeling 6 zero-shot translation\ndirections, all directions improve between 4 and 15 BLEU points, again,\nreaching performance near that of the supervised setting.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 19:27:43 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Sestorain", "Lierni", ""], ["Ciaramita", "Massimiliano", ""], ["Buck", "Christian", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1805.10365", "submitter": "Luiz Otavio Vilas Boas Oliveira", "authors": "Luiz Otavio Vilas Boas Oliveira, Joao Francisco Barreto da Silva\n  Martins, Luis Fernando Miranda, Gisele Lobo Pappa", "title": "Analysing Symbolic Regression Benchmarks under a Meta-Learning Approach", "comments": "8 pages, 3 Figures, Proceedings of Genetic and Evolutionary\n  Computation Conference Companion, Kyoto, Japan", "journal-ref": null, "doi": "10.1145/3205651.3208293", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The definition of a concise and effective testbed for Genetic Programming\n(GP) is a recurrent matter in the research community. This paper takes a new\nstep in this direction, proposing a different approach to measure the quality\nof the symbolic regression benchmarks quantitatively. The proposed approach is\nbased on meta-learning and uses a set of dataset meta-features---such as the\nnumber of examples or output skewness---to describe the datasets. Our idea is\nto correlate these meta-features with the errors obtained by a GP method. These\nmeta-features define a space of benchmarks that should, ideally, have datasets\n(points) covering different regions of the space. An initial analysis of 63\ndatasets showed that current benchmarks are concentrated in a small region of\nthis benchmark space. We also found out that number of instances and output\nskewness are the most relevant meta-features to GP output error. Both\nconclusions can help define which datasets should compose an effective testbed\nfor symbolic regression methods.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 21:08:30 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Oliveira", "Luiz Otavio Vilas Boas", ""], ["Martins", "Joao Francisco Barreto da Silva", ""], ["Miranda", "Luis Fernando", ""], ["Pappa", "Gisele Lobo", ""]]}, {"id": "1805.10498", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Maurizio Omologo", "title": "Automatic context window composition for distant speech recognition", "comments": "This is a preprint version of the paper published on Speech\n  Communication Journal, 2018. Please see\n  https://www.sciencedirect.com/science/article/pii/S0167639318300128 for the\n  published version of this article", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distant speech recognition is being revolutionized by deep learning, that has\ncontributed to significantly outperform previous HMM-GMM systems. A key aspect\nbehind the rapid rise and success of DNNs is their ability to better manage\nlarge time contexts. With this regard, asymmetric context windows that embed\nmore past than future frames have been recently used with feed-forward neural\nnetworks. This context configuration turns out to be useful not only to address\nlow-latency speech recognition, but also to boost the recognition performance\nunder reverberant conditions. This paper investigates on the mechanisms\noccurring inside DNNs, which lead to an effective application of asymmetric\ncontexts.In particular, we propose a novel method for automatic context window\ncomposition based on a gradient analysis. The experiments, performed with\ndifferent acoustic environments, features, DNN architectures, microphone\nsettings, and recognition tasks show that our simple and efficient strategy\nleads to a less redundant frame configuration, which makes DNN training more\neffective in reverberant scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 15:36:44 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Omologo", "Maurizio", ""]]}, {"id": "1805.10547", "submitter": "Volkan Cirik", "authors": "Volkan Cirik, Taylor Berg-Kirkpatrick, Louis-Philippe Morency", "title": "Using Syntax to Ground Referring Expressions in Natural Images", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce GroundNet, a neural network for referring expression recognition\n-- the task of localizing (or grounding) in an image the object referred to by\na natural language expression. Our approach to this task is the first to rely\non a syntactic analysis of the input referring expression in order to inform\nthe structure of the computation graph. Given a parse tree for an input\nexpression, we explicitly map the syntactic constituents and relationships\npresent in the tree to a composed graph of neural modules that defines our\narchitecture for performing localization. This syntax-based approach aids\nlocalization of \\textit{both} the target object and auxiliary supporting\nobjects mentioned in the expression. As a result, GroundNet is more\ninterpretable than previous methods: we can (1) determine which phrase of the\nreferring expression points to which object in the image and (2) track how the\nlocalization of the target object is determined by the network. We study this\nproperty empirically by introducing a new set of annotations on the GoogleRef\ndataset to evaluate localization of supporting objects. Our experiments show\nthat GroundNet achieves state-of-the-art accuracy in identifying supporting\nobjects, while maintaining comparable performance in the localization of target\nobjects.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 22:02:05 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Cirik", "Volkan", ""], ["Berg-Kirkpatrick", "Taylor", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1805.10606", "submitter": "Aleksey Zakharov", "authors": "Aleksey O. Zakharov and Yulia V. Kovalenko", "title": "Reduction of the Pareto Set in Bicriteria Asymmetric Traveling Salesman\n  Problem", "comments": "Proc. of The 7th International Conference on Optimization Problems\n  and Their Applications (OPTA-2018). CCIS, vol. 871", "journal-ref": null, "doi": "10.1007/978-3-319-93800-4_8", "report-no": null, "categories": "cs.DM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the bicriteria asymmetric traveling salesman problem (bi-ATSP).\nOptimal solution to a multicriteria problem is usually supposed to be the\nPareto set, which is rather wide in real-world problems. We apply to the\nbi-ATSP the axiomatic approach of the Pareto set reduction proposed by V.\nNoghin. We identify series of \"quanta of information\" that guarantee the\nreduction of the Pareto set for particular cases of the bi-ATSP. An\napproximation of the Pareto set to the bi-ATSP is constructed by a new\nmulti-objective genetic algorithm. The experimental evaluation carried out in\nthis paper shows the degree of reduction of the Pareto set approximation for\nvarious \"quanta of information\" and various structures of the bi-ATSP instances\ngenerated randomly.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 11:14:17 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Zakharov", "Aleksey O.", ""], ["Kovalenko", "Yulia V.", ""]]}, {"id": "1805.10636", "submitter": "Federico Errica", "authors": "Davide Bacciu, Federico Errica, Alessio Micheli", "title": "Contextual Graph Markov Model: A Deep and Generative Approach to Graph\n  Processing", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80 (2018) 294-303", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Contextual Graph Markov Model, an approach combining ideas\nfrom generative models and neural networks for the processing of graph data. It\nfounds on a constructive methodology to build a deep architecture comprising\nlayers of probabilistic models that learn to encode the structured information\nin an incremental fashion. Context is diffused in an efficient and scalable way\nacross the graph vertexes and edges. The resulting graph encoding is used in\ncombination with discriminative models to address structure classification\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 15:04:05 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 09:45:51 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bacciu", "Davide", ""], ["Errica", "Federico", ""], ["Micheli", "Alessio", ""]]}, {"id": "1805.10644", "submitter": "Douglas Winston Ribeiro Soares", "authors": "Douglas Winston. R. S., Gustavo T. Laureano, Celso G. Camilo Jr", "title": "Comparison of VCA and GAEE algorithms for Endmember Extraction", "comments": "Accepted by IEEE CEC 2018: IEEE Congress on Evolutionary Computation", "journal-ref": null, "doi": "10.1109/CEC.2018.8477743", "report-no": null, "categories": "cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Endmember Extraction is a critical step in hyperspectral image analysis and\nclassification. It is an useful method to decompose a mixed spectrum into a\ncollection of spectra and their corresponding proportions. In this paper, we\nsolve a linear endmember extraction problem as an evolutionary optimization\ntask, maximizing the Simplex Volume in the endmember space. We propose a\nstandard genetic algorithm and a variation with In Vitro Fertilization module\n(IVFm) to find the best solutions and compare the results with the state-of-art\nVertex Component Analysis (VCA) method and the traditional algorithms Pixel\nPurity Index (PPI) and N-FINDR. The experimental results on real and synthetic\nhyperspectral data confirms the overcome in performance and accuracy of the\nproposed approaches over the mentioned algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 15:53:10 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["S.", "Douglas Winston. R.", ""], ["Laureano", "Gustavo T.", ""], ["Camilo", "Celso G.", "Jr"]]}, {"id": "1805.10692", "submitter": "Simon Wiedemann", "authors": "Simon Wiedemann, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Compact and Computationally Efficient Representation of Deep Neural\n  Networks", "comments": "17 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the core of any inference procedure in deep neural networks are dot\nproduct operations, which are the component that require the highest\ncomputational resources. A common approach to reduce the cost of inference is\nto reduce its memory complexity by lowering the entropy of the weight matrices\nof the neural network, e.g., by pruning and quantizing their elements. However,\nthe quantized weight matrices are then usually represented either by a dense or\nsparse matrix storage format, whose associated dot product complexity is not\nbounded by the entropy of the matrix. This means that the associated inference\ncomplexity ultimately depends on the implicit statistical assumptions that\nthese matrix representations make about the weight distribution, which can be\nin many cases suboptimal. In this paper we address this issue and present new\nefficient representations for matrices with low entropy statistics. These new\nmatrix formats have the novel property that their memory and algorithmic\ncomplexity are implicitly bounded by the entropy of the matrix, consequently\nimplying that they are guaranteed to become more efficient as the entropy of\nthe matrix is being reduced. In our experiments we show that performing the dot\nproduct under these new matrix formats can indeed be more energy and time\nefficient under practically relevant assumptions. For instance, we are able to\nattain up to x42 compression ratios, x5 speed ups and x90 energy savings when\nwe convert in a lossless manner the weight matrices of state-of-the-art\nnetworks such as AlexNet, VGG-16, ResNet152 and DenseNet into the new matrix\nformats and benchmark their respective dot product operation.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 21:30:33 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 17:38:52 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Wiedemann", "Simon", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1805.10795", "submitter": "Elad Tzoreff", "authors": "Elad Tzoreff, Olga Kogan and Yoni Choukroun", "title": "Deep Discriminative Latent Space for Clustering", "comments": "A version of this paper has been submitted to NIPS 2018. The paper\n  contains 9 pages including references, and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most fundamental tasks in data analysis and machine\nlearning. It is central to many data-driven applications that aim to separate\nthe data into groups with similar patterns. Moreover, clustering is a complex\nprocedure that is affected significantly by the choice of the data\nrepresentation method. Recent research has demonstrated encouraging clustering\nresults by learning effectively these representations. In most of these works a\ndeep auto-encoder is initially pre-trained to minimize a reconstruction loss,\nand then jointly optimized with clustering centroids in order to improve the\nclustering objective. Those works focus mainly on the clustering phase of the\nprocedure, while not utilizing the potential benefit out of the initial phase.\nIn this paper we propose to optimize an auto-encoder with respect to a\ndiscriminative pairwise loss function during the auto-encoder pre-training\nphase. We demonstrate the high accuracy obtained by the proposed method as well\nas its rapid convergence (e.g. reaching above 92% accuracy on MNIST during the\npre-training phase, in less than 50 epochs), even with small networks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 07:34:14 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tzoreff", "Elad", ""], ["Kogan", "Olga", ""], ["Choukroun", "Yoni", ""]]}, {"id": "1805.10796", "submitter": "Micha{\\l} Karwatowski", "authors": "Krzysztof Wr\\'obel, Marcin Pietro\\'n, Maciej Wielgosz, Micha{\\l}\n  Karwatowski and Kazimierz Wiatr", "title": "Convolutional neural network compression for natural language processing", "comments": "7 pages, 4 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are modern models that are very efficient in\nmany classification tasks. They were originally created for image processing\npurposes. Then some trials were performed to use them in different domains like\nnatural language processing. The artificial intelligence systems (like humanoid\nrobots) are very often based on embedded systems with constraints on memory,\npower consumption etc. Therefore convolutional neural network because of its\nmemory capacity should be reduced to be mapped to given hardware. In this\npaper, results are presented of compressing the efficient convolutional neural\nnetworks for sentiment analysis. The main steps are quantization and pruning\nprocesses. The method responsible for mapping compressed network to FPGA and\nresults of this implementation are presented. The described simulations showed\nthat 5-bit width is enough to have no drop in accuracy from floating point\nversion of the network. Additionally, significant memory footprint reduction\nwas achieved (from 85% up to 93%).\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 07:40:33 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Wr\u00f3bel", "Krzysztof", ""], ["Pietro\u0144", "Marcin", ""], ["Wielgosz", "Maciej", ""], ["Karwatowski", "Micha\u0142", ""], ["Wiatr", "Kazimierz", ""]]}, {"id": "1805.11014", "submitter": "Michael Lones", "authors": "David W. Corne and Michael A. Lones", "title": "Evolutionary Algorithms", "comments": "To appear in R. Marti, P. Pardalos, and M. Resende, eds., Handbook of\n  Heuristics, Springer", "journal-ref": null, "doi": "10.1007/978-3-319-07153-4_27-1", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) are population-based metaheuristics, originally\ninspired by aspects of natural evolution. Modern varieties incorporate a broad\nmixture of search mechanisms, and tend to blend inspiration from nature with\npragmatic engineering concerns; however, all EAs essentially operate by\nmaintaining a population of potential solutions and in some way artificially\n'evolving' that population over time. Particularly well-known categories of EAs\ninclude genetic algorithms (GAs), Genetic Programming (GP), and Evolution\nStrategies (ES). EAs have proven very successful in practical applications,\nparticularly those requiring solutions to combinatorial problems. EAs are\nhighly flexible and can be configured to address any optimization task, without\nthe requirements for reformulation and/or simplification that would be needed\nfor other techniques. However, this flexibility goes hand in hand with a cost:\nthe tailoring of an EA's configuration and parameters, so as to provide robust\nperformance for a given class of tasks, is often a complex and time-consuming\nprocess. This tailoring process is one of the many ongoing research areas\nassociated with EAs.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:13:08 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Corne", "David W.", ""], ["Lones", "Michael A.", ""]]}, {"id": "1805.11144", "submitter": "Daniel Rasmussen", "authors": "Daniel Rasmussen", "title": "NengoDL: Combining deep learning and neuromorphic modelling methods", "comments": "22 pages, 9 figures; v2 fixes a link in the metadata; v3 minor text\n  updates and updating code snippets to 2.0 syntax", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NengoDL is a software framework designed to combine the strengths of\nneuromorphic modelling and deep learning. NengoDL allows users to construct\nbiologically detailed neural models, intermix those models with deep learning\nelements (such as convolutional networks), and then efficiently simulate those\nmodels in an easy-to-use, unified framework. In addition, NengoDL allows users\nto apply deep learning training methods to optimize the parameters of\nbiological neural models. In this paper we present basic usage examples,\nbenchmarking, and details on the key implementation elements of NengoDL. More\ndetails can be found at https://www.nengo.ai/nengo-dl .\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 19:36:45 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 00:13:05 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 16:25:30 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Rasmussen", "Daniel", ""]]}, {"id": "1805.11201", "submitter": "Najeeb Khan", "authors": "Najeeb Khan", "title": "A parallel implementation of the covariance matrix adaptation evolution\n  strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many practical optimization problems, the derivatives of the functions to\nbe optimized are unavailable or unreliable. Such optimization problems are\nsolved using derivative-free optimization techniques. One of the\nstate-of-the-art techniques for derivative-free optimization is the covariance\nmatrix adaptation evolution strategy (CMA-ES) algorithm. However, the\ncomplexity of CMA-ES algorithm makes it undesirable for tasks where fast\noptimization is needed. To reduce the execution time of CMA-ES, a parallel\nimplementation is proposed, and its performance is analyzed using the benchmark\nproblems in PythOPT optimization environment.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 23:44:44 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Khan", "Najeeb", ""]]}, {"id": "1805.11232", "submitter": "Gon\\c{c}alo Abreu", "authors": "Gon\\c{c}alo Abreu, Rui Neves, Nuno Horta", "title": "Currency exchange prediction using machine learning, genetic algorithms\n  and technical analysis", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technical analysis is used to discover investment opportunities. To test this\nhypothesis we propose an hybrid system using machine learning techniques\ntogether with genetic algorithms. Using technical analysis there are more ways\nto represent a currency exchange time series than the ones it is possible to\ntest computationally, i.e., it is unfeasible to search the whole input feature\nspace thus a genetic algorithm is an alternative. In this work, an architecture\nfor automatic feature selection is proposed to optimize the cross validated\nperformance estimation of a Naive Bayes model using a genetic algorithm. The\nproposed architecture improves the return on investment of the unoptimized\nsystem from 0,43% to 10,29% in the validation set. The features selected and\nthe model decision boundary are visualized using the algorithm t-Distributed\nStochastic Neighbor embedding.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 03:36:34 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Abreu", "Gon\u00e7alo", ""], ["Neves", "Rui", ""], ["Horta", "Nuno", ""]]}, {"id": "1805.11236", "submitter": "Ahmad Jobran Al-Mahasneh", "authors": "Ahmad Jobran Al-Mahasneh, Sreenatha G. Anavatti, Matthew A. Garratt", "title": "Review of Applications of Generalized Regression Neural Networks in\n  Identification and Control of Dynamic Systems", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper depicts a brief revision of Generalized Regression Neural Networks\n(GRNN) applications in system identification and control of dynamic systems. In\naddition, a comparison study between the performance of back-propagation neural\nnetworks and GRNN is presented for system identification problems. The results\nof the comparison confirm that GRNN has shorter training time and higher\naccuracy than the counterpart back-propagation neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 03:54:05 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Al-Mahasneh", "Ahmad Jobran", ""], ["Anavatti", "Sreenatha G.", ""], ["Garratt", "Matthew A.", ""]]}, {"id": "1805.11359", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Properties of interaction networks, structure coefficients, and\n  benefit-to-cost ratios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In structured populations the spatial arrangement of cooperators and\ndefectors on the interaction graph together with the structure of the graph\nitself determines the game dynamics and particularly whether or not fixation of\ncooperation (or defection) is favored. For a single cooperator (and a single\ndefector) and a network described by a regular graph the question of fixation\ncan be addressed by a single parameter, the structure coefficient. As this\nquantity is generic for any regular graph, we may call it the generic structure\ncoefficient. For two and more cooperators (or several defectors) fixation\nproperties can also be assigned by structure coefficients. These structure\ncoefficients, however, depend on the arrangement of cooperators and defectors\nwhich we may interpret as a configuration of the game. Moreover, the\ncoefficients are specific for a given interaction network modeled as regular\ngraph, which is why we may call them specific structure coefficients. In this\npaper, we study how specific structure coefficients vary over interaction\ngraphs and link the distributions obtained over different graphs to spectral\nproperties of interaction networks. We also discuss implications for the\nbenefit-to-cost ratios of donation games.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 11:25:13 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 09:29:55 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "1805.11371", "submitter": "Jos\\'e Halloy", "authors": "Leo Cazenille, Yohann Chemtob, Frank Bonnet, Alexey Gribovskiy,\n  Francesco Mondada, Nicolas Bredeche, Jose Halloy", "title": "How to Blend a Robot within a Group of Zebrafish: Achieving Social\n  Acceptance through Real-time Calibration of a Multi-level Behavioural Model", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": "10.1007/978-3-319-95972-6_9", "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have previously shown how to socially integrate a fish robot into a group\nof zebrafish thanks to biomimetic behavioural models. The models have to be\ncalibrated on experimental data to present correct behavioural features. This\ncalibration is essential to enhance the social integration of the robot into\nthe group. When calibrated, the behavioural model of fish behaviour is\nimplemented to drive a robot with closed-loop control of social interactions\ninto a group of zebrafish. This approach can be useful to form mixed-groups,\nand study animal individual and collective behaviour by using biomimetic\nautonomous robots capable of responding to the animals in long-standing\nexperiments. Here, we show a methodology for continuous real-time calibration\nand refinement of multi-level behavioural model. The real-time calibration, by\nan evolutionary algorithm, is based on simulation of the model to correspond to\nthe observed fish behaviour in real-time. The calibrated model is updated on\nthe robot and tested during the experiments. This method allows to cope with\nchanges of dynamics in fish behaviour. Moreover, each fish presents individual\nbehavioural differences. Thus, each trial is done with naive fish groups that\ndisplay behavioural variability. This real-time calibration methodology can\noptimise the robot behaviours during the experiments. Our implementation of\nthis methodology runs on three different computers that perform individual\ntracking, data-analysis, multi-objective evolutionary algorithms, simulation of\nthe fish robot and adaptation of the robot behavioural models, all in\nreal-time.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 11:59:04 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Cazenille", "Leo", ""], ["Chemtob", "Yohann", ""], ["Bonnet", "Frank", ""], ["Gribovskiy", "Alexey", ""], ["Mondada", "Francesco", ""], ["Bredeche", "Nicolas", ""], ["Halloy", "Jose", ""]]}, {"id": "1805.11535", "submitter": "Yi Tay", "authors": "Yi Tay, Anh Tuan Luu, Siu Cheung Hui", "title": "CoupleNet: Paying Attention to Couples with Coupled Attention for\n  Relationship Recommendation", "comments": "Accepted at ICWSM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dating and romantic relationships not only play a huge role in our personal\nlives but also collectively influence and shape society. Today, many romantic\npartnerships originate from the Internet, signifying the importance of\ntechnology and the web in modern dating. In this paper, we present a text-based\ncomputational approach for estimating the relationship compatibility of two\nusers on social media. Unlike many previous works that propose reciprocal\nrecommender systems for online dating websites, we devise a distant supervision\nheuristic to obtain real world couples from social platforms such as Twitter.\nOur approach, the CoupleNet is an end-to-end deep learning based estimator that\nanalyzes the social profiles of two users and subsequently performs a\nsimilarity match between the users. Intuitively, our approach performs both\nuser profiling and match-making within a unified end-to-end framework.\nCoupleNet utilizes hierarchical recurrent neural models for learning\nrepresentations of user profiles and subsequently coupled attention mechanisms\nto fuse information aggregated from two users. To the best of our knowledge,\nour approach is the first data-driven deep learning approach for our novel\nrelationship recommendation problem. We benchmark our CoupleNet against several\nmachine learning and deep learning baselines. Experimental results show that\nour approach outperforms all approaches significantly in terms of precision.\nQualitative analysis shows that our model is capable of also producing\nexplainable results to users.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:14:41 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Tay", "Yi", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1805.11604", "submitter": "Dimitris Tsipras", "authors": "Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, Aleksander Madry", "title": "How Does Batch Normalization Help Optimization?", "comments": "In NeurIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BatchNorm) is a widely adopted technique that enables\nfaster and more stable training of deep neural networks (DNNs). Despite its\npervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly\nunderstood. The popular belief is that this effectiveness stems from\ncontrolling the change of the layers' input distributions during training to\nreduce the so-called \"internal covariate shift\". In this work, we demonstrate\nthat such distributional stability of layer inputs has little to do with the\nsuccess of BatchNorm. Instead, we uncover a more fundamental impact of\nBatchNorm on the training process: it makes the optimization landscape\nsignificantly smoother. This smoothness induces a more predictive and stable\nbehavior of the gradients, allowing for faster training.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:42:00 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 16:07:57 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 03:07:13 GMT"}, {"version": "v4", "created": "Wed, 6 Mar 2019 15:59:21 GMT"}, {"version": "v5", "created": "Mon, 15 Apr 2019 02:34:55 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Ilyas", "Andrew", ""], ["Madry", "Aleksander", ""]]}, {"id": "1805.11703", "submitter": "Alexander Ororbia", "authors": "Alexander G. Ororbia, Ankur Mali", "title": "Biologically Motivated Algorithms for Propagating Local Target\n  Representations", "comments": "Final version for AAAI (accepted paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding biologically plausible alternatives to back-propagation of errors is\na fundamentally important challenge in artificial neural network research. In\nthis paper, we propose a learning algorithm called error-driven Local\nRepresentation Alignment (LRA-E), which has strong connections to predictive\ncoding, a theory that offers a mechanistic way of describing neurocomputational\nmachinery. In addition, we propose an improved variant of Difference Target\nPropagation, another procedure that comes from the same family of algorithms as\nLRA-E. We compare our procedures to several other biologically-motivated\nalgorithms, including two feedback alignment algorithms and Equilibrium\nPropagation. In two benchmarks, we find that both of our proposed algorithms\nyield stable performance and strong generalization compared to other competing\nback-propagation alternatives when training deeper, highly nonlinear networks,\nwith LRA-E performing the best overall.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 15:11:16 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 18:52:00 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 22:21:04 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Ororbia", "Alexander G.", ""], ["Mali", "Ankur", ""]]}, {"id": "1805.11752", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Alan Salimov, Anish Khazane, Erik T. Mueller", "title": "Multi-turn Dialogue Response Generation in an Adversarial Learning\n  Framework", "comments": "Accepted at ACL 2019 Workshop on NLP for Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose an adversarial learning approach for generating multi-turn\ndialogue responses. Our proposed framework, hredGAN, is based on conditional\ngenerative adversarial networks (GANs). The GAN's generator is a modified\nhierarchical recurrent encoder-decoder network (HRED) and the discriminator is\na word-level bidirectional RNN that shares context and word embeddings with the\ngenerator. During inference, noise samples conditioned on the dialogue history\nare used to perturb the generator's latent space to generate several possible\nresponses. The final response is the one ranked best by the discriminator. The\nhredGAN shows improved performance over existing methods: (1) it generalizes\nbetter than networks trained using only the log-likelihood criterion, and (2)\nit generates longer, more informative and more diverse responses with high\nutterance and topic relevance even with limited training data. This improvement\nis demonstrated on the Movie triples and Ubuntu dialogue datasets using both\nautomatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:05:53 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 20:49:03 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 13:35:08 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 13:26:28 GMT"}, {"version": "v5", "created": "Wed, 26 Jun 2019 14:39:24 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Salimov", "Alan", ""], ["Khazane", "Anish", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1805.11778", "submitter": "Sakyasingha Dasgupta", "authors": "Fernando Camaro Nogues, Andrew Huie, Sakyasingha Dasgupta", "title": "Object Detection using Domain Randomization and Generative Adversarial\n  Refinement of Synthetic Images", "comments": "CVPR 2018 Deep Vision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an application of domain randomization and\ngenerative adversarial networks (GAN) to train a near real-time object detector\nfor industrial electric parts, entirely in a simulated environment. Large scale\navailability of labelled real world data is typically rare and difficult to\nobtain in many industrial settings. As such here, only a few hundred of\nunlabelled real images are used to train a Cyclic-GAN network, in combination\nwith various degree of domain randomization procedures. We demonstrate that\nthis enables robust translation of synthetic images to the real world domain.\nWe show that a combination of the original synthetic (simulation) and GAN\ntranslated images, when used for training a Mask-RCNN object detection network\nachieves greater than 0.95 mean average precision in detecting and classifying\na collection of industrial electric parts. We evaluate the performance across\ndifferent combinations of training data.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 02:27:10 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 09:50:33 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Nogues", "Fernando Camaro", ""], ["Huie", "Andrew", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1805.11797", "submitter": "Xiaoliang Dai", "authors": "Xiaoliang Dai, Hongxu Yin, Niraj K. Jha", "title": "Grow and Prune Compact, Fast, and Accurate LSTMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long short-term memory (LSTM) has been widely used for sequential data\nmodeling. Researchers have increased LSTM depth by stacking LSTM cells to\nimprove performance. This incurs model redundancy, increases run-time delay,\nand makes the LSTMs more prone to overfitting. To address these problems, we\npropose a hidden-layer LSTM (H-LSTM) that adds hidden layers to LSTM's original\none level non-linear control gates. H-LSTM increases accuracy while employing\nfewer external stacked layers, thus reducing the number of parameters and\nrun-time latency significantly. We employ grow-and-prune (GP) training to\niteratively adjust the hidden layers through gradient-based growth and\nmagnitude-based pruning of connections. This learns both the weights and the\ncompact architecture of H-LSTM control gates. We have GP-trained H-LSTMs for\nimage captioning and speech recognition applications. For the NeuralTalk\narchitecture on the MSCOCO dataset, our three models reduce the number of\nparameters by 38.7x [floating-point operations (FLOPs) by 45.5x], run-time\nlatency by 4.5x, and improve the CIDEr score by 2.6. For the DeepSpeech2\narchitecture on the AN4 dataset, our two models reduce the number of parameters\nby 19.4x (FLOPs by 23.5x), run-time latency by 15.7%, and the word error rate\nfrom 12.9% to 8.7%. Thus, GP-trained H-LSTMs can be seen to be compact, fast,\nand accurate.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 04:15:58 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 03:49:25 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Dai", "Xiaoliang", ""], ["Yin", "Hongxu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1805.11818", "submitter": "Volkan Cirik", "authors": "Volkan Cirik, Louis-Philippe Morency, Taylor Berg-Kirkpatrick", "title": "Visual Referring Expression Recognition: What Do Systems Actually Learn?", "comments": "NAACL2018 short", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical analysis of the state-of-the-art systems for\nreferring expression recognition -- the task of identifying the object in an\nimage referred to by a natural language expression -- with the goal of gaining\ninsight into how these systems reason about language and vision. Surprisingly,\nwe find strong evidence that even sophisticated and linguistically-motivated\nmodels for this task may ignore the linguistic structure, instead relying on\nshallow correlations introduced by unintended biases in the data selection and\nannotation process. For example, we show that a system trained and tested on\nthe input image $\\textit{without the input referring expression}$ can achieve a\nprecision of 71.2% in top-2 predictions. Furthermore, a system that predicts\nonly the object category given the input can achieve a precision of 84.2% in\ntop-2 predictions. These surprisingly positive results for what should be\ndeficient prediction scenarios suggest that careful analysis of what our models\nare learning -- and further, how our data is constructed -- is critical as we\nseek to make substantive progress on grounded language tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 06:03:21 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Cirik", "Volkan", ""], ["Morency", "Louis-Philippe", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1805.11987", "submitter": "Wang Hao", "authors": "Hao Wang, Chi-Sing Leung, Hing Cheung So, Ruibin Feng, and Zifa Han", "title": "l0-norm Based Centers Selection for Training Fault Tolerant RBF Networks\n  and Selecting Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to train an RBF neural network and select centers\nunder concurrent faults. It is well known that fault tolerance is a very\nattractive property for neural networks. And center selection is an important\nprocedure during the training process of an RBF neural network. In this paper,\nwe devise two novel algorithms to address these two issues simultaneously. Both\nof them are based on the ADMM framework. In the first method, the minimax\nconcave penalty (MCP) function is introduced to select centers. In the second\nmethod, an l0-norm term is directly used, and the hard threshold (HT) is\nutilized to address the l0-norm term. Under several mild conditions, we can\nprove that both methods can globally converge to a unique limit point.\nSimulation results show that, under concurrent fault, the proposed algorithms\nare superior to many existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 14:01:55 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 09:01:58 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 02:14:50 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Wang", "Hao", ""], ["Leung", "Chi-Sing", ""], ["So", "Hing Cheung", ""], ["Feng", "Ruibin", ""], ["Han", "Zifa", ""]]}, {"id": "1805.12024", "submitter": "Sam Leroux", "authors": "Sam Leroux, Tim Verbelen, Pieter Simoens, Bart Dhoedt", "title": "Privacy Aware Offloading of Deep Neural Networks", "comments": "ICML 2018 Privacy in Machine Learning and Artificial Intelligence\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks require large amounts of resources which makes them hard\nto use on resource constrained devices such as Internet-of-things devices.\nOffloading the computations to the cloud can circumvent these constraints but\nintroduces a privacy risk since the operator of the cloud is not necessarily\ntrustworthy. We propose a technique that obfuscates the data before sending it\nto the remote computation node. The obfuscated data is unintelligible for a\nhuman eavesdropper but can still be classified with a high accuracy by a neural\nnetwork trained on unobfuscated images.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 15:10:20 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Leroux", "Sam", ""], ["Verbelen", "Tim", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1805.12152", "submitter": "Dimitris Tsipras", "authors": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner,\n  Aleksander Madry", "title": "Robustness May Be at Odds with Accuracy", "comments": "ICLR'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that there may exist an inherent tension between the goal of\nadversarial robustness and that of standard generalization. Specifically,\ntraining robust models may not only be more resource-consuming, but also lead\nto a reduction of standard accuracy. We demonstrate that this trade-off between\nthe standard accuracy of a model and its robustness to adversarial\nperturbations provably exists in a fairly simple and natural setting. These\nfindings also corroborate a similar phenomenon observed empirically in more\ncomplex settings. Further, we argue that this phenomenon is a consequence of\nrobust classifiers learning fundamentally different feature representations\nthan standard classifiers. These differences, in particular, seem to result in\nunexpected benefits: the representations learned by robust models tend to align\nbetter with salient data characteristics and human perception.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 18:00:32 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 03:35:11 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 05:09:19 GMT"}, {"version": "v4", "created": "Fri, 30 Aug 2019 22:57:22 GMT"}, {"version": "v5", "created": "Mon, 9 Sep 2019 08:09:25 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Tsipras", "Dimitris", ""], ["Santurkar", "Shibani", ""], ["Engstrom", "Logan", ""], ["Turner", "Alexander", ""], ["Madry", "Aleksander", ""]]}, {"id": "1805.12270", "submitter": "Elaheh Rashedi", "authors": "Elaheh Rashedi, Abdolreza Mirzaei", "title": "Optimized Participation of Multiple Fusion Functions in Consensus\n  Creation: An Evolutionary Approach", "comments": "The 16th CSI International Symposium on Artificial Intelligence and\n  Signal Processing (AISP 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies show that ensemble methods enhance the stability and\nrobustness of unsupervised learning. These approaches are successfully utilized\nto construct multiple clustering and combine them into a one representative\nconsensus clustering of an improved quality. The quality of the consensus\nclustering is directly depended on fusion functions used in combination. In\nthis article, the hierarchical clustering ensemble techniques are extended by\nintroducing a new evolutionary fusion function. In the proposed method,\nmultiple hierarchical clustering methods are generated via bagging. Thereafter,\nthe consensus clustering is obtained using the search capability of genetic\nalgorithm among different aggregated clustering methods made by different\nfusion functions. Putting some popular data sets to empirical study, the\nquality of the proposed method is compared with regular clustering ensembles.\nExperimental results demonstrate the accuracy improvement of the aggregated\nclustering results.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 00:44:37 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Rashedi", "Elaheh", ""], ["Mirzaei", "Abdolreza", ""]]}, {"id": "1805.12352", "submitter": "Xiaodong Gu", "authors": "Xiaodong Gu, Kyunghyun Cho, Jung-Woo Ha, Sunghun Kim", "title": "DialogWAE: Multimodal Response Generation with Conditional Wasserstein\n  Auto-Encoder", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders~(VAEs) have shown a promise in data-driven\nconversation modeling. However, most VAE conversation models match the\napproximate posterior distribution over the latent variables to a simple prior\nsuch as standard normal distribution, thereby restricting the generated\nresponses to a relatively simple (e.g., unimodal) scope. In this paper, we\npropose DialogWAE, a conditional Wasserstein autoencoder~(WAE) specially\ndesigned for dialogue modeling. Unlike VAEs that impose a simple distribution\nover the latent variables, DialogWAE models the distribution of data by\ntraining a GAN within the latent variable space. Specifically, our model\nsamples from the prior and posterior distributions over the latent variables by\ntransforming context-dependent random noise using neural networks and minimizes\nthe Wasserstein distance between the two distributions. We further develop a\nGaussian mixture prior network to enrich the latent space. Experiments on two\npopular datasets show that DialogWAE outperforms the state-of-the-art\napproaches in generating more coherent, informative and diverse responses.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 07:25:04 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 02:32:44 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gu", "Xiaodong", ""], ["Cho", "Kyunghyun", ""], ["Ha", "Jung-Woo", ""], ["Kim", "Sunghun", ""]]}, {"id": "1805.12368", "submitter": "Enzo Marinari", "authors": "Enzo Marinari", "title": "Forgetting Memories and their Attractiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study numerically the memory which forgets, introduced in 1986 by Parisi\nby bounding the synaptic strength, with a mechanism which avoid confusion,\nallows to remember the pattern learned more recently and has a physiologically\nvery well defined meaning. We analyze a number of features of the learning at\nfinite number of neurons and finite number of patterns. We discuss how the\nsystem behaves in the large but finite N limit. We analyze the basin of\nattraction of the patterns that have been learned, and we show that it is\nexponentially small in the age of the pattern. This is a clearly non\nphysiological feature of the model.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 08:02:00 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Marinari", "Enzo", ""]]}, {"id": "1805.12388", "submitter": "Shinichi Shirakawa", "authors": "Shinichi Shirakawa, Youhei Akimoto, Kazuki Ouchi, Kouzou Ohara", "title": "Sample Reuse via Importance Sampling in Information Geometric\n  Optimization", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a technique to reduce the number of function\nevaluations, which is often the bottleneck of the black-box optimization, in\nthe information geometric optimization (IGO) that is a generic framework of the\nprobability model-based black-box optimization algorithms and generalizes\nseveral well-known evolutionary algorithms, such as the population-based\nincremental learning (PBIL) and the pure rank-$\\mu$ update covariance matrix\nadaptation evolution strategy (CMA-ES). In each iteration, the IGO algorithms\nupdate the parameters of the probability distribution to the natural gradient\ndirection estimated by Monte-Carlo with the samples drawn from the current\ndistribution. Our strategy is to reuse previously generated and evaluated\nsamples based on the importance sampling. It is a technique to reduce the\nestimation variance without introducing a bias in Monte-Carlo estimation. We\napply the sample reuse technique to the PBIL and the pure rank-$\\mu$ update\nCMA-ES and empirically investigate its effect. The experimental results show\nthat the sample reuse helps to reduce the number of function evaluations on\nmany benchmark functions for both the PBIL and the pure rank-$\\mu$ update\nCMA-ES. Moreover, we demonstrate how to combine the importance sampling\ntechnique with a variant of the CMA-ES involving an algorithmic component that\nis not derived in the IGO framework.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 09:14:34 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Shirakawa", "Shinichi", ""], ["Akimoto", "Youhei", ""], ["Ouchi", "Kazuki", ""], ["Ohara", "Kouzou", ""]]}]