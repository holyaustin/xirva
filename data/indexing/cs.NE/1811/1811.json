[{"id": "1811.00135", "submitter": "Yijun Xiao", "authors": "Yijun Xiao, Tiancheng Zhao, William Yang Wang", "title": "Dirichlet Variational Autoencoder for Text Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an improved variational autoencoder (VAE) for text modeling with\ntopic information explicitly modeled as a Dirichlet latent variable. By\nproviding the proposed model topic awareness, it is more superior at\nreconstructing input texts. Furthermore, due to the inherent interactions\nbetween the newly introduced Dirichlet variable and the conventional\nmultivariate Gaussian variable, the model is less prone to KL divergence\nvanishing. We derive the variational lower bound for the new model and conduct\nexperiments on four different data sets. The results show that the proposed\nmodel is superior at text reconstruction across the latent space and\nclassifications on learned representations have higher test accuracies.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 22:04:22 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Xiao", "Yijun", ""], ["Zhao", "Tiancheng", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.00147", "submitter": "Haoyu Wang", "authors": "Haoyu Wang, Vivek Kulkarni, William Yang Wang", "title": "DOLORES: Deep Contextualized Knowledge Graph Embeddings", "comments": "10 pages, 6 figures", "journal-ref": "Automated Knowledge Base Construction (AKBC), 2020", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new method DOLORES for learning knowledge graph embeddings\nthat effectively captures contextual cues and dependencies among entities and\nrelations. First, we note that short paths on knowledge graphs comprising of\nchains of entities and relations can encode valuable information regarding\ntheir contextual usage. We operationalize this notion by representing knowledge\ngraphs not as a collection of triples but as a collection of entity-relation\nchains, and learn embeddings for entities and relations using deep neural\nmodels that capture such contextual usage. In particular, our model is based on\nBi-Directional LSTMs and learn deep representations of entities and relations\nfrom constructed entity-relation chains. We show that these representations can\nvery easily be incorporated into existing models to significantly advance the\nstate of the art on several knowledge graph prediction tasks like link\nprediction, triple classification, and missing relation type prediction (in\nsome cases by at least 9.5%).\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 22:59:57 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Wang", "Haoyu", ""], ["Kulkarni", "Vivek", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.00196", "submitter": "Qingyu Yin", "authors": "Hui Liu, Qingyu Yin, William Yang Wang", "title": "Towards Explainable NLP: A Generative Explanation Framework for Text\n  Classification", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building explainable systems is a critical problem in the field of Natural\nLanguage Processing (NLP), since most machine learning models provide no\nexplanations for the predictions. Existing approaches for explainable machine\nlearning systems tend to focus on interpreting the outputs or the connections\nbetween inputs and outputs. However, the fine-grained information is often\nignored, and the systems do not explicitly generate the human-readable\nexplanations. To better alleviate this problem, we propose a novel generative\nexplanation framework that learns to make classification decisions and generate\nfine-grained explanations at the same time. More specifically, we introduce the\nexplainable factor and the minimum risk training approach that learn to\ngenerate more reasonable explanations. We construct two new datasets that\ncontain summaries, rating scores, and fine-grained reasons. We conduct\nexperiments on both datasets, comparing with several strong neural network\nbaseline systems. Experimental results show that our method surpasses all\nbaselines on both datasets, and is able to generate concise explanations at the\nsame time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 02:45:57 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 13:12:58 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Liu", "Hui", ""], ["Yin", "Qingyu", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.00198", "submitter": "Yu Hao", "authors": "Hao Yu, Vivek Kulkarni, William Wang", "title": "MOHONE: Modeling Higher Order Network Effects in KnowledgeGraphs via\n  Network Infused Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many knowledge graph embedding methods operate on triples and are therefore\nimplicitly limited by a very local view of the entire knowledge graph. We\npresent a new framework MOHONE to effectively model higher order network\neffects in knowledge-graphs, thus enabling one to capture varying degrees of\nnetwork connectivity (from the local to the global). Our framework is generic,\nexplicitly models the network scale, and captures two different aspects of\nsimilarity in networks: (a) shared local neighborhood and (b) structural\nrole-based similarity. First, we introduce methods that learn network\nrepresentations of entities in the knowledge graph capturing these varied\naspects of similarity. We then propose a fast, efficient method to incorporate\nthe information captured by these network representations into existing\nknowledge graph embeddings. We show that our method consistently and\nsignificantly improves the performance on link prediction of several different\nknowledge-graph embedding methods including TRANSE, TRANSD, DISTMULT, and\nCOMPLEX(by at least 4 points or 17% in some cases).\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:04:09 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Yu", "Hao", ""], ["Kulkarni", "Vivek", ""], ["Wang", "William", ""]]}, {"id": "1811.00225", "submitter": "Naomi Saphra", "authors": "Naomi Saphra and Adam Lopez", "title": "Understanding Learning Dynamics Of Language Models with SVCCA", "comments": "Accepted for publication in NAACL 2019", "journal-ref": null, "doi": "10.18653/v1/N19-1329", "report-no": null, "categories": "cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research has shown that neural models implicitly encode linguistic features,\nbut there has been no research showing \\emph{how} these encodings arise as the\nmodels are trained. We present the first study on the learning dynamics of\nneural language models, using a simple and flexible analysis method called\nSingular Vector Canonical Correlation Analysis (SVCCA), which enables us to\ncompare learned representations across time and across models, without the need\nto evaluate directly on annotated data. We probe the evolution of syntactic,\nsemantic, and topic representations and find that part-of-speech is learned\nearlier than topic; that recurrent layers become more similar to those of a\ntagger during training; and embedding layers less similar. Our results and\nmethods could inform better learning algorithms for NLP models, possibly to\nincorporate linguistic information more effectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 04:51:20 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 10:15:06 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 14:45:07 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Saphra", "Naomi", ""], ["Lopez", "Adam", ""]]}, {"id": "1811.00321", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, Radu\n  Grosu", "title": "Liquid Time-constant Recurrent Neural Networks as Universal\n  Approximators", "comments": "This short report introduces the universal approximation capabilities\n  of liquid time-constant (LTC) recurrent neural networks, and provides\n  theoretical bounds for its dynamics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the notion of liquid time-constant (LTC)\nrecurrent neural networks (RNN)s, a subclass of continuous-time RNNs, with\nvarying neuronal time-constant realized by their nonlinear synaptic\ntransmission model. This feature is inspired by the communication principles in\nthe nervous system of small species. It enables the model to approximate\ncontinuous mapping with a small number of computational units. We show that any\nfinite trajectory of an $n$-dimensional continuous dynamical system can be\napproximated by the internal state of the hidden units and $n$ output units of\nan LTC network. Here, we also theoretically find bounds on their neuronal\nstates and varying time-constant.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 11:36:56 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Lechner", "Mathias", ""], ["Amini", "Alexander", ""], ["Rus", "Daniela", ""], ["Grosu", "Radu", ""]]}, {"id": "1811.00323", "submitter": "Emna Krichen Tn", "authors": "Emna Krichene, Wael Ouarda, Habib Chabchoub, Adel M. Alimi", "title": "Taylor-based Optimized Recursive Extended Exponential Smoothed Neural\n  Networks Forecasting Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A newly introduced method called Taylor-based Optimized Recursive Extended\nExponential Smoothed Neural Networks Forecasting method is applied and extended\nin this study to forecast numerical values. Unlike traditional forecasting\ntechniques which forecast only future values, our proposed method provides a\nnew extension to correct the predicted values which is done by forecasting the\nestimated error. Experimental results demonstrated that the proposed method has\na high accuracy both in training and testing data and outperform the\nstate-of-the-art RNN models on Mackey-Glass, NARMA, Lorenz and Henon map\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 11:39:49 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Krichene", "Emna", ""], ["Ouarda", "Wael", ""], ["Chabchoub", "Habib", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1811.00482", "submitter": "Xiaofan Xu", "authors": "Xiaofan Xu, Mi Sun Park, Cormac Brick", "title": "Hybrid Pruning: Thinner Sparse Networks for Fast Inference on Edge\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce hybrid pruning which combines both coarse-grained channel and\nfine-grained weight pruning to reduce model size, computation and power demands\nwith no to little loss in accuracy for enabling modern networks deployment on\nresource-constrained devices, such as always-on security cameras and drones.\nAdditionally, to effectively perform channel pruning, we propose a fast\nsensitivity test that helps us quickly identify the sensitivity of within and\nacross layers of a network to the output accuracy for target multiplier\naccumulators (MACs) or accuracy tolerance. Our experiment shows significantly\nbetter results on ResNet50 on ImageNet compared to existing work, even with an\nadditional constraint of channels be hardware-friendly number.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 16:24:50 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Xu", "Xiaofan", ""], ["Park", "Mi Sun", ""], ["Brick", "Cormac", ""]]}, {"id": "1811.00639", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov and Boris Flach", "title": "Stochastic Normalizations as Bayesian Learning", "comments": "Accepted to ACCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we investigate the reasons why Batch Normalization (BN) improves\nthe generalization performance of deep networks. We argue that one major\nreason, distinguishing it from data-independent normalization methods, is\nrandomness of batch statistics. This randomness appears in the parameters\nrather than in activations and admits an interpretation as a practical Bayesian\nlearning. We apply this idea to other (deterministic) normalization techniques\nthat are oblivious to the batch size. We show that their generalization\nperformance can be improved significantly by Bayesian learning of the same\nform. We obtain test performance comparable to BN and, at the same time, better\nvalidation losses suitable for subsequent output uncertainty estimation through\napproximate Bayesian posterior.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 21:30:39 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""]]}, {"id": "1811.00659", "submitter": "Deren Lei", "authors": "Deren Lei, Zichen Sun, Yijun Xiao, William Yang Wang", "title": "Implicit Regularization of Stochastic Gradient Descent in Natural\n  Language Processing: Observations and Implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks with remarkably strong generalization performances are\nusually over-parameterized. Despite explicit regularization strategies are used\nfor practitioners to avoid over-fitting, the impacts are often small. Some\ntheoretical studies have analyzed the implicit regularization effect of\nstochastic gradient descent (SGD) on simple machine learning models with\ncertain assumptions. However, how it behaves practically in state-of-the-art\nmodels and real-world datasets is still unknown. To bridge this gap, we study\nthe role of SGD implicit regularization in deep learning systems. We show pure\nSGD tends to converge to minimas that have better generalization performances\nin multiple natural language processing (NLP) tasks. This phenomenon coexists\nwith dropout, an explicit regularizer. In addition, neural network's finite\nlearning capability does not impact the intrinsic nature of SGD's implicit\nregularization effect. Specifically, under limited training samples or with\ncertain corrupted labels, the implicit regularization effect remains strong. We\nfurther analyze the stability by varying the weight initialization range. We\ncorroborate these experimental findings with a decision boundary visualization\nusing a 3-layer neural network for interpretation. Altogether, our work enables\na deepened understanding on how implicit regularization affects the deep\nlearning model and sheds light on the future study of the over-parameterized\nmodel's generalization ability.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 22:24:25 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Lei", "Deren", ""], ["Sun", "Zichen", ""], ["Xiao", "Yijun", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.00764", "submitter": "Naoki Sakamoto", "authors": "Naoki Sakamoto, Youhei Akimoto", "title": "Adaptive Ranking Based Constraint Handling for Explicitly Constrained\n  Black-Box Optimization", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel explicit constraint handling technique for the covariance matrix\nadaptation evolution strategy (CMA-ES) is proposed. The proposed constraint\nhandling exhibits two invariance properties. One is the invariance to arbitrary\nelement-wise increasing transformation of the objective and constraint\nfunctions. The other is the invariance to arbitrary affine transformation of\nthe search space. The proposed technique virtually transforms a constrained\noptimization problem into an unconstrained optimization problem by considering\nan adaptive weighted sum of the ranking of the objective function values and\nthe ranking of the constraint violations that are measured by the Mahalanobis\ndistance between each candidate solution to its projection onto the boundary of\nthe constraints. Simulation results are presented and show that the CMA-ES with\nthe proposed constraint handling exhibits the affine invariance and performs\nsimilarly to the CMA-ES on unconstrained counterparts.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 07:40:54 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 07:10:15 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Sakamoto", "Naoki", ""], ["Akimoto", "Youhei", ""]]}, {"id": "1811.00784", "submitter": "Jamie Caldwell", "authors": "J. R. Caldwell, R. A. Watson, C. Thies and J. D. Knowles", "title": "Deep Optimisation: Solving Combinatorial Optimisation Problems using\n  Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Optimisation (DO) combines evolutionary search with Deep Neural Networks\n(DNNs) in a novel way - not for optimising a learning algorithm, but for\nfinding a solution to an optimisation problem. Deep learning has been\nsuccessfully applied to classification, regression, decision and generative\ntasks and in this paper we extend its application to solving optimisation\nproblems. Model Building Optimisation Algorithms (MBOAs), a branch of\nevolutionary algorithms, have been successful in combining machine learning\nmethods and evolutionary search but, until now, they have not utilised DNNs. DO\nis the first algorithm to use a DNN to learn and exploit the problem structure\nto adapt the variation operator (changing the neighbourhood structure of the\nsearch process). We demonstrate the performance of DO using two theoretical\noptimisation problems within the MAXSAT class. The Hierarchical Transformation\nOptimisation Problem (HTOP) has controllable deep structure that provides a\nclear evaluation of how DO works and why using a layerwise technique is\nessential for learning and exploiting problem structure. The Parity Modular\nConstraint Problem (MCparity) is a simplistic example of a problem containing\nhigher-order dependencies (greater than pairwise) which DO can solve and state\nof the art MBOAs cannot. Further, we show that DO can exploit deep structure in\nTSP instances. Together these results show that there exists problems that DO\ncan find and exploit deep problem structure that other algorithms cannot.\nMaking this connection between DNNs and optimisation allows for the utilisation\nof advanced tools applicable to DNNs that current MBOAs are unable to use.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 09:04:29 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Caldwell", "J. R.", ""], ["Watson", "R. A.", ""], ["Thies", "C.", ""], ["Knowles", "J. D.", ""]]}, {"id": "1811.00989", "submitter": "David A. Monge", "authors": "David A. Monge (1), Elina Pacini (1, 2), Cristian Mateos (3), Enrique\n  Alba (4), Carlos Garc\\'ia Garino (1) ((1) ITIC, Universidad Nacional de Cuyo.\n  Mendoza, Argentina, (2) Consejo Nacional de Investigaciones Cient\\'ificas y\n  T\\'ecnicas (CONICET). Argentina., (3) ISISTAN-UNICEN-CONICET. Tandil, Buenos\n  Aires, Argentina., (4) Departamento de Lenguajes y Ciencias de la\n  Computaci\\'on, Universidad de M\\'alaga. Spain.)", "title": "CMI: An Online Multi-objective Genetic Autoscaler for Scientific and\n  Engineering Workflows in Cloud Infrastructures with Unreliable Virtual\n  Machines", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing is becoming the leading paradigm for executing scientific and\nengineering workflows. The large-scale nature of the experiments they model and\ntheir variable workloads make clouds the ideal execution environment due to\nprompt and elastic access to huge amounts of computing resources. Autoscalers\nare middleware-level software components that allow scaling up and down the\ncomputing platform by acquiring or terminating virtual machines (VM) at the\ntime that workflow's tasks are being scheduled. In this work we propose a novel\nonline multi-objective autoscaler for workflows denominated Cloud\nMulti-objective Intelligence (CMI), that aims at the minimization of makespan,\nmonetary cost and the potential impact of errors derived from unreliable VMs.\nIn addition, this problem is subject to monetary budget constraints. CMI is\nresponsible for periodically solving the autoscaling problems encountered along\nthe execution of a workflow. Simulation experiments on four well-known\nworkflows exhibit that CMI significantly outperforms a state-of-the-art\nautoscaler of similar characteristics called Spot Instances Aware Autoscaling\n(SIAA). These results convey a solid base for deepening in the study of other\nmeta-heuristic methods for autoscaling workflow applications using cheap but\nunreliable infrastructures.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 17:11:57 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Monge", "David A.", ""], ["Pacini", "Elina", ""], ["Mateos", "Cristian", ""], ["Alba", "Enrique", ""], ["Garino", "Carlos Garc\u00eda", ""]]}, {"id": "1811.00998", "submitter": "James O' Neill", "authors": "James O' Neill, Danushka Bollegala", "title": "Analysing Dropout and Compounding Errors in Neural Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper carries out an empirical analysis of various dropout techniques\nfor language modelling, such as Bernoulli dropout, Gaussian dropout, Curriculum\nDropout, Variational Dropout and Concrete Dropout. Moreover, we propose an\nextension of variational dropout to concrete dropout and curriculum dropout\nwith varying schedules. We find these extensions to perform well when compared\nto standard dropout approaches, particularly variational curriculum dropout\nwith a linear schedule. Largest performance increases are made when applying\ndropout on the decoder layer. Lastly, we analyze where most of the errors occur\nat test time as a post-analysis step to determine if the well-known problem of\ncompounding errors is apparent and to what end do the proposed methods mitigate\nthis issue for each dataset. We report results on a 2-hidden layer LSTM, GRU\nand Highway network with embedding dropout, dropout on the gated hidden layers\nand the output projection layer for each model. We report our results on\nPenn-TreeBank and WikiText-2 word-level language modelling datasets, where the\nformer reduces the long-tail distribution through preprocessing and one which\npreserves rare words in the training and test set.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 17:31:53 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1811.01312", "submitter": "Rahul Aralikatte", "authors": "Shreya Khare, Rahul Aralikatte, Senthil Mani", "title": "Adversarial Black-Box Attacks on Automatic Speech Recognition Systems\n  using Multi-Objective Evolutionary Optimization", "comments": "Published in Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fooling deep neural networks with adversarial input have exposed a\nsignificant vulnerability in the current state-of-the-art systems in multiple\ndomains. Both black-box and white-box approaches have been used to either\nreplicate the model itself or to craft examples which cause the model to fail.\nIn this work, we propose a framework which uses multi-objective evolutionary\noptimization to perform both targeted and un-targeted black-box attacks on\nAutomatic Speech Recognition (ASR) systems. We apply this framework on two ASR\nsystems: Deepspeech and Kaldi-ASR, which increases the Word Error Rates (WER)\nof these systems by upto 980%, indicating the potency of our approach. During\nboth un-targeted and targeted attacks, the adversarial samples maintain a high\nacoustic similarity of 0.98 and 0.97 with the original audio.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 02:05:16 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 09:49:56 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Khare", "Shreya", ""], ["Aralikatte", "Rahul", ""], ["Mani", "Senthil", ""]]}, {"id": "1811.01323", "submitter": "Xi Lin", "authors": "Xi Lin, Hui-Ling Zhen, Zhenhua Li, Qingfu Zhang, Sam Kwong", "title": "A Batched Scalable Multi-Objective Bayesian Optimization Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The surrogate-assisted optimization algorithm is a promising approach for\nsolving expensive multi-objective optimization problems. However, most existing\nsurrogate-assisted multi-objective optimization algorithms have three main\ndrawbacks: 1) cannot scale well for solving problems with high dimensional\ndecision space, 2) cannot incorporate available gradient information, and 3) do\nnot support batch optimization. These drawbacks prevent their use for solving\nmany real-world large scale optimization problems. This paper proposes a\nbatched scalable multi-objective Bayesian optimization algorithm to tackle\nthese issues. The proposed algorithm uses the Bayesian neural network as the\nscalable surrogate model. Powered with Monte Carlo dropout and Sobolov\ntraining, the model can be easily trained and can incorporate available\ngradient information. We also propose a novel batch hypervolume upper\nconfidence bound acquisition function to support batch optimization.\nExperimental results on various benchmark problems and a real-world application\ndemonstrate the efficiency of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 05:00:47 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Lin", "Xi", ""], ["Zhen", "Hui-Ling", ""], ["Li", "Zhenhua", ""], ["Zhang", "Qingfu", ""], ["Kwong", "Sam", ""]]}, {"id": "1811.01476", "submitter": "Alexander Wong", "authors": "Mohammad Saeed Shafiee, Mohammad Javad Shafiee, and Alexander Wong", "title": "Dynamic Representations Toward Efficient Inference on Deep Neural\n  Networks by Decision Gates", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks extract rich features from the input data, the\ncurrent trade-off between depth and computational cost makes it difficult to\nadopt deep neural networks for many industrial applications, especially when\ncomputing power is limited. Here, we are inspired by the idea that, while\ndeeper embeddings are needed to discriminate difficult samples (i.e.,\nfine-grained discrimination), a large number of samples can be well\ndiscriminated via much shallower embeddings (i.e., coarse-grained\ndiscrimination). In this study, we introduce the simple yet effective concept\nof decision gates (d-gate), modules trained to decide whether a sample needs to\nbe projected into a deeper embedding or if an early prediction can be made at\nthe d-gate, thus enabling the computation of dynamic representations at\ndifferent depths. The proposed d-gate modules can be integrated with any deep\nneural network and reduces the average computational cost of the deep neural\nnetworks while maintaining modeling accuracy. The proposed d-gate framework is\nexamined via different network architectures and datasets, with experimental\nresults showing that leveraging the proposed d-gate modules led to a ~43%\nspeed-up and 44% FLOPs reduction on ResNet-101 and 55% speed-up and 39% FLOPs\nreduction on DenseNet-201 trained on the CIFAR10 dataset with only ~2% drop in\naccuracy. Furthermore, experiments where d-gate modules are integrated into\nResNet-101 trained on the ImageNet dataset demonstrate that it is possible to\nreduce the computational cost of the network by 1.5 GFLOPs without any drop in\nthe modeling accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 01:37:39 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 02:55:19 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 02:47:56 GMT"}, {"version": "v4", "created": "Sat, 11 May 2019 16:35:49 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Shafiee", "Mohammad Saeed", ""], ["Shafiee", "Mohammad Javad", ""], ["Wong", "Alexander", ""]]}, {"id": "1811.01567", "submitter": "Naiyan Wang", "authors": "Xinbang Zhang, Zehao Huang, Naiyan Wang", "title": "You Only Search Once: Single Shot Neural Architecture Search via Direct\n  Sparse Optimization", "comments": "ICLR2019 Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Neural Architecture Search (NAS) has aroused great interest in both\nacademia and industry, however it remains challenging because of its huge and\nnon-continuous search space. Instead of applying evolutionary algorithm or\nreinforcement learning as previous works, this paper proposes a Direct Sparse\nOptimization NAS (DSO-NAS) method. In DSO-NAS, we provide a novel model pruning\nview to NAS problem. In specific, we start from a completely connected block,\nand then introduce scaling factors to scale the information flow between\noperations. Next, we impose sparse regularizations to prune useless connections\nin the architecture. Lastly, we derive an efficient and theoretically sound\noptimization method to solve it. Our method enjoys both advantages of\ndifferentiability and efficiency, therefore can be directly applied to large\ndatasets like ImageNet. Particularly, On CIFAR-10 dataset, DSO-NAS achieves an\naverage test error 2.84\\%, while on the ImageNet dataset DSO-NAS achieves\n25.4\\% test error under 600M FLOPs with 8 GPUs in 18 hours.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 09:28:13 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Zhang", "Xinbang", ""], ["Huang", "Zehao", ""], ["Wang", "Naiyan", ""]]}, {"id": "1811.01757", "submitter": "Nikolaos Passalis", "authors": "Angeliki Papadimitriou, Nikolaos Passalis and Anastasios Tefas", "title": "Decoding Generic Visual Representations From Human Brain Activity using\n  Machine Learning", "comments": "Accepted at 1st Workshop on Brain-Driven Computer Vision - ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the most impressive recent applications of neural decoding is the\nvisual representation decoding, where the category of an object that a subject\neither sees or imagines is inferred by observing his/her brain activity. Even\nthough there is an increasing interest in the aforementioned visual\nrepresentation decoding task, there is no extensive study of the effect of\nusing different machine learning models on the decoding accuracy. In this paper\nwe provide an extensive evaluation of several machine learning models, along\nwith different similarity metrics, for the aforementioned task, drawing many\ninteresting conclusions. That way, this paper a) paves the way for developing\nmore advanced and accurate methods and b) provides an extensive and easily\nreproducible baseline for the aforementioned decoding task.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:48:15 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Papadimitriou", "Angeliki", ""], ["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""]]}, {"id": "1811.01768", "submitter": "Isabella Pozzi", "authors": "Isabella Pozzi, Sander Boht\\'e and Pieter Roelfsema", "title": "A Biologically Plausible Learning Rule for Deep Learning in the Brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have proposed that deep learning, which is providing important\nprogress in a wide range of high complexity tasks, might inspire new insights\ninto learning in the brain. However, the methods used for deep learning by\nartificial neural networks are biologically unrealistic and would need to be\nreplaced by biologically realistic counterparts. Previous biologically\nplausible reinforcement learning rules, like AGREL and AuGMEnT, showed\npromising results but focused on shallow networks with three layers. Will these\nlearning rules also generalize to networks with more layers and can they handle\ntasks of higher complexity? We demonstrate the learning scheme on classical and\nhard image-classification benchmarks, namely MNIST, CIFAR10 and CIFAR100, cast\nas direct reward tasks, both for fully connected, convolutional and locally\nconnected architectures. We show that our learning rule - Q-AGREL - performs\ncomparably to supervised learning via error-backpropagation, with this type of\ntrial-and-error reinforcement learning requiring only 1.5-2.5 times more\nepochs, even when classifying 100 different classes as in CIFAR100. Our results\nprovide new insights into how deep learning may be implemented in the brain.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 15:01:59 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 07:37:39 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 09:45:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Pozzi", "Isabella", ""], ["Boht\u00e9", "Sander", ""], ["Roelfsema", "Pieter", ""]]}, {"id": "1811.01845", "submitter": "Siddhartha Dhar Choudhury", "authors": "Siddhartha Dhar Choudhury, Shashank Pandey, Kunal Mehrotra", "title": "Deep Genetic Network", "comments": "The paper has some major flaws and needs to be re written, it will\n  take time so cannot be replaced soon enough", "journal-ref": null, "doi": "10.35940/ijeat.A1128.109119", "report-no": "A1128109119", "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optimizing a neural network's performance is a tedious and time taking\nprocess, this iterative process does not have any defined solution which can\nwork for all the problems. Optimization can be roughly categorized into -\nArchitecture and Hyperparameter optimization. Many algorithms have been devised\nto address this problem. In this paper we introduce a neural network\narchitecture (Deep Genetic Network) which will optimize its parameters during\ntraining based on its fitness. Deep Genetic Net uses genetic algorithms along\nwith deep neural networks to address the hyperparameter optimization problem,\nthis approach uses ideas like mating and mutation which are key to genetic\nalgorithms which help the neural net architecture to learn to optimize its\nhyperparameters by itself rather than depending on a person to explicitly set\nthe values. Using genetic algorithms for this problem proved to work\nexceptionally well when given enough time to train the network. The proposed\narchitecture is found to work well in optimizing hyperparameters in affine,\nconvolutional and recurrent layers proving to be a good choice for conventional\nsupervised learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 17:04:02 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 17:02:45 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Choudhury", "Siddhartha Dhar", ""], ["Pandey", "Shashank", ""], ["Mehrotra", "Kunal", ""]]}, {"id": "1811.01907", "submitter": "Tianyun Zhang", "authors": "Shaokai Ye, Tianyun Zhang, Kaiqi Zhang, Jiayu Li, Jiaming Xie, Yun\n  Liang, Sijia Liu, Xue Lin and Yanzhi Wang", "title": "A Unified Framework of DNN Weight Pruning and Weight\n  Clustering/Quantization Using ADMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many model compression techniques of Deep Neural Networks (DNNs) have been\ninvestigated, including weight pruning, weight clustering and quantization,\netc. Weight pruning leverages the redundancy in the number of weights in DNNs,\nwhile weight clustering/quantization leverages the redundancy in the number of\nbit representations of weights. They can be effectively combined in order to\nexploit the maximum degree of redundancy. However, there lacks a systematic\ninvestigation in literature towards this direction.\n  In this paper, we fill this void and develop a unified, systematic framework\nof DNN weight pruning and clustering/quantization using Alternating Direction\nMethod of Multipliers (ADMM), a powerful technique in optimization theory to\ndeal with non-convex optimization problems. Both DNN weight pruning and\nclustering/quantization, as well as their combinations, can be solved in a\nunified manner. For further performance improvement in this framework, we adopt\nmultiple techniques including iterative weight quantization and retraining,\njoint weight clustering training and centroid updating, weight clustering\nretraining, etc. The proposed framework achieves significant improvements both\nin individual weight pruning and clustering/quantization problems, as well as\ntheir combinations. For weight pruning alone, we achieve 167x weight reduction\nin LeNet-5, 24.7x in AlexNet, and 23.4x in VGGNet, without any accuracy loss.\nFor the combination of DNN weight pruning and clustering/quantization, we\nachieve 1,910x and 210x storage reduction of weight data on LeNet-5 and\nAlexNet, respectively, without accuracy loss. Our codes and models are released\nat the link http://bit.ly/2D3F0np\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:34:17 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Ye", "Shaokai", ""], ["Zhang", "Tianyun", ""], ["Zhang", "Kaiqi", ""], ["Li", "Jiayu", ""], ["Xie", "Jiaming", ""], ["Liang", "Yun", ""], ["Liu", "Sijia", ""], ["Lin", "Xue", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1811.01910", "submitter": "Nikolai Rozanov", "authors": "Edward Collins, Nikolai Rozanov, Bingbing Zhang", "title": "Evolutionary Data Measures: Understanding the Difficulty of Text\n  Classification Tasks", "comments": "27 pages, 6 tables, 3 figures (submitted for publication in June\n  2018), CoNLL 2018", "journal-ref": "ACL, CoNLL(K18-1037), 22, 380--391, (2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification tasks are usually analysed and improved through new model\narchitectures or hyperparameter optimisation but the underlying properties of\ndatasets are discovered on an ad-hoc basis as errors occur. However,\nunderstanding the properties of the data is crucial in perfecting models. In\nthis paper we analyse exactly which characteristics of a dataset best determine\nhow difficult that dataset is for the task of text classification. We then\npropose an intuitive measure of difficulty for text classification datasets\nwhich is simple and fast to calculate. We show that this measure generalises to\nunseen data by comparing it to state-of-the-art datasets and results. This\nmeasure can be used to analyse the precise source of errors in a dataset and\nallows fast estimation of how difficult a dataset is to learn. We searched for\nthis measure by training 12 classical and neural network based models on 78\nreal-world datasets, then use a genetic algorithm to discover the best measure\nof difficulty. Our difficulty-calculating code ( https://github.com/Wluper/edm\n) and datasets ( http://data.wluper.com ) are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:39:54 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 10:07:20 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Collins", "Edward", ""], ["Rozanov", "Nikolai", ""], ["Zhang", "Bingbing", ""]]}, {"id": "1811.01945", "submitter": "Saptarshi Sengupta", "authors": "Saptarshi Sengupta, Sanchita Basak, Richard Alan Peters II", "title": "Chaotic Quantum Double Delta Swarm Algorithm using Chebyshev Maps:\n  Theoretical Foundations, Performance Analyses and Convergence Issues", "comments": "27 pages, 4 figures, 19 tables", "journal-ref": "J. Sens. Actuator Netw. 2019, 8(1), 9", "doi": "10.3390/jsan8010009", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Double Delta Swarm (QDDS) Algorithm is a new metaheuristic algorithm\ninspired by the convergence mechanism to the center of potential generated\nwithin a single well of a spatially co-located double-delta well setup. It\nmimics the wave nature of candidate positions in solution spaces and draws upon\nquantum mechanical interpretations much like other quantum-inspired\ncomputational intelligence paradigms. In this work, we introduce a Chebyshev\nmap driven chaotic perturbation in the optimization phase of the algorithm to\ndiversify weights placed on contemporary and historical, socially-optimal\nagents' solutions. We follow this up with a characterization of solution\nquality on a suite of 23 single-objective functions and carry out a comparative\nanalysis with eight other related nature-inspired approaches. By comparing\nsolution quality and successful runs over dynamic solution ranges, insights\nabout the nature of convergence are obtained. A two-tailed t-test establishes\nthe statistical significance of the solution data whereas Cohen's d and Hedge's\ng values provide a measure of effect sizes. We trace the trajectory of the\nfittest pseudo-agent over all function evaluations to comment on the dynamics\nof the system and prove that the proposed algorithm is theoretically globally\nconvergent under the assumptions adopted for proofs of other closely-related\nrandom search algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 17:28:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 04:46:14 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Sengupta", "Saptarshi", ""], ["Basak", "Sanchita", ""], ["Peters", "Richard Alan", "II"]]}, {"id": "1811.02010", "submitter": "Oindrila Chatterjee", "authors": "Oindrila Chatterjee, Shantanu Chakrabartty", "title": "A Unified Perspective of Evolutionary Game Dynamics Using Generalized\n  Growth Transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.GT math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that different types of evolutionary game dynamics\nare, in principle, special cases of a dynamical system model based on our\npreviously reported framework of generalized growth transforms. The framework\nshows that different dynamics arise as a result of minimizing a population\nenergy such that the population as a whole evolves to reach the most stable\nstate. By introducing a population dependent time-constant in the generalized\ngrowth transform model, the proposed framework can be used to explain a vast\nrepertoire of evolutionary dynamics, including some novel forms of game\ndynamics with non-linear payoffs.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 19:57:53 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Chatterjee", "Oindrila", ""], ["Chakrabartty", "Shantanu", ""]]}, {"id": "1811.02113", "submitter": "German I. Parisi", "authors": "German I. Parisi, Xu Ji, Stefan Wermter", "title": "On the role of neurogenesis in overcoming catastrophic forgetting", "comments": "Accepted to NIPS'18 Workshop on Continual Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning capabilities are crucial for artificial autonomous agents\noperating on real-world data, which is typically non-stationary and temporally\ncorrelated. In this work, we demonstrate that dynamically grown networks\noutperform static networks in incremental learning scenarios, even when bounded\nby the same amount of memory in both cases. Learning is unsupervised in our\nmodels, a condition that additionally makes training more challenging whilst\nincreasing the realism of the study, since humans are able to learn without\ndense manual annotation. Our results on artificial neural networks reinforce\nthat structural plasticity constitutes effective prevention against\ncatastrophic forgetting in non-stationary environments, as well as empirically\nsupporting the importance of neurogenesis in the mammalian brain.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 01:38:26 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 04:41:56 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Parisi", "German I.", ""], ["Ji", "Xu", ""], ["Wermter", "Stefan", ""]]}, {"id": "1811.02187", "submitter": "Yulhwa Kim", "authors": "Yulhwa Kim, Hyungjun Kim, Jae-Joon Kim", "title": "Neural Network-Hardware Co-design for Scalable RRAM-based BNN\n  Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, RRAM-based Binary Neural Network (BNN) hardware has been gaining\ninterests as it requires 1-bit sense-amp only and eliminates the need for\nhigh-resolution ADC and DAC. However, RRAM-based BNN hardware still requires\nhigh-resolution ADC for partial sum calculation to implement large-scale neural\nnetwork using multiple memory arrays. We propose a neural network-hardware\nco-design approach to split input to fit each split network on a RRAM array so\nthat the reconstructed BNNs calculate 1-bit output neuron in each array. As a\nresult, ADC can be completely eliminated from the design even for large-scale\nneural network. Simulation results show that the proposed network\nreconstruction and retraining recovers the inference accuracy of the original\nBNN. The accuracy loss of the proposed scheme in the CIFAR-10 testcase was less\nthan 1.1% compared to the original network. The code for training and running\nproposed BNN models is available at:\nhttps://github.com/YulhwaKim/RRAMScalable_BNN.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 06:47:00 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 00:35:30 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Kim", "Yulhwa", ""], ["Kim", "Hyungjun", ""], ["Kim", "Jae-Joon", ""]]}, {"id": "1811.02234", "submitter": "Maxime Bucher", "authors": "Maxime Bucher (Palaiseau), St\\'ephane Herbin (Palaiseau), Fr\\'ed\\'eric\n  Jurie", "title": "Semantic bottleneck for computer vision tasks", "comments": null, "journal-ref": "Asian Conference on Computer Vision (ACCV), Dec 2018, Perth,\n  Australia", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel method for the representation of images that is\nsemantic by nature, addressing the question of computation intelligibility in\ncomputer vision tasks. More specifically, our proposition is to introduce what\nwe call a semantic bottleneck in the processing pipeline, which is a crossing\npoint in which the representation of the image is entirely expressed with\nnatural language , while retaining the efficiency of numerical representations.\nWe show that our approach is able to generate semantic representations that\ngive state-of-the-art results on semantic content-based image retrieval and\nalso perform very well on image classification tasks. Intelligibility is\nevaluated through user centered experiments for failure detection.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 09:01:02 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Bucher", "Maxime", "", "Palaiseau"], ["Herbin", "St\u00e9phane", "", "Palaiseau"], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1811.02271", "submitter": "Sadek Bouroubi", "authors": "Kantour Nedjmeddine, Bouroubi Sadek and Chaabane Djamel", "title": "A Parallel MOEA with Criterion-based Selection Applied to the Knapsack\n  Problem", "comments": "24 pages, 08 figures, 05 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a parallel multiobjective evolutionary algorithm\ncalled Parallel Criterion-based Partitioning MOEA (PCPMOEA), with an\napplication to the Mutliobjective Knapsack Problem (MOKP). The suggested search\nstrategy is based on a periodic partitioning of potentially efficient\nsolutions, which are distributed to multiple multiobjective evolutionary\nalgorithms (MOEAs). Each MOEA is dedicated to a sole objective, in which it\ncombines both criterion-based and dominance-based approaches. The suggested\nalgorithm addresses two main sub-objectives: minimizing the distance between\nthe current non-dominated solutions and the ideal point, and ensuring the\nspread of the potentially efficient solutions. Experimental results are\nincluded, where we assess the performance of the suggested algorithm against\nthe above mentioned sub-objectives, compared with state-of-the-art results\nusing well-known multi-objective metaheuristics.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 10:27:30 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Nedjmeddine", "Kantour", ""], ["Sadek", "Bouroubi", ""], ["Djamel", "Chaabane", ""]]}, {"id": "1811.02309", "submitter": "Ali Reihanian", "authors": "Ali Reihanian, Mohammad-Reza Feizi-Derakhshi, Hadi S. Aghdasi", "title": "An Enhanced Multi-Objective Biogeography-Based Optimization Algorithm\n  for Automatic Detection of Overlapping Communities in a Social Network with\n  Node Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection is one of the most important and interesting issues in\nsocial network analysis. In recent years, simultaneous considering of nodes'\nattributes and topological structures of social networks in the process of\ncommunity detection has attracted the attentions of many scholars, and this\nconsideration has been recently used in some community detection methods to\nincrease their efficiencies and to enhance their performances in finding\nmeaningful and relevant communities. But the problem is that most of these\nmethods tend to find non-overlapping communities, while many real-world\nnetworks include communities that often overlap to some extent. In order to\nsolve this problem, an evolutionary algorithm called MOBBO-OCD, which is based\non multi-objective biogeography-based optimization (BBO), is proposed in this\npaper to automatically find overlapping communities in a social network with\nnode attributes with synchronously considering the density of connections and\nthe similarity of nodes' attributes in the network. In MOBBO-OCD, an extended\nlocus-based adjacency representation called OLAR is introduced to encode and\ndecode overlapping communities. Based on OLAR, a rank-based migration operator\nalong with a novel two-phase mutation strategy and a new double-point crossover\nare used in the evolution process of MOBBO-OCD to effectively lead the\npopulation into the evolution path. In order to assess the performance of\nMOBBO-OCD, a new metric called alpha_SAEM is proposed in this paper, which is\nable to evaluate the goodness of both overlapping and non-overlapping\npartitions with considering the two aspects of node attributes and linkage\nstructure. Quantitative evaluations reveal that MOBBO-OCD achieves favorable\nresults which are quite superior to the results of 15 relevant community\ndetection algorithms in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 12:09:36 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Reihanian", "Ali", ""], ["Feizi-Derakhshi", "Mohammad-Reza", ""], ["Aghdasi", "Hadi S.", ""]]}, {"id": "1811.02553", "submitter": "Andrew Ilyas", "authors": "Andrew Ilyas, Logan Engstrom, Shibani Santurkar, Dimitris Tsipras,\n  Firdaus Janoos, Larry Rudolph, Aleksander Madry", "title": "A Closer Look at Deep Policy Gradients", "comments": "ICLR 2020 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how the behavior of deep policy gradient algorithms reflects the\nconceptual framework motivating their development. To this end, we propose a\nfine-grained analysis of state-of-the-art methods based on key elements of this\nframework: gradient estimation, value prediction, and optimization landscapes.\nOur results show that the behavior of deep policy gradient algorithms often\ndeviates from what their motivating framework would predict: the surrogate\nobjective does not match the true reward landscape, learned value estimators\nfail to fit the true value function, and gradient estimates poorly correlate\nwith the \"true\" gradient. The mismatch between predicted and empirical behavior\nwe uncover highlights our poor understanding of current methods, and indicates\nthe need to move beyond current benchmark-centric evaluation methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:54:21 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 18:54:30 GMT"}, {"version": "v3", "created": "Sun, 2 Dec 2018 02:45:35 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 16:24:26 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Ilyas", "Andrew", ""], ["Engstrom", "Logan", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Janoos", "Firdaus", ""], ["Rudolph", "Larry", ""], ["Madry", "Aleksander", ""]]}, {"id": "1811.02657", "submitter": "Tan Nguyen", "authors": "Tan Nguyen, Nhat Ho, Ankit Patel, Anima Anandkumar, Michael I. Jordan,\n  Richard G. Baraniuk", "title": "A Bayesian Perspective of Convolutional Neural Networks through a\n  Deconvolutional Generative Model", "comments": "Keywords: neural nets, generative models, semi-supervised learning,\n  cross-entropy, statistical guarantees 80 pages, 7 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the success of Convolutional Neural Networks (CNNs) for\nsupervised prediction in images, we design the Deconvolutional Generative Model\n(DGM), a new probabilistic generative model whose inference calculations\ncorrespond to those in a given CNN architecture. The DGM uses a CNN to design\nthe prior distribution in the probabilistic model. Furthermore, the DGM\ngenerates images from coarse to finer scales. It introduces a small set of\nlatent variables at each scale, and enforces dependencies among all the latent\nvariables via a conjugate prior distribution. This conjugate prior yields a new\nregularizer based on paths rendered in the generative model for training\nCNNs-the Rendering Path Normalization (RPN). We demonstrate that this\nregularizer improves generalization, both in theory and in practice. In\naddition, likelihood estimation in the DGM yields training losses for CNNs, and\ninspired by this, we design a new loss termed as the Max-Min cross entropy\nwhich outperforms the traditional cross-entropy loss for object classification.\nThe Max-Min cross entropy suggests a new deep network architecture, namely the\nMax-Min network, which can learn from less labeled data while maintaining good\nprediction performance. Our experiments demonstrate that the DGM with the RPN\nand the Max-Min architecture exceeds or matches the-state-of-art on benchmarks\nincluding SVHN, CIFAR10, and CIFAR100 for semi-supervised and supervised\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 01:27:37 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 10:21:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Nguyen", "Tan", ""], ["Ho", "Nhat", ""], ["Patel", "Ankit", ""], ["Anandkumar", "Anima", ""], ["Jordan", "Michael I.", ""], ["Baraniuk", "Richard G.", ""]]}, {"id": "1811.03242", "submitter": "Faisal Mohammad", "authors": "Faisal Mohammad, Ki Boem Lee, Young-Chon Kim", "title": "Short Term Load Forecasting Using Deep Neural Networks", "comments": "6 pages, 8 figures, International Symposium on Information Technology\n  Convergence 2018, South Korea", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electricity load forecasting plays an important role in the energy planning\nsuch as generation and distribution. However, the nonlinearity and dynamic\nuncertainties in the smart grid environment are the main obstacles in\nforecasting accuracy. Deep Neural Network (DNN) is a set of intelligent\ncomputational algorithms that provide a comprehensive solution for modelling a\ncomplicated nonlinear relationship between the input and output through\nmultiple hidden layers. In this paper, we propose DNN based electricity load\nforecasting system to manage the energy consumption in an efficient manner. We\ninvestigate the applicability of two deep neural network architectures\nFeed-forward Deep Neural Network (Deep-FNN) and Recurrent Deep Neural Network\n(Deep-RNN) to the New York Independent System Operator (NYISO) electricity load\nforecasting task. We test our algorithm with various activation functions such\nas Sigmoid, Hyperbolic Tangent (tanh) and Rectifier Linear Unit (ReLU). The\nperformance measurement of two network architectures is compared in terms of\nMean Absolute Percentage Error (MAPE) metric.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 03:09:39 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Mohammad", "Faisal", ""], ["Lee", "Ki Boem", ""], ["Kim", "Young-Chon", ""]]}, {"id": "1811.03305", "submitter": "Mahesh Subedar", "authors": "Ranganath Krishnan, Mahesh Subedar, Omesh Tickoo", "title": "BAR: Bayesian Activity Recognition using variational inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty estimation in deep neural networks is essential for designing\nreliable and robust AI systems. Applications such as video surveillance for\nidentifying suspicious activities are designed with deep neural networks\n(DNNs), but DNNs do not provide uncertainty estimates. Capturing reliable\nuncertainty estimates in safety and security critical applications will help to\nestablish trust in the AI system. Our contribution is to apply Bayesian deep\nlearning framework to visual activity recognition application and quantify\nmodel uncertainty along with principled confidence. We utilize the stochastic\nvariational inference technique while training the Bayesian DNNs to infer the\napproximate posterior distribution around model parameters and perform Monte\nCarlo sampling on the posterior of model parameters to obtain the predictive\ndistribution. We show that the Bayesian inference applied to DNNs provide\nreliable confidence measures for visual activity recognition task as compared\nto conventional DNNs. We also show that our method improves the visual activity\nrecognition precision-recall AUC by 6.2% compared to non-Bayesian baseline. We\nevaluate our models on Moments-In-Time (MiT) activity recognition dataset by\nselecting a subset of in- and out-of-distribution video samples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 08:04:09 GMT"}, {"version": "v2", "created": "Sat, 1 Dec 2018 08:08:34 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Krishnan", "Ranganath", ""], ["Subedar", "Mahesh", ""], ["Tickoo", "Omesh", ""]]}, {"id": "1811.03403", "submitter": "Jarryd Son", "authors": "Jarryd Son, Amit Mishra", "title": "ExGate: Externally Controlled Gating for Feature-based Attention in\n  Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptual capabilities of artificial systems have come a long way since the\nadvent of deep learning. These methods have proven to be effective, however\nthey are not as efficient as their biological counterparts. Visual attention is\na set of mechanisms that are employed in biological visual systems to ease\ncomputational load by only processing pertinent parts of the stimuli. This\npaper addresses the implementation of top-down, feature-based attention in an\nartificial neural network by use of externally controlled neuron gating. Our\nresults showed a 5% increase in classification accuracy on the CIFAR-10 dataset\nversus a non-gated version, while adding very few parameters. Our gated model\nalso produces more reasonable errors in predictions by drastically reducing\nprediction of classes that belong to a different category to the true class.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 13:39:49 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Son", "Jarryd", ""], ["Mishra", "Amit", ""]]}, {"id": "1811.03493", "submitter": "Gopal P. Sarma", "authors": "Gopal P. Sarma, Adam Safron, and Nick J. Hay", "title": "Integrative Biological Simulation, Neuropsychology, and AI Safety", "comments": "5 pages", "journal-ref": "Proceedings of the AAAI Workshop on Artificial Intelligence Safety\n  2019 co-located with the Thirty-Third AAAI Conference on Artificial\n  Intelligence 2019 (AAAI 2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a biologically-inspired research agenda with parallel tracks\naimed at AI and AI safety. The bottom-up component consists of building a\nsequence of biophysically realistic simulations of simple organisms such as the\nnematode $Caenorhabditis$ $elegans$, the fruit fly $Drosophila$ $melanogaster$,\nand the zebrafish $Danio$ $rerio$ to serve as platforms for research into AI\nalgorithms and system architectures. The top-down component consists of an\napproach to value alignment that grounds AI goal structures in neuropsychology,\nbroadly considered. Our belief is that parallel pursuit of these tracks will\ninform the development of value-aligned AI systems that have been inspired by\nembodied organisms with sensorimotor integration. An important set of side\nbenefits is that the research trajectories we describe here are grounded in\nlong-standing intellectual traditions within existing research communities and\nfunding structures. In addition, these research programs overlap with\nsignificant contemporary themes in the biological and psychological sciences\nsuch as data/model integration and reproducibility.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 01:38:24 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 19:04:47 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sarma", "Gopal P.", ""], ["Safron", "Adam", ""], ["Hay", "Nick J.", ""]]}, {"id": "1811.03539", "submitter": "Marcos Oliveira", "authors": "Marcos Oliveira, Diego Pinheiro, Mariana Macedo, Carmelo Bastos-Filho,\n  Ronaldo Menezes", "title": "Uncovering the Social Interaction in Swarm Intelligence with Network\n  Science", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.MA cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm intelligence is the collective behavior emerging in systems with\nlocally interacting components. Because of their self-organization\ncapabilities, swarm-based systems show essential properties for handling\nreal-world problems such as robustness, scalability, and flexibility. Yet, we\ndo not know why swarm-based algorithms work well and neither we can compare the\ndifferent approaches in the literature. The lack of a common framework capable\nof characterizing these several swarm-based algorithms, transcending their\nparticularities, has led to a stream of publications inspired by different\naspects of nature without a systematic comparison over existing approaches.\nHere, we address this gap by introducing a network-based framework---the\ninteraction network---to examine computational swarm-based systems via the\noptics of the social dynamics of such interaction network; a clear example of\nnetwork science being applied to bring further clarity to a complicated field\nwithin artificial intelligence. We discuss the social interactions of four\nwell-known swarm-based algorithms and provide an in-depth case study of the\nParticle Swarm Optimization. The interaction network enables researchers to\nstudy swarm algorithms as systems, removing the algorithm particularities from\nthe analyses while focusing on the structure of the social interactions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:36:11 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 10:27:16 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Oliveira", "Marcos", ""], ["Pinheiro", "Diego", ""], ["Macedo", "Mariana", ""], ["Bastos-Filho", "Carmelo", ""], ["Menezes", "Ronaldo", ""]]}, {"id": "1811.03567", "submitter": "Honglin Chen", "authors": "Will Xiao, Honglin Chen, Qianli Liao and Tomaso Poggio", "title": "Biologically-plausible learning algorithms can scale to large datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation (BP) algorithm is often thought to be biologically\nimplausible in the brain. One of the main reasons is that BP requires symmetric\nweight matrices in the feedforward and feedback pathways. To address this\n\"weight transport problem\" (Grossberg, 1987), two more biologically plausible\nalgorithms, proposed by Liao et al. (2016) and Lillicrap et al. (2016), relax\nBP's weight symmetry requirements and demonstrate comparable learning\ncapabilities to that of BP on small datasets. However, a recent study by\nBartunov et al. (2018) evaluate variants of target-propagation (TP) and\nfeedback alignment (FA) on MINIST, CIFAR, and ImageNet datasets, and find that\nalthough many of the proposed algorithms perform well on MNIST and CIFAR, they\nperform significantly worse than BP on ImageNet. Here, we additionally evaluate\nthe sign-symmetry algorithm (Liao et al., 2016), which differs from both BP and\nFA in that the feedback and feedforward weights share signs but not magnitudes.\nWe examine the performance of sign-symmetry and feedback alignment on ImageNet\nand MS COCO datasets using different network architectures (ResNet-18 and\nAlexNet for ImageNet, RetinaNet for MS COCO). Surprisingly, networks trained\nwith sign-symmetry can attain classification performance approaching that of\nBP-trained networks. These results complement the study by Bartunov et al.\n(2018), and establish a new benchmark for future biologically plausible\nlearning algorithms on more difficult datasets and more complex architectures.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:43:59 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 21:23:57 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 02:03:52 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Xiao", "Will", ""], ["Chen", "Honglin", ""], ["Liao", "Qianli", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1811.03618", "submitter": "Timo Wunderlich", "authors": "Timo Wunderlich, Akos F. Kungl, Eric M\\\"uller, Andreas Hartel, Yannik\n  Stradmann, Syed Ahmed Aamir, Andreas Gr\\\"ubl, Arthur Heimbrecht, Korbinian\n  Schreiber, David St\\\"ockel, Christian Pehle, Sebastian Billaudelle, Gerd\n  Kiene, Christian Mauch, Johannes Schemmel, Karlheinz Meier, Mihai A.\n  Petrovici", "title": "Demonstrating Advantages of Neuromorphic Computation: A Pilot Study", "comments": "Added measurements with noise in NEST simulation, add notice about\n  journal publication. Frontiers in Neuromorphic Engineering (2019)", "journal-ref": null, "doi": "10.3389/fnins.2019.00260", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic devices represent an attempt to mimic aspects of the brain's\narchitecture and dynamics with the aim of replicating its hallmark functional\ncapabilities in terms of computational power, robust learning and energy\nefficiency. We employ a single-chip prototype of the BrainScaleS 2 neuromorphic\nsystem to implement a proof-of-concept demonstration of reward-modulated\nspike-timing-dependent plasticity in a spiking network that learns to play the\nPong video game by smooth pursuit. This system combines an electronic\nmixed-signal substrate for emulating neuron and synapse dynamics with an\nembedded digital processor for on-chip learning, which in this work also serves\nto simulate the virtual environment and learning agent. The analog emulation of\nneuronal membrane dynamics enables a 1000-fold acceleration with respect to\nbiological real-time, with the entire chip operating on a power budget of 57mW.\nCompared to an equivalent simulation using state-of-the-art software, the\non-chip emulation is at least one order of magnitude faster and three orders of\nmagnitude more energy-efficient. We demonstrate how on-chip learning can\nmitigate the effects of fixed-pattern noise, which is unavoidable in analog\nsubstrates, while making use of temporal variability for action exploration.\nLearning compensates imperfections of the physical substrate, as manifested in\nneuronal parameter variability, by adapting synaptic weights to match\nrespective excitability of individual neurons.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 18:59:52 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 11:33:38 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 09:32:06 GMT"}, {"version": "v4", "created": "Fri, 8 Mar 2019 13:01:22 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Wunderlich", "Timo", ""], ["Kungl", "Akos F.", ""], ["M\u00fcller", "Eric", ""], ["Hartel", "Andreas", ""], ["Stradmann", "Yannik", ""], ["Aamir", "Syed Ahmed", ""], ["Gr\u00fcbl", "Andreas", ""], ["Heimbrecht", "Arthur", ""], ["Schreiber", "Korbinian", ""], ["St\u00f6ckel", "David", ""], ["Pehle", "Christian", ""], ["Billaudelle", "Sebastian", ""], ["Kiene", "Gerd", ""], ["Mauch", "Christian", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "1811.03760", "submitter": "Youru Li", "authors": "Youru Li, Zhenfeng Zhu, Deqiang Kong, Hua Han, Yao Zhao", "title": "EA-LSTM: Evolutionary Attention-based LSTM for Time Series Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series prediction with deep learning methods, especially long short-term\nmemory neural networks (LSTMs), have scored significant achievements in recent\nyears. Despite the fact that the LSTMs can help to capture long-term\ndependencies, its ability to pay different degree of attention on sub-window\nfeature within multiple time-steps is insufficient. To address this issue, an\nevolutionary attention-based LSTM training with competitive random search is\nproposed for multivariate time series prediction. By transferring shared\nparameters, an evolutionary attention learning approach is introduced to the\nLSTMs model. Thus, like that for biological evolution, the pattern for\nimportance-based attention sampling can be confirmed during temporal\nrelationship mining. To refrain from being trapped into partial optimization\nlike traditional gradient-based methods, an evolutionary computation inspired\ncompetitive random search method is proposed, which can well configure the\nparameters in the attention layer. Experimental results have illustrated that\nthe proposed model can achieve competetive prediction performance compared with\nother baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 03:42:36 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Li", "Youru", ""], ["Zhu", "Zhenfeng", ""], ["Kong", "Deqiang", ""], ["Han", "Hua", ""], ["Zhao", "Yao", ""]]}, {"id": "1811.03962", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Yuanzhi Li, Zhao Song", "title": "A Convergence Theory for Deep Learning via Over-Parameterization", "comments": "V2 adds citation and V3/V4/V5 polish writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated dominating performance in many\nfields; since AlexNet, networks used in practice are going wider and deeper. On\nthe theoretical side, a long line of works has been focusing on training neural\nnetworks with one hidden layer. The theory of multi-layer networks remains\nlargely unsettled.\n  In this work, we prove why stochastic gradient descent (SGD) can find\n$\\textit{global minima}$ on the training objective of DNNs in\n$\\textit{polynomial time}$. We only make two assumptions: the inputs are\nnon-degenerate and the network is over-parameterized. The latter means the\nnetwork width is sufficiently large: $\\textit{polynomial}$ in $L$, the number\nof layers and in $n$, the number of samples.\n  Our key technique is to derive that, in a sufficiently large neighborhood of\nthe random initialization, the optimization landscape is almost-convex and\nsemi-smooth even with ReLU activations. This implies an equivalence between\nover-parameterized neural networks and neural tangent kernel (NTK) in the\nfinite (and polynomial) width setting.\n  As concrete examples, starting from randomly initialized weights, we prove\nthat SGD can attain 100% training accuracy in classification tasks, or minimize\nregression loss in linear convergence speed, with running time polynomial in\n$n,L$. Our theory applies to the widely-used but non-smooth ReLU activation,\nand to any smooth and possibly non-convex loss functions. In terms of network\narchitectures, our theory at least applies to fully-connected neural networks,\nconvolutional neural networks (CNN), and residual neural networks (ResNet).\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 15:16:13 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2018 18:54:20 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 11:44:07 GMT"}, {"version": "v4", "created": "Mon, 4 Feb 2019 03:57:59 GMT"}, {"version": "v5", "created": "Mon, 17 Jun 2019 06:39:04 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""], ["Song", "Zhao", ""]]}, {"id": "1811.03980", "submitter": "Alberto Marchisio", "authors": "Alberto Marchisio, Muhammad Abdullah Hanif, Semeen Rehman, Maurizio\n  Martina, and Muhammad Shafique", "title": "A Methodology for Automatic Selection of Activation Functions to Design\n  Hybrid Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions influence behavior and performance of DNNs. Nonlinear\nactivation functions, like Rectified Linear Units (ReLU), Exponential Linear\nUnits (ELU) and Scaled Exponential Linear Units (SELU), outperform the linear\ncounterparts. However, selecting an appropriate activation function is a\nchallenging problem, as it affects the accuracy and the complexity of the given\nDNN. In this paper, we propose a novel methodology to automatically select the\nbest-possible activation function for each layer of a given DNN, such that the\noverall DNN accuracy, compared to considering only one type of activation\nfunction for the whole DNN, is improved. However, an associated scientific\nchallenge in exploring all the different configurations of activation functions\nwould be time and resource-consuming. Towards this, our methodology identifies\nthe Evaluation Points during learning to evaluate the accuracy in an\nintermediate step of training and to perform early termination by checking the\naccuracy gradient of the learning curve. This helps in significantly reducing\nthe exploration time during training. Moreover, our methodology selects, for\neach layer, the dropout rate that optimizes the accuracy. Experiments show that\nwe are able to achieve on average 7% to 15% Relative Error Reduction on MNIST,\nCIFAR-10 and CIFAR-100 benchmarks, with limited performance and power penalty\non GPUs.\n", "versions": [{"version": "v1", "created": "Sat, 27 Oct 2018 14:30:58 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Marchisio", "Alberto", ""], ["Hanif", "Muhammad Abdullah", ""], ["Rehman", "Semeen", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "1811.04000", "submitter": "Alexey Ozerov", "authors": "Sanjeel Parekh, Alexey Ozerov, Slim Essid (LTCI), Ngoc Duong, Patrick\n  P\\'erez, Ga\\\"el Richard (LTCI)", "title": "Identify, locate and separate: Audio-visual object extraction in large\n  video collections using weak supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of audiovisual scene analysis for weakly-labeled data.\nTo this end, we build upon our previous audiovisual representation learning\nframework to perform object classification in noisy acoustic environments and\nintegrate audio source enhancement capability. This is made possible by a novel\nuse of non-negative matrix factorization for the audio modality. Our approach\nis founded on the multiple instance learning paradigm. Its effectiveness is\nestablished through experiments over a challenging dataset of music instrument\nperformance videos. We also show encouraging visual object localization\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 16:19:41 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Parekh", "Sanjeel", "", "LTCI"], ["Ozerov", "Alexey", "", "LTCI"], ["Essid", "Slim", "", "LTCI"], ["Duong", "Ngoc", "", "LTCI"], ["P\u00e9rez", "Patrick", "", "LTCI"], ["Richard", "Ga\u00ebl", "", "LTCI"]]}, {"id": "1811.04073", "submitter": "Larry Bull", "authors": "Larry Bull", "title": "The Evolution of Gene Dominance through the Baldwin Effect", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.03471", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been suggested that the fundamental haploid-diploid cycle of\neukaryotic sex exploits a rudimentary form of the Baldwin effect. Thereafter\nthe other associated phenomena can be explained as evolution tuning the amount\nand frequency of learning experienced by an organism. Using the well-known NK\nmodel of fitness landscapes it is here shown that the emergence of dominance\ncan also be explained under this view of eukaryotic evolution.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:08:26 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Bull", "Larry", ""]]}, {"id": "1811.04122", "submitter": "Helge Spieker", "authors": "Helge Spieker, Arnaud Gotlieb, Dusica Marijan, Morten Mossige", "title": "Reinforcement Learning for Automatic Test Case Prioritization and\n  Selection in Continuous Integration", "comments": "Spieker, H., Gotlieb, A., Marijan, D., & Mossige, M. (2017).\n  Reinforcement Learning for Automatic Test Case Prioritization and Selection\n  in Continuous Integration. In Proceedings of 26th International Symposium on\n  Software Testing and Analysis (ISSTA'17) (pp. 12--22). ACM", "journal-ref": null, "doi": "10.1145/3092703.3092709", "report-no": null, "categories": "cs.SE cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing in Continuous Integration (CI) involves test case prioritization,\nselection, and execution at each cycle. Selecting the most promising test cases\nto detect bugs is hard if there are uncertainties on the impact of committed\ncode changes or, if traceability links between code and tests are not\navailable. This paper introduces Retecs, a new method for automatically\nlearning test case selection and prioritization in CI with the goal to minimize\nthe round-trip time between code commits and developer feedback on failed test\ncases. The Retecs method uses reinforcement learning to select and prioritize\ntest cases according to their duration, previous last execution and failure\nhistory. In a constantly changing environment, where new test cases are created\nand obsolete test cases are deleted, the Retecs method learns to prioritize\nerror-prone test cases higher under guidance of a reward function and by\nobserving previous CI cycles. By applying Retecs on data extracted from three\nindustrial case studies, we show for the first time that reinforcement learning\nenables fruitful automatic adaptive test case selection and prioritization in\nCI and regression testing.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 20:08:58 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Spieker", "Helge", ""], ["Gotlieb", "Arnaud", ""], ["Marijan", "Dusica", ""], ["Mossige", "Morten", ""]]}, {"id": "1811.04210", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui, Jian Su", "title": "Densely Connected Attention Propagation for Reading Comprehension", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DecaProp (Densely Connected Attention Propagation), a new densely\nconnected neural architecture for reading comprehension (RC). There are two\ndistinct characteristics of our model. Firstly, our model densely connects all\npairwise layers of the network, modeling relationships between passage and\nquery across all hierarchical levels. Secondly, the dense connectors in our\nnetwork are learned via attention instead of standard residual skip-connectors.\nTo this end, we propose novel Bidirectional Attention Connectors (BAC) for\nefficiently forging connections throughout the network. We conduct extensive\nexperiments on four challenging RC benchmarks. Our proposed approach achieves\nstate-of-the-art results on all four, outperforming existing baselines by up to\n$2.6\\%-14.2\\%$ in absolute F1 score.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 07:54:13 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 11:19:54 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""], ["Su", "Jian", ""]]}, {"id": "1811.04233", "submitter": "Zonghua Gu", "authors": "Ming Zhang, Nenggan Zheng, De Ma, Gang Pan, Zonghua Gu", "title": "Efficient Spiking Neural Networks with Logarithmic Temporal Coding", "comments": null, "journal-ref": "IEEE Access 8 (2020): 98156-98167", "doi": "10.1109/ACCESS.2020.2994360", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Spiking Neural Network (SNN) can be trained indirectly by first training an\nArtificial Neural Network (ANN) with the conventional backpropagation\nalgorithm, then converting it into an SNN. The conventional rate-coding method\nfor SNNs uses the number of spikes to encode magnitude of an activation value,\nand may be computationally inefficient due to the large number of spikes.\nTemporal-coding is typically more efficient by leveraging the timing of spikes\nto encode information. In this paper, we present Logarithmic Temporal Coding\n(LTC), where the number of spikes used to encode an activation value grows\nlogarithmically with the activation value; and the accompanying\nExponentiate-and-Fire (EF) spiking neuron model, which only involves efficient\nbit-shift and addition operations. Moreover, we improve the training process of\nANN to compensate for approximation errors due to LTC. Experimental results\nindicate that the resulting SNN achieves competitive performance at\nsignificantly lower computational cost than related work.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 11:14:06 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Ming", ""], ["Zheng", "Nenggan", ""], ["Ma", "De", ""], ["Pan", "Gang", ""], ["Gu", "Zonghua", ""]]}, {"id": "1811.04303", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski and Alexander Wong", "title": "PolyNeuron: Automatic Neuron Discovery via Learned Polyharmonic Spline\n  Activations", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated deep neural network architecture design has received a significant\namount of recent attention. However, this attention has not been equally shared\nby one of the fundamental building blocks of a deep neural network, the\nneurons. In this study, we propose PolyNeuron, a novel automatic neuron\ndiscovery approach based on learned polyharmonic spline activations. More\nspecifically, PolyNeuron revolves around learning polyharmonic splines,\ncharacterized by a set of control points, that represent the activation\nfunctions of the neurons in a deep neural network. A relaxed variant of\nPolyNeuron, which we term PolyNeuron-R, loosens the constraints imposed by\nPolyNeuron to reduce the computational complexity for discovering the neuron\nactivation functions in an automated manner. Experiments show both PolyNeuron\nand PolyNeuron-R lead to networks that have improved or comparable performance\non multiple network architectures (LeNet-5 and ResNet-20) using different\ndatasets (MNIST and CIFAR10). As such, automatic neuron discovery approaches\nsuch as PolyNeuron is a worthy direction to explore.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 20:14:26 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wong", "Alexander", ""]]}, {"id": "1811.04465", "submitter": "Andrei Lissovoi", "authors": "Andrei Lissovoi, Pietro S. Oliveto", "title": "Computational Complexity Analysis of Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic programming (GP) is an evolutionary computation technique to solve\nproblems in an automated, domain-independent way. Rather than identifying the\noptimum of a function as in more traditional evolutionary optimization, the aim\nof GP is to evolve computer programs with a given functionality. While many GP\napplications have produced human competitive results, the theoretical\nunderstanding of what problem characteristics and algorithm properties allow GP\nto be effective is comparatively limited. Compared with traditional\nevolutionary algorithms for function optimization, GP applications are further\ncomplicated by two additional factors: the variable-length representation of\ncandidate programs, and the difficulty of evaluating their quality efficiently.\nSuch difficulties considerably impact the runtime analysis of GP, where space\ncomplexity also comes into play. As a result, initial complexity analyses of GP\nhave focused on restricted settings such as the evolution of trees with given\nstructures or the estimation of solution quality using only a small polynomial\nnumber of input/output examples. However, the first computational complexity\nanalyses of GP for evolving proper functions with defined input/output behavior\nhave recently appeared. In this chapter, we present an overview of the state of\nthe art.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 19:54:28 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 13:35:41 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Lissovoi", "Andrei", ""], ["Oliveto", "Pietro S.", ""]]}, {"id": "1811.04624", "submitter": "V\\'ictor Campos", "authors": "V\\'ictor Campos, Xavier Giro-i-Nieto, Jordi Torres", "title": "Importance Weighted Evolution Strategies", "comments": "NIPS Deep Reinforcement Learning Workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution Strategies (ES) emerged as a scalable alternative to popular\nReinforcement Learning (RL) techniques, providing an almost perfect speedup\nwhen distributed across hundreds of CPU cores thanks to a reduced communication\noverhead. Despite providing large improvements in wall-clock time, ES is data\ninefficient when compared to competing RL methods. One of the main causes of\nsuch inefficiency is the collection of large batches of experience, which are\ndiscarded after each policy update. In this work, we study how to perform more\nthan one update per batch of experience by means of Importance Sampling while\npreserving the scalability of the original method. The proposed method,\nImportance Weighted Evolution Strategies (IW-ES), shows promising results and\nis a first step towards designing efficient ES algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 09:44:50 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Campos", "V\u00edctor", ""], ["Giro-i-Nieto", "Xavier", ""], ["Torres", "Jordi", ""]]}, {"id": "1811.04784", "submitter": "Tim Verbelen", "authors": "Xander Steenbrugge, Sam Leroux, Tim Verbelen, Bart Dhoedt", "title": "Improving Generalization for Abstract Reasoning Tasks Using Disentangled\n  Feature Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the generalization characteristics of unsupervised\nrepresentation learning by leveraging disentangled VAE's to learn a useful\nlatent space on a set of relational reasoning problems derived from Raven\nProgressive Matrices. We show that the latent representations, learned by\nunsupervised training using the right objective function, significantly\noutperform the same architectures trained with purely supervised learning,\nespecially when it comes to generalization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 15:23:26 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Steenbrugge", "Xander", ""], ["Leroux", "Sam", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1811.04918", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li and Yingyu Liang", "title": "Learning and Generalization in Overparameterized Neural Networks, Going\n  Beyond Two Layers", "comments": "V1/V2/V3/V4 polish writing, V5 adds experiments, V6 reflects our\n  camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental learning theory behind neural networks remains largely open.\nWhat classes of functions can neural networks actually learn? Why doesn't the\ntrained network overfit when it is overparameterized?\n  In this work, we prove that overparameterized neural networks can learn some\nnotable concept classes, including two and three-layer networks with fewer\nparameters and smooth activations. Moreover, the learning can be simply done by\nSGD (stochastic gradient descent) or its variants in polynomial time using\npolynomially many samples. The sample complexity can also be almost independent\nof the number of parameters in the network.\n  On the technique side, our analysis goes beyond the so-called NTK (neural\ntangent kernel) linearization of neural networks in prior works. We establish a\nnew notion of quadratic approximation of the neural network (that can be viewed\nas a second-order variant of NTK), and connect it to the SGD theory of escaping\nsaddle points.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 18:57:02 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 15:56:01 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 04:10:51 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 17:09:46 GMT"}, {"version": "v5", "created": "Tue, 28 May 2019 10:25:09 GMT"}, {"version": "v6", "created": "Mon, 1 Jun 2020 17:11:51 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""], ["Liang", "Yingyu", ""]]}, {"id": "1811.05290", "submitter": "Larry Bull", "authors": "Larry Bull and Neil Phillips", "title": "Towards the Design of Aerostat Wind Turbine Arrays through AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new form of aerostat wind generation system which contains an array of\ninteracting turbines is proposed. The design of the balloon turbine components\nis undertaken through the combination of artificial intelligence and rapid\nprototyping techniques such that the need for highly accurate\nmodels/simulations of the lift and wake dynamics is removed/reduced. Initial\nsmall-scale wind tunnel testing to determine design and algorithmic\nfundamentals will be presented.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 13:55:18 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Bull", "Larry", ""], ["Phillips", "Neil", ""]]}, {"id": "1811.05537", "submitter": "Tong Qin", "authors": "Tong Qin, Kailiang Wu, Dongbin Xiu", "title": "Data Driven Governing Equations Approximation Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.06.042", "report-no": null, "categories": "math.NA cs.LG cs.NE math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a numerical framework for approximating unknown governing\nequations using observation data and deep neural networks (DNN). In particular,\nwe propose to use residual network (ResNet) as the basic building block for\nequation approximation. We demonstrate that the ResNet block can be considered\nas a one-step method that is exact in temporal integration. We then present two\nmulti-step methods, recurrent ResNet (RT-ResNet) method and recursive ReNet\n(RS-ResNet) method. The RT-ResNet is a multi-step method on uniform time steps,\nwhereas the RS-ResNet is an adaptive multi-step method using variable time\nsteps. All three methods presented here are based on integral form of the\nunderlying dynamical system. As a result, they do not require time derivative\ndata for equation recovery and can cope with relatively coarsely distributed\ntrajectory data. Several numerical examples are presented to demonstrate the\nperformance of the methods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 21:47:27 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Qin", "Tong", ""], ["Wu", "Kailiang", ""], ["Xiu", "Dongbin", ""]]}, {"id": "1811.05592", "submitter": "C. H. Huck Yang", "authors": "Rise Ooi, Chao-Han Huck Yang, Pin-Yu Chen, V\\`ictor Egu\\`iluz, Narsis\n  Kiani, Hector Zenil, David Gomez-Cabrero, Jesper Tegn\\`er", "title": "Controllability, Multiplexing, and Transfer Learning in Networks using\n  Evolutionary Learning", "comments": "A revised version. (word source code to pdf; owing to the algo\n  package conflicts)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Networks are fundamental building blocks for representing data, and\ncomputations. Remarkable progress in learning in structurally defined (shallow\nor deep) networks has recently been achieved. Here we introduce evolutionary\nexploratory search and learning method of topologically flexible networks under\nthe constraint of producing elementary computational steady-state input-output\noperations.\n  Our results include; (1) the identification of networks, over four orders of\nmagnitude, implementing computation of steady-state input-output functions,\nsuch as a band-pass filter, a threshold function, and an inverse band-pass\nfunction. Next, (2) the learned networks are technically controllable as only a\nsmall number of driver nodes are required to move the system to a new state.\nFurthermore, we find that the fraction of required driver nodes is constant\nduring evolutionary learning, suggesting a stable system design. (3), our\nframework allows multiplexing of different computations using the same network.\nFor example, using a binary representation of the inputs, the network can\nreadily compute three different input-output functions. Finally, (4) the\nproposed evolutionary learning demonstrates transfer learning. If the system\nlearns one function A, then learning B requires on average less number of steps\nas compared to learning B from tabula rasa.\n  We conclude that the constrained evolutionary learning produces large robust\ncontrollable circuits, capable of multiplexing and transfer learning. Our study\nsuggests that network-based computations of steady-state functions,\nrepresenting either cellular modules of cell-to-cell communication networks or\ninternal molecular circuits communicating within a cell, could be a powerful\nmodel for biologically inspired computing. This complements conceptualizations\nsuch as attractor based models, or reservoir computing.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 01:36:52 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 02:51:52 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Ooi", "Rise", ""], ["Yang", "Chao-Han Huck", ""], ["Chen", "Pin-Yu", ""], ["Egu\u00ecluz", "V\u00ecctor", ""], ["Kiani", "Narsis", ""], ["Zenil", "Hector", ""], ["Gomez-Cabrero", "David", ""], ["Tegn\u00e8r", "Jesper", ""]]}, {"id": "1811.05817", "submitter": "Alexander Wong", "authors": "Xiaodan Hu, Audrey G. Chung, Paul Fieguth, Farzad Khalvati, Masoom A.\n  Haider, and Alexander Wong", "title": "ProstateGAN: Mitigating Data Bias via Prostate Diffusion Imaging\n  Synthesis with Generative Adversarial Networks", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have shown considerable promise for\nmitigating the challenge of data scarcity when building machine learning-driven\nanalysis algorithms. Specifically, a number of studies have shown that\nGAN-based image synthesis for data augmentation can aid in improving\nclassification accuracy in a number of medical image analysis tasks, such as\nbrain and liver image analysis. However, the efficacy of leveraging GANs for\ntackling prostate cancer analysis has not been previously explored. Motivated\nby this, in this study we introduce ProstateGAN, a GAN-based model for\nsynthesizing realistic prostate diffusion imaging data. More specifically, in\norder to generate new diffusion imaging data corresponding to a particular\ncancer grade (Gleason score), we propose a conditional deep convolutional GAN\narchitecture that takes Gleason scores into consideration during the training\nprocess. Experimental results show that high-quality synthetic prostate\ndiffusion imaging data can be generated using the proposed ProstateGAN for\nspecified Gleason scores.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 14:44:42 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 01:35:54 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Hu", "Xiaodan", ""], ["Chung", "Audrey G.", ""], ["Fieguth", "Paul", ""], ["Khalvati", "Farzad", ""], ["Haider", "Masoom A.", ""], ["Wong", "Alexander", ""]]}, {"id": "1811.05896", "submitter": "Miguel De Prado", "authors": "Miguel de Prado, Maurizio Denna, Luca Benini and Nuria Pazos", "title": "QUENN: QUantization Engine for low-power Neural Networks", "comments": "Computing Frontiers 2018", "journal-ref": null, "doi": "10.1145/3203217.3203282", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is moving to edge devices, ushering in a new age of distributed\nArtificial Intelligence (AI). The high demand of computational resources\nrequired by deep neural networks may be alleviated by approximate computing\ntechniques, and most notably reduced-precision arithmetic with coarsely\nquantized numerical representations. In this context, Bonseyes comes in as an\ninitiative to enable stakeholders to bring AI to low-power and autonomous\nenvironments such as: Automotive, Medical Healthcare and Consumer Electronics.\nTo achieve this, we introduce LPDNN, a framework for optimized deployment of\nDeep Neural Networks on heterogeneous embedded devices. In this work, we detail\nthe quantization engine that is integrated in LPDNN. The engine depends on a\nfine-grained workflow which enables a Neural Network Design Exploration and a\nsensitivity analysis of each layer for quantization. We demonstrate the engine\nwith a case study on Alexnet and VGG16 for three different techniques for\ndirect quantization: standard fixed-point, dynamic fixed-point and k-means\nclustering, and demonstrate the potential of the latter. We argue that using a\nGaussian quantizer with k-means clustering can achieve better performance than\nlinear quantizers. Without retraining, we achieve over 55.64\\% saving for\nweights' storage and 69.17\\% for run-time memory accesses with less than 1\\%\ndrop in top5 accuracy in Imagenet.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 16:38:42 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["de Prado", "Miguel", ""], ["Denna", "Maurizio", ""], ["Benini", "Luca", ""], ["Pazos", "Nuria", ""]]}, {"id": "1811.05949", "submitter": "Marek Rei", "authors": "Marek Rei, Anders S{\\o}gaard", "title": "Jointly Learning to Label Sentences and Tokens", "comments": "AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to construct text representations in end-to-end systems can be\ndifficult, as natural languages are highly compositional and task-specific\nannotated datasets are often limited in size. Methods for directly supervising\nlanguage composition can allow us to guide the models based on existing\nknowledge, regularizing them towards more robust and interpretable\nrepresentations. In this paper, we investigate how objectives at different\ngranularities can be used to learn better language representations and we\npropose an architecture for jointly learning to label sentences and tokens. The\npredictions at each level are combined together using an attention mechanism,\nwith token-level labels also acting as explicit supervision for composing\nsentence-level representations. Our experiments show that by learning to\nperform these tasks jointly on multiple levels, the model achieves substantial\nimprovements for both sentence classification and sequence labeling.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 18:32:18 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Rei", "Marek", ""], ["S\u00f8gaard", "Anders", ""]]}, {"id": "1811.06477", "submitter": "Thomas Cherian", "authors": "Thomas Cherian, Akshay Badola and Vineet Padmanabhan", "title": "Multi-cell LSTM Based Neural Language Model", "comments": "7 pages including 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language models, being at the heart of many NLP problems, are always of great\ninterest to researchers. Neural language models come with the advantage of\ndistributed representations and long range contexts. With its particular\ndynamics that allow the cycling of information within the network, `Recurrent\nneural network' (RNN) becomes an ideal paradigm for neural language modeling.\nLong Short-Term Memory (LSTM) architecture solves the inadequacies of the\nstandard RNN in modeling long-range contexts. In spite of a plethora of RNN\nvariants, possibility to add multiple memory cells in LSTM nodes was seldom\nexplored. Here we propose a multi-cell node architecture for LSTMs and study\nits applicability for neural language modeling. The proposed multi-cell LSTM\nlanguage models outperform the state-of-the-art results on well-known Penn\nTreebank (PTB) setup.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 17:09:53 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Cherian", "Thomas", ""], ["Badola", "Akshay", ""], ["Padmanabhan", "Vineet", ""]]}, {"id": "1811.06488", "submitter": "Ezra Webb", "authors": "Ezra Webb, Cheng Lei, Chun-Jung Huang, Hirofumi Kobayashi, Hideharu\n  Mikami, Keisuke Goda", "title": "Exploring the Deep Feature Space of a Cell Classification Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present contemporary techniques for visualising the feature\nspace of a deep learning image classification neural network. These techniques\nare viewed in the context of a feed-forward network trained to classify low\nresolution fluorescence images of white blood cells captured using optofluidic\nimaging. The model has two output classes corresponding to two different cell\ntypes, which are often difficult to distinguish by eye. This paper has two\nmajor sections. The first looks to develop the information space presented by\ndimension reduction techniques, such as t-SNE, used to embed high-dimensional\npre-softmax layer activations into a two-dimensional plane. The second section\nlooks at feature visualisation by optimisation to generate feature images\nrepresenting the learned features of the network. Using and developing these\ntechniques we visualise class separation and structures within the dataset at\nvarious depths using clustering algorithms and feature images; track the\ndevelopment of feature complexity as we ascend the network; and begin to\nextract the features the network has learnt by modulating single-channel\nfeature images with up-scaled neuron activation maps to distinguish their most\nsalient parts.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 17:26:17 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Webb", "Ezra", ""], ["Lei", "Cheng", ""], ["Huang", "Chun-Jung", ""], ["Kobayashi", "Hirofumi", ""], ["Mikami", "Hideharu", ""], ["Goda", "Keisuke", ""]]}, {"id": "1811.06521", "submitter": "Jan Leike", "authors": "Borja Ibarz and Jan Leike and Tobias Pohlen and Geoffrey Irving and\n  Shane Legg and Dario Amodei", "title": "Reward learning from human preferences and demonstrations in Atari", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To solve complex real-world problems with reinforcement learning, we cannot\nrely on manually specified reward functions. Instead, we can have humans\ncommunicate an objective to the agent directly. In this work, we combine two\napproaches to learning from human feedback: expert demonstrations and\ntrajectory preferences. We train a deep neural network to model the reward\nfunction and use its predicted reward to train an DQN-based deep reinforcement\nlearning agent on 9 Atari games. Our approach beats the imitation learning\nbaseline in 7 games and achieves strictly superhuman performance on 2 games\nwithout using game rewards. Additionally, we investigate the goodness of fit of\nthe reward model, present some reward hacking problems, and study the effects\nof noise in the human labels.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 18:33:43 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Ibarz", "Borja", ""], ["Leike", "Jan", ""], ["Pohlen", "Tobias", ""], ["Irving", "Geoffrey", ""], ["Legg", "Shane", ""], ["Amodei", "Dario", ""]]}, {"id": "1811.06672", "submitter": "Haruna Isah", "authors": "Sazia Mahfuz, Haruna Isah, Farhana Zulkernine, Peter Nicholls", "title": "Detecting Irregular Patterns in IoT Streaming Data for Fall Detection", "comments": "7 pages", "journal-ref": null, "doi": "10.1109/IEMCON.2018.8614822", "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting patterns in real time streaming data has been an interesting and\nchallenging data analytics problem. With the proliferation of a variety of\nsensor devices, real-time analytics of data from the Internet of Things (IoT)\nto learn regular and irregular patterns has become an important machine\nlearning problem to enable predictive analytics for automated notification and\ndecision support. In this work, we address the problem of learning an irregular\nhuman activity pattern, fall, from streaming IoT data from wearable sensors. We\npresent a deep neural network model for detecting fall based on accelerometer\ndata giving 98.75 percent accuracy using an online physical activity monitoring\ndataset called \"MobiAct\", which was published by Vavoulas et al. The initial\nmodel was developed using IBM Watson studio and then later transferred and\ndeployed on IBM Cloud with the streaming analytics service supported by IBM\nStreams for monitoring real-time IoT data. We also present the systems\narchitecture of the real-time fall detection framework that we intend to use\nwith mbientlabs wearable health monitoring sensors for real time patient\nmonitoring at retirement homes or rehabilitation clinics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 03:59:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Mahfuz", "Sazia", ""], ["Isah", "Haruna", ""], ["Zulkernine", "Farhana", ""], ["Nicholls", "Peter", ""]]}, {"id": "1811.06804", "submitter": "Aneta Neumann", "authors": "Aneta Neumann, Wanru Gao, Markus Wagner, Frank Neumann", "title": "Evolutionary Diversity Optimization Using Multi-Objective Indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary diversity optimization aims to compute a diverse set of\nsolutions where all solutions meet a given quality criterion. With this paper,\nwe bridge the areas of evolutionary diversity optimization and evolutionary\nmulti-objective optimization. We show how popular indicators frequently used in\nthe area of multi-objective optimization can be used for evolutionary diversity\noptimization. Our experimental investigations for evolving diverse sets of TSP\ninstances and images according to various features show that two of the most\nprominent multi-objective indicators, namely the hypervolume indicator and the\ninverted generational distance, provide excellent results in terms of\nvisualization and various diversity indicators.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 13:58:21 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Neumann", "Aneta", ""], ["Gao", "Wanru", ""], ["Wagner", "Markus", ""], ["Neumann", "Frank", ""]]}, {"id": "1811.06809", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Fixation properties of multiple cooperator configurations on regular\n  graphs", "comments": null, "journal-ref": "Theory in Biosciences (2019)", "doi": "10.1007/s12064-019-00293-3", "report-no": null, "categories": "q-bio.PE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whether or not cooperation is favored in evolutionary games on graphs depends\non the population structure and spatial properties of the interaction network.\nPopulation structures can be expressed as configurations. Such configurations\nextend scenarios with a single cooperator among defectors to any number of\ncooperators and any arrangement of cooperators and defectors. Thus, as a single\ncooperator can be interpreted as a lone mutant, the discussion about fixation\nproperties based on configurations also applies to multiple mutants. For\ninteraction networks modeled as regular graphs and for weak selection, the\nemergence of cooperation can be assessed by structure coefficients, which are\nspecific for a configuration and a graph. We analyze these structure\ncoefficients and particularly show that under certain conditions the\ncoefficients strongly correlate to the average shortest path length between\ncooperators on the evolutionary graph. Thus,for multiple cooperators fixation\nproperties on regular evolutionary graphs can be linked to cooperator path\nlength.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 14:13:51 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 14:13:37 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "1811.07020", "submitter": "Daniele Q.M. Madureira", "authors": "Daniele Q. M. Madureira, Vera Lucia P. S. Caminha and Rogerio Salvini", "title": "Brain Connectivity Impairments and Categorization Disabilities in\n  Autism: A Theoretical Approach via Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A developmental disorder that severely damages communicative and social\nfunctions, the Autism Spectrum Disorder (ASD) also presents aspects related to\nmental rigidity, repetitive behavior, and difficulty in abstract reasoning.\nMore, imbalances between excitatory and inhibitory brain states, in addition to\ncortical connectivity disruptions, are at the source of the autistic behavior.\nOur main goal consists in unveiling the way by which these local excitatory\nimbalances and/or long brain connections disruptions are linked to the above\nmentioned cognitive features. We developed a theoretical model based on\nSelf-Organizing Maps (SOM), where a three-level artificial neural network\nqualitatively incorporates these kinds of alterations observed in brains of\npatients with ASD. Computational simulations of our model indicate that high\nexcitatory states or long distance under-connectivity are at the origins of\ncognitive alterations, as difficulty in categorization and mental rigidity.\nMore specifically, the enlargement of excitatory synaptic reach areas in a\ncortical map development conducts to low categorization (over-selectivity) and\npoor concepts formation. And, both the over-strengthening of local excitatory\nsynapses and the long distance under-connectivity, although through distinct\nmechanisms, contribute to impaired categorization (under-selectivity) and\nmental rigidity. Our results indicate how, together, both local and global\nbrain connectivity alterations give rise to spoiled cortical structures in\ndistinct ways and in distinct cortical areas. These alterations would disrupt\nthe codification of sensory stimuli, the representation of concepts and, thus,\nthe process of categorization - by this way imposing serious limits to the\nmental flexibility and to the capacity of generalization in the autistic\nreasoning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 20:20:09 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Madureira", "Daniele Q. M.", ""], ["Caminha", "Vera Lucia P. S.", ""], ["Salvini", "Rogerio", ""]]}, {"id": "1811.07115", "submitter": "Soochang Lee", "authors": "Soochang Lee, Chul-Heung Kim, Seongbin Oh, Byung-Gook Park, and\n  Jong-Ho Lee", "title": "Unsupervised Online Learning With Multiple Postsynaptic Neurons Based on\n  Spike-Timing-Dependent Plasticity Using a TFT-Type NOR Flash Memory Array", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a two-layer fully connected neuromorphic system based on a\nthin-film transistor (TFT)-type NOR flash memory array with multiple\npostsynaptic (POST) neurons. Unsupervised online learning by\nspike-timing-dependent plasticity (STDP) on the binary MNIST handwritten\ndatasets is implemented, and its recognition result is determined by measuring\nfiring rate of POST neurons. Using a proposed learning scheme, we investigate\nthe impact of the number of POST neurons in terms of recognition rate. In this\nneuromorphic system, lateral inhibition function and homeostatic property are\nexploited for competitive learning of multiple POST neurons. The simulation\nresults demonstrate unsupervised online learning of the full black-and-white\nMNIST handwritten digits by STDP, which indicates the performance of pattern\nrecognition and classification without preprocessing of input patterns.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 07:48:27 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Lee", "Soochang", ""], ["Kim", "Chul-Heung", ""], ["Oh", "Seongbin", ""], ["Park", "Byung-Gook", ""], ["Lee", "Jong-Ho", ""]]}, {"id": "1811.07211", "submitter": "Jacob Springer", "authors": "Jacob M. Springer, Charles S. Strauss, Austin M. Thresher, Edward Kim,\n  Garrett T. Kenyon", "title": "Classifiers Based on Deep Sparse Coding Architectures are Robust to Deep\n  Learning Transferable Examples", "comments": "8 pages, 8 figures, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has shown great success in recent years, researchers\nhave discovered a critical flaw where small, imperceptible changes in the input\nto the system can drastically change the output classification. These attacks\nare exploitable in nearly all of the existing deep learning classification\nframeworks. However, the susceptibility of deep sparse coding models to\nadversarial examples has not been examined. Here, we show that classifiers\nbased on a deep sparse coding model whose classification accuracy is\ncompetitive with a variety of deep neural network models are robust to\nadversarial examples that effectively fool those same deep learning models. We\ndemonstrate both quantitatively and qualitatively that the robustness of deep\nsparse coding models to adversarial examples arises from two key properties.\nFirst, because deep sparse coding models learn general features corresponding\nto generators of the dataset as a whole, rather than highly discriminative\nfeatures for distinguishing specific classes, the resulting classifiers are\nless dependent on idiosyncratic features that might be more easily exploited.\nSecond, because deep sparse coding models utilize fixed point attractor\ndynamics with top-down feedback, it is more difficult to find small changes to\nthe input that drive the resulting representations out of the correct attractor\nbasin.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 19:39:54 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 18:55:55 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Springer", "Jacob M.", ""], ["Strauss", "Charles S.", ""], ["Thresher", "Austin M.", ""], ["Kim", "Edward", ""], ["Kenyon", "Garrett T.", ""]]}, {"id": "1811.07253", "submitter": "Yijun Xiao", "authors": "Yijun Xiao, William Yang Wang", "title": "Quantifying Uncertainties in Natural Language Processing Tasks", "comments": "To appear at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable uncertainty quantification is a first step towards building\nexplainable, transparent, and accountable artificial intelligent systems.\nRecent progress in Bayesian deep learning has made such quantification\nrealizable. In this paper, we propose novel methods to study the benefits of\ncharacterizing model and data uncertainties for natural language processing\n(NLP) tasks. With empirical experiments on sentiment analysis, named entity\nrecognition, and language modeling using convolutional and recurrent neural\nnetwork models, we show that explicitly modeling uncertainties is not only\nnecessary to measure output confidence levels, but also useful at enhancing\nmodel performances in various NLP tasks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 01:36:05 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Xiao", "Yijun", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.07453", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli and Titouan Parcollet and Yoshua Bengio", "title": "The PyTorch-Kaldi Speech Recognition Toolkit", "comments": "Accepted at ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of open-source software is playing a remarkable role in the\npopularization of speech recognition and deep learning. Kaldi, for instance, is\nnowadays an established framework used to develop state-of-the-art speech\nrecognizers. PyTorch is used to build neural networks with the Python language\nand has recently spawn tremendous interest within the machine learning\ncommunity thanks to its simplicity and flexibility.\n  The PyTorch-Kaldi project aims to bridge the gap between these popular\ntoolkits, trying to inherit the efficiency of Kaldi and the flexibility of\nPyTorch. PyTorch-Kaldi is not only a simple interface between these software,\nbut it embeds several useful features for developing modern speech recognizers.\nFor instance, the code is specifically designed to naturally plug-in\nuser-defined acoustic models. As an alternative, users can exploit several\npre-implemented neural networks that can be customized using intuitive\nconfiguration files. PyTorch-Kaldi supports multiple feature and label streams\nas well as combinations of neural networks, enabling the use of complex neural\narchitectures. The toolkit is publicly-released along with a rich documentation\nand is designed to properly work locally or on HPC clusters.\n  Experiments, that are conducted on several datasets and tasks, show that\nPyTorch-Kaldi can effectively be used to develop modern state-of-the-art speech\nrecognizers.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 01:57:05 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 19:13:03 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Parcollet", "Titouan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1811.07511", "submitter": "Anton Eremeev", "authors": "Anton Eremeev, Alexander Spirov", "title": "Modularity in biological evolution and evolutionary computation", "comments": "The main text is in Russian", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main properties of biological systems is modularity, which\nmanifests itself at all levels of their organization, starting with the level\nof molecular genetics, ending with the level of whole organisms and their\ncommunities. In a simplified form, these basic principles were transferred from\nthe genetics of populations to the field of evolutionary computations, in order\nto solve applied optimization problems. Over almost half a century of\ndevelopment in this field of computer science, considerable practical\nexperience has been gained and interesting theoretical results have been\nobtained. In this survey, the phenomena and patterns associated with modularity\nin genetics and evolutionary computations are compared. An analysis of\nsimilarities and differences in the results obtained in these areas is carried\nout from the modularity view point. The possibilities for knowledge transfer\nbetween the areas are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 05:42:41 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Eremeev", "Anton", ""], ["Spirov", "Alexander", ""]]}, {"id": "1811.07514", "submitter": "Shobeir Fakhraei", "authors": "Shobeir Fakhraei, Joel Mathew, Jose Luis Ambite", "title": "NSEEN: Neural Semantic Embedding for Entity Normalization", "comments": "Accepted for publication at ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DB cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of human knowledge is encoded in text, available in scientific\npublications, books, and the web. Given the rapid growth of these resources, we\nneed automated methods to extract such knowledge into machine-processable\nstructures, such as knowledge graphs. An important task in this process is\nentity normalization, which consists of mapping noisy entity mentions in text\nto canonical entities in well-known reference sets. However, entity\nnormalization is a challenging problem; there often are many textual forms for\na canonical entity that may not be captured in the reference set, and entities\nmentioned in text may include many syntactic variations, or errors. The problem\nis particularly acute in scientific domains, such as biology. To address this\nproblem, we have developed a general, scalable solution based on a deep Siamese\nneural network model to embed the semantic information about the entities, as\nwell as their syntactic variations. We use these embeddings for fast mapping of\nnew entities to large reference sets, and empirically show the effectiveness of\nour framework in challenging bio-entity normalization datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:04:13 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 07:19:08 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fakhraei", "Shobeir", ""], ["Mathew", "Joel", ""], ["Ambite", "Jose Luis", ""]]}, {"id": "1811.07516", "submitter": "Rahma Fourati", "authors": "Rahma Fourati, Boudour Ammar, Javier Sanchez-Medina and Adel M. Alimi", "title": "Unsupervised Learning in Reservoir Computing for EEG-based Emotion\n  Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world applications such as emotion recognition from recorded brain\nactivity, data are captured from electrodes over time. These signals constitute\na multidimensional time series. In this paper, Echo State Network (ESN), a\nrecurrent neural network with a great success in time series prediction and\nclassification, is optimized with different neural plasticity rules for\nclassification of emotions based on electroencephalogram (EEG) time series.\nActually, the neural plasticity rules are a kind of unsupervised learning\nadapted for the reservoir, i.e. the hidden layer of ESN. More specifically, an\ninvestigation of Oja's rule, BCM rule and gaussian intrinsic plasticity rule\nwas carried out in the context of EEG-based emotion recognition. The study,\nalso, includes a comparison of the offline and online training of the ESN. When\ntesting on the well-known affective benchmark \"DEAP dataset\" which contains EEG\nsignals from 32 subjects, we find that pretraining ESN with gaussian intrinsic\nplasticity enhanced the classification accuracy and outperformed the results\nachieved with an ESN pretrained with synaptic plasticity. Four classification\nproblems were conducted in which the system complexity is increased and the\ndiscrimination is more challenging, i.e. inter-subject emotion discrimination.\nOur proposed method achieves higher performance over the state of the art\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:07:33 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 03:24:25 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Fourati", "Rahma", ""], ["Ammar", "Boudour", ""], ["Sanchez-Medina", "Javier", ""], ["Alimi", "Adel M.", ""]]}, {"id": "1811.07550", "submitter": "Xiujun Li", "authors": "Yuexin Wu and Xiujun Li and Jingjing Liu and Jianfeng Gao and Yiming\n  Yang", "title": "Switch-based Active Deep Dyna-Q: Efficient Adaptive Planning for\n  Task-Completion Dialogue Policy Learning", "comments": "8 pages, 9 figures, AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training task-completion dialogue agents with reinforcement learning usually\nrequires a large number of real user experiences. The Dyna-Q algorithm extends\nQ-learning by integrating a world model, and thus can effectively boost\ntraining efficiency using simulated experiences generated by the world model.\nThe effectiveness of Dyna-Q, however, depends on the quality of the world model\n- or implicitly, the pre-specified ratio of real vs. simulated experiences used\nfor Q-learning. To this end, we extend the recently proposed Deep Dyna-Q (DDQ)\nframework by integrating a switcher that automatically determines whether to\nuse a real or simulated experience for Q-learning. Furthermore, we explore the\nuse of active learning for improving sample efficiency, by encouraging the\nworld model to generate simulated experiences in the state-action space where\nthe agent has not (fully) explored. Our results show that by combining switcher\nand active learning, the new framework named as Switch-based Active Deep Dyna-Q\n(Switch-DDQ), leads to significant improvement over DDQ and Q-learning\nbaselines in both simulation and human evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 08:23:34 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Wu", "Yuexin", ""], ["Li", "Xiujun", ""], ["Liu", "Jingjing", ""], ["Gao", "Jianfeng", ""], ["Yang", "Yiming", ""]]}, {"id": "1811.07630", "submitter": "Elizaveta Logacheva", "authors": "Pavel Ostyakov, Roman Suvorov, Elizaveta Logacheva, Oleg Khomenko,\n  Sergey I. Nikolenko", "title": "SEIGAN: Towards Compositional Image Generation by Simultaneously\n  Learning to Segment, Enhance, and Inpaint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to image manipulation and understanding by\nsimultaneously learning to segment object masks, paste objects to another\nbackground image, and remove them from original images. For this purpose, we\ndevelop a novel generative model for compositional image generation, SEIGAN\n(Segment-Enhance-Inpaint Generative Adversarial Network), which learns these\nthree operations together in an adversarial architecture with additional cycle\nconsistency losses. To train, SEIGAN needs only bounding box supervision and\ndoes not require pairing or ground truth masks. SEIGAN produces better\ngenerated images (evaluated by human assessors) than other approaches and\nproduces high-quality segmentation masks, improving over other adversarially\ntrained approaches and getting closer to the results of fully supervised\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 11:50:20 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 19:33:07 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Ostyakov", "Pavel", ""], ["Suvorov", "Roman", ""], ["Logacheva", "Elizaveta", ""], ["Khomenko", "Oleg", ""], ["Nikolenko", "Sergey I.", ""]]}, {"id": "1811.07672", "submitter": "Ryad Benjamin Benosman", "authors": "Marco Macanovic, Fabian Chersi, Felix Rutard, Sio-Hoi Ieng, Ryad\n  Benosman", "title": "When Conventional machine learning meets neuromorphic engineering: Deep\n  Temporal Networks (DTNets) a machine learning frawmework allowing to operate\n  on Events and Frames and implantable on Tensor Flow Like Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We introduce in this paper the principle of Deep Temporal Networks that allow\nto add time to convolutional networks by allowing deep integration principles\nnot only using spatial information but also increasingly large temporal window.\nThe concept can be used for conventional image inputs but also event based\ndata. Although inspired by the architecture of brain that inegrates information\nover increasingly larger spatial but also temporal scales it can operate on\nconventional hardware using existing architectures. We introduce preliminary\nresults to show the efficiency of the method. More in-depth results and\nanalysis will be reported soon!\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 13:32:30 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Macanovic", "Marco", ""], ["Chersi", "Fabian", ""], ["Rutard", "Felix", ""], ["Ieng", "Sio-Hoi", ""], ["Benosman", "Ryad", ""]]}, {"id": "1811.07806", "submitter": "Vahid Roostapour", "authors": "Vahid Roostapour, Aneta Neumann, Frank Neumann, Tobias Friedrich", "title": "Pareto Optimization for Subset Selection with Dynamic Cost Constraints", "comments": "A preliminary version of this article has been presented at the\n  Thirty-Third AAAI Conference on Artificial Intelligence (AAAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the subset selection problem for function $f$ with constraint\nbound $B$ that changes over time. Within the area of submodular optimization,\nvarious greedy approaches are commonly used. For dynamic environments we\nobserve that the adaptive variants of these greedy approaches are not able to\nmaintain their approximation quality. Investigating the recently introduced\nPOMC Pareto optimization approach, we show that this algorithm efficiently\ncomputes a $\\phi= (\\alpha_f/2)(1-\\frac{1}{e^{\\alpha_f}})$-approximation, where\n$\\alpha_f$ is the submodularity ratio of $f$, for each possible constraint\nbound $b \\leq B$. Furthermore, we show that POMC is able to adapt its set of\nsolutions quickly in the case that $B$ increases. Our experimental\ninvestigations for the influence maximization in social networks show the\nadvantage of POMC over generalized greedy algorithms. We also consider EAMC, a\nnew evolutionary algorithm with polynomial expected time guarantee to maintain\n$\\phi$ approximation ratio, and NSGA-II as an advanced multi-objective\noptimization algorithm, to demonstrate their challenges in optimizing the\nmaximum coverage problem. Our empirical analysis shows that, within the same\nnumber of evaluations, POMC is able to outperform NSGA-II under linear\nconstraint, while EAMC performs significantly worse than all considered\nalgorithms in most cases.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 07:03:18 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 11:52:28 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Roostapour", "Vahid", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""], ["Friedrich", "Tobias", ""]]}, {"id": "1811.07871", "submitter": "Jan Leike", "authors": "Jan Leike and David Krueger and Tom Everitt and Miljan Martic and\n  Vishal Maini and Shane Legg", "title": "Scalable agent alignment via reward modeling: a research direction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One obstacle to applying reinforcement learning algorithms to real-world\nproblems is the lack of suitable reward functions. Designing such reward\nfunctions is difficult in part because the user only has an implicit\nunderstanding of the task objective. This gives rise to the agent alignment\nproblem: how do we create agents that behave in accordance with the user's\nintentions? We outline a high-level research direction to solve the agent\nalignment problem centered around reward modeling: learning a reward function\nfrom interaction with the user and optimizing the learned reward function with\nreinforcement learning. We discuss the key challenges we expect to face when\nscaling reward modeling to complex and general domains, concrete approaches to\nmitigate these challenges, and ways to establish trust in the resulting agents.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 18:48:04 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Leike", "Jan", ""], ["Krueger", "David", ""], ["Everitt", "Tom", ""], ["Martic", "Miljan", ""], ["Maini", "Vishal", ""], ["Legg", "Shane", ""]]}, {"id": "1811.07966", "submitter": "Alexander Wong", "authors": "Audrey Chung, Paul Fieguth, Alexander Wong", "title": "Mitigating Architectural Mismatch During the Evolutionary Synthesis of\n  Deep Neural Networks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary deep intelligence has recently shown great promise for producing\nsmall, powerful deep neural network models via the organic synthesis of\nincreasingly efficient architectures over successive generations. Existing\nevolutionary synthesis processes, however, have allowed the mating of parent\nnetworks independent of architectural alignment, resulting in a mismatch of\nnetwork structures. We present a preliminary study into the effects of\narchitectural alignment during evolutionary synthesis using a gene tagging\nsystem. Surprisingly, the network architectures synthesized using the gene\ntagging approach resulted in slower decreases in performance accuracy and\nstorage size; however, the resultant networks were comparable in size and\nperformance accuracy to the non-gene tagging networks. Furthermore, we\nspeculate that there is a noticeable decrease in network variability for\nnetworks synthesized with gene tagging, indicating that enforcing a\nlike-with-like mating policy potentially restricts the exploration of the\nsearch space of possible network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 20:36:16 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Chung", "Audrey", ""], ["Fieguth", "Paul", ""], ["Wong", "Alexander", ""]]}, {"id": "1811.08150", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Jiaoyang Huang, Leslie Pack Kaelbling", "title": "Effect of Depth and Width on Local Minima in Deep Learning", "comments": null, "journal-ref": "Neural computation, volume 31, pages 1462-1498 (2019)", "doi": "10.1162/neco_a_01195", "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the effects of depth and width on the quality of\nlocal minima, without strong over-parameterization and simplification\nassumptions in the literature. Without any simplification assumption, for deep\nnonlinear neural networks with the squared loss, we theoretically show that the\nquality of local minima tends to improve towards the global minimum value as\ndepth and width increase. Furthermore, with a locally-induced structure on deep\nnonlinear neural networks, the values of local minima of neural networks are\ntheoretically proven to be no worse than the globally optimal values of\ncorresponding classical machine learning models. We empirically support our\ntheoretical observation with a synthetic dataset as well as MNIST, CIFAR-10 and\nSVHN datasets. When compared to previous studies with strong\nover-parameterization assumptions, the results in this paper do not require\nover-parameterization, and instead show the gradual effects of\nover-parameterization as consequences of general results.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 09:41:52 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 19:48:28 GMT"}, {"version": "v3", "created": "Mon, 17 Jun 2019 18:40:43 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 15:32:37 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Huang", "Jiaoyang", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1811.08210", "submitter": "Xing Hsu", "authors": "Xing Hsu, Zhifeng Zhao, Rongpeng Li, Honggang Zhang", "title": "Brain-Inspired Stigmergy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stigmergy has proved its great superiority in terms of distributed control,\nrobustness and adaptability, thus being regarded as an ideal solution for\nlarge-scale swarm control problems. Based on new discoveries on astrocytes in\nregulating synaptic transmission in the brain, this paper has mapped stigmergy\nmechanism into the interaction between synapses and investigated its\ncharacteristics and advantages. Particularly, we have divided the interaction\nbetween synapses which are not directly connected into three phases and\nproposed a stigmergic learning model. In this model, the state change of a\nstigmergy agent will expand its influence to affect the states of others. The\nstrength of the interaction is determined by the level of neural activity as\nwell as the distance between stigmergy agents. Inspired by the morphological\nand functional changes in astrocytes during environmental enrichment, it is\nlikely that the regulation of distance between stigmergy agents plays a\ncritical role in the stigmergy learning process. Simulation results have\nverified its importance and indicated that the well-regulated distance between\nstigmergy agents can help to obtain stigmergy learning gain.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 12:36:25 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Hsu", "Xing", ""], ["Zhao", "Zhifeng", ""], ["Li", "Rongpeng", ""], ["Zhang", "Honggang", ""]]}, {"id": "1811.08225", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Hirotaka Takano and Junichi Murata", "title": "Self Organizing Classifiers: First Steps in Structured Evolutionary\n  Machine Learning", "comments": null, "journal-ref": "Evolutionary Intelligence 6 (2), 57-72 (2013)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems (LCSs) are evolutionary machine learning\nalgorithms, flexible enough to be applied to reinforcement, supervised and\nunsupervised learning problems with good performance. Recently, self organizing\nclassifiers were proposed which are similar to LCSs but have the advantage that\nin its structured population no balance between niching and fitness pressure is\nnecessary. However, more tests and analysis are required to verify its\nbenefits. Here, a variation of the first algorithm is proposed which uses a\nparameterless self organizing map (SOM). This algorithm is applied in\nchallenging problems such as big, noisy as well as dynamically changing\ncontinuous input-action mazes (growing and compressing mazes are included) with\ngood performance. Moreover, a genetic operator is proposed which utilizes the\ntopological information of the SOM's population structure, improving the\nresults. Thus, the first steps in structured evolutionary machine learning are\nshown, nonetheless, the problems faced are more difficult than the state-of-art\ncontinuous input-action multi-step ones.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:00:51 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1811.08226", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas and Hirotaka Takano and Junichi Murata", "title": "Self Organizing Classifiers and Niched Fitness", "comments": "arXiv admin note: text overlap with arXiv:1811.08225", "journal-ref": "Proceedings of the 15th annual conference on Genetic and\n  evolutionary computation (GECCO 2013)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems are adaptive learning systems which have been\nwidely applied in a multitude of application domains. However, there are still\nsome generalization problems unsolved. The hurdle is that fitness and niching\npressures are difficult to balance. Here, a new algorithm called Self\nOrganizing Classifiers is proposed which faces this problem from a different\nperspective. Instead of balancing the pressures, both pressures are separated\nand no balance is necessary. In fact, the proposed algorithm possesses a\ndynamical population structure that self-organizes itself to better project the\ninput space into a map. The niched fitness concept is defined along with its\ndynamical population structure, both are indispensable for the understanding of\nthe proposed method. Promising results are shown on two continuous multi-step\nproblems. One of which is yet more challenging than previous problems of this\nclass in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 13:01:29 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1811.08286", "submitter": "Travis Desell", "authors": "Travis Desell", "title": "Accelerating the Evolution of Convolutional Neural Networks with\n  Node-Level Mutations and Epigenetic Weight Initialization", "comments": "arXiv admin note: text overlap with arXiv:1703.05422", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines three generic strategies for improving the performance of\nneuro-evolution techniques aimed at evolving convolutional neural networks\n(CNNs). These were implemented as part of the Evolutionary eXploration of\nAugmenting Convolutional Topologies (EXACT) algorithm. EXACT evolves arbitrary\nconvolutional neural networks (CNNs) with goals of better discovering and\nunderstanding new effective architectures of CNNs for machine learning tasks\nand to potentially automate the process of network design and selection. The\nstrategies examined are node-level mutation operations, epigenetic weight\ninitialization and pooling connections. Results were gathered over the period\nof a month using a volunteer computing project, where over 225,000 CNNs were\ntrained and evaluated across 16 different EXACT searches. The node mutation\noperations where shown to dramatically improve evolution rates over traditional\nedge mutation operations (as used by the NEAT algorithm), and epigenetic weight\ninitialization was shown to further increase the accuracy and generalizability\nof the trained CNNs. As a negative but interesting result, allowing for pooling\nconnections was shown to degrade the evolution progress. The best trained CNNs\nreached 99.46% accuracy on the MNIST test data in under 13,500 CNN evaluations\n-- accuracy comparable with some of the best human designed CNNs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 21:41:48 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Desell", "Travis", ""]]}, {"id": "1811.08393", "submitter": "Kush Bhatia", "authors": "Kush Bhatia, Aldo Pacchiano, Nicolas Flammarion, Peter L. Bartlett,\n  Michael I. Jordan", "title": "Gen-Oja: A Two-time-scale approach for Streaming CCA", "comments": "Accepted at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problems of principal Generalized Eigenvector\ncomputation and Canonical Correlation Analysis in the stochastic setting. We\npropose a simple and efficient algorithm, Gen-Oja, for these problems. We prove\nthe global convergence of our algorithm, borrowing ideas from the theory of\nfast-mixing Markov chains and two-time-scale stochastic approximation, showing\nthat it achieves the optimal rate of convergence. In the process, we develop\ntools for understanding stochastic processes with Markovian noise which might\nbe of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 17:57:13 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 01:19:06 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Bhatia", "Kush", ""], ["Pacchiano", "Aldo", ""], ["Flammarion", "Nicolas", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1811.08701", "submitter": "Shahin Pourbahrami", "authors": "Shahin Pourbahrami", "title": "Improving PSO Global Method for Feature Selection According to\n  Iterations Global Search and Chaotic Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Making a simple model by choosing a limited number of features with the\npurpose of reducing the computational complexity of the algorithms involved in\nclassification is one of the main issues in machine learning and data mining.\nThe aim of Feature Selection (FS) is to reduce the number of redundant and\nirrelevant features and improve the accuracy of classification in a data set.\nWe propose an efficient ISPSO-GLOBAL (Improved Seeding Particle Swarm\nOptimization GLOBAL) method which investigates the specified iterations to\nproduce prominent features and store them in storage list. The goal is to find\ninformative features based on its iteration frequency with favorable fitness\nfor the next generation and high exploration. Our method exploits of a new\ninitialization strategy in PSO which improves space search and utilizes chaos\ntheory to enhance the population initialization, then we offer a new formula to\ndetermine the features size used in proposed method. Our experiments with\nreal-world data sets show that the performance of the ISPSO-GLOBAL is superior\ncomparing with state-of-the-art methods in most of the data sets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 11:53:58 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Pourbahrami", "Shahin", ""]]}, {"id": "1811.09100", "submitter": "Xixian Zhang", "authors": "Xixian Zhang, Zhijing Yang, Faxian Cao, Jiangzhong Cao, Meilin Wang,\n  Nian Cai", "title": "Conditioning Optimization of Extreme Learning Machine by Multitask\n  Beetle Antennae Swarm Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme learning machine (ELM) as a simple and rapid neural network has been\nshown its good performance in various areas. Different from the general single\nhidden layer feedforward neural network (SLFN), the input weights and biases in\nhidden layer of ELM are generated randomly, so that it only takes a little\ncomputation overhead to train the model. However, the strategy of selecting\ninput weights and biases at random may result in ill-posed problem. Aiming to\noptimize the conditioning of ELM, we propose an effective particle swarm\nheuristic algorithm called Multitask Beetle Antennae Swarm Algorithm (MBAS),\nwhich is inspired by the structures of artificial bee colony (ABS) algorithm\nand Beetle Antennae Search (BAS) algorithm. Then, the proposed MBAS is applied\nto optimize the input weights and biases of ELM. Experiment results show that\nthe proposed method is capable of simultaneously reducing the condition number\nand regression error, and achieving good generalization performances.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 10:43:53 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Zhang", "Xixian", ""], ["Yang", "Zhijing", ""], ["Cao", "Faxian", ""], ["Cao", "Jiangzhong", ""], ["Wang", "Meilin", ""], ["Cai", "Nian", ""]]}, {"id": "1811.09196", "submitter": "Mahesh Patil", "authors": "Mahesh B. Patil", "title": "Using External Archive for Improved Performance in Multi-Objective\n  Optimization", "comments": "9 pages, 8 figures, submitted to IEEE Transactions on Evolutionary\n  Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that the use of an external archive, purely for storage purposes,\ncan bring substantial benefits in multi-objective optimization. A new scheme\nfor archive management for the above purpose is described. The new scheme is\ncombined with the NSGA-II algorithm for solving two multi-objective\noptimization problems, and it is demonstrated that this combination gives\nsignificantly improved sets of Pareto-optimal solutions. The additional\ncomputational effort because of the external archive is found to be\ninsignificant when the objective functions are expensive to evaluate.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 14:40:55 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Patil", "Mahesh B.", ""]]}, {"id": "1811.09300", "submitter": "Edward Grefenstette", "authors": "Edward Grefenstette, Robert Stanforth, Brendan O'Donoghue, Jonathan\n  Uesato, Grzegorz Swirszcz, Pushmeet Kohli", "title": "Strength in Numbers: Trading-off Robustness and Computation via\n  Adversarially-Trained Ensembles", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has led to remarkable results on a number of challenging\nproblems, researchers have discovered a vulnerability of neural networks in\nadversarial settings, where small but carefully chosen perturbations to the\ninput can make the models produce extremely inaccurate outputs. This makes\nthese models particularly unsuitable for safety-critical application domains\n(e.g. self-driving cars) where robustness is extremely important. Recent work\nhas shown that augmenting training with adversarially generated data provides\nsome degree of robustness against test-time attacks. In this paper we\ninvestigate how this approach scales as we increase the computational budget\ngiven to the defender. We show that increasing the number of parameters in\nadversarially-trained models increases their robustness, and in particular that\nensembling smaller models while adversarially training the entire ensemble as a\nsingle model is a more efficient way of spending said budget than simply using\na larger single model. Crucially, we show that it is the adversarial training\nof the ensemble, rather than the ensembling of adversarially trained models,\nwhich provides robustness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 20:32:58 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Grefenstette", "Edward", ""], ["Stanforth", "Robert", ""], ["O'Donoghue", "Brendan", ""], ["Uesato", "Jonathan", ""], ["Swirszcz", "Grzegorz", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1811.09332", "submitter": "Carl Lemaire", "authors": "Carl Lemaire, Andrew Achkar, Pierre-Marc Jodoin", "title": "Structured Pruning of Neural Networks with Budget-Aware Regularization", "comments": "Paper: 9 pages, 8 figures. Supplementary materials: 7 pages, 3\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning methods have shown to be effective at reducing the size of deep\nneural networks while keeping accuracy almost intact. Among the most effective\nmethods are those that prune a network while training it with a sparsity prior\nloss and learnable dropout parameters. A shortcoming of these approaches\nhowever is that neither the size nor the inference speed of the pruned network\ncan be controlled directly; yet this is a key feature for targeting deployment\nof CNNs on low-power hardware. To overcome this, we introduce a budgeted\nregularized pruning framework for deep CNNs. Our approach naturally fits into\ntraditional neural network training as it consists of a learnable masking\nlayer, a novel budget-aware objective function, and the use of knowledge\ndistillation. We also provide insights on how to prune a residual network and\nhow this can lead to new architectures. Experimental results reveal that CNNs\npruned with our method are more accurate and less compute-hungry than\nstate-of-the-art methods. Also, our approach is more effective at preventing\naccuracy collapse in case of severe pruning; this allows us to attain pruning\nfactors up to 16x without significant accuracy drop.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 00:30:40 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 22:47:57 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 14:52:06 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Lemaire", "Carl", ""], ["Achkar", "Andrew", ""], ["Jodoin", "Pierre-Marc", ""]]}, {"id": "1811.09725", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Yoshua Bengio", "title": "Interpretable Convolutional Filters with SincNet", "comments": "In Proceedings of NIPS@IRASL 2018. arXiv admin note: substantial text\n  overlap with arXiv:1808.00158", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is currently playing a crucial role toward higher levels of\nartificial intelligence. This paradigm allows neural networks to learn complex\nand abstract representations, that are progressively obtained by combining\nsimpler ones. Nevertheless, the internal \"black-box\" representations\nautomatically discovered by current neural architectures often suffer from a\nlack of interpretability, making of primary interest the study of explainable\nmachine learning techniques. This paper summarizes our recent efforts to\ndevelop a more interpretable neural model for directly processing speech from\nthe raw waveform. In particular, we propose SincNet, a novel Convolutional\nNeural Network (CNN) that encourages the first layer to discover more\nmeaningful filters by exploiting parametrized sinc functions. In contrast to\nstandard CNNs, which learn all the elements of each filter, only low and high\ncutoff frequencies of band-pass filters are directly learned from data. This\ninductive bias offers a very compact way to derive a customized filter-bank\nfront-end, that only depends on some parameters with a clear physical meaning.\nOur experiments, conducted on both speaker and speech recognition, show that\nthe proposed architecture converges faster, performs better, and is more\ninterpretable than standard CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 23:13:09 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 16:09:38 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1811.09786", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Recurrently Controlled Recurrent Networks", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) such as long short-term memory and gated\nrecurrent units are pivotal building blocks across a broad spectrum of sequence\nmodeling problems. This paper proposes a recurrently controlled recurrent\nnetwork (RCRN) for expressive and powerful sequence encoding. More concretely,\nthe key idea behind our approach is to learn the recurrent gating functions\nusing recurrent networks. Our architecture is split into two components - a\ncontroller cell and a listener cell whereby the recurrent controller actively\ninfluences the compositionality of the listener cell. We conduct extensive\nexperiments on a myriad of tasks in the NLP domain such as sentiment analysis\n(SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment\nclassification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading\ncomprehension (NarrativeQA). Across all 26 datasets, our results demonstrate\nthat RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs,\nsuggesting that our controller architecture might be a suitable replacement for\nthe widely adopted stacked architecture.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 08:15:50 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1811.09828", "submitter": "Krzysztof Maziarz", "authors": "Krzysztof Maziarz, Mingxing Tan, Andrey Khorlin, Marin Georgiev,\n  Andrea Gesmundo", "title": "Evolutionary-Neural Hybrid Agents for Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search has shown potential to automate the design of\nneural networks. Deep Reinforcement Learning based agents can learn complex\narchitectural patterns, as well as explore a vast and compositional search\nspace. On the other hand, evolutionary algorithms offer higher sample\nefficiency, which is critical for such a resource intensive application. In\norder to capture the best of both worlds, we propose a class of\nEvolutionary-Neural hybrid agents (Evo-NAS). We show that the Evo-NAS agent\noutperforms both neural and evolutionary agents when applied to architecture\nsearch for a suite of text and image classification benchmarks. On a\nhigh-complexity architecture search space for image classification, the Evo-NAS\nagent surpasses the accuracy achieved by commonly used agents with only 1/3 of\nthe search cost.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 13:00:47 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2019 16:05:51 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 15:27:38 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 13:25:42 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Maziarz", "Krzysztof", ""], ["Tan", "Mingxing", ""], ["Khorlin", "Andrey", ""], ["Georgiev", "Marin", ""], ["Gesmundo", "Andrea", ""]]}, {"id": "1811.09966", "submitter": "Debanjan Bhowmik", "authors": "Apoorv Dankar, Anand Verma, Utkarsh Saxena, Divya Kaushik, Shouri\n  Chatterjee and Debanjan Bhowmik", "title": "On-chip learning for domain wall synapse based Fully Connected Neural\n  Network", "comments": "Submitted on November 5, 2018 for review in journal", "journal-ref": "Journal of Magnetism and Magnetic Materials vol. 489, no. 165434,\n  2019", "doi": "10.1016/j.jmmm.2019.165434", "report-no": "Accepted for publication in Journal of Magnetism and Magnetic\n  Materials on June 7, 2019", "categories": "physics.app-ph cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spintronic devices are considered as promising candidates in implementing\nneuromorphic systems or hardware neural networks, which are expected to perform\nbetter than other existing computing systems for certain data classification\nand regression tasks. In this paper, we have designed a feedforward Fully\nConnected Neural Network (FCNN) with no hidden layer using spin orbit torque\ndriven domain wall devices as synapses and transistor based analog circuits as\nneurons. A feedback circuit is also designed using transistors, which at every\niteration computes the change in weights of the synapses needed to train the\nnetwork using Stochastic Gradient Descent (SGD) method. Subsequently it sends\nwrite current pulses to the domain wall based synaptic devices which move the\ndomain walls and updates the weights of the synapses. Through a combination of\nmicromagnetic simulations, analog circuit simulations and numerically solving\nFCNN training equations, we demonstrate \"on-chip\" training of the designed FCNN\non the MNIST database of handwritten digits in this paper. We report the\ntraining and test accuracies, energy consumed in the synaptic devices for the\ntraining and possible issues with hardware implementation of FCNN that can\nlimit its test accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 07:20:30 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Dankar", "Apoorv", ""], ["Verma", "Anand", ""], ["Saxena", "Utkarsh", ""], ["Kaushik", "Divya", ""], ["Chatterjee", "Shouri", ""], ["Bhowmik", "Debanjan", ""]]}, {"id": "1811.10005", "submitter": "Yashaswini Murthy", "authors": "Yashaswini Murthy", "title": "Nonlinear Dynamics of Binocular Rivalry: A Comparative Study", "comments": "6 pages, 7 sets of figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When our eyes are presented with the same image, the brain processes it to\nview it as a single coherent one. The lateral shift in the position of our\neyes, causes the two images to possess certain differences, which our brain\nexploits for the purpose of depth perception and to gauge the size of objects\nat different distances, a process commonly known as stereopsis. However, when\npresented with two different visual stimuli, the visual awareness alternates.\nThis phenomenon of binocular rivalry is a result of competition between the\ncorresponding neuronal populations of the two eyes. The article presents a\ncomparative study of various dynamical models proposed to capture this process.\nIt goes on to study the effect of a certain parameter on the rate of perceptual\nalternations and proceeds to disprove the initial propositions laid down to\ncharacterise this phenomenon. It concludes with a discussion on the possible\nfuture work that can be conducted to obtain a better picture of the neuronal\nfunctioning behind this rivalry.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 13:16:07 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Murthy", "Yashaswini", ""]]}, {"id": "1811.10114", "submitter": "Matjaz Perc", "authors": "Marcos Cardinot, Josephine Griffith, Colm O'Riordan, Matjaz Perc", "title": "Cooperation in the spatial prisoner's dilemma game with probabilistic\n  abstention", "comments": "7 pages, 4 figures; published in Scientific Reports", "journal-ref": "Sci. Rep. 8, 14531 (2018)", "doi": "10.1038/s41598-018-32933-x", "report-no": null, "categories": "cs.GT cs.MA cs.NE physics.data-an physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research has shown that the addition of abstention as an option transforms\nsocial dilemmas to rock-paper-scissor type games, where defectors dominate\ncooperators, cooperators dominate abstainers (loners), and abstainers (loners),\nin turn, dominate defectors. In this way, abstention can sustain cooperation\neven under adverse conditions, although defection also persists due to cyclic\ndominance. However, to abstain or to act as a loner has, to date, always been\nconsidered as an independent, third strategy to complement traditional\ncooperation and defection. Here we consider probabilistic abstention, where\neach player is assigned a probability to abstain in a particular instance of\nthe game. In the two limiting cases, the studied game reverts to the prisoner's\ndilemma game without loners or to the optional prisoner's dilemma game. For\nintermediate probabilities, we have a new hybrid game, which turns out to be\nmost favorable for the successful evolution of cooperation. We hope this novel\nhybrid game provides a more realistic view of the dilemma of optional/voluntary\nparticipation.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 23:19:07 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 21:10:50 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Cardinot", "Marcos", ""], ["Griffith", "Josephine", ""], ["O'Riordan", "Colm", ""], ["Perc", "Matjaz", ""]]}, {"id": "1811.10116", "submitter": "Marcos Cardinot", "authors": "Marcos Cardinot, Colm O'Riordan, Josephine Griffith, Matja\\v{z} Perc", "title": "Evoplex: A platform for agent-based modeling on networks", "comments": "6 pages, 5 figures; accepted for publication in SoftwareX [software\n  available at https://evoplex.org]", "journal-ref": "SoftwareX 9, 199-204 (2019)", "doi": "10.1016/j.softx.2019.02.009", "report-no": null, "categories": "cs.MA cs.NE physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Agent-based modeling and network science have been used extensively to\nadvance our understanding of emergent collective behavior in systems that are\ncomposed of a large number of simple interacting individuals or agents. With\nthe increasing availability of high computational power in affordable personal\ncomputers, dedicated efforts to develop multi-threaded, scalable and\neasy-to-use software for agent-based simulations are needed more than ever.\nEvoplex meets this need by providing a fast, robust and extensible platform for\ndeveloping agent-based models and multi-agent systems on networks. Each agent\nis represented as a node and interacts with its neighbors, as defined by the\nnetwork structure. Evoplex is ideal for modeling complex systems, for example\nin evolutionary game theory and computational social science. In Evoplex, the\nmodels are not coupled to the execution parameters or the visualization tools,\nand there is a user-friendly graphical interface which makes it easy for all\nusers, ranging from newcomers to experienced, to create, analyze, replicate and\nreproduce the experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 23:32:48 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 21:00:16 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Cardinot", "Marcos", ""], ["O'Riordan", "Colm", ""], ["Griffith", "Josephine", ""], ["Perc", "Matja\u017e", ""]]}, {"id": "1811.10225", "submitter": "Genggeng Liu", "authors": "Genggeng Liu, Zhen Zhuang, Wenzhong Guo, Naixue Xiong, and Guolong\n  Chen", "title": "A novel particle swarm optimizer with multi-stage transformation and\n  genetic operation for VLSI routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the basic model for very large scale integration (VLSI) routing, the\nSteiner minimal tree (SMT) can be used in various practical problems, such as\nwire length optimization, congestion, and time delay estimation. In this paper,\na novel particle swarm optimization (PSO) algorithm based on multi-stage\ntransformation and genetic operation is presented to construct two types of\nSMT, including non-Manhattan SMT and Manhattan SMT. Firstly, in order to be\nable to handle two types of SMT problems at the same time, an effective\nedge-vertex encoding strategy is proposed. Secondly, a multi-stage\ntransformation strategy is proposed to both expand the algorithm search space\nand ensure the effective convergence. We have tested three types from two to\nfour stages and various combinations under each type to highlight the best\ncombination. Thirdly, the genetic operators combined with union-find partition\nare designed to construct the discrete particle update formula for discrete\nVLSI routing. Moreover, in order to introduce uncertainty and diversity into\nthe search of PSO algorithm, we propose an improved mutation operation with\nedge transformation. Experimental results show that our algorithm from a global\nperspective of multilayer structure can achieve the best solution quality among\nthe existing algorithms. Finally, to our best knowledge, it is the first work\nto address both manhattan and non-manhattan routing at the same time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 08:11:46 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Liu", "Genggeng", ""], ["Zhuang", "Zhen", ""], ["Guo", "Wenzhong", ""], ["Xiong", "Naixue", ""], ["Chen", "Guolong", ""]]}, {"id": "1811.10574", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G.C.A. Cimino, Gigliola Vaglini", "title": "Using stigmergy to incorporate the time into artificial neural networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-05918-7_22", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A current research trend in neurocomputing involves the design of novel\nartificial neural networks incorporating the concept of time into their\noperating model. In this paper, a novel architecture that employs stigmergy is\nproposed. Computational stigmergy is used to dynamically increase (or decrease)\nthe strength of a connection, or the activation level, of an artificial neuron\nwhen stimulated (or released). This study lays down a basic framework for the\nderivation of a stigmergic NN with a related training algorithm. To show its\npotential, some pilot experiments have been reported. The XOR problem is solved\nby using only one single stigmergic neuron with one input and one output. A\nstatic NN, a stigmergic NN, a recurrent NN and a long short-term memory NN have\nbeen trained to solve the MNIST digits recognition benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2018 00:12:11 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1811.10636", "submitter": "Michael S. Ryoo", "authors": "AJ Piergiovanni, Anelia Angelova, Alexander Toshev, Michael S. Ryoo", "title": "Evolving Space-Time Neural Architectures for Videos", "comments": null, "journal-ref": "ICCV 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for finding video CNN architectures that capture rich\nspatio-temporal information in videos. Previous work, taking advantage of 3D\nconvolutions, obtained promising results by manually designing video CNN\narchitectures. We here develop a novel evolutionary search algorithm that\nautomatically explores models with different types and combinations of layers\nto jointly learn interactions between spatial and temporal aspects of video\nrepresentations. We demonstrate the generality of this algorithm by applying it\nto two meta-architectures, obtaining new architectures superior to manually\ndesigned architectures. Further, we propose a new component, the iTGM layer,\nwhich more efficiently utilizes its parameters to allow learning of space-time\ninteractions over longer time horizons. The iTGM layer is often preferred by\nthe evolutionary algorithm and allows building cost-efficient networks. The\nproposed approach discovers new and diverse video architectures that were\npreviously unknown. More importantly they are both more accurate and faster\nthan prior models, and outperform the state-of-the-art results on multiple\ndatasets we test, including HMDB, Kinetics, and Moments in Time. We will open\nsource the code and models, to encourage future model development.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 19:00:12 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:17:46 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Piergiovanni", "AJ", ""], ["Angelova", "Anelia", ""], ["Toshev", "Alexander", ""], ["Ryoo", "Michael S.", ""]]}, {"id": "1811.10678", "submitter": "Navin Anwani", "authors": "Navin Anwani and Bipin Rajendran", "title": "Training Multi-layer Spiking Neural Networks using NormAD based\n  Spatio-Temporal Error Backpropagation", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) have garnered a great amount of interest for\nsupervised and unsupervised learning applications. This paper deals with the\nproblem of training multi-layer feedforward SNNs. The non-linear\nintegrate-and-fire dynamics employed by spiking neurons make it difficult to\ntrain SNNs to generate desired spike trains in response to a given input. To\ntackle this, first the problem of training a multi-layer SNN is formulated as\nan optimization problem such that its objective function is based on the\ndeviation in membrane potential rather than the spike arrival instants. Then,\nan optimization method named Normalized Approximate Descent (NormAD),\nhand-crafted for such non-convex optimization problems, is employed to derive\nthe iterative synaptic weight update rule. Next, it is reformulated to\nefficiently train multi-layer SNNs, and is shown to be effectively performing\nspatio-temporal error backpropagation. The learning rule is validated by\ntraining $2$-layer SNNs to solve a spike based formulation of the XOR problem\nas well as training $3$-layer SNNs for generic spike based training problems.\nThus, the new algorithm is a key step towards building deep spiking neural\nnetworks capable of efficient event-triggered learning.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 19:19:44 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 03:37:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Anwani", "Navin", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1811.10766", "submitter": "Emre Neftci", "authors": "Jacques Kaiser and Hesham Mostafa and Emre Neftci", "title": "Synaptic Plasticity Dynamics for Deep Continuous Local Learning\n  (DECOLLE)", "comments": "Published in Frontiers in Neuroscience - Neuromorphic Engineering", "journal-ref": "Frontiers in Neuroscience, 2020", "doi": "10.3389/fnins.2020.00424", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing body of work underlines striking similarities between biological\nneural networks and recurrent, binary neural networks. A relatively smaller\nbody of work, however, discusses similarities between learning dynamics\nemployed in deep artificial neural networks and synaptic plasticity in spiking\nneural networks. The challenge preventing this is largely caused by the\ndiscrepancy between the dynamical properties of synaptic plasticity and the\nrequirements for gradient backpropagation. Learning algorithms that approximate\ngradient backpropagation using locally synthesized gradients can overcome this\nchallenge. Here, we show that synthetic gradients enable the derivation of Deep\nContinuous Local Learning (DECOLLE) in spiking neural networks. DECOLLE is\ncapable of learning deep spatio-temporal representations from spikes relying\nsolely on local information. Synaptic plasticity rules are derived\nsystematically from user-defined cost functions and neural dynamics by\nleveraging existing autodifferentiation methods of machine learning frameworks.\nWe benchmark our approach on the MNIST and the event-based neuromorphic\nDvsGesture dataset, on which DECOLLE performs comparably to the\nstate-of-the-art. DECOLLE networks provide continuously learning machines that\nare relevant to biology and supportive of event-based, low-power computer\nvision architectures matching the accuracies of conventional computers on tasks\nwhere temporal precision and speed are essential.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 01:50:08 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 23:12:19 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 16:53:46 GMT"}, {"version": "v4", "created": "Wed, 20 May 2020 19:00:57 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Kaiser", "Jacques", ""], ["Mostafa", "Hesham", ""], ["Neftci", "Emre", ""]]}, {"id": "1811.10811", "submitter": "Mahesh Subedar", "authors": "Mahesh Subedar, Ranganath Krishnan, Paulo Lopez Meyer, Omesh Tickoo,\n  Jonathan Huang", "title": "Uncertainty aware audiovisual activity recognition using deep Bayesian\n  variational inference", "comments": "Accepted at ICCV 2019 for Oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) provide state-of-the-art results for a multitude\nof applications, but the approaches using DNNs for multimodal audiovisual\napplications do not consider predictive uncertainty associated with individual\nmodalities. Bayesian deep learning methods provide principled confidence and\nquantify predictive uncertainty. Our contribution in this work is to propose an\nuncertainty aware multimodal Bayesian fusion framework for activity\nrecognition. We demonstrate a novel approach that combines deterministic and\nvariational layers to scale Bayesian DNNs to deeper architectures. Our\nexperiments using in- and out-of-distribution samples selected from a subset of\nMoments-in-Time (MiT) dataset show a more reliable confidence measure as\ncompared to the non-Bayesian baseline and the Monte Carlo dropout (MC dropout)\napproximate Bayesian inference. We also demonstrate the uncertainty estimates\nobtained from the proposed framework can identify out-of-distribution data on\nthe UCF101 and MiT datasets. In the multimodal setting, the proposed framework\nimproved precision-recall AUC by 10.2% on the subset of MiT dataset as compared\nto non-Bayesian baseline.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 04:51:54 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 06:01:04 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 05:35:30 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Subedar", "Mahesh", ""], ["Krishnan", "Ranganath", ""], ["Meyer", "Paulo Lopez", ""], ["Tickoo", "Omesh", ""], ["Huang", "Jonathan", ""]]}, {"id": "1811.10892", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio", "title": "Chasing the Echo State Property", "comments": "This paper is a preprint of the paper presented at ESANN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir Computing (RC) provides an efficient way for designing dynamical\nrecurrent neural models. While training is restricted to a simple output\ncomponent, the recurrent connections are left untrained after initialization,\nsubject to stability constraints specified by the Echo State Property (ESP).\nLiterature conditions for the ESP typically fail to properly account for the\neffects of driving input signals, often limiting the potentialities of the RC\napproach. In this paper, we study the fundamental aspect of asymptotic\nstability of RC models in presence of driving input, introducing an empirical\nESP index that enables to easily analyze the stability regimes of reservoirs.\nResults on two benchmark datasets reveal interesting insights on the dynamical\nproperties of input-driven reservoirs, suggesting that the actual domain of ESP\nvalidity is much wider than what covered by literature conditions commonly used\nin RC practice.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 09:44:35 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:57:00 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gallicchio", "Claudio", ""]]}, {"id": "1811.11226", "submitter": "Blaine Rister", "authors": "Blaine Rister, Darvin Yi, Kaushik Shivakumar, Tomomi Nobashi and\n  Daniel L. Rubin", "title": "CT organ segmentation using GPU data augmentation, unsupervised labels\n  and IOU loss", "comments": "Journal submission pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully-convolutional neural networks have achieved superior performance in a\nvariety of image segmentation tasks. However, their training requires laborious\nmanual annotation of large datasets, as well as acceleration by parallel\nprocessors with high-bandwidth memory, such as GPUs. We show that simple models\ncan achieve competitive accuracy for organ segmentation on CT images when\ntrained with extensive data augmentation, which leverages existing graphics\nhardware to quickly apply geometric and photometric transformations to 3D image\ndata. On 3 mm^3 CT volumes, our GPU implementation is 2.6-8X faster than a\nwidely-used CPU version, including communication overhead. We also show how to\nautomatically generate training labels using rudimentary morphological\noperations, which are efficiently computed by 3D Fourier transforms. We\ncombined fully-automatic labels for the lungs and bone with semi-automatic ones\nfor the liver, kidneys and bladder, to create a dataset of 130 labeled CT\nscans. To achieve the best results from data augmentation, our model uses the\nintersection-over-union (IOU) loss function, a close relative of the Dice loss.\nWe discuss its mathematical properties and explain why it outperforms the usual\nweighted cross-entropy loss for unbalanced segmentation tasks. We conclude that\nthere is no unique IOU loss function, as the naive one belongs to a broad\nfamily of functions with the same essential properties. When combining data\naugmentation with the IOU loss, our model achieves a Dice score of 78-92% for\neach organ. The trained model, code and dataset will be made publicly\navailable, to further medical imaging research.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 19:53:59 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Rister", "Blaine", ""], ["Yi", "Darvin", ""], ["Shivakumar", "Kaushik", ""], ["Nobashi", "Tomomi", ""], ["Rubin", "Daniel L.", ""]]}, {"id": "1811.11307", "submitter": "Craig Macartney", "authors": "Craig Macartney and Tillman Weyde", "title": "Improved Speech Enhancement with the Wave-U-Net", "comments": "5 pages (including 1 for References), 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE eess.AS eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the use of the Wave-U-Net architecture for speech enhancement, a\nmodel introduced by Stoller et al for the separation of music vocals and\naccompaniment. This end-to-end learning method for audio source separation\noperates directly in the time domain, permitting the integrated modelling of\nphase information and being able to take large temporal contexts into account.\nOur experiments show that the proposed method improves several metrics, namely\nPESQ, CSIG, CBAK, COVL and SSNR, over the state-of-the-art with respect to the\nspeech enhancement task on the Voice Bank corpus (VCTK) dataset. We find that a\nreduced number of hidden layers is sufficient for speech enhancement in\ncomparison to the original system designed for singing voice separation in\nmusic. We see this initial result as an encouraging signal to further explore\nspeech enhancement in the time-domain, both as an end in itself and as a\npre-processing step to speech recognition systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 23:11:05 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Macartney", "Craig", ""], ["Weyde", "Tillman", ""]]}, {"id": "1811.11390", "submitter": "Kerem Camsari", "authors": "Ramtin Zand, Kerem Y. Camsari, Supriyo Datta and Ronald F. DeMara", "title": "Composable Probabilistic Inference Networks Using MRAM-based Stochastic\n  Neurons", "comments": null, "journal-ref": "ACM Journal on Emerging Technologies in Computing Systems (JETC)\n  (2019)", "doi": "10.1145/3304105", "report-no": null, "categories": "cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetoresistive random access memory (MRAM) technologies with thermally\nunstable nanomagnets are leveraged to develop an intrinsic stochastic neuron as\na building block for restricted Boltzmann machines (RBMs) to form deep belief\nnetworks (DBNs). The embedded MRAM-based neuron is modeled using precise\nphysics equations. The simulation results exhibit the desired sigmoidal\nrelation between the input voltages and probability of the output state. A\nprobabilistic inference network simulator (PIN-Sim) is developed to realize a\ncircuit-level model of an RBM utilizing resistive crossbar arrays along with\ndifferential amplifiers to implement the positive and negative weight values.\nThe PIN-Sim is composed of five main blocks to train a DBN, evaluate its\naccuracy, and measure its power consumption. The MNIST dataset is leveraged to\ninvestigate the energy and accuracy tradeoffs of seven distinct network\ntopologies in SPICE using the 14nm HP-FinFET technology library with the\nnominal voltage of 0.8V, in which an MRAM-based neuron is used as the\nactivation function. The software and hardware level simulations indicate that\na $784\\times200\\times10$ topology can achieve less than 5% error rates with\n$\\sim400 pJ$ energy consumption. The error rates can be reduced to 2.5% by\nusing a $784\\times500\\times500\\times500\\times10$ DBN at the cost of\n$\\sim10\\times$ higher energy consumption and significant area overhead.\nFinally, the effects of specific hardware-level parameters on power dissipation\nand accuracy tradeoffs are identified via the developed PIN-Sim framework.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 05:23:19 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Zand", "Ramtin", ""], ["Camsari", "Kerem Y.", ""], ["Datta", "Supriyo", ""], ["DeMara", "Ronald F.", ""]]}, {"id": "1811.11620", "submitter": "Waddah Waheeb", "authors": "Waddah Waheeb and Rozaida Ghazali", "title": "Multi-step Time Series Forecasting Using Ridge Polynomial Neural Network\n  with Error-Output Feedbacks", "comments": "This is a pre-print of an article published in the International\n  Conference on Soft Computing in Data Science, 2016. The final authenticated\n  version is available online at:\n  http://link.springer.com/chapter/10.1007/978-981-10-2777-2_5", "journal-ref": null, "doi": "10.1007/978-981-10-2777-2_5", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting gets much attention due to its impact on many\npractical applications. Higher-order neural network with recurrent feedback is\na powerful technique which used successfully for forecasting. It maintains fast\nlearning and the ability to learn the dynamics of the series over time. For\nthat, in this paper, we propose a novel model which is called Ridge Polynomial\nNeural Network with Error-Output Feedbacks (RPNN-EOFs) that combines the\nproperties of higher order and error-output feedbacks. The well-known\nMackey-Glass time series is used to test the forecasting capability of\nRPNN-EOFS. Simulation results showed that the proposed RPNN-EOFs provides\nbetter understanding for the Mackey-Glass time series with root mean square\nerror equal to 0.00416. This result is smaller than other models in the\nliterature. Therefore, we can conclude that the RPNN-EOFs can be applied\nsuccessfully for time series forecasting.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 15:19:45 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Waheeb", "Waddah", ""], ["Ghazali", "Rozaida", ""]]}, {"id": "1811.11876", "submitter": "Rajesh Rao", "authors": "Rajesh P. N. Rao", "title": "Towards Neural Co-Processors for the Brain: Combining Decoding and\n  Encoding in Brain-Computer Interfaces", "comments": "Invited submission to the journal Current Opinion in Neurobiology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of brain-computer interfaces is poised to advance from the\ntraditional goal of controlling prosthetic devices using brain signals to\ncombining neural decoding and encoding within a single neuroprosthetic device.\nSuch a device acts as a \"co-processor\" for the brain, with applications ranging\nfrom inducing Hebbian plasticity for rehabilitation after brain injury to\nreanimating paralyzed limbs and enhancing memory. We review recent progress in\nsimultaneous decoding and encoding for closed-loop control and plasticity\ninduction. To address the challenge of multi-channel decoding and encoding, we\nintroduce a unifying framework for developing brain co-processors based on\nartificial neural networks and deep learning. These \"neural co-processors\" can\nbe used to jointly optimize cost functions with the nervous system to achieve\ndesired behaviors ranging from targeted neuro-rehabilitation to augmentation of\nbrain function.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 23:13:24 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 18:56:32 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Rao", "Rajesh P. N.", ""]]}, {"id": "1811.12065", "submitter": "Lile Cai", "authors": "Lile Cai, Anne-Maelle Barneche, Arthur Herbout, Chuan Sheng Foo, Jie\n  Lin, Vijay Ramaseshan Chandrasekhar and Mohamed M. Sabry", "title": "TEA-DNN: the Quest for Time-Energy-Accuracy Co-optimized Deep Neural\n  Networks", "comments": "Accepted by ISLPED2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded deep learning platforms have witnessed two simultaneous\nimprovements. First, the accuracy of convolutional neural networks (CNNs) has\nbeen significantly improved through the use of automated neural-architecture\nsearch (NAS) algorithms to determine CNN structure. Second, there has been\nincreasing interest in developing hardware accelerators for CNNs that provide\nimproved inference performance and energy consumption compared to GPUs. Such\nembedded deep learning platforms differ in the amount of compute resources and\nmemory-access bandwidth, which would affect performance and energy consumption\nof CNNs. It is therefore critical to consider the available hardware resources\nin the network architecture search. To this end, we introduce TEA-DNN, a NAS\nalgorithm targeting multi-objective optimization of execution time, energy\nconsumption, and classification accuracy of CNN workloads on embedded\narchitectures. TEA-DNN leverages energy and execution time measurements on\nembedded hardware when exploring the Pareto-optimal curves across accuracy,\nexecution time, and energy consumption and does not require additional effort\nto model the underlying hardware. We apply TEA-DNN for image classification on\nactual embedded platforms (NVIDIA Jetson TX2 and Intel Movidius Neural Compute\nStick). We highlight the Pareto-optimal operating points that emphasize the\nnecessity to explicitly consider hardware characteristics in the search\nprocess. To the best of our knowledge, this is the most comprehensive study of\nPareto-optimal models across a range of hardware platforms using actual\nmeasurements on hardware to obtain objective values.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 11:05:28 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 07:39:19 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Cai", "Lile", ""], ["Barneche", "Anne-Maelle", ""], ["Herbout", "Arthur", ""], ["Foo", "Chuan Sheng", ""], ["Lin", "Jie", ""], ["Chandrasekhar", "Vijay Ramaseshan", ""], ["Sabry", "Mohamed M.", ""]]}, {"id": "1811.12143", "submitter": "Imanol Schlag", "authors": "Imanol Schlag, J\\\"urgen Schmidhuber", "title": "Learning to Reason with Third-Order Tensor Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We combine Recurrent Neural Networks with Tensor Product Representations to\nlearn combinatorial representations of sequential data. This improves symbolic\ninterpretation and systematic generalisation. Our architecture is trained\nend-to-end through gradient descent on a variety of simple natural language\nreasoning tasks, significantly outperforming the latest state-of-the-art models\nin single-task and all-tasks settings. We also augment a subset of the data\nsuch that training and test data exhibit large systematic differences and show\nthat our approach generalises better than the previous state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 13:50:58 GMT"}, {"version": "v2", "created": "Tue, 8 Jan 2019 10:36:24 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Schlag", "Imanol", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1811.12667", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Xinjie Yu", "title": "Improved Crowding Distance for NSGA-II", "comments": "EC course paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-dominated sorting genetic algorithm II (NSGA-II) does well in dealing\nwith multi-objective problems. When evaluating validity of an algorithm for\nmulti-objective problems, two kinds of indices are often considered\nsimultaneously, i.e. the convergence to Pareto Front and the distribution\ncharacteristic. The crowding distance in the standard NSGA-II has the property\nthat solutions within a cubic have the same crowding distance, which has no\ncontribution to the convergence of the algorithm. Actually the closer to the\nPareto Front a solution is, the higher priority it should have. In the paper,\nthe crowding distance is redefined while keeping almost all the advantages of\nthe original one. Moreover, the speed of converging to the Pareto Front is\nfaster. Finally, the improvement is proved to be effective by applying it to\nsolve nine Benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 08:18:05 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Yu", "Xinjie", ""]]}, {"id": "1811.12809", "submitter": "Luis Lamb", "authors": "Felipe Grando and Luis C. Lamb", "title": "Computing Vertex Centrality Measures in Massive Real Networks with a\n  Neural Learning Model", "comments": "8 pages, 5 tables, 2 figures, version accepted at IJCNN 2018. arXiv\n  admin note: text overlap with arXiv:1810.11760", "journal-ref": "IEEE International Joint Conference on Neural Networks, IJCNN\n  2018: 1-8", "doi": "10.1109/IJCNN.2018.8489690", "report-no": null, "categories": "cs.SI cs.LG cs.NE cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vertex centrality measures are a multi-purpose analysis tool, commonly used\nin many application environments to retrieve information and unveil knowledge\nfrom the graphs and network structural properties. However, the algorithms of\nsuch metrics are expensive in terms of computational resources when running\nreal-time applications or massive real world networks. Thus, approximation\ntechniques have been developed and used to compute the measures in such\nscenarios. In this paper, we demonstrate and analyze the use of neural network\nlearning algorithms to tackle such task and compare their performance in terms\nof solution quality and computation time with other techniques from the\nliterature. Our work offers several contributions. We highlight both the pros\nand cons of approximating centralities though neural learning. By empirical\nmeans and statistics, we then show that the regression model generated with a\nfeedforward neural networks trained by the Levenberg-Marquardt algorithm is not\nonly the best option considering computational resources, but also achieves the\nbest solution quality for relevant applications and large-scale networks.\nKeywords: Vertex Centrality Measures, Neural Networks, Complex Network Models,\nMachine Learning, Regression Model\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 03:37:44 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Grando", "Felipe", ""], ["Lamb", "Luis C.", ""]]}, {"id": "1811.12824", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr, Carsten Witt, Jing Yang", "title": "Runtime Analysis for Self-adaptive Mutation Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a self-adaptive version of the $(1,\\lambda)$\nevolutionary algorithm in which the current mutation rate is part of the\nindividual and thus also subject to mutation. A rigorous runtime analysis on\nthe OneMax benchmark function reveals that a simple local mutation scheme for\nthe rate leads to an expected optimization time (number of fitness evaluations)\nof $O(n\\lambda/\\log\\lambda+n\\log n)$ when $\\lambda$ is at least $C \\ln n$ for\nsome constant $C > 0$. For all values of $\\lambda \\ge C \\ln n$, this\nperformance is asymptotically best possible among all $\\lambda$-parallel\nmutation-based unbiased black-box algorithms.\n  Our result shows that self-adaptation in evolutionary computation can find\ncomplex optimal parameter settings on the fly. At the same time, it proves that\na relatively complicated self-adjusting scheme for the mutation rate proposed\nby Doerr, Gie{\\ss}en, Witt, and Yang~(GECCO~2017) can be replaced by our simple\nendogenous scheme.\n  On the technical side, the paper contributes new tools for the analysis of\ntwo-dimensional drift processes arising in the analysis of dynamic parameter\nchoices in EAs, including bounds on occupation probabilities in processes with\nnon-constant drift.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 14:38:05 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Doerr", "Benjamin", ""], ["Witt", "Carsten", ""], ["Yang", "Jing", ""]]}, {"id": "1811.12843", "submitter": "Abdullah Al-Dujaili", "authors": "Tom Schmiedlechner and Ignavier Ng Zhi Yong and Abdullah Al-Dujaili\n  and Erik Hemberg and Una-May O'Reilly", "title": "Lipizzaner: A System That Scales Robust Generative Adversarial Network\n  Training", "comments": "Systems for ML Workshop (MLSYS) at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANs are difficult to train due to convergence pathologies such as mode and\ndiscriminator collapse. We introduce Lipizzaner, an open source software system\nthat allows machine learning engineers to train GANs in a distributed and\nrobust way. Lipizzaner distributes a competitive coevolutionary algorithm\nwhich, by virtue of dual, adapting, generator and discriminator populations, is\nrobust to collapses. The algorithm is well suited to efficient distribution\nbecause it uses a spatial grid abstraction. Training is local to each cell and\nstrong intermediate training results are exchanged among overlapping\nneighborhoods allowing high performing solutions to propagate and improve with\nmore rounds of training. Experiments on common image datasets overcome critical\ncollapses. Communication overhead scales linearly when increasing the number of\ncompute instances and we observe that increasing scale leads to improved model\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 15:23:03 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Schmiedlechner", "Tom", ""], ["Yong", "Ignavier Ng Zhi", ""], ["Al-Dujaili", "Abdullah", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}]