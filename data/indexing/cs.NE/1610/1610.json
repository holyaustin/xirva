[{"id": "1610.00053", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline and Sonia M. Buckley and Richard P. Mirin and Sae\n  Woo Nam", "title": "Superconducting optoelectronic circuits for neuromorphic computing", "comments": "34 pages, 22 figures", "journal-ref": null, "doi": "10.1103/PhysRevApplied.7.034013", "report-no": null, "categories": "cs.NE cond-mat.supr-con physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have proven effective for solving many difficult\ncomputational problems. Implementing complex neural networks in software is\nvery computationally expensive. To explore the limits of information\nprocessing, it will be necessary to implement new hardware platforms with large\nnumbers of neurons, each with a large number of connections to other neurons.\nHere we propose a hybrid semiconductor-superconductor hardware platform for the\nimplementation of neural networks and large-scale neuromorphic computing. The\nplatform combines semiconducting few-photon light-emitting diodes with\nsuperconducting-nanowire single-photon detectors to behave as spiking neurons.\nThese processing units are connected via a network of optical waveguides, and\nvariable weights of connection can be implemented using several approaches. The\nuse of light as a signaling mechanism overcomes fanout and parasitic\nconstraints on electrical signals while simultaneously introducing physical\ndegrees of freedom which can be employed for computation. The use of\nsupercurrents achieves the low power density necessary to scale to systems with\nenormous entropy. The proposed processing units can operate at speeds of at\nleast $20$ MHz with fully asynchronous activity, light-speed-limited latency,\nand power densities on the order of 1 mW/cm$^2$ for neurons with 700\nconnections operating at full speed at 2 K. The processing units achieve an\nenergy efficiency of $\\approx 20$ aJ per synapse event. By leveraging\nmultilayer photonics with deposited waveguides and superconductors with feature\nsizes $>$ 100 nm, this approach could scale to systems with massive\ninterconnectivity and complexity for advanced computing as well as explorations\nof information processing capacity in systems with an enormous number of\ninformation-bearing microstates.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 23:11:00 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 23:17:10 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Shainline", "Jeffrey M.", ""], ["Buckley", "Sonia M.", ""], ["Mirin", "Richard P.", ""], ["Nam", "Sae Woo", ""]]}, {"id": "1610.00087", "submitter": "Wei Dai", "authors": "Wei Dai, Chia Dai, Shuhui Qu, Juncheng Li, Samarjit Das", "title": "Very Deep Convolutional Neural Networks for Raw Waveforms", "comments": "5 pages, 2 figures, under submission to International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning acoustic models directly from the raw waveform data with minimal\nprocessing is challenging. Current waveform-based models have generally used\nvery few (~2) convolutional layers, which might be insufficient for building\nhigh-level discriminative features. In this work, we propose very deep\nconvolutional neural networks (CNNs) that directly use time-domain waveforms as\ninputs. Our CNNs, with up to 34 weight layers, are efficient to optimize over\nvery long sequences (e.g., vector of size 32000), necessary for processing\nacoustic waveforms. This is achieved through batch normalization, residual\nlearning, and a careful design of down-sampling in the initial layers. Our\nnetworks are fully convolutional, without the use of fully connected layers and\ndropout, to maximize representation learning. We use a large receptive field in\nthe first convolutional layer to mimic bandpass filters, but very small\nreceptive fields subsequently to control the model capacity. We demonstrate the\nperformance gains with the deeper models. Our evaluation shows that the CNN\nwith 18 weight layers outperform the CNN with 3 weight layers by over 15% in\nabsolute accuracy for an environmental sound recognition task and matches the\nperformance of models using log-mel features.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 05:15:15 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Dai", "Wei", ""], ["Dai", "Chia", ""], ["Qu", "Shuhui", ""], ["Li", "Juncheng", ""], ["Das", "Samarjit", ""]]}, {"id": "1610.00324", "submitter": "Ganesh Venkatesh", "authors": "Ganesh Venkatesh, Eriko Nurvitadhi, Debbie Marr", "title": "Accelerating Deep Convolutional Networks using low-precision and\n  sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore techniques to significantly improve the compute efficiency and\nperformance of Deep Convolution Networks without impacting their accuracy. To\nimprove the compute efficiency, we focus on achieving high accuracy with\nextremely low-precision (2-bit) weight networks, and to accelerate the\nexecution time, we aggressively skip operations on zero-values. We achieve the\nhighest reported accuracy of 76.6% Top-1/93% Top-5 on the Imagenet object\nclassification challenge with low-precision network\\footnote{github release of\nthe source code coming soon} while reducing the compute requirement by ~3x\ncompared to a full-precision network that achieves similar accuracy.\nFurthermore, to fully exploit the benefits of our low-precision networks, we\nbuild a deep learning accelerator core, dLAC, that can achieve up to 1\nTFLOP/mm^2 equivalent for single-precision floating-point operations (~2\nTFLOP/mm^2 for half-precision).\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 17:59:31 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Venkatesh", "Ganesh", ""], ["Nurvitadhi", "Eriko", ""], ["Marr", "Debbie", ""]]}, {"id": "1610.00369", "submitter": "Asif Hassan", "authors": "A. Hassan, M. R. Amin, N. Mohammed, A. K. A. Azad", "title": "Sentiment Analysis on Bangla and Romanized Bangla Text (BRBT) using Deep\n  Recurrent models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment Analysis (SA) is an action research area in the digital age. With\nrapid and constant growth of online social media sites and services, and the\nincreasing amount of textual data such as - statuses, comments, reviews etc.\navailable in them, application of automatic SA is on the rise. However, most of\nthe research works on SA in natural language processing (NLP) are based on\nEnglish language. Despite being the sixth most widely spoken language in the\nworld, Bangla still does not have a large and standard dataset. Because of\nthis, recent research works in Bangla have failed to produce results that can\nbe both comparable to works done by others and reusable as stepping stones for\nfuture researchers to progress in this field. Therefore, we first tried to\nprovide a textual dataset - that includes not just Bangla, but Romanized Bangla\ntexts as well, is substantial, post-processed and multiple validated, ready to\nbe used in SA experiments. We tested this dataset in Deep Recurrent model,\nspecifically, Long Short Term Memory (LSTM), using two types of loss functions\n- binary crossentropy and categorical crossentropy, and also did some\nexperimental pre-training by using data from one validation to pre-train the\nother and vice versa. Lastly, we documented the results along with some\nanalysis on them, which were promising.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 23:45:23 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 02:13:05 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Hassan", "A.", ""], ["Amin", "M. R.", ""], ["Mohammed", "N.", ""], ["Azad", "A. K. A.", ""]]}, {"id": "1610.00790", "submitter": "Charles Siegel", "authors": "Charles Siegel, Jeff Daily, Abhinav Vishnu", "title": "Adaptive Neuron Apoptosis for Accelerating Deep Learning on Large Scale\n  Systems", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present novel techniques to accelerate the convergence of Deep Learning\nalgorithms by conducting low overhead removal of redundant neurons -- apoptosis\nof neurons -- which do not contribute to model learning, during the training\nphase itself. We provide in-depth theoretical underpinnings of our heuristics\n(bounding accuracy loss and handling apoptosis of several neuron types), and\npresent the methods to conduct adaptive neuron apoptosis. Specifically, we are\nable to improve the training time for several datasets by 2-3x, while reducing\nthe number of parameters by up to 30x (4-5x on average) on datasets such as\nImageNet classification. For the Higgs Boson dataset, our implementation\nimproves the accuracy (measured by Area Under Curve (AUC)) for classification\nfrom 0.88/1 to 0.94/1, while reducing the number of parameters by 3x in\ncomparison to existing literature. The proposed methods achieve a 2.44x speedup\nin comparison to the default (no apoptosis) algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 23:23:34 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Siegel", "Charles", ""], ["Daily", "Jeff", ""], ["Vishnu", "Abhinav", ""]]}, {"id": "1610.00956", "submitter": "Ondrej Bajgar", "authors": "Ondrej Bajgar, Rudolf Kadlec and Jan Kleindienst", "title": "Embracing data abundance: BookTest Dataset for Reading Comprehension", "comments": "The first two authors contributed equally to this work. Submitted to\n  EACL 2017. Code and dataset are publicly available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a practically unlimited amount of natural language data available.\nStill, recent work in text comprehension has focused on datasets which are\nsmall relative to current computing possibilities. This article is making a\ncase for the community to move to larger data and as a step in that direction\nit is proposing the BookTest, a new dataset similar to the popular Children's\nBook Test (CBT), however more than 60 times larger. We show that training on\nthe new data improves the accuracy of our Attention-Sum Reader model on the\noriginal CBT test data by a much larger margin than many recent attempts to\nimprove the model architecture. On one version of the dataset our ensemble even\nexceeds the human baseline provided by Facebook. We then show in our own human\nstudy that there is still space for further improvement.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 12:48:51 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Bajgar", "Ondrej", ""], ["Kadlec", "Rudolf", ""], ["Kleindienst", "Jan", ""]]}, {"id": "1610.01076", "submitter": "Mateusz Malinowski", "authors": "Mateusz Malinowski and Mario Fritz", "title": "Tutorial on Answering Questions about Images with Deep Learning", "comments": "The tutorial was presented at '2nd Summer School on Integrating\n  Vision and Language: Deep Learning' in Malta, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Together with the development of more accurate methods in Computer Vision and\nNatural Language Understanding, holistic architectures that answer on questions\nabout the content of real-world images have emerged. In this tutorial, we build\na neural-based approach to answer questions about images. We base our tutorial\non two datasets: (mostly on) DAQUAR, and (a bit on) VQA. With small tweaks the\nmodels that we present here can achieve a competitive performance on both\ndatasets, in fact, they are among the best methods that use a combination of\nLSTM with a global, full frame CNN representation of an image. We hope that\nafter reading this tutorial, the reader will be able to use Deep Learning\nframeworks, such as Keras and introduced Kraino, to build various architectures\nthat will lead to a further performance improvement on this challenging task.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 16:29:28 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Malinowski", "Mateusz", ""], ["Fritz", "Mario", ""]]}, {"id": "1610.01145", "submitter": "Dmitry Yarotsky", "authors": "Dmitry Yarotsky", "title": "Error bounds for approximations with deep ReLU networks", "comments": "31 pages; major revision in v3; submitted to Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study expressive power of shallow and deep neural networks with piece-wise\nlinear activation functions. We establish new rigorous upper and lower bounds\nfor the network complexity in the setting of approximations in Sobolev spaces.\nIn particular, we prove that deep ReLU networks more efficiently approximate\nsmooth functions than shallow networks. In the case of approximations of 1D\nLipschitz functions we describe adaptive depth-6 network architectures more\nefficient than the standard shallow architecture.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 23:08:22 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 16:57:35 GMT"}, {"version": "v3", "created": "Mon, 1 May 2017 14:01:32 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Yarotsky", "Dmitry", ""]]}, {"id": "1610.01407", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis (LORIA, LARSEN), Antoine Cully,\n  Jean-Baptiste Mouret (LORIA, LARSEN)", "title": "Towards semi-episodic learning for robot damage recovery", "comments": "Workshop on AI for Long-Term Autonomy at the IEEE International\n  Conference on Robotics and Automation (ICRA), May 2016, Stockholm, Sweden.\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced Intelligent Trial and Error algorithm (IT\\&E) enables\nrobots to creatively adapt to damage in a matter of minutes by combining an\noff-line evolutionary algorithm and an on-line learning algorithm based on\nBayesian Optimization. We extend the IT\\&E algorithm to allow for robots to\nlearn to compensate for damages while executing their task(s). This leads to a\nsemi-episodic learning scheme that increases the robot's lifetime autonomy and\nadaptivity. Preliminary experiments on a toy simulation and a 6-legged robot\nlocomotion task show promising results.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 13:21:43 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", "", "LORIA, LARSEN"], ["Cully", "Antoine", "", "LORIA, LARSEN"], ["Mouret", "Jean-Baptiste", "", "LORIA, LARSEN"]]}, {"id": "1610.01430", "submitter": "Roberto Paredes", "authors": "Roberto Paredes and Jos\\'e-Miguel Bened\\'i", "title": "LAYERS: Yet another Neural Network toolkit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layers is an open source neural network toolkit aim at providing an easy way\nto implement modern neural networks. The main user target are students and to\nthis end layers provides an easy scriptting language that can be early adopted.\nThe user has to focus only on design details as network totpology and parameter\ntunning.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 14:14:51 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 13:28:41 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Paredes", "Roberto", ""], ["Bened\u00ed", "Jos\u00e9-Miguel", ""]]}, {"id": "1610.01439", "submitter": "Olalekan Ogunmolu", "authors": "Olalekan Ogunmolu, Xuejun Gu, Steve Jiang, and Nicholas Gans", "title": "Nonlinear Systems Identification Using Deep Dynamic Neural Networks", "comments": "American Control Conference, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural networks are known to be effective function approximators. Recently,\ndeep neural networks have proven to be very effective in pattern recognition,\nclassification tasks and human-level control to model highly nonlinear\nrealworld systems. This paper investigates the effectiveness of deep neural\nnetworks in the modeling of dynamical systems with complex behavior. Three deep\nneural network structures are trained on sequential data, and we investigate\nthe effectiveness of these networks in modeling associated characteristics of\nthe underlying dynamical systems. We carry out similar evaluations on select\npublicly available system identification datasets. We demonstrate that deep\nneural networks are effective model estimators from input-output data\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 14:26:27 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Ogunmolu", "Olalekan", ""], ["Gu", "Xuejun", ""], ["Jiang", "Steve", ""], ["Gans", "Nicholas", ""]]}, {"id": "1610.01549", "submitter": "Anthony Caterini", "authors": "Anthony Caterini and Dong Eui Chang", "title": "A Novel Representation of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have become very popular for prediction in many\nareas. Their strength is in representation with a high number of parameters\nthat are commonly learned via gradient descent or similar optimization methods.\nHowever, the representation is non-standardized, and the gradient calculation\nmethods are often performed using component-based approaches that break\nparameters down into scalar units, instead of considering the parameters as\nwhole entities. In this work, these problems are addressed. Standard notation\nis used to represent DNNs in a compact framework. Gradients of DNN loss\nfunctions are calculated directly over the inner product space on which the\nparameters are defined. This framework is general and is applied to two common\nnetwork types: the Multilayer Perceptron and the Deep Autoencoder.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 18:06:44 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 21:31:13 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Caterini", "Anthony", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1610.01741", "submitter": "Mohamad Ivan Fanany", "authors": "Endang Purnama Giri, Mohamad Ivan Fanany, Aniati Murni Arymurthy", "title": "Combining Generative and Discriminative Neural Networks for Sleep Stages\n  Classification", "comments": "Submitted to Computational Intelligence and Neuroscience (Hindawi\n  Publishing). 13 pages", "journal-ref": null, "doi": null, "report-no": "3184843", "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep stages pattern provides important clues in diagnosing the presence of\nsleep disorder. By analyzing sleep stages pattern and extracting its features\nfrom EEG, EOG, and EMG signals, we can classify sleep stages. This study\npresents a novel classification model for predicting sleep stages with a high\naccuracy. The main idea is to combine the generative capability of Deep Belief\nNetwork (DBN) with a discriminative ability and sequence pattern recognizing\ncapability of Long Short-term Memory (LSTM). We use DBN that is treated as an\nautomatic higher level features generator. The input to DBN is 28 \"handcrafted\"\nfeatures as used in previous sleep stages studies. We compared our method with\nother techniques which combined DBN with Hidden Markov Model (HMM).In this\nstudy, we exploit the sequence or time series characteristics of sleep dataset.\nTo the best of our knowledge, most of the present sleep analysis from\npolysomnogram relies only on single instanced label (nonsequence) for\nclassification. In this study, we used two datasets: an open data set that is\ntreated as a benchmark; the other dataset is our sleep stages dataset\n(available for download) to verify the results further. Our experiments showed\nthat the combination of DBN with LSTM gives better overall accuracy 98.75\\%\n(Fscore=0.9875) for benchmark dataset and 98.94\\% (Fscore=0.9894) for MKG\ndataset. This result is better than the state of the art of sleep stages\nclassification that was 91.31\\%.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 06:05:16 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Giri", "Endang Purnama", ""], ["Fanany", "Mohamad Ivan", ""], ["Arymurthy", "Aniati Murni", ""]]}, {"id": "1610.01757", "submitter": "Mohamad Ivan Fanany", "authors": "Endang Purnama Giri, Mohamad Ivan Fanany, Aniati Murni Arymurthy", "title": "Ischemic Stroke Identification Based on EEG and EOG using 1D\n  Convolutional Neural Network and Batch Normalization", "comments": "13 pages. To be published in ICACSIS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, stroke was the number one cause of death in Indonesia. The majority\ntype of stroke is ischemic. The standard tool for diagnosing stroke is CT-Scan.\nFor developing countries like Indonesia, the availability of CT-Scan is very\nlimited and still relatively expensive. Because of the availability, another\ndevice that potential to diagnose stroke in Indonesia is EEG. Ischemic stroke\noccurs because of obstruction that can make the cerebral blood flow (CBF) on a\nperson with stroke has become lower than CBF on a normal person (control) so\nthat the EEG signal have a deceleration. On this study, we perform the ability\nof 1D Convolutional Neural Network (1DCNN) to construct classification model\nthat can distinguish the EEG and EOG stroke data from EEG and EOG control data.\nTo accelerate training process our model we use Batch Normalization. Involving\n62 person data object and from leave one out the scenario with five times\nrepetition of measurement we obtain the average of accuracy 0.86 (F-Score\n0.861) only at 200 epoch. This result is better than all over shallow and\npopular classifiers as the comparator (the best result of accuracy 0.69 and\nF-Score 0.72 ). The feature used in our study were only 24 handcrafted feature\nwith simple feature extraction process.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 07:19:27 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Giri", "Endang Purnama", ""], ["Fanany", "Mohamad Ivan", ""], ["Arymurthy", "Aniati Murni", ""]]}, {"id": "1610.01795", "submitter": "Mohamad Ivan Fanany", "authors": "Ines Heidieni Ikasari, Vina Ayumi, Mohamad Ivan Fanany, Sidik Mulyono", "title": "Multiple Regularizations Deep Learning for Paddy Growth Stages\n  Classification from LANDSAT-8", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study uses remote sensing technology that can provide information about\nthe condition of the earth's surface area, fast, and spatially. The study area\nwas in Karawang District, lying in the Northern part of West Java-Indonesia. We\naddress a paddy growth stages classification using LANDSAT 8 image data\nobtained from multi-sensor remote sensing image taken in October 2015 to August\n2016. This study pursues a fast and accurate classification of paddy growth\nstages by employing multiple regularizations learning on some deep learning\nmethods such as DNN (Deep Neural Networks) and 1-D CNN (1-D Convolutional\nNeural Networks). The used regularizations are Fast Dropout, Dropout, and Batch\nNormalization. To evaluate the effectiveness, we also compared our method with\nother machine learning methods such as (Logistic Regression, SVM, Random\nForest, and XGBoost). The data used are seven bands of LANDSAT-8 spectral data\nsamples that correspond to paddy growth stages data obtained from i-Sky (eye in\nthe sky) Innovation system. The growth stages are determined based on paddy\ncrop phenology profile from time series of LANDSAT-8 images. The classification\nresults show that MLP using multiple regularization Dropout and Batch\nNormalization achieves the highest accuracy for this dataset.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 09:46:08 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Ikasari", "Ines Heidieni", ""], ["Ayumi", "Vina", ""], ["Fanany", "Mohamad Ivan", ""], ["Mulyono", "Sidik", ""]]}, {"id": "1610.01891", "submitter": "Mohamad Ivan Fanany", "authors": "Sadikin Mujiono, Mohamad Ivan Fanany, Chan Basaruddin", "title": "A New Data Representation Based on Training Data Characteristics to\n  Extract Drug Named-Entity in Medical Text", "comments": "Hindawi Publishing. Computational Intelligence and Neuroscience\n  Volume 2016 (2016), Article ID 3483528, 24 pages Received 27 May 2016;\n  Revised 8 August 2016; Accepted 18 September 2016. Special Issue on \"Smart\n  Data: Where the Big Data Meets the Semantics\". Academic Editor: Trong H.\n  Duong", "journal-ref": "Computational Intelligence and Neuroscience Volume 2016 (2016),\n  Article ID 3483528, 24 pages", "doi": null, "report-no": "3483528", "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One essential task in information extraction from the medical corpus is drug\nname recognition. Compared with text sources come from other domains, the\nmedical text is special and has unique characteristics. In addition, the\nmedical text mining poses more challenges, e.g., more unstructured text, the\nfast growing of new terms addition, a wide range of name variation for the same\ndrug. The mining is even more challenging due to the lack of labeled dataset\nsources and external knowledge, as well as multiple token representations for a\nsingle drug name that is more common in the real application setting. Although\nmany approaches have been proposed to overwhelm the task, some problems\nremained with poor F-score performance (less than 0.75). This paper presents a\nnew treatment in data representation techniques to overcome some of those\nchallenges. We propose three data representation techniques based on the\ncharacteristics of word distribution and word similarities as a result of word\nembedding training. The first technique is evaluated with the standard NN\nmodel, i.e., MLP (Multi-Layer Perceptrons). The second technique involves two\ndeep network classifiers, i.e., DBN (Deep Belief Networks), and SAE (Stacked\nDenoising Encoders). The third technique represents the sentence as a sequence\nthat is evaluated with a recurrent NN model, i.e., LSTM (Long Short Term\nMemory). In extracting the drug name entities, the third technique gives the\nbest F-score performance compared to the state of the art, with its average\nF-score being 0.8645.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 14:38:09 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Mujiono", "Sadikin", ""], ["Fanany", "Mohamad Ivan", ""], ["Basaruddin", "Chan", ""]]}, {"id": "1610.01922", "submitter": "Mohamad Ivan Fanany", "authors": "Arif Budiman, Mohamad Ivan Fanany, Chan Basaruddin", "title": "Adaptive Online Sequential ELM for Concept Drift Tackling", "comments": "Hindawi Publishing. Computational Intelligence and Neuroscience\n  Volume 2016 (2016), Article ID 8091267, 17 pages Received 29 January 2016,\n  Accepted 17 May 2016. Special Issue on \"Advances in Neural Networks and\n  Hybrid-Metaheuristics: Theory, Algorithms, and Novel Engineering\n  Applications\". Academic Editor: Stefan Haufe", "journal-ref": "Computational Intelligence and Neuroscience Volume 2016 (2016),\n  Article ID 8091267, 17 pages", "doi": "10.1155/2016/8091267", "report-no": "8091267", "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A machine learning method needs to adapt to over time changes in the\nenvironment. Such changes are known as concept drift. In this paper, we propose\nconcept drift tackling method as an enhancement of Online Sequential Extreme\nLearning Machine (OS-ELM) and Constructive Enhancement OS-ELM (CEOS-ELM) by\nadding adaptive capability for classification and regression problem. The\nscheme is named as adaptive OS-ELM (AOS-ELM). It is a single classifier scheme\nthat works well to handle real drift, virtual drift, and hybrid drift. The\nAOS-ELM also works well for sudden drift and recurrent context change type. The\nscheme is a simple unified method implemented in simple lines of code. We\nevaluated AOS-ELM on regression and classification problem by using concept\ndrift public data set (SEA and STAGGER) and other public data sets such as\nMNIST, USPS, and IDS. Experiments show that our method gives higher kappa value\ncompared to the multiclassifier ELM ensemble. Even though AOS-ELM in practice\ndoes not need hidden nodes increase, we address some issues related to the\nincreasing of the hidden nodes such as error condition and rank values. We\npropose taking the rank of the pseudoinverse matrix as an indicator parameter\nto detect underfitting condition.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 16:08:52 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Budiman", "Arif", ""], ["Fanany", "Mohamad Ivan", ""], ["Basaruddin", "Chan", ""]]}, {"id": "1610.01925", "submitter": "Mohamad Ivan Fanany", "authors": "L. M. Rasdi Rere, Mohamad Ivan Fanany, and Aniati Murni Arymurthy", "title": "Metaheuristic Algorithms for Convolution Neural Network", "comments": "Article ID 1537325, 13 pages. Received 29 January 2016; Revised 15\n  April 2016; Accepted 10 May 2016. Academic Editor: Martin Hagan. in Hindawi\n  Publishing. Computational Intelligence and Neuroscience Volume 2016 (2016)", "journal-ref": "Computational Intelligence and Neuroscience Volume 2016 (2016),\n  Article ID 1537325, 13 pages", "doi": "10.1155/2016/1537325", "report-no": "1537325", "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical modern optimization technique is usually either heuristic or\nmetaheuristic. This technique has managed to solve some optimization problems\nin the research area of science, engineering, and industry. However,\nimplementation strategy of metaheuristic for accuracy improvement on\nconvolution neural networks (CNN), a famous deep learning method, is still\nrarely investigated. Deep learning relates to a type of machine learning\ntechnique, where its aim is to move closer to the goal of artificial\nintelligence of creating a machine that could successfully perform any\nintellectual tasks that can be carried out by a human. In this paper, we\npropose the implementation strategy of three popular metaheuristic approaches,\nthat is, simulated annealing, differential evolution, and harmony search, to\noptimize CNN. The performances of these metaheuristic methods in optimizing CNN\non classifying MNIST and CIFAR dataset were evaluated and compared.\nFurthermore, the proposed methods are also compared with the original CNN.\nAlthough the proposed methods show an increase in the computation time, their\naccuracy has also been improved (up to 7.14 percent).\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 16:11:06 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Rere", "L. M. Rasdi", ""], ["Fanany", "Mohamad Ivan", ""], ["Arymurthy", "Aniati Murni", ""]]}, {"id": "1610.01935", "submitter": "Mohamad Ivan Fanany", "authors": "Intan Nurma Yulita, Mohamad Ivan Fanany, Aniati Murni Arymurthy", "title": "Sequence-based Sleep Stage Classification using Conditional Neural\n  Fields", "comments": "14 pages. Submitted to Computational and Mathematical Methods in\n  Medicine (Hindawi Publishin). Article ID 7163687", "journal-ref": null, "doi": null, "report-no": "7163687", "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep signals from a polysomnographic database are sequences in nature.\nCommonly employed analysis and classification methods, however, ignored this\nfact and treated the sleep signals as non-sequence data. Treating the sleep\nsignals as sequences, this paper compared two powerful unsupervised feature\nextractors and three sequence-based classifiers regarding accuracy and\ncomputational (training and testing) time after 10-folds cross-validation. The\ncompared feature extractors are Deep Belief Networks (DBN) and Fuzzy C-Means\n(FCM) clustering. Whereas the compared sequence-based classifiers are Hidden\nMarkov Models (HMM), Conditional Random Fields (CRF) and its variants, i.e.,\nHidden-state CRF (HCRF) and Latent-Dynamic CRF (LDCRF); and Conditional Neural\nFields (CNF) and its variant (LDCNF). In this study, we use two datasets. The\nfirst dataset is an open (public) polysomnographic dataset downloadable from\nthe Internet, while the second dataset is our polysomnographic dataset (also\navailable for download). For the first dataset, the combination of FCM and CNF\ngives the highest accuracy (96.75\\%) with relatively short training time (0.33\nhours). For the second dataset, the combination of DBN and CRF gives the\naccuracy of 99.96\\% but with 1.02 hours training time, whereas the combination\nof DBN and CNF gives slightly less accuracy (99.69\\%) but also less computation\ntime (0.89 hours).\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 16:26:58 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Yulita", "Intan Nurma", ""], ["Fanany", "Mohamad Ivan", ""], ["Arymurthy", "Aniati Murni", ""]]}, {"id": "1610.01989", "submitter": "Sakyasingha Dasgupta", "authors": "Sakyasingha Dasgupta and Takayuki Yoshizumi and Takayuki Osogami", "title": "Regularized Dynamic Boltzmann Machine with Delay Pruning for\n  Unsupervised Learning of Temporal Sequences", "comments": "6 pages, 5 figures, accepted full paper (oral presentation) at ICPR\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Delay Pruning, a simple yet powerful technique to regularize\ndynamic Boltzmann machines (DyBM). The recently introduced DyBM provides a\nparticularly structured Boltzmann machine, as a generative model of a\nmulti-dimensional time-series. This Boltzmann machine can have infinitely many\nlayers of units but allows exact inference and learning based on its\nbiologically motivated structure. DyBM uses the idea of conduction delays in\nthe form of fixed length first-in first-out (FIFO) queues, with a neuron\nconnected to another via this FIFO queue, and spikes from a pre-synaptic neuron\ntravel along the queue to the post-synaptic neuron with a constant period of\ndelay. Here, we present Delay Pruning as a mechanism to prune the lengths of\nthe FIFO queues (making them zero) by setting some delay lengths to one with a\nfixed probability, and finally selecting the best performing model with fixed\ndelays. The uniqueness of structure and a non-sampling based learning rule in\nDyBM, make the application of previously proposed regularization techniques\nlike Dropout or DropConnect difficult, leading to poor generalization. First,\nwe evaluate the performance of Delay Pruning to let DyBM learn a\nmultidimensional temporal sequence generated by a Markov chain. Finally, we\nshow the effectiveness of delay pruning in learning high dimensional sequences\nusing the moving MNIST dataset, and compare it with Dropout and DropConnect\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 10:04:59 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Dasgupta", "Sakyasingha", ""], ["Yoshizumi", "Takayuki", ""], ["Osogami", "Takayuki", ""]]}, {"id": "1610.02084", "submitter": "Cameron Musco", "authors": "Nancy Lynch, Cameron Musco, Merav Parter", "title": "Computational Tradeoffs in Biological Neural Networks: Self-Stabilizing\n  Winner-Take-All Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a line of investigation into biological neural networks from an\nalgorithmic perspective. We develop a simplified but biologically plausible\nmodel for distributed computation in stochastic spiking neural networks and\nstudy tradeoffs between computation time and network complexity in this model.\nOur aim is to abstract real neural networks in a way that, while not capturing\nall interesting features, preserves high-level behavior and allows us to make\nbiologically relevant conclusions.\n  In this paper, we focus on the important `winner-take-all' (WTA) problem,\nwhich is analogous to a neural leader election unit: a network consisting of\n$n$ input neurons and $n$ corresponding output neurons must converge to a state\nin which a single output corresponding to a firing input (the `winner') fires,\nwhile all other outputs remain silent. Neural circuits for WTA rely on\ninhibitory neurons, which suppress the activity of competing outputs and drive\nthe network towards a converged state with a single firing winner. We attempt\nto understand how the number of inhibitors used affects network convergence\ntime.\n  We show that it is possible to significantly outperform naive WTA\nconstructions through a more refined use of inhibition, solving the problem in\n$O(\\theta)$ rounds in expectation with just $O(\\log^{1/\\theta} n)$ inhibitors\nfor any $\\theta$. An alternative construction gives convergence in\n$O(\\log^{1/\\theta} n)$ rounds with $O(\\theta)$ inhibitors. We compliment these\nupper bounds with our main technical contribution, a nearly matching lower\nbound for networks using $\\ge \\log\\log n$ inhibitors. Our lower bound uses\nfamiliar indistinguishability and locality arguments from distributed computing\ntheory. It lets us derive a number of interesting conclusions about the\nstructure of any network solving WTA with good probability, and the use of\nrandomness and inhibition within such a network.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 21:56:38 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Lynch", "Nancy", ""], ["Musco", "Cameron", ""], ["Parter", "Merav", ""]]}, {"id": "1610.02136", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks and Kevin Gimpel", "title": "A Baseline for Detecting Misclassified and Out-of-Distribution Examples\n  in Neural Networks", "comments": "Published as a conference paper at ICLR 2017. 1 Figure in 1 Appendix.\n  Minor changes from the previous version", "journal-ref": "International Conference on Learning Representations 2017", "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the two related problems of detecting if an example is\nmisclassified or out-of-distribution. We present a simple baseline that\nutilizes probabilities from softmax distributions. Correctly classified\nexamples tend to have greater maximum softmax probabilities than erroneously\nclassified and out-of-distribution examples, allowing for their detection. We\nassess performance by defining several tasks in computer vision, natural\nlanguage processing, and automatic speech recognition, showing the\neffectiveness of this baseline across all. We then show the baseline can\nsometimes be surpassed, demonstrating the room for future research on these\nunderexplored detection tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 04:06:01 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 18:11:25 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 07:32:57 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Hendrycks", "Dan", ""], ["Gimpel", "Kevin", ""]]}, {"id": "1610.02242", "submitter": "Samuli Laine", "authors": "Samuli Laine, Timo Aila", "title": "Temporal Ensembling for Semi-Supervised Learning", "comments": "Final ICLR 2017 version. Includes new results for CIFAR-100 with\n  additional unlabeled data from Tiny Images dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a simple and efficient method for training deep\nneural networks in a semi-supervised setting where only a small portion of\ntraining data is labeled. We introduce self-ensembling, where we form a\nconsensus prediction of the unknown labels using the outputs of the\nnetwork-in-training on different epochs, and most importantly, under different\nregularization and input augmentation conditions. This ensemble prediction can\nbe expected to be a better predictor for the unknown labels than the output of\nthe network at the most recent training epoch, and can thus be used as a target\nfor training. Using our method, we set new records for two standard\nsemi-supervised learning benchmarks, reducing the (non-augmented)\nclassification error rate from 18.44% to 7.05% in SVHN with 500 labels and from\n18.63% to 16.55% in CIFAR-10 with 4000 labels, and further to 5.12% and 12.16%\nby enabling the standard augmentations. We additionally obtain a clear\nimprovement in CIFAR-100 classification accuracy by using random images from\nthe Tiny Images dataset as unlabeled extra inputs during training. Finally, we\ndemonstrate good tolerance to incorrect labels.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 12:15:42 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 13:27:40 GMT"}, {"version": "v3", "created": "Wed, 15 Mar 2017 14:22:41 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Laine", "Samuli", ""], ["Aila", "Timo", ""]]}, {"id": "1610.02348", "submitter": "Mohamad Ivan Fanany", "authors": "Arif Budiman, Mohamad Ivan Fanany, Chan Basaruddin", "title": "Adaptive Convolutional ELM For Concept Drift Handling in Online Stream\n  Data", "comments": "Submitted to IEEE Transactions on Systems, Man and Cybernetics:\n  Systems. Special Issue on Efficient and Rapid Machine Learning Algorithms for\n  Big Data and Dynamic Varying Systems", "journal-ref": null, "doi": null, "report-no": "SMCA-16-09-1038", "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In big data era, the data continuously generated and its distribution may\nkeep changes overtime. These challenges in online stream of data are known as\nconcept drift. In this paper, we proposed the Adaptive Convolutional ELM method\n(ACNNELM) as enhancement of Convolutional Neural Network (CNN) with a hybrid\nExtreme Learning Machine (ELM) model plus adaptive capability. This method is\naimed for concept drift handling. We enhanced the CNN as convolutional\nhiererchical features representation learner combined with Elastic ELM\n(E$^2$LM) as a parallel supervised classifier. We propose an Adaptive OS-ELM\n(AOS-ELM) for concept drift adaptability in classifier level (named ACNNELM-1)\nand matrices concatenation ensembles for concept drift adaptability in ensemble\nlevel (named ACNNELM-2). Our proposed Adaptive CNNELM is flexible that works\nwell in classifier level and ensemble level while most current methods only\nproposed to work on either one of the levels.\n  We verified our method in extended MNIST data set and not MNIST data set. We\nset the experiment to simulate virtual drift, real drift, and hybrid drift\nevent and we demonstrated how our CNNELM adaptability works. Our proposed\nmethod works well and gives better accuracy, computation scalability, and\nconcept drifts adaptability compared to the regular ELM and CNN. Further\nresearches are still required to study the optimum parameters and to use more\nvaried image data set.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 16:53:09 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Budiman", "Arif", ""], ["Fanany", "Mohamad Ivan", ""], ["Basaruddin", "Chan", ""]]}, {"id": "1610.02454", "submitter": "Scott Reed", "authors": "Scott Reed, Zeynep Akata, Santosh Mohan, Samuel Tenka, Bernt Schiele,\n  Honglak Lee", "title": "Learning What and Where to Draw", "comments": "In NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have recently demonstrated the\ncapability to synthesize compelling real-world images, such as room interiors,\nalbum covers, manga, faces, birds, and flowers. While existing models can\nsynthesize images based on global constraints such as a class label or caption,\nthey do not provide control over pose or object location. We propose a new\nmodel, the Generative Adversarial What-Where Network (GAWWN), that synthesizes\nimages given instructions describing what content to draw in which location. We\nshow high-quality 128 x 128 image synthesis on the Caltech-UCSD Birds dataset,\nconditioned on both informal text descriptions and also object location. Our\nsystem exposes control over both the bounding box around the bird and its\nconstituent parts. By modeling the conditional distributions over part\nlocations, our system also enables conditioning on arbitrary subsets of parts\n(e.g. only the beak and tail), yielding an efficient interface for picking part\nlocations. We also show preliminary results on the more challenging domain of\ntext- and location-controllable synthesis of images of human actions on the\nMPII Human Pose dataset.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 00:27:57 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Reed", "Scott", ""], ["Akata", "Zeynep", ""], ["Mohan", "Santosh", ""], ["Tenka", "Samuel", ""], ["Schiele", "Bernt", ""], ["Lee", "Honglak", ""]]}, {"id": "1610.02478", "submitter": "Liane Gabora", "authors": "Graeme McCaig, Steve DiPaola, and Liane Gabora", "title": "Deep Convolutional Networks as Models of Generalization and Blending\n  Within Visual Creativity", "comments": "8 pages, In Proceedings of the 7th International Conference on\n  Computational Creativity. Palo Alto: Association for the Advancement of\n  Artificial Intelligence (AAAI) Press (2016)", "journal-ref": "In Proceedings of the 7th International Conference on\n  Computational Creativity (pp. 156-163). Palo Alto, CA: Association for the\n  Advancement of Artificial Intelligence (AAAI) Press. (2016)", "doi": null, "report-no": null, "categories": "cs.NE cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine two recent artificial intelligence (AI) based deep learning\nalgorithms for visual blending in convolutional neural networks (Mordvintsev et\nal. 2015, Gatys et al. 2015). To investigate the potential value of these\nalgorithms as tools for computational creativity research, we explain and\nschematize the essential aspects of the algorithms' operation and give visual\nexamples of their output. We discuss the relationship of the two algorithms to\nhuman cognitive science theories of creativity such as conceptual blending\ntheory and honing theory, and characterize the algorithms with respect to\ngeneration of novelty and aesthetic quality.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 04:15:26 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 21:02:30 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["McCaig", "Graeme", ""], ["DiPaola", "Steve", ""], ["Gabora", "Liane", ""]]}, {"id": "1610.02732", "submitter": "Matthew Hughes", "authors": "Matthew Hughes", "title": "Investigating the effects Diversity Mechanisms have on Evolutionary\n  Algorithms in Dynamic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms have been successfully applied to a variety of\noptimisation problems in stationary environments. However, many real world\noptimisation problems are set in dynamic environments where the success\ncriteria shifts regularly. Population diversity affects algorithmic\nperformance, particularly on multiobjective and dynamic problems. Diversity\nmechanisms are methods of altering evolutionary algorithms in a way that\npromotes the maintenance of population diversity. This project intends to\nmeasure and compare the performance effect a variety of diversity mechanisms\nhave on an evolutionary algorithm when facing an assortment of dynamic\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2016 22:16:32 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Hughes", "Matthew", ""]]}, {"id": "1610.03165", "submitter": "Xiangang Li", "authors": "Xiangang Li and Xihong Wu", "title": "Long Short-Term Memory based Convolutional Recurrent Neural Networks for\n  Large Vocabulary Speech Recognition", "comments": "Published in INTERSPEECH 2015, September 6-10, 2015, Dresden, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long short-term memory (LSTM) recurrent neural networks (RNNs) have been\nshown to give state-of-the-art performance on many speech recognition tasks, as\nthey are able to provide the learned dynamically changing contextual window of\nall sequence history. On the other hand, the convolutional neural networks\n(CNNs) have brought significant improvements to deep feed-forward neural\nnetworks (FFNNs), as they are able to better reduce spectral variation in the\ninput signal. In this paper, a network architecture called as convolutional\nrecurrent neural network (CRNN) is proposed by combining the CNN and LSTM RNN.\nIn the proposed CRNNs, each speech frame, without adjacent context frames, is\norganized as a number of local feature patches along the frequency axis, and\nthen a LSTM network is performed on each feature patch along the time axis. We\ntrain and compare FFNNs, LSTM RNNs and the proposed LSTM CRNNs at various\nnumber of configurations. Experimental results show that the LSTM CRNNs can\nexceed state-of-the-art speech recognition performance.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 02:48:13 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Li", "Xiangang", ""], ["Wu", "Xihong", ""]]}, {"id": "1610.03618", "submitter": "Chao Li", "authors": "Chao Li, Yi Yang, Min Feng, Srimat Chakradhar, Huiyang Zhou", "title": "Optimizing Memory Efficiency for Deep Convolutional Neural Networks on\n  GPUs", "comments": "Published as a conference paper International Conference on High\n  Performance Computing, Networking, Storage, and Analysis (SC'16), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging large data sets, deep Convolutional Neural Networks (CNNs) achieve\nstate-of-the-art recognition accuracy. Due to the substantial compute and\nmemory operations, however, they require significant execution time. The\nmassive parallel computing capability of GPUs make them as one of the ideal\nplatforms to accelerate CNNs and a number of GPU-based CNN libraries have been\ndeveloped. While existing works mainly focus on the computational efficiency of\nCNNs, the memory efficiency of CNNs have been largely overlooked. Yet CNNs have\nintricate data structures and their memory behavior can have significant impact\non the performance. In this work, we study the memory efficiency of various CNN\nlayers and reveal the performance implication from both data layouts and memory\naccess patterns. Experiments show the universal effect of our proposed\noptimizations on both single layers and various networks, with up to 27.9x for\na single layer and up to 5.6x on the whole networks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 07:02:48 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Li", "Chao", ""], ["Yang", "Yi", ""], ["Feng", "Min", ""], ["Chakradhar", "Srimat", ""], ["Zhou", "Huiyang", ""]]}, {"id": "1610.03628", "submitter": "Carlos Ciller Mr.", "authors": "Stefanos Apostolopoulos, Carlos Ciller, Sandro I. De Zanet, Sebastian\n  Wolf and Raphael Sznitman", "title": "RetiNet: Automatic AMD identification in OCT volumetric data", "comments": "14 pages, 10 figures, Code available", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Coherence Tomography (OCT) provides a unique ability to image the eye\nretina in 3D at micrometer resolution and gives ophthalmologist the ability to\nvisualize retinal diseases such as Age-Related Macular Degeneration (AMD).\nWhile visual inspection of OCT volumes remains the main method for AMD\nidentification, doing so is time consuming as each cross-section within the\nvolume must be inspected individually by the clinician. In much the same way,\nacquiring ground truth information for each cross-section is expensive and time\nconsuming. This fact heavily limits the ability to acquire large amounts of\nground truth, which subsequently impacts the performance of learning-based\nmethods geared at automatic pathology identification. To avoid this burden, we\npropose a novel strategy for automatic analysis of OCT volumes where only\nvolume labels are needed. That is, we train a classifier in a semi-supervised\nmanner to conduct this task. Our approach uses a novel Convolutional Neural\nNetwork (CNN) architecture, that only needs volume-level labels to be trained\nto automatically asses whether an OCT volume is healthy or contains AMD. Our\narchitecture involves first learning a cross-section pathology classifier using\npseudo-labels that could be corrupted and then leverage these towards a more\naccurate volume-level classification. We then show that our approach provides\nexcellent performances on a publicly available dataset and outperforms a number\nof existing automatic techniques.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 07:56:24 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Apostolopoulos", "Stefanos", ""], ["Ciller", "Carlos", ""], ["De Zanet", "Sandro I.", ""], ["Wolf", "Sebastian", ""], ["Sznitman", "Raphael", ""]]}, {"id": "1610.03934", "submitter": "Krupakar Hans", "authors": "Hans Krupakar, Keerthika Rajvel, Bharathi B, Angel Deborah S,\n  Vallidevi Krishnamurthy", "title": "A Survey of Voice Translation Methodologies - Acoustic Dialect Decoder", "comments": "(8 pages, 7 figures, IEEE Digital Xplore paper)", "journal-ref": "2016 International Conference on Information Communication and\n  Embedded Systems (ICICES), Chennai, 2016, pp. 1-9", "doi": "10.1109/ICICES.2016.7518940", "report-no": null, "categories": "cs.CL cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech Translation has always been about giving source text or audio input\nand waiting for system to give translated output in desired form. In this\npaper, we present the Acoustic Dialect Decoder (ADD) - a voice to voice\near-piece translation device. We introduce and survey the recent advances made\nin the field of Speech Engineering, to employ in the ADD, particularly focusing\non the three major processing steps of Recognition, Translation and Synthesis.\nWe tackle the problem of machine understanding of natural language by designing\na recognition unit for source audio to text, a translation unit for source\nlanguage text to target language text, and a synthesis unit for target language\ntext to target language speech. Speech from the surroundings will be recorded\nby the recognition unit present on the ear-piece and translation will start as\nsoon as one sentence is successfully read. This way, we hope to give translated\noutput as and when input is being read. The recognition unit will use Hidden\nMarkov Models (HMMs) Based Tool-Kit (HTK), hybrid RNN systems with gated memory\ncells, and the synthesis unit, HMM based speech synthesis system HTS. This\nsystem will initially be built as an English to Tamil translation device.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 04:10:58 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Krupakar", "Hans", ""], ["Rajvel", "Keerthika", ""], ["B", "Bharathi", ""], ["S", "Angel Deborah", ""], ["Krishnamurthy", "Vallidevi", ""]]}, {"id": "1610.04120", "submitter": "Lina Rojas-Barahona", "authors": "Lina M. Rojas Barahona, Milica Gasic, Nikola Mrk\\v{s}i\\'c, Pei-Hao Su,\n  Stefan Ultes, Tsung-Hsien Wen and Steve Young", "title": "Exploiting Sentence and Context Representations in Deep Neural Models\n  for Spoken Language Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deep learning architecture for the semantic decoder\ncomponent of a Statistical Spoken Dialogue System. In a slot-filling dialogue,\nthe semantic decoder predicts the dialogue act and a set of slot-value pairs\nfrom a set of n-best hypotheses returned by the Automatic Speech Recognition.\nMost current models for spoken language understanding assume (i) word-aligned\nsemantic annotations as in sequence taggers and (ii) delexicalisation, or a\nmapping of input words to domain-specific concepts using heuristics that try to\ncapture morphological variation but that do not scale to other domains nor to\nlanguage variation (e.g., morphology, synonyms, paraphrasing ). In this work\nthe semantic decoder is trained using unaligned semantic annotations and it\nuses distributed semantic representation learning to overcome the limitations\nof explicit delexicalisation. The proposed architecture uses a convolutional\nneural network for the sentence representation and a long-short term memory\nnetwork for the context representation. Results are presented for the publicly\navailable DSTC2 corpus and an In-car corpus which is similar to DSTC2 but has a\nsignificantly higher word error rate (WER).\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 15:11:40 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Barahona", "Lina M. Rojas", ""], ["Gasic", "Milica", ""], ["Mrk\u0161i\u0107", "Nikola", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Wen", "Tsung-Hsien", ""], ["Young", "Steve", ""]]}, {"id": "1610.04161", "submitter": "Shiyu Liang", "authors": "Shiyu Liang and R. Srikant", "title": "Why Deep Neural Networks for Function Approximation?", "comments": "The paper is published at the 5th International Conference on\n  Learning Representations (ICLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recently there has been much interest in understanding why deep neural\nnetworks are preferred to shallow networks. We show that, for a large class of\npiecewise smooth functions, the number of neurons needed by a shallow network\nto approximate a function is exponentially larger than the corresponding number\nof neurons needed by a deep network for a given degree of function\napproximation. First, we consider univariate functions on a bounded interval\nand require a neural network to achieve an approximation error of $\\varepsilon$\nuniformly over the interval. We show that shallow networks (i.e., networks\nwhose depth does not depend on $\\varepsilon$) require\n$\\Omega(\\text{poly}(1/\\varepsilon))$ neurons while deep networks (i.e.,\nnetworks whose depth grows with $1/\\varepsilon$) require\n$\\mathcal{O}(\\text{polylog}(1/\\varepsilon))$ neurons. We then extend these\nresults to certain classes of important multivariate functions. Our results are\nderived for neural networks which use a combination of rectifier linear units\n(ReLUs) and binary step units, two of the most popular type of activation\nfunctions. Our analysis builds on a simple observation: the multiplication of\ntwo bits can be represented by a ReLU.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 16:34:30 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 20:43:04 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Liang", "Shiyu", ""], ["Srikant", "R.", ""]]}, {"id": "1610.04167", "submitter": "Or Sharir", "authors": "Or Sharir, Ronen Tamari, Nadav Cohen and Amnon Shashua", "title": "Tensorial Mixture Models", "comments": "A git repository for reproducing our experiments is available at:\n  https://github.com/HUJI-Deep/Generative-ConvACs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Casting neural networks in generative frameworks is a highly sought-after\nendeavor these days. Contemporary methods, such as Generative Adversarial\nNetworks, capture some of the generative capabilities, but not all. In\nparticular, they lack the ability of tractable marginalization, and thus are\nnot suitable for many tasks. Other methods, based on arithmetic circuits and\nsum-product networks, do allow tractable marginalization, but their performance\nis challenged by the need to learn the structure of a circuit. Building on the\ntractability of arithmetic circuits, we leverage concepts from tensor analysis,\nand derive a family of generative models we call Tensorial Mixture Models\n(TMMs). TMMs assume a simple convolutional network structure, and in addition,\nlend themselves to theoretical analyses that allow comprehensive understanding\nof the relation between their structure and their expressive properties. We\nthus obtain a generative model that is tractable on one hand, and on the other\nhand, allows effective representation of rich distributions in an easily\ncontrolled manner. These two capabilities are brought together in the task of\nclassification under missing data, where TMMs deliver state of the art\naccuracies with seamless implementation and design.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 16:43:32 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 12:13:45 GMT"}, {"version": "v3", "created": "Mon, 6 Mar 2017 07:50:12 GMT"}, {"version": "v4", "created": "Tue, 21 Mar 2017 09:08:31 GMT"}, {"version": "v5", "created": "Sun, 25 Mar 2018 09:42:59 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sharir", "Or", ""], ["Tamari", "Ronen", ""], ["Cohen", "Nadav", ""], ["Shashua", "Amnon", ""]]}, {"id": "1610.04325", "submitter": "Jin-Hwa Kim", "authors": "Jin-Hwa Kim, Kyoung-Woon On, Woosang Lim, Jeonghee Kim, Jung-Woo Ha,\n  Byoung-Tak Zhang", "title": "Hadamard Product for Low-rank Bilinear Pooling", "comments": "13 pages, 1 figure, & appendix. ICLR 2017 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilinear models provide rich representations compared with linear models.\nThey have been applied in various visual tasks, such as object recognition,\nsegmentation, and visual question-answering, to get state-of-the-art\nperformances taking advantage of the expanded representations. However,\nbilinear representations tend to be high-dimensional, limiting the\napplicability to computationally complex tasks. We propose low-rank bilinear\npooling using Hadamard product for an efficient attention mechanism of\nmultimodal learning. We show that our model outperforms compact bilinear\npooling in visual question-answering tasks with the state-of-the-art results on\nthe VQA dataset, having a better parsimonious property.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 04:29:52 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2016 05:31:27 GMT"}, {"version": "v3", "created": "Tue, 14 Feb 2017 05:22:01 GMT"}, {"version": "v4", "created": "Sun, 26 Mar 2017 16:22:47 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["On", "Kyoung-Woon", ""], ["Lim", "Woosang", ""], ["Kim", "Jeonghee", ""], ["Ha", "Jung-Woo", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1610.04973", "submitter": "Amine Ben Khalifa", "authors": "Amine Ben Khalifa and Hichem Frigui", "title": "Multiple Instance Fuzzy Inference Neural Networks", "comments": "Submitted to IEEE Transactions On Cybernetics for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy logic is a powerful tool to model knowledge uncertainty, measurements\nimprecision, and vagueness. However, there is another type of vagueness that\narises when data have multiple forms of expression that fuzzy logic does not\naddress quite well. This is the case for multiple instance learning problems\n(MIL). In MIL, an object is represented by a collection of instances, called a\nbag. A bag is labeled negative if all of its instances are negative, and\npositive if at least one of its instances is positive. Positive bags encode\nambiguity since the instances themselves are not labeled. In this paper, we\nintroduce fuzzy inference systems and neural networks designed to handle bags\nof instances as input and capable of learning from ambiguously labeled data.\nFirst, we introduce the Multiple Instance Sugeno style fuzzy inference\n(MI-Sugeno) that extends the standard Sugeno style inference to handle\nreasoning with multiple instances. Second, we use MI-Sugeno to define and\ndevelop Multiple Instance Adaptive Neuro Fuzzy Inference System (MI-ANFIS). We\nexpand the architecture of the standard ANFIS to allow reasoning with bags and\nderive a learning algorithm using backpropagation to identify the premise and\nconsequent parameters of the network. The proposed inference system is tested\nand validated using synthetic and benchmark datasets suitable for MIL problems.\nWe also apply the proposed MI-ANFIS to fuse the output of multiple\ndiscrimination algorithms for the purpose of landmine detection using Ground\nPenetrating Radar.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 05:07:09 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Khalifa", "Amine Ben", ""], ["Frigui", "Hichem", ""]]}, {"id": "1610.04989", "submitter": "Jiacheng Xu", "authors": "Jiacheng Xu, Danlu Chen, Xipeng Qiu and Xuangjing Huang", "title": "Cached Long Short-Term Memory Neural Networks for Document-Level\n  Sentiment Classification", "comments": "Published as long paper of EMNLP2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks have achieved great success on sentiment\nclassification due to their ability to alleviate feature engineering. However,\none of the remaining challenges is to model long texts in document-level\nsentiment classification under a recurrent architecture because of the\ndeficiency of the memory unit. To address this problem, we present a Cached\nLong Short-Term Memory neural networks (CLSTM) to capture the overall semantic\ninformation in long texts. CLSTM introduces a cache mechanism, which divides\nmemory into several groups with different forgetting rates and thus enables the\nnetwork to keep sentiment information better within a recurrent unit. The\nproposed CLSTM outperforms the state-of-the-art models on three publicly\navailable document-level sentiment analysis datasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 07:28:06 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Xu", "Jiacheng", ""], ["Chen", "Danlu", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuangjing", ""]]}, {"id": "1610.05016", "submitter": "Andrew Palmer", "authors": "Andrew W. Palmer, Robin Vujanic, Andrew J. Hill, Steven J. Scheding", "title": "Weekly maintenance scheduling using exact and genetic methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The weekly maintenance schedule specifies when maintenance activities should\nbe performed on the equipment, taking into account the availability of workers\nand maintenance bays, and other operational constraints. The current approach\nto generating this schedule is labour intensive and requires coordination\nbetween the maintenance schedulers and operations staff to minimise its impact\non the operation of the mine. This paper presents methods for automatically\ngenerating this schedule from the list of maintenance tasks to be performed,\nthe availability roster of the maintenance staff, and time windows in which\neach piece of equipment is available for maintenance. Both Mixed-Integer Linear\nProgramming (MILP) and genetic algorithms are evaluated, with the genetic\nalgorithm shown to significantly outperform the MILP. Two fitness functions for\nthe genetic algorithm are also examined, with a linear fitness function\noutperforming an inverse fitness function by up to 5% for the same calculation\ntime. The genetic algorithm approach is computationally fast, allowing the\nschedule to be rapidly recalculated in response to unexpected delays and\nbreakdowns.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 08:54:47 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Palmer", "Andrew W.", ""], ["Vujanic", "Robin", ""], ["Hill", "Andrew J.", ""], ["Scheding", "Steven J.", ""]]}, {"id": "1610.05231", "submitter": "Sander Van Rijn", "authors": "Sander van Rijn, Hao Wang, Matthijs van Leeuwen, Thomas B\\\"ack", "title": "Evolving the Structure of Evolution Strategies", "comments": "10 pages. Extended (pre-print) version of SSCI 2016 submission", "journal-ref": "2016 IEEE Symposium Series on Computational Intelligence (SSCI),\n  Athens, Greece - 6-9 Dec. 2016, pp. 1-8", "doi": "10.1109/SSCI.2016.7850138", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various variants of the well known Covariance Matrix Adaptation Evolution\nStrategy (CMA-ES) have been proposed recently, which improve the empirical\nperformance of the original algorithm by structural modifications. However, in\npractice it is often unclear which variation is best suited to the specific\noptimization problem at hand. As one approach to tackle this issue, algorithmic\nmechanisms attached to CMA-ES variants are considered and extracted as\nfunctional \\emph{modules}, allowing for combinations of them. This leads to a\nconfiguration space over ES structures, which enables the exploration of\nalgorithm structures and paves the way toward novel algorithm generation.\nSpecifically, eleven modules are incorporated in this framework with two or\nthree alternative configurations for each module, resulting in $4\\,608$\nalgorithms. A self-adaptive Genetic Algorithm (GA) is used to efficiently\nevolve effective ES-structures for given classes of optimization problems,\noutperforming any classical CMA-ES variants from literature. The proposed\napproach is evaluated on noiseless functions from BBOB suite. Furthermore, such\nan observation is again confirmed on different function groups and\ndimensionality, indicating the feasibility of ES configuration on real-world\nproblem classes.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 17:56:28 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["van Rijn", "Sander", ""], ["Wang", "Hao", ""], ["van Leeuwen", "Matthijs", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "1610.05555", "submitter": "Decebal Constantin Mocanu", "authors": "Decebal Constantin Mocanu and Maria Torres Vega and Eric Eaton and\n  Peter Stone and Antonio Liotta", "title": "Online Contrastive Divergence with Generative Replay: Experience Replay\n  without Storing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceived in the early 1990s, Experience Replay (ER) has been shown to be a\nsuccessful mechanism to allow online learning algorithms to reuse past\nexperiences. Traditionally, ER can be applied to all machine learning paradigms\n(i.e., unsupervised, supervised, and reinforcement learning). Recently, ER has\ncontributed to improving the performance of deep reinforcement learning. Yet,\nits application to many practical settings is still limited by the memory\nrequirements of ER, necessary to explicitly store previous observations. To\nremedy this issue, we explore a novel approach, Online Contrastive Divergence\nwith Generative Replay (OCD_GR), which uses the generative capability of\nRestricted Boltzmann Machines (RBMs) instead of recorded past experiences. The\nRBM is trained online, and does not require the system to store any of the\nobserved data points. We compare OCD_GR to ER on 9 real-world datasets,\nconsidering a worst-case scenario (data points arriving in sorted order) as\nwell as a more realistic one (sequential random-order data points). Our results\nshow that in 64.28% of the cases OCD_GR outperforms ER and in the remaining\n35.72% it has an almost equal performance, while having a considerably reduced\nspace complexity (i.e., memory usage) at a comparable time complexity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 12:06:14 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Mocanu", "Decebal Constantin", ""], ["Vega", "Maria Torres", ""], ["Eaton", "Eric", ""], ["Stone", "Peter", ""], ["Liotta", "Antonio", ""]]}, {"id": "1610.05716", "submitter": "Richard Preen", "authors": "Richard J. Preen, Jiseon You, Larry Bull, and Ioannis A. Ieropoulos", "title": "Design Mining Microbial Fuel Cell Cascades", "comments": null, "journal-ref": "Soft Computing (2019), 23(13):4673-4683", "doi": "10.1007/s00500-018-3117-x", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microbial fuel cells (MFCs) perform wastewater treatment and electricity\nproduction through the conversion of organic matter using microorganisms. For\npractical applications, it has been suggested that greater efficiency can be\nachieved by arranging multiple MFC units into physical stacks in a cascade with\nfeedstock flowing sequentially between units. In this paper, we investigate the\nuse of computational intelligence to physically explore and optimise\n(potentially) heterogeneous MFC designs in a cascade, i.e. without simulation.\nConductive structures are 3-D printed and inserted into the anodic chamber of\neach MFC unit, augmenting a carbon fibre veil anode and affecting the\nhydrodynamics, including the feedstock volume and hydraulic retention time, as\nwell as providing unique habitats for microbial colonisation. We show that it\nis possible to use design mining to identify new conductive inserts that\nincrease both the cascade power output and power density.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 17:36:26 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 17:10:00 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Preen", "Richard J.", ""], ["You", "Jiseon", ""], ["Bull", "Larry", ""], ["Ieropoulos", "Ioannis A.", ""]]}, {"id": "1610.05729", "submitter": "Vassilis Vassiliades", "authors": "Vassilis Vassiliades, Konstantinos Chatzilygeroudis, and Jean-Baptiste\n  Mouret", "title": "Using Centroidal Voronoi Tessellations to Scale Up the Multi-dimensional\n  Archive of Phenotypic Elites Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced Multi-dimensional Archive of Phenotypic Elites\n(MAP-Elites) is an evolutionary algorithm capable of producing a large archive\nof diverse, high-performing solutions in a single run. It works by discretizing\na continuous feature space into unique regions according to the desired\ndiscretization per dimension. While simple, this algorithm has a main drawback:\nit cannot scale to high-dimensional feature spaces since the number of regions\nincrease exponentially with the number of dimensions. In this paper, we address\nthis limitation by introducing a simple extension of MAP-Elites that has a\nconstant, pre-defined number of regions irrespective of the dimensionality of\nthe feature space. Our main insight is that methods from computational geometry\ncould partition a high-dimensional space into well-spread geometric regions. In\nparticular, our algorithm uses a centroidal Voronoi tessellation (CVT) to\ndivide the feature space into a desired number of regions; it then places every\ngenerated individual in its closest region, replacing a less fit one if the\nregion is already occupied. We demonstrate the effectiveness of the new\n\"CVT-MAP-Elites\" algorithm in high-dimensional feature spaces through\ncomparisons against MAP-Elites in maze navigation and hexapod locomotion tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 18:18:47 GMT"}, {"version": "v2", "created": "Sat, 29 Jul 2017 12:37:12 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Vassiliades", "Vassilis", ""], ["Chatzilygeroudis", "Konstantinos", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1610.05984", "submitter": "Daniel Hein", "authors": "Daniel Hein, Alexander Hentschel, Thomas Runkler, Steffen Udluft", "title": "Particle Swarm Optimization for Generating Interpretable Fuzzy\n  Reinforcement Learning Policies", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence, Volume 65C,\n  October 2017, Pages 87-98", "doi": "10.1016/j.engappai.2017.07.005", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy controllers are efficient and interpretable system controllers for\ncontinuous state and action spaces. To date, such controllers have been\nconstructed manually or trained automatically either using expert-generated\nproblem-specific cost functions or incorporating detailed knowledge about the\noptimal control strategy. Both requirements for automatic training processes\nare not found in most real-world reinforcement learning (RL) problems. In such\napplications, online learning is often prohibited for safety reasons because\nonline learning requires exploration of the problem's dynamics during policy\ntraining. We introduce a fuzzy particle swarm reinforcement learning (FPSRL)\napproach that can construct fuzzy RL policies solely by training parameters on\nworld models that simulate real system dynamics. These world models are created\nby employing an autonomous machine learning technique that uses previously\ngenerated transition samples of a real system. To the best of our knowledge,\nthis approach is the first to relate self-organizing fuzzy controllers to\nmodel-based batch RL. Therefore, FPSRL is intended to solve problems in domains\nwhere online learning is prohibited, system dynamics are relatively easy to\nmodel from previously generated default policy transition samples, and it is\nexpected that a relatively easily interpretable control policy exists. The\nefficiency of the proposed approach with problems from such domains is\ndemonstrated using three standard RL benchmarks, i.e., mountain car, cart-pole\nbalancing, and cart-pole swing-up. Our experimental results demonstrate\nhigh-performing, interpretable fuzzy policies.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 12:41:52 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 07:22:21 GMT"}, {"version": "v3", "created": "Fri, 5 May 2017 09:01:41 GMT"}, {"version": "v4", "created": "Thu, 29 Jun 2017 07:13:09 GMT"}, {"version": "v5", "created": "Tue, 15 Aug 2017 21:41:03 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Hein", "Daniel", ""], ["Hentschel", "Alexander", ""], ["Runkler", "Thomas", ""], ["Udluft", "Steffen", ""]]}, {"id": "1610.06160", "submitter": "Qianli Liao", "authors": "Qianli Liao, Kenji Kawaguchi, Tomaso Poggio", "title": "Streaming Normalization: Towards Simpler and More Biologically-plausible\n  Normalizations for Online and Recurrent Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We systematically explored a spectrum of normalization algorithms related to\nBatch Normalization (BN) and propose a generalized formulation that\nsimultaneously solves two major limitations of BN: (1) online learning and (2)\nrecurrent learning. Our proposal is simpler and more biologically-plausible.\nUnlike previous approaches, our technique can be applied out of the box to all\nlearning scenarios (e.g., online learning, batch learning, fully-connected,\nconvolutional, feedforward, recurrent and mixed --- recurrent and\nconvolutional) and compare favorably with existing approaches. We also propose\nLp Normalization for normalizing by different orders of statistical moments. In\nparticular, L1 normalization is well-performing, simple to implement, fast to\ncompute, more biologically-plausible and thus ideal for GPU or hardware\nimplementations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 19:34:48 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Liao", "Qianli", ""], ["Kawaguchi", "Kenji", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1610.06258", "submitter": "Jimmy Ba", "authors": "Jimmy Ba, Geoffrey Hinton, Volodymyr Mnih, Joel Z. Leibo, Catalin\n  Ionescu", "title": "Using Fast Weights to Attend to the Recent Past", "comments": "Added [Schmidhuber 1993] citation to the last paragraph of the\n  introduction. Fixed typo appendix A.1 uniform initialization to 1/\\sqrt{H}", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until recently, research on artificial neural networks was largely restricted\nto systems with only two types of variable: Neural activities that represent\nthe current or recent input and weights that learn to capture regularities\namong inputs, outputs and payoffs. There is no good reason for this\nrestriction. Synapses have dynamics at many different time-scales and this\nsuggests that artificial neural networks might benefit from variables that\nchange slower than activities but much faster than the standard weights. These\n\"fast weights\" can be used to store temporary memories of the recent past and\nthey provide a neurally plausible way of implementing the type of attention to\nthe past that has recently proved very helpful in sequence-to-sequence models.\nBy using fast weights we can avoid the need to store copies of neural activity\npatterns.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 01:03:20 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 19:53:07 GMT"}, {"version": "v3", "created": "Mon, 5 Dec 2016 00:14:01 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Ba", "Jimmy", ""], ["Hinton", "Geoffrey", ""], ["Mnih", "Volodymyr", ""], ["Leibo", "Joel Z.", ""], ["Ionescu", "Catalin", ""]]}, {"id": "1610.06268", "submitter": "Piotr Antonik", "authors": "Piotr Antonik, Fran\\c{c}ois Duport, Michiel Hermans, Anteo Smerieri,\n  Marc Haelterman, Serge Massar", "title": "Online Training of an Opto-Electronic Reservoir Computer Applied to\n  Real-Time Channel Equalisation", "comments": "13 pages, 10 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (\n  Volume: 28, Issue: 11, Nov. 2017 )", "doi": "10.1109/TNNLS.2016.2598655", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir Computing is a bio-inspired computing paradigm for processing time\ndependent signals. The performance of its analogue implementation are\ncomparable to other state of the art algorithms for tasks such as speech\nrecognition or chaotic time series prediction, but these are often constrained\nby the offline training methods commonly employed. Here we investigated the\nonline learning approach by training an opto-electronic reservoir computer\nusing a simple gradient descent algorithm, programmed on an FPGA chip. Our\nsystem was applied to wireless communications, a quickly growing domain with an\nincreasing demand for fast analogue devices to equalise the nonlinear distorted\nchannels. We report error rates up to two orders of magnitude lower than\nprevious implementations on this task. We show that our system is particularly\nwell-suited for realistic channel equalisation by testing it on a drifting and\na switching channels and obtaining good performances\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 02:31:09 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Antonik", "Piotr", ""], ["Duport", "Fran\u00e7ois", ""], ["Hermans", "Michiel", ""], ["Smerieri", "Anteo", ""], ["Haelterman", "Marc", ""], ["Massar", "Serge", ""]]}, {"id": "1610.06269", "submitter": "Piotr Antonik", "authors": "Michiel Hermans, Piotr Antonik, Marc Haelterman, Serge Massar", "title": "Embodiment of Learning in Electro-Optical Signal Processors", "comments": "Main text (5 pages, 2 figures) merged with the supplementary material\n  (8 pages, 5 figures)", "journal-ref": "Physical Review Letters 117, 128301 (2016)", "doi": "10.1103/PhysRevLett.117.128301", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delay-coupled electro-optical systems have received much attention for their\ndynamical properties and their potential use in signal processing. In\nparticular it has recently been demonstrated, using the artificial intelligence\nalgorithm known as reservoir computing, that photonic implementations of such\nsystems solve complex tasks such as speech recognition. Here we show how the\nbackpropagation algorithm can be physically implemented on the same\nelectro-optical delay-coupled architecture used for computation with only minor\nchanges to the original design. We find that, compared when the backpropagation\nalgorithm is not used, the error rate of the resulting computing device,\nevaluated on three benchmark tasks, decreases considerably. This demonstrates\nthat electro-optical analog computers can embody a large part of their own\ntraining process, allowing them to be applied to new, more difficult tasks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 02:58:09 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 09:40:07 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Hermans", "Michiel", ""], ["Antonik", "Piotr", ""], ["Haelterman", "Marc", ""], ["Massar", "Serge", ""]]}, {"id": "1610.06283", "submitter": "Mohamed K. Helwa", "authors": "Qiyang Li, Jingxing Qian, Zining Zhu, Xuchan Bao, Mohamed K. Helwa,\n  Angela P. Schoellig", "title": "Deep Neural Networks for Improved, Impromptu Trajectory Tracking of\n  Quadrotors", "comments": "7 pages, 8 figures. Accepted final version. To appear in the proc. of\n  the 2017 IEEE International Conference on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory tracking control for quadrotors is important for applications\nranging from surveying and inspection, to film making. However, designing and\ntuning classical controllers, such as proportional-integral-derivative (PID)\ncontrollers, to achieve high tracking precision can be time-consuming and\ndifficult, due to hidden dynamics and other non-idealities. The Deep Neural\nNetwork (DNN), with its superior capability of approximating abstract,\nnonlinear functions, proposes a novel approach for enhancing trajectory\ntracking control. This paper presents a DNN-based algorithm as an add-on module\nthat improves the tracking performance of a classical feedback controller.\nGiven a desired trajectory, the DNNs provide a tailored reference input to the\ncontroller based on their gained experience. The input aims to achieve a unity\nmap between the desired and the output trajectory. The motivation for this work\nis an interactive \"fly-as-you-draw\" application, in which a user draws a\ntrajectory on a mobile device, and a quadrotor instantly flies that trajectory\nwith the DNN-enhanced control system. Experimental results demonstrate that the\nproposed approach improves the tracking precision for user-drawn trajectories\nafter the DNNs are trained on selected periodic trajectories, suggesting the\nmethod's potential in real-world applications. Tracking errors are reduced by\naround 40-50% for both training and testing trajectories from users,\nhighlighting the DNNs' capability of generalizing knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 04:00:27 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 00:47:25 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Li", "Qiyang", ""], ["Qian", "Jingxing", ""], ["Zhu", "Zining", ""], ["Bao", "Xuchan", ""], ["Helwa", "Mohamed K.", ""], ["Schoellig", "Angela P.", ""]]}, {"id": "1610.06370", "submitter": "Georgios Spithourakis", "authors": "Georgios P. Spithourakis and Steffen E. Petersen and Sebastian Riedel", "title": "Clinical Text Prediction with Numerically Grounded Conditional Language\n  Models", "comments": "Accepted at the 7th International Workshop on Health Text Mining and\n  Information Analysis (LOUHI) EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assisted text input techniques can save time and effort and improve text\nquality. In this paper, we investigate how grounded and conditional extensions\nto standard neural language models can bring improvements in the tasks of word\nprediction and completion. These extensions incorporate a structured knowledge\nbase and numerical values from the text into the context used to predict the\nnext word. Our automated evaluation on a clinical dataset shows extended models\nsignificantly outperform standard models. Our best system uses both\nconditioning and grounding, because of their orthogonal benefits. For word\nprediction with a list of 5 suggestions, it improves recall from 25.03% to\n71.28% and for word completion it improves keystroke savings from 34.35% to\n44.81%, where theoretical bound for this dataset is 58.78%. We also perform a\nqualitative investigation of how models with lower perplexity occasionally fare\nbetter at the tasks. We found that at test time numbers have more influence on\nthe document level than on individual word probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 11:48:30 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Spithourakis", "Georgios P.", ""], ["Petersen", "Steffen E.", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1610.06402", "submitter": "Marc Pickett", "authors": "Marc Pickett and Rami Al-Rfou and Louis Shao and Chris Tar", "title": "A Growing Long-term Episodic & Semantic Memory", "comments": "Submission to NIPS workshop on Continual Learning. 4 page extended\n  abstract plus 5 more pages of references, figures, and supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The long-term memory of most connectionist systems lies entirely in the\nweights of the system. Since the number of weights is typically fixed, this\nbounds the total amount of knowledge that can be learned and stored. Though\nthis is not normally a problem for a neural network designed for a specific\ntask, such a bound is undesirable for a system that continually learns over an\nopen range of domains. To address this, we describe a lifelong learning system\nthat leverages a fast, though non-differentiable, content-addressable memory\nwhich can be exploited to encode both a long history of sequential episodic\nknowledge and semantic knowledge over many episodes for an unbounded number of\ndomains. This opens the door for investigation into transfer learning, and\nleveraging prior knowledge that has been learned over a lifetime of experiences\nto new domains.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 13:29:56 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Pickett", "Marc", ""], ["Al-Rfou", "Rami", ""], ["Shao", "Louis", ""], ["Tar", "Chris", ""]]}, {"id": "1610.06421", "submitter": "Hao Dong", "authors": "Hao Dong, Akara Supratak, Wei Pan, Chao Wu, Paul M. Matthews and Yike\n  Guo", "title": "Mixed Neural Network Approach for Temporal Sleep Stage Classification", "comments": "THIS ARTICLE HAS BEEN PUBLISHED IN IEEE TRANSACTIONS ON NEURAL\n  SYSTEMS AND REHABILITATION ENGINEERING", "journal-ref": null, "doi": "10.1109/TNSRE.2017.2733220", "report-no": null, "categories": "q-bio.NC cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a practical approach to addressing limitations posed by\nuse of single active electrodes in applications for sleep stage classification.\nElectroencephalography (EEG)-based characterizations of sleep stage progression\ncontribute the diagnosis and monitoring of the many pathologies of sleep.\nSeveral prior reports have explored ways of automating the analysis of sleep\nEEG and of reducing the complexity of the data needed for reliable\ndiscrimination of sleep stages in order to make it possible to perform sleep\nstudies at lower cost in the home (rather than only in specialized clinical\nfacilities). However, these reports have involved recordings from electrodes\nplaced on the cranial vertex or occiput, which can be uncomfortable or\ndifficult for subjects to position. Those that have utilized single EEG\nchannels which contain less sleep information, have showed poor classification\nperformance. We have taken advantage of Rectifier Neural Network for feature\ndetection and Long Short-Term Memory (LSTM) network for sequential data\nlearning to optimize classification performance with single electrode\nrecordings. After exploring alternative electrode placements, we found a\ncomfortable configuration of a single-channel EEG on the forehead and have\nshown that it can be integrated with additional electrodes for simultaneous\nrecording of the electroocuolgram (EOG). Evaluation of data from 62 people\n(with 494 hours sleep) demonstrated better performance of our analytical\nalgorithm for automated sleep classification than existing approaches using\nvertex or occipital electrode placements. Use of this recording configuration\nwith neural network deconvolution promises to make clinically indicated home\nsleep studies practical.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2016 18:48:00 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 17:39:53 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 15:00:48 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Dong", "Hao", ""], ["Supratak", "Akara", ""], ["Pan", "Wei", ""], ["Wu", "Chao", ""], ["Matthews", "Paul M.", ""], ["Guo", "Yike", ""]]}, {"id": "1610.06454", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai and Hong Yu", "title": "Reasoning with Memory Augmented Neural Networks for Language\n  Comprehension", "comments": "Accepted at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypothesis testing is an important cognitive process that supports human\nreasoning. In this paper, we introduce a computational hypothesis testing\napproach based on memory augmented neural networks. Our approach involves a\nhypothesis testing loop that reconsiders and progressively refines a previously\nformed hypothesis in order to generate new hypotheses to test. We apply the\nproposed approach to language comprehension task by using Neural Semantic\nEncoders (NSE). Our NSE models achieve the state-of-the-art results showing an\nabsolute improvement of 1.2% to 2.6% accuracy over previous results obtained by\nsingle and ensemble systems on standard machine comprehension benchmarks such\nas the Children's Book Test (CBT) and Who-Did-What (WDW) news article datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 15:17:04 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 17:06:17 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Yu", "Hong", ""]]}, {"id": "1610.06483", "submitter": "Oleksii Tyshchenko Dr", "authors": "Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko, Daria S. Kopaliani", "title": "An Extended Neo-Fuzzy Neuron and its Adaptive Learning Algorithm", "comments": null, "journal-ref": "I.J. Intelligent Systems and Applications, 2015, 02, 21-26", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modification of the neo-fuzzy neuron is proposed (an extended neo-fuzzy\nneuron (ENFN)) that is characterized by improved approximating properties. An\nadaptive learning algorithm is proposed that has both tracking and smoothing\nproperties. An ENFN distinctive feature is its computational simplicity\ncompared to other artificial neural networks and neuro-fuzzy systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:25:38 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Kopaliani", "Daria S.", ""]]}, {"id": "1610.06484", "submitter": "Oleksii Tyshchenko Dr", "authors": "Zhengbing Hu, Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Olena\n  O. Boiko", "title": "An Evolving Cascade System Based on A Set Of Neo Fuzzy Nodes", "comments": null, "journal-ref": "I.J. Intelligent Systems and Applications, 2016, 9, 1-7", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neo-fuzzy elements are used as nodes for an evolving cascade system. The\nproposed system can tune both its parameters and architecture in an online\nmode. It can be used for solving a wide range of Data Mining tasks (namely time\nseries forecasting). The evolving cascade system with neo-fuzzy nodes can\nprocess rather large data sets with high speed and effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:27:11 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Hu", "Zhengbing", ""], ["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Boiko", "Olena O.", ""]]}, {"id": "1610.06485", "submitter": "Oleksii Tyshchenko Dr", "authors": "Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Daria S. Kopaliani", "title": "A Multidimensional Cascade Neuro-Fuzzy System with Neuron Pool\n  Optimization in Each Cascade", "comments": null, "journal-ref": "I.J. Information Technology and Computer Science, 2014, 08, 11-17", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new architecture and learning algorithms for the multidimensional hybrid\ncascade neural network with neuron pool optimization in each cascade are\nproposed in this paper. The proposed system differs from the well-known cascade\nsystems in its capability to process multidimensional time series in an online\nmode, which makes it possible to process non-stationary stochastic and chaotic\nsignals with the required accuracy. Compared to conventional analogs, the\nproposed system provides computational simplicity and possesses both tracking\nand filtering capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:27:51 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Kopaliani", "Daria S.", ""]]}, {"id": "1610.06486", "submitter": "Oleksii Tyshchenko Dr", "authors": "Zhengbing Hu, Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Olena\n  O. Boiko", "title": "Adaptive Forecasting of Non-Stationary Nonlinear Time Series Based on\n  the Evolving Weighted Neuro-Neo-Fuzzy-ANARX-Model", "comments": null, "journal-ref": "I.J. Information Technology and Computer Science, 2016, 10, 1-10", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An evolving weighted neuro-neo-fuzzy-ANARX model and its learning procedures\nare introduced in the article. This system is basically used for time series\nforecasting. This system may be considered as a pool of elements that process\ndata in a parallel manner. The proposed evolving system may provide online\nprocessing data streams.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:28:43 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Hu", "Zhengbing", ""], ["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Boiko", "Olena O.", ""]]}, {"id": "1610.06488", "submitter": "Oleksii Tyshchenko Dr", "authors": "Yevgeniy V. Bodyanskiy, Oleksii K. Tyshchenko and Anastasiia O.\n  Deineko", "title": "An Evolving Neuro-Fuzzy System with Online Learning/Self-learning", "comments": null, "journal-ref": "I.J. Modern Education and Computer Science, 2015, 2, 1-7", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An architecture of a new neuro-fuzzy system is proposed. The basic idea of\nthis approach is to tune both synaptic weights and membership functions with\nthe help of the supervised learning and self-learning paradigms. The approach\nto solving the problem has to do with evolving online neuro-fuzzy systems that\ncan process data under uncertainty conditions. The results prove the\neffectiveness of the developed architecture and the learning procedure.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 16:29:40 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Bodyanskiy", "Yevgeniy V.", ""], ["Tyshchenko", "Oleksii K.", ""], ["Deineko", "Anastasiia O.", ""]]}, {"id": "1610.07161", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Johannes Bill, Ilja Bytschok, Johannes Schemmel,\n  Karlheinz Meier", "title": "Stochastic inference with spiking neurons in the high-conductance state", "comments": null, "journal-ref": "Phys. Rev. E 94, 042312 (2016)", "doi": "10.1103/PhysRevE.94.042312", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The highly variable dynamics of neocortical circuits observed in vivo have\nbeen hypothesized to represent a signature of ongoing stochastic inference but\nstand in apparent contrast to the deterministic response of neurons measured in\nvitro. Based on a propagation of the membrane autocorrelation across spike\nbursts, we provide an analytical derivation of the neural activation function\nthat holds for a large parameter space, including the high-conductance state.\nOn this basis, we show how an ensemble of leaky integrate-and-fire neurons with\nconductance-based synapses embedded in a spiking environment can attain the\ncorrect firing statistics for sampling from a well-defined target distribution.\nFor recurrent networks, we examine convergence toward stationarity in computer\nsimulations and demonstrate sample-based Bayesian inference in a mixed\ngraphical model. This points to a new computational role of high-conductance\nstates and establishes a rigorous link between deterministic neuron models and\nfunctional stochastic dynamics on the network level.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 12:27:05 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Bill", "Johannes", ""], ["Bytschok", "Ilja", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1610.07258", "submitter": "Zhiguang Wang", "authors": "Zhiguang Wang, Wei Song, Lu Liu, Fan Zhang, Junxiao Xue, Yangdong Ye,\n  Ming Fan, Mingliang Xu", "title": "Representation Learning with Deconvolution for Multivariate Time Series\n  Classification and Visualization", "comments": "arXiv admin note: text overlap with arXiv:1505.04366 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model based on the deconvolutional networks and SAX\ndiscretization to learn the representation for multivariate time series.\nDeconvolutional networks fully exploit the advantage the powerful\nexpressiveness of deep neural networks in the manner of unsupervised learning.\nWe design a network structure specifically to capture the cross-channel\ncorrelation with deconvolution, forcing the pooling operation to perform the\ndimension reduction along each position in the individual channel.\nDiscretization based on Symbolic Aggregate Approximation is applied on the\nfeature vectors to further extract the bag of features. We show how this\nrepresentation and bag of features helps on classification. A full comparison\nwith the sequence distance based approach is provided to demonstrate the\neffectiveness of our approach on the standard datasets. We further build the\nMarkov matrix from the discretized representation from the deconvolution to\nvisualize the time series as complex networks, which show more class-specific\nstatistical properties and clear structures with respect to different labels.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 01:53:12 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2016 00:17:45 GMT"}, {"version": "v3", "created": "Sat, 26 Nov 2016 21:02:49 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Wang", "Zhiguang", ""], ["Song", "Wei", ""], ["Liu", "Lu", ""], ["Zhang", "Fan", ""], ["Xue", "Junxiao", ""], ["Ye", "Yangdong", ""], ["Fan", "Ming", ""], ["Xu", "Mingliang", ""]]}, {"id": "1610.07355", "submitter": "Timoth\\'ee Masquelier Dr", "authors": "Timoth\\'ee Masquelier", "title": "STDP allows close-to-optimal spatiotemporal spike pattern detection by\n  single coincidence detector neurons", "comments": "12 pages, 6 figures, 1 table", "journal-ref": "Neuroscience 2017", "doi": "10.1016/j.neuroscience.2017.06.032", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By recording multiple cells simultaneously, electrophysiologists have found\nevidence for repeating spatiotemporal spike patterns, which can carry\ninformation. How this information is extracted by downstream neurons is\nunclear. In this theoretical paper, we investigate to what extent a single cell\ncould detect a given spike pattern and what the optimal parameters to do so\nare, in particular the membrane time constant $\\tau$. Using a leaky\nintegrate-and-fire (LIF) neuron with instantaneous synapses and homogeneous\nPoisson input, we were able to compute this optimum analytically. Our results\nindicate that a relatively small $\\tau$ (at most a few tens of ms) is usually\noptimal, even when the pattern is much longer. This is somewhat counter\nintuitive as the resulting detector ignores most of the pattern, due to its\nfast memory decay. Next, we wondered if spike-timing-dependent plasticity\n(STDP) could enable a neuron to reach the theoretical optimum. We simulated a\nLIF neuron equipped with additive spike-timing-dependent potentiation and\nhomeostatic rate-based depression, and repeatedly exposed it to a given input\nspike pattern. As in previous studies, the LIF progressively became selective\nto the repeating pattern with no supervision, even when the pattern was\nembedded in Poisson activity. Here we show that, using certain STDP parameters,\nthe resulting pattern detector can be optimal. Taken together, these results\nmay explain how humans can learn repeating visual or auditory sequences. Long\nsequences could be recognized thanks to coincidence detectors working at a much\nshorter timescale. This is consistent with the fact that recognition is still\npossible if a sound sequence is compressed, played backward, or scrambled using\n10ms bins. Coincidence detection is a simple yet powerful mechanism, which\ncould be the main function of neurons in the brain.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 10:54:28 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 12:12:00 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "1610.07647", "submitter": "Mark Neumann", "authors": "Mark Neumann, Pontus Stenetorp, Sebastian Riedel", "title": "Learning to Reason With Adaptive Computation", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-hop inference is necessary for machine learning systems to successfully\nsolve tasks such as Recognising Textual Entailment and Machine Reading. In this\nwork, we demonstrate the effectiveness of adaptive computation for learning the\nnumber of inference steps required for examples of different complexity and\nthat learning the correct number of inference steps is difficult. We introduce\nthe first model involving Adaptive Computation Time which provides a small\nperformance benefit on top of a similar model without an adaptive component as\nwell as enabling considerable insight into the reasoning process of the model.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 20:48:04 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 19:35:11 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Neumann", "Mark", ""], ["Stenetorp", "Pontus", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1610.07675", "submitter": "Kamil Rocki", "authors": "Kamil Rocki, Tomasz Kornuta, Tegan Maharaj", "title": "Surprisal-Driven Zoneout", "comments": "Published at the Continual Learning and Deep Networks Workshop; NIPS\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method of regularization for recurrent neural networks\ncalled suprisal-driven zoneout. In this method, states zoneout (maintain their\nprevious value rather than updating), when the suprisal (discrepancy between\nthe last state's prediction and target) is small. Thus regularization is\nadaptive and input-driven on a per-neuron basis. We demonstrate the\neffectiveness of this idea by achieving state-of-the-art bits per character of\n1.31 on the Hutter Prize Wikipedia dataset, significantly reducing the gap to\nthe best known highly-engineered compression methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 22:38:52 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 19:55:16 GMT"}, {"version": "v3", "created": "Mon, 31 Oct 2016 15:18:11 GMT"}, {"version": "v4", "created": "Thu, 3 Nov 2016 17:09:23 GMT"}, {"version": "v5", "created": "Thu, 24 Nov 2016 06:40:26 GMT"}, {"version": "v6", "created": "Tue, 13 Dec 2016 23:32:24 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Rocki", "Kamil", ""], ["Kornuta", "Tomasz", ""], ["Maharaj", "Tegan", ""]]}, {"id": "1610.07690", "submitter": "\\v{Z}iga Sajovic", "authors": "\\v{Z}iga Sajovic, Martin Vuk", "title": "Operational Calculus for Differentiable Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.NE math.FA math.OA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a theoretical model for differentiable programming.\nWe construct an algebraic language that encapsulates formal semantics of\ndifferentiable programs by way of Operational Calculus. The algebraic nature of\nOperational Calculus can alter the properties of the programs that are\nexpressed within the language and transform them into their solutions.\n  In our model programs are elements of programming spaces and viewed as maps\nfrom the virtual memory space to itself. Virtual memory space is an algebra of\nprograms, an algebraic data structure one can calculate with. We define the\noperator of differentiation ($\\partial$) on programming spaces and, using its\npowers, implement the general shift operator and the operator of program\ncomposition. We provide the formula for the expansion of a differentiable\nprogram into an infinite tensor series in terms of the powers of $\\partial$. We\nexpress the operator of program composition in terms of the generalized shift\noperator and $\\partial$, which implements a differentiable composition in the\nlanguage. Such operators serve as abstractions over the tensor series algebra,\nas main actors in our language.\n  We demonstrate our models usefulness in differentiable programming by using\nit to analyse iterators, deriving fractional iterations and their iterating\nvelocities, and explicitly solve the special case of ReduceSum.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 00:45:10 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 19:08:27 GMT"}, {"version": "v3", "created": "Thu, 5 Jan 2017 18:20:55 GMT"}, {"version": "v4", "created": "Sun, 5 Feb 2017 15:38:54 GMT"}, {"version": "v5", "created": "Tue, 14 Aug 2018 20:27:03 GMT"}, {"version": "v6", "created": "Sun, 6 Jan 2019 14:52:56 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Sajovic", "\u017diga", ""], ["Vuk", "Martin", ""]]}, {"id": "1610.07752", "submitter": "Mrutyunjaya Panda", "authors": "Mrutyunjaya Panda", "title": "Big Models for Big Data using Multi objective averaged one dependence\n  estimators", "comments": "21 pages, 2 Figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though, many researchers tried to explore the various possibilities on\nmulti objective feature selection, still it is yet to be explored with best of\nits capabilities in data mining applications rather than going for developing\nnew ones. In this paper, multi-objective evolutionary algorithm ENORA is used\nto select the features in a multi-class classification problem. The fusion of\nAnDE (averaged n-dependence estimators) with n=1, a variant of naive Bayes with\nefficient feature selection by ENORA is performed in order to obtain a fast\nhybrid classifier which can effectively learn from big data. This method aims\nat solving the problem of finding optimal feature subset from full data which\nat present still remains to be a difficult problem. The efficacy of the\nobtained classifier is extensively evaluated with a range of most popular 21\nreal world dataset, ranging from small to big. The results obtained are\nencouraging in terms of time, Root mean square error, zero-one loss and\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 07:11:11 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Panda", "Mrutyunjaya", ""]]}, {"id": "1610.07857", "submitter": "Yevgeniy Bodyanskiy", "authors": "Yevgeniy Bodyanskiy, Olena Vynokurova, Volodymyr Savvo, Tatiana\n  Tverdokhlib, Pavlo Mulesa", "title": "Hybrid clustering-classification neural network in the medical\n  diagnostics of reactive arthritis", "comments": null, "journal-ref": "International Journal of Intelligent Systems and Applications,\n  2016, Vol. 8, No. 8, pp.1-9", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hybrid clustering-classification neural network is proposed. This network\nallows increasing a quality of information processing under the condition of\noverlapping classes due to the rational choice of a learning rate parameter and\nintroducing a special procedure of fuzzy reasoning in the clustering process,\nwhich occurs both with an external learning signal (supervised) and without the\none (unsupervised). As similarity measure neighborhood function or membership\none, cosine structures are used, which allow to provide a high flexibility due\nto self-learning-learning process and to provide some new useful properties.\nMany realized experiments have confirmed the efficiency of proposed hybrid\nclustering-classification neural network; also, this network was used for\nsolving diagnostics task of reactive arthritis.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 09:11:53 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Bodyanskiy", "Yevgeniy", ""], ["Vynokurova", "Olena", ""], ["Savvo", "Volodymyr", ""], ["Tverdokhlib", "Tatiana", ""], ["Mulesa", "Pavlo", ""]]}, {"id": "1610.09460", "submitter": "Daniel L. Marino", "authors": "Daniel L. Marino, Kasun Amarasinghe, Milos Manic", "title": "Building Energy Load Forecasting using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1109/IECON.2016.7793413", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring sustainability demands more efficient energy management with\nminimized energy wastage. Therefore, the power grid of the future should\nprovide an unprecedented level of flexibility in energy management. To that\nend, intelligent decision making requires accurate predictions of future energy\ndemand/load, both at aggregate and individual site level. Thus, energy load\nforecasting have received increased attention in the recent past, however has\nproven to be a difficult problem. This paper presents a novel energy load\nforecasting methodology based on Deep Neural Networks, specifically Long Short\nTerm Memory (LSTM) algorithms. The presented work investigates two variants of\nthe LSTM: 1) standard LSTM and 2) LSTM-based Sequence to Sequence (S2S)\narchitecture. Both methods were implemented on a benchmark data set of\nelectricity consumption data from one residential customer. Both architectures\nwhere trained and tested on one hour and one-minute time-step resolution\ndatasets. Experimental results showed that the standard LSTM failed at\none-minute resolution data while performing well in one-hour resolution data.\nIt was shown that S2S architecture performed well on both datasets. Further, it\nwas shown that the presented methods produced comparable results with the other\ndeep learning methods for energy forecasting in literature.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 06:02:03 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Marino", "Daniel L.", ""], ["Amarasinghe", "Kasun", ""], ["Manic", "Milos", ""]]}, {"id": "1610.09493", "submitter": "Witold Dyrka", "authors": "Jakub Czakon, Filip Drapejkowski, Grzegorz Zurek, Piotr Giedziun,\n  Jacek Zebrowski, Witold Dyrka", "title": "Machine learning methods for accurate delineation of tumors in PET\n  images", "comments": "19th International Conference on Medical Image Computing and Computer\n  Assisted Intervention (MICCAI 2016) - PETSEG challenge, Athens, Greece,\n  21/10/2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In oncology, Positron Emission Tomography imaging is widely used in\ndiagnostics of cancer metastases, in monitoring of progress in course of the\ncancer treatment, and in planning radiotherapeutic interventions. Accurate and\nreproducible delineation of the tumor in the Positron Emission Tomography scans\nremains a difficult task, despite being crucial for delivering appropriate\nradiation dose, minimizing adverse side-effects of the therapy, and reliable\nevaluation of treatment. In this piece of research we attempt to solve the\nproblem of automated delineation of the tumor using 3d implementations of the\nspatial distance weighted fuzzy c-means, the deep convolutional neural network\nand a dictionary model. The methods, in diverse ways, combine intensity and\nspatial information.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 11:56:38 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Czakon", "Jakub", ""], ["Drapejkowski", "Filip", ""], ["Zurek", "Grzegorz", ""], ["Giedziun", "Piotr", ""], ["Zebrowski", "Jacek", ""], ["Dyrka", "Witold", ""]]}, {"id": "1610.09608", "submitter": "Enmei Tu", "authors": "Enmei Tu, Guanghao Zhang, Lily Rachmawati, Eshan Rajabally and\n  Guang-Bin Huang", "title": "A Theoretical Study of The Relationship Between Whole An ELM Network and\n  Its Subnetworks", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A biological neural network is constituted by numerous subnetworks and\nmodules with different functionalities. For an artificial neural network, the\nrelationship between a network and its subnetworks is also important and useful\nfor both theoretical and algorithmic research, i.e. it can be exploited to\ndevelop incremental network training algorithm or parallel network training\nalgorithm. In this paper we explore the relationship between an ELM neural\nnetwork and its subnetworks. To the best of our knowledge, we are the first to\nprove a theorem that shows an ELM neural network can be scattered into\nsubnetworks and its optimal solution can be constructed recursively by the\noptimal solutions of these subnetworks. Based on the theorem we also present\ntwo algorithms to train a large ELM neural network efficiently: one is a\nparallel network training algorithm and the other is an incremental network\ntraining algorithm. The experimental results demonstrate the usefulness of the\ntheorem and the validity of the developed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 06:34:19 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Tu", "Enmei", ""], ["Zhang", "Guanghao", ""], ["Rachmawati", "Lily", ""], ["Rajabally", "Eshan", ""], ["Huang", "Guang-Bin", ""]]}, {"id": "1610.09609", "submitter": "Keyu Lu", "authors": "Keyu Lu and Jian Li and Xiangjing An and Hangen He", "title": "Generalized Haar Filter based Deep Networks for Real-Time Object\n  Detection in Traffic Scene", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision-based object detection is one of the fundamental functions in numerous\ntraffic scene applications such as self-driving vehicle systems and advance\ndriver assistance systems (ADAS). However, it is also a challenging task due to\nthe diversity of traffic scene and the storage, power and computing source\nlimitations of the platforms for traffic scene applications. This paper\npresents a generalized Haar filter based deep network which is suitable for the\nobject detection tasks in traffic scene. In this approach, we first decompose a\nobject detection task into several easier local regression tasks. Then, we\nhandle the local regression tasks by using several tiny deep networks which\nsimultaneously output the bounding boxes, categories and confidence scores of\ndetected objects. To reduce the consumption of storage and computing resources,\nthe weights of the deep networks are constrained to the form of generalized\nHaar filter in training phase. Additionally, we introduce the strategy of\nsparse windows generation to improve the efficiency of the algorithm. Finally,\nwe perform several experiments to validate the performance of our proposed\napproach. Experimental results demonstrate that the proposed approach is both\nefficient and effective in traffic scene compared with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 07:02:57 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Lu", "Keyu", ""], ["Li", "Jian", ""], ["An", "Xiangjing", ""], ["He", "Hangen", ""]]}, {"id": "1610.09639", "submitter": "Sajid Anwar", "authors": "Sajid Anwar, Wonyong Sung", "title": "Compact Deep Convolutional Neural Networks With Coarse Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning capability of a neural network improves with increasing depth at\nhigher computational costs. Wider layers with dense kernel connectivity\npatterns furhter increase this cost and may hinder real-time inference. We\npropose feature map and kernel level pruning for reducing the computational\ncomplexity of a deep convolutional neural network. Pruning feature maps reduces\nthe width of a layer and hence does not need any sparse representation.\nFurther, kernel pruning converts the dense connectivity pattern into a sparse\none. Due to coarse nature, these pruning granularities can be exploited by GPUs\nand VLSI based implementations. We propose a simple and generic strategy to\nchoose the least adversarial pruning masks for both granularities. The pruned\nnetworks are retrained which compensates the loss in accuracy. We obtain the\nbest pruning ratios when we prune a network with both granularities.\nExperiments with the CIFAR-10 dataset show that more than 85% sparsity can be\ninduced in the convolution layers with less than 1% increase in the\nmissclassification rate of the baseline network.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 11:57:20 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Anwar", "Sajid", ""], ["Sung", "Wonyong", ""]]}, {"id": "1610.09704", "submitter": "Franck Dernoncourt", "authors": "Ji Young Lee, Franck Dernoncourt, Ozlem Uzuner, Peter Szolovits", "title": "Feature-Augmented Neural Networks for Patient Note De-identification", "comments": "Accepted as a conference paper at COLING ClinicalNLP 2016. The first\n  two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Patient notes contain a wealth of information of potentially great interest\nto medical investigators. However, to protect patients' privacy, Protected\nHealth Information (PHI) must be removed from the patient notes before they can\nbe legally released, a process known as patient note de-identification. The\nmain objective for a de-identification system is to have the highest possible\nrecall. Recently, the first neural-network-based de-identification system has\nbeen proposed, yielding state-of-the-art results. Unlike other systems, it does\nnot rely on human-engineered features, which allows it to be quickly deployed,\nbut does not leverage knowledge from human experts or from electronic health\nrecords (EHRs). In this work, we explore a method to incorporate\nhuman-engineered features as well as features derived from EHRs to a\nneural-network-based de-identification system. Our results show that the\naddition of features, especially the EHR-derived features, further improves the\nstate-of-the-art in patient note de-identification, including for some of the\nmost sensitive PHI types such as patient names. Since in a real-life setting\npatient notes typically come with EHRs, we recommend developers of\nde-identification systems to leverage the information EHRs contain.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 20:09:46 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Lee", "Ji Young", ""], ["Dernoncourt", "Franck", ""], ["Uzuner", "Ozlem", ""], ["Szolovits", "Peter", ""]]}, {"id": "1610.09882", "submitter": "Amit Mishra", "authors": "Jarryd Son and Amit Kumar Mishra", "title": "A Survey of Brain Inspired Technologies for Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive engineering is a multi-disciplinary field and hence it is difficult\nto find a review article consolidating the leading developments in the field.\nThe in-credible pace at which technology is advancing pushes the boundaries of\nwhat is achievable in cognitive engineering. There are also differing\napproaches to cognitive engineering brought about from the multi-disciplinary\nnature of the field and the vastness of possible applications. Thus research\ncommunities require more frequent reviews to keep up to date with the latest\ntrends. In this paper we shall dis-cuss some of the approaches to cognitive\nengineering holistically to clarify the reasoning behind the different\napproaches and to highlight their strengths and weaknesses. We shall then show\nhow developments from seemingly disjointed views could be integrated to achieve\nthe same goal of creating cognitive machines. By reviewing the major\ncontributions in the different fields and showing the potential for a combined\napproach, this work intends to assist the research community in devising more\nunified methods and techniques for developing cognitive machines.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 11:58:29 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Son", "Jarryd", ""], ["Mishra", "Amit Kumar", ""]]}, {"id": "1610.09887", "submitter": "Itay Safran", "authors": "Itay Safran, Ohad Shamir", "title": "Depth-Width Tradeoffs in Approximating Natural Functions with Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide several new depth-based separation results for feed-forward neural\nnetworks, proving that various types of simple and natural functions can be\nbetter approximated using deeper networks than shallower ones, even if the\nshallower networks are much larger. This includes indicators of balls and\nellipses; non-linear functions which are radial with respect to the $L_1$ norm;\nand smooth non-linear functions. We also show that these gaps can be observed\nexperimentally: Increasing the depth indeed allows better learning than\nincreasing width, when training neural networks to learn an indicator of a unit\nball.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 12:08:46 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 18:07:37 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 12:08:04 GMT"}], "update_date": "2020-05-14", "authors_parsed": [["Safran", "Itay", ""], ["Shamir", "Ohad", ""]]}, {"id": "1610.09975", "submitter": "Hasim Sak", "authors": "Hagen Soltau, Hank Liao, Hasim Sak", "title": "Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large\n  Vocabulary Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present results that show it is possible to build a competitive, greatly\nsimplified, large vocabulary continuous speech recognition system with whole\nwords as acoustic units. We model the output vocabulary of about 100,000 words\ndirectly using deep bi-directional LSTM RNNs with CTC loss. The model is\ntrained on 125,000 hours of semi-supervised acoustic training data, which\nenables us to alleviate the data sparsity problem for word models. We show that\nthe CTC word models work very well as an end-to-end all-neural speech\nrecognition model without the use of traditional context-dependent sub-word\nphone units that require a pronunciation lexicon, and without any language\nmodel removing the need to decode. We demonstrate that the CTC word models\nperform better than a strong, more complex, state-of-the-art baseline with\nsub-word units.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 15:36:42 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Soltau", "Hagen", ""], ["Liao", "Hank", ""], ["Sak", "Hasim", ""]]}, {"id": "1610.10087", "submitter": "Chuan-Yung Tsai", "authors": "Chuan-Yung Tsai, Andrew Saxe, David Cox", "title": "Tensor Switching Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel neural network algorithm, the Tensor Switching (TS)\nnetwork, which generalizes the Rectified Linear Unit (ReLU) nonlinearity to\ntensor-valued hidden units. The TS network copies its entire input vector to\ndifferent locations in an expanded representation, with the location determined\nby its hidden unit activity. In this way, even a simple linear readout from the\nTS representation can implement a highly expressive deep-network-like function.\nThe TS network hence avoids the vanishing gradient problem by construction, at\nthe cost of larger representation size. We develop several methods to train the\nTS network, including equivalent kernels for infinitely wide and deep TS\nnetworks, a one-pass linear learning algorithm, and two\nbackpropagation-inspired representation learning algorithms. Our experimental\nresults demonstrate that the TS network is indeed more expressive and\nconsistently learns faster than standard ReLU networks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 19:44:50 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Tsai", "Chuan-Yung", ""], ["Saxe", "Andrew", ""], ["Cox", "David", ""]]}]